{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all recipe instances for the given badges.", "response": "def get_recipe_instances(self, badges=None, excluded=None):\n        \"\"\"\n        Returns all recipe instances or just those for the given badges.\n        \"\"\"\n        if badges:\n            if not isinstance(badges, (list, tuple)):\n                badges = [badges]\n\n        if excluded:\n            if not isinstance(excluded, (list, tuple)):\n                excluded = [excluded]\n            badges = list(set(self.registered) - set(excluded))\n\n        if badges:\n            valid, invalid = self.get_recipe_instances_for_badges(badges=badges)\n            return valid\n\n        return self.recipes.values()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a list of badges and returns a tuple of valid and invalid recipe instances.", "response": "def get_recipe_instances_for_badges(self, badges):\n        \"\"\"\n        Takes a list of badge slugs and returns a tuple: ``(valid, invalid)``.\n        \"\"\"\n        from .exceptions import BadgeNotFound\n\n        valid, invalid = [], []\n\n        if not isinstance(badges, (list, tuple)):\n            badges = [badges]\n\n        for badge in badges:\n            try:\n                recipe = self.get_recipe_instance(badge)\n                valid.append(recipe)\n            except BadgeNotFound:\n                logger.debug('\u2718 Badge \"%s\" has not been registered', badge)\n                invalid.append(badge)\n\n        return (valid, invalid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_taskqueue_stub(self, **stub_kwargs):\n        task_args = {}\n        # root_path is required so the stub can find 'queue.yaml' or 'queue.yml'\n        if 'root_path' not in stub_kwargs:\n            for p in self._app_path:\n                # support --gae-application values that may be a .yaml file\n                dir_ = os.path.dirname(p) if os.path.isfile(p) else p\n                if os.path.isfile(os.path.join(dir_, 'queue.yaml')) or \\\n                        os.path.isfile(os.path.join(dir_, 'queue.yml')):\n                    task_args['root_path'] = dir_\n                    break\n        task_args.update(stub_kwargs)\n        self.testbed.init_taskqueue_stub(**task_args)", "response": "Initializes the taskqueue stub using nosegae config magic"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_datastore_v3_stub(self, **stub_kwargs):\n        task_args = dict(datastore_file=self._data_path)\n        task_args.update(stub_kwargs)\n        self.testbed.init_datastore_v3_stub(**task_args)", "response": "Initializes the datastore stub using nosegae config magic"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the user stub using nosegae config magic", "response": "def _init_user_stub(self, **stub_kwargs):\n        \"\"\"Initializes the user stub using nosegae config magic\"\"\"\n        # do a little dance to keep the same kwargs for multiple tests in the same class\n        # because the user stub will barf if you pass these items into it\n        # stub = user_service_stub.UserServiceStub(**stub_kw_args)\n        # TypeError: __init__() got an unexpected keyword argument 'USER_IS_ADMIN'\n        task_args = stub_kwargs.copy()\n        self.testbed.setup_env(overwrite=True,\n                               USER_ID=task_args.pop('USER_ID', 'testuser'),\n                               USER_EMAIL=task_args.pop('USER_EMAIL', 'testuser@example.org'),\n                               USER_IS_ADMIN=task_args.pop('USER_IS_ADMIN', '1'))\n        self.testbed.init_user_stub(**task_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the modules stub based off of your current yaml files Implements solution from google. appengine. api. request_info. init_modules_stub", "response": "def _init_modules_stub(self, **_):\n        \"\"\"Initializes the modules stub based off of your current yaml files\n\n        Implements solution from\n        http://stackoverflow.com/questions/28166558/invalidmoduleerror-when-using-testbed-to-unit-test-google-app-engine\n        \"\"\"\n        from google.appengine.api import request_info\n        # edit all_versions per modules & versions thereof needing tests\n        all_versions = {}  # {'default': [1], 'andsome': [2], 'others': [1]}\n        def_versions = {}  # {m: all_versions[m][0] for m in all_versions}\n        m2h = {}  # {m: {def_versions[m]: 'localhost:8080'} for m in def_versions}\n        for module in self.configuration.modules:\n            module_name = module._module_name or 'default'\n            module_version = module._version or '1'\n            all_versions[module_name] = [module_version]\n            def_versions[module_name] = module_version\n            m2h[module_name] = {module_version: 'localhost:8080'}\n\n        request_info._local_dispatcher = request_info._LocalFakeDispatcher(\n            module_names=list(all_versions),\n            module_name_to_versions=all_versions,\n            module_name_to_default_versions=def_versions,\n            module_name_to_version_to_hostname=m2h)\n        self.testbed.init_modules_stub()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _init_stub(self, stub_init, **stub_kwargs):\n        getattr(self.testbed, stub_init, lambda **kwargs: None)(**stub_kwargs)", "response": "Initializes all other stubs for consistency sake"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef html_for_env_var(key):\n    value = os.getenv(key)\n    return KEY_VALUE_TEMPLATE.format(key, value)", "response": "Returns an HTML snippet for an environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef html_for_cgi_argument(argument, form):\n    value = form[argument].value if argument in form else None\n    return KEY_VALUE_TEMPLATE.format(argument, value)", "response": "Returns an HTML snippet for a CGI argument in a form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an HTML snippet for a Modules API method.", "response": "def html_for_modules_method(method_name, *args, **kwargs):\n    \"\"\"Returns an HTML snippet for a Modules API method.\n\n    Args:\n        method_name: A string containing a Modules API method.\n        args: Positional arguments to be passed to the method.\n        kwargs: Keyword arguments to be passed to the method.\n\n    Returns:\n        String HTML representing the Modules API method and value.\n    \"\"\"\n    method = getattr(modules, method_name)\n    value = method(*args, **kwargs)\n    return KEY_VALUE_TEMPLATE.format(method_name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self):\n        environment_variables_output = [html_for_env_var(key)\n                                        for key in sorted(os.environ)]\n\n        cgi_arguments_output = []\n        if os.getenv('CONTENT_TYPE') == 'application/x-www-form-urlencoded':\n            # Note: a blank Content-type header will still sometimes\n            # (in dev_appserver) show up as 'application/x-www-form-urlencoded'\n            form = cgi.FieldStorage()\n            if not form:\n                cgi_arguments_output.append('No CGI arguments given...')\n            else:\n                for cgi_argument in form:\n                    cgi_arguments_output.append(\n                            html_for_cgi_argument(cgi_argument, form))\n        else:\n            data = ''\n            cgi_arguments_output.append(STDIN_TEMPLATE.format(len(data)))\n            cgi_arguments_output.append(cgi.escape(data))\n\n        modules_api_output = [\n            html_for_modules_method('get_current_module_name'),\n            html_for_modules_method('get_current_version_name'),\n            html_for_modules_method('get_current_instance_id'),\n            html_for_modules_method('get_modules'),\n            html_for_modules_method('get_versions'),\n            html_for_modules_method('get_default_version'),\n            html_for_modules_method('get_hostname'),\n        ]\n\n        result = PAGE_TEMPLATE.format(\n            users.CreateLoginURL(self.request.url),\n            users.CreateLogoutURL(self.request.url),\n            '<br>\\n'.join(environment_variables_output),\n            '<br>\\n'.join(cgi_arguments_output),\n            '<br>\\n'.join(modules_api_output),\n        )\n\n        self.response.write(result)", "response": "GET handler that serves environment data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync_badges(**kwargs):\n    update = kwargs.get('update', False)\n    created_badges = []\n    instances = registry.get_recipe_instances()\n\n    for instance in instances:\n        reset_queries()\n        badge, created = instance.create_badge(update=update)\n        if created:\n            created_badges.append(badge)\n        log_queries(instance)\n\n    return created_badges", "response": "Creates missing badges for all recipes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the count of users in the badges and returns a tuple of lists of updated and unchanged ones.", "response": "def sync_counts(**kwargs):\n    \"\"\"\n    Iterates over registered recipes and denormalizes ``Badge.users.count()``\n    into ``Badge.users_count`` field.\n    \"\"\"\n    badges = kwargs.get('badges')\n    excluded = kwargs.get('exclude_badges')\n\n    instances = registry.get_recipe_instances(badges=badges, excluded=excluded)\n    updated_badges, unchanged_badges = [], []\n\n    for instance in instances:\n        reset_queries()\n        badge, updated = instance.update_badge_users_count()\n        if updated:\n            updated_badges.append(badge)\n        else:\n            unchanged_badges.append(badge)\n        log_queries(instance)\n\n    return (updated_badges, unchanged_badges)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync_awards(**kwargs):\n    badges = kwargs.get('badges')\n    excluded = kwargs.get('exclude_badges')\n    disable_signals = kwargs.get('disable_signals')\n    batch_size = kwargs.get('batch_size', None)\n    db_read = kwargs.get('db_read', None)\n\n    award_post_save = True\n\n    if disable_signals:\n        settings.AUTO_DENORMALIZE = False\n        award_post_save = False\n\n    instances = registry.get_recipe_instances(badges=badges, excluded=excluded)\n\n    for instance in instances:\n        reset_queries()\n        instance.create_awards(\n            batch_size=batch_size,\n            db_read=db_read,\n            post_save_signal=award_post_save)\n        log_queries(instance)", "response": "Synchronizes the awards of all recipes with the current ones."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_badge(self):\n        try:\n            obj = Badge.objects.using(self.db_read).get(slug=self.slug)\n            logger.debug('\u2713 Badge %s: fetched from db (%s)', obj.slug, self.db_read)\n        except Badge.DoesNotExist:\n            obj = None\n        return obj", "response": "Returns the related Badge object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new badge for the current object.", "response": "def create_badge(self, update=False):\n        \"\"\"\n        Saves the badge in the database (or updates it if ``update`` is ``True``).\n        Returns a tuple: ``badge`` (the badge object) and ``created`` (``True``, if\n        badge has been created).\n        \"\"\"\n        badge, created = self.badge, False\n        if badge:\n            logger.debug('\u2713 Badge %s: already created', badge.slug)\n            if update:\n                to_update = {}\n                for field in ('name', 'slug', 'description', 'image'):\n                    attr = getattr(self, field)\n                    badge_attr = getattr(badge, field)\n                    if attr != badge_attr:\n                        to_update[field] = attr\n                        logger.debug('\u2713 Badge %s: updated \"%s\" field', self.slug, field)\n                Badge.objects.filter(id=badge.id).update(**to_update)\n        else:\n            kwargs = {'name': self.name, 'image': self.image}\n            optional_fields = ['slug', 'description']\n            for field in optional_fields:\n                value = getattr(self, field)\n                if value is not None:\n                    kwargs[field] = value\n            badge = Badge.objects.create(**kwargs)\n            created = True\n            logger.debug('\u2713 Badge %s: created', badge.slug)\n        return (badge, created)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if we can perform awarding process. Returns True if we can perform awarding process False otherwise.", "response": "def can_perform_awarding(self):\n        \"\"\"\n        Checks if we can perform awarding process (is ``user_ids`` property\n        defined? Does Badge object exists? and so on). If we can perform db\n        operations safely, returns ``True``. Otherwise, ``False``.\n        \"\"\"\n        if not self.user_ids:\n            logger.debug(\n                '\u2718 Badge %s: no users to check (empty user_ids property)',\n                self.slug)\n            return False\n\n        if not self.badge:\n            logger.debug(\n                '\u2718 Badge %s: does not exist in the database (run badgify_sync badges)',\n                self.slug)\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the users count of the current object in the database.", "response": "def update_badge_users_count(self):\n        \"\"\"\n        Denormalizes ``Badge.users.count()`` into ``Bagdes.users_count`` field.\n        \"\"\"\n        logger.debug('\u2192 Badge %s: syncing users count...', self.slug)\n\n        badge, updated = self.badge, False\n\n        if not badge:\n            logger.debug(\n                '\u2718 Badge %s: does not exist in the database (run badgify_sync badges)',\n                self.slug)\n            return (self.slug, updated)\n\n        old_value, new_value = badge.users_count, badge.users.count()\n\n        if old_value != new_value:\n            badge = Badge.objects.get(slug=self.slug)\n            badge.users_count = new_value\n            badge.save()\n            updated = True\n\n        if updated:\n            logger.debug('\u2713 Badge %s: updated users count (from %d to %d)',\n                         self.slug,\n                         old_value,\n                         new_value)\n        else:\n            logger.debug('\u2713 Badge %s: users count up-to-date (%d)',\n                         self.slug,\n                         new_value)\n\n        return (badge, updated)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_already_awarded_user_ids(self, db_read=None, show_log=True):\n\n        db_read = db_read or self.db_read\n\n        already_awarded_ids = self.badge.users.using(db_read).values_list('id', flat=True)\n        already_awarded_ids_count = len(already_awarded_ids)\n\n        if show_log:\n            logger.debug(\n                \"\u2192 Badge %s: %d users already awarded (fetched from db '%s')\",\n                self.slug,\n                already_awarded_ids_count,\n                db_read)\n\n        return already_awarded_ids", "response": "Returns already awarded user ids and the count."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_user_ids(self, db_read=None):\n        db_read = db_read or self.db_read\n\n        return self.user_ids.using(db_read)", "response": "Returns the current user ids and the count."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple of the unawarded user ids and the count of unawarded users.", "response": "def get_unawarded_user_ids(self, db_read=None):\n        \"\"\"\n        Returns unawarded user ids (need to be saved) and the count.\n        \"\"\"\n        db_read = db_read or self.db_read\n\n        already_awarded_ids = self.get_already_awarded_user_ids(db_read=db_read)\n        current_ids = self.get_current_user_ids(db_read=db_read)\n        unawarded_ids = list(set(current_ids) - set(already_awarded_ids))\n        unawarded_ids_count = len(unawarded_ids)\n\n        logger.debug(\n            '\u2192 Badge %s: %d users need to be awarded',\n            self.slug,\n            unawarded_ids_count)\n\n        return (unawarded_ids, unawarded_ids_count)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_obsolete_user_ids(self, db_read=None):\n        db_read = db_read or self.db_read\n\n        already_awarded_ids = self.get_already_awarded_user_ids(db_read=db_read, show_log=False)\n        current_ids = self.get_current_user_ids(db_read=db_read)\n        obsolete_ids = list(set(already_awarded_ids) - set(current_ids))\n        obsolete_ids_count = len(obsolete_ids)\n\n        logger.debug(\n            '\u2192 Badge %s: %d users need to be unawarded',\n            self.slug,\n            obsolete_ids_count)\n\n        return (obsolete_ids, obsolete_ids_count)", "response": "Returns a tuple of user IDs to unaward."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_arguments(self, parser):\n        super(Command, self).add_arguments(parser)\n\n        parser.add_argument('--badges',\n                            action='store',\n                            dest='badges',\n                            type=str)\n\n        parser.add_argument('--db-read',\n                            action='store',\n                            dest='db_read',\n                            type=str)\n\n        parser.add_argument('--disable-signals',\n                            action='store_true',\n                            dest='disable_signals')\n\n        parser.add_argument('--batch-size',\n                            action='store',\n                            dest='batch_size',\n                            type=int)\n\n        parser.add_argument('--update',\n                            action='store_true',\n                            dest='update')\n\n        parser.add_argument('--exclude-badges',\n                            action='store',\n                            dest='exclude_badges',\n                            type=str)", "response": "Add command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a single label.", "response": "def handle_label(self, label, **options):\n        \"\"\"\n        Command handler.\n        \"\"\"\n        if not hasattr(commands, 'sync_%s' % label):\n            raise CommandError('\"%s\" is not a valid command.' % label)\n\n        getattr(commands, 'sync_%s' % label)(**sanitize_command_options(options))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_suffix(self, name):\n        # don't extract suffixes if we can't reasonably suspect we have enough parts to the name for there to be one\n        if len(name.strip().split()) > 2:\n            name, suffix = self.extract_matching_portion(r'\\b(?P<suffix>{})(?=\\b|\\s|\\Z|\\W)'.format(SUFFIX_RE), name)\n            suffix, degree = self.extract_matching_portion(DEGREE_RE, suffix or '')\n            return name, suffix or None\n\n        return name, None", "response": "Extracts the suffix from the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a name that is in last first format and returns it in a hopefully [ first last order.", "response": "def reverse_last_first(self, name):\n        \"\"\" Takes a name that is in [last, first] format and returns it in a hopefully [first last] order.\n            Also extracts the suffix and puts it back on the end, in case it's embedded somewhere in the middle.\n        \"\"\"\n        # make sure we don't put a suffix in the middle, as in \"Smith, Tom II\"\n        name, suffix = self.extract_suffix(name)\n\n        split = re.split(', ?', name)\n\n        # make sure that the comma is not just preceding a suffix, such as \"Jr\",\n        # by checking that we have at least 2 name parts and the last doesn't match\n        # our suffix regex\n        if len(split) >= 2:\n            split.reverse()\n\n        if suffix:\n            split.append(suffix)\n\n        return ' '.join(split)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compare(cls, match, subject):\n        if match.expand().lower() == subject.expand().lower():\n            return 4\n        elif match.kernel().lower() == subject.kernel().lower():\n            return 3\n        # law and lobbying firms in CRP data typically list only the first two partners\n        # before 'et al'\n        elif ',' in subject.expand():  # we may have a list of partners\n            if subject.crp_style_firm_name() == str(match).lower():\n                return 3\n        else:\n            return 2", "response": "Compare two OrganizationName objects and returns an arbitrary score based upon how well the names match."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef badgify_badges(**kwargs):\n    User = get_user_model()\n    user = kwargs.get('user', None)\n    username = kwargs.get('username', None)\n    if username:\n        try:\n            user = User.objects.get(username=username)\n        except User.DoesNotExist:\n            pass\n    if user:\n        awards = Award.objects.filter(user=user).select_related('badge')\n        badges = [award.badge for award in awards]\n        return badges\n    return Badge.objects.all()", "response": "Returns all badges or only awarded badges for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove parenthethical and dashed phrases from the name and returns the name without any extra phrases.", "response": "def without_extra_phrases(self):\n        \"\"\"Removes parenthethical and dashed phrases\"\"\"\n        # the last parenthesis is optional, because sometimes they are truncated\n        name = re.sub(r'\\s*\\([^)]*\\)?\\s*$', '', self.name)\n        name = re.sub(r'(?i)\\s* formerly.*$', '', name)\n        name = re.sub(r'(?i)\\s*and its affiliates$', '', name)\n        name = re.sub(r'\\bet al\\b', '', name)\n        \n        # in some datasets, the name of an organization is followed by a hyphen and an abbreviated name, or a specific\n        # department or geographic subdivision; we want to remove this extraneous stuff without breaking names like\n        # Wal-Mart or Williams-Sonoma\n\n        # if there's a hyphen at least four characters in, proceed\n        if \"-\" in name:\n            hyphen_parts = name.rsplit(\"-\", 1)\n            # if the part after the hyphen is shorter than the part before,\n            # AND isn't either a number (often occurs in Union names) or a single letter (e.g., Tech-X),\n            # AND the hyphen is preceded by either whitespace or at least four characters,\n            # discard the hyphen and whatever follows\n            if len(hyphen_parts[1]) < len(hyphen_parts[0]) and re.search(r'(\\w{4,}|\\s+)$', hyphen_parts[0]) and not re.match(r'^([a-zA-Z]|[0-9]+)$', hyphen_parts[1]):\n                name = hyphen_parts[0].strip()\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kernel(self):\n        stop_words = [ y.lower() for y in self.abbreviations.values() + self.filler_words ]\n        kernel = ' '.join([ x for x in self.expand().split() if x.lower() not in stop_words ])\n\n        # this is a hack to get around the fact that this is the only two-word phrase we want to block\n        # amongst our stop words. if we end up with more, we may need a better way to do this\n        kernel = re.sub(r'\\s*United States', '', kernel)\n\n        return kernel", "response": "The kernel is an attempt to get at just the most pithy words in the name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake in a name that has been split by spaces. Names which are in [last, first] format need to be preprocessed. The nickname must be in double quotes to be recognized as such. This can take name parts in in these orders: first, middle, last, nick, suffix, honorific first, middle, last, nick, suffix first, middle, last, suffix, honorific first, middle, last, honorific first, middle, last, suffix first, middle, last, nick first, last, honorific first, last, suffix first, last, nick first, middle, last first, last last", "response": "def new_from_tokens(self, *args, **kwargs):\n        \"\"\"\n            Takes in a name that has been split by spaces.\n            Names which are in [last, first] format need to be preprocessed.\n            The nickname must be in double quotes to be recognized as such.\n\n            This can take name parts in in these orders:\n            first, middle, last, nick, suffix, honorific\n            first, middle, last, nick, suffix\n            first, middle, last, suffix, honorific\n            first, middle, last, honorific\n            first, middle, last, suffix\n            first, middle, last, nick\n            first, last, honorific\n            first, last, suffix\n            first, last, nick\n            first, middle, last\n            first, last\n            last\n        \"\"\"\n\n        if kwargs.get('allow_quoted_nicknames'):\n            args = [ x.strip() for x in args if not re.match(r'^[(]', x) ]\n        else:\n            args = [ x.strip() for x in args if not re.match(r'^[(\"]', x) ]\n\n        if len(args) > 2:\n            self.detect_and_fix_two_part_surname(args)\n\n        # set defaults\n        self.first = ''\n        self.last = ''\n\n        # the final few tokens should always be detectable, otherwise a last name\n        if len(args):\n            if self.is_an_honorific(args[-1]):\n                self.honorific = args.pop()\n                if not self.honorific[-1] == '.':\n                    self.honorific += '.'\n            if self.is_a_suffix(args[-1]):\n                self.suffix = args.pop()\n                if re.match(r'[js]r(?!\\.)', self.suffix, re.IGNORECASE):\n                    self.suffix += '.'\n            if self.is_a_nickname(args[-1]):\n                self.nick = args.pop()\n            self.last = args.pop()\n\n        num_remaining_parts = len(args)\n\n        if num_remaining_parts == 3:\n            # if we've still got this many parts, we'll consider what's left as first name\n            # plus multi-part middle name\n            self.first = args[0]\n            self.middle = ' '.join(args[1:3])\n\n        elif num_remaining_parts == 2:\n            self.first, self.middle = args\n            if len(self.middle) == 1:\n                self.middle += '.'\n\n        elif num_remaining_parts == 1:\n            self.first = ' '.join(args)\n\n        if self.first and len(self.first) == 1:\n            self.first += '.'\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detect_and_fix_two_part_surname(self, args):\n        i = 0\n        while i < len(args) - 1:\n            if args[i].lower() in self.family_name_prefixes:\n                args[i] = ' '.join(args[i:i+2])\n                del(args[i+1])\n                break\n            else:\n                i += 1", "response": "This detects common family name prefixes and joins them to the last name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef case_name_parts(self):\n        if not self.is_mixed_case():\n            self.honorific = self.honorific.title() if self.honorific else None\n            self.nick = self.nick.title() if self.nick else None\n\n            if self.first:\n                self.first = self.first.title()\n                self.first = self.capitalize_and_punctuate_initials(self.first)\n\n            if self.last:\n                self.last = self.last.title()\n                self.last = self.uppercase_the_scots(self.last)\n\n            self.middle = self.middle.title() if self.middle else None\n\n            if self.suffix:\n                # Title case Jr/Sr, but uppercase roman numerals\n                if re.match(r'(?i).*[js]r', self.suffix):\n                    self.suffix = self.suffix.title()\n                else:\n                    self.suffix = self.suffix.upper()\n\n        return self", "response": "Convert all the parts of the name to the proper case... carefully!"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(args=None):\n    args = sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"safe_file\", type=str, nargs='+')\n    parser.add_argument(\"--granules\", action=\"store_true\")\n    parsed = parser.parse_args(args)\n\n    pp = pprint.PrettyPrinter()\n    for safe_file in parsed.safe_file:\n        with s2reader.open(safe_file) as safe_dataset:\n            if parsed.granules:\n                pp.pprint(\n                    dict(\n                        safe_file=safe_file,\n                        granules=[\n                            dict(\n                                granule_identifier=granule.granule_identifier,\n                                footprint=str(granule.footprint),\n                                srid=granule.srid,\n                                # cloudmask_polys=str(granule.cloudmask),\n                                # nodata_mask=str(granule.nodata_mask),\n                                cloud_percent=granule.cloud_percent\n                                )\n                            for granule in safe_dataset.granules\n                            ]\n                        )\n                    )\n            else:\n                pp.pprint(\n                    dict(\n                        safe_file=safe_file,\n                        product_start_time=safe_dataset.product_start_time,\n                        product_stop_time=safe_dataset.product_stop_time,\n                        generation_time=safe_dataset.generation_time,\n                        footprint=str(safe_dataset.footprint),\n                        bounds=str(safe_dataset.footprint.bounds),\n                        granules=len(safe_dataset.granules),\n                        granules_srids=list(set([\n                            granule.srid\n                            for granule in safe_dataset.granules\n                            ]))\n                        )\n                    )\n            print \"\\n\"", "response": "Print metadata as JSON strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a SentinelDataSet object.", "response": "def open(safe_file):\n    \"\"\"Return a SentinelDataSet object.\"\"\"\n    if os.path.isdir(safe_file) or os.path.isfile(safe_file):\n        return SentinelDataSet(safe_file)\n    else:\n        raise IOError(\"file not found: %s\" % safe_file)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pvi_path(granule):\n    pvi_name = granule._metadata.iter(\"PVI_FILENAME\").next().text\n    pvi_name = pvi_name.split(\"/\")\n    pvi_path = os.path.join(\n        granule.granule_path,\n        pvi_name[len(pvi_name)-2], pvi_name[len(pvi_name)-1]\n    )\n    try:\n        assert os.path.isfile(pvi_path) or \\\n            pvi_path in granule.dataset._zipfile.namelist()\n    except (AssertionError, AttributeError):\n        return None\n    return pvi_path", "response": "Determine the PreView Image ( PVI path inside the SAFE pkg."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a granule identifier to an XML name.", "response": "def _granule_identifier_to_xml_name(granule_identifier):\n    \"\"\"\n    Very ugly way to convert the granule identifier.\n\n    e.g.\n    From\n    Granule Identifier:\n    S2A_OPER_MSI_L1C_TL_SGS__20150817T131818_A000792_T28QBG_N01.03\n    To\n    Granule Metadata XML name:\n    S2A_OPER_MTD_L1C_TL_SGS__20150817T131818_A000792_T28QBG.xml\n    \"\"\"\n    # Replace \"MSI\" with \"MTD\".\n    changed_item_type = re.sub(\"_MSI_\", \"_MTD_\", granule_identifier)\n    # Split string up by underscores.\n    split_by_underscores = changed_item_type.split(\"_\")\n    del split_by_underscores[-1]\n    cleaned = str()\n    # Stitch string list together, adding the previously removed underscores.\n    for i in split_by_underscores:\n        cleaned += (i + \"_\")\n    # Remove last underscore and append XML file extension.\n    out_xml = cleaned[:-1] + \".xml\"\n\n    return out_xml"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns Shapely Polygon from list of alterating latitude / longitude coordinates.", "response": "def _polygon_from_coords(coords, fix_geom=False, swap=True, dims=2):\n    \"\"\"\n    Return Shapely Polygon from coordinates.\n\n    - coords: list of alterating latitude / longitude coordinates\n    - fix_geom: automatically fix geometry\n    \"\"\"\n    assert len(coords) % dims == 0\n    number_of_points = len(coords)/dims\n    coords_as_array = np.array(coords)\n    reshaped = coords_as_array.reshape(number_of_points, dims)\n    points = [\n        (float(i[1]), float(i[0])) if swap else ((float(i[0]), float(i[1])))\n        for i in reshaped.tolist()\n        ]\n    polygon = Polygon(points).buffer(0)\n    try:\n        assert polygon.is_valid\n        return polygon\n    except AssertionError:\n        if fix_geom:\n            return polygon.buffer(0)\n        else:\n            raise RuntimeError(\"Geometry is not valid.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns path to product metadata XML file.", "response": "def product_metadata_path(self):\n        \"\"\"Return path to product metadata XML file.\"\"\"\n        data_object_section = self._manifest_safe.find(\"dataObjectSection\")\n        for data_object in data_object_section:\n            # Find product metadata XML.\n            if data_object.attrib.get(\"ID\") == \"S2_Level-1C_Product_Metadata\":\n                relpath = os.path.relpath(\n                    data_object.iter(\"fileLocation\").next().attrib[\"href\"])\n                try:\n                    if self.is_zip:\n                        abspath = os.path.join(self._zip_root, relpath)\n                        assert abspath in self._zipfile.namelist()\n                    else:\n                        abspath = os.path.join(self.path, relpath)\n                        assert os.path.isfile(abspath)\n                except AssertionError:\n                    raise S2ReaderIOError(\n                        \"S2_Level-1C_product_metadata_path not found: %s \\\n                        \" % abspath\n                    )\n                return abspath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef granules(self):\n        for element in self._product_metadata.iter(\"Product_Info\"):\n            product_organisation = element.find(\"Product_Organisation\")\n        if self.product_format == 'SAFE':\n            return [\n                SentinelGranule(_id.find(\"Granules\"), self)\n                for _id in product_organisation.findall(\"Granule_List\")\n                ]\n        elif self.product_format == 'SAFE_COMPACT':\n            return [\n                SentinelGranuleCompact(_id.find(\"Granule\"), self)\n                for _id in product_organisation.findall(\"Granule_List\")\n                ]\n        else:\n            raise Exception(\n                \"PRODUCT_FORMAT not recognized in metadata file, found: '\" +\n                str(self.safe_format) +\n                \"' accepted are 'SAFE' and 'SAFE_COMPACT'\"\n            )", "response": "Return list of SentinelGranule objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef granule_paths(self, band_id):\n        band_id = str(band_id).zfill(2)\n        try:\n            assert isinstance(band_id, str)\n            assert band_id in BAND_IDS\n        except AssertionError:\n            raise AttributeError(\n                \"band ID not valid: %s\" % band_id\n                )\n        return [\n            granule.band_path(band_id)\n            for granule in self.granules\n            ]", "response": "Return the path of all granules of a given band."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef metadata_path(self):\n        xml_name = _granule_identifier_to_xml_name(self.granule_identifier)\n        metadata_path = os.path.join(self.granule_path, xml_name)\n        try:\n            assert os.path.isfile(metadata_path) or \\\n                metadata_path in self.dataset._zipfile.namelist()\n        except AssertionError:\n            raise S2ReaderIOError(\n                \"Granule metadata XML does not exist:\", metadata_path)\n        return metadata_path", "response": "Determine the metadata path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path to the granules TrueColorImage.", "response": "def tci_path(self):\n        \"\"\"Return the path to the granules TrueColorImage.\"\"\"\n        tci_paths = [\n            path for path in self.dataset._product_metadata.xpath(\n                \".//Granule[@granuleIdentifier='%s']/IMAGE_FILE/text()\"\n                % self.granule_identifier\n            ) if path.endswith('TCI')\n        ]\n        try:\n            tci_path = tci_paths[0]\n        except IndexError:\n            return None\n\n        return os.path.join(\n            self.dataset._zip_root if self.dataset.is_zip else self.dataset.path,\n            tci_path\n        ) + '.jp2'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cloud_percent(self):\n        image_content_qi = self._metadata.findtext(\n            (\n                \"\"\"n1:Quality_Indicators_Info/Image_Content_QI/\"\"\"\n                \"\"\"CLOUDY_PIXEL_PERCENTAGE\"\"\"\n            ),\n            namespaces=self._nsmap)\n        return float(image_content_qi)", "response": "Return percentage of cloud coverage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding and return footprint as Shapely Polygon.", "response": "def footprint(self):\n        \"\"\"Find and return footprint as Shapely Polygon.\"\"\"\n        # Check whether product or granule footprint needs to be calculated.\n        tile_geocoding = self._metadata.iter(\"Tile_Geocoding\").next()\n        resolution = 10\n        searchstring = \".//*[@resolution='%s']\" % resolution\n        size, geoposition = tile_geocoding.findall(searchstring)\n        nrows, ncols = (int(i.text) for i in size)\n        ulx, uly, xdim, ydim = (int(i.text) for i in geoposition)\n        lrx = ulx + nrows * resolution\n        lry = uly - ncols * resolution\n        utm_footprint = box(ulx, lry, lrx, uly)\n        project = partial(\n            pyproj.transform,\n            pyproj.Proj(init=self.srid),\n            pyproj.Proj(init='EPSG:4326')\n            )\n        footprint = transform(project, utm_footprint).buffer(0)\n        return footprint"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a shapely geometry.", "response": "def cloudmask(self):\n        \"\"\"Return cloudmask as a shapely geometry.\"\"\"\n        polys = list(self._get_mask(mask_type=\"MSK_CLOUDS\"))\n        return MultiPolygon([\n            poly[\"geometry\"]\n            for poly in polys\n            if poly[\"attributes\"][\"maskType\"] == \"OPAQUE\"\n        ]).buffer(0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning paths of given band s jp2 files for all granules.", "response": "def band_path(self, band_id, for_gdal=False, absolute=False):\n        \"\"\"Return paths of given band's jp2 files for all granules.\"\"\"\n        band_id = str(band_id).zfill(2)\n        if not isinstance(band_id, str) or band_id not in BAND_IDS:\n            raise ValueError(\"band ID not valid: %s\" % band_id)\n        if self.dataset.is_zip and for_gdal:\n            zip_prefix = \"/vsizip/\"\n            if absolute:\n                granule_basepath = zip_prefix + os.path.dirname(os.path.join(\n                    self.dataset.path,\n                    self.dataset.product_metadata_path\n                ))\n            else:\n                granule_basepath = zip_prefix + os.path.dirname(\n                    self.dataset.product_metadata_path\n                )\n        else:\n            if absolute:\n                granule_basepath = os.path.dirname(os.path.join(\n                    self.dataset.path,\n                    self.dataset.product_metadata_path\n                ))\n            else:\n                granule_basepath = os.path.dirname(\n                    self.dataset.product_metadata_path\n                )\n        product_org = self.dataset._product_metadata.iter(\n            \"Product_Organisation\").next()\n        granule_item = [\n            g\n            for g in chain(*[gl for gl in product_org.iter(\"Granule_List\")])\n            if self.granule_identifier == g.attrib[\"granuleIdentifier\"]\n        ]\n        if len(granule_item) != 1:\n            raise S2ReaderMetadataError(\n                \"Granule ID cannot be found in product metadata.\"\n            )\n        rel_path = [\n            f.text for f in granule_item[0].iter() if f.text[-2:] == band_id\n        ]\n        if len(rel_path) != 1:\n            # Apparently some SAFE files don't contain all bands. In such a\n            # case, raise a warning and return None.\n            warnings.warn(\n                \"%s: image path to band %s could not be extracted\" % (\n                    self.dataset.path, band_id\n                )\n            )\n            return\n        img_path = os.path.join(granule_basepath, rel_path[0]) + \".jp2\"\n        # Above solution still fails on the \"safe\" test dataset. Therefore,\n        # the path gets checked if it contains the IMG_DATA folder and if not,\n        # try to guess the path from the old schema. Not happy with this but\n        # couldn't find a better way yet.\n        if \"IMG_DATA\" in img_path:\n            return img_path\n        else:\n            if self.dataset.is_zip:\n                zip_prefix = \"/vsizip/\"\n                granule_basepath = zip_prefix + os.path.join(\n                    self.dataset.path, self.granule_path)\n            else:\n                granule_basepath = self.granule_path\n            return os.path.join(\n                os.path.join(granule_basepath, \"IMG_DATA\"),\n                \"\".join([\n                    \"_\".join((self.granule_identifier).split(\"_\")[:-1]),\n                    \"_B\",\n                    band_id,\n                    \".jp2\"\n                ])\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets ground resolution in meters / pixel", "response": "def ground_resolution(lat, level):\n        \"\"\"Gets ground res in meters / pixel\"\"\"\n        lat = TileSystem.clip(lat, TileSystem.LATITUDE_RANGE)\n        return cos(lat * pi / 180) * 2 * pi * TileSystem.EARTH_RADIUS / TileSystem.map_size(level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef geo_to_pixel(geo, level):\n        lat, lon = float(geo[0]), float(geo[1])\n        lat = TileSystem.clip(lat, TileSystem.LATITUDE_RANGE)\n        lon = TileSystem.clip(lon, TileSystem.LONGITUDE_RANGE)\n        x = (lon + 180) / 360\n        sin_lat = sin(lat * pi / 180)\n        y = 0.5 - log((1 + sin_lat) / (1 - sin_lat)) / (4 * pi)\n        # might need to cast to uint\n        map_size = TileSystem.map_size(level)\n        pixel_x = int(TileSystem.clip(x * map_size + 0.5, (0, map_size - 1)))\n        pixel_y = int(TileSystem.clip(y * map_size + 0.5, (0, map_size - 1)))\n        # print '\\n'+str( ((lat, lon), sin_lat, (x, y), map_size, (pixel_x,\n        # pixel_y)) )+'\\n'\n        return pixel_x, pixel_y", "response": "Transform from geo coordinates to pixel coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform from pixel to geo coordinates", "response": "def pixel_to_geo(pixel, level):\n        \"\"\"Transform from pixel to geo coordinates\"\"\"\n        pixel_x = pixel[0]\n        pixel_y = pixel[1]\n        map_size = float(TileSystem.map_size(level))\n        x = (TileSystem.clip(pixel_x, (0, map_size - 1)) / map_size) - 0.5\n        y = 0.5 - (TileSystem.clip(pixel_y, (0, map_size - 1)) / map_size)\n        lat = 90 - 360 * atan(exp(-y * 2 * pi)) / pi\n        lon = 360 * x\n        return round(lat, 6), round(lon, 6)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming tile to pixel coordinates", "response": "def tile_to_pixel(tile, centered=False):\n        \"\"\"Transform tile to pixel coordinates\"\"\"\n        pixel = [tile[0] * 256, tile[1] * 256]\n        if centered:\n            # should clip on max map size\n            pixel = [pix + 128 for pix in pixel]\n        return pixel[0], pixel[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms tile coordinates to a quadkey", "response": "def tile_to_quadkey(tile, level):\n        \"\"\"Transform tile coordinates to a quadkey\"\"\"\n        tile_x = tile[0]\n        tile_y = tile[1]\n        quadkey = \"\"\n        for i in xrange(level):\n            bit = level - i\n            digit = ord('0')\n            mask = 1 << (bit - 1)  # if (bit - 1) > 0 else 1 >> (bit - 1)\n            if (tile_x & mask) is not 0:\n                digit += 1\n            if (tile_y & mask) is not 0:\n                digit += 2\n            quadkey += chr(digit)\n        return quadkey"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming quadkey to tile coordinates", "response": "def quadkey_to_tile(quadkey):\n        \"\"\"Transform quadkey to tile coordinates\"\"\"\n        tile_x, tile_y = (0, 0)\n        level = len(quadkey)\n        for i in xrange(level):\n            bit = level - i\n            mask = 1 << (bit - 1)\n            if quadkey[level - bit] == '1':\n                tile_x |= mask\n            if quadkey[level - bit] == '2':\n                tile_y |= mask\n            if quadkey[level - bit] == '3':\n                tile_x |= mask\n                tile_y |= mask\n        return [(tile_x, tile_y), level]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authorize_url(self, state=''):\n        url = 'https://openapi.youku.com/v2/oauth2/authorize?'\n        params = {\n            'client_id': self.client_id,\n            'response_type': 'code',\n            'state': state,\n            'redirect_uri': self.redirect_uri\n        }\n        return url + urlencode(params)", "response": "return user authorize url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refresh_token(self, refresh_token):\n        '''return origin json'''\n        url = 'https://api.youku.com/oauth2/token.json'\n        data = {'client_id': self.client_id,\n                'grant_type': 'refresh_token',\n                'refresh_token': refresh_token}\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()", "response": "refresh_token is the refresh_token that is used to refresh the token"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if response is in json form and raise YoukuError if not", "response": "def check_error(response, expect_status=200):\n    \"\"\"\n    Youku error should return in json form, like:\n    HTTP 400\n    {\n        \"error\":{\n            \"code\":120010223,\n            \"type\":\"UploadsException\",\n            \"description\":\"Expired upload token\"\n        }\n    }\n\n    But error also maybe in response url params or response booy.\n\n    Content-Type maybe application/json or text/plain, so\n    don't relay on it.\n\n    Args:\n        expect_status: normally is 200 or 201\n    \"\"\"\n    json = None\n    try:\n        json = response.json()\n    except:\n        pass\n    if (response.status_code != expect_status or\n            response.status_code == 400 or\n            'error' in json):\n        if json:\n            error = json['error']\n            raise YoukuError(error['code'], error['type'],\n                             error['description'], response.status_code)\n        else:\n            # try to parse error from body\n            error = parse_qs(response.text)\n            raise YoukuError(error.get('code', [None])[0],\n                             error.get('type', [None])[0],\n                             error.get('description', [None])[0],\n                             response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove item from dict if value is None.", "response": "def remove_none_value(data):\n    \"\"\"remove item from dict if value is None.\n    return new dict.\n    \"\"\"\n    return dict((k, v) for k, v in data.items() if v is not None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind person by id", "response": "def find_person_by_id(self, person_id):\n        \"\"\"doc: http://open.youku.com/docs/docs?id=87\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/persons/show.json'\n        params = {\n            'client_id': self.client_id,\n            'person_id': person_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding persons by ids", "response": "def find_persons_by_ids(self, person_ids):\n        \"\"\"doc: http://open.youku.com/docs/docs?id=88\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/persons/show_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'person_ids': person_ids\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind persons by type", "response": "def find_persons_by_type(self, type, nationality=None, gender=None,\n                             firstletter=None, orderby='view-week-count',\n                             page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/docs?id=89\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/persons/by_type.json'\n        params = {\n            'client_id': self.client_id,\n            'type': type,\n            'nationality': nationality,\n            'gender': gender,\n            'firstletter': firstletter,\n            'orderby': orderby,\n            'page': page,\n            'count': count\n        }\n        params = remove_none_value(params)\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets my info about youku", "response": "def my_info(self, access_token):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=23\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/users/myinfo.json'\n        data = {'client_id': self.client_id,\n                'access_token': access_token}\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfollows is a wrapper for the following function of the following function.", "response": "def friendship_followings(self, user_id=None, user_name=None,\n                              page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=26\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/users/friendship/followings.json'\n        data = {\n            'client_id': self.client_id,\n            'page': page,\n            'count': count,\n            'user_id': user_id,\n            'user_name': user_name\n        }\n        data = remove_none_value(data)\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_friendship(self, access_token,\n                          user_id=None, user_name=None):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=28\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/users/friendship/create.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'user_id': user_id,\n            'user_name': user_name\n        }\n        data = remove_none_value(data)\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()", "response": "create a user s user s friendship"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_subscribe(self, access_token, show_id):\n        url = 'https://openapi.youku.com/v2/users/subscribe/create.json'\n        params = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'show_id': show_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()['result'] == 0", "response": "create a new subscription"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cancel_subscribe(self, access_token, show_id):\n        url = 'https://openapi.youku.com/v2/users/subscribe/cancel.json'\n        params = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'show_id': show_id\n        }\n        r = requests.post(url, data=params)\n        check_error(r)\n        return r.json()['result'] == 0", "response": "cancel subscription to a specific user"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of youku user s unique id", "response": "def subscribe_get(self, access_token, page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=30\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/users/subscribe/get.json'\n        params = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_show_by_id(self, show_id):\n        url = 'https://openapi.youku.com/v2/shows/show.json'\n        params = {\n            'client_id': self.client_id,\n            'show_id': show_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find show by id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_shows_by_ids(self, show_ids):\n        url = 'https://openapi.youku.com/v2/shows/show_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'show_ids': show_ids\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find shows by ids"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind show premium by show ids", "response": "def find_show_premium_by_ids(self, show_ids, page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=61\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/shows/show_premium.json'\n        params = {\n            'client_id': self.client_id,\n            'show_ids': show_ids,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_shows_by_category(self, category, genre=None, area=None,\n                               release_year=None, paid=None,\n                               orderby='view-today-count',\n                               streamtypes=None, person=None,\n                               page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=62\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/shows/by_category.json'\n        params = {\n            'client_id': self.client_id,\n            'category': category,\n            'genre': genre,\n            'area': area,\n            'release_year': release_year,\n            'paid': paid,\n            'orderby': orderby,\n            'streamtypes': streamtypes,\n            'person': person,\n            'page': page,\n            'count': count\n        }\n        params = remove_none_value(params)\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "This method returns a list of shows for a given category."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind shows by related id", "response": "def find_shows_by_related(self, show_id,\n                              count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=63\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/shows/by_related.json'\n        params = {\n            'client_id': self.client_id,\n            'show_id': show_id,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_videos_by_show(self, show_id, show_videotype=None,\n                            show_videostage=None, orderby='videoseq-asc',\n                            page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=64\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/shows/videos.json'\n        params = {\n            'client_id': self.client_id,\n            'show_id': show_id,\n            'page': page,\n            'count': count,\n            'show_videotype': show_videotype,\n            'show_videostage': show_videostage,\n            'orderby': orderby\n        }\n        params = remove_none_value(params)\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find_videos_by_show - Returns a list of the available videos for a show"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_video_params(self, title=None, tags='Others', description='',\n                             copyright_type='original', public_type='all',\n                             category=None, watch_password=None,\n                             latitude=None, longitude=None, shoot_time=None\n                             ):\n        \"\"\" util method for create video params to upload.\n\n        Only need to provide a minimum of two essential parameters:\n        title and tags, other video params are optional. All params spec\n        see: http://cloud.youku.com/docs?id=110#create .\n\n        Args:\n            title: string, 2-50 characters.\n            tags: string, 1-10 tags joind with comma.\n            description: string, less than 2000 characters.\n            copyright_type: string, 'original' or 'reproduced'\n            public_type: string, 'all' or 'friend' or 'password'\n            watch_password: string, if public_type is password.\n            latitude: double.\n            longitude: double.\n            shoot_time: datetime.\n\n        Returns:\n            dict params that upload/create method need.\n        \"\"\"\n        params = {}\n        if title is None:\n            title = self.file_name\n        elif len(title) > 80:\n            title = title[:80]\n\n        if len(description) > 2000:\n            description = description[0:2000]\n\n        params['title'] = title\n        params['tags'] = tags\n        params['description'] = description\n        params['copyright_type'] = copyright_type\n        params['public_type'] = public_type\n        if category:\n            params['category'] = category\n        if watch_password:\n            params['watch_password'] = watch_password\n        if latitude:\n            params['latitude'] = latitude\n        if longitude:\n            params['longitude'] = longitude\n        if shoot_time:\n            params['shoot_time'] = shoot_time\n\n        return params", "response": "util method for creating video params that upload and create video files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the current upload state to file.", "response": "def _save_upload_state_to_file(self):\n        \"\"\"if create and create_file has execute, save upload state\n        to file for next resume upload if current upload process is\n        interrupted.\n        \"\"\"\n        if os.access(self.file_dir, os.W_OK | os.R_OK | os.X_OK):\n            save_file = self.file + '.upload'\n            data = {\n                'upload_token': self.upload_token,\n                'upload_server_ip': self.upload_server_ip\n            }\n            with open(save_file, 'w') as f:\n                json.dump(data, f)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload(self, params={}):\n        if self.upload_token is not None:\n            # resume upload\n            status = self.check()\n            if status['status'] != 4:\n                return self.commit()\n            else:\n                self.new_slice()\n                while self.slice_task_id != 0:\n                    self.upload_slice()\n                return self.commit()\n        else:\n            # new upload\n            self.create(self.prepare_video_params(**params))\n            self.create_file()\n            self.new_slice()\n            while self.slice_task_id != 0:\n                self.upload_slice()\n            return self.commit()", "response": "start uploading the file until upload is complete or error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_groups(self):\n        if self.settings.GROUP_FILTER:\n            ldap_groups = self.ldap.search(self.settings.GROUP_FILTER, self.settings.GROUP_ATTRIBUTES.keys())\n            self._sync_ldap_groups(ldap_groups)\n            logger.info(\"Groups are synchronized\")", "response": "Synchronize LDAP groups with local group model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsynchronizing LDAP users with local user model.", "response": "def sync_users(self):\n        \"\"\"Synchronize LDAP users with local user model.\"\"\"\n        if self.settings.USER_FILTER:\n            user_attributes = self.settings.USER_ATTRIBUTES.keys() + self.settings.USER_EXTRA_ATTRIBUTES\n            ldap_users = self.ldap.search(self.settings.USER_FILTER, user_attributes)\n            self._sync_ldap_users(ldap_users)\n            logger.info(\"Users are synchronized\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(args=sys.argv[1:]):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"filename\", nargs=1)\n    parser.add_argument(\"--granule-id\", dest=\"granule_id\",\n        help=(\n            \"Optional. Specify a granule to export metadata from.\"\n        )\n    )\n    parser.add_argument(\"--single-granule\", dest=\"single_granule\",\n        action=\"store_true\", default=False,\n        help=(\n            \"When only one granule is contained in the package, include product \"\n            \"metadata from this one granule. Fails when more than one granule \"\n            \"is contained.\"\n        )\n    )\n    parser.add_argument(\"--out-file\", \"-f\", dest=\"out_file\",\n        help=(\n            \"Specify an output file to write the metadata to. By default, the \"\n            \"XML is printed on stdout.\"\n        )\n    )\n    parser.add_argument(\"--resolution\", \"-r\", dest=\"resolution\", default=\"10\",\n        help=(\n            \"Only produce metadata for bands of this resolution (in meters). \"\n            \"Default is 10.\"\n        )\n    )\n\n    parsed = parser.parse_args(args)\n\n    try:\n        safe_pkg = s2reader.open(parsed.filename[0])\n    except IOError, e:\n        parser.error('Could not open SAFE package. Error was \"%s\"' % e)\n\n    granules = safe_pkg.granules\n\n    granule = None\n    if parsed.granule_id:\n        granule_dict = dict(\n            (granule.granule_identifier, granule) for granule in granules\n        )\n        try:\n            granule = granule_dict[parsed.granule_id]\n        except KeyError:\n            parser.error('No such granule %r' % parsed.granule_id)\n\n    elif parsed.single_granule:\n        if len(granules) > 1:\n            parser.error('Package contains more than one granule.')\n\n        granule = granules[0]\n\n    params = _get_product_template_params(safe_pkg, parsed.resolution)\n\n    if granule:\n        params.update(_get_granule_template_params(granule, parsed.resolution))\n        xml_string = EOOM_TEMPLATE_GRANULE.format(**params)\n    else:\n        xml_string = EOOM_TEMPLATE_PRODUCT.format(**params)\n\n    if parsed.out_file:\n        with open(parsed.out_file, \"w\") as f:\n            f.write(xml_string)\n    else:\n        print(xml_string)", "response": "Generate EO O & M XML metadata from a SAFE package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_videos_by_tag(self, tag, category=None,\n                             period='today',\n                             orderby='relevance',\n                             page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=80\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/searches/video/by_tag.json'\n        params = {\n            'client_id': self.client_id,\n            'tag': tag,\n            'period': period,\n            'orderby': orderby,\n            'page': page,\n            'count': count\n        }\n        if category:\n            params['category'] = category\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "Search for videos by tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_videos_by_keyword(self, keyword, category=None,\n                                 period='week', orderby='relevance',\n                                 public_type='all', paid=None,\n                                 timeless=None, timemore=None,\n                                 streamtypes=None,\n                                 page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=81\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/searches/video/by_keyword.json'\n        params = {\n            'client_id': self.client_id,\n            'keyword': keyword,\n            'category': category,\n            'period': period,\n            'orderby': orderby,\n            'public_type': public_type,\n            'paid': paid,\n            'timeless': timeless,\n            'timemore': timemore,\n            'streamtypes': streamtypes,\n            'page': page,\n            'count': count\n        }\n        params = remove_none_value(params)\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "Search for videos by keyword."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_show_top_unite(self, category, genre=None, area=None,\n                              year=None, orderby=None, headnum=1,\n                              tailnum=1, onesiteflag=None,\n                              page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=86\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/searches/show/top_unite.json'\n        params = {\n            'client_id': self.client_id,\n            'category': category,\n            'genre': genre,\n            'area': area,\n            'year': year,\n            'orderby': orderby,\n            'headnum': headnum,\n            'tailnum': tailnum,\n            'onesiteflag': onesiteflag,\n            'page': page,\n            'count': count\n        }\n        params = remove_none_value(params)\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "search_show_top_unite - Returns a dict of top unite entries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a playlist by id", "response": "def find_playlist_by_id(self, playlist_id):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=66\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/playlists/show.json'\n        params = {\n            'client_id': self.client_id,\n            'playlist_id': playlist_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding playlist by ids", "response": "def find_playlists_by_ids(self, playlist_ids):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=67\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/playlists/show_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'playlist_ids': playlist_ids\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_videos_by_playlist(self, playlist_id, page=1, count=20):\n        url = 'https://openapi.youku.com/v2/playlists/videos.json'\n        params = {\n            'client_id': self.client_id,\n            'playlist_id': playlist_id,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find videos by playlist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a playlist s metadata", "response": "def update_playlist(self, access_token, playlist_id, title,\n                        tags=None, category=None, description=None):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=73\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/playlists/update.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'playlist_id': playlist_id,\n            'title': title,\n            'tags': tags,\n            'category': category,\n            'description': description\n        }\n        data = remove_none_value(data)\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_videos_to_playlist(self, access_token, playlist_id, video_ids):\n        url = 'https://openapi.youku.com/v2/playlists/video/add.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'playlist_id': playlist_id,\n            'video_ids': video_ids\n        }\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']", "response": "add videos to a playlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets cover video for playlist", "response": "def set_cover_video_for_playlist(self, access_token, playlist_id,\n                                     video_id):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=77\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/playlists/video/setcover.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'playlist_id': playlist_id,\n            'video_id': video_id\n        }\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_next_video_in_playlist(self, playlist_id, cur_video_id):\n        url = 'https://openapi.youku.com/v2/playlists/video/next.json'\n        params = {\n            'client_id': self.client_id,\n            'playlist_id': playlist_id,\n            'video_id': cur_video_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find next video in playlist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a quadkey representation from geo and level", "response": "def from_geo(geo, level):\n    \"\"\"\n    Constucts a quadkey representation from geo and level\n    geo => (lat, lon)\n    If lat or lon are outside of bounds, they will be clipped\n    If level is outside of bounds, an AssertionError is raised\n\n    \"\"\"\n    pixel = TileSystem.geo_to_pixel(geo, level)\n    tile = TileSystem.pixel_to_tile(pixel)\n    key = TileSystem.tile_to_quadkey(tile, level)\n    return QuadKey(key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_ancestor(self, node):\n        if self.level <= node.level or self.key[:len(node.key)] != node.key:\n            return None\n        return self.level - node.level", "response": "Returns True if node is an ancestor of self otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of all ancestors in descending order of level including a new instance of self", "response": "def unwind(self):\n        \"\"\" Get a list of all ancestors in descending order of level, including a new instance  of self\n        \"\"\"\n        return [ QuadKey(self.key[:l+1]) for l in reversed(range(len(self.key))) ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a comment by its id", "response": "def find_comment_by_id(self, comment_id):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=32\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/comments/show.json'\n        params = {\n            'client_id': self.client_id,\n            'comment_id': comment_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_comments_by_ids(self, comment_ids):\n        url = 'https://openapi.youku.com/v2/comments/show_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'comment_ids': comment_ids\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find_comments_by_ids - Search for comments by ids"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind comments by video", "response": "def find_comments_by_video(self, video_id, page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=35\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/comments/by_video.json'\n        params = {\n            'client_id': self.client_id,\n            'video_id': video_id,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_comments_by_me(self, access_token, page=1, count=20):\n        url = 'https://openapi.youku.com/v2/comments/by_me.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'page': page,\n            'count': count\n        }\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()", "response": "find_comments_by_me - Returns a list of comments by user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndestroy a comment from youku", "response": "def destroy_comment(self, access_token, comment_id):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=42\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/comments/destroy.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'comment_id': comment_id\n        }\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply validation rules for loaded settings.", "response": "def validate(self):\n        \"\"\"Apply validation rules for loaded settings.\"\"\"\n        if self.GROUP_ATTRIBUTES and self.GROUPNAME_FIELD not in self.GROUP_ATTRIBUTES.values():\n            raise ImproperlyConfigured(\"LDAP_SYNC_GROUP_ATTRIBUTES must contain '%s'\" % self.GROUPNAME_FIELD)\n\n        if not self.model._meta.get_field(self.USERNAME_FIELD).unique:\n            raise ImproperlyConfigured(\"LDAP_SYNC_USERNAME_FIELD '%s' must be unique\" % self.USERNAME_FIELD)\n\n        if self.USER_ATTRIBUTES and self.USERNAME_FIELD not in self.USER_ATTRIBUTES.values():\n            raise ImproperlyConfigured(\"LDAP_SYNC_USER_ATTRIBUTES must contain '%s'\" % self.USERNAME_FIELD)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_active_directory_enabled(user, attributes, created, updated):\n    try:\n        user_account_control = int(attributes['userAccountControl'][0])\n        if user_account_control & 2:\n            user.is_active = False\n        else:\n            user.is_active = True\n    except KeyError:\n        pass", "response": "Sets the user s is_active attribute to True if the user s Active Directory is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_video_by_id(self, video_id):\n        url = 'https://openapi.youku.com/v2/videos/show_basic.json'\n        params = {\n            'client_id': self.client_id,\n            'video_id': video_id\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find video by id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_video_by_url(self, video_url):\n        url = 'https://openapi.youku.com/v2/videos/show_basic.json'\n        params = {\n            'client_id': self.client_id,\n            'video_url': video_url\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find video by url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_videos_by_ids(self, video_ids):\n        url = 'https://openapi.youku.com/v2/videos/show_basic_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'video_ids': video_ids\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find videos by ids"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding video detail by id", "response": "def find_video_detail_by_id(self, video_id, ext=None):\n        \"\"\"doc: http://cloud.youku.com/docs?id=46\n        \"\"\"\n        url = 'https://api.youku.com/videos/show.json'\n        params = {\n            'client_id': self.client_id,\n            'video_id': video_id\n        }\n        if ext:\n            params['ext'] = ext\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_video_details_by_ids(self, video_ids, ext=None):\n        url = 'https://openapi.youku.com/v2/videos/show_batch.json'\n        params = {\n            'client_id': self.client_id,\n            'video_ids': video_ids\n        }\n        if ext:\n            params['ext'] = ext\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()", "response": "find video details by ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_video(self, access_token, video_id, title=None,\n                     tags=None, category=None, copyright_type=None,\n                     public_type=None, watch_password=None,\n                     description=None, thumbnail_seq=None):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=50\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/videos/update.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'video_id': video_id,\n            'title': title,\n            'tags': tags,\n            'category': category,\n            'copyright_type': copyright_type,\n            'public_type': public_type,\n            'watch_password': watch_password,\n            'description': description,\n            'thumbnail_seq': thumbnail_seq\n        }\n        data = remove_none_value(data)\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']", "response": "Update the video with optional parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds videos by related video_id", "response": "def find_videos_by_related(self, video_id, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=52\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/videos/by_related.json'\n        params = {\n            'client_id': self.client_id,\n            'video_id': video_id,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the user s favorite videos by user_id", "response": "def find_favorite_videos_by_userid(self, user_id,\n                                       orderby='favorite-time',\n                                       page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=54\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/videos/favorite/by_user.json'\n        params = {\n            'client_id': self.client_id,\n            'user_id': user_id,\n            'orderby': orderby,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the user s favorite videos by their username", "response": "def find_favorite_videos_by_username(self, user_name,\n                                         orderby='favorite-time',\n                                         page=1, count=20):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=54\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/videos/favorite/by_user.json'\n        params = {\n            'client_id': self.client_id,\n            'user_name': user_name,\n            'orderby': orderby,\n            'page': page,\n            'count': count\n        }\n        r = requests.get(url, params=params)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_favorite_video(self, access_token, video_id):\n        url = 'https://openapi.youku.com/v2/videos/favorite/create.json'\n        data = {\n            'client_id': self.client_id,\n            'access_token': access_token,\n            'video_id': video_id\n        }\n        r = requests.post(url, data=data)\n        check_error(r)\n        return r.json()['id']", "response": "create a new user s user s user s site"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the configured LDAP server.", "response": "def search(self, filterstr, attrlist):\n        \"\"\"Query the configured LDAP server.\"\"\"\n        return self._paged_search_ext_s(self.settings.BASE, ldap.SCOPE_SUBTREE, filterstr=filterstr,\n                                        attrlist=attrlist, page_size=self.settings.PAGE_SIZE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _paged_search_ext_s(self, base, scope, filterstr='(objectClass=*)', attrlist=None, attrsonly=0,\n                            serverctrls=None, clientctrls=None, timeout=-1, sizelimit=0, page_size=10):\n        \"\"\"\n        Behaves similarly to LDAPObject.search_ext_s() but internally uses the\n        simple paged results control to retrieve search results in chunks.\n\n        Taken from the python-ldap paged_search_ext_s.py demo, showing how to use\n        the paged results control: https://bitbucket.org/jaraco/python-ldap/\n        \"\"\"\n        request_ctrl = SimplePagedResultsControl(True, size=page_size, cookie='')\n        results = []\n\n        while True:\n            msgid = self.conn.search_ext(base, scope, filterstr=filterstr, attrlist=attrlist, attrsonly=attrsonly,\n                                         serverctrls=(serverctrls or []) + [request_ctrl], clientctrls=clientctrls,\n                                         timeout=timeout, sizelimit=sizelimit)\n            result_type, result_data, result_msgid, result_ctrls = self.conn.result3(msgid)\n            results.extend(result_data)\n\n            # Extract the simple paged results response control\n            paged_ctrls = [c for c in result_ctrls if c.controlType == SimplePagedResultsControl.controlType]\n\n            if paged_ctrls and paged_ctrls[0].cookie:\n                # Copy cookie from response control to request control\n                request_ctrl.cookie = paged_ctrls[0].cookie\n            else:\n                break\n\n        return results", "response": "This is a simple paged search_ext_s implementation that uses the simple paged results control to retrieve search results in chunks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload spec to youku", "response": "def upload_spec(self):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=91\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/schemas/upload/spec.json'\n        r = requests.get(url)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comment_expression(self):\n        url = 'https://openapi.youku.com/v2/schemas/comment/expression.json'\n        r = requests.get(url)\n        check_error(r)\n        return r.json()", "response": "doc: http://open. youku. com / docs / doc?id = 92\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_category(self):\n        url = 'https://openapi.youku.com/v2/schemas/show/category.json'\n        r = requests.get(url)\n        check_error(r)\n        return r.json()", "response": "show_category - Returns the category of youku"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the category of youku", "response": "def playlist_category(self):\n        \"\"\"doc: http://open.youku.com/docs/doc?id=94\n        \"\"\"\n        url = 'https://openapi.youku.com/v2/schemas/playlist/category.json'\n        r = requests.get(url)\n        check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef searche_top_category(self):\n        url = 'https://openapi.youku.com/v2/schemas/searche/top/category.json'\n        r = requests.get(url)\n        check_error(r)\n        return r.json()", "response": "get the top category of youku"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, feature_id, name, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.set_name(feature_id, name, organism=organism, sequence=sequence)", "response": "Set a feature s name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.delete_sequence_alteration(feature_id, organism=organism, sequence=sequence)", "response": "Delete a specific feature alteration"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_lid(self, woeid):\n        rss = self._fetch_xml(LID_LOOKUP_URL.format(woeid, \"f\"))\n\n        # We are pulling the LID from the permalink tag in the XML file\n        # returned by Yahoo.\n\n        try:\n            link = rss.find(\"channel/link\").text\n        except AttributeError:\n            return None\n\n        # use regex or string.split\n        # regex assumes the format XXXXNNNN for the LID.\n        # string.split works more general of the context.\n\n        lid = re.search(\"[A-Za-z]{4}[0-9]{4}\", link).group()\n        # lid = link.split(\"/forecast/\")[1].split(\"_\")[0]\n\n        return lid", "response": "Fetch a location s corresponding LID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching a location s weather.", "response": "def fetch_weather(self, id, metric=False):\n        \"\"\"Fetch a location's weather.\n\n        *id* can be either a WOEID or LID. The weather data returned for each\n        is identical except that the WOEID returns a 2-day forecast and the LID\n        returns a 5-day forecast. The LID uses an undocumented API, so use it\n        at your own risk.\n\n        Args:\n            id: (string) the location's WOEID or LID.\n            metric: (bool) return metric data; defaults to False.\n\n        Returns:\n            a dict containing the location's weather data or None if\n                the weather data couldn't be fetched.\n\n        Raises:\n            urllib.error.URLError: urllib.request could not open the URL\n                (Python 3).\n            urllib2.URLError: urllib2 could not open the URL (Python 2).\n            xml.etree.ElementTree.ParseError: xml.etree.ElementTree failed to\n                parse the XML document.\n\n        \"\"\"\n\n        units = \"c\" if metric else \"f\"\n\n        # WOEID is a 32-bit integer, while LID is XXXXNNNN, where X is a letter\n        # and N is a number. So, we pick the URL to use based on whether or not\n        # the *id* begins with a letter.\n\n        if re.match(\"^[A-Za-z]\", id):\n            url = LID_WEATHER_URL.format(id, units)\n        else:\n            url = WEATHER_URL.format(id, units)\n\n        rss = self._fetch_xml(url)\n\n        if rss.find(\"channel/item/title\").text == \"City not found\":\n            return None\n\n        # xml_items details which tags should be read and what their\n        # destination dict key should be. These tags don't appear\n        # multiple times.\n        # {XML tag: [ElementTree access method, dict key]}\n\n        xml_items = {\n            \"channel/title\": [\"text\", \"title\"],\n            \"channel/link\": [\"text\", \"link\"],\n            \"channel/language\": [\"text\", \"language\"],\n            \"channel/description\": [\"text\", \"description\"],\n            \"channel/lastBuildDate\": [\"text\", \"lastBuildDate\"],\n            \"channel/ttl\": [\"text\", \"ttl\"],\n            \"channel/image/url\": [\"text\", \"logo\"],\n            \"channel/item/guid\": [\"text\", \"guid\"],\n            \"channel/{%s}location\" % WEATHER_NS:\n                [\"attrib\", \"location\"],\n            # \"channel/{%s}units\" % WEATHER_NS:\n            #     [\"attrib\", \"units\"],\n            \"channel/{%s}wind\" % WEATHER_NS:\n                [\"attrib\", \"wind\"],\n            \"channel/{%s}atmosphere\" % WEATHER_NS:\n                [\"attrib\", \"atmosphere\"],\n            \"channel/{%s}astronomy\" % WEATHER_NS:\n                [\"attrib\", \"astronomy\"],\n            \"channel/item/{%s}condition\" % WEATHER_NS:\n                [\"attrib\", \"condition\"],\n        }\n        weather = {}\n        weather[\"units\"] = UNITS[units]\n\n        for (tag, meta) in xml_items.items():\n            if meta[0] == \"text\":\n                try:\n                    weather[meta[1]] = rss.find(tag).text\n                except AttributeError:\n                    weather[meta[1]] = None\n            elif meta[0] == \"attrib\":\n                try:\n                    weather[meta[1]] = rss.find(tag).attrib\n                except AttributeError:\n                    weather[meta[1]] = None\n            else:\n                weather[meta[1]] = None\n\n        try:\n            image_url = CONDITION_IMAGE_URL.format(weather[\"condition\"][\"code\"])\n            weather[\"condition\"][\"image\"] = image_url\n        except (AttributeError, TypeError):\n            pass\n\n        try:\n            state = weather[\"atmosphere\"][\"rising\"]\n            if state == \"0\":\n                weather[\"atmosphere\"][\"state\"] = \"steady\"\n            elif state == \"1\":\n                weather[\"atmosphere\"][\"state\"] = \"rising\"\n            elif state == \"2\":\n                weather[\"atmosphere\"][\"state\"] = \"falling\"\n            else:\n                weather[\"atmosphere\"][\"state\"] = None\n        except (AttributeError, TypeError):\n            pass\n\n        weather[\"forecast\"] = []\n        try:\n            for item in rss.findall(\n                    \"channel/item/{%s}forecast\" % WEATHER_NS):\n                weather[\"forecast\"].append(item.attrib)\n        except AttributeError:\n            weather[\"forecast\"] = None\n\n        weather[\"geo\"] = {}\n        try:\n            weather[\"geo\"][\"lat\"] = rss.find(\n                \"channel/item/{%s}lat\" % GEO_NS).text\n            weather[\"geo\"][\"long\"] = rss.find(\n                \"channel/item/{%s}long\" % GEO_NS).text\n        except AttributeError:\n            weather[\"geo\"] = None\n\n        try:\n            weather[\"wind\"][\"compass\"] = self._degrees_to_direction(\n                weather[\"wind\"][\"direction\"])\n        except TypeError:\n            pass\n\n        return weather"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a location s corresponding WOEID.", "response": "def fetch_woeid(self, location):\n        \"\"\"Fetch a location's corresponding WOEID.\n\n        Args:\n            location: (string) a location (e.g. 23454 or Berlin, Germany).\n\n        Returns:\n            a string containing the location's corresponding WOEID or None if\n                the WOEID could not be found.\n\n        Raises:\n            urllib.error.URLError: urllib.request could not open the URL\n                (Python 3).\n            urllib2.URLError: urllib2 could not open the URL (Python 2).\n            xml.etree.ElementTree.ParseError: xml.etree.ElementTree failed to\n                parse the XML document.\n\n        \"\"\"\n        rss = self._fetch_xml(\n            WOEID_LOOKUP_URL.format(quote(location)))\n        try:\n            woeid = rss.find(\"results/Result/woeid\").text\n        except AttributeError:\n            return None\n        return woeid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert wind direction from degrees to compass direction.", "response": "def _degrees_to_direction(self, degrees):\n        \"\"\"Convert wind direction from degrees to compass direction.\"\"\"\n        try:\n            degrees = float(degrees)\n        except ValueError:\n            return None\n        if degrees < 0 or degrees > 360:\n            return None\n        if degrees <= 11.25 or degrees >= 348.76:\n            return \"N\"\n        elif degrees <= 33.75:\n            return \"NNE\"\n        elif degrees <= 56.25:\n            return \"NE\"\n        elif degrees <= 78.75:\n            return \"ENE\"\n        elif degrees <= 101.25:\n            return \"E\"\n        elif degrees <= 123.75:\n            return \"ESE\"\n        elif degrees <= 146.25:\n            return \"SE\"\n        elif degrees <= 168.75:\n            return \"SSE\"\n        elif degrees <= 191.25:\n            return \"S\"\n        elif degrees <= 213.75:\n            return \"SSW\"\n        elif degrees <= 236.25:\n            return \"SW\"\n        elif degrees <= 258.75:\n            return \"WSW\"\n        elif degrees <= 281.25:\n            return \"W\"\n        elif degrees <= 303.75:\n            return \"WNW\"\n        elif degrees <= 326.25:\n            return \"NW\"\n        elif degrees <= 348.75:\n            return \"NNW\"\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fetch_xml(self, url):\n        with contextlib.closing(urlopen(url)) as f:\n            return xml.etree.ElementTree.parse(f).getroot()", "response": "Fetch a url and parse the document s XML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, feature_id, symbol, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.set_symbol(feature_id, symbol, organism=organism, sequence=sequence)", "response": "Set a feature s description"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx, feature={}, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.add_feature(feature=feature, organism=organism, sequence=sequence)", "response": "Add a feature\nOutput"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an organism Output: a dictionary with information about the new organism", "response": "def cli(ctx, common_name, directory, blatdb=\"\", genus=\"\", species=\"\", public=False):\n    \"\"\"Add an organism\n\nOutput:\n\n    a dictionary with information about the new organism\n    \"\"\"\n    return ctx.gi.organisms.add_organism(common_name, directory, blatdb=blatdb, genus=genus, species=species, public=public)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the Apollo s Arrow configuration.", "response": "def cli(ctx, url=None, api_key=None, admin=False, **kwds):\n    \"\"\"Help initialize global configuration (in home directory)\n    \"\"\"\n    # TODO: prompt for values someday.\n    click.echo(\"\"\"Welcome to Apollo's Arrow!\"\"\")\n    if os.path.exists(config.global_config_path()):\n        info(\"Your arrow configuration already exists. Please edit it instead: %s\" % config.global_config_path())\n        return 0\n\n    while True:\n        apollo_url= click.prompt(\"Please entry your Apollo's URL\")\n        apollo_username = click.prompt(\"Please entry your Apollo Username\")\n        apollo_password = click.prompt(\"Please entry your Apollo Password\", hide_input=True)\n        info(\"Testing connection...\")\n        try:\n            ai = ApolloInstance(apollo_url, apollo_username, apollo_password)\n            try:\n                ai.metrics.get_metrics()\n                # Ok, success\n                info(\"Ok! Everything looks good.\")\n                break\n            except Exception as e:\n                print(e)\n                warn(\"Error, we could not access the configuration data for your instance.\")\n                should_break = click.prompt(\"Continue despite inability to contact this Apollo Instance? [y/n]\")\n                if should_break in ('Y', 'y'):\n                    break\n        except Exception as e:\n            warn(\"Error, we could not access the configuration data for your instance.\")\n            should_break = click.prompt(\"Continue despite inability to contact this Apollo Instance? [y/n]\")\n            if should_break in ('Y', 'y'):\n                break\n\n    config_path = config.global_config_path()\n    if os.path.exists(config_path):\n        warn(\"File %s already exists, refusing to overwrite.\" % config_path)\n        return -1\n    with open(config_path, \"w\") as f:\n        f.write(\n            CONFIG_TEMPLATE % {\n                'url': apollo_url,\n                'username': apollo_username,\n                'password': apollo_password,\n            })\n        info(SUCCESS_MESSAGE)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a canned key", "response": "def cli(ctx, id_number, new_key, metadata=\"\"):\n    \"\"\"Update a canned key\n\nOutput:\n\n    an empty dictionary\n    \"\"\"\n    return ctx.gi.cannedkeys.update_key(id_number, new_key, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a single organism", "response": "def cli(ctx, organism, export_type=\"FASTA\", seq_type=\"peptide\", export_format=\"text\", export_gff3_fasta=False, sequences=None, region=\"\"):\n    \"\"\"Prepare a download for an organism\n\nOutput:\n\n    a dictionary containing download information\n    \"\"\"\n    return ctx.gi.io.write_downloadable(organism, export_type=export_type, seq_type=seq_type, export_format=export_format, export_gff3_fasta=export_gff3_fasta, sequences=sequences, region=region)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx, transcript={}, suppress_history=False, suppress_events=False, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.add_transcript(transcript=transcript, suppress_history=suppress_history, suppress_events=suppress_events, organism=organism, sequence=sequence)", "response": "Add a transcript to a feature\n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_value(self, value, metadata=\"\"):\n        data = {\n            'value': value,\n            'metadata': metadata\n        }\n\n        return self.post('createValue', data)", "response": "Adds a new canned value to the local canned value list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_value(self, value):\n        values = self.get_values()\n        values = [x for x in values if x['label'] == value]\n        if len(values) == 0:\n            raise Exception(\"Unknown value\")\n        else:\n            return values[0]", "response": "Get a specific canned value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_value(self, id_number, new_value, metadata=None):\n        data = {\n            'id': id_number,\n            'new_value': new_value\n        }\n\n        if metadata is not None:\n            data['metadata'] = metadata\n\n        return self.post('updateValue', data)", "response": "Update a canned value with a new value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a canned key to the cable.", "response": "def add_key(self, key, metadata=\"\"):\n        \"\"\"\n        Add a canned key\n\n        :type key: str\n        :param key: New canned key\n\n        :type metadata: str\n        :param metadata: Optional metadata\n\n        :rtype: dict\n        :return: A dictionnary containing canned key description\n        \"\"\"\n        data = {\n            'key': key,\n            'metadata': metadata\n        }\n\n        return self.post('createKey', data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_key(self, value):\n        keys = self.get_keys()\n        keys = [x for x in keys if x['label'] == value]\n        if len(keys) == 0:\n            raise Exception(\"Unknown key\")\n        else:\n            return keys[0]", "response": "Get a specific canned key from the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a canned key", "response": "def update_key(self, id_number, new_key, metadata=None):\n        \"\"\"\n        Update a canned key\n\n        :type id_number: int\n        :param id_number: canned key ID number\n\n        :type new_key: str\n        :param new_key: New canned key value\n\n        :type metadata: str\n        :param metadata: Optional metadata\n\n        :rtype: dict\n        :return: an empty dictionary\n        \"\"\"\n        data = {\n            'id': id_number,\n            'new_key': new_key\n        }\n\n        if metadata is not None:\n            data['metadata'] = metadata\n\n        return self.post('updateKey', data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(ctx, id_number, new_value, metadata=\"\"):\n    return ctx.gi.cannedvalues.update_value(id_number, new_value, metadata=metadata)", "response": "Update a canned value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(self, dest_pattern=\"{originalFilename}\", override=True, parent=False):\n        if self.id is None:\n            raise ValueError(\"Cannot download image with no ID.\")\n\n        pattern = re.compile(\"{(.*?)}\")\n        dest_pattern = re.sub(pattern, lambda m: str(getattr(self, str(m.group(0))[1:-1], \"_\")), dest_pattern)\n        parameters = {\"parent\": parent}\n\n        destination = os.path.dirname(dest_pattern)\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n\n        return Cytomine.get_instance().download_file(\"{}/{}/download\".format(self.callback_identifier, self.id),\n                                                     dest_pattern, override, parameters)", "response": "Download the original image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(self, dest_pattern=\"{id}.jpg\", override=True, max_size=None, bits=8, contrast=None, gamma=None,\n             colormap=None, inverse=None):\n        \"\"\"\n        Download the image with optional image modifications.\n\n        Parameters\n        ----------\n        dest_pattern : str, optional\n            Destination path for the downloaded image. \"{X}\" patterns are replaced by the value of X attribute\n            if it exists.\n        override : bool, optional\n            True if a file with same name can be overrided by the new file.\n        max_size : int, tuple, optional\n            Maximum size (width or height) of returned image. None to get original size.\n        bits : int (8,16,32) or str (\"max\"), optional\n            Bit depth (bit per channel) of returned image. \"max\" returns the original image bit depth\n        contrast : float, optional\n            Optional contrast applied on returned image.\n        gamma : float, optional\n            Optional gamma applied on returned image.\n        colormap : int, optional\n            Cytomine identifier of a colormap to apply on returned image.\n        inverse : bool, optional\n            True to inverse color mapping, False otherwise.\n\n        Returns\n        -------\n        downloaded : bool\n            True if everything happens correctly, False otherwise. As a side effect, object attribute \"filename\"\n            is filled with downloaded file path.\n        \"\"\"\n        if self.id is None:\n            raise ValueError(\"Cannot dump an annotation with no ID.\")\n\n        pattern = re.compile(\"{(.*?)}\")\n        dest_pattern = re.sub(pattern, lambda m: str(getattr(self, str(m.group(0))[1:-1], \"_\")), dest_pattern)\n\n        destination = os.path.dirname(dest_pattern)\n        filename, extension = os.path.splitext(os.path.basename(dest_pattern))\n        extension = extension[1:]\n\n        if extension not in (\"jpg\", \"png\", \"tif\", \"tiff\"):\n            extension = \"jpg\"\n\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n\n        if isinstance(max_size, tuple) or max_size is None:\n            max_size = max(self.width, self.height)\n\n        parameters = {\n            \"maxSize\": max_size,\n            \"contrast\": contrast,\n            \"gamma\": gamma,\n            \"colormap\": colormap,\n            \"inverse\": inverse,\n            \"bits\": bits\n        }\n\n        file_path = os.path.join(destination, \"{}.{}\".format(filename, extension))\n\n        url = self.preview[:self.preview.index(\"?\")]\n        url = url.replace(\".png\", \".{}\".format(extension))\n        result = Cytomine.get_instance().download_file(url, file_path, override, parameters)\n        if result:\n            self.filename = file_path\n        return result", "response": "Dump the image with optional image modifications."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a window from an image and download it.", "response": "def window(self, x, y, w, h, dest_pattern=\"{id}-{x}-{y}-{w}-{h}.jpg\", override=True, mask=None, alpha=None,\n               bits=8, annotations=None, terms=None, users=None, reviewed=None):\n        \"\"\"\n        Extract a window (rectangle) from an image and download it.\n\n        Parameters\n        ----------\n        x : int\n            The X position of window top-left corner. 0 is image left.\n        y : int\n            The Y position of window top-left corner. 0 is image top.\n        w : int\n            The window width\n        h : int\n            The window height\n        dest_pattern : str, optional\n            Destination path for the downloaded image. \"{X}\" patterns are replaced by the value of X attribute\n            if it exists.\n        override : bool, optional\n            True if a file with same name can be overrided by the new file.\n        mask : bool, optional\n            True if a binary mask based on given annotations must be returned, False otherwise.\n        alpha : bool, optional\n            True if image background (outside annotations) must be transparent, False otherwise.\n        bits : int (8/16/32), optional\n            Optional output bit depth of returned images\n        annotations : list of int, optional\n            If mask=True or alpha=True, annotation identifiers that must be taken into account for masking\n        terms : list of int, optional\n            If mask=True or alpha=True, term identifiers that must be taken into account for masking\n        users : list of int, optional\n            If mask=True or alpha=True, user identifiers that must be taken into account for masking\n        reviewed : bool, optional\n            If mask=True or alpha=True, indicate if only reviewed annotations mut be taken into account for masking\n\n        Returns\n        -------\n        downloaded : bool\n            True if everything happens correctly, False otherwise.\n        \"\"\"\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        pattern = re.compile(\"{(.*?)}\")\n        dest_pattern = re.sub(pattern, lambda m: str(getattr(self, str(m.group(0))[1:-1], \"_\")), dest_pattern)\n        del self.x\n        del self.y\n        del self.w\n        del self.h\n\n        destination = os.path.dirname(dest_pattern)\n        filename, extension = os.path.splitext(os.path.basename(dest_pattern))\n        extension = extension[1:]\n\n        if extension not in (\"jpg\", \"png\", \"tif\", \"tiff\"):\n            extension = \"jpg\"\n\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n\n        if mask is None and alpha is None:\n            alphamask = None\n        elif mask and alpha:\n            alphamask = True\n            if extension == \"jpg\":\n                extension = \"png\"\n        else:\n            alphamask = False\n\n        # Temporary fix due to Cytomine-core\n        if mask is not None:\n            mask = str(mask).lower()\n\n        if alphamask is not None:\n            alphamask = str(alphamask).lower()\n        # ===\n\n        parameters = {\n            \"annotations\": \",\".join(str(item) for item in annotations) if annotations else None,\n            \"terms\": \",\".join(str(item) for item in terms) if terms else None,\n            \"users\": \",\".join(str(item) for item in users) if users else None,\n            \"reviewed\": reviewed,\n            \"bits\": bits,\n            \"mask\": mask,\n            \"alphaMask\": alphamask\n        }\n\n        file_path = os.path.join(destination, \"{}.{}\".format(filename, extension))\n\n        return Cytomine.get_instance().download_file(\"{}/{}/window-{}-{}-{}-{}.{}\".format(\n            self.callback_identifier, self.id, x, y, w, h, extension), file_path, override, parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning iterator based on element_type.", "response": "def filtered_elements(self, model):\n        \"\"\"Return iterator based on `element_type`.\"\"\"\n        if isinstance(model, self.element_type):\n            yield model\n        yield from (e for e in model.eAllContents() if isinstance(e, self.element_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns path to folder holding generated artifact for given element.", "response": "def folder_path_for_package(cls, package: ecore.EPackage):\n        \"\"\"Returns path to folder holding generated artifact for given element.\"\"\"\n        parent = package.eContainer()\n        if parent:\n            return os.path.join(cls.folder_path_for_package(parent), package.name)\n        return package.name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine which classifiers have to be imported into given package.", "response": "def imported_classifiers_package(p: ecore.EPackage):\n        \"\"\"Determines which classifiers have to be imported into given package.\"\"\"\n        classes = {c for c in p.eClassifiers if isinstance(c, ecore.EClass)}\n\n        references = itertools.chain(*(c.eAllReferences() for c in classes))\n        references_types = (r.eType for r in references)\n        imported = {c for c in references_types if getattr(c, 'ePackage', p) is not p}\n\n        imported_dict = {}\n        for classifier in imported:\n            imported_dict.setdefault(classifier.ePackage, set()).add(classifier)\n\n        return imported_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef imported_classifiers(p: ecore.EPackage):\n        classes = {c for c in p.eClassifiers if isinstance(c, ecore.EClass)}\n\n        supertypes = itertools.chain(*(c.eAllSuperTypes() for c in classes))\n        imported = {c for c in supertypes if c.ePackage is not p}\n\n        attributes = itertools.chain(*(c.eAttributes for c in classes))\n        attributes_types = (a.eType for a in attributes)\n        imported |= {t for t in attributes_types if t.ePackage not in {p, ecore.eClass, None}}\n\n        imported_dict = {}\n        for classifier in imported:\n            imported_dict.setdefault(classifier.ePackage, set()).add(classifier)\n\n        return imported_dict", "response": "Determines which classifiers have to be imported into given module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classes(p: ecore.EPackage):\n        classes = (c for c in p.eClassifiers if isinstance(c, ecore.EClass))\n        return sorted(classes, key=lambda c: len(set(c.eAllSuperTypes())))", "response": "Returns classes in package in ordered by number of bases."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_all_contents(value: ecore.EPackage, type_):\n        return (c for c in value.eAllContents() if isinstance(c, type_))", "response": "Returns a list of all contents of type type_."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_pyfqn(cls, value, relative_to=0):\n\n        def collect_packages(element, packages):\n            parent = element.eContainer()\n            if parent:\n                collect_packages(parent, packages)\n            packages.append(element.name)\n\n        packages = []\n        collect_packages(value, packages)\n\n        if relative_to < 0 or relative_to > len(packages):\n            raise ValueError('relative_to not in range of number of packages')\n\n        fqn = '.'.join(packages[relative_to:])\n\n        if relative_to:\n            fqn = '.' + fqn\n\n        return cls.module_path_map.get(fqn, fqn)", "response": "Returns Python form of fully qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_environment(self, **kwargs):\n        environment = super().create_environment(**kwargs)\n        environment.tests.update({\n            'type': self.test_type,\n            'kind': self.test_kind,\n            'opposite_before_self': self.test_opposite_before_self,\n        })\n        environment.filters.update({\n            'docstringline': self.filter_docstringline,\n            'pyquotesingle': self.filter_pyquotesingle,\n            'derivedname': self.filter_derived_name,\n            'refqualifiers': self.filter_refqualifiers,\n            'attrqualifiers': self.filter_attrqualifiers,\n            'supertypes': self.filter_supertypes,\n            'all_contents': self.filter_all_contents,\n            'pyfqn': self.filter_pyfqn,\n            're_sub': lambda v, p, r: re.sub(p, r, v),\n            'set': self.filter_set,\n        })\n\n        from pyecore import ecore\n        environment.globals.update({'ecore': ecore})\n\n        return environment", "response": "Create a new Jinja environment with all the necessary variables set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(self, model, outfolder, *, exclude=None):\n        with pythonic_names():\n            super().generate(model, outfolder)\n\n            check_dependency = self.with_dependencies and model.eResource\n            if check_dependency:\n                if exclude is None:\n                    exclude = set()\n                resource = model.eResource\n                # the current resource had been managed and is excluded from further generations\n                exclude.add(resource)\n                rset = resource.resource_set\n                direct_resources = {r for r in rset.resources.values() if r not in exclude}\n                for resource in direct_resources:\n                    self.generate(resource.contents[0], outfolder, exclude=exclude)", "response": "Generate code for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a dbxref from a feature", "response": "def cli(ctx, feature_id, db, accession, organism=\"\", sequence=\"\"):\n    \"\"\"Delete a dbxref from a feature\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.delete_dbxref(feature_id, db, accession, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_organism(self, common_name, directory, blatdb=None, genus=None,\n                     species=None, public=False):\n        \"\"\"\n        Add an organism\n\n        :type common_name: str\n        :param common_name: Organism common name\n\n        :type directory: str\n        :param directory: Server-side directory\n\n        :type blatdb: str\n        :param blatdb: Server-side Blat directory for the organism\n\n        :type genus: str\n        :param genus: Genus\n\n        :type species: str\n        :param species: Species\n\n        :type public: bool\n        :param public: User's email\n\n        :rtype: dict\n        :return: a dictionary with information about the new organism\n        \"\"\"\n        data = {\n            'commonName': common_name,\n            'directory': directory,\n            'publicMode': public,\n        }\n\n        if blatdb is not None:\n            data['blatdb'] = blatdb\n        if genus is not None:\n            data['genus'] = genus\n        if species is not None:\n            data['species'] = species\n\n        response = self.post('addOrganism', data)\n        # Apollo decides here that it would be nice to return information about\n        # EVERY organism. LMAO.\n        if type(response) is not list:\n            return response\n        return [x for x in response if x['commonName'] == common_name][0]", "response": "Adds an organism to the LMAO server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_organism(self, organism_id, common_name, directory, blatdb=None, species=None, genus=None, public=False):\n        data = {\n            'id': organism_id,\n            'name': common_name,\n            'directory': directory,\n            'publicMode': public,\n        }\n\n        if blatdb is not None:\n            data['blatdb'] = blatdb\n        if genus is not None:\n            data['genus'] = genus\n        if species is not None:\n            data['species'] = species\n\n        response = self.post('updateOrganismInfo', data)\n        if len(response.keys()) == 0:\n            return self.show_organism(organism_id)\n        return response", "response": "Update an organism with new information"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the feature to read through the first encountered stop codon", "response": "def cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    \"\"\"Set the feature to read through the first encountered stop codon\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.set_readthrough_stop_codon(feature_id, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, exon_a, exon_b, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.merge_exons(exon_a, exon_b, organism=organism, sequence=sequence)", "response": "Merge two exons\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a status name Output: an empty dictionary", "response": "def cli(ctx, id_number, new_value):\n    \"\"\"Update a status name\n\nOutput:\n\n    an empty dictionary\n    \"\"\"\n    return ctx.gi.status.update_status(id_number, new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a feature s description", "response": "def cli(ctx, feature_id, description, organism=\"\", sequence=\"\"):\n    \"\"\"Set a feature's description\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.set_description(feature_id, description, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a user from a group", "response": "def cli(ctx, group, user):\n    \"\"\"Remove a user from a group\n\nOutput:\n\n    an empty dictionary\n    \"\"\"\n    return ctx.gi.users.remove_from_group(group, user)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a feature s end date", "response": "def cli(ctx, feature_id, end, organism=\"\", sequence=\"\"):\n    \"\"\"Set a feature's end\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.set_translation_end(feature_id, end, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nduplicate a transcripte Output: A standard apollo feature dictionary ({\"features\": [{...}]})", "response": "def cli(ctx, transcript_id, organism=\"\", sequence=\"\"):\n    \"\"\"Duplicate a transcripte\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.duplicate_transcript(transcript_id, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.get_feature_sequence(feature_id, organism=organism, sequence=sequence)", "response": "Get the sequence of a feature"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget information about a group", "response": "def show_group(self, group_id):\n        \"\"\"\n        Get information about a group\n\n        :type group_id: int\n        :param group_id: Group ID Number\n\n        :rtype: dict\n        :return: a dictionary containing group information\n        \"\"\"\n        res = self.post('loadGroups', {'groupId': group_id})\n        if isinstance(res, list):\n            return _fix_group(res[0])\n        else:\n            return _fix_group(res)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the name of a group", "response": "def update_group(self, group_id, new_name):\n        \"\"\"\n        Update the name of a group\n\n        :type group_id: int\n        :param group_id: group ID number\n\n        :type new_name: str\n        :param new_name: New name for the group\n\n        :rtype: dict\n        :return: a dictionary containing group information\n        \"\"\"\n        data = {\n            'id': group_id,\n            'name': new_name,\n        }\n        try:\n            response = self.post('updateGroup', data)\n        except Exception:\n            pass\n\n        # Apollo returns a 404 here for some unholy reason, despite actually\n        # renaming the group.\n        response = self.post('loadGroups', {'groupId': group_id})[0]\n        return _fix_group(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the group s organism permissions", "response": "def get_organism_permissions(self, group):\n        \"\"\"\n        Get the group's organism permissions\n\n        :type group: str\n        :param group: group name\n\n        :rtype: list\n        :return: a list containing organism permissions (if any)\n        \"\"\"\n        data = {\n            'name': group,\n        }\n        response = _fix_group(self.post('getOrganismPermissionsForGroup', data))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the group s permissions on an organism", "response": "def update_organism_permissions(self, group, organism_name,\n                                    administrate=False, write=False,\n                                    read=False, export=False):\n        \"\"\"\n        Update the group's permissions on an organism\n\n        :type group: str\n        :param group: group name\n\n        :type organism_name: str\n        :param organism_name: Organism name\n\n        :type administrate: bool\n        :param administrate: Should the group have administrate privileges\n\n        :type read: bool\n        :param read: Should the group have read privileges\n\n        :type write: bool\n        :param write: Should the group have write privileges\n\n        :type export: bool\n        :param export: Should the group have export privileges\n\n        :rtype: list\n        :return: list of group organism permissions\n        \"\"\"\n        data = {\n            'name': group,\n            'organism': organism_name,\n            'ADMINISTRATE': administrate,\n            'WRITE': write,\n            'EXPORT': export,\n            'READ': read,\n        }\n        response = self.post('updateOrganismPermission', data)\n        response['permissions'] = json.loads(response['permissions'])\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the group s membership with the given list of users.", "response": "def update_membership(self, group_id, users=[]):\n        \"\"\"\n        Update the group's membership\n\n        :type group_id: int\n        :param group_id: Group ID Number\n\n        :type users: list of str\n        :param users: List of emails\n\n        :rtype: dict\n        :return: dictionary of group information\n        \"\"\"\n        data = {\n            'groupId': group_id,\n            'users': users,\n        }\n        return _fix_group(self.post('updateMembership', data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_group_admin(self, group_id, users=[]):\n        data = {\n            'groupId': group_id,\n            'users': users,\n        }\n        return _fix_group(self.post('updateGroupAdmin', data))", "response": "Update the group s admins with the given list of users."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the group s admins and their local names", "response": "def get_group_admin(self, group):\n        \"\"\"\n        Get the group's admins\n\n        :type group: str\n        :param group: group name\n\n        :rtype: list\n        :return: a list containing group admins\n        \"\"\"\n        data = {\n            'name': group,\n        }\n        response = _fix_group(self.post('getGroupAdmin', data))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the group s creator", "response": "def get_group_creator(self, group):\n        \"\"\"\n        Get the group's creator\n\n        :type group: str\n        :param group: group name\n\n        :rtype: list\n        :return: creator userId\n        \"\"\"\n        data = {\n            'name': group,\n        }\n        response = _fix_group(self.post('getGroupCreator', data))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a query string for the resource cache.", "response": "def _create_query_string(params):\n        \"\"\"\n        Support Elasticsearch 5.X\n        \"\"\"\n        parameters = params or {}\n\n        for param, value in parameters.items():\n            param_value = str(value).lower() if isinstance(value, bool) else value\n            parameters[param] = param_value\n\n        return urlencode(parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(ctx, feature_id, attribute_key, attribute_value, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.delete_attribute(feature_id, attribute_key, attribute_value, organism=organism, sequence=sequence)", "response": "Delete an attribute from a feature"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_status(self, status):\n        statuses = self.get_statuses()\n        statuses = [x for x in statuses if x['value'] == status]\n        if len(statuses) == 0:\n            raise Exception(\"Unknown status value\")\n        else:\n            return statuses[0]", "response": "Get a specific status from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a status of a specific entry in the cache.", "response": "def update_status(self, id_number, new_value):\n        \"\"\"\n        Update a status name\n\n        :type id_number: int\n        :param id_number: status ID number\n\n        :type new_value: str\n        :param new_value: The new status name\n\n        :rtype: dict\n        :return: an empty dictionary\n        \"\"\"\n        data = {\n            'id': id_number,\n            'new_value': new_value\n        }\n\n        return self.post('updateStatus', data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a canned comment", "response": "def cli(ctx, id_number, new_value, metadata=\"\"):\n    \"\"\"Update a canned comment\n\nOutput:\n\n    an empty dictionary\n    \"\"\"\n    return ctx.gi.cannedcomments.update_comment(id_number, new_value, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a feature s description", "response": "def set_description(self, feature_id, description, organism=None, sequence=None):\n        \"\"\"\n        Set a feature's description\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type description: str\n        :param description: Feature description\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'description': description,\n                }\n            ]\n        }\n        data = self._update_data(data, sequence, organism)\n        return self.post('setDescription', data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_name(self, feature_id, name, organism=None, sequence=None):\n        # TODO\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'name': name,\n                }\n            ],\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setName', data)", "response": "Set a feature s name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_status(self, feature_id, status, organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'status': status,\n                }\n            ],\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setStatus', data)", "response": "Set a feature s status"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_symbol(self, feature_id, symbol, organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'symbol': symbol,\n                }\n            ],\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setSymbol', data)", "response": "Set a feature s symbol"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a feature s comments", "response": "def get_comments(self, feature_id, organism=None, sequence=None):\n        \"\"\"\n        Get a feature's comments\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                }\n            ],\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('getComments', data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_comment(self, feature_id, comments=[], organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'comments': comments\n                }\n            ],\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('addComments', data)", "response": "Adds a comment to a feature s description"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an attribute to a feature", "response": "def add_attribute(self, feature_id, attribute_key, attribute_value, organism=None, sequence=None):\n        \"\"\"\n        Add an attribute to a feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type attribute_key: str\n        :param attribute_key: Attribute Key\n\n        :type attribute_value: str\n        :param attribute_value: Attribute Value\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        This seems to show two attributes being added, but it behaves like those two are one.\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'non_reserved_properties': [\n                        {\n                            'tag': attribute_key,\n                            'value': attribute_value,\n                        }\n                    ]\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('addAttribute', data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate an attribute in a feature", "response": "def update_attribute(self, feature_id, attribute_key, old_value, new_value, organism=None, sequence=None):\n        \"\"\"\n        Delete an attribute from a feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type attribute_key: str\n        :param attribute_key: Attribute Key\n\n        :type old_value: str\n        :param old_value: Old attribute value\n\n        :type new_value: str\n        :param new_value: New attribute value\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'old_non_reserved_properties': [\n                        {\n                            'tag': attribute_key,\n                            'value': old_value,\n                        }\n                    ],\n                    'new_non_reserved_properties': [\n                        {\n                            'tag': attribute_key,\n                            'value': new_value,\n                        }\n                    ]\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('deleteAttribute', data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_dbxref(self, feature_id, db, accession, organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'dbxrefs': [\n                        {\n                            'db': db,\n                            'accession': accession,\n                        }\n                    ]\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('addDbxref', data)", "response": "Adds a dbxref to a feature"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a dbxref of a feature", "response": "def update_dbxref(self, feature_id, old_db, old_accession, new_db, new_accession, organism=None, sequence=None):\n        \"\"\"\n        Delete a dbxref from a feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type old_db: str\n        :param old_db: Old DB Name (e.g. PMID)\n\n        :type old_accession: str\n        :param old_accession: Old accession Value\n\n        :type new_db: str\n        :param new_db: New DB Name (e.g. PMID)\n\n        :type new_accession: str\n        :param new_accession: New accession Value\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                    'old_dbxrefs': [\n                        {\n                            'db': old_db,\n                            'accession': old_accession,\n                        }\n                    ],\n                    'new_dbxrefs': [\n                        {\n                            'db': new_db,\n                            'accession': new_accession,\n                        }\n                    ]\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('deleteDbxref', data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the features for an organism or sequence", "response": "def get_features(self, organism=None, sequence=None):\n        \"\"\"\n        Get the features for an organism / sequence\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {}\n        data = self._update_data(data, organism, sequence)\n        return self.post('getFeatures', data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_feature_sequence(self, feature_id, organism=None, sequence=None):\n        # Choices: peptide, cds, cdna, genomic\n        # { \"track\": \"Miro.v2\", \"features\": [ { \"uniquename\": \"714dcda6-2358-467d-855e-f495a82aa154\"  }  ], \"operation\": \"get_sequence\", \"type\": \"peptide\"  }:\n        # { \"track\": \"Miro.v2\", \"features\": [ { \"uniquename\": \"714dcda6-2358-467d-855e-f495a82aa154\"  }  ], \"operation\": \"get_sequence\", \"flank\": 500, \"type\": \"genomic\"  }:\n        # This API is not behaving as expected. Wrong documentation?\n        data = {\n            'type': 'peptide',\n            'features': [\n                {'uniquename': feature_id}\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('getSequence', data)", "response": "Get the sequence of a feature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a feature to the internal feature dictionary", "response": "def add_feature(self, feature={}, organism=None, sequence=None):\n        \"\"\"\n        Add a feature\n\n        :type feature: dict\n        :param feature: Feature information\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n\n        data = {\n            'features': feature,\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('addFeature', data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a transcript to the apollo feature dictionary", "response": "def add_transcript(self, transcript={}, suppress_history=False, suppress_events=False, organism=None, sequence=None):\n        \"\"\"\n        [UNTESTED] Add a transcript to a feature\n\n        :type transcript: dict\n        :param transcript: Transcript data\n\n        :type suppress_history: bool\n        :param suppress_history: Suppress the history of this operation\n\n        :type suppress_events: bool\n        :param suppress_events: Suppress instant update of the user interface\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'suppressHistory': suppress_history,\n            'suppressEvents': suppress_events,\n            'features': [\n                transcript\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('addTranscript', data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef duplicate_transcript(self, transcript_id, organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': transcript_id\n                }\n            ]\n        }\n\n        data = self._update_data(data, organism, sequence)\n        return self.post('duplicateTranscript', data)", "response": "Duplicate a transcripte\n\n        :type transcript_id: str\n        :param transcript_id: Transcript UUID\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_translation_start(self, feature_id, start, organism=None, sequence=None):\n        data = {\n            'features': [{\n                'uniquename': feature_id,\n                'location': {\n                    'fmin': start\n                }\n            }]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setTranslationStart', data)", "response": "Set the translation start of a feature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset a feature s end date", "response": "def set_translation_end(self, feature_id, end, organism=None, sequence=None):\n        \"\"\"\n        Set a feature's end\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type end: int\n        :param end: Feature end\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [{\n                'uniquename': feature_id,\n                'location': {\n                    'fmax': end\n                }\n            }]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setTranslationEnd', data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the boundaries of a genomic feature", "response": "def set_boundaries(self, feature_id, start, end, organism=None, sequence=None):\n        \"\"\"\n        Set the boundaries of a genomic feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type start: int\n        :param start: Feature start\n\n        :type end: int\n        :param end: Feature end\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [{\n                'uniquename': feature_id,\n                'location': {\n                    'fmin': start,\n                    'fmax': end,\n                }\n            }]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setBoundaries', data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_readthrough_stop_codon(self, feature_id, organism=None, sequence=None):\n        data = {\n            'features': [{\n                'uniquename': feature_id,\n            }]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('setReadthroughStopCodon', data)", "response": "Set the feature to read through the first encountered stop codon of the specified feature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all of the sequence s alterations", "response": "def get_sequence_alterations(self, organism=None, sequence=None):\n        \"\"\"\n        [UNTESTED] Get all of the sequence's alterations\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: list\n        :return: A list of sequence alterations(?)\n        \"\"\"\n        data = {}\n        data = self._update_data(data, organism, sequence)\n        return self.post('getSequenceAlterations', data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_sequence_alteration(self, feature_id, organism=None, sequence=None):\n        data = {\n            'features': [{\n                'uniquename': feature_id,\n            }]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('deleteSequenceAlteration', data)", "response": "Delete a specific feature alteration"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflips the strand of a feature", "response": "def flip_strand(self, feature_id, organism=None, sequence=None):\n        \"\"\"\n        Flip the strand of a feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('flipStrand', data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge two exons into a standard apollo feature dictionary.", "response": "def merge_exons(self, exon_a, exon_b, organism=None, sequence=None):\n        \"\"\"\n        Merge two exons\n\n        :type exon_a: str\n        :param exon_a: Feature UUID\n\n        :type exon_b: str\n        :param exon_b: Feature UUID\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {'uniquename': exon_a},\n                {'uniquename': exon_b},\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('mergeExons', data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a feature from the system", "response": "def delete_feature(self, feature_id, organism=None, sequence=None):\n        \"\"\"\n        Delete a feature\n\n        :type feature_id: str\n        :param feature_id: Feature UUID\n\n        :type organism: str\n        :param organism: Organism Common Name\n\n        :type sequence: str\n        :param sequence: Sequence Name\n\n        :rtype: dict\n        :return: A standard apollo feature dictionary ({\"features\": [{...}]})\n        \"\"\"\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id,\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('deleteFeature', data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_gff3(self, feature_id, organism=None, sequence=None):\n        data = {\n            'features': [\n                {\n                    'uniquename': feature_id\n                }\n            ]\n        }\n        data = self._update_data(data, organism, sequence)\n        return self.post('getGff3', data, is_json=False)", "response": "Get the GFF3 associated with a feature"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle empty user arrays.", "response": "def _handle_empty(self, user, response):\n        \"\"\"Apollo likes to return empty user arrays, even when you REALLY\n        want a user response back... like creating a user.\"\"\"\n        if len(response.keys()) == 0:\n            response = self.show_user(user)\n\n            # And sometimes show_user can return nothing. Ask again...\n            if len(response) == 0:\n                response = self.show_user(user)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all users known to this Apollo instance.", "response": "def get_users(self, omit_empty_organisms=False):\n        \"\"\"\n        Get all users known to this Apollo instance\n\n        :type omit_empty_organisms: bool\n        :param omit_empty_organisms: Will omit users having no access to any organism\n\n        :rtype: list of dicts\n        :return: list of user info dictionaries\n        \"\"\"\n        payload = {}\n        if omit_empty_organisms:\n            payload['omitEmptyOrganisms'] = omit_empty_organisms\n        res = self.post('loadUsers', payload)\n        data = [_fix_user(user) for user in res]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_user(self, user):\n        res = self.post('loadUsers', {'userId': user})\n        if isinstance(res, list) and len(res) > 0:\n            res = res[0]\n        return _fix_user(res)", "response": "Get a specific user s information"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_organism_permissions(self, user, organism, administrate=False,\n                                    write=False, export=False, read=False):\n        \"\"\"\n        Update the permissions of a user on a specified organism\n\n        :type user: str\n        :param user: User's email\n\n        :type organism: str\n        :param organism: organism common name\n\n        :type administrate: bool\n        :param administrate: Grants administrative privileges\n\n        :type write: bool\n        :param write: Grants write privileges\n\n        :type read: bool\n        :param read: Grants read privileges\n\n        :type export: bool\n        :param export: Grants export privileges\n\n        :rtype: dict\n        :return: a dictionary containing user's organism permissions\n        \"\"\"\n        data = {\n            'user': user,\n            'organism': organism,\n            'ADMINISTRATE': administrate,\n            'WRITE': write,\n            'EXPORT': export,\n            'READ': read,\n        }\n        response = self.post('updateOrganismPermission', data)\n        if 'permissions' in response:\n            response['permissions'] = json.loads(response['permissions'])\n        return response", "response": "Update the permissions of a user on a specified organism"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a user to a group", "response": "def add_to_group(self, group, user):\n        \"\"\"\n        Add a user to a group\n\n        :type user: str\n        :param user: User's email\n\n        :type group: str\n        :param group: Group name\n\n        :rtype: dict\n        :return: an empty dictionary\n        \"\"\"\n        data = {'group': group, 'user': user}\n        return self.post('addUserToGroup', data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_from_group(self, group, user):\n        data = {'group': group, 'user': user}\n        return self.post('removeUserFromGroup', data)", "response": "Remove a user from a group"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new user in the cache", "response": "def create_user(self, email, first_name, last_name, password, role=\"user\", metadata={}):\n        \"\"\"\n        Create a new user\n\n        :type email: str\n        :param email: User's email\n\n        :type first_name: str\n        :param first_name: User's first name\n\n        :type last_name: str\n        :param last_name: User's last name\n\n        :type password: str\n        :param password: User's password\n\n        :type role: str\n        :param role: User's default role, one of \"admin\" or \"user\"\n\n        :type metadata: dict\n        :param metadata: User metadata\n\n        :rtype: dict\n        :return: an empty dictionary\n        \"\"\"\n        data = {\n            'firstName': first_name,\n            'lastName': last_name,\n            'email': email,\n            'metadata': metadata,\n            'role': role.upper() if role else role,\n            'newPassword': password,\n        }\n        response = self.post('createUser', data)\n        return self._handle_empty(email, response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates an existing user", "response": "def update_user(self, email, first_name, last_name, password, metadata={}):\n        \"\"\"\n        Update an existing user\n\n        :type email: str\n        :param email: User's email\n\n        :type first_name: str\n        :param first_name: User's first name\n\n        :type last_name: str\n        :param last_name: User's last name\n\n        :type password: str\n        :param password: User's password\n\n        :type metadata: dict\n        :param metadata: User metadata\n\n        :rtype: dict\n        :return: a dictionary containing user information\n        \"\"\"\n        data = {\n            'email': email,\n            'firstName': first_name,\n            'lastName': last_name,\n            'newPassword': password,\n            'metadata': metadata,\n        }\n        response = self.post('updateUser', data)\n        return self._handle_empty(email, response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequire that the user has an account", "response": "def require_user(wa, email):\n    \"\"\"Require that the user has an account\"\"\"\n    cache_key = 'user-list'\n    try:\n        # Get the cached value\n        data = userCache[cache_key]\n    except KeyError:\n        # If we hit a key error above, indicating that\n        # we couldn't find the key, we'll simply re-request\n        # the data\n        data = wa.users.loadUsers()\n        userCache[cache_key] = data\n\n    return AssertUser([x for x in data if x.username == email])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accessible_organisms(user, orgs):\n    permission_map = {\n        x['organism']: x['permissions']\n        for x in user.organismPermissions\n        if 'WRITE' in x['permissions'] or\n        'READ' in x['permissions'] or\n        'ADMINISTRATE' in x['permissions'] or\n        user.role == 'ADMIN'\n    }\n\n    if 'error' in orgs:\n        raise Exception(\"Error received from Apollo server: \\\"%s\\\"\" % orgs['error'])\n\n    return [\n        (org['commonName'], org['id'], False)\n        for org in sorted(orgs, key=lambda x: x['commonName'])\n        if org['commonName'] in permission_map\n    ]", "response": "Get the list of organisms accessible to a user filtered by orgs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.get_comments(feature_id, organism=organism, sequence=sequence)", "response": "Get a feature s comments"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, uuid, output_format=\"gzip\"):\n    return ctx.gi.io.download(uuid, output_format=output_format)", "response": "Download pre - prepared data by UUID"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the group s membership", "response": "def cli(ctx, group_id, users=None):\n    \"\"\"Update the group's membership\n\nOutput:\n\n    dictionary of group information\n    \"\"\"\n    return ctx.gi.groups.update_membership(group_id, users=users)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a canned key", "response": "def cli(ctx, key, metadata=\"\"):\n    \"\"\"Add a canned key\n\nOutput:\n\n    A dictionnary containing canned key description\n    \"\"\"\n    return ctx.gi.cannedkeys.add_key(key, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(ctx, feature_id, status, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.set_status(feature_id, status, organism=organism, sequence=sequence)", "response": "Set a feature s status"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects the client with the given host and credentials.", "response": "def connect(cls, host, public_key, private_key, verbose=0, use_cache=True):\n        \"\"\"\n        Connect the client with the given host and the provided credentials.\n\n        Parameters\n        ----------\n        host : str\n            The Cytomine host (without protocol).\n        public_key : str\n            The Cytomine public key.\n        private_key : str\n            The Cytomine private key.\n        verbose : int\n            The verbosity level of the client.\n        use_cache : bool\n            True to use HTTP cache, False otherwise.\n\n        Returns\n        -------\n        client : Cytomine\n            A connected Cytomine client.\n        \"\"\"\n        return cls(host, public_key, private_key, verbose, use_cache)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect with data taken from a command line interface.", "response": "def connect_from_cli(cls, argv, use_cache=True):\n        \"\"\"\n        Connect with data taken from a command line interface.\n\n        Parameters\n        ----------\n        argv: list\n            Command line parameters (executable name excluded)\n        use_cache : bool\n            True to use HTTP cache, False otherwise.\n\n        Returns\n        -------\n        client : Cytomine\n            A connected Cytomine client.\n\n        Notes\n        -----\n        If some parameters are invalid, the function stops the execution and displays an help.\n        \"\"\"\n        argparse = cls._add_cytomine_cli_args(ArgumentParser())\n        params, _ = argparse.parse_known_args(args=argv)\n        log_level = params.verbose\n        if params.log_level is not None:\n            log_level = logging.getLevelName(params.log_level)\n        return cls.connect(params.host, params.public_key, params.private_key, log_level, use_cache=use_cache)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the cytomine CLI args to the ArgumentParser object.", "response": "def _add_cytomine_cli_args(argparse):\n        \"\"\"\n        Add cytomine CLI args to the ArgumentParser object: cytomine_host, cytomine_public_key, cytomine_private_key and\n        cytomine_verbose.\n\n        Parameters\n        ----------\n        argparse: ArgumentParser\n            The argument parser\n\n        Return\n        ------\n        argparse: ArgumentParser\n            The argument parser (same object as parameter)\n        \"\"\"\n        argparse.add_argument(*_cytomine_parameter_name_synonyms(\"host\"),\n                              dest=\"host\", help=\"The Cytomine host (without protocol).\", required=True)\n        argparse.add_argument(*_cytomine_parameter_name_synonyms(\"public_key\"),\n                              dest=\"public_key\", help=\"The Cytomine public key.\", required=True)\n        argparse.add_argument(*_cytomine_parameter_name_synonyms(\"private_key\"),\n                              dest=\"private_key\", help=\"The Cytomine private key.\", required=True)\n        argparse.add_argument(\"--verbose\", \"--cytomine_verbose\",\n                              dest=\"verbose\", type=int, default=logging.INFO,\n                              help=\"The verbosity level of the client (as an integer value).\")\n        argparse.add_argument(\"-l\", \"--log_level\", \"--cytomine_log_level\",\n                              dest=\"log_level\", choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],\n                              help=\"The logging level of the client (as a string value)\")\n        return argparse"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_url(host, provided_protocol=None):\n        protocol = \"http\" # default protocol\n        \n        if host.startswith(\"http://\"):\n            protocol = \"http\"\n        elif host.startswith(\"https://\"):\n            protocol = \"https\"\n        elif provided_protocol is not None:\n            provided_protocol = provided_protocol.replace(\"://\", \"\")\n            if provided_protocol in (\"http\", \"https\"):\n                protocol = provided_protocol\n        \n        host = host.replace(\"http://\", \"\").replace(\"https://\", \"\")\n        if host.endswith(\"/\"):\n            host = host[:-1]\n\n        return host, protocol", "response": "Parse the provided host and protocol and return the host and protocol in a standardized way."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading a crop associated with an annotation as a new image.", "response": "def upload_crop(self, ims_host, filename, id_annot, id_storage, \n                id_project=None, sync=False, protocol=None):\n        \"\"\"\n        Upload the crop associated with an annotation as a new image.\n\n        Parameters\n        ----------\n        ims_host: str\n            Cytomine IMS host, with or without the protocol\n        filename: str\n            Filename to give to the newly created image\n        id_annot: int\n            Identifier of the annotation to crop\n        id_storage: int\n            Identifier of the storage to use to upload the new image\n        id_project: int, optional\n            Identifier of a project in which the new image should be added\n        sync: bool, optional\n            True:   the server will answer once the uploaded file is \n                    deployed (response will include the created image)\n            False (default): the server will answer as soon as it receives the file\n        protocol: str (\"http\", \"http://\", \"https\", \"https://\")\n            The default protocol - used only if the host value does not specify one\n\n        Return\n        ------\n        uf: UploadedFile\n            The uploaded file. Its images attribute is populated with the collection of created abstract images.\n        \"\"\"\n\n        \n        if not protocol:\n                protocol = self._protocol\n        ims_host, protocol = self._parse_url(ims_host, protocol)\n        ims_host = \"{}://{}\".format(protocol, ims_host)\n    \n        query_parameters = {\n            \"annotation\" : id_annot,\n            \"storage\": id_storage,\n            \"cytomine\": \"{}://{}\".format(self._protocol, self._host),\n            \"name\": filename,\n            \"sync\": sync\n        }\n    \n        if id_project:\n            query_parameters[\"project\"] = id_project\n    \n        response = self._session.post(\"{}/uploadCrop\".format(ims_host),\n                                      auth=CytomineAuth(\n                                          self._public_key, \n                                          self._private_key,\n                                          ims_host, \"\"),\n                                      headers=self._headers(),\n                                      params=query_parameters)\n    \n        if response.status_code == requests.codes.ok:\n            uf = self._process_upload_response(response.json())\n            self._logger.info(\"Image crop uploaded successfully to {}\".format(ims_host))\n            return uf\n        else:\n            self._logger.error(\"Error during crop upload. Response: %s\", response)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(self, max=None):\n        if max:\n            self.max = max\n            n_pages = 0\n            while not self._total_pages or n_pages < self._total_pages:\n                self.fetch_next_page(True)\n                n_pages += 1\n\n            return self\n        else:\n            return self._fetch()", "response": "Fetch all collection by page of max items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, email, first_name, last_name, password, metadata={}):\n    return ctx.gi.users.update_user(email, first_name, last_name, password, metadata=metadata)", "response": "Update an existing user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(ctx, omit_empty_organisms=False):\n    return ctx.gi.users.get_users(omit_empty_organisms=omit_empty_organisms)", "response": "Get all users known to this Apollo instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating an organism Output: a dictionary with information about the new organism", "response": "def cli(ctx, organism_id, common_name, directory, blatdb=\"\", species=\"\", genus=\"\", public=False):\n    \"\"\"Update an organism\n\nOutput:\n\n    a dictionary with information about the new organism\n    \"\"\"\n    return ctx.gi.organisms.update_organism(organism_id, common_name, directory, blatdb=blatdb, species=species, genus=genus, public=public)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(ctx, feature_id, attribute_key, old_value, new_value, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.update_attribute(feature_id, attribute_key, old_value, new_value, organism=organism, sequence=sequence)", "response": "Update an attribute in a feature"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_comment(self, comment, metadata=\"\"):\n        data = {\n            'comment': comment,\n            'metadata': metadata\n        }\n\n        return self.post('createComment', data)", "response": "Adds a canned comment to the canned comment list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_comment(self, value):\n        comments = self.get_comments()\n        comments = [x for x in comments if x['comment'] == value]\n        if len(comments) == 0:\n            raise Exception(\"Unknown comment\")\n        else:\n            return comments[0]", "response": "Get a specific canned comment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_comment(self, id_number, new_value, metadata=None):\n        data = {\n            'id': id_number,\n            'new_comment': new_value\n        }\n\n        if metadata is not None:\n            data['metadata'] = metadata\n\n        return self.post('updateComment', data)", "response": "Update a canned comment"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, value, metadata=\"\"):\n    return ctx.gi.cannedvalues.add_value(value, metadata=metadata)", "response": "Add a canned value to a canned value list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx, feature_id, comments=None, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.add_comment(feature_id, comments=comments, organism=organism, sequence=sequence)", "response": "Add a feature s description to a sequence"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new user", "response": "def cli(ctx, email, first_name, last_name, password, role=\"user\", metadata={}):\n    \"\"\"Create a new user\n\nOutput:\n\n    an empty dictionary\n    \"\"\"\n    return ctx.gi.users.create_user(email, first_name, last_name, password, role=role, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the permissions of an organism", "response": "def cli(ctx, group, organism_name, administrate=False, write=False, read=False, export=False):\n    \"\"\"Update the group's permissions on an organism\n\nOutput:\n\n    list of group organism permissions\n    \"\"\"\n    return ctx.gi.groups.update_organism_permissions(group, organism_name, administrate=administrate, write=write, read=read, export=export)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.delete_feature(feature_id, organism=organism, sequence=sequence)", "response": "Delete a feature\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the GFF3 associated with a feature", "response": "def cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    \"\"\"Get the GFF3 associated with a feature\n\nOutput:\n\n    GFF3 text content\n    \"\"\"\n    return ctx.gi.annotations.get_gff3(feature_id, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, group, user):\n    return ctx.gi.users.add_to_group(group, user)", "response": "Add a user to a group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arrow(ctx, apollo_instance, verbose, log_level):\n    set_logging_level(log_level)\n\n    # We abuse this, knowing that calls to one will fail.\n    try:\n        ctx.gi = get_apollo_instance(apollo_instance)\n    except TypeError:\n        pass\n        # ctx.log(\"Could not access Galaxy instance configuration\")\n\n    ctx.verbose = verbose", "response": "Command line wrappers around Apollo functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload json data allowing - to represent stdin.", "response": "def json_loads(data):\n    \"\"\"Load json data, allowing - to represent stdin.\"\"\"\n    if data is None:\n        return \"\"\n\n    if data == \"-\":\n        return json.load(sys.stdin)\n    elif os.path.exists(data):\n        with open(data, 'r') as handle:\n            return json.load(handle)\n    else:\n        return json.loads(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a queryset of all log objects in the database.", "response": "def get_queryset(self, **options):\n        \"\"\"\n        Filters the list of log objects to display\n        \"\"\"\n        days = options.get('days')\n        queryset = TimelineLog.objects.order_by('-timestamp')\n        if days:\n            try:\n                start = timezone.now() - timedelta(days=days)\n            except TypeError:\n                raise CommandError(\"Incorrect 'days' parameter. 'days' must be a number of days.\")\n            else:\n                return queryset.filter(timestamp__gte=start)\n\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all the recipients that are set in the settings. TIMELINE_DIGEST_EMAIL_RECIPIENTS_DEFAULT_FIELD.", "response": "def get_recipients(self, **options):\n        \"\"\"\n        Figures out the recipients\n        \"\"\"\n        if options['recipients_from_setting']:\n            return settings.TIMELINE_DIGEST_EMAIL_RECIPIENTS\n\n        users = get_user_model()._default_manager.all()\n        if options['staff']:\n            users = users.filter(is_staff=True)\n        elif not options['all']:\n            users = users.filter(is_staff=True, is_superuser=True)\n        return users.values_list(settings.TIMELINE_USER_EMAIL_FIELD, flat=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_downloadable(self, organism, export_type='FASTA',\n                           seq_type='peptide', export_format='text',\n                           export_gff3_fasta=False, sequences=[], region=None):\n        \"\"\"\n        Prepare a download for an organism\n\n        :type organism: str\n        :param organism: organism common name\n\n        :type sequences: str\n        :param sequences: Names of references sequences to add (default is all)\n\n        :type export_type: str\n        :param export_type: Export type. Choices: FASTA, GFF3, VCF\n\n        :type seq_type: str\n        :param seq_type: Export selection. Choices: peptide, cds, cdna, genomic\n\n        :type export_format: str\n        :param export_format: Export format, either gzip or text\n\n        :type export_gff3_fasta: bool\n        :param export_gff3_fasta: Export reference sequence when exporting GFF3 annotations.\n\n        :type region: str\n        :param region: Region to export in form sequence:min..max e.g., chr3:1001..1034\n\n        :rtype: dict\n        :return: a dictionary containing download information\n        \"\"\"\n\n        if export_format.lower() not in ('gzip', 'text'):\n            raise Exception(\"export_format must be one of file, text\")\n\n        if export_type.lower() not in ('fasta', 'gff3', 'vcf'):\n            raise Exception(\"export_type must be one of FASTA, GFF3, VCF\")\n\n        data = {\n            'type': export_type,\n            'seq_type': seq_type,\n            'format': export_format,\n            'sequences': sequences,\n            'organism': organism,\n            'output': 'file',\n            'exportAllSequences': True if not sequences else len(sequences) == 0,\n            'exportGff3Fasta': export_gff3_fasta,\n        }\n\n        if region:\n            data['region'] = region\n\n        return self.post('write', data)", "response": "Writes a new file to the local file system"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a text file for the given organism", "response": "def write_text(self, organism, export_type='FASTA', seq_type='peptide',\n                   export_format='text', export_gff3_fasta=False,\n                   sequences=[], region=None):\n        \"\"\"\n        [DEPRECATED, use write_downloadable] Download or prepare a download for an organism\n\n        :type organism: str\n        :param organism: organism common name\n\n        :type sequences: str\n        :param sequences: Names of references sequences to add (default is all)\n\n        :type export_type: str\n        :param export_type: Export type. Choices: FASTA, GFF3, VCF\n\n        :type seq_type: str\n        :param seq_type: Export selection. Choices: peptide, cds, cdna, genomic\n\n        :type export_format: str\n        :param export_format: Export format, either gzip or text\n\n        :type export_gff3_fasta: bool\n        :param export_gff3_fasta: Export reference sequence when exporting GFF3 annotations.\n\n        :type region: str\n        :param region: Region to export in form sequence:min..max e.g., chr3:1001..1034\n\n        :rtype: str\n        :return: the exported data\n        \"\"\"\n\n        return self.write_downloadable(organism, export_type, seq_type,\n                                       export_format, export_gff3_fasta,\n                                       sequences, region)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload pre - prepared data by UUID", "response": "def download(self, uuid, output_format='gzip'):\n        \"\"\"\n        Download pre-prepared data by UUID\n\n        :type uuid: str\n        :param uuid: Data UUID\n\n        :type output_format: str\n        :param output_format: Output format of the data, either \"gzip\" or \"text\"\n\n        :rtype: str\n        :return: The downloaded content\n        \"\"\"\n\n        if output_format.lower() not in ('gzip', 'text'):\n            raise Exception(\"output_format must be one of file, text\")\n\n        data = {\n            'format': output_format,\n            'uuid': uuid,\n        }\n        return self.get('download', get_params=data, is_json=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli(ctx, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.get_sequence_alterations(organism=organism, sequence=sequence)", "response": "Get all of the sequence s alterations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\naccept an array of actions and returns an array of actions which match.", "response": "def expand_actions(self, actions):\n        \"\"\"Accepts an array of actions and returns an array of actions which match.\n        This should be called before \"matches?\" and other checking methods since they\n        rely on the actions to be expanded.\"\"\"\n        results = list()\n\n        for action in actions:\n            if action in self.aliased_actions:\n                results.append(action)\n                for item in self.expand_actions(self.aliased_actions[action]):\n                    results.append(item)\n            else:\n                results.append(action)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _software_params_to_argparse(parameters):\n    # Check software parameters\n    argparse = ArgumentParser()\n    boolean_defaults = {}\n    for parameter in parameters:\n        arg_desc = {\"dest\": parameter.name, \"required\": parameter.required, \"help\": \"\"}  # TODO add help\n        if parameter.type == \"Boolean\":\n            default = _to_bool(parameter.defaultParamValue)\n            arg_desc[\"action\"] = \"store_true\" if not default else \"store_false\"\n            boolean_defaults[parameter.name] = default\n        else:\n            python_type = _convert_type(parameter.type)\n            arg_desc[\"type\"] = python_type\n            arg_desc[\"default\"] = None if parameter.defaultParamValue is None else python_type(parameter.defaultParamValue)\n        argparse.add_argument(*_cytomine_parameter_name_synonyms(parameter.name), **arg_desc)\n    argparse.set_defaults(**boolean_defaults)\n    return argparse", "response": "Converts a SoftwareParameterCollection into an ArgumentParser object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n\n        run_by_ui = False\n        if not self.current_user.algo:\n            # If user connects as a human (CLI execution)\n            self._job = Job(self._project.id, self._software.id).save()\n            user_job = User().fetch(self._job.userJob)\n            self.set_credentials(user_job.publicKey, user_job.privateKey)\n        else:\n            # If the user executes the job through the Cytomine interface\n            self._job = Job().fetch(self.current_user.job)\n            run_by_ui = True\n\n        # set job state to RUNNING\n        self._job.status = Job.RUNNING\n        self._job.update()\n\n        # add software parameters\n        if not run_by_ui and self._parameters is not None:\n            parameters = vars(self._parameters)\n            for software_param in self._software.parameters:\n                name = software_param[\"name\"]\n                if name in parameters:\n                    value = parameters[name]\n                else:\n                    value = software_param[\"defaultParamValue\"]\n\n                JobParameter(self._job.id, software_param[\"id\"], value).save()", "response": "Connect to the Cytomine server and switch to job connection\n        Incurs dataflows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnotifying the Cytomine server of the job s end", "response": "def close(self, value):\n        \"\"\"\n        Notify the Cytomine server of the job's end\n        Incurs a dataflows\n        \"\"\"\n        if value is None:\n            status = Job.TERMINATED\n            status_comment = \"Job successfully terminated\"\n        else:\n            status = Job.FAILED\n            status_comment = str(value)[:255]\n\n        self._job.status = status\n        self._job.statusComment = status_comment \n        self._job.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_from_cli(args):\n    parser = argparse.ArgumentParser(description=\"Generate Python classes from an Ecore model.\")\n    parser.add_argument(\n        '--ecore-model',\n        '-e',\n        help=\"Path to Ecore XMI file.\",\n        required=True\n    )\n    parser.add_argument(\n        '--out-folder',\n        '-o',\n        help=\"Path to directory, where output files are generated.\",\n        required=True\n    )\n    parser.add_argument(\n        '--auto-register-package',\n        help=\"Generate package auto-registration for the PyEcore 'global_registry'.\",\n        action='store_true'\n    )\n    parser.add_argument(\n        '--user-module',\n        help=\"Dotted name of module with user-provided mixins to import from generated classes.\",\n    )\n    parser.add_argument(\n        '--with-dependencies',\n        help=\"Generates code for every metamodel the input metamodel depends on.\",\n        action='store_true'\n    )\n    parser.add_argument(\n        '--verbose',\n        '-v',\n        help=\"Increase logging verbosity.\",\n        action='count'\n    )\n\n    parsed_args = parser.parse_args(args)\n\n    configure_logging(parsed_args)\n    model = load_model(parsed_args.ecore_model)\n    EcoreGenerator(\n        auto_register_package=parsed_args.auto_register_package,\n        user_module=parsed_args.user_module,\n        with_dependencies=parsed_args.with_dependencies\n    ).generate(model, parsed_args.out_folder)", "response": "Entry point for the generate_from_ecore_model function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_uri_implementation(ecore_model_path):\n    if URL_PATTERN.match(ecore_model_path):\n        return pyecore.resources.resource.HttpURI\n    return pyecore.resources.URI", "response": "Select the right URI implementation regarding the Ecore model path schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_model(ecore_model_path):\n    rset = pyecore.resources.ResourceSet()\n    uri_implementation = select_uri_implementation(ecore_model_path)\n    resource = rset.get_resource(uri_implementation(ecore_model_path))\n    return resource.contents[0]", "response": "Load a single Ecore model and return the root package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the boundaries of a genomic feature", "response": "def cli(ctx, feature_id, start, end, organism=\"\", sequence=\"\"):\n    \"\"\"Set the boundaries of a genomic feature\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.set_boundaries(feature_id, start, end, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflips the strand of a feature", "response": "def cli(ctx, feature_id, organism=\"\", sequence=\"\"):\n    \"\"\"Flip the strand of a feature\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.flip_strand(feature_id, organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, group_id, users=None):\n    return ctx.gi.groups.update_group_admin(group_id, users=users)", "response": "Update the group s admins"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the name of a group", "response": "def cli(ctx, group_id, new_name):\n    \"\"\"Update the name of a group\n\nOutput:\n\n    a dictionary containing group information\n    \"\"\"\n    return ctx.gi.groups.update_group(group_id, new_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a POST request to the API.", "response": "def post(self, client_method, data, post_params=None, is_json=True):\n        \"\"\"Make a POST request\"\"\"\n        url = self._wa.apollo_url + self.CLIENT_BASE + client_method\n\n        if post_params is None:\n            post_params = {}\n\n        headers = {\n            'Content-Type': 'application/json'\n        }\n\n        data.update({\n            'username': self._wa.username,\n            'password': self._wa.password,\n        })\n\n        curl_command = ['curl', url]\n        for (k, v) in headers.items():\n            curl_command += ['-H', quote('%s: %s' % (k, v))]\n        curl_command += ['-d', quote(json.dumps(data))]\n        log.info(' '.join(curl_command))\n\n        resp = requests.post(url, data=json.dumps(data),\n                             headers=headers, verify=self.__verify,\n                             params=post_params, allow_redirects=False,\n                             **self._request_args)\n\n        if resp.status_code == 200 or resp.status_code == 302:\n            if is_json:\n                data = resp.json()\n                return self._scrub_data(data)\n            else:\n                return resp.text\n\n        # @see self.body for HTTP response body\n        raise Exception(\"Unexpected response from apollo %s: %s\" %\n                        (resp.status_code, resp.text))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, client_method, get_params, is_json=True):\n        url = self._wa.apollo_url + self.CLIENT_BASE + client_method\n        headers = {}\n\n        response = requests.get(url, headers=headers,\n                                verify=self.__verify, params=get_params,\n                                **self._request_args)\n        if response.status_code == 200:\n            if is_json:\n                data = response.json()\n                return self._scrub_data(data)\n            else:\n                return response.text\n        # @see self.body for HTTP response body\n        raise Exception(\"Unexpected response from apollo %s: %s\" %\n                        (response.status_code, response.text))", "response": "Make a GET request to the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can(user, action, subject):\n    ability = Ability(user, get_authorization_method())\n    return ability.can(action, subject)", "response": "Checks if a given user has the ability to perform the action on a specific object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of strings that can be used to access a subject.", "response": "def cannot(user, action, subject):\n    \"\"\"inverse of ``can``\"\"\"\n    ability = Ability(user, get_authorization_method())\n    return ability.cannot(action, subject)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure(user, action, subject):\n    ability = Ability(user, get_authorization_method())\n    if ability.cannot(action, subject):\n        raise AccessDenied()", "response": "Ensures that the user has permission to perform the given action and subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authorization_target(original_class):\n\n    def can(self, action, subject):\n        ability = Ability(self, get_authorization_method())\n        return ability.can(action, subject)\n\n    def cannot(self, action, subject):\n        return not can(self, action, subject)\n\n    setattr(original_class, 'can', can)\n    setattr(original_class, 'cannot', cannot)\n\n    return original_class", "response": "Add bouncer goodness to the User model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli(ctx, feature_id, start, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.set_translation_start(feature_id, start, organism=organism, sequence=sequence)", "response": "Set the translation start of a feature"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cli(ctx, feature_id, old_db, old_accession, new_db, new_accession, organism=\"\", sequence=\"\"):\n    return ctx.gi.annotations.update_dbxref(feature_id, old_db, old_accession, new_db, new_accession, organism=organism, sequence=sequence)", "response": "Update a feature in a featuregraph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self, dest_pattern=\"{id}.jpg\", override=True, mask=False, alpha=False, bits=8,\n             zoom=None, max_size=None, increase_area=None, contrast=None, gamma=None, colormap=None, inverse=None):\n        \"\"\"\n        Download the annotation crop, with optional image modifications.\n\n        Parameters\n        ----------\n        dest_pattern : str, optional\n            Destination path for the downloaded image. \"{X}\" patterns are replaced by the value of X attribute\n            if it exists.\n        override : bool, optional\n            True if a file with same name can be overrided by the new file.\n        mask : bool, optional\n            True if a binary mask based on given annotations must be returned, False otherwise.\n        alpha : bool, optional\n            True if image background (outside annotations) must be transparent, False otherwise.\n        zoom : int, optional\n            Optional image zoom number\n        bits : int (8,16,32) or str (\"max\"), optional\n            Bit depth (bit per channel) of returned image. \"max\" returns the original image bit depth\n        max_size : int, tuple, optional\n            Maximum size (width or height) of returned image. None to get original size.\n        increase_area : float, optional\n            Increase the crop size. For example, an annotation whose bounding box size is (w,h) will have\n            a crop dimension of (w*increase_area, h*increase_area).\n        contrast : float, optional\n            Optional contrast applied on returned image.\n        gamma : float, optional\n            Optional gamma applied on returned image.\n        colormap : int, optional\n            Cytomine identifier of a colormap to apply on returned image.\n        inverse : bool, optional\n            True to inverse color mapping, False otherwise.\n\n        Returns\n        -------\n        downloaded : bool\n            True if everything happens correctly, False otherwise. As a side effect, object attribute \"filename\"\n            is filled with downloaded file path.\n        \"\"\"\n        if self.id is None:\n            raise ValueError(\"Cannot dump an annotation with no ID.\")\n\n        pattern = re.compile(\"{(.*?)}\")\n        dest_pattern = re.sub(pattern, lambda m: str(getattr(self, str(m.group(0))[1:-1], \"_\")), dest_pattern)\n\n        destination = os.path.dirname(dest_pattern)\n        filename, extension = os.path.splitext(os.path.basename(dest_pattern))\n        extension = extension[1:]\n\n        if extension not in (\"jpg\", \"png\", \"tif\", \"tiff\"):\n            extension = \"jpg\"\n\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n\n        parameters = {\n            \"zoom\": zoom,\n            \"maxSize\": max_size,\n            \"increaseArea\": increase_area,\n            \"contrast\": contrast,\n            \"gamma\": gamma,\n            \"colormap\": colormap,\n            \"inverse\": inverse,\n            \"bits\": bits\n        }\n\n        if mask and alpha:\n            image = \"alphamask\"\n            if extension == \"jpg\":\n                extension = \"png\"\n        elif mask:\n            image = \"mask\"\n        else:\n            image = \"crop\"\n\n        file_path = os.path.join(destination, \"{}.{}\".format(filename, extension))\n\n        url = self.cropURL.replace(\"crop.jpg\", \"{}.{}\".format(image, extension))\n        result = Cytomine.get_instance().download_file(url, file_path, override, parameters)\n        if result:\n            self.filename = file_path\n        return result", "response": "Download the annotation crop and save it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, organism, sequence):\n    return ctx.gi.annotations.set_sequence(organism, sequence)", "response": "Sets the sequence for subsequent requests."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the features for an organism", "response": "def cli(ctx, organism=\"\", sequence=\"\"):\n    \"\"\"Get the features for an organism / sequence\n\nOutput:\n\n    A standard apollo feature dictionary ({\"features\": [{...}]})\n    \"\"\"\n    return ctx.gi.annotations.get_features(organism=organism, sequence=sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a canned comment to a canned comment list", "response": "def cli(ctx, comment, metadata=\"\"):\n    \"\"\"Add a canned comment\n\nOutput:\n\n    A dictionnary containing canned comment description\n    \"\"\"\n    return ctx.gi.cannedcomments.add_comment(comment, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, user, organism, administrate=False, write=False, export=False, read=False):\n    return ctx.gi.users.update_organism_permissions(user, organism, administrate=administrate, write=write, export=export, read=read)", "response": "Update the permissions of a user on a specified organism"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a copy of the passed object which only contains the parts which are pointed to by one of the FieldSelectors that were used to generate the MultiFieldSelector.", "response": "def get(self, obj):\n        \"\"\"Creates a copy of the passed object which only contains the parts\n        which are pointed to by one of the FieldSelectors that were used to\n        construct the MultiFieldSelector.  Can be used to produce 'filtered'\n        versions of objects.\n        \"\"\"\n        ctor = type(obj)\n        if isinstance(obj, (list, ListCollection)):\n            if self.has_string:\n                raise TypeError(\n                    \"MultiFieldSelector has string in list collection context\"\n                )\n            if self.has_none:\n                tail = self.heads[None]\n                vals = list(self._get(x, tail) for x in obj)\n            else:\n                vals = list(\n                    self._get(obj[head], tail) for head, tail in\n                    self.heads.iteritems()\n                )\n            if isinstance(obj, ListCollection):\n                return ctor(values=vals)\n            else:\n                return vals\n        elif isinstance(obj, (dict, DictCollection)):\n            if self.has_none:\n                tail = self.heads[None]\n                return ctor(\n                    (k, self._get(v, tail)) for k, v in obj.iteritems()\n                )\n            else:\n                return ctor(\n                    (head, self._get(obj[head], tail)) for head, tail in\n                    self.heads.iteritems() if head in obj\n                )\n        else:\n            if self.has_int or (self.has_none and self.heads[None] is not all):\n                raise TypeError(\n                    \"MultiFieldSelector has %s in %s context\" % (\n                        \"int\" if self.has_int else \"none\", ctor.__name__\n                    )\n                )\n            if self.has_none:\n                return self._get(obj, all)\n            else:\n                kwargs = dict()\n                for head, tail in self.heads.iteritems():\n                    val = getattr(obj, head, None)\n                    if val is not None:\n                        kwargs[head] = self._get(val, tail)\n                return ctor(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting all of the fields from the specified locations.", "response": "def delete(self, obj, force=False):\n        \"\"\"Deletes all of the fields at the specified locations.\n\n        args:\n\n            ``obj=``\\ *OBJECT*\n                the object to remove the fields from\n\n            ``force=``\\ *BOOL*\n                if True, missing attributes do not raise errors.  Otherwise,\n                the first failure raises an exception without making any\n                changes to ``obj``.\n        \"\"\"\n        # TODO: this could be a whole lot more efficient!\n        if not force:\n            for fs in self:\n                try:\n                    fs.get(obj)\n                except FieldSelectorException:\n                    raise\n\n        for fs in self:\n            try:\n                fs.delete(obj)\n            except FieldSelectorException:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patch(self, target, source, copy=False):\n        # TODO: this could also be a whole lot more efficient!\n        fs_val = []\n        for fs in self:\n            try:\n                fs_val.append((fs, fs.get(source)))\n            except AttributeError:\n                fs_val.append((fs, _None))\n            except FieldSelectorException:\n                raise\n\n        if copy and not callable(copy):\n            copy = deepcopy\n\n        for fs, val in fs_val:\n            if val is _None:\n                fs.delete(target)\n            else:\n                fs.post(target, val if not copy else copy(val))", "response": "Copies fields from obj to target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n\n        # Load compound information\n        def compound_name(id):\n            if id not in self._model.compounds:\n                return id\n            return self._model.compounds[id].properties.get('name', id)\n\n        # Calculate penalty if penalty file exists\n        penalties = {}\n        if self._args.penalty is not None:\n            for line in self._args.penalty:\n                line, _, comment = line.partition('#')\n                line = line.strip()\n                if line == '':\n                    continue\n                rxnid, penalty = line.split(None, 1)\n                penalties[rxnid] = float(penalty)\n\n        core = set(self._mm.reactions)\n\n        solver = self._get_solver(integer=True)\n        default_comp = self._model.default_compartment\n        epsilon = self._args.epsilon\n        v_max = float(self._model.default_flux_limit)\n\n        blocked = set()\n        for compound in self._args.compound:\n            if compound.compartment is None:\n                compound = compound.in_compartment(default_comp)\n            blocked.add(compound)\n\n        if len(blocked) > 0:\n            logger.info('Unblocking compounds: {}...'.format(\n                ', '.join(text_type(c) for c in sorted(blocked))))\n        else:\n            logger.info(\n                'Unblocking all compounds in model. Use --compound option to'\n                ' unblock specific compounds.')\n            blocked = set(self._mm.compounds)\n\n        exclude = set()\n        if self._model.biomass_reaction is not None:\n            exclude.add(self._model.biomass_reaction)\n\n        # Add exchange and transport reactions to database\n        model_complete, weights = create_extended_model(\n            self._model,\n            db_penalty=self._args.db_penalty,\n            ex_penalty=self._args.ex_penalty,\n            tp_penalty=self._args.tp_penalty,\n            penalties=penalties)\n\n        implicit_sinks = not self._args.no_implicit_sinks\n\n        logger.info('Searching for reactions to fill gaps')\n        try:\n            added_reactions, no_bounds_reactions = gapfill(\n                model_complete, core, blocked, exclude, solver=solver,\n                epsilon=epsilon, v_max=v_max, weights=weights,\n                implicit_sinks=implicit_sinks,\n                allow_bounds_expansion=self._args.allow_bounds_expansion)\n        except GapFillError as e:\n            self._log_epsilon_and_fail(epsilon, e)\n\n        for reaction_id in sorted(self._mm.reactions):\n            rx = self._mm.get_reaction(reaction_id)\n            rxt = rx.translated_compounds(compound_name)\n            print('{}\\t{}\\t{}\\t{}'.format(reaction_id, 'Model', 0, rxt))\n\n        for rxnid in sorted(added_reactions):\n            rx = model_complete.get_reaction(rxnid)\n            rxt = rx.translated_compounds(compound_name)\n            print('{}\\t{}\\t{}\\t{}'.format(\n                rxnid, 'Add', weights.get(rxnid, 1), rxt))\n\n        for rxnid in sorted(no_bounds_reactions):\n            rx = model_complete.get_reaction(rxnid)\n            rxt = rx.translated_compounds(compound_name)\n            print('{}\\t{}\\t{}\\t{}'.format(\n                rxnid, 'Remove bounds', weights.get(rxnid, 1), rxt))", "response": "Run the gap fill command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving all processes from the specified socat.", "response": "def reset_socat(use_sudo=False):\n    \"\"\"\n    Finds and closes all processes of `socat`.\n\n    :param use_sudo: Use `sudo` command. As Docker-Fabric does not run `socat` with `sudo`, this is by default set to\n      ``False``. Setting it to ``True`` could unintentionally remove instances from other users.\n    :type use_sudo: bool\n    \"\"\"\n    output = stdout_result('ps -o pid -C socat', quiet=True)\n    pids = output.split('\\n')[1:]\n    puts(\"Removing process(es) with id(s) {0}.\".format(', '.join(pids)))\n    which = sudo if use_sudo else run\n    which('kill {0}'.format(' '.join(pids)), quiet=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef version():\n    output = docker_fabric().version()\n    col_len = max(map(len, output.keys())) + 1\n    puts('')\n    for k, v in six.iteritems(output):\n        fastprint('{0:{1}} {2}'.format(''.join((k, ':')), col_len, v), end='\\n', flush=False)\n    fastprint('', flush=True)", "response": "Show version information of the remote Docker service similar to docker version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all images on the Docker remote host similar to docker images.", "response": "def list_images(list_all=False, full_ids=False):\n    \"\"\"\n    Lists images on the Docker remote host, similar to ``docker images``.\n\n    :param list_all: Lists all images (e.g. dependencies). Default is ``False``, only shows named images.\n    :type list_all: bool\n    :param full_ids: Shows the full ids. When ``False`` (default) only shows the first 12 characters.\n    :type full_ids: bool\n    \"\"\"\n    images = docker_fabric().images(all=list_all)\n    _format_output_table(images, IMAGE_COLUMNS, full_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_containers(list_all=True, short_image=True, full_ids=False, full_cmd=False):\n    containers = docker_fabric().containers(all=list_all)\n    _format_output_table(containers, CONTAINER_COLUMNS, full_ids, full_cmd, short_image)", "response": "Lists all containers on the Docker remote host."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_networks(full_ids=False):\n    networks = docker_fabric().networks()\n    _format_output_table(networks, NETWORK_COLUMNS, full_ids)", "response": "Lists the networks on the Docker remote host similar to docker network ls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all containers that have finished running.", "response": "def cleanup_containers(**kwargs):\n    \"\"\"\n    Removes all containers that have finished running. Similar to the ``prune`` functionality in newer Docker versions.\n    \"\"\"\n    containers = docker_fabric().cleanup_containers(**kwargs)\n    if kwargs.get('list_only'):\n        puts('Existing containers:')\n        for c_id, c_name in containers:\n            fastprint('{0}  {1}'.format(c_id, c_name), end='\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving all images that are not references by any other named image.", "response": "def cleanup_images(remove_old=False, **kwargs):\n    \"\"\"\n    Removes all images that have no name, and that are not references as dependency by any other named image. Similar\n    to the ``prune`` functionality in newer Docker versions, but supports more filters.\n\n    :param remove_old: Also remove images that do have a name, but no `latest` tag.\n    :type remove_old: bool\n    \"\"\"\n    keep_tags = env.get('docker_keep_tags')\n    if keep_tags is not None:\n        kwargs.setdefault('keep_tags', keep_tags)\n    removed_images = docker_fabric().cleanup_images(remove_old=remove_old, **kwargs)\n    if kwargs.get('list_only'):\n        puts('Unused images:')\n        for image_name in removed_images:\n            fastprint(image_name, end='\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops and removes all containers from the remote.", "response": "def remove_all_containers(**kwargs):\n    \"\"\"\n    Stops and removes all containers from the remote. Use with caution outside of a development environment!\n    :return:\n    \"\"\"\n    containers = docker_fabric().remove_all_containers(**kwargs)\n    if kwargs.get('list_only'):\n        puts('Existing containers:')\n        for c_id in containers[1]:\n            fastprint(c_id, end='\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving a Docker image to a local file.", "response": "def save_image(image, filename=None):\n    \"\"\"\n    Saves a Docker image from the remote to a local files. For performance reasons, uses the Docker command line client\n    on the host, generates a gzip-tarball and downloads that.\n\n    :param image: Image name or id.\n    :type image: unicode\n    :param filename: File name to store the local file. If not provided, will use ``<image>.tar.gz`` in the current\n      working directory.\n    :type filename: unicode\n    \"\"\"\n    local_name = filename or '{0}.tar.gz'.format(image)\n    cli.save_image(image, local_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_image(filename, timeout=120):\n    c = docker_fabric()\n    with open(expand_path(filename), 'r') as f:\n        _timeout = c._timeout\n        c._timeout = timeout\n        try:\n            c.load_image(f)\n        finally:\n            c._timeout = _timeout", "response": "Uploads an image from a local file to a Docker remote."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting all the commands in the current pipeline", "response": "def execute(self, raise_on_error=True):\n        \"Execute all the commands in the current pipeline\"\n        stack = self.command_stack\n        if not stack:\n            return []\n        execute = self._execute_pipeline\n\n        conn = self.connection\n        if not conn:\n            conn = self.connection_pool.get_connection('batch')\n            # assign to self.connection so reset() releases the connection\n            # back to the pool after we're done\n            self.connection = conn\n\n        try:\n            return execute(conn, stack, raise_on_error)\n        except ConnectionError:\n            conn.disconnect()\n            return execute(conn, stack, raise_on_error)\n        finally:\n            self.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare an object with another and return a DiffInfo object. Accepts the same arguments as the diff_iter method.", "response": "def diff(self, other, **kwargs):\n        \"\"\"Compare an object with another and return a :py:class:`DiffInfo`\n        object.  Accepts the same arguments as\n        :py:meth:`normalize.record.Record.diff_iter`\n        \"\"\"\n        from normalize.diff import diff\n        return diff(self, other, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_weights(weight_args, default_weight=0.6):\n    weights_dict = {}\n    r_group_weight = default_weight\n    for weight_arg in weight_args:\n        for weight_assignment in weight_arg.split(','):\n            if '=' not in weight_assignment:\n                raise ValueError(\n                    'Invalid weight assignment: {}'.format(weight_assignment))\n\n            key, value = weight_assignment.split('=', 1)\n            value = float(value)\n            if key == 'R':\n                r_group_weight = value\n            elif key == '*':\n                default_weight = value\n            elif hasattr(Atom, key):\n                weights_dict[Atom(key)] = value\n            else:\n                raise ValueError('Invalid element: {}'.format(key))\n\n    return weights_dict, r_group_weight, default_weight", "response": "Parse list of weight assignments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncombines multiple pair transfers into one.", "response": "def _combine_transfers(self, result):\n        \"\"\"Combine multiple pair transfers into one.\"\"\"\n        transfers = {}\n        for reaction_id, c1, c2, form in result:\n            key = reaction_id, c1, c2\n            combined_form = transfers.setdefault(key, Formula())\n            transfers[key] = combined_form | form\n\n        for (reaction_id, c1, c2), form in iteritems(transfers):\n            yield reaction_id, c1, c2, form"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_resource(container, resource, local_filename, contents_only=True):\n    with temp_dir() as remote_tmp:\n        base_name = os.path.basename(resource)\n        copy_path = posixpath.join(remote_tmp, 'copy_tmp')\n        run(mkdir(copy_path, check_if_exists=True))\n        remote_name = posixpath.join(copy_path, base_name)\n        archive_name = 'container_{0}.tar.gz'.format(container)\n        archive_path = posixpath.join(remote_tmp, archive_name)\n        run('docker cp {0}:{1} {2}'.format(container, resource, copy_path), shell=False)\n        if contents_only and is_directory(remote_name):\n            src_dir = remote_name\n            src_files = '*'\n        else:\n            src_dir = copy_path\n            src_files = base_name\n        with cd(src_dir):\n            run(targz(archive_path, src_files))\n        get(archive_path, local_filename)", "response": "Copy a resource from a container to a compressed tarball and downloads it locally."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_resources(src_container, src_resources, storage_dir, dst_directories=None, apply_chown=None, apply_chmod=None):\n    def _copy_resource(resource):\n        default_dest_path = generic_path if generic_path is not None else resource\n        dest_path = directories.get(resource, default_dest_path).strip(posixpath.sep)\n        head, tail = posixpath.split(dest_path)\n        rel_path = posixpath.join(storage_dir, head)\n        run(mkdir(rel_path, check_if_exists=True))\n        run('docker cp {0}:{1} {2}'.format(src_container, resource, rel_path), shell=False)\n\n    directories = dst_directories or {}\n    generic_path = directories.get('*')\n    for res in src_resources:\n        _copy_resource(res)\n    if apply_chmod:\n        run(chmod(apply_chmod, storage_dir))\n    if apply_chown:\n        sudo(chown(apply_chown, storage_dir))", "response": "Copy resources from a Docker container to a new container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nisolating a container and downloads it.", "response": "def isolate_and_get(src_container, src_resources, local_dst_dir, **kwargs):\n    \"\"\"\n    Uses :func:`copy_resources` to copy resources from a container, but afterwards generates a compressed tarball\n    and downloads it.\n\n    :param src_container: Container name or id.\n    :type src_container: unicode\n    :param src_resources: Resources, as (file or directory) names to copy.\n    :type src_resources: iterable\n    :param local_dst_dir: Local directory to store the compressed tarball in. Can also be a file name; the default file\n      name is ``container_<container name>.tar.gz``.\n    :type local_dst_dir: unicode\n    :param kwargs: Additional kwargs for :func:`copy_resources`.\n    \"\"\"\n    with temp_dir() as remote_tmp:\n        copy_path = posixpath.join(remote_tmp, 'copy_tmp')\n        archive_path = posixpath.join(remote_tmp, 'container_{0}.tar.gz'.format(src_container))\n        copy_resources(src_container, src_resources, copy_path, **kwargs)\n        with cd(copy_path):\n            sudo(targz(archive_path, '*'))\n        get(archive_path, local_dst_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy resources from a container and import them into a Docker image.", "response": "def isolate_to_image(src_container, src_resources, dst_image, **kwargs):\n    \"\"\"\n    Uses :func:`copy_resources` to copy resources from a container, but afterwards imports the contents into a new\n    (otherwise empty) Docker image.\n\n    :param src_container: Container name or id.\n    :type src_container: unicode\n    :param src_resources: Resources, as (file or directory) names to copy.\n    :type src_resources: iterable\n    :param dst_image: Tag for the new image.\n    :type dst_image: unicode\n    :param kwargs: Additional kwargs for :func:`copy_resources`.\n    \"\"\"\n    with temp_dir() as remote_tmp:\n        copy_resources(src_container, src_resources, remote_tmp, **kwargs)\n        with cd(remote_tmp):\n            sudo('tar -cz * | docker import - {0}'.format(dst_image))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_image(image, local_filename):\n    r_name, __, i_name = image.rpartition('/')\n    i_name, __, __ = i_name.partition(':')\n    with temp_dir() as remote_tmp:\n        archive = posixpath.join(remote_tmp, 'image_{0}.tar.gz'.format(i_name))\n        run('docker save {0} | gzip --stdout > {1}'.format(image, archive), shell=False)\n        get(archive, local_filename)", "response": "Saves a Docker image as a compressed tarball."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flatten_image(image, dest_image=None, no_op_cmd='/bin/true', create_kwargs={}, start_kwargs={}):\n    dest_image = dest_image or image\n    with temp_container(image, no_op_cmd=no_op_cmd, create_kwargs=create_kwargs, start_kwargs=start_kwargs) as c:\n        run('docker export {0} | docker import - {1}'.format(c, dest_image), shell=False)", "response": "Flatten an image into a new image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode_name(s):\n    # Some names contain XML-like entity codes\n    return re.sub(r'&#(\\d+);', lambda x: chr(int(x.group(1))), s)", "response": "Decode names in ModelSEED files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating over the compound entries in the given file f.", "response": "def parse_compound_file(f, context=None):\n    \"\"\"Iterate over the compound entries in the given file\"\"\"\n\n    f.readline()  # Skip header\n    for lineno, row in enumerate(csv.reader(f, delimiter='\\t')):\n        compound_id, names, formula = row[:3]\n        names = (decode_name(name) for name in names.split(',<br>'))\n\n        # ModelSEED sometimes uses an asterisk and number at\n        # the end of formulas. This seems to have a similar\n        # meaning as '(...)n'.\n        m = re.match(r'^(.*)\\*(\\d*)$', formula)\n        if m is not None:\n            if m.group(2) != '':\n                formula = '({}){}'.format(m.group(1), m.group(2))\n            else:\n                formula = '({})n'.format(m.group(1))\n\n        formula = formula.strip()\n        if formula == '' or formula == 'noformula':\n            formula = None\n\n        mark = FileMark(context, lineno, 0)\n        yield CompoundEntry(compound_id, names, formula, filemark=mark)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the search command.", "response": "def run(self):\n        \"\"\"Run search command.\"\"\"\n\n        which_command = self._args.which\n        if which_command == 'compound':\n            self._search_compound()\n        elif which_command == 'reaction':\n            self._search_reaction()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the value of the attribute to a JSON string.", "response": "def to_json(self, propval, extraneous=False, to_json_func=None):\n        \"\"\"This function calls the ``json_out`` function, if it was specified,\n        otherwise continues with JSON conversion of the value in the slot by\n        calling ``to_json_func`` on it.\n        \"\"\"\n        if self.json_out:\n            return self.json_out(propval)\n        else:\n            if not to_json_func:\n                from normalize.record.json import to_json\n                to_json_func = to_json\n            return to_json_func(propval, extraneous)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the Rate - Limiter and CORS and error handlers.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\n\n        Initialize the Rate-Limiter, CORS and error handlers.\n\n        :param app: An instance of :class:`flask.Flask`.\n        \"\"\"\n        self.init_config(app)\n\n        # Enable CORS support if desired\n        if app.config['REST_ENABLE_CORS']:\n            from flask_cors import CORS\n            CORS(app)\n            # CORS can be configured using CORS_* configuration variables.\n\n        app.errorhandler(400)(create_api_errorhandler(\n            status=400, message='Bad Request'))\n        app.errorhandler(401)(create_api_errorhandler(\n            status=401, message='Unauthorized'))\n        app.errorhandler(403)(create_api_errorhandler(\n            status=403, message='Forbidden'))\n        app.errorhandler(404)(create_api_errorhandler(\n            status=404, message='Not Found'))\n        app.errorhandler(405)(create_api_errorhandler(\n            status=405, message='Method Not Allowed'))\n        app.errorhandler(406)(create_api_errorhandler(\n            status=406, message='Not Acceptable'))\n        app.errorhandler(409)(create_api_errorhandler(\n            status=409, message='Conflict'))\n        app.errorhandler(410)(create_api_errorhandler(\n            status=410, message='Gone'))\n        app.errorhandler(412)(create_api_errorhandler(\n            status=412, message='Precondition Failed'))\n        app.errorhandler(415)(create_api_errorhandler(\n            status=415, message='Unsupported media type'))\n        app.errorhandler(422)(create_api_errorhandler(\n            status=422, message='Unprocessable Entity'))\n        app.errorhandler(429)(create_api_errorhandler(\n            status=429, message='Rate limit exceeded'))\n        app.errorhandler(500)(create_api_errorhandler(\n            status=500, message='Internal Server Error'))\n        app.errorhandler(501)(create_api_errorhandler(\n            status=501, message='Not Implemented'))\n        app.errorhandler(502)(create_api_errorhandler(\n            status=502, message='Bad Gateway'))\n        app.errorhandler(503)(create_api_errorhandler(\n            status=503, message='Service Unavailable'))\n        app.errorhandler(504)(create_api_errorhandler(\n            status=504, message='Gateway Timeout'))\n\n        app.extensions['invenio-rest'] = self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing configuration. .. note:: Change Flask-CORS and Flask-Limiter defaults. :param app: An instance of :class:`flask.Flask`.", "response": "def init_config(self, app):\n        \"\"\"Initialize configuration.\n\n        .. note:: Change Flask-CORS and Flask-Limiter defaults.\n\n        :param app: An instance of :class:`flask.Flask`.\n        \"\"\"\n        config_apps = ['REST_', 'CORS_', ]\n        for k in dir(config):\n            if any([k.startswith(prefix) for prefix in config_apps]):\n                app.config.setdefault(k, getattr(config, k))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_compound(s, global_compartment=None):\n    m = re.match(r'^\\|(.*)\\|$', s)\n    if m:\n        s = m.group(1)\n\n    m = re.match(r'^(.+)\\[(\\S+)\\]$', s)\n    if m:\n        compound_id = m.group(1)\n        compartment = m.group(2)\n    else:\n        compound_id = s\n        compartment = global_compartment\n\n    return Compound(compound_id, compartment=compartment)", "response": "Parse a compound specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_compound_count(s):\n    m = re.match(r'^\\((.*)\\)$', s)\n    if m:\n        s = m.group(1)\n\n    for count_type in (int, Decimal, affine.Expression):\n        try:\n            return count_type(s)\n        except:\n            pass\n\n    raise ValueError('Unable to parse compound count: {}'.format(s))", "response": "Parse a compound count (number of compounds )."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_gene_associations(model):\n\n    for reaction in model.reactions:\n        assoc = None\n        if reaction.genes is None:\n            continue\n        elif isinstance(reaction.genes, string_types):\n            assoc = boolean.Expression(reaction.genes)\n        else:\n            variables = [boolean.Variable(g) for g in reaction.genes]\n            assoc = boolean.Expression(boolean.And(*variables))\n        yield reaction.id, assoc", "response": "Returns a generator that yields reaction IDs to sequence of gene associations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a random minimal network of model reactions.", "response": "def random_sparse(strategy, prob, obj_reaction, flux_threshold):\n    \"\"\"Find a random minimal network of model reactions.\n\n    Given a reaction to optimize and a threshold, delete entities randomly\n    until the flux of the reaction to optimize falls under the threshold.\n    Keep deleting until no more entities can be deleted. It works\n    with two strategies: deleting reactions or deleting genes (reactions\n    related to certain genes).\n\n    Args:\n        strategy: :class:`.ReactionDeletionStrategy` or\n            :class:`.GeneDeletionStrategy`.\n        prob: :class:`psamm.fluxanalysis.FluxBalanceProblem`.\n        obj_reaction: objective reactions to optimize.\n        flux_threshold: threshold of max reaction flux.\n    \"\"\"\n\n    essential = set()\n    deleted = set()\n    for entity, deleted_reactions in strategy.iter_tests():\n        if obj_reaction in deleted_reactions:\n            logger.info(\n                'Marking entity {} as essential because the objective'\n                ' reaction depends on this entity...'.format(entity))\n            essential.add(entity)\n            continue\n\n        if len(deleted_reactions) == 0:\n            logger.info(\n                'No reactions were removed when entity {}'\n                ' was deleted'.format(entity))\n            deleted.add(entity)\n            strategy.delete(entity, deleted_reactions)\n            continue\n\n        logger.info('Deleted reactions: {}'.format(\n            ', '.join(deleted_reactions)))\n\n        constr = []\n        for r in deleted_reactions:\n            flux_var = prob.get_flux_var(r)\n            c, = prob.prob.add_linear_constraints(flux_var == 0)\n            constr.append(c)\n\n        logger.info('Trying FBA without reactions {}...'.format(\n            ', '.join(deleted_reactions)))\n\n        try:\n            prob.maximize(obj_reaction)\n        except fluxanalysis.FluxBalanceError:\n            logger.info(\n                'FBA is infeasible, marking {} as essential'.format(\n                    entity))\n            for c in constr:\n                c.delete()\n            essential.add(entity)\n            continue\n\n        logger.debug('Reaction {} has flux {}'.format(\n            obj_reaction, prob.get_flux(obj_reaction)))\n\n        if prob.get_flux(obj_reaction) < flux_threshold:\n            for c in constr:\n                c.delete()\n            essential.add(entity)\n            logger.info('Entity {} was essential'.format(\n                entity))\n        else:\n            deleted.add(entity)\n            strategy.delete(entity, deleted_reactions)\n            logger.info('Entity {} was deleted'.format(entity))\n\n    return essential, deleted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun sink production check method.", "response": "def run_sink_check(self, model, solver, threshold, implicit_sinks=True):\n        \"\"\"Run sink production check method.\"\"\"\n        prob = solver.create_problem()\n\n        # Create flux variables\n        v = prob.namespace()\n        for reaction_id in model.reactions:\n            lower, upper = model.limits[reaction_id]\n            v.define([reaction_id], lower=lower, upper=upper)\n\n        # Build mass balance constraints\n        massbalance_lhs = {compound: 0 for compound in model.compounds}\n        for spec, value in iteritems(model.matrix):\n            compound, reaction_id = spec\n            massbalance_lhs[compound] += v(reaction_id) * value\n\n        mass_balance_constrs = {}\n        for compound, lhs in iteritems(massbalance_lhs):\n            if implicit_sinks:\n                # The constraint is merely >0 meaning that we have implicit\n                # sinks for all compounds.\n                prob.add_linear_constraints(lhs >= 0)\n            else:\n                # Save these constraints so we can temporarily remove them\n                # to create a sink.\n                c, = prob.add_linear_constraints(lhs == 0)\n                mass_balance_constrs[compound] = c\n\n        for compound, lhs in sorted(iteritems(massbalance_lhs)):\n            if not implicit_sinks:\n                mass_balance_constrs[compound].delete()\n\n            prob.set_objective(lhs)\n            try:\n                result = prob.solve(lp.ObjectiveSense.Maximize)\n            except lp.SolverError as e:\n                logger.warning('Failed to solve for compound: {} ({})'.format(\n                    compound, e))\n\n            if result.get_value(lhs) < threshold:\n                yield compound\n\n            if not implicit_sinks:\n                # Restore mass balance constraint.\n                c, = prob.add_linear_constraints(lhs == 0)\n                mass_balance_constrs[compound] = c"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_reaction_production_check(self, model, solver, threshold,\n                                      implicit_sinks=True):\n        \"\"\"Run reaction production check method.\"\"\"\n        prob = solver.create_problem()\n\n        # Create flux variables\n        v = prob.namespace()\n        for reaction_id in model.reactions:\n            lower, upper = model.limits[reaction_id]\n            v.define([reaction_id], lower=lower, upper=upper)\n\n        # Build mass balance constraints\n        massbalance_lhs = {compound: 0 for compound in model.compounds}\n        for spec, value in iteritems(model.matrix):\n            compound, reaction_id = spec\n            massbalance_lhs[compound] += v(reaction_id) * value\n\n        # Create production variables and apply constraints\n        for compound, lhs in iteritems(massbalance_lhs):\n            if implicit_sinks:\n                # The constraint is merely >0 meaning that we have implicit\n                # sinks for all compounds.\n                prob.add_linear_constraints(lhs >= 0)\n            else:\n                prob.add_linear_constraints(lhs == 0)\n\n        confirmed_production = set()\n        for reaction in model.reactions:\n            if all(c in confirmed_production for c, _ in\n                   model.get_reaction_values(reaction)):\n                continue\n\n            prob.set_objective(v(reaction))\n            for sense in (lp.ObjectiveSense.Maximize,\n                          lp.ObjectiveSense.Minimize):\n                try:\n                    result = prob.solve(sense)\n                except lp.SolverError as e:\n                    self.fail(\n                        'Failed to solve for compound, reaction: {}, {}:'\n                        ' {}'.format(compound, reaction, e))\n\n                flux = result.get_value(v(reaction))\n                for compound, value in model.get_reaction_values(reaction):\n                    if compound in confirmed_production:\n                        continue\n\n                    production = 0\n                    if sense == lp.ObjectiveSense.Maximize and flux > 0:\n                        production = float(value) * flux\n                    elif sense == lp.ObjectiveSense.Minimize and flux < 0:\n                        production = float(value) * flux\n\n                    if production >= threshold:\n                        confirmed_production.add(compound)\n\n        for compound in sorted(model.compounds):\n            if compound not in confirmed_production:\n                yield compound", "response": "Runs reaction production check method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefining a variable in the problem.", "response": "def define(self, *names, **kwargs):\n        \"\"\"Define a variable in the problem.\n\n        Variables must be defined before they can be accessed by var() or\n        set(). This function takes keyword arguments lower and upper to define\n        the bounds of the variable (default: -inf to inf). The keyword argument\n        types can be used to select the type of the variable (Continuous\n        (default), Binary or Integer). Setting any variables different than\n        Continuous will turn the problem into an MILP problem. Raises\n        ValueError if a name is already defined.\n        \"\"\"\n        names = tuple(names)\n        for name in names:\n            if name in self._variables:\n                raise ValueError('Variable already defined: {!r}'.format(name))\n\n        lower = kwargs.get('lower', None)\n        upper = kwargs.get('upper', None)\n        vartype = kwargs.get('types', None)\n\n        # Repeat values if a scalar is given\n        if lower is None or isinstance(lower, numbers.Number):\n            lower = repeat(lower, len(names))\n        if upper is None or isinstance(upper, numbers.Number):\n            upper = repeat(upper, len(names))\n        if vartype is None or vartype in (\n                VariableType.Continuous, VariableType.Binary,\n                VariableType.Integer):\n            vartype = repeat(vartype, len(names))\n\n        lp_names = tuple(next(self._var_names) for name in names)\n\n        # Assign default values\n        lower = (-cp.infinity if value is None or value == -_INF\n                 else float(value) for value in lower)\n        upper = (cp.infinity if value is None or value == _INF\n                 else float(value) for value in upper)\n        vartype = tuple(VariableType.Continuous if value is None else value\n                        for value in vartype)\n\n        args = {'lb': tuple(lower), 'ub': tuple(upper)}\n        if any(value != VariableType.Continuous for value in vartype):\n            # Set types only if some are integer (otherwise Cplex will change\n            # the solver to MILP).\n            args['types'] = tuple(Problem.VARTYPE_MAP[t] for t in vartype)\n\n        self._variables.update(zip(names, lp_names))\n        self._cp.variables.add(**args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_constraints(self, relation):\n        expression = relation.expression\n        pairs = []\n        for value_set in expression.value_sets():\n            ind, val = zip(*((self._variables[variable], float(value))\n                             for variable, value in value_set))\n            pairs.append(cp.SparsePair(ind=ind, val=val))\n\n        names = [next(self._constr_names) for _ in pairs]\n\n        sense = self.CONSTR_SENSE_MAP[relation.sense]\n        self._cp.linear_constraints.add(\n            names=names, lin_expr=pairs,\n            senses=tuple(repeat(sense, len(pairs))),\n            rhs=tuple(repeat(float(-expression.offset), len(pairs))))\n\n        return names", "response": "Add the given relation as one or more constraints\n        Return a list of the names of the constraints added."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_linear_constraints(self, *relations):\n        constraints = []\n\n        for relation in relations:\n            if self._check_relation(relation):\n                constraints.append(Constraint(self, None))\n            else:\n                for name in self._add_constraints(relation):\n                    constraints.append(Constraint(self, name))\n\n        return constraints", "response": "Add constraints to the problem\nCOOKIE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_objective(self, expression):\n\n        if isinstance(expression, numbers.Number):\n            # Allow expressions with no variables as objective,\n            # represented as a number\n            expression = Expression(offset=expression)\n\n        linear = []\n        quad = []\n\n        # Reset previous objective.\n        for var in self._non_zero_objective:\n            if var not in expression:\n                if not isinstance(var, Product):\n                    linear.append((self._variables[var], 0))\n                else:\n                    t = self._variables[var[0]], self._variables[var[1]], 0\n                    quad.append(t)\n\n        self._non_zero_objective.clear()\n\n        # Set actual objective values\n        for var, value in expression.values():\n            if not isinstance(var, Product):\n                self._non_zero_objective.add(var)\n                linear.append((self._variables[var], float(value)))\n            else:\n                if len(var) > 2:\n                    raise ValueError('Invalid objective: {}'.format(var))\n                self._non_zero_objective.add(var)\n                var1 = self._variables[var[0]]\n                var2 = self._variables[var[1]]\n                if var1 == var2:\n                    value *= 2\n                quad.append((var1, var2, float(value)))\n\n        # We have to build the set of variables to\n        # update so that we can avoid calling set_linear if the set is empty.\n        # This is due to set_linear failing if the input is an empty\n        # iterable.\n        if len(linear) > 0:\n            self._cp.objective.set_linear(linear)\n        if len(quad) > 0:\n            self._cp.objective.set_quadratic_coefficients(quad)\n\n        if hasattr(self._cp.objective, 'set_offset'):\n            self._cp.objective.set_offset(float(expression.offset))", "response": "Set the objective expression of the problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_objective_sense(self, sense):\n        if sense == ObjectiveSense.Minimize:\n            self._cp.objective.set_sense(self._cp.objective.sense.minimize)\n        elif sense == ObjectiveSense.Maximize:\n            self._cp.objective.set_sense(self._cp.objective.sense.maximize)\n        else:\n            raise ValueError('Invalid objective sense')", "response": "Set type of problem (maximize or minimize)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets problem type to whatever is appropriate.", "response": "def _reset_problem_type(self):\n        \"\"\"Reset problem type to whatever is appropriate.\"\"\"\n\n        # Only need to reset the type after the first solve. This also works\n        # around a bug in Cplex where get_num_binary() is some rare cases\n        # causes a segfault.\n        if self._solve_count > 0:\n            integer_count = 0\n            for func in (self._cp.variables.get_num_binary,\n                         self._cp.variables.get_num_integer,\n                         self._cp.variables.get_num_semicontinuous,\n                         self._cp.variables.get_num_semiinteger):\n                integer_count += func()\n\n            integer = integer_count > 0\n            quad_constr = self._cp.quadratic_constraints.get_num() > 0\n            quad_obj = self._cp.objective.get_num_quadratic_variables() > 0\n\n            if not integer:\n                if quad_constr:\n                    new_type = self._cp.problem_type.QCP\n                elif quad_obj:\n                    new_type = self._cp.problem_type.QP\n                else:\n                    new_type = self._cp.problem_type.LP\n            else:\n                if quad_constr:\n                    new_type = self._cp.problem_type.MIQCP\n                elif quad_obj:\n                    new_type = self._cp.problem_type.MIQP\n                else:\n                    new_type = self._cp.problem_type.MILP\n\n            logger.debug('Setting problem type to {}...'.format(\n                self._cp.problem_type[new_type]))\n            self._cp.set_problem_type(new_type)\n        else:\n            logger.debug('Problem type is {}'.format(\n                self._cp.problem_type[self._cp.get_problem_type()]))\n\n        # Force QP/MIQP solver to look for global optimum. We set it here only\n        # for QP/MIQP problems to avoid the warnings generated for other\n        # problem types when this parameter is set.\n        quad_obj = self._cp.objective.get_num_quadratic_variables() > 0\n\n        if hasattr(self._cp.parameters, 'optimalitytarget'):\n            target_param = self._cp.parameters.optimalitytarget\n        else:\n            target_param = self._cp.parameters.solutiontarget\n\n        if quad_obj:\n            target_param.set(target_param.values.optimal_global)\n        else:\n            target_param.set(target_param.values.auto)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving problem and return result.", "response": "def solve_unchecked(self, sense=None):\n        \"\"\"Solve problem and return result.\n\n        The user must manually check the status of the result to determine\n        whether an optimal solution was found. A :class:`SolverError` may still\n        be raised if the underlying solver raises an exception.\n        \"\"\"\n        if sense is not None:\n            self.set_objective_sense(sense)\n\n        self._solve()\n        self._result = Result(self)\n\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef success(self):\n        self._check_valid()\n        return self._problem._cp.solution.get_status() in (\n            self._problem._cp.solution.status.optimal,\n            self._problem._cp.solution.status.optimal_tolerance,\n            self._problem._cp.solution.status.MIP_optimal)", "response": "Return whether a solution was found"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unbounded(self):\n        self._check_valid()\n\n        cp = self._problem._cp\n        status = cp.solution.get_status()\n        presolve = cp.parameters.preprocessing.presolve.get()\n        if (status == cp.solution.status.infeasible_or_unbounded and\n                presolve):\n            # Disable presolve to obtain a definitive answer\n            logger.info('Disabling presolver and solving again to determine'\n                        ' whether objective is unbounded.')\n            cp.parameters.preprocessing.presolve.set(False)\n            try:\n                self._problem._solve()\n            finally:\n                cp.parameters.preprocessing.presolve.set(True)\n\n            status = cp.solution.get_status()\n\n        return status == cp.solution.status.unbounded", "response": "Whether the current solution is unbounded."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_value(self, var):\n        return self._problem._cp.solution.get_values(\n            self._problem._variables[var])", "response": "Return value of variable in solution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning value of expression.", "response": "def get_value(self, expression):\n        \"\"\"Return value of expression.\"\"\"\n        self._check_valid()\n        return super(Result, self).get_value(expression)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        obj_reaction = self._get_objective()\n\n        genes = set()\n        gene_assoc = {}\n        for reaction in self._model.reactions:\n            assoc = None\n            if reaction.genes is None:\n                continue\n            elif isinstance(reaction.genes, string_types):\n                assoc = boolean.Expression(reaction.genes)\n            else:\n                variables = [boolean.Variable(g) for g in reaction.genes]\n                assoc = boolean.Expression(boolean.And(*variables))\n            genes.update(v.symbol for v in assoc.variables)\n            gene_assoc[reaction.id] = assoc\n\n        reactions = set(self._mm.reactions)\n        start_time = time.time()\n        testing_genes = set(self._args.gene)\n        deleted_reactions = set()\n\n        logger.info('Trying model without genes: {}...'.format(\n                    ', '.join(sorted(testing_genes))))\n\n        for reaction in reactions:\n            if reaction not in gene_assoc:\n                continue\n            assoc = gene_assoc[reaction]\n            if any(boolean.Variable(gene) in assoc.variables\n                    for gene in testing_genes):\n                new_assoc = assoc.substitute(\n                    lambda v: v if v.symbol not in testing_genes else False)\n                if new_assoc.has_value() and not new_assoc.value:\n                    logger.info('Deleting reaction {}...'.format(reaction))\n                    deleted_reactions.add(reaction)\n\n        if self._args.method in ['moma', 'moma2']:\n            solver = self._get_solver(quadratic=True)\n        else:\n            solver = self._get_solver()\n\n        if self._args.method == 'fba':\n            logger.info('Solving using FBA...')\n            prob = fluxanalysis.FluxBalanceProblem(self._mm, solver)\n\n            try:\n                prob.maximize(obj_reaction)\n            except fluxanalysis.FluxBalanceError as e:\n                self.report_flux_balance_error(e)\n\n            wild = prob.get_flux(obj_reaction)\n\n            for reaction in deleted_reactions:\n                flux_var = prob.get_flux_var(reaction)\n                prob.prob.add_linear_constraints(flux_var == 0)\n\n            prob.maximize(obj_reaction)\n            deleteflux = prob.get_flux(obj_reaction)\n        elif self._args.method in ['lin_moma', 'lin_moma2', 'moma', 'moma2']:\n            prob = moma.MOMAProblem(self._mm, solver)\n            wt_fluxes = prob.get_minimal_fba_flux(obj_reaction)\n            wild = wt_fluxes[obj_reaction]\n\n            for reaction in deleted_reactions:\n                flux_var = prob.get_flux_var(reaction)\n                prob.prob.add_linear_constraints(flux_var == 0)\n\n            try:\n                if self._args.method == 'moma':\n                    logger.info('Solving using MOMA...')\n                    prob.moma(wt_fluxes)\n                elif self._args.method == 'lin_moma':\n                    logger.info('Solving using linear MOMA...')\n                    prob.lin_moma(wt_fluxes)\n                elif self._args.method == 'moma2':\n                    logger.info('Solving using combined-model MOMA...')\n                    prob.moma2(obj_reaction, wild)\n                elif self._args.method == 'lin_moma2':\n                    logger.info('Solving using combined-model linear MOMA...')\n                    prob.lin_moma2(obj_reaction, wild)\n            except moma.MOMAError:\n                self.fail('Error computing the MOMA result.')\n\n            deleteflux = prob.get_flux(obj_reaction)\n\n        logger.info(\n            'Solving took {:.2f} seconds'.format(time.time() - start_time))\n        logger.info(\n            'Objective reaction after gene deletion has flux {}'.format(\n                deleteflux + 0))\n        if wild != 0:\n            logger.info(\n                'Objective reaction has {:.2%} flux of wild type flux'.format(\n                    abs(deleteflux / wild)))", "response": "Delete the specified gene and solve using the desired method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_formula(s):\n    scanner = re.compile(r'''\n        (\\s+) |         # whitespace\n        (\\(|\\)) |       # group\n        ([A-Z][a-z]*) | # element\n        (\\d+) |         # number\n        ([a-z]) |       # variable\n        (\\Z) |          # end\n        (.)             # error\n    ''', re.DOTALL | re.VERBOSE)\n\n    def transform_subformula(form):\n        \"\"\"Extract radical if subformula is a singleton with a radical.\"\"\"\n        if isinstance(form, dict) and len(form) == 1:\n            # A radical in a singleton subformula is interpreted as a\n            # numbered radical.\n            element, value = next(iteritems(form))\n            if isinstance(element, Radical):\n                return Radical('{}{}'.format(element.symbol, value))\n        return form\n\n    stack = []\n    formula = {}\n    expect_count = False\n\n    def close(formula, count=1):\n        if len(stack) == 0:\n            raise ParseError('Unbalanced parenthesis group in formula')\n        subformula = transform_subformula(formula)\n        if isinstance(subformula, dict):\n            subformula = Formula(subformula)\n\n        formula = stack.pop()\n        if subformula not in formula:\n            formula[subformula] = 0\n        formula[subformula] += count\n        return formula\n\n    for match in re.finditer(scanner, s):\n        (whitespace, group, element, number, variable, end,\n            error) = match.groups()\n\n        if error is not None:\n            raise ParseError(\n                'Invalid token in formula string: {!r}'.format(match.group(0)),\n                span=(match.start(), match.end()))\n        elif whitespace is not None:\n            continue\n        elif group is not None and group == '(':\n            if expect_count:\n                formula = close(formula)\n            stack.append(formula)\n            formula = {}\n            expect_count = False\n        elif group is not None and group == ')':\n            if expect_count:\n                formula = close(formula)\n            expect_count = True\n        elif element is not None:\n            if expect_count:\n                formula = close(formula)\n            stack.append(formula)\n            if element in 'RX':\n                formula = Radical(element)\n            else:\n                formula = Atom(element)\n            expect_count = True\n        elif number is not None and expect_count:\n            formula = close(formula, int(number))\n            expect_count = False\n        elif variable is not None and expect_count:\n            formula = close(formula, Expression(variable))\n            expect_count = False\n        elif end is not None:\n            if expect_count:\n                formula = close(formula)\n        else:\n            raise ParseError(\n                'Invalid token in formula string: {!r}'.format(match.group(0)),\n                span=(match.start(), match.end()))\n\n    if len(stack) > 0:\n        raise ParseError('Unbalanced parenthesis group in formula')\n\n    return Formula(formula)", "response": "Parse a string of radical formulas into a single tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of the current object.", "response": "def copy(self):\n        \"\"\"Be sure to implement this method when sub-classing, otherwise you\n        will lose any specialization context.\"\"\"\n        doppel = type(self)(\n            self.unpack, self.apply, self.collect, self.reduce,\n            apply_empty_slots=self.apply_empty_slots,\n            extraneous=self.extraneous,\n            ignore_empty_string=self.ignore_empty_string,\n            ignore_none=self.ignore_none,\n            visit_filter=self.visit_filter,\n        )\n        for x in self.cue:\n            doppel.push(x)\n        doppel.seen = self.seen\n        return doppel"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack(cls, value, value_type, visitor):\n        if issubclass(value_type, Collection):\n            try:\n                generator = value.itertuples()\n            except AttributeError:\n                if isinstance(value, value_type.colltype):\n                    generator = value_type.coll_to_tuples(value)\n                else:\n                    raise exc.VisitorUnpackError(\n                        passed=value,\n                        colltype=value_type.colltype.__name__,\n                        context=visitor,\n                    )\n        else:\n            generator = None\n\n        if issubclass(value_type, Record):\n            def propget(prop):\n                return prop.__get__(value)\n        else:\n            propget = None\n\n        return propget, generator", "response": "Unpack a value during a visit"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(cls, value, prop, visitor):\n        return (\n            None if isinstance(value, (AttributeError, KeyError)) else\n            value\n        )", "response": "This function is used to apply the value of the current record in the class. It is used to apply the value of the current record in the class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate(self, mapped_coll_generator, coll_type, visitor):\n        return coll_type.tuples_to_coll(mapped_coll_generator, coerce=False)", "response": "Hook called for each normalize. coll. Collection after mapping over\n            each of the items in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cast(cls, value_type, value, visitor=None, **kwargs):\n        if visitor is None:\n            visitor = cls.Visitor(\n                cls.grok, cls.reverse, cls.collect, cls.produce,\n                **kwargs)\n\n        return cls.map(visitor, value, value_type)", "response": "Casts the value to the specified type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a value and returns a generator that returns the value of the given type.", "response": "def grok(cls, value, value_type, visitor):\n        \"\"\"Like :py:meth:`normalize.visitor.VisitorPattern.unpack` but called\n        for ``cast`` operations.  Expects to work with dictionaries and lists\n        instead of Record objects.\n\n        Reverses the transform performed in\n        :py:meth:`normalize.visitor.VisitorPattern.reduce` for collections with\n        properties.\n\n        If you pass tuples to ``isa`` of your Properties, then you might need\n        to override this function and throw ``TypeError`` if the passed\n        ``value_type`` is not appropriate for ``value``.\n        \"\"\"\n        is_coll = issubclass(value_type, Collection)\n        is_record = issubclass(value_type, Record) and any(\n            not visitor.is_filtered(prop) for prop in\n            value_type.properties.values()\n        )\n\n        if is_record and not isinstance(value, cls.grok_mapping_types):\n            raise exc.VisitorGrokRecordError(\n                val=repr(value),\n                record_type=value_type,\n                record_type_name=value_type.__name__,\n                field_selector=visitor.field_selector,\n            )\n\n        values = value\n        if is_coll and is_record:\n            try:\n                if \"values\" in value:\n                    values = value['values']\n            except TypeError:\n                pass\n\n        generator = None\n        if is_coll:\n            if not isinstance(values, cls.grok_coll_types):\n                raise exc.VisitorGrokCollectionError(\n                    val=repr(values),\n                    record_type=value_type,\n                    record_type_name=value_type.__name__,\n                    field_selector=visitor.field_selector,\n                )\n            generator = value_type.coll_to_tuples(values)\n\n        propget = None\n        if is_record:\n            def propget(prop):\n                return value[prop.name]\n\n        return propget, generator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reverse(cls, value, prop, visitor):\n        return (\n            None if isinstance(value, (AttributeError, KeyError)) else\n            value\n        )", "response": "Reverse the value of the key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef produce(cls, mapped_props, aggregated, value_type, visitor):\n        kwargs = {} if not mapped_props else dict(\n            (k.name, v) for k, v in mapped_props\n        )\n        if issubclass(value_type, Collection):\n            kwargs['values'] = aggregated\n        return value_type(**kwargs)", "response": "Like normal. visitor. VisitorPattern. produce but\n            constructs instances rather than returning plain dicts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreflecting the class X to the type X.", "response": "def reflect(cls, X, **kwargs):\n        \"\"\"Reflect is for visitors where you are exposing some information\n        about the types reachable from a starting type to an external system.\n        For example, a front-end, a REST URL router and documentation\n        framework, an avro schema definition, etc.\n\n        X can be a type or an instance.\n\n        This API should be considered **experimental**\n        \"\"\"\n        if isinstance(X, type):\n            value = None\n            value_type = X\n        else:\n            value = X\n            value_type = type(X)\n        if not issubclass(value_type, Record):\n            raise TypeError(\"Cannot reflect on %s\" % value_type.__name__)\n\n        visitor = cls.Visitor(\n            cls.scantypes, cls.propinfo, cls.itemtypes,\n            cls.typeinfo,\n            **kwargs)\n\n        return cls.map(visitor, value, value_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scantypes(cls, value, value_type, visitor):\n\n        item_type_generator = None\n        if issubclass(value_type, Collection):\n\n            def get_item_types():\n                if isinstance(value_type.itemtype, tuple):\n                    # not actually supported by Collection yet, but whatever\n                    for vt in value_type.itemtype:\n                        yield (vt, vt)\n                else:\n                    yield value_type.itemtype, value_type.itemtype\n\n            item_type_generator = get_item_types()\n\n        propget = None\n        if issubclass(value_type, Record):\n            def propget(prop):\n                return prop\n\n        return propget, item_type_generator", "response": "Like normalize. visitor. VisitorPattern. unpack but\n            returns a getter which just returns the property and a collection\n            which returns a set with a single item in it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict with some basic info about the a property.", "response": "def propinfo(cls, value, prop, visitor):\n        \"\"\"Like :py:meth:`normalize.visitor.VisitorPattern.apply`, but takes a\n        property and returns a dict with some basic info.  The default\n        implementation returns just the name of the property and the type in\n        here.\n        \"\"\"\n        if not prop:\n            return {\"name\": value.__name__}\n\n        rv = {\"name\": prop.name}\n        if prop.valuetype:\n            if isinstance(prop.valuetype, tuple):\n                rv['type'] = [typ.__name__ for typ in prop.valuetype]\n            else:\n                rv['type'] = prop.valuetype.__name__\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes normalize. visitor. VisitorPattern. aggregate but returns.", "response": "def itemtypes(cls, mapped_types, coll_type, visitor):\n        \"\"\"Like :py:meth:`normalize.visitor.VisitorPattern.aggregate`, but\n        returns .  This will normally only get called with a single type.\n        \"\"\"\n        rv = list(v for k, v in mapped_types)\n        return rv[0] if len(rv) == 1 else rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef typeinfo(cls, propinfo, type_parameters, value_type, visitor):\n        propspec = dict((prop.name, info) for prop, info in propinfo)\n        ts = {'name': value_type.__name__}\n        if propspec:\n            ts['properties'] = propspec\n        if type_parameters:\n            ts['itemtype'] = type_parameters\n        return ts", "response": "This method returns a dictionary that corresponds to a type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map(cls, visitor, value, value_type):\n        unpacked = visitor.unpack(value, value_type, visitor)\n\n        if unpacked == cls.StopVisiting or isinstance(\n            unpacked, cls.StopVisiting\n        ):\n            return unpacked.return_value\n\n        if isinstance(unpacked, tuple):\n            props, coll = unpacked\n        else:\n            props, coll = unpacked, None\n\n        # recurse into values for collections\n        if coll:\n            coll_map_generator = cls.map_collection(\n                visitor, coll, value_type,\n            )\n            mapped_coll = visitor.collect(\n                coll_map_generator, value_type, visitor,\n            )\n        else:\n            mapped_coll = None\n\n        # recurse into regular properties\n        mapped_props = None\n        if props:\n            mapped_props = cls.map_record(visitor, props, value_type)\n        elif mapped_coll is None:\n            return visitor.apply(value, None, visitor)\n\n        return visitor.reduce(\n            mapped_props, mapped_coll, value_type, visitor,\n        )", "response": "This method maps the value of the object to the type of the object being visited by the given visitor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning flux balance analysis on the given model.", "response": "def flux_balance(model, reaction, tfba, solver):\n    \"\"\"Run flux balance analysis on the given model.\n\n    Yields the reaction id and flux value for each reaction in the model.\n\n    This is a convenience function for sertting up and running the\n    FluxBalanceProblem. If the FBA is solved for more than one parameter\n    it is recommended to setup and reuse the FluxBalanceProblem manually\n    for a speed up.\n\n    This is an implementation of flux balance analysis (FBA) as described in\n    [Orth10]_ and [Fell86]_.\n\n    Args:\n        model: MetabolicModel to solve.\n        reaction: Reaction to maximize. If a dict is given, this instead\n            represents the objective function weights on each reaction.\n        tfba: If True enable thermodynamic constraints.\n        solver: LP solver instance to use.\n\n    Returns:\n        Iterator over reaction ID and reaction flux pairs.\n    \"\"\"\n\n    fba = _get_fba_problem(model, tfba, solver)\n    fba.maximize(reaction)\n    for reaction in model.reactions:\n        yield reaction, fba.get_flux(reaction)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the variability of each reaction while fixing certain fluxes.", "response": "def flux_variability(model, reactions, fixed, tfba, solver):\n    \"\"\"Find the variability of each reaction while fixing certain fluxes.\n\n    Yields the reaction id, and a tuple of minimum and maximum value for each\n    of the given reactions. The fixed reactions are given in a dictionary as\n    a reaction id to value mapping.\n\n    This is an implementation of flux variability analysis (FVA) as described\n    in [Mahadevan03]_.\n\n    Args:\n        model: MetabolicModel to solve.\n        reactions: Reactions on which to report variablity.\n        fixed: dict of additional lower bounds on reaction fluxes.\n        tfba: If True enable thermodynamic constraints.\n        solver: LP solver instance to use.\n\n    Returns:\n        Iterator over pairs of reaction ID and bounds. Bounds are returned as\n        pairs of lower and upper values.\n    \"\"\"\n\n    fba = _get_fba_problem(model, tfba, solver)\n\n    for reaction_id, value in iteritems(fixed):\n        flux = fba.get_flux_var(reaction_id)\n        fba.prob.add_linear_constraints(flux >= value)\n\n    def min_max_solve(reaction_id):\n        for direction in (-1, 1):\n            yield fba.flux_bound(reaction_id, direction)\n\n    # Solve for each reaction\n    for reaction_id in reactions:\n        yield reaction_id, tuple(min_max_solve(reaction_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flux_minimization(model, fixed, solver, weights={}):\n\n    fba = FluxBalanceProblem(model, solver)\n\n    for reaction_id, value in iteritems(fixed):\n        flux = fba.get_flux_var(reaction_id)\n        fba.prob.add_linear_constraints(flux >= value)\n\n    fba.minimize_l1()\n\n    return ((reaction_id, fba.get_flux(reaction_id))\n            for reaction_id in model.reactions)", "response": "Minimizes the flux of all reactions while keeping certain fluxes fixed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flux_randomization(model, threshold, tfba, solver):\n\n    optimize = {}\n    for reaction_id in model.reactions:\n        if model.is_reversible(reaction_id):\n            optimize[reaction_id] = 2*random.random() - 1.0\n        else:\n            optimize[reaction_id] = random.random()\n\n    fba = _get_fba_problem(model, tfba, solver)\n    for reaction_id, value in iteritems(threshold):\n        fba.prob.add_linear_constraints(fba.get_flux_var(reaction_id) >= value)\n\n    fba.maximize(optimize)\n    for reaction_id in model.reactions:\n        yield reaction_id, fba.get_flux(reaction_id)", "response": "Find a random flux solution on the boundary of the solution space."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the subset of model is consistent with FBA.", "response": "def consistency_check(model, subset, epsilon, tfba, solver):\n    \"\"\"Check that reaction subset of model is consistent using FBA.\n\n    Yields all reactions that are *not* flux consistent. A reaction is\n    consistent if there is at least one flux solution to the model that both\n    respects the model constraints and also allows the reaction in question to\n    have non-zero flux.\n\n    This can be determined by running FBA on each reaction in turn\n    and checking whether the flux in the solution is non-zero. Since FBA\n    only tries to maximize the flux (and the flux can be negative for\n    reversible reactions), we have to try to both maximize and minimize\n    the flux. An optimization to this method is implemented such that if\n    checking one reaction results in flux in another unchecked reaction,\n    that reaction will immediately be marked flux consistent.\n\n    Args:\n        model: MetabolicModel to check for consistency.\n        subset: Subset of model reactions to check.\n        epsilon: The threshold at which the flux is considered non-zero.\n        tfba: If True enable thermodynamic constraints.\n        solver: LP solver instance to use.\n\n    Returns:\n        An iterator of flux inconsistent reactions in the subset.\n    \"\"\"\n\n    fba = _get_fba_problem(model, tfba, solver)\n\n    subset = set(subset)\n    while len(subset) > 0:\n        reaction = next(iter(subset))\n\n        logger.info('{} left, checking {}...'.format(len(subset), reaction))\n\n        fba.maximize(reaction)\n        subset = set(reaction_id for reaction_id in subset\n                     if abs(fba.get_flux(reaction_id)) <= epsilon)\n        if reaction not in subset:\n            continue\n        elif model.is_reversible(reaction):\n            fba.maximize({reaction: -1})\n            subset = set(reaction_id for reaction_id in subset\n                         if abs(fba.get_flux(reaction_id)) <= epsilon)\n            if reaction not in subset:\n                continue\n\n        logger.info('{} not consistent!'.format(reaction))\n\n        yield reaction\n        subset.remove(reaction)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_thermodynamic(self, em=1000):\n\n        internal = set(r for r in self._model.reactions\n                       if not self._model.is_exchange(r))\n\n        # Reaction fluxes\n        v = self._v\n\n        # Indicator variable\n        alpha = self._prob.namespace(internal, types=lp.VariableType.Binary)\n\n        # Delta mu is the stoichiometrically weighted sum of the compound mus.\n        dmu = self._prob.namespace(internal)\n\n        for reaction_id in self._model.reactions:\n            if not self._model.is_exchange(reaction_id):\n                flux = v(reaction_id)\n                alpha_r = alpha(reaction_id)\n                dmu_r = dmu(reaction_id)\n\n                lower, upper = self._model.limits[reaction_id]\n\n                # Constrain the reaction to a direction determined by alpha\n                # and contrain the delta mu to a value in [-em; -1] if\n                # alpha is one, otherwise in [1; em].\n                self._prob.add_linear_constraints(\n                    flux >= lower * (1 - alpha_r),\n                    flux <= upper * alpha_r,\n                    dmu_r >= -em * alpha_r + (1 - alpha_r),\n                    dmu_r <= em * (1 - alpha_r) - alpha_r)\n\n        # Define mu variables\n        mu = self._prob.namespace(self._model.compounds)\n\n        tdbalance_lhs = {reaction_id: 0\n                         for reaction_id in self._model.reactions}\n        for spec, value in iteritems(self._model.matrix):\n            compound, reaction_id = spec\n            if not self._model.is_exchange(reaction_id):\n                tdbalance_lhs[reaction_id] += mu(compound) * value\n        for reaction_id, lhs in iteritems(tdbalance_lhs):\n            if not self._model.is_exchange(reaction_id):\n                self._prob.add_linear_constraints(lhs == dmu(reaction_id))", "response": "Add thermodynamic constraints to the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsolves the model by maximizing the given reaction.", "response": "def maximize(self, reaction):\n        \"\"\"Solve the model by maximizing the given reaction.\n\n        If reaction is a dictionary object, each entry is interpreted as a\n        weight on the objective for that reaction (non-existent reaction will\n        have zero weight).\n        \"\"\"\n\n        self._prob.set_objective(self.flux_expr(reaction))\n        self._solve()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the flux bound of the reaction.", "response": "def flux_bound(self, reaction, direction):\n        \"\"\"Return the flux bound of the reaction.\n\n        Direction must be a positive number to obtain the upper bound or a\n        negative number to obtain the lower bound. A value of inf or -inf is\n        returned if the problem is unbounded.\n        \"\"\"\n        try:\n            self.maximize({reaction: direction})\n        except FluxBalanceError as e:\n            if not e.result.unbounded:\n                raise\n            return direction * _INF\n        else:\n            return self.get_flux(reaction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds variables and constraints for L1 norm minimization.", "response": "def _add_minimization_vars(self):\n        \"\"\"Add variables and constraints for L1 norm minimization.\"\"\"\n\n        self._z = self._prob.namespace(self._model.reactions, lower=0)\n\n        # Define constraints\n        v = self._v.set(self._model.reactions)\n        z = self._z.set(self._model.reactions)\n\n        self._prob.add_linear_constraints(z >= v, v >= -z)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsolving the model by minimizing the L1 norm of the fluxes.", "response": "def minimize_l1(self, weights={}):\n        \"\"\"Solve the model by minimizing the L1 norm of the fluxes.\n\n        If the weights dictionary is given, the weighted L1 norm if minimized\n        instead. The dictionary contains the weights of each reaction\n        (default 1).\n        \"\"\"\n\n        if self._z is None:\n            self._add_minimization_vars()\n\n        objective = self._z.expr(\n            (reaction_id, -weights.get(reaction_id, 1))\n            for reaction_id in self._model.reactions)\n        self._prob.set_objective(objective)\n\n        self._solve()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef max_min_l1(self, reaction, weights={}):\n\n        self.maximize(reaction)\n\n        if isinstance(reaction, dict):\n            reactions = list(reaction)\n        else:\n            reactions = [reaction]\n\n        # Save flux values before modifying the LP problem\n        fluxes = {r: self.get_flux(r) for r in reactions}\n\n        # Add constraints on the maximized reactions\n        for r in reactions:\n            flux_var = self.get_flux_var(r)\n            c, = self._prob.add_linear_constraints(flux_var == fluxes[r])\n            self._temp_constr.append(c)\n\n        self.minimize_l1(weights)", "response": "Maximize the flux of reaction then minimize the L1 norm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _solve(self):\n\n        # Remove temporary constraints\n        while len(self._remove_constr) > 0:\n            self._remove_constr.pop().delete()\n\n        try:\n            self._prob.solve(lp.ObjectiveSense.Maximize)\n        except lp.SolverError as e:\n            raise_from(FluxBalanceError('Failed to solve: {}'.format(\n                e), result=self._prob.result), e)\n        finally:\n            # Set temporary constraints to be removed on next solve call\n            self._remove_constr = self._temp_constr\n            self._temp_constr = []", "response": "Solve the problem with the current objective."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flux_expr(self, reaction):\n        if isinstance(reaction, dict):\n            return self._v.expr(iteritems(reaction))\n        return self._v(reaction)", "response": "Get LP expression representing the reaction flux."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the result flux value for reaction.", "response": "def get_flux(self, reaction):\n        \"\"\"Get resulting flux value for reaction.\"\"\"\n        return self._prob.result.get_value(self._v(reaction))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef define(self, *names, **kwargs):\n        names = tuple(names)\n        for name in names:\n            if name in self._variables:\n                raise ValueError('Variable already defined: {!r}'.format(name))\n\n        lower = kwargs.get('lower', None)\n        upper = kwargs.get('upper', None)\n        vartype = kwargs.get('types', None)\n\n        # Repeat values if a scalar is given\n        if lower is None or isinstance(lower, numbers.Number):\n            lower = repeat(lower, len(names))\n        if upper is None or isinstance(upper, numbers.Number):\n            upper = repeat(upper, len(names))\n        if vartype is None or vartype in (\n                VariableType.Continuous, VariableType.Binary,\n                VariableType.Integer):\n            vartype = repeat(vartype, len(names))\n\n        lp_names = tuple(next(self._var_names) for name in names)\n\n        # Assign default values\n        vartype = (VariableType.Continuous if value is None else value\n                   for value in vartype)\n\n        self._variables.update(zip(names, lp_names))\n        for name, lower, upper, t in zip(lp_names, lower, upper, vartype):\n            if t != VariableType.Continuous:\n                raise ValueError(\n                    'Solver does not support non-continuous types')\n            self._p.add_variable(0, lower, upper, name)", "response": "Define a variable in the problem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the given relation as one or more constraints", "response": "def _add_constraints(self, relation):\n        \"\"\"Add the given relation as one or more constraints\n\n        Return a list of the names of the constraints added.\n        \"\"\"\n        expression = relation.expression\n        names = []\n        for value_set in expression.value_sets():\n            values = ((self._variables[variable], value)\n                      for variable, value in value_set)\n            constr_name = next(self._constr_names)\n            sense = self.CONSTR_SENSE_MAP[relation.sense]\n            self._p.add_linear_constraint(\n                sense=sense, values=values, rhs=-expression.offset,\n                name=constr_name)\n            names.append(constr_name)\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_objective(self, expression):\n\n        if isinstance(expression, numbers.Number):\n            # Allow expressions with no variables as objective,\n            # represented as a number\n            expression = Expression()\n\n        self._p.set_linear_objective(\n            (lp_name, expression.value(var))\n            for var, lp_name in iteritems(self._variables))", "response": "Set linear objective of problem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset type of problem (maximize or minimize)", "response": "def set_objective_sense(self, sense):\n        \"\"\"Set type of problem (maximize or minimize)\"\"\"\n        if sense == ObjectiveSense.Minimize:\n            self._p.set_objective_sense(qsoptex.ObjectiveSense.MINIMIZE)\n        elif sense == ObjectiveSense.Maximize:\n            self._p.set_objective_sense(qsoptex.ObjectiveSense.MAXIMIZE)\n        else:\n            raise ValueError('Invalid objective sense')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsolves problem and return result.", "response": "def solve_unchecked(self, sense=None):\n        \"\"\"Solve problem and return result.\n\n        The user must manually check the status of the result to determine\n        whether an optimal solution was found. A :class:`SolverError` may still\n        be raised if the underlying solver raises an exception.\n        \"\"\"\n        if sense is not None:\n            self.set_objective_sense(sense)\n        self._p.solve()\n\n        self._result = Result(self)\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef success(self):\n        self._check_valid()\n        return self._problem._p.get_status() == qsoptex.SolutionStatus.OPTIMAL", "response": "Return whether a solution was found"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unbounded(self):\n        self._check_valid()\n        return (self._problem._p.get_status() ==\n                qsoptex.SolutionStatus.UNBOUNDED)", "response": "Whether the solution is unbounded"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns value of variable in solution.", "response": "def _get_value(self, var):\n        \"\"\"Return value of variable in solution.\"\"\"\n        return self._problem._p.get_value(self._problem._variables[var])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a librsync job.", "response": "def _execute(job, f, o=None):\n    \"\"\"\n    Executes a librsync \"job\" by reading bytes from `f` and writing results to\n    `o` if provided. If `o` is omitted, the output is ignored.\n    \"\"\"\n    # Re-use the same buffer for output, we will read from it after each\n    # iteration.\n    out = ctypes.create_string_buffer(RS_JOB_BLOCKSIZE)\n    while True:\n        block = f.read(RS_JOB_BLOCKSIZE)\n        buff = Buffer()\n        # provide the data block via input buffer.\n        buff.next_in = ctypes.c_char_p(block)\n        buff.avail_in = ctypes.c_size_t(len(block))\n        buff.eof_in = ctypes.c_int(not block)\n        # Set up our buffer for output.\n        buff.next_out = ctypes.cast(out, ctypes.c_char_p)\n        buff.avail_out = ctypes.c_size_t(RS_JOB_BLOCKSIZE)\n        r = _librsync.rs_job_iter(job, ctypes.byref(buff))\n        if o:\n            o.write(out.raw[:RS_JOB_BLOCKSIZE - buff.avail_out])\n        if r == RS_DONE:\n            break\n        elif r != RS_BLOCKED:\n            raise LibrsyncError(r)\n        if buff.avail_in > 0:\n            # There is data left in the input buffer, librsync did not consume\n            # all of it. Rewind the file a bit so we include that data in our\n            # next read. It would be better to simply tack data to the end of\n            # this buffer, but that is very difficult in Python.\n            f.seek(f.tell() - buff.avail_in)\n    if o and callable(getattr(o, 'seek', None)):\n        # As a matter of convenience, rewind the output file.\n        o.seek(0)\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef signature(f, s=None, block_size=RS_DEFAULT_BLOCK_LEN):\n    if s is None:\n        s = tempfile.SpooledTemporaryFile(max_size=MAX_SPOOL, mode='wb+')\n    job = _librsync.rs_sig_begin(block_size, RS_DEFAULT_STRONG_LEN)\n    try:\n        _execute(job, f, s)\n    finally:\n        _librsync.rs_job_free(job)\n    return s", "response": "Generate a signature for the file f."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a delta file for the file f using the signature read from s.", "response": "def delta(f, s, d=None):\n    \"\"\"\n    Create a delta for the file `f` using the signature read from `s`. The delta\n    will be written to `d`. If `d` is omitted, a temporary file will be used.\n    This function returns the delta file `d`. All parameters must be file-like\n    objects.\n    \"\"\"\n    if d is None:\n        d = tempfile.SpooledTemporaryFile(max_size=MAX_SPOOL, mode='wb+')\n    sig = ctypes.c_void_p()\n    try:\n        job = _librsync.rs_loadsig_begin(ctypes.byref(sig))\n        try:\n            _execute(job, s)\n        finally:\n            _librsync.rs_job_free(job)\n        r = _librsync.rs_build_hash_table(sig)\n        if r != RS_DONE:\n            raise LibrsyncError(r)\n        job = _librsync.rs_delta_begin(sig)\n        try:\n            _execute(job, f, d)\n        finally:\n            _librsync.rs_job_free(job)\n    finally:\n        _librsync.rs_free_sumset(sig)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npatches the file f using the delta d.", "response": "def patch(f, d, o=None):\n    \"\"\"\n    Patch the file `f` using the delta `d`. The patched file will be written to\n    `o`. If `o` is omitted, a temporary file will be used. This function returns\n    the be patched file `o`. All parameters should be file-like objects. `f` is\n    required to be seekable.\n    \"\"\"\n    if o is None:\n        o = tempfile.SpooledTemporaryFile(max_size=MAX_SPOOL, mode='wb+')\n\n    @patch_callback\n    def read_cb(opaque, pos, length, buff):\n        f.seek(pos)\n        size_p = ctypes.cast(length, ctypes.POINTER(ctypes.c_size_t)).contents\n        size = size_p.value\n        block = f.read(size)\n        size_p.value = len(block)\n        buff_p = ctypes.cast(buff, ctypes.POINTER(ctypes.c_char_p)).contents\n        buff_p.value = block\n        return RS_DONE\n\n    job = _librsync.rs_patch_begin(read_cb, None)\n    try:\n        _execute(job, d, o)\n    finally:\n        _librsync.rs_job_free(job)\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind appropriate integer tolerance for gap - filling problems.", "response": "def _find_integer_tolerance(epsilon, v_max, min_tol):\n    \"\"\"Find appropriate integer tolerance for gap-filling problems.\"\"\"\n    int_tol = min(epsilon / (10 * v_max), 0.1)\n    min_tol = max(1e-10, min_tol)\n    if int_tol < min_tol:\n        eps_lower = min_tol * 10 * v_max\n        logger.warning(\n            'When the maximum flux is {}, it is recommended that'\n            ' epsilon > {} to avoid numerical issues with this'\n            ' solver. Results may be incorrect with'\n            ' the current settings!'.format(v_max, eps_lower))\n        return min_tol\n\n    return int_tol"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gapfind(model, solver, epsilon=0.001, v_max=1000, implicit_sinks=True):\n    prob = solver.create_problem()\n\n    # Set integrality tolerance such that w constraints are correct\n    min_tol = prob.integrality_tolerance.min\n    int_tol = _find_integer_tolerance(epsilon, v_max, min_tol)\n    if int_tol < prob.integrality_tolerance.value:\n        prob.integrality_tolerance.value = int_tol\n\n    # Define flux variables\n    v = prob.namespace()\n    for reaction_id in model.reactions:\n        lower, upper = model.limits[reaction_id]\n        v.define([reaction_id], lower=lower, upper=upper)\n\n    # Define constraints on production of metabolites in reaction\n    w = prob.namespace(types=lp.VariableType.Binary)\n    binary_cons_lhs = {compound: 0 for compound in model.compounds}\n    for spec, value in iteritems(model.matrix):\n        compound, reaction_id = spec\n        if value != 0:\n            w.define([spec])\n            w_var = w(spec)\n\n            lower, upper = (float(x) for x in model.limits[reaction_id])\n            if value > 0:\n                dv = v(reaction_id)\n            else:\n                dv = -v(reaction_id)\n                lower, upper = -upper, -lower\n\n            prob.add_linear_constraints(\n                dv <= upper * w_var,\n                dv >= epsilon + (lower - epsilon) * (1 - w_var))\n\n            binary_cons_lhs[compound] += w_var\n\n    xp = prob.namespace(model.compounds, types=lp.VariableType.Binary)\n    objective = xp.sum(model.compounds)\n    prob.set_objective(objective)\n\n    for compound, lhs in iteritems(binary_cons_lhs):\n        prob.add_linear_constraints(lhs >= xp(compound))\n\n    # Define mass balance constraints\n    massbalance_lhs = {compound: 0 for compound in model.compounds}\n    for spec, value in iteritems(model.matrix):\n        compound, reaction_id = spec\n        massbalance_lhs[compound] += v(reaction_id) * value\n    for compound, lhs in iteritems(massbalance_lhs):\n        if implicit_sinks:\n            # The constraint is merely >0 meaning that we have implicit sinks\n            # for all compounds.\n            prob.add_linear_constraints(lhs >= 0)\n        else:\n            prob.add_linear_constraints(lhs == 0)\n\n    # Solve\n    try:\n        result = prob.solve(lp.ObjectiveSense.Maximize)\n    except lp.SolverError as e:\n        raise_from(GapFillError('Failed to solve gapfill: {}'.format(e), e))\n\n    for compound in model.compounds:\n        if result.get_value(xp(compound)) < 0.5:\n            yield compound", "response": "Returns a generator that yields all compounds that cannot be produced by the given model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a set of reactions to add such that no compounds are blocked. Returns two iterators: first an iterator of reactions not in core, that were added to resolve the model. Second, an iterator of reactions in core that had flux bounds expanded (i.e. irreversible reactions become reversible). Similarly to GapFind, this method assumes, by default, implicit sinks for all compounds in the model so the only factor that influences whether a compound can be produced is the presence of the compounds needed to produce it. This means that the resulting model will not necessarily be flux consistent. This method is implemented as a MILP-program. Therefore it may not be efficient for larger models. Args: model: :class:`MetabolicModel` containing core reactions and reactions that can be added for gap-filling. core: The set of core (already present) reactions in the model. blocked: The compounds to unblock. exclude: Set of reactions in core to be excluded from gap-filling (e.g. biomass reaction). solver: MILP solver instance. epsilon: Threshold amount of a compound produced for it to not be considered blocked. v_max: Maximum flux. weights: Dictionary of weights for reactions. Weight is the penalty score for adding the reaction (non-core reactions) or expanding the flux bounds (all reactions). implicit_sinks: Whether implicit sinks for all compounds are included when gap-filling (traditional GapFill uses implicit sinks). allow_bounds_expansion: Allow flux bounds to be expanded at the cost of a penalty which can be specified using weights (traditional GapFill does not allow this). This includes turning irreversible reactions reversible.", "response": "def gapfill(\n        model, core, blocked, exclude, solver, epsilon=0.001, v_max=1000,\n        weights={}, implicit_sinks=True, allow_bounds_expansion=False):\n    \"\"\"Find a set of reactions to add such that no compounds are blocked.\n\n    Returns two iterators: first an iterator of reactions not in\n    core, that were added to resolve the model. Second, an\n    iterator of reactions in core that had flux bounds expanded (i.e.\n    irreversible reactions become reversible). Similarly to\n    GapFind, this method assumes, by default, implicit sinks for all compounds\n    in the model so the only factor that influences whether a compound\n    can be produced is the presence of the compounds needed to produce\n    it. This means that the resulting model will not necessarily be\n    flux consistent.\n\n    This method is implemented as a MILP-program. Therefore it may\n    not be efficient for larger models.\n\n    Args:\n        model: :class:`MetabolicModel` containing core reactions and reactions\n            that can be added for gap-filling.\n        core: The set of core (already present) reactions in the model.\n        blocked: The compounds to unblock.\n        exclude: Set of reactions in core to be excluded from gap-filling (e.g.\n            biomass reaction).\n        solver: MILP solver instance.\n        epsilon: Threshold amount of a compound produced for it to not be\n            considered blocked.\n        v_max: Maximum flux.\n        weights: Dictionary of weights for reactions. Weight is the penalty\n            score for adding the reaction (non-core reactions) or expanding the\n            flux bounds (all reactions).\n        implicit_sinks: Whether implicit sinks for all compounds are included\n            when gap-filling (traditional GapFill uses implicit sinks).\n        allow_bounds_expansion: Allow flux bounds to be expanded at the cost\n            of a penalty which can be specified using weights (traditional\n            GapFill does not allow this). This includes turning irreversible\n            reactions reversible.\n    \"\"\"\n    prob = solver.create_problem()\n\n    # Set integrality tolerance such that w constraints are correct\n    min_tol = prob.integrality_tolerance.min\n    int_tol = _find_integer_tolerance(epsilon, v_max, min_tol)\n    if int_tol < prob.integrality_tolerance.value:\n        prob.integrality_tolerance.value = int_tol\n\n    # Define flux variables\n    v = prob.namespace(model.reactions, lower=-v_max, upper=v_max)\n\n    # Add binary indicator variables\n    database_reactions = set(model.reactions).difference(core, exclude)\n    ym = prob.namespace(model.reactions, types=lp.VariableType.Binary)\n    yd = prob.namespace(database_reactions, types=lp.VariableType.Binary)\n\n    objective = ym.expr(\n        (rxnid, weights.get(rxnid, 1)) for rxnid in model.reactions)\n    objective += yd.expr(\n        (rxnid, weights.get(rxnid, 1)) for rxnid in database_reactions)\n    prob.set_objective(objective)\n\n    # Add constraints on all reactions\n    for reaction_id in model.reactions:\n        lower, upper = (float(x) for x in model.limits[reaction_id])\n\n        if reaction_id in exclude or not allow_bounds_expansion:\n            prob.add_linear_constraints(\n                upper >= v(reaction_id), v(reaction_id) >= lower)\n        else:\n            # Allow flux bounds to expand up to v_max with penalty\n            delta_lower = min(0, -v_max - lower)\n            delta_upper = max(0, v_max - upper)\n            prob.add_linear_constraints(\n                v(reaction_id) >= lower + ym(reaction_id) * delta_lower,\n                v(reaction_id) <= upper + ym(reaction_id) * delta_upper)\n\n    # Add constraints on database reactions\n    for reaction_id in database_reactions:\n        lower, upper = model.limits[reaction_id]\n        prob.add_linear_constraints(\n            v(reaction_id) >= yd(reaction_id) * -v_max,\n            v(reaction_id) <= yd(reaction_id) * v_max)\n\n    # Define constraints on production of blocked metabolites in reaction\n    w = prob.namespace(types=lp.VariableType.Binary)\n    binary_cons_lhs = {compound: 0 for compound in blocked}\n    for (compound, reaction_id), value in iteritems(model.matrix):\n        if reaction_id not in exclude and compound in blocked and value != 0:\n            w.define([(compound, reaction_id)])\n            w_var = w((compound, reaction_id))\n\n            dv = v(reaction_id) if value > 0 else -v(reaction_id)\n            prob.add_linear_constraints(\n                dv <= v_max * w_var,\n                dv >= epsilon + (-v_max - epsilon) * (1 - w_var))\n\n            binary_cons_lhs[compound] += w_var\n\n    for compound, lhs in iteritems(binary_cons_lhs):\n        prob.add_linear_constraints(lhs >= 1)\n\n    # Define mass balance constraints\n    massbalance_lhs = {compound: 0 for compound in model.compounds}\n    for (compound, reaction_id), value in iteritems(model.matrix):\n        if reaction_id not in exclude:\n            massbalance_lhs[compound] += v(reaction_id) * value\n    for compound, lhs in iteritems(massbalance_lhs):\n        if implicit_sinks:\n            # The constraint is merely >0 meaning that we have implicit sinks\n            # for all compounds.\n            prob.add_linear_constraints(lhs >= 0)\n        else:\n            prob.add_linear_constraints(lhs == 0)\n\n    # Solve\n    try:\n        prob.solve(lp.ObjectiveSense.Minimize)\n    except lp.SolverError as e:\n        raise_from(GapFillError('Failed to solve gapfill: {}'.format(e)), e)\n\n    def added_iter():\n        for reaction_id in database_reactions:\n            if yd.value(reaction_id) > 0.5:\n                yield reaction_id\n\n    def no_bounds_iter():\n        for reaction_id in model.reactions:\n            if ym.value(reaction_id) > 0.5:\n                yield reaction_id\n\n    return added_iter(), no_bounds_iter()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef float_constructor(loader, node):\n    s = loader.construct_scalar(node)\n    if s == '.inf':\n        return Decimal('Infinity')\n    elif s == '-.inf':\n        return -Decimal('Infinity')\n    elif s == '.nan':\n        return Decimal('NaN')\n    return Decimal(s)", "response": "Construct Decimal from YAML float encoding."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef yaml_load(stream):\n    # Surprisingly, the CSafeLoader does not seem to be used by default.\n    # Check whether the CSafeLoader is available and provide a log message\n    # if it is not available.\n    global _HAS_YAML_LIBRARY\n\n    if _HAS_YAML_LIBRARY is None:\n        _HAS_YAML_LIBRARY = hasattr(yaml, 'CSafeLoader')\n        if not _HAS_YAML_LIBRARY:\n            logger.warning('libyaml was not found! Please install libyaml to'\n                           ' speed up loading the model files.')\n\n    if _HAS_YAML_LIBRARY:\n        loader = yaml.CSafeLoader(stream)\n    else:\n        loader = yaml.SafeLoader(stream)\n    loader.add_constructor('tag:yaml.org,2002:float', float_constructor)\n    return loader.get_data()", "response": "Load YAML file using safe loader."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_id(entity, entity_type):\n\n    if entity is None:\n        raise ParseError('{} ID missing'.format(entity_type))\n    elif not isinstance(entity, string_types):\n        msg = '{} ID must be a string, id was {}.'.format(entity_type, entity)\n        if isinstance(entity, bool):\n            msg += (' You may have accidentally used an ID value that YAML'\n                    ' interprets as a boolean, such as \"yes\", \"no\", \"on\",'\n                    ' \"off\", \"true\" or \"false\". To use this ID, you have to'\n                    ' quote it with single or double quotes')\n        raise ParseError(msg)\n    elif len(entity) == 0:\n        raise ParseError('{} ID must not be empty'.format(entity_type))", "response": "Checks whether the ID is valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_compound(compound_def, context=None):\n\n    compound_id = compound_def.get('id')\n    _check_id(compound_id, 'Compound')\n\n    mark = FileMark(context, None, None)\n    return CompoundEntry(compound_def, mark)", "response": "Parse a structured compound definition as obtained from a YAML file\n\n    Returns a CompoundEntry object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a structured list of compounds as obtained from a YAML file and yield CompoundEntries.", "response": "def parse_compound_list(path, compounds):\n    \"\"\"Parse a structured list of compounds as obtained from a YAML file\n\n    Yields CompoundEntries. Path can be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for compound_def in compounds:\n        if 'include' in compound_def:\n            file_format = compound_def.get('format')\n            include_context = context.resolve(compound_def['include'])\n            for compound in parse_compound_file(include_context, file_format):\n                yield compound\n        else:\n            yield parse_compound(compound_def, context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a tab - separated file containing compound IDs and properties.", "response": "def parse_compound_table_file(path, f):\n    \"\"\"Parse a tab-separated file containing compound IDs and properties\n\n    The compound properties are parsed according to the header which specifies\n    which property is contained in each column.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for i, row in enumerate(csv.DictReader(f, delimiter=str('\\t'))):\n        if 'id' not in row or row['id'].strip() == '':\n            raise ParseError('Expected `id` column in table')\n\n        props = {key: value for key, value in iteritems(row) if value != ''}\n\n        if 'charge' in props:\n            props['charge'] = int(props['charge'])\n\n        mark = FileMark(context, i + 2, None)\n        yield CompoundEntry(props, mark)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve the format of a file based on the path.", "response": "def resolve_format(format, path):\n    \"\"\"Looks at a file's extension and format (if any) and returns format.\n    \"\"\"\n    if format is None:\n        if (re.match(r'.+\\.(yml|yaml)$', path)):\n            return 'yaml'\n        elif (re.match(r'.+\\.tsv$', path)):\n            return 'tsv'\n    else:\n        return format.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening and parse reaction file based on file extension or given format", "response": "def parse_compound_file(path, format):\n    \"\"\"Open and parse reaction file based on file extension or given format\n\n    Path can be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    # YAML files do not need to explicitly specify format\n    format = resolve_format(format, context.filepath)\n    if format == 'yaml':\n        logger.debug('Parsing compound file {} as YAML'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for compound in parse_compound_yaml_file(context, f):\n                yield compound\n    elif format == 'modelseed':\n        logger.debug('Parsing compound file {} as ModelSEED TSV'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for compound in modelseed.parse_compound_file(f, context):\n                yield compound\n    elif format == 'tsv':\n        logger.debug('Parsing compound file {} as TSV'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for compound in parse_compound_table_file(context, f):\n                yield compound\n    else:\n        raise ParseError('Unable to detect format of compound file {}'.format(\n            context.filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_reaction_equation_string(equation, default_compartment):\n    def _translate_compartments(reaction, compartment):\n        \"\"\"Translate compound with missing compartments.\n\n        These compounds will have the specified compartment in the output.\n        \"\"\"\n        left = (((c.in_compartment(compartment), v)\n                 if c.compartment is None else (c, v))\n                for c, v in reaction.left)\n        right = (((c.in_compartment(compartment), v)\n                  if c.compartment is None else (c, v))\n                 for c, v in reaction.right)\n        return Reaction(reaction.direction, left, right)\n\n    eq = _REACTION_PARSER.parse(equation).normalized()\n    return _translate_compartments(eq, default_compartment)", "response": "Parses a string representation of a reaction equation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_reaction_equation(equation_def, default_compartment):\n\n    def parse_compound_list(l, compartment):\n        \"\"\"Parse a list of reactants or metabolites\"\"\"\n        for compound_def in l:\n            compound_id = compound_def.get('id')\n            _check_id(compound_id, 'Compound')\n\n            value = compound_def.get('value')\n            if value is None:\n                raise ParseError('Missing value for compound {}'.format(\n                    compound_id))\n\n            compound_compartment = compound_def.get('compartment')\n            if compound_compartment is None:\n                compound_compartment = compartment\n\n            compound = Compound(compound_id, compartment=compound_compartment)\n            yield compound, value\n\n    if isinstance(equation_def, string_types):\n        return parse_reaction_equation_string(\n            equation_def, default_compartment)\n    else:\n        compartment = equation_def.get('compartment', default_compartment)\n        reversible = bool(equation_def.get('reversible', True))\n        left = equation_def.get('left', [])\n        right = equation_def.get('right', [])\n        if len(left) == 0 and len(right) == 0:\n            raise ParseError('Reaction values are missing')\n\n        return Reaction(Direction.Both if reversible else Direction.Forward,\n                        parse_compound_list(left, compartment),\n                        parse_compound_list(right, compartment))", "response": "Parse a structured reaction equation as obtained from a YAML file containing a list of reactants or metabolites."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a structured reaction definition as obtained from a YAML file Returns a ReactionEntry object", "response": "def parse_reaction(reaction_def, default_compartment, context=None):\n    \"\"\"Parse a structured reaction definition as obtained from a YAML file\n\n    Returns a ReactionEntry.\n    \"\"\"\n\n    reaction_id = reaction_def.get('id')\n    _check_id(reaction_id, 'Reaction')\n\n    reaction_props = dict(reaction_def)\n\n    # Parse reaction equation\n    if 'equation' in reaction_def:\n        reaction_props['equation'] = parse_reaction_equation(\n            reaction_def['equation'], default_compartment)\n\n    mark = FileMark(context, None, None)\n    return ReactionEntry(reaction_props, mark)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a structured list of reactions as obtained from a YAML file.", "response": "def parse_reaction_list(path, reactions, default_compartment=None):\n    \"\"\"Parse a structured list of reactions as obtained from a YAML file\n\n    Yields tuples of reaction ID and reaction object. Path can be given as a\n    string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for reaction_def in reactions:\n        if 'include' in reaction_def:\n            include_context = context.resolve(reaction_def['include'])\n            for reaction in parse_reaction_file(\n                    include_context, default_compartment):\n                yield reaction\n        else:\n            yield parse_reaction(reaction_def, default_compartment, context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a tab - separated file containing reaction IDs and properties.", "response": "def parse_reaction_table_file(path, f, default_compartment):\n    \"\"\"Parse a tab-separated file containing reaction IDs and properties\n\n    The reaction properties are parsed according to the header which specifies\n    which property is contained in each column.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for lineno, row in enumerate(csv.DictReader(f, delimiter=str('\\t'))):\n        if 'id' not in row or row['id'].strip() == '':\n            raise ParseError('Expected `id` column in table')\n\n        props = {key: value for key, value in iteritems(row) if value != ''}\n\n        if 'equation' in props:\n            props['equation'] = parse_reaction_equation_string(\n                props['equation'], default_compartment)\n\n        mark = FileMark(context, lineno + 2, 0)\n        yield ReactionEntry(props, mark)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening and parse reaction file based on file extension", "response": "def parse_reaction_file(path, default_compartment=None):\n    \"\"\"Open and parse reaction file based on file extension\n\n    Path can be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    format = resolve_format(None, context.filepath)\n    if format == 'tsv':\n        logger.debug('Parsing reaction file {} as TSV'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for reaction in parse_reaction_table_file(\n                    context, f, default_compartment):\n                yield reaction\n    elif format == 'yaml':\n        logger.debug('Parsing reaction file {} as YAML'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for reaction in parse_reaction_yaml_file(\n                    context, f, default_compartment):\n                yield reaction\n    else:\n        raise ParseError('Unable to detect format of reaction file {}'.format(\n            context.filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_exchange(exchange_def, default_compartment):\n\n    default_compartment = exchange_def.get('compartment', default_compartment)\n\n    for compound_def in exchange_def.get('compounds', []):\n        compartment = compound_def.get('compartment', default_compartment)\n        compound = Compound(compound_def['id'], compartment=compartment)\n        reaction = compound_def.get('reaction')\n        lower, upper = get_limits(compound_def)\n        yield compound, reaction, lower, upper", "response": "Parse a structured exchange definition as obtained from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a structured exchange list as obtained from a YAML file.", "response": "def parse_exchange_list(path, exchange, default_compartment):\n    \"\"\"Parse a structured exchange list as obtained from a YAML file.\n\n    Yields tuples of compound, reaction ID, lower and upper flux bounds. Path\n    can be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for exchange_def in exchange:\n        if 'include' in exchange_def:\n            include_context = context.resolve(exchange_def['include'])\n            for exchange_compound in parse_exchange_file(\n                    include_context, default_compartment):\n                yield exchange_compound\n        else:\n            for exchange_compound in parse_exchange(\n                    exchange_def, default_compartment):\n                yield exchange_compound"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_exchange_table_file(f):\n\n    for line in f:\n        line, _, comment = line.partition('#')\n        line = line.strip()\n        if line == '':\n            continue\n\n        # A line can specify lower limit only (useful for\n        # medium compounds), or both lower and upper limit.\n        fields = line.split(None)\n        if len(fields) < 2 or len(fields) > 4:\n            raise ParseError('Malformed compound limit: {}'.format(fields))\n\n        # Extend to four values and unpack\n        fields.extend(['-']*(4-len(fields)))\n        compound_id, compartment, lower, upper = fields\n\n        compound = Compound(compound_id, compartment)\n        lower = float(lower) if lower != '-' else None\n        upper = float(upper) if upper != '-' else None\n\n        yield compound, None, lower, upper", "response": "Parse a space - separated file containing exchange compound flux limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_exchange_file(path, default_compartment):\n\n    context = FilePathContext(path)\n\n    format = resolve_format(None, context.filepath)\n    if format == 'tsv':\n        logger.debug('Parsing exchange file {} as TSV'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for entry in parse_exchange_table_file(f):\n                yield entry\n    elif format == 'yaml':\n        logger.debug('Parsing exchange file {} as YAML'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for entry in parse_exchange_yaml_file(\n                    context, f, default_compartment):\n                yield entry\n    else:\n        raise ParseError('Unable to detect format of exchange file {}'.format(\n            context.filepath))", "response": "Parse a file as a list of exchange compounds with flux limits."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_limit(limit_def):\n\n    lower, upper = get_limits(limit_def)\n    reaction = limit_def.get('reaction')\n\n    return reaction, lower, upper", "response": "Parse a structured flux limit definition as obtained from a YAML file\n    Returns a tuple of reaction lower upper bound"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_limits_list(path, limits):\n\n    context = FilePathContext(path)\n\n    for limit_def in limits:\n        if 'include' in limit_def:\n            include_context = context.resolve(limit_def['include'])\n            for limit in parse_limits_file(include_context):\n                yield limit\n        else:\n            yield parse_limit(limit_def)", "response": "Parse a structured list of flux limits as obtained from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a space - separated file containing reaction flux limits.", "response": "def parse_limits_table_file(f):\n    \"\"\"Parse a space-separated file containing reaction flux limits\n\n    The first column contains reaction IDs while the second column contains\n    the lower flux limits. The third column is optional and contains the\n    upper flux limit.\n    \"\"\"\n\n    for line in f:\n        line, _, comment = line.partition('#')\n        line = line.strip()\n        if line == '':\n            continue\n\n        # A line can specify lower limit only (useful for\n        # exchange reactions), or both lower and upper limit.\n        fields = line.split(None)\n        if len(fields) < 1 or len(fields) > 3:\n            raise ParseError('Malformed reaction limit: {}'.format(fields))\n\n        # Extend to three values and unpack\n        fields.extend(['-']*(3-len(fields)))\n        reaction_id, lower, upper = fields\n\n        lower = float(lower) if lower != '-' else None\n        upper = float(upper) if upper != '-' else None\n\n        yield reaction_id, lower, upper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a file as a list of reaction flux limits.", "response": "def parse_limits_file(path):\n    \"\"\"Parse a file as a list of reaction flux limits\n\n    The file format is detected and the file is parsed accordingly. Path can\n    be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    format = resolve_format(None, context.filepath)\n    if format == 'tsv':\n        logger.debug('Parsing limits file {} as TSV'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for limit in parse_limits_table_file(f):\n                yield limit\n    elif format == 'yaml':\n        logger.debug('Parsing limits file {} as YAML'.format(\n            context.filepath))\n        with context.open('r') as f:\n            for limit in parse_limits_yaml_file(context, f):\n                yield limit\n    else:\n        raise ParseError('Unable to detect format of limits file {}'.format(\n            context.filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a structured model group as obtained from a YAML file.", "response": "def parse_model_group(path, group):\n    \"\"\"Parse a structured model group as obtained from a YAML file\n\n    Path can be given as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    for reaction_id in group.get('reactions', []):\n        yield reaction_id\n\n    # Parse subgroups\n    for reaction_id in parse_model_group_list(\n            context, group.get('groups', [])):\n        yield reaction_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_model_group_list(path, groups):\n\n    context = FilePathContext(path)\n    for model_group in groups:\n        if 'include' in model_group:\n            include_context = context.resolve(model_group['include'])\n            for reaction_id in parse_model_file(include_context):\n                yield reaction_id\n        else:\n            for reaction_id in parse_model_group(context, model_group):\n                yield reaction_id", "response": "Parse a structured list of model groups as obtained from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a file as a list of model reactions Taxonomy Yields reactions IDs. Path can be given as a string or a context. f is a file - like object", "response": "def parse_model_table_file(path, f):\n    \"\"\"Parse a file as a list of model reactions\n\n    Yields reactions IDs. Path can be given as a string or a context.\n    \"\"\"\n\n    for line in f:\n        line, _, comment = line.partition('#')\n        line = line.strip()\n        if line == '':\n            continue\n\n        yield line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a file as a list of model reactions", "response": "def parse_model_file(path):\n    \"\"\"Parse a file as a list of model reactions\n\n    The file format is detected and the file is parsed accordinly. The file is\n    specified as a file path that will be opened for reading. Path can be given\n    as a string or a context.\n    \"\"\"\n\n    context = FilePathContext(path)\n\n    format = resolve_format(None, context.filepath)\n    if format == 'tsv':\n        logger.debug('Parsing model file {} as TSV'.format(context.filepath))\n        with context.open('r') as f:\n            for reaction_id in parse_model_table_file(context, f):\n                yield reaction_id\n    elif format == 'yaml':\n        logger.debug('Parsing model file {} as YAML'.format(context.filepath))\n        with context.open('r') as f:\n            for reaction_id in parse_model_yaml_file(context, f):\n                yield reaction_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reaction_representer(dumper, data):\n    if len(data.compounds) > _MAX_REACTION_LENGTH:\n        def dict_make(compounds):\n            for compound, value in compounds:\n                yield OrderedDict([\n                    ('id', text_type(compound.name)),\n                    ('compartment', compound.compartment),\n                    ('value', value)])\n\n        left = list(dict_make(data.left))\n        right = list(dict_make(data.right))\n\n        direction = data.direction == Direction.Both\n\n        reaction = OrderedDict()\n        reaction['reversible'] = direction\n        if data.direction == Direction.Reverse:\n            reaction['left'] = right\n            reaction['right'] = left\n        else:\n            reaction['left'] = left\n            reaction['right'] = right\n\n        return dumper.represent_data(reaction)\n    else:\n        return _represent_text_type(dumper, text_type(data))", "response": "Return a parsable reaction representation to the YAML parser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a model from a specified path.", "response": "def reader_from_path(cls, path):\n        \"\"\"Create a model from specified path.\n\n        Path can be a directory containing a ``model.yaml`` or ``model.yml``\n        file or it can be a path naming the central model file directly.\n        \"\"\"\n        context = FilePathContext(path)\n        try:\n            with open(context.filepath, 'r') as f:\n                return ModelReader(f, context)\n        except IOError:\n            # Try to open the default file\n            for filename in cls.DEFAULT_MODEL:\n                try:\n                    context = FilePathContext(\n                        os.path.join(path, filename))\n                    with open(context.filepath, 'r') as f:\n                        return ModelReader(f, context)\n                except:\n                    logger.debug('Failed to load model file',\n                                 exc_info=True)\n\n        # No model could be loaded\n        raise ParseError('No model file could be found ({})'.format(\n            ', '.join(cls.DEFAULT_MODEL)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing compartment information from model.", "response": "def parse_compartments(self):\n        \"\"\"Parse compartment information from model.\n\n        Return tuple of: 1) iterator of\n        :class:`psamm.datasource.entry.CompartmentEntry`; 2) Set of pairs\n        defining the compartment boundaries of the model.\n        \"\"\"\n\n        compartments = OrderedDict()\n        boundaries = set()\n\n        if 'compartments' in self._model:\n            boundary_map = {}\n            for compartment_def in self._model['compartments']:\n                compartment_id = compartment_def.get('id')\n                _check_id(compartment_id, 'Compartment')\n                if compartment_id in compartments:\n                    raise ParseError('Duplicate compartment ID: {}'.format(\n                        compartment_id))\n\n                props = dict(compartment_def)\n                adjacent_to = props.pop('adjacent_to', None)\n                if adjacent_to is not None:\n                    if not isinstance(adjacent_to, list):\n                        adjacent_to = [adjacent_to]\n                    for other in adjacent_to:\n                        boundary_map.setdefault(other, set()).add(\n                            compartment_id)\n\n                mark = FileMark(self._context, None, None)\n                compartment = CompartmentEntry(props, mark)\n                compartments[compartment_id] = compartment\n\n            # Check boundaries from boundary_map\n            for source, dest_set in iteritems(boundary_map):\n                if source not in compartments:\n                    raise ParseError(\n                        'Invalid compartment {} referenced'\n                        ' by compartment {}'.format(\n                            source, ', '.join(dest_set)))\n                for dest in dest_set:\n                    boundaries.add(tuple(sorted((source, dest))))\n\n        return itervalues(compartments), frozenset(boundaries)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield tuples of reaction ID and reactions defined in the model", "response": "def parse_reactions(self):\n        \"\"\"Yield tuples of reaction ID and reactions defined in the model\"\"\"\n\n        # Parse reactions defined in the main model file\n        if 'reactions' in self._model:\n            for reaction in parse_reaction_list(\n                    self._context, self._model['reactions'],\n                    self.default_compartment):\n                yield reaction"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_model(self):\n\n        if self.has_model_definition():\n            for reaction_id in parse_model_group_list(\n                    self._context, self._model['model']):\n                yield reaction_id", "response": "Yield reaction IDs of model reactions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_limits(self):\n\n        if 'limits' in self._model:\n            if not isinstance(self._model['limits'], list):\n                raise ParseError('Expected limits to be a list')\n\n            for limit in parse_limits_list(\n                    self._context, self._model['limits']):\n                yield limit", "response": "Yields tuples of reaction ID lower and upper bound flux limits"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_exchange(self):\n\n        if 'media' in self._model:\n            if 'exchange' in self._model:\n                raise ParseError('Both \"media\" and \"exchange\" are specified')\n            logger.warning(\n                'The \"media\" key is deprecated! Please use \"exchange\" instead:'\n                ' https://psamm.readthedocs.io/en/stable/file_format.html')\n            exchange_list = self._model['media']\n        else:\n            exchange_list = self._model.get('exchange')\n\n        extracellular = self.extracellular_compartment\n        if exchange_list is not None:\n            if not isinstance(exchange_list, list):\n                raise ParseError('Expected \"exchange\" to be a list')\n\n            for exchange_compound in parse_exchange_list(\n                    self._context, exchange_list, extracellular):\n                compound, reaction_id, lower, upper = exchange_compound\n                if compound.compartment is None:\n                    compound = compound.in_compartment(extracellular)\n                yield compound, reaction_id, lower, upper", "response": "Yields tuples of exchange compounds. Each exchange compound is a tuple of compound reaction ID lower and upper flux limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_compounds(self):\n\n        if 'compounds' in self._model:\n            for compound in parse_compound_list(\n                    self._context, self._model['compounds']):\n                yield compound", "response": "Yields CompoundEntries for defined compounds"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_model(self):\n\n        properties = {\n            'name': self.name,\n            'biomass': self.biomass_reaction,\n            'extracellular': self.extracellular_compartment,\n            'default_compartment': self.default_compartment,\n            'default_flux_limit': self.default_flux_limit\n        }\n\n        if self.context is not None:\n            git_version = util.git_try_describe(self.context.basepath)\n            properties['version_string'] = git_version\n\n        model = NativeModel(properties)\n\n        # Load compartments into model\n        compartment_iter, boundaries = self.parse_compartments()\n        for compartment in compartment_iter:\n            model.compartments.add_entry(compartment)\n        model.compartment_boundaries.update(boundaries)\n\n        # Load compounds into model\n        for compound in self.parse_compounds():\n            if compound.id in model.compounds:\n                existing_entry = model.compounds[compound.id]\n                common_props = set(compound.properties).intersection(\n                    existing_entry.properties).difference({'id'})\n                if len(common_props) > 0:\n                    logger.warning(\n                        'Compound entry {} at {} overrides already defined'\n                        ' properties: {}'.format(\n                            compound.id, compound.filemark, common_props))\n\n                properties = dict(compound.properties)\n                properties.update(existing_entry.properties)\n                compound = CompoundEntry(\n                    properties, filemark=compound.filemark)\n            model.compounds.add_entry(compound)\n\n        # Load reactions into model\n        for reaction in self.parse_reactions():\n            if reaction.id in model.reactions:\n                existing_entry = model.reactions[reaction.id]\n                common_props = set(reaction.properties).intersection(\n                    existing_entry.properties).difference({'id'})\n                if len(common_props) > 0:\n                    logger.warning(\n                        'Reaction entry {} at {} overrides already defined'\n                        ' properties: {}'.format(\n                            reaction.id, reaction.filemark, common_props))\n\n                properties = dict(reaction.properties)\n                properties.update(existing_entry.properties)\n                reaction = ReactionEntry(\n                    properties, filemark=reaction.filemark)\n            model.reactions.add_entry(reaction)\n\n        for exchange_def in self.parse_exchange():\n            model.exchange[exchange_def[0]] = exchange_def\n\n        for limit in self.parse_limits():\n            model.limits[limit[0]] = limit\n\n        if self.has_model_definition():\n            for model_reaction in self.parse_model():\n                model.model[model_reaction] = None\n        else:\n            for reaction in model.reactions:\n                model.model[reaction.id] = None\n\n        return model", "response": "Create a new model for this entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a metabolic model.", "response": "def create_metabolic_model(self):\n        \"\"\"Create a :class:`psamm.metabolicmodel.MetabolicModel`.\"\"\"\n\n        def _translate_compartments(reaction, compartment):\n            \"\"\"Translate compound with missing compartments.\n\n            These compounds will have the specified compartment in the output.\n            \"\"\"\n            left = (((c.in_compartment(compartment), v)\n                     if c.compartment is None else (c, v))\n                    for c, v in reaction.left)\n            right = (((c.in_compartment(compartment), v)\n                      if c.compartment is None else (c, v))\n                     for c, v in reaction.right)\n            return Reaction(reaction.direction, left, right)\n\n        # Create metabolic model\n        database = DictDatabase()\n        for reaction in self.reactions:\n            if reaction.equation is not None:\n                equation = _translate_compartments(\n                    reaction.equation, self.default_compartment)\n                database.set_reaction(reaction.id, equation)\n\n        undefined_compartments = set()\n        undefined_compounds = set()\n        extracellular_compounds = set()\n        extracellular = self.extracellular_compartment\n        for reaction in database.reactions:\n            for compound, _ in database.get_reaction_values(reaction):\n                if compound.name not in self.compounds:\n                    undefined_compounds.add(compound.name)\n                if compound.compartment == extracellular:\n                    extracellular_compounds.add(compound.name)\n                if compound.compartment not in self.compartments:\n                    undefined_compartments.add(compound.compartment)\n\n        for compartment in sorted(undefined_compartments):\n            logger.warning(\n                'The compartment {} was not defined in the list'\n                ' of compartments'.format(compartment))\n\n        for compound in sorted(undefined_compounds):\n            logger.warning(\n                'The compound {} was not defined in the list'\n                ' of compounds'.format(compound))\n\n        exchange_compounds = set()\n        for exchange_compound in self.exchange:\n            if exchange_compound.compartment == extracellular:\n                exchange_compounds.add(exchange_compound.name)\n\n        for compound in sorted(extracellular_compounds - exchange_compounds):\n            logger.warning(\n                'The compound {} was in the extracellular compartment'\n                ' but not defined in the exchange compounds'.format(compound))\n        for compound in sorted(exchange_compounds - extracellular_compounds):\n            logger.warning(\n                'The compound {} was defined in the exchange compounds but'\n                ' is not in the extracellular compartment'.format(compound))\n\n        model_definition = None\n        if len(self.model) > 0:\n            model_definition = self.model\n\n        return MetabolicModel.load_model(\n            database, model_definition, itervalues(self.exchange),\n            itervalues(self.limits), v_max=self.default_flux_limit)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_compartment_entry(self, compartment, adjacencies):\n        d = OrderedDict()\n        d['id'] = compartment.id\n        if adjacencies is not None:\n            d['adjacent_to'] = adjacencies\n\n        order = {key: i for i, key in enumerate(['name'])}\n        prop_keys = set(compartment.properties)\n        for prop in sorted(prop_keys,\n                           key=lambda x: (order.get(x, 1000), x)):\n            if compartment.properties[prop] is not None:\n                d[prop] = compartment.properties[prop]\n\n        return d", "response": "Convert a compartment entry to YAML dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_compound_entry(self, compound):\n        d = OrderedDict()\n        d['id'] = compound.id\n\n        order = {\n            key: i for i, key in enumerate(\n                ['name', 'formula', 'formula_neutral', 'charge', 'kegg',\n                 'cas'])}\n        prop_keys = (\n            set(compound.properties) - {'boundary', 'compartment'})\n        for prop in sorted(prop_keys,\n                           key=lambda x: (order.get(x, 1000), x)):\n            if compound.properties[prop] is not None:\n                d[prop] = compound.properties[prop]\n\n        return d", "response": "Convert a compound entry to YAML dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_reaction_entry(self, reaction):\n        d = OrderedDict()\n        d['id'] = reaction.id\n\n        def is_equation_valid(equation):\n            # If the equation is a Reaction object, it must have non-zero\n            # number of compounds.\n            return (equation is not None and (\n                    not isinstance(equation, Reaction) or\n                    len(equation.compounds) > 0))\n\n        order = {\n            key: i for i, key in enumerate(\n                ['name', 'genes', 'equation', 'subsystem', 'ec'])}\n        prop_keys = (set(reaction.properties) -\n                     {'lower_flux', 'upper_flux', 'reversible'})\n        for prop in sorted(prop_keys, key=lambda x: (order.get(x, 1000), x)):\n            if reaction.properties[prop] is None:\n                continue\n            d[prop] = reaction.properties[prop]\n            if prop == 'equation' and not is_equation_valid(d[prop]):\n                del d[prop]\n\n        return d", "response": "Convert reaction entry to YAML dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting iterable of entries as YAML object to stream.", "response": "def _write_entries(self, stream, entries, converter, properties=None):\n        \"\"\"Write iterable of entries as YAML object to stream.\n\n        Args:\n            stream: File-like object.\n            entries: Iterable of entries.\n            converter: Conversion function from entry to YAML object.\n            properties: Set of compartment properties to output (or None to\n                output all).\n        \"\"\"\n        def iter_entries():\n            for c in entries:\n                entry = converter(c)\n                if entry is None:\n                    continue\n                if properties is not None:\n                    entry = OrderedDict(\n                        (key, value) for key, value in iteritems(entry)\n                        if key == 'id' or key in properties)\n                yield entry\n\n        self._dump(stream, list(iter_entries()))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite iterable of compartments as YAML object to stream.", "response": "def write_compartments(self, stream, compartments, adjacencies,\n                           properties=None):\n        \"\"\"Write iterable of compartments as YAML object to stream.\n\n        Args:\n            stream: File-like object.\n            compartments: Iterable of compartment entries.\n            adjacencies: Dictionary mapping IDs to adjacent compartment IDs.\n            properties: Set of compartment properties to output (or None to\n                output all).\n        \"\"\"\n        def convert(entry):\n            return self.convert_compartment_entry(\n                entry, adjacencies.get(entry.id))\n\n        self._write_entries(stream, compartments, convert, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_compounds(self, stream, compounds, properties=None):\n        self._write_entries(\n            stream, compounds, self.convert_compound_entry, properties)", "response": "Write iterable of compounds as YAML object to stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting iterable of reactions as YAML object to stream.", "response": "def write_reactions(self, stream, reactions, properties=None):\n        \"\"\"Write iterable of reactions as YAML object to stream.\n\n        Args:\n            stream: File-like object.\n            compounds: Iterable of reaction entries.\n            properties: Set of reaction properties to output (or None to output\n                all).\n        \"\"\"\n        self._write_entries(\n            stream, reactions, self.convert_reaction_entry, properties)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_api_errorhandler(**kwargs):\n    def api_errorhandler(e):\n        if isinstance(e, RESTException):\n            return e.get_response()\n        elif isinstance(e, HTTPException) and e.description:\n            kwargs['message'] = e.description\n        if kwargs.get('status', 400) >= 500 and hasattr(g, 'sentry_event_id'):\n            kwargs['error_id'] = str(g.sentry_event_id)\n        return make_response(jsonify(kwargs), kwargs['status'])\n    return api_errorhandler", "response": "r Create an error handler that returns a REST response with the given status and message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting method serializers + default media type.", "response": "def get_method_serializers(self, http_method):\n        \"\"\"Get request method serializers + default media type.\n\n        Grab serializers from ``method_serializers`` if defined, otherwise\n        returns the default serializers. Uses GET serializers for HEAD requests\n        if no HEAD serializers were specified.\n\n        The method also determines the default media type.\n\n        :param http_method: HTTP method as a string.\n        :returns: Tuple of serializers and default media type.\n        \"\"\"\n        if http_method == 'HEAD' and 'HEAD' not in self.method_serializers:\n            http_method = 'GET'\n\n        return (\n            self.method_serializers.get(http_method, self.serializers),\n            self.default_method_media_type.get(\n                http_method, self.default_media_type)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _match_serializers_by_query_arg(self, serializers):\n        # if the format query argument is present, match the serializer\n        arg_name = current_app.config.get('REST_MIMETYPE_QUERY_ARG_NAME')\n        if arg_name:\n            arg_value = request.args.get(arg_name, None)\n\n            if arg_value is None:\n                return None\n            # Search for the serializer matching the format\n            try:\n                return serializers[\n                    self.serializers_query_aliases[arg_value]]\n            except KeyError:  # either no serializer for this format\n                return None\n\n        return None", "response": "Match serializer by query arg."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _match_serializers_by_accept_headers(self, serializers,\n                                             default_media_type):\n        \"\"\"Match serializer by `Accept` headers.\"\"\"\n        # Bail out fast if no accept headers were given.\n        if len(request.accept_mimetypes) == 0:\n            return serializers[default_media_type]\n\n        # Determine best match based on quality.\n        best_quality = -1\n        best = None\n        has_wildcard = False\n        for client_accept, quality in request.accept_mimetypes:\n            if quality <= best_quality:\n                continue\n            if client_accept == '*/*':\n                has_wildcard = True\n            for s in serializers:\n                if s in ['*/*', client_accept] and quality > 0:\n                    best_quality = quality\n                    best = s\n\n        # If no match found, but wildcard exists, them use default media\n        # type.\n        if best is None and has_wildcard:\n            best = default_media_type\n\n        if best is not None:\n            return serializers[best]\n        return None", "response": "Match serializer by Accept headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_serializers(self, serializers, default_media_type):\n        return self._match_serializers_by_query_arg(serializers) or self.\\\n            _match_serializers_by_accept_headers(serializers,\n                                                 default_media_type)", "response": "Returns a serializer for a given request based on the given serializers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_response(self, *args, **kwargs):\n        serializer = self.match_serializers(\n            *self.get_method_serializers(request.method))\n\n        if serializer:\n            return serializer(*args, **kwargs)\n        abort(406)", "response": "Create a Flask Response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispatch_request(self, *args, **kwargs):\n        result = super(ContentNegotiatedMethodView, self).dispatch_request(\n            *args, **kwargs\n        )\n\n        if isinstance(result, Response):\n            return result\n        elif isinstance(result, (list, tuple)):\n            return self.make_response(*result)\n        else:\n            return self.make_response(result)", "response": "Dispatch the current request using the current request s Accept header and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_etag(self, etag, weak=False):\n        # bool(:py:class:`werkzeug.datastructures.ETags`) is not consistent\n        # in Python 3. bool(Etags()) == True even though it is empty.\n        if len(request.if_match.as_set(include_weak=weak)) > 0 or \\\n                request.if_match.star_tag:\n            contains_etag = (request.if_match.contains_weak(etag) if weak\n                             else request.if_match.contains(etag))\n            if not contains_etag and '*' not in request.if_match:\n                abort(412)\n        if len(request.if_none_match.as_set(include_weak=weak)) > 0 or \\\n                request.if_none_match.star_tag:\n            contains_etag = (request.if_none_match.contains_weak(etag) if weak\n                             else request.if_none_match.contains(etag))\n            if contains_etag or '*' in request.if_none_match:\n                if request.method in ('GET', 'HEAD'):\n                    raise SameContentException(etag)\n                else:\n                    abort(412)", "response": "Validate the given ETag with current request conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_if_modified_since(self, dt, etag=None):\n        dt = dt.replace(microsecond=0)\n        if request.if_modified_since and dt <= request.if_modified_since:\n            raise SameContentException(etag, last_modified=dt)", "response": "Validate If - Modified - Since with current request conditions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning what the default compartment should be set to.", "response": "def get_default_compartment(model):\n    \"\"\"Return what the default compartment should be set to.\n\n    If some compounds have no compartment, unique compartment\n    name is returned to avoid collisions.\n    \"\"\"\n    default_compartment = 'c'\n    default_key = set()\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        for compound, _ in equation.compounds:\n            default_key.add(compound.compartment)\n\n    if None in default_key and default_compartment in default_key:\n        suffix = 1\n        while True:\n            new_key = '{}_{}'.format(default_compartment, suffix)\n            if new_key not in default_key:\n                default_compartment = new_key\n                break\n            suffix += 1\n\n    if None in default_key:\n        logger.warning(\n            'Compound(s) found without compartment, default'\n            ' compartment is set to {}.'.format(default_compartment))\n    return default_compartment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_best_flux_limit(model):\n    flux_limit_count = Counter()\n\n    for reaction in model.reactions:\n        if reaction.id not in model.limits:\n            continue\n\n        equation = reaction.properties['equation']\n        if equation is None:\n            continue\n\n        _, lower, upper = model.limits[reaction.id]\n        if upper is not None and upper > 0 and equation.direction.forward:\n            flux_limit_count[upper] += 1\n        if lower is not None and -lower > 0 and equation.direction.reverse:\n            flux_limit_count[-lower] += 1\n\n    if len(flux_limit_count) == 0:\n        return None\n\n    best_flux_limit, _ = flux_limit_count.most_common(1)[0]\n    return best_flux_limit", "response": "Detect the best default flux limit to use for model output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns the reactions into their own files.", "response": "def reactions_to_files(model, dest, writer, split_subsystem):\n    \"\"\"Turn the reaction subsystems into their own files.\n\n    If a subsystem has a number of reactions over the threshold, it gets its\n    own YAML file. All other reactions, those that don't have a subsystem or\n    are in a subsystem that falls below the threshold, get added to a common\n    reaction file.\n\n    Args:\n        model: :class:`psamm_import.model.MetabolicModel`.\n        dest: output path for model files.\n        writer: :class:`psamm.datasource.native.ModelWriter`.\n        split_subsystem: Divide reactions into multiple files by subsystem.\n    \"\"\"\n    def safe_file_name(origin_name):\n        safe_name = re.sub(\n            r'\\W+', '_', origin_name, flags=re.UNICODE)\n        safe_name = re.sub(\n            r'_+', '_', safe_name.lower(), flags=re.UNICODE)\n        safe_name = safe_name.strip('_')\n        return safe_name\n\n    common_reactions = []\n    reaction_files = []\n    if not split_subsystem:\n        common_reactions = sorted(model.reactions, key=lambda r: r.id)\n        if len(common_reactions) > 0:\n            reaction_file = 'reactions.yaml'\n            with open(os.path.join(dest, reaction_file), 'w') as f:\n                writer.write_reactions(f, common_reactions)\n            reaction_files.append(reaction_file)\n    else:\n        subsystems = {}\n        for reaction in sorted(model.reactions, key=lambda r: r.id):\n            if 'subsystem' in reaction.properties:\n                subsystem_file = safe_file_name(\n                    reaction.properties['subsystem'])\n                subsystems.setdefault(subsystem_file, []).append(reaction)\n            else:\n                common_reactions.append(reaction)\n\n        subsystem_folder = 'reactions'\n        sub_existance = False\n        for subsystem_file, reactions in iteritems(subsystems):\n            if len(reactions) < _MAX_REACTION_COUNT:\n                for reaction in reactions:\n                    common_reactions.append(reaction)\n            else:\n                if len(reactions) > 0:\n                    mkdir_p(os.path.join(dest, subsystem_folder))\n                    subsystem_file = os.path.join(\n                        subsystem_folder, '{}.yaml'.format(subsystem_file))\n\n                    with open(os.path.join(dest, subsystem_file), 'w') as f:\n                        writer.write_reactions(f, reactions)\n                    reaction_files.append(subsystem_file)\n                    sub_existance = True\n\n        reaction_files.sort()\n        if sub_existance:\n            reaction_file = os.path.join(\n                subsystem_folder, 'other_reactions.yaml')\n        else:\n            reaction_file = 'reactions.yaml'\n        if len(common_reactions) > 0:\n            with open(os.path.join(dest, reaction_file), 'w') as f:\n                writer.write_reactions(f, common_reactions)\n            reaction_files.append(reaction_file)\n\n    return reaction_files"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield key value pairs for limits dictionary.", "response": "def _generate_limit_items(lower, upper):\n    \"\"\"Yield key, value pairs for limits dictionary.\n\n    Yield pairs of key, value where key is ``lower``, ``upper`` or ``fixed``.\n    A key, value pair is emitted if the bounds are not None.\n    \"\"\"\n    # Use value + 0 to convert any -0.0 to 0.0 which looks better.\n    if lower is not None and upper is not None and lower == upper:\n        yield 'fixed', upper + 0\n    else:\n        if lower is not None:\n            yield 'lower', lower + 0\n        if upper is not None:\n            yield 'upper', upper + 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef model_exchange(model):\n    # Determine the default flux limits. If the value is already at the\n    # default it does not need to be included in the output.\n    lower_default, upper_default = None, None\n    if model.default_flux_limit is not None:\n        lower_default = -model.default_flux_limit\n        upper_default = model.default_flux_limit\n\n    compounds = []\n    for compound, reaction_id, lower, upper in sorted(\n            itervalues(model.exchange)):\n        d = OrderedDict([('id', compound.name)])\n        if reaction_id is not None:\n            d['reaction'] = reaction_id\n\n        lower = _get_output_limit(lower, lower_default)\n        upper = _get_output_limit(upper, upper_default)\n        d.update(_generate_limit_items(lower, upper))\n\n        compounds.append(d)\n\n    return OrderedDict([('compounds', compounds)])", "response": "Return exchange definition as YAML dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding reaction limits as YAML dicts.", "response": "def model_reaction_limits(model):\n    \"\"\"Yield model reaction limits as YAML dicts.\"\"\"\n    for reaction in sorted(model.reactions, key=lambda r: r.id):\n        equation = reaction.properties.get('equation')\n        if equation is None:\n            continue\n\n        # Determine the default flux limits. If the value is already at the\n        # default it does not need to be included in the output.\n        lower_default, upper_default = None, None\n        if model.default_flux_limit is not None:\n            if equation.direction.reverse:\n                lower_default = -model.default_flux_limit\n            else:\n                lower_default = 0.0\n\n            if equation.direction.forward:\n                upper_default = model.default_flux_limit\n            else:\n                upper_default = 0.0\n\n        lower_flux, upper_flux = None, None\n        if reaction.id in model.limits:\n            _, lower, upper = model.limits[reaction.id]\n            lower_flux = _get_output_limit(lower, lower_default)\n            upper_flux = _get_output_limit(upper, upper_default)\n\n        if lower_flux is not None or upper_flux is not None:\n            d = OrderedDict([('reaction', reaction.id)])\n            d.update(_generate_limit_items(lower_flux, upper_flux))\n\n            yield d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef infer_compartment_entries(model):\n    compartment_ids = set()\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        for compound, _ in equation.compounds:\n            compartment = compound.compartment\n            if compartment is None:\n                compartment = model.default_compartment\n\n            if compartment is not None:\n                compartment_ids.add(compartment)\n\n    for compartment in compartment_ids:\n        if compartment in model.compartments:\n            continue\n\n        entry = DictCompartmentEntry(dict(id=compartment))\n        model.compartments.add_entry(entry)", "response": "Infer compartment entries for model based on reaction compounds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninfer compartment adjacency for model based on reactions.", "response": "def infer_compartment_adjacency(model):\n    \"\"\"Infer compartment adjacency for model based on reactions.\"\"\"\n    def reaction_compartments(seq):\n        for compound, _ in seq:\n            compartment = compound.compartment\n            if compartment is None:\n                compartment = model.default_compartment\n\n            if compartment is not None:\n                yield compartment\n\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        left = reaction_compartments(equation.left)\n        right = reaction_compartments(equation.right)\n        for c1, c2 in product(left, right):\n            if c1 == c2:\n                continue\n            model.compartment_boundaries.add((c1, c2))\n            model.compartment_boundaries.add((c2, c1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncount the number of distinct genes in model reactions.", "response": "def count_genes(model):\n    \"\"\"Count the number of distinct genes in model reactions.\"\"\"\n    genes = set()\n    for reaction in model.reactions:\n        if reaction.genes is None:\n            continue\n\n        if isinstance(reaction.genes, boolean.Expression):\n            genes.update(v.symbol for v in reaction.genes.variables)\n        else:\n            genes.update(reaction.genes)\n\n    return len(genes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the given MetabolicModel to YAML files in dest folder.", "response": "def write_yaml_model(model, dest='.', convert_exchange=True,\n                     split_subsystem=True):\n    \"\"\"Write the given MetabolicModel to YAML files in dest folder.\n\n    The parameter ``convert_exchange`` indicates whether the exchange reactions\n    should be converted automatically to an exchange file.\n    \"\"\"\n    yaml.SafeDumper.add_representer(OrderedDict, _dict_representer)\n    yaml.SafeDumper.add_representer(set, _set_representer)\n    yaml.SafeDumper.add_representer(frozenset, _set_representer)\n    yaml.SafeDumper.add_representer(\n        boolean.Expression, _boolean_expression_representer)\n    yaml.SafeDumper.add_representer(Decimal, _decimal_representer)\n\n    yaml.SafeDumper.ignore_aliases = lambda *args: True\n\n    yaml.add_constructor(yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,\n                         _dict_constructor)\n\n    yaml_args = {'default_flow_style': False,\n                 'encoding': 'utf-8',\n                 'allow_unicode': True,\n                 'width': 79}\n\n    # The ModelWriter from PSAMM is not yet able to write the full model but\n    # only reactions and compounds.\n    writer = ModelWriter()\n\n    with open(os.path.join(dest, 'compounds.yaml'), 'w+') as f:\n        writer.write_compounds(f, sorted(model.compounds, key=lambda c: c.id))\n\n    if model.default_flux_limit is None:\n        model.default_flux_limit = detect_best_flux_limit(model)\n\n    if model.extracellular_compartment is None:\n        model.extracellular_compartment = (\n            sbml.detect_extracellular_compartment(model))\n\n    if model.default_compartment is None:\n        model.default_compartment = get_default_compartment(model)\n\n    if model.default_flux_limit is not None:\n        logger.info('Using default flux limit of {}'.format(\n            model.default_flux_limit))\n\n    if convert_exchange:\n        logger.info('Converting exchange reactions to exchange file')\n        sbml.convert_exchange_to_compounds(model)\n\n    if len(model.compartments) == 0:\n        infer_compartment_entries(model)\n        logger.info('Inferred {} compartments: {}'.format(\n            len(model.compartments),\n            ', '.join(c.id for c in model.compartments)))\n\n    if len(model.compartments) != 0 and len(model.compartment_boundaries) == 0:\n        infer_compartment_adjacency(model)\n\n    reaction_files = reactions_to_files(model, dest, writer, split_subsystem)\n\n    if len(model.exchange) > 0:\n        with open(os.path.join(dest, 'exchange.yaml'), 'w+') as f:\n            yaml.safe_dump(model_exchange(model), f, **yaml_args)\n\n    reaction_limits = list(model_reaction_limits(model))\n    if len(reaction_limits) > 0:\n        with open(os.path.join(dest, 'limits.yaml'), 'w+') as f:\n            yaml.safe_dump(reaction_limits, f, **yaml_args)\n\n    model_d = OrderedDict()\n    if model.name is not None:\n        model_d['name'] = model.name\n\n    if model.biomass_reaction is not None:\n        model_d['biomass'] = model.biomass_reaction\n    if model.default_flux_limit is not None:\n        model_d['default_flux_limit'] = model.default_flux_limit\n    if model.extracellular_compartment != 'e':\n        model_d['extracellular'] = model.extracellular_compartment\n    if model.default_compartment != 'c':\n        model_d['default_compartment'] = model.default_compartment\n\n    if len(model.compartments) > 0:\n        adjacency = {}\n        for c1, c2 in model.compartment_boundaries:\n            adjacency.setdefault(c1, set()).add(c2)\n            adjacency.setdefault(c2, set()).add(c1)\n\n        compartment_list = []\n        for compartment in sorted(model.compartments, key=lambda c: c.id):\n            adjacent = adjacency.get(compartment.id)\n            if adjacent is not None and len(adjacent) == 1:\n                adjacent = next(iter(adjacent))\n            compartment_list.append(writer.convert_compartment_entry(\n                compartment, adjacent))\n\n        model_d['compartments'] = compartment_list\n\n    model_d['compounds'] = [{'include': 'compounds.yaml'}]\n    model_d['reactions'] = []\n    for reaction_file in reaction_files:\n        model_d['reactions'].append({'include': reaction_file})\n\n    if len(model.exchange) > 0:\n        model_d['exchange'] = [{'include': 'exchange.yaml'}]\n\n    if len(reaction_limits) > 0:\n        model_d['limits'] = [{'include': 'limits.yaml'}]\n\n    with open(os.path.join(dest, 'model.yaml'), 'w+') as f:\n        yaml.safe_dump(model_d, f, **yaml_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _try_parse_formula(self, compound_id, s):\n        s = s.strip()\n        if s == '':\n            return None\n\n        try:\n            # Do not return the parsed formula. For now it is better to keep\n            # the original formula string unchanged in all cases.\n            formula.Formula.parse(s)\n        except formula.ParseError:\n            logger.warning('Unable to parse compound formula {}: {}'.format(\n                compound_id, s))\n\n        return s", "response": "Try to parse the given compound formula string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to parse the given reaction equation string.", "response": "def _try_parse_reaction(self, reaction_id, s,\n                            parser=parse_reaction, **kwargs):\n        \"\"\"Try to parse the given reaction equation string.\n\n        Returns the parsed Reaction object, or raises an error if the reaction\n        could not be parsed.\n        \"\"\"\n        try:\n            return parser(s, **kwargs)\n        except ReactionParseError as e:\n            if e.indicator is not None:\n                logger.error('{}\\n{}\\n{}'.format(\n                    str(e), s, e.indicator))\n            raise ParseError('Unable to parse reaction {}: {}'.format(\n                reaction_id, s))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to parse the given gene association rule.", "response": "def _try_parse_gene_association(self, reaction_id, s):\n        \"\"\"Try to parse the given gene association rule.\n\n        Logs a warning if the association rule could not be parsed and returns\n        the original string. Otherwise, returns the boolean.Expression object.\n        \"\"\"\n        s = s.strip()\n        if s == '':\n            return None\n\n        try:\n            return boolean.Expression(s)\n        except boolean.ParseError as e:\n            msg = 'Failed to parse gene association for {}: {}'.format(\n                reaction_id, text_type(e))\n            if e.indicator is not None:\n                msg += '\\n{}\\n{}'.format(s, e.indicator)\n            logger.warning(msg)\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning FastGapFill gap-filling algorithm by calling :func:`psamm.fastcore.fastcore`. FastGapFill will try to find a minimum subset of reactions that includes the core reactions and it also has no blocked reactions. Return the set of reactions in the minimum subset. An extended model that includes artificial transport and exchange reactions can be generated by calling :func:`.create_extended_model`. Args: model: :class:`psamm.metabolicmodel.MetabolicModel`. core: reactions in the original metabolic model. weights: a weight dictionary for reactions in the model. solver: linear programming library to use. epsilon: float number, threshold for Fastcore algorithm.", "response": "def fastgapfill(model_extended, core, solver, weights={}, epsilon=1e-5):\n    \"\"\"Run FastGapFill gap-filling algorithm by calling\n    :func:`psamm.fastcore.fastcore`.\n\n    FastGapFill will try to find a minimum subset of reactions that includes\n    the core reactions and it also has no blocked reactions.\n    Return the set of reactions in the minimum subset. An extended model that\n    includes artificial transport and exchange reactions can be generated by\n    calling :func:`.create_extended_model`.\n\n    Args:\n        model: :class:`psamm.metabolicmodel.MetabolicModel`.\n        core: reactions in the original metabolic model.\n        weights: a weight dictionary for reactions in the model.\n        solver: linear programming library to use.\n        epsilon: float number, threshold for Fastcore algorithm.\n    \"\"\"\n\n    # Run Fastcore and print the induced reaction set\n    logger.info('Calculating Fastcore induced set on model')\n    induced = fastcore(\n        model_extended, core, epsilon=epsilon, weights=weights, solver=solver)\n    logger.debug('Result: |A| = {}, A = {}'.format(len(induced), induced))\n    added_reactions = induced - core\n    logger.debug('Extended: |E| = {}, E = {}'.format(\n        len(added_reactions), added_reactions))\n    return induced"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef require_content_types(*allowed_content_types):\n    def decorator(f):\n        @wraps(f)\n        def inner(*args, **kwargs):\n            if request.mimetype not in allowed_content_types:\n                raise InvalidContentType(allowed_content_types)\n            return f(*args, **kwargs)\n        return inner\n    return decorator", "response": "Decorator to test if proper Content - Type is provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a new connection from the cache or return an existing one.", "response": "def get_connection(self, *args, **kwargs):\n        \"\"\"\n        Create a new connection, or return an existing one from the cache. Uses Fabric's current ``env.host_string``\n        and the URL to the Docker service.\n\n        :param args: Additional arguments for the client constructor, if a new client has to be instantiated.\n        :param kwargs: Additional keyword args for the client constructor, if a new client has to be instantiated.\n        \"\"\"\n        key = env.get('host_string'), kwargs.get('base_url', env.get('docker_base_url'))\n        default_config = _get_default_config(None)\n        if default_config:\n            if key not in self:\n                self[key] = default_config\n            return default_config.get_client()\n        config = self.get_or_create_connection(key, self.configuration_class, *args, **kwargs)\n        return config.get_client()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_solvers(solvers, requirements):\n    for solver in solvers:\n        for req, value in iteritems(requirements):\n            if (req in ('integer', 'quadratic', 'rational', 'name') and\n                    (req not in solver or solver[req] != value)):\n                break\n        else:\n            yield solver", "response": "Yield solvers that fullfil the requirements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string containing a solver setting", "response": "def parse_solver_setting(s):\n    \"\"\"Parse a string containing a solver setting\"\"\"\n\n    try:\n        key, value = s.split('=', 1)\n    except ValueError:\n        key, value = s, 'yes'\n\n    if key in ('rational', 'integer', 'quadratic'):\n        value = value.lower() in ('1', 'yes', 'true', 'on')\n    elif key in ('threads',):\n        value = int(value)\n    elif key in ('feasibility_tolerance', 'optimality_tolerance',\n                 'integrality_tolerance'):\n        value = float(value)\n\n    return key, value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a boolean expression containing and or operators and return a tree of trees.", "response": "def _parse_expression(s):\n    \"\"\"Parse boolean expression containing and/or operators\"\"\"\n\n    # Converters for opeartor clauses\n    operators = {\n        'and': And,\n        'or': Or,\n        None: lambda *args: args[0]\n    }\n\n    # Pairing of end group symbols with start group symbols\n    group_pairs = {\n        ')': '(',\n        ']': '['\n    }\n\n    scanner = re.compile(r'''\n        (\\s+) |              # space\n        (\\(|\\[) |            # group_start\n        (\\)|\\]) |            # group_end\n        ((?:or|and)\\b) |     # operator\n        ([^\\s\\(\\)\\[\\]]+) |   # variable\n        (\\Z) |               # end\n        (.)                  # error\n    ''', re.DOTALL | re.VERBOSE | re.UNICODE | re.IGNORECASE)\n\n    # Parsed using two states and a stack of open clauses\n    # At state 0 (not expect_operator): Expect variable, or parenthesis group\n    #  start.\n    # At state 1 (expect_operator): Expect operator, parenthesis group end, or\n    #  end.\n    expect_operator = False\n    clause_stack = []\n    current_clause = []\n    clause_operator = None\n    clause_symbol = None\n\n    def close():\n        prev_op, prev_symbol, prev_clause = clause_stack.pop()\n        prev_clause.append(operators[clause_operator](*current_clause))\n        return prev_op, prev_symbol, prev_clause\n\n    for match in re.finditer(scanner, s):\n        (space, group_start, group_end, operator, variable, end,\n            error) = match.groups()\n\n        if error is not None:\n            raise ParseError('Invalid token in expression string: {}'.format(\n                repr(match.group(0))), span=(match.start(), match.end()))\n        elif space is not None:\n            continue\n        elif expect_operator and operator is not None:\n            operator = operator.lower()\n            if operator == 'and' and clause_operator != 'and':\n                prev_term = current_clause.pop()\n                clause_stack.append(\n                    (clause_operator, clause_symbol, current_clause))\n                current_clause = [prev_term]\n            elif operator == 'or' and clause_operator == 'and':\n                clause_operator, clause_symbol, current_clause = close()\n            clause_operator = operator\n            expect_operator = False\n        elif expect_operator and group_end is not None:\n            if clause_operator == 'and':\n                clause_operator, clause_symbol, current_clause = close()\n            if len(clause_stack) == 0:\n                raise ParseError(\n                    'Unbalanced parenthesis group in expression',\n                    span=(match.start(), match.end()))\n            if group_pairs[group_end] != clause_symbol:\n                raise ParseError(\n                    'Group started with {} ended with {}'.format(\n                        clause_symbol, group_end),\n                    span=(match.start(), match.end()))\n            clause_operator, clause_symbol, current_clause = close()\n        elif expect_operator and end is not None:\n            if clause_operator == 'and':\n                clause_operator, clause_symbol, current_clause = close()\n        elif not expect_operator and variable is not None:\n            current_clause.append(Variable(variable))\n            expect_operator = True\n        elif not expect_operator and group_start is not None:\n            clause_stack.append(\n                (clause_operator, clause_symbol, current_clause))\n            current_clause = []\n            clause_operator = None\n            clause_symbol = group_start\n        else:\n            raise ParseError(\n                'Invalid token in expression string: {!r}'.format(\n                    match.group(0)),\n                span=(match.start(), match.end()))\n\n    if len(clause_stack) > 0:\n        raise ParseError('Unbalanced parenthesis group in expression')\n\n    expr = operators[clause_operator](*current_clause)\n    return expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lower(self):\n        '''Lower bound'''\n        try:\n            return self._model._limits_lower[self._reaction]\n        except KeyError:\n            if self._model.is_reversible(self._reaction):\n                return -self._model._v_max\n            else:\n                return 0", "response": "Lower bound of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upper(self):\n        '''Upper bound'''\n        try:\n            return self._model._limits_upper[self._reaction]\n        except KeyError:\n            return self._model._v_max", "response": "Upper bound of the current reaction."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_reaction_values(self, reaction_id):\n        if reaction_id not in self._reaction_set:\n            raise ValueError('Unknown reaction: {}'.format(repr(reaction_id)))\n        return self._database.get_reaction_values(reaction_id)", "response": "Return stoichiometric values of reaction as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_compound_reactions(self, compound_id):\n        if compound_id not in self._compound_set:\n            raise ValueError('Compound not in model: {}'.format(compound_id))\n\n        for reaction_id in self._database.get_compound_reactions(compound_id):\n            if reaction_id in self._reaction_set:\n                yield reaction_id", "response": "Iterate over all reaction ids the includes the given compound"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_reversible(self, reaction_id):\n        if reaction_id not in self._reaction_set:\n            raise ValueError('Reaction not in model: {}'.format(reaction_id))\n        return self._database.is_reversible(reaction_id)", "response": "Whether the given reaction is reversible"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_exchange(self, reaction_id):\n        reaction = self.get_reaction(reaction_id)\n        return (len(reaction.left) == 0) != (len(reaction.right) == 0)", "response": "Returns True if the given reaction is an exchange reaction."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_reaction(self, reaction_id):\n\n        if reaction_id in self._reaction_set:\n            return\n\n        reaction = self._database.get_reaction(reaction_id)\n        self._reaction_set.add(reaction_id)\n        for compound, _ in reaction.compounds:\n            self._compound_set.add(compound)", "response": "Add reaction to model"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_reaction(self, reaction):\n\n        if reaction not in self._reaction_set:\n            return\n\n        self._reaction_set.remove(reaction)\n        self._limits_lower.pop(reaction, None)\n        self._limits_upper.pop(reaction, None)\n\n        # Remove compound from compound_set if it is not referenced\n        # by any other reactions in the model.\n        for compound, value in self._database.get_reaction_values(reaction):\n            reactions = frozenset(\n                self._database.get_compound_reactions(compound))\n            if all(other_reaction not in self._reaction_set\n                   for other_reaction in reactions):\n                self._compound_set.remove(compound)", "response": "Removes reaction from the model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the current object", "response": "def copy(self):\n        \"\"\"Return copy of model\"\"\"\n\n        model = self.__class__(self._database)\n        model._limits_lower = dict(self._limits_lower)\n        model._limits_upper = dict(self._limits_upper)\n        model._reaction_set = set(self._reaction_set)\n        model._compound_set = set(self._compound_set)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_model(cls, database, reaction_iter=None, exchange=None,\n                   limits=None, v_max=None):\n        \"\"\"Get model from reaction name iterator.\n\n        The model will contain all reactions of the iterator.\n        \"\"\"\n\n        model_args = {}\n        if v_max is not None:\n            model_args['v_max'] = v_max\n\n        model = cls(database, **model_args)\n        if reaction_iter is None:\n            reaction_iter = iter(database.reactions)\n        for reaction_id in reaction_iter:\n            model.add_reaction(reaction_id)\n\n        # Apply reaction limits\n        if limits is not None:\n            for reaction_id, lower, upper in limits:\n                if lower is not None:\n                    model.limits[reaction_id].lower = lower\n                if upper is not None:\n                    model.limits[reaction_id].upper = upper\n\n        # TODO: Currently we just create a new exchange reaction in the\n        # database and add it to the model. Ideally, we should not modify\n        # the database. The exchange reaction could be created on the\n        # fly when required.\n        if exchange is not None:\n            for compound, reaction_id, lower, upper in exchange:\n                # Create exchange reaction\n                if reaction_id is None:\n                    reaction_id = create_exchange_id(\n                        model.database.reactions, compound)\n                model.database.set_reaction(\n                    reaction_id, Reaction(Direction.Both, {compound: -1}))\n                model.add_reaction(reaction_id)\n                if lower is not None:\n                    model.limits[reaction_id].lower = lower\n                if upper is not None:\n                    model.limits[reaction_id].upper = upper\n\n        return model", "response": "Load a model from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlowering bound of the FlipableFlux.", "response": "def lower(self):\n        \"\"\"Lower bound\"\"\"\n        if self._reaction in self._view._flipped:\n            return -super(FlipableFluxBounds, self).upper\n        return super(FlipableFluxBounds, self).lower"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n\n        # Load compound information\n        def compound_name(id):\n            if id not in self._model.compounds:\n                return id\n            return self._model.compounds[id].properties.get('name', id)\n\n        # Reaction genes information\n        def reaction_genes_string(id):\n            if id not in self._model.reactions:\n                return ''\n            return self._model.reactions[id].properties.get('genes', '')\n\n        reaction = self._get_objective()\n        if not self._mm.has_reaction(reaction):\n            self.fail(\n                'Specified reaction is not in model: {}'.format(reaction))\n\n        loop_removal = self._get_loop_removal_option()\n        if loop_removal == 'none':\n            result = self.run_fba(reaction)\n        elif loop_removal == 'l1min':\n            result = self.run_fba_minimized(reaction)\n        elif loop_removal == 'tfba':\n            result = self.run_tfba(reaction)\n\n        optimum = None\n        total_reactions = 0\n        nonzero_reactions = 0\n        for reaction_id, flux in sorted(result):\n            total_reactions += 1\n            if abs(flux) > self._args.epsilon:\n                nonzero_reactions += 1\n\n            if abs(flux) > self._args.epsilon or self._args.all_reactions:\n                rx = self._mm.get_reaction(reaction_id)\n                rx_trans = rx.translated_compounds(compound_name)\n                genes = reaction_genes_string(reaction_id)\n                print('{}\\t{}\\t{}\\t{}'.format(\n                    reaction_id, flux, rx_trans, genes))\n\n            # Remember flux of requested reaction\n            if reaction_id == reaction:\n                optimum = flux\n\n        logger.info('Objective flux: {}'.format(optimum))\n        logger.info('Reactions at zero flux: {}/{}'.format(\n            total_reactions - nonzero_reactions, total_reactions))", "response": "Run the flux analysis command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning FBA and flux minimization on model.", "response": "def run_fba_minimized(self, reaction):\n        \"\"\"Run normal FBA and flux minimization on model.\"\"\"\n\n        epsilon = self._args.epsilon\n        solver = self._get_solver()\n\n        p = fluxanalysis.FluxBalanceProblem(self._mm, solver)\n\n        start_time = time.time()\n\n        # Maximize reaction flux\n        try:\n            p.maximize(reaction)\n        except fluxanalysis.FluxBalanceError as e:\n            self.report_flux_balance_error(e)\n\n        fluxes = {r: p.get_flux(r) for r in self._mm.reactions}\n\n        # Run flux minimization\n        flux_var = p.get_flux_var(reaction)\n        p.prob.add_linear_constraints(flux_var == p.get_flux(reaction))\n        p.minimize_l1()\n\n        logger.info('Solving took {:.2f} seconds'.format(\n            time.time() - start_time))\n\n        count = 0\n        for reaction_id in self._mm.reactions:\n            flux = p.get_flux(reaction_id)\n            if abs(flux - fluxes[reaction_id]) > epsilon:\n                count += 1\n            yield reaction_id, flux\n        logger.info('Minimized reactions: {}'.format(count))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun FBA and tFBA on model.", "response": "def run_tfba(self, reaction):\n        \"\"\"Run FBA and tFBA on model.\"\"\"\n\n        solver = self._get_solver(integer=True)\n        p = fluxanalysis.FluxBalanceProblem(self._mm, solver)\n\n        start_time = time.time()\n\n        p.add_thermodynamic()\n\n        try:\n            p.maximize(reaction)\n        except fluxanalysis.FluxBalanceError as e:\n            self.report_flux_balance_error(e)\n\n        logger.info('Solving took {:.2f} seconds'.format(\n            time.time() - start_time))\n\n        for reaction_id in self._mm.reactions:\n            yield reaction_id, p.get_flux(reaction_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_reaction_consistency(database, solver, exchange=set(),\n                               checked=set(), zeromass=set(), weights={}):\n    \"\"\"Check inconsistent reactions by minimizing mass residuals\n\n    Return a reaction iterable, and compound iterable. The reaction iterable\n    yields reaction ids and mass residuals. The compound iterable yields\n    compound ids and mass assignments.\n\n    Each compound is assigned a mass of at least one, and the masses are\n    balanced using the stoichiometric matrix. In addition, each reaction has a\n    residual mass that is included in the mass balance equations. The L1-norm\n    of the residuals is minimized. Reactions in the checked set are assumed to\n    have been manually checked and therefore have the residual fixed at zero.\n    \"\"\"\n\n    # Create Flux balance problem\n    prob = solver.create_problem()\n    compound_set = _non_localized_compounds(database)\n    mass_compounds = compound_set.difference(zeromass)\n\n    # Define mass variables\n    m = prob.namespace(mass_compounds, lower=1)\n\n    # Define residual mass variables and objective constriants\n    z = prob.namespace(database.reactions, lower=0)\n    r = prob.namespace(database.reactions)\n\n    objective = z.expr((reaction_id, weights.get(reaction_id, 1))\n                       for reaction_id in database.reactions)\n    prob.set_objective(objective)\n\n    rs = r.set(database.reactions)\n    zs = z.set(database.reactions)\n    prob.add_linear_constraints(zs >= rs, rs >= -zs)\n\n    massbalance_lhs = {reaction_id: 0 for reaction_id in database.reactions}\n    for (compound, reaction_id), value in iteritems(database.matrix):\n        if compound not in zeromass:\n            mass_var = m(compound.in_compartment(None))\n            massbalance_lhs[reaction_id] += mass_var * value\n    for reaction_id, lhs in iteritems(massbalance_lhs):\n        if reaction_id not in exchange:\n            if reaction_id not in checked:\n                prob.add_linear_constraints(lhs + r(reaction_id) == 0)\n            else:\n                prob.add_linear_constraints(lhs == 0)\n\n    # Solve\n    try:\n        prob.solve(lp.ObjectiveSense.Minimize)\n    except lp.SolverError as e:\n        raise_from(\n            MassConsistencyError('Failed to solve mass consistency: {}'.format(\n                e)), e)\n\n    def iterate_reactions():\n        for reaction_id in database.reactions:\n            residual = r.value(reaction_id)\n            yield reaction_id, residual\n\n    def iterate_compounds():\n        for compound in mass_compounds:\n            yield compound, m.value(compound)\n\n    return iterate_reactions(), iterate_compounds()", "response": "Check inconsistent reactions by minimizing mass residuals and objective."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding each compound in the database with assigned mass and the number of non - localized compounds having a positive mass.", "response": "def check_compound_consistency(database, solver, exchange=set(),\n                               zeromass=set()):\n    \"\"\"Yield each compound in the database with assigned mass\n\n    Each compound will be assigned a mass and the number of compounds having a\n    positive mass will be approximately maximized.\n\n    This is an implementation of the solution originally proposed by\n    [Gevorgyan08]_  but using the new method proposed by [Thiele14]_ to avoid\n    MILP constraints. This is similar to the way Fastcore avoids MILP\n    contraints.\n    \"\"\"\n\n    # Create mass balance problem\n    prob = solver.create_problem()\n    compound_set = _non_localized_compounds(database)\n    mass_compounds = compound_set.difference(zeromass)\n\n    # Define mass variables\n    m = prob.namespace(mass_compounds, lower=0)\n\n    # Define z variables\n    z = prob.namespace(mass_compounds, lower=0, upper=1)\n    prob.set_objective(z.sum(mass_compounds))\n\n    prob.add_linear_constraints(m.set(mass_compounds) >= z.set(mass_compounds))\n\n    massbalance_lhs = {reaction_id: 0 for reaction_id in database.reactions}\n    for (compound, reaction_id), value in iteritems(database.matrix):\n        if compound not in zeromass:\n            mass_var = m(compound.in_compartment(None))\n            massbalance_lhs[reaction_id] += mass_var * value\n    for reaction_id, lhs in iteritems(massbalance_lhs):\n        if reaction_id not in exchange:\n            prob.add_linear_constraints(lhs == 0)\n\n    # Solve\n    try:\n        prob.solve(lp.ObjectiveSense.Maximize)\n    except lp.SolverError as e:\n        raise_from(\n            MassConsistencyError('Failed to solve mass consistency: {}'.format(\n                e)), e)\n\n    for compound in mass_compounds:\n        yield compound, m.value(compound)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a unique string ID from the prefix.", "response": "def create_unique_id(prefix, existing_ids):\n    \"\"\"Return a unique string ID from the prefix.\n\n    First check if the prefix is itself a unique ID in the set-like parameter\n    existing_ids. If not, try integers in ascending order appended to the\n    prefix until a unique ID is found.\n    \"\"\"\n    if prefix in existing_ids:\n        suffix = 1\n        while True:\n            new_id = '{}_{}'.format(prefix, suffix)\n            if new_id not in existing_ids:\n                return new_id\n            suffix += 1\n\n    return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to describe the current commit of a Git repository.", "response": "def git_try_describe(repo_path):\n    \"\"\"Try to describe the current commit of a Git repository.\n\n    Return a string containing a string with the commit ID and/or a base tag,\n    if successful. Otherwise, return None.\n    \"\"\"\n    try:\n        p = subprocess.Popen(['git', 'describe', '--always', '--dirty'],\n                             cwd=repo_path, stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE)\n        output, _ = p.communicate()\n    except:\n        return None\n    else:\n        if p.returncode == 0:\n            return output.strip()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform a function into a convex cardinality optimization function.", "response": "def convex_cardinality_relaxed(f, epsilon=1e-5):\n    \"\"\"Transform L1-norm optimization function into cardinality optimization.\n\n    The given function must optimize a convex problem with\n    a weighted L1-norm as the objective. The transformed function\n    will apply the iterated weighted L1 heuristic to approximately\n    optimize the cardinality of the solution. This method is\n    described by S. Boyd, \"L1-norm norm methods for convex cardinality\n    problems.\" Lecture Notes for EE364b, Stanford University, 2007.\n    Available online at www.stanford.edu/class/ee364b/.\n\n    The given function must take an optional keyword parameter weights\n    (dictionary), and the weights must be set to one if not specified.\n    The function must return the non-weighted solution as an iterator\n    over (identifier, value)-tuples, either directly or as the first\n    element of a tuple.\n    \"\"\"\n\n    def convex_cardinality_wrapper(*args, **kwargs):\n        def dict_result(r):\n            if isinstance(r, tuple):\n                return dict(r[0])\n            return dict(r)\n\n        # Initial run with default weights\n        full_result = f(*args, **kwargs)\n        result = dict_result(full_result)\n\n        def update_weight(value):\n            return 1/(epsilon + abs(value))\n\n        # Iterate until the difference from one iteration to\n        # the next is less than epsilon.\n        while True:\n            weights = {identifier: update_weight(value)\n                       for identifier, value in iteritems(result)}\n            kwargs['weights'] = weights\n\n            last_result = result\n            full_result = f(*args, **kwargs)\n            result = dict_result(full_result)\n\n            delta = math.sqrt(sum(pow(value - last_result[identifier], 2)\n                                  for identifier, value in iteritems(result)))\n            if delta < epsilon:\n                break\n\n        if isinstance(full_result, tuple):\n            return (iteritems(result),) + full_result[1:]\n        return iteritems(result)\n\n    return convex_cardinality_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write(self, s):\n        for line in re.split(r'\\n+', s):\n            if line != '':\n                self._logger.log(self._level, line)", "response": "Write a message to the logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_property_type(name, base_type=Property,\n                       attrs=None, trait_name=None,\n                       **default_kwargs):\n    \"\"\"Makes a new ``Property`` type, which supplies the given arguments\n    as defaults to the ``Property()`` constructor.\n\n    The typical use of this function is to make types for the API you are\n    mapping so that, for instance, any time they use a date you can convert\n    it in a consistent way to a ``datetime.date``.\n\n    It's also used by :py:mod:`normalize.property.types` to create all\n    of its Property subclasses.\n\n    Args:\n        ``name=``\\ *STR*\n            Specifies the name of the new property type.  This is entirely\n            cosmetic, but it is probably a good idea to make this exactly\n            the same as the symbol you are assigning the result to.\n\n        ``base_type=``\\ *Property sub-class*\n            Specifies which property type you are adding defaults to.\n            You can pass in a tuple of types here.\n\n        ``attrs=``\\ *DICT*\n            This lets you pass in a dictionary that will be used as\n            the new Property type's class dictionary.  i.e., it gets\n            passed as the third argument to ``type(NAME, BASES, ATTRS)``,\n            after the properties necessary to implement the defaults\n            are added to it.  If you use this for anything less than\n            trivial, it may be simpler just to make a whole class\n            definition.\n\n        ``trait_name=``\\ *STR*\n            Specify the unique identifier of the trait that is created.\n            This probably doesn't matter, unless you want to use the\n            ``traits=`` keyword to ``Property()``.  The default is to\n            make up a new numbered trait name, starting with \"``trait1``\".\n\n        ``**kwargs``\n            Everything not known is used as defaults for the eventual\n            call to ``Property()``.  If the user of the Property type\n            passes it as well, this overrides the defaults passed to\n            ``make_property_type``.\n    \"\"\"\n\n    if not attrs:\n        attrs = {}\n    bases = base_type if isinstance(base_type, tuple) else (base_type,)\n    self_type = []\n    if not trait_name:\n        global trait_num\n        trait_num += 1\n        trait_name = \"trait%d\" % trait_num\n\n    def __init__(self, **kwargs):\n        for arg, val in default_kwargs.iteritems():\n            if arg not in kwargs:\n                kwargs[arg] = val\n        return super(self_type[0], self).__init__(**kwargs)\n\n    attrs['default_kwargs'] = default_kwargs\n    attrs['__init__'] = __init__\n    attrs['__trait__'] = trait_name\n\n    new_property_type = type(name, bases, attrs)\n    self_type.append(new_property_type)\n    return new_property_type", "response": "Makes a new property type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of the Record class this property is attached to and attribute name it is attached to.", "response": "def fullname(self):\n        \"\"\"Returns the name of the ``Record`` class this ``Property`` is\n        attached to, and attribute name it is attached as.\"\"\"\n        if not self.bound:\n            if self.name is not None:\n                return \"(unbound).%s\" % self.name\n            else:\n                return \"(unbound)\"\n        elif not self.class_():\n            classname = \"(GC'd class)\"\n        else:\n            classname = self.class_().__name__\n        return \"%s.%s\" % (classname, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines a variable in the problem.", "response": "def define(self, *names, **kwargs):\n        \"\"\"Define a variable in the problem.\n\n        Variables must be defined before they can be accessed by var() or\n        set(). This function takes keyword arguments lower and upper to define\n        the bounds of the variable (default: -inf to inf). The keyword argument\n        types can be used to select the type of the variable (Continuous\n        (default), Binary or Integer). Setting any variables different than\n        Continuous will turn the problem into an MILP problem. Raises\n        ValueError if a name is already defined.\n        \"\"\"\n        names = tuple(names)\n        for name in names:\n            if name in self._variables:\n                raise ValueError('Variable already defined: {!r}'.format(name))\n\n        lower = kwargs.get('lower', None)\n        upper = kwargs.get('upper', None)\n        vartype = kwargs.get('types', None)\n\n        # Repeat values if a scalar is given\n        if lower is None or isinstance(lower, numbers.Number):\n            lower = repeat(lower, len(names))\n        if upper is None or isinstance(upper, numbers.Number):\n            upper = repeat(upper, len(names))\n        if vartype is None or vartype in (\n                VariableType.Continuous, VariableType.Binary,\n                VariableType.Integer):\n            vartype = repeat(vartype, len(names))\n\n        # Assign default values\n        vartype = tuple(VariableType.Continuous if value is None else value\n                        for value in vartype)\n\n        if len(names) == 0:\n            return\n\n        var_indices = count(swiglpk.glp_add_cols(self._p, len(names)))\n\n        for i, name, lb, ub, vt in zip(\n                var_indices, names, lower, upper, vartype):\n            self._variables[name] = i\n\n            lb = None if lb == -_INF else lb\n            ub = None if ub == _INF else ub\n\n            if lb is None and ub is None:\n                swiglpk.glp_set_col_bnds(self._p, i, swiglpk.GLP_FR, 0, 0)\n            elif lb is None:\n                swiglpk.glp_set_col_bnds(\n                    self._p, i, swiglpk.GLP_UP, 0, float(ub))\n            elif ub is None:\n                swiglpk.glp_set_col_bnds(\n                    self._p, i, swiglpk.GLP_LO, float(lb), 0)\n            elif lb == ub:\n                swiglpk.glp_set_col_bnds(\n                    self._p, i, swiglpk.GLP_FX, float(lb), 0)\n            else:\n                swiglpk.glp_set_col_bnds(\n                    self._p, i, swiglpk.GLP_DB, float(lb), float(ub))\n\n            if vt != VariableType.Continuous:\n                swiglpk.glp_set_col_kind(self._p, i, self.VARTYPE_MAP[vt])\n\n        self._do_presolve = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the given relation as one or more constraints. Return a list of the names of the constraints added.", "response": "def _add_constraints(self, relation):\n        \"\"\"Add the given relation as one or more constraints.\n\n        Return a list of the names of the constraints added.\n        \"\"\"\n\n        expression = relation.expression\n        constr_count = sum(True for _ in expression.value_sets())\n        if constr_count == 0:\n            return []\n\n        row_indices = count(swiglpk.glp_add_rows(self._p, constr_count))\n\n        names = []\n        for i, value_set in zip(row_indices, expression.value_sets()):\n            value_set = list(value_set)\n            var_indices = swiglpk.intArray(1 + len(value_set))\n            var_values = swiglpk.doubleArray(1 + len(value_set))\n            for j, (variable, coeff) in enumerate(value_set):\n                var_indices[1 + j] = self._variables[variable]\n                var_values[1 + j] = float(coeff)\n\n            swiglpk.glp_set_mat_row(\n                self._p, i, len(value_set), var_indices, var_values)\n\n            if relation.sense == RelationSense.Greater:\n                swiglpk.glp_set_row_bnds(\n                    self._p, i, swiglpk.GLP_LO, -float(expression.offset), 0)\n            elif relation.sense == RelationSense.Less:\n                swiglpk.glp_set_row_bnds(\n                    self._p, i, swiglpk.GLP_UP, 0, -float(expression.offset))\n            else:\n                swiglpk.glp_set_row_bnds(\n                    self._p, i, swiglpk.GLP_FX, -float(expression.offset), 0)\n\n            names.append(i)\n\n        self._do_presolve = True\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_objective(self, expression):\n\n        if isinstance(expression, numbers.Number):\n            # Allow expressions with no variables as objective,\n            # represented as a number\n            expression = Expression(offset=expression)\n\n        # Clear previous objective\n        for i in range(swiglpk.glp_get_num_cols(self._p)):\n            swiglpk.glp_set_obj_coef(self._p, 1 + i, 0)\n\n        for variable, value in expression.values():\n            var_index = self._variables[variable]\n            swiglpk.glp_set_obj_coef(self._p, var_index, float(value))\n\n        swiglpk.glp_set_obj_coef(self._p, 0, float(expression.offset))", "response": "Set objective of problem."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the type of problem maximize or minimize.", "response": "def set_objective_sense(self, sense):\n        \"\"\"Set type of problem (maximize or minimize).\"\"\"\n\n        if sense not in (ObjectiveSense.Minimize, ObjectiveSense.Maximize):\n            raise ValueError('Invalid objective sense')\n\n        swiglpk.glp_set_obj_dir(self._p, self.OBJ_SENSE_MAP[sense])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsolves problem and return result.", "response": "def solve_unchecked(self, sense=None):\n        \"\"\"Solve problem and return result.\n\n        The user must manually check the status of the result to determine\n        whether an optimal solution was found. A :class:`SolverError` may still\n        be raised if the underlying solver raises an exception.\n        \"\"\"\n        if sense is not None:\n            self.set_objective_sense(sense)\n\n        parm = swiglpk.glp_smcp()\n        swiglpk.glp_init_smcp(parm)\n        if self._do_presolve:\n            parm.presolve = swiglpk.GLP_ON\n            self._do_presolve = False\n        else:\n            parm.presolve = swiglpk.GLP_OFF\n\n        parm.tol_bnd = self._feasibility_tolerance\n        parm.tol_dj = self._optimality_tolerance\n\n        logger.debug('Solving using glp_simplex()')\n        r = swiglpk.glp_simplex(self._p, parm)\n        if r in (swiglpk.GLP_ENOPFS, swiglpk.GLP_ENODFS):\n            self._result = Result(self, r)\n            return self._result\n        elif r != 0:\n            raise GLPKError('glp_simplex: {}'.format(r))\n\n        if swiglpk.glp_get_num_int(self._p) == 0:\n            self._result = Result(self)\n        else:\n            # The intopt MILP solver needs an optimal solution to the LP\n            # relaxation. Therefore, glp_simplex has to run before glp_intopt\n            # for MILP problems.\n            logger.debug('Solving using glp_intopt()')\n            parm = swiglpk.glp_iocp()\n            swiglpk.glp_init_iocp(parm)\n            parm.tol_int = self._integrality_tolerance\n            r = swiglpk.glp_intopt(self._p, parm)\n            if r != 0:\n                raise GLPKError('glp_intopt: {}'.format(r))\n\n            self._result = MIPResult(self)\n\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef success(self):\n        self._check_valid()\n        if self._ret_val != 0:\n            return False\n        return swiglpk.glp_get_status(self._problem._p) == swiglpk.GLP_OPT", "response": "Return boolean indicating whether a solution was found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unbounded(self):\n        self._check_valid()\n        if self._ret_val != 0:\n            return self._ret_val == swiglpk.GLP_ENODFS\n        return swiglpk.glp_get_status(self._problem._p) == swiglpk.GLP_UNBND", "response": "Whether the solution is unbounded."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef status(self):\n        self._check_valid()\n        if self._ret_val == swiglpk.GLP_ENOPFS:\n            return 'No primal feasible solution'\n        elif self._ret_val == swiglpk.GLP_ENODFS:\n            return 'No dual feasible solution'\n        return str(swiglpk.glp_get_status(self._problem._p))", "response": "Return string indicating the error encountered on failure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_value(self, variable):\n        return swiglpk.glp_get_col_prim(\n            self._problem._p, self._problem._variables[variable])", "response": "Return value of variable in solution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn value of variable in solution.", "response": "def _get_value(self, variable):\n        \"\"\"Return value of variable in solution.\"\"\"\n        return swiglpk.glp_mip_col_val(\n            self._problem._p, self._problem._variables[variable])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default_weight(element):\n    if element in (Atom.N, Atom.O, Atom.P):\n        return 0.4\n    elif isinstance(element, Radical):\n        return 40.0\n    return 1.0", "response": "Return weight of formula element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _weighted_formula(form, weight_func):\n    for e, mf in form.items():\n        if e == Atom.H:\n            continue\n\n        yield e, mf, weight_func(e)", "response": "Yields weighted formula elements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all transfers obtained from result.", "response": "def _transfers(reaction, delta, elements, result, epsilon):\n    \"\"\"Yield transfers obtained from result.\"\"\"\n    left = set(c for c, _ in reaction.left)\n    right = set(c for c, _ in reaction.right)\n    for c1, c2 in product(left, right):\n        items = {}\n        for e in elements:\n            v = result.get_value(delta[c1, c2, e])\n            nearest_int = round(v)\n            if abs(v - nearest_int) < epsilon:\n                v = int(nearest_int)\n            if v >= epsilon:\n                items[e] = v\n\n        if len(items) > 0:\n            yield (c1, c2), Formula(items)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reaction_to_dicts(reaction):\n\n    def dict_from_iter_sum(it):\n        d = {}\n        for k, v in it:\n            if k not in d:\n                d[k] = 0\n            d[k] += v\n        return d\n\n    left = dict_from_iter_sum(reaction.left)\n    right = dict_from_iter_sum(reaction.right)\n\n    return left, right", "response": "Convert a reaction to reduced left right dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict_compound_pairs(reaction, compound_formula, solver, epsilon=1e-5,\n                           alt_elements=None, weight_func=default_weight):\n    \"\"\"Predict compound pairs of reaction using MapMaker.\n\n    Yields all solutions as dictionaries with compound pairs as keys and\n    formula objects as values.\n\n    Args:\n        reaction: :class:`psamm.reaction.Reaction` object.\n        compound_formula: Dictionary mapping compound IDs to formulas. Formulas\n            must be flattened.\n        solver: LP solver (MILP).\n        epsilon: Threshold for rounding floating-point values to integers in\n            the predicted transfers.\n        alt_elements: Iterable of elements to consider for alternative\n              solutions. Only alternate solutions that have different transfers\n              of these elements will be returned (default=all elements).\n        weight_func: Optional function that returns a weight for a formula\n            element (should handle specific Atom and Radical objects). By\n            default, the standard MapMaker weights will be used\n            (H=0, R=40, N=0.4, O=0.4, P=0.4, *=1).\n    \"\"\"\n    elements = set()\n    for compound, value in reaction.compounds:\n        if compound.name not in compound_formula:\n            return\n\n        f = compound_formula[compound.name]\n        elements.update(e for e, _, _ in _weighted_formula(f, weight_func))\n\n    if len(elements) == 0:\n        return\n\n    p = solver.create_problem()\n\n    x = p.namespace(name='x')\n    y = p.namespace(name='y')\n    m = p.namespace(name='m')\n    q = p.namespace(name='q')\n    omega = p.namespace(name='omega')\n    gamma = p.namespace(name='gamma')\n    delta = p.namespace(name='delta')\n\n    left, right = _reaction_to_dicts(reaction)\n\n    objective = 0\n    for c1, c2 in product(left, right):\n        m.define([(c1, c2)], lower=0)\n        q.define([(c1, c2)], lower=0)\n        omega.define([(c1, c2)], types=lp.VariableType.Binary)\n\n        objective += 100 * m[c1, c2] + 90 * q[c1, c2] - 0.1 * omega[c1, c2]\n\n        gamma.define(((c1, c2, e) for e in elements),\n                     types=lp.VariableType.Binary)\n        delta.define(((c1, c2, e) for e in elements), lower=0)\n\n        # Eq 12\n        x.define([(c1, c2)], types=lp.VariableType.Binary)\n        y.define([(c1, c2)], types=lp.VariableType.Binary)\n        p.add_linear_constraints(y[c1, c2] <= 1 - x[c1, c2])\n\n        # Eq 6, 9\n        delta_wsum = delta.expr(\n            ((c1, c2, e), weight_func(e)) for e in elements)\n        p.add_linear_constraints(\n            m[c1, c2] <= delta_wsum, q[c1, c2] <= delta_wsum)\n\n        objective -= gamma.sum((c1, c2, e) for e in elements)\n\n    p.set_objective(objective)\n\n    # Eq 3\n    zs = {}\n    for c1, v in iteritems(left):\n        f = compound_formula[c1.name]\n        for e in elements:\n            mf = f.get(e, 0)\n            delta_sum = delta.sum((c1, c2, e) for c2 in right)\n            try:\n                p.add_linear_constraints(delta_sum == v * mf)\n            except ValueError:\n                raise UnbalancedReactionError('Unable to add constraint')\n\n        # Eq 8, 11\n        x_sum = x.sum((c1, c2) for c2 in right)\n        y_sum = y.sum((c1, c2) for c2 in right)\n        p.add_linear_constraints(x_sum <= 1, y_sum <= 1)\n\n        # Eq 13\n        zs[c1] = 0\n        for e, mf, w in _weighted_formula(f, weight_func):\n            zs[c1] += w * mf\n\n    # Eq 2\n    for c2, v in iteritems(right):\n        f = compound_formula[c2.name]\n        for e in elements:\n            mf = f.get(e, 0)\n            delta_sum = delta.sum((c1, c2, e) for c1 in left)\n            try:\n                p.add_linear_constraints(delta_sum == v * mf)\n            except ValueError:\n                raise UnbalancedReactionError('Unable to add constraint')\n\n    for c1, v1 in iteritems(left):\n        for c2 in right:\n            f1 = compound_formula[c1.name]\n            f2 = compound_formula[c2.name]\n            for e in elements:\n                mf = f1.get(e, 0)\n\n                # Eq 4\n                p.add_linear_constraints(\n                    delta[c1, c2, e] <= float(v1) * mf * omega[c1, c2])\n\n                # Eq 5\n                if e in f2:\n                    p.add_linear_constraints(\n                        delta[c1, c2, e] <= float(v1) * mf * gamma[c1, c2, e])\n\n            # Eq 7, 10\n            p.add_linear_constraints(\n                m[c1, c2] <= float(v1) * zs[c1] * x[c1, c2],\n                q[c1, c2] <= float(v1) * zs[c1] * y[c1, c2])\n\n    try:\n        result = p.solve(lp.ObjectiveSense.Maximize)\n    except lp.SolverError:\n        raise UnbalancedReactionError('Unable to solve')\n\n    first_objective = result.get_value(objective)\n\n    # Yield the first result\n    yield dict(_transfers(reaction, delta, elements, result, epsilon))\n\n    # Find alternative solutions\n    if alt_elements is None:\n        alt_elements = elements\n    else:\n        alt_elements = elements.intersection(alt_elements)\n\n    if len(alt_elements) == 0:\n        return\n\n    # Add a constraint that disallows the current transfer solution until no\n    # alternative solutions are left.\n    add_objective_constraint = True\n    while True:\n        elem_vars = 0\n        elem_count = 0\n        for c1, c2 in product(left, right):\n            for e in alt_elements:\n                if result.get_value(gamma[c1, c2, e]) > 0.5:\n                    elem_count += 1\n                    elem_vars += gamma[c1, c2, e]\n\n        if elem_count == 0:\n            break\n\n        if add_objective_constraint:\n            p.add_linear_constraints(objective >= first_objective)\n            add_objective_constraint = False\n\n        p.add_linear_constraints(elem_vars <= elem_count - 1)\n        try:\n            result = p.solve(lp.ObjectiveSense.Maximize)\n        except lp.SolverError:\n            break\n\n        yield dict(_transfers(reaction, delta, elements, result, epsilon))", "response": "Predicts the pairs of a reaction using MapMaker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a temporary container which can be used e. g. for copying resources.", "response": "def temp_container(image, no_op_cmd='/bin/true', create_kwargs=None, start_kwargs=None):\n    \"\"\"\n    Creates a temporary container, which can be used e.g. for copying resources. The container is removed once it\n    is no longer needed. Note that ``no_op_cmd`` needs to be set appropriately, since the method will wait for the\n    container to finish before copying resources.\n\n    :param image: Image name or id to create the container from.\n    :type image: unicode\n    :param no_op_cmd: Dummy-command to run, only for being able to access the container.\n    :type no_op_cmd: unicode\n    :param create_kwargs: Additional kwargs for creating the container. The ``entrypoint`` will be set to ``no_op_cmd``.\n    :type create_kwargs: dict\n    :param start_kwargs: Additional kwargs for starting the container. ``restart_policy`` will be set to ``None``.\n    :type start_kwargs: dict\n    :return: Id of the temporary container.\n    :rtype: unicode\n    \"\"\"\n    df = docker_fabric()\n    create_kwargs = create_kwargs.copy() if create_kwargs else dict()\n    start_kwargs = start_kwargs.copy() if start_kwargs else dict()\n    create_kwargs.update(entrypoint=no_op_cmd)\n    start_kwargs.update(restart_policy=None)\n    container = df.create_container(image, **create_kwargs)['Id']\n    df.start(container, **start_kwargs)\n    df.wait(container)\n    yield container\n    df.remove_container(container)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_generic(of, coll):\n\n    assert(issubclass(coll, Collection))\n    key = (coll.__name__, \"%s.%s\" % (of.__module__, of.__name__))\n    if key in GENERIC_TYPES:\n        if GENERIC_TYPES[key].itemtype != of:\n            raise exc.PropertyNotUnique(key=key)\n    else:\n        # oh, we get to name it?  Goodie!\n        generic_name = \"%s%s\" % (of.__name__, coll.suffix)\n        GENERIC_TYPES[key] = type(\n            generic_name, (coll, _Generic), dict(itemtype=of, generic_key=key)\n        )\n        mod = sys.modules[of.__module__]\n        if not hasattr(mod, generic_name):\n            setattr(mod, generic_name, GENERIC_TYPES[key])\n    return GENERIC_TYPES[key]", "response": "Used to make a new type with that type having to be\n    defined explicitly."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coerce_value(cls, v):\n        if isinstance(v, cls.itemtype):\n            return v\n        else:\n            try:\n                return cls.coerceitem(v)\n            except Exception as e:\n                raise exc.CollectionItemCoerceError(\n                    itemtype=cls.itemtype,\n                    colltype=cls,\n                    passed=v,\n                    exc=e,\n                )", "response": "Coerce a value to the right type for the collection or return it if it is already of the right type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a collection of types to tuples.", "response": "def coll_to_tuples(cls, coll):\n        \"\"\"``coll_to_tuples`` is capable of unpacking its own collection types\n        (`list`), ``collections.Mapping`` objects, as well generators,\n        sequences and iterators.  Returns ``(*int*, Value)``.  Does not coerce\n        items.\n        \"\"\"\n        if isinstance(coll, basestring):\n            raise exc.CollectionCoerceError(\n                passed=coll,\n                colltype=cls,\n            )\n        if isinstance(coll, collections.Mapping):\n            i = 0\n            for k in sorted(coll.keys()):\n                yield (i, coll[k])\n        elif isinstance(coll, (collections.Sequence, types.GeneratorType)) or (\n            hasattr(coll, \"next\") and callable(coll.next)\n        ) or (\n            hasattr(coll, \"__iter__\") and callable(coll.__iter__)\n        ):\n            i = 0\n            for v in coll:\n                yield i, v\n                i += 1\n        elif not coll:\n            return\n        else:\n            raise exc.CollectionCoerceError(\n                passed=coll,\n                colltype=cls,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd new values to the end of the collection coercing items.", "response": "def extend(self, iterable):\n        \"\"\"Adds new values to the end of the collection, coercing items.\n        \"\"\"\n        # perhaps: self[len(self):len(self)] = iterable\n        self._values.extend(self.coerce_value(item) for item in iterable)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_command(self, *args, **options):\n        pool = self.connection_pool\n        command_name = args[0]\n        connection = pool.get_connection(command_name, **options)\n        try:\n            connection.send_command(*args)\n            return self.parse_response(connection, command_name, **options)\n        except ConnectionError:\n            connection.disconnect()\n            connection.send_command(*args)\n            return self.parse_response(connection, command_name, **options)\n        finally:\n            pool.release(connection)", "response": "Execute a command and return a parsed response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_response(self, connection, command_name, **options):\n        response = connection.read_response()\n        if command_name in self.response_callbacks and len(response):\n            status = nativestr(response[0])\n            if status == RES_STATUS.OK:\n                return self.response_callbacks[command_name](response[1:],\n                                                             **options)\n            elif status == RES_STATUS.NOT_FOUND:\n                return None\n            else:\n                raise DataError(RES_STATUS_MSG[status]+':'.join(response))\n                #raise DataError('Not Found')\n        return response", "response": "Parses a response from the ssdb server and returns a dictionary of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nincreases the value at key name by amount.", "response": "def incr(self, name, amount=1):\n        \"\"\"\n        Increase the value at key ``name`` by ``amount``. If no key exists, the value\n        will be initialized as ``amount`` .\n\n        Like **Redis.INCR**\n\n        :param string name: the key name\n        :param int amount: increments\n        :return: the integer value at key ``name``\n        :rtype: int\n\n        >>> ssdb.incr('set_count', 3)\n        13\n        >>> ssdb.incr('set_count', 1)\n        14\n        >>> ssdb.incr('set_count', -2)\n        12\n        >>> ssdb.incr('temp_count', 42)\n        42        \n        \"\"\"                \n        amount = get_integer('amount', amount)\n        return self.execute_command('incr', name, amount)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecreasing the value at key name by amount.", "response": "def decr(self, name, amount=1):\n        \"\"\"\n        Decrease the value at key ``name`` by ``amount``. If no key exists, the value\n        will be initialized as 0 - ``amount`` .\n\n        Like **Redis.DECR**\n\n        :param string name: the key name\n        :param int amount: decrements\n        :return: the integer value at key ``name``\n        :rtype: int\n\n        >>> ssdb.decr('set_count', 3)\n        7\n        >>> ssdb.decr('set_count', 1)\n        6\n        >>> ssdb.decr('temp_count', 42)\n        -42                \n        \"\"\"                        \n        amount = get_positive_integer('amount', amount)\n        return self.execute_command('decr', name, amount)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a boolean indicating the value of offset in name", "response": "def getbit(self, name, offset):\n        \"\"\"\n        Returns a boolean indicating the value of ``offset`` in ``name``\n\n        Like **Redis.GETBIT**\n\n        :param string name: the key name\n        :param int offset: the bit position\n        :param bool val: the bit value\n        :return: the bit at the ``offset`` , ``False`` if key doesn't exist or\n         offset exceeds the string length.\n        :rtype: bool\n        \n        >>> ssdb.set('bit_test', 1)\n        True\n        >>> ssdb.getbit('bit_test', 0)\n        True\n        >>> ssdb.getbit('bit_test', 1)\n        False\n        \"\"\"                        \n        offset = get_positive_integer('offset', offset)\n        return self.execute_command('getbit', name, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of offset in key name to val. Returns a boolean indicating the previous value of offset in name.", "response": "def setbit(self, name, offset, val):\n        \"\"\"\n        Flag the ``offset`` in ``name`` as ``value``. Returns a boolean\n        indicating the previous value of ``offset``.        \n\n        Like **Redis.SETBIT**        \n\n        :param string name: the key name\n        :param int offset: the bit position\n        :param bool val: the bit value\n        :return: the previous bit (False or True) at the ``offset``\n        :rtype: bool\n        \n        >>> ssdb.set('bit_test', 1)\n        True\n        >>> ssdb.setbit('bit_test', 1, 1)\n        False\n        >>> ssdb.get('bit_test')\n        3\n        >>> ssdb.setbit('bit_test', 2, 1)\n        False\n        >>> ssdb.get('bit_test')\n        7        \n        \"\"\"                        \n        val = int(get_boolean('val', val))\n        offset = get_positive_integer('offset', offset)\n        return self.execute_command('setbit', name, offset, val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef countbit(self, name, start=None, size=None):\n        if start is not None and size is not None:\n            start = get_integer('start', start)\n            size = get_integer('size', size)\n            return self.execute_command('countbit', name, start, size)\n        elif start is not None:\n            start = get_integer('start', start)            \n            return self.execute_command('countbit', name, start)\n        return self.execute_command('countbit', name)", "response": "Returns the number of bits in the value of key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a substring of the string at key name. start and size are 0 - based integers specifying the portion of the string to return.", "response": "def substr(self, name, start=None, size=None):\n        \"\"\"\n        Return a substring of the string at key ``name``. ``start`` and ``size``\n        are 0-based integers specifying the portion of the string to return.\n\n        Like **Redis.SUBSTR**\n\n        :param string name: the key name\n        :param int start: Optional, the offset of first byte returned. If start\n         is negative, the returned string will start at the start'th character\n         from the end of string.\n        :param int size: Optional, number of bytes returned. If size is\n         negative, then that many characters will be omitted from the end of string.\n        :return: The extracted part of the string.\n        :rtype: string\n        \n        >>> ssdb.set('str_test', 'abc12345678')\n        True\n        >>> ssdb.substr('str_test', 2, 4)\n        'c123'\n        >>> ssdb.substr('str_test', -2, 2)\n        '78'\n        >>> ssdb.substr('str_test', 1, -1)\n        'bc1234567'\n        \"\"\"\n        if start is not None and size is not None:\n            start = get_integer('start', start)\n            size = get_integer('size', size)\n            return self.execute_command('substr', name, start, size)\n        elif start is not None:\n            start = get_integer('start', start)            \n            return self.execute_command('substr', name, start)\n        return self.execute_command('substr', name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef keys(self, name_start, name_end, limit=10):\n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('keys', name_start, name_end, limit)", "response": "Return a list of the top limit keys between name_start and name_end"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscanning and return a dict mapping key - value pairs between name_start and name_end.", "response": "def scan(self, name_start, name_end, limit=10):\n        \"\"\"\n        Scan and return a dict mapping key/value in the top ``limit`` keys between\n        ``name_start`` and ``name_end`` in ascending order\n\n        Similiar with **Redis.SCAN**        \n\n        .. note:: The range is (``name_start``, ``name_end``]. ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param string name_end: The upper bound(included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param int limit: number of elements will be returned.\n        :return: a dict mapping key/value in ascending order\n        :rtype: OrderedDict\n        \n        >>> ssdb.scan('set_x1', 'set_x3', 10)\n        {'set_x2': 'x2', 'set_x3': 'x3'}\n        >>> ssdb.scan('set_x ', 'set_xx', 3)\n        {'set_x1': 'x1', 'set_x2': 'x2', 'set_x3': 'x3'}\n        >>> ssdb.scan('set_x ', '', 10)\n        {'set_x1': 'x1', 'set_x2': 'x2', 'set_x3': 'x3', 'set_x4': 'x4'}\n        >>> ssdb.scan('set_zzzzz ', '', 10)\n        {}\n        \"\"\"        \n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('scan', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans and return a dict mapping key - value pairs between name_start and name_end in descending order.", "response": "def rscan(self, name_start, name_end, limit=10):\n        \"\"\"\n        Scan and return a dict mapping key/value in the top ``limit`` keys between\n        ``name_start`` and ``name_end`` in descending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The upper bound(not included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param string name_end: The lower bound(included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param int limit: number of elements will be returned.\n        :return: a dict mapping key/value in descending order\n        :rtype: OrderedDict\n        \n        >>> ssdb.scan('set_x3', 'set_x1', 10)\n        {'set_x2': 'x2', 'set_x1': 'x1'}\n        >>> ssdb.scan('set_xx', 'set_x ', 3)\n        {'set_x4': 'x4', 'set_x3': 'x3', 'set_x2': 'x2'}\n        >>> ssdb.scan('', 'set_x ', 10)\n        {'set_x4': 'x4', 'set_x3': 'x3', 'set_x2': 'x2', 'set_x1': 'x1'}\n        >>> ssdb.scan('', 'set_zzzzz', 10)\n        {}\n        \"\"\"                \n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('rscan', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hincr(self, name, key, amount=1):\n        amount = get_integer('amount', amount)        \n        return self.execute_command('hincr', name, key, amount)", "response": "Increase the value of key in hash name by amount."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecrease the value of key in hash name by amount.", "response": "def hdecr(self, name, key, amount=1):\n        \"\"\"\n        Decrease the value of ``key`` in hash ``name`` by ``amount``. If no key\n        exists, the value will be initialized as 0 - ``amount`` \n\n        :param string name: the hash name\n        :param string key: the key name        \n        :param int amount: increments\n        :return: the integer value of ``key`` in hash ``name``\n        :rtype: int\n\n        >>> ssdb.hdecr('hash_2', 'key1', 7)\n        35\n        >>> ssdb.hdecr('hash_2', 'key2', 3)\n        0\n        >>> ssdb.hdecr('hash_2', 'key_not_exists', 101)\n        -101\n        >>> ssdb.hdecr('hash_not_exists', 'key_not_exists', 8848)\n        -8848\n        \"\"\"                                \n        amount = get_positive_integer('amount', amount)        \n        return self.execute_command('hdecr', name, key, amount)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hkeys(self, name, key_start, key_end, limit=10):\n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('hkeys', name, key_start, key_end, limit)", "response": "Return a list of the top limit keys between key_start and key_end in hash name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hlist(self, name_start, name_end, limit=10):\n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('hlist', name_start, name_end, limit)", "response": "Return a list of the top limit hash s name between name_start and name_end in ascending order"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of the top limit hash s name between name_start and name_end in descending order", "response": "def hrlist(self, name_start, name_end, limit=10):\n        \"\"\"\n        Return a list of the top ``limit`` hash's name between ``name_start`` and\n        ``name_end`` in descending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. The ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of hash names to\n         be returned, empty string ``''`` means +inf\n        :param string name_end: The upper bound(included) of hash names to be\n         returned, empty string ``''`` means -inf\n        :param int limit: number of elements will be returned.\n        :return: a list of hash's name\n        :rtype: list\n        \n        >>> ssdb.hrlist('hash_ ', 'hash_z', 10)\n        ['hash_2', 'hash_1']\n        >>> ssdb.hrlist('hash_ ', '', 3)\n        ['hash_2', 'hash_1']\n        >>> ssdb.hrlist('', 'aaa_not_exist', 10)\n        []\n        \"\"\"                \n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('hrlist', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of the top limit keys between key_start and key_end within hash name.", "response": "def hscan(self, name, key_start, key_end, limit=10):\n        \"\"\"\n        Return a dict mapping key/value in the top ``limit`` keys between\n        ``key_start`` and ``key_end`` within hash ``name`` in ascending order\n\n        Similiar with **Redis.HSCAN**\n\n        .. note:: The range is (``key_start``, ``key_end``]. The ``key_start``\n           isn't in the range, but ``key_end`` is.\n\n        :param string name: the hash name\n        :param string key_start: The lower bound(not included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param string key_end: The upper bound(included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param int limit: number of elements will be returned.\n        :return: a dict mapping key/value in ascending order\n        :rtype: OrderedDict\n        \n        >>> ssdb.hscan('hash_1', 'a', 'g', 10)\n        {'b': 'B', 'c': 'C', 'd': 'D', 'e': 'E', 'f': 'F', 'g': 'G'}\n        >>> ssdb.hscan('hash_2', 'key ', 'key4', 3)\n        {'key1': '42', 'key2': '3.1415926', 'key3': '-1.41421'}\n        >>> ssdb.hscan('hash_1', 'f', '', 10)\n        {'g': 'G'}\n        >>> ssdb.hscan('hash_2', 'keys', '', 10)\n        {}\n        \"\"\"                \n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('hscan', name, key_start, key_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hrscan(self, name, key_start, key_end, limit=10):\n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('hrscan', name, key_start, key_end, limit)", "response": "Return the top limit keys between key_start and key_end within hash name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the score of key from the zset name to score", "response": "def zset(self, name, key, score=1):\n        \"\"\"\n        Set the score of ``key`` from the zset ``name`` to ``score``\n\n        Like **Redis.ZADD**\n\n        :param string name: the zset name\n        :param string key: the key name\n        :param int score: the score for ranking\n        :return: ``True`` if ``zset`` created a new score, otherwise ``False``\n        :rtype: bool\n\n        >>> ssdb.zset(\"zset_1\", 'z', 1024)\n        True\n        >>> ssdb.zset(\"zset_1\", 'a', 1024)\n        False\n        >>> ssdb.zset(\"zset_2\", 'key_10', -4)\n        >>>\n        >>> ssdb.zget(\"zset_2\", 'key1')\n        42        \n        \"\"\"\n        score = get_integer('score', score)        \n        return self.execute_command('zset', name, key, score)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zincr(self, name, key, amount=1):\n        amount = get_integer('amount', amount)        \n        return self.execute_command('zincr', name, key, amount)", "response": "Increase the score of key in zset name by amount."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecrease the value of key in zset name by amount.", "response": "def zdecr(self, name, key, amount=1):\n        \"\"\"\n        Decrease the value of ``key`` in zset ``name`` by ``amount``. If no key\n        exists, the value will be initialized as 0 - ``amount`` \n\n        :param string name: the zset name\n        :param string key: the key name        \n        :param int amount: increments\n        :return: the integer value of ``key`` in zset ``name``\n        :rtype: int\n\n        >>> ssdb.zdecr('zset_2', 'key1', 7)\n        36\n        >>> ssdb.zdecr('zset_2', 'key2', 3)\n        311\n        >>> ssdb.zdecr('zset_2', 'key_not_exists', 101)\n        -101\n        >>> ssdb.zdecr('zset_not_exists', 'key_not_exists', 8848)\n        -8848\n        \"\"\"                                        \n        amount = get_positive_integer('amount', amount)\n        return self.execute_command('zdecr', name, key, amount)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary mapping key = > value by keys from zset names", "response": "def multi_zset(self, name, **kvs):\n        \"\"\"\n        Return a dictionary mapping key/value by ``keys`` from zset ``names``\n\n        :param string name: the zset name        \n        :param list keys: a list of keys\n        :return: the number of successful creation\n        :rtype: int\n\n        >>> ssdb.multi_zset('zset_4', a=100, b=80, c=90, d=70)\n        4\n        >>> ssdb.multi_zset('zset_4', a=100, b=80, c=90, d=70)\n        0\n        >>> ssdb.multi_zset('zset_4', a=100, b=80, c=90, d=70, e=60)\n        1        \n        \"\"\"                                        \n        for k,v in kvs.items():\n            kvs[k] = get_integer(k, int(v))\n        return self.execute_command('multi_zset', name, *dict_to_list(kvs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of the top limit zset s name between name_start and name_end in ascending order", "response": "def zlist(self, name_start, name_end, limit=10):\n        \"\"\"\n        Return a list of the top ``limit`` zset's name between ``name_start`` and\n        ``name_end`` in ascending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. The ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of zset names to\n         be returned, empty string ``''`` means -inf\n        :param string name_end: The upper bound(included) of zset names to be\n         returned, empty string ``''`` means +inf\n        :param int limit: number of elements will be returned.\n        :return: a list of zset's name\n        :rtype: list\n        \n        >>> ssdb.zlist('zset_ ', 'zset_z', 10)\n        ['zset_1', 'zset_2']\n        >>> ssdb.zlist('zset_ ', '', 3)\n        ['zset_1', 'zset_2']\n        >>> ssdb.zlist('', 'aaa_not_exist', 10)\n        []\n        \"\"\"        \n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('zlist', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of the top limit zset s name between name_start and name_end in descending order", "response": "def zrlist(self, name_start, name_end, limit=10):\n        \"\"\"\n        Return a list of the top ``limit`` zset's name between ``name_start`` and\n        ``name_end`` in descending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. The ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of zset names to\n         be returned, empty string ``''`` means +inf\n        :param string name_end: The upper bound(included) of zset names to be\n         returned, empty string ``''`` means -inf\n        :param int limit: number of elements will be returned.\n        :return: a list of zset's name\n        :rtype: list\n        \n        >>> ssdb.zlist('zset_ ', 'zset_z', 10)\n        ['zset_2', 'zset_1']\n        >>> ssdb.zlist('zset_ ', '', 3)\n        ['zset_2', 'zset_1']\n        >>> ssdb.zlist('', 'aaa_not_exist', 10)\n        []\n        \"\"\"        \n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('zrlist', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of top limit keys after key_start and score_end from zset name with scores between score_start and score_end.", "response": "def zkeys(self, name, key_start, score_start, score_end, limit=10):\n        \"\"\"\n        Return a list of the top ``limit`` keys after ``key_start`` from zset\n        ``name`` with scores between ``score_start`` and ``score_end`` \n\n        .. note:: The range is (``key_start``+``score_start``, ``key_end``]. That\n           means (key.score == score_start && key > key_start || key.score >\n           score_start)\n\n        :param string name: the zset name\n        :param string key_start: The lower bound(not included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param string key_end: The upper bound(included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param int limit: number of elements will be returned.\n        :return: a list of keys\n        :rtype: list\n\n        >>> ssdb.zkeys('zset_1', '', 0, 200, 10)\n        ['g', 'd', 'b', 'a', 'e', 'c']\n        >>> ssdb.zkeys('zset_1', '', 0, 200, 3)\n        ['g', 'd', 'b']\n        >>> ssdb.zkeys('zset_1', 'b', 20, 200, 3)\n        ['a', 'e', 'c']\n        >>> ssdb.zkeys('zset_1', 'c', 100, 200, 3)\n        []\n        \"\"\"                \n        score_start = get_integer_or_emptystring('score_start', score_start)\n        score_end = get_integer_or_emptystring('score_end', score_end)        \n        limit = get_positive_integer('limit', limit)\n        return self.execute_command('zkeys', name, key_start, score_start,\n                                    score_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of the key - value pairs in a sorted order from zset name between offset and limit.", "response": "def zrange(self, name, offset, limit):\n        \"\"\"\n        Return a dict mapping key/score in a range of score from zset ``name``\n        between ``offset`` and ``offset+limit`` sorted in ascending order.\n\n        Like **Redis.ZRANGE**                \n        \n        .. warning:: This method is SLOW for large offset!\n           \n        :param string name: the zset name\n        :param int offset: zero or positive,the returned pairs will start at\n         this offset\n        :param int limit: number of elements will be returned\n        :return: a dict mapping key/score in ascending order\n        :rtype: OrderedDict\n\n        >>> ssdb.zrange('zset_1', 2, 3)\n        {'d': 1, 'b': 20, 'a': 30}\n        >>> ssdb.zrange('zset_1', 0, 2)\n        {'f': -3, 'g': 0}\n        >>> ssdb.zrange('zset_1', 10, 10)\n        {}\n        \"\"\"\n        offset = get_nonnegative_integer('offset', offset)        \n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('zrange', name, offset, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict mapping key - score pairs from zset name between offset and limit.", "response": "def zrrange(self, name, offset, limit):\n        \"\"\"\n        Return a dict mapping key/score in a range of score from zset ``name``\n        between ``offset`` and ``offset+limit`` sorted in descending order.        \n        \n        .. warning:: This method is SLOW for large offset!\n           \n        :param string name: the zset name\n        :param int offset: zero or positive,the returned pairs will start at\n         this offset\n        :param int limit: number of elements will be returned\n        :return: a dict mapping key/score in ascending order\n        :rtype: OrderedDict\n\n        >>> ssdb.zrrange('zset_1', 0, 4)\n        {'c': 100, 'e': 64, 'a': 30, 'b': 20}\n        >>> ssdb.zrrange('zset_1', 4, 5)\n        {'d': 1, 'g': 0, 'f': -3}\n        >>> ssdb.zrrange('zset_1', 10, 10)\n        {}        \n        \"\"\"        \n        offset = get_nonnegative_integer('offset', offset)        \n        limit = get_positive_integer('limit', limit)        \n        return self.execute_command('zrrange', name, offset, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of elements in the sorted set at key name with a score between score_start and score_end.", "response": "def zcount(self, name, score_start, score_end):\n        \"\"\"\n        Returns the number of elements in the sorted set at key ``name`` with\n        a score between ``score_start`` and ``score_end``.\n\n        Like **Redis.ZCOUNT**\n\n        .. note:: The range is [``score_start``, ``score_end``]\n\n        :param string name: the zset name\n        :param int score_start: The minimum score related to keys(included),\n         empty string ``''`` means -inf\n        :param int score_end: The maximum score(included) related to keys,\n         empty string ``''`` means +inf\n        :return: the number of keys in specified range\n        :rtype: int\n        \n        >>> ssdb.zount('zset_1', 20, 70)\n        3\n        >>> ssdb.zcount('zset_1', 0, 100)\n        6\n        >>> ssdb.zcount('zset_1', 2, 3)\n        0\n        \"\"\"        \n        score_start = get_integer_or_emptystring('score_start', score_start)\n        score_end = get_integer_or_emptystring('score_end', score_end)\n        return self.execute_command('zcount', name, score_start, score_end)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zsum(self, name, score_start, score_end):\n        score_start = get_integer_or_emptystring('score_start', score_start)\n        score_end = get_integer_or_emptystring('score_end', score_end)\n        return self.execute_command('zsum', name, score_start, score_end)", "response": "Returns the sum of the elements of the specified sorted set at the specified key which have scores in the range [ score_start score_end )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zavg(self, name, score_start, score_end):\n        score_start = get_integer_or_emptystring('score_start', score_start)\n        score_end = get_integer_or_emptystring('score_end', score_end)\n        return self.execute_command('zavg', name, score_start, score_end)", "response": "Returns the average of the elements of the sorted set stored at the key name with scores in the range [ score_start score_end )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zremrangebyrank(self, name, rank_start, rank_end):\n        rank_start = get_nonnegative_integer('rank_start', rank_start)\n        rank_end = get_nonnegative_integer('rank_end', rank_end)\n        return self.execute_command('zremrangebyrank', name, rank_start,\n                                    rank_end)", "response": "Remove the elements of the zset with rank rank_start and rank_end from the range\n        [ rank_start rank_end )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the elements of the set with rank in the range [ score_start score_end )", "response": "def zremrangebyscore(self, name, score_start, score_end):\n        \"\"\"\n        Delete the elements of the zset which have rank in the range\n        [score_start,score_end].\n        \n        .. note:: The range is [``score_start``, ``score_end``]\n\n        :param string name: the zset name\n        :param int score_start: The minimum score related to keys(included),\n         empty string ``''`` means -inf\n        :param int score_end: The maximum score(included) related to keys,\n         empty string ``''`` means +inf        \n        :return: the number of deleted elements\n        :rtype: int\n        \n        >>> ssdb.zremrangebyscore('zset_1', 20, 70)\n        3\n        >>> ssdb.zremrangebyscore('zset_1', 0, 100)\n        6\n        >>> ssdb.zremrangebyscore('zset_1', 2, 3)\n        0        \n        \"\"\"        \n        score_start = get_integer_or_emptystring('score_start', score_start)\n        score_end = get_integer_or_emptystring('score_end', score_end)\n        return self.execute_command('zremrangebyscore', name, score_start,\n                                    score_end)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the element of the specified index within the specified queue name.", "response": "def qget(self, name, index):\n        \"\"\"\n        Get the element of ``index`` within the queue ``name``\n\n        :param string name: the queue name\n        :param int index: the specified index, can < 0\n        :return: the value at ``index`` within queue ``name`` , or ``None`` if the\n         element doesn't exist\n        :rtype: string\n\n        \"\"\"\n        index = get_integer('index', index)\n        return self.execute_command('qget', name, index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of the list element at index to value.", "response": "def qset(self, name, index, value):\n        \"\"\"\n        Set the list element at ``index`` to ``value``. \n\n        :param string name: the queue name\n        :param int index: the specified index, can < 0\n        :param string value: the element value\n        :return: Unknown\n        :rtype: True\n        \n        \"\"\"\n        index = get_integer('index', index)        \n        return self.execute_command('qset', name, index, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving and return the first size item of the list name", "response": "def qpop_front(self, name, size=1):\n        \"\"\"\n        Remove and return the first ``size`` item of the list ``name``\n\n        Like **Redis.LPOP**        \n\n        :param string name: the queue name\n        :param int size: the length of result\n        :return: the list of pop elements\n        :rtype: list\n        \n        \"\"\"\n        size = get_positive_integer(\"size\", size)\n        return self.execute_command('qpop_front', name, size)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving and return the last size item of the list name", "response": "def qpop_back(self, name, size=1):\n        \"\"\"\n        Remove and return the last ``size`` item of the list ``name``\n\n        Like **Redis.RPOP**\n\n        :param string name: the queue name\n        :param int size: the length of result\n        :return: the list of pop elements\n        :rtype: list\n        \n        \"\"\"\n        size = get_positive_integer(\"size\", size)\n        return self.execute_command('qpop_back', name, size)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of the top limit keys between name_start and name_end in ascending order", "response": "def qlist(self, name_start, name_end, limit):\n        \"\"\"\n        Return a list of the top ``limit`` keys between ``name_start`` and\n        ``name_end``  in ascending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param string name_end: The upper bound(included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param int limit: number of elements will be returned.\n        :return: a list of keys\n        :rtype: list\n\n        >>> ssdb.qlist('queue_1', 'queue_2', 10)\n        ['queue_2']\n        >>> ssdb.qlist('queue_', 'queue_2', 10)\n        ['queue_1', 'queue_2']\n        >>> ssdb.qlist('z', '', 10)\n        []        \n        \"\"\"\n        limit = get_positive_integer(\"limit\", limit)\n        return self.execute_command('qlist', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of top limit keys between name_start and name_end in descending order", "response": "def qrlist(self, name_start, name_end, limit):\n        \"\"\"\n        Return a list of the top ``limit`` keys between ``name_start`` and\n        ``name_end``  in descending order\n\n        .. note:: The range is (``name_start``, ``name_end``]. ``name_start``\n           isn't in the range, but ``name_end`` is.\n\n        :param string name_start: The lower bound(not included) of keys to be\n         returned, empty string ``''`` means +inf\n        :param string name_end: The upper bound(included) of keys to be\n         returned, empty string ``''`` means -inf\n        :param int limit: number of elements will be returned.\n        :return: a list of keys\n        :rtype: list\n\n        >>> ssdb.qrlist('queue_2', 'queue_1', 10)\n        ['queue_1']\n        >>> ssdb.qrlist('queue_z', 'queue_', 10)\n        ['queue_2', 'queue_1']\n        >>> ssdb.qrlist('z', '', 10)\n        ['queue_2', 'queue_1']\n        \"\"\"\n        limit = get_positive_integer(\"limit\", limit)\n        return self.execute_command('qrlist', name_start, name_end, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a slice of the list name at position offset and limit", "response": "def qrange(self, name, offset, limit):\n        \"\"\"\n        Return a ``limit`` slice of the list ``name`` at position ``offset``\n\n        ``offset`` can be negative numbers just like Python slicing notation\n\n        Similiar with **Redis.LRANGE**\n\n        :param string name: the queue name\n        :param int offset: the returned list will start at this offset\n        :param int limit: number of elements will be returned\n        :return: a list of elements\n        :rtype: list\n        \n        \"\"\"\n        offset = get_integer('offset', offset)        \n        limit = get_positive_integer('limit', limit)                \n        return self.execute_command('qrange', name, offset, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef qslice(self, name, start, end):\n        start = get_integer('start', start)\n        end = get_integer('end', end)\n        return self.execute_command('qslice', name, start, end)", "response": "Returns a list of the elements in the named queue between the start and end indices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the first size elements from the list name.", "response": "def qtrim_front(self, name, size=1):\n        \"\"\"\n        Sets the list element at ``index`` to ``value``. An error is returned for out of\n        range indexes.\n\n        :param string name: the queue name\n        :param int size: the max length of removed elements\n        :return: the length of removed elements\n        :rtype: int\n        \n        \"\"\"\n        size = get_positive_integer(\"size\", size)\n        return self.execute_command('qtrim_front', name, size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the first size elements from the list name.", "response": "def qtrim_back(self, name, size=1):\n        \"\"\"\n        Sets the list element at ``index`` to ``value``. An error is returned for out of\n        range indexes.\n\n        :param string name: the queue name\n        :param int size: the max length of removed elements        \n        :return: the length of removed elements\n        :rtype: int\n        \n        \"\"\"\n        size = get_positive_integer(\"size\", size)\n        return self.execute_command('qtrim_back', name, size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setx(self, name, value, ttl):\n        if isinstance(ttl, datetime.timedelta):\n            ttl = ttl.seconds + ttl.days * 24 * 3600\n        ttl = get_positive_integer('ttl', ttl)\n        return self.execute_command('setx', name, value, ttl)", "response": "Set the value of key name to value that expires in ttl seconds. ttl can be represented by an integer or a Python timedelta object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the IPv6 address for a particular network interface from ifconfig.", "response": "def get_ip6_address(interface_name, expand=False):\n    \"\"\"\n    Extracts the IPv6 address for a particular interface from `ifconfig`.\n\n    :param interface_name: Name of the network interface (e.g. ``eth0``).\n    :type interface_name: unicode\n    :param expand: If set to ``True``, an abbreviated address is expanded to the full address.\n    :type expand: bool\n    :return: IPv6 address; ``None`` if the interface is present but no address could be extracted.\n    :rtype: unicode\n    \"\"\"\n    address = _get_address(interface_name, IP6_PATTERN)\n    if address and expand:\n        return ':'.join(_expand_groups(address))\n    return address"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the list of roles that the current host is assigned to.", "response": "def get_current_roles():\n    \"\"\"\n    Determines the list of roles, that the current host is assigned to. If ``env.roledefs`` is not set, an empty list\n    is returned.\n\n    :return: List of roles of the current host.\n    :rtype: list\n    \"\"\"\n    current_host = env.host_string\n    roledefs = env.get('roledefs')\n    if roledefs:\n        return [role for role, hosts in six.iteritems(roledefs) if current_host in hosts]\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding all reactions from database that occur in given compartments.", "response": "def add_all_database_reactions(model, compartments):\n    \"\"\"Add all reactions from database that occur in given compartments.\n\n    Args:\n        model: :class:`psamm.metabolicmodel.MetabolicModel`.\n    \"\"\"\n\n    added = set()\n    for rxnid in model.database.reactions:\n        reaction = model.database.get_reaction(rxnid)\n        if all(compound.compartment in compartments\n               for compound, _ in reaction.compounds):\n            if not model.has_reaction(rxnid):\n                added.add(rxnid)\n            model.add_reaction(rxnid)\n\n    return added"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_all_exchange_reactions(model, compartment, allow_duplicates=False):\n\n    all_reactions = {}\n    if not allow_duplicates:\n        # TODO: Avoid adding reactions that already exist in the database.\n        # This should be integrated in the database.\n        for rxnid in model.database.reactions:\n            rx = model.database.get_reaction(rxnid)\n            all_reactions[rx] = rxnid\n\n    added = set()\n    added_compounds = set()\n    initial_compounds = set(model.compounds)\n    reactions = set(model.database.reactions)\n    for model_compound in initial_compounds:\n        compound = model_compound.in_compartment(compartment)\n        if compound in added_compounds:\n            continue\n\n        rxnid_ex = create_exchange_id(reactions, compound)\n\n        reaction_ex = Reaction(Direction.Both, {compound: -1})\n        if reaction_ex not in all_reactions:\n            model.database.set_reaction(rxnid_ex, reaction_ex)\n            reactions.add(rxnid_ex)\n        else:\n            rxnid_ex = all_reactions[reaction_ex]\n\n        if not model.has_reaction(rxnid_ex):\n            added.add(rxnid_ex)\n        model.add_reaction(rxnid_ex)\n        added_compounds.add(compound)\n\n    return added", "response": "Add all exchange reactions to the database and to the model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd all transport reactions to the database and to the model.", "response": "def add_all_transport_reactions(model, boundaries, allow_duplicates=False):\n    \"\"\"Add all transport reactions to database and to model.\n\n    Add transport reactions for all boundaries. Boundaries are defined\n    by pairs (2-tuples) of compartment IDs. Transport reactions are\n    added for all compounds in the model, not just for compounds in the\n    two boundary compartments.\n\n    Args:\n        model: :class:`psamm.metabolicmodel.MetabolicModel`.\n        boundaries: Set of compartment boundary pairs.\n\n    Returns:\n        Set of IDs of reactions that were added.\n    \"\"\"\n\n    all_reactions = {}\n    if not allow_duplicates:\n        # TODO: Avoid adding reactions that already exist in the database.\n        # This should be integrated in the database.\n        for rxnid in model.database.reactions:\n            rx = model.database.get_reaction(rxnid)\n            all_reactions[rx] = rxnid\n\n    boundary_pairs = set()\n    for source, dest in boundaries:\n        if source != dest:\n            boundary_pairs.add(tuple(sorted((source, dest))))\n\n    added = set()\n    added_pairs = set()\n    initial_compounds = set(model.compounds)\n    reactions = set(model.database.reactions)\n    for compound in initial_compounds:\n        for c1, c2 in boundary_pairs:\n            compound1 = compound.in_compartment(c1)\n            compound2 = compound.in_compartment(c2)\n            pair = compound1, compound2\n            if pair in added_pairs:\n                continue\n\n            rxnid_tp = create_transport_id(reactions, compound1, compound2)\n\n            reaction_tp = Reaction(Direction.Both, {\n                compound1: -1,\n                compound2: 1\n            })\n            if reaction_tp not in all_reactions:\n                model.database.set_reaction(rxnid_tp, reaction_tp)\n                reactions.add(rxnid_tp)\n            else:\n                rxnid_tp = all_reactions[reaction_tp]\n\n            if not model.has_reaction(rxnid_tp):\n                added.add(rxnid_tp)\n            model.add_reaction(rxnid_tp)\n            added_pairs.add(pair)\n\n    return added"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_extended_model(model, db_penalty=None, ex_penalty=None,\n                          tp_penalty=None, penalties=None):\n    \"\"\"Create an extended model for gap-filling.\n\n    Create a :class:`psamm.metabolicmodel.MetabolicModel` with\n    all reactions added (the reaction database in the model is taken\n    to be the universal database) and also with artificial exchange\n    and transport reactions added. Return the extended\n    :class:`psamm.metabolicmodel.MetabolicModel`\n    and a weight dictionary for added reactions in that model.\n\n    Args:\n        model: :class:`psamm.datasource.native.NativeModel`.\n        db_penalty: penalty score for database reactions, default is `None`.\n        ex_penalty: penalty score for exchange reactions, default is `None`.\n        tb_penalty: penalty score for transport reactions, default is `None`.\n        penalties: a dictionary of penalty scores for database reactions.\n    \"\"\"\n\n    # Create metabolic model\n    model_extended = model.create_metabolic_model()\n    extra_compartment = model.extracellular_compartment\n\n    compartment_ids = set(c.id for c in model.compartments)\n\n    # Add database reactions to extended model\n    if len(compartment_ids) > 0:\n        logger.info(\n            'Using all database reactions in compartments: {}...'.format(\n                ', '.join('{}'.format(c) for c in compartment_ids)))\n        db_added = add_all_database_reactions(model_extended, compartment_ids)\n    else:\n        logger.warning(\n            'No compartments specified in the model; database reactions will'\n            ' not be used! Add compartment specification to model to include'\n            ' database reactions for those compartments.')\n        db_added = set()\n\n    # Add exchange reactions to extended model\n    logger.info(\n        'Using artificial exchange reactions for compartment: {}...'.format(\n            extra_compartment))\n    ex_added = add_all_exchange_reactions(\n        model_extended, extra_compartment, allow_duplicates=True)\n\n    # Add transport reactions to extended model\n    boundaries = model.compartment_boundaries\n    if len(boundaries) > 0:\n        logger.info(\n            'Using artificial transport reactions for the compartment'\n            ' boundaries: {}...'.format(\n                '; '.join('{}<->{}'.format(c1, c2) for c1, c2 in boundaries)))\n        tp_added = add_all_transport_reactions(\n            model_extended, boundaries, allow_duplicates=True)\n    else:\n        logger.warning(\n            'No compartment boundaries specified in the model;'\n            ' artificial transport reactions will not be used!')\n        tp_added = set()\n\n    # Add penalty weights on reactions\n    weights = {}\n    if db_penalty is not None:\n        weights.update((rxnid, db_penalty) for rxnid in db_added)\n    if tp_penalty is not None:\n        weights.update((rxnid, tp_penalty) for rxnid in tp_added)\n    if ex_penalty is not None:\n        weights.update((rxnid, ex_penalty) for rxnid in ex_added)\n\n    if penalties is not None:\n        for rxnid, penalty in iteritems(penalties):\n            weights[rxnid] = penalty\n    return model_extended, weights", "response": "Create an extended model for gap - filling."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns formula balance command", "response": "def run(self):\n        \"\"\"Run formula balance command\"\"\"\n\n        # Create a set of excluded reactions\n        exclude = set(self._args.exclude)\n        count = 0\n        unbalanced = 0\n        unchecked = 0\n        for reaction, result in formula_balance(self._model):\n            count += 1\n\n            if reaction.id in exclude or reaction.equation is None:\n                continue\n\n            if result is None:\n                unchecked += 1\n                continue\n\n            left_form, right_form = result\n            if right_form != left_form:\n                unbalanced += 1\n                right_missing, left_missing = Formula.balance(\n                    right_form, left_form)\n\n                print('{}\\t{}\\t{}\\t{}\\t{}'.format(\n                    reaction.id, left_form, right_form,\n                    left_missing, right_missing))\n\n        logger.info('Unbalanced reactions: {}/{}'.format(unbalanced, count))\n        logger.info('Unchecked reactions due to missing formula: {}/{}'.format(\n            unchecked, count))\n        logger.info('Reactions excluded from check: {}/{}'.format(\n            len(exclude), count))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the reaction ID to a reaction given by reaction_id.", "response": "def set_reaction(self, reaction_id, reaction):\n        \"\"\"Set the reaction ID to a reaction given by a\n        :class:`Reaction <psamm.reaction.Reaction>`\n\n        If an existing reaction exists with the given reaction ID it will be\n        overwritten.\n        \"\"\"\n\n        # Overwrite previous reaction if the same id is used\n        if reaction_id in self._reactions:\n            # Clean up compound to reaction mapping\n            for compound in self._reactions[reaction_id]:\n                self._compound_reactions[compound].remove(reaction_id)\n\n            self._reversible.discard(reaction_id)\n            del self._reactions[reaction_id]\n\n        self._reactions[reaction_id] = OrderedDict()\n        # Add values to global (sparse) stoichiometric matrix\n        # Compounds that occur on both sides will get a stoichiometric\n        # value based on the sum of the signed values on each side.\n        for compound, _ in reaction.compounds:\n            if compound not in self._reactions[reaction_id]:\n                self._reactions[reaction_id][compound] = 0\n                self._compound_reactions[compound].add(reaction_id)\n        for compound, value in reaction.left:\n            self._reactions[reaction_id][compound] -= value\n        for compound, value in reaction.right:\n            self._reactions[reaction_id][compound] += value\n\n        # Remove reaction from compound reactions if the resulting\n        # stoichiometric value turned out to be zero.\n        zero_compounds = set()\n        for compound, value in iteritems(self._reactions[reaction_id]):\n            if value == 0:\n                zero_compounds.add(compound)\n\n        for compound in zero_compounds:\n            del self._reactions[reaction_id][compound]\n            self._compound_reactions[compound].remove(reaction_id)\n\n        if reaction.direction != Direction.Forward:\n            self._reversible.add(reaction_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push_log(self, info, level=None, *args, **kwargs):\n        if args:\n            msg = info % args\n        else:\n            msg = info\n        try:\n            puts('docker: {0}'.format(msg))\n        except UnicodeDecodeError:\n            puts('docker: -- non-printable output --')", "response": "Prints the log as usual for fabric output enhanced with the prefix docker."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push_progress(self, status, object_id, progress):\n        fastprint(progress_fmt(status, object_id, progress), end='\\n')", "response": "Prints a progress bar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        try:\n            super(DockerFabricClient, self).close()\n        finally:\n            if self._tunnel is not None:\n                self._tunnel.close()", "response": "Closes the connection and any tunnels created for it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build(self, tag, **kwargs):\n        self.push_log(\"Building image '{0}'.\".format(tag))\n        set_raise_on_error(kwargs)\n        try:\n            return super(DockerFabricClient, self).build(tag, **kwargs)\n        except DockerStatusError as e:\n            error(e.message)", "response": "Build an image with the specified tag."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_container(self, image, name=None, **kwargs):\n        name_str = \" '{0}'\".format(name) if name else \"\"\n        self.push_log(\"Creating container{0} from image '{1}'.\".format(name_str, image))\n        return super(DockerFabricClient, self).create_container(image, name=name, **kwargs)", "response": "Creates a container from an image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy a tarball from a container to a local file.", "response": "def copy_resource(self, container, resource, local_filename):\n        \"\"\"\n        Identical to :meth:`dockermap.client.base.DockerClientWrapper.copy_resource` with additional logging.\n        \"\"\"\n        self.push_log(\"Receiving tarball for resource '{0}:{1}' and storing as {2}\".format(container, resource, local_filename))\n        super(DockerFabricClient, self).copy_resource(container, resource, local_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cleanup_images(self, remove_old=False, keep_tags=None, **kwargs):\n        self.push_log(\"Checking images for dependent images and containers.\")\n        set_raise_on_error(kwargs, False)\n        return super(DockerFabricClient, self).cleanup_images(remove_old=remove_old, keep_tags=keep_tags, **kwargs)", "response": "This method is used to clean up images that are not part of a container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding to add additional logging to the image API.", "response": "def import_image(self, image=None, tag='latest', **kwargs):\n        \"\"\"\n        Identical to :meth:`docker.api.image.ImageApiMixin.import_image` with additional logging.\n        \"\"\"\n        self.push_log(\"Fetching image '{0}' from registry.\".format(image))\n        return super(DockerFabricClient, self).import_image(image=image, tag=tag, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlogin to the Docker registry.", "response": "def login(self, **kwargs):\n        \"\"\"\n        Identical to :meth:`dockermap.client.base.DockerClientWrapper.login` with two enhancements:\n\n        * additional logging;\n        * login parameters can be passed through ``kwargs``, or set as default using the following ``env``\n          variables:\n\n          * ``env.docker_registry_user`` (kwarg: ``username``),\n          * ``env.docker_registry_password`` (kwarg: ``password``),\n          * ``env.docker_registry_mail`` (kwarg: ``email``),\n          * ``env.docker_registry_repository`` (kwarg: ``registry``),\n          * ``env.docker_registry_insecure`` (kwarg: ``insecure_registry``).\n        \"\"\"\n        c_user = kwargs.pop('username', env.get('docker_registry_user'))\n        c_pass = kwargs.pop('password', env.get('docker_registry_password'))\n        c_mail = kwargs.pop('email', env.get('docker_registry_mail'))\n        c_registry = kwargs.pop('registry', env.get('docker_registry_repository'))\n        c_insecure = kwargs.pop('insecure_registry', env.get('docker_registry_insecure'))\n        if super(DockerFabricClient, self).login(c_user, password=c_pass, email=c_mail, registry=c_registry,\n                                                 insecure_registry=c_insecure, **kwargs):\n            self.push_log(\"Login at registry '{0}' succeeded.\".format(c_registry))\n            return True\n        self.push_log(\"Login at registry '{0}' failed.\".format(c_registry))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pull(self, repository, tag=None, stream=True, **kwargs):\n        c_insecure = kwargs.pop('insecure_registry', env.get('docker_registry_insecure'))\n        set_raise_on_error(kwargs)\n        try:\n            return super(DockerFabricClient, self).pull(repository, tag=tag, stream=stream,\n                                                        insecure_registry=c_insecure, **kwargs)\n        except DockerStatusError as e:\n            error(e.message)", "response": "Wrapper for DockerClientWrapper. pull"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restart(self, container, **kwargs):\n        self.push_log(\"Restarting container '{0}'.\".format(container))\n        super(DockerFabricClient, self).restart(container, **kwargs)", "response": "Identical to :meth:`docker.api.container.ContainerApiMixin.restart` with additional logging."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_all_containers(self, **kwargs):\n        self.push_log(\"Fetching container list.\")\n        set_raise_on_error(kwargs)\n        super(DockerFabricClient, self).remove_all_containers(**kwargs)", "response": "Overridden to remove all containers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove an image from the cluster.", "response": "def remove_image(self, image, **kwargs):\n        \"\"\"\n        Identical to :meth:`dockermap.client.base.DockerClientWrapper.remove_image` with additional logging.\n        \"\"\"\n        self.push_log(\"Removing image '{0}'.\".format(image))\n        set_raise_on_error(kwargs)\n        super(DockerFabricClient, self).remove_image(image, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_image(self, image, local_filename):\n        self.push_log(\"Receiving tarball for image '{0}' and storing as '{1}'\".format(image, local_filename))\n        super(DockerFabricClient, self).save_image(image, local_filename)", "response": "Save the tarball for the given image and store it as local_filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, container, **kwargs):\n        self.push_log(\"Starting container '{0}'.\".format(container))\n        super(DockerFabricClient, self).start(container, **kwargs)", "response": "Identical to :meth:`docker.api.container.ContainerApiMixin.start` with additional logging."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self, container, **kwargs):\n        self.push_log(\"Stopping container '{0}'.\".format(container))\n        super(DockerFabricClient, self).stop(container, **kwargs)", "response": "Identical to :meth:`dockermap.client.base.DockerClientWrapper.stop` with additional logging."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait(self, container, **kwargs):\n        self.push_log(\"Waiting for container '{0}'.\".format(container))\n        super(DockerFabricClient, self).wait(container, **kwargs)", "response": "Waits for a container to be ready."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ranged_property(min=None, max=None):\n    min_value = -_INF if min is None else min\n    max_value = _INF if max is None else max\n    return lambda fget: RangedProperty(\n        fget, fmin=lambda obj: min_value, fmax=lambda obj: max_value)", "response": "Decorator for creating ranged property with fixed bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value(self):\n        if self._prop.fget is None:\n            raise AttributeError('Unable to read attribute')\n        return self._prop.fget(self._obj)", "response": "Return the value of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the minimum value of the object.", "response": "def min(self):\n        \"\"\"Minimum value.\"\"\"\n        if self._prop.fmin is None:\n            return -_INF\n        return self._prop.fmin(self._obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefining variables within the namespace.", "response": "def define(self, names, **kwargs):\n        \"\"\"Define variables within the namespace.\n\n        This is similar to :meth:`.Problem.define` except that names must be\n        given as an iterable. This method accepts the same keyword arguments\n        as :meth:`.Problem.define`.\n        \"\"\"\n        define_kwargs = dict(self._define_kwargs)\n        define_kwargs.update(kwargs)\n        self._problem.define(\n            *((self, name) for name in names), **define_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a variable set of the given names in the namespace.", "response": "def set(self, names):\n        \"\"\"Return a variable set of the given names in the namespace.\n\n        >>> v = prob.namespace(name='v')\n        >>> v.define([1, 2, 5], lower=0, upper=10)\n        >>> prob.add_linear_constraints(v.set([1, 2]) >= 4)\n        \"\"\"\n        return self._problem.set((self, name) for name in names)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expr(self, items):\n        return Expression({(self, name): value for name, value in items})", "response": "Return the sum of each name multiplied by a coefficient."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _evaluate_expression(self, expr):\n        def cast_value(v):\n            # Convert Decimal to Fraction to allow successful multiplication\n            # by either float (most solvers) or Fraction (exact solver).\n            # Multiplying Fraction and float results in a float, and\n            # multiplying Fraction and Fraction result in Fraction, which are\n            # exactly the types of results we want.\n            if isinstance(v, Decimal):\n                return Fraction(v)\n            return v\n\n        total = cast_value(expr.offset)\n        for var, value in expr.values():\n            value = cast_value(value)\n            if not isinstance(var, Product):\n                total += self._get_value(var) * value\n            else:\n                total += reduce(\n                    operator.mul, (self._get_value(v) for v in var), value)\n        return total", "response": "Evaluate an expression using _get_value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_value(self, expression):\n        if isinstance(expression, Expression):\n            return self._evaluate_expression(expression)\n        elif not self._has_variable(expression):\n            raise ValueError('Unknown expression: {}'.format(expression))\n\n        return self._get_value(expression)", "response": "Get value of variable or expression in result\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef define(self, *names, **kwargs):\n        names = tuple(names)\n        for name in names:\n            if name in self._variables:\n                raise ValueError('Variable already defined: {!r}'.format(name))\n\n        lower = kwargs.get('lower', None)\n        upper = kwargs.get('upper', None)\n        vartype = kwargs.get('types', None)\n\n        # Repeat values if a scalar is given\n        if lower is None or isinstance(lower, numbers.Number):\n            lower = repeat(lower, len(names))\n        if upper is None or isinstance(upper, numbers.Number):\n            upper = repeat(upper, len(names))\n        if vartype is None or vartype in (\n                VariableType.Continuous, VariableType.Binary,\n                VariableType.Integer):\n            vartype = repeat(vartype, len(names))\n\n        lp_names = tuple(next(self._var_names) for name in names)\n\n        # Assign default values\n        lower = (-gurobipy.GRB.INFINITY if value is None else float(value)\n                 for value in lower)\n        upper = (gurobipy.GRB.INFINITY if value is None else float(value)\n                 for value in upper)\n        vartype = tuple(VariableType.Continuous if value is None else value\n                        for value in vartype)\n\n        self._variables.update(zip(names, lp_names))\n        for name, lb, ub, vt in zip(lp_names, lower, upper, vartype):\n            self._p.addVar(name=name, lb=lb, ub=ub, vtype=self.VARTYPE_MAP[vt])\n\n        self._p.update()", "response": "Define a variable in the problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_constraints(self, relation):\n        names = []\n        expression = relation.expression\n        for value_set in expression.value_sets():\n            name = next(self._constr_names)\n            self._p.addConstr(\n                self._grb_expr_from_value_set(value_set),\n                self.CONSTR_SENSE_MAP[relation.sense],\n                -float(expression.offset), name)\n            names.append(name)\n\n        self._p.update()\n\n        return names", "response": "Add the given relation as one or more constraints.\n        returns a list of the names of the constraints added."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_objective(self, expression):\n\n        if isinstance(expression, numbers.Number):\n            # Allow expressions with no variables as objective,\n            # represented as a number\n            expression = Expression()\n\n        self._p.setObjective(\n            self._grb_expr_from_value_set(expression.values()))", "response": "Set linear objective of problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset type of problem (maximize or minimize).", "response": "def set_objective_sense(self, sense):\n        \"\"\"Set type of problem (maximize or minimize).\"\"\"\n\n        if sense not in (ObjectiveSense.Minimize, ObjectiveSense.Maximize):\n            raise ValueError('Invalid objective sense')\n\n        self._p.ModelSense = self.OBJ_SENSE_MAP[sense]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef solve_unchecked(self, sense=None):\n        if sense is not None:\n            self.set_objective_sense(sense)\n        self._p.optimize()\n\n        self._result = Result(self)\n        return self._result", "response": "Solve problem and return result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn whether a solution was found.", "response": "def success(self):\n        \"\"\"Return boolean indicating whether a solution was found.\"\"\"\n        self._check_valid()\n        return self._problem._p.Status == gurobipy.GRB.OPTIMAL"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns value of variable in solution.", "response": "def _get_value(self, var):\n        \"\"\"Return value of variable in solution.\"\"\"\n        return self._problem._p.getVarByName(self._problem._variables[var]).x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_python(self, message, namespace):\n\n        # Importing readline will in some cases print weird escape\n        # characters to stdout. To avoid this we only import readline\n        # and related packages at this point when we are certain\n        # they are needed.\n        from code import InteractiveConsole\n        import readline\n        import rlcompleter\n\n        readline.set_completer(rlcompleter.Completer(namespace).complete)\n        readline.parse_and_bind('tab: complete')\n        console = InteractiveConsole(namespace)\n        console.interact(message)", "response": "Open interactive python console"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning unique signature object for reaction.", "response": "def reaction_signature(eq, direction=False, stoichiometry=False):\n    \"\"\"Return unique signature object for :class:`Reaction`.\n\n    Signature objects are hashable, and compare equal only if the reactions\n    are considered the same according to the specified rules.\n\n    Args:\n        direction: Include reaction directionality when considering equality.\n        stoichiometry: Include stoichiometry when considering equality.\n    \"\"\"\n    def compounds_sig(compounds):\n        if stoichiometry:\n            return tuple(sorted(compounds))\n        else:\n            return tuple(sorted(compound for compound, _ in compounds))\n\n    left = compounds_sig(eq.left)\n    right = compounds_sig(eq.right)\n\n    if left < right:\n        reaction_sig = left, right\n        direction_sig = eq.direction\n    else:\n        reaction_sig = right, left\n        direction_sig = eq.direction.flipped()\n\n    if direction:\n        return reaction_sig, direction_sig\n    return reaction_sig"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n\n        # Create dictonary of signatures\n        database_signatures = {}\n        for entry in self._model.reactions:\n            signature = reaction_signature(\n                entry.equation, direction=self._args.compare_direction,\n                stoichiometry=self._args.compare_stoichiometry)\n            database_signatures.setdefault(signature, set()).add(\n                (entry.id, entry.equation, entry.filemark))\n\n        for reaction_set in itervalues(database_signatures):\n            if len(reaction_set) > 1:\n                print('Found {} duplicate reactions:'.format(\n                    len(reaction_set)))\n                for reaction, equation, filemark in reaction_set:\n                    result = ' - {}: {}'.format(reaction, equation)\n                    if filemark is not None:\n                        result += ' (found in {})'.format(filemark)\n                    print(result)", "response": "Run check for duplicates"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the overall charge for the specified reaction.", "response": "def reaction_charge(reaction, compound_charge):\n    \"\"\"Calculate the overall charge for the specified reaction.\n\n    Args:\n        reaction: :class:`psamm.reaction.Reaction`.\n        compound_charge: a map from each compound to charge values.\n    \"\"\"\n\n    charge_sum = 0.0\n    for compound, value in reaction.compounds:\n        charge = compound_charge.get(compound.name, float('nan'))\n        charge_sum += charge * float(value)\n    return charge_sum"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef charge_balance(model):\n\n    compound_charge = {}\n    for compound in model.compounds:\n        if compound.charge is not None:\n            compound_charge[compound.id] = compound.charge\n\n    for reaction in model.reactions:\n        charge = reaction_charge(reaction.equation, compound_charge)\n        yield reaction, charge", "response": "Calculate the overall charge for all reactions in the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates formula compositions for both sides of the specified reaction.", "response": "def reaction_formula(reaction, compound_formula):\n    \"\"\"Calculate formula compositions for both sides of the specified reaction.\n\n    If the compounds in the reaction all have formula, then calculate and\n    return the chemical compositions for both sides, otherwise return `None`.\n\n    Args:\n        reaction: :class:`psamm.reaction.Reaction`.\n        compound_formula: a map from compound id to formula.\n    \"\"\"\n\n    def multiply_formula(compound_list):\n        for compound, count in compound_list:\n            yield count * compound_formula[compound.name]\n\n    for compound, _ in reaction.compounds:\n        if compound.name not in compound_formula:\n            return None\n    else:\n        left_form = reduce(\n            operator.or_, multiply_formula(reaction.left), Formula())\n        right_form = reduce(\n            operator.or_, multiply_formula(reaction.right), Formula())\n    return left_form, right_form"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating formula compositions for each reaction.", "response": "def formula_balance(model):\n    \"\"\"Calculate formula compositions for each reaction.\n\n    Call :func:`reaction_formula` for each reaction.\n    Yield (reaction, result) pairs, where result has two formula compositions\n    or `None`.\n\n    Args:\n        model: :class:`psamm.datasource.native.NativeModel`.\n    \"\"\"\n\n    # Mapping from compound id to formula\n    compound_formula = {}\n    for compound in model.compounds:\n        if compound.formula is not None:\n            try:\n                f = Formula.parse(compound.formula).flattened()\n                compound_formula[compound.id] = f\n            except ParseError as e:\n                msg = 'Error parsing formula for compound {}:\\n{}\\n{}'.format(\n                    compound.id, e, compound.formula)\n                if e.indicator is not None:\n                    msg += '\\n{}'.format(e.indicator)\n                logger.warning(msg)\n\n    for reaction in model.reactions:\n        yield reaction, reaction_formula(reaction.equation, compound_formula)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the flux consistency check command.", "response": "def run(self):\n        \"\"\"Run flux consistency check command\"\"\"\n\n        # Load compound information\n        def compound_name(id):\n            if id not in self._model.compounds:\n                return id\n            return self._model.compounds[id].properties.get('name', id)\n\n        epsilon = self._args.epsilon\n\n        if self._args.unrestricted:\n            # Allow all exchange reactions with no flux limits\n            for reaction in self._mm.reactions:\n                if self._mm.is_exchange(reaction):\n                    del self._mm.limits[reaction].bounds\n\n        loop_removal = self._get_loop_removal_option()\n        enable_tfba = loop_removal == 'tfba'\n        enable_fastcore = self._args.fastcore\n\n        if enable_tfba and enable_fastcore:\n            self.argument_error(\n                'Using Fastcore with thermodynamic constraints'\n                ' is not supported!')\n        start_time = time.time()\n\n        if enable_fastcore:\n            solver = self._get_solver()\n            try:\n                inconsistent = set(fastcore.fastcc(\n                    self._mm, epsilon, solver=solver))\n            except fluxanalysis.FluxBalanceError as e:\n                self.report_flux_balance_error(e)\n        else:\n            if enable_tfba:\n                solver = self._get_solver(integer=True)\n            else:\n                solver = self._get_solver()\n\n            if self._args.reduce_lp:\n                logger.info('Running with reduced number of LP problems.')\n                try:\n                    inconsistent = set(\n                        fluxanalysis.consistency_check(\n                            self._mm, self._mm.reactions, epsilon,\n                            tfba=enable_tfba, solver=solver))\n                except fluxanalysis.FluxBalanceError as e:\n                    self.report_flux_balance_error(e)\n            else:\n                logger.info('Using flux bounds to determine consistency.')\n                try:\n                    inconsistent = set(self._run_fva_fluxcheck(\n                        self._mm, solver, enable_tfba, epsilon))\n                except FluxCheckFVATaskError:\n                    self.report_flux_balance_error()\n\n        logger.info('Solving took {:.2f} seconds'.format(\n            time.time() - start_time))\n\n        # Count the number of reactions that are fixed at zero. While these\n        # reactions are still inconsistent, they are inconsistent because they\n        # have been explicitly disabled.\n        disabled_exchange = 0\n        disabled_internal = 0\n\n        count_exchange = 0\n        total_exchange = 0\n\n        count_internal = 0\n        total_internal = 0\n\n        # Print result\n        for reaction in sorted(self._mm.reactions):\n            disabled = self._mm.limits[reaction].bounds == (0, 0)\n\n            if self._mm.is_exchange(reaction):\n                total_exchange += 1\n                count_exchange += int(reaction in inconsistent)\n                disabled_exchange += int(disabled)\n            else:\n                total_internal += 1\n                count_internal += int(reaction in inconsistent)\n                disabled_internal += int(disabled)\n\n            if reaction in inconsistent:\n                rx = self._mm.get_reaction(reaction)\n                rxt = rx.translated_compounds(compound_name)\n                print('{}\\t{}'.format(reaction, rxt))\n\n        logger.info('Model has {}/{} inconsistent internal reactions'\n                    ' ({} disabled by user)'.format(\n                        count_internal, total_internal, disabled_internal))\n        logger.info('Model has {}/{} inconsistent exchange reactions'\n                    ' ({} disabled by user)'.format(\n                        count_exchange, total_exchange, disabled_exchange))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun charge balance command", "response": "def run(self):\n        \"\"\"Run charge balance command\"\"\"\n\n        # Load compound information\n        def compound_name(id):\n            if id not in self._model.compounds:\n                return id\n            return self._model.compounds[id].properties.get('name', id)\n\n        # Create a set of excluded reactions\n        exclude = set(self._args.exclude)\n        count = 0\n        unbalanced = 0\n        unchecked = 0\n        for reaction, charge in charge_balance(self._model):\n            count += 1\n\n            if reaction.id in exclude or reaction.equation is None:\n                continue\n\n            if math.isnan(charge):\n                logger.debug('Not checking reaction {};'\n                             ' missing charge'.format(reaction.id))\n                unchecked += 1\n            elif abs(charge) > self._args.epsilon:\n                unbalanced += 1\n                rxt = reaction.equation.translated_compounds(compound_name)\n                print('{}\\t{}\\t{}'.format(reaction.id, charge, rxt))\n\n        logger.info('Unbalanced reactions: {}/{}'.format(unbalanced, count))\n        logger.info('Unchecked reactions due to missing charge: {}/{}'.format(\n            unchecked, count))\n        logger.info('Reactions excluded from check: {}/{}'.format(\n            len(exclude), count))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_property_type_from_traits(trait_set):\n    wanted_traits = set(trait_set)\n    stock_types = dict(\n        (k, v) for k, v in PROPERTY_TYPES.items() if\n        set(k).issubset(wanted_traits)\n    )\n\n    traits_available = set()\n    for key in stock_types.keys():\n        traits_available.update(key)\n\n    missing_traits = wanted_traits - traits_available\n    if missing_traits:\n        raise exc.PropertyTypeMixinNotPossible(\n            traitlist=repr(trait_set),\n            missing=repr(tuple(sorted(missing_traits))),\n        )\n\n    made_types = []\n    # mix together property types, until we have made the right type.\n    while trait_set not in PROPERTY_TYPES:\n\n        # be somewhat deterministic: always start with types which provide the\n        # 'first' trait on the list\n        start_with = set(\n            k for k in stock_types.keys() if k and k[0] == trait_set[0]\n        )\n\n        # prefer extending already composed trait sets, by only adding to the\n        # longest ones\n        longest = max(len(x) for x in start_with)\n        made_type = False\n\n        for base in sorted(start_with):\n            if len(base) != longest:\n                continue\n\n            # pick a type to join on which reduces the short-fall as much as\n            # possible.\n            shortfall = len(wanted_traits) - len(base)\n            mix_in = None\n            for other in sorted(stock_types.keys()):\n                # skip mixes that will fail; this means that the type on the\n                # list is a trait subset of 'base'\n                mixed_traits = tuple(sorted(set(base) | set(other)))\n                if mixed_traits in PROPERTY_TYPES:\n                    continue\n\n                this_shortfall = len(wanted_traits - (set(base) | set(other)))\n                if this_shortfall < shortfall:\n                    mix_in = other\n                    mixed_in_product = mixed_traits\n                    shortfall = this_shortfall\n                    if shortfall == 0:\n                        break\n\n            if mix_in:\n                base_type = PROPERTY_TYPES[base]\n                other_type = PROPERTY_TYPES[other]\n                new_name = _merge_camel_case_names(\n                    base_type.__name__, other_type.__name__,\n                )\n                new_type = type(new_name, (base_type, other_type), {})\n                stock_types[mixed_in_product] = new_type\n                made_types.append(new_type)\n                made_type = True\n\n        if not made_type:\n            raise exc.PropertyTypeMixinFailure(\n                traitlist=repr(trait_set),\n                newtypelist=\", \".join(\n                    \"%r (%s)\" % (x.traits, x.__name__) for x in made_types\n                )\n            )", "response": "Creates a property type from a set of traits."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve source to filepath if it is a directory.", "response": "def _resolve_source(self, source):\n        \"\"\"Resolve source to filepath if it is a directory.\"\"\"\n        if os.path.isdir(source):\n            sources = glob.glob(os.path.join(source, '*.sbml'))\n            if len(sources) == 0:\n                raise ModelLoadError('No .sbml file found in source directory')\n            elif len(sources) > 1:\n                raise ModelLoadError(\n                    'More than one .sbml file found in source directory')\n            return sources[0]\n        return source"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting and return model instance.", "response": "def import_model(self, source):\n        \"\"\"Import and return model instance.\"\"\"\n        source = self._resolve_source(source)\n        self._context = FilePathContext(source)\n        with self._context.open() as f:\n            self._reader = self._open_reader(f)\n\n        return self._reader.create_model()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_model(self, source):\n        model = super(StrictImporter, self).import_model(source)\n\n        # Translate entries into dict-based entries.\n        sbml.convert_model_entries(\n            model, convert_id=lambda entry: entry.id,\n            translate_compartment=self._translate_compartment,\n            translate_compound=self._translate_compound,\n            translate_reaction=self._translate_reaction)\n\n        return model", "response": "Import and return model instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport and return model instance.", "response": "def import_model(self, source):\n        \"\"\"Import and return model instance.\"\"\"\n        model = super(NonstrictImporter, self).import_model(source)\n        sbml.convert_sbml_model(model)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the flipped version of this direction.", "response": "def flipped(self):\n        \"\"\"Return the flipped version of this direction.\"\"\"\n        forward, reverse = self.value\n        return self.__class__((reverse, forward))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the flux variability command", "response": "def run(self):\n        \"\"\"Run flux variability command\"\"\"\n\n        # Load compound information\n        def compound_name(id):\n            if id not in self._model.compounds:\n                return id\n            return self._model.compounds[id].properties.get('name', id)\n\n        reaction = self._get_objective()\n        if not self._mm.has_reaction(reaction):\n            self.fail(\n                'Specified reaction is not in model: {}'.format(reaction))\n\n        loop_removal = self._get_loop_removal_option()\n        enable_tfba = loop_removal == 'tfba'\n        if enable_tfba:\n            solver = self._get_solver(integer=True)\n        else:\n            solver = self._get_solver()\n\n        start_time = time.time()\n\n        try:\n            fba_fluxes = dict(fluxanalysis.flux_balance(\n                self._mm, reaction, tfba=False, solver=solver))\n        except fluxanalysis.FluxBalanceError as e:\n            self.report_flux_balance_error(e)\n\n        threshold = self._args.threshold\n        if threshold.relative:\n            threshold.reference = fba_fluxes[reaction]\n\n        logger.info('Setting objective threshold to {}'.format(\n            threshold))\n\n        handler_args = (\n            self._mm, solver, enable_tfba, float(threshold), reaction)\n        executor = self._create_executor(\n            FVATaskHandler, handler_args, cpus_per_worker=2)\n\n        def iter_results():\n            results = {}\n            with executor:\n                for (reaction_id, direction), value in executor.imap_unordered(\n                        product(self._mm.reactions, (1, -1)), 16):\n                    if reaction_id not in results:\n                        results[reaction_id] = value\n                        continue\n\n                    other_value = results[reaction_id]\n                    if direction == -1:\n                        bounds = value, other_value\n                    else:\n                        bounds = other_value, value\n\n                    yield reaction_id, bounds\n\n            executor.join()\n\n        for reaction_id, (lower, upper) in iter_results():\n            rx = self._mm.get_reaction(reaction_id)\n            rxt = rx.translated_compounds(compound_name)\n            print('{}\\t{}\\t{}\\t{}'.format(reaction_id, lower, upper, rxt))\n\n        logger.info('Solving took {:.2f} seconds'.format(\n            time.time() - start_time))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef placeholder(type_):\n    typetuple = type_ if isinstance(type_, tuple) else (type_,)\n    if any in typetuple:\n        typetuple = any\n    if typetuple not in EMPTY_VALS:\n        EMPTY_VALS[typetuple] = EmptyVal(typetuple)\n    return EMPTY_VALS[typetuple]", "response": "Returns the EmptyVal instance for the given type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over an iterable containing either type objects or tuples of type objects and yields once for every type object found.", "response": "def itertypes(iterable):\n    \"\"\"Iterates over an iterable containing either type objects or tuples of\n    type objects and yields once for every type object found.\"\"\"\n    seen = set()\n    for entry in iterable:\n        if isinstance(entry, tuple):\n            for type_ in entry:\n                if type_ not in seen:\n                    seen.add(type_)\n                    yield type_\n        else:\n            if entry not in seen:\n                seen.add(entry)\n                yield entry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the remote path exists and is a directory.", "response": "def is_directory(path, use_sudo=False):\n    \"\"\"\n    Check if the remote path exists and is a directory.\n\n    :param path: Remote path to check.\n    :type path: unicode\n    :param use_sudo: Use the `sudo` command.\n    :type use_sudo: bool\n    :return: `True` if the path exists and is a directory; `False` if it exists, but is a file; `None` if it does not\n      exist.\n    :rtype: bool or ``None``\n    \"\"\"\n    result = single_line_stdout('if [[ -f {0} ]]; then echo 0; elif [[ -d {0} ]]; then echo 1; else echo -1; fi'.format(path), sudo=use_sudo, quiet=True)\n    if result == '0':\n        return False\n    elif result == '1':\n        return True\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a temporary directory on the remote machine. The directory is removed when no longer needed. Failure to do so will be ignored. :param apply_chown: Optional; change the owner of the directory. :type apply_chown: unicode :param apply_chmod: Optional; change the permissions of the directory. :type apply_chmod: unicode :param remove_using_sudo: Use sudo for removing the directory. ``None`` (default) means it is used depending on whether ``apply_chown`` has been set. :type remove_using_sudo: bool | NoneType :param remove_force: Force the removal. :type remove_force: bool :return: Path to the temporary directory. :rtype: unicode", "response": "def temp_dir(apply_chown=None, apply_chmod=None, remove_using_sudo=None, remove_force=False):\n    \"\"\"\n    Creates a temporary directory on the remote machine. The directory is removed when no longer needed. Failure to do\n    so will be ignored.\n\n    :param apply_chown: Optional; change the owner of the directory.\n    :type apply_chown: unicode\n    :param apply_chmod: Optional; change the permissions of the directory.\n    :type apply_chmod: unicode\n    :param remove_using_sudo: Use sudo for removing the directory. ``None`` (default) means it is used depending on\n     whether ``apply_chown`` has been set.\n    :type remove_using_sudo: bool | NoneType\n    :param remove_force: Force the removal.\n    :type remove_force: bool\n    :return: Path to the temporary directory.\n    :rtype: unicode\n    \"\"\"\n    path = get_remote_temp()\n    try:\n        if apply_chmod:\n            run(chmod(apply_chmod, path))\n        if apply_chown:\n            if remove_using_sudo is None:\n                remove_using_sudo = True\n            sudo(chown(apply_chown, path))\n        yield path\n    finally:\n        remove_ignore(path, use_sudo=remove_using_sudo, force=remove_force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a local temporary directory.", "response": "def local_temp_dir():\n    \"\"\"\n    Creates a local temporary directory. The directory is removed when no longer needed. Failure to do\n    so will be ignored.\n\n    :return: Path to the temporary directory.\n    :rtype: unicode\n    \"\"\"\n    path = tempfile.mkdtemp()\n    yield path\n    shutil.rmtree(path, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a TAR file to a destination path.", "response": "def extract_tar(filename, dest_path, **kwargs):\n    \"\"\"\n    Extracts a TAR archive. All element names starting with ``/`` (indicating an absolute path) or that contain ``..``\n    as references to a parent directory are not extracted.\n\n    :param filename: Path to the tar file.\n    :type filename: unicode\n    :param dest_path: Destination path to extract the contents to.\n    :type dest_path: unicode\n    :param kwargs: Additional kwargs for opening the TAR file (:func:`tarfile.open`).\n    \"\"\"\n    with tarfile.open(filename, 'r', **kwargs) as tf:\n        safe_members = [name for name in tf.getmembers() if _safe_name(name)]\n        if safe_members:\n            tf.extractall(dest_path, safe_members)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_body(self, environ=None):\n        body = dict(\n            status=self.code,\n            message=self.get_description(environ),\n        )\n\n        errors = self.get_errors()\n        if self.errors:\n            body['errors'] = errors\n\n        if self.code and (self.code >= 500) and hasattr(g, 'sentry_event_id'):\n            body['error_id'] = str(g.sentry_event_id)\n\n        return json.dumps(body)", "response": "Get the request body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_response(self, environ=None):\n        response = super(SameContentException, self).get_response(\n            environ=environ\n        )\n        if self.etag is not None:\n            response.set_etag(self.etag)\n        if self.last_modified is not None:\n            response.headers['Last-Modified'] = http_date(self.last_modified)\n        return response", "response": "Get a list of headers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record_id(object_, type_=None, selector=None, normalize_object_slot=None):\n    if type_ is None or isinstance(type_, tuple):\n        type_ = type(object_)\n\n    key_vals = list()\n    if hasattr(type_, \"primary_key\"):\n        pk_cols = type_.primary_key\n    elif object_.__hash__:\n        return object_\n    else:\n        raise exc.IdentityCrisis(\n            val=object_,\n            val_repr=repr(object_),\n            val_type=type_,\n            val_type_name=type_.__name__,\n        )\n    if selector and pk_cols and not all(\n        selector[(x.name,)] for x in pk_cols\n    ):\n        pk_cols = None\n\n    if not pk_cols and issubclass(\n        type_, normalize.coll.Collection\n    ):\n        # FIXME: unordered collections will rarely match each other\n        gen = (\n            object_.itertuples() if hasattr(object_, \"itertuples\") else\n            type_.coll_to_tuples(object_)\n        )\n        return tuple(\n            record_id(\n                v, type_.itemtype, selector[k], normalize_object_slot,\n            ) for k, v in gen if selector[(k,)]\n        ) if selector else tuple(\n            record_id(v, type_.itemtype, None, normalize_object_slot) for\n            k, v in gen\n        )\n\n    if not pk_cols:\n        all_properties = type_._sorted_properties\n        if selector:\n            all_properties = tuple(\n                x for x in all_properties if selector[(x.name,)]\n            )\n\n    for prop in pk_cols or all_properties:\n        val = getattr(object_, prop.name, None)\n        if normalize_object_slot:\n            val = normalize_object_slot(val, prop, object_)\n        _none = (\n            normalize_object_slot(None, prop, object_) if\n            normalize_object_slot else None\n        )\n        if val is not _none and prop.valuetype:\n            value_type_list = (\n                prop.valuetype if isinstance(prop.valuetype, tuple) else\n                (prop.valuetype,)\n            )\n            val_pk = ()\n            set_elements = 0\n            for value_type in value_type_list:\n                if issubclass(value_type, normalize.record.Record):\n                    pk = record_id(val, value_type,\n                                   selector[prop.name] if selector else None,\n                                   normalize_object_slot)\n                    pk_elements = len([x for x in pk if x is not None])\n                    if not val_pk or pk_elements > set_elements:\n                        val_pk = pk\n                        set_elements = pk_elements\n\n            val_pk = val_pk or val\n            try:\n                val_pk.__hash__()\n            except TypeError:\n                raise exc.KeyHashError(\n                    prop=str(prop),\n                    typename=type_.__name__,\n                )\n            key_vals.append(val_pk)\n        else:\n            key_vals.append(val)\n\n    return tuple(key_vals)", "response": "Implementation of id which is overridable and knows about record s primary_key property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a constant indicating the type of coupling.", "response": "def classify_coupling(coupling):\n    \"\"\"Return a constant indicating the type of coupling.\n\n    Depending on the type of coupling, one of the constants from\n    :class:`.CouplingClass` is returned.\n\n    Args:\n        coupling: Tuple of minimum and maximum flux ratio\n    \"\"\"\n    lower, upper = coupling\n\n    if lower is None and upper is None:\n        return CouplingClass.Uncoupled\n    elif lower is None or upper is None:\n        return CouplingClass.DirectionalReverse\n    elif lower == 0.0 and upper == 0.0:\n        return CouplingClass.Inconsistent\n    elif lower <= 0.0 and upper >= 0.0:\n        return CouplingClass.DirectionalForward\n    elif abs(lower - upper) < 1e-6:\n        return CouplingClass.Full\n    else:\n        return CouplingClass.Partial"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef solve(self, reaction_1, reaction_2):\n        # Update objective for reaction_1\n        self._prob.set_objective(self._vbow(reaction_1))\n\n        # Update constraint for reaction_2\n        if self._reaction_constr is not None:\n            self._reaction_constr.delete()\n\n        self._reaction_constr, = self._prob.add_linear_constraints(\n            self._vbow(reaction_2) == 1)\n\n        results = []\n        for sense in (lp.ObjectiveSense.Minimize, lp.ObjectiveSense.Maximize):\n            try:\n                result = self._prob.solve(sense)\n            except lp.SolverError:\n                results.append(None)\n            else:\n                results.append(result.get_value(self._vbow(reaction_1)))\n\n        return tuple(results)", "response": "Solve the flux coupling between two reactions and return the flux coupling between the minimum and maximum value of the v1 / v2 reaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform an action on the given container map and configuration.", "response": "def perform(action_name, container, **kwargs):\n    \"\"\"\n    Performs an action on the given container map and configuration.\n\n    :param action_name: Name of the action (e.g. ``update``).\n    :param container: Container configuration name.\n    :param kwargs: Keyword arguments for the action implementation.\n    \"\"\"\n    cf = container_fabric()\n    cf.call(action_name, container, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a script inside a container.", "response": "def script(container, script_path, fail_nonzero=False, upload_dir=False, **kwargs):\n    \"\"\"\n    Runs a script inside a container, which is created with all its dependencies. The container is removed after it\n    has been run, whereas the dependencies are not destroyed. The output is printed to the console.\n\n    :param container: Container configuration name.\n    :param script_path: Local path to the script file.\n    :param fail_nonzero: Fail if the script returns with a nonzero exit code.\n    :param upload_dir: Upload the entire parent directory of the script file to the remote.\n    :param kwargs: Additional keyword arguments to the run_script action.\n    \"\"\"\n    full_script_path = os.path.abspath(script_path)\n    prefix, name = os.path.split(full_script_path)\n    with temp_dir() as remote_tmp:\n        if upload_dir:\n            prefix_path, prefix_name = os.path.split(prefix)\n            remote_script = posixpath.join(remote_tmp, prefix_name, name)\n            put(prefix, remote_tmp, mirror_local_mode=True)\n        else:\n            remote_script = posixpath.join(remote_tmp, name)\n            put(script_path, remote_script, mirror_local_mode=True)\n        results = [output.result\n                   for output in container_fabric().run_script(container, script_path=remote_script, **kwargs)\n                   if o.action_type == ContainerUtilAction.SCRIPT]\n    for res in results:\n        puts(\"Exit code: {0}\".format(res['exit_code']))\n        if res['exit_code'] == 0 or not fail_nonzero:\n            puts(res['log'])\n        else:\n            error(res['log'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_cmd(container, command, fail_nonzero=False, download_result=None, **kwargs):\n    with temp_dir() as remote_tmp:\n        kwargs.setdefault('command_format', ['-c', command])\n        results = [output.result\n                   for output in container_fabric().run_script(container, script_path=remote_tmp, **kwargs)\n                   if o.action_type == ContainerUtilAction.SCRIPT]\n        if download_result:\n            get(posixpath.join(remote_tmp, '*'), local_path=download_result)\n    for res in results:\n        puts(\"Exit code: {0}\".format(res['exit_code']))\n        if res['exit_code'] == 0 or not fail_nonzero:\n            puts(res['log'])\n        else:\n            error(res['log'])", "response": "Runs a single command inside a container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef docker_fabric(*args, **kwargs):\n    ci = kwargs.get('client_implementation') or env.get('docker_fabric_implementation') or CLIENT_API\n    if ci == CLIENT_API:\n        return docker_api(*args, **kwargs)\n    elif ci == CLIENT_CLI:\n        return docker_cli(*args, **kwargs)\n    raise ValueError(\"Invalid client implementation.\", ci)", "response": "Returns a Docker client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef container_fabric(container_maps=None, docker_client=None, clients=None, client_implementation=None):\n    ci = client_implementation or env.get('docker_fabric_implementation') or CLIENT_API\n    if ci == CLIENT_API:\n        return ContainerApiFabricClient(container_maps, docker_client, clients)\n    elif ci == CLIENT_CLI:\n        return ContainerCliFabricClient(container_maps, docker_client, clients)\n    raise ValueError(\"Invalid client implementation.\", ci)", "response": "Returns a container mapping client."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts raw SBML model to extended model.", "response": "def convert_sbml_model(model):\n    \"\"\"Convert raw SBML model to extended model.\n\n    Args:\n        model: :class:`NativeModel` obtained from :class:`SBMLReader`.\n    \"\"\"\n    biomass_reactions = set()\n    for reaction in model.reactions:\n        # Extract limits\n        if reaction.id not in model.limits:\n            lower, upper = parse_flux_bounds(reaction)\n            if lower is not None or upper is not None:\n                model.limits[reaction.id] = reaction.id, lower, upper\n\n        # Detect objective\n        objective = parse_objective_coefficient(reaction)\n        if objective is not None and objective != 0:\n            biomass_reactions.add(reaction.id)\n\n    if len(biomass_reactions) == 1:\n        model.biomass_reaction = next(iter(biomass_reactions))\n\n    # Convert model to mutable entries\n    convert_model_entries(model)\n\n    # Detect extracelluar compartment\n    if model.extracellular_compartment is None:\n        extracellular = detect_extracellular_compartment(model)\n        model.extracellular_compartment = extracellular\n\n    # Convert exchange reactions to exchange compounds\n    convert_exchange_to_compounds(model)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting COBRA - encoded ID string to decoded ID string.", "response": "def entry_id_from_cobra_encoding(cobra_id):\n    \"\"\"Convert COBRA-encoded ID string to decoded ID string.\"\"\"\n    for escape, symbol in iteritems(_COBRA_DECODE_ESCAPES):\n        cobra_id = cobra_id.replace(escape, symbol)\n    return cobra_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_convert_sbml_id_function(\n        compartment_prefix='C_', reaction_prefix='R_',\n        compound_prefix='M_', decode_id=entry_id_from_cobra_encoding):\n    \"\"\"Create function for converting SBML IDs.\n\n    The returned function will strip prefixes, decode the ID using the provided\n    function. These prefixes are common on IDs in SBML models because the IDs\n    live in a global namespace.\n    \"\"\"\n    def convert_sbml_id(entry):\n        if isinstance(entry, BaseCompartmentEntry):\n            prefix = compartment_prefix\n        elif isinstance(entry, BaseReactionEntry):\n            prefix = reaction_prefix\n        elif isinstance(entry, BaseCompoundEntry):\n            prefix = compound_prefix\n\n        new_id = entry.id\n        if decode_id is not None:\n            new_id = decode_id(new_id)\n        if prefix is not None and new_id.startswith(prefix):\n            new_id = new_id[len(prefix):]\n\n        return new_id\n\n    return convert_sbml_id", "response": "Create function for converting SBML IDs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef translate_sbml_reaction(entry, new_id, compartment_map, compound_map):\n    new_entry = DictReactionEntry(entry, id=new_id)\n\n    # Convert compound IDs in reaction equation\n    if new_entry.equation is not None:\n        compounds = []\n        for compound, value in new_entry.equation.compounds:\n            # Translate compartment to new ID, if available.\n            compartment = compartment_map.get(\n                compound.compartment, compound.compartment)\n            new_compound = compound.translate(\n                lambda name: compound_map.get(name, name)).in_compartment(\n                    compartment)\n            compounds.append((new_compound, value))\n\n        new_entry.equation = Reaction(\n            new_entry.equation.direction, compounds)\n\n    # Get XHTML notes properties\n    for key, value in iteritems(parse_xhtml_reaction_notes(entry)):\n        if key not in new_entry.properties:\n            new_entry.properties[key] = value\n\n    return new_entry", "response": "Translate SBML reaction entry to new ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_sbml_compound(entry, new_id, compartment_map):\n    new_entry = DictCompoundEntry(entry, id=new_id)\n\n    if 'compartment' in new_entry.properties:\n        old_compartment = new_entry.properties['compartment']\n        new_entry.properties['compartment'] = compartment_map.get(\n            old_compartment, old_compartment)\n\n    # Get XHTML notes properties\n    for key, value in iteritems(parse_xhtml_species_notes(entry)):\n        if key not in new_entry.properties:\n            new_entry.properties[key] = value\n\n    return new_entry", "response": "Translate SBML compound entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting and decode model entries.", "response": "def convert_model_entries(\n        model, convert_id=create_convert_sbml_id_function(),\n        create_unique_id=None,\n        translate_compartment=translate_sbml_compartment,\n        translate_reaction=translate_sbml_reaction,\n        translate_compound=translate_sbml_compound):\n    \"\"\"Convert and decode model entries.\n\n    Model entries are converted to new entries using the translate functions\n    and IDs are converted using the given coversion function. If ID conversion\n    would create a clash of IDs, the ``create_unique_id`` function is called\n    with a container of current IDs and the base ID to generate a unique ID\n    from. The translation functions take an existing entry and the new ID.\n\n    All references within the model are updated to use new IDs: compartment\n    boundaries, limits, exchange, model, biomass reaction, etc.\n\n    Args:\n        model: :class:`NativeModel`.\n    \"\"\"\n    def find_new_ids(entries):\n        \"\"\"Create new IDs for entries.\"\"\"\n        id_map = {}\n        new_ids = set()\n        for entry in entries:\n            new_id = convert_id(entry)\n            if new_id in new_ids:\n                if create_unique_id is not None:\n                    new_id = create_unique_id(new_ids, new_id)\n                else:\n                    raise ValueError(\n                        'Entity ID {!r} is not unique after conversion'.format(\n                            entry.id))\n\n            id_map[entry.id] = new_id\n            new_ids.add(new_id)\n\n        return id_map\n\n    # Find new IDs for all entries\n    compartment_map = find_new_ids(model.compartments)\n    compound_map = find_new_ids(model.compounds)\n    reaction_map = find_new_ids(model.reactions)\n\n    # Create new compartment entries\n    new_compartments = []\n    for compartment in model.compartments:\n        new_id = compartment_map[compartment.id]\n        new_compartments.append(translate_compartment(compartment, new_id))\n\n    # Create new compound entries\n    new_compounds = []\n    for compound in model.compounds:\n        new_id = compound_map[compound.id]\n        new_compounds.append(\n            translate_compound(compound, new_id, compartment_map))\n\n    # Create new reaction entries\n    new_reactions = []\n    for reaction in model.reactions:\n        new_id = reaction_map[reaction.id]\n        new_entry = translate_reaction(\n            reaction, new_id, compartment_map, compound_map)\n        new_reactions.append(new_entry)\n\n    # Update entries\n    model.compartments.clear()\n    model.compartments.update(new_compartments)\n\n    model.compounds.clear()\n    model.compounds.update(new_compounds)\n\n    model.reactions.clear()\n    model.reactions.update(new_reactions)\n\n    # Convert compartment boundaries\n    new_boundaries = []\n    for boundary in model.compartment_boundaries:\n        c1, c2 = (compartment_map.get(c, c) for c in boundary)\n        new_boundaries.append(tuple(sorted(c1, c2)))\n\n    model.compartment_boundaries.clear()\n    model.compartment_boundaries.update(new_boundaries)\n\n    # Convert limits\n    new_limits = []\n    for reaction, lower, upper in itervalues(model.limits):\n        new_reaction_id = reaction_map.get(reaction, reaction)\n        new_limits.append((new_reaction_id, lower, upper))\n\n    model.limits.clear()\n    model.limits.update((limit[0], limit) for limit in new_limits)\n\n    # Convert exchange\n    new_exchanges = []\n    for compound, reaction, lower, upper in itervalues(model.exchange):\n        new_compound_id = compound.translated(\n            lambda name: compound_map.get(name, name))\n        new_reaction_id = reaction_map.get(reaction, reaction)\n        new_exchanges.append((new_compound_id, new_reaction_id, lower, upper))\n\n    model.exchange.clear()\n    model.exchange.update((ex[0], ex) for ex in new_exchanges)\n\n    # Convert model\n    new_model = []\n    for reaction in model.model:\n        new_id = reaction_map.get(reaction, reaction)\n        new_model.append(new_id)\n\n    model.model.clear()\n    model.model.update((new_id, None) for new_id in new_model)\n\n    # Convert other properties\n    if model.biomass_reaction is not None:\n        old_id = model.biomass_reaction\n        model.biomass_reaction = reaction_map.get(old_id, old_id)\n\n    if model.extracellular_compartment is not None:\n        old_id = model.extracellular_compartment\n        model.extracellular_compartment = compartment_map.get(old_id, old_id)\n\n    if model.default_compartment is not None:\n        old_id = model.default_compartment\n        model.default_compartment = compartment_map.get(old_id, old_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_xhtml_notes(entry):\n    for note in entry.xml_notes.itertext():\n        m = re.match(r'^([^:]+):(.+)$', note)\n        if m:\n            key, value = m.groups()\n            key = key.strip().lower().replace(' ', '_')\n            value = value.strip()\n            m = re.match(r'^\"(.*)\"$', value)\n            if m:\n                value = m.group(1)\n            if value != '':\n                yield key, value", "response": "Yields key value pairs parsed from the XHTML notes section."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the XHTML notes and return species properties defined in the SBML notes", "response": "def parse_xhtml_species_notes(entry):\n    \"\"\"Return species properties defined in the XHTML notes.\n\n    Older SBML models often define additional properties in the XHTML notes\n    section because structured methods for defining properties had not been\n    developed. This will try to parse the following properties: ``PUBCHEM ID``,\n    ``CHEBI ID``, ``FORMULA``, ``KEGG ID``, ``CHARGE``.\n\n    Args:\n        entry: :class:`SBMLSpeciesEntry`.\n    \"\"\"\n    properties = {}\n    if entry.xml_notes is not None:\n        cobra_notes = dict(parse_xhtml_notes(entry))\n\n        for key in ('pubchem_id', 'chebi_id'):\n            if key in cobra_notes:\n                properties[key] = cobra_notes[key]\n\n        if 'formula' in cobra_notes:\n            properties['formula'] = cobra_notes['formula']\n\n        if 'kegg_id' in cobra_notes:\n            properties['kegg'] = cobra_notes['kegg_id']\n\n        if 'charge' in cobra_notes:\n            try:\n                value = int(cobra_notes['charge'])\n            except ValueError:\n                logger.warning(\n                    'Unable to parse charge for {} as an'\n                    ' integer: {}'.format(\n                        entry.id, cobra_notes['charge']))\n                value = cobra_notes['charge']\n            properties['charge'] = value\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the reaction properties in the XHTML notes section.", "response": "def parse_xhtml_reaction_notes(entry):\n    \"\"\"Return reaction properties defined in the XHTML notes.\n\n    Older SBML models often define additional properties in the XHTML notes\n    section because structured methods for defining properties had not been\n    developed. This will try to parse the following properties: ``SUBSYSTEM``,\n    ``GENE ASSOCIATION``, ``EC NUMBER``, ``AUTHORS``, ``CONFIDENCE``.\n\n    Args:\n        entry: :class:`SBMLReactionEntry`.\n    \"\"\"\n    properties = {}\n    if entry.xml_notes is not None:\n        cobra_notes = dict(parse_xhtml_notes(entry))\n\n        if 'subsystem' in cobra_notes:\n            properties['subsystem'] = cobra_notes['subsystem']\n\n        if 'gene_association' in cobra_notes:\n            properties['genes'] = cobra_notes['gene_association']\n\n        if 'ec_number' in cobra_notes:\n            properties['ec'] = cobra_notes['ec_number']\n\n        if 'authors' in cobra_notes:\n            properties['authors'] = [\n                a.strip() for a in cobra_notes['authors'].split(';')]\n\n        if 'confidence' in cobra_notes:\n            try:\n                value = int(cobra_notes['confidence'])\n            except ValueError:\n                logger.warning(\n                    'Unable to parse confidence level for {} as an'\n                    ' integer: {}'.format(\n                        entry.id, cobra_notes['confidence']))\n                value = cobra_notes['confidence']\n            properties['confidence'] = value\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_objective_coefficient(entry):\n    for parameter in entry.kinetic_law_reaction_parameters:\n        pid, name, value, units = parameter\n        if (pid == 'OBJECTIVE_COEFFICIENT' or\n                name == 'OBJECTIVE_COEFFICIENT'):\n            return value\n\n    return None", "response": "Return objective value for a given entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the flux bounds for a reaction entry.", "response": "def parse_flux_bounds(entry):\n    \"\"\"Return flux bounds for reaction entry.\n\n    Detect flux bounds that are specified using the non-standardized\n    kinetic law parameters which are used by many pre-FBC SBML models. The\n    flux bounds are returned as a pair of lower, upper bounds. The returned\n    bound is None if undefined.\n\n    Args:\n        entry: :class:`SBMLReactionEntry`.\n    \"\"\"\n    lower_bound = None\n    upper_bound = None\n    for parameter in entry.kinetic_law_reaction_parameters:\n        pid, name, value, units = parameter\n        if pid == 'UPPER_BOUND' or name == 'UPPER_BOUND':\n            upper_bound = value\n        elif pid == 'LOWER_BOUND' or name == 'LOWER_BOUND':\n            lower_bound = value\n\n    return lower_bound, upper_bound"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_extracellular_compartment(model):\n    extracellular_key = Counter()\n\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        if len(equation.compounds) == 1:\n            compound, _ = equation.compounds[0]\n            compartment = compound.compartment\n            extracellular_key[compartment] += 1\n    if len(extracellular_key) == 0:\n        return None\n    else:\n        best_key, _ = extracellular_key.most_common(1)[0]\n\n    logger.info('{} is extracellular compartment'.format(best_key))\n\n    return best_key", "response": "Detects the identifier for equations with extracellular compartments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts exchange reactions in model to exchange compounds.", "response": "def convert_exchange_to_compounds(model):\n    \"\"\"Convert exchange reactions in model to exchange compounds.\n\n    Only exchange reactions in the extracellular compartment are converted.\n    The extracelluar compartment must be defined for the model.\n\n    Args:\n        model: :class:`NativeModel`.\n    \"\"\"\n    # Build set of exchange reactions\n    exchanges = set()\n    for reaction in model.reactions:\n        equation = reaction.properties.get('equation')\n        if equation is None:\n            continue\n\n        if len(equation.compounds) != 1:\n            # Provide warning for exchange reactions with more than\n            # one compound, they won't be put into the exchange definition\n            if (len(equation.left) == 0) != (len(equation.right) == 0):\n                logger.warning('Exchange reaction {} has more than one'\n                               ' compound, it was not converted to'\n                               ' exchange compound'.format(reaction.id))\n            continue\n\n        exchanges.add(reaction.id)\n\n    # Convert exchange reactions into exchange compounds\n    for reaction_id in exchanges:\n        equation = model.reactions[reaction_id].equation\n        compound, value = equation.compounds[0]\n        if compound.compartment != model.extracellular_compartment:\n            continue\n\n        if compound in model.exchange:\n            logger.warning(\n                'Compound {} is already defined in the exchange'\n                ' definition'.format(compound))\n            continue\n\n        # We multiply the flux bounds by value in order to create equivalent\n        # exchange reactions with stoichiometric value of one. If the flux\n        # bounds are not set but the reaction is unidirectional, the implicit\n        # flux bounds must be used.\n        lower_flux, upper_flux = None, None\n        if reaction_id in model.limits:\n            _, lower, upper = model.limits[reaction_id]\n            if lower is not None:\n                lower_flux = lower * abs(value)\n            if upper is not None:\n                upper_flux = upper * abs(value)\n\n        if lower_flux is None and equation.direction == Direction.Forward:\n            lower_flux = 0\n        if upper_flux is None and equation.direction == Direction.Reverse:\n            upper_flux = 0\n\n        # If the stoichiometric value of the reaction is reversed, the flux\n        # limits must be flipped.\n        if value > 0:\n            lower_flux, upper_flux = (\n                -upper_flux if upper_flux is not None else None,\n                -lower_flux if lower_flux is not None else None)\n\n        model.exchange[compound] = (\n            compound, reaction_id, lower_flux, upper_flux)\n\n        model.reactions.discard(reaction_id)\n        model.limits.pop(reaction_id, None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging equivalent compounds in various compartments.", "response": "def merge_equivalent_compounds(model):\n    \"\"\"Merge equivalent compounds in various compartments.\n\n    Tries to detect and merge compound entries that represent the same\n    compound in different compartments. The entries are only merged if all\n    properties are equivalent. Compound entries must have an ID with a suffix\n    of an underscore followed by the compartment ID. This suffix will be\n    stripped and compounds with identical IDs are merged if the properties\n    are identical.\n\n    Args:\n        model: :class:`NativeModel`.\n    \"\"\"\n    def dicts_are_compatible(d1, d2):\n        return all(key not in d1 or key not in d2 or d1[key] == d2[key]\n                   for key in set(d1) | set(d2))\n\n    compound_compartment = {}\n    inelegible = set()\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        for compound, _ in equation.compounds:\n            compartment = compound.compartment\n            if compartment is not None:\n                compound_compartment[compound.name] = compartment\n                if not compound.name.endswith('_{}'.format(compartment)):\n                    inelegible.add(compound.name)\n\n    compound_groups = {}\n    for compound_id, compartment in iteritems(compound_compartment):\n        if compound_id in inelegible:\n            continue\n\n        suffix = '_{}'.format(compound_compartment[compound_id])\n        if compound_id.endswith(suffix):\n            group_name = compound_id[:-len(suffix)]\n            compound_groups.setdefault(group_name, set()).add(compound_id)\n\n    compound_mapping = {}\n    merged_compounds = {}\n    for group, compound_set in iteritems(compound_groups):\n        # Try to merge as many compounds as possible\n        merged = []\n        for compound_id in compound_set:\n            props = dict(model.compounds[compound_id].properties)\n\n            # Ignore differences in ID and compartment properties\n            props.pop('id', None)\n            props.pop('compartment', None)\n\n            for merged_props, merged_set in merged:\n                if dicts_are_compatible(props, merged_props):\n                    merged_set.add(compound_id)\n                    merged_props.update(props)\n                    break\n                else:\n                    keys = set(key for key in set(props) | set(merged_props)\n                               if key not in props or\n                               key not in merged_props or\n                               props[key] != merged_props[key])\n                    logger.info(\n                        'Unable to merge {} into {}, difference in'\n                        ' keys: {}'.format(\n                            compound_id, ', '.join(merged_set),\n                            ', '.join(keys)))\n            else:\n                merged.append((props, {compound_id}))\n\n        if len(merged) == 1:\n            # Merge into one set with the group name\n            merged_props, merged_set = merged[0]\n\n            for compound_id in merged_set:\n                compound_mapping[compound_id] = group\n            merged_compounds[group] = merged_props\n        else:\n            # Since we cannot merge all compounds, create new group names\n            # based on the group and compartments.\n            for merged_props, merged_set in merged:\n                compartments = set(compound_compartment[c] for c in merged_set)\n                merged_name = '{}_{}'.format(\n                    group, '_'.join(sorted(compartments)))\n\n                for compound_id in merged_set:\n                    compound_mapping[compound_id] = merged_name\n                merged_compounds[merged_name] = merged_props\n\n    # Translate reaction compounds\n    for reaction in model.reactions:\n        equation = reaction.equation\n        if equation is None:\n            continue\n\n        reaction.equation = equation.translated_compounds(\n            lambda c: compound_mapping.get(c, c))\n\n    # Translate compound entries\n    new_compounds = []\n    for compound in model.compounds:\n        if compound.id not in compound_mapping:\n            new_compounds.append(compound)\n        else:\n            group = compound_mapping[compound.id]\n            if group not in merged_compounds:\n                continue\n            props = merged_compounds.pop(group)\n            props['id'] = group\n            new_compounds.append(DictCompoundEntry(\n                props, filemark=compound.filemark))\n\n    model.compounds.clear()\n    model.compounds.update(new_compounds)\n\n    # Translate exchange\n    new_exchange = OrderedDict()\n    for compound, reaction_id, lower, upper in itervalues(model.exchange):\n        new_compound = compound.translate(\n            lambda name: compound_mapping.get(name, name))\n        new_exchange[new_compound] = new_compound, reaction_id, lower, upper\n\n    model.exchange.clear()\n    model.exchange.update(new_exchange)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _element_get_id(self, element):\n        if self._reader._level > 1:\n            entry_id = element.get('id')\n        else:\n            entry_id = element.get('name')\n        return entry_id", "response": "Get id of reaction or species element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef charge(self):\n        if self._reader._level == 3:\n            # Look for FBC charge\n            for ns in (FBC_V2, FBC_V1):\n                charge = self._root.get(_tag('charge', ns))\n                if charge is not None:\n                    return self._parse_charge_string(charge)\n        else:\n            charge = self._root.get('charge')\n            if charge is not None:\n                return self._parse_charge_string(charge)\n\n        return None", "response": "Returns the charge tag if it exists else None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef properties(self):\n        properties = {'id': self._id,\n                      'boundary': self._boundary}\n        if 'name' in self._root.attrib:\n            properties['name'] = self._root.get('name')\n        if 'compartment' in self._root.attrib:\n            properties['compartment'] = self._root.get('compartment')\n\n        charge = self.charge\n        if charge is not None:\n            properties['charge'] = charge\n\n        formula = self.formula\n        if formula is not None:\n            properties['formula'] = formula\n\n        return properties", "response": "All species properties as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield the species id and parsed value for a speciesReference list", "response": "def _parse_species_references(self, name):\n        \"\"\"Yield species id and parsed value for a speciesReference list\"\"\"\n        for species in self._root.iterfind('./{}/{}'.format(\n                self._reader._sbml_tag(name),\n                self._reader._sbml_tag('speciesReference'))):\n\n            species_id = species.get('species')\n\n            if self._reader._level == 1:\n                # In SBML level 1 only positive integers are allowed for\n                # stoichiometry but a positive integer denominator can be\n                # specified.\n                try:\n                    value = int(species.get('stoichiometry', 1))\n                    denom = int(species.get('denominator', 1))\n                    species_value = Fraction(value, denom)\n                except ValueError:\n                    message = ('Non-integer stoichiometry is not allowed in'\n                               ' SBML level 1 (reaction {})'.format(self.id))\n                    if self._reader._strict:\n                        raise ParseError(message)\n                    else:\n                        logger.warning(message)\n                    species_value = Decimal(species.get('stoichiometry', 1))\n            elif self._reader._level == 2:\n                # Stoichiometric value is a double but can alternatively be\n                # specified using math (not implemented).\n                value_str = species.get('stoichiometry', None)\n                if value_str is None:\n                    if 'stoichiometryMath' in species:\n                        raise ParseError('stoichiometryMath in '\n                                         'speciesReference is not implemented')\n                    species_value = 1\n                else:\n                    species_value = Decimal(value_str)\n            elif self._reader._level == 3:\n                # Stoichiometric value is a double but can alternatively be\n                # specified using initial assignment (not implemented).\n                value_str = species.get('stoichiometry', None)\n                if value_str is None:\n                    raise ParseError('Missing stoichiometry in'\n                                     ' speciesReference is not implemented')\n                species_value = Decimal(value_str)\n\n            if species_value % 1 == 0:\n                species_value = int(species_value)\n\n            yield species_id, species_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kinetic_law_reaction_parameters(self):\n\n        for parameter in self._root.iterfind(\n                './{}/{}/{}'.format(self._reader._sbml_tag('kineticLaw'),\n                                    self._reader._sbml_tag('listOfParameters'),\n                                    self._reader._sbml_tag('parameter'))):\n            param_id = parameter.get('id')\n            param_name = parameter.get('name')\n            param_value = Decimal(parameter.get('value'))\n            param_units = parameter.get('units')\n\n            yield param_id, param_name, param_value, param_units", "response": "Iterate over the values of kinetic law reaction parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef properties(self):\n        properties = {'id': self._id,\n                      'reversible': self._rev,\n                      'equation': self._equation}\n        if 'name' in self._root.attrib:\n            properties['name'] = self._root.get('name')\n        if self._lower_flux is not None:\n            properties['lower_flux'] = self._lower_flux\n        if self._upper_flux is not None:\n            properties['upper_flux'] = self._upper_flux\n\n        return properties", "response": "All reaction properties as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef species(self):\n        return (c for c in itervalues(self._model_species)\n                if not self._ignore_boundary or not c.boundary)", "response": "Iterator over all species in the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_model(self):\n        properties = {\n            'name': self.name,\n            'default_flux_limit': 1000\n        }\n\n        # Load objective as biomass reaction\n        objective = self.get_active_objective()\n        if objective is not None:\n            reactions = dict(objective.reactions)\n            if len(reactions) == 1:\n                reaction, value = next(iteritems(reactions))\n                if ((value < 0 and objective.type == 'minimize') or\n                        (value > 0 and objective.type == 'maximize')):\n                    properties['biomass'] = reaction\n\n        model = NativeModel(properties)\n\n        # Load compartments into model\n        for compartment in self.compartments:\n            model.compartments.add_entry(compartment)\n\n        # Load compounds into model\n        for compound in self.species:\n            model.compounds.add_entry(compound)\n\n        # Load reactions into model\n        for reaction in self.reactions:\n            model.reactions.add_entry(reaction)\n\n        # Create model reaction set\n        for reaction in model.reactions:\n            model.model[reaction.id] = None\n\n        # Convert reaction limits properties to proper limits\n        for reaction in model.reactions:\n            props = reaction.properties\n            if 'lower_flux' in props or 'upper_flux' in props:\n                lower = props.get('lower_flux')\n                upper = props.get('upper_flux')\n                model.limits[reaction.id] = reaction.id, lower, upper\n\n        # Load model limits from FBC V1 bounds if present, i.e. if FBC V1 is\n        # used instead of V2.\n        limits_lower = {}\n        limits_upper = {}\n        for bounds in self.flux_bounds:\n            reaction = bounds.reaction\n            if reaction in model.limits:\n                continue\n\n            if bounds.operation == SBMLFluxBoundEntry.LESS_EQUAL:\n                if reaction not in limits_upper:\n                    limits_upper[reaction] = bounds.value\n                else:\n                    raise ParseError(\n                        'Conflicting bounds for {}'.format(reaction))\n            elif bounds.operation == SBMLFluxBoundEntry.GREATER_EQUAL:\n                if reaction not in limits_lower:\n                    limits_lower[reaction] = bounds.value\n                else:\n                    raise ParseError(\n                        'Conflicting bounds for {}'.format(reaction))\n            elif bounds.operation == SBMLFluxBoundEntry.EQUAL:\n                if (reaction not in limits_lower and\n                        reaction not in limits_upper):\n                    limits_lower[reaction] = bounds.value\n                    limits_upper[reaction] = bounds.value\n                else:\n                    raise ParseError(\n                        'Conflicting bounds for {}'.format(reaction))\n\n        for reaction in model.reactions:\n            if reaction.id in limits_lower or reaction.id in limits_upper:\n                lower = limits_lower.get(reaction.id, None)\n                upper = limits_upper.get(reaction.id, None)\n                model.limits[reaction.id] = reaction.id, lower, upper\n\n        return model", "response": "Create model from reader."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a modified id that is safe for SBML.", "response": "def _make_safe_id(self, id):\n        \"\"\"Returns a modified id that has been made safe for SBML.\n\n        Replaces or deletes the ones that aren't allowed.\n        \"\"\"\n\n        substitutions = {\n            '-': '_DASH_',\n            '/': '_FSLASH_',\n            '\\\\': '_BSLASH_',\n            '(': '_LPAREN_',\n            ')': '_RPAREN_',\n            '[': '_LSQBKT_',\n            ']': '_RSQBKT_',\n            ',': '_COMMA_',\n            '.': '_PERIOD_',\n            \"'\": '_APOS_'\n        }\n\n        id = re.sub(r'\\(([a-z])\\)$', '_\\\\1', id)\n        for symbol, escape in iteritems(substitutions):\n            id = id.replace(symbol, escape)\n        id = re.sub(r'[^a-zA-Z0-9_]', '', id)\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_flux_bounds(self, r_id, model, flux_limits, equation):\n        if r_id not in flux_limits or flux_limits[r_id][0] is None:\n            if equation.direction == Direction.Forward:\n                lower = 0\n            else:\n                lower = -model.default_flux_limit\n        else:\n            lower = flux_limits[r_id][0]\n\n        if r_id not in flux_limits or flux_limits[r_id][1] is None:\n            if equation.direction == Direction.Reverse:\n                upper = 0\n            else:\n                upper = model.default_flux_limit\n        else:\n            upper = flux_limits[r_id][1]\n\n        if lower % 1 == 0:\n            lower = int(lower)\n        if upper % 1 == 0:\n            upper = int(upper)\n        return text_type(lower), text_type(upper)", "response": "Get the lower and upper flux bounds for a given reaction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd all the different kinds of genes into a list.", "response": "def _add_gene_associations(self, r_id, r_genes, gene_ids, r_tag):\n        \"\"\"Adds all the different kinds of genes into a list.\"\"\"\n        genes = ET.SubElement(\n            r_tag, _tag('geneProductAssociation', FBC_V2))\n        if isinstance(r_genes, list):\n            e = Expression(And(*(Variable(i) for i in r_genes)))\n        else:\n            e = Expression(r_genes)\n        gene_stack = [(e.root, genes)]\n        while len(gene_stack) > 0:\n            current, parent = gene_stack.pop()\n            if isinstance(current, Or):\n                gene_tag = ET.SubElement(parent, _tag('or', FBC_V2))\n            elif isinstance(current, And):\n                gene_tag = ET.SubElement(parent, _tag('and', FBC_V2))\n            elif isinstance(current, Variable):\n                gene_tag = ET.SubElement(parent, _tag(\n                    'geneProductRef', FBC_V2))\n                if current.symbol not in gene_ids:\n                    id = 'g_' + util.create_unique_id(\n                        self._make_safe_id(current.symbol), gene_ids)\n                    gene_ids[id] = current.symbol\n                    gene_tag.set(_tag('geneProduct', FBC_V2), id)\n            if isinstance(current, (Or, And)):\n                for item in current:\n                    gene_stack.append((item, gene_tag))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_fbc_objective(self, model_tag, obj_id):\n        objective_list = ET.SubElement(model_tag, _tag(\n            'listOfObjectives', FBC_V2))\n        objective_list.set(_tag('activeObjective', FBC_V2), 'O_1')\n        objective_tag = ET.SubElement(\n            objective_list, _tag('objective', FBC_V2))\n        objective_tag.set(_tag('id', FBC_V2), 'O_1')\n        objective_tag.set(_tag('type', FBC_V2), 'maximize')\n        flux_objective_list = ET.SubElement(objective_tag, _tag(\n            'listOfFluxObjectives', FBC_V2))\n        flux_objective_tag = ET.SubElement(flux_objective_list, _tag(\n            'fluxObjective', FBC_V2))\n        flux_objective_tag.set(_tag('reaction', FBC_V2), 'R_' + obj_id)\n        flux_objective_tag.set(_tag('coefficient', FBC_V2), '1')", "response": "Adds the objective to the sbml document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_gene_list(self, parent_tag, gene_id_dict):\n        list_all_genes = ET.SubElement(parent_tag, _tag(\n            'listOfGeneProducts', FBC_V2))\n        for id, label in sorted(iteritems(gene_id_dict)):\n            gene_tag = ET.SubElement(\n                list_all_genes, _tag('geneProduct', FBC_V2))\n            gene_tag.set(_tag('id', FBC_V2), id)\n            gene_tag.set(_tag('label', FBC_V2), label)", "response": "Create list of all gene products as sbml readable elements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_model(self, file, model, pretty=False):\n        ET.register_namespace('mathml', MATHML_NS)\n        ET.register_namespace('xhtml', XHTML_NS)\n        ET.register_namespace('fbc', FBC_V2)\n\n        # Load compound information\n        compound_name = {}\n        compound_properties = {}\n        for compound in model.compounds:\n            compound_name[compound.id] = (\n                compound.name if compound.name is not None else compound.id)\n            compound_properties[compound.id] = compound.properties\n\n        model_reactions = set(model.model)\n\n        reaction_properties = {}\n        biomass_id = None\n        for r in model.reactions:\n            if (model_reactions is not None and\n                    r.id not in model_reactions):\n                continue\n\n            reaction_id = util.create_unique_id(\n                self._make_safe_id(r.id), reaction_properties)\n            if r.id == model.biomass_reaction:\n                biomass_id = reaction_id\n\n            reaction_properties[reaction_id] = r.properties\n\n        # Add exchange reactions to reaction_properties,\n        # also add flux limit info to flux_limits\n        flux_limits = {}\n        for compound, reaction_id, lower, upper in itervalues(model.exchange):\n            # Create exchange reaction\n            if reaction_id is None:\n                reaction_id = create_exchange_id(reaction_properties, compound)\n            reaction_id = util.create_unique_id(\n                self._make_safe_id(reaction_id), reaction_properties)\n\n            reaction_properties[reaction_id] = {\n                'id': reaction_id,\n                'equation': Reaction(Direction.Both, {compound: -1})\n            }\n\n            if lower is None:\n                lower = -model.default_flux_limit\n            if upper is None:\n                upper = model.default_flux_limit\n            flux_limits[reaction_id] = (lower, upper)\n\n            # Create a dummy properties dict for undefined compounds\n            if compound.name not in compound_properties:\n                compound_properties[compound.name] = {\n                    'id': compound.name\n                }\n\n        root = ET.Element(self._sbml_tag('sbml'))\n        root.set(self._sbml_tag('level'), '3')\n        root.set(self._sbml_tag('version'), '1')\n        root.set(_tag('required', FBC_V2), 'false')\n        if model.version_string is not None:\n            notes_tag = ET.SubElement(root, self._sbml_tag('notes'))\n            body_tag = ET.SubElement(notes_tag, _tag('body', XHTML_NS))\n            self._add_properties_notes(\n                body_tag, {'model version': model.version_string})\n\n        model_tag = ET.SubElement(root, self._sbml_tag('model'))\n        model_tag.set(_tag('strict', FBC_V2), 'true')\n        if model.name is not None:\n            model_tag.set(self._sbml_tag('name'), model.name)\n\n        # Build mapping from Compound to species ID\n        model_compartments = {}\n        model_species = {}\n        species_ids = set()\n        for _, properties in iteritems(reaction_properties):\n            for compound, _ in properties['equation'].compounds:\n                if compound in model_species:\n                    continue\n\n                # Create a dummy properties dict for undefined compounds\n                if compound.name not in compound_properties:\n                    compound_properties[compound.name] = {\n                        'id': compound.name\n                    }\n\n                compound_id = util.create_unique_id(\n                    self._make_safe_id(compound.name), species_ids)\n                model_species[compound] = compound_id\n                species_ids.add(compound_id)\n                if compound.compartment not in model_compartments:\n                    model_compartments[\n                        compound.compartment] = 'C_' + util.create_unique_id(\n                            self._make_safe_id(compound.compartment),\n                            model_compartments)\n\n        # Create list of compartments\n        compartments = ET.SubElement(\n            model_tag, self._sbml_tag('listOfCompartments'))\n        for _, compartment_id in iteritems(model_compartments):\n            compartment_tag = ET.SubElement(\n                compartments, self._sbml_tag('compartment'))\n            compartment_tag.set(self._sbml_tag('id'), compartment_id)\n            compartment_tag.set(self._sbml_tag('constant'), 'true')\n\n        # Create list of species\n        species_list = ET.SubElement(\n            model_tag, self._sbml_tag('listOfSpecies'))\n        for species, species_id in sorted(\n                iteritems(model_species), key=lambda x: x[1]):\n            species_tag = ET.SubElement(species_list,\n                                        self._sbml_tag('species'))\n            species_tag.set(self._sbml_tag('id'), 'M_' + species_id)\n            species_tag.set(\n                self._sbml_tag('name'),\n                compound_name.get(species.name, species.name))\n            species_tag.set(\n                self._sbml_tag('compartment'),\n                model_compartments[species.compartment])\n            species_tag.set(self._sbml_tag('constant'), 'false')\n            species_tag.set(self._sbml_tag('boundaryCondition'), 'false')\n            species_tag.set(self._sbml_tag('hasOnlySubstanceUnits'), 'true')\n            if 'charge' in compound_properties[species.name]:\n                species_tag.set(_tag('charge', FBC_V2), text_type(\n                    compound_properties[species.name]['charge']))\n            if 'formula' in compound_properties[species.name]:\n                species_tag.set(_tag(\n                    'chemicalFormula', FBC_V2), text_type(\n                        compound_properties[species.name]['formula']))\n\n            notes_tag = ET.SubElement(species_tag, self._sbml_tag('notes'))\n            body_tag = ET.SubElement(notes_tag, _tag('body', XHTML_NS))\n            self._add_properties_notes(\n                body_tag, compound_properties[species.name])\n\n        params_list = ET.SubElement(\n            model_tag, self._sbml_tag('listOfParameters'))\n\n        # Create mapping for reactions containing flux limit definitions\n        for rxn_id, lower_lim, upper_lim in itervalues(model.limits):\n            flux_limits[rxn_id] = lower_lim, upper_lim\n\n        params = {}\n        gene_ids = {}\n\n        if biomass_id is not None:\n            self._add_fbc_objective(model_tag, biomass_id)\n\n        # Create list of reactions\n        reactions = ET.SubElement(model_tag, self._sbml_tag('listOfReactions'))\n        for eq_id, properties in sorted(iteritems(reaction_properties)):\n            reaction_tag = ET.SubElement(reactions, self._sbml_tag('reaction'))\n            equation = properties['equation']\n\n            reaction_tag.set(self._sbml_tag('id'), 'R_' + eq_id)\n            if 'name' in properties:\n                reaction_tag.set(self._sbml_tag('name'), properties['name'])\n            reaction_tag.set(self._sbml_tag('reversible'), text_type(\n                equation.direction == Direction.Both).lower())\n            reaction_tag.set(self._sbml_tag('fast'), 'false')\n            lower_str, upper_str = self._get_flux_bounds(\n                eq_id, model, flux_limits, equation)\n\n            params[upper_str] = 'P_'+self._make_safe_numerical_id(upper_str)\n            params[lower_str] = 'P_'+self._make_safe_numerical_id(lower_str)\n            reaction_tag.set(\n                _tag('upperFluxBound', FBC_V2), params[upper_str])\n            reaction_tag.set(\n                _tag('lowerFluxBound', FBC_V2), params[lower_str])\n\n            if 'genes' in properties:\n                self._add_gene_associations(\n                    eq_id, properties['genes'], gene_ids, reaction_tag)\n\n            if any(value < 0 for _, value in equation.compounds):\n                reactants = ET.SubElement(\n                    reaction_tag, self._sbml_tag('listOfReactants'))\n\n            if any(value > 0 for _, value in equation.compounds):\n                products = ET.SubElement(\n                    reaction_tag, self._sbml_tag('listOfProducts'))\n\n            for compound, value in sorted(equation.compounds):\n                dest_list = reactants if value < 0 else products\n                spec_ref = ET.SubElement(\n                    dest_list, self._sbml_tag('speciesReference'))\n                spec_ref.set(\n                    self._sbml_tag('species'), 'M_' + model_species[compound])\n                spec_ref.set(\n                    self._sbml_tag('constant'), 'true')\n                spec_ref.set(\n                    self._sbml_tag('stoichiometry'), text_type(abs(value)))\n\n            notes_tag = ET.SubElement(reaction_tag, self._sbml_tag('notes'))\n            body_tag = ET.SubElement(notes_tag, _tag('body', XHTML_NS))\n            self._add_properties_notes(body_tag, reaction_properties[eq_id])\n\n            if self._cobra_flux_bounds is True:\n                # Create COBRA-compliant parameter list\n                kl_tag = ET.SubElement(\n                    reaction_tag, self._sbml_tag('kineticLaw'))\n                math_tag = ET.SubElement(kl_tag, self._sbml_tag('math'))\n                ci_tag = ET.SubElement(math_tag, _tag('ci', MATHML_NS))\n                ci_tag.text = 'FLUX_VALUE'\n                param_list = ET.SubElement(\n                    kl_tag, self._sbml_tag('listOfParameters'))\n\n                ET.SubElement(param_list, self._sbml_tag('parameter'), {\n                    self._sbml_tag('id'): 'LOWER_BOUND',\n                    self._sbml_tag('name'): 'LOWER_BOUND',\n                    self._sbml_tag('value'): lower_str,\n                    self._sbml_tag('constant'): 'true'\n                })\n                ET.SubElement(param_list, self._sbml_tag('parameter'), {\n                    self._sbml_tag('id'): 'UPPER_BOUND',\n                    self._sbml_tag('name'): 'UPPER_BOUND',\n                    self._sbml_tag('value'): upper_str,\n                    self._sbml_tag('constant'): 'true'\n                })\n\n        for val, id in iteritems(params):\n            param_tag = ET.SubElement(params_list, self._sbml_tag('parameter'))\n            param_tag.set(self._sbml_tag('id'), id)\n            param_tag.set(self._sbml_tag('value'), val)\n            param_tag.set(self._sbml_tag('constant'), 'true')\n\n        self._add_gene_list(model_tag, gene_ids)\n\n        tree = ET.ElementTree(root)\n        if pretty:\n            self._indent(root)\n\n        write_options = dict(\n            encoding='utf-8',\n            default_namespace=self._namespace)\n        if PY3:\n            write_options['encoding'] = 'unicode'\n        tree.write(file, **write_options)", "response": "Writes a given model to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_data(self, extraneous=False):\n        jd = to_json(self, extraneous)\n        if hasattr(self, \"unknown_json_keys\"):\n            prop = type(self).properties['unknown_json_keys']\n            if extraneous or not prop.extraneous:\n                for k, v in self.unknown_json_keys.iteritems():\n                    if k not in jd:\n                        jd[k] = to_json(v, extraneous)\n        return jd", "response": "Returns the JSON data form of this object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomparing an object with another. This specializes :py:meth:`Record.diff` by returning a :py:class:`JsonDiff` object.", "response": "def diff(self, other, **kwargs):\n        \"\"\"Compare an object with another.  This specializes\n        :py:meth:`Record.diff` by returning a :py:class:`JsonDiff` object.\n        \"\"\"\n        return JsonDiff(\n            base_type_name=type(self).__name__,\n            other_type_name=type(other).__name__,\n            values=self.diff_iter(other, **kwargs),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the group id to a given group name.", "response": "def get_group_id(groupname):\n    \"\"\"\n    Returns the group id to a given group name. Returns ``None`` if the group does not exist.\n\n    :param groupname: Group name.\n    :type groupname: unicode\n    :return: Group id.\n    :rtype: int\n    \"\"\"\n    gid = single_line_stdout('id -g {0}'.format(groupname), expected_errors=(1,), shell=False)\n    return check_int(gid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the user id to a given user name.", "response": "def get_user_id(username):\n    \"\"\"\n    Returns the user id to a given user name. Returns ``None`` if the user does not exist.\n\n    :param username: User name.\n    :type username: unicode\n    :return: User id.\n    :rtype: int\n    \"\"\"\n    uid = single_line_stdout('id -u {0}'.format(username), expected_errors=(1,), shell=False)\n    return check_int(uid)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new user group with a specific id.", "response": "def create_group(groupname, gid, system=True):\n    \"\"\"\n    Creates a new user group with a specific id.\n\n    :param groupname: Group name.\n    :type groupname: unicode\n    :param gid: Group id.\n    :type gid: int or unicode\n    :param system: Creates a system group.\n    \"\"\"\n    sudo(addgroup(groupname, gid, system))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a user in the NCBI node.", "response": "def create_user(username, uid, system=False, no_login=True, no_password=False, group=False, gecos=None):\n    \"\"\"\n    Creates a new user with a specific id.\n\n    :param username: User name.\n    :type username: unicode\n    :param uid: User id.\n    :type uid: int or unicode\n    :param system: Creates a system user.\n    :type system: bool\n    :param no_login: Disallow login of this user and group, and skip creating the home directory. Default is ``True``.\n    :type no_login: bool\n    :param no_password: Do not set a password for the new user.\n    :type: no_password: bool\n    :param group: Create a group with the same id.\n    :type group: bool\n    :param gecos: Provide GECOS info and suppress prompt.\n    :type gecos: unicode\n    \"\"\"\n    sudo(adduser(username, uid, system, no_login, no_password, group, gecos))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_create_group(groupname, gid_preset, system=False, id_dependent=True):\n    gid = get_group_id(groupname)\n    if gid is None:\n        create_group(groupname, gid_preset, system)\n        return gid_preset\n    elif id_dependent and gid != gid_preset:\n        error(\"Present group id '{0}' does not match the required id of the environment '{1}'.\".format(gid, gid_preset))\n    return gid", "response": "Returns the id for the given group and creates it if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_or_create_user(username, uid_preset, groupnames=[], system=False, no_password=False, no_login=True,\n                       gecos=None, id_dependent=True):\n    \"\"\"\n    Returns the id of the given user name, and creates it first in case it does not exist. A default group is created\n    as well.\n\n    :param username: User name.\n    :type username: unicode\n    :param uid_preset: User id to set in case a new user is created.\n    :type uid_preset: int or unicode\n    :param groupnames: Additional names of groups to assign the user to. If the user exists, these will be appended to\n      existing group assignments.\n    :type groupnames: iterable\n    :param system: Create a system user.\n    :type system: bool\n    :param no_login: Disallow login of this user and group, and skip creating the home directory. Default is ``True``.\n    :type no_login: bool\n    :param no_password: Do not set a password for the new user.\n    :type: no_password: bool\n    :param gecos: Provide GECOS info and suppress prompt.\n    :type gecos: unicode\n    :param id_dependent: If the user exists, but its id does not match `uid_preset`, an error is thrown.\n    :type id_dependent: bool\n    :return:\n    \"\"\"\n    uid = get_user_id(username)\n    gid = get_group_id(username)\n    if id_dependent and gid is not None and gid != uid_preset:\n        error(\"Present group id '{0}' does not match the required id of the environment '{1}'.\".format(gid, uid_preset))\n    if gid is None:\n        create_group(username, uid_preset, system)\n        gid = uid_preset\n    if uid is None:\n        create_user(username, gid, system, no_login, no_password, False, gecos)\n        if groupnames:\n            assign_user_groups(username, groupnames)\n        return uid\n    elif id_dependent and uid != uid_preset:\n        error(\"Present user id '{0}' does not match the required id of the environment '{1}'.\".format(uid, uid_preset))\n    current_groups = get_user_groups(username)\n    new_groups = set(groupnames).discard(tuple(current_groups))\n    if new_groups:\n        assign_user_groups(username, new_groups)\n    return uid", "response": "Returns the id of the given user name and creates it if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over entries in KEGG file.", "response": "def parse_kegg_entries(f, context=None):\n    \"\"\"Iterate over entries in KEGG file.\"\"\"\n\n    section_id = None\n    entry_line = None\n    properties = {}\n    for lineno, line in enumerate(f):\n        if line.strip() == '///':\n            # End of entry\n            mark = FileMark(context, entry_line, 0)\n            yield KEGGEntry(properties, filemark=mark)\n            properties = {}\n            section_id = None\n            entry_line = None\n        else:\n            if entry_line is None:\n                entry_line = lineno\n\n            # Look for beginning of section\n            m = re.match(r'([A-Z_]+)\\s+(.*)', line.rstrip())\n            if m is not None:\n                section_id = m.group(1).lower()\n                properties[section_id] = [m.group(2)]\n            elif section_id is not None:\n                properties[section_id].append(line.strip())\n            else:\n                raise ParseError(\n                    'Missing section identifier at line {}'.format(lineno))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_reaction(s):\n\n    def parse_count(s):\n        m = re.match(r'^\\((.+)\\)$', s)\n        if m is not None:\n            s = m.group(1)\n\n        m = re.match(r'^\\d+$', s)\n        if m is not None:\n            return int(m.group(0))\n\n        return Expression(s)\n\n    def parse_compound(s):\n        m = re.match(r'(.+)\\((.+)\\)', s)\n        if m is not None:\n            return Compound(m.group(1), arguments=[Expression(m.group(2))])\n        return Compound(s)\n\n    def parse_compound_list(s):\n        for cpd in s.split(' + '):\n            if cpd == '':\n                continue\n\n            fields = cpd.strip().split(' ')\n            if len(fields) > 2:\n                raise ParseError(\n                    'Malformed compound specification: {}'.format(cpd))\n            if len(fields) == 1:\n                count = 1\n                compound = parse_compound(fields[0])\n            else:\n                count = parse_count(fields[0])\n                compound = parse_compound(fields[1])\n\n            yield compound, count\n\n    cpd_left, cpd_right = s.split('<=>')\n    left = parse_compound_list(cpd_left.strip())\n    right = parse_compound_list(cpd_right.strip())\n\n    return Reaction(Direction.Both, left, right)", "response": "Parse a KEGG reaction string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a command and returns the result that would be written to stdout as a string.", "response": "def stdout_result(cmd, expected_errors=(), shell=True, sudo=False, quiet=False):\n    \"\"\"\n    Runs a command and returns the result, that would be written to `stdout`, as a string. The output itself can\n    be suppressed.\n\n    :param cmd: Command to run.\n    :type cmd: unicode\n    :param expected_errors: If the return code is non-zero, but found in this tuple, it will be ignored. ``None`` is\n      returned in this case.\n    :type expected_errors: tuple\n    :param shell: Use a shell.\n    :type shell: bool\n    :param sudo: Use `sudo`.\n    :type sudo: bool\n    :param quiet: If set to ``True``, does not show any output.\n    :type quiet: bool\n    :return: The result of the command as would be written to `stdout`.\n    :rtype: unicode\n    \"\"\"\n    which = operations.sudo if sudo else operations.run\n    with hide('warnings'):\n        result = which(cmd, shell=shell, quiet=quiet, warn_only=True)\n    if result.return_code == 0:\n        return result\n\n    if result.return_code not in expected_errors:\n        error(\"Received unexpected error code {0} while executing!\".format(result.return_code))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_line_stdout(cmd, expected_errors=(), shell=True, sudo=False, quiet=False):\n    return single_line(stdout_result(cmd, expected_errors, shell, sudo, quiet))", "response": "Runs a command and returns the first line of the output as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport and return model instance.", "response": "def import_model(self, source):\n        \"\"\"Import and return model instance.\"\"\"\n        if not hasattr(source, 'read'):  # Not a File-like object\n            with open(self._resolve_source(source), 'r') as f:\n                return self._import(f)\n        else:\n            return self._import(source)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds constraints to the model.", "response": "def add(self, *args):\n        \"\"\"Add constraints to the model.\"\"\"\n        self._constrs.extend(self._moma._prob.add_linear_constraints(*args))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield all the non exchange reactions in the model.", "response": "def _adjustment_reactions(self):\n        \"\"\"Yield all the non exchange reactions in the model.\"\"\"\n        for reaction_id in self._model.reactions:\n            if not self._model.is_exchange(reaction_id):\n                yield reaction_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves old constraints and then solve the current problem.", "response": "def _solve(self, sense=None):\n        \"\"\"Remove old constraints and then solve the current problem.\n\n        Args:\n            sense: Minimize or maximize the objective.\n                (:class:`.lp.ObjectiveSense)\n\n        Returns:\n            The Result object for the solved LP problem\n        \"\"\"\n        # Remove the constraints from the last run\n        while len(self._remove_constr) > 0:\n            self._remove_constr.pop().delete()\n\n        try:\n            return self._prob.solve(sense=sense)\n        except lp.SolverError as e:\n            raise_from(MOMAError(text_type(e)), e)\n        finally:\n            self._remove_constr = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsolving the wild type problem using FBA.", "response": "def solve_fba(self, objective):\n        \"\"\"Solve the wild type problem using FBA.\n\n        Args:\n            objective: The objective reaction to be maximized.\n\n        Returns:\n            The LP Result object for the solved FBA problem.\n        \"\"\"\n        self._prob.set_objective(self._v_wt[objective])\n        return self._solve(lp.ObjectiveSense.Maximize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of all the fluxes solved by FBA.", "response": "def get_fba_flux(self, objective):\n        \"\"\"Return a dictionary of all the fluxes solved by FBA.\n\n        Dictionary of fluxes is used in :meth:`.lin_moma` and :meth:`.moma`\n        to minimize changes in the flux distributions following model\n        perturbation.\n\n        Args:\n            objective: The objective reaction that is maximized.\n\n        Returns:\n            Dictionary of fluxes for each reaction in the model.\n        \"\"\"\n        flux_result = self.solve_fba(objective)\n        fba_fluxes = {}\n\n        # Place all the flux values in a dictionary\n        for key in self._model.reactions:\n            fba_fluxes[key] = flux_result.get_value(self._v_wt[key])\n        return fba_fluxes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the FBA solution that minimizes all the flux values.", "response": "def get_minimal_fba_flux(self, objective):\n        \"\"\"Find the FBA solution that minimizes all the flux values.\n\n        Maximize the objective flux then minimize all other fluxes\n        while keeping the objective flux at the maximum.\n\n        Args:\n            objective: The objective reaction that is maximized.\n\n        Returns:\n            A dictionary of all the reactions and their minimized fluxes.\n        \"\"\"\n        # Define constraints\n        vs_wt = self._v_wt.set(self._model.reactions)\n        zs = self._z.set(self._model.reactions)\n\n        wt_obj_flux = self.get_fba_obj_flux(objective)\n\n        with self.constraints() as constr:\n            constr.add(\n                zs >= vs_wt, vs_wt >= -zs,\n                self._v_wt[objective] >= wt_obj_flux)\n            self._prob.set_objective(self._z.sum(self._model.reactions))\n            result = self._solve(lp.ObjectiveSense.Minimize)\n\n        fba_fluxes = {}\n        for key in self._model.reactions:\n            fba_fluxes[key] = result.get_value(self._v_wt[key])\n        return fba_fluxes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the maximum objective flux solved by FBA.", "response": "def get_fba_obj_flux(self, objective):\n        \"\"\"Return the maximum objective flux solved by FBA.\"\"\"\n        flux_result = self.solve_fba(objective)\n        return flux_result.get_value(self._v_wt[objective])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lin_moma(self, wt_fluxes):\n        reactions = set(self._adjustment_reactions())\n\n        z_diff = self._z_diff\n        v = self._v\n\n        with self.constraints() as constr:\n            for f_reaction, f_value in iteritems(wt_fluxes):\n                if f_reaction in reactions:\n                    # Add the constraint that finds the optimal solution, such\n                    # that the difference between the wildtype flux is similar\n                    # to the knockout flux.\n                    constr.add(\n                        z_diff[f_reaction] >= f_value - v[f_reaction],\n                        f_value - v[f_reaction] >= -z_diff[f_reaction])\n\n            # If we minimize the sum of the z vector then we will minimize\n            # the |vs_wt - vs| from above\n            self._prob.set_objective(z_diff.sum(reactions))\n\n            self._solve(lp.ObjectiveSense.Minimize)", "response": "Minimize the redistribution of fluxes using a linear objective."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the smallest redistribution vector using a linear objective.", "response": "def lin_moma2(self, objective, wt_obj):\n        \"\"\"Find the smallest redistribution vector using a linear objective.\n\n        The change in flux distribution is mimimized by minimizing the sum\n        of the absolute values of the differences of wild type FBA solution\n        and the knockout strain flux solution.\n\n        Creates the constraint that the we select the optimal flux vector that\n        is closest to the wildtype. This might still return an arbitrary flux\n        vector the maximizes the objective function.\n\n        Args:\n            objective: Objective reaction for the model.\n            wt_obj: The flux value for your wild type objective reactions.\n                Can either use an expiremental value or on determined by FBA\n                by using :meth:`.get_fba_obj_flux(objective)`.\n        \"\"\"\n        reactions = set(self._adjustment_reactions())\n\n        z_diff = self._z_diff\n        v = self._v\n        v_wt = self._v_wt\n\n        with self.constraints() as constr:\n            for f_reaction in reactions:\n                # Add the constraint that finds the optimal solution, such\n                # that the difference between the wildtype flux\n                # is similar to the knockout flux.\n                constr.add(\n                    z_diff[f_reaction] >= v_wt[f_reaction] - v[f_reaction],\n                    v_wt[f_reaction] - v[f_reaction] >= -z_diff[f_reaction])\n\n            # If we minimize the sum of the z vector then we will minimize\n            # the |v_wt - v| from above\n            self._prob.set_objective(z_diff.sum(reactions))\n\n            constr.add(self._v_wt[objective] >= wt_obj)\n\n            self._solve(lp.ObjectiveSense.Minimize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nminimizing the redistribution of fluxes using a quadratic objective.", "response": "def moma(self, wt_fluxes):\n        \"\"\"Minimize the redistribution of fluxes using Euclidean distance.\n\n        Minimizing the redistribution of fluxes using a quadratic objective\n        function. The distance is minimized by minimizing the sum of\n        (wild type - knockout)^2.\n\n        Args:\n            wt_fluxes: Dictionary of all the wild type fluxes that will be\n                used to find a close MOMA solution. Fluxes can be expiremental\n                or calculated using :meth: get_fba_flux(objective).\n        \"\"\"\n        reactions = set(self._adjustment_reactions())\n        v = self._v\n\n        obj_expr = 0\n        for f_reaction, f_value in iteritems(wt_fluxes):\n            if f_reaction in reactions:\n                # Minimize the Euclidean distance between the two vectors\n                obj_expr += (f_value - v[f_reaction])**2\n\n        self._prob.set_objective(obj_expr)\n        self._solve(lp.ObjectiveSense.Minimize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the smallest redistribution vector using Euclidean distance.", "response": "def moma2(self, objective, wt_obj):\n        \"\"\"Find the smallest redistribution vector using Euclidean distance.\n\n        Minimizing the redistribution of fluxes using a quadratic objective\n        function. The distance is minimized by minimizing the sum of\n        (wild type - knockout)^2.\n\n        Creates the constraint that the we select the optimal flux vector that\n        is closest to the wildtype. This might still return an arbitrary flux\n        vector the maximizes the objective function.\n\n        Args:\n            objective: Objective reaction for the model.\n            wt_obj: The flux value for your wild type objective reactions.\n                Can either use an expiremental value or on determined by FBA\n                by using :meth:`.get_fba_obj_flux(objective)`.\n        \"\"\"\n        obj_expr = 0\n        for reaction in self._adjustment_reactions():\n            v_wt = self._v_wt[reaction]\n            v = self._v[reaction]\n            obj_expr += (v_wt - v)**2\n\n        self._prob.set_objective(obj_expr)\n\n        with self.constraints(self._v_wt[objective] >= wt_obj):\n            self._solve(lp.ObjectiveSense.Minimize)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the command line interface with the given :class:`Command`. If no command class is specified the user will be able to select a specific command through the first command line argument. If the ``args`` are provided, these should be a list of strings that will be used instead of ``sys.argv[1:]``. This is mostly useful for testing.", "response": "def main(command_class=None, args=None):\n    \"\"\"Run the command line interface with the given :class:`Command`.\n\n    If no command class is specified the user will be able to select a specific\n    command through the first command line argument. If the ``args`` are\n    provided, these should be a list of strings that will be used instead of\n    ``sys.argv[1:]``. This is mostly useful for testing.\n    \"\"\"\n\n    # Set up logging for the command line interface\n    if 'PSAMM_DEBUG' in os.environ:\n        level = getattr(logging, os.environ['PSAMM_DEBUG'].upper(), None)\n        if level is not None:\n            logging.basicConfig(level=level)\n    else:\n        logging.basicConfig(level=logging.INFO)\n        base_logger = logging.getLogger('psamm')\n        if len(base_logger.handlers) == 0:\n            handler = logging.StreamHandler()\n            handler.setFormatter(\n                logging.Formatter(u'%(levelname)s: %(message)s'))\n            base_logger.addHandler(handler)\n            base_logger.propagate = False\n\n    title = 'Metabolic modeling tools'\n    if command_class is not None:\n        title, _, _ = command_class.__doc__.partition('\\n\\n')\n\n    parser = argparse.ArgumentParser(description=title)\n    parser.add_argument('--model', metavar='file', default='.',\n                        help='Model definition')\n    parser.add_argument(\n        '-V', '--version', action='version',\n        version='%(prog)s ' + package_version)\n\n    if command_class is not None:\n        # Command explicitly given, only allow that command\n        command_class.init_parser(parser)\n        parser.set_defaults(command=command_class)\n    else:\n        # Discover all available commands\n        commands = {}\n        for entry in pkg_resources.iter_entry_points('psamm.commands'):\n            canonical = entry.name.lower()\n            if canonical not in commands:\n                command_class = entry.load()\n                commands[canonical] = command_class\n            else:\n                logger.warning('Command {} was found more than once!'.format(\n                    canonical))\n\n        # Create parsers for subcommands\n        subparsers = parser.add_subparsers(title='Commands', metavar='command')\n        for name, command_class in sorted(iteritems(commands)):\n            title, _, _ = command_class.__doc__.partition('\\n\\n')\n            subparser = subparsers.add_parser(\n                name, help=title.rstrip('.'),\n                formatter_class=argparse.RawDescriptionHelpFormatter,\n                description=_trim(command_class.__doc__))\n            subparser.set_defaults(command=command_class)\n            command_class.init_parser(subparser)\n\n    parsed_args = parser.parse_args(args)\n\n    # Load model definition\n    model = native.ModelReader.reader_from_path(\n        parsed_args.model).create_model()\n\n    # Instantiate command with model and run\n    command = parsed_args.command(model, parsed_args)\n    try:\n        command.run()\n    except CommandError as e:\n        parser.error(text_type(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_solver(self, **kwargs):\n        solver_args = dict(kwargs)\n        solver_args.update(self._solver_args)\n        return generic.Solver(**solver_args)", "response": "Return a new solver instance with the given kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_executor(self, handler, args, cpus_per_worker=1):\n        if self._args.parallel > 0:\n            workers = self._args.parallel\n        else:\n            try:\n                workers = mp.cpu_count() // cpus_per_worker\n            except NotImplementedError:\n                workers = 1\n\n        if workers != 1:\n            logger.info('Using {} parallel worker processes...'.format(\n                workers))\n            executor = ProcessPoolExecutor(\n                processes=workers, handler_init=handler, handler_args=args)\n        else:\n            logger.info('Using single worker...')\n            executor = SequentialExecutor(\n                handler_init=handler, handler_args=args)\n\n        return executor", "response": "Create a new executor instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_error(self, response):\n        \"Parse an error response\"\n        error_code = response.split(' ')[0]\n        if error_code in self.EXCEPTION_CLASSES:\n            response = response[len(error_code) + 1:]\n            return self.EXCEPTION_CLASSES[error_code](response)\n        return ResponseError(response)", "response": "Parse an error response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when the socket connects", "response": "def on_connect(self, connection):\n        \"\"\"\n        Called when the socket connects\n        \"\"\"\n        self._sock = connection._sock\n        self._buffer = SocketBuffer(self._sock, self.socket_read_size)        \n        if connection.decode_responses:\n            self.encoding = connection.encoding"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when the socket disconnects", "response": "def on_disconnect(self):\n        \"Called when the socket disconnects\"\n        if self._sock is not None:\n            self._sock.close()\n            self._sock = None\n        if self._buffer is not None:\n            self._buffer.close()\n            self._buffer = None\n        self.encoding = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self):\n        if self._sock:\n            return\n        try:\n            sock = self._connect()\n        except socket.error:\n            e = sys.exc_info()[1]\n            raise ConnectionError(self._error_message(e))\n\n        self._sock = sock\n        try:\n            self.on_connect()\n        except SSDBError:\n            # clean up after any error in on_connect\n            self.disconnect()\n            raise\n\n        # run any user callbacks. right now the only internal callback\n        # is for pubsub channel/pattern resubscription\n        for callback in self._connect_callbacks:\n            callback(self)", "response": "Connects to the SSDB server if not already connected."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to the server and return a TCP socket connection.", "response": "def _connect(self):\n        \"\"\"\n        Create a TCP socket connection\n        \"\"\"\n        # we want to mimic what socket.create_connection does to support\n        # ipv4/ipv6, but we want to set options prior to calling\n        # socket.connect()\n        err = None\n        for res in socket.getaddrinfo(self.host, self.port, 0,\n                                      socket.SOCK_STREAM):\n            family, socktype, proto, canonname, socket_address = res\n            sock = None\n            try:\n                sock = socket.socket(family, socktype, proto)\n                # TCP_NODELAY\n                sock.setsockopt(socket.IPPROTO_TCP,socket.TCP_NODELAY, 1)\n\n                # TCP_KEEPALIVE\n                if self.socket_keepalive:\n                    sock.setsockopt(socket.SOL_SOCKET,socket.SO_KEEPALIVE, 1)\n                    for k, v in iteritems(self.socket_keepalive_options):\n                        sock.setsockopt(socket.SOL_TCP, k, v)                \n\n                # set the socket_connect_timeout before we connect\n                sock.settimeout(self.socket_connect_timeout)\n                # connect\n                sock.connect(socket_address)\n                # set the socket_timeout now that we're connected\n                sock.settimeout(self.socket_timeout)\n                return sock                \n\n            except socket.error as _:\n                err = _\n                if sock is not None:\n                    sock.close()\n        if err is not None:\n            raise err\n        raise socket.error(\"socket.getaddrinfo returned an empty list\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisconnect from the SSDB server.", "response": "def disconnect(self):\n        \"\"\"\n        Disconnects from the SSDB server\n        \"\"\"\n        self._parser.on_disconnect()\n        if self._sock is None:\n            return\n        try:\n            self._sock.shutdown(socket.SHUT_RDWR)\n            self._sock.close()\n        except socket.error:\n            pass\n        self._sock = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npolls the socket to see if there s data that can be read.", "response": "def can_read(self, timeout=0):\n        \"Poll the socket to see if there's data that can be read.\"\n        sock = self._sock\n        if not sock:\n            self.connect()\n            sock = self._sock\n        return self._parser.can_read() or \\\n            bool(select([sock], [], [], timeout)[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the response from a previously sent command", "response": "def read_response(self):\n        \"\"\"\n        Read the response from a previously sent command\n        \"\"\"\n        try:\n            response = self._parser.read_response()\n        except:\n            self.disconnect()\n            raise\n        if isinstance(response, ResponseError):\n            raise response\n        #print(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode the value into a bytestring representation of the value.", "response": "def encode(self, value):\n        \"\"\"\n        Return a bytestring representation of the value\n        \"\"\"\n        if isinstance(value, Token):\n            return b(value.value)        \n        if isinstance(value, bytes):\n            return value\n        elif isinstance(value, (int, long)):\n            value = b(str(value))        \n        elif isinstance(value, float):\n            value = repr(value)\n        elif not isinstance(value, basestring):\n            value = str(value)\n        if isinstance(value, unicode):\n            value = value.encode(self.encoding, self.encoding_errors)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npacking a series of arguments into a value SSDB command.", "response": "def pack_command(self, *args):\n        \"\"\"\n        Pack a series of arguments into a value SSDB command\n        \"\"\"\n        # the client might have included 1 or more literal arguments in\n        # the command name, e.g., 'CONFIG GET'. The SSDB server expects\n        # these arguments to be sent separately, so split the first\n        # argument manually. All of these arguements get wrapped\n        # in the Token class to prevent them from being encoded.\n        command = args[0]\n        if ' ' in command:\n            args = tuple([Token(s) for s in command.split(' ')]) + args[1:]\n        else:\n            args = (Token(command),) + args[1:]\n        args_output = SYM_EMPTY.join([\n            SYM_EMPTY.join((\n                b(str(len(k))),\n                SYM_LF,\n                k,\n                SYM_LF\n            )) for k in imap(self.encode, args)\n        ])\n        output = \"%s%s\" % (args_output,SYM_LF)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_connection(self, command_name, *keys, **options):\n\n        # Make sure we haven't changed process.\n        self._checkpid()\n\n        # Try and get a connection from the pool. If one isn't available within\n        # self.timeout then raise a ``ConnectionError``.\n        connection = None\n        try:\n            connection = self.pool.get(block=True,timeout=self.timeout)\n        except Empty:\n            # Note that this is not caught by the redis client and will be\n            # raised unless handled by application code. If you want never to            \n            raise ConnectionError(\"No connection available.\")\n\n        # If the ``connection`` is actually ``None`` then that's a cue to make\n        # a new connection to add to the pool.\n        if connection is None:\n            connection = self.make_connection()\n\n        return connection", "response": "Get a connection from the pool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexpand a YAML node with the value stored in Fabric s env dictionary.", "response": "def expand_env_lazy(loader, node):\n    \"\"\"\n    Substitutes a variable read from a YAML node with the value stored in Fabric's ``env`` dictionary. Creates an\n    object for late resolution.\n\n    :param loader: YAML loader.\n    :type loader: yaml.loader.SafeLoader\n    :param node: Document node.\n    :type node: ScalarNode\n    :return: Corresponding value stored in the ``env`` dictionary.\n    :rtype: any\n    \"\"\"\n    val = loader.construct_scalar(node)\n    return lazy_once(env_get, val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compare_record_iter(a, b, fs_a=None, fs_b=None, options=None):\n    if not options:\n        options = DiffOptions()\n\n    if not options.duck_type and type(a) != type(b) and not (\n        a is _nothing or b is _nothing\n    ):\n        raise TypeError(\n            \"cannot compare %s with %s\" % (type(a).__name__, type(b).__name__)\n        )\n\n    if fs_a is None:\n        fs_a = FieldSelector(tuple())\n        fs_b = FieldSelector(tuple())\n\n    properties = (\n        type(a).properties if a is not _nothing else type(b).properties\n    )\n    for propname in sorted(properties):\n\n        prop = properties[propname]\n\n        if options.is_filtered(prop, fs_a + propname):\n            continue\n\n        propval_a = options.normalize_object_slot(\n            getattr(a, propname, _nothing), prop, a,\n        )\n        propval_b = options.normalize_object_slot(\n            getattr(b, propname, _nothing), prop, b,\n        )\n\n        if propval_a is _nothing and propval_b is _nothing:\n            # don't yield NO_CHANGE for fields missing on both sides\n            continue\n\n        one_side_nothing = (propval_a is _nothing) != (propval_b is _nothing)\n        types_match = type(propval_a) == type(propval_b)\n        comparable = (\n            isinstance(propval_a, COMPARABLE) or\n            isinstance(propval_b, COMPARABLE)\n        )\n        prop_fs_a = fs_a + [propname]\n        prop_fs_b = fs_b + [propname]\n\n        if comparable and (\n            types_match or options.duck_type or (\n                options.ignore_empty_slots and one_side_nothing\n            )\n        ):\n            if one_side_nothing:\n                diff_types_found = set()\n\n            for diff in _diff_iter(\n                propval_a, propval_b, prop_fs_a,\n                prop_fs_b, options,\n            ):\n                if one_side_nothing:\n                    if diff.diff_type != DiffTypes.NO_CHANGE:\n                        diff_types_found.add(diff.diff_type)\n                else:\n                    yield diff\n\n            if one_side_nothing:\n                net_diff = None\n                if diff_types_found:\n                    assert(len(diff_types_found) == 1)\n                    net_diff = tuple(diff_types_found)[0]\n                elif options.unchanged:\n                    net_diff = DiffTypes.NO_CHANGE\n                if net_diff:\n                    yield DiffInfo(\n                        diff_type=net_diff,\n                        base=prop_fs_a,\n                        other=prop_fs_b,\n                    )\n\n        elif one_side_nothing:\n            yield DiffInfo(\n                diff_type=(\n                    DiffTypes.ADDED if propval_a is _nothing else\n                    DiffTypes.REMOVED\n                ),\n                base=fs_a + [propname],\n                other=fs_b + [propname],\n            )\n\n        elif not options.items_equal(propval_a, propval_b):\n            yield DiffInfo(\n                diff_type=DiffTypes.MODIFIED,\n                base=fs_a + [propname],\n                other=fs_b + [propname],\n            )\n\n        elif options.unchanged:\n            yield DiffInfo(\n                diff_type=DiffTypes.NO_CHANGE,\n                base=fs_a + [propname],\n                other=fs_b + [propname],\n            )", "response": "This function returns an iterator over the differences found in a record by slot and yields DiffInfo objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compare_collection_iter(propval_a, propval_b, fs_a=None, fs_b=None,\n                            options=None):\n    \"\"\"Generator function to compare two collections, and yield differences.\n    This function does not currently report moved items in collections, and\n    uses the :py:meth:`DiffOptions.record_id` method to decide if objects are\n    to be considered the same, and differences within returned.\n\n    Arguments are the same as :py:func:`compare_record_iter`.\n\n    Note that ``diff_iter`` and ``compare_record_iter`` will call *both* this\n    function and ``compare_record_iter`` on ``RecordList`` types.  However, as\n    most ``RecordList`` types have no extra properties, no differences are\n    yielded by the ``compare_record_iter`` method.\n    \"\"\"\n    if fs_a is None:\n        fs_a = FieldSelector(tuple())\n        fs_b = FieldSelector(tuple())\n    if options is None:\n        options = DiffOptions()\n\n    propvals = dict(a=propval_a, b=propval_b)\n    values = dict()\n    rev_keys = dict()\n    compare_values = None\n    coll_type = (\n        type(propval_a) if propval_a is not _nothing else type(propval_b)\n    )\n    force_descent = (propval_a is _nothing) or (propval_b is _nothing)\n    if isinstance(coll_type.itemtype, tuple):\n        raise exc.CollectionItemTypeUnsupported()\n    elif not issubclass(coll_type.itemtype, Record):\n        iter_func = (\n            compare_dict_iter if issubclass(coll_type, DictCollection) else\n            compare_list_iter if issubclass(coll_type, ListCollection) else\n            None\n        )\n        if not iter_func:\n            raise exc.CollectionDiffUnsupported(\n                coll_type=coll_type,\n                item_type=coll_type.itemtype,\n                item_type_name=coll_type.itemtype.__name__,\n            )\n        for diff in iter_func(propval_a, propval_b, fs_a, fs_b, options):\n            yield diff\n        return\n\n    id_args = options.id_args(coll_type.itemtype, fs_a)\n    if not callable(id_args) and 'selector' in id_args and \\\n            not id_args['selector']:\n        # early exit shortcut\n        return\n\n    for x in \"a\", \"b\":\n        propval_x = propvals[x]\n        vals = values[x] = set()\n        rev_key = rev_keys[x] = dict()\n\n        seen = collections.Counter()\n\n        for k, v in collection_generator(propval_x):\n            if callable(id_args):\n                if fs_a + [k] not in options.compare_filter:\n                    continue\n            pk = options.record_id(\n                v, **(id_args(k) if callable(id_args) else id_args))\n            if options.ignore_empty_items and _nested_empty(pk):\n                continue\n            if compare_values is None:\n                # the primary key being a tuple is taken to imply that\n                # the value type is a Record, and hence descent is\n                # possible.\n                compare_values = isinstance(pk, tuple)\n            vals.add((pk, seen[pk]))\n            rev_key[(pk, seen[pk])] = k\n            seen[pk] += 1\n\n    if options.recurse:\n        # we can be sure that both records have these keys\n        set_a = set(rev_keys[\"a\"].values())\n        set_b = set(rev_keys[\"b\"].values())\n        shared_keys = set_a.intersection(set_b)\n        removed = set_a - set_b\n        added = set_b - set_a\n        for key in shared_keys:\n            if (isinstance(propval_a, collections.Iterable) and\n               isinstance(propval_b, collections.Iterable)):\n                diffs = _diff_iter(propval_a[key], propval_b[key],\n                                   fs_a + [key], fs_b + [key], options)\n\n                for diff in diffs:\n                    yield diff\n\n        for key in removed:\n            yield DiffInfo(diff_type=DiffTypes.REMOVED,\n                           base=fs_a + [key],\n                           other=fs_b)\n\n        for key in added:\n            yield DiffInfo(diff_type=DiffTypes.ADDED,\n                           base=fs_a,\n                           other=fs_b + [key])\n    else:\n        removed = values['a'] - values['b']\n        added = values['b'] - values['a']\n        common = values['a'].intersection(values['b'])\n\n        if compare_values or force_descent:\n            descendable = (removed | added) if force_descent else common\n\n            for pk, seq in descendable:\n                if not force_descent or propval_a is not _nothing:\n                    a_key = rev_keys['a'][pk, seq]\n                    a_val = propval_a[a_key]\n                if not force_descent or propval_b is not _nothing:\n                    b_key = rev_keys['b'][pk, seq]\n                    b_val = propval_b[b_key]\n                if force_descent:\n                    if propval_a is _nothing:\n                        a_key = b_key\n                        a_val = _nothing\n                    else:\n                        b_key = a_key\n                        b_val = _nothing\n                selector_a = fs_a + a_key\n                selector_b = fs_b + b_key\n                for diff in _diff_iter(\n                    a_val, b_val, selector_a, selector_b, options,\n                ):\n                    yield diff\n\n            if not force_descent and options.fuzzy_match:\n                for a_pk_seq, b_pk_seq in _fuzzy_match(removed, added):\n                    removed.remove(a_pk_seq)\n                    added.remove(b_pk_seq)\n                    a_key = rev_keys['a'][a_pk_seq]\n                    a_val = propval_a[a_key]\n                    b_key = rev_keys['b'][b_pk_seq]\n                    b_val = propval_b[b_key]\n                    selector_a = fs_a + a_key\n                    selector_b = fs_b + b_key\n                    any_diffs = False\n                    for diff in _diff_iter(\n                        a_val, b_val, selector_a, selector_b, options,\n                    ):\n                        if diff.diff_type != DiffTypes.NO_CHANGE:\n                            any_diffs = True\n                        yield diff\n\n                    if options.moved and a_key != b_key:\n                        yield DiffInfo(\n                            diff_type=DiffTypes.MOVED,\n                            base=fs_a + [a_key],\n                            other=fs_b + [b_key],\n                        )\n                    elif options.unchanged and not any_diffs:\n                        yield DiffInfo(\n                            diff_type=DiffTypes.NO_CHANGE,\n                            base=fs_a + [a_key],\n                            other=fs_b + [b_key],\n                        )\n\n        if options.unchanged or options.moved:\n            unchanged = values['a'] & values['b']\n            for pk, seq in unchanged:\n                a_key = rev_keys['a'][pk, seq]\n                b_key = rev_keys['b'][pk, seq]\n                if options.moved and a_key != b_key:\n                    yield DiffInfo(\n                        diff_type=DiffTypes.MOVED,\n                        base=fs_a + [a_key],\n                        other=fs_b + [b_key],\n                    )\n                elif options.unchanged:\n                    yield DiffInfo(\n                        diff_type=DiffTypes.NO_CHANGE,\n                        base=fs_a + [a_key],\n                        other=fs_b + [b_key],\n                    )\n\n        if not force_descent:\n            for pk, seq in removed:\n                a_key = rev_keys['a'][pk, seq]\n                selector = fs_a + [a_key]\n                yield DiffInfo(\n                    diff_type=DiffTypes.REMOVED,\n                    base=selector,\n                    other=fs_b,\n                )\n\n            for pk, seq in added:\n                b_key = rev_keys['b'][pk, seq]\n                selector = fs_b + [b_key]\n                yield DiffInfo(\n                    diff_type=DiffTypes.ADDED,\n                    base=fs_a,\n                    other=selector,\n                )", "response": "Generator function to compare two collections and yield differences."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compare_list_iter(propval_a, propval_b, fs_a=None, fs_b=None,\n                      options=None):\n    \"\"\"Generator for comparing 'simple' lists when they are encountered.  This\n    does not currently recurse further.  Arguments are as per other\n    ``compare_``\\ *X* functions.\n    \"\"\"\n    if fs_a is None:\n        fs_a = FieldSelector(tuple())\n        fs_b = FieldSelector(tuple())\n    if not options:\n        options = DiffOptions()\n    propvals = dict(a=propval_a, b=propval_b)\n    values = dict()\n    indices = dict()\n    for x in \"a\", \"b\":\n        propval_x = propvals[x]\n        vals = values[x] = set()\n        rev_key = indices[x] = dict()\n        seen = collections.Counter()\n        for i, v in collection_generator(propval_x):\n            v = options.normalize_item(\n                v, propval_a if options.duck_type else propval_x\n            )\n            if not v.__hash__:\n                v = repr(v)\n            if v is not _nothing or not options.ignore_empty_slots:\n                vals.add((v, seen[v]))\n                rev_key[(v, seen[v])] = i\n                seen[v] += 1\n\n    removed = values['a'] - values['b']\n    added = values['b'] - values['a']\n\n    if options.unchanged or options.moved:\n        unchanged = values['a'] & values['b']\n        for v, seq in unchanged:\n            a_idx = indices['a'][v, seq]\n            b_idx = indices['b'][v, seq]\n            if options.moved and a_idx != b_idx:\n                yield DiffInfo(\n                    diff_type=DiffTypes.MOVED,\n                    base=fs_a + [a_idx],\n                    other=fs_b + [b_idx],\n                )\n            elif options.unchanged:\n                yield DiffInfo(\n                    diff_type=DiffTypes.NO_CHANGE,\n                    base=fs_a + [a_idx],\n                    other=fs_b + [b_idx],\n                )\n\n    removed_idx = set(indices['a'][v, seq] for v, seq in removed)\n    added_idx = set(indices['b'][v, seq] for v, seq in added)\n    modified_idx = set(removed_idx.intersection(added_idx))\n\n    for v, seq in removed:\n        a_key = indices['a'][v, seq]\n        if a_key in modified_idx:\n            continue\n        selector = fs_a + [a_key]\n        yield DiffInfo(\n            diff_type=DiffTypes.REMOVED,\n            base=selector,\n            other=fs_b,\n        )\n\n    for v, seq in added:\n        b_key = indices['b'][v, seq]\n        if b_key in modified_idx:\n            continue\n        selector = fs_b + [b_key]\n        yield DiffInfo(\n            diff_type=DiffTypes.ADDED,\n            base=fs_a,\n            other=selector,\n        )\n\n    for idx in modified_idx:\n        yield DiffInfo(\n            diff_type=DiffTypes.MODIFIED,\n            base=fs_a + [idx],\n            other=fs_b + [idx],\n        )", "response": "Generator for comparing simple lists when they are encountered."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compare_dict_iter(propval_a, propval_b, fs_a=None, fs_b=None,\n                      options=None):\n    \"\"\"Generator for comparing 'simple' dicts when they are encountered.  This\n    does not currently recurse further.  Arguments are as per other\n    ``compare_``\\ *X* functions.\n    \"\"\"\n    if fs_a is None:\n        fs_a = FieldSelector(tuple())\n        fs_b = FieldSelector(tuple())\n    if not options:\n        options = DiffOptions()\n    propvals = dict(a=propval_a, b=propval_b)\n    values = dict()\n    rev_keys = dict()\n    for x in \"a\", \"b\":\n        propval_x = propvals[x]\n        vals = values[x] = set()\n        rev_key = rev_keys[x] = dict()\n        seen = collections.Counter()\n        for k, v in collection_generator(propval_x):\n            v = options.normalize_item(\n                v, propval_a if options.duck_type else propval_x\n            )\n            if not v.__hash__:\n                v = repr(v)\n            if v is not _nothing or not options.ignore_empty_slots:\n                vals.add((v, seen[v]))\n                rev_key[(v, seen[v])] = k\n                seen[v] += 1\n\n    removed = values['a'] - values['b']\n    added = values['b'] - values['a']\n\n    if options.moved or options.unchanged:\n        unchanged = values['a'] & values['b']\n        for v, seq in unchanged:\n            a_key = rev_keys['a'][v, seq]\n            b_key = rev_keys['b'][v, seq]\n            if options.moved and a_key != b_key:\n                yield DiffInfo(\n                    diff_type=DiffTypes.MOVED,\n                    base=fs_a + [a_key],\n                    other=fs_b + [b_key],\n                )\n            elif options.unchanged:\n                yield DiffInfo(\n                    diff_type=DiffTypes.NO_CHANGE,\n                    base=fs_a + [a_key],\n                    other=fs_b + [b_key],\n                )\n\n    removed_keys = set(rev_keys['a'][v, seq] for v, seq in removed)\n    added_keys = set(rev_keys['b'][v, seq] for v, seq in added)\n    modified_keys = set(removed_keys.intersection(added_keys))\n\n    for v, seq in removed:\n        a_key = rev_keys['a'][v, seq]\n        if a_key in modified_keys:\n            continue\n        selector = fs_a + [a_key]\n        yield DiffInfo(\n            diff_type=DiffTypes.REMOVED,\n            base=selector,\n            other=fs_b,\n        )\n\n    for v, seq in added:\n        b_key = rev_keys['b'][v, seq]\n        if b_key in modified_keys:\n            continue\n        selector = fs_b + [b_key]\n        yield DiffInfo(\n            diff_type=DiffTypes.ADDED,\n            base=fs_a,\n            other=selector,\n        )\n\n    for key in modified_keys:\n        yield DiffInfo(\n            diff_type=DiffTypes.MODIFIED,\n            base=fs_a + [key],\n            other=fs_b + [key],\n        )", "response": "Generator for comparing simple dicts when they are encountered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompare a Record with another object and yield differences as DiffInfo instances.", "response": "def diff_iter(base, other, options=None, **kwargs):\n    \"\"\"Compare a Record with another object (usually a record of the same\n    type), and yield differences as :py:class:`DiffInfo` instances.\n\n    args:\n        ``base=``\\ *Record*\n            The 'base' object to compare against.  The enumeration in\n            :py:class:`DiffTypes` is relative to this object.\n\n        ``other=``\\ *Record*\\ \\|\\ *<object>*\n            The 'other' object to compare against.  If ``duck_type`` is not\n            true, then it must be of the same type as the ``base``.\n\n        ``**kwargs``\n            Specify comparison options: ``duck_type``, ``ignore_ws``, etc.  See\n            :py:meth:`normalize.diff.DiffOptions.__init__` for the complete\n            list.\n\n        ``options=``\\ *DiffOptions instance*\n            Pass in a pre-constructed :py:class:`DiffOptions` instance.  This\n            may not be specified along with ``**kwargs``.\n    \"\"\"\n    if options is None:\n        options = DiffOptions(**kwargs)\n    elif len(kwargs):\n        raise exc.DiffOptionsException()\n\n    null_fs = FieldSelector(tuple())\n    return _diff_iter(base, other, null_fs, null_fs, options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff(base, other, **kwargs):\n    return Diff(diff_iter(base, other, **kwargs),\n                base_type_name=type(base).__name__,\n                other_type_name=type(other).__name__)", "response": "Eager version of diff_iter which takes all the same options\n    and returns a Diff instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_whitespace(self, value):\n        if isinstance(value, unicode):\n            return u\" \".join(\n                x for x in re.split(r'\\s+', value, flags=re.UNICODE) if\n                len(x)\n            )\n        else:\n            return \" \".join(value.split())", "response": "Normalizes whitespace ; called if ignore_ws is true."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_unf(self, value):\n        if isinstance(value, unicode):\n            return unicodedata.normalize('NFC', value)\n        else:\n            return value", "response": "Normalizes Unicode Normal Form to NFC."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhook which is called on every value before comparison and should return the scrubbed value or self. _nothing if the value is not set.", "response": "def normalize_val(self, value=_nothing):\n        \"\"\"Hook which is called on every value before comparison, and should\n        return the scrubbed value or ``self._nothing`` to indicate that the\n        value is not set.\n        \"\"\"\n        if isinstance(value, basestring):\n            value = self.normalize_text(value)\n        if self.ignore_empty_slots and self.value_is_empty(value):\n            value = _nothing\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_item(self, value=_nothing, coll=None, index=None):\n        if value is not _nothing and hasattr(coll, \"compare_item_as\"):\n            value = coll.compare_item_as(value)\n        return self.normalize_val(value)", "response": "This method is called by the item class to normalize the value of the item in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef record_id(self, record, type_=None, selector=None):\n        pk = record_id(record, type_, selector, self.normalize_object_slot)\n        return pk", "response": "Retrieve an object identifier from the given record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fastcc(model, epsilon, solver):\n    reaction_set = set(model.reactions)\n    subset = set(reaction_id for reaction_id in reaction_set\n                 if model.limits[reaction_id].lower >= 0)\n\n    logger.info('Checking {} irreversible reactions...'.format(len(subset)))\n    logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n\n    p = FastcoreProblem(model, solver, epsilon=epsilon)\n    p.lp7(subset)\n\n    consistent_subset = set(\n        reaction_id for reaction_id in model.reactions\n        if abs(p.get_flux(reaction_id)) >= 0.999 * epsilon)\n\n    logger.debug('|A| = {}, A = {}'.format(\n        len(consistent_subset), consistent_subset))\n\n    for reaction in subset - consistent_subset:\n        # Inconsistent reaction\n        yield reaction\n\n    # Check remaining reactions\n    subset = (reaction_set - subset) - consistent_subset\n\n    logger.info('Checking reversible reactions...')\n    logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n\n    flipped = False\n    singleton = False\n    while len(subset) > 0:\n        logger.info('{} reversible reactions left to check...'.format(\n            len(subset)))\n        if singleton:\n            reaction = next(iter(subset))\n            subset_i = {reaction}\n\n            logger.debug('LP3 on {}'.format(subset_i))\n            p.maximize({reaction: -1 if p.is_flipped(reaction) else 1})\n        else:\n            subset_i = subset\n\n            logger.debug('LP7 on {}'.format(subset_i))\n            p.lp7(subset_i)\n\n        consistent_subset.update(\n            reaction_id for reaction_id in subset\n            if abs(p.get_flux(reaction_id) >= 0.999 * epsilon))\n\n        logger.debug('|A| = {}, A = {}'.format(\n            len(consistent_subset), consistent_subset))\n\n        if not subset.isdisjoint(consistent_subset):\n            subset -= consistent_subset\n            logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n            flipped = False\n        else:\n            # TODO: irreversible reactions are taken care of before the\n            # loop so at this point all reactions in subset_i are reversble(?).\n            subset_rev_i = subset_i & model.reversible\n            if flipped or len(subset_rev_i) == 0:\n                flipped = False\n                if singleton:\n                    subset -= subset_rev_i\n                    for reaction in subset_rev_i:\n                        logger.info('Inconsistent: {}'.format(reaction))\n                        yield reaction\n                else:\n                    singleton = True\n            else:\n                p.flip(subset_rev_i)\n                flipped = True\n                logger.info('Flipped {} reactions'.format(len(subset_rev_i)))", "response": "Yield all reactions in the model that are not part of the consistent set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fastcc_consistent_subset(model, epsilon, solver):\n    reaction_set = set(model.reactions)\n    return reaction_set.difference(fastcc(model, epsilon, solver))", "response": "Return a set of reaction IDs that are consistent with the given model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a flux consistent subnetwork containing the core subset.", "response": "def fastcore(model, core, epsilon, solver, scaling=1e5, weights={}):\n    \"\"\"Find a flux consistent subnetwork containing the core subset.\n\n    The result will contain the core subset and as few of the additional\n    reactions as possible.\n\n    Args:\n        model: :class:`MetabolicModel` to solve.\n        core: Set of core reaction IDs.\n        epsilon: Flux threshold value.\n        solver: LP solver instance to use.\n        scaling: Scaling value to apply (see [Vlassis14]_ for more\n            information on this parameter).\n        weights: Dictionary with reaction IDs as keys and values as weights.\n            Weights specify the cost of adding a reaction to the consistent\n            subnetwork. Default value is 1.\n\n    Returns:\n        Set of reaction IDs in the consistent reaction subset.\n    \"\"\"\n    consistent_subset = set()\n    reaction_set = set(model.reactions)\n\n    subset = core - model.reversible\n    logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n\n    penalty_set = reaction_set - core\n    logger.debug('|P| = {}, P = {}'.format(len(penalty_set), penalty_set))\n\n    p = FastcoreProblem(model, solver, epsilon=epsilon)\n    mode = set(p.find_sparse_mode(subset, penalty_set, scaling, weights))\n    if not subset.issubset(mode):\n        raise FastcoreError('Inconsistent irreversible core reactions:'\n                            ' {}'.format(subset - mode))\n\n    consistent_subset |= mode\n    logger.debug('|A| = {}, A = {}'.format(\n        len(consistent_subset), consistent_subset))\n\n    subset = core - mode\n    logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n\n    flipped = False\n    singleton = False\n    while len(subset) > 0:\n        penalty_set -= consistent_subset\n        if singleton:\n            subset_i = set((next(iter(subset)),))\n        else:\n            subset_i = subset\n\n        mode = set(p.find_sparse_mode(subset_i, penalty_set, scaling, weights))\n        consistent_subset.update(mode)\n        logger.debug('|A| = {}, A = {}'.format(\n            len(consistent_subset), consistent_subset))\n\n        if not subset.isdisjoint(consistent_subset):\n            logger.debug('Subset improved {} -> {}'.format(\n                len(subset), len(subset - consistent_subset)))\n            subset -= consistent_subset\n            logger.debug('|J| = {}, J = {}'.format(len(subset), subset))\n            flipped = False\n        else:\n            logger.debug('Nothing found, changing state...')\n            subset_rev_i = subset_i & model.reversible\n            if flipped or len(subset_rev_i) == 0:\n                if singleton:\n                    raise FastcoreError('Global network inconsistent:'\n                                        ' {}'.format(subset_rev_i))\n\n                logger.debug('Going to non-flipped, singleton state...')\n                singleton = True\n                flipped = False\n            else:\n                p.flip(subset_rev_i)\n                flipped = True\n                logger.debug('Flipped {} reactions'.format(\n                    len(subset_rev_i)))\n\n    return consistent_subset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaximizing the number of reactions in subset with flux > epsilon.", "response": "def lp7(self, reaction_subset):\n        \"\"\"Approximately maximize the number of reaction with flux.\n\n        This is similar to FBA but approximately maximizing the number of\n        reactions in subset with flux > epsilon, instead of just maximizing the\n        flux of one particular reaction. LP7 prefers \"flux splitting\" over\n        \"flux concentrating\".\n        \"\"\"\n\n        if self._zl is None:\n            self._add_maximization_vars()\n\n        positive = set(reaction_subset) - self._flipped\n        negative = set(reaction_subset) & self._flipped\n\n        v = self._v.set(positive)\n        zl = self._zl.set(positive)\n        cs = self._prob.add_linear_constraints(v >= zl)\n        self._temp_constr.extend(cs)\n\n        v = self._v.set(negative)\n        zl = self._zl.set(negative)\n        cs = self._prob.add_linear_constraints(v <= -zl)\n        self._temp_constr.extend(cs)\n\n        self._prob.set_objective(self._zl.sum(reaction_subset))\n\n        self._solve()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nforce reactions in K above epsilon while minimizing support of P. This program forces reactions in subset K to attain flux > epsilon while minimizing the sum of absolute flux values for reactions in subset P (L1-regularization).", "response": "def lp10(self, subset_k, subset_p, weights={}):\n        \"\"\"Force reactions in K above epsilon while minimizing support of P.\n\n        This program forces reactions in subset K to attain flux > epsilon\n        while minimizing the sum of absolute flux values for reactions\n        in subset P (L1-regularization).\n        \"\"\"\n\n        if self._z is None:\n            self._add_minimization_vars()\n\n        positive = set(subset_k) - self._flipped\n        negative = set(subset_k) & self._flipped\n\n        v = self._v.set(positive)\n        cs = self._prob.add_linear_constraints(v >= self._epsilon)\n        self._temp_constr.extend(cs)\n\n        v = self._v.set(negative)\n        cs = self._prob.add_linear_constraints(v <= -self._epsilon)\n        self._temp_constr.extend(cs)\n\n        self._prob.set_objective(self._z.expr(\n            (rxnid, -weights.get(rxnid, 1)) for rxnid in subset_p))\n\n        self._solve()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind a sparse mode containing reactions of the core subset.", "response": "def find_sparse_mode(self, core, additional, scaling, weights={}):\n        \"\"\"Find a sparse mode containing reactions of the core subset.\n\n        Return an iterator of the support of a sparse mode that contains as\n        many reactions from core as possible, and as few reactions from\n        additional as possible (approximately). A dictionary of weights can be\n        supplied which gives further penalties for including specific\n        additional reactions.\n        \"\"\"\n\n        if len(core) == 0:\n            return\n\n        self.lp7(core)\n        k = set()\n        for reaction_id in core:\n            flux = self.get_flux(reaction_id)\n            if self.is_flipped(reaction_id):\n                flux *= -1\n            if flux >= self._epsilon:\n                k.add(reaction_id)\n\n        if len(k) == 0:\n            return\n\n        self.lp10(k, additional, weights)\n        for reaction_id in self._model.reactions:\n            flux = self.get_flux(reaction_id)\n            if abs(flux) >= self._epsilon / scaling:\n                yield reaction_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flip(self, reactions):\n        for reaction in reactions:\n            if reaction in self._flipped:\n                self._flipped.remove(reaction)\n            else:\n                self._flipped.add(reaction)", "response": "Flip the specified reactions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the generalized Jaccard similarity of formulas.", "response": "def _jaccard_similarity(f1, f2, weight_func):\n    \"\"\"Calculate generalized Jaccard similarity of formulas.\n\n    Returns the weighted similarity value or None if there is no overlap\n    at all. If the union of the formulas has a weight of zero (i.e. the\n    denominator in the Jaccard similarity is zero), a value of zero is\n    returned.\n    \"\"\"\n    elements = set(f1)\n    elements.update(f2)\n\n    count, w_count, w_total = 0, 0, 0\n    for element in elements:\n        mi = min(f1.get(element, 0), f2.get(element, 0))\n        mx = max(f1.get(element, 0), f2.get(element, 0))\n        count += mi\n        w = weight_func(element)\n        w_count += w * mi\n        w_total += w * mx\n\n    if count == 0:\n        return None\n\n    return 0.0 if w_total == 0.0 else w_count / w_total"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _reaction_to_dicts(reaction):\n    def dict_from_iter_sum(it, div):\n        d = {}\n        for k, v in it:\n            if k not in d:\n                d[k] = 0\n            d[k] += int(v / div)\n        return d\n\n    div = reduce(gcd, (abs(v) for _, v in reaction.compounds), 0)\n    if div == 0:\n        raise ValueError('Empty reaction')\n\n    left = dict_from_iter_sum(reaction.left, div)\n    right = dict_from_iter_sum(reaction.right, div)\n\n    return left, right", "response": "Convert a reaction to reduced left right dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict_compound_pairs_iterated(\n        reactions, formulas, prior=(1, 43), max_iterations=None,\n        element_weight=element_weight):\n    \"\"\"Predict reaction pairs using iterated method.\n\n    Returns a tuple containing a dictionary of predictions keyed by the\n    reaction IDs, and the final number of iterations. Each reaction prediction\n    entry contains a tuple with a dictionary of transfers and a dictionary of\n    unbalanced compounds. The dictionary of unbalanced compounds is empty only\n    if the reaction is balanced.\n\n    Args:\n        reactions: Dictionary or pair-iterable of (id, equation) pairs.\n            IDs must be any hashable reaction identifier (e.g. string) and\n            equation must be :class:`psamm.reaction.Reaction` objects.\n        formulas: Dictionary mapping compound IDs to\n            :class:`psamm.formula.Formula`. Formulas must be flattened.\n        prior: Tuple of (alpha, beta) parameters for the MAP inference.\n            If not provided, the default parameters will be used: (1, 43).\n        max_iterations: Maximum iterations to run before stopping. If the\n            stopping condition is reached before this number of iterations,\n            the procedure also stops. If None, the procedure only stops when\n            the stopping condition is reached.\n        element_weight: A function providing returning weight value for the\n            given :class:`psamm.formula.Atom` or\n            :class:`psamm.formula.Radical`. If not provided, the default weight\n            will be used (H=0, C=1, *=0.82)\n    \"\"\"\n    prior_alpha, prior_beta = prior\n    reactions = dict(reactions)\n\n    pair_reactions = {}\n    possible_pairs = Counter()\n    for reaction_id, equation in iteritems(reactions):\n        for (c1, _), (c2, _) in product(equation.left, equation.right):\n            spair = tuple(sorted([c1.name, c2.name]))\n            possible_pairs[spair] += 1\n            pair_reactions.setdefault(spair, set()).add(reaction_id)\n\n    next_reactions = set(reactions)\n    pairs_predicted = None\n    prediction = {}\n    weights = {}\n    iteration = 0\n    while len(next_reactions) > 0:\n        iteration += 1\n        if max_iterations is not None and iteration > max_iterations:\n            break\n\n        logger.info('Iteration {}: {} reactions...'.format(\n            iteration, len(next_reactions)))\n\n        for reaction_id in next_reactions:\n            result = predict_compound_pairs(\n                reactions[reaction_id], formulas, weights, element_weight)\n            if result is None:\n                continue\n\n            transfer, balance = result\n\n            rpairs = {}\n            for ((c1, _), (c2, _)), form in iteritems(transfer):\n                rpairs.setdefault((c1, c2), []).append(form)\n\n            prediction[reaction_id] = rpairs, balance\n\n        pairs_predicted = Counter()\n        for reaction_id, (rpairs, _) in iteritems(prediction):\n            for c1, c2 in rpairs:\n                spair = tuple(sorted([c1.name, c2.name]))\n                pairs_predicted[spair] += 1\n\n        next_reactions = set()\n        for spair, total in sorted(iteritems(possible_pairs)):\n            pred = pairs_predicted[spair]\n\n            # The weight is set to the maximum a posteriori (MAP) estimate\n            # of the primary pair probability distribution.\n            posterior_alpha = prior_alpha + pred\n            posterior_beta = prior_beta + total - pred\n            pair_weight = ((posterior_alpha - 1) /\n                           (posterior_alpha + posterior_beta - 2))\n\n            if (spair not in weights or\n                    abs(pair_weight - weights[spair]) > 1e-5):\n                next_reactions.update(pair_reactions[spair])\n\n            c1, c2 = spair\n            weights[c1, c2] = pair_weight\n            weights[c2, c1] = pair_weight\n\n    return prediction, iteration", "response": "Predict reaction pairs using iterated method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _match_greedily(reaction, compound_formula, score_func):\n    uninstantiated_left, uninstantiated_right = _reaction_to_dicts(reaction)\n\n    def compound_instances(uninstantiated):\n        instances = []\n        for compound, value in iteritems(uninstantiated):\n            if value > 0:\n                f = compound_formula[compound.name]\n                instances.append(_CompoundInstance(compound, value, f))\n\n        for inst in instances:\n            uninstantiated[inst.compound] -= 1\n\n        return instances\n\n    def instantiate(uninstantiated, compound):\n        n = uninstantiated[compound]\n        if n > 0:\n            f = compound_formula[compound.name]\n            inst = _CompoundInstance(compound, n, f)\n            uninstantiated[compound] -= 1\n            return inst\n\n        return None\n\n    left = compound_instances(uninstantiated_left)\n    right = compound_instances(uninstantiated_right)\n    instances = left + right\n\n    pairs = {}\n    for inst1, inst2 in product(left, right):\n        result = score_func(inst1, inst2)\n        if result is not None:\n            pairs[inst1, inst2] = result\n\n    def inst_pair_sort_key(entry):\n        \"\"\"Sort key for finding best match among instance pairs.\n\n        Rank by score in general but always match identical compounds first\n        (these will always have score equal to one but are handled specially\n        to put them ahead of other compounds with score equal to one). Use\n        compound names to break ties to produce a deterministic result.\n        \"\"\"\n        (inst1, inst2), score = entry\n        c1, c2 = inst1.compound, inst2.compound\n        same_compound = c1.name == c2.name and c1.compartment != c2.compartment\n        return same_compound, score, c1.name, c2.name\n\n    transfer = {}\n    while len(pairs) > 0:\n        (inst1, inst2), _ = max(iteritems(pairs), key=inst_pair_sort_key)\n        common = inst1.formula & inst2.formula\n\n        key = (inst1.compound, inst1.index), (inst2.compound, inst2.index)\n        if key not in transfer:\n            transfer[key] = Formula()\n        transfer[key] |= common\n\n        for inst in (inst1, inst2):\n            inst.formula -= common\n\n        to_insert = set()\n\n        inst = instantiate(uninstantiated_left, inst1.compound)\n        if inst is not None:\n            left.append(inst)\n            instances.append(inst)\n            to_insert.add(inst)\n\n        inst = instantiate(uninstantiated_right, inst2.compound)\n        if inst is not None:\n            right.append(inst)\n            instances.append(inst)\n            to_insert.add(inst)\n\n        to_update = {inst1, inst2}\n\n        to_delete = set()\n        for inst1, inst2 in pairs:\n            if inst1 in to_update or inst2 in to_update:\n                if len(inst1.formula) > 0 and len(inst2.formula) > 0:\n                    result = score_func(inst1, inst2)\n                    if result is None:\n                        to_delete.add((inst1, inst2))\n                    else:\n                        pairs[inst1, inst2] = result\n                else:\n                    to_delete.add((inst1, inst2))\n\n        for pair in to_delete:\n            del pairs[pair]\n\n        for inst1, inst2 in product(left, right):\n            if inst1 in to_insert or inst2 in to_insert:\n                result = score_func(inst1, inst2)\n                if result is not None:\n                    pairs[inst1, inst2] = result\n\n    balance = {}\n    for inst in instances:\n        if len(inst.formula) > 0:\n            key = inst.compound, inst.index\n            balance[key] = inst.formula\n\n    return transfer, balance", "response": "Match compounds greedily based on score function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npredicts the pair of pairs for a single reaction.", "response": "def predict_compound_pairs(reaction, compound_formula, pair_weights={},\n                           weight_func=element_weight):\n    \"\"\"Predict compound pairs for a single reaction.\n\n    Performs greedy matching on reaction compounds using a scoring function\n    that uses generalized Jaccard similarity corrected by the weights in the\n    given dictionary. Returns a tuple of a transfer dictionary and a dictionary\n    of unbalanced compounds. The dictionary of unbalanced compounds is empty\n    only if the reaction is balanced.\n\n    Args:\n        reaction: :class:`psamm.reaction.Reaction`.\n        compound_formula: Dictionary mapping compound IDs to\n            :class:`psamm.formula.Formula`. Formulas must be flattened.\n        pair_weights: Dictionary mapping pairs of compound IDs to correction\n            values. This value is multiplied by the calculated Jaccard\n            similarity. If a pair is not in the dictionary, the value 1 is\n            used. Pairs are looked up in the weights dictionary as a tuple of\n            compound names (``c1``, ``c2``) where ``c1`` is the left-hand side\n            and ``c2`` is the right-hand side.\n        weight_func: Weight function for caclulating the generalized Jaccard\n            similarity. This function will be given an\n            :class:`psamm.formula.Atom` or :class:`psamm.formula.Radical` and\n            should return a corresponding weight.\n    \"\"\"\n    def score_func(inst1, inst2):\n        score = _jaccard_similarity(\n            inst1.formula, inst2.formula, weight_func)\n        if score is None:\n            return None\n        pair = inst1.compound.name, inst2.compound.name\n        pair_weight = pair_weights.get(pair, 1.0)\n        return pair_weight * score\n\n    return _match_greedily(reaction, compound_formula, score_func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches all resources for a charm.", "response": "def fetch(which=None, mirror_url=None, resources_yaml='resources.yaml',\n          force=False, reporthook=None):\n    \"\"\"\n    Attempt to fetch all resources for a charm.\n\n    :param list which: A name, or a list of one or more resource names, to\n        fetch.  If ommitted, all non-optional resources are fetched.\n        You can also pass ``jujuresources.ALL`` to fetch all optional *and*\n        required resources.\n    :param str mirror_url: Fetch resources from the given mirror.\n    :param str resources_yaml: Location of the yaml file containing the\n        resource descriptions (default: ``./resources.yaml``).\n        Can be a local file name or a remote URL.\n    :param force bool: Force re-downloading of valid resources.\n    :param func reporthook: Callback for reporting download progress.\n        Will be called once for each resource, just prior to fetching, and will\n        be passed the resource name.\n    :return: True or False indicating whether the resources were successfully\n        downloaded.\n    \"\"\"\n    resources = _load(resources_yaml, None)\n    if reporthook is None:\n        reporthook = lambda r: juju_log('Fetching %s' % r, level='INFO')\n    _fetch(resources, which, mirror_url, force, reporthook)\n    failed = _invalid(resources, which)\n    if failed:\n        juju_log('Failed to fetch resource%s: %s' % (\n            's' if len(failed) > 1 else '',\n            ', '.join(failed)\n        ), level='WARNING')\n    else:\n        juju_log('All resources successfully fetched', level='INFO')\n    return not failed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install(which=None, mirror_url=None, destination=None, skip_top_level=False,\n            resources_yaml='resources.yaml'):\n    \"\"\"\n    Install one or more resources.\n\n    The resource(s) will be fetched, if necessary, and different resource\n    types are handled appropriately (e.g., PyPI resources are installed\n    with ``pip``, archive file resources are extracted, non-archive file\n    resources are copied, etc).\n\n    For PyPI resources, this is roughly equivalent to the following::\n\n        pip install `juju-resources resource_spec $resource` -i $mirror_url\n\n    :param list which: A name, or a list of one or more resource names, to\n        fetch.  If ommitted, all non-optional resources are installed.\n    :param str mirror_url: Fetch resources from the given mirror.\n    :param str destination: Destination to which to extract or copy file resources.\n    :param bool skip_top_level: When extracting archive file resources, skip\n        all members that are at the top level of the archive and instead extract\n        all nested members directly into ``destination``.  E.g., an archive\n        containing ``foo/bar.txt`` and ``foo/qux/baz.txt`` will be extracted as\n        ``destination/bar.txt`` and ``destination/qux/baz.txt``.\n    :param str resources_yaml: Location of the yaml file containing the\n        resource descriptions (default: ``resources.yaml``).\n        Can be a local file name or a remote URL.\n    :returns: True if all resources were successfully installed.\n    \"\"\"\n    resources = _load(resources_yaml, None)\n    return _install(resources, which, mirror_url, destination, skip_top_level)", "response": "Install one or more resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a command set for controlling a specific bridge and led type.", "response": "def command_set_factory(bridge, group_number, led_type):\n    \"\"\"\n    Create command set for controlling a specific led group.\n    :param bridge: The bridge the leds are connected to.\n    :param group_number: The group number.\n    :param led_type: The type of the leds.\n    :return: The created command set.\n    \"\"\"\n    from limitlessled.group.commands.legacy import (\n        CommandSetWhiteLegacy, CommandSetRgbwLegacy)\n    from limitlessled.group.commands.v6 import (\n        CommandSetBridgeLightV6, CommandSetWhiteV6,\n        CommandSetDimmerV6, CommandSetRgbwV6,\n        CommandSetRgbwwV6, CommandSetWrgbV6)\n\n    command_sets = [CommandSetWhiteLegacy, CommandSetRgbwLegacy,\n                    CommandSetBridgeLightV6, CommandSetWhiteV6,\n                    CommandSetDimmerV6, CommandSetRgbwV6,\n                    CommandSetRgbwwV6, CommandSetWrgbV6]\n    try:\n        cls = next(cs for cs in command_sets if\n                   bridge.version in cs.SUPPORTED_VERSIONS and\n                   led_type in cs.SUPPORTED_LED_TYPES)\n        return cls(group_number)\n    except StopIteration:\n        raise ValueError('There is no command set for '\n                         'specified bridge version and led type.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming the LiveReload request.", "response": "def livereload_request(self, **options):\n        \"\"\"\n        Performs the LiveReload request.\n        \"\"\"\n        style = color_style()\n        verbosity = int(options['verbosity'])\n        host = '%s:%s' % (options['livereload_host'],\n                          options['livereload_port'])\n        try:\n            urlopen('http://%s/changed?files=.' % host)\n            self.message('LiveReload request emitted.\\n',\n                         verbosity, style.HTTP_INFO)\n        except IOError as e:\n            self.stdout.write(\n                self.style.WARNING('LiveReload exception: %s' % e)\n            )\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_handler(self, *args, **options):\n        handler = super(Command, self).get_handler(*args, **options)\n        if options['use_livereload']:\n            self.livereload_request(**options)\n        return handler", "response": "Get the handler for this command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rate(wait=MIN_WAIT, reps=REPS):\n    def decorator(function):\n        \"\"\" Decorator function.\n\n        :returns: Wrapper.\n        \"\"\"\n        def wrapper(self, *args, **kwargs):\n            \"\"\" Wrapper.\n\n            :param args: Passthrough positional arguments.\n            :param kwargs: Passthrough keyword arguments.\n            \"\"\"\n            saved_wait = self.wait\n            saved_reps = self.reps\n            self.wait = wait\n            self.reps = reps\n            function(self, *args, **kwargs)\n            self.wait = saved_wait\n            self.reps = saved_reps\n        return wrapper\n    return decorator", "response": "Rate limit a command function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns on or off.", "response": "def on(self, state):\n        \"\"\" Turn on or off.\n\n        :param state: True (on) or False (off).\n        \"\"\"\n        self._on = state\n        cmd = self.command_set.off()\n        if state:\n            cmd = self.command_set.on()\n        self.send(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flash(self, duration=0.0):\n        for _ in range(2):\n            self.on = not self.on\n            time.sleep(duration)", "response": "Flash a group.\n\n        :param duration: How quickly to flash (in seconds)."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a command to the bridge.", "response": "def send(self, cmd):\n        \"\"\" Send a command to the bridge.\n\n        :param cmd: List of command bytes.\n        \"\"\"\n        self._bridge.send(cmd, wait=self.wait, reps=self.reps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enqueue(self, pipeline):\n        copied = Pipeline().append(pipeline)\n        copied.group = self\n        self._queue.put(copied)", "response": "Enqueue a new pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _wait(self, duration, steps, commands):\n        wait = ((duration - self.wait * self.reps * commands) / steps) - \\\n               (self.wait * self.reps * self._bridge.active)\n        return max(0, wait)", "response": "Compute wait time.\n\n        :param duration: Total time (in seconds).\n        :param steps: Number of steps.\n        :param commands: Number of commands.\n        :returns: Wait in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scale_steps(self, duration, commands, *steps):\n        factor = duration / ((self.wait * self.reps * commands) - \\\n                 (self.wait * self.reps * self._bridge.active))\n        steps = [math.ceil(factor * step) for step in steps]\n        if len(steps) == 1:\n            return steps[0]\n        else:\n            return steps", "response": "Scale the number of steps to time and total."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, name, definition, output_dir):\n        if 'url' in definition:\n            return URLResource(name, definition, output_dir)\n        elif 'pypi' in definition:\n            return PyPIResource(name, definition, output_dir)\n        else:\n            return Resource(name, definition, output_dir)", "response": "Dispatch to the right subclass based on the definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks for tar file that is bugged.", "response": "def _is_bugged_tarfile(self):\n        \"\"\"\n        Check for tar file that tarfile library mistakenly reports as invalid.\n        Happens with tar files created on FAT systems.  See:\n        http://stackoverflow.com/questions/25552162/tarfile-readerror-file-could-not-be-opened-successfully\n        \"\"\"\n        try:\n            output = subprocess.check_output(['file', '-z', self.destination]).decode('utf8')\n            return 'tar archive' in output and 'gzip compressed data' in output\n        except subprocess.CalledProcessError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_bugged_tarfile(self, destination, skip_top_level):\n        args = ['tar', '-xzf', self.destination, '-C', destination]\n        if skip_top_level:\n            args.extend(['--strip-components', '1'])\n        subprocess.check_call(args)", "response": "Handle bugged tar files created on FAT systems."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrying Use magic instead of code to get a string for the correct log level when calling ``print_log_msg``. Because writing the same boilerplate code in each log_XXX def was too painful to commit.", "response": "def log_wrap(origfunc):\n    \"\"\"\n    DRY: Use magic instead of code to get a string for the correct log\n    level when calling ``print_log_msg``. Because writing the same\n    boilerplate code in each log_XXX def was too painful to commit.\n    \"\"\"\n    def orig_func_wraper(msg, *args):\n        # Take the callers name and snap it in two, result is log\n        # level, e.g.: log_debug is DEBUG level.\n        log_level = origfunc.__name__.split(\"_\")[1]\n\n        import Log\n        if getattr(Log, \"LOG_%s\" % log_level.upper()) <= \\\n                Log.LOG_LEVEL_CURRENT:\n            # flatten and stringify the positional params so we don't\n            # tuple() a tuple or an array and end up with\n            # weirdness.\n            a = map(str, juicer.utils.flatten(args))\n            print_log_msg(log_level, str(msg) % tuple(a))\n    return orig_func_wraper"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the pipeline queue.", "response": "def run(self):\n        \"\"\" Run the pipeline queue.\n\n        The pipeline queue will run forever.\n        \"\"\"\n        while True:\n            self._event.clear()\n            self._queue.get().run(self._event)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, stop):\n        _LOGGER.info(\"Starting a new pipeline on group %s\", self._group)\n        self._group.bridge.incr_active()\n        for i, stage in enumerate(self._pipe):\n            self._execute_stage(i, stage, stop)\n        _LOGGER.info(\"Finished pipeline on group %s\", self._group)\n        self._group.bridge.decr_active()", "response": "Run the pipeline.\n\n        :param stop: Stop event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append(self, pipeline):\n        for stage in pipeline.pipe:\n            self._pipe.append(stage)\n        return self", "response": "Append a pipeline to this list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds stage methods at runtime.", "response": "def _add_stage(self, name):\n        \"\"\" Add stage methods at runtime.\n\n        Stage methods all follow the same pattern.\n\n        :param name: Stage name.\n        \"\"\"\n        def stage_func(self, *args, **kwargs):\n            \"\"\" Stage function.\n\n            :param args: Positional arguments.\n            :param kwargs: Keyword arguments.\n            :return: Pipeline (for method chaining).\n            \"\"\"\n            self._pipe.append(Stage(name, args, kwargs))\n            return self\n\n        setattr(Pipeline, name, stage_func)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a pipeline stage.", "response": "def _execute_stage(self, index, stage, stop):\n        \"\"\" Execute a pipeline stage.\n\n        :param index: Stage index.\n        :param stage: Stage object.\n        \"\"\"\n        if stop.is_set():\n            _LOGGER.info(\"Stopped pipeline on group %s\", self._group)\n            return\n        _LOGGER.info(\" -> Running stage '%s' on group %s\", stage, self._group)\n        if stage.name == 'on':\n            self._group.on = True\n        elif stage.name == 'off':\n            self._group.on = False\n        elif stage.name == 'hue':\n            self._group.hue = stage.args[0]\n        elif stage.name == 'saturation':\n            self._group.saturation = stage.args[0]\n        elif stage.name == 'color':\n            self._group.color = Color(*stage.args)\n        elif stage.name == 'brightness':\n            self._group.brightness = stage.args[0]\n        elif stage.name == 'temperature':\n            self._group.temperature = stage.args[0]\n        elif stage.name == 'transition':\n            self._group.transition(*stage.args, **stage.kwargs)\n        elif stage.name == 'white':\n            self._group.white()\n        elif stage.name == 'white_up':\n            self._group.white_up()\n        elif stage.name == 'white_down':\n            self._group.white_down()\n        elif stage.name == 'red_up':\n            self._group.red_up()\n        elif stage.name == 'red_down':\n            self._group.red_down()\n        elif stage.name == 'green_up':\n            self._group.green_up()\n        elif stage.name == 'green_down':\n            self._group.green_down()\n        elif stage.name == 'blue_up':\n            self._group.blue_up()\n        elif stage.name == 'blue_down':\n            self._group.blue_down()\n        elif stage.name == 'night_light':\n            self._group.night_light()\n        elif stage.name == 'flash':\n            self._group.flash(**stage.kwargs)\n        elif stage.name == 'repeat':\n            self._repeat(index, stage, stop)\n        elif stage.name == 'wait':\n            time.sleep(*stage.args)\n        elif stage.name == 'callback':\n            stage.args[0](*stage.args[1:], **stage.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _repeat(self, index, stage, stop):\n        times = None\n        if 'iterations' in stage.kwargs:\n            times = stage.kwargs['iterations'] - 1\n        stages_back = 1\n        if 'stages' in stage.kwargs:\n            stages_back = stage.kwargs['stages']\n        i = 0\n        while i != times:\n            if stop.is_set():\n                break\n            for forward in range(stages_back):\n                if stop.is_set():\n                    break\n                stage_index = index - stages_back + forward\n                self._execute_stage(stage_index, self._pipe[stage_index], stop)\n            i += 1", "response": "Repeat a stage.\n\n        :param index: Stage index.\n        :param stage: Stage object to repeat.\n        :param iterations: Number of iterations (default infinite).\n        :param stages: Stages back to repeat (default 1)."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef brightness(self, brightness):\n        try:\n            cmd = self.command_set.brightness(brightness)\n            self.send(cmd)\n            self._brightness = brightness\n        except AttributeError:\n            self._setter('_brightness', brightness,\n                         self._dimmest, self._brightest,\n                         self._to_brightness)", "response": "Set the brightness of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransitioning to this one.", "response": "def transition(self, duration, brightness=None):\n        \"\"\" Transition wrapper.\n\n        Short-circuit transition if necessary.\n\n        :param duration: Duration of transition.\n        :param brightness: Transition to this brightness.\n        \"\"\"\n        if duration == 0:\n            if brightness is not None:\n                self.brightness = brightness\n            return\n        if brightness != self.brightness:\n            self._transition(duration, brightness)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _transition(self, duration, brightness):\n        # Set initial value.\n        b_start = self.brightness\n        # Compute ideal step amount.\n        b_steps = 0\n        if brightness is not None:\n            b_steps = steps(self.brightness, brightness,\n                            self.command_set.brightness_steps)\n        # Compute ideal step amount (at least one).\n        # Calculate wait.\n        wait = self._wait(duration, b_steps, b_steps)\n        # Scale down steps if no wait time.\n        if wait == 0:\n            b_steps = self._scale_steps(duration, b_steps,\n                                                 b_steps)\n        # Perform transition.\n        for i in range(b_steps):\n            # Brightness.\n            if b_steps > 0:\n                self.brightness = util.transition(i, b_steps,\n                                                  b_start, brightness)\n            time.sleep(wait)", "response": "Complete a transition.\n\n        :param duration: Duration of transition.\n        :param brightness: Transition to this brightness."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setter(self, attr, value, bottom, top, to_step):\n        if value < 0 or value > 1:\n            raise ValueError(\"out of range\")\n        if value == 0.0:\n            bottom()\n        elif value == 1.0:\n            top()\n        else:\n            to_step(value)\n        setattr(self, attr, value)", "response": "Set a value.\n\n        :param attr: Attribute to set.\n        :param value: Value to use.\n        :param bottom: Get to bottom value.\n        :param top: Get to top value.\n        :param to_step: Get to intermediary value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _to_brightness(self, brightness):\n        self._to_value(self._brightness, brightness,\n                       self.command_set.brightness_steps,\n                       self._dimmer, self._brighter)", "response": "Step to a given brightness."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_value(self, current, target, max_steps, step_down, step_up):\n        for _ in range(steps(current, target, max_steps)):\n            if (current - target) > 0:\n                step_down()\n            else:\n                step_up()", "response": "Step to a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dimmest(self):\n        for _ in range(steps(self.brightness, 0.0,\n                             self.command_set.brightness_steps)):\n            self._dimmer()", "response": "Group brightness as dim as possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(in_bytes):\n    if isinstance(in_bytes, str):\n        raise TypeError('Unicode-objects must be encoded as bytes first')\n    in_bytes_mv = _get_buffer_view(in_bytes)\n    out_bytes = bytearray()\n    idx = 0\n    search_start_idx = 0\n    for in_char in in_bytes_mv:\n        if idx - search_start_idx == 0xFE:\n            out_bytes.append(0xFF)\n            out_bytes += in_bytes_mv[search_start_idx:idx]\n            search_start_idx = idx\n        if in_char == b'\\x00':\n            out_bytes.append(idx - search_start_idx + 1)\n            out_bytes += in_bytes_mv[search_start_idx:idx]\n            search_start_idx = idx + 1\n        idx += 1\n    try:\n        final_byte_value = ord(in_bytes_mv[-1])\n    except IndexError:\n        final_byte_value = 0\n    length_value = idx - search_start_idx + 1\n    if final_byte_value < length_value:\n        # Encoding same as plain COBS\n        out_bytes.append(length_value)\n        out_bytes += in_bytes_mv[search_start_idx:idx]\n    else:\n        # Special COBS/R encoding: length code is final byte,\n        # and final byte is removed from data sequence.\n        out_bytes.append(final_byte_value)\n        out_bytes += in_bytes_mv[search_start_idx:idx - 1]\n    return bytes(out_bytes)", "response": "Encodes a string using Consistent Overhead Byte Stuffing and Redced COBS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd items to the local and remote resources of a repository.", "response": "def add_repo(self, repo_name, items):\n        \"\"\"\n        Build up repos\n\n        `name` - Name of this repo.\n        `items` - List of paths to rpm.\n        \"\"\"\n        juicer.utils.Log.log_debug(\"[CART:%s] Adding %s items to repo '%s'\" % \\\n                                       (self.cart_name, len(items), repo_name))\n        # We can't just straight-away add all of `items` to the\n        # repo. `items` may be composed of a mix of local files, local\n        # directories, remote files, and remote directories. We need\n        # to filter and validate each item.\n        items = juicer.utils.filter_package_list(items)\n        cart_items = []\n        for item in items:\n            juicer.utils.Log.log_debug(\"Creating CartObject for %s\" % item)\n            i = juicer.common.CartItem.CartItem(item)\n            cart_items.append(i)\n        self.repo_items_hash[repo_name] = cart_items"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, json_file):\n        cart_file = os.path.join(CART_LOCATION, json_file)\n        try:\n            cart_body = juicer.utils.read_json_document(cart_file)\n        except IOError as e:\n            juicer.utils.Log.log_error('an error occured while accessing %s:' %\n                    cart_file)\n            raise JuicerError(e.message)\n\n        self.cart_name = cart_body['_id']\n\n        if cart_body['current_env'] == '':\n                self.current_env = juicer.utils.get_login_info()[1]['start_in']\n        else:\n            self.current_env = cart_body['current_env']\n\n        for repo, items in cart_body['repos_items'].iteritems():\n            self.add_repo(repo, items)", "response": "Load a new instance of the class from a json file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iterrepos(self):\n        for repo, items in self.repo_items_hash.iteritems():\n            if items:\n                yield (repo, items)", "response": "A generator function that yields a tuple for each non - empty repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsigns the items in the cart with a GPG key.", "response": "def sign_items(self, sign_with):\n        \"\"\"\n        Sign the items in the cart with a GPG key.\n\n        After everything is collected and signed all the cart items\n        are issued a refresh() to sync their is_signed attributes.\n\n        `sign_with` is a reference to the method that implements\n        juicer.common.RpmSignPlugin.\n        \"\"\"\n        cart_items = self.items()\n        item_paths = [item.path for item in cart_items]\n        sign_with(item_paths)\n\n        for item in cart_items:\n            item.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npull down all non - local items and saves them into remotes_storage.", "response": "def sync_remotes(self, force=False):\n        \"\"\"\n        Pull down all non-local items and save them into remotes_storage.\n        \"\"\"\n        connectors = juicer.utils.get_login_info()[0]\n        for repo, items in self.iterrepos():\n            repoid = \"%s-%s\" % (repo, self.current_env)\n            for rpm in items:\n                # don't bother syncing down if it's already in the pulp repo it needs to go to\n                if not rpm.path.startswith(juicer.utils.pulp_repo_path(connectors[self.current_env], repoid)) or force:\n                    rpm.sync_to(self.remotes_storage)\n                else:\n                    juicer.utils.Log.log_debug(\"Not syncing %s because it's already in pulp\" % rpm.path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef items(self):\n        cart_items = []\n        for repo, items in self.iterrepos():\n            cart_items.extend(items)\n        return cart_items", "response": "Build and return a list of all items in this cart"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef implode(self, env):\n        juicer.utils.Log.log_debug(\"imploding %s\" % self.cart_name)\n\n        # rm -r self.remotes_storage()\n        if os.path.exists(self.remotes_storage):\n            for item in os.listdir(self.remotes_storage):\n                ipath = os.path.expanduser(self.remotes_storage + '/' + item)\n                if os.path.exists(ipath):\n                    juicer.utils.Log.log_debug(\"removing %s\" % ipath)\n                    os.remove(ipath)\n                juicer.utils.Log.log_debug(\"removing %s's remote item storage dir\" % self.cart_name)\n                os.rmdir(self.remotes_storage)\n\n        # rm cart_file()\n        if os.path.exists(self.cart_file()):\n            juicer.utils.Log.log_debug(\"removing %s's cart file\" % self.cart_name)\n            os.remove(self.cart_file())\n\n        # db.carts.delete(self.name)\n        juicer.utils.Log.log_debug(\"removing %s from the database\" % self.cart_name)\n        juicer.utils.cart_db()[env].remove({'_id': self.cart_name})", "response": "remove all trace of this cart"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_api_version(self):\n        url = self.base_url + \"/status/\"\n        juicer.utils.Log.log_debug(\"[REST:GET:%s]\", url)\n\n        _r = requests.get(url, auth=self.auth, headers=self.headers,\n                          verify=False)\n\n        if _r.status_code == Constants.PULP_GET_OK:  # server is up, cool.\n            version = juicer.utils.load_json_str(_r.content)['api_version'].strip()\n            if version != Constants.EXPECTED_SERVER_VERSION:  # we done goofed\n                raise JuicerPulpError(\"Client expects %s and got %s -- you should probably update!\" \\\n                                      % (Constants.EXPECTED_SERVER_VERSION, version))\n        return True", "response": "check that the client expects the api version used by the item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arg(*args, **kwargs):\n    def _arg(f):\n        if not hasattr(f, '_subcommand_args'):\n            f._subcommand_args = []\n        f._subcommand_args.append((args, kwargs))\n        return f\n    return _arg", "response": "Decorator to add args to subcommands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef argset(name, *args, **kwargs):\n    def _arg(f):\n        if not hasattr(f, '_subcommand_argsets'):\n            f._subcommand_argsets = {}\n        f._subcommand_argsets.setdefault(name, []).append((args, kwargs))\n        return f\n    return _arg", "response": "Decorator to add sets of required mutually exclusive args to subcommands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resources(argv=sys.argv[1:]):\n    eps = iter_entry_points('jujuresources.subcommands')\n    ep_map = {ep.name: ep.load() for ep in eps}\n\n    parser = argparse.ArgumentParser()\n    if '--description' in argv:\n        print('Manage and mirror charm resources')\n        return 0\n\n    subparsers = {}\n    subparser_factory = parser.add_subparsers()\n    subparsers['help'] = subparser_factory.add_parser('help', help='Display help for a subcommand')\n    subparsers['help'].add_argument('command', nargs='?')\n    subparsers['help'].set_defaults(subcommand='help')\n    for name, subcommand in ep_map.items():\n        subparsers[name] = subparser_factory.add_parser(name, help=subcommand.__doc__)\n        subparsers[name].set_defaults(subcommand=subcommand)\n        for args, kwargs in getattr(subcommand, '_subcommand_args', []):\n            subparsers[name].add_argument(*args, **kwargs)\n        for argset in getattr(subcommand, '_subcommand_argsets', {}).values():\n            group = subparsers[name].add_mutually_exclusive_group(required=True)\n            for args, kwargs in argset:\n                group.add_argument(*args, **kwargs)\n    opts = parser.parse_args(argv)\n    if opts.subcommand == 'help':\n        if opts.command:\n            subparsers[opts.command].print_help()\n        else:\n            parser.print_help()\n    else:\n        return _exit(opts.subcommand(opts) or 0)", "response": "Dispatches resources to the Juju CLI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching a single or all resources from the local mirror of one or more resources.", "response": "def fetch(opts):\n    \"\"\"\n    Create a local mirror of one or more resources.\n    \"\"\"\n    resources = _load(opts.resources, opts.output_dir)\n    if opts.all:\n        opts.resource_names = ALL\n    reporthook = None if opts.quiet else lambda name: print('Fetching {}...'.format(name))\n    if opts.verbose:\n        backend.VERBOSE = True\n    _fetch(resources, opts.resource_names, opts.mirror_url, opts.force, reporthook)\n    return verify(opts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that one or more resources were downloaded successfully.", "response": "def verify(opts):\n    \"\"\"\n    Verify that one or more resources were downloaded successfully.\n    \"\"\"\n    resources = _load(opts.resources, opts.output_dir)\n    if opts.all:\n        opts.resource_names = ALL\n    invalid = _invalid(resources, opts.resource_names)\n    if not invalid:\n        if not opts.quiet:\n            print(\"All resources successfully downloaded\")\n        return 0\n    else:\n        if not opts.quiet:\n            print(\"Invalid or missing resources: {}\".format(', '.join(invalid)))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling one or more resources.", "response": "def install(opts):\n    \"\"\"\n    Install one or more resources.\n    \"\"\"\n    resources = _load(opts.resources, opts.output_dir)\n    if opts.all:\n        opts.resource_names = ALL\n    success = _install(resources, opts.resource_names, opts.mirror_url,\n                       opts.destination, opts.skip_top_level)\n    if success:\n        if not opts.quiet:\n            print(\"All resources successfully installed\")\n        return 0\n    else:\n        if not opts.quiet:\n            invalid = _invalid(resources, opts.resource_names)\n            print(\"Unable to install some resources: {}\".format(', '.join(invalid)))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resource_path(opts):\n    resources = _load(opts.resources, opts.output_dir)\n    if opts.resource_name not in resources:\n        sys.stderr.write('Invalid resource name: {}\\n'.format(opts.resource_name))\n        return 1\n    print(resources[opts.resource_name].destination)", "response": "Return the full path to a named resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_spec(opts):\n    resources = _load(opts.resources, opts.output_dir)\n    if opts.resource_name not in resources:\n        sys.stderr.write('Invalid resource name: {}\\n'.format(opts.resource_name))\n        return 1\n    print(resources[opts.resource_name].spec)", "response": "Get the spec for a named resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a light - weight HTTP server hosting previously mirrored resources", "response": "def serve(opts):\n    \"\"\"\n    Run a light-weight HTTP server hosting previously mirrored resources\n    \"\"\"\n    resources = _load(opts.resources, opts.output_dir)\n    opts.output_dir = resources.output_dir  # allow resources.yaml to set default output_dir\n    if not os.path.exists(opts.output_dir):\n        sys.stderr.write(\"Resources dir '{}' not found.  Did you fetch?\\n\".format(opts.output_dir))\n        return 1\n    backend.PyPIResource.build_pypi_indexes(opts.output_dir)\n    os.chdir(opts.output_dir)\n\n    HTTPServer.allow_reuse_address = True\n    httpd = HTTPServer((opts.host, opts.port), SimpleHTTPRequestHandler)\n\n    if opts.ssl_cert:\n        httpd.socket = ssl.wrap_socket(httpd.socket, certfile=opts.ssl_cert, server_side=True)\n\n    print(\"Serving at: http{}://{}:{}/\".format(\n        's' if opts.ssl_cert else '', socket.gethostname(), opts.port))\n    httpd.serve_forever()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(in_bytes):\n    if isinstance(in_bytes, str):\n        raise TypeError('Unicode-objects must be encoded as bytes first')\n    in_bytes_mv = _get_buffer_view(in_bytes)\n    final_zero = True\n    out_bytes = bytearray()\n    idx = 0\n    search_start_idx = 0\n    for in_char in in_bytes_mv:\n        if in_char == b'\\x00':\n            final_zero = True\n            out_bytes.append(idx - search_start_idx + 1)\n            out_bytes += in_bytes_mv[search_start_idx:idx]\n            search_start_idx = idx + 1\n        else:\n            if idx - search_start_idx == 0xFD:\n                final_zero = False\n                out_bytes.append(0xFF)\n                out_bytes += in_bytes_mv[search_start_idx:idx+1]\n                search_start_idx = idx + 1\n        idx += 1\n    if idx != search_start_idx or final_zero:\n        out_bytes.append(idx - search_start_idx + 1)\n        out_bytes += in_bytes_mv[search_start_idx:idx]\n    return bytes(out_bytes)", "response": "Encodes a string using Consistent Overhead Byte Stuffing ( COBS )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(in_bytes):\n    if isinstance(in_bytes, str):\n        raise TypeError('Unicode-objects are not supported; byte buffer objects only')\n    in_bytes_mv = _get_buffer_view(in_bytes)\n    out_bytes = bytearray()\n    idx = 0\n\n    if len(in_bytes_mv) > 0:\n        while True:\n            length = ord(in_bytes_mv[idx])\n            if length == 0:\n                raise DecodeError(\"zero byte found in input\")\n            idx += 1\n            end = idx + length - 1\n            copy_mv = in_bytes_mv[idx:end]\n            if b'\\x00' in copy_mv:\n                raise DecodeError(\"zero byte found in input\")\n            out_bytes += copy_mv\n            idx = end\n            if idx > len(in_bytes_mv):\n                raise DecodeError(\"not enough input bytes for length code\")\n            if idx < len(in_bytes_mv):\n                if length < 0xFF:\n                    out_bytes.append(0)\n            else:\n                break\n    return bytes(out_bytes)", "response": "Decodes a byte string using Consistent Overhead Byte Stuffing ( COBS )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef temperature(self, temperature):\n        try:\n            cmd = self.command_set.temperature(temperature)\n            self.send(cmd)\n            self._temperature = temperature\n        except AttributeError:\n            self._setter('_temperature', temperature,\n                         self._warmest, self._coolest,\n                         self._to_temperature)", "response": "Set the temperature.\n\n        :param temperature: Value to set (0.0-1.0)."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transition(self, duration, brightness=None, temperature=None):\n        # Transition immediately if duration is zero.\n        if duration == 0:\n            if brightness is not None:\n                self.brightness = brightness\n            if temperature is not None:\n                self.temperature = temperature\n            return\n        if brightness != self.brightness or temperature != self.temperature:\n            self._transition(duration, brightness, temperature)", "response": "Transition to this one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompleting a transition. :param duration: Duration of transition. :param brightness: Transition to this brightness. :param temperature: Transition to this temperature.", "response": "def _transition(self, duration, brightness, temperature):\n        \"\"\" Complete a transition.\n\n        :param duration: Duration of transition.\n        :param brightness: Transition to this brightness.\n        :param temperature: Transition to this temperature.\n        \"\"\"\n        # Set initial value.\n        b_start = self.brightness\n        t_start = self.temperature\n        # Compute ideal step amount.\n        b_steps = 0\n        if brightness is not None:\n            b_steps = steps(self.brightness, brightness,\n                            self.command_set.brightness_steps)\n        t_steps = 0\n        if temperature is not None:\n            t_steps = steps(self.temperature, temperature,\n                            self.command_set.temperature_steps)\n        # Compute ideal step amount (at least one).\n        total_steps = max(b_steps, t_steps, 1)\n        total_commands = b_steps + t_steps\n        # Calculate wait.\n        wait = self._wait(duration, total_steps, total_commands)\n        # Scale down steps if no wait time.\n        if wait == 0:\n            b_steps, t_steps = self._scale_steps(duration, total_commands,\n                                                 b_steps, t_steps)\n            total_steps = max(b_steps, t_steps, 1)\n        # Perform transition.\n        for i in range(total_steps):\n            # Brightness.\n            if b_steps > 0 and i % (total_steps / b_steps) == 0:\n                self.brightness = util.transition(i, total_steps,\n                                                  b_start, brightness)\n            # Temperature.\n            elif t_steps > 0:\n                self.temperature = util.transition(i, total_steps,\n                                                   t_start, temperature)\n            # Wait.\n            time.sleep(wait)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsteps to a given temperature.", "response": "def _to_temperature(self, temperature):\n        \"\"\" Step to a given temperature.\n\n        :param temperature: Get to this temperature.\n        \"\"\"\n        self._to_value(self._temperature, temperature,\n                       self.command_set.temperature_steps,\n                       self._warmer, self._cooler)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _warmest(self):\n        for _ in range(steps(self.temperature, 0.0,\n                             self.command_set.temperature_steps)):\n            self._warmer()", "response": "Warm the group temperature as possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngroups temperature as cool as possible.", "response": "def _coolest(self):\n        \"\"\" Group temperature as cool as possible. \"\"\"\n        for _ in range(steps(self.temperature, 1.0,\n                             self.command_set.temperature_steps)):\n            self._cooler()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ip_to_array(ipaddress):\n    res = []\n    for i in ipaddress.split(\".\"):\n        res.append(int(i))\n\n    assert len(res) == 4\n    return res", "response": "Convert a string representing an IPv4 address to 4 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an integer to an array of bytes.", "response": "def int_to_array(i, length=2):\n    \"\"\"Convert an length byte integer to an array of bytes.\"\"\"\n    res = []\n    for dummy in range(0, length):\n        res.append(i & 0xff)\n        i = i >> 8\n    return reversed(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef blink1(switch_off=True, gamma=None, white_point=None):\n    b1 = Blink1(gamma=gamma, white_point=white_point)\n    yield b1\n    if switch_off:\n        b1.off()\n    b1.close()", "response": "Context manager which automatically shuts down the Blink1 after use."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a praticular blink ( 1 ) device or the first one.", "response": "def find(serial_number=None):\n        \"\"\"\n        Find a praticular blink(1) device, or the first one\n        :param serial_number: serial number of blink(1) device (from Blink1.list())\n        \"\"\"\n        try:\n            hidraw = hid.device(VENDOR_ID,PRODUCT_ID,serial_number)\n            hidraw.open(VENDOR_ID,PRODUCT_ID,serial_number)\n            # hidraw = hid.device(VENDOR_ID,PRODUCT_ID,unicode(serial_number))\n            # hidraw.open(VENDOR_ID,PRODUCT_ID,unicode(serial_number))\n        except IOError as e:  # python2\n            raise Blink1ConnectionFailed(e)\n            hidraw = None\n        except OSError as e:  # python3\n            raise Blink1ConnectionFailed(e)\n            hidraw = None\n\n        return hidraw"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist blink ( 1 ) devices connected by serial number", "response": "def list():\n        \"\"\"\n        List blink(1) devices connected, by serial number\n        :return: List of blink(1) device serial numbers\n        \"\"\"\n        try:\n            devs = hid.enumerate(VENDOR_ID,PRODUCT_ID)\n            serials = list(map(lambda d:d.get('serial_number'), devs))\n            return serials\n        except IOError as e:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite to blink 1 low - level internal use", "response": "def write(self,buf):\n        \"\"\"\n        Write command to blink(1), low-level internal use\n        Send USB Feature Report 0x01 to blink(1) with 8-byte payload\n        Note: arg 'buf' must be 8 bytes or bad things happen\n        \"\"\"\n        log.debug(\"blink1write:\" + \",\".join('0x%02x' % v for v in buf))\n        self.dev.send_feature_report(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfading to RGB color", "response": "def fade_to_rgb_uncorrected(self, fade_milliseconds, red, green, blue, led_number=0):\n        \"\"\"\n        Command blink(1) to fade to RGB color, no color correction applied.\n        \"\"\"\n        action = ord('c')\n        fade_time = int(fade_milliseconds / 10)\n        th = (fade_time & 0xff00) >> 8\n        tl = fade_time & 0x00ff\n        buf = [REPORT_ID, action, int(red), int(green), int(blue), th, tl, led_number, 0]\n        self.write( buf )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting color name or hexcode to rgb tuple", "response": "def color_to_rgb(color):\n        \"\"\"\n        Convert color name or hexcode to (r,g,b) tuple\n        \"\"\"\n        if isinstance(color, tuple):\n            return color\n        if color.startswith('#'):\n            try:\n                return webcolors.hex_to_rgb(color)\n            except ValueError:\n                raise InvalidColor(color)\n\n        try:\n            return webcolors.name_to_rgb(color)\n        except ValueError:\n            raise InvalidColor(color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fade_to_color(self, fade_milliseconds, color):\n        red, green, blue = self.color_to_rgb(color)\n\n        return self.fade_to_rgb(fade_milliseconds, red, green, blue)", "response": "Fade the light to a known colour in a specific color"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting blink firmware version", "response": "def get_version(self):\n        \"\"\"Get blink(1) firmware version\n        \"\"\"\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('v'), 0, 0, 0, 0, 0, 0, 0]\n        self.write(buf)\n        time.sleep(.05)\n        version_raw = self.read()\n        version = (version_raw[3] - ord('0')) * 100 + (version_raw[4] - ord('0'))\n        return str(version)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef play(self, start_pos=0, end_pos=0, count=0):\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('p'), 1, int(start_pos), int(end_pos), int(count), 0, 0, 0]\n        return self.write(buf);", "response": "Play internal color pattern\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop internal color pattern playing", "response": "def stop(self):\n        \"\"\"Stop internal color pattern playing\n        \"\"\"\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('p'), 0, 0, 0, 0, 0, 0, 0]\n        return self.write(buf);"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef savePattern(self):\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('W'), 0xBE, 0xEF, 0xCA, 0xFE, 0, 0, 0]\n        return self.write(buf);", "response": "Save internal RAM pattern to flash \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setLedN(self, led_number=0):\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('l'), led_number, 0,0,0,0,0,0]\n        self.write(buf)", "response": "Set the current LED number for writePatternLine\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a pattern line to RAM", "response": "def writePatternLine(self, step_milliseconds, color, pos, led_number=0):\n        \"\"\"Write a color & step time color pattern line to RAM \n        :param step_milliseconds: how long for this pattern line to take\n        :param color: LED color\n        :param pos: color pattern line number (0-15)\n        :param led_number: LED to adjust, 0=all, 1=LEDA, 2=LEDB\n        \"\"\"\n        if ( self.dev == None ): return ''\n        self.setLedN(led_number)\n        red, green, blue = self.color_to_rgb(color)\n        r, g, b = self.cc(red, green, blue)\n        step_time = int(step_milliseconds / 10)\n        th = (step_time & 0xff00) >> 8\n        tl = step_time & 0x00ff\n        buf = [REPORT_ID, ord('P'), int(r), int(g), int(b), th,tl, pos, 0]\n        return self.write(buf);"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readPatternLine(self, pos):\n        if ( self.dev == None ): return ''\n        buf = [REPORT_ID, ord('R'), 0, 0, 0, 0, 0, int(pos), 0]\n        self.write(buf)\n        buf = self.read()\n        (r,g,b) = (buf[2],buf[3],buf[4])\n        step_millis = ((buf[5] << 8) | buf[6]) * 10\n        return (r,g,b,step_millis)", "response": "Read a color pattern line at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the entire color pattern", "response": "def readPattern(self):\n        \"\"\"Read the entire color pattern\n        :return List of pattern line tuples\n        \"\"\"\n        if ( self.dev == None ): return ''\n        pattern=[]\n        for i in range(0,16):    # FIXME: adjustable for diff blink(1) models\n            pattern.append( self.readPatternLine(i) )\n        return pattern"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serverTickle(self, enable, timeout_millis=0, stay_lit=False, start_pos=0, end_pos=16):\n        if ( self.dev == None ): return ''\n        en = int(enable == True)\n        timeout_time = int(timeout_millis/10)\n        th = (timeout_time & 0xff00) >>8\n        tl = timeout_time & 0x00ff\n        st = int(stay_lit == True)\n        buf = [REPORT_ID, ord('D'), en, th, tl, st, start_pos, end_pos, 0]\n        self.write(buf)", "response": "Enable or disable servertickle server tickle"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_repo(self, repo_name=None, feed=None, envs=[], checksum_type=\"sha256\", query='/repositories/'):\n\n        data = {'display_name': repo_name,\n                'notes': {\n                    '_repo-type': 'rpm-repo',\n                    }\n                }\n        juicer.utils.Log.log_debug(\"Create Repo: %s\", repo_name)\n\n        for env in envs:\n            if juicer.utils.repo_exists_p(repo_name, self.connectors[env], env):\n                juicer.utils.Log.log_info(\"repo `%s` already exists in %s... skipping!\",\n                                          (repo_name, env))\n                continue\n            else:\n                data['relative_path'] = '/%s/%s/' % (env, repo_name)\n                data['id'] = '-'.join([repo_name, env])\n\n                _r = self.connectors[env].post(query, data)\n\n                if _r.status_code == Constants.PULP_POST_CREATED:\n                    imp_query = '/repositories/%s/importers/' % data['id']\n                    imp_data = {\n                        'importer_id': 'yum_importer',\n                        'importer_type_id': 'yum_importer',\n                        'importer_config': {},\n                    }\n\n                    if feed:\n                        imp_data['importer_config']['feed_url'] = feed\n\n                    _r = self.connectors[env].post(imp_query, imp_data)\n\n                    dist_query = '/repositories/%s/distributors/' % data['id']\n                    dist_data = {'distributor_id': 'yum_distributor',\n                            'distributor_type_id': 'yum_distributor',\n                            'distributor_config': {\n                                'relative_url': '/%s/%s/' % (env, repo_name),\n                                'http': True,\n                                'https': True,\n                                'checksum_type': checksum_type\n                                },\n                            'auto_publish': True,\n                            'relative_path': '/%s/%s/' % (env, repo_name)\n                            }\n\n                    _r = self.connectors[env].post(dist_query, dist_data)\n\n                    if _r.status_code == Constants.PULP_POST_CREATED:\n                        pub_query = '/repositories/%s/actions/publish/' % data['id']\n                        pub_data = {'id': 'yum_distributor'}\n\n                        _r = self.connectors[env].post(pub_query, pub_data)\n\n                        if _r.status_code == Constants.PULP_POST_ACCEPTED:\n                            juicer.utils.Log.log_info(\"created repo `%s` in %s\", repo_name, env)\n                    else:\n                        _r.raise_for_status()\n                else:\n                    _r.raise_for_status()\n        return True", "response": "create a new repository in specified environments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport a repo from a JSON file.", "response": "def import_repo(self, from_file, noop=False, query='/repositories/'):\n        \"\"\"\n        `from_file` - JSON file of repo definitions\n        `noop` - Boolean, if true don't actually create/update repos, just show what would have happened\n        \"\"\"\n        try:\n            repo_defs = juicer.utils.ValidateRepoDef.validate_document(from_file)\n        except JuicerRepoDefError, e:\n            juicer.utils.Log.log_error(\"Could not load repo defs from %s:\" % from_file)\n            raise e\n        else:\n            juicer.utils.Log.log_debug(\"Loaded and validated repo defs from %s\" % from_file)\n\n        # All our known envs, for cases where no value is supplied for 'env'\n        all_envs = juicer.utils.get_environments()\n\n        # Repos to create/update, sorted by environment.\n        repo_objects_create = []\n        repo_objects_update = {}\n        for env in all_envs:\n            repo_objects_update[env] = []\n\n        # All repo defs as Repo objects\n        all_repos = [JuicerRepo(repo['name'], repo_def=repo) for repo in repo_defs]\n\n        # Detailed information on all existing repos\n        existing_repos = {}\n        repo_pool = ThreadPool()\n\n        # Parallelize getting the repo lists\n        env_results = [repo_pool.apply_async(self.list_repos, tuple(), kwds={'envs': [er]}, callback=existing_repos.update) for er in all_envs]\n        repo_pool.close()\n\n        for result_async in env_results:\n            result_async.wait()\n\n        repo_pool.join()\n\n        for repo in all_repos:\n            # 'env' is all environments if: 'env' is not defined; 'env' is an empty list\n            current_env = repo.get('env', [])\n            if current_env == []:\n                juicer.utils.Log.log_debug(\"Setting 'env' to all_envs for repo: %s\" % repo['name'])\n                repo['env'] = all_envs\n\n        #  Assemble a set of all specified environments.\n        defined_envs = juicer.utils.unique_repo_def_envs(all_repos)\n        juicer.utils.Log.log_notice(\"Discovered environments: %s\" % \", \".join(list(defined_envs)))\n\n        widgets = [\n            \"Importing: \",\n            progressbar.Percentage(),\n            \" \",\n            \"(\",\n            progressbar.SimpleProgress(),\n            \") \",\n            progressbar.ETA()\n        ]\n        progress_bar = JuiceBar(len(all_repos), widgets)\n        repos_processed = juicer.admin.ThreaddedQuery.LookupObject()\n        repos_processed.processed = 0\n        # sort out new vs. existing\n        # Break these into batches we can process at once\n        for chunks in juicer.utils.chunks(all_repos, multiprocessing.cpu_count() - 1):\n            crud_pool = ThreadPool()\n            crud_args = (all_repos, all_envs, existing_repos, self, repo_objects_create, repo_objects_update, repos_processed, progress_bar)\n            calculate_results = [crud_pool.apply_async(juicer.admin.ThreaddedQuery.calculate_create_and_update,\n                                                       crud_args,\n                                                       kwds={'repo': repo},\n                                                       callback=juicer.admin.ThreaddedQuery.crud_progress_updater)\n                                 for repo in chunks]\n            crud_pool.close()\n            to_process = len(calculate_results)\n            juicer.utils.Log.log_debug(\"And we started the pool; items: %s\" % len(calculate_results))\n            while to_process > 0:\n                for thingy in calculate_results:\n                    thingy.wait(0.5)\n                    if thingy.ready():\n                        to_process -= 1\n            crud_pool.join()\n\n        juicer.utils.Log.log_debug(\"And we joined all threads\")\n        \"\"\"repo_objects_update looks like this:\n\n        {'environment': [repo_update_spec, ...]}\n\n        repo_update_spec :: [env, repo_diff_spec, pulp_repo]\n\n        env :: environment to apply diff to\n\n        repo_diff_spec :: {\n            'distributor': {'distributor_config': {PARAMETERS_TO_UPDATE: VALUES}},\n            'importer': {'importer_config': {PARAMETERS_TO_UPDATE: VALUES}\n            }\n        }\n\n        pulp_repo :: Json serialization of a repo as returned from pulp (or juicer-admin repo show --json)\n        \"\"\"\n        return (repo_objects_create, repo_objects_update)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_repo(self, juicer_repo, pulp_repo, env, repo_diff, query='/repositories/'):\n        repo_id = \"%s-%s\" % (juicer_repo['name'], env)\n        distributor_id = \"yum_distributor\"\n        importer_id = \"yum_importer\"\n        distributor_diff = repo_diff.diff()['distributor']\n        importer_diff = repo_diff.diff()['importer']\n\n        distributor_query = query + \"%s/distributors/%s/\" % (repo_id, distributor_id)\n        importer_query = query + \"%s/importers/%s/\" % (repo_id, importer_id)\n\n        ##############################################################\n        # Importer update\n        _r = self.connectors[env].put(distributor_query, distributor_diff)\n        if _r.status_code == Constants.PULP_PUT_OK:\n            juicer.utils.Log.log_notice(\"Update request accepted for %s\", repo_id)\n        elif _r.status_code == Constants.PULP_PUT_CONFLICT:\n            juicer.utils.Log.log_debug(str(_r.content))\n        elif _r.status_code == Constants.PULP_PUT_NOT_FOUND:\n            juicer.utils.Log.log_debug(str(_r.content))\n        else:\n            _r.raise_for_status()\n\n        ##############################################################\n        # Distributor update\n        _r = self.connectors[env].put(importer_query, importer_diff)\n        if _r.status_code == Constants.PULP_PUT_OK:\n            juicer.utils.Log.log_notice(\"Update request accepted for %s\", repo_id)\n        elif _r.status_code == Constants.PULP_PUT_CONFLICT:\n            juicer.utils.Log.log_debug(str(_r.content))\n        elif _r.status_code == Constants.PULP_PUT_NOT_FOUND:\n            juicer.utils.Log.log_debug(str(_r.content))\n        else:\n            _r.raise_for_status()\n\n        return True", "response": "`from_file` - JSON file of repo definitions\n        `noop` - Boolean, if true don't actually create/update repos, just show what would have happened\n\n        https://pulp-dev-guide.readthedocs.org/en/pulp-2.3/integration/rest-api/repo/cud.html#update-a-distributor-associated-with-a-repository\n        https://pulp-dev-guide.readthedocs.org/en/pulp-2.3/integration/rest-api/repo/cud.html#update-an-importer-associated-with-a-repository\n\n        Distributor update:\n        Method: PUT\n        Path: /pulp/api/v2/repositories/<repo_id>/distributors/<distributor_id>/\n\n        Importer update:\n        Method: PUT\n        Path: /pulp/api/v2/repositories/<repo_id>/importers/<importer_id>/"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping all repos in all environments.", "response": "def export_repos(self, envs=[]):\n        \"\"\"Dump JuicerRepo() objects for all repos in all environments.\n\n        Note that this has undefined results should a repo exist with\n        different configurations in different environments.\n        \"\"\"\n        all_envs = envs\n        juicer.utils.Log.log_notice(\"Only exporting repos in environment(s): %s\", \", \".join(all_envs))\n        all_pulp_repo_names = self.list_repos(envs=all_envs)\n        all_pulp_repo_names_uniqued = set()\n        num_repos = 0\n\n        # Track name of all processed repos. Update when we've found\n        # all environments a PulpRepo lives in.\n        repos_processed = []\n\n        for env, repos in all_pulp_repo_names.iteritems():\n            juicer.utils.Log.log_debug(\"Uniqued environment: %s with %s repos\", env, int(len(repos)))\n            all_pulp_repo_names_uniqued.update(set(repos))\n\n        num_repos += len(all_pulp_repo_names_uniqued)\n\n        widgets = [\n            \"Exporting: \",\n            progressbar.Percentage(),\n            \" \",\n            \"(\",\n            progressbar.SimpleProgress(),\n            \") \",\n            progressbar.ETA()\n        ]\n        progress_bar = JuiceBar(num_repos, widgets)\n\n        # Hacky way to get around not easily being able to pass\n        # multiple arguments to a function in a multiprocessing pool\n        lookup_objects = []\n\n        for repo in all_pulp_repo_names_uniqued:\n            lookup_args = juicer.admin.ThreaddedQuery.LookupObject()\n            setattr(lookup_args, 'progress_bar', progress_bar)\n            setattr(lookup_args, 'all_pulp_repo_names', all_pulp_repo_names)\n            setattr(lookup_args, 'all_envs', all_envs)\n            setattr(lookup_args, 'ja', self)\n            setattr(lookup_args, 'pulp_repo', repo)\n            setattr(lookup_args, 'repos_processed', repos_processed)\n            lookup_objects.append(lookup_args)\n\n        # TODO: Add the serial/concurrent logic here\n\n        try:\n            # Make our thread pool\n            p = ThreadPool()\n            # Get an AsyncResult object\n            r = p.map_async(juicer.admin.ThreaddedQuery.concurrent_pulp_lookup, lookup_objects)\n            # TODO: We should probably use p.apply_async here to avoid the crappy lookup_objects hack\n\n            while not r.ready():\n                r.wait(1)\n        except KeyboardInterrupt:\n            juicer.utils.Log.log_error(\"User pressed ^C during repo export\")\n            juicer.utils.Log.log_error(\"Terminating %s worker threads and then exiting\", len(p._pool))\n            # Prevents any more tasks from being submitted to the\n            # pool. Once all the tasks have been completed the worker\n            # threads will exit.\n            #p.close()\n            p.terminate()\n            p.join()\n\n        # XXX: End serial/concurrent logic\n\n        progress_bar.finish()\n        juicer_repos = [pr.to_juicer_repo() for pr in repos_processed]\n        return sorted(juicer_repos, key=lambda d: d['name'].lower())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a repository in specified environments", "response": "def delete_repo(self, repo_name=None, envs=[], query='/repositories/'):\n        \"\"\"\n        `repo_name` - Name of repository to delete\n\n        Delete repo in specified environments\n        \"\"\"\n        orphan_query = '/content/orphans/rpm/'\n        juicer.utils.Log.log_debug(\"Delete Repo: %s\", repo_name)\n\n        for env in self.args.envs:\n            if not juicer.utils.repo_exists_p(repo_name, self.connectors[env], env):\n                juicer.utils.Log.log_info(\"repo `%s` doesn't exist in %s... skipping!\",\n                                           (repo_name, env))\n                continue\n            else:\n                url = \"%s%s-%s/\" % (query, repo_name, env)\n                _r = self.connectors[env].delete(url)\n                if _r.status_code == Constants.PULP_DELETE_ACCEPTED:\n                    juicer.utils.Log.log_info(\"deleted repo `%s` in %s\",\n                                              (repo_name, env))\n\n                    # if delete was successful, delete orphaned rpms\n                    _r = self.connectors[env].get(orphan_query)\n                    if _r.status_code is Constants.PULP_GET_OK:\n                        if len(juicer.utils.load_json_str(_r.content)) > 0:\n                            __r = self.connectors[env].delete(orphan_query)\n                            if __r.status_code is Constants.PULP_DELETE_ACCEPTED:\n                                juicer.utils.Log.log_debug(\"deleted orphaned rpms in %s.\" % env)\n                            else:\n                                juicer.utils.Log.log_error(\"unable to delete orphaned rpms in %s. a %s error was returned\", (env, __r.status_code))\n                    else:\n                        juicer.utils.Log.log_error(\"unable to get a list of orphaned rpms. encountered a %s error.\" % _r.status_code)\n                else:\n                    _r.raise_for_status()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_user(self, login=None, envs=[], query='/users/'):\n        juicer.utils.Log.log_debug(\"Delete User: %s\", login)\n\n        for env in envs:\n            if envs.index(env) != 0 and juicer.utils.env_same_host(env, envs[envs.index(env) - 1]):\n                juicer.utils.Log.log_info(\"environment `%s` shares a host with environment `%s`... skipping!\",\n                                          (env, envs[envs.index(env) - 1]))\n                continue\n            elif not juicer.utils.user_exists_p(login, self.connectors[env]):\n                juicer.utils.Log.log_info(\"user `%s` doesn't exist in %s... skipping!\",\n                                          (login, env))\n                continue\n            else:\n                url = \"%s%s/\" % (query, login)\n                _r = self.connectors[env].delete(url)\n                if _r.status_code == Constants.PULP_DELETE_OK:\n                    juicer.utils.Log.log_info(\"deleted user `%s` in %s\",\n                                              (login, env))\n                else:\n                    _r.raise_for_status()\n        return True", "response": "login - Login or username of user to delete envs - list of environments to delete"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_repos(self, envs=[], query='/repositories/'):\n        juicer.utils.Log.log_debug(\n                \"List Repos In: %s\", \", \".join(envs))\n\n        repo_lists = {}\n        for env in envs:\n            repo_lists[env] = []\n\n        for env in envs:\n            _r = self.connectors[env].get(query)\n            if _r.status_code == Constants.PULP_GET_OK:\n                for repo in juicer.utils.load_json_str(_r.content):\n                    if re.match(\".*-{0}$\".format(env), repo['id']):\n                        repo_lists[env].append(repo['display_name'])\n            else:\n                _r.raise_for_status()\n        return repo_lists", "response": "List repositories in specified environments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist users in specified environments", "response": "def list_users(self, envs=[], query=\"/users/\"):\n        \"\"\"\n        List users in specified environments\n        \"\"\"\n        juicer.utils.Log.log_debug(\n                \"List Users In: %s\", \", \".join(envs))\n        for env in envs:\n            juicer.utils.Log.log_info(\"%s:\" % (env))\n            _r = self.connectors[env].get(query)\n            if _r.status_code == Constants.PULP_GET_OK:\n                for user in juicer.utils.load_json_str(_r.content):\n                    roles = user['roles']\n                    if roles:\n                        user_roles = ', '.join(roles)\n                    else:\n                        user_roles = \"None\"\n                    juicer.utils.Log.log_info(\"\\t%s - %s\" % (user['login'], user_roles))\n            else:\n                _r.raise_for_status()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef role_add(self, role=None, login=None, envs=[], query='/roles/'):\n        data = {'login': self.args.login}\n        juicer.utils.Log.log_debug(\n                \"Add Role '%s' to '%s'\", role, login)\n\n        for env in self.args.envs:\n            if not juicer.utils.role_exists_p(role, self.connectors[env]):\n                juicer.utils.Log.log_info(\"role `%s` doesn't exist in %s... skipping!\",\n                                          (role, env))\n                continue\n            elif not juicer.utils.user_exists_p(login, self.connectors[env]):\n                juicer.utils.Log.log_info(\"user `%s` doesn't exist in %s... skipping!\",\n                                          (login, env))\n            else:\n                url = \"%s%s/users/\" % (query, role)\n                _r = self.connectors[env].post(url, data)\n                if _r.status_code == Constants.PULP_POST_OK:\n                    juicer.utils.Log.log_info(\"added user `%s` to role `%s` in %s\",\n                                              (login, role, env))\n                else:\n                    _r.raise_for_status()\n        return True", "response": "login - Login or username of user to add role to envs - list of environments to add user to"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs-in - Login or username of user show user in specified environments", "response": "def show_user(self, login=None, envs=[], query='/users/'):\n        \"\"\"\n        `login` - Login or username of user\n\n        Show user in specified environments\n        \"\"\"\n        juicer.utils.Log.log_debug(\"Show User: %s\", login)\n\n        # keep track of which iteration of environment we're in\n        count = 0\n\n        for env in self.args.envs:\n            count += 1\n\n            juicer.utils.Log.log_info(\"%s:\", env)\n            if not juicer.utils.user_exists_p(login, self.connectors[env]):\n                juicer.utils.Log.log_info(\"user `%s` doesn't exist in %s... skipping!\",\n                                          (login, env))\n                continue\n            else:\n                url = \"%s%s/\" % (query, login)\n                _r = self.connectors[env].get(url)\n                if _r.status_code == Constants.PULP_GET_OK:\n                    user = juicer.utils.load_json_str(_r.content)\n\n                    juicer.utils.Log.log_info(\"Login: %s\" % user['login'])\n                    juicer.utils.Log.log_info(\"Name: %s\" % user['name'])\n                    juicer.utils.Log.log_info(\"Roles: %s\" % ', '.join(user['roles']))\n\n                    if count < len(envs):\n                        # just want a new line\n                        juicer.utils.Log.log_info(\"\")\n                else:\n                    _r.raise_for_status()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_roles(self, envs=[], query='/roles/'):\n        juicer.utils.Log.log_debug(\"List Roles %s\", \", \".join(envs))\n\n        count = 0\n\n        for env in envs:\n            count += 1\n            rcount = 0\n\n            juicer.utils.Log.log_info(\"%s:\", env)\n            _r = self.connectors[env].get(query)\n            if _r.status_code == Constants.PULP_GET_OK:\n                roles = juicer.utils.load_json_str(_r.content)\n\n                for role in roles:\n                    rcount += 1\n\n                    juicer.utils.Log.log_info(\"Name: %s\" % role['display_name'])\n                    juicer.utils.Log.log_info(\"Description: %s\" % role['description'])\n                    juicer.utils.Log.log_info(\"ID: %s\" % role['id'])\n                    juicer.utils.Log.log_info(\"Users: %s\" % ', '.join(role['users']))\n\n                    if rcount < len(roles):\n                        # just want a new line\n                        juicer.utils.Log.log_info(\"\\n\")\n\n                if count < len(envs):\n                    # just want a new line\n                    juicer.utils.Log.log_info(\"\\n\")\n            else:\n                _r.raise_for_status()\n        return True", "response": "List roles in specified environments"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a JuicerRepo object representing this pulp repo", "response": "def to_juicer_repo(self):\n        \"\"\"Returns a JuicerRepo() object representing this pulp repo\"\"\"\n        repo_def = {}\n        defaults = juicer.common.Constants.REPO_DEF_DEFAULTS\n        repo_def['name'] = self['name']\n        for key in juicer.common.Constants.REPO_DEF_OPT_KEYS:\n            repo_def[key] = self.spec.get(key, defaults[key])\n            juicer.utils.Log.log_debug(\"Defined %s as %s\" % (key, str(self[key])))\n        return JuicerRepo(None, repo_def=repo_def)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _diff(self):\n        j_cs = self.j['checksum_type']\n        j_feed = self.j['feed']\n\n        p_cs = self.p['checksum_type']\n        p_feed = self.p['feed']\n\n        # checksum is a distributor property\n        # Is the pulp checksum wrong?\n        if not p_cs == j_cs:\n            juicer.utils.Log.log_debug(\"Pulp checksum_type does not match juicer\")\n            self.distributor_diff['distributor_config']['checksum_type'] = j_cs\n            juicer.utils.Log.log_debug(\"distributor_config::checksum_type SHOULD BE %s\" % j_cs)\n\n        # feed is an importer property\n        if not p_feed == j_feed:\n            juicer.utils.Log.log_debug(\"Pulp feed does not match juicer\")\n            self.importer_diff['importer_config']['feed'] = j_feed\n            juicer.utils.Log.log_debug(\"importer_config::feed SHOULD BE %s\" % j_feed)", "response": "Calculates what you need to make a pulp repo match a juicer repo def"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the graphite key prefixes for the current object.", "response": "def _set_prefixes(self, conf):\n        \"\"\"Set the graphite key prefixes\n\n        :param dict conf: The configuration data\n\n        \"\"\"\n        if conf.get('legacy_namespace', 'y') in self.TRUE_VALUES:\n            self.count_prefix = 'stats_counts'\n            self.count_suffix = ''\n            self.gauge_prefix = 'stats.gauges'\n            self.timer_prefix = 'stats.timers'\n            self.rate_prefix = 'stats'\n            self.rate_suffix = ''\n        else:\n            global_prefix = conf.get('global_prefix', 'stats')\n            self.count_prefix = '%s.%s' % (global_prefix,\n                                           conf.get('prefix_counter',\n                                                    'counters'))\n            self.count_suffix = '.count'\n            self.gauge_prefix = '%s.%s' % (global_prefix,\n                                           conf.get('prefix_gauge', 'gauges'))\n            self.timer_prefix = '%s.%s' % (global_prefix,\n                                           conf.get('prefix_timer', 'timers'))\n            self.rate_prefix = self.count_prefix\n            self.rate_suffix = '.rate'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list yield all the batches of self. max_batch_size in size", "response": "def _get_batches(self, items):\n        \"\"\"given a list yield list at most self.max_batch_size in size\"\"\"\n        for i in xrange(0, len(items), self.max_batch_size):\n            yield items[i:i + self.max_batch_size]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends data to graphite host and report stats.", "response": "def report_stats(self, payload, is_retry=False):\n        \"\"\"\n        Send data to graphite host\n\n        :param payload: Data to send to graphite\n        \"\"\"\n        if self.debug:\n            if self.pickle_proto:\n                print \"reporting pickled stats\"\n            else:\n                print \"reporting stats -> {\\n%s}\" % payload\n        try:\n            graphite = socket.socket()\n            with eventlet.Timeout(self.graphite_timeout, True):\n                graphite.connect(self.graphite_addr)\n                graphite.sendall(payload)\n                graphite.close()\n        except eventlet.timeout.Timeout:\n            self.logger.critical(\"Timeout sending to graphite\")\n            if self.debug:\n                print \"Timeout talking to graphite\"\n            if not is_retry:\n                self.logger.critical('Attempting 1 retry!')\n                self.report_stats(payload, is_retry=True)\n            else:\n                self.logger.critical('Already retried once, giving up')\n        except Exception as err:\n            self.logger.critical(\"error connecting to graphite: %s\" % err)\n            if self.debug:\n                print \"error connecting to graphite: %s\" % err\n        finally:\n            try:\n                graphite.close()\n            except Exception:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats_flush(self):\n        while True:\n            try:\n                eventlet.sleep(self.flush_interval)\n                if self.debug:\n                    print \"seen %d stats so far.\" % self.stats_seen\n                    print \"current counters: %s\" % self.counters\n                if self.pickle_proto:\n                    payload = self.pickle_payload()\n                    if payload:\n                        for batch in payload:\n                            self.report_stats(batch)\n                else:\n                    payload = self.plain_payload()\n                    if payload:\n                        self.report_stats(payload)\n            except: # safety net\n                self.logger.critical('Encountered error in stats_flush loop')", "response": "Flush stats to graphite."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pickle_payload(self):\n        tstamp = int(time.time())\n        payload = []\n\n        for item in self.counters:\n            payload.append((\"%s.%s%s\" % (self.rate_prefix, item,\n                                         self.rate_suffix),\n                            (tstamp,\n                             self.counters[item] / self.flush_interval)))\n            payload.append((\"%s.%s%s\" % (self.count_prefix, item,\n                                         self.count_suffix),\n                            (tstamp, self.counters[item])))\n            self.counters[item] = 0\n\n        for key in self.timers:\n            if len(self.timers[key]) > 0:\n                self.process_timer_key(key, tstamp, payload, pickled=True)\n                self.timers[key] = []\n\n        for key in self.gauges:\n            payload.append((\"%s.%s\" % (self.gauge_prefix, key),\n                            (tstamp, self.gauges[key])))\n            self.gauges[key] = 0\n\n        if payload:\n            batched_payload = []\n            for batch in self._get_batches(payload):\n                if self.debug:\n                    print \"pickling batch: %r\" % batch\n                serialized_data = pickle.dumps(batch, protocol=-1)\n                length_prefix = struct.pack(\"!L\", len(serialized_data))\n                batched_payload.append(length_prefix + serialized_data)\n            return batched_payload\n        return None", "response": "obtain stats payload in batches of pickle format"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nobtains stats payload in plaintext format", "response": "def plain_payload(self):\n        \"\"\"obtain stats payload in plaintext format\"\"\"\n        tstamp = int(time.time())\n        payload = []\n        for item in self.counters:\n            payload.append('%s.%s%s %s %s\\n' % (self.rate_prefix,\n                                                item,\n                                                self.rate_suffix,\n                                                self.counters[item] /\n                                                self.flush_interval,\n                                                tstamp))\n            payload.append('%s.%s%s %s %s\\n' % (self.count_prefix,\n                                                item,\n                                                self.count_suffix,\n                                                self.counters[item],\n                                                tstamp))\n            self.counters[item] = 0\n\n        for key in self.timers:\n            if len(self.timers[key]) > 0:\n                self.process_timer_key(key, tstamp, payload)\n                self.timers[key] = []\n\n        for key in self.gauges:\n            payload.append(\"%s.%s %d %d\\n\" % (self.gauge_prefix, key,\n                                              self.gauges[key], tstamp))\n            self.gauges[key] = 0\n\n        if self.debug:\n            print payload\n\n        if payload:\n            return \"\".join(payload)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_gauge(self, key, fields):\n        try:\n            self.gauges[key] = float(fields[0])\n            if self.stats_seen >= maxint:\n                self.logger.info(\"hit maxint, reset seen counter\")\n                self.stats_seen = 0\n            self.stats_seen += 1\n        except Exception as err:\n            self.logger.info(\"error decoding gauge event: %s\" % err)\n            if self.debug:\n                print \"error decoding gauge event: %s\" % err", "response": "Process a received gauge event and store it in the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_timer(self, key, fields):\n        try:\n            if key not in self.timers:\n                self.timers[key] = []\n            self.timers[key].append(float(fields[0]))\n            if self.stats_seen >= maxint:\n                self.logger.info(\"hit maxint, reset seen counter\")\n                self.stats_seen = 0\n            self.stats_seen += 1\n        except Exception as err:\n            self.logger.info(\"error decoding timer event: %s\" % err)\n            if self.debug:\n                print \"error decoding timer event: %s\" % err", "response": "Process a received timer event and store the result in the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a received counter event.", "response": "def process_counter(self, key, fields):\n        \"\"\"\n        Process a received counter event\n\n        :param key: Key of counter\n        :param fields: Received fields\n        \"\"\"\n        sample_rate = 1.0\n        try:\n            if len(fields) is 3:\n                if self.ratecheck.match(fields[2]):\n                    sample_rate = float(fields[2].lstrip(\"@\"))\n                else:\n                    raise Exception(\"bad sample rate.\")\n            counter_value = float(fields[0] or 1) * (1 / float(sample_rate))\n            if key not in self.counters:\n                self.counters[key] = 0\n            self.counters[key] += counter_value\n            if self.stats_seen >= maxint:\n                self.logger.info(\"hit maxint, reset seen counter\")\n                self.stats_seen = 0\n            self.stats_seen += 1\n        except Exception as err:\n            self.logger.info(\"error decoding counter event: %s\" % err)\n            if self.debug:\n                print \"error decoding counter event: %s\" % err"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_timer_key(self, key, tstamp, stack, pickled=False):\n        self.timers[key].sort()\n        values = {'count': len(self.timers[key]),\n                  'low': min(self.timers[key]),\n                  'high': max(self.timers[key]),\n                  'total': sum(self.timers[key])}\n        values['mean'] = values['low']\n        nth_percentile = 'upper_%i' % self.pct_threshold\n        values[nth_percentile] = values['high']\n\n        if values['count']:\n            threshold_idx = int(self.threshold_numerator * values['count']) - 1\n            values[nth_percentile] = self.timers[key][threshold_idx]\n            values['mean'] = float(values['total']) / float(values['count'])\n\n        for metric in values:\n            if pickled:\n                stack.append((\"%s.%s.%s\" % (self.timer_prefix, key, metric),\n                              (tstamp, values[metric])))\n            else:\n                stack.append(\"%s.%s.%s %s %s\\n\" % (self.timer_prefix,\n                                                   key,\n                                                   metric,\n                                                   values[metric],\n                                                   tstamp))", "response": "Process the timer key and add the output to the stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes and process the data from a received event.", "response": "def decode_recvd(self, data):\n        \"\"\"\n        Decode and process the data from a received event.\n\n        :param data: Data to decode and process.\n        \"\"\"\n        bits = data.split(':')\n        if len(bits) == 2:\n            key = self.keycheck.sub('_', bits[0])\n            fields = bits[1].split(\"|\")\n            field_count = len(fields)\n            if field_count >= 2:\n                processor = self.processors.get(fields[1])\n                if processor:\n                    if self.debug:\n                        print \"got key: %s %r\" % (key, fields)\n                    processor(key, fields)\n                else:\n                    print \"error: unsupported stats type\"\n                    print \"key -> %s\\nfields ->%s\" % (key, fields)\n            else:\n                print \"error (%s): not enough fields received\" % key\n        else:\n            print \"error: invalid request [%s]\" % data[:40]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_usage(self):\n        parser = argparse.ArgumentParser()\n        parser.prog = 'juju-resources {}'.format(self.object_name)\n        for set_name, set_args in getattr(self.object, '_subcommand_argsets', {}).items():\n            for ap_args, ap_kwargs in set_args:\n                parser.add_argument(*ap_args, **ap_kwargs)\n        for ap_args, ap_kwargs in getattr(self.object, '_subcommand_args', []):\n            parser.add_argument(*ap_args, **ap_kwargs)\n        usage = parser.format_usage()\n        usage = re.sub(r'\\n *', ' ', usage)\n        return usage.strip()", "response": "Build usage string from argparser args.\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the given address and return the address as an integer.", "response": "def parse_group_address(addr):\n    \"\"\"Parse KNX group addresses and return the address as an integer.\n\n    This allows to convert x/x/x and x/x address syntax to a numeric\n    KNX group address\n    \"\"\"\n\n    if addr is None:\n        raise KNXException(\"No address given\")\n\n    res = None\n\n    if re.match('[0-9]+$', addr):\n        res = int(addr)\n\n    match = re.match(\"([0-9]+)/([0-9]+)$\", addr)\n    if match:\n        main = match.group(1)\n        sub = match.group(2)\n        res = int(main) * 2048 + int(sub)\n\n    match = re.match(\"([0-9]+)/([0-9]+)/([0-9]+)$\", addr)\n    if match:\n        main = match.group(1)\n        middle = match.group(2)\n        sub = match.group(3)\n        res = int(main) * 256 * 8 + int(middle) * 256 + int(sub)\n\n    if res is None:\n        raise KNXException(\"Address {} does not match any address scheme\".\n                           format(addr))\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, name, value):\n        old_val = self.values.get(name)\n        if old_val != value:\n            self.values[name] = value\n            return True\n        else:\n            return False", "response": "Set the cached value for the given name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsanitizing all fields of the KNX message.", "response": "def sanitize(self):\n        \"\"\"Sanitize all fields of the KNX message.\"\"\"\n        self.repeat = self.repeat % 2\n        self.priority = self.priority % 4\n        self.src_addr = self.src_addr % 0x10000\n        self.dst_addr = self.dst_addr % 0x10000\n        self.multicast = self.multicast % 2\n        self.routing = self.routing % 8\n        self.length = self.length % 16\n        for i in range(0, self.length - 1):\n            self.data[i] = self.data[i] % 0x100"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the object to its frame format.", "response": "def to_frame(self):\n        \"\"\"Convert the object to its frame format.\"\"\"\n        self.sanitize()\n        res = []\n        res.append((1 << 7) + (1 << 4) + (self.repeat << 5) +\n                   (self.priority << 2))\n        res.append(self.src_addr >> 8)\n        res.append(self.src_addr % 0x100)\n        res.append(self.dst_addr >> 8)\n        res.append(self.dst_addr % 0x100)\n        res.append((self.multicast << 7) + (self.routing << 4) + self.length)\n\n        for i in range(0, self.length - 1):\n            res.append(self.data[i])\n\n        checksum = 0\n        for i in range(0, 5 + self.length):\n            checksum += res[i]\n\n        res.append(checksum % 0x100)\n\n        return bytearray(res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a KNXMessage object from the frame format.", "response": "def from_frame(cls, frame):\n        \"\"\"Create a KNXMessage object from the frame format.\"\"\"\n        message = cls()\n\n        # Check checksum first\n        checksum = 0\n        for i in range(0, len(frame) - 1):\n            checksum += frame[i]\n\n        if (checksum % 0x100) != frame[len(frame) - 1]:\n            raise KNXException('Checksum error in frame {}, '\n                               'expected {} but got {}'\n                               .format(tohex(frame), frame[len(frame) - 1],\n                                       checksum % 0x100))\n\n        message.repeat = (frame[0] >> 5) & 0x01\n        message.priority = (frame[0] >> 2) & 0x03\n        message.src_addr = (frame[1] << 8) + frame[2]\n        message.dst_addr = (frame[3] << 8) + frame[4]\n        message.multicast = (frame[5] >> 7)\n        message.routing = (frame[5] >> 4) & 0x03\n        message.length = frame[5] & 0x0f\n        message.data = frame[6:-1]\n\n        if len(message.data) + 1 != message.length:\n            raise KNXException(\n                'Frame {} has not the correct length'.format(tohex(frame)))\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assemble_remotes(resource):\n    resource_type = classify_resource_type(resource)\n\n    if resource_type is None:\n        juicer.utils.Log.log_debug(\"Could not classify or find the input resource.\")\n        return []\n    elif resource_type == REMOTE_PKG_TYPE:\n        return [resource]\n    elif resource_type == REMOTE_INDEX_TYPE:\n        return parse_directory_index(resource)\n    elif resource_type == REMOTE_INPUT_FILE_TYPE:\n        # Later on this could examine the excluded data for directory\n        # indexes and iterate over those too.\n        remote_packages, excluded_data = parse_input_file(resource)\n        return remote_packages", "response": "This function will assemble a list of rpm URLs for a remote package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classify_resource_type(resource):\n    if is_remote_package(resource):\n        juicer.utils.Log.log_debug(\"Classified %s as a remote package\" % resource)\n        return REMOTE_PKG_TYPE\n    elif is_directory_index(resource):\n        juicer.utils.Log.log_debug(\"Classified %s as a directory index\" % resource)\n        return REMOTE_INDEX_TYPE\n    elif exists(expanduser(resource)):\n        juicer.utils.Log.log_debug(\"Classified %s as an input file\" % resource)\n        return REMOTE_INPUT_FILE_TYPE\n    else:\n        juicer.utils.Log.log_debug(\"Classified %s as unclassifiable\" % resource)\n        return None", "response": "This function is used to classify a resource type by looking at the command line and the system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a boolean value indicating whether the input resource is a remote RPM or not.", "response": "def is_remote_package(resource):\n    \"\"\"\n    Classify the input resource as a remote RPM or not.\n    \"\"\"\n    remote_regexp = re.compile(r\"^https?://(.+).rpm$\", re.I)\n    result = remote_regexp.match(resource)\n\n    if result is not None:\n        juicer.utils.Log.log_debug(\"%s matches remote package regexp\" % resource)\n        return True\n    else:\n        juicer.utils.Log.log_debug(\"%s doesn't match remote package regexp\" % resource)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a boolean value indicating whether the input resource is a directory index or not.", "response": "def is_directory_index(resource):\n    \"\"\"\n    Classify the input resource as a directory index or not.\n    \"\"\"\n    remote_regexp = re.compile(r\"^https?://(.+)/?$\", re.I)\n    result = remote_regexp.match(resource)\n\n    if result is not None:\n        juicer.utils.Log.log_debug(\"%s matches directory index regexp\" % resource)\n        return True\n    else:\n        juicer.utils.Log.log_debug(\"%s doesn't match directory index regexp\" % resource)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_input_file(resource):\n    input_resource = open(resource, 'r').read()\n    remotes_list = [url for url in input_resource.split()]\n\n    juicer.utils.Log.log_debug(\"Input file parsed into: %s\\n\" % str(remotes_list))\n\n    remote_packages = [pkg for pkg in remotes_list if is_remote_package(pkg) is True]\n    juicer.utils.Log.log_debug(\"remote_packages filtered into %s\\n\" % str(remote_packages))\n\n    excluded_data = [datum for datum in remotes_list if datum not in remote_packages]\n    juicer.utils.Log.log_debug(\"excluded_data filtered into %s\\n\" % str(excluded_data))\n\n    http_indexes = [index for index in excluded_data if is_directory_index(index)]\n    remotes_from_indexes = reduce(lambda x, y: x + parse_directory_index(y), http_indexes, [])\n\n    return (remote_packages + remotes_from_indexes, excluded_data)", "response": "Parse input file into remote packages and excluded data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_directory_index(directory_index):\n    # Normalize our URL style\n    if not directory_index.endswith('/'):\n        directory_index = directory_index + '/'\n\n    site_index = urllib2.urlopen(directory_index)\n    parsed_site_index = bs(site_index)\n    rpm_link_tags = parsed_site_index.findAll('a', href=re.compile(r'.*rpm$'))\n\n    # Only save the HREF attribute values from the links found\n    rpm_names = [link['href'] for link in rpm_link_tags]\n\n    # Join the index path with the discovered names so we only return complete paths\n    remote_list = map(lambda end: \"\".join([directory_index, end]), rpm_names)\n\n    return remote_list", "response": "Retrieve a directory index and make a list of the RPMs listed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncorrect the output of a n - term log file.", "response": "def correct_output(luminosity):\n    \"\"\"\n    :param luminosity: Input luminosity\n    :return: Luminosity limited to the 0 <= l <= 255 range.\n    \"\"\"\n    if luminosity < 0:\n        val = 0\n    elif luminosity > 255:\n        val = 255\n    else:\n        val = luminosity\n    return round(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a color temperature given in kelvin to an approximate RGB value.", "response": "def kelvin_to_rgb(kelvin):\n    \"\"\"\n    Convert a color temperature given in kelvin to an approximate RGB value.\n\n    :param kelvin: Color temp in K\n    :return: Tuple of (r, g, b), equivalent color for the temperature\n    \"\"\"\n    temp = kelvin / 100.0\n\n    # Calculate Red:\n    if temp <= 66:\n        red = 255\n    else:\n        red = 329.698727446 * ((temp - 60) ** -0.1332047592)\n\n    # Calculate Green:\n\n    if temp <= 66:\n        green = 99.4708025861 * math.log(temp) - 161.1195681661\n    else:\n        green = 288.1221695283 * ((temp - 60) ** -0.0755148492)\n\n    #Calculate Blue:\n    if temp > 66:\n        blue = 255\n    elif temp <= 19:\n        blue = 0\n    else:\n        blue = 138.5177312231 * math.log(temp - 10) - 305.0447927307\n\n    return tuple(correct_output(c) for c in (red, green, blue))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef color(self, color):\n        if saturation_of_color(color) == 0:\n            self.white()\n            return\n        self._color = color\n        self.hue = hue_of_color(color)", "response": "Set the color of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef white(self):\n        self._color = RGB_WHITE\n        cmd = self.command_set.white()\n        self.send(cmd)", "response": "Set color to white."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the group brightness.", "response": "def brightness(self, brightness):\n        \"\"\" Set the group brightness.\n\n        :param brightness: Brightness in decimal percent (0.0-1.0).\n        \"\"\"\n        if brightness < 0 or brightness > 1:\n            raise ValueError(\"Brightness must be a percentage \"\n                             \"represented as decimal 0-1.0\")\n        self._brightness = brightness\n        cmd = self.command_set.brightness(brightness)\n        self.send(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hue(self, hue):\n        if hue < 0 or hue > 1:\n            raise ValueError(\"Hue must be a percentage \"\n                             \"represented as decimal 0-1.0\")\n        self._hue = hue\n        cmd = self.command_set.hue(hue)\n        self.send(cmd)", "response": "Set the group hue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transition(self, duration, color=None, brightness=None):\n        # Transition to white immediately.\n        if color == RGB_WHITE:\n            self.white()\n            color = None\n        # Transition away from white immediately.\n        elif self.color == RGB_WHITE and color is not None:\n            self.color = color\n            color = None\n        # Transition immediately if duration is zero.\n        if duration == 0:\n            if color:\n                self.color = color\n            if brightness is not None:\n                self.brightness = brightness\n            return\n        # Perform transition\n        if color != self.color or brightness != self.brightness:\n            if color is None and brightness == self.brightness:\n                return\n            if color is None:\n                self._transition(duration, brightness=brightness)\n            else:\n                self._transition(duration, hue_of_color(color), brightness)", "response": "Transition to color and brightness."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransitions to the next state of the object.", "response": "def _transition(self, duration, hue=None, brightness=None):\n        \"\"\" Transition.\n\n        :param duration: Time to transition.\n        :param hue: Transition to this hue.\n        :param brightness: Transition to this brightness.\n        \"\"\"\n        # Calculate brightness steps.\n        b_steps = 0\n        if brightness is not None:\n            b_steps = steps(self.brightness,\n                            brightness, self.command_set.brightness_steps)\n            b_start = self.brightness\n        # Calculate hue steps.\n        h_steps = 0\n        if hue is not None:\n            h_steps = steps(self.hue,\n                            hue, self.command_set.hue_steps)\n            h_start = self.hue\n        # Compute ideal step amount (at least one).\n        total_steps = max(b_steps, h_steps, 1)\n        total_commands = b_steps + h_steps\n        # Calculate wait.\n        wait = self._wait(duration, total_steps, total_commands)\n        # Scale down steps if no wait time.\n        if wait == 0:\n            b_steps, h_steps = self._scale_steps(duration, total_commands,\n                                                 b_steps, h_steps)\n            total_steps = max(b_steps, h_steps, 1)\n        # Perform transition.\n        for i in range(total_steps):\n            # Brightness.\n            if b_steps > 0 and i % math.ceil(total_steps/b_steps) == 0:\n                self.brightness = util.transition(i, total_steps,\n                                                  b_start, brightness)\n            # Hue.\n            if h_steps > 0 and i % math.ceil(total_steps/h_steps) == 0:\n                self.hue = util.transition(i, total_steps,\n                                           h_start, hue)\n            # Wait.\n            time.sleep(wait)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend updated to the KNX bus.", "response": "def send_updates(self):\n        \"\"\" Send updated to the KNX bus. \"\"\"\n        d = datetime.now()\n        if self.timeaddr:\n            self.tunnel.group_write(self.timeaddr,\n                                    time_to_knx(d))\n\n        if self.dateaddr:\n            self.tunnel.group_write(self.dateaddr,\n                                    date_to_knx(d))\n\n        if self.datetimeaddr:\n            self.tunnel.group_write(self.datetimeaddr,\n                                    datetime_to_knx(d))\n\n        if self.daynightaddr:\n            from pysolar.solar import get_altitude\n            alt = get_altitude(self.lat, self.long, d)\n            if alt > 0:\n                self.tunnel.group_write(self.daynightaddr, 1)\n            else:\n                self.tunnel.group_write(self.daynightaddr, 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a thread that runs the updater in the background.", "response": "def run_updater_in_background(self):\n        \"\"\" Starts a thread that runs the updater in the background. \"\"\"\n        thread = threading.Thread(target=self.updater_loop())\n        thread.daemon = True\n        thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the parent of a directory.", "response": "def parent_dir(path):\n    '''Return the parent of a directory.'''\n    return os.path.abspath(os.path.join(path, os.pardir, os.pardir, '_build'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, path):\n        self._reset()\n        self.path = path\n        self._refresh_synced()\n        if self.is_synced:\n            self._refresh_path()\n            self._refresh_signed()\n            self._refresh_nvr()", "response": "Update the attributes of this CartItem with the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _refresh_synced(self):\n        if self.path.startswith('http'):\n            juicer.utils.Log.log_debug(\"%s is not synced\" % self.path)\n            self.is_synced = False\n        else:\n            juicer.utils.Log.log_debug(\"%s is synced\" % self.path)\n            self.is_synced = True", "response": "Refresh is_synced attribute accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _refresh_path(self):\n        # Unsynced items are remote so we can't check some of their\n        # properties yet\n        if os.path.exists(self.path):\n            try:\n                i = open(self.path, 'r')\n                i.close()\n                juicer.utils.Log.log_debug(\"Successfully read item at: %s\" % self.path)\n            except:\n                raise IOError(\"Error while attempting to access item at path: %s\" % self.path)\n        else:\n            raise IOError(\"Could not locate item at path: %s\" % self.path)", "response": "Refresh the path of the item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefreshing our name - version - release attributes.", "response": "def _refresh_nvr(self):\n        \"\"\" Refresh our name-version-release attributes. \"\"\"\n        rpm_info = juicer.utils.rpm_info(self.path)\n        self.name = rpm_info['name']\n        self.version = rpm_info['version']\n        self.release = rpm_info['release']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the internal state of the object.", "response": "def _reset(self):\n        \"\"\" Used during update operations and when initialized. \"\"\"\n        self.path = ''\n        self.version = ''\n        self.release = ''\n        self.is_signed = False\n        self.is_synced = False\n        self.rpm = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding groups from this bridge.", "response": "def add_bridge(self, bridge):\n        \"\"\" Add bridge groups.\n\n        :param bridge: Add groups from this bridge.\n        \"\"\"\n        for group in bridge.groups:\n            self._groups[group.name] = group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode(in_bytes):\n    out_bytes = []\n    idx = 0\n    search_start_idx = 0\n    for in_char in in_bytes:\n        if idx - search_start_idx == 0xFE:\n            out_bytes.append('\\xFF')\n            out_bytes.append(in_bytes[search_start_idx:idx])\n            search_start_idx = idx\n        if in_char == '\\x00':\n            out_bytes.append(chr(idx - search_start_idx + 1))\n            out_bytes.append(in_bytes[search_start_idx:idx])\n            search_start_idx = idx + 1\n        idx += 1\n    try:\n        final_byte = in_bytes[-1]\n    except IndexError:\n        final_byte = '\\x00'\n    length_value = idx - search_start_idx + 1\n    if ord(final_byte) < length_value:\n        # Encoding same as plain COBS\n        out_bytes.append(chr(length_value))\n        out_bytes.append(in_bytes[search_start_idx:idx])\n    else:\n        # Special COBS/R encoding: length code is final byte,\n        # and final byte is removed from data sequence.\n        out_bytes.append(final_byte)\n        out_bytes.append(in_bytes[search_start_idx:idx - 1])\n    return ''.join(out_bytes)", "response": "Encode a string using Consistent Overhead Byte Stuffing and Redced COBS."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the full command as bytes.", "response": "def get_bytes(self, bridge):\n        \"\"\"\n        Gets the full command as bytes.\n        :param bridge: The bridge, to which the command should be sent.\n        \"\"\"\n        if not bridge.is_ready:\n            raise Exception('The bridge has to be ready to construct command.')\n\n        wb1 = bridge.wb1\n        wb2 = bridge.wb2\n        sn = bridge.sn\n\n        preamble = [0x80, 0x00, 0x00, 0x00, 0x11, wb1, wb2, 0x00, sn, 0x00]\n        cmd = [0x31, self.PASSWORD_BYTE1, self.PASSWORD_BYTE2,\n               self._remote_style, self._cmd_1,\n               self._cmd_2, self._cmd_2, self._cmd_2, self._cmd_2]\n        zone_selector = [self._group_number, 0x00]\n        checksum = sum(cmd + zone_selector) & 0xFF\n\n        return bytearray(preamble + cmd + zone_selector + [checksum])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the saturation from decimal percent 0. 0 - 1. 0 to byte representation for use in commands.", "response": "def convert_saturation(self, saturation):\n        \"\"\"\n        Convert the saturation from decimal percent (0.0-1.0)\n        to byte representation for use in commands.\n        :param saturation: The saturation from in decimal percent (0.0-1.0).\n        1.0 is the maximum saturation where no white leds will be on. 0.0 is no\n        saturation.\n        :return: The saturation in byte representation.\n        \"\"\"\n\n        saturation_inverted = 1 - saturation\n        return math.ceil(saturation_inverted * self.MAX_SATURATION)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_hue(self, hue, legacy_color_wheel=False):\n        hue = math.ceil(hue * self.MAX_HUE)\n        if legacy_color_wheel:\n            hue = (176 - hue) % (self.MAX_HUE + 1)\n            hue = (self.MAX_HUE - hue - 0x37) % (self.MAX_HUE + 1)\n        else:\n            hue += 10  # The color wheel for RGBWW bulbs seems to be shifted\n\n        return hue % (self.MAX_HUE + 1)", "response": "Converts the hue from HSV color circle to LimitlessLED color wheel."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_command(self, cmd_1, cmd_2,\n                       select=False, select_command=None):\n        \"\"\"\n        Constructs the complete command.\n        :param cmd_1: Light command 1.\n        :param cmd_2: Light command 2.\n        :return: The complete command.\n        \"\"\"\n\n        return CommandV6(cmd_1, cmd_2, self._remote_style, self._group_number,\n                         select, select_command)", "response": "Builds a complete command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef json(self, json_string=None):\n        if json_string is not None:\n            return self.__init__(loads(json_string))\n        dump = self\n        if isinstance(self, HAR.log):\n            dump = {\"log\": dump}\n        return dumps(dump, default=lambda x: dict(x))", "response": "Returns a dict containing the current object s attributes and the given json string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_search(self):\n\n        self._asyncio_loop = asyncio.get_event_loop()\n\n        # Creating Broadcast Receiver\n        coroutine_listen = self._asyncio_loop.create_datagram_endpoint(\n            lambda: self.KNXSearchBroadcastReceiverProtocol(\n                self._process_response,\n                self._timeout_handling,\n                self._timeout,\n                self._asyncio_loop\n            ), local_addr=(self._broadcast_ip_address, 0)\n        )\n        self._listener_transport, listener_protocol = \\\n            self._asyncio_loop.run_until_complete(coroutine_listen)\n\n        # We are ready to fire the broadcast message\n        coroutine_broadcaster = self._asyncio_loop.create_datagram_endpoint(\n            lambda: self.KNXSearchBroadcastProtocol(\n                self._asyncio_loop,\n                self._listener_transport.get_extra_info('sockname')\n                [1]),\n            remote_addr=(self._broadcast_address, self._broadcast_port))\n\n        self._broadcaster_transport, broadcast_protocol = \\\n            self._asyncio_loop.run_until_complete(coroutine_broadcaster)\n        # Waiting for all Broadcast receive or timeout\n        self._asyncio_loop.run_forever()\n\n        # Got Response or Timeout\n        if self._resolved_gateway_ip_address is None and \\\n           self._resolved_gateway_ip_port is None:\n            LOGGER.debug(\"Gateway not found!\")\n            return None\n        else:\n            LOGGER.debug(\"Gateway found at %s:%s\",\n                         self._resolved_gateway_ip_address,\n                         self._resolved_gateway_ip_port)\n\n            return self._resolved_gateway_ip_address, \\\n                self._resolved_gateway_ip_port", "response": "Starts the Gateway Search Request and returns the address information when found or None when timeout occurs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_response(self, received_data):\n        resp = bytearray(received_data)\n        self._resolved_gateway_ip_address = str.format(\n            \"{}.{}.{}.{}\", resp[8], resp[9], resp[10], resp[11])\n        self._resolved_gateway_ip_port = struct.unpack(\n            '!h', bytes(resp[12:14]))[0]", "response": "Processes the incoming UDP Datagram from the Broadcast Socket\n\n        and sets the IP address and port fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a binary data to an upload", "response": "def append(self, fdata, offset, query='/content/uploads'):\n        \"\"\"\n        append binary data to an upload\n        `fdata` - binary data to send to pulp\n        `offset` - the amount of previously-uploaded data\n        \"\"\"\n        query = '%s/%s/%s/' % (query, self.uid, offset)\n        _r = self.connector.put(query, fdata, log_data=False, auto_create_json_str=False)\n\n        juicer.utils.Log.log_notice(\"Appending to: %s\" % query)\n        juicer.utils.Log.log_debug(\"Continuing upload with append. POST returned with data: %s\" % str(_r.content))\n\n        return _r.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports the completed upload into pulp `ftype` - the type of the upload `rpm_name` - the name of the uploaded rpm `desc` - description of the rpm `htype` - checksum type `lic` - license used in the packaged software `group` - package group `vendor` - software vendor `req` - dependencies", "response": "def import_upload(self, nvrea, ftype='rpm', rpm_name='', desc=None, htype='md5', lic=None, group=None, vendor=None, req=None):\n        \"\"\"\n        import the completed upload into pulp\n        `ftype` - the type of the upload\n        `rpm_name` - the name of the uploaded rpm\n        `desc` - description of the rpm\n        `htype` - checksum type\n        `lic` - license used in the packaged software\n        `group` - package group\n        `vendor` - software vendor\n        `req` - dependencies\n        \"\"\"\n        query = '/repositories/%s/actions/import_upload/' % self.repoid\n        data = {'upload_id': self.uid,\n                'unit_type_id': ftype,\n                'unit_key': {\n                    'name': rpm_name,\n                    'version': nvrea[1],\n                    'release': nvrea[2],\n                    'epoch': nvrea[3],\n                    'arch': nvrea[4],\n                    'checksumtype': htype,\n                    'checksum': self.cksum,\n                    },\n                'unit_metadata': {\n                    'filename': self.pkg_name,\n                    'license': lic if lic else '',\n                    'requires': req if req else '',\n                    #    'type': ftype,\n                    'description': desc if desc else '',\n                    #    'size': self.size,\n                    'vendor': vendor if vendor else '',\n                    'relativepath': self.pkg_name,\n                    }\n                }\n\n        _r = self.connector.post(query, data)\n\n        if _r.status_code not in [Constants.PULP_POST_OK, Constants.PULP_POST_ACCEPTED]:\n            juicer.utils.Log.log_error(\"Import error importing '%s'... server said: \\n %s\", (self.pkg_name,\n                                       juicer.utils.load_json_str(_r.content)))\n            _r.raise_for_status()\n\n        juicer.utils.Log.log_debug(\"Finalized upload id %s\" % self.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_upload(self, query='/content/uploads/'):\n        query = query + self.uid + '/'\n        _r = self.connector.delete(query)\n\n        if _r.status_code == Constants.PULP_DELETE_OK:\n            juicer.utils.Log.log_info(\"Cleaned up after upload request.\")\n        else:\n            _r.raise_for_status()", "response": "pulp leaves droppings if you don t specifically tell it\n        to clean up after itself. use this to do so."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the user config file is present and readable. If not copy a template in place.", "response": "def _user_config_file():\n    \"\"\"\n    Check that the config file is present and readable. If not,\n    copy a template in place.\n    \"\"\"\n    config_file = Constants.USER_CONFIG\n    if os.path.exists(config_file) and os.access(config_file, os.R_OK):\n        return config_file\n    elif os.path.exists(config_file) and not os.access(config_file, os.R_OK):\n        raise IOError(\"Can not read %s\" % config_file)\n    else:\n        shutil.copy(Constants.EXAMPLE_USER_CONFIG, config_file)\n\n        raise JuicerConfigError(\"Default config file created.\\nCheck man 5 juicer.conf.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the user config file", "response": "def _config_file():\n    \"\"\"\n    combine the user config file with the system config file (if present)\n    \"\"\"\n    config = ConfigParser.SafeConfigParser()\n    configs = []\n\n    try:\n        configs.append(_user_config_file())\n    except Exception, e:\n        juicer.utils.Log.log_debug(e)\n\n    config.read(configs)\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a pymongo db connection for interacting with cart objects", "response": "def cart_db():\n    \"\"\"\n    return a pymongo db connection for interacting with cart objects\n    \"\"\"\n    config = _config_file()\n    _config_test(config)\n\n    juicer.utils.Log.log_debug(\"Establishing cart connection:\")\n    cart_con = MongoClient(dict(config.items(config.sections()[0]))['cart_host'])\n    cart_db = cart_con.carts\n\n    return cart_db"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a cart to the specified collection", "response": "def upload_cart(cart, collection):\n    \"\"\"\n    Connect to mongo and store your cart in the specified collection.\n    \"\"\"\n    cart_cols = cart_db()\n\n    cart_json = read_json_document(cart.cart_file())\n    try:\n        cart_id = cart_cols[collection].save(cart_json)\n    except MongoErrors.AutoReconnect:\n        raise JuicerConfigError(\"Error saving cart to `cart_host`. Ensure that this node is the master.\")\n    return cart_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of dicts with the connection information for all the environments.", "response": "def get_login_info():\n    \"\"\"\n    Give back an array of dicts with the connection\n    information for all the environments.\n    \"\"\"\n    connections = {}\n    _defaults = {}\n    _defaults['start_in'] = ''\n    _defaults['rpm_sign_plugin'] = ''\n\n    config = _config_file()\n\n    _config_test(config)\n\n    juicer.utils.Log.log_debug(\"Loading connection information:\")\n    for section in config.sections():\n        cfg = dict(config.items(section))\n\n        connections[section] = Connectors(cfg)\n\n        if 'start_in' in cfg:\n            _defaults['start_in'] = cfg['start_in']\n\n        if 'rpm_sign_plugin' in cfg:\n            _defaults['rpm_sign_plugin'] = cfg['rpm_sign_plugin']\n\n        juicer.utils.Log.log_debug(\"[%s] username: %s, base_url: %s\" % \\\n                                       (section, \\\n                                            cfg['username'], \\\n                                            cfg['base_url']))\n\n    _defaults['environments'] = config.sections()\n\n    return (connections, _defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_environments():\n    config = ConfigParser.SafeConfigParser()\n\n    config = _config_file()\n\n    juicer.utils.Log.log_debug(\"Reading environment sections:\")\n\n    environments = config.sections()\n    juicer.utils.Log.log_debug(\"Read environment sections: %s\", ', '.join(environments))\n    return environments", "response": "Return defined environments from config file for default\n    environment values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef env_same_host(env1, env2):\n    config = _config_file()\n\n    h1 = dict(config.items(env1))['base_url']\n    h2 = dict(config.items(env2))['base_url']\n\n    return h1 == h2", "response": "returns true if two environments are on the same host. returns false otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next_environment(env):\n    config = _config_file()\n\n    juicer.utils.Log.log_debug(\"Finding next environment...\")\n\n    if env not in config.sections():\n        raise JuicerConfigError(\"%s is not a server configured in juicer.conf\", env)\n\n    section = dict(config.items(env))\n\n    if 'promotes_to' not in section.keys():\n        err = \"Environment `%s` has no entry for `promotes_to`\\nCheck man 5 juicer.conf.\" % env\n        raise JuicerConfigError(err)\n\n    return section['promotes_to']", "response": "Given an environment return the next environment in the promotion hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pulp_repo_path(connection, repoid):\n    dl_base = connection.base_url.replace('/pulp/api/v2', '/pulp/repos')\n    _m = re.match('(.*)-(.*)', repoid)\n    repo = _m.group(1)\n    env = _m.group(2)\n\n    return \"%s/%s/%s\" % (dl_base, env, repo)", "response": "Given a connection and a repoid return the url of the repository"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_exists_p(login, connector):\n    url = '/users/' + login + '/'\n    _r = connector.get(url)\n    return (_r.status_code == Constants.PULP_GET_OK)", "response": "Checks if user exists in specified environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatten(x):\n    # Lifted from: http://stackoverflow.com/a/406822/263969\n    result = []\n    for el in x:\n        if hasattr(el, \"__iter__\") and not isinstance(el, basestring):\n            result.extend(flatten(el))\n        else:\n            result.append(el)\n    return result", "response": "Flatten an arbitrary depth nested list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_json_document(title, body):\n    if not title.endswith('.json'):\n        title += '.json'\n\n    json_body = create_json_str(body)\n\n    if os.path.exists(title):\n        juicer.utils.Log.log_warn(\"Cart file '%s' already exists, overwriting with new data.\" % title)\n\n    f = open(title, 'w')\n    f.write(json_body)\n    f.flush()\n    f.close()", "response": "This method writes a JSON document to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_json_document(title):\n    if not title.endswith('.json'):\n        juicer.utils.Log.log_warn(\"File name (%s) does not end with '.json', appending it automatically.\" % title)\n        title += '.json'\n\n    if not os.path.exists(title):\n        raise IOError(\"Could not find file: '%s'\" % title)\n\n    f = open(title, 'r')\n    doc = f.read()\n    f.close()\n\n    return load_json_str(doc)", "response": "Reads in a json document and returns a native python\n    datastructure."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all files in a directory and return a generator that yields the full path to the files which match the given glob pattern.", "response": "def find_pattern(search_base, pattern='*.rpm'):\n    \"\"\"\n    `search_base` - The directory to begin walking down.\n    `pattern` - File pattern to match for.\n\n    This is a generator which yields the full path to files (one at a\n    time) which match the given glob (`pattern`).\n    \"\"\"\n    # Stolen from http://rosettacode.org/wiki/Walk_a_directory/Recursively#Python\n    if (not os.path.isdir(search_base)) and os.path.exists(search_base):\n        # Adapt the algorithm to gracefully handle non-directory search paths\n        yield search_base\n    else:\n        for root, dirs, files in os.walk(search_base):\n            for filename in fnmatch.filter(files, pattern):\n                yield os.path.join(root, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_package_list(package_list):\n    remote_pkgs = []\n    local_pkgs = []\n\n    possible_remotes = filter(lambda i: not os.path.exists(i), package_list)\n    juicer.utils.Log.log_debug(\"Considering %s possible remotes\" % len(possible_remotes))\n\n    for item in possible_remotes:\n        remote_pkgs.extend(juicer.utils.Remotes.assemble_remotes(item))\n    juicer.utils.Log.log_notice(\"Remote packages: %s\" % str(remote_pkgs))\n\n    possible_locals = filter(os.path.exists, package_list)\n    possible_locals = filter(is_rpm, possible_locals)\n    juicer.utils.Log.log_debug(\"Considering %s possible locals\" % len(possible_locals))\n\n    for item in possible_locals:\n        for match in find_pattern(item):\n            local_pkgs.append(match)\n    juicer.utils.Log.log_notice(\"Local packages: %s\" % str(local_pkgs))\n\n    filtered_package_list = dedupe(remote_pkgs + local_pkgs)\n    return filtered_package_list", "response": "Filter a list of packages into remote and local packages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the path is an RPM.", "response": "def is_rpm(path):\n    \"\"\"\n    Attempt to validate the path as an actual (S)RPM. If an exception\n    is raised then this is not an RPM.\n    \"\"\"\n\n    import magic\n    m = magic.open(magic.MAGIC_MIME)\n    m.load()\n    mime = m.file(path)\n    # rpms or directories are cool\n    if 'rpm' in mime or 'directory' in mime:\n        return True\n    else:\n        juicer.utils.Log.log_info(\"error: File `%s` is not an rpm\" % path)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the file url and save it to the local disk as save_as.", "response": "def save_url_as(url, save_as):\n    \"\"\"\n    Download the file `url` and save it to the local disk as\n    `save_as`.\n    \"\"\"\n\n    remote = requests.get(url, verify=False)\n\n    if not remote.status_code == Constants.PULP_GET_OK:\n        raise JuicerPulpError(\"A %s error occurred trying to get %s\" %\n                                   (remote.status_code, url))\n\n    with open(save_as, 'wb') as data:\n        data.write(remote.content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a str containing a link to the rpm in the pulp repository", "response": "def remote_url(connector, env, repo, filename):\n    \"\"\"\n    return a str containing a link to the rpm in the pulp repository\n    \"\"\"\n    dl_base = connector.base_url.replace('/pulp/api/v2', '/pulp/repos')\n\n    repoid = '%s-%s' % (repo, env)\n\n    _r = connector.get('/repositories/%s/' % repoid)\n    if not _r.status_code == Constants.PULP_GET_OK:\n        # maybe the repo name is the repoid\n        _r = connector.get('/repositories/%s/' % repo)\n        if not _r.status_code == Constants.PULP_GET_OK:\n            raise JuicerPulpError(\"%s was not found as a repoid. Status code %s returned by pulp\" % \\\n                    (repoid, _r.status_code))\n\n    repo = juicer.utils.load_json_str(_r.content)['display_name']\n\n    link = '%s/%s/%s/%s' % (dl_base, env, repo, filename)\n\n    return link"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the rpm. hdr for the given package.", "response": "def return_hdr(ts, package):\n    \"\"\"\n    Hand back the hdr - duh - if the pkg is foobar handback None\n\n    Shamelessly stolen from Seth Vidal\n    http://yum.baseurl.org/download/misc/checksig.py\n    \"\"\"\n    try:\n        fdno = os.open(package, os.O_RDONLY)\n    except OSError:\n        hdr = None\n        return hdr\n    ts.setVSFlags(~(rpm.RPMVSF_NOMD5 | rpm.RPMVSF_NEEDPAYLOAD))\n    try:\n        hdr = ts.hdrFromFdno(fdno)\n    except rpm.error:\n        hdr = None\n        raise rpm.error\n    if type(hdr) != rpm.hdr:\n        hdr = None\n    ts.setVSFlags(0)\n    os.close(fdno)\n    return hdr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget signature information and error code from header", "response": "def get_sig_info(hdr):\n    \"\"\"\n    hand back signature information and an error code\n\n    Shamelessly stolen from Seth Vidal\n    http://yum.baseurl.org/download/misc/checksig.py\n    \"\"\"\n    string = '%|DSAHEADER?{%{DSAHEADER:pgpsig}}:{%|RSAHEADER?{%{RSAHEADER:pgpsig}}:{%|SIGGPG?{%{SIGGPG:pgpsig}}:{%|SIGPGP?{%{SIGPGP:pgpsig}}:{(none)}|}|}|}|'\n    siginfo = hdr.sprintf(string)\n    if siginfo != '(none)':\n        error = 0\n        sigtype, sigdate, sigid = siginfo.split(',')\n    else:\n        error = 101\n        sigtype = 'MD5'\n        sigdate = 'None'\n        sigid = 'None'\n\n    infotuple = (sigtype, sigdate, sigid)\n    return error, infotuple"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_sig(package):\n    rpmroot = '/'\n\n    ts = rpm.TransactionSet(rpmroot)\n\n    sigerror = 0\n    ts.setVSFlags(0)\n    hdr = return_hdr(ts, package)\n    sigerror, (sigtype, sigdate, sigid) = get_sig_info(hdr)\n    if sigid == 'None':\n        keyid = 'None'\n    else:\n        keyid = sigid[-8:]\n    if keyid != 'None':\n        return True\n    else:\n        return False", "response": "check if rpm has a signature"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_manifest(manifest):\n    regex = re.compile('(.*)-(.*)')\n    manifest = os.path.expanduser(manifest)\n\n    if not os.path.exists(manifest):\n        raise JuicerManifestError('File not found: %s' % manifest)\n\n    rpm_list = []\n    fd = open(manifest)\n    data = yaml.load(fd)\n\n    if data is None:\n        raise JuicerManifestError('%s contains no items' % manifest)\n\n    for pkg_name, version in data.iteritems():\n        if version == 'absent' or version == 'purged':\n            juicer.utils.Log.log_debug('%s is absent/purged. Skipping...' % pkg_name)\n        elif version == 'latest':\n            juicer.utils.Log.log_debug('%s is set to latest. Finding...' % pkg_name)\n            lversion, release = juicer.utils.find_latest(pkg_name)\n            if not lversion and not release:\n                # package wasn't found in repo so don't add it to the list\n                continue\n            juicer.utils.Log.log_debug('Adding %s version %s release %s' % (pkg_name, lversion, release))\n            rpm_list.append({'name': pkg_name, 'version': lversion, 'release': release})\n        else:\n            try:\n                _m = regex.match(version)\n                version = _m.group(1)\n                release = _m.group(2)\n                rpm_list.append({'name': pkg_name, 'version': _m.group(1), 'release': _m.group(2)})\n                juicer.utils.Log.log_debug('Adding %s version %s release %s' % (pkg_name, version, release))\n            except:\n                raise JuicerManifestError('The manifest %s is improperly formatted' % manifest)\n                return False\n\n    return rpm_list", "response": "parse a manifest file to get a list of rpm names version and release"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpm_info(rpm_path):\n    ts = rpm.TransactionSet()\n    ts.setVSFlags(rpm._RPMVSF_NOSIGNATURES)\n    rpm_info = {}\n\n    rpm_fd = open(rpm_path, 'rb')\n    pkg = ts.hdrFromFdno(rpm_fd)\n    rpm_info['name'] = pkg['name']\n    rpm_info['version'] = pkg['version']\n    rpm_info['release'] = pkg['release']\n    rpm_info['epoch'] = 0\n    rpm_info['arch'] = pkg['arch']\n    rpm_info['nvrea'] = tuple((rpm_info['name'], rpm_info['version'], rpm_info['release'], rpm_info['epoch'], rpm_info['arch']))\n    rpm_info['cksum'] = hashlib.md5(rpm_path).hexdigest()\n    rpm_info['size'] = os.path.getsize(rpm_path)\n    rpm_info['package_basename'] = os.path.basename(rpm_path)\n    rpm_fd.close()\n    return rpm_info", "response": "Query information about the RPM at rpm_path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_rpm(rpm_path, repoid, connector, callback=None):\n    ts = rpm.TransactionSet()\n    ts.setVSFlags(rpm._RPMVSF_NOSIGNATURES)\n\n    info = rpm_info(rpm_path)\n    pkg_name = info['name']\n    nvrea = info['nvrea']\n    cksum = info['cksum']\n    size = info['size']\n    package_basename = info['package_basename']\n\n    juicer.utils.Log.log_notice(\"Expected amount to seek: %s (package size by os.path.getsize)\" % size)\n\n    # initiate upload\n    upload = juicer.utils.Upload.Upload(package_basename, cksum, size, repoid, connector)\n\n    #create a statusbar\n    pbar = ProgressBar(size)\n\n    # read in rpm\n    total_seeked = 0\n    rpm_fd = open(rpm_path, 'rb')\n    rpm_fd.seek(0)\n    while total_seeked < size:\n        rpm_data = rpm_fd.read(Constants.UPLOAD_AT_ONCE)\n        last_offset = total_seeked\n        total_seeked += len(rpm_data)\n        juicer.utils.Log.log_notice(\"Seeked %s data... (total seeked: %s)\" % (len(rpm_data), total_seeked))\n        upload_code = upload.append(fdata=rpm_data, offset=last_offset)\n        if upload_code != Constants.PULP_PUT_OK:\n            juicer.utils.Log.log_error(\"Upload failed.\")\n        pbar.update(len(rpm_data))\n    pbar.finish()\n    rpm_fd.close()\n\n    juicer.utils.Log.log_notice(\"Seeked total data: %s\" % total_seeked)\n\n    # finalize upload\n    rpm_id = upload.import_upload(nvrea=nvrea, rpm_name=pkg_name)\n\n    juicer.utils.Log.log_debug(\"RPM upload complete. New 'packageid': %s\" % rpm_id)\n\n    # clean up working dir\n    upload.clean_upload()\n\n    # Run callbacks?\n    if callback:\n        try:\n            juicer.utils.Log.log_debug(\"Calling upload callack: %s\" % str(callback))\n            callback(pkg_name)\n        except Exception:\n            juicer.utils.Log.log_error(\"Exception raised in callback: %s\", str(callback))\n            pass\n\n    return rpm_id", "response": "upload an rpm into pulp\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads a cart spec from mongodb", "response": "def download_cart(cart_name, env):\n    \"\"\"\n    accesses mongodb and return a cart spec stored there\n    \"\"\"\n    cart_con = cart_db()\n    carts = cart_con[env]\n\n    return carts.find_one({'_id': cart_name})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cart(base_url, env, cart_name):\n    base_url = base_url.replace('/pulp/api/', '/pulp/repos')\n    url = '%s/%s/carts/%s.json' % (base_url, env, cart_name)\n\n    rsock = urllib2.urlopen(url)\n    data = rsock.read()\n    rsock.close()\n\n    return load_json_str(data)", "response": "Get a cart from a base_url environment and cart_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_carts(env, pkg_name, repos):\n    db = cart_db()\n    carts = db[env]\n\n    for repo in repos:\n        field = 'repos_items.%s' % repo\n        value = '.*%s.*' % pkg_name\n\n        found_carts = []\n\n        for cart in carts.find({field: {'$regex': value}}):\n            found_carts.append(cart)\n        return found_carts", "response": "search_carts returns a list of carts containing a package with the specified name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef header(msg):\n    # Accounting for '| ' and ' |'\n    width = len(msg) + 4\n    s = []\n    s.append('-' * width)\n    s.append(\"| %s |\" % msg)\n    s.append('-' * width)\n    return '\\n'.join(s)", "response": "Wrap msg in bars to create a header effect\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising exception if the repo references undefined environments", "response": "def repo_in_defined_envs(repo, all_envs):\n    \"\"\"Raises exception if the repo references undefined environments\"\"\"\n    remaining_envs = set(repo['env']) - set(all_envs)\n    if set(repo['env']) - set(all_envs):\n        raise JuicerRepoInUndefinedEnvs(\"Repo def %s references undefined environments: %s\" %\n                                        (repo['name'], \", \".join(list(remaining_envs))))\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompares a juicer repo def with a given pulp definition. Compute and return the update necessary to make pulp_def match juicer_def.", "response": "def repo_def_matches_reality(juicer_def, pulp_def):\n    \"\"\"Compare a juicer repo def with a given pulp definition. Compute and\n    return the update necessary to make `pulp_def` match `juicer_def`.\n\n    `juicer_def` - A JuicerRepo() object representing a juicer repository\n    `pulp_def` - A PulpRepo() object representing a pulp repository\n    \"\"\"\n    return juicer.common.Repo.RepoDiff(juicer_repo=juicer_def, pulp_repo=pulp_def)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunk_list(l, n):\n    return [l[i:i + n] for i in range(0, len(l), n)]", "response": "Return n size lists from a given list l"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef debug_log_repo(repo):\n    ds_str = juicer.utils.create_json_str(repo,\n                                          indent=4,\n                                          cls=juicer.common.Repo.RepoEncoder)\n    juicer.utils.Log.log_debug(ds_str)", "response": "Log to DEBUG level a Repo or subclass pretty - printed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading config file and return config items as a dict", "response": "def readconf(conffile, section_name=None, log_name=None, defaults=None,\n             raw=False):\n    \"\"\"\n    Read config file and return config items as a dict\n\n    :param conffile: path to config file, or a file-like object (hasattr\n                     readline)\n    :param section_name: config section to read (will return all sections if\n                     not defined)\n    :param log_name: name to be used with logging (will use section_name if\n                     not defined)\n    :param defaults: dict of default values to pre-populate the config with\n    :returns: dict of config items\n    \"\"\"\n    if defaults is None:\n        defaults = {}\n    if raw:\n        c = RawConfigParser(defaults)\n    else:\n        c = ConfigParser(defaults)\n    if hasattr(conffile, 'readline'):\n        c.readfp(conffile)\n    else:\n        if not c.read(conffile):\n            print (\"Unable to read config file %s\") % conffile\n            sys.exit(1)\n    if section_name:\n        if c.has_section(section_name):\n            conf = dict(c.items(section_name))\n        else:\n            print (\"Unable to find %s config section in %s\") % \\\n                  (section_name, conffile)\n            sys.exit(1)\n        if \"log_name\" not in conf:\n            if log_name is not None:\n                conf['log_name'] = log_name\n            else:\n                conf['log_name'] = section_name\n    else:\n        conf = {}\n        for s in c.sections():\n            conf.update({s: dict(c.items(s))})\n        if 'log_name' not in conf:\n            conf['log_name'] = log_name\n    conf['__file__'] = conffile\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a group. :param bridge: Member of this bridge. :param number: Group number (1-4). :param name: Name of group. :param led_type: Either `RGBW`, `WRGB`, `RGBWW`, `WHITE`, `DIMMER` or `BRIDGE_LED`. :returns: New group.", "response": "def group_factory(bridge, number, name, led_type):\n    \"\"\" Make a group.\n\n    :param bridge: Member of this bridge.\n    :param number: Group number (1-4).\n    :param name: Name of group.\n    :param led_type: Either `RGBW`, `WRGB`, `RGBWW`, `WHITE`, `DIMMER` or `BRIDGE_LED`.\n    :returns: New group.\n    \"\"\"\n    if led_type in [RGBW, BRIDGE_LED]:\n        return RgbwGroup(bridge, number, name, led_type)\n    elif led_type == RGBWW:\n        return RgbwwGroup(bridge, number, name)\n    elif led_type == WHITE:\n        return WhiteGroup(bridge, number, name)\n    elif led_type == DIMMER:\n        return DimmerGroup(bridge, number, name)\n    elif led_type == WRGB:\n        return WrgbGroup(bridge, number, name)\n    else:\n        raise ValueError('Invalid LED type: %s', led_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a group. :param number: Group number (1-4). :param name: Group name. :param led_type: Either `RGBW`, `WRGB`, `RGBWW`, `WHITE`, `DIMMER` or `BRIDGE_LED`. :returns: Added group.", "response": "def add_group(self, number, name, led_type):\n        \"\"\" Add a group.\n\n        :param number: Group number (1-4).\n        :param name: Group name.\n        :param led_type: Either `RGBW`, `WRGB`, `RGBWW`, `WHITE`, `DIMMER` or `BRIDGE_LED`.\n        :returns: Added group.\n        \"\"\"\n        group = group_factory(self, number, name, led_type)\n        self.groups.append(group)\n        return group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, command, reps=REPS, wait=MIN_WAIT):\n        # Enqueue the command.\n        self._command_queue.put((command, reps, wait))\n        # Wait before accepting another command.\n        # This keeps individual groups relatively synchronized.\n        sleep = reps * wait * self.active\n        if command.select and self._selected_number != command.group_number:\n            sleep += SELECT_WAIT\n        time.sleep(sleep)", "response": "Send a command to the physical bridge."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsume commands from the queue and return the next command.", "response": "def _consume(self):\n        \"\"\" Consume commands from the queue.\n\n        The command is repeated according to the configured value.\n        Wait after each command is sent.\n\n        The bridge socket is a shared resource. It must only\n        be used by one thread at a time. Note that this can and\n        will delay commands if multiple groups are attempting\n        to communicate at the same time on the same bridge.\n        \"\"\"\n        while not self.is_closed:\n            # Get command from queue.\n            msg = self._command_queue.get()\n\n            # Closed\n            if msg is None:\n                return\n\n            # Use the lock so we are sure is_ready is not changed during execution\n            # and the socket is not in use\n            with self._lock:\n                # Check if bridge is ready\n                if self.is_ready:\n                    (command, reps, wait) = msg\n\n                    # Select group if a different group is currently selected.\n                    if command.select and self._selected_number != command.group_number:\n                        if self._send_raw(command.select_command.get_bytes(self)):\n                            self._selected_number = command.group_number\n                            time.sleep(SELECT_WAIT)\n                        else:\n                            # Stop sending on socket error\n                            self.is_ready = False\n\n                    # Repeat command as necessary.\n                    for _ in range(reps):\n                        if self.is_ready:\n                            if self._send_raw(command.get_bytes(self)):\n                                time.sleep(wait)\n                            else:\n                                # Stop sending on socket error\n                                self.is_ready = False\n\n            # Wait if bridge is not ready, we're only reading is_ready, no lock needed\n            if not self.is_ready and not self.is_closed:\n                # For older bridges, always try again, there's no keep-alive thread\n                if self.version < 6:\n                    # Give the reconnect some time\n                    time.sleep(RECONNECT_TIME)\n                    self.is_ready = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_raw(self, command):\n        try:\n            self._socket.send(bytearray(command))\n            self._sn = (self._sn + 1) % 256\n            return True\n        except (socket.error, socket.timeout):\n            # We can get a socket.error or timeout exception if the bridge is disconnected,\n            # but we are still sending data. In that case, return False to indicate that data is not sent.\n            return False", "response": "Sends a raw command directly to the physical bridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_connection(self):\n        try:\n            # We are changing self.is_ready: lock it up!\n            self._lock.acquire()\n\n            response = bytearray(22)\n            self._send_raw(BRIDGE_INITIALIZATION_COMMAND)\n            self._socket.recv_into(response)\n            self._wb1 = response[19]\n            self._wb2 = response[20]\n            self.is_ready = True\n        except (socket.error, socket.timeout):\n            # Connection timed out, bridge is not ready for us\n            self.is_ready = False\n        finally:\n            # Prevent deadlocks: always release the lock\n            self._lock.release()\n\n        return self.is_ready", "response": "Initializes the connection to the bridge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _keep_alive(self):\n        send_next_keep_alive_at = 0\n        while not self.is_closed:\n            if not self.is_ready:\n                self._reconnect()\n                continue\n\n            if time.monotonic() > send_next_keep_alive_at:\n                command = KEEP_ALIVE_COMMAND_PREAMBLE + [self.wb1, self.wb2]\n                self._send_raw(command)\n                need_response_by = time.monotonic() + KEEP_ALIVE_TIME\n\n            # Wait for responses\n            timeout = max(0, need_response_by - time.monotonic())\n            ready = select.select([self._socket], [], [], timeout)\n            if ready[0]:\n                try:\n                    response = bytearray(12)\n                    self._socket.recv_into(response)\n\n                    if response[:5] == bytearray(KEEP_ALIVE_RESPONSE_PREAMBLE):\n                        send_next_keep_alive_at = need_response_by\n                except (socket.error, socket.timeout):\n                    with self._lock:\n                        self.is_ready = False\n            elif send_next_keep_alive_at < need_response_by:\n                # Acquire the lock to make sure we don't change self.is_ready\n                # while _consume() is sending commands\n                with self._lock:\n                    self.is_ready = False", "response": "Send keep alive messages continuously to bridge."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the connection to the bridge.", "response": "def close(self):\n        \"\"\"\n        Closes the connection to the bridge.\n        \"\"\"\n        self.is_closed = True\n        self.is_ready = False\n        self._command_queue.put(None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef header(self):\n        total_length = self.total_length()\n        res = [0x06, 0x10, 0, 0, 0, 0]\n        res[2] = (self.service_type_id >> 8) & 0xff\n        res[3] = (self.service_type_id >> 0) & 0xff\n        res[4] = (total_length >> 8) & 0xff\n        res[5] = (total_length >> 0) & 0xff\n        return res", "response": "Return the frame header as an array of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a tunnelling request from a given body of a KNX / IP frame.", "response": "def from_body(cls, body):\n        \"\"\"Create a tunnelling request from a given body of a KNX/IP frame.\"\"\"\n        # TODO: Check length\n        request = cls()\n        request.channel = body[1]\n        request.seq = body[2]\n        request.cemi = body[4:]\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_body(cls, cemi):\n        # TODO: check that length matches\n        message = cls()\n        message.code = cemi[0]\n        offset = cemi[1]\n\n        message.ctl1 = cemi[2 + offset]\n        message.ctl2 = cemi[3 + offset]\n\n        message.src_addr = cemi[4 + offset] * 256 + cemi[5 + offset]\n        message.dst_addr = cemi[6 + offset] * 256 + cemi[7 + offset]\n\n        message.mpdu_len = cemi[8 + offset]\n\n        tpci_apci = cemi[9 + offset] * 256 + cemi[10 + offset]\n        apci = tpci_apci & 0x3ff\n\n        # for APCI codes see KNX Standard 03/03/07 Application layer\n        # table Application Layer control field\n        if apci & 0x080:\n            # Group write\n            message.cmd = CEMIMessage.CMD_GROUP_WRITE\n        elif apci == 0:\n            message.cmd = CEMIMessage.CMD_GROUP_READ\n        elif apci & 0x40:\n            message.cmd = CEMIMessage.CMD_GROUP_RESPONSE\n        else:\n            message.cmd = CEMIMessage.CMD_UNKNOWN\n\n        apdu = cemi[10 + offset:]\n        if len(apdu) != message.mpdu_len:\n            raise KNXException(\n                \"APDU LEN should be {} but is {}\".format(\n                    message.mpdu_len, len(apdu)))\n\n        if len(apdu) == 1:\n            message.data = [apci & 0x2f]\n        else:\n            message.data = cemi[11 + offset:]\n\n        return message", "response": "Create a new CEMIMessage initialized from the given CEMI data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the CEMI frame for a group write operation.", "response": "def init_group_write(self, dst_addr=1, data=None, dptsize=0):\n        \"\"\"Initialize the CEMI frame for a group write operation.\"\"\"\n        self.init_group(dst_addr)\n\n        # unnumbered data packet, group write\n        self.tpci_apci = 0x00 * 256 + 0x80\n\n        self.dptsize = dptsize\n        if data is None:\n            self.data = [0]\n        else:\n            self.data = data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the CEMI frame for a group read operation.", "response": "def init_group_read(self, dst_addr=1):\n        \"\"\"Initialize the CEMI frame for a group read operation.\"\"\"\n        self.init_group(dst_addr)\n        self.tpci_apci = 0x00  # unnumbered data packet, group read\n        self.data = [0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_body(self):\n        body = [self.code, 0x00, self.ctl1, self.ctl2,\n                (self.src_addr >> 8) & 0xff, (self.src_addr >> 0) & 0xff,\n                (self.dst_addr >> 8) & 0xff, (self.dst_addr >> 0) & 0xff]\n        if self.dptsize == 0 and (len(self.data) == 1) and ((self.data[0] & 0xC0) == 0):\n            # less than 6 bit of data, pack into APCI byte\n            body.extend([1, (self.tpci_apci >> 8) & 0xff,\n                         ((self.tpci_apci >> 0) & 0xff) + self.data[0]])\n        else:\n            body.extend([1 + len(self.data), (self.tpci_apci >> 8) &\n                         0xff, (self.tpci_apci >> 0) & 0xff])\n            body.extend(self.data)\n\n        return body", "response": "Convert the CEMI frame object to its byte representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, timeout=2):\n\n        if self.connected:\n            logging.info(\"KNXIPTunnel connect request ignored, \"\n                         \"already connected\")\n            return True\n\n        if self.remote_ip == \"0.0.0.0\":\n            scanner = GatewayScanner()\n            try:\n                ipaddr, port = scanner.start_search()\n                logging.info(\"Found KNX gateway %s/%s\", ipaddr, port)\n                self.remote_ip = ipaddr\n                self.remote_port = port\n            except TypeError:\n                logging.error(\"No KNX/IP gateway given and no gateway \"\n                              \"found by scanner, aborting %s\")\n\n        # Clean up cache\n        self.value_cache.clear()\n\n        # Find my own IP\n        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        sock.connect((self.remote_ip, self.remote_port))\n        local_ip = sock.getsockname()[0]\n\n        if self.data_server:\n            logging.info(\"Data server already running, not starting again\")\n        else:\n            self.data_server = DataServer((local_ip, 0),\n                                          DataRequestHandler,\n                                          self)\n            dummy_ip, self.data_port = self.data_server.server_address\n            data_server_thread = threading.Thread(\n                target=self.data_server.serve_forever)\n            data_server_thread.daemon = True\n            data_server_thread.start()\n            logging.debug(\n                \"Started data server on UDP port %s\", self.data_port)\n\n        self.control_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        self.control_socket.bind((local_ip, 0))\n        self.control_socket.settimeout(timeout)\n\n        # Connect packet\n        frame = KNXIPFrame(KNXIPFrame.CONNECT_REQUEST)\n\n        # Control endpoint\n        body = []\n        body.extend([0x08, 0x01])  # length 8 bytes, UPD\n        dummy_ip, port = self.control_socket.getsockname()\n        body.extend(ip_to_array(local_ip))\n        body.extend(int_to_array(port, 2))\n\n        # Data endpoint\n        body.extend([0x08, 0x01])  # length 8 bytes, UPD\n        body.extend(ip_to_array(local_ip))\n        body.extend(int_to_array(self.data_port, 2))\n\n        #\n        body.extend([0x04, 0x04, 0x02, 0x00])\n        frame.body = body\n\n        try:\n            self.control_socket.sendto(bytes(frame.to_frame()),\n                                       (self.remote_ip, self.remote_port))\n            received = self.control_socket.recv(1024)\n        except socket.error:\n            self.control_socket.close()\n            self.control_socket = None\n            logging.error(\"KNX/IP gateway did not respond to connect request\")\n            return False\n\n        # Check if the response is an TUNNELING ACK\n        r_sid = received[2] * 256 + received[3]\n\n        if r_sid == KNXIPFrame.CONNECT_RESPONSE:\n            self.channel = received[6]\n            status = received[7]\n            if status == 0:\n                hpai = received[8:10]\n                logging.debug(\"Connected KNX IP tunnel \" +\n                              \"(Channel: {}, HPAI: {} {})\".format(\n                                  self.channel, hpai[0], hpai[1]))\n            else:\n                logging.error(\"KNX IP tunnel connect error:\" +\n                              \"(Channel: {}, Status: {})\".format(\n                                  self.channel, status))\n                return False\n\n        else:\n            logging.error(\n                \"Could not initiate tunnel connection, STI = {0:%s}\", r_sid)\n            return False\n\n        self.connected = True\n\n        return True", "response": "Connect to the KNX tunnelling interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disconnect(self):\n        if self.connected and self.channel:\n            logging.debug(\"Disconnecting KNX/IP tunnel...\")\n\n            frame = KNXIPFrame(KNXIPFrame.DISCONNECT_REQUEST)\n            frame.body = self.hpai_body()\n\n            # TODO: Glaube Sequence erhoehen ist nicht notwendig im Control\n            # Tunnel beim Disconnect???\n            if self.seq < 0xff:\n                self.seq += 1\n            else:\n                self.seq = 0\n\n            self.control_socket.sendto(\n                bytes(frame.to_frame()), (self.remote_ip, self.remote_port))\n            # TODO: Impelement the Disconnect_Response Handling from Gateway\n            # Control Channel > Client Control Channel\n\n        else:\n            logging.debug(\"Disconnect - no connection, nothing to do\")\n\n        self.channel = None\n        self.connected = False", "response": "Disconnect an open tunnel connection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the state of the connection using connection state request. This sends a CONNECTION_STATE_REQUEST. This method will only return True, if the connection is established and no error code is returned from the KNX/IP gateway", "response": "def check_connection_state(self):\n        \"\"\"Check the state of the connection using connection state request.\n\n        This sends a CONNECTION_STATE_REQUEST. This method will only return\n        True, if the connection is established and no error code is returned\n        from the KNX/IP gateway\n        \"\"\"\n        if not self.connected:\n            self.connection_state = -1\n            return False\n\n        frame = KNXIPFrame(KNXIPFrame.CONNECTIONSTATE_REQUEST)\n        frame.body = self.hpai_body()\n\n        # Send maximum 3 connection state requests with a 10 second timeout\n        res = False\n        self.connection_state = 0\n\n        maximum_retry = 3\n        for retry_counter in range(0, maximum_retry):\n            logging.debug(\"Heartbeat: Send connection state request\")\n\n            # Suggestion:\n            # Carve the Control Socket out of the KNXIPTunnel\n            # Class and Public only the Send and Receive\n            # function and Implement in there the Heartbeat so we\n            # can block when other Functions want to send\n            self.control_socket.settimeout(10)  # Kind of a quirks\n            self.control_socket.sendto(bytes(frame.to_frame()),\n                                       (self.remote_ip, self.remote_port))\n\n            try:\n                self.control_socket.sendto(bytes(frame.to_frame()),\n                                           (self.remote_ip, self.remote_port))\n                receive = self.control_socket.recv(1024)\n\n            except socket.timeout:\n                logging.info(\"Heartbeat: No response, Retry Counter %d/%d\",\n                             retry_counter, maximum_retry)\n                break\n\n            frame = KNXIPFrame.from_frame(receive)\n            if frame.service_type_id == KNXIPFrame.CONNECTIONSTATE_RESPONSE:\n                if frame.body[1] == KNXIPFrame.E_NO_ERROR:\n                    logging.debug(\"Heartbeat: Successful\")\n                    res = True\n                    break\n                if frame.body[1] == KNXIPFrame.E_CONNECTION_ID:\n                    logging.error(\n                        \"Heartbeat: Response No active \"\n                        \"connection found for Channel:%d \", self.channel\n                    )\n                if frame.body[1] == KNXIPFrame.E_DATA_CONNECTION:\n                    logging.error(\n                        \"Heartbeat: Response Data Connection Error Response \"\n                        \"for  Channel:%d \", self.channel\n                    )\n                if frame.body[1] == KNXIPFrame.E_DATA_CONNECTION:\n                    logging.error(\n                        \"Heartbeat: Response KNX Sub Network Error Response \"\n                        \"for  Channel:%d \", self.channel\n                    )\n            else:\n                logging.error(\"Heartbeat: Invalid Response!\")\n\n        if self.connection_state != 0:\n            logging.info(\"Heartbeat: Connection state was %s\",\n                         self.connection_state)\n            res = False\n\n        if not res:\n            if self.connection_state == 0:\n                self.connection_state = -1\n            self.disconnect()\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a list of bytes containing HPAI information.", "response": "def hpai_body(self):\n        \"\"\" Create a body with HPAI information.\n\n        This is used for disconnect and connection state requests.\n        \"\"\"\n        body = []\n        # ============ IP Body ==========\n        body.extend([self.channel])  # Communication Channel Id\n        body.extend([0x00])  # Reserverd\n        # =========== Client HPAI ===========\n        body.extend([0x08])  # HPAI Length\n        body.extend([0x01])  # Host Protocol\n        # Tunnel Client Socket IP\n        body.extend(ip_to_array(self.control_socket.getsockname()[0]))\n        # Tunnel Client Socket Port\n        body.extend(int_to_array(self.control_socket.getsockname()[1]))\n\n        return body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a tunneling request based on the given CEMI data.", "response": "def send_tunnelling_request(self, cemi, auto_connect=True):\n        \"\"\"Sends a tunneling request based on the given CEMI data.\n\n        This method does not wait for an acknowledge or result frame.\n        \"\"\"\n        if not self.connected:\n            if auto_connect:\n                if not self.connect():\n                    raise KNXException(\"KNX tunnel not reconnected\")\n            else:\n                raise KNXException(\"KNX tunnel not connected\")\n\n        frame = KNXIPFrame(KNXIPFrame.TUNNELING_REQUEST)\n        # Connection header see KNXnet/IP 4.4.6 TUNNELLING_REQUEST\n        body = [0x04, self.channel, self.seq, 0x00]\n        if self.seq < 0xff:\n            self.seq += 1\n        else:\n            self.seq = 0\n        body.extend(cemi.to_body())\n        frame.body = body\n        self.data_server.socket.sendto(\n            frame.to_frame(), (self.remote_ip, self.remote_port))\n\n        # See KNX specification 3.8.4 chapter 2.6 \"Frame confirmation\"\n        # Send KNX packet 2 times if not acknowledged and close\n        # the connection if no ack is received\n        res = self.ack_semaphore.acquire(blocking=True, timeout=1)\n        # Resend package if not acknowledged after 1 seconds\n        if not res:\n            self.data_server.socket.sendto(\n                frame.to_frame(), (self.remote_ip, self.remote_port))\n\n            res = self.ack_semaphore.acquire(blocking=True, timeout=1)\n\n        # disconnect and reconnect of not acknowledged\n        if not res:\n            self.disconnect()\n            self.connect()\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a group read to the KNX bus and return the result.", "response": "def group_read(self, addr, use_cache=True, timeout=1):\n        \"\"\"Send a group read to the KNX bus and return the result.\"\"\"\n        if use_cache:\n            res = self.value_cache.get(addr)\n            if res:\n                logging.debug(\n                    \"Got value of group address %s from cache: %s\", addr, res)\n                return res\n\n        cemi = CEMIMessage()\n        cemi.init_group_read(addr)\n\n        with self._lock:\n            # There might be old messages in the result quue, remove them\n            self.result_queue.queue.clear()\n            self.send_tunnelling_request(cemi)\n            # Wait for the result\n            try:\n                res = self.result_queue.get(block=True, timeout=timeout)\n            except queue.Empty:\n                return None\n\n            self.result_queue.task_done()\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef group_write(self, addr, data, dptsize=0):\n        cemi = CEMIMessage()\n        cemi.init_group_write(addr, data, dptsize)\n\n        with self._lock:\n            self.send_tunnelling_request(cemi)\n            # Workaround for lost KNX packets\n            if self._write_delay: \n                time.sleep(self._write_delay)", "response": "Send a group write to the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntoggles the value of an 1 - bit group address.", "response": "def group_toggle(self, addr, use_cache=True):\n        \"\"\"Toggle the value of an 1-bit group address.\n\n        If the object has a value != 0, it will be set to 0, otherwise to 1\n        \"\"\"\n        data = self.group_read(addr, use_cache)\n        if len(data) != 1:\n            problem = \"Can't toggle a {}-octet group address {}\".format(\n                len(data), addr)\n            logging.error(problem)\n            raise KNXException(problem)\n\n        if data[0] == 0:\n            self.group_write(addr, [1])\n        elif data[0] == 1:\n            self.group_write(addr, [0])\n        else:\n            problem = \"Can't toggle group address {} as value is {}\".format(\n                addr, data[0])\n            logging.error(problem)\n            raise KNXException(problem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_listener(self, address, func):\n        try:\n            listeners = self.address_listeners[address]\n        except KeyError:\n            listeners = []\n            self.address_listeners[address] = listeners\n\n        if not func in listeners:\n            listeners.append(func)\n\n        return True", "response": "Adds a listener to messages received on a specific address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a listener function for a given address. Returns True if the listener was found and removed False otherwise.", "response": "def unregister_listener(self, address, func):\n        \"\"\"Removes a listener function for a given address\n\n        Remove the listener for the given address. Returns true if the listener\n        was found and removed, false otherwise\n        \"\"\"\n        listeners = self.address_listeners[address]\n        if listeners is None:\n            return False\n\n        if func in listeners:\n            listeners.remove(func)\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef received_message(self, address, data):\n        self.value_cache.set(address, data)\n        if self.notify:\n            self.notify(address, data)\n\n        try:\n            listeners = self.address_listeners[address]\n        except KeyError:\n            listeners = []\n\n        for listener in listeners:\n            listener(address, data)", "response": "Process a message received from the KNX bus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(self):\n        data = self.request[0]\n        sock = self.request[1]\n\n        frame = KNXIPFrame.from_frame(data)\n\n        if frame.service_type_id == KNXIPFrame.TUNNELING_REQUEST:\n            req = KNXTunnelingRequest.from_body(frame.body)\n            msg = CEMIMessage.from_body(req.cemi)\n            send_ack = False\n\n            tunnel = self.server.tunnel\n\n            if msg.code == 0x29:\n                # LData.req\n                send_ack = True\n            elif msg.code == 0x2e:\n                # LData.con\n                send_ack = True\n            else:\n                problem = \"Unimplemented cEMI message code {}\".format(msg.code)\n                logging.error(problem)\n                raise KNXException(problem)\n\n            # Cache data\n            if (msg.cmd == CEMIMessage.CMD_GROUP_WRITE) or (\n                    msg.cmd == CEMIMessage.CMD_GROUP_RESPONSE):\n                    # saw a value for a group address on the bus\n                tunnel.received_message(msg.dst_addr, msg.data)\n\n            # Put RESPONSES into the result queue\n            if msg.cmd == CEMIMessage.CMD_GROUP_RESPONSE:\n                tunnel.result_queue.put(msg.data)\n\n            if send_ack:\n                bodyack = [0x04, req.channel, req.seq, E_NO_ERROR]\n                ack = KNXIPFrame(KNXIPFrame.TUNNELLING_ACK)\n                ack.body = bodyack\n                sock.sendto(ack.to_frame(), self.client_address)\n\n        elif frame.service_type_id == KNXIPFrame.TUNNELLING_ACK:\n            logging.debug(\"Received tunneling ACK\")\n            self.server.tunnel.ack_semaphore.release()\n        elif frame.service_type_id == KNXIPFrame.DISCONNECT_RESPONSE:\n            logging.debug(\"Disconnected\")\n            self.channel = None\n            tunnel = self.server.tunnel\n            tunnel.data_server.shutdown()\n            tunnel.data_server = None\n        elif frame.service_type_id == KNXIPFrame.CONNECTIONSTATE_RESPONSE:\n            logging.debug(\"Connection state response\")\n            tunnel.connection_state = frame.body[2]\n        else:\n            logging.info(\n                \"Message type %s not yet implemented\", frame.service_type_id)", "response": "Process an incoming package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a float to a 2 byte KNX float value", "response": "def float_to_knx2(floatval):\n    \"\"\"Convert a float to a 2 byte KNX float value\"\"\"\n\n    if floatval < -671088.64 or floatval > 670760.96:\n        raise KNXException(\"float {} out of valid range\".format(floatval))\n\n    floatval = floatval * 100\n\n    i = 0\n    for i in range(0, 15):\n        exp = pow(2, i)\n        if ((floatval / exp) >= -2048) and ((floatval / exp) < 2047):\n            break\n\n    if floatval < 0:\n        sign = 1\n        mantisse = int(2048 + (floatval / exp))\n    else:\n        sign = 0\n        mantisse = int(floatval / exp)\n\n    return [(sign << 7) + (i << 3) + (mantisse >> 8),\n            mantisse & 0xff]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a KNX 2 byte float object to a float", "response": "def knx2_to_float(knxdata):\n    \"\"\"Convert a KNX 2 byte float object to a float\"\"\"\n    if len(knxdata) != 2:\n        raise KNXException(\"Can only convert a 2 Byte object to float\")\n\n    data = knxdata[0] * 256 + knxdata[1]\n    sign = data >> 15\n    exponent = (data >> 11) & 0x0f\n    mantisse = float(data & 0x7ff)\n    if sign == 1:\n        mantisse = -2048 + mantisse\n\n    return mantisse * pow(2, exponent) / 100"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a time and day - of - week to a KNX time object", "response": "def time_to_knx(timeval, dow=0):\n    \"\"\"Converts a time and day-of-week to a KNX time object\"\"\"\n\n    knxdata = [0, 0, 0]\n    knxdata[0] = ((dow & 0x07) << 5) + timeval.hour\n    knxdata[1] = timeval.minute\n    knxdata[2] = timeval.second\n    return knxdata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a KNX time to a tuple of a time object and the day of week", "response": "def knx_to_time(knxdata):\n    \"\"\"Converts a KNX time to a tuple of a time object and the day of week\"\"\"\n\n    if len(knxdata) != 3:\n        raise KNXException(\"Can only convert a 3 Byte object to time\")\n\n    dow = knxdata[0] >> 5\n    res = time(knxdata[0] & 0x1f, knxdata[1], knxdata[2])\n\n    return [res, dow]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef date_to_knx(dateval):\n\n    if (dateval.year < 1990) or (dateval.year > 2089):\n        raise KNXException(\"Year has to be between 1990 and 2089\")\n\n    if dateval.year < 2000:\n        year = dateval.year - 1900\n    else:\n        year = dateval.year - 2000\n\n    return([dateval.day, dateval.month, year])", "response": "Convert a date to a 3 byte KNX data array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef knx_to_date(knxdata):\n\n    if len(knxdata) != 3:\n        raise KNXException(\"Can only convert a 3 Byte object to date\")\n\n    year = knxdata[2]\n    if year >= 90:\n        year += 1900\n    else:\n        year += 2000\n\n    return date(year, knxdata[1], knxdata[0])", "response": "Convert a 3 byte KNX data object to a date"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a Python timestamp to an 8 byte KNX time and date object", "response": "def datetime_to_knx(datetimeval, clock_synced_external=1):\n    \"\"\"Convert a Python timestamp to an 8 byte KNX time and date object\"\"\"\n\n    res = [0, 0, 0, 0, 0, 0, 0, 0]\n    year = datetimeval.year\n    if (year < 1900) or (year > 2155):\n        raise KNXException(\"Only years between 1900 and 2155 supported\")\n    res[0] = year - 1900\n    res[1] = datetimeval.month\n    res[2] = datetimeval.day\n    res[3] = (datetimeval.isoweekday() << 5) + datetimeval.hour\n    res[4] = datetimeval.minute\n    res[5] = datetimeval.second\n    if datetimeval.isoweekday() < 6:\n        is_working_day = 1\n    else:\n        is_working_day = 0\n\n    # DST starts last Sunday in March\n    date1 = datetime(year, 4, 1)\n    dston = date1 - timedelta(days=date1.weekday() + 1)\n    # ends last Sunday in October\n    date2 = datetime(year, 11, 1)\n    dstoff = date2 - timedelta(days=date2.weekday() + 1)\n    if dston <= datetimeval.replace(tzinfo=None) < dstoff:\n        dst = 1\n    else:\n        dst = 0\n\n    res[6] = (is_working_day << 6) + (1 << 5) + dst\n    if clock_synced_external:\n        res[7] = 128\n    else:\n        res[7] = 0\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a 8 byte KNX time and date object to a datetime object", "response": "def knx_to_datetime(knxdata):\n    \"\"\"Convert a an 8 byte KNX time and date object to its components\"\"\"\n\n    if len(knxdata) != 8:\n        raise KNXException(\"Can only convert an 8 Byte object to datetime\")\n\n    year = knxdata[0] + 1900\n    month = knxdata[1]\n    day = knxdata[2]\n    hour = knxdata[3] & 0x1f\n    minute = knxdata[4]\n    second = knxdata[5]\n\n    return datetime(year, month, day, hour, minute, second)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the color of the current object.", "response": "def color(self, color):\n        \"\"\" Set group color.\n\n        Color is set on a best-effort basis.\n\n        :param color: RGB color tuple.\n        \"\"\"\n        self._color = color\n        self.saturation = saturation_of_color(color)\n        if self.saturation != 0:\n            self.hue = hue_of_color(color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the group saturation.", "response": "def saturation(self, saturation):\n        \"\"\" Set the group saturation.\n\n        :param saturation: Saturation in decimal percent (0.0-1.0).\n        \"\"\"\n        if saturation < 0 or saturation > 1:\n            raise ValueError(\"Saturation must be a percentage \"\n                             \"represented as decimal 0-1.0\")\n        self._saturation = saturation\n        self._update_color()\n        if saturation == 0:\n            self.white()\n        else:\n            cmd = self.command_set.saturation(saturation)\n            self.send(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the temperature. :param temperature: Value to set (0.0-1.0).", "response": "def temperature(self, temperature):\n        \"\"\" Set the temperature.\n\n        :param temperature: Value to set (0.0-1.0).\n        \"\"\"\n        if temperature < 0 or temperature > 1:\n            raise ValueError(\"Temperature must be a percentage \"\n                             \"represented as decimal 0-1.0\")\n        self._temperature = temperature\n        cmd = self.command_set.temperature(temperature)\n        self.send(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transition(self, duration,\n                   color=None, brightness=None, temperature=None):\n        \"\"\" Transition wrapper.\n\n        Short-circuit transition as necessary.\n\n        :param duration: Time to transition.\n        :param color: Transition to this color.\n        :param brightness: Transition to this brightness.\n        :param temperature: Transition to this temperature.\n        \"\"\"\n        if color and temperature is not None:\n            raise ValueError(\"Cannot transition to color and temperature \"\n                             \"simultaneously.\")\n\n        # Transition to white immediately.\n        if color == RGB_WHITE:\n            self.white()\n        # Transition away from white immediately.\n        elif self.color == RGB_WHITE and color is not None:\n            self.color = color\n        # Transition immediately if duration is zero.\n        if duration == 0:\n            if brightness is not None:\n                self.brightness = brightness\n            if color:\n                self.color = color\n            if temperature is not None:\n                self.temperature = temperature\n            return\n        # Perform transition\n        if color and color != self.color:\n            self._transition(duration, brightness,\n                             hue=hue_of_color(color),\n                             saturation=saturation_of_color(color))\n        elif temperature != self.temperature:\n            self._transition(duration, brightness, temperature=temperature)\n        elif brightness != self.brightness:\n            self._transition(duration, brightness)", "response": "Transition to color and brightness."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransition to a new state.", "response": "def _transition(self, duration, brightness,\n                    hue=None, saturation=None, temperature=None):\n        \"\"\" Transition.\n\n        :param duration: Time to transition.\n        :param brightness: Transition to this brightness.\n        :param hue: Transition to this hue.\n        :param saturation: Transition to this saturation.\n        :param temperature: Transition to this temperature.\n        \"\"\"\n        # Calculate brightness steps.\n        b_steps = 0\n        if brightness is not None:\n            b_steps = steps(self.brightness,\n                            brightness, self.command_set.brightness_steps)\n            b_start = self.brightness\n        # Calculate hue steps.\n        h_steps = 0\n        if hue is not None:\n            h_steps = steps(self.hue,\n                            hue, self.command_set.hue_steps)\n            h_start = self.hue\n        # Calculate saturation steps.\n        s_steps = 0\n        if saturation is not None:\n            s_steps = steps(self.saturation,\n                            saturation, self.command_set.saturation_steps)\n            s_start = self.saturation\n        # Calculate temperature steps.\n        t_steps = 0\n        if temperature is not None:\n            t_steps = steps(self.temperature,\n                            temperature, self.command_set.temperature_steps)\n            t_start = self.temperature\n        # Compute ideal step amount (at least one).\n        total_steps = max(b_steps, h_steps, s_steps, t_steps, 1)\n        total_commands = b_steps + h_steps + s_steps + t_steps\n        # Calculate wait.\n        wait = self._wait(duration, total_steps, total_commands)\n        # Scale down steps if no wait time.\n        if wait == 0:\n            scaled_steps = self._scale_steps(duration, total_commands, b_steps,\n                                             h_steps, s_steps, t_steps)\n            b_steps, h_steps, s_steps, t_steps = scaled_steps\n            total_steps = max(b_steps, h_steps, s_steps, t_steps, 1)\n        # Perform transition.\n        for i in range(total_steps):\n            # Brightness.\n            if b_steps > 0 and i % math.ceil(total_steps/b_steps) == 0:\n                self.brightness = util.transition(i, total_steps,\n                                                  b_start, brightness)\n            # Hue.\n            if h_steps > 0 and i % math.ceil(total_steps/h_steps) == 0:\n                self.hue = util.transition(i, total_steps,\n                                           h_start, hue)\n            # Saturation.\n            if s_steps > 0 and i % math.ceil(total_steps/s_steps) == 0:\n                self.saturation = util.transition(i, total_steps,\n                                                  s_start, saturation)\n            # Temperature.\n            if t_steps > 0 and i % math.ceil(total_steps/t_steps) == 0:\n                self.temperature = util.transition(i, total_steps,\n                                                   t_start, temperature)\n\n            # Wait.\n            time.sleep(wait)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize_outputdir(outputdir=None):\n    normalized = ''\n    cwd = os.getcwd()\n    if not outputdir:\n        outputdir_drivers = os.path.join(cwd, 'drivers')\n        if os.path.isdir(outputdir_drivers):\n            normalized = outputdir_drivers\n        else:\n            normalized = cwd\n    else:\n        normalized = os.path.join(cwd, os.path.normpath(outputdir))\n    return normalized", "response": "Normalizes the output directory to be a valid path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_platform():\n    platform_data = {\n        'os_name': None,\n        'os_bits': None\n    }\n    os_name = platform.system()\n    normalize_os = {\n        'Windows': 'windows',\n        'Linux': 'linux',\n        'Darwin': 'mac'\n    }\n    if os_name in normalize_os.keys():\n        platform_data['os_name'] = normalize_os[os_name]\n    else:\n        raise Exception('Could not normalize os name {}'.format(os_name))\n    # try to get the os bits\n    maxsize = sys.maxsize\n    if maxsize == EXPECTED_MAXSIZE_32:\n        platform_data['os_bits'] = '32'\n    elif maxsize == EXPECTED_MAXSIZE_64:\n        platform_data['os_bits'] = '64'\n    else:\n        platform_data['os_bits'] = '64'\n        logger.warning('could not determine os bits, setting default to 64')\n    return platform_data", "response": "Get the current platform data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a file from the given url displays a progress bar.", "response": "def download_file_with_progress_bar(url):\n    \"\"\"Downloads a file from the given url, displays \n    a progress bar.\n    Returns a io.BytesIO object\n    \"\"\"\n    request = requests.get(url, stream=True)\n    if request.status_code == 404:\n        msg = ('there was a 404 error trying to reach {} \\nThis probably '\n               'means the requested version does not exist.'.format(url))\n        logger.error(msg)\n        sys.exit()\n    total_size = int(request.headers[\"Content-Length\"])\n    chunk_size = 1024\n    bars = int(total_size / chunk_size)\n    bytes_io = io.BytesIO()\n    pbar = tqdm(request.iter_content(chunk_size=chunk_size), total=bars,\n                unit=\"kb\", leave=False)\n    for chunk in pbar:\n        bytes_io.write(chunk)\n    return bytes_io"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract a file from a bytes_io zip. Returns bytes", "response": "def extract_file_from_zip(bytes_io, expected_file):\n    \"\"\"Extracts a file from a bytes_io zip. Returns bytes\"\"\"\n    zipf = zipfile.ZipFile(bytes_io) \n    return zipf.read(expected_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting a file from a bytes_io tar. Returns bytes", "response": "def extract_file_from_tar(bytes_io, expected_file):\n    \"\"\"extract a file from a bytes_io tar. Returns bytes\"\"\"\n    with open('temp', 'wb+') as f:\n        bytes_io.seek(0)\n        shutil.copyfileobj(bytes_io, f, length=131072)\n    tar = tarfile.open('temp', mode='r:gz')\n    os.remove('temp')\n    return tar.extractfile(expected_file).read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef color(self, color):\n        if color == RGB_WHITE:\n            self.white()\n            return\n        self._color = color\n        self.hue = hue_of_color(color)", "response": "Set the color of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(driver_name, outputdir, version=None):\n    platform = helpers.get_platform()\n    driver_name = helpers.normalize_driver_name(driver_name)\n    driver_class = helpers.get_driver_class(driver_name)\n    driver = driver_class(outputdir, platform['os_name'], platform['os_bits'])\n    if version:\n        driver.download_driver_executable(version=version)\n    elif driver.is_remote_higher_than_local():\n        latest_remote_version = driver.get_latest_remote_version()\n        driver.download_driver_executable(version=latest_remote_version)\n    else:\n        logger.info('{} is up to date'.format(driver_name))", "response": "Update the local driver executable to the latest version or a specific version."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all executables from the specified outputdir.", "response": "def clean(outputdir, drivers=None):\n    \"\"\"Remove driver executables from the specified outputdir.\n\n    drivers can be a list of drivers to filter which executables\n    to remove. Specify a version using an equal sign i.e.: 'chrome=2.2'\n    \"\"\"\n    if drivers:\n        # Generate a list of tuples: [(driver_name, requested_version)]\n        # If driver string does not contain a version, the second element\n        # of the tuple is None.\n        # Example:\n        # [('driver_a', '2.2'), ('driver_b', None)]\n        drivers_split = [helpers.split_driver_name_and_version(x) for x in\n                         drivers]\n        file_data = [(helpers.normalize_driver_name(x[0]), x[1]) for x in\n                     drivers_split]\n    else:\n        file_data = [(x, None) for x in config.ALL_DRIVERS]\n\n    files = [file for file in os.listdir(outputdir)\n             if os.path.isfile(os.path.join(outputdir, file))]\n    for file in files:\n        for data in file_data:\n            prefix, version = data\n            starts_with = file.startswith(prefix)\n            version_match = 'N/A'\n            if version is not None:\n                file_version = helpers.extract_version_from_filename(file)\n                if file_version == version:\n                    version_match = True\n                else:\n                    version_match = False\n            if starts_with and version_match in [True, 'N/A']:\n                filepath = os.path.join(outputdir, file)\n                try:\n                    os.remove(filepath)\n                except OSError:\n                    pass\n                finally:\n                    logger.info('removed {}'.format(file))\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads items in a release cart to a pre - release environment", "response": "def push(self, cart, env=None, callback=None):\n        \"\"\"\n        `cart` - Release cart to push items from\n        `callback` - Optional callback to call if juicer.utils.upload_rpm succeeds\n\n        Pushes the items in a release cart to the pre-release environment.\n        \"\"\"\n        juicer.utils.Log.log_debug(\"Initializing push of cart '%s'\" % cart.cart_name)\n\n        if not env:\n            env = self._defaults['start_in']\n\n        cart.current_env = env\n        self.sign_cart_for_env_maybe(cart, env)\n        self.upload(env, cart, callback)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publish(self, cart, env=None):\n        juicer.utils.Log.log_debug(\"Initializing publish of cart '%s'\" % cart.cart_name)\n\n        if not env:\n            env = self._defaults['start_in']\n\n        cart_id = juicer.utils.upload_cart(cart, env)\n        juicer.utils.Log.log_debug('%s uploaded with an id of %s' %\n                                   (cart.cart_name, cart_id))\n        return True", "response": "publish a release cart in json format"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new release cart", "response": "def create(self, cart_name, cart_description):\n        \"\"\"\n        `cart_name` - Name of this release cart\n        `cart_description` - list of ['reponame', item1, ..., itemN] lists\n        \"\"\"\n        cart = juicer.common.Cart.Cart(cart_name)\n\n        # repo_items is a list that starts with the REPO name,\n        # followed by the ITEMS going into the repo.\n        for repo_items in cart_description:\n            (repo, items) = (repo_items[0], repo_items[1:])\n            juicer.utils.Log.log_debug(\"Processing %s input items for repo '%s'.\" % (len(items), repo))\n            cart[repo] = items\n\n        cart.save()\n        return cart"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, cart_name, cart_description, manifests):\n        if cart_description is None:\n            juicer.utils.Log.log_debug(\"No cart_description provided.\")\n            cart_description = []\n\n        if manifests is None:\n            juicer.utils.Log.log_debug(\"No manifests provided.\")\n            manifests = []\n\n        juicer.utils.Log.log_debug(\"Loading cart '%s'.\" % cart_name)\n        cart = juicer.common.Cart.Cart(cart_name, autoload=True)\n\n        for repo_items in cart_description:\n            (repo, items) = (repo_items[0], repo_items[1:])\n            juicer.utils.Log.log_debug(\"Processing %s input items for repo '%s'.\" % (len(items), repo))\n\n            if repo not in cart.keys():\n                cart[repo] = items\n            else:\n                for item in items:\n                    cart[repo].append(juicer.common.CartItem.CartItem(os.path.expanduser(item)))\n\n        for manifest in manifests:\n            cart.add_from_manifest(manifest, self.connectors)\n\n        cart.save()\n        return cart", "response": "update the cart with the given data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new manifest for this release", "response": "def create_manifest(self, cart_name, manifests):\n        \"\"\"\n        `cart_name` - Name of this release cart\n        `manifests` - a list of manifest files\n        \"\"\"\n        cart = juicer.common.Cart.Cart(cart_name)\n\n        for manifest in manifests:\n            cart.add_from_manifest(manifest, self.connectors)\n\n        cart.save()\n        return cart"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, cart_glob=['*.json']):\n        carts = []\n        for glob in cart_glob:\n            # Translate cart names into cart file names\n            if not glob.endswith('.json'):\n                search_glob = glob + \".json\"\n            else:\n                search_glob = glob\n\n            for cart in juicer.utils.find_pattern(Constants.CART_LOCATION, search_glob):\n                cart_name = cart.split('/')[-1].replace('.json', '')\n                carts.append(cart_name)\n\n        return carts", "response": "List all carts in the specified glob"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, pkg_name=None, search_carts=False, query='/content/units/rpm/search/'):\n        # this data block is... yeah. searching in pulp v2 is painful\n        #\n        # https://pulp-dev-guide.readthedocs.org/en/latest/rest-api/content/retrieval.html#search-for-units\n        # https://pulp-dev-guide.readthedocs.org/en/latest/rest-api/conventions/criteria.html#search-criteria\n        #\n        # those are the API docs for searching\n        data = {\n                    'criteria': {\n                        'filters': {'filename': {'$regex': \".*%s.*\" % pkg_name}},\n                        'sort': [['name', 'ascending']],\n                        'fields': ['name', 'description', 'version', 'release', 'arch', 'filename']\n                    },\n                    'include_repos': 'true'\n                }\n        repos = []\n\n        juicer.utils.Log.log_info('Packages:')\n\n        for env in self.args.environment:\n            juicer.utils.Log.log_debug(\"Querying %s server\" % env)\n            _r = self.connectors[env].post(query, data)\n\n            if not _r.status_code == Constants.PULP_POST_OK:\n                juicer.utils.Log.log_debug(\"Expected PULP_POST_OK, got %s\", _r.status_code)\n                _r.raise_for_status()\n\n            juicer.utils.Log.log_info('%s:' % str.upper(env))\n\n            pkg_list = juicer.utils.load_json_str(_r.content)\n\n            for package in pkg_list:\n                # if the package is in a repo, show a link to the package in said repo\n                # otherwise, show nothing\n                if len(package['repository_memberships']) > 0:\n                    target = package['repository_memberships'][0]\n\n                    _r = self.connectors[env].get('/repositories/%s/' % target)\n                    if not _r.status_code == Constants.PULP_GET_OK:\n                        raise JuicerPulpError(\"%s was not found as a repoid. A %s status code was returned\" %\n                                (target, _r.status_code))\n                    repo = juicer.utils.load_json_str(_r.content)['display_name']\n                    repos.append(repo)\n\n                    link = juicer.utils.remote_url(self.connectors[env], env, repo, package['filename'])\n                else:\n                    link = ''\n\n                juicer.utils.Log.log_info('%s\\t%s\\t%s\\t%s' % (package['name'], package['version'], package['release'], link))\n\n        if search_carts:\n            # if the package is in a cart, show the cart name\n            juicer.utils.Log.log_info('\\nCarts:')\n\n            for env in self.args.environment:\n                carts = juicer.utils.search_carts(env, pkg_name, repos)\n                for cart in carts:\n                    juicer.utils.Log.log_info(cart['_id'])", "response": "search for a package stored in a pulp repo"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hello(self):\n        for env in self.args.environment:\n            juicer.utils.Log.log_info(\"Trying to open a connection to %s, %s ...\",\n                                      env, self.connectors[env].base_url)\n            try:\n                _r = self.connectors[env].get()\n                juicer.utils.Log.log_info(\"OK\")\n            except JuicerError:\n                juicer.utils.Log.log_info(\"FAILED\")\n                continue\n\n            juicer.utils.Log.log_info(\"Attempting to authenticate as %s\",\n                                      self.connectors[env].auth[0])\n\n            _r = self.connectors[env].get('/repositories/')\n\n            if _r.status_code == Constants.PULP_GET_OK:\n                juicer.utils.Log.log_info(\"OK\")\n            else:\n                juicer.utils.Log.log_info(\"FAILED\")\n                juicer.utils.Log.log_info(\"Server said: %s\", _r.content)\n                continue\n        return True", "response": "Test if the server is up and authenticated"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(self, carts=None, new_cart_name=None):\n        if new_cart_name is not None:\n            cart_name = new_cart_name\n        else:\n            cart_name = carts[0]\n\n        result_cart = juicer.common.Cart.Cart(cart_name)\n        items_hash = {}\n        for cart in carts:\n            # 1. Grab items from each cart and shit them into result_cart\n            tmpcart = juicer.common.Cart.Cart(cart, autoload=True)\n            for repo, items in tmpcart.iterrepos():\n                if str(repo) in [str(key) for key in items_hash.keys()]:\n                    items_hash[str(repo)] += [str(item) for item in items]\n                else:\n                    items_hash[str(repo)] = [str(item) for item in items]\n        # 2. Remove duplicates\n        for key in items_hash.keys():\n            items_hash[key] = list(set(items_hash[key]))\n            # 3. Wrap it up\n            result_cart[key] = items_hash[key]\n        result_cart.save()\n        # You can not fail at merging carts?\n        return True", "response": "Merge the contents of N carts into a new cart."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npulls cart from the pre release", "response": "def pull(self, cartname=None, env=None):\n        \"\"\"\n        `cartname` - Name of cart\n\n        Pull remote cart from the pre release (base) environment\n        \"\"\"\n        if not env:\n            env = self._defaults['start_in']\n        juicer.utils.Log.log_debug(\"Initializing pulling cart: %s ...\", cartname)\n\n        cart_file = os.path.join(juicer.common.Cart.CART_LOCATION, cartname)\n        cart_file += '.json'\n\n        cart_check = juicer.utils.download_cart(cartname, env)\n        if cart_check is None:\n            print 'error: cart \\'%s\\' does not exist' % cartname\n            return None\n        else:\n            juicer.utils.write_json_document(cart_file, juicer.utils.download_cart(cartname, env))\n            return cart_check"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef promote(self, cart_name):\n        cart = juicer.common.Cart.Cart(cart_name=cart_name, autoload=True, autosync=True)\n        old_env = cart.current_env\n        cart.current_env = juicer.utils.get_next_environment(cart.current_env)\n\n        # figure out what needs to be done to promote packages. If\n        # packages are going between environments that are on the same\n        # host and we don't need to sign them just associate with both\n        # repos.\n        if juicer.utils.env_same_host(old_env, cart.current_env) and (self.connectors[old_env].requires_signature == self.connectors[cart.current_env].requires_signature):\n            juicer.utils.Log.log_info(\"Envs %s and %s exist on the same host, calling remote associate action\" % (old_env, cart.current_env))\n            juicer.utils.Log.log_info(\"Promoting %s from %s to %s\" %\n                    (cart_name, old_env, cart.current_env))\n            # iterate through packages and associate to new repo\n            for repo, items in cart.iterrepos():\n                query = '/repositories/%s-%s/actions/associate/' % (repo, cart.current_env)\n                for item in items:\n                    source_repo_id = '%s-%s' % (repo, old_env)\n                    data = {\n                        'source_repo_id': str(source_repo_id),\n                        'criteria': {\n                            'type_ids': ['rpm'],\n                            'filters': {\n                                'unit': {\n                                    'filename': str(item.path.split('/')[-1])\n                                    }\n                                }\n                            }\n                        }\n                    _r = self.connectors[cart.current_env].post(query, data)\n                    if _r.status_code != Constants.PULP_POST_ACCEPTED:\n                        raise JuicerPulpError(\"Package association call was not accepted. Terminating!\")\n                    else:\n                        # association was accepted so publish destination repo\n                        con = self.connectors[cart.current_env]\n                        con.post('/repositories/%s-%s/actions/publish/' % (repo, cart.current_env), {'id': 'yum_distributor'})\n                        # also update the item's remote path\n                        filename = item.path.split('/')[-1]\n                        item.update('%s/%s' % (juicer.utils.pulp_repo_path(con, '%s-%s' % (repo, cart.current_env)), filename))\n            # we didn't bomb out yet so let the user know what's up\n            juicer.utils.Log.log_info(\"Package association calls were accepted. Trusting that your packages existed in %s\" % old_env)\n            # we can save and publish here because upload does this too...\n            cart.save()\n            self.publish(cart)\n        else:\n            juicer.utils.Log.log_debug(\"Syncing down rpms...\")\n            cart.sync_remotes()\n            self.sign_cart_for_env_maybe(cart, cart.current_env)\n\n            juicer.utils.Log.log_info(\"Promoting %s from %s to %s\" %\n                    (cart_name, old_env, cart.current_env))\n\n            for repo in cart.repos():\n                juicer.utils.Log.log_debug(\"Promoting %s to %s in %s\" %\n                                           (cart[repo], repo, cart.current_env))\n            # reiterating that upload will save and publish the cart\n            self.upload(cart.current_env, cart)", "response": "promote a cart from its current environment to the next in the chain"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting rpms from a repository in a specified environments", "response": "def delete_rpms(self, repo_name, rpms, env):\n        \"\"\"\n        `repo_name` - Name of the repository rpms live in (includes -env)\n        `rpms` - A list of rpm filenames to delete\n        `env` - Environment we're currently deleting in\n\n        Delete rpms from a repository in specified environments\n        \"\"\"\n        for rpm in rpms:\n            data = {\n                'criteria': {\n                    'type_ids': ['rpm'],\n                    'filters': {\n                        'unit': {\n                            'filename': {\n                                \"$regex\": rpm\n                                }\n                            }\n                        }\n                    }\n                }\n            _r = self.connectors[env].post(\"/repositories/%s/actions/unassociate/\" % (repo_name), data)\n            if _r.status_code != Constants.PULP_POST_ACCEPTED:\n                _r.raise_for_status()\n            else:\n                unassociate_task = juicer.utils.load_json_str(_r.content)['task_id']\n                unassociate_poller = TaskPoller.TaskPoller(unassociate_task, self.connectors, env)\n                unassociate_poller.poll_until_finished()\n                juicer.utils.Log.log_info(\"Remove call for %s from %s was accepted\" %\n                                          (rpm, repo_name))\n                # unassociation was accepted so publish destination repo after deleting orphans\n                _r = self.connectors[env].delete('/content/orphans/rpm/')\n                delete_task = juicer.utils.load_json_str(_r.content)['task_id']\n                delete_poller = TaskPoller.TaskPoller(delete_task, self.connectors, env)\n                delete_poller.poll_until_finished()\n                self.connectors[env].post('/repositories/%s/actions/publish/' % (repo_name), {'id': 'yum_distributor'})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign_cart_for_env_maybe(self, cart, env=None):\n        if self.connectors[env].requires_signature:\n            cart.sync_remotes(force=True)\n            juicer.utils.Log.log_notice(\"%s requires RPM signatures\", env)\n            juicer.utils.Log.log_notice(\"Checking for rpm_sign_plugin definition ...\")\n            module_name = self._defaults['rpm_sign_plugin']\n            if self._defaults['rpm_sign_plugin']:\n                juicer.utils.Log.log_notice(\"Found rpm_sign_plugin definition: %s\",\n                                            self._defaults['rpm_sign_plugin'])\n                juicer.utils.Log.log_notice(\"Attempting to load ...\")\n\n                try:\n                    rpm_sign_plugin = __import__(module_name, fromlist=[module_name])\n                    juicer.utils.Log.log_notice(\"Successfully loaded %s ...\", module_name)\n                    plugin_object = getattr(rpm_sign_plugin, module_name.split('.')[-1])\n                    signer = plugin_object()\n                    cart.sign_items(signer.sign_rpms)\n                except ImportError as e:\n                    juicer.utils.Log.log_notice(\"there was a problem using %s ... error: %s\",\n                                                module_name, e)\n                    raise JuicerRpmSignPluginError(\"could not load rpm_sign_plugin: %s; additional information: %s\" % \\\n                                                       (module_name,\n                                                        e))\n\n                if not juicer.utils.rpms_signed_p([item.path for item in cart.items()]):\n                    raise JuicerNotSignedError('RPMs have not been signed.')\n\n            else:\n                raise JuicerConfigError(\"Did not find an rpm_sign_plugin in config file but the %s environment requires signed RPMs.\" % env)\n            return True\n        else:\n            return None", "response": "Sign the items to upload for an environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish a repository in an environment", "response": "def publish_repo(self, repo, env):\n        \"\"\"\n        `repo` - Repo name.\n        `env` - Environment.\n\n        Publish a repository. This action regenerates metadata.\n        \"\"\"\n        _r = self.connectors[env].post('/repositories/%s-%s/actions/publish/' % (repo, env), {'id': 'yum_distributor'})\n        if _r.status_code != Constants.PULP_POST_ACCEPTED:\n            _r.raise_for_status()\n        else:\n            juicer.utils.Log.log_info(\"`%s` published in `%s`\" % (repo, env))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a cart from the local filesystem", "response": "def delete(self, cartname):\n        \"\"\"\n        `cartname` - name of the cart to delete\n        Delete a cart both from your local filesystem and the mongo database\n        \"\"\"\n        cart = juicer.common.Cart.Cart(cart_name=cartname)\n        cart.implode(self._defaults['start_in'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode(in_bytes):\n    final_zero = True\n    out_bytes = []\n    idx = 0\n    search_start_idx = 0\n    for in_char in in_bytes:\n        if in_char == '\\x00':\n            final_zero = True\n            out_bytes.append(chr(idx - search_start_idx + 1))\n            out_bytes.append(in_bytes[search_start_idx:idx])\n            search_start_idx = idx + 1\n        else:\n            if idx - search_start_idx == 0xFD:\n                final_zero = False\n                out_bytes.append('\\xFF')\n                out_bytes.append(in_bytes[search_start_idx:idx+1])\n                search_start_idx = idx + 1\n        idx += 1\n    if idx != search_start_idx or final_zero:\n        out_bytes.append(chr(idx - search_start_idx + 1))\n        out_bytes.append(in_bytes[search_start_idx:idx])\n    return ''.join(out_bytes)", "response": "Encode a string using Consistent Overhead Byte Stuffing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode(in_bytes):\n    out_bytes = []\n    idx = 0\n\n    if len(in_bytes) > 0:\n        while True:\n            length = ord(in_bytes[idx])\n            if length == 0:\n                raise DecodeError(\"zero byte found in input\")\n            idx += 1\n            end = idx + length - 1\n            copy_bytes = in_bytes[idx:end]\n            if '\\x00' in copy_bytes:\n                raise DecodeError(\"zero byte found in input\")\n            out_bytes.append(copy_bytes)\n            idx = end\n            if idx > len(in_bytes):\n                raise DecodeError(\"not enough input bytes for length code\")\n            if idx < len(in_bytes):\n                if length < 0xFF:\n                    out_bytes.append('\\x00')\n            else:\n                break\n    return ''.join(out_bytes)", "response": "Decodes a byte string using Consistent Overhead Byte Stuffing ( COBS )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef len(iterable):\n    if not isinstance(iterable, str):\n        return iterable.__len__()\n\n    try:\n        return len(unicode(iterable, 'utf'))\n    except:\n        return iterable.__len__()", "response": "Redefining len here so it will be able to work with non - ASCII characters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self):\n\n        self._hline_string = None\n        self._row_size = None\n        self._header = []\n        self._rows = []", "response": "Reset the instance variable to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nspecifies the header of the table", "response": "def header(self, array):\n        \"\"\"Specify the header of the table\n        \"\"\"\n\n        self._check_row_size(array)\n        self._header = map(str, array)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the desired columns width", "response": "def set_cols_width(self, array):\n        \"\"\"Set the desired columns width\n\n        - the elements of the array should be integers, specifying the\n          width of each column. For example:\n\n                [10, 20, 5]\n        \"\"\"\n\n        self._check_row_size(array)\n        try:\n            array = map(int, array)\n            if reduce(min, array) <= 0:\n                raise ValueError\n        except ValueError:\n            sys.stderr.write(\"Wrong argument in column width specification\\n\")\n            raise\n        self._width = array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the specified array fits the previous rows size.", "response": "def _check_row_size(self, array):\n        \"\"\"Check that the specified array fits the previous rows size\n        \"\"\"\n\n        if not self._row_size:\n            self._row_size = len(array)\n        elif self._row_size != len(array):\n            raise ArraySizeError, \"array should contain %d elements\" \\\n                % self._row_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compute_cols_width(self):\n\n        if hasattr(self, \"_width\"):\n            return\n        maxi = []\n        if self._header:\n            maxi = [ self._len_cell(x) for x in self._header ]\n        for row in self._rows:\n            for cell,i in zip(row, range(len(row))):\n                try:\n                    maxi[i] = max(maxi[i], self._len_cell(cell))\n                except (TypeError, IndexError):\n                    maxi.append(self._len_cell(cell))\n        items = len(maxi)\n        length = reduce(lambda x,y: x+y, maxi)\n        if self._max_width and length + items*3 + 1 > self._max_width:\n            maxi = [(self._max_width - items*3 -1) / items \\\n                for n in range(items)]\n        self._width = maxi", "response": "Compute the width of each column in the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_align(self):\n\n        if not hasattr(self, \"_align\"):\n            self._align = [\"l\"]*self._row_size\n        if not hasattr(self, \"_valign\"):\n            self._valign = [\"t\"]*self._row_size", "response": "Check if alignment has been specified set default one if not"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _draw_line(self, line, isheader=False):\n\n        line = self._splitit(line, isheader)\n        space = \" \"\n        out  = \"\"\n        for i in range(len(line[0])):\n            if self._has_border():\n                out += \"%s \" % self._char_vert\n            length = 0\n            for cell, width, align in zip(line, self._width, self._align):\n                length += 1\n                cell_line = cell[i]\n                fill = width - len(cell_line)\n                if isheader:\n                    align = \"c\"\n                if align == \"r\":\n                    out += \"%s \" % (fill * space + cell_line)\n                elif align == \"c\":\n                    out += \"%s \" % (fill/2 * space + cell_line \\\n                            + (fill/2 + fill%2) * space)\n                else:\n                    out += \"%s \" % (cell_line + fill * space)\n                if length < len(line):\n                    out += \"%s \" % [space, self._char_vert][self._has_vlines()]\n            out += \"%s\\n\" % ['', self._char_vert][self._has_border()]\n        return out", "response": "Draw a line of data from a single cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits each element of line to fit the column width", "response": "def _splitit(self, line, isheader):\n        \"\"\"Split each element of line to fit the column width\n\n        Each element is turned into a list, result of the wrapping of the\n        string to the desired width\n        \"\"\"\n\n        line_wrapped = []\n        for cell, width in zip(line, self._width):\n            array = []\n            for c in cell.split('\\n'):\n                array.extend(textwrap.wrap(unicode(c, 'utf'), width))\n            line_wrapped.append(array)\n        max_cell_lines = reduce(max, map(len, line_wrapped))\n        for cell, valign in zip(line_wrapped, self._valign):\n            if isheader:\n                valign = \"t\"\n            if valign == \"m\":\n                missing = max_cell_lines - len(cell)\n                cell[:0] = [\"\"] * (missing / 2)\n                cell.extend([\"\"] * (missing / 2 + missing % 2))\n            elif valign == \"b\":\n                cell[:0] = [\"\"] * (max_cell_lines - len(cell))\n            else:\n                cell.extend([\"\"] * (max_cell_lines - len(cell)))\n        return line_wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransitions between two values.", "response": "def transition(value, maximum, start, end):\n    \"\"\" Transition between two values.\n\n    :param value: Current iteration.\n    :param maximum: Maximum number of iterations.\n    :param start: Start value.\n    :param end: End value.\n    :returns: Transitional value.\n    \"\"\"\n    return round(start + (end - start) * value / maximum, 2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the number of steps between two values.", "response": "def steps(current, target, max_steps):\n    \"\"\" Steps between two values.\n\n    :param current: Current value (0.0-1.0).\n    :param target: Target value (0.0-1.0).\n    :param max_steps: Maximum number of steps.\n    \"\"\"\n    if current < 0 or current > 1.0:\n        raise ValueError(\"current value %s is out of bounds (0.0-1.0)\", current)\n    if target < 0 or target > 1.0:\n        raise ValueError(\"target value %s is out of bounds (0.0-1.0)\", target)\n    return int(abs((current * max_steps) - (target * max_steps)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the full command as bytes.", "response": "def get_bytes(self, bridge):\n        \"\"\"\n        Gets the full command as bytes.\n        :param bridge: The bridge, to which the command should be sent.\n        \"\"\"\n        if self.cmd_2 is not None:\n            cmd = [self.cmd_1, self.cmd_2]\n        else:\n            cmd = [self.cmd_1, self.SUFFIX_BYTE]\n\n        if bridge.version < self.BRIDGE_SHORT_VERSION_MIN:\n            cmd.append(self.BRIDGE_LONG_BYTE)\n\n        return bytearray(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the brightness from decimal percent to byte representation for use in commands.", "response": "def convert_brightness(self, brightness):\n        \"\"\"\n        Convert the brightness from decimal percent (0.0-1.0)\n        to byte representation for use in commands.\n        :param brightness: The brightness from in decimal percent (0.0-1.0).\n        :return: The brightness in byte representation.\n        \"\"\"\n        brightness = math.ceil(brightness * self.brightness_steps)\n        return brightness + self.BRIGHTNESS_OFFSET"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a complete command.", "response": "def _build_command(self, cmd_1, cmd_2=None,\n                       select=False, select_command=None):\n        \"\"\"\n        Constructs the complete command.\n        :param cmd_1: Light command 1.\n        :param cmd_2: Light command 2.\n        :param select: If command requires selection.\n        :param select_command: Selection command bytes.\n        :return: The complete command.\n        \"\"\"\n\n        return CommandLegacy(cmd_1, cmd_2,\n                             self._group_number, select, select_command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a night light mode command for turning the led to night light mode.", "response": "def night_light(self):\n        \"\"\"\n        Build command for turning the led to night light mode.\n        :return: The command.\n        \"\"\"\n        return self._build_command(self.NIGHT_BYTES[self._group_number - 1],\n                                   select=True, select_command=self.off())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef night_light(self):\n        return self._build_command(self._offset(0xC6),\n                                   select=True, select_command=self.off())", "response": "Build command for turning the led to night light mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef white(self):\n        return self._build_command(self._offset(0xC5),\n                                   select=True, select_command=self.on())", "response": "Build command for turning the led into white mode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding command for setting the hue of the led.", "response": "def hue(self, hue):\n        \"\"\"\n        Build command for setting the hue of the led.\n        :param hue: Value to set (0.0-1.0).\n        :return: The command.\n        \"\"\"\n        return self._build_command(0x40, self.convert_hue(hue),\n                                   select=True, select_command=self.on())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef brightness(self, brightness):\n        return self._build_command(0x4E, self.convert_brightness(brightness),\n                                   select=True, select_command=self.on())", "response": "Build command for setting the brightness of the led."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a VOTable table from an url and load its data into the widget", "response": "def add_catalog_from_URL(self, votable_URL, votable_options={}):\n        \"\"\" load a VOTable table from an url and load its data into the widget \n            Args:\n                votable_URL: string url\n                votable_options: dictionary object\"\"\"\n        self.votable_URL= votable_URL\n        self.votable_options= votable_options\n        self.votable_from_URL_flag= not self.votable_from_URL_flag"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a MOC from a URL and display it in Aladin Lite widget Arguments: moc_URL: string url moc_options: dictionary object", "response": "def add_moc_from_URL(self, moc_URL, moc_options = {}):\n        \"\"\" load a MOC from a URL and display it in Aladin Lite widget\n            Arguments:\n            moc_URL: string url\n            moc_options: dictionary object\"\"\"\n        self.moc_URL = moc_URL\n        self.moc_options = moc_options\n        self.moc_from_URL_flag = not self.moc_from_URL_flag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a MOC from a dict object and display it in Aladin Lite widget Arguments: moc_dict: the dict containing the MOC cells. Key are the HEALPix orders, values are the pixel indexes, eg: {\"1\":[1,2,4], \"2\":[12,13,14,21,23,25]} moc_options: dictionary object", "response": "def add_moc_from_dict(self, moc_dict, moc_options = {}):\n        \"\"\" load a MOC from a dict object and display it in Aladin Lite widget\n            Arguments:\n            moc_dict: the dict containing the MOC cells. Key are the HEALPix orders,\n                      values are the pixel indexes, eg: {\"1\":[1,2,4], \"2\":[12,13,14,21,23,25]} \n            moc_options: dictionary object\"\"\"\n        self.moc_dict = moc_dict\n        self.moc_options = moc_options\n        self.moc_from_dict_flag = not self.moc_from_dict_flag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_table(self, table):\n\n        # theses library must be installed, and are used in votable operations\n        # http://www.astropy.org/\n        import astropy\n        \n        table_array = table.__array__()\n        self.table_keys= table.keys()\n        table_columns= []\n        for i in range(0,len(table.columns[0])):\n            row_data = []\n\n            # this step is needed in order to properly retrieve strings data\n            # (otherwise, Aladin Lite shows these values as DataView object)\n            for item in table_array[i]:\n                if isinstance(item, bytes):\n                    row_data.append(item.decode('utf-8'))\n                else:\n                    row_data.append(item)\n            table_columns.append(row_data)\n\n        self.table_columns = table_columns\n        self.table_flag= not self.table_flag", "response": "add a table to the widget"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_listener(self, listener_type, callback):\n        self.listener_type= listener_type\n        if listener_type == 'objectHovered':\n            self.listener_callback_source_hover= callback\n        elif listener_type == 'objectClicked':\n            self.listener_callback_source_click= callback\n        elif listener_type == 'click':\n            self.listener_callback_click= callback\n        elif listener_type == 'select':\n            self.listener_callback_select= callback\n\n        self.listener_flag= not self.listener_flag", "response": "add a listener to the widget\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing to collect json objects that are sent by the js-side of the application by using the send() method", "response": "def handle_aladin_event(self, _, content, buffers):\n        \"\"\" used to collect json objects that are sent by the js-side of the application by using the send() method \"\"\"\n        if content.get('event', '').startswith('callback'):\n            if content.get('type') == 'objectHovered':\n                result= self.listener_callback_source_hover(content.get('data'))\n            elif content.get('type') == 'objectClicked':\n                result= self.listener_callback_source_click(content.get('data'))\n            elif content.get('type') == 'click':\n                result= self.listener_callback_click(content.get('data'))\n            elif content.get('type') == 'select':\n                result= self.listener_callback_select(content.get('data'))\n            result= str(result)\n            for i in  range(len(result),self.last_prompt_length):\n                result= result+' '\n            print(result, end='\\r')\n            self.last_prompt_length= len(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_email(self):\n        try:\n            accounts = APPLICATION.accounts.search({'email': self.cleaned_data['email']})\n            if len(accounts):\n                msg = 'User with that email already exists.'\n                raise forms.ValidationError(msg)\n        except Error as e:\n            raise forms.ValidationError(str(e))\n\n        return self.cleaned_data['email']", "response": "Check if email exists on Stormpath."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_new_password2(self):\n        password1 = self.cleaned_data.get('new_password1')\n        password2 = self.cleaned_data.get('new_password2')\n\n        try:\n            directory = APPLICATION.default_account_store_mapping.account_store\n            directory.password_policy.strength.validate_password(password2)\n        except ValueError as e:\n            raise forms.ValidationError(str(e))\n\n        if password1 and password2:\n            if password1 != password2:\n                raise forms.ValidationError(\"The two passwords didn't match.\")\n\n        return password2", "response": "Check if passwords match and are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_provider_directory(provider, redirect_uri):\n    dir = CLIENT.directories.create({\n        'name': APPLICATION.name + '-' + provider,\n        'provider': {\n            'client_id': settings.STORMPATH_SOCIAL[provider.upper()]['client_id'],\n            'client_secret': settings.STORMPATH_SOCIAL[provider.upper()]['client_secret'],\n            'redirect_uri': redirect_uri,\n            'provider_id': provider,\n        },\n    })\n\n    APPLICATION.account_store_mappings.create({\n        'application': APPLICATION,\n        'account_store': dir,\n        'list_index': 99,\n        'is_default_account_store': False,\n        'is_default_group_store': False,\n    })", "response": "Helper function for creating a provider directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_header(canvas):\n    canvas.setStrokeColorRGB(0.9, 0.5, 0.2)\n    canvas.setFillColorRGB(0.2, 0.2, 0.2)\n    canvas.setFont('Helvetica', 16)\n    canvas.drawString(18 * cm, -1 * cm, 'Invoice')\n    canvas.drawInlineImage(settings.INV_LOGO, 1 * cm, -1 * cm, 250, 16)\n    canvas.setLineWidth(4)\n    canvas.line(0, -1.25 * cm, 21.7 * cm, -1.25 * cm)", "response": "Draws the invoice header"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the business address", "response": "def draw_address(canvas):\n    \"\"\" Draws the business address \"\"\"\n    business_details = (\n        u'COMPANY NAME LTD',\n        u'STREET',\n        u'TOWN',\n        U'COUNTY',\n        U'POSTCODE',\n        U'COUNTRY',\n        u'',\n        u'',\n        u'Phone: +00 (0) 000 000 000',\n        u'Email: example@example.com',\n        u'Website: www.example.com',\n        u'Reg No: 00000000'\n    )\n    canvas.setFont('Helvetica', 9)\n    textobject = canvas.beginText(13 * cm, -2.5 * cm)\n    for line in business_details:\n        textobject.textLine(line)\n    canvas.drawText(textobject)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_footer(canvas):\n    note = (\n        u'Bank Details: Street address, Town, County, POSTCODE',\n        u'Sort Code: 00-00-00 Account No: 00000000 (Quote invoice number).',\n        u'Please pay via bank transfer or cheque. All payments should be made in CURRENCY.',\n        u'Make cheques payable to Company Name Ltd.',\n    )\n    textobject = canvas.beginText(1 * cm, -27 * cm)\n    for line in note:\n        textobject.textLine(line)\n    canvas.drawText(textobject)", "response": "Draws the invoice footer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws the PDF for the invoice.", "response": "def draw_pdf(buffer, invoice):\n    \"\"\" Draws the invoice \"\"\"\n    canvas = Canvas(buffer, pagesize=A4)\n    canvas.translate(0, 29.7 * cm)\n    canvas.setFont('Helvetica', 10)\n\n    canvas.saveState()\n    header_func(canvas)\n    canvas.restoreState()\n\n    canvas.saveState()\n    footer_func(canvas)\n    canvas.restoreState()\n\n    canvas.saveState()\n    address_func(canvas)\n    canvas.restoreState()\n\n    # Client address\n    textobject = canvas.beginText(1.5 * cm, -2.5 * cm)\n    try:\n        if invoice.address.invoice_contact_name:\n            textobject.textLine(invoice.address.invoice_contact_name)\n        textobject.textLine(invoice.address.invoice_address_one)\n        if invoice.address.invoice_address_two:\n            textobject.textLine(invoice.address.invoice_address_two)\n        textobject.textLine(invoice.address.invoice_town)\n        if invoice.address.invoice_county:\n            textobject.textLine(invoice.address.invoice_county)\n        textobject.textLine(invoice.address.invoice_postcode)\n        textobject.textLine(invoice.address.country.invoice_name)\n    except:\n        pass\n    canvas.drawText(textobject)\n\n    # Info\n    textobject = canvas.beginText(1.5 * cm, -6.75 * cm)\n    textobject.textLine(u'Invoice ID: %s' % invoice.invoice_id)\n    textobject.textLine(u'Invoice Date: %s' % invoice.invoice_date.strftime(\n        '%d %b %Y'))\n    canvas.drawText(textobject)\n\n    # Items\n    data = [[u'Quantity', u'Description', u'Amount', u'Total'], ]\n    for item in invoice.items.all():\n        data.append([\n            item.quantity,\n            item.description,\n            format_currency(item.unit_price, invoice.currency),\n            format_currency(item.total(), invoice.currency)\n        ])\n    data.append([u'', u'', u'Total:', format_currency(invoice.total(),\n                 invoice.currency)])\n    table = Table(data, colWidths=[2 * cm, 11 * cm, 3 * cm, 3 * cm])\n    table.setStyle([\n        ('FONT', (0, 0), (-1, -1), 'Helvetica'),\n        ('FONTSIZE', (0, 0), (-1, -1), 10),\n        ('TEXTCOLOR', (0, 0), (-1, -1), (0.2, 0.2, 0.2)),\n        ('GRID', (0, 0), (-1, -2), 1, (0.7, 0.7, 0.7)),\n        ('GRID', (-2, -1), (-1, -1), 1, (0.7, 0.7, 0.7)),\n        ('ALIGN', (-2, 0), (-1, -1), 'RIGHT'),\n        ('BACKGROUND', (0, 0), (-1, 0), (0.8, 0.8, 0.8)),\n    ])\n    tw, th, = table.wrapOn(canvas, 15 * cm, 19 * cm)\n    table.drawOn(canvas, 1 * cm, -8 * cm - th)\n\n    canvas.showPage()\n    canvas.save()\n\n    return canvas"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mkmanpage(name):\n    mod_name, class_name = name.rsplit('.', 1)\n    mod = __import__(mod_name)\n    inst = getattr(mod, class_name)()\n    sections = cmdln.man_sections_from_cmdln(inst)\n    sys.stdout.write(''.join(sections))", "response": "Return man page content for the given cmdln. Cmdln subclass name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef form_valid(self, form):\n        self.check_and_delete_test_cookie()\n        login(self.request, form.get_user())\n        return super(LoginView, self).form_valid(form)", "response": "Check if the user has provided valid credentials and log in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request, *args, **kwargs):\n        self.set_test_cookie()\n        return super(LoginView, self).get(request, *args, **kwargs)", "response": "Same as django. views. generic. edit. ProcessFormView. get but adds test cookie stuff"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_uri(endpoint, api_version, uri_parts, uri_args={}):\n    # to unicode\n    uri_parts = [unicode(x) for x in uri_parts]\n    # and encoded \n    uri_parts = [urllib.quote(x) for x in uri_parts]\n    # Add enpoint and version \n    all_uri_parts = [endpoint, api_version, ] + uri_parts\n    # join parts\n    url_to_call = \"/\".join(all_uri_parts)\n    # add params if any\n    if uri_args:\n        url_to_call = \"{}?{}\".format(url_to_call, urllib.urlencode(uri_args))\n    # return\n    return url_to_call", "response": "Builds the URL for the request based on the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrap_response(resp, api_call):\n    try:\n        js_resp = resp.json()\n        if resp.ok:\n            if \"items\" in js_resp.keys():\n                r = ApiListResponse(js_resp[\"items\"])\n            else:\n                r = ApiDictResponse(js_resp)\n            if \"paging\" in js_resp.keys():\n                cursors = js_resp.get(\"paging\", {}).get(\"cursors\", {})\n                if \"after\" in cursors.keys():\n                    r.next = api_call(after=cursors[\"after\"])\n                if \"before\" in cursors.keys():\n                    r.previous = api_call(after=cursors[\"before\"])\n        else:\n            r = ApiDictResponse(js_resp)\n            if \"error\" in js_resp.keys():\n                r.error = js_resp['error']\n            elif \"message\" in js_resp.keys():\n                r.error = js_resp['message']\n        # common to all\n        r.status_code = resp.status_code \n        r.headers = resp.headers\n        return r\n    except:\n        return resp", "response": "Wrap the requests response in an ApiResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncrushing the enemy s cache.", "response": "def do_crush(self, subcmd, opts, *enemies):\n        \"\"\"${cmd_name}: crush your enemies!\n\n        ${cmd_usage}\n        ${cmd_option_list}\n        C.f. Conan the Barbarian.\n        \"\"\"\n        action = {\n            None: \"Crush\",\n            \"sword\": \"Swipe\",\n            \"spear\": \"Pierce\",\n            \"maul\": \"Crush\",\n        }.get(opts.weapon, None)\n        if not action:\n            print(\"Conan confused.\")\n        else:\n            for enemy in enemies:\n                print(\"%s %s!\" % (action, enemy))\n            print(\"Yargh!\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_add(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Add files and directories under version control to repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_cat(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Output the content of specified files or URLs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck out a working copy from a repository.", "response": "def do_checkout(self, subcmd, opts, *args):\n        \"\"\"Check out a working copy from a repository.\n\n        usage:\n            checkout URL... [PATH]\n        \n        Note: If PATH is omitted, the basename of the URL will be used as\n        the destination. If multiple URLs are given each will be checked\n        out into a sub-directory of PATH, with the name of the sub-directory\n        being the basename of the URL.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_cleanup(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Recursively clean up the working copy removing locks resuming\n            unfinished operations etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_commit(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Send changes from your working copy to the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nduplicates something in working copy or repository", "response": "def do_copy(self, subcmd, opts, *args):\n        \"\"\"Duplicate something in working copy or repository, remembering history.\n\n        usage:\n            copy SRC DST\n        \n        SRC and DST can each be either a working copy (WC) path or URL:\n          WC  -> WC:   copy and schedule for addition (with history)\n          WC  -> URL:  immediately commit a copy of WC to URL\n          URL -> WC:   check out URL into WC, schedule for addition\n          URL -> URL:  complete server-side copy;  used to branch & tag\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove files and directories from version control.", "response": "def do_delete(self, subcmd, opts, *args):\n        \"\"\"Remove files and directories from version control.\n\n        usage:\n            1. delete PATH...\n            2. delete URL...\n        \n        1. Each item specified by a PATH is scheduled for deletion upon\n          the next commit.  Files, and directories that have not been\n          committed, are immediately removed from the working copy.\n          PATHs that are, or contain, unversioned or modified items will\n          not be removed unless the --force option is given.\n        \n        2. Each item specified by a URL is deleted from the repository\n          via an immediate commit.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays the differences between two files in the current working copy and the current working copy.", "response": "def do_diff(self, subcmd, opts, *args):\n        \"\"\"Display the differences between two paths.\n\n        usage:\n            1. diff [-r N[:M]] [TARGET[@REV]...]\n            2. diff [-r N[:M]] --old=OLD-TGT[@OLDREV] [--new=NEW-TGT[@NEWREV]] \\\n                    [PATH...]\n            3. diff OLD-URL[@OLDREV] NEW-URL[@NEWREV]\n        \n        1. Display the changes made to TARGETs as they are seen in REV between\n           two revisions.  TARGETs may be working copy paths or URLs.\n        \n           N defaults to BASE if any TARGET is a working copy path, otherwise it\n           must be specified.  M defaults to the current working version if any\n           TARGET is a working copy path, otherwise it defaults to HEAD.\n        \n        2. Display the differences between OLD-TGT as it was seen in OLDREV and\n           NEW-TGT as it was seen in NEWREV.  PATHs, if given, are relative to\n           OLD-TGT and NEW-TGT and restrict the output to differences for those\n           paths.  OLD-TGT and NEW-TGT may be working copy paths or URL[@REV]. \n           NEW-TGT defaults to OLD-TGT if not specified.  -r N makes OLDREV default\n           to N, -r N:M makes OLDREV default to N and NEWREV default to M.\n        \n        3. Shorthand for 'svn diff --old=OLD-URL[@OLDREV] --new=NEW-URL[@NEWREV]'\n        \n        Use just 'svn diff' to display local modifications in a working copy.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_export(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Create an unversioned copy of a tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_import(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Commit an unversioned file or tree into the repository."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying information about a file or directory.", "response": "def do_info(self, subcmd, opts, *args):\n        \"\"\"Display information about a file or directory.\n\n        usage:\n            info [PATH...]\n        \n        Print information about each PATH (default: '.').\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist the directory entries in the repository.", "response": "def do_list(self, subcmd, opts, *args):\n        \"\"\"List directory entries in the repository.\n\n        usage:\n            list [TARGET...]\n        \n        List each TARGET file and the contents of each TARGET directory as\n        they exist in the repository.  If TARGET is a working copy path, the\n        corresponding repository URL will be used.\n        \n        The default TARGET is '.', meaning the repository URL of the current\n        working directory.\n        \n        With --verbose, the following fields show the status of the item:\n        \n          Revision number of the last commit\n          Author of the last commit\n          Size (in bytes)\n          Date and time of the last commit\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_log(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Prints the log messages for a set of revision and file ( s."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the differences between two sources to a working copy path.", "response": "def do_merge(self, subcmd, opts, *args):\n        \"\"\"Apply the differences between two sources to a working copy path.\n\n        usage:\n            1. merge sourceURL1[@N] sourceURL2[@M] [WCPATH]\n            2. merge sourceWCPATH1@N sourceWCPATH2@M [WCPATH]\n            3. merge -r N:M SOURCE[@REV] [WCPATH]\n        \n        1. In the first form, the source URLs are specified at revisions\n           N and M.  These are the two sources to be compared.  The revisions\n           default to HEAD if omitted.\n        \n        2. In the second form, the URLs corresponding to the source working\n           copy paths define the sources to be compared.  The revisions must\n           be specified.\n        \n        3. In the third form, SOURCE can be a URL, or working copy item\n           in which case the corresponding URL is used.  This URL in\n           revision REV is compared as it existed between revisions N and \n           M.  If REV is not specified, HEAD is assumed.\n        \n        WCPATH is the working copy path that will receive the changes.\n        If WCPATH is omitted, a default value of '.' is assumed, unless\n        the sources have identical basenames that match a file within '.':\n        in which case, the differences will be applied to that file.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new directory under version control.", "response": "def do_mkdir(self, subcmd, opts, *args):\n        \"\"\"Create a new directory under version control.\n\n        usage:\n            1. mkdir PATH...\n            2. mkdir URL...\n        \n        Create version controlled directories.\n        \n        1. Each directory specified by a working copy PATH is created locally\n          and scheduled for addition upon the next commit.\n        \n        2. Each directory specified by a URL is created in the repository via\n          an immediate commit.\n        \n        In both cases, all the intermediate directories must already exist.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove and or rename something in working copy or repository.", "response": "def do_move(self, subcmd, opts, *args):\n        \"\"\"Move and/or rename something in working copy or repository.\n\n        usage:\n            move SRC DST\n        \n        Note:  this subcommand is equivalent to a 'copy' and 'delete'.\n        \n        SRC and DST can both be working copy (WC) paths or URLs:\n          WC  -> WC:   move and schedule for addition (with history)\n          URL -> URL:  complete server-side rename.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves PROPNAME from files dirs or revisions.", "response": "def do_propdel(self, subcmd, opts, *args):\n        \"\"\"Remove PROPNAME from files, dirs, or revisions.\n\n        usage:\n            1. propdel PROPNAME [PATH...]\n            2. propdel PROPNAME --revprop -r REV [URL]\n        \n        1. Removes versioned props in working copy.\n        2. Removes unversioned remote prop on repos revision.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting property PROPNAME with an external editor on targets.", "response": "def do_propedit(self, subcmd, opts, *args):\n        \"\"\"Edit property PROPNAME with an external editor on targets.\n\n        usage:\n            1. propedit PROPNAME PATH...\n            2. propedit PROPNAME --revprop -r REV [URL]\n        \n        1. Edits versioned props in working copy.\n        2. Edits unversioned remote prop on repos revision.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint value of PROPNAME on files dirs or revisions.", "response": "def do_propget(self, subcmd, opts, *args):\n        \"\"\"Print value of PROPNAME on files, dirs, or revisions.\n\n        usage:\n            1. propget PROPNAME [PATH...]\n            2. propget PROPNAME --revprop -r REV [URL]\n        \n        1. Prints versioned prop in working copy.\n        2. Prints unversioned remote prop on repos revision.\n        \n        By default, this subcommand will add an extra newline to the end\n        of the property values so that the output looks pretty.  Also,\n        whenever there are multiple paths involved, each property value\n        is prefixed with the path with which it is associated.  Use\n        the --strict option to disable these beautifications (useful,\n        for example, when redirecting binary property values to a file).\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_proplist(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "List all properties on files dirs or revisions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_propset(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Set the PROPNAME property of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_resolved(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Remove conflict markers on working copy files or directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreverting the current state of a local copy.", "response": "def do_revert(self, subcmd, opts, *args):\n        \"\"\"Restore pristine working copy file (undo most local edits).\n\n        usage:\n            revert PATH...\n        \n        Note:  this subcommand does not require network access, and resolves\n        any conflicted states.  However, it does not restore removed directories.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the status of the specified item.", "response": "def do_status(self, subcmd, opts, *args):\n        \"\"\"Print the status of working copy files and directories.\n\n        usage:\n            status [PATH...]\n        \n        With no args, print only locally modified items (no network access).\n        With -u, add working revision and server out-of-date information.\n        With -v, print full revision information on every item.\n        \n        The first five columns in the output are each one character wide:\n          First column: Says if item was added, deleted, or otherwise changed\n            ' ' no modifications\n            'A' Added\n            'C' Conflicted\n            'D' Deleted\n            'G' Merged\n            'I' Ignored\n            'M' Modified\n            'R' Replaced\n            'X' item is unversioned, but is used by an externals definition\n            '?' item is not under version control\n            '!' item is missing (removed by non-svn command) or incomplete\n            '~' versioned item obstructed by some item of a different kind\n          Second column: Modifications of a file's or directory's properties\n            ' ' no modifications\n            'C' Conflicted\n            'M' Modified\n          Third column: Whether the working copy directory is locked\n            ' ' not locked\n            'L' locked\n          Fourth column: Scheduled commit will contain addition-with-history\n            ' ' no history scheduled with commit\n            '+' history scheduled with commit\n          Fifth column: Whether the item is switched relative to its parent\n            ' ' normal\n            'S' switched\n        \n        The out-of-date information appears in the eighth column (with -u):\n            '*' a newer revision exists on the server\n            ' ' the working copy is up to date\n        \n        Remaining fields are variable width and delimited by spaces:\n          The working revision (with -u or -v)\n          The last committed revision and last committed author (with -v)\n          The working copy path is always the final field, so it can\n            include spaces.\n        \n        Example output:\n          svn status wc\n           M     wc/bar.c\n          A  +   wc/qax.c\n        \n          svn status -u wc\n           M           965    wc/bar.c\n                 *     965    wc/foo.c\n          A  +         965    wc/qax.c\n          Head revision:   981\n        \n          svn status --show-updates --verbose wc\n           M           965       938 kfogel       wc/bar.c\n                 *     965       922 sussman      wc/foo.c\n          A  +         965       687 joe          wc/qax.c\n                       965       687 joe          wc/zig.c\n          Head revision:   981\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswitch the current working copy to a different URL.", "response": "def do_switch(self, subcmd, opts, *args):\n        \"\"\"Update the working copy to a different URL.\n\n        usage:\n            1. switch URL [PATH]\n            2. switch --relocate FROM TO [PATH...]\n        \n        1. Update the working copy to mirror a new URL within the repository.\n           This behaviour is similar to 'svn update', and is the way to\n           move a working copy to a branch or tag within the same repository.\n        \n        2. Rewrite working copy URL metadata to reflect a syntactic change only.\n           This is used when repository's root URL changes (such as a schema\n           or hostname change) but your working copy still reflects the same\n           directory within the same repository.\n\n        ${cmd_option_list}\n        \"\"\"\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_update(self, subcmd, opts, *args):\n        print \"'svn %s' opts: %s\" % (subcmd, opts)\n        print \"'svn %s' args: %s\" % (subcmd, args)", "response": "Handles the svn update subcommand"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cutarelease(project_name, version_files, dry_run=False):\n    dry_run_str = dry_run and \" (dry-run)\" or \"\"\n\n    if not version_files:\n        log.info(\"guessing version file\")\n        candidates = [\n            \"package.json\",\n            \"VERSION.txt\",\n            \"VERSION\",\n            \"%s.py\" % project_name,\n            \"lib/%s.py\" % project_name,\n            \"%s.js\" % project_name,\n            \"lib/%s.js\" % project_name,\n        ]\n        for candidate in candidates:\n            if exists(candidate):\n                version_files = [candidate]\n                break\n        else:\n            raise Error(\"could not find a version file: specify its path or \"\n                \"add one of the following to your project: '%s'\"\n                % \"', '\".join(candidates))\n        log.info(\"using '%s' as version file\", version_files[0])\n\n    parsed_version_files = [_parse_version_file(f) for f in version_files]\n    version_file_type, version_info = parsed_version_files[0]\n    version = _version_from_version_info(version_info)\n\n    # Confirm\n    if not dry_run:\n        answer = query_yes_no(\"* * *\\n\"\n            \"Are you sure you want cut a %s release?\\n\"\n            \"This will involved commits and a push.\" % version,\n            default=\"no\")\n        print \"* * *\"\n        if answer != \"yes\":\n            log.info(\"user abort\")\n            return\n    log.info(\"cutting a %s release%s\", version, dry_run_str)\n\n    # Checks: Ensure there is a section in changes for this version.\n\n\n\n    changes_path = \"CHANGES.md\"\n    changes_txt, changes, nyr = parse_changelog(changes_path)\n    #pprint(changes)\n    top_ver = changes[0][\"version\"]\n    if top_ver != version:\n        raise Error(\"changelog '%s' top section says \"\n            \"version %r, expected version %r: aborting\"\n            % (changes_path, top_ver, version))\n    top_verline = changes[0][\"verline\"]\n    if not top_verline.endswith(nyr):\n        answer = query_yes_no(\"\\n* * *\\n\"\n            \"The changelog '%s' top section doesn't have the expected\\n\"\n            \"'%s' marker. Has this been released already?\"\n            % (changes_path, nyr), default=\"yes\")\n        print \"* * *\"\n        if answer != \"no\":\n            log.info(\"abort\")\n            return\n    top_body = changes[0][\"body\"]\n    if top_body.strip() == \"(nothing yet)\":\n        raise Error(\"top section body is `(nothing yet)': it looks like \"\n            \"nothing has been added to this release\")\n\n    # Commits to prepare release.\n    changes_txt_before = changes_txt\n    changes_txt = changes_txt.replace(\" (not yet released)\", \"\", 1)\n    if not dry_run and changes_txt != changes_txt_before:\n        log.info(\"prepare `%s' for release\", changes_path)\n        f = codecs.open(changes_path, 'w', 'utf-8')\n        f.write(changes_txt)\n        f.close()\n        run('git commit %s -m \"prepare for %s release\"'\n            % (changes_path, version))\n\n    # Tag version and push.\n    curr_tags = set(t for t in _capture_stdout([\"git\", \"tag\", \"-l\"]).split('\\n') if t)\n    if not dry_run and version not in curr_tags:\n        log.info(\"tag the release\")\n        run('git tag -a \"%s\" -m \"version %s\"' % (version, version))\n        run('git push --tags')\n\n    # Optionally release.\n    if exists(\"package.json\"):\n        answer = query_yes_no(\"\\n* * *\\nPublish to npm?\", default=\"yes\")\n        print \"* * *\"\n        if answer == \"yes\":\n            if dry_run:\n                log.info(\"skipping npm publish (dry-run)\")\n            else:\n                run('npm publish')\n    elif exists(\"setup.py\"):\n        answer = query_yes_no(\"\\n* * *\\nPublish to pypi?\", default=\"yes\")\n        print \"* * *\"\n        if answer == \"yes\":\n            if dry_run:\n                log.info(\"skipping pypi publish (dry-run)\")\n            else:\n                run(\"%spython setup.py sdist --formats zip upload\"\n                    % _setup_command_prefix())\n\n    # Commits to prepare for future dev and push.\n    # - update changelog file\n    next_version_info = _get_next_version_info(version_info)\n    next_version = _version_from_version_info(next_version_info)\n    log.info(\"prepare for future dev (version %s)\", next_version)\n    marker = \"## \" + changes[0][\"verline\"]\n    if marker.endswith(nyr):\n        marker = marker[0:-len(nyr)]\n    if marker not in changes_txt:\n        raise Error(\"couldn't find `%s' marker in `%s' \"\n            \"content: can't prep for subsequent dev\" % (marker, changes_path))\n    next_verline = \"%s %s%s\" % (marker.rsplit(None, 1)[0], next_version, nyr)\n    changes_txt = changes_txt.replace(marker + '\\n',\n        \"%s\\n\\n(nothing yet)\\n\\n\\n%s\\n\" % (next_verline, marker))\n    if not dry_run:\n        f = codecs.open(changes_path, 'w', 'utf-8')\n        f.write(changes_txt)\n        f.close()\n\n    # - update version file\n    next_version_tuple = _tuple_from_version(next_version)\n    for i, ver_file in enumerate(version_files):\n        ver_content = codecs.open(ver_file, 'r', 'utf-8').read()\n        ver_file_type, ver_info = parsed_version_files[i]\n        if ver_file_type == \"json\":\n            marker = '\"version\": \"%s\"' % version\n            if marker not in ver_content:\n                raise Error(\"couldn't find `%s' version marker in `%s' \"\n                    \"content: can't prep for subsequent dev\" % (marker, ver_file))\n            ver_content = ver_content.replace(marker,\n                '\"version\": \"%s\"' % next_version)\n        elif ver_file_type == \"javascript\":\n            candidates = [\n                (\"single\", \"var VERSION = '%s';\" % version),\n                (\"double\", 'var VERSION = \"%s\";' % version),\n            ]\n            for quote_type, marker in candidates:\n                if marker in ver_content:\n                    break\n            else:\n                raise Error(\"couldn't find any candidate version marker in \"\n                    \"`%s' content: can't prep for subsequent dev: %r\"\n                    % (ver_file, candidates))\n            if quote_type == \"single\":\n                ver_content = ver_content.replace(marker,\n                    \"var VERSION = '%s';\" % next_version)\n            else:\n                ver_content = ver_content.replace(marker,\n                    'var VERSION = \"%s\";' % next_version)\n        elif ver_file_type == \"python\":\n            marker = \"__version_info__ = %r\" % (version_info,)\n            if marker not in ver_content:\n                raise Error(\"couldn't find `%s' version marker in `%s' \"\n                    \"content: can't prep for subsequent dev\" % (marker, ver_file))\n            ver_content = ver_content.replace(marker,\n                \"__version_info__ = %r\" % (next_version_tuple,))\n        elif ver_file_type == \"version\":\n            ver_content = next_version\n        else:\n            raise Error(\"unknown ver_file_type: %r\" % ver_file_type)\n        if not dry_run:\n            log.info(\"update version to '%s' in '%s'\", next_version, ver_file)\n            f = codecs.open(ver_file, 'w', 'utf-8')\n            f.write(ver_content)\n            f.close()\n\n    if not dry_run:\n        run('git commit %s %s -m \"prep for future dev\"' % (\n            changes_path, ' '.join(version_files)))\n        run('git push')", "response": "Cut a release.\n\n    @param project_name {str}\n    @param version_files {list} List of paths to files holding the version\n        info for this project.\n\n        If none are given it attempts to guess the version file:\n        package.json or VERSION.txt or VERSION or $project_name.py\n        or lib/$project_name.py or $project_name.js or lib/$project_name.js.\n\n        The version file can be in one of the following forms:\n\n        - A .py file, in which case the file is expect to have a top-level\n          global called \"__version_info__\" as follows. [1]\n\n            __version_info__ = (0, 7, 6)\n\n          Note that I typically follow that with the following to get a\n          string version attribute on my modules:\n\n            __version__ = '.'.join(map(str, __version_info__))\n\n        - A .js file, in which case the file is expected to have a top-level\n          global called \"VERSION\" as follows:\n\n            ver VERSION = \"1.2.3\";\n\n        - A \"package.json\" file, typical of a node.js npm-using project.\n          The package.json file must have a \"version\" field.\n\n        - TODO: A simple version file whose only content is a \"1.2.3\"-style version\n          string.\n\n    [1]: This is a convention I tend to follow in my projects.\n        Granted it might not be your cup of tea. I should add support for\n        just `__version__ = \"1.2.3\"`. I'm open to other suggestions too."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_version_file(version_file):\n    # Get version file *type*.\n    version_file_type = None\n    match = re.compile(\"^([a-z]+):(.*)$\").search(version_file)\n    if match:\n        version_file = match.group(2)\n        version_file_type = match.group(1)\n        aliases = {\n            \"js\": \"javascript\"\n        }\n        if version_file_type in aliases:\n            version_file_type = aliases[version_file_type]\n\n    f = codecs.open(version_file, 'r', 'utf-8')\n    content = f.read()\n    f.close()\n\n    if not version_file_type:\n        # Guess the type.\n        base = basename(version_file)\n        ext = splitext(base)[1]\n        if ext == \".json\":\n            version_file_type = \"json\"\n        elif ext == \".py\":\n            version_file_type = \"python\"\n        elif ext == \".js\":\n            version_file_type = \"javascript\"\n        elif content.startswith(\"#!\"):\n            shebang = content.splitlines(False)[0]\n            shebang_bits = re.split(r'[/ \\t]', shebang)\n            for name, typ in {\"python\": \"python\", \"node\": \"javascript\"}.items():\n                if name in shebang_bits:\n                    version_file_type = typ\n                    break\n        elif base in (\"VERSION\", \"VERSION.txt\"):\n            version_file_type = \"version\"\n    if not version_file_type:\n        raise RuntimeError(\"can't extract version from '%s': no idea \"\n            \"what type of file it it\" % version_file)\n\n    if version_file_type == \"json\":\n        obj = json.loads(content)\n        version_info = _version_info_from_version(obj[\"version\"])\n    elif version_file_type == \"python\":\n        m = re.search(r'^__version_info__ = (.*?)$', content, re.M)\n        version_info = eval(m.group(1))\n    elif version_file_type == \"javascript\":\n        m = re.search(r'^var VERSION = (\\'|\")(.*?)\\1;$', content, re.M)\n        version_info = _version_info_from_version(m.group(2))\n    elif version_file_type == \"version\":\n        version_info = _version_info_from_version(content.strip())\n    else:\n        raise RuntimeError(\"unexpected version_file_type: %r\"\n            % version_file_type)\n    return version_file_type, version_info", "response": "Parse the version file and return the version info."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the given changelog file and return a tuple of content parsed nyr", "response": "def parse_changelog(changes_path):\n    \"\"\"Parse the given changelog path and return `(content, parsed, nyr)`\n    where `nyr` is the ' (not yet released)' marker and `parsed` looks like:\n\n        [{'body': u'\\n(nothing yet)\\n\\n',\n          'verline': u'restify 1.0.1 (not yet released)',\n          'version': u'1.0.1'},    # version is parsed out for top section only\n         {'body': u'...',\n          'verline': u'1.0.0'},\n         {'body': u'...',\n          'verline': u'1.0.0-rc2'},\n         {'body': u'...',\n          'verline': u'1.0.0-rc1'}]\n\n    A changelog (CHANGES.md) is expected to look like this:\n\n        # $project Changelog\n\n        ## $next_version (not yet released)\n\n        ...\n\n        ## $version1\n\n        ...\n\n        ## $version2\n\n        ... and so on\n\n    The version lines are enforced as follows:\n\n    - The top entry should have a \" (not yet released)\" suffix. \"Should\"\n      because recovery from half-cutarelease failures is supported.\n    - A version string must be extractable from there, but it tries to\n      be loose (though strict \"X.Y.Z\" versioning is preferred). Allowed\n\n            ## 1.0.0\n            ## my project 1.0.1\n            ## foo 1.2.3-rc2\n\n      Basically, (a) the \" (not yet released)\" is stripped, (b) the\n      last token is the version, and (c) that version must start with\n      a digit (sanity check).\n    \"\"\"\n    if not exists(changes_path):\n        raise Error(\"changelog file '%s' not found\" % changes_path)\n    content = codecs.open(changes_path, 'r', 'utf-8').read()\n\n    parser = re.compile(\n        r'^##\\s*(?P<verline>[^\\n]*?)\\s*$(?P<body>.*?)(?=^##|\\Z)',\n        re.M | re.S)\n    sections = parser.findall(content)\n\n    # Sanity checks on changelog format.\n    if not sections:\n        template = \"## 1.0.0 (not yet released)\\n\\n(nothing yet)\\n\"\n        raise Error(\"changelog '%s' must have at least one section, \"\n            \"suggestion:\\n\\n%s\" % (changes_path, _indent(template)))\n    first_section_verline = sections[0][0]\n    nyr = ' (not yet released)'\n    #if not first_section_verline.endswith(nyr):\n    #    eg = \"## %s%s\" % (first_section_verline, nyr)\n    #    raise Error(\"changelog '%s' top section must end with %r, \"\n    #        \"naive e.g.: '%s'\" % (changes_path, nyr, eg))\n\n    items = []\n    for i, section in enumerate(sections):\n        item = {\n            \"verline\": section[0],\n            \"body\": section[1]\n        }\n        if i == 0:\n            # We only bother to pull out 'version' for the top section.\n            verline = section[0]\n            if verline.endswith(nyr):\n                verline = verline[0:-len(nyr)]\n            version = verline.split()[-1]\n            try:\n                int(version[0])\n            except ValueError:\n                msg = ''\n                if version.endswith(')'):\n                    msg = \" (cutarelease is picky about the trailing %r \" \\\n                        \"on the top version line. Perhaps you misspelled \" \\\n                        \"that?)\" % nyr\n                raise Error(\"changelog '%s' top section version '%s' is \"\n                    \"invalid: first char isn't a number%s\"\n                    % (changes_path, version, msg))\n            item[\"version\"] = version\n        items.append(item)\n\n    return content, items, nyr"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the given command. Raises OSError is the command returns a non - zero exit status.", "response": "def run(cmd):\n    \"\"\"Run the given command.\n\n    Raises OSError is the command returns a non-zero exit status.\n    \"\"\"\n    log.debug(\"running '%s'\", cmd)\n    fixed_cmd = cmd\n    if sys.platform == \"win32\" and cmd.count('\"') > 2:\n        fixed_cmd = '\"' + cmd + '\"'\n    retval = os.system(fixed_cmd)\n    if hasattr(os, \"WEXITSTATUS\"):\n        status = os.WEXITSTATUS(retval)\n    else:\n        status = retval\n    if status:\n        raise OSError(status, \"error running '%s'\" % cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_redirect(request, fallback_url, **kwargs):\n    redirect_field_name = kwargs.get(\"redirect_field_name\", \"next\")\n    next = request.POST.get(redirect_field_name,\n                            request.GET.get(redirect_field_name, ''))\n    if not next:\n        # try the session if available\n        if hasattr(request, \"session\"):\n            session_key_value = kwargs.get(\"session_key_value\", \"redirect_to\")\n            next = request.session.get(session_key_value)\n    is_safe = functools.partial(\n        ensure_safe_url,\n        allowed_protocols=kwargs.get(\"allowed_protocols\"),\n        allowed_host=request.get_host()\n    )\n    redirect_to = next if next and is_safe(next) else fallback_url\n    # perform one last check to ensure the URL is safe to redirect to. if it\n    # is not then we should bail here as it is likely developer error and\n    # they should be notified\n    is_safe(redirect_to, raise_on_fail=True)\n    return redirect_to", "response": "Evaluate a redirect url by consulting GET POST and session."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_errors(errors1, errors2):\n    if errors1 is None:\n        return errors2\n    elif errors2 is None:\n        return errors1\n\n    if isinstance(errors1, list):\n        if not errors1:\n            return errors2\n\n        if isinstance(errors2, list):\n            return errors1 + errors2\n        elif isinstance(errors2, dict):\n            return dict(\n                errors2,\n                **{SCHEMA: merge_errors(errors1, errors2.get(SCHEMA))}\n            )\n        else:\n            return errors1 + [errors2]\n    elif isinstance(errors1, dict):\n        if isinstance(errors2, list):\n            return dict(\n                errors1,\n                **{SCHEMA: merge_errors(errors1.get(SCHEMA), errors2)}\n            )\n        elif isinstance(errors2, dict):\n            errors = dict(errors1)\n            for k, v in iteritems(errors2):\n                if k in errors:\n                    errors[k] = merge_errors(errors[k], v)\n                else:\n                    errors[k] = v\n            return errors\n        else:\n            return dict(\n                errors1,\n                **{SCHEMA: merge_errors(errors1.get(SCHEMA), errors2)}\n            )\n    else:\n        if isinstance(errors2, list):\n            return [errors1] + errors2 if errors2 else errors1\n        elif isinstance(errors2, dict):\n            return dict(\n                errors2,\n                **{SCHEMA: merge_errors(errors1, errors2.get(SCHEMA))}\n            )\n        else:\n            return [errors1, errors2]", "response": "Merge two error messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_error(self, path, error):\n        self.errors = merge_errors(self.errors, self._make_error(path, error))", "response": "Add error message for given field path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef friendly_number(num):\n    # Convert to a (shorter) string for human consumption\n    string = \"\"\n    # The length of the string can be determined by STRING_LENGTH or by how many\n    # characters are necessary to present a base 30 representation of SIZE.\n    while STRING_LENGTH and len(string) <= STRING_LENGTH \\\n            or len(VALID_CHARS) ** len(string) <= SIZE:\n        # PREpend string (to remove all obvious signs of order)\n        string = VALID_CHARS[num % len(VALID_CHARS)] + string\n        num = num / len(VALID_CHARS)\n    return string", "response": "Convert a base 10 number to a base X string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlogin to Fedex Delivery Manager.", "response": "def _login(session):\n    \"\"\"Login to Fedex Delivery Manager.\"\"\"\n    session.get(LOGIN_REFERER)\n    resp = session.post(LOGIN_URL, {\n        'user': session.auth.username,\n        'pwd': session.auth.password\n    }, headers={\n        'Referer': LOGIN_REFERER,\n        'X-Requested-With': 'XMLHttpRequest'\n    })\n    if resp.status_code != 200:\n        raise FedexError('could not login')\n    data = resp.json()\n    if not data['successful']:\n        raise FedexError(data['errorList'][0]['error']['message'])\n    _save_cookies(session.cookies, session.auth.cookie_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets packages from tracking.", "response": "def get_packages(session):\n    \"\"\"Get packages.\"\"\"\n    resp = session.post(TRACKING_URL, {\n        'data': json.dumps(SHIPMENT_LIST_REQUEST),\n        'action': SHIPMENT_LIST_ACTION,\n        'format': SHIPMENT_LIST_FORMAT,\n        'locale': session.auth.locale,\n        'version': 1\n    })\n    data = resp.json().get('ShipmentListLightResponse')\n    if not data.get('successful'):\n        err = 'failed to get shipment list: {}'.format(data.get('errorList')[0]\n                                                       .get('message'))\n        raise FedexError(err)\n    packages = []\n    for package in data.get('shipmentLightList'):\n        if 'trkNbr' not in package or not package['trkNbr']:\n            continue\n        if 'isOut' in package and package['isOut'] == '1':\n            continue\n        packages.append({\n            'weight': package['dispPkgLbsWgt'],\n            'dimensions': package['pkgDimIn'],\n            'tracking_number': package['trkNbr'],\n            'from': package['shpBy'],\n            'shipped_from': '{} {} {} {}'.format(package['shprAddr1'], package['shprCity'],\n                                                 package['shprStCD'], package['shprCntryCD']),\n            'primary_status': package['keyStat'],\n            'secondary_status': package['mainStat'],\n            'estimated_delivery_date': (str(parse(package['estDelTs']).date())\n                                        if package['estDelTs'] else ''),\n            'delivery_date': str(parse(package['delTs']).date()) if package['delTs'] else ''\n        })\n    return packages"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_value_hint(key, mapper=None):\n    if mapper is None:\n        mapper = identity\n\n    def hinter(data):\n        return mapper(data.get(key))\n\n    return hinter", "response": "Returns a function that takes a dictionary and returns value of\n    particular key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validated_type(base_type, name=None, validate=None):\n    if validate is None:\n        validate = []\n    if not is_sequence(validate):\n        validate = [validate]\n\n    class ValidatedSubtype(base_type):\n        if name is not None:\n            __name__ = name\n\n        def __init__(self, *args, **kwargs):\n            super(ValidatedSubtype, self).__init__(*args, **kwargs)\n            for validator in reversed(validate):\n                self.validators.insert(0, validator)\n\n    return ValidatedSubtype", "response": "Convenient way to create a new type by adding validation to existing type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake serialized data and returns validation errors or None.", "response": "def validate(self, data, context=None):\n        \"\"\"Takes serialized data and returns validation errors or None.\n\n        :param data: Data to validate.\n        :param context: Context data.\n        :returns: validation errors or None\n        \"\"\"\n        try:\n            self.load(data, context)\n            return None\n        except ValidationError as ve:\n            return ve.messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self, name, data, context=None):\n        return self.field_type.load(data.get(name, MISSING), context=context)", "response": "Deserialize data from primitive types. Raises lollipop. errors. ValidationError if data is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize data to primitive types. Raises lollipop. errors. ValidationError if data is invalid.", "response": "def dump(self, name, obj, context=None):\n        \"\"\"Serialize data to primitive types. Raises\n        :exc:`~lollipop.errors.ValidationError` if data is invalid.\n\n        :param str name: Name of attribute to serialize.\n        :param obj: Application object to extract serialized value from.\n        :returns: Serialized data.\n        :raises: :exc:`~lollipop.errors.ValidationError`\n        \"\"\"\n        value = self.get_value(name, obj, context=context)\n        return self.field_type.dump(value, context=context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads data into an object.", "response": "def load_into(self, obj, data, inplace=True, *args, **kwargs):\n        \"\"\"Load data and update existing object.\n\n        :param obj: Object to update with deserialized data.\n        :param data: Raw data to get value to deserialize from.\n        :param bool inplace: If True update data inplace;\n            otherwise - create new data.\n        :param kwargs: Same keyword arguments as for :meth:`Type.load`.\n        :returns: Updated object.\n        :raises: :exc:`~lollipop.errors.ValidationError`\n        \"\"\"\n        if obj is None:\n            raise ValueError('Load target should not be None')\n\n        if data is MISSING:\n            return\n\n        if data is None:\n            self._fail('required')\n\n        if not is_mapping(data):\n            self._fail('invalid', data=data)\n\n        errors_builder = ValidationErrorBuilder()\n\n        data1 = {}\n        for name, field in iteritems(self.fields):\n            try:\n                if name in data:\n                    # Load new data\n                    value = field.load_into(obj, name, data,\n                                            inplace=not self.immutable and inplace,\n                                            *args, **kwargs)\n                else:\n                    # Retrive data from existing object\n                    value = field.load(name, {\n                        name: field.dump(name, obj, *args, **kwargs)\n                    })\n\n                if value is not MISSING:\n                    data1[name] = value\n            except ValidationError as ve:\n                errors_builder.add_error(name, ve.messages)\n\n        if self.allow_extra_fields is False:\n            field_names = [name for name, _ in iteritems(self.fields)]\n            for name in data:\n                if name not in field_names:\n                    errors_builder.add_error(name, self._error_messages['unknown'])\n        elif isinstance(self.allow_extra_fields, Field):\n            field_names = [name for name, _ in iteritems(self.fields)]\n            for name in data:\n                if name not in field_names:\n                    try:\n                        loaded = self.allow_extra_fields.load_into(\n                            obj, name, data,\n                            inplace=not self.immutable and inplace,\n                            *args, **kwargs\n                        )\n                        if loaded != MISSING:\n                            data1[name] = loaded\n                    except ValidationError as ve:\n                        errors_builder.add_error(name, ve.messages)\n\n        errors_builder.raise_errors()\n\n        data2 = super(Object, self).load(data1, *args, **kwargs)\n\n        if self.immutable or not inplace:\n            result = data2\n            if self.constructor:\n                result = self.constructor(**result)\n        else:\n            for name, value in iteritems(data2):\n                field = self.fields.get(name, self.allow_extra_fields)\n                if not isinstance(field, Field):\n                    continue\n\n                field.set_value(name, obj, value, *args, **kwargs)\n\n            result = obj\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_for(self, obj, data, *args, **kwargs):\n        try:\n            self.load_into(obj, data, inplace=False, *args, **kwargs)\n            return None\n        except ValidationError as ve:\n            return ve.messages", "response": "Takes target object and serialized data and validates that the data is valid. Returns validation errors or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering the response to only include the elements that are countries.", "response": "def filter_country_locations(api_response, is_country=True):\n    \"\"\" \n    Filter the response to only include the elements that are countries. \n    \n    This uses the 'api_response' object as input. Plain `list`s are also \n    valid, but they must contain the location elements, not the `items` wrapper. \n    \"\"\"\n    return [item for item in api_response if item[ISCOUNTRY]==is_country]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_next_number(self):\n\n        # Recupere les facture de l annee\n        relative_invoices = Invoice.objects.filter(invoice_date__year=self.invoice_date.year)\n        # on prend le numero le plus eleve du champs number, sinon on met 0\n        last_number = relative_invoices.aggregate(Max('number'))['number__max'] or 0\n\n        return last_number + 1", "response": "Returns next invoice number"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if given function has more arguments than given. If so wrap it into another function that takes extra argument and drops it.", "response": "def make_context_aware(func, numargs):\n    \"\"\"\n    Check if given function has no more arguments than given. If so, wrap it\n    into another function that takes extra argument and drops it.\n    Used to support user providing callback functions that are not context aware.\n    \"\"\"\n    try:\n        if inspect.ismethod(func):\n            arg_count = len(inspect.getargspec(func).args) - 1\n        elif inspect.isfunction(func):\n            arg_count = len(inspect.getargspec(func).args)\n        elif inspect.isclass(func):\n            arg_count = len(inspect.getargspec(func.__init__).args) - 1\n        else:\n            arg_count = len(inspect.getargspec(func.__call__).args) - 1\n    except TypeError:\n        arg_count = numargs\n\n    if arg_count <= numargs:\n        def normalized(*args):\n            return func(*args[:-1])\n\n        return normalized\n\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if given function has more arguments than given.", "response": "def call_with_context(func, context, *args):\n    \"\"\"\n    Check if given function has more arguments than given. Call it with context\n    as last argument or without it.\n    \"\"\"\n    return make_context_aware(func, len(args))(*args + (context,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts camel - case identifiers to snake - case.", "response": "def to_snake_case(s):\n    \"\"\"Converts camel-case identifiers to snake-case.\"\"\"\n    return re.sub('([^_A-Z])([A-Z])', lambda m: m.group(1) + '_' + m.group(2).lower(), s)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_settings(settings):\n    if not (settings.STORMPATH_ID and settings.STORMPATH_SECRET):\n        raise ImproperlyConfigured('Both STORMPATH_ID and STORMPATH_SECRET must be specified in settings.py.')\n\n    if not settings.STORMPATH_APPLICATION:\n        raise ImproperlyConfigured('STORMPATH_APPLICATION must be specified in settings.py.')", "response": "Ensure all user - supplied settings exist."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_default_is_active():\n    directory = APPLICATION.default_account_store_mapping.account_store\n    verif_email = directory.account_creation_policy.verification_email_status\n    return verif_email == AccountCreationPolicy.EMAIL_STATUS_DISABLED", "response": "Returns True if default user is active by default by default."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsynchronize accounts from stormpath to local database.", "response": "def sync_accounts_from_stormpath(self, sync_groups=True):\n        \"\"\" :arg sync_groups: WARNING!!! Groups will be deleted from stormpath\n                                if not present locally when user logs in!\n\n        Sync accounts from stormpath -> local database.\n        This may take a long time, depending on how many users you have in your\n        Stormpath application. It also makes numerous database queries.\n\n        This method updates local users from stormpath or creates new ones\n        where the user does not exist locally. This is an additive operation,\n        meaning it should delete no data from the local database OR stormpath.\n        \"\"\"\n        if sync_groups:\n            sp_groups = [g.name for g in APPLICATION.groups]\n            db_groups = set(Group.objects.all().values_list('name', flat=True))\n            missing_from_db = set(sp_groups).difference(db_groups)\n            if missing_from_db:\n                groups_to_create = []\n                for g_name in missing_from_db:\n                    groups_to_create.append(Group(name=g_name))\n                Group.objects.bulk_create(groups_to_create)\n\n        for account in APPLICATION.accounts:\n            try:\n                user = StormpathUser.objects.get(email=account.email)\n                created = True\n            except StormpathUser.DoesNotExist:\n                user = StormpathUser()\n                created = True\n            user._mirror_data_from_stormpath_account(account)\n            user.set_unusable_password()\n\n            if created:\n                user._save_db_only()\n\n            if sync_groups:\n                users_sp_groups = [g.name for g in account.groups]\n                user.groups = Group.objects.filter(name__in=users_sp_groups)\n            user._save_db_only()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if Stormpath authentication works and returns an account object if successful.", "response": "def _stormpath_authenticate(self, username, password):\n        \"\"\"Check if Stormpath authentication works\n\n        :param username: Can be actual username or email\n        :param password: Account password\n\n        Returns an account object if successful or None otherwise.\n        \"\"\"\n        APPLICATION = get_application()\n        try:\n            result = APPLICATION.authenticate_account(username, password)\n            return result.account\n        except Error as e:\n            log.debug(e)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _mirror_groups_from_stormpath(self):\n        APPLICATION = get_application()\n        sp_groups = [g.name for g in APPLICATION.groups]\n        missing_from_db, missing_from_sp = self._get_group_difference(sp_groups)\n\n        if missing_from_db:\n            groups_to_create = []\n\n            for g_name in missing_from_db:\n                groups_to_create.append(Group(name=g_name))\n\n            Group.objects.bulk_create(groups_to_create)", "response": "Mirroring groups that are missing but are on Stormpath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of pairs (train_context, test_context), one for each cross-validation fold. The split is stratified. :param context: DBContext to be split :param folds: number of folds :param random_seed: random seed to be used :return: returns a list of (train_context, test_context) pairs :rtype: list :Example: >>> for train_context, test_context in cv_split(context, folds=10, random_seed=0): >>> pass # Your CV loop", "response": "def cv_split(context, folds=10, random_seed=None):\n    '''\n    Returns a list of pairs (train_context, test_context), one for each cross-validation fold.\n\n    The split is stratified.\n\n        :param context: DBContext to be split\n        :param folds: number of folds\n        :param random_seed: random seed to be used\n\n        :return: returns a list of (train_context, test_context) pairs\n        :rtype: list\n\n        :Example:\n\n        >>> for train_context, test_context in cv_split(context, folds=10, random_seed=0):\n        >>>     pass  # Your CV loop\n    '''\n    import orange\n    random_seed = random.randint(0, 10**6) if not random_seed else random_seed\n    input_list = context.orng_tables.get(context.target_table, None)\n    indices = orange.MakeRandomIndicesCV(input_list, randseed=random_seed, folds=folds,\n                                         stratified=orange.MakeRandomIndices.Stratified)\n\n    fold_contexts = []\n    for i in range(folds):\n        train = input_list.select(indices, i, negate=1)\n        test = input_list.select(indices, i)\n        train.name = input_list.name\n        test.name = input_list.name\n        train_context = context.copy()\n        train_context.orng_tables[context.target_table] = train\n        test_context = context.copy()\n        test_context.orng_tables[context.target_table] = test\n        fold_contexts.append((train_context, test_context))\n\n    return fold_contexts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fmtstring(offset, writes, written=0, max_width=2, target=None):\n\n    if max_width not in (1, 2, 4):\n        raise ValueError('max_width should be 1, 2 or 4')\n\n    if target is None:\n        target = pwnypack.target.target\n\n    addrs = []\n    cmds = []\n    piece_writes = []\n\n    for write in writes:\n        if len(write) == 2:\n            addr, value = write\n            width = target.bits // 8\n        else:\n            addr, value, width = write\n            if width not in (1, 2, 4, 8):\n                raise ValueError('Invalid write width')\n\n        piece_width = min(max_width, width)\n        piece_value = getattr(pwnypack.packing, 'P%d' % (8 * width))(value, target=target)\n        piece_unpack = getattr(pwnypack.packing, 'U%d' % (piece_width * 8))\n\n        for i in range(0, width, piece_width):\n            piece_writes.append((piece_width, addr, piece_unpack(piece_value[i:i + piece_width], target=target)))\n            addr += piece_width\n\n    written += len(piece_writes) * int(target.bits) // 8\n\n    piece_writes.sort(key=lambda w_a_v: (w_a_v[2] - written) % (2 ** (max_width * 8)))\n\n    for piece_width, piece_addr, piece_value in piece_writes:\n        addrs.append(pwnypack.packing.P(piece_addr, target=target))\n\n        piece_modulo = 2 ** (piece_width * 8)\n\n        padding = (piece_value - written) % piece_modulo\n        if padding:\n            cmds.append(b'%' + str(padding).encode('ascii') + b'c')\n        written = piece_value\n\n        cmds.append(b'%' + str(offset).encode('ascii') + b'$' + FMTSTRING_OPS[piece_width])\n        offset += 1\n\n    return b''.join(addrs + cmds)", "response": "Builds a format string that writes given data to given locations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding a ROP gadget in a set of executable sections of an ELF executable or a regular expression.", "response": "def find_gadget(elf, gadget, align=1, unique=True):\n    \"\"\"\n    Find a ROP gadget in a the executable sections of an ELF executable or\n    library. The ROP gadget can be either a set of bytes for an exact match\n    or a (bytes) regular expression. Once it finds gadgets, it uses the\n    capstone engine to verify if the gadget consists of valid instructions\n    and doesn't contain any call or jump instructions.\n\n    Args:\n        elf(:class:`~pwnypack.elf.ELF`): The ELF instance to find a gadget in.\n        gadget(bytes or regexp): The gadget to find.\n        align(int): Make sure the gadget starts at a multiple of this number\n        unique(bool): If true, only unique gadgets are returned.\n\n    Returns:\n        dict: A dictionary containing a description of the found\n            gadget. Contains the following fields:\n\n            - section: The section the gadget was found in.\n            - offset: The offset inside the segment the gadget was found at.\n            - addr: The virtual memory address the gadget will be located at.\n            - gadget: The machine code of the found gadget.\n            - asm: A list of disassembled instructions.\n\n    \"\"\"\n\n    if not HAVE_CAPSTONE:\n        raise NotImplementedError('pwnypack requires capstone to find ROP gadgets')\n\n    if not isinstance(elf, pwnypack.elf.ELF):\n        elf = pwnypack.elf.ELF(elf)\n\n    matches = []\n    gadgets = []\n\n    if isinstance(gadget, six.binary_type):\n        gadget = re.compile(re.escape(gadget))\n\n    for section in elf.section_headers:\n        if section.type != section.Type.progbits:\n            continue\n\n        for match in gadget.finditer(section.content):\n            match_index = match.start()\n            if match_index % align != 0:\n                continue\n\n            match_gadget = match.group()\n\n            if match_gadget in gadgets:\n                continue\n\n            match_addr = section.addr + match_index\n\n            md = pwnypack.asm.prepare_capstone(syntax=pwnypack.asm.AsmSyntax.intel, target=elf)\n            md.detail = True\n            match_asm = []\n\n            for insn in md.disasm(match_gadget, match_addr):\n                if insn.id == capstone.CS_OP_INVALID or set(insn.groups) & INVALID_GROUPS:\n                    # Don't try to disassemble this particular gadget again.\n                    gadgets.append(match_gadget)\n                    break\n                match_asm.append((insn.mnemonic + ' ' + insn.op_str).strip())\n            else:\n                matches.append({\n                    'section': section,\n                    'offset': match_index,\n                    'addr': match_addr,\n                    'gadget': match_gadget,\n                    'asm': match_asm,\n                })\n                if unique:\n                    gadgets.append(match_gadget)\n\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind ROP gadgets in an ELF binary.", "response": "def gadget_app(_parser, cmd, args):  # pragma: no cover\n    \"\"\"\n    Find ROP gadgets in an ELF binary.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n    parser.add_argument('file', help='ELF file to find gadgets in')\n    parser.add_argument('gadget', help='the assembler source or reghex expression')\n    parser.add_argument(\n        '--reghex', '-r',\n        dest='mode',\n        action='store_const',\n        const='reghex',\n        help='use reghex expression (hex bytes interspaced with ? for wildcard)',\n    )\n    parser.add_argument(\n        '--asm', '-a',\n        dest='mode',\n        action='store_const',\n        const='asm',\n        help='use assembler expression (separate lines with semi-colon)',\n    )\n    parser.add_argument(\n        '--all', '-l',\n        dest='unique',\n        action='store_const',\n        const=False,\n        default=True,\n        help='also show non-unique gadgets',\n    )\n    args = parser.parse_args(args)\n\n    if args.mode is None:\n        try:\n            pwnypack.util.reghex(args.gadget)\n            args.mode = 'reghex'\n        except SyntaxError:\n            args.mode = 'asm'\n\n    elf = pwnypack.elf.ELF(args.file)\n\n    if args.mode == 'reghex':\n        try:\n            gadget = pwnypack.util.reghex(args.gadget)\n        except SyntaxError:\n            print('Invalid reghex pattern.')\n            sys.exit(1)\n    else:\n        try:\n            gadget = pwnypack.util.reghex('*'.join([\n                pwnypack.codec.enhex(pwnypack.asm.asm(piece.replace(';', '\\n'), target=elf))\n                for piece in ';'.join([line.strip() for line in args.gadget.split(';')]).split('*')\n            ]))\n        except SyntaxError as e:\n            print('Could not assemble:', e.msg)\n            sys.exit(1)\n\n    matches = find_gadget(\n        elf,\n        gadget,\n        unique=args.unique\n    )\n\n    if not matches:\n        print('No gadgets found.', file=sys.stdout)\n        return\n\n    longest_gadget = max(len(m['gadget']) for m in matches)\n    fmt = '  0x%%0%dx: [ %%-%ds ] %%s' % (elf.bits / 4, longest_gadget * 3 - 1)\n\n    current_section = None\n\n    for match in matches:\n        if match['section'].name != current_section:\n            if current_section is not None:\n                print()\n            print('Section: %s' % match['section'].name)\n            current_section = match['section'].name\n\n        hex_gadget = pwnypack.codec.enhex(match['gadget'])\n        print(fmt % (\n            match['addr'],\n            ' '.join(\n                hex_gadget[i:i+2]\n                for i in range(0, len(hex_gadget), 2)\n            ),\n            ' ; '.join(match['asm'])\n        ))\n\n    print()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_class(import_path=None):\n    from django.core.exceptions import ImproperlyConfigured\n    if import_path is None:\n        raise ImproperlyConfigured('No class path specified.')\n    try:\n        dot = import_path.rindex('.')\n    except ValueError:\n        raise ImproperlyConfigured(\"%s isn't a module.\" % import_path)\n    module, classname = import_path[:dot], import_path[dot+1:]\n    try:\n        mod = import_module(module)\n    except ImportError as e:\n        raise ImproperlyConfigured('Error importing module %s: \"%s\"' % (module, e))\n    try:\n        return getattr(mod, classname)\n    except AttributeError:\n        raise ImproperlyConfigured('Module \"%s\" does not define a \"%s\" class.' % (module, classname))", "response": "Returns the class object for the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serve_private_file(request, path):\n    logger.debug('Serving {0} to {1}'.format(path, request.user))\n    if not permissions.has_read_permission(request, path):\n        if settings.DEBUG:\n            raise PermissionDenied\n        else:\n            raise Http404('File not found')\n    return server.serve(request, path=path)", "response": "Serve private files to users with read permission."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist the symbols of an ELF file.", "response": "def symbols_app(parser, _, args):  # pragma: no cover\n    \"\"\"\n    List ELF symbol table.\n    \"\"\"\n\n    parser.add_argument('file', help='ELF file to list the symbols of')\n    parser.add_argument('symbol', nargs='?', help='show only this symbol')\n    parser.add_argument('--exact', '-e', action='store_const', const=True, help='filter by exact symbol name')\n    args = parser.parse_args(args)\n\n    print('%-18s %5s %-7s %-7s %-10s %5s %s' % (\n        'value',\n        'size',\n        'type',\n        'binding',\n        'visibility',\n        'index',\n        'name',\n    ))\n\n    elf = ELF(args.file)\n    for symbol in elf.symbols:\n        if args.symbol:\n            if args.exact:\n                if symbol.name != args.symbol:\n                    continue\n            else:\n                if args.symbol.lower() not in symbol.name.lower():\n                    continue\n\n        if symbol.shndx == symbol.SpecialSection.undef:\n            shndx = 'UND'\n        elif symbol.shndx == symbol.SpecialSection.abs:\n            shndx = 'ABS'\n        elif symbol.shndx == symbol.SpecialSection.common:\n            shndx = 'COM'\n        else:\n            shndx = str(symbol.shndx)\n\n        print('0x%016x %5d %-7s %-7s %-10s %5s %s' % (\n            symbol.value,\n            symbol.size,\n            symbol.type.name,\n            symbol.binding.name,\n            symbol.visibility.name,\n            shndx,\n            symbol.name,\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_symbol_app(parser, _, args):  # pragma: no cover\n\n    parser.add_argument('file', help='ELF file to extract a symbol from')\n    parser.add_argument('symbol', help='the symbol to extract')\n    args = parser.parse_args(args)\n    return ELF(args.file).get_symbol(args.symbol).content", "response": "Extract a symbol from an ELF file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking security features of an ELF file.", "response": "def checksec_app(_parser, _, args):  # pragma: no cover\n    \"\"\"\n    Check security features of an ELF file.\n    \"\"\"\n\n    import sys\n    import argparse\n    import csv\n    import os.path\n\n    def checksec(elf, path, fortifiable_funcs):\n        relro = 0\n        nx = False\n        pie = 0\n        rpath = False\n        runpath = False\n\n        for header in elf.program_headers:\n            if header.type == ELF.ProgramHeader.Type.gnu_relro:\n                relro = 1\n            elif header.type == ELF.ProgramHeader.Type.gnu_stack:\n                if not header.flags & ELF.ProgramHeader.Flags.x:\n                    nx = True\n\n        if elf.type == ELF.Type.shared:\n            pie = 1\n\n        for entry in elf.dynamic_section_entries:\n            if entry.type == ELF.DynamicSectionEntry.Type.bind_now and relro == 1:\n                relro = 2\n            elif entry.type == ELF.DynamicSectionEntry.Type.flags and \\\n                    entry.value & ELF.DynamicSectionEntry.Flags.bind_now:\n                relro = 2\n            elif entry.type == ELF.DynamicSectionEntry.Type.flags_1 and \\\n                    entry.value & ELF.DynamicSectionEntry.Flags_1.now:\n                relro = 2\n            elif entry.type == ELF.DynamicSectionEntry.Type.debug and pie == 1:\n                pie = 2\n            elif entry.type == ELF.DynamicSectionEntry.Type.rpath:\n                rpath = True\n            elif entry.type == ELF.DynamicSectionEntry.Type.runpath:\n                runpath = True\n\n        rtl_symbol_names = set(\n            symbol.name\n            for symbol in elf.symbols\n            if symbol.name and symbol.shndx == ELF.Symbol.SpecialSection.undef\n        )\n\n        fortified = fortifiable_funcs & rtl_symbol_names\n        unfortified = fortifiable_funcs & set('__%s_chk' % symbol_name for symbol_name in rtl_symbol_names)\n\n        canary = '__stack_chk_fail' in rtl_symbol_names\n\n        return {\n            'path': path,\n            'relro': relro,\n            'nx': nx,\n            'pie': pie,\n            'rpath': rpath,\n            'runpath': runpath,\n            'canary': canary,\n            'fortified': len(fortified),\n            'unfortified': len(unfortified),\n            'fortifiable': len(fortified | unfortified),\n        }\n\n    def check_paths(paths, fortifiable_funcs):\n        for path in paths:\n            if os.path.isdir(path):\n                for data in check_paths(\n                        (os.path.join(path, fn) for fn in os.listdir(path) if fn not in ('.', '..')),\n                        fortifiable_funcs,\n                ):\n                    yield data\n            else:\n                try:\n                    elf = ELF(path)\n                except:\n                    continue\n\n                yield checksec(elf, path, fortifiable_funcs)\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n    parser.add_argument('path', nargs='+', help='ELF file to check security features of')\n    parser.add_argument(\n        '-f', '--format',\n        dest='format',\n        choices=['text', 'csv'],\n        default='text',\n        help='set output format'\n    )\n    parser.add_argument(\n        '-l', '--libc',\n        dest='libc',\n        help='path to the applicable libc.so'\n    )\n    args = parser.parse_args(args)\n\n    if args.libc:\n        libc = ELF(args.libc)\n        fortifiable_funcs = set([\n            symbol.name\n            for symbol in libc.symbols\n            if symbol.name.startswith('__') and symbol.name.endswith('_chk')\n        ])\n    else:\n        fortifiable_funcs = set('''__wctomb_chk __wcsncat_chk __mbstowcs_chk __strncpy_chk __syslog_chk __mempcpy_chk\n                                   __fprintf_chk __recvfrom_chk __readlinkat_chk __wcsncpy_chk __fread_chk\n                                   __getlogin_r_chk __vfwprintf_chk __recv_chk __strncat_chk __printf_chk __confstr_chk\n                                   __pread_chk __ppoll_chk __ptsname_r_chk __wcscat_chk __snprintf_chk __vwprintf_chk\n                                   __memset_chk __memmove_chk __gets_chk __fgetws_unlocked_chk __asprintf_chk __poll_chk\n                                   __fdelt_chk __fgets_unlocked_chk __strcat_chk __vsyslog_chk __stpcpy_chk\n                                   __vdprintf_chk __strcpy_chk __obstack_printf_chk __getwd_chk __pread64_chk\n                                   __wcpcpy_chk __fread_unlocked_chk __dprintf_chk __fgets_chk __wcpncpy_chk\n                                   __obstack_vprintf_chk __wprintf_chk __getgroups_chk __wcscpy_chk __vfprintf_chk\n                                   __fgetws_chk __vswprintf_chk __ttyname_r_chk __mbsrtowcs_chk\n                                   __wmempcpy_chk __wcsrtombs_chk __fwprintf_chk __read_chk __getcwd_chk __vsnprintf_chk\n                                   __memcpy_chk __wmemmove_chk __vasprintf_chk __sprintf_chk __vprintf_chk\n                                   __mbsnrtowcs_chk __wcrtomb_chk __realpath_chk __vsprintf_chk __wcsnrtombs_chk\n                                   __gethostname_chk __swprintf_chk __readlink_chk __wmemset_chk __getdomainname_chk\n                                   __wmemcpy_chk __longjmp_chk __stpncpy_chk __wcstombs_chk'''.split())\n\n    if args.format == 'text':\n        print('RELRO    CANARY  NX   PIE  RPATH  RUNPATH  FORTIFIED  PATH')\n        for data in check_paths(args.path, fortifiable_funcs):\n            print('{:7}  {:6}  {:3}  {:3}  {:5}  {:7}  {:>9}  {}'.format(\n                ('No', 'Partial', 'Full')[data['relro']],\n                'Yes' if data['canary'] else 'No',\n                'Yes' if data['nx'] else 'No',\n                ('No', 'DSO', 'Yes')[data['pie']],\n                'Yes' if data['rpath'] else 'No',\n                'Yes' if data['runpath'] else 'No',\n                '{}/{}/{}'.format(data['fortified'], data['unfortified'], data['fortifiable']),\n                data['path']\n            ))\n    else:\n        writer = csv.writer(sys.stdout)\n        writer.writerow(['path', 'relro', 'canary', 'nx', 'pie', 'rpath', 'runpath', 'fortified', 'unfortified',\n                         'fortifiable'])\n        for data in check_paths(args.path, fortifiable_funcs):\n            writer.writerow([\n                data['path'],\n                ('no', 'partial', 'full')[data['relro']],\n                'yes' if data['canary'] else 'no',\n                'yes' if data['nx'] else 'no',\n                ('no', 'dso', 'yes')[data['pie']],\n                'yes' if data['rpath'] else 'no',\n                'yes' if data['runpath'] else 'no',\n                data['fortified'],\n                data['unfortified'],\n                data['fortifiable'],\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_header(self, data):\n\n        (magic, word_size, byte_order, version, osabi, abi_version, _), data = \\\n            unpack('4sBBBBB7s', data[:16]), data[16:]\n\n        assert magic == self._ELF_MAGIC, 'Missing ELF magic'\n        assert word_size in (1, 2), 'Invalid word size'\n        assert byte_order in (1, 2), 'Invalid byte order'\n\n        assert version == 1, 'Invalid version'\n\n        self.osabi = self.OSABI(osabi)\n        self.abi_version = abi_version\n\n        endian = Target.Endian(byte_order - 1)\n        (type_, machine, version), data = unpack('HHI', data[:8], endian=endian), data[8:]\n\n        try:\n            self.type = self.Type(type_)\n        except ValueError:\n            self.type = self.Type.unknown\n\n        try:\n            self.machine = ELF.Machine(machine)\n        except ValueError:\n            self.machine = ELF.Machine.unknown\n\n        assert version == 1, 'Invalid version'\n\n        if self.machine is ELF.Machine.i386:\n            arch = Target.Arch.x86\n            assert word_size == 1, 'Unexpected ELF64 for machine type x86'\n            assert endian is Target.Endian.little, 'Unexpected big-endian for machine type x86'\n        elif self.machine is ELF.Machine.x86_64:\n            arch = Target.Arch.x86\n            assert word_size == 2, 'Unexpected ELF32 for machine type x64_64'\n            assert endian is Target.Endian.little, 'Unexpected big-endian for machine type x86'\n        elif self.machine is ELF.Machine.arm:\n            arch = Target.Arch.arm\n            assert word_size == 1, 'Unexpected ELF64 for machine type arm'\n        elif self.machine is ELF.Machine.aarch64:\n            arch = Target.Arch.arm\n            assert word_size == 2, 'Unexpected ELF32 for machine type aarch64'\n        else:\n            arch = Target.Arch.unknown\n\n        self.arch = arch\n        self.bits = 32 * word_size\n        self.endian = endian\n\n        if self.bits == 32:\n            fmt = 'IIIIHHHHHH'\n        else:\n            fmt = 'QQQIHHHHHH'\n\n        fmt_size = pack_size(fmt)\n        (self.entry, self.phoff, self.shoff, self.flags, self.hsize, self.phentsize,\n            self.phnum, self.shentsize, self.shnum, self.shstrndx) = \\\n            unpack(fmt, data[:fmt_size], target=self)", "response": "Parse the header of the ELF file and populate the properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_file(self, f):\n\n        if type(f) is str:\n            self.f = open(f, 'rb')\n        else:\n            self.f = f\n        self._parse_header(self.f.read(64))", "response": "Parse an ELF file and fill the class properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a specific section header by index or name.", "response": "def get_section_header(self, section):\n        \"\"\"\n        Get a specific section header by index or name.\n\n        Args:\n            section(int or str): The index or name of the section header to return.\n\n        Returns:\n            :class:`~ELF.SectionHeader`: The section header.\n\n        Raises:\n            KeyError: The requested section header does not exist.\n        \"\"\"\n\n        self._ensure_section_headers_loaded()\n        if type(section) is int:\n            return self._section_headers_by_index[section]\n        else:\n            return self._section_headers_by_name[section]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a specific symbol by index or name.", "response": "def get_symbol(self, symbol):\n        \"\"\"\n        Get a specific symbol by index or name.\n\n        Args:\n            symbol(int or str): The index or name of the symbol to return.\n\n        Returns:\n            ELF.Symbol: The symbol.\n\n        Raises:\n            KeyError: The requested symbol does not exist.\n        \"\"\"\n\n        self._ensure_symbols_loaded()\n        if type(symbol) is int:\n            return self._symbols_by_index[symbol]\n        else:\n            return self._symbols_by_name[symbol]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connected(self, tables, cols, find_connections=False):\n        '''\n        Returns a list of tuples of connected table pairs.\n\n            :param tables: a list of table names\n            :param cols: a list of column names\n            :param find_connections: set this to True to detect relationships from column names.\n\n            :return: a tuple (connected, pkeys, fkeys, reverse_fkeys)\n        '''\n        connected = defaultdict(list)\n        fkeys = defaultdict(set)\n        reverse_fkeys = {}\n        pkeys = {}\n        with self.connect() as con:\n            fk_result = self.foreign_keys()\n            if find_connections:\n                for table in tables:\n                    for col in cols[table]:\n                        if col.endswith('_id'):\n                            ref_table = (col[:-4] + 'ies') if col[-4] == 'y' and col[-5] != 'e' else (col[:-3] + 's')\n                            if ref_table in tables:\n                                connected[(table, ref_table)].append((col, 'id'))\n                                connected[(ref_table, table)].append(('id', col))\n                                fkeys[table].add(col)\n                                reverse_fkeys[(table, col)] = ref_table\n                        if col == 'id':\n                            pkeys[table] = col\n            for (table, col, ref_table, ref_col) in fk_result:\n                connected[(table, ref_table)].append((col, ref_col))\n                connected[(ref_table, table)].append((ref_col, col))\n                fkeys[table].add(col)\n                reverse_fkeys[(table, col)] = ref_table\n\n            tbl_col_names = self.table_column_names()\n            for (table, pk) in tbl_col_names:\n                pkeys[table] = pk\n\n        return connected, pkeys, fkeys, reverse_fkeys", "response": "Returns a list of tuples of connected table pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes a value for use with PHP s serialize() function. This function can be used with PHP s deserialize() function.", "response": "def php_serialize(value):\n    \"\"\"\n    Serialize a value for use with PHP's deserialize() function. This function\n    can serialize bytes, strings, integers, floats, booleans, None, lists,\n    dicts and custom objects implementing __php__().\n\n    Args:\n        value: The value to serialize.\n\n    Returns:\n        bytes: The serialized form of `value` ready to be unserialized by PHP.\n\n    Example:\n        >>> from pwny import *\n        >>> php_serialize([b'foo', u'bar', 42, 2.5, True, None, {'a': 'b'}])\n        b'a:7:{i:0;s:3:\"foo\";i:1;s:3:\"bar\";i:2;i:42;i:3;d:2.5;i:4;b:1;i:5;N;i:6;a:1:{s:1:\"a\";s:1:\"b\";}}'\n    \"\"\"\n\n    def serialize_array(items):\n        content = b''.join(\n            php_serialize(i) + php_serialize(v)\n            for i, v in items\n        )\n        return 'a:{0}:'.format(len(value)).encode('utf8') + b'{' + content + b'}'\n\n    def serialize_str(prefix, item):\n        return prefix + b':' + str(item).encode('utf8') + b';'\n\n    if isinstance(value, six.binary_type):\n        return b's:' + str(len(value)).encode('utf8') + b':\"' + value + b'\";'\n    elif isinstance(value, six.text_type):\n        return php_serialize(value.encode('utf8'))\n    elif isinstance(value, bool):\n        return serialize_str(b'b', 1 if value else 0)\n    elif isinstance(value, int):\n        return serialize_str(b'i', value)\n    elif isinstance(value, float):\n        return serialize_str(b'd', value)\n    elif value is None:\n        return b'N;'\n    elif isinstance(value, (list, tuple)):\n        return serialize_array(enumerate(value))\n    elif isinstance(value, dict):\n        return serialize_array(six.iteritems(value))\n    else:\n        return value.__php__()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef marshal_load(fp, origin=None):\n\n    origin = get_py_internals(origin)\n    version = origin['version']\n\n    refs = []\n\n    def ref(o, flags):\n        if flags & FLAG_REF:\n            refs.append(o)\n        return o\n\n    def read_byte():\n        return six.byte2int(fp.read(1))\n\n    def read_short():\n        return u16(fp.read(2), target=MARSHAL_TARGET)\n\n    def read_long():\n        return u32(fp.read(4), target=MARSHAL_TARGET)\n\n    def read_int64():\n        return u64(fp.read(8), target=MARSHAL_TARGET)\n\n    def read_float_binary():\n        return unpack('d', fp.read(8), target=MARSHAL_TARGET)[0]\n\n    def read_bytes():\n        return fp.read(read_long())\n\n    def read_bytes_short():\n        return fp.read(read_byte())\n\n    def read_float_text():\n        return float(read_bytes_short())\n\n    def read_object():\n        c = six.byte2int(fp.read(1))\n        flags = c & FLAG_REF\n        c = ObjectType(c & ~FLAG_REF)\n\n        if c is ObjectType.null:\n            return NULL\n        elif c is ObjectType.none:\n            return None\n        elif c is ObjectType.stopiter:\n            return StopIteration\n        elif c is ObjectType.ellipsis:\n            return Ellipsis\n        elif c is ObjectType.false:\n            return False\n        elif c is ObjectType.true:\n            return True\n        elif c is ObjectType.int:\n            return ref(read_long(), flags)\n        elif c is ObjectType.int64:\n            return ref(read_int64(), flags)\n        elif c is ObjectType.long:\n            n = read_long()\n            r = sum(\n                read_short() << (i * PyLong_MARSHAL_SHIFT)\n                for i in range(abs(n))\n            )\n            return ref(-r if n < 0 else r, flags)\n        elif c is ObjectType.float:\n            return ref(read_float_text(), flags)\n        elif c is ObjectType.binary_float:\n            return ref(read_float_binary(), flags)\n        elif c is ObjectType.complex:\n            real = read_float_text()\n            imag = read_float_text()\n            return ref(complex(real, imag), flags)\n        elif c is ObjectType.binary_complex:\n            real = read_float_binary()\n            imag = read_float_binary()\n            return ref(complex(real, imag), flags)\n        elif c is ObjectType.string:\n            return ref(read_bytes(), flags)\n        elif c is ObjectType.unicode:\n            return ref(read_bytes().decode('utf-8'), flags)\n        elif c is ObjectType.interned:\n            if version < 30:\n                return ref(read_bytes(), FLAG_REF)\n            else:\n                return ref(read_bytes().decode('utf-8'), flags)\n        elif c is ObjectType.ascii:\n            return ref(read_bytes().decode('ascii'), flags)\n        elif c is ObjectType.ascii_interned:\n            return ref(read_bytes().decode('ascii'), flags)\n        elif c is ObjectType.short_ascii:\n            return ref(read_bytes_short().decode('ascii'), flags)\n        elif c is ObjectType.short_ascii_interned:\n            return ref(read_bytes_short().decode('ascii'), flags)\n        elif c in (ObjectType.tuple, ObjectType.small_tuple, ObjectType.frozenset):\n            ref_index = len(refs)\n            ref(NULL, flags)\n            r_type = frozenset if c is ObjectType.frozenset else tuple\n            n = read_byte() if c is ObjectType.small_tuple else read_long()\n            r = r_type(read_object() for _ in range(n))\n            if flags & FLAG_REF:\n                refs[ref_index] = r\n            return r\n        elif c is ObjectType.list:\n            r = ref([], flags)\n            for _ in range(read_long()):\n                r.append(read_object())\n            return r\n        elif c is ObjectType.set:\n            r = ref(set(), flags)\n            for _ in range(read_long()):\n                r.add(read_object())\n            return r\n        elif c is ObjectType.dict:\n            r = ref({}, flags)\n            while True:\n                k = read_object()\n                if k is NULL:\n                    break\n                r[k] = read_object()\n            return r\n        elif c in (ObjectType.stringref, ObjectType.ref):\n            return refs[read_long()]\n        elif c is ObjectType.code:\n            ref_index = len(refs)\n            ref(NULL, flags)\n\n            co_argcount = read_long()\n            if version < 30:\n                co_kwonlyargcount = 0\n            else:\n                co_kwonlyargcount = read_long()\n            co_nlocals = read_long()\n            co_stacksize = read_long()\n            co_flags = read_long()\n            co_code = read_object()\n            co_consts = read_object()\n            co_names = read_object()\n            co_varnames = read_object()\n            co_freevars = read_object()\n            co_cellvars = read_object()\n            co_filename = read_object()\n            co_name = read_object()\n            co_firstlineno = read_long()\n            co_lnotab = read_object()\n\n            r = CodeObject(\n                co_argcount,\n                co_kwonlyargcount,\n                co_nlocals,\n                co_stacksize,\n                co_flags,\n                co_code,\n                co_consts,\n                co_names,\n                co_varnames,\n                co_filename,\n                co_name,\n                co_firstlineno,\n                co_lnotab,\n                co_freevars,\n                co_cellvars,\n                origin,\n            )\n            if flags & FLAG_REF:\n                refs[ref_index] = r\n            return r\n        else:\n            raise ValueError('Unexpected object type %s.' % c)\n\n    return read_object()", "response": "Unserialize data serialized with marshal. dump."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pyc_load(fp):\n\n    magic_1 = U16(fp.read(2), target=MARSHAL_TARGET)\n    magic_2 = U16(fp.read(2), target=MARSHAL_TARGET)\n\n    internals = MAGIC_MAP.get(magic_1)\n    if internals is None:\n        raise ValueError('Invalid or unknown magic (%d).' % magic_1)\n\n    if magic_2 != 2573:\n        raise ValueError('Invalid secondary magic (%d).' % magic_2)\n\n    timestamp = datetime.datetime.fromtimestamp(U32(fp.read(4), target=MARSHAL_TARGET))\n\n    if internals['version'] >= 33:\n        file_size = U32(fp.read(4))\n    else:\n        file_size = None\n\n    code_object = marshal_load(fp, internals)\n\n    return PycFile(magic_1, internals, timestamp, file_size, code_object)", "response": "Loads a. pyc file from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mode(self, predicate, args, recall=1, head=False):\n        '''\n        Emits mode declarations in Aleph-like format.\n\n            :param predicate: predicate name\n            :param args: predicate arguments with input/output specification, e.g.:\n\n            >>> [('+', 'train'), ('-', 'car')]\n\n            :param recall: recall setting (see `Aleph manual <http://www.cs.ox.ac.uk/activities/machinelearning/Aleph/aleph>`_)\n            :param head: set to True for head clauses\n        '''\n        return ':- mode%s(%s, %s(%s)).' % (\n            'h' if head else 'b', str(recall), predicate, ','.join([t + arg for t, arg in args]))", "response": "Emits mode declarations in Aleph - like format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nemit all examples in prolog form for RSD.", "response": "def all_examples(self, pred_name=None):\n        '''\n        Emits all examples in prolog form for RSD.\n\n            :param pred_name: override for the emitted predicate name\n        '''\n        target = self.db.target_table\n        pred_name = pred_name if pred_name else target\n        examples = self.db.rows(target, [self.db.target_att, self.db.pkeys[target]])\n        return '\\n'.join([\"%s(%s, %s).\" % (pred_name, ILPConverter.fmt_col(cls), pk) for cls, pk in examples])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef background_knowledge(self):\n        '''\n        Emits the background knowledge in prolog form for RSD.\n        '''\n        modeslist, getters = [self.mode(self.db.target_table, [('+', self.db.target_table)], head=True)], []\n        for (table, ref_table) in self.db.connected.keys():\n            if ref_table == self.db.target_table:\n                continue  # Skip backward connections\n            modeslist.append(self.mode('%s_has_%s' % (table.lower(), ref_table), [('+', table), ('-', ref_table)]))\n            getters.extend(self.connecting_clause(table, ref_table))\n        for table, atts in self.db.cols.items():\n            for att in atts:\n                if att == self.db.target_att and table == self.db.target_table or \\\n                                att in self.db.fkeys[table] or att == self.db.pkeys[table]:\n                    continue\n                modeslist.append(self.mode('%s_%s' % (table, att), [('+', table), ('-', att)]))\n                modeslist.append(self.mode('instantiate', [('+', att)]))\n                getters.extend(self.attribute_clause(table, att))\n\n        return '\\n'.join(modeslist + getters + self.user_settings() + self.dump_tables())", "response": "Emits the background knowledge in prolog form for RSD."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nemits the background knowledge in prolog form for Aleph.", "response": "def background_knowledge(self):\n        '''\n        Emits the background knowledge in prolog form for Aleph.\n        '''\n        modeslist, getters = [self.mode(self.__target_predicate(), [('+', self.db.target_table)], head=True)], []\n        determinations, types = [], []\n        for (table, ref_table) in self.db.connected.keys():\n            if ref_table == self.db.target_table:\n                continue  # Skip backward connections\n            modeslist.append(\n                self.mode('%s_has_%s' % (table.lower(), ref_table), [('+', table), ('-', ref_table)], recall='*'))\n            determinations.append(\n                ':- determination(%s/1, %s_has_%s/2).' % (self.__target_predicate(), table.lower(), ref_table))\n            types.extend(self.concept_type_def(table))\n            types.extend(self.concept_type_def(ref_table))\n            getters.extend(self.connecting_clause(table, ref_table))\n        for table, atts in self.db.cols.items():\n            for att in atts:\n                if att == self.db.target_att and table == self.db.target_table or \\\n                                att in self.db.fkeys[table] or att == self.db.pkeys[table]:\n                    continue\n                modeslist.append(self.mode('%s_%s' % (table, att), [('+', table), ('#', att.lower())], recall='*'))\n                determinations.append(':- determination(%s/1, %s_%s/2).' % (self.__target_predicate(), table, att))\n                types.extend(self.constant_type_def(table, att))\n                getters.extend(self.attribute_clause(table, att))\n        return '\\n'.join(self.user_settings() + modeslist + determinations + types + getters + self.dump_tables())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the target table as an Orange example table.", "response": "def target_Orange_table(self):\n        '''\n        Returns the target table as an Orange example table.\n\n            :rtype: orange.ExampleTable\n        '''\n        table, cls_att = self.db.target_table, self.db.target_att\n        if not self.db.orng_tables:\n            return self.convert_table(table, cls_att=cls_att)\n        else:\n            return self.db.orng_tables[table]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef other_Orange_tables(self):\n        '''\n            Returns the related tables as Orange example tables.\n\n            :rtype: list\n        '''\n        target_table = self.db.target_table\n        if not self.db.orng_tables:\n            return [self.convert_table(table, None) for table in self.db.tables if table != target_table]\n        else:\n            return [table for name, table in list(self.db.orng_tables.items()) if name != target_table]", "response": "Returns the related tables as Orange example tables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the specified table into an orange example table.", "response": "def convert_table(self, table_name, cls_att=None):\n        '''\n        Returns the specified table as an orange example table.\n\n            :param table_name: table name to convert\n            :cls_att: class attribute name\n            :rtype: orange.ExampleTable\n        '''\n        import Orange\n\n        cols = self.db.cols[table_name]\n        attributes, metas, class_var = [], [], None\n        for col in cols:\n            att_type = self.orng_type(table_name, col)\n            if att_type == 'd':\n                att_vals = self.db.col_vals[table_name][col]\n                att_var = Orange.data.DiscreteVariable(str(col), values=[str(val) for val in att_vals])\n            elif att_type == 'c':\n                att_var = Orange.data.ContinuousVariable(str(col))\n            else:\n                att_var = Orange.data.StringVariable(str(col))\n            if col == cls_att:\n                if att_type == 'string':\n                    raise Exception('Unsuitable data type for a target variable: %s' % att_type)\n                class_var = att_var\n                continue\n            elif att_type == 'string' or table_name in self.db.pkeys and col in self.db.pkeys[\n                table_name] or table_name in self.db.fkeys and col in self.db.fkeys[table_name]:\n                metas.append(att_var)\n            else:\n                attributes.append(att_var)\n        domain = Orange.data.Domain(attributes, class_vars=class_var, metas=metas)\n        # for meta in metas:\n        #    domain.addmeta(Orange.newmetaid(), meta)\n        dataset = Orange.data.Table(domain)\n        dataset.name = table_name\n        for row in self.db.rows(table_name, cols):\n            example = Orange.data.Instance(domain)\n            for col, val in zip(cols, row):\n                example[str(col)] = str(val) if val != None else '?'\n            dataset.append(example)\n        return dataset"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef orng_type(self, table_name, col):\n        '''\n        Returns an Orange datatype for a given mysql column.\n\n            :param table_name: target table name\n            :param col: column to determine the Orange datatype\n        '''\n        mysql_type = self.types[table_name][col]\n        n_vals = len(self.db.col_vals[table_name][col])\n        if mysql_type in OrangeConverter.continuous_types or (\n                        n_vals >= 50 and mysql_type in OrangeConverter.integer_types):\n            return 'c'\n        elif mysql_type in OrangeConverter.ordinal_types + OrangeConverter.integer_types:\n            return 'd'\n        else:\n            return 'string'", "response": "Returns an Orange datatype for a given mysql column."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _facts(self, pk, pk_att, target, visited=set(), parent_table='', parent_pk=''):\n        '''\n        Returns the facts for the given entity with pk in `target`.\n        '''\n        facts = []\n        cols = self.db.cols[target]\n        if target != self.db.target_table:\n\n            # Skip the class attribute\n            if self.db.target_att in cols:\n                cols.remove(self.db.target_att)\n\n            # All rows matching `pk`\n            for row in self.db.select_where(target, cols, pk_att, pk):\n                row_pk = self._row_pk(target, cols, row)\n                row_pk_name = '%s%s' % (target, str(row_pk))\n                parent_pk_name = '%s%s' % (parent_table, str(parent_pk))\n\n                # Each attr-value becomes one fact\n                for idx, col in enumerate(row):\n                    attr_name = cols[idx]\n\n                    # We give pks/fks a symbolic name based on the table and id\n                    if attr_name in self.db.fkeys[target]:\n                        origin_table = self.db.reverse_fkeys[(target, attr_name)]\n                        if origin_table != self.db.target_table:\n                            col = '%s%s' % (origin_table, str(col))\n                        else:\n                            continue\n                    elif attr_name == self.db.pkeys[target]:\n                        if parent_table and parent_table != self.db.target_table:\n                            predicate = '%s_has_%s' % (parent_table, target)\n                            predicate_template = '%s(+%s, -%s)' % (predicate,\n                                                                   parent_table,\n                                                                   target)\n                            facts.append('%s(%s, %s)' % (predicate,\n                                                         parent_pk_name,\n                                                         row_pk_name))\n                        else:\n                            predicate = 'has_%s' % (target)\n                            predicate_template = '%s(-%s)' % (predicate,\n                                                              target)\n                            facts.append('%s(%s)' % (predicate, row_pk_name))\n\n                        output_type = '-%s' % target\n                        if predicate_template not in self._predicates and \\\n                                        output_type not in self._output_types:\n                            self._output_types.add('-%s' % target)\n                            self._predicates.add(predicate_template)\n                            self._template.append(predicate_template)\n\n                    # Constants\n                    else:\n                        predicate = 'has_%s' % attr_name\n\n                        col = self._discretize_check(target, attr_name, col)\n                        facts.append('%s(%s, %s)' % (predicate,\n                                                     row_pk_name,\n                                                     str(col)))\n                        predicate_template = '%s(+%s, #%s)' % (predicate,\n                                                               target,\n                                                               attr_name)\n\n                        if predicate_template not in self._predicates:\n                            self._predicates.add(predicate_template)\n                            self._template.append(predicate_template)\n\n        # Recursively follow links to other tables\n        for table in self.db.tables:\n            if (target, table) not in self.db.connected:\n                continue\n\n            for this_att, that_att in self.db.connected[(target, table)]:\n                if (target, table, this_att, that_att) not in visited:\n                    visited.add((target, table, this_att, that_att))\n\n                    # Link case 1: this_att = pk_att is a fk in another table\n                    if this_att == pk_att:\n                        facts.extend(self._facts(pk,\n                                                 that_att,\n                                                 table,\n                                                 visited=visited,\n                                                 parent_table=target,\n                                                 parent_pk=pk))\n\n                    # Link case 2: this_att is a fk of another table\n                    else:\n                        fk_list = []\n                        for row in self.db.select_where(target, [this_att] + cols, pk_att, pk):\n                            row_pk = self._row_pk(target, cols, row[1:])\n                            fk_list.append((row[0], row_pk))\n                        for fk, row_pk in fk_list:\n                            facts.extend(self._facts(fk,\n                                                     that_att,\n                                                     table,\n                                                     visited=visited,\n                                                     parent_table=target,\n                                                     parent_pk=row_pk))\n        return facts", "response": "Returns the facts for the given entity with pk in target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _discretize_check(self, table, att, col):\n        '''\n        Replaces the value with an appropriate interval symbol, if available.\n        '''\n        label = \"'%s'\" % col\n        if table in self.discr_intervals and att in self.discr_intervals[table]:\n            intervals = self.discr_intervals[table][att]\n            n_intervals = len(intervals)\n\n            prev_value = None\n            for i, value in enumerate(intervals):\n\n                if i > 0:\n                    prev_value = intervals[i - 1]\n\n                if not prev_value and col <= value:\n                    label = \"'=<%.2f'\" % value\n                    break\n                elif prev_value and col <= value:\n                    label = \"'(%.2f;%.2f]'\" % (prev_value, value)\n                    break\n                elif col > value and i == n_intervals - 1:\n                    label = \"'>%.2f'\" % value\n                    break\n        else:\n            # For some reason using [ and ] crashes TreeLiker\n            label = label.replace('[', 'I')\n            label = label.replace(']', 'I')\n\n        return label", "response": "Returns the label for a check in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the DBContext as a list of interpretations i. e. a list of facts true for each example in the format for TreeLiker.", "response": "def dataset(self):\n        '''\n        Returns the DBContext as a list of interpretations, i.e., a list of\n        facts true for each example in the format for TreeLiker.\n        '''\n        target = self.db.target_table\n        db_examples = self.db.rows(target, [self.db.target_att, self.db.pkeys[target]])\n\n        examples = []\n        for cls, pk in sorted(db_examples, key=lambda ex: ex[0]):\n            facts = self._facts(pk, self.db.pkeys[target], target, visited=set())\n            examples.append('%s %s' % (cls, ', '.join(facts)))\n\n        return '\\n'.join(examples)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_prd_file(self):\n        '''\n        Emits the background knowledge in prd format.\n        '''\n        prd_str = ''\n        prd_str += '--INDIVIDUAL\\n'\n        prd_str += '%s 1 %s cwa\\n' % (self.db.target_table, self.db.target_table)\n        prd_str += '--STRUCTURAL\\n'\n        for ftable, ptable in self.db.reverse_fkeys.items():\n            prd_str += '%s2%s 2 1:%s *:%s 1 cwa li\\n' % (ptable, ftable[0], ptable, ftable[0])\n        prd_str += '--PROPERTIES\\n'\n        prd_str += 'class 2 %s #class cwa\\n' % self.db.target_table\n        for table, cols in self.db.cols.items():\n            for col in cols:\n                if col != self.db.pkeys[table] and col not in self.db.fkeys[table] and (\n                                table != self.db.target_table or col != self.db.target_att):\n                    prd_str += '%s_%s 2 %s #%s_%s 1 cwa\\n' % (table, col, table, table, col)\n        return prd_str", "response": "Emits the background knowledge in prd format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_fct_file(self):\n        '''\n        Emits examples in fct format.\n        '''\n        fct_str = ''\n        fct_str += self.fct_rec(self.db.target_table)\n        return fct_str", "response": "Emits examples in fct format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning points on convex hull of an array of points in CCW order.", "response": "def convex_hull(features):\n    \"\"\"Returns points on convex hull of an array of points in CCW order.\"\"\"\n    points = sorted([s.point() for s in features])\n    l = reduce(_keep_left, points, [])\n    u = reduce(_keep_left, reversed(points), [])\n    return l.extend(u[i] for i in xrange(1, len(u) - 1)) or l"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisassemble a python bytecode into a series of Op and Label instances.", "response": "def disassemble(code, origin=None):\n    \"\"\"\n    Disassemble python bytecode into a series of :class:`Op` and\n    :class:`Label` instances.\n\n    Arguments:\n        code(bytes): The bytecode (a code object's ``co_code`` property). You\n            can also provide a function.\n        origin(dict): The opcode specification of the python version that\n            generated ``code``. If you provide ``None``, the specs for the\n            currently running python version will be used.\n\n    Returns:\n        list: A list of opcodes and labels.\n    \"\"\"\n\n    if inspect.isfunction(code):\n        code = six.get_function_code(code).co_code\n\n    origin = get_py_internals(origin)\n\n    opname = origin['opname']\n    hasjrel = origin['hasjrel']\n    hasjabs = origin['hasjabs']\n    hasjump = set(hasjrel) | set(hasjabs)\n    wordcode = origin['wordcode']\n    if not wordcode:\n        ext_arg_shift = 16\n    else:\n        ext_arg_shift = 8\n\n    ext_arg_name = opname[origin['extended_arg']]\n    ext_arg = 0\n\n    addr_labels = {}\n    addr_ops = []\n\n    code_iter = enumerate(six.iterbytes(code))\n    for op_addr, op_code in code_iter:\n        if op_code >= origin['have_argument']:\n            rel_addr, arg = next(code_iter)\n            if not wordcode:\n                rel_addr, b = next(code_iter)\n                arg += b << 8\n\n            arg += ext_arg\n\n            if op_code in hasjrel:\n                arg += rel_addr\n\n            if op_code in hasjump:\n                arg = addr_labels.setdefault(arg, Label())\n        else:\n            if wordcode:\n                next(code_iter)\n            arg = None\n        ext_arg = 0\n\n        op_name = opname[op_code]\n\n        if op_name == ext_arg_name:\n            ext_arg = arg << ext_arg_shift\n            op = None\n        else:\n            op = Op(op_name, arg)\n\n        addr_ops.append((op_addr, op))\n\n    ops = []\n    for op_addr, op in addr_ops:\n        label = addr_labels.get(op_addr)\n        if label is not None:\n            ops.append(label)\n\n        if op is not None:\n            ops.append(op)\n\n    return ops"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassemble a list of opcodes and labels into a single binary tree.", "response": "def assemble(ops, target=None):\n    \"\"\"\n    Assemble a set of :class:`Op` and :class:`Label` instance back into\n    bytecode.\n\n    Arguments:\n        ops(list): A list of opcodes and labels (as returned by\n            :func:`disassemble`).\n        target: The opcode specification of the targeted python\n            version. If this is ``None`` the specification of the currently\n            running python version will be used.\n\n    Returns:\n        bytes: The assembled bytecode.\n    \"\"\"\n\n\n    target = get_py_internals(target)\n\n    opmap = target['opmap']\n    hasjrel = target['hasjrel']\n    hasjabs = target['hasjabs']\n    hasjump = set(hasjrel) | set(hasjabs)\n    have_argument = target['have_argument']\n    extended_arg = target['extended_arg']\n    wordcode = target['wordcode']\n\n    if not wordcode:\n        def encode_op(output, op_code, op_arg=None):\n            n = 1\n            if op_arg is None:\n                output.append(op_code)\n            else:\n                n += 2\n                ext_arg = op_arg >> 16\n                if ext_arg:\n                    n += 3\n                    output.extend([extended_arg, ext_arg & 255, ext_arg >> 8])\n                    op_arg &= 65535\n                output.extend([op_code, op_arg & 255, op_arg >> 8])\n            return n\n    else:\n        def encode_op(output, op_code, op_arg=None):\n            n = 2\n            if op_arg is None:\n                output.extend([op_code, 0])\n            else:\n                ext_arg = op_arg >> 8\n                if ext_arg:\n                    n += encode_op(extended_arg, ext_arg)\n                output.extend([op_code, op_arg & 255])\n            return n\n\n    # A bit of a chicken and egg problem: The address of a label depends on the instructions before it. However,\n    # the instructions before a label might depend on the label itself: For very large functions, jumps may\n    # require an EXTENDED_ARG opcode if the jump destination is far away. Which we only know when the label\n    # has materialized, which means the address of the label will change on the next pass, which might mean\n    # a different jump offset might become larger, etc... We run passes until no label changes address.\n\n    label_address = {}\n    while True:\n        retry = False\n        output = bytearray()\n        address = 0\n\n        for op in ops:\n            if isinstance(op, Label):\n                if label_address.get(op) != address:\n                    retry = True\n                    label_address[op] = address\n                continue\n\n            op_code = opmap[op.name]\n            op_arg = op.arg\n\n            if op_code >= have_argument and op_arg is None:\n                # Sanity check.\n                raise ValueError('Opcode %s requires argument.' % op)\n            elif op_code < have_argument and op_arg is not None:\n                # Sanity check.\n                raise ValueError('Opcode %s should not have an argument.' % op)\n            elif isinstance(op_arg, Label):\n                if op_code not in hasjump:\n                    # Sanity check.\n                    raise ValueError('Did not expect label as argument for opcode %s.' % op)\n\n                if op_arg not in ops:\n                    # Sanity check.\n                    raise ValueError('Label is not part of this op list.')\n\n                # Try to turn the label argument into an address.\n                op_arg = label_address.get(op_arg)\n                if op_arg is None:\n                    # Label hasn't materialized yet, we'll catch it on the next pass.\n                    address += encode_op(output, op_code, 0)\n                    continue\n\n                if op_code in hasjrel:\n                    op_arg -= address\n            elif op_code in hasjump:\n                # Sanity check.\n                raise ValueError('Expected label as argument for opcode %s.' % op)\n\n            # Encode the opcode and the argument.\n            n = encode_op(output, op_code, op_arg)\n            address += n\n\n            if op_code in hasjrel:\n                if not wordcode:\n                    op_arg = output[-2] + (output[-1] << 8)\n                    if op_arg < n:\n                        ext_arg = output[-5] + (output[-4] << 8) - 1\n                        output[-5], output[-4] = ext_arg & 255, ext_arg >> 8\n                        op_arg += 65536\n                    op_arg -= n\n                    output[-2], output[-1] = op_arg & 255, op_arg >> 8\n                else:\n                    for i in itertools.count(1, 2):\n                        if n <= output[-i]:\n                            output[-i] -= n\n                            break\n                        output[-i] += 256 - n\n                        n = 1\n\n        if not retry:\n            return bytes(output)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef blocks_from_ops(ops):\n\n    blocks = {}\n    current_block = blocks[None] = Block()\n    for op in ops:\n        if isinstance(op, Label):\n            next_block = blocks[op] = Block(op)\n            current_block.next = next_block\n            current_block = next_block\n            continue\n        current_block.ops.append(op)\n    return blocks", "response": "Returns a dictionary of blocks grouped by label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the maximum stack depth for a series of opcodes and labels.", "response": "def calculate_max_stack_depth(ops, target=None):\n    \"\"\"\n    Calculate the maximum stack depth (and required stack size) from a series\n    of :class:`Op` and :class:`Label` instances. This is required when you\n    manipulate the opcodes in such a way that the stack layout might change\n    and you want to re-create a working function from it.\n\n    This is a fairly literal re-implementation of python's stackdepth and\n    stackdepth_walk.\n\n    Arguments:\n        ops(list): A list of opcodes and labels (as returned by\n            :func:`disassemble`).\n        target: The opcode specification of the targeted python\n            version. If this is ``None`` the specification of the currently\n            running python version will be used.\n\n    Returns:\n        int: The calculated maximum stack depth.\n    \"\"\"\n\n    blocks = blocks_from_ops(ops)\n    target = get_py_internals(target)\n\n    block = blocks[None]\n    while block:\n        block.seen = False\n        block.startdepth = -1\n        block = block.next\n\n    stackeffect = target['stackeffect']\n    stackeffect_traits = target['stackeffect_traits']\n\n    def walk(block=None, depth=0, max_depth=0):\n        if not isinstance(block, Block):\n            block = blocks[block]\n\n        if block.seen or block.startdepth >= depth:\n            return max_depth\n\n        block.seen = True\n        block.startdepth = depth\n\n        for op in block.ops:\n            effect = stackeffect[op.name]\n            if callable(effect):\n                effect = effect(op.arg)\n\n            depth += effect\n            if depth > max_depth:\n                max_depth = depth\n\n            op_code = target['opmap'][op.name]\n            if op_code in target['hasjrel'] or op_code in target['hasjabs']:\n                target_depth = depth\n\n                if stackeffect_traits & 1:\n                    if op.name == 'FOR_ITER':\n                        target_depth -= 2\n                    elif op.name in ('SETUP_FINALLY', 'SETUP_EXCEPT'):\n                        target_depth += 3\n                        if target_depth > max_depth:\n                            max_depth = target_depth\n                if stackeffect_traits & 2:\n                    if op.name in ('JUMP_IF_TRUE_OR_POP', 'JUMP_IF_FALSE_OR_POP'):\n                        depth -= 1\n\n                max_depth = walk(op.arg, target_depth, max_depth)\n            if op.name in ('JUMP_ABSOLUTE', 'JUMP_FORWARD'):\n                break\n\n        else:\n            if block.next:\n                max_depth = walk(block.next, depth, max_depth)\n\n        block.seen = False\n\n        return max_depth\n\n    return walk()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_code(cls, code, co_argcount=BORROW, co_kwonlyargcount=BORROW, co_nlocals=BORROW, co_stacksize=BORROW,\n                  co_flags=BORROW, co_code=BORROW, co_consts=BORROW, co_names=BORROW, co_varnames=BORROW,\n                  co_filename=BORROW, co_name=BORROW, co_firstlineno=BORROW, co_lnotab=BORROW, co_freevars=BORROW,\n                  co_cellvars=BORROW):\n        \"\"\"from_code(code, co_argcount=BORROW, co_kwonlyargcount=BORROW, co_nlocals=BORROW, co_stacksize=BORROW, co_flags=BORROW, co_code=BORROW, co_consts=BORROW, co_names=BORROW, co_varnames=BORROW, co_filename=BORROW, co_name=BORROW, co_firstlineno=BORROW, co_lnotab=BORROW, co_freevars=BORROW, co_cellvars=BORROW)\n\n        Create a new instance from an existing code object. The originating\n        internals of the instance will be that of the running python version.\n\n        Any properties explicitly specified will be overridden on the new\n        instance.\n\n        Arguments:\n            code(types.CodeType): The code object to get the properties of.\n            ...: The properties to override.\n\n        Returns:\n            CodeObject: A new :class:`CodeObject` instance.\n        \"\"\"\n\n        if six.PY2:\n            co_kwonlyargcount = co_kwonlyargcount if co_kwonlyargcount is not BORROW else 0\n        else:\n            co_kwonlyargcount = co_kwonlyargcount if co_kwonlyargcount is not BORROW else code.co_kwonlyargcount\n\n        return cls(\n            co_argcount if co_argcount is not BORROW else code.co_argcount,\n            co_kwonlyargcount,\n            co_nlocals if co_nlocals is not BORROW else code.co_nlocals,\n            co_stacksize if co_stacksize is not BORROW else code.co_stacksize,\n            co_flags if co_flags is not BORROW else code.co_flags,\n            co_code if co_code is not BORROW else code.co_code,\n            co_consts if co_consts is not BORROW else code.co_consts,\n            co_names if co_names is not BORROW else code.co_names,\n            co_varnames if co_varnames is not BORROW else code.co_varnames,\n            co_filename if co_filename is not BORROW else code.co_filename,\n            co_name if co_name is not BORROW else code.co_name,\n            co_firstlineno if co_firstlineno is not BORROW else code.co_firstlineno,\n            co_lnotab if co_lnotab is not BORROW else code.co_lnotab,\n            co_freevars if co_freevars is not BORROW else code.co_freevars,\n            co_cellvars if co_cellvars is not BORROW else code.co_cellvars,\n        )", "response": "Create a new CodeObject instance from an existing code object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance from a function.", "response": "def from_function(cls, f, *args, **kwargs):\n        \"\"\"\n        Create a new instance from a function. Gets the code object from\n        the function and passes it and any other specified parameters to\n        :meth:`from_code`.\n\n        Arguments:\n            f(function): The function to get the code object from.\n\n        Returns:\n            CodeObject: A new :class:`CodeObject` instance.\n        \"\"\"\n\n        return cls.from_code(six.get_function_code(f), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef annotate_op(self, op):\n\n        if isinstance(op, Label):\n            return op\n        else:\n            return AnnotatedOp(self, op.name, op.arg)", "response": "Takes a bytecode operation and returns an AnnotatedOp object that can be used to annotate it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisassembling the bytecode of this code object into a series of opcodes and labels.", "response": "def disassemble(self, annotate=False, blocks=False):\n        \"\"\"\n        Disassemble the bytecode of this code object into a series of\n        opcodes and labels. Can also annotate the opcodes and group\n        the opcodes into blocks based on the labels.\n\n        Arguments:\n            annotate(bool): Whether to annotate the operations.\n            blocks(bool): Whether to group the operations into blocks.\n\n        Returns:\n            list: A list of :class:`Op` (or :class:`AnnotatedOp`) instances\n            and labels.\n        \"\"\"\n\n        ops = disassemble(self.co_code, self.internals)\n\n        if annotate:\n            ops = [self.annotate_op(op) for op in ops]\n\n        if blocks:\n            return blocks_from_ops(ops)\n        else:\n            return ops"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assemble(self, ops, target=None):\n\n        self.internals = target = get_py_internals(target, self.internals)\n        self.co_code = assemble(ops, target)\n        self.co_stacksize = calculate_max_stack_depth(ops, target)\n        return self", "response": "Assemble a series of operations and labels into bytecode and replace the bytecode and stack size of this codeCOOKIE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_code(self):\n\n        if self.internals is not get_py_internals():\n            raise ValueError('CodeObject is not compatible with the running python internals.')\n\n        if six.PY2:\n            return types.CodeType(\n                self.co_argcount, self.co_nlocals, self.co_stacksize, self.co_flags, self.co_code, self.co_consts,\n                self.co_names, self.co_varnames, self.co_filename, self.co_name, self.co_firstlineno, self.co_lnotab,\n                self.co_freevars, self.co_cellvars\n            )\n        else:\n            return types.CodeType(\n                self.co_argcount, self.co_kwonlyargcount, self.co_nlocals, self.co_stacksize, self.co_flags,\n                self.co_code, self.co_consts, self.co_names, self.co_varnames, self.co_filename, self.co_name,\n                self.co_firstlineno, self.co_lnotab, self.co_freevars, self.co_cellvars\n            )", "response": "Converts this instance into a native python code object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_page_cb(self, print_op, print_context, page_nb, keep_refs={}):\n        self.pages[page_nb].print_page_cb(print_op, print_context,\n                                          keep_refs=keep_refs)", "response": "Called for printing operation by Gtk\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef examine_rootdir(self,\n                        on_new_doc,\n                        on_doc_modified,\n                        on_doc_deleted,\n                        on_doc_unchanged,\n                        progress_cb=dummy_progress_cb):\n        \"\"\"\n        Examine the rootdir.\n        Calls on_new_doc(doc), on_doc_modified(doc), on_doc_deleted(docid)\n        every time a new, modified, or deleted document is found\n        \"\"\"\n\n        count = self.docsearch.index.start_examine_rootdir()\n\n        progress = 0\n        while True:\n            (status, doc) = self.docsearch.index.continue_examine_rootdir()\n            if status == 'end':\n                break\n            elif status == 'modified':\n                on_doc_modified(doc)\n            elif status == 'unchanged':\n                on_doc_unchanged(doc)\n            elif status == 'new':\n                on_new_doc(doc)\n            progress_cb(progress, count,\n                        DocSearch.INDEX_STEP_CHECKING, doc)\n            progress += 1\n\n        while True:\n            (status, doc) = self.docsearch.index.continue_examine_rootdir2()\n            if status == 'end':\n                break\n            on_doc_deleted(doc)\n\n        progress_cb(1, 1, DocSearch.INDEX_STEP_CHECKING)\n        self.docsearch.index.end_examine_rootdir()", "response": "Examine the rootdir.\n        Calls on_new_doc(doc), on_doc_modified(doc), on_doc_deleted(docid)\n        every time a new, modified, or deleted document is found"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a document to the index", "response": "def add_doc(self, doc, index_update=True, label_guesser_update=True):\n        \"\"\"\n        Add a document to the index\n        \"\"\"\n        logger.info(\"Indexing new doc: %s\" % doc)\n        doc = doc.clone()  # make sure it can be serialized safely\n        self.docsearch.index.add_doc(doc, index_update=index_update,\n                                     label_guesser_update=label_guesser_update)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_doc(self, doc):\n        logger.info(\"Removing doc from the index: %s\" % doc)\n        doc = doc.clone()  # make sure it can be serialized safely\n        self.docsearch.index.del_doc(doc)", "response": "Delete a document from the index"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncommit changes to the index", "response": "def commit(self, index_update=True, label_guesser_update=True):\n        \"\"\"\n        Apply the changes to the index\n        \"\"\"\n        logger.info(\"Index: Commiting changes\")\n        self.docsearch.index.commit(index_update=index_update,\n                                    label_guesser_update=label_guesser_update)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef guess_labels(self, doc):\n        doc = doc.clone()  # make sure it can be serialized safely\n        return self.index.guess_labels(doc)", "response": "Guess the set of labels that can be used for the given document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reload_index(self, progress_cb=dummy_progress_cb):\n        nb_results = self.index.start_reload_index()\n        progress = 0\n        while self.index.continue_reload_index():\n            progress_cb(progress, nb_results, self.INDEX_STEP_LOADING)\n            progress += 1\n        progress_cb(1, 1, self.INDEX_STEP_LOADING)\n        self.index.end_reload_index()", "response": "Reloads the index and loads the document list from it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_label(self, label, doc=None, callback=dummy_progress_cb):\n        if doc:\n            clone = doc.clone()  # make sure it's serializable\n        r = self.index.create_label(label, doc=clone)\n        return r", "response": "Create a new label"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_label(self, doc, label, update_index=True):\n        doc = doc.clone()  # make sure it's serializable\n        r = self.index.remove_label(doc, label, update_index=update_index)\n        return r", "response": "Removes a label from a doc. Takes care of updating the index\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_label(self, old_label, new_label, callback=dummy_progress_cb):\n        current = 0\n        total = self.index.get_nb_docs()\n        self.index.start_update_label(old_label, new_label)\n        while True:\n            (op, doc) = self.index.continue_update_label()\n            if op == 'end':\n                break\n            callback(current, total, self.LABEL_STEP_UPDATING, doc)\n            current += 1\n        self.index.end_update_label()", "response": "Update the label of the entries in the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the label from all the documents. Takes care of updating the index.", "response": "def destroy_label(self, label, callback=dummy_progress_cb):\n        \"\"\"\n        Remove the label 'label' from all the documents. Takes care of updating\n        the index.\n        \"\"\"\n        current = 0\n        total = self.index.get_nb_docs()\n        self.index.start_destroy_label(label)\n        while True:\n            (op, doc) = self.index.continue_destroy_label()\n            if op == 'end':\n                break\n            callback(current, total, self.LABEL_STEP_DESTROYING, doc)\n            current += 1\n        self.index.end_destroy_label()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the context with the user s selections.", "response": "def _update_context(context, postdata):\n    '''\n    Updates the default selections with user's selections.\n    '''\n    listCheck = lambda el: el[0] if type(el) == list else el  # For handling lists of size 1\n    widget_id = listCheck(postdata.get('widget_id'))\n    context.target_table = listCheck(postdata.get('target_table%s' % widget_id))\n    context.target_att = listCheck(postdata.get('target_att%s' % widget_id))\n    context.tables = postdata.get('tables%s' % widget_id, [])\n    if context.target_table not in context.tables:\n        raise Exception('The selected target table \"%s\" is not among the selected tables.' % context.target_table)\n    # Propagate the selected tables\n    for table in context.cols.keys():\n        if table not in context.tables:\n            del context.cols[table]\n    for pair in context.connected.keys():\n        if pair[0] in context.tables and pair[1] in context.tables:\n            continue\n        del context.connected[pair]\n    for table in context.tables:\n        context.cols[table] = postdata.get('%s_columns%s' % (table, widget_id), [])\n        if table == context.target_table and context.target_att not in context.cols[table]:\n            raise Exception(\n                'The selected target attribute (\"%s\") is not among the columns selected for the target table (\"%s\").' % (\n                context.target_att, context.target_table))\n    if context.in_memory:\n        context.orng_tables = None  # Reset to make sure up-to-date tables are created\n        context.orng_tables = context.read_into_orange()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_map(input_dict, feature_format, positive_class=None):\n    '''\n    Maps a new example to a set of features.\n    '''\n    # Context of the unseen example(s)\n    train_context = input_dict['train_ctx']\n    test_context = input_dict['test_ctx']\n\n    # Currently known examples & background knowledge\n    features = input_dict['features']\n    format = input_dict['output_format']\n\n    evaluations = domain_map(features, feature_format, train_context,\n                             test_context, format=format,\n                             positive_class=positive_class)\n    return {'evaluations': evaluations}", "response": "Maps a new example to a set of features."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(self, queryset, **options):\n        self.options = options\n\n        self.stream = options.get(\"stream\", StringIO())\n        self.selected_fields = options.get(\"fields\")\n        self.use_natural_keys = options.get(\"use_natural_keys\", True)\n        \n        self.xml = options.get(\"xml\", None)\n        self.root = (self.xml == None)\n        \n        self.start_serialization()\n        for obj in queryset:\n            # hook for having custom serialization\n            if hasattr(obj, '__serialize__'):\n                obj.__serialize__(self.xml)\n            else:\n                self.serialize_object(obj)\n        self.end_serialization()\n        return self.getvalue()", "response": "Serialize a queryset into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize an object to the xml stream.", "response": "def serialize_object(self, obj):\n        \"\"\"\n        Write one item to the object stream\n        \"\"\"\n        self.start_object(obj)\n        for field in obj._meta.local_fields:\n            if field.serialize and getattr(field, 'include_in_xml', True):\n                if field.rel is None:\n                    if self.selected_fields is None or field.attname in self.selected_fields:\n                        self.handle_field(obj, field)\n                else:\n                    if self.selected_fields is None or field.attname[:-3] in self.selected_fields:\n                        self.handle_fk_field(obj, field)\n\n        # recursively serialize all foreign key relations\n        for (foreign_key_descriptor_name, foreign_key_descriptor ) in get_foreign_key_desciptors(obj):\n            # don't follow foreign keys that have a 'nofollow' attribute\n            if foreign_key_descriptor.related.field.serialize \\\n                and not hasattr(foreign_key_descriptor.related.field, 'nofollow'):\n                bound_foreign_key_descriptor = foreign_key_descriptor.__get__(obj)\n                s = RecursiveXmlSerializer()                \n                s.serialize( bound_foreign_key_descriptor.all(), xml=self.xml, stream=self.stream)\n\n        #recursively serialize all one to one relations\n        # TODO: make this work for non abstract inheritance but without infinite recursion\n        # for (one_to_one_descriptor_name, one_to_one_descriptor) in get_one_to_one_descriptors(obj):\n        #     related_objects = []\n        #     try:\n        #         related_object = one_to_one_descriptor.__get__(obj)\n        #         related_objects.append(related_object)\n        #     except Exception as e:\n        #         pass\n        # \n        #     s = RecursiveXmlSerializer()                \n        #     s.serialize( related_objects, xml=self.xml, stream=self.stream)\n\n        # add generic relations\n        for (generic_relation_descriptor_name, generic_relation_descriptor) in get_generic_relation_descriptors(obj):\n            # generic relations always have serialize set to False so we always include them.\n            bound_generic_relation_descriptor = generic_relation_descriptor.__get__(obj)\n            s = RecursiveXmlSerializer()                \n            s.serialize( bound_generic_relation_descriptor.all(), xml=self.xml, stream=self.stream)\n        \n        #serialize the default field descriptors:\n        for (default_field_descriptor_name, default_field_descriptor) in get_default_field_descriptors(obj):\n            if default_field_descriptor.serialize:\n                self.handle_field(obj, default_field_descriptor)\n        \n        for field in obj._meta.many_to_many:\n            if field.serialize:\n                if self.selected_fields is None or field.attname in self.selected_fields:\n                    self.handle_m2m_field(obj, field)\n        self.end_object(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_serialization(self):\n        if (self.root):\n            self.xml = XmlPrinter(self.stream, self.options.get(\"encoding\", settings.DEFAULT_CHARSET))\n            self.xml.startDocument()\n            self.xml.startElement(\"django-objects\", {\"version\" : \"1.0\"})", "response": "Start serialization of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef end_serialization(self):\n        if (self.root):\n            self.indent(0)\n            self.xml.endElement(\"django-objects\")\n            self.xml.endDocument()", "response": "End serialization -- end the document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the fields of a specific object.", "response": "def handle_field(self, obj, field):\n        \"\"\"\n        Called to handle each field on an object (except for ForeignKeys and\n        ManyToManyFields)\n        \"\"\"\n        self.indent(2)\n\n        field_attrs = {\n            \"name\" : field.name,\n            \"type\" : field.get_internal_type()\n        }\n        # handle fields with a extra_attrs set as speciul\n        if hasattr(field, 'extra_attrs'):\n            if field.extra_attrs:\n                for (key, value) in field.extra_attrs.iteritems():\n                    field_attrs[key] = force_unicode(value)\n\n            field_attrs['name'] = field.name.replace('_', '.')\n\n        self.xml.startElement(\"field\", field_attrs)\n\n        # Checks for a custom value serializer \n        if not hasattr(field, '__serialize__'):\n            # Get a \"string version\" of the object's data.\n            if getattr(obj, field.name) is not None:\n                self.xml.characters(field.value_to_string(obj))\n            else:\n                self.xml.addQuickElement(\"None\")\n        else:\n            field.__serialize__(obj, self.xml)\n\n        self.xml.endElement(\"field\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_fk_field(self, obj, field):\n        self._start_relational_field(field)\n        related = getattr(obj, field.name)\n        if related is not None:\n            if self.use_natural_keys and hasattr(related, 'natural_key'):\n                # If related object has a natural key, use it\n                related = related.natural_key()\n                # Iterable natural keys are rolled out as subelements\n                for key_value in related:\n                    self.xml.startElement(\"natural\", {})\n                    self.xml.characters(smart_unicode(key_value))\n                    self.xml.endElement(\"natural\")\n            else:\n                if field.rel.field_name == related._meta.pk.name:\n                    # Related to remote object via primary key\n                    related = related._get_pk_val()\n                else:\n                    # Related to remote object via other field\n                    related = getattr(related, field.rel.field_name)\n                self.xml.characters(smart_unicode(related))\n        else:\n            self.xml.addQuickElement(\"None\")\n        self.xml.endElement(\"field\")", "response": "Handles a ForeignKey field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle a many - to - many relationship between two objects.", "response": "def handle_m2m_field(self, obj, field):\n        \"\"\"\n        while easymode follows inverse relations for foreign keys,\n        for manytomayfields it follows the forward relation.\n        \n        While easymode excludes all relations to \"self\" you could\n        still create a loop if you add one extra level of indirection.\n        \"\"\"\n        \n        if field.rel.through._meta.auto_created:#  and obj.__class__ is not field.rel.to:\n            # keep approximate recursion level\n            with recursion_depth('handle_m2m_field') as recursion_level:\n                \n                # a stack trace is better than python crashing.\n                if recursion_level > getattr(settings, 'RECURSION_LIMIT', sys.getrecursionlimit() / 10):\n                    raise Exception(MANY_TO_MANY_RECURSION_LIMIT_ERROR % \n                            (field.name, obj.__class__.__name__, field.rel.to.__name__))\n\n                self._start_relational_field(field)\n\n                s = RecursiveXmlSerializer()\n                s.serialize( getattr(obj, field.name).iterator(), xml=self.xml, stream=self.stream)\n\n                self.xml.endElement(\"field\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassembles a string of code into a machine readable code.", "response": "def asm(code, addr=0, syntax=None, target=None, gnu_binutils_prefix=None):\n    \"\"\"\n    Assemble statements into machine readable code.\n\n    Args:\n        code(str): The statements to assemble.\n        addr(int): The memory address where the code will run.\n        syntax(AsmSyntax): The input assembler syntax for x86. Defaults to\n            nasm, ignored on other platforms.\n        target(~pwnypack.target.Target): The target architecture. The\n            global target is used if this argument is ``None``.\n        gnu_binutils_prefix(str): When the syntax is AT&T, gnu binutils'\n            as and ld will be used. By default, it selects\n            ``arm-*-as/ld`` for 32bit ARM targets,\n            ``aarch64-*-as/ld`` for 64 bit ARM targets,\n            ``i386-*-as/ld`` for 32bit X86 targets and\n            ``amd64-*-as/ld`` for 64bit X86 targets (all for various flavors\n            of ``*``. This option allows you to pick a different toolchain.\n            The prefix should always end with a '-' (or be empty).\n\n    Returns:\n        bytes: The assembled machine code.\n\n    Raises:\n        SyntaxError: If the assembler statements are invalid.\n        NotImplementedError: In an unsupported target platform is specified.\n\n    Example:\n        >>> from pwny import *\n        >>> asm('''\n        ...     pop rdi\n        ...     ret\n        ... ''', target=Target(arch=Target.Arch.x86, bits=64))\n        b'_\\\\xc3'\n    \"\"\"\n\n    if target is None:\n        target = pwnypack.target.target\n\n    if syntax is None and target.arch is pwnypack.target.Target.Arch.x86:\n        syntax = AsmSyntax.nasm\n\n    if HAVE_KEYSTONE and WANT_KEYSTONE:\n        ks_mode = 0\n        ks_syntax = None\n\n        if target.arch is pwnypack.target.Target.Arch.x86:\n            ks_arch = keystone.KS_ARCH_X86\n            if target.bits is pwnypack.target.Target.Bits.bits_32:\n                ks_mode |= keystone.KS_MODE_32\n            else:\n                ks_mode |= keystone.KS_MODE_64\n            if syntax is AsmSyntax.nasm:\n                ks_syntax = keystone.KS_OPT_SYNTAX_NASM\n            elif syntax is AsmSyntax.intel:\n                ks_syntax = keystone.KS_OPT_SYNTAX_INTEL\n            else:\n                ks_syntax = keystone.KS_OPT_SYNTAX_ATT\n\n        elif target.arch is pwnypack.target.Target.Arch.arm:\n            if target.bits is pwnypack.target.Target.Bits.bits_32:\n                ks_arch = keystone.KS_ARCH_ARM\n\n                if target.mode & pwnypack.target.Target.Mode.arm_thumb:\n                    ks_mode |= keystone.KS_MODE_THUMB\n                else:\n                    ks_mode |= keystone.KS_MODE_ARM\n\n                if target.mode & pwnypack.target.Target.Mode.arm_v8:\n                    ks_mode |= keystone.KS_MODE_V8\n\n                if target.mode & pwnypack.target.Target.Mode.arm_m_class:\n                    ks_mode |= keystone.KS_MODE_MICRO\n\n                if target.endian is pwnypack.target.Target.Endian.little:\n                    ks_mode |= keystone.KS_MODE_LITTLE_ENDIAN\n                else:\n                    ks_mode |= keystone.KS_MODE_BIG_ENDIAN\n            else:\n                ks_arch = keystone.KS_ARCH_ARM64\n                ks_mode |= keystone.KS_MODE_LITTLE_ENDIAN\n        else:\n            raise NotImplementedError('Unsupported syntax or target platform.')\n\n        ks = keystone.Ks(ks_arch, ks_mode)\n        if ks_syntax is not None:\n            ks.syntax = ks_syntax\n        try:\n            data, insn_count = ks.asm(code, addr)\n        except keystone.KsError as e:\n            import traceback\n            traceback.print_exc()\n            raise SyntaxError(e.message)\n        return b''.join(six.int2byte(b) for b in data)\n\n    if target.arch is pwnypack.target.Target.Arch.x86 and syntax is AsmSyntax.nasm:\n        with tempfile.NamedTemporaryFile() as tmp_asm:\n            tmp_asm.write(('bits %d\\norg %d\\n%s' % (target.bits.value, addr, code)).encode('utf-8'))\n            tmp_asm.flush()\n\n            tmp_bin_fd, tmp_bin_name = tempfile.mkstemp()\n            os.close(tmp_bin_fd)\n\n            try:\n                p = subprocess.Popen(\n                    [\n                        'nasm',\n                        '-o', tmp_bin_name,\n                        '-f', 'bin',\n                        tmp_asm.name,\n                    ],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                )\n                stdout, stderr = p.communicate()\n\n                if p.returncode:\n                    raise SyntaxError(stderr.decode('utf-8'))\n\n                tmp_bin = open(tmp_bin_name, 'rb')\n                result = tmp_bin.read()\n                tmp_bin.close()\n                return result\n            finally:\n                try:\n                    os.unlink(tmp_bin_name)\n                except OSError:\n                    pass\n    elif target.arch in (pwnypack.target.Target.Arch.x86, pwnypack.target.Target.Arch.arm):\n        preamble = ''\n        as_flags = []\n        ld_flags = []\n\n        if target.arch is pwnypack.target.Target.Arch.x86:\n            if target.bits == 32:\n                binutils_arch = 'i386'\n            else:\n                binutils_arch = 'amd64'\n\n            if syntax is AsmSyntax.intel:\n                preamble = '.intel_syntax noprefix\\n'\n\n            ld_flags.extend(['--oformat', 'binary'])\n        else:\n            if target.bits == 32:\n                binutils_arch = 'arm'\n                if target.mode & pwnypack.target.Target.Mode.arm_v8:\n                    as_flags.append('-march=armv8-a')\n                elif target.mode & pwnypack.target.Target.Mode.arm_m_class:\n                    as_flags.append('-march=armv7m')\n            else:\n                binutils_arch = 'aarch64'\n\n            if target.endian is pwnypack.target.Target.Endian.little:\n                as_flags.append('-mlittle-endian')\n                ld_flags.append('-EL')\n            else:\n                as_flags.append('-mbig-endian')\n                ld_flags.append('-EB')\n\n            if target.mode & pwnypack.target.Target.Mode.arm_thumb:\n                as_flags.append('-mthumb')\n\n        if gnu_binutils_prefix is None:\n            gnu_binutils_prefix = find_binutils_prefix(binutils_arch)\n\n        tmp_out_fd, tmp_out_name = tempfile.mkstemp()\n        try:\n            os.close(tmp_out_fd)\n\n            p = subprocess.Popen(\n                [\n                    '%sas' % gnu_binutils_prefix,\n                    '-o', tmp_out_name\n                ] + as_flags,\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n            stdout, stderr = p.communicate((preamble + code).encode('utf-8'))\n\n            if p.returncode:\n                raise SyntaxError(stderr.decode('utf-8'))\n\n            tmp_bin_fd, tmp_bin_name = tempfile.mkstemp()\n            try:\n                os.close(tmp_bin_fd)\n\n                p = subprocess.Popen(\n                    [\n                        '%sld' % gnu_binutils_prefix,\n                        '-Ttext', str(addr),\n                    ] + ld_flags + [\n                        '-o', tmp_bin_name,\n                        tmp_out_name,\n                    ],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                )\n                stdout, stderr = p.communicate()\n\n                if p.returncode:\n                    raise SyntaxError(stderr.decode('utf-8'))\n\n                if 'binary' in ld_flags:\n                    tmp_bin = open(tmp_bin_name, 'rb')\n                    result = tmp_bin.read()\n                    tmp_bin.close()\n                    return result\n                else:\n                    tmp_bin = ELF(tmp_bin_name)\n                    return tmp_bin.get_section_header('.text').content\n            finally:\n                try:\n                    os.unlink(tmp_bin_name)\n                except OSError:\n                    pass\n        finally:\n            try:\n                os.unlink(tmp_out_name)\n            except OSError:\n                pass  # pragma: no cover\n\n    else:\n        raise NotImplementedError('Unsupported syntax or target platform.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares a capstone disassembler instance for a given target and syntax.", "response": "def prepare_capstone(syntax=AsmSyntax.att, target=None):\n    \"\"\"\n    Prepare a capstone disassembler instance for a given target and syntax.\n\n    Args:\n        syntax(AsmSyntax): The assembler syntax (Intel or AT&T).\n        target(~pwnypack.target.Target): The target to create a disassembler\n            instance for. The global target is used if this argument is\n            ``None``.\n\n    Returns:\n        An instance of the capstone disassembler.\n\n    Raises:\n        NotImplementedError: If the specified target isn't supported.\n    \"\"\"\n\n    if not HAVE_CAPSTONE:\n        raise NotImplementedError('pwnypack requires capstone to disassemble to AT&T and Intel syntax')\n\n    if target is None:\n        target = pwnypack.target.target\n\n    if target.arch == pwnypack.target.Target.Arch.x86:\n        if target.bits is pwnypack.target.Target.Bits.bits_32:\n            md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_32)\n        else:\n            md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64)\n    elif target.arch == pwnypack.target.Target.Arch.arm:\n        mode = 0\n\n        if target.bits is pwnypack.target.Target.Bits.bits_32:\n            arch = capstone.CS_ARCH_ARM\n\n            if target.mode and pwnypack.target.Target.Mode.arm_thumb:\n                mode = capstone.CS_MODE_THUMB\n            else:\n                mode = capstone.CS_MODE_ARM\n                if target.mode and pwnypack.target.Target.Mode.arm_m_class:\n                    mode |= capstone.CS_MODE_MCLASS\n\n            if target.mode and pwnypack.target.Target.Mode.arm_v8:\n                mode |= capstone.CS_MODE_V8\n        else:\n            arch = capstone.CS_ARCH_ARM64\n\n        if target.endian is pwnypack.target.Target.Endian.little:\n            mode |= capstone.CS_MODE_LITTLE_ENDIAN\n        else:\n            mode |= capstone.CS_MODE_BIG_ENDIAN\n\n        md = capstone.Cs(arch, mode)\n    else:\n        raise NotImplementedError('Only x86 is currently supported.')\n\n    md.skipdata = True\n\n    if syntax is AsmSyntax.att:\n        md.syntax = capstone.CS_OPT_SYNTAX_ATT\n    elif syntax is AsmSyntax.intel:\n        md.skipdata_setup(('db', None, None))\n    else:\n        raise NotImplementedError('capstone engine only implements AT&T and Intel syntax.')\n\n    return md"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisassemble a machine readable code into a list of strings.", "response": "def disasm(code, addr=0, syntax=None, target=None):\n    \"\"\"\n    Disassemble machine readable code into human readable statements.\n\n    Args:\n        code(bytes): The machine code that is to be disassembled.\n        addr(int): The memory address of the code (used for relative\n            references).\n        syntax(AsmSyntax): The output assembler syntax. This defaults to\n            nasm on x86 architectures, AT&T on all other architectures.\n        target(~pwnypack.target.Target): The architecture for which the code\n            was written.  The global target is used if this argument is\n            ``None``.\n\n    Returns:\n        list of str: The disassembled machine code.\n\n    Raises:\n        NotImplementedError: In an unsupported target platform is specified.\n        RuntimeError: If ndisasm encounters an error.\n\n    Example:\n        >>> from pwny import *\n        >>> disasm(b'_\\\\xc3', target=Target(arch=Target.Arch.x86, bits=64))\n        ['pop rdi', 'ret']\n    \"\"\"\n\n    if target is None:\n        target = pwnypack.target.target\n\n    if syntax is None:\n        if target.arch is pwnypack.target.Target.Arch.x86:\n            syntax = AsmSyntax.nasm\n        else:\n            syntax = AsmSyntax.att\n\n    if syntax is AsmSyntax.nasm:\n        if target.arch is not pwnypack.target.Target.Arch.x86:\n            raise NotImplementedError('nasm only supports x86.')\n\n        p = subprocess.Popen(\n            [\n                'ndisasm',\n                '-b',\n                str(target.bits.value),\n                '-o',\n                str(addr),\n                '-',\n            ],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        stdout, stderr = p.communicate(code)\n        if p.returncode:\n            raise RuntimeError(stderr.decode('utf-8'))\n\n        return [\n            line.split(None, 2)[2]\n            for line in stdout.decode('utf-8').split('\\n')\n            if line and not line.startswith(' ')\n        ]\n    elif syntax in (AsmSyntax.intel, AsmSyntax.att):\n        md = prepare_capstone(syntax, target)\n        statements = []\n        total_size = 0\n        for (_, size, mnemonic, op_str) in md.disasm_lite(code, addr):\n            statements.append((mnemonic + ' ' + op_str).strip())\n            total_size += size\n        return statements\n    else:\n        raise NotImplementedError('Unsupported syntax for host platform.')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asm_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('source', help='the code to assemble, read from stdin if omitted', nargs='?')\n    pwnypack.main.add_target_arguments(parser)\n    parser.add_argument(\n        '--syntax', '-s',\n        choices=AsmSyntax.__members__.keys(),\n        default=None,\n    )\n    parser.add_argument(\n        '--address', '-o',\n        type=lambda v: int(v, 0),\n        default=0,\n        help='the address where the code is expected to run',\n    )\n\n    args = parser.parse_args(args)\n    target = pwnypack.main.target_from_arguments(args)\n    if args.syntax is not None:\n        syntax = AsmSyntax.__members__[args.syntax]\n    else:\n        syntax = None\n    if args.source is None:\n        args.source = sys.stdin.read()\n    else:\n        args.source = args.source.replace(';', '\\n')\n\n    return asm(\n        args.source,\n        syntax=syntax,\n        target=target,\n        addr=args.address,\n    )", "response": "Assemble code from commandline or stdin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisassembling code from commandline or stdin.", "response": "def disasm_app(_parser, cmd, args):  # pragma: no cover\n    \"\"\"\n    Disassemble code from commandline or stdin.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n    parser.add_argument('code', help='the code to disassemble, read from stdin if omitted', nargs='?')\n    pwnypack.main.add_target_arguments(parser)\n    parser.add_argument(\n        '--syntax', '-s',\n        choices=AsmSyntax.__members__.keys(),\n        default=None,\n    )\n    parser.add_argument(\n        '--address', '-o',\n        type=lambda v: int(v, 0),\n        default=0,\n        help='the address of the disassembled code',\n    )\n    parser.add_argument(\n        '--format', '-f',\n        choices=['hex', 'bin'],\n        help='the input format (defaults to hex for commandline, bin for stdin)',\n    )\n\n    args = parser.parse_args(args)\n    target = pwnypack.main.target_from_arguments(args)\n    if args.syntax is not None:\n        syntax = AsmSyntax.__members__[args.syntax]\n    else:\n        syntax = None\n\n    if args.format is None:\n        if args.code is None:\n            args.format = 'bin'\n        else:\n            args.format = 'hex'\n\n    if args.format == 'hex':\n        code = pwnypack.codec.dehex(pwnypack.main.string_value_or_stdin(args.code))\n    else:\n        code = pwnypack.main.binary_value_or_stdin(args.code)\n\n    print('\\n'.join(disasm(code, args.address, syntax=syntax, target=target)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisassemble a symbol from an ELF file.", "response": "def disasm_symbol_app(_parser, _, args):  # pragma: no cover\n    \"\"\"\n    Disassemble a symbol from an ELF file.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n    parser.add_argument(\n        '--syntax', '-s',\n        choices=AsmSyntax.__members__.keys(),\n        default=None,\n    )\n    parser.add_argument('file', help='ELF file to extract a symbol from')\n    parser.add_argument('symbol', help='the symbol to disassemble')\n\n    args = parser.parse_args(args)\n    if args.syntax is not None:\n        syntax = AsmSyntax.__members__[args.syntax]\n    else:\n        syntax = None\n    elf = ELF(args.file)\n    symbol = elf.get_symbol(args.symbol)\n    print('\\n'.join(disasm(symbol.content, symbol.value, syntax=syntax, target=elf)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms the xml using the libxslt engine.", "response": "def _transform_libxslt(xml, xslt, params=None):\n    \"\"\"\n    Transform ``xslt`` using any of the 3 supported xslt engines:\n\n    - `lxml <http://codespeak.net/lxml/>`_\n    - `libxml <http://xmlsoft.org/python.html>`_\n\n    :param xml: The xml to be transformed.\n    :param xslt: The xslt to be used when transforming the ``xml``.\n    :param params: A dictionary containing xslt parameters. Use :func:`~easymode.xslt.prepare_string_param`\\\n        on strings you want to pass in.\n    \"\"\"\n    try:\n        xslt_doc = libxml2.parseFile(xslt)\n        xslt_proc = libxslt.parseStylesheetDoc(xslt_doc)\n        xml_doc = libxml2.parseDoc(xml)\n        \n        result = xslt_proc.applyStylesheet(xml_doc, params)\n\n        xml_string = str(result)\n        xml_unicode_string = xml_string.decode('utf-8')\n\n        xslt_proc.freeStylesheet()\n        xml_doc.freeDoc()\n\n        return xml_unicode_string\n    except RuntimeError as e:\n        raise XsltError(str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transform_lxml(xml, xslt_path, params=None):\n    # assuming params where created with prepare_string_param,\n    # they are encoded as unicode, which lxml does not like\n    \n    xml_doc = etree.fromstring(xml)\n    xslt_doc = etree.parse(xslt_path)\n    xslt_proc = etree.XSLT(xslt_doc)\n\n    if params:\n        for (key, value) in params.iteritems():\n            params[key] = value.decode('utf-8')\n        result = xslt_proc(xml_doc, **params)\n    else:\n        result = xslt_proc(xml_doc)\n    \n    return unicode(result)", "response": "Transform the xml using the lxml XSLT engine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering all models in the specified module with the admin.", "response": "def register_all(module, exclude=[], AdminClass=admin.ModelAdmin):\n    \"\"\"\n    Register all models in *module* with the admin\n    \n    :param module: The module that contains the models\n    :param exclude: A list of models classes that should not be registered\n    \"\"\"\n    member_names = dir(module)\n\n    for member_name in member_names:\n        obj = getattr(module, member_name, None)\n        if isinstance(obj, ModelBase) \\\n            and obj not in exclude \\\n            and not obj._meta.abstract:\n            try:\n                if hasattr(obj, 'localized_fields'):\n                    admin.site.register(obj, L10n(obj, AdminClass))\n                else:\n                    admin.site.register(obj, AdminClass)\n            except AlreadyRegistered:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef settingsAsFacts(self, settings):\n        pattern = re.compile('set\\(([a-zA-Z0-9_]+),(\\[a-zA-Z0-9_]+)\\)')\n        pairs = pattern.findall(settings)\n        for name, val in pairs:\n            self.set(name, val)", "response": "Parses a string of settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef induce(self, b, filestem='default',\n               examples=None,\n               pos=None,\n               neg=None,\n               cn2sd=True,\n               printOutput=False):\n        \"\"\"\n        Generate features and find subgroups.\n        \n            :param filestem: The base name of this experiment.\n            :param examples: Classified examples; can be used instead of separate pos / neg files below.\n            :param pos: String of positive examples.\n            :param neg: String of negative examples.\n            :param b: String with background knowledge.\n            :param cn2sd: Find subgroups after feature construction?\n\n            :return: a tuple ``(features, weka, rules)``, where:\n            - features is a set of prolog clauses of generated features,\n            - weka is the propositional form of the input data,\n            - rules is a set of generated cn2sd subgroup descriptions; \n              this will be an empty string if cn2sd is set to False.\n            :rtype: tuple\n        \"\"\"\n        # Write the inputs\n        self.__prepare(filestem, b, examples=examples, pos=pos, neg=neg)\n\n        # Write scripts\n        self.__scripts(filestem)\n\n        dumpFile = None\n        if not printOutput:\n            dumpFile = tempfile.TemporaryFile()\n\n        # Run the script\n        logger.info(\"Running RSD...\")\n        try:\n            for script in RSD.SCRIPTS:\n                # Skip subgroup discovery part?\n                if script == RSD.SUBGROUPS and not cn2sd:\n                    continue\n                p = SafePopen(['yap', '-s50000', '-h200000', '-L', script],\n                              cwd=self.tmpdir,\n                              stdout=dumpFile,\n                              stderr=dumpFile).safe_run()\n                stdout_str, stderr_str = p.communicate()\n                logger.debug(stdout_str)\n                logger.debug(stderr_str)\n            logger.info(\"Done.\")\n\n            # Return the rules written in the output file.\n            features = open('%s/%s' % (self.tmpdir, filestem + '_frs.pl')).read()\n            weka = open('%s/%s' % (self.tmpdir, filestem + '.arff')).read()\n            rules = open('%s/%s' % (self.tmpdir, filestem + '.rules')).read() if cn2sd else ''\n\n            self.__cleanup()\n            return (features, weka, rules)\n        except OSError:\n            raise RuntimeError(\"Yap compiler could not be loaded! (see http://www.dcc.fc.up.pt/~vsc/Yap/).\")", "response": "This function generates features and weka and rules for a single experiment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __prepare(self, filestem, b, examples=None, pos=None, neg=None):\n        if examples:\n            examplesFile = open('%s/%s.pl' % (self.tmpdir, filestem), 'w')\n            examplesFile.write(examples)\n            examplesFile.close()\n        elif pos and neg:\n            posFile = open('%s/%s.f' % (self.tmpdir, filestem), 'w')\n            negFile = open('%s/%s.n' % (self.tmpdir, filestem), 'w')\n            posFile.write(pos)\n            negFile.write(neg)\n            posFile.close()\n            negFile.close()\n        else:\n            raise Exception('You need to provide either a single file of classified examples or \\\n                two files, positive and negative examples.')\n        bFile = open('%s/%s.b' % (self.tmpdir, filestem), 'w')\n        # Write settings.\n        for setting, val in self.settings.items():\n            bFile.write(':- set(%s,%s).\\n' % (setting, val))\n        bFile.write(b)\n        bFile.close()", "response": "Prepares the needed files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __scripts(self, filestem):\n        script_construct = open('%s/%s' % (self.tmpdir, RSD.CONSTRUCT), 'w')\n        script_save = open('%s/%s' % (self.tmpdir, RSD.SAVE), 'w')\n        script_subgroups = open('%s/%s' % (self.tmpdir, RSD.SUBGROUPS), 'w')\n\n        # Permit the owner to execute and read this script\n        for fn in RSD.SCRIPTS:\n            os.chmod('%s/%s' % (self.tmpdir, fn), S_IREAD | S_IEXEC)\n\n        # Writes one line of script\n        new_script = lambda script: lambda x: script.write(x + '\\n')\n\n        #\n        # 'Construction' script\n        #\n        w = new_script(script_construct)\n        w(':- initialization(main).')\n        w('main :-')\n        w('[featurize],')\n        w('r(%s),' % filestem)\n        w('w.')\n        script_construct.close()\n\n        #\n        # 'Saving' script\n        #\n        w = new_script(script_save)\n        w(':- initialization(main).')\n        w('main :-')\n        w('[process],')\n        w('r(%s),' % filestem)\n        w('w,')\n        w('w(weka, %s),' % filestem)\n        w('w(rsd, %s).' % filestem)\n        script_save.close()\n\n        #\n        # 'Subgroups' script\n        #\n        w = new_script(script_subgroups)\n        w(':- initialization(main).')\n        w('main :-')\n        w('[rules],')\n        w('r(%s),' % filestem)\n        w('i,')\n        w('w.')\n        script_subgroups.close()", "response": "Generates the required scripts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a de Bruijn sequence of a given length and width.", "response": "def cycle(length, width=4):\n    \"\"\"\n    Generate a de Bruijn sequence of a given length (and width). A de Bruijn\n    sequence is a set of varying repetitions where each sequence of *n*\n    characters is unique within the sequence. This type of sequence can be\n    used to easily find the offset to the return pointer when exploiting a\n    buffer overflow.\n\n    Args:\n        length(int): The length of the sequence to generate.\n        width(int): The width of each element in the sequence.\n\n    Returns:\n        str: The sequence.\n\n    Example:\n        >>> from pwny import *\n        >>> cycle(80)\n        AAAABAAACAAADAAAEAAAFAAAGAAAHAAAIAAAJAAAKAAALAAAMAAANAAAOAAAPAAAQAAARAAASAAATAAA\n    \"\"\"\n\n    iter = deBruijn(width, 26)\n    return ''.join([chr(ord('A') + next(iter)) for i in range(length)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an element of a de Bruijn sequence find its index in that sequence.", "response": "def cycle_find(key, width=4):\n    \"\"\"\n    Given an element of a de Bruijn sequence, find its index in that sequence.\n\n    Args:\n        key(str): The piece of the de Bruijn sequence to find.\n        width(int): The width of each element in the sequence.\n\n    Returns:\n        int: The index of ``key`` in the de Bruijn sequence.\n    \"\"\"\n\n    key_len = len(key)\n    buf = ''\n\n    it = deBruijn(width, 26)\n\n    for i in range(key_len):\n        buf += chr(ord('A') + next(it))\n\n    if buf == key:\n        return 0\n\n    for i, c in enumerate(it):\n        buf = buf[1:] + chr(ord('A') + c)\n        if buf == key:\n            return i + 1\n\n    return -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles a regular hexpression of a set of control characters.", "response": "def reghex(pattern):\n    \"\"\"\n    Compile a regular hexpression (a short form regular expression subset\n    specifically designed for searching for binary strings).\n\n    A regular hexpression consists of hex tuples interspaced with control\n    characters. The available control characters are:\n\n    - ``?``: Any byte (optional).\n    - ``.``: Any byte (required).\n    - ``?{n}``: A set of 0 up to *n* bytes.\n    - ``.{n}``: A set of exactly *n* bytes.\n    - ``*``: Any number of bytes (or no bytes at all).\n    - ``+``: Any number of bytes (at least one byte).\n\n    Args:\n        pattern(str): The reghex pattern.\n\n    Returns:\n        regexp: A regular expression as returned by ``re.compile()``.\n    \"\"\"\n\n    if not reghex_check.match(pattern):\n        raise SyntaxError('Invalid reghex pattern.')\n\n    b_pattern = b''\n\n    for match in reghex_regex.finditer(pattern):\n        _, match_hex, _, match_char, match_char_len, match_star_plus = match.groups()\n        if match_hex:\n            b_pattern += re.escape(pwnypack.codec.dehex(match_hex))\n        elif match_char:\n            if match_char == '?':\n                if match_char_len is None:\n                    b_pattern += b'.?'\n                else:\n                    b_pattern += ('.{0,%d}?' % int(match_char_len[1:-1])).encode('ascii')\n            else:\n                if match_char_len is None:\n                    b_pattern += b'.'\n                else:\n                    b_pattern += b'.' * int(match_char_len[1:-1])\n        elif match_star_plus:\n            b_pattern += b'.' + match_star_plus.encode('ascii') + b'?'\n\n    try:\n        return re.compile(b_pattern)\n    except (TypeError, binascii.Error, re.error):\n        raise SyntaxError('Invalid reghex pattern.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cycle_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('-w', '--width', type=int, default=4, help='the length of the cycled value')\n    parser.add_argument('length', type=int, help='the cycle length to generate')\n    args = parser.parse_args(args)\n    return cycle(args.length, args.width)", "response": "Generate a de Bruijn sequence of a given length."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the first position of a value in a de Bruijn sequence.", "response": "def cycle_find_app(_parser, cmd, args):  # pragma: no cover\n    \"\"\"\n    Find the first position of a value in a de Bruijn sequence.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n    parser.add_argument('-w', '--width', type=int, default=4, help='the length of the cycled value')\n    parser.add_argument('value', help='the value to determine the position of, read from stdin if missing', nargs='?')\n    args = parser.parse_args(args)\n    index = cycle_find(pwnypack.main.string_value_or_stdin(args.value), args.width)\n    if index == -1:\n        print('Not found.')\n        sys.exit(1)\n    else:\n        print('Found at position: %d' % index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unescape_all(string):\n    def escape_single(matchobj):\n        return _unicode_for_entity_with_name(matchobj.group(1))\n    return entities.sub(escape_single, string)", "response": "Resolve all html entities to their corresponding unicode character"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid(xml_string):\n    xml_file = StringIO.StringIO(xml_string.encode('utf-8'))\n    \n    parser = XmlScanner()\n    parser.setContentHandler(ContentHandler())\n    try:\n        parser.parse(xml_file)\n    except SAXParseException:\n        return False\n    \n    return True", "response": "validates a unicode string containing xml"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_template_path(name):\n    global template_source_loaders\n    if template_source_loaders is None:\n        loaders = []\n        for loader_name in settings.TEMPLATE_LOADERS:\n            loader = find_template_loader(loader_name)\n            if loader is not None:\n                loaders.append(loader)\n        template_source_loaders = tuple(loaders)\n    for loader in template_source_loaders:\n        try:\n            _, display_name = loader(name)\n            if display_name:\n                return display_name\n        except TemplateDoesNotExist:\n            pass\n    raise TemplateDoesNotExist(name)", "response": "Find the path to the template file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_doc_from_docid(self, docid, doc_type_name=None, inst=True):\n        assert(docid is not None)\n        if docid in self._docs_by_id:\n            return self._docs_by_id[docid]\n        if not inst:\n            return None\n        doc = self.__inst_doc(docid, doc_type_name)\n        if doc is None:\n            return None\n        self._docs_by_id[docid] = doc\n        return doc", "response": "Try to find a document based on its document id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_doc_in_index(self, index_writer, doc):\n        all_labels = set(self.label_list)\n        doc_labels = set(doc.labels)\n        new_labels = doc_labels.difference(all_labels)\n\n        # can happen when we recreate the index from scratch\n        for label in new_labels:\n            self.create_label(label)\n\n        last_mod = datetime.datetime.fromtimestamp(doc.last_mod)\n        docid = str(doc.docid)\n\n        dochash = doc.get_docfilehash()\n        dochash = (u\"%X\" % dochash)\n\n        doc_txt = doc.get_index_text()\n        assert(isinstance(doc_txt, str))\n        labels_txt = doc.get_index_labels()\n        assert(isinstance(labels_txt, str))\n\n        # append labels to doc txt, because we usually search on doc_txt\n        doc_txt += \" \" + labels_txt\n\n        query = whoosh.query.Term(\"docid\", docid)\n        index_writer.delete_by_query(query)\n\n        index_writer.update_document(\n            docid=docid,\n            doctype=doc.doctype,\n            docfilehash=dochash,\n            content=strip_accents(doc_txt),\n            label=strip_accents(labels_txt),\n            date=doc.date,\n            last_read=last_mod\n        )\n        return True", "response": "Add or update a document in the index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a document from the index.", "response": "def _delete_doc_from_index(index_writer, docid):\n        \"\"\"\n        Remove a document from the index\n        \"\"\"\n        query = whoosh.query.Term(\"docid\", docid)\n        index_writer.delete_by_query(query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_doc(self, doc, index_update=True, label_guesser_update=True):\n        if not self.index_writer and index_update:\n            self.index_writer = self.index.writer()\n        if not self.label_guesser_updater and label_guesser_update:\n            self.label_guesser_updater = self.label_guesser.get_updater()\n        logger.info(\"Indexing new doc: %s\" % doc)\n        if index_update:\n            self._update_doc_in_index(self.index_writer, doc)\n        if label_guesser_update:\n            self.label_guesser_updater.add_doc(doc)\n        if doc.docid not in self._docs_by_id:\n            self._docs_by_id[doc.docid] = doc", "response": "Add a document to the index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a document in the index", "response": "def upd_doc(self, doc, index_update=True, label_guesser_update=True):\n        \"\"\"\n        Update a document in the index\n        \"\"\"\n        if not self.index_writer and index_update:\n            self.index_writer = self.index.writer()\n        if not self.label_guesser_updater and label_guesser_update:\n            self.label_guesser_updater = self.label_guesser.get_updater()\n        logger.info(\"Updating modified doc: %s\" % doc)\n        if index_update:\n            self._update_doc_in_index(self.index_writer, doc)\n        if label_guesser_update:\n            self.label_guesser_updater.upd_doc(doc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_doc(self, doc):\n        if not self.index_writer:\n            self.index_writer = self.index.writer()\n        if not self.label_guesser_updater:\n            self.label_guesser_updater = self.label_guesser.get_updater()\n        logger.info(\"Removing doc from the index: %s\" % doc)\n        if doc.docid in self._docs_by_id:\n            self._docs_by_id.pop(doc.docid)\n        if isinstance(doc, str):\n            # annoying case : we can't know which labels were on it\n            # so we can't roll back the label guesser training ...\n            self._delete_doc_from_index(self.index_writer, doc)\n            return\n        self._delete_doc_from_index(self.index_writer, doc.docid)\n        self.label_guesser_updater.del_doc(doc)", "response": "Delete a document from the index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommit the changes to the index and the label_guesser.", "response": "def commit(self, index_update=True, label_guesser_update=True):\n        \"\"\"\n        Apply the changes to the index\n        \"\"\"\n        logger.info(\"Index: Commiting changes\")\n        if self.index_writer:\n            if index_update:\n                self.index_writer.commit()\n            else:\n                self.index_writer.cancel()\n            del self.index_writer\n        self.index_writer = None\n\n        self.index.refresh()\n\n        if self.label_guesser:\n            if label_guesser_update and self.label_guesser_updater is not None:\n                self.label_guesser_updater.commit()\n            if index_update:\n                self.reload_searcher()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncanceling the current index update.", "response": "def cancel(self):\n        \"\"\"\n        Forget about the changes\n        \"\"\"\n        logger.info(\"Index: Index update cancelled\")\n        if self.index_writer:\n            self.index_writer.cancel()\n            del self.index_writer\n        self.index_writer = None\n        if self.label_guesser_updater:\n            self.label_guesser_updater.cancel()\n        self.label_guesser_updater = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a prediction of label names", "response": "def guess_labels(self, doc):\n        \"\"\"\n        return a prediction of label names\n        \"\"\"\n        if doc.nb_pages <= 0:\n            return set()\n        self.label_guesser.total_nb_documents = len(self._docs_by_id.keys())\n        label_names = self.label_guesser.guess(doc)\n        labels = set()\n        for label_name in label_names:\n            label = self.labels[label_name]\n            labels.add(label)\n        return labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a document or a page using its ID", "response": "def get(self, obj_id):\n        \"\"\"\n        Get a document or a page using its ID\n        Won't instantiate them if they are not yet available\n        \"\"\"\n        if BasicPage.PAGE_ID_SEPARATOR in obj_id:\n            (docid, page_nb) = obj_id.split(BasicPage.PAGE_ID_SEPARATOR)\n            page_nb = int(page_nb)\n            return self._docs_by_id[docid].pages[page_nb]\n        return self._docs_by_id[obj_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching the database for documents matching the given keywords.", "response": "def find_documents(self, sentence, limit=None, must_sort=True,\n                       search_type='fuzzy'):\n        \"\"\"\n        Returns all the documents matching the given keywords\n\n        Arguments:\n            sentence --- a sentenced query\n        Returns:\n            An array of document (doc objects)\n        \"\"\"\n        sentence = sentence.strip()\n        sentence = strip_accents(sentence)\n\n        if sentence == u\"\":\n            return self.get_all_docs()\n\n        result_list_list = []\n        total_results = 0\n\n        for query_parser in self.search_param_list[search_type]:\n            query = query_parser[\"query_parser\"].parse(sentence)\n\n            sortedby = None\n            if must_sort and \"sortedby\" in query_parser:\n                sortedby = query_parser['sortedby']\n            if sortedby:\n                results = self.__searcher.search(\n                    query, limit=limit, sortedby=sortedby\n                )\n            else:\n                results = self.__searcher.search(\n                    query, limit=limit\n                )\n            results = [\n                (result['docid'], result['doctype'])\n                for result in results\n            ]\n\n            result_list_list.append(results)\n            total_results += len(results)\n\n            if not must_sort and total_results >= limit:\n                break\n\n        # merging results\n        docs = set()\n        for result_intermediate in result_list_list:\n            for result in result_intermediate:\n                doc = self._docs_by_id.get(result[0])\n                if doc is None:\n                    continue\n                docs.add(doc)\n\n        docs = [d for d in docs]\n\n        if not must_sort and limit is not None:\n            docs = docs[:limit]\n\n        return docs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_suggestions(self, sentence):\n        if not isinstance(sentence, str):\n            sentence = str(sentence)\n\n        keywords = sentence.split(\" \")\n\n        query_parser = self.search_param_list['strict'][0]['query_parser']\n\n        base_search = u\" \".join(keywords).strip()\n        final_suggestions = []\n        corrector = self.__searcher.corrector(\"content\")\n        label_corrector = self.__searcher.corrector(\"label\")\n        for (keyword_idx, keyword) in enumerate(keywords):\n            if (len(keyword) <= MIN_KEYWORD_LEN):\n                continue\n            keyword_suggestions = label_corrector.suggest(\n                keyword, limit=2\n            )[:]\n            keyword_suggestions += corrector.suggest(keyword, limit=5)[:]\n            for keyword_suggestion in keyword_suggestions:\n                new_suggestion = keywords[:]\n                new_suggestion[keyword_idx] = keyword_suggestion\n                new_suggestion = u\" \".join(new_suggestion).strip()\n\n                if new_suggestion == base_search:\n                    continue\n\n                # make sure it would return results\n                query = query_parser.parse(new_suggestion)\n                results = self.__searcher.search(query, limit=1)\n                if len(results) <= 0:\n                    continue\n                final_suggestions.append(new_suggestion)\n        final_suggestions.sort()\n        return final_suggestions", "response": "Search all possible suggestions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new label and update the database with it", "response": "def create_label(self, label, doc=None):\n        \"\"\"\n        Create a new label\n\n        Arguments:\n            doc --- first document on which the label must be added (required\n                    for now)\n        \"\"\"\n        label = copy.copy(label)\n        assert(label not in self.labels.values())\n        self.labels[label.name] = label\n        self.label_guesser.load(label.name)\n        # TODO(Jflesch): Should train with previous documents\n        if doc:\n            doc.add_label(label)\n            self.upd_doc(doc)\n            self.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a label to a document.", "response": "def add_label(self, doc, label, update_index=True):\n        \"\"\"\n        Add a label on a document.\n\n        Arguments:\n            label --- The new label (see labels.Label)\n            doc --- The first document on which this label has been added\n        \"\"\"\n        label = copy.copy(label)\n        assert(label in self.labels.values())\n        doc.add_label(label)\n        if update_index:\n            self.upd_doc(doc)\n            self.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a label from a doc.", "response": "def remove_label(self, doc, label, update_index=True):\n        \"\"\"\n        Remove a label from a doc. Takes care of updating the index\n        \"\"\"\n        doc.remove_label(label)\n        if update_index:\n            self.upd_doc(doc)\n            self.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndestroys the index. Don't use this Index object anymore after this call. Index will have to be rebuilt from scratch", "response": "def destroy_index(self):\n        \"\"\"\n        Destroy the index. Don't use this Index object anymore after this\n        call. Index will have to be rebuilt from scratch\n        \"\"\"\n        self.close()\n        logger.info(\"Destroying the index ...\")\n        rm_rf(self.indexdir)\n        rm_rf(self.label_guesser_dir)\n        logger.info(\"Done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if there is a document using this file hash in the index.", "response": "def is_hash_in_index(self, filehash):\n        \"\"\"\n        Check if there is a document using this file hash\n        \"\"\"\n        filehash = (u\"%X\" % filehash)\n        results = self.__searcher.search(\n            whoosh.query.Term('docfilehash', filehash))\n        return bool(results)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preview(request, content_type_id, object_id):\n    \n    try:\n        content_type = ContentType.objects.get(pk=content_type_id)\n        obj = content_type.get_object_for_this_type(pk=object_id)\n    except ObjectDoesNotExist:\n        raise http.Http404(\"Content type %s object %s doesn't exist\" % (content_type_id, object_id))\n    try:\n        absolute_url = obj.get_absolute_url()\n    except AttributeError:\n        raise http.Http404(\"%s objects don't have get_absolute_url() methods\" % content_type.name)\n        \n    if absolute_url.startswith('http://') or absolute_url.startswith('https://'):        \n        http.HttpResponseRedirect(absolute_url)        \n    else:\n        absolute_url = fix_language_code(absolute_url, request.LANGUAGE_CODE)                \n        return http.HttpResponseRedirect(absolute_url)", "response": "This method is used to preview a single object in a content type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the flatpak tessdata directory.", "response": "def init_flatpak():\n    \"\"\"\n    If we are in Flatpak, we must build a tessdata/ directory using the\n    .traineddata files from each locale directory\n    \"\"\"\n    tessdata_files = glob.glob(\"/app/share/locale/*/*.traineddata\")\n    if len(tessdata_files) <= 0:\n        return os.path.exists(\"/app\")\n\n    localdir = os.path.expanduser(\"~/.local\")\n    base_data_dir = os.getenv(\n        \"XDG_DATA_HOME\",\n        os.path.join(localdir, \"share\")\n    )\n    tessdatadir = os.path.join(base_data_dir, \"paperwork\", \"tessdata\")\n\n    logger.info(\"Assuming we are running in Flatpak.\"\n                \" Building tessdata directory {} ...\".format(tessdatadir))\n    util.rm_rf(tessdatadir)\n    util.mkdir_p(tessdatadir)\n\n    os.symlink(\"/app/share/tessdata/eng.traineddata\",\n               os.path.join(tessdatadir, \"eng.traineddata\"))\n    os.symlink(\"/app/share/tessdata/osd.traineddata\",\n               os.path.join(tessdatadir, \"osd.traineddata\"))\n    os.symlink(\"/app/share/tessdata/configs\",\n               os.path.join(tessdatadir, \"configs\"))\n    os.symlink(\"/app/share/tessdata/tessconfigs\",\n               os.path.join(tessdatadir, \"tessconfigs\"))\n    for tessdata in tessdata_files:\n        logger.info(\"{} found\".format(tessdata))\n        os.symlink(tessdata, os.path.join(tessdatadir,\n                                          os.path.basename(tessdata)))\n    os.environ['TESSDATA_PREFIX'] = os.path.dirname(tessdatadir)\n    logger.info(\"Tessdata directory ready\")\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the fallback languages from the settings. py", "response": "def get_fallback_languages():\n    \"\"\"Retrieve the fallback languages from the settings.py\"\"\"\n    lang = translation.get_language()\n    fallback_list = settings.FALLBACK_LANGUAGES.get(lang, None)\n    if fallback_list:\n        return fallback_list\n\n    return settings.FALLBACK_LANGUAGES.get(lang[:2], [])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the localized property of a given field.", "response": "def get_localized_property(context, field=None, language=None):\n    '''\n    When accessing to the name of the field itself, the value\n    in the current language will be returned. Unless it's set,\n    the value in the default language will be returned.\n    '''\n    if language:\n        return getattr(context, get_real_fieldname(field, language))\n    \n    if hasattr(settings, 'FALLBACK_LANGUAGES'):\n        attrs = [translation.get_language()]\n        attrs += get_fallback_languages()\n    else:\n        attrs = [\n            translation.get_language(),\n            translation.get_language()[:2],\n            settings.LANGUAGE_CODE, \n        ]\n    \n    def predicate(x):\n        value = getattr(context, get_real_fieldname(field, x), None)\n        return value if valid_for_gettext(value) else None\n\n    return first_match(predicate, attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_localized_field_name(context, field):\n    attrs = [\n             translation.get_language(), \n             translation.get_language()[:2], \n             settings.LANGUAGE_CODE\n            ]\n            \n    def predicate(x):\n        field_name = get_real_fieldname(field, x)\n        if hasattr(context, field_name):\n            return field_name\n        return None\n\n    return first_match(predicate, attrs)", "response": "Get the name of the localized field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_field_from_model_by_name(model_class, field_name):\n    return first_match(lambda x: x if x.name == field_name else None, model_class._meta.fields)", "response": "Get a field from a model class by name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chkdeps(*args):\n    module_names = args\n    if len(module_names) <= 0:\n        error(\"No module specified\")\n        return\n    distribution = get_distribution()\n    for module_name in module_names:\n        _chkdeps(module_name, distribution)", "response": "Check for missing dependencies and install them using the local distribution package manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting help for all available commands.", "response": "def cmd_help(*args):\n    \"\"\"\n    Arguments: [<command>]\n    List available commands\n    \"\"\"\n    if len(args) == 0:\n        print(\"Possible commands are:\")\n        print(\"\")\n        for cmd_name in sorted(COMMANDS.keys()):\n            cmd_func = COMMANDS[cmd_name]\n            print(\"{}:\".format(cmd_name))\n            print(\"=\" * (len(cmd_name) + 1))\n            print(\"    {}\".format(cmd_func.__doc__.strip()))\n            print(\"\")\n    else:\n        cmd_name = args[0]\n        cmd_func = COMMANDS[cmd_name]\n        print(\"{}:\".format(cmd_name))\n        print(\"=\" * (len(cmd_name) + 1))\n        print(\"    {}\".format(cmd_func.__doc__.strip()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraining the SOM on the data and calibrate it.", "response": "def fit(self, data, labels, **kwargs):\n        \"\"\"\\\n        Training the SOM on the the data and calibrate itself.\n\n        After the training, `self.quant_error` and `self.topog_error` are \n        respectively set.\n\n        :param data: sparse input matrix (ideal dtype is `numpy.float32`)\n        :type data: :class:`scipy.sparse.csr_matrix`\n        :param labels: the labels associated with data\n        :type labels: iterable\n        :param \\**kwargs: optional parameters for :meth:`train`\n        \"\"\"\n        # train the network\n        self._som.train(data, **kwargs)\n        # retrieve first and second bmus and distances\n        bmus, q_error, t_error = self.bmus_with_errors(data)\n        # set errors measures of training data\n        self.quant_error = q_error\n        self.topog_error = t_error\n        # store training bmus\n        self._bmus = bmus\n        # calibrate\n        self._calibrate(data, labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalibrates the network using self. _bmus.", "response": "def _calibrate(self, data, labels):\n        \"\"\"\\\n        Calibrate the network using `self._bmus`.\n        \"\"\"\n        # network calibration\n        classifier = defaultdict(Counter)\n        for (i,j), label in zip(self._bmus, labels):\n            classifier[i,j][label] += 1\n        self.classifier = {}\n        for ij, cnt in classifier.items():\n            maxi = max(cnt.items(), key=itemgetter(1))\n            nb = sum(cnt.values())\n            self.classifier[ij] = maxi[0], maxi[1] / nb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npredicting the set of labels for the given data.", "response": "def predict(self, data, unkown=None):\n        \"\"\"\\\n        Classify data according to previous calibration.\n\n        :param data: sparse input matrix (ideal dtype is `numpy.float32`)\n        :type data: :class:`scipy.sparse.csr_matrix`\n        :param unkown: the label to attribute if no label is known\n        :returns: the labels guessed for data\n        :rtype: `numpy.array`\n        \"\"\"\n        assert self.classifier is not None, 'not calibrated'\n        bmus = self._som.bmus(data)\n        return self._predict_from_bmus(bmus, unkown)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_predict(self, data, labels, unkown=None):\n        self.fit(data, labels)\n        return self._predict_from_bmus(self._bmus, unkown)", "response": "Fit and classify data efficiently."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef histogram(self, bmus=None):\n        if bmus is None:\n            assert self._bmus is not None, 'not trained'\n            bmus = self._bmus\n        arr = np.zeros((self._som.nrows, self._som.ncols))\n        for i,j in bmus:\n            arr[i,j] += 1\n        return arr", "response": "\\ Returns a 2D histogram of the best - match units for underlying data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a suitable pickle protocol version for a given target.", "response": "def get_protocol_version(protocol=None, target=None):\n    \"\"\"\n    Return a suitable pickle protocol version for a given target.\n\n    Arguments:\n        target: The internals description of the targeted python\n            version. If this is ``None`` the specification of the currently\n            running python version will be used.\n        protocol(None or int): The requested protocol version (or None for the\n            default of the target python version).\n\n    Returns:\n        int: A suitable pickle protocol version.\n    \"\"\"\n\n    target = get_py_internals(target)\n\n    if protocol is None:\n        protocol = target['pickle_default_protocol']\n\n    if protocol > cPickle.HIGHEST_PROTOCOL:\n        warnings.warn('Downgrading pickle protocol, running python supports up to %d.' % cPickle.HIGHEST_PROTOCOL)\n        protocol = cPickle.HIGHEST_PROTOCOL\n\n    target_highest_protocol = target['pickle_highest_protocol']\n    if protocol > target_highest_protocol:\n        warnings.warn('Downgrading pickle protocol, target python supports up to %d.' % target_highest_protocol)\n        protocol = target_highest_protocol\n\n    return protocol"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npickles a function and arguments into a byte sequence.", "response": "def pickle_invoke(func, target=None, protocol=None, *args):\n    \"\"\"pickle_invoke(func, *args, target=None, protocol=None)\n\n    Create a byte sequence which when unpickled calls a callable with given\n    arguments.\n\n    Note:\n        The function has to be importable using the same name on the system\n        that unpickles this invocation.\n\n    Arguments:\n        func(callable): The function to call or class to instantiate.\n        args(tuple): The arguments to call the callable with.\n        target: The internals description of the targeted python\n            version. If this is ``None`` the specification of the currently\n            running python version will be used.\n        protocol: The pickle protocol version to use (use None for default).\n\n    Returns:\n        bytes: The data that when unpickled calls ``func(*args)``.\n\n    Example:\n        >>> from pwny import *\n        >>> import pickle\n        >>> def hello(arg):\n        ...     print('Hello, %s!' % arg)\n        ...\n        >>> pickle.loads(pickle_invoke(hello, 'world'))\n        Hello, world!\n    \"\"\"\n\n    protocol = get_protocol_version(protocol, target)\n    return cPickle.dumps(PickleInvoke(func, *args), protocol)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef translate_opcodes(code_obj, target):\n\n    target = get_py_internals(target)\n    src_ops = code_obj.disassemble()\n\n    dst_opmap = target['opmap']\n    dst_ops = []\n\n    op_iter = enumerate(src_ops)\n    for i, op in op_iter:\n        if isinstance(op, pwnypack.bytecode.Label):\n            dst_ops.append(op)\n            continue\n\n        if op.name not in dst_opmap:\n            if op.name == 'POP_JUMP_IF_FALSE' and 'JUMP_IF_TRUE' in dst_opmap:\n                lbl = pwnypack.bytecode.Label()\n                dst_ops.extend([\n                    pwnypack.bytecode.Op('JUMP_IF_TRUE', lbl),\n                    pwnypack.bytecode.Op('POP_TOP', None),\n                    pwnypack.bytecode.Op('JUMP_ABSOLUTE', op.arg),\n                    lbl,\n                    pwnypack.bytecode.Op('POP_TOP', None),\n                ])\n            elif op.name == 'POP_JUMP_IF_TRUE' and 'JUMP_IF_FALSE' in dst_opmap:\n                lbl = pwnypack.bytecode.Label()\n                dst_ops.extend([\n                    pwnypack.bytecode.Op('JUMP_IF_FALSE', lbl),\n                    pwnypack.bytecode.Op('POP_TOP', None),\n                    pwnypack.bytecode.Op('JUMP_ABSOLUTE', op.arg),\n                    lbl,\n                    pwnypack.bytecode.Op('POP_TOP', None),\n                ])\n            elif op.name == 'JUMP_IF_FALSE' and 'JUMP_IF_FALSE_OR_POP' in dst_opmap and \\\n                    src_ops[i + 1].name == 'POP_TOP':\n                next(op_iter)\n                dst_ops.append(pwnypack.bytecode.Op('JUMP_IF_FALSE_OR_POP', op.arg))\n            elif op.name == 'JUMP_IF_TRUE' and 'JUMP_IF_TRUE_OR_POP' in dst_opmap and \\\n                    src_ops[i + 1].name == 'POP_TOP':\n                next(op_iter)\n                dst_ops.append(pwnypack.bytecode.Op('JUMP_IF_TRUE_OR_POP', op.arg))\n            else:\n                raise SyntaxError('Opcode %s not supported on target.' % op.name)\n        else:\n            dst_ops.append(op)\n\n    code_obj.assemble(dst_ops, target)", "response": "Translate the opcode of a code object into a new opcode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pickle_func(func, target=None, protocol=None, b64encode=None, *args):\n\n    target = get_py_internals(target)\n\n    code = six.get_function_code(func)\n    code_obj = pwnypack.bytecode.CodeObject.from_code(code)\n    translate_opcodes(code_obj, target)\n\n    def code_reduce_v2(_):\n        if b64encode:\n            # b64encode co_code and co_lnotab as they contain 8bit data.\n            co_code = PickleInvoke(base64.b64decode, base64.b64encode(code_obj.co_code))\n            co_lnotab = PickleInvoke(base64.b64decode, base64.b64encode(code_obj.co_lnotab))\n        else:\n            co_code = code_obj.co_code\n            co_lnotab = code_obj.co_lnotab\n\n        if six.PY3:\n            # Encode unicode to bytes as python 2 doesn't support unicode identifiers.\n            co_names = tuple(n.encode('ascii') for n in code_obj.co_names)\n            co_varnames = tuple(n.encode('ascii') for n in code_obj.co_varnames)\n            co_filename = code_obj.co_filename.encode('ascii')\n            co_name = code_obj.co_name.encode('ascii')\n        else:\n            co_names = code_obj.co_names\n            co_varnames = code_obj.co_varnames\n            co_filename = code_obj.co_filename\n            co_name = code_obj.co_name\n\n        return types.CodeType, (code_obj.co_argcount, code_obj.co_nlocals, code_obj.co_stacksize, code_obj.co_flags,\n                                co_code, code_obj.co_consts, co_names, co_varnames, co_filename, co_name,\n                                code_obj.co_firstlineno, co_lnotab)\n\n    def code_reduce_v3(_):\n        if b64encode:\n            # b64encode co_code and co_lnotab as they contain 8bit data.\n            co_code = PickleInvoke(base64.b64decode, base64.b64encode(code_obj.co_code))\n            co_lnotab = PickleInvoke(base64.b64decode, base64.b64encode(code_obj.co_lnotab))\n        else:\n            co_code = code_obj.co_code\n            co_lnotab = code_obj.co_lnotab\n\n        return types.CodeType, (code_obj.co_argcount, code_obj.co_kwonlyargcount, code_obj.co_nlocals,\n                                code_obj.co_stacksize, code_obj.co_flags, co_code, code_obj.co_consts,\n                                code_obj.co_names, code_obj.co_varnames, code_obj.co_filename, code_obj.co_name,\n                                code_obj.co_firstlineno, co_lnotab)\n\n    # Stubs to trick cPickle into pickling calls to CodeType/FunctionType.\n    class CodeType(object):  # pragma: no cover\n        pass\n    CodeType.__module__ = 'types'\n    CodeType.__qualname__ = 'CodeType'\n\n    class FunctionType(object):  # pragma: no cover\n        pass\n    FunctionType.__module__ = 'types'\n    FunctionType.__qualname__ = 'FunctionType'\n\n    protocol = get_protocol_version(protocol, target)\n\n    old_code_reduce = copyreg.dispatch_table.pop(types.CodeType, None)\n    if target['version'] < 300:\n        copyreg.pickle(types.CodeType, code_reduce_v2)\n    else:\n        if six.PY2:\n            if b64encode is False:\n                warnings.warn('Enabling b64encode, pickling from python 2 to 3.')\n            b64encode = True\n        copyreg.pickle(types.CodeType, code_reduce_v3)\n\n    # This has an astonishing level of evil just to convince pickle to pickle CodeType and FunctionType:\n    old_code_type, types.CodeType = types.CodeType, CodeType\n    old_function_type, types.FunctionType = types.FunctionType, FunctionType\n\n    try:\n        build_func = PickleInvoke(types.FunctionType, code, PickleInvoke(globals))\n        return cPickle.dumps(PickleInvoke(build_func, *args), protocol)\n    finally:\n        types.CodeType = old_code_type\n        types.FunctionType = old_function_type\n\n        if old_code_reduce is not None:\n            copyreg.pickle(types.CodeType, old_code_reduce)\n        else:\n            del copyreg.dispatch_table[types.CodeType]", "response": "Pickles a function in such a way that it s unpickled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding extra attributes in value if they are there", "response": "def find_extra_attrs(value):\n    \"finds extra attributes in *value* if they are there\"\n    extra = None\n    value_is_from_database = True\n\n    if hasattr(value, 'standin_value_is_from_database'):\n        value_is_from_database = value.standin_value_is_from_database\n\n        if value.stored_value != value.msg:\n            extra = value.msg\n        elif value.stored_value != value.fallback:\n            extra = value.fallback\n    \n    return extra, value_is_from_database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering a set of entities based on method return. Use keyword arguments.", "response": "def filtany(entities, **kw):\n  \"\"\"Filter a set of entities based on method return. Use keyword arguments.\n  \n  Example:\n    filtmeth(entities, id='123')\n    filtmeth(entities, name='bart')\n\n  Multiple filters are 'OR'.\n  \"\"\"\n  ret = set()\n  for k,v in kw.items():\n    for entity in entities:\n      if getattr(entity, k)() == v:\n        ret.add(entity)\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filtfirst(entities, **kw):\n  ret = sorted(filtany(entities, **kw), key=lambda x:x.id())\n  if not ret:\n    raise ValueError('No result')\n  return ret[0]", "response": "Return the first matching entity sorted by id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a print friendly stack trace at the current frame.", "response": "def stack_trace(depth=None):\n    \"\"\"\n    returns a print friendly stack trace at the current frame,\n    without aborting the application.\n    \n    :param depth: The depth of the stack trace. if omitted, the entire\n        stack will be printed.\n    \n    usage::\n    \n        print stack_trace(10)\n    \"\"\"\n    frames = inspect.stack()[2:]\n    if depth:\n        frames = frames[:depth]\n        \n    result = StringIO()\n    result.write(\"----------------------------------------------------\\n\")\n    for (frame, file, line, context, code, status) in frames:\n        result.write(\"In %s from %s\\n%s %s\" % (context, file, line, \"\\n\".join(code)))\n        result.write(\"----------------------------------------------------\\n\")        \n    return result.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stops(self):\n    serves = set()\n    for trip in self.trips():\n      for stop_time in trip.stop_times():\n        serves |= stop_time.stops()\n    return serves", "response": "Return a set of stops served by this route."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pack(fmt, *args, **kwargs):\n\n    endian, target = kwargs.get('endian'), kwargs.get('target')\n    endian = endian if endian is not None else target.endian if target is not None else pwnypack.target.target.endian\n    if fmt and fmt[0] not in '@=<>!':\n        if endian is pwnypack.target.Target.Endian.little:\n            fmt = '<' + fmt\n        elif endian is pwnypack.target.Target.Endian.big:\n            fmt = '>' + fmt\n        else:\n            raise NotImplementedError('Unsupported endianness: %s' % endian)\n    return struct.pack(fmt, *args)", "response": "Pack the values v1 v2... according to the format string fmt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunpack the string according to the given format string.", "response": "def unpack(fmt, data, endian=None, target=None):\n    \"\"\"\n    Unpack the string (presumably packed by pack(fmt, ...)) according to the\n    given format. The actual unpacking is performed by ``struct.unpack``\n    but the byte order will be set according to the given `endian`, `target`\n    or byte order of the global target.\n\n    Args:\n        fmt(str): The format string.\n        data(bytes): The data to unpack.\n        endian(:class:`~pwnypack.target.Target.Endian`): Override the default\n            byte order. If ``None``, it will look at the byte order of\n            the ``target`` argument.\n        target(:class:`~pwnypack.target.Target`): Override the default byte\n            order. If ``None``, it will look at the byte order of\n            the global :data:`~pwnypack.target.target`.\n\n    Returns:\n        list: The unpacked values according to the format.\n    \"\"\"\n\n    endian = endian if endian is not None else target.endian if target is not None else pwnypack.target.target.endian\n    if fmt and fmt[0] not in '@=<>!':\n        if endian is pwnypack.target.Target.Endian.little:\n            fmt = '<' + fmt\n        elif endian is pwnypack.target.Target.Endian.big:\n            fmt = '>' + fmt\n        else:\n            raise NotImplementedError('Unsupported endianness: %s' % endian)\n    return struct.unpack(fmt, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the number of bits to pack or unpack.", "response": "def _get_bits(bits=None, target=None):\n    \"\"\"\n    Determine the number of bits to pack/unpack.\n    \"\"\"\n\n    if bits is not None:\n        bits = int(bits)\n        if bits in (8, 16, 32, 64):\n            return bits\n        else:\n            raise ValueError('bits needs to be 8, 16, 32 or 64')\n    else:\n        return int((target if target is not None else pwnypack.target.target).bits)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef P(value, bits=None, endian=None, target=None):\n\n    return globals()['P%d' % _get_bits(bits, target)](value, endian=endian, target=target)", "response": "Pack an unsigned pointer for a given target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npack a signed pointer for a given target.", "response": "def p(value, bits=None, endian=None, target=None):\n    \"\"\"\n    Pack a signed pointer for a given target.\n\n    Args:\n        value(int): The value to pack.\n        bits(:class:`pwnypack.target.Target.Bits`): Override the default\n            word size. If ``None`` it will look at the word size of\n            ``target``.\n        endian(:class:`~pwnypack.target.Target.Endian`): Override the default\n            byte order. If ``None``, it will look at the byte order of\n            the ``target`` argument.\n        target(:class:`~pwnypack.target.Target`): Override the default byte\n            order. If ``None``, it will look at the byte order of\n            the global :data:`~pwnypack.target.target`.\n    \"\"\"\n\n    return globals()['p%d' % _get_bits(bits, target)](value, endian=endian, target=target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef U(data, bits=None, endian=None, target=None):\n\n    return globals()['U%d' % _get_bits(bits, target)](data, endian=endian, target=target)", "response": "Unpack an unsigned pointer for a given target."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef u(data, bits=None, endian=None, target=None):\n\n    return globals()['u%d' % _get_bits(bits, target)](data, endian=endian, target=target)", "response": "Unpack a signed pointer for a given target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trips(self):\n    trips = set()\n    for route in self.routes():\n      trips |= route.trips()\n    return trips", "response": "Return all trips for this agency."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stops(self):\n    stops = set()\n    for stop_time in self.stop_times():\n      stops |= stop_time.stops()\n    return stops", "response": "Return all stops visited by trips for this agency."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all stop_times for this agency.", "response": "def stop_times(self):\n    \"\"\"Return all stop_times for this agency.\"\"\"\n    stop_times = set()\n    for trip in self.trips():\n      stop_times |= trip.stop_times()\n    return stop_times"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_boxes(self):\n        if self.__boxes is not None:\n            return self.__boxes\n\n        # Check first if there is an OCR file available\n        boxfile = self.__get_box_path()\n        if self.fs.exists(boxfile):\n            box_builder = pyocr.builders.LineBoxBuilder()\n\n            try:\n                with self.fs.open(boxfile, 'r') as file_desc:\n                    self.__boxes = box_builder.read_file(file_desc)\n                return self.__boxes\n            except IOError as exc:\n                logger.error(\"Unable to get boxes for '%s': %s\"\n                             % (self.doc.docid, exc))\n                # will fall back on pdf boxes\n\n        # fall back on what libpoppler tells us\n\n        txt = self.pdf_page.get_text()\n        self.__boxes = []\n\n        layout = self.pdf_page.get_text_layout()\n        if not layout[0]:\n            layout = []\n            return self.__boxes\n        layout = layout[1]\n\n        for (line, line_rects) in custom_split(\n            txt, layout, lambda x: x == \"\\n\"\n        ):\n            words = []\n            for (word, word_rects) in custom_split(\n                line, line_rects, lambda x: x.isspace()\n            ):\n                word_box = PdfWordBox(word, word_rects)\n                words.append(word_box)\n            line_box = PdfLineBox(words, line_rects)\n            self.__boxes.append(line_box)\n        return self.__boxes", "response": "Get all the word boxes of this page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef destroy(self):\n        logger.info(\"Destroying doc: %s\" % self.path)\n        self.fs.rm_rf(self.path)\n        logger.info(\"Done\")", "response": "Delete the entire document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_label(self, to_remove):\n        if to_remove not in self.labels:\n            return\n        labels = self.labels\n        labels.remove(to_remove)\n        with self.fs.open(self.fs.join(self.path, self.LABEL_FILE), 'w') \\\n                as file_desc:\n            for label in labels:\n                file_desc.write(\"%s,%s\\n\" % (label.name,\n                                             label.get_color_str()))", "response": "Removes a label from the document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __get_labels(self):\n        labels = []\n        try:\n            with self.fs.open(self.fs.join(self.path, self.LABEL_FILE),\n                                'r') as file_desc:\n                for line in file_desc.readlines():\n                    line = line.strip()\n                    (label_name, label_color) = line.split(\",\", 1)\n                    labels.append(Label(name=label_name,\n                                        color=label_color))\n        except IOError:\n            pass\n        return labels", "response": "Read the label file of the documents and extract all the labels\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the labels of the related resources.", "response": "def __set_labels(self, labels):\n        \"\"\"\n        Add a label on the document.\n        \"\"\"\n        with self.fs.open(self.fs.join(self.path, self.LABEL_FILE), 'w') \\\n                as file_desc:\n            for label in labels:\n                file_desc.write(\"%s,%s\\n\" % (label.name,\n                                             label.get_color_str()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_label(self, old_label, new_label):\n        logger.info(\"%s : Updating label ([%s] -> [%s])\"\n                    % (str(self), old_label.name, new_label.name))\n        labels = self.labels\n        try:\n            labels.remove(old_label)\n        except ValueError:\n            # this document doesn't have this label\n            return\n\n        logger.info(\"%s : Updating label ([%s] -> [%s])\"\n                    % (str(self), old_label.name, new_label.name))\n        labels.append(new_label)\n        with self.fs.open(self.fs.join(self.path, self.LABEL_FILE), 'w') \\\n                as file_desc:\n            for label in labels:\n                file_desc.write(\"%s,%s\\n\" % (label.name,\n                                             label.get_color_str()))", "response": "Update a label by replacing old_label by new_label"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __doc_cmp(self, other):\n        if other is None:\n            return -1\n        if self.is_new and other.is_new:\n            return 0\n        if self.__docid < other.__docid:\n            return -1\n        elif self.__docid == other.__docid:\n            return 0\n        else:\n            return 1", "response": "Comparison function. Can be used to sort docs alphabetically."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_name(self):\n        if self.is_new:\n            return _(\"New document\")\n        try:\n            split = self.__docid.split(\"_\")\n            short_docid = \"_\".join(split[:3])\n            datetime_obj = datetime.datetime.strptime(\n                short_docid, self.DOCNAME_FORMAT)\n            final = datetime_obj.strftime(\"%x\")\n            return final\n        except Exception as exc:\n            logger.error(\"Unable to parse document id [%s]: %s\"\n                         % (self.docid, exc))\n            return self.docid", "response": "Returns the localized name of the document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a PO object into a unicode string.", "response": "def po_to_unicode(po_obj):\n    \"\"\"\n    Turns a polib :class:`polib.PoFile` or a :class:`polib.PoEntry` \n    into a :class:`unicode` string.\n    \n    :param po_obj: Either a :class:`polib.PoFile` or :class:`polib.PoEntry`.\n    :rtype: :class:`unicode` string.\n    \"\"\"\n    po_text = po_obj.__str__()\n    if type(po_text) != types.UnicodeType:\n        po_text = po_text.decode('utf-8')\n    \n    return po_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arff_to_orange_table(arff):\n    '''\n    Convert a string in arff format to an Orange table.\n\n        :param arff: string in arff format\n\n        :return: Orange data table object constructed from the arff string\n        :rtype: orange.ExampleTable\n    '''\n    with tempfile.NamedTemporaryFile(suffix='.arff', delete=True) as f:\n        f.write(arff)\n        f.flush()\n        table = orange.ExampleTable(f.name)\n        return table", "response": "Convert a string in arff format to an Orange data table object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all language codes defined in settings. LANGUAGES and also the MSGID_LANGUAGE if defined.", "response": "def get_all_language_codes():\n    \"\"\"\n    Returns all language codes defined in settings.LANGUAGES and also the\n    settings.MSGID_LANGUAGE if defined.\n    \n    >>> from django.conf import settings\n    >>> settings.MSGID_LANGUAGE = 'en-us'\n    >>> settings.LANGUAGES = (('en','English'),('de','German'),('nl-be','Belgium dutch'),('fr-be','Belgium french'),)\n    >>> sorted( get_language_codes() )\n    ['en-us', 'en','de', 'nl-be','fr-be']\n    \n    :rtype: A :class:`list` of language codes.\n    \"\"\"\n    languages = get_language_codes()\n    if hasattr(settings, 'MSGID_LANGUAGE'):\n        if not settings.MSGID_LANGUAGE in languages:\n            languages.insert(0, settings.MSGID_LANGUAGE)\n            \n    return languages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_language_code(url, current_language):\n    stripped_url = strip_language_code(url)\n    if not getattr(settings, 'MASTER_SITE', False) and len(settings.LANGUAGES) == 1:\n        # no MASTER_SITE and only one language, do not add language code to url\n        return stripped_url\n    \n    # add the language code to the url        \n    return u\"/%s%s\" % (get_shorthand_from_language_code(current_language), stripped_url)", "response": "Fixes the language code in the url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef localize_fieldnames(fields, internationalized_fields):\n    result = []\n    lang = get_language()    \n    for field in fields:\n        if field in internationalized_fields:\n            result.append(get_real_fieldname(field, lang))\n        else:\n            result.append(field)    \n    return result", "response": "Given a list of fields and a list of internationalized fields will return a list with the actual field names that are localized."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn a django model into a po file.", "response": "def poify(self, model):\n        \"\"\"turn a django model into a po file.\"\"\"\n        if not hasattr(model, 'localized_fields'):\n            return None\n\n        # create po stream with header\n        po_stream = polibext.PoStream(StringIO.StringIO(self.po_header)).parse()\n\n        for (name, field) in easymode.tree.introspection.get_default_field_descriptors(model):\n            occurrence = u\"%s.%s.%s\" % (model._meta.app_label, model.__class__.__name__, name)\n            value = field.value_to_string(model)\n\n            # only add empty strings\n            if value != \"\":\n                entry = polib.POEntry(msgid=value, occurrences=[(occurrence, model.pk)])\n                # make sure no duplicate entries in the po_stream\n                existing_entry = po_stream.find(entry.msgid)\n                if existing_entry is None:\n                    po_stream.append(entry)\n                else:\n                    # no really, existing_entry.merge does not merge the occurrences.\n                    existing_entry.occurrences += entry.occurrences\n\n        return po_stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xgettext(self, template):\n\n        cmd = 'xgettext -d django -L Python --keyword=gettext_noop \\\n            --keyword=gettext_lazy --keyword=ngettext_lazy:1,2 --from-code=UTF-8 \\\n            --output=- -'\n\n        p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        (msg, err) = p.communicate(input=templatize(template))\n\n        if err:\n            # dont raise exception, some stuff in stderr are just warmings\n            logging.warning(err)\n\n        if XGETTEXT_REENCODES_UTF8:\n            return msg.decode('utf-8').encode('iso-8859-1')\n\n        return msg", "response": "Extracts to be translated strings from template and turns it into po format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef msgmerge(self, locale_file, po_string):\n\n        cmd = \"msgmerge -q %s -\" % locale_file\n        p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        (msg, err) = p.communicate(input=po_string)\n\n        if err:\n            # dont raise exception, some stuff in stderr are just warmings\n            logging.warning(\"%s \\nfile: %s\\npostring: %s\" % (err, locale_file, po_string))\n\n        return msg", "response": "Runs msgmerge on a locale_file and po_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun msguniq on the locale_file", "response": "def msguniq(self, locale_file):\n        \"\"\"\n        run msgunique on the locale_file\n        \"\"\"\n\n        # group related language strings together.\n        # except if no real entries where written or the header will be removed.\n        p = subprocess.Popen('msguniq --to-code=utf-8 %s' % (locale_file,),\n            shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE )\n        (msg, err) = p.communicate()\n\n        if err:\n            # raise exception, none of the stuff in stderr are just warmings\n            logging.error(err)\n            try:\n                err = unicodedata.normalize('NFKD', err.decode('utf-8')).encode('ascii','ignore')\n            except UnicodeError:\n                err = \"can not decode error message\"\n            raise CommandError(\n                u\"error happened while running msguniq on: %s %s\" % \\\n                    (locale_file, err)\n            )\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _utf8(value):\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\n            \"Expected bytes, unicode, or None; got %r\" % type(value)\n        )\n    return value.encode(\"utf-8\")", "response": "Converts a string argument to a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a string argument to a unicode string.", "response": "def _unicode(value):\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes_type):\n        raise TypeError(\n            \"Expected bytes, unicode, or None; got %r\" % type(value)\n        )\n    return value.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk a simple data structure converting unicode to byte string.", "response": "def to_utf8(obj):\n    \"\"\"Walks a simple data structure, converting unicode to byte string.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, unicode_type):\n        return _utf8(obj)\n    elif isinstance(obj, dict):\n        return dict((to_utf8(k), to_utf8(v)) for (k, v) in obj.items())\n    elif isinstance(obj, list):\n        return list(to_utf8(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(to_utf8(i) for i in obj)\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd_add_label(docid, label_name, color=None):\n    dsearch = get_docsearch()\n    doc = dsearch.get(docid)\n    if doc is None:\n        raise Exception(\n            \"Document {} not found. Cannot add label on it\".format(\n                docid\n            )\n        )\n\n    label = None\n    for clabel in dsearch.label_list:\n        if clabel.name == label_name:\n            label = clabel\n            break\n    if not label and not color:\n        raise Exception(\n            \"Label {} doesn't exist yet, and no color has been provided\".format(\n                label_name\n            )\n        )\n    if not label:\n        label = Label(label_name, color)\n        dsearch.create_label(label)\n\n    dsearch.add_label(doc, label)\n    verbose(\"Label {} added on document {}\".format(\n        label_name, docid\n    ))\n    reply({\n        \"docid\": docid,\n        \"label\": label_name,\n    })", "response": "Adds a label on a document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the content of a document.", "response": "def cmd_dump(docid, page_nb=None):\n    \"\"\"\n    Arguments: <document id> [<page number>]\n\n    Dump the content of the specified document.\n    Beware, page numbers start from 1.\n    See 'search' for the document ids.\n\n    Replies with page content.\n    Beware: This is the only command not replying in JSON format.\n    \"\"\"\n    dsearch = get_docsearch()\n    doc = dsearch.get(docid)\n    pages = doc.pages\n    pages = [page for page in pages]\n    if page_nb:\n        page_nb = int(page_nb)\n        pages = pages[page_nb - 1:page_nb]\n    for page in pages:\n        verbose(\"=== Page {} ===\".format(page.page_nb + 1))\n        _dump_page(page)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd_export_all(*args):\n    (output_dir, quality, page_format) = _get_export_params(args)\n\n    dsearch = get_docsearch()\n\n    try:\n        os.mkdir(output_dir)\n    except FileExistsError:  # NOQA (Python 3.x only)\n        pass\n\n    out = []\n\n    docs = [d for d in dsearch.docs]\n    docs.sort(key=lambda doc: doc.docid)\n    output_dir = FS.safe(output_dir)\n    for (doc_idx, doc) in enumerate(docs):\n        output_pdf = FS.join(output_dir, doc.docid + \".pdf\")\n\n        exporter = doc.build_exporter(file_format=\"pdf\")\n        if exporter.can_change_quality:\n            exporter.set_quality(quality)\n        if exporter.can_select_format:\n            exporter.set_page_format(page_format)\n        verbose(\n            \"[{}/{}] Exporting {} --> {} ...\".format(\n                doc_idx + 1, len(docs), doc.docid, output_pdf\n            )\n        )\n        exporter.save(output_pdf)\n        out.append((doc.docid, output_pdf))\n        doc = None\n        gc.collect()\n\n    verbose(\"Done\")\n    reply({\n        \"docids\": out,\n        \"output_dir\": output_dir,\n    })", "response": "Export all documents as PDF files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd_export_doc(*args):\n    (docid, output_pdf, quality, page_format) = _get_export_params(args)\n\n    dsearch = get_docsearch()\n    doc = dsearch.get(docid)\n\n    exporter = doc.build_exporter(file_format=\"pdf\")\n    if exporter.can_change_quality:\n        exporter.set_quality(quality)\n    if exporter.can_select_format:\n        exporter.set_page_format(page_format)\n    verbose(\"Exporting {} --> {} ...\".format(docid, output_pdf))\n    output_pdf = FS.safe(output_pdf)\n    exporter.save(output_pdf)\n    verbose(\"Done\")\n    r = {\n        \"docid\": doc.docid,\n        \"output_file\": output_pdf,\n    }\n    if exporter.can_change_quality:\n        r['quality'] = quality\n    if exporter.can_select_format:\n        r['page_format'] = page_format\n    reply(r)", "response": "Export one document as a PDF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd_guess_labels(*args):\n    args = list(args)\n\n    apply_labels = False\n    if \"--apply\" in args:\n        apply_labels = True\n        args.remove(\"--apply\")\n    docid = args[0]\n\n    dsearch = get_docsearch()\n    doc = dsearch.get(docid)\n    if doc is None:\n        raise Exception(\n            \"Document {} not found. Cannot guess labels\".format(\n                docid\n            )\n        )\n\n    verbose(\"Current labels: {}\".format(\n        \", \".join([label.name for label in doc.labels])\n    ))\n\n    guessed = dsearch.guess_labels(doc)\n\n    verbose(\"Guessed labels: {}\".format(\n        \", \".join([label.name for label in guessed])\n    ))\n\n    r = {\n        'docid': doc.docid,\n        'current_labels': [label.name for label in doc.labels],\n        'guessed_labels': [label.name for label in guessed],\n        'applied': \"yes\" if apply_labels else \"no\",\n    }\n\n    changed = False\n    if apply_labels:\n        for label in guessed:\n            if label not in doc.labels:\n                dsearch.add_label(doc, label, update_index=False)\n                changed = True\n        for label in doc.labels:\n            if label not in guessed:\n                dsearch.remove_label(doc, label, update_index=False)\n                changed = True\n\n    if changed:\n        index_updater = dsearch.get_index_updater(optimize=False)\n        index_updater.upd_doc(doc)\n        index_updater.commit()\n        verbose(\"Document {} updated\".format(docid))\n    elif apply_labels:\n        verbose(\"Document {} unchanged\".format(docid))\n    reply(r)", "response": "Guess the labels that should be set on the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd_remove_label(docid, label_name):\n    dsearch = get_docsearch()\n    doc = dsearch.get(docid)\n    if doc is None:\n        raise Exception(\n            \"Document {} not found. Cannot remove label from it\".format(\n                docid\n            )\n        )\n\n    for clabel in dsearch.label_list:\n        if clabel.name == label_name:\n            label = clabel\n    else:\n        raise Exception(\"Unknown label {}\".format(label_name))\n\n    dsearch.remove_label(doc, label)\n    verbose(\"Label {} removed from document {}\".format(label_name, docid))\n    reply({\n        \"docid\": docid,\n        \"labels\": [l.name for l in doc.labels],\n    })", "response": "Remove a label from a document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenames a document in the current language.", "response": "def cmd_rename(old_docid, new_docid):\n    \"\"\"\n    Arguments: <current document_id> <new document_id>\n\n    Change the ID of a document.\n\n    Note that the document id are also their date.\n    Using an ID that is not a date may have side effects\n    (the main one being the document won't be sorted correctly).\n\n    Possible JSON replies:\n        --\n        {\n            \"status\": \"error\", \"exception\": \"yyy\",\n            \"reason\": \"xxxx\", \"args\": \"(xxxx, )\"\n        }\n        --\n        {\n            \"status\": \"ok\",\n            \"old_docid\": \"xxxx\",\n            \"new_docid\": \"yyyy\",\n        }\n    \"\"\"\n    dsearch = get_docsearch()\n    doc = dsearch.get(old_docid)\n    if doc is None:\n        raise Exception(\n            \"Document {} not found. Cannot remove label from it\".format(\n                old_docid\n            )\n        )\n\n    index_updater = dsearch.get_index_updater(optimize=False)\n\n    # just clone the in-memory data, not the on-disk content\n    clone = doc.clone()\n\n    # so we can change the ID safely\n    doc.docid = new_docid\n\n    index_updater.del_doc(clone)\n    index_updater.add_doc(doc)\n    index_updater.commit()\n\n    verbose(\"Document {} renamed into {}\".format(old_docid, new_docid))\n    reply({\n        \"old_docid\": old_docid,\n        \"new_docid\": new_docid\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for the documents in the specified language.", "response": "def cmd_search(*args):\n    \"\"\"\n    Arguments: <keyword1> [<keyword2> [<keyword3> [...]]]\n\n    List the documents containing the keywords.\n\n    Syntax is the same than with the search field in Paperwork-gui.\n    Search \"\" (empty string) to get all the documents.\n\n    Example: 'label:contrat AND paperwork'\n\n    Possible JSON replies:\n        --\n        {\n            \"status\": \"error\", \"exception\": \"yyy\",\n            \"reason\": \"xxxx\", \"args\": \"(xxxx, )\"\n        }\n        --\n        {\n            \"status\": \"ok\",\n            \"results\" [\n                {\"docid\": \"xxxx\", \"nb_pages\": 22, \"labels\": [\"xxx\", \"yyy\"]}\n                {\"docid\": \"yyyy\", \"nb_pages\": 22, \"labels\": [\"xxx\", \"yyy\"]}\n                {\"docid\": \"zzzz\", \"nb_pages\": 22, \"labels\": [\"xxx\", \"yyy\"]}\n            ],\n        }\n    \"\"\"\n    dsearch = get_docsearch()\n\n    verbose(\"Search: {}\".format(\" \".join(args)))\n\n    r = {'results': []}\n\n    docs = dsearch.find_documents(\" \".join(args))\n    docs.sort(key=lambda doc: doc.docid)\n    for doc in docs:\n        r['results'].append({\n            'docid': doc.docid,\n            'nb_pages': doc.nb_pages,\n            'labels': [l.name for l in doc.labels],\n        })\n    reply(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nswitches the current paperwork s work directory.", "response": "def cmd_switch_workdir(new_workdir):\n    \"\"\"\n    Arguments: <new work directory path>\n\n    Change current Paperwork's work directory.\n\n    Does *not* update the index.\n    You should run 'paperwork-shell rescan' after this command.\n\n    Possible JSON replies:\n        --\n        {\n            \"status\": \"error\", \"exception\": \"yyy\",\n            \"reason\": \"xxxx\", \"args\": \"(xxxx, )\"\n        }\n        --\n        {\n            \"status\": \"ok\",\n            \"old_workdir\": \"file:///home/jflesch/papers\",\n            \"new_workdir\": \"file:///tmp/papers\",\n        }\n    \"\"\"\n    new_workdir = FS.safe(new_workdir)\n    if not FS.exists(new_workdir) or not FS.isdir(new_workdir):\n        sys.stderr.write(\"New work directory {} doesn't exists\".format(\n            new_workdir\n        ))\n        return\n    pconfig = config.PaperworkConfig()\n    pconfig.read()\n    r = {\n        'old_workdir': pconfig.settings['workdir'].value,\n        'new_workdir': new_workdir\n    }\n    pconfig.settings['workdir'].value = new_workdir\n    pconfig.write()\n    reply(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setPostScript(self, goal, script):\n        self.postGoal = goal\n        self.postScript = script", "response": "After learning call the given script using goal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninducing a theory or features in mode.", "response": "def induce(self, mode, pos, neg, b, filestem='default', printOutput=False):\n        \"\"\"\n        Induce a theory or features in 'mode'.\n\n            :param filestem: The base name of this experiment.\n            :param mode: In which mode to induce rules/features.\n            :param pos: String of positive examples.\n            :param neg: String of negative examples.\n            :param b: String of background knowledge.\n\n            :return: The theory as a string or an arff dataset in induce_features mode.\n            :rtype: str\n\n        \"\"\"\n        # Write the inputs to appropriate files.\n        self.__prepare(filestem, pos, neg, b)\n\n        # Make a script to run aleph (with appropriate settings).\n        self.__script(mode, filestem)\n\n        logger.info(\"Running aleph...\")\n\n        dumpFile = None\n        if not printOutput:\n            dumpFile = tempfile.TemporaryFile()\n\n        # Run the aleph script.\n        p = SafePopen(['yap', '-s50000', '-h200000', '-L', Aleph.SCRIPT],\n                      cwd=self.tmpdir,\n                      stdout=dumpFile,\n                      stderr=dumpFile\n                      ).safe_run()\n        stdout_str, stderr_str = p.communicate()\n\n        logger.info(\"Done.\")\n\n        result = None\n        if mode != 'induce_features':\n            # Return the rules written in the output file.\n            rules_fn = filestem + Aleph.RULES_SUFFIX\n            result = open('%s/%s' % (self.tmpdir, rules_fn)).read()\n            features = None\n        else:\n            features_fn = filestem + Aleph.FEATURES_SUFFIX\n            features = open('%s/%s' % (self.tmpdir, features_fn)).read()\n            dataset_fn = filestem + Aleph.PROP_DATASET_SUFFIX\n            pl_dataset = open('%s/%s' % (self.tmpdir, dataset_fn)).read()\n            result = self.__to_arff(features, pl_dataset, filestem)\n\n        # Cleanup.\n        self.__cleanup()\n        return (result, features)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the needed files.", "response": "def __prepare(self, filestem, pos, neg, b):\n        \"\"\"\n        Prepares the needed files.\n        \"\"\"\n        posFile = open('%s/%s.f' % (self.tmpdir, filestem), 'w')\n        negFile = open('%s/%s.n' % (self.tmpdir, filestem), 'w')\n        bFile = open('%s/%s.b' % (self.tmpdir, filestem), 'w')\n\n        posFile.write(pos)\n        negFile.write(neg)\n        bFile.write(b)\n\n        posFile.close()\n        negFile.close()\n        bFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the script file for the Aleph.", "response": "def __script(self, mode, filestem):\n        \"\"\"\n        Makes the script file to be run by yap.\n        \"\"\"\n        scriptPath = '%s/%s' % (self.tmpdir, Aleph.SCRIPT)\n        script = open(scriptPath, 'w')\n\n        # Permit the owner to execute and read this script\n        os.chmod(scriptPath, S_IREAD | S_IEXEC)\n\n        cat = lambda x: script.write(x + '\\n')\n        cat(\":- initialization(run_aleph).\")\n        cat(\"run_aleph :- \")\n        cat(\"consult(aleph),\")\n        cat(\"read_all('%s'),\" % filestem)\n        # Cat all the non-default settings\n        for setting, value in self.settings.items():\n            cat(\"set(%s, %s),\" % (setting, str(value)))\n        cat(\"%s,\" % mode)\n\n        eof = ',' if self.postScript else '.'\n        if mode == 'induce_features':\n            cat(\"consult(features),\")\n            features_fn = filestem + Aleph.FEATURES_SUFFIX\n            dataset_fn = filestem + Aleph.PROP_DATASET_SUFFIX\n            cat('save_features(%s),' % features_fn)\n            cat('save_dataset(%s)%s' % (dataset_fn, eof))\n        else:\n            rules_fn = filestem + Aleph.RULES_SUFFIX\n            cat(\"write_rules('%s')%s\" % (rules_fn, eof))\n        if self.postScript:\n            cat(self.postGoal + \".\")\n            cat(self.postScript)\n        script.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw(request):\n    foos = foobar_models.Foo.objects.all()\n    return HttpResponse(tree.xml(foos), mimetype='text/xml')", "response": "shows untransformed hierarchical xml output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows how the XmlQuerySetChain can be used instead of toxml decorator", "response": "def chain(request):\n    \"\"\"shows how the XmlQuerySetChain can be used instead of @toxml decorator\"\"\"\n    bars = foobar_models.Bar.objects.all()\n    bazs = foobar_models.Baz.objects.all()\n    qsc = XmlQuerySetChain(bars, bazs)\n    return HttpResponse(tree.xml(qsc), mimetype='text/xml')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xslt(request):\n    foos = foobar_models.Foo.objects.all()\n    return render_xslt_to_response('xslt/model-to-xml.xsl', foos, mimetype='text/xml')", "response": "Shows xml output transformed with standard xslt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_hist(self, bins=None, density=True, folded=False, weight=\"duration\"):\n        #Step 1: get the right pitch values\n        assert isinstance(self.pitch_obj.pitch, np.ndarray)\n        valid_pitch = self.pitch_obj.pitch\n        valid_pitch = [i for i in valid_pitch if i > -10000]\n        if folded:\n            valid_pitch = map(lambda x: int(x % 1200), valid_pitch)\n\n        #Step 2: based on the weighing scheme, compute the histogram\n        if weight == \"duration\":\n            #Step 2.1 set the number of bins (if not passed)\n            if not bins:\n                bins = max(valid_pitch) - min(valid_pitch)\n            n, bin_edges = np.histogram(valid_pitch, bins, density=density)\n            bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n            self.histogram = Data(bin_centers, n)\n        elif weight == \"instance\":\n            n = {}\n            i = 1\n            while i < len(valid_pitch) - 1:\n                if (valid_pitch[i] - valid_pitch[i - 1] != 0) and \\\n                        (valid_pitch[i + 1] - valid_pitch[i] == 0):\n                    if valid_pitch[i] in n.keys():\n                        n[valid_pitch[i]] += 1\n                    else:\n                        n[valid_pitch[i]] = 1\n                i += 1\n            n = n.items()\n            n.sort(key=lambda x: x[0])\n            n = np.array(n)\n            self.histogram = Data(n[:, 0], n[:, 1])\n\n            median_diff = np.median(np.diff(n[:, 0]))\n            bin_edges = [n[0, 0] - median_diff/2]\n            bin_edges.extend(median_diff/2 + n[:, 0])\n            n[:, 1] = n[:, 1]/(n[:, 1].sum()*np.diff(bin_edges))\n            self.histogram = Data(n[:, 0], n[:, 1], default_smooth=False)", "response": "Compute the histogram from the pitch data and creates a new object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parametrize_peaks(self, intervals, max_peakwidth=50, min_peakwidth=25, symmetric_bounds=True):\n        assert isinstance(self.pitch_obj.pitch, np.ndarray)\n        valid_pitch = self.pitch_obj.pitch\n        valid_pitch = [i for i in valid_pitch if i > -10000]\n        valid_pitch = np.array(valid_pitch)\n\n        parameters = {}\n        for i in xrange(len(self.histogram.peaks[\"peaks\"][0])):\n            peak_pos = self.histogram.peaks[\"peaks\"][0][i]\n            #Set left and right bounds of the distribution.\n            max_leftbound = peak_pos - max_peakwidth\n            max_rightbound = peak_pos + max_peakwidth\n            leftbound = max_leftbound\n            rightbound = max_rightbound\n            nearest_valleyindex = utils.find_nearest_index(self.histogram.peaks[\"valleys\"][0], peak_pos)\n            if peak_pos > self.histogram.peaks[\"valleys\"][0][nearest_valleyindex]:\n                leftbound = self.histogram.peaks[\"valleys\"][0][nearest_valleyindex]\n                if len(self.histogram.peaks[\"valleys\"][0][nearest_valleyindex + 1:]) == 0:\n                    rightbound = peak_pos + max_peakwidth\n                else:\n                    offset = nearest_valleyindex + 1\n                    nearest_valleyindex = utils.find_nearest_index(\n                        self.histogram.peaks[\"valleys\"][0][offset:], peak_pos)\n                    rightbound = self.histogram.peaks[\"valleys\"][0][offset + nearest_valleyindex]\n            else:\n                rightbound = self.histogram.peaks[\"valleys\"][0][nearest_valleyindex]\n                if len(self.histogram.peaks[\"valleys\"][0][:nearest_valleyindex]) == 0:\n                    leftbound = peak_pos - max_peakwidth\n                else:\n                    nearest_valleyindex = utils.find_nearest_index(\n                        self.histogram.peaks[\"valleys\"][0][:nearest_valleyindex], peak_pos)\n                    leftbound = self.histogram.peaks[\"valleys\"][0][nearest_valleyindex]\n\n            #In terms of x-axis, leftbound should be at least min_peakwidth\n            # less than peak_pos, and at max max_peakwidth less than peak_pos,\n            # and viceversa for the rightbound.\n            if leftbound < max_leftbound:\n                leftbound = max_leftbound\n            elif leftbound > peak_pos - min_peakwidth:\n                leftbound = peak_pos - min_peakwidth\n\n            if rightbound > max_rightbound:\n                rightbound = max_rightbound\n            elif rightbound < peak_pos + min_peakwidth:\n                rightbound = peak_pos + min_peakwidth\n\n            #If symmetric bounds are asked for, then make the bounds symmetric\n            if symmetric_bounds:\n                if peak_pos - leftbound < rightbound - peak_pos:\n                    imbalance = (rightbound - peak_pos) - (peak_pos - leftbound)\n                    rightbound -= imbalance\n                else:\n                    imbalance = (peak_pos - leftbound) - (rightbound - peak_pos)\n                    leftbound += imbalance\n\n            #extract the distribution and estimate the parameters\n            distribution = valid_pitch[valid_pitch >= leftbound]\n            distribution = distribution[distribution <= rightbound]\n            #print peak_pos, \"\\t\", len(distribution), \"\\t\", leftbound, \"\\t\", rightbound\n\n            interval_index = utils.find_nearest_index(intervals, peak_pos)\n            interval = intervals[interval_index]\n            _mean = float(np.mean(distribution))\n            _variance = float(variation(distribution))\n            _skew = float(skew(distribution))\n            _kurtosis = float(kurtosis(distribution))\n            pearson_skew = float(3.0 * (_mean - peak_pos) / np.sqrt(abs(_variance)))\n            parameters[interval] = {\"position\": float(peak_pos),\n                                    \"mean\": _mean,\n                                    \"amplitude\": float(self.histogram.peaks[\"peaks\"][1][i]),\n                                    \"variance\": _variance,\n                                    \"skew1\": _skew,\n                                    \"skew2\": pearson_skew,\n                                    \"kurtosis\": _kurtosis}\n\n        self.intonation_profile = parameters", "response": "Computes and stores the intonation profile of the audio recording."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef label_contours(self, intervals, window=150, hop=30):\n        window /= 1000.0\n        hop /= 1000.0\n        exposure = int(window / hop)\n\n        boundary = window - hop\n        final_index = utils.find_nearest_index(self.pitch_obj.timestamps,\n                                               self.pitch_obj.timestamps[-1] - boundary)\n\n        interval = np.median(np.diff(self.pitch_obj.timestamps))\n        #interval = 0.00290254832393\n        window_step = window / interval\n        hop_step = hop / interval\n        start_index = 0\n        end_index = window_step\n        contour_labels = {}\n        means = []\n        while end_index < final_index:\n            temp = self.pitch_obj.pitch[start_index:end_index][self.pitch_obj.pitch[start_index:end_index] > -10000]\n            means.append(np.mean(temp))\n            start_index = start_index + hop_step\n            end_index = start_index + window_step\n\n        for i in xrange(exposure, len(means) - exposure + 1):\n            _median = np.median(means[i - exposure:i])\n            if _median < -5000:\n                continue\n            ind = utils.find_nearest_index(_median, intervals)\n            contour_end = (i - exposure) * hop_step + window_step\n            contour_start = contour_end - hop_step\n            #print sliceBegin, sliceEnd, JICents[ind]\n            #newPitch[sliceBegin:sliceEnd] = JICents[ind]\n            if intervals[ind] in contour_labels.keys():\n                contour_labels[intervals[ind]].append([contour_start, contour_end])\n            else:\n                contour_labels[intervals[ind]] = [[contour_start, contour_end]]\n\n        self.contour_labels = contour_labels", "response": "This function labels the contours with the given intervals."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_contour_labels(self, new_fig=True):\n        timestamps = []\n        pitch = []\n\n        if new_fig:\n            p.figure()\n        for interval, contours in self.contour_labels.items():\n            for contour in contours:\n                x = self.pitch_obj.timestamps[contour[0]:contour[1]]\n                y = [interval]*len(x)\n                timestamps.extend(x)\n                pitch.extend(y)\n\n        data = np.array([timestamps, pitch]).T\n        data = np.array(sorted(data, key=lambda xx: xx[0]))\n        p.plot(data[:, 0], data[:, 1], 'g-')", "response": "Plots the labelled contours!"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield n successive chunks from l.", "response": "def chunks(l, n):\n    \"\"\" Yield n successive chunks from l.\n    \"\"\"\n    newn = int(1.0 * len(l) / n + 0.5)\n    for i in range(0, n - 1):\n        yield l[i * newn:i * newn + newn]\n    yield l[n * newn - newn:]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wordify_example(name_to_table, connecting_tables, context, cached_sentences, index_by_value, target_table_name,\n                    word_att_length, data_name, ex, searched_connections):\n    \"\"\"\n    Recursively constructs the 'wordification' document for the given example.\n\n        :param data: The given examples ExampleTable\n        :param ex: Example for which the document is constructed\n    \"\"\"\n    debug = False\n    data_name = str(data_name)\n\n    if debug:\n        print(\"======================================\")\n        print(\"example:\", ex)\n        print(\"table name:\", data_name)\n        print(\"searched_connections:\", len(searched_connections), searched_connections)\n        print(\"connecting_tables:\", len(connecting_tables[data_name]), connecting_tables[data_name])\n\n    ex_pkey_value = data_name in context.pkeys and ex[str(context.pkeys[data_name])]\n\n    if not data_name in cached_sentences or not str(ex_pkey_value) in cached_sentences[data_name]:\n\n        words = []  # word list for every example\n        if debug:\n            print(\"words:\", len(words))\n        # Construct words (tableName_attributeName_attributeValue) from the given table\n        for att in name_to_table[data_name].domain.attributes:\n            if not str(att.name) in context.pkeys[data_name] and not str(att.name) in context.fkeys[data_name]:\n                words.append(att_to_s(data_name) + \"_\" + att_to_s(att.name) + \"_\" + att_to_s(ex[att]))\n\n        # Words from pairs of attributes\n        single_words = words[:]\n        for comb_length in range(word_att_length + 1):\n            if comb_length > 1:\n                words.extend([\"__\".join(sorted(b)) for b in itertools.combinations(single_words, comb_length)])\n\n        # Apply the wordification methodology recursively on all connecting tables\n        for sec_t_name, sec_fkey, prim_fkey in connecting_tables[data_name]:\n            sec_t = name_to_table[sec_t_name]\n            if debug:\n                print(\"------------------\")\n                print(\"(sec_t,sec_fkey,prim):\", (sec_t_name, sec_fkey, prim_fkey))\n                print(\"search this table:\", not (sec_t_name,\n                                                 sec_fkey) in searched_connections and sec_t_name != target_table_name)\n                print(\"search this table:\", not prim_fkey or not (data_name,\n                                                                  sec_fkey) in searched_connections)  # and sec_t!=self.target_table\n            if not (sec_t_name, sec_fkey) in searched_connections and sec_t_name != target_table_name and (\n                        not prim_fkey or not (data_name, sec_fkey) in searched_connections):\n                example_indexes = index_by_value[sec_t_name][str(sec_fkey)][str(ex_pkey_value)] if not prim_fkey else \\\n                    index_by_value[sec_t_name][str(prim_fkey)][str(ex[str(sec_fkey)])]\n\n                for sec_ex_idx in example_indexes:\n                    words += wordify_example(name_to_table, connecting_tables, context, cached_sentences,\n                                             index_by_value, target_table_name, word_att_length, sec_t_name,\n                                             sec_t[sec_ex_idx], searched_connections | set(\n                            [(sec_t_name, sec_fkey), prim_fkey and (data_name, prim_fkey)]))\n\n        cached_sentences[data_name][str(ex_pkey_value)] = words\n\n    return cached_sentences[data_name][str(ex_pkey_value)]", "response": "This function creates a wordification document for the given example."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, num_of_processes=multiprocessing.cpu_count()):\n\n        # class + wordification on every example of the main table\n\n        p = multiprocessing.Pool(num_of_processes)\n\n        indices = chunks(list(range(len(self.target_table))), num_of_processes)  # )\n\n        for ex_idxs in indices:\n            self.resulting_documents.extend(wordify_examples(self.name_to_table, self.connecting_tables, self.context,\n                                                             self.index_by_value, self.target_table.name,\n                                                             self.word_att_length, ex_idxs))\n        p.close()\n        p.join()\n\n        for i, ex in enumerate(self.target_table):\n            self.resulting_classes.append(ex.get_class())", "response": "Applies the wordification methodology on the target table\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the tf - idf values for words in every document.", "response": "def calculate_weights(self, measure='tfidf'):\n        \"\"\"\n        Counts word frequency and calculates tf-idf values for words in every document.\n\n            :param measure: example weights approach (can be one of ``tfidf, binary, tf``).\n        \"\"\"\n        from math import log\n\n        # TODO replace with spipy matrices (and calculate with scikit)\n\n        if measure == 'tfidf':\n            self.calculate_idf()\n\n        for doc_idx, document in enumerate(self.resulting_documents):\n            train_word_count = defaultdict(int)\n            self.tf_idfs[doc_idx] = {}\n            for word in document:\n                train_word_count[word] += 1\n\n            for word in document:\n                if measure == \"binary\":\n                    tf = 1\n                    idf = 1\n                else:\n                    tf = train_word_count[word]\n                    idf = 1 if measure == \"tf\" else (self.idf[word] if word in self.idf else None)\n\n                if idf != None:\n                    self.tf_idfs[doc_idx][word] = tf * idf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the wordified representation in ARFF.", "response": "def to_arff(self):\n        '''\n        Returns the \"wordified\" representation in ARFF.\n\n            :rtype: str\n        '''\n        arff_string = \"@RELATION \" + self.target_table.name + \"\\n\\n\"\n        words = set()\n        for document in self.resulting_documents:\n            for word in document:\n                words.add(word)\n        words = sorted(words)\n\n        for i, word in enumerate(words):\n            arff_string += \"@ATTRIBUTE '\" + word.replace(\"'\", \"\") + \"' REAL\\n\"\n\n        arff_string += \"@ATTRIBUTE class {\" + ','.join(set([str(a) for a in self.resulting_classes])) + \"}\\n\\n@DATA\\n\"\n\n        self.word_features = []\n        for doc_idx in range(len(self.resulting_documents)):\n            features = []\n            for word in words:\n                if word not in self.word_features:\n                    self.word_features.append(word)\n                if word in self.tf_idfs[doc_idx]:\n                    features.append(str(self.tf_idfs[doc_idx][word]))\n                else:\n                    features.append(\"0\")\n            features.append(str(self.resulting_classes[doc_idx]))\n\n            arff_string += ','.join(features)\n            arff_string += \"\\n\"\n\n        return arff_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prune(self, minimum_word_frequency_percentage=1):\n        pruned_resulting_documents = []\n\n        for document in self.resulting_documents:\n            new_document = []\n            for word in document:\n                if self.word_in_how_many_documents[word] >= minimum_word_frequency_percentage / 100. * len(\n                        self.resulting_documents):\n                    new_document.append(word)\n            pruned_resulting_documents.append(new_document)\n        self.resulting_documents = pruned_resulting_documents", "response": "Remove words that occur less than minimum_word_frequency times."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wordify(self):\n        string_documents = []\n        for klass, document in zip(self.resulting_classes, self.resulting_documents):\n            string_documents.append(\"!\" + str(klass) + \" \" + '' .join(document))\n        return '\\n'.join(string_documents)", "response": "Constructs a string of all documents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nasm_mutable_data_finalizer(env, code, data):\n\n    if env.target.bits == 32:\n        get_pc = [\n            '\\tcall __getpc0',\n            '__getpc0:',\n            '\\tpop %s' % env.OFFSET_REG,\n            '\\tadd %s, __data - __getpc0' % env.OFFSET_REG,\n            '__realstart:',\n        ]\n    else:\n        get_pc = ['\\tlea %s, [rel __data]' % env.OFFSET_REG]\n\n    if data or env.buffers:\n        return get_pc + code + _pack_data(data)\n    else:\n        return code", "response": "This function is used to finalize the mutable data allocation strategy that expects the code to be in a writable\n    segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nasm_null_safe_mutable_data_finalizer(env, code, data):\n\n    if data or env.buffers:\n        # Determine length of nullify + shellcode and adjust data pointer\n        xor_offsets = []\n        masked_data = OrderedDict()\n\n        for datum, (offset, orig_datum) in six.iteritems(data):\n            xor_offsets.extend([\n                                   offset + i\n                                   for i, b in enumerate(six.iterbytes(datum))\n                                   if b in (0, 10, 13)\n                                   ])\n\n            masked_datum = b''.join([\n                                        six.int2byte(b) if b not in (0, 10, 13)\n                                        else six.int2byte(b ^ 0xff)\n                                        for b in six.iterbytes(datum)\n                                        ])\n            masked_data[masked_datum] = (offset, orig_datum)\n\n        if xor_offsets:\n            # Build code to restore NUL, \\r and \\n\n            temp_reg = env.TEMP_REG[env.target.bits]\n            null_code = env.reg_load(env.BL, 255) + \\\n                        env.reg_load(temp_reg, env.OFFSET_REG)\n\n            last_offset = 0\n            for offset in xor_offsets:\n                offset -= last_offset\n                null_code.extend(\n                    env.reg_add(temp_reg, offset) +\n                    ['xor [%s], bl' % temp_reg]\n                )\n                last_offset += offset\n            code = ['\\t%s' % line for line in null_code] + code\n            data = masked_data\n\n        code_len = len(asm('\\n'.join(code), target=env.target))\n        adjust_ebp = env.reg_add(env.OFFSET_REG, code_len)\n\n        return [\n            '\\tjmp __getpc1',\n            '__getpc0:',\n            '\\tpop %s' % env.OFFSET_REG,\n        ] + [\n            '\\t%s' % line for line in adjust_ebp\n        ] + [\n            '\\tjmp __realstart',\n            '__getpc1:',\n            '\\tcall __getpc0',\n            '__realstart:',\n        ] + code + _pack_data(data)\n    else:\n        return code", "response": "This function is used to restore null - safe mutable data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns value or raw data from stdin or return raw data from stdin.", "response": "def binary_value_or_stdin(value):\n    \"\"\"\n    Return fsencoded value or read raw data from stdin if value is None.\n    \"\"\"\n    if value is None:\n        reader = io.open(sys.stdin.fileno(), mode='rb', closefd=False)\n        return reader.read()\n    elif six.PY3:\n        return os.fsencode(value)\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates symlinks for pwny apps.", "response": "def symlink(parser, cmd, args):\n    \"\"\"\n    Set up symlinks for (a subset of) the pwny apps.\n    \"\"\"\n\n    parser.add_argument(\n        'apps',\n        nargs=argparse.REMAINDER,\n        help='Which apps to create symlinks for.'\n    )\n    args = parser.parse_args(args)\n\n    base_dir, pwny_main = os.path.split(sys.argv[0])\n\n    for app_name, config in MAIN_FUNCTIONS.items():\n        if not config['symlink'] or (args.apps and app_name not in args.apps):\n            continue\n        dest = os.path.join(base_dir, app_name)\n        if not os.path.exists(dest):\n            print('Creating symlink %s' % dest)\n            os.symlink(pwny_main, dest)\n        else:\n            print('Not creating symlink %s (file already exists)' % dest)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __label_cmp(self, other):\n        if other is None:\n            return -1\n\n        label_name = strip_accents(self.name).lower()\n        other_name = strip_accents(other.name).lower()\n        if label_name < other_name:\n            return -1\n        elif label_name == other_name:\n            return 0\n        else:\n            return 1\n\n        if self.get_color_str() < other.get_color_str():\n            return -1\n        elif self.get_color_str() == other.get_color_str():\n            return 0\n        else:\n            return 1", "response": "Comparaison function. Can be used to sort labels alphabetically."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_html_color(self):\n        color = self.color\n        return (\"#%02x%02x%02x\" % (\n            int(color.red), int(color.green), int(color.blue)\n        ))", "response": "get a string representing the color using HTML notation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forget(self, label_name):\n        self._bayes.pop(label_name)\n        baye_dir = self._get_baye_dir(label_name)\n        logger.info(\"Deleting label training {} : {}\".format(\n            label_name, baye_dir\n        ))\n        rm_rf(baye_dir)", "response": "Forget training for label label_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrename a label training class.", "response": "def rename(self, old_label_name, new_label_name):\n        \"\"\"\n        Take into account that a label has been renamed\n        \"\"\"\n        assert(old_label_name != new_label_name)\n        self._bayes.pop(old_label_name)\n        old_baye_dir = self._get_baye_dir(old_label_name)\n        new_baye_dir = self._get_baye_dir(new_label_name)\n        logger.info(\"Renaming label training {} -> {} : {} -> {}\".format(\n            old_label_name, new_label_name, old_baye_dir, new_baye_dir\n        ))\n        os.rename(old_baye_dir, new_baye_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_filepath(self, ext):\n        filename = (\"%s%d.%s\" % (self.FILE_PREFIX, self.page_nb + 1, ext))\n        return self.fs.join(self.doc.path, filename)", "response": "Returns a file path relative to this page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __make_thumbnail(self, width, height):\n        (w, h) = self.size\n        factor = max(\n            (float(w) / width),\n            (float(h) / height)\n        )\n        w /= factor\n        h /= factor\n        return self.get_image((round(w), round(h)))", "response": "Create the page s thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_thumbnail(self, width, height):\n        # get from the file\n        thumb_path = self._get_thumb_path()\n        try:\n            doc_file_path = self.get_doc_file_path()\n\n            if (self.fs.exists(thumb_path) and\n                    self.fs.getmtime(doc_file_path) <\n                    self.fs.getmtime(thumb_path)):\n                with self.fs.open(thumb_path, 'rb') as fd:\n                    thumbnail = PIL.Image.open(fd)\n                    thumbnail.load()\n                if thumbnail.size[0] == width or thumbnail.size[1] == height:\n                    # fills the specified area\n                    return thumbnail\n                logger.warning(\n                    \"[%s] Unexpected thumbnail size: %s instead of %s ;\"\n                    \" Updating thumbnail ...\",\n                    str(self.doc.docid), str(thumbnail.size),\n                    str((width, height))\n                )\n        except Exception as exc:\n            logger.warning(\n                \"[%s] Failed to check doc and thumbnail mdate. Forcing update\"\n                \" of the thumbnail\", str(self.doc.docid), exc_info=exc\n            )\n\n        logger.info(\"[%s] Updating thumbnail ...\", str(self.doc.docid))\n        thumbnail = self.__make_thumbnail(width, height)\n        with self.fs.open(thumb_path, 'wb') as fd:\n            thumbnail.save(fd, format=\"JPEG\")\n\n        return thumbnail", "response": "Returns the thumbnail of the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the keywords related to this page", "response": "def __get_keywords(self):\n        \"\"\"\n        Get all the keywords related of this page\n\n        Returns:\n            An array of strings\n        \"\"\"\n        txt = self.text\n        for line in txt:\n            for word in split_words(line):\n                yield(word)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_accents(string):\n    return u''.join(\n        (character for character in unicodedata.normalize('NFD', string)\n         if unicodedata.category(character) != 'Mn'))", "response": "Strip all the accents from the string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract and yield the keywords from the given sentence.", "response": "def split_words(sentence, modify=True, keep_shorts=False):\n    \"\"\"\n    Extract and yield the keywords from the sentence:\n    - Drop keywords that are too short (keep_shorts=False)\n    - Drop the accents (modify=True)\n    - Make everything lower case (modify=True)\n    - Try to separate the words as much as possible (using 2 list of\n      separators, one being more complete than the others)\n    \"\"\"\n    if (sentence == \"*\"):\n        yield sentence\n        return\n\n    # TODO: i18n\n    if modify:\n        sentence = sentence.lower()\n        sentence = strip_accents(sentence)\n\n    words = FORCED_SPLIT_KEYWORDS_REGEX.split(sentence)\n    if keep_shorts:\n        word_iter = words\n    else:\n        word_iter = __cleanup_word_array(words)\n    for word in word_iter:\n        can_split = True\n        can_yield = False\n        subwords = WISHED_SPLIT_KEYWORDS_REGEX.split(word)\n        for subword in subwords:\n            if subword == \"\":\n                continue\n            can_yield = True\n            if not keep_shorts and len(subword) < MIN_KEYWORD_LEN:\n                can_split = False\n                break\n        if can_split:\n            for subword in subwords:\n                if subword == \"\":\n                    continue\n                if subword[0] == '\"':\n                    subword = subword[1:]\n                if subword[-1] == '\"':\n                    subword = subword[:-1]\n                yield subword\n        elif can_yield:\n            if word[0] == '\"':\n                word = word[1:]\n            if word[-1] == '\"':\n                word = word[:-1]\n            yield word"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the spelling in the text and compute a score.", "response": "def check_spelling(spelling_lang, txt):\n    \"\"\"\n    Check the spelling in the text, and compute a score. The score is the\n    number of words correctly (or almost correctly) spelled, minus the number\n    of mispelled words. Words \"almost\" correct remains neutral (-> are not\n    included in the score)\n\n    Returns:\n        A tuple : (fixed text, score)\n    \"\"\"\n    if os.name == \"nt\":\n        assert(not \"check_spelling() not available on Windows\")\n        return\n    with _ENCHANT_LOCK:\n        # Maximum distance from the first suggestion from python-enchant\n\n        words_dict = enchant.request_dict(spelling_lang)\n        try:\n            tknzr = enchant.tokenize.get_tokenizer(spelling_lang)\n        except enchant.tokenize.TokenizerNotFoundError:\n            # Fall back to default tokenization if no match for 'lang'\n            tknzr = enchant.tokenize.get_tokenizer()\n\n        score = 0\n        offset = 0\n        for (word, word_pos) in tknzr(txt):\n            if len(word) < _MIN_WORD_LEN:\n                continue\n            if words_dict.check(word):\n                # immediately correct words are a really good hint for\n                # orientation\n                score += 100\n                continue\n            suggestions = words_dict.suggest(word)\n            if (len(suggestions) <= 0):\n                # this word is useless. It may even indicates a bad orientation\n                score -= 10\n                continue\n            main_suggestion = suggestions[0]\n            lv_dist = Levenshtein.distance(word, main_suggestion)\n            if (lv_dist > _MAX_LEVENSHTEIN_DISTANCE):\n                # hm, this word looks like it's in a bad shape\n                continue\n\n            logger.debug(\"Spell checking: Replacing: %s -> %s\"\n                         % (word, main_suggestion))\n\n            # let's replace the word by its suggestion\n\n            pre_txt = txt[:word_pos + offset]\n            post_txt = txt[word_pos + len(word) + offset:]\n            txt = pre_txt + main_suggestion + post_txt\n            offset += (len(main_suggestion) - len(word))\n\n            # fixed words may be a good hint for orientation\n            score += 5\n\n        return (txt, score)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete all files and directories in the shell.", "response": "def rm_rf(path):\n    \"\"\"\n    Act as 'rm -rf' in the shell\n    \"\"\"\n    if os.path.isfile(path):\n        os.unlink(path)\n    elif os.path.isdir(path):\n        for root, dirs, files in os.walk(path, topdown=False):\n            for filename in files:\n                filepath = os.path.join(root, filename)\n                logger.info(\"Deleting file %s\" % filepath)\n                os.unlink(filepath)\n            for dirname in dirs:\n                dirpath = os.path.join(root, dirname)\n                if os.path.islink(dirpath):\n                    logger.info(\"Deleting link %s\" % dirpath)\n                    os.unlink(dirpath)\n                else:\n                    logger.info(\"Deleting dir %s\" % dirpath)\n                    os.rmdir(dirpath)\n        logger.info(\"Deleting dir %s\", path)\n        os.rmdir(path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a cairo surface into a PIL image", "response": "def surface2image(surface):\n    \"\"\"\n    Convert a cairo surface into a PIL image\n    \"\"\"\n    # TODO(Jflesch): Python 3 problem\n    # cairo.ImageSurface.get_data() raises NotImplementedYet ...\n\n    # import PIL.ImageDraw\n    #\n    # if surface is None:\n    #     return None\n    # dimension = (surface.get_width(), surface.get_height())\n    # img = PIL.Image.frombuffer(\"RGBA\", dimension,\n    #                            surface.get_data(), \"raw\", \"BGRA\", 0, 1)\n    #\n    # background = PIL.Image.new(\"RGB\", img.size, (255, 255, 255))\n    # background.paste(img, mask=img.split()[3])  # 3 is the alpha channel\n    # return background\n\n    global g_lock\n    with g_lock:\n        img_io = io.BytesIO()\n        surface.write_to_png(img_io)\n        img_io.seek(0)\n        img = PIL.Image.open(img_io)\n        img.load()\n\n        if \"A\" not in img.getbands():\n            return img\n\n        img_no_alpha = PIL.Image.new(\"RGB\", img.size, (255, 255, 255))\n        img_no_alpha.paste(img, mask=img.split()[3])  # 3 is the alpha channel\n        return img_no_alpha"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a PIL image into a Cairo surface.", "response": "def image2surface(img):\n    \"\"\"\n    Convert a PIL image into a Cairo surface\n    \"\"\"\n    if not CAIRO_AVAILABLE:\n        raise Exception(\"Cairo not available(). image2surface() cannot work.\")\n\n    # TODO(Jflesch): Python 3 problem\n    # cairo.ImageSurface.create_for_data() raises NotImplementedYet ...\n\n    # img.putalpha(256)\n    # (width, height) = img.size\n    # imgd = img.tobytes('raw', 'BGRA')\n    # imga = array.array('B', imgd)\n    # stride = width * 4\n    #  return cairo.ImageSurface.create_for_data(\n    #      imga, cairo.FORMAT_ARGB32, width, height, stride)\n\n    # So we fall back to this method:\n    global g_lock\n    with g_lock:\n        img_io = io.BytesIO()\n        img.save(img_io, format=\"PNG\")\n        img_io.seek(0)\n        return cairo.ImageSurface.create_from_png(img_io)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_input(prolog_file):\n    '''\n    Check for illegal predicates (like reading/writing, opening sockets, etc).\n    '''\n    if prolog_file == None:\n        return\n    for pred in illegal_predicates:\n        if type(pred) == tuple:\n            print_name = pred[1]\n            pred = pred[0]\n        else:\n            print_name = pred\n        if re.search(r'[^\\w]' + pred + r'\\s*[\\(\\)\\:\\.\\,\\;]+', prolog_file):\n            raise Exception('Illegal predicate \"%s\" used in your input, aborting. If your own predicate clashes with a predefined YAP predicate, you must rename it.' % print_name)", "response": "Check for illegal predicates in the input file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse the features returned by a propositionalization method to map unseen test examples into the new feature space. :param features: string of features as returned by rsd, aleph or treeliker :param feature_format: 'rsd', 'aleph', 'treeliker' :param train_context: DBContext with training examples :param test_context: DBContext with test examples :param intervals: discretization intervals (optional) :param format: output format (only arff is used atm) :param positive_class: required for aleph :return: returns the test examples in propositional form :rtype: str :Example: >>> test_arff = mapper.domain_map(features, 'rsd', train_context, test_context)", "response": "def domain_map(features, feature_format, train_context, test_context,\n               intervals={},\n               format='arff',\n               positive_class=None):\n    '''\n    Use the features returned by a propositionalization method to map\n    unseen test examples into the new feature space.\n\n      :param features: string of features as returned by rsd, aleph or treeliker\n      :param feature_format: 'rsd', 'aleph', 'treeliker'\n      :param train_context: DBContext with training examples\n      :param test_context: DBContext with test examples\n      :param intervals: discretization intervals (optional)\n      :param format: output format (only arff is used atm)\n      :param positive_class: required for aleph\n\n      :return: returns the test examples in propositional form\n      :rtype: str\n\n      :Example:\n\n      >>> test_arff = mapper.domain_map(features, 'rsd', train_context, test_context)\n    '''\n    dataset = None\n    if feature_format in ['rsd', 'aleph']:\n        train_rsd = RSDConverter(train_context)\n        test_rsd = RSDConverter(test_context, discr_intervals=intervals)\n        mapper_target_name = train_context.target_table + '_mapper'\n        train_examples = train_rsd.all_examples(pred_name=mapper_target_name)\n        test_examples = test_rsd.all_examples(pred_name=mapper_target_name)\n        \n        if feature_format == 'aleph':\n            features = aleph_to_rsd_features(features)\n\n        prolog_bk = '\\n'.join([\n            _example_ids('testExampleIDs', test_examples),\n            '%% test examples',\n            test_examples,\n            '%% train examples',\n            train_examples, \n            '%% train background knowledge',\n            train_rsd.background_knowledge(),\n            '%% test background knowledge',\n            test_rsd.background_knowledge(),\n            _feature_numbers(features),\n            '%% features',\n            features,\n        ])\n        THIS_DIR = os.path.dirname(__file__) if os.path.dirname(__file__) else '.'\n        f = tempfile.NamedTemporaryFile(delete=False, mode='w')\n        f.write(prolog_bk)\n        f.close()\n        cmd_args = ['yap', '-L', '--', '%s/mapper.pl' % THIS_DIR, f.name, mapper_target_name]\n        evaluations = subprocess.check_output(cmd_args).decode()\n        dataset = dump_dataset(features, feature_format, evaluations,\n                               train_context,\n                               format=format,\n                               positive_class=positive_class)\n\n        # Cleanup\n        os.remove(f.name)\n\n    elif feature_format == 'treeliker':\n        # We provide treeliker with the test dataset\n        # since it has a built-in ability to evaluate features\n        treeliker_test = TreeLikerConverter(test_context, \n                                            discr_intervals=intervals)\n        treeliker = features\n        treeliker.test_dataset = treeliker_test.dataset()\n        _, test_dataset = treeliker.run()\n\n        if format == 'arff':\n            dataset = test_dataset\n        else:\n            return 'unsupported format'\n    \n    return dataset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the text corresponding to this page.", "response": "def _get_text(self):\n        \"\"\"\n        Get the text corresponding to this page\n        \"\"\"\n        boxes = self.boxes\n        txt = []\n        for line in boxes:\n            txt_line = u\"\"\n            for box in line.word_boxes:\n                txt_line += u\" \" + box.content\n            txt.append(txt_line)\n        return txt"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the word boxes of this page.", "response": "def __get_boxes(self):\n        \"\"\"\n        Get all the word boxes of this page.\n        \"\"\"\n        boxfile = self.__box_path\n\n        try:\n            box_builder = pyocr.builders.LineBoxBuilder()\n            with self.fs.open(boxfile, 'r') as file_desc:\n                boxes = box_builder.read_file(file_desc)\n            if boxes != []:\n                return boxes\n            # fallback: old format: word boxes\n            # shouldn't be used anymore ...\n            box_builder = pyocr.builders.WordBoxBuilder()\n            with self.fs.open(boxfile, 'r') as file_desc:\n                boxes = box_builder.read_file(file_desc)\n            if len(boxes) <= 0:\n                return []\n            logger.warning(\"WARNING: Doc %s uses old box format\" %\n                           (str(self.doc)))\n            return [pyocr.builders.LineBox(boxes, boxes[0].position)]\n        except IOError as exc:\n            logger.error(\"Unable to get boxes for '%s': %s\"\n                         % (self.doc.docid, exc))\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __get_img(self):\n        with self.fs.open(self.__img_path, 'rb') as fd:\n            img = PIL.Image.open(fd)\n            img.load()\n            return img", "response": "Returns an image object corresponding to the page\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls by Gtk when a print operation is done.", "response": "def print_page_cb(self, print_op, print_context, keep_refs={}):\n        \"\"\"\n        Called for printing operation by Gtk\n        \"\"\"\n        ORIENTATION_PORTRAIT = 0\n        ORIENTATION_LANDSCAPE = 1\n        scaling = 2.0\n\n        img = self.img\n        (width, height) = img.size\n\n        # take care of rotating the image if required\n        if print_context.get_width() <= print_context.get_height():\n            print_orientation = ORIENTATION_PORTRAIT\n        else:\n            print_orientation = ORIENTATION_LANDSCAPE\n        if width <= height:\n            img_orientation = ORIENTATION_PORTRAIT\n        else:\n            img_orientation = ORIENTATION_LANDSCAPE\n        if print_orientation != img_orientation:\n            logger.info(\"Rotating the page ...\")\n            img = img.rotate(90, expand=True)\n\n        (width, height) = img.size\n\n        # scale the image down\n        # XXX(Jflesch): beware that we get floats for the page size ...\n        scaling = min(\n            print_context.get_width() / width,\n            print_context.get_height() / height\n        )\n\n        logger.info(\"DPI: %fx%f\" % (print_context.get_dpi_x(),\n                                    print_context.get_dpi_y()))\n\n        surface = image2surface(img)\n        keep_refs['surface_cache_' + str(self.page_nb)] = surface\n\n        # .. and print !\n        cairo_context = print_context.get_cairo_context()\n        cairo_context.scale(scaling, scaling)\n        cairo_context.set_source_surface(surface, 0, 0)\n        cairo_context.paint()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef change_index(self, offset=0):\n        src = {}\n        src[\"box\"] = self.__get_box_path()\n        src[\"img\"] = self.__get_img_path()\n        src[\"thumb\"] = self._get_thumb_path()\n\n        page_nb = self.page_nb\n\n        page_nb += offset\n\n        logger.info(\"--> Moving page %d (+%d) to index %d\"\n                    % (self.page_nb, offset, page_nb))\n\n        self.page_nb = page_nb\n\n        dst = {}\n        dst[\"box\"] = self.__get_box_path()\n        dst[\"img\"] = self.__get_img_path()\n        dst[\"thumb\"] = self._get_thumb_path()\n\n        for key in src.keys():\n            if self.fs.exists(src[key]):\n                if self.fs.exists(dst[key]):\n                    logger.error(\"Error: file already exists: %s\" % dst[key])\n                    assert(0)\n                self.fs.rename(src[key], dst[key])", "response": "Move the current page number by a given offset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef destroy(self):\n        logger.info(\"Destroying page: %s\" % self)\n        if self.doc.nb_pages <= 1:\n            self.doc.destroy()\n            return\n        doc_pages = self.doc.pages[:]\n        current_doc_nb_pages = self.doc.nb_pages\n        paths = [\n            self.__get_box_path(),\n            self.__get_img_path(),\n            self._get_thumb_path(),\n        ]\n        for path in paths:\n            if self.fs.exists(path):\n                self.fs.unlink(path)\n        for page_nb in range(self.page_nb + 1, current_doc_nb_pages):\n            page = doc_pages[page_nb]\n            page.change_index(offset=-1)", "response": "Delete the page. May delete the whole document if it's actually the\n        last page."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove content from box to other page.", "response": "def _steal_content(self, other_page):\n        \"\"\"\n        Call ImgDoc.steal_page() instead\n        \"\"\"\n        other_doc = other_page.doc\n        other_doc_pages = other_doc.pages[:]\n        other_doc_nb_pages = other_doc.nb_pages\n        other_page_nb = other_page.page_nb\n\n        to_move = [\n            (other_page.__get_box_path(), self.__get_box_path()),\n            (other_page.__get_img_path(), self.__get_img_path()),\n            (other_page._get_thumb_path(), self._get_thumb_path())\n        ]\n        for (src, dst) in to_move:\n            # sanity check\n            if self.fs.exists(dst):\n                logger.error(\"Error, file already exists: %s\" % dst)\n                assert(0)\n        for (src, dst) in to_move:\n            logger.info(\"%s --> %s\" % (src, dst))\n            self.fs.rename(src, dst)\n\n        if (other_doc_nb_pages <= 1):\n            other_doc.destroy()\n        else:\n            for page_nb in range(other_page_nb + 1, other_doc_nb_pages):\n                page = other_doc_pages[page_nb]\n                page.change_index(offset=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the configuration file and load all settings.", "response": "def read(self):\n        \"\"\"\n        (Re)read the configuration.\n\n        Beware that the current work directory may affect this operation:\n        If there is a 'paperwork.conf' in the current directory, it will be\n        read instead of '~/.paperwork.conf', see __init__())\n        \"\"\"\n        logger.info(\"Reloading %s ...\" % self.__configfile)\n\n        # smash the previous config\n        self._configparser = configparser.SafeConfigParser()\n        self._configparser.read([self.__configfile])\n\n        sections = set()\n        for setting in self.settings.values():\n            sections.add(setting.section)\n        for section in sections:\n            # make sure that all the sections exist\n            if not self._configparser.has_section(section):\n                self._configparser.add_section(section)\n\n        for setting in self.settings.values():\n            setting.load(self._configparser)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self):\n        logger.info(\"Updating %s ...\" % self.__configfile)\n\n        for setting in self.settings.values():\n            setting.update(self._configparser)\n\n        file_path = self.__configfile\n        try:\n            with open(file_path, 'w') as file_descriptor:\n                self._configparser.write(file_descriptor)\n            logger.info(\"Done\")\n        except IOError as e:\n            logger.warn(\n                \"Cannot write to configuration file %s : %s\"\n                % (self.__configfile, e.strerror)\n            )\n            return False\n\n        try:\n            # Windows support\n            util.hide_file(os.path.expanduser(os.path.join(\"~\", \".config\")))\n        except Exception as exc:\n            logger.warn(\"Failed to hide configuration file\")\n            logger.exception(exc)\n\n        return True", "response": "Write the current version of the paperwork configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a parent - child relationship.", "response": "def pclink(self, parent, child):\n    \"\"\"Create a parent-child relationship.\"\"\"\n    if parent._children is None:\n      parent._children = set()\n    if child._parents is None:\n      child._parents = set()\n    parent._children.add(child)\n    child._parents.add(parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enforce_duration(self, duration_thresh):\n        i = 1\n        while i < len(self.pitch)-1:\n            if self.pitch[i] == -10000:\n                i += 1\n                continue\n            if self.pitch[i]-self.pitch[i-1] != 0 and self.pitch[i+1]-self.pitch[i] == 0:\n                start = i\n                while i < len(self.pitch) and self.pitch[i+1]-self.pitch[i] == 0:\n                    i += 1\n                if (self.timestamps[i]-self.timestamps[start])*1000 < duration_thresh:\n                    self.pitch[start:i+1] = np.zeros(i+1-start)-10000\n            else:\n                self.pitch[i] = -10000\n                i += 1", "response": "This method enforces the duration of the time section of the contour."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_lines(self, window=1500, break_thresh=1500):\n        window /= 1000\n        hop = window/3\n        break_thresh /= 1000\n\n        #cut the whole song into pieces if there are gaps more than break_thresh seconds\n        i = 0\n        break_indices = []\n        count = 0\n        while i < len(self.pitch):\n            if self.pitch[i] == -10000:\n                count = 1\n                start_index = i\n                while i < len(self.pitch) and self.pitch[i] == -10000:\n                    count += 1\n                    i += 1\n                end_index = i-1\n                if self.timestamps[end_index]-self.timestamps[start_index] >= break_thresh:\n                    break_indices.append([start_index, end_index])\n            i += 1\n        break_indices = np.array(break_indices)\n\n        #In creating the data blocks which are not silences, note that we\n        # take complimentary break indices. i.e., if [[s1, e1], [s2, e2] ...]\n        # is break_indices, we take e1-s2, e2-s3 chunks and build data blocks\n\n        data_blocks = []\n        if len(break_indices) == 0:\n            t_pitch = self.pitch.reshape(len(self.pitch), 1)\n            t_timestamps = self.timestamps.reshape(len(self.timestamps), 1)\n            data_blocks = [np.append(t_timestamps, t_pitch, axis=1)]\n        else:\n            if break_indices[0, 0] != 0:\n                t_pitch = self.pitch[:break_indices[0, 0]]\n                t_pitch = t_pitch.reshape(len(t_pitch), 1)\n                t_timestamps = self.timestamps[:break_indices[0, 0]]\n                t_timestamps = t_timestamps.reshape(len(t_timestamps), 1)\n                data_blocks.append(np.append(t_timestamps, t_pitch, axis=1))\n            block_start = break_indices[0, 1]\n            for i in xrange(1, len(break_indices)):\n                block_end = break_indices[i, 0]\n                t_pitch = self.pitch[block_start:block_end]\n                t_pitch = t_pitch.reshape(len(t_pitch), 1)\n                t_timestamps = self.timestamps[block_start:block_end]\n                t_timestamps = t_timestamps.reshape(len(t_timestamps), 1)\n                data_blocks.append(np.append(t_timestamps, t_pitch, axis=1))\n                block_start = break_indices[i, 1]\n            if block_start != len(self.pitch)-1:\n                t_pitch = self.pitch[block_start:]\n                t_pitch = t_pitch.reshape(len(t_pitch), 1)\n                t_timestamps = self.timestamps[block_start:]\n                t_timestamps = t_timestamps.reshape(len(t_timestamps), 1)\n                data_blocks.append(np.append(t_timestamps, t_pitch, axis=1))\n\n        label_start_offset = (window-hop)/2\n        label_end_offset = label_start_offset+hop\n\n        #dataNew = np.zeros_like(data)\n        #dataNew[:, 0] = data[:, 0]\n        data_new = np.array([[0, 0]])\n        for data in data_blocks:\n            start_index = 0\n            while start_index < len(data)-1:\n                end_index = utils.find_nearest_index(data[:, 0], data[start_index][0]+window)\n                segment = data[start_index:end_index]\n                if len(segment) == 0:\n                    start_index = utils.find_nearest_index(data[:, 0], data[start_index, 0]+hop)\n                    continue\n                segment_clean = np.delete(segment, np.where(segment[:, 1] == -10000), axis=0)\n                if len(segment_clean) == 0:\n                    #After splitting into blocks, this loop better not come into play\n                    #raise ValueError(\"This part of the block is absolute silence! Make sure block_thresh >= window!\")\n                    start_index = utils.find_nearest_index(data[:, 0], data[start_index, 0]+hop)\n                    continue\n                n_clean = len(segment_clean)\n                x_clean = np.matrix(segment_clean[:, 0]).reshape(n_clean, 1)\n                y_clean = np.matrix(segment_clean[:, 1]).reshape(n_clean, 1)\n                #return [x_clean, y_clean]\n                theta = utils.normal_equation(x_clean, y_clean)\n\n                #determine the start and end of the segment to be labelled\n                label_start_index = utils.find_nearest_index(x_clean, data[start_index, 0]+label_start_offset)\n                label_end_index = utils.find_nearest_index(x_clean, data[start_index, 0]+label_end_offset)\n                x_clean = x_clean[label_start_index:label_end_index]\n                #return x_clean\n                x_clean = np.insert(x_clean, 0, np.ones(len(x_clean)), axis=1)\n                newy = x_clean*theta\n                result = np.append(x_clean[:, 1], newy, axis=1)\n                data_new = np.append(data_new, result, axis=0)\n\n                start_index = utils.find_nearest_index(data[:, 0], data[start_index, 0]+hop)\n\n        return [data_new[:, 0], data_new[:, 1]]", "response": "Fits lines to pitch contours."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bits(self):\n        if self._bits is None:\n            value = self._DEFAULT_BITS.get(self.arch)\n            if value is None:\n                raise NotImplementedError('Could not determine the default word size of %s architecture.' % self.arch)\n            return value\n        else:\n            return self._bits", "response": "Returns the word size of the target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef endian(self):\n        if self._endian is None:\n            value = self._DEFAULT_ENDIAN[self.arch]\n            if value is None:\n                raise NotImplementedError('Could not determine the default byte order of %s architecture.' % self.arch)\n            return value\n        else:\n            return self._endian", "response": "Returns the byte order of the target architectural data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assume(self, other):\n\n        self._arch = other._arch\n        self._bits = other._bits\n        self._endian = other._endian\n        self._mode = other._mode", "response": "Assume the identity of another target."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate(env, func, *args, **kwargs):\n\n    func_code = six.get_function_code(func)\n    func_globals = dict(__builtins__)\n    func_globals.update(six.get_function_globals(func))\n\n    ops = bc.disassemble(func_code.co_code)\n\n    program = []\n\n    f_args = inspect.getcallargs(func, *args, **kwargs)\n    variables = dict(\n        (func_code.co_varnames.index(arg_name), arg_value)\n        for arg_name, arg_value in six.iteritems(f_args)\n    )\n\n    stack = []\n    for op in ops:\n        if op.name == 'LOAD_CONST':\n            stack.append(func_code.co_consts[op.arg])\n\n        elif op.name == 'LOAD_GLOBAL':\n            global_name = func_code.co_names[op.arg]\n            stack.append(getattr(env, global_name, func_globals.get(global_name)))\n\n        elif op.name == 'LOAD_FAST':\n            var_name = func_code.co_varnames[op.arg]\n            stack.append(getattr(env, var_name, variables.get(op.arg)))\n\n        elif op.name == 'BUILD_LIST':\n            items = stack[-op.arg:]\n            del stack[-op.arg:]\n            stack.append(items)\n\n        elif op.name == 'LOAD_ATTR':\n            obj = stack.pop()\n            stack.append(getattr(obj, func_code.co_names[op.arg]))\n\n        elif op.name == 'CALL_FUNCTION':\n            nargs = op.arg & 0xff\n            nkwargs = op.arg >> 8\n\n            if nkwargs:\n                f_kwargs = dict(zip(stack[-nkwargs * 2::2], stack[-nkwargs * 2 + 1::2]))\n                del stack[-nkwargs * 2:]\n            else:\n                f_kwargs = {}\n\n            if nargs:\n                f_args = stack[-nargs:]\n                del stack[-nargs:]\n            else:\n                f_args = []\n\n            f = stack.pop()\n            if isinstance(f, Fragment):\n                stack.append(f(env, *f_args, **f_kwargs))\n            else:\n                stack.append(f(*f_args, **f_kwargs))\n\n        elif op.name == 'STORE_FAST':\n            value = stack.pop()\n            var_name = func_code.co_varnames[op.arg]\n            var = getattr(env, var_name, variables.get(op.arg, None))\n            if isinstance(var, Register):\n                program.append(LoadRegister(var, value))\n            else:\n                variables[op.arg] = value\n\n        elif op.name == 'POP_TOP':\n            value = stack.pop()\n            if isinstance(value, SyscallInvoke):\n                program.append(value)\n            elif isinstance(value, list):\n                program.extend(value)\n            else:\n                raise ValueError('No idea how to compile %s' % (value,))\n\n        elif op.name == 'RETURN_VALUE':\n            stack.pop()\n\n        elif op.name == 'DUP_TOP':\n            value = stack[-1]\n            if isinstance(value, SyscallInvoke):\n                stack.insert(-1, env.SYSCALL_RET_REG)\n            else:\n                stack.append(value)\n\n        elif op.name == 'BINARY_SUBSCR':\n            index = stack.pop()\n            value = stack.pop()\n            stack.append(value[index])\n\n        elif op.name == 'STORE_SUBSCR':\n            index = stack.pop()\n            value = stack.pop()\n            new_value = stack.pop()\n            var = value[index]\n            if isinstance(var, Register):\n                program.append(LoadRegister(var, new_value))\n            else:\n                value[index] = new_value\n\n        elif op.name == 'INPLACE_ADD':\n            value = stack.pop()\n            reg = stack.pop()\n            if not isinstance(reg, Register):\n                raise TypeError('In-place addition is only supported on registers')\n            program.extend(env.reg_add(reg, value))\n            stack.append(reg)\n\n        elif op.name == 'INPLACE_SUBTRACT':\n            value = stack.pop()\n            reg = stack.pop()\n            if not isinstance(reg, Register):\n                raise TypeError('In-place subtraction is only supported on registers')\n            program.extend(env.reg_sub(reg, value))\n            stack.append(reg)\n\n        else:\n            raise RuntimeError('Unsupported opcode: %s' % op.name)\n\n    return program", "response": "Given a shellcode environment a function and its arguments translate it to a list of high - level shellcode operations ready to be compiled using the Python interpreter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the user has read permission on the path.", "response": "def has_read_permission(self, request, path):\n        \"\"\"\n        Just return True if the user is an authenticated staff member.\n        Extensions could base the permissions on the path too.\n        \"\"\"\n        user = request.user\n        if not user.is_authenticated():\n            return False\n        elif user.is_superuser:\n            return True\n        elif user.is_staff:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding all the children and the parent.", "response": "def _recurse(self, parent, dir_included=False):\n        \"\"\"\n        Yield all the children (depth first), but not the parent.\n        \"\"\"\n        try:\n            children = parent.enumerate_children(\n                Gio.FILE_ATTRIBUTE_STANDARD_NAME,\n                Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                None\n            )\n        except GLib.GError:\n            # assumes it's a file and not a directory\n            yield parent\n            return\n\n        for child in children:\n            name = child.get_name()\n            child = parent.get_child(name)\n            try:\n                for sub in self._recurse(child):\n                    yield sub\n            except GLib.GError:\n                yield child\n\n        if dir_included:\n            yield parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rows(self, table, cols):\n        '''\n        Fetches rows from the local cache or from the db if there's no cache.\n\n            :param table: table name to select\n            :cols: list of columns to select\n            :return: list of rows\n            :rtype: list\n        '''\n        if self.orng_tables:\n            data = []\n            for ex in self.orng_tables[table]:\n                data.append([ex[str(col)] for col in cols])\n            return data\n        else:\n            return self.fetch(table, cols)", "response": "Fetches rows from the local cache or from the db"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_where(self, table, cols, pk_att, pk):\n        '''\n        SELECT with WHERE clause.\n\n            :param table: target table\n            :param cols: list of columns to select\n            :param pk_att: attribute for the where clause\n            :param pk: the id that the pk_att should match\n            :return: rows from the given table and cols, with the condition pk_att==pk\n            :rtype: list\n        '''\n        if self.orng_tables:\n            data = []\n            for ex in self.orng_tables[table]:\n                if str(ex[str(pk_att)]) == str(pk):\n                    data.append([ex[str(col)] for col in cols])\n            return data\n        else:\n            return self.src.select_where(table, cols, pk_att, pk)", "response": "Select rows from the given table and columns with the condition pk_att == pk."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes the given string as an OID.", "response": "def encode(string):\n\t\t\"\"\"\n\t\tEncode the given string as an OID.\n\n\t\t>>> import snmp_passpersist as snmp\n\t\t>>> snmp.PassPersist.encode(\"hello\")\n\t\t'5.104.101.108.108.111'\n\t\t>>>\n\t\t\"\"\"\n\n\t\tresult=\".\".join([ str(ord(s)) for s in string ])\n\t\treturn  \"%s.\" % (len(string)) + result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self,oid):\n\t\ttry:\n\t\t\tself.lock.acquire()\n\t\t\tif oid not in self.data:\n\t\t\t\treturn \"NONE\"\n\t\t\telse:\n\t\t\t\treturn self.base_oid + oid + '\\n' + self.data[oid]['type'] + '\\n' +\tstr(self.data[oid]['value'])\n\t\tfinally:\n\t\t\tself.lock.release()", "response": "Return the SNMP value for the given OID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_next(self,oid):\n\t\ttry: # Nested try..except because of Python 2.4\n\t\t\tself.lock.acquire()\n\t\t\ttry:\n\t\t\t\t# remove trailing zeroes from the oid\n\t\t\t\twhile len(oid) > 0 and oid[-2:] == \".0\" and oid not in self.data:\n\t\t\t\t\toid = oid[:-2];\n\t\t\t\treturn self.get(self.data_idx[self.data_idx.index(oid)+1])\n\t\t\texcept ValueError:\n\t\t\t\t# Not found: try to match partial oid\n\t\t\t\tfor real_oid in self.data_idx:\n\t\t\t\t\tif real_oid.startswith(oid):\n\t\t\t\t\t\treturn self.get(real_oid)\n\t\t\t\treturn \"NONE\" # Unknown OID\n\t\t\texcept IndexError:\n\t\t\t\treturn \"NONE\" # End of MIB\n\t\tfinally:\n\t\t\tself.lock.release()", "response": "Return snmp value for the next OID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_first(self):\n\t\ttry: # Nested try..except because of Python 2.4\n\t\t\tself.lock.acquire()\n\t\t\ttry:\n\t\t\t\treturn self.get(self.data_idx[0])\n\t\t\texcept (IndexError, ValueError):\n\t\t\t\treturn \"NONE\"\n\t\tfinally:\n\t\t\tself.lock.release()", "response": "Return the first OID in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cut_oid(self,full_oid):\n\t\tif not full_oid.startswith(self.base_oid.rstrip('.')):\n\t\t\treturn None\n\t\telse:\n\t\t\treturn full_oid[len(self.base_oid):]", "response": "Return the base OID from the given string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_oid_entry(self, oid, type, value, label=None):\n\t\tif self.debug:\n\t\t\tprint('DEBUG: %s %s %s %s'%(oid,type,value,label))\n\t\titem={'type': str(type), 'value': str(value)}\n\t\tif label is not None:\n\t\t    item['label']=str(label)\n\t\tself.pending[oid]=item", "response": "General function to add an oid entry to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_oid(self,oid,value,label=None):\n\t\tself.add_oid_entry(oid,'OBJECTID',value,label=label)", "response": "Short helper to add an object ID value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshorting helper to add an integer value to the MIB subtree.", "response": "def add_int(self,oid,value,label=None):\n\t\t\"\"\"Short helper to add an integer value to the MIB subtree.\"\"\"\n\t\tself.add_oid_entry(oid,'INTEGER',value,label=label)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_oct(self,oid,value,label=None):\n\t\tself.add_oid_entry(oid,'OCTET',value,label=label)", "response": "Short helper to add an octet value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshort helper to add a string value to the MIB subtree.", "response": "def add_str(self,oid,value,label=None):\n\t\t\"\"\"Short helper to add a string value to the MIB subtree.\"\"\"\n\t\tself.add_oid_entry(oid,'STRING',value,label=label)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_ip(self,oid,value,label=None):\n\t\tself.add_oid_entry(oid,'IPADDRESS',value,label=label)", "response": "Short helper to add an IP address value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_cnt_32bit(self,oid,value,label=None):\n\t\t# Truncate integer to 32bits ma,x\n\t\tself.add_oid_entry(oid,'Counter32',int(value)%4294967296,label=label)", "response": "Short helper to add a 32 bit counter value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_cnt_64bit(self,oid,value,label=None):\n\t\t# Truncate integer to 64bits ma,x\n\t\tself.add_oid_entry(oid,'Counter64',int(value)%18446744073709551615,label=label)", "response": "Short helper to add a 64 bit counter value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshorts helper to add a gauge value to the MIB subtree.", "response": "def add_gau(self,oid,value,label=None):\n\t\t\"\"\"Short helper to add a gauge value to the MIB subtree.\"\"\"\n\t\tself.add_oid_entry(oid,'GAUGE',value,label=label)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tt(self,oid,value,label=None):\t\n\t\tself.add_oid_entry(oid,'TIMETICKS',value,label=label)", "response": "Short helper to add a timeticks value to the MIB subtree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main_passpersist(self):\n\t\tline = sys.stdin.readline().strip()\n\t\tif not line:\n\t\t\traise EOFError()\n\n\t\tif 'PING' in line:\n\t\t\tprint(\"PONG\")\n\t\telif 'getnext' in line:\n\t\t\toid = self.cut_oid(sys.stdin.readline().strip())\n\t\t\tif oid is None:\n\t\t\t\tprint(\"NONE\")\n\t\t\telif oid == \"\":\n\t\t\t\t# Fallback to the first entry\n\t\t\t\tprint(self.get_first())\n\t\t\telse:\n\t\t\t\tprint(self.get_next(oid))\n\t\telif 'get' in line:\n\t\t\toid = self.cut_oid(sys.stdin.readline().strip())\n\t\t\tif oid is None:\n\t\t\t\tprint(\"NONE\")\n\t\t\telse:\n\t\t\t\tprint(self.get(oid))\n\t\telif 'set' in line:\n\t\t\toid = sys.stdin.readline().strip()\n\t\t\ttypevalue = sys.stdin.readline().strip()\n\t\t\tself.set(oid, typevalue)\n\t\telif 'DUMP' in line: # Just for debbuging\n\t\t\tfrom pprint import pprint\n\t\t\tpprint(self.data)\n\t\telse:\n\t\t\tprint(\"NONE\")\n\n\t\tsys.stdout.flush()", "response": "This function handles the SNMP s pass_persist protocol. It is used by the main function of the main protocol. It is used by the main function of the main protocol. It is used by the main protocol to handle the pass_persist protocol."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit(self):\n\n\t\t# Generate index before acquiring lock to keep locked section fast\n\t\t# Works because this thread is the only writer of self.pending\n\t\tpending_idx = sorted(list(self.pending.keys()), key=lambda k: tuple(int(part) for part in k.split('.')))\n\n\t\t# Commit new data\n\t\ttry:\n\t\t\tself.lock.acquire()\n\t\t\tself.data=self.pending\n\t\t\tself.pending=dict()\n\t\t\tself.data_idx = pending_idx\n\t\tfinally:\n\t\t\tself.lock.release()", "response": "Commit changes made by the add_* methods."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main_update(self):\n\t\t# Renice updater thread to limit overload\n\t\ttry:\n\t\t\tos.nice(1)\n\t\texcept AttributeError as er:\n\t\t\tpass # os.nice is not available on windows\n\t\ttime.sleep(self.refresh)\n\n\t\ttry:\n\t\t\twhile True:\n\t\t\t\t# We pick a timestamp to take in account the time used by update()\n\t\t\t\ttimestamp=time.time()\n\n\t\t\t\t# Update data with user's defined function\n\t\t\t\tself.update()\n\n\t\t\t\t# We use this trick because we cannot use signals in a backoffice threads\n\t\t\t\t# and alarm() mess up with readline() in the main thread.\n\t\t\t\tdelay=(timestamp+self.refresh)-time.time()\n\t\t\t\tif delay > 0:\n\t\t\t\t\tif delay > self.refresh:\n\t\t\t\t\t\ttime.sleep(self.refresh)\n\t\t\t\t\telse:\n\t\t\t\t\t\ttime.sleep(delay)\n\n\t\t\t\t# Commit change exactly every 'refresh' seconds, whatever update() takes long.\n\t\t\t\t# Commited values are a bit old, but for RRD, punctuals values\n\t\t\t\t# are better than fresh-but-not-time-constants values.\n\t\t\t\tself.commit()\n\n\t\texcept Exception as e:\n\t\t\tself.error=e\n\t\t\traise", "response": "Main function called by the updater thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the nearest parent setter function for an OID.", "response": "def get_setter(self, oid):\n\t\t\"\"\"\n\t\tRetrieve the nearest parent setter function for an OID\n\t\t\"\"\"\n\t\tif hasattr(self.setter, oid):\n\t\t\treturn self.setter[oid]\n\t\tparents = [ poid for poid in list(self.setter.keys()) if oid.startswith(poid) ]\n\t\tif parents:\n\t\t\treturn self.setter[max(parents)]\n\t\treturn self.default_setter"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of a field in the object", "response": "def set(self, oid, typevalue):\n\t\t\"\"\"\n\t\tCall the default or user setter function if available \n\t\t\"\"\"\n\t\tsuccess = False\n\t\ttype_ = typevalue.split()[0]\n\t\tvalue = typevalue.lstrip(type_).strip().strip('\"')\n\t\tret_value = self.get_setter(oid)(oid, type_, value)\n\t\tif ret_value:\n\t\t\tif ret_value in ErrorValues or ret_value == 'DONE':\n\t\t\t\tprint(ret_value)\n\t\t\telif ret_value == True:\n\t\t\t\tprint('DONE')\n\t\t\telif ret_value == False:\n\t\t\t\tprint(Error.NotWritable)\n\t\t\telse:\n\t\t\t\traise RuntimeError(\"wrong return value: %s\" % str(ret_value))\n\t\telse:\t\n\t\t\tprint(Error.NotWritable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, user_func, refresh):\n\t\tself.update=user_func\n\t\tself.refresh=refresh\n\t\tself.error=None\n\n\t\t# First load\n\t\tself.update()\n\t\tself.commit()\n\n\t\t# Start updater thread\n\t\tup = threading.Thread(None,self.main_update,\"Updater\")\n\t\tup.daemon = True\n\t\tup.start()\n\n\t\t# Main loop\n\t\twhile up.isAlive(): # Do not serve data if the Updater thread has died\n\t\t\ttry:\n\t\t\t\tself.main_passpersist()\n\t\t\texcept:\n\t\t\t\tup._Thread__stop()\n\t\t\t\traise", "response": "Start the SNMP s protocol handler and the updater thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of members of a certain type in obj.", "response": "def _get_members_of_type(obj, member_type):\n    \"\"\"\n    Finds members of a certain type in obj.\n\n    :param obj: A model instance or class.\n    :param member_type: The type of the menber we are trying to find.\n    :rtype: A :class:`list` of ``member_type`` found in ``obj``\n    \"\"\"\n\n    if not issubclass(type(obj), ModelBase):\n        obj = obj.__class__\n\n    key_hash = []\n    for key in dir(obj):\n        try:\n            attr = getattr(obj, key)\n        except AttributeError as e:\n            try:\n                attr = obj.__dict__[key]\n            except KeyError:\n                raise AttributeError(INTROSPECTION_ERROR % (e, obj, member_type))\n\n        if type(attr) is member_type:\n            key_hash.append((key, attr))\n\n    return key_hash"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next(self):\n        if self.idx >= len(self.page_list):\n            raise StopIteration()\n        page = self.page_list[self.idx]\n        self.idx += 1\n        return page", "response": "Returns the next element of the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the number of pages in the document.", "response": "def _get_nb_pages(self):\n        \"\"\"\n        Compute the number of pages in the document. It basically counts\n        how many JPG files there are in the document.\n        \"\"\"\n        try:\n            filelist = self.fs.listdir(self.path)\n            count = 0\n            for filepath in filelist:\n                filename = self.fs.basename(filepath)\n                if (filename[-4:].lower() != \".\" + ImgPage.EXT_IMG or\n                    (filename[-10:].lower() == \".\" + ImgPage.EXT_THUMB) or\n                    (filename[:len(ImgPage.FILE_PREFIX)].lower() !=\n                        ImgPage.FILE_PREFIX)):\n                    continue\n                count += 1\n            return count\n        except IOError as exc:\n            logger.debug(\"Exception while trying to get the number of\"\n                         \" pages of '%s': %s\", self.docid, exc)\n            return 0\n        except OSError as exc:\n            if exc.errno != errno.ENOENT:\n                logger.error(\"Exception while trying to get the number of\"\n                             \" pages of '%s': %s\", self.docid, exc)\n                raise\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_page_cb(self, print_op, print_context, page_nb, keep_refs={}):\n        page = ImgPage(self, page_nb)\n        page.print_page_cb(print_op, print_context, keep_refs=keep_refs)", "response": "Called for printing operation by Gtk. PrintContext"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef steal_page(self, page):\n        if page.doc == self:\n            return\n        self.fs.mkdir_p(self.path)\n\n        new_page = ImgPage(self, self.nb_pages)\n        logger.info(\"%s --> %s\" % (str(page), str(new_page)))\n        new_page._steal_content(page)", "response": "Steal a page from another document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recursion_depth(key):\n    try:\n        if not getattr(RECURSION_LEVEL_DICT, 'key', False):\n            RECURSION_LEVEL_DICT.key = 0\n        RECURSION_LEVEL_DICT.key += 1\n        yield RECURSION_LEVEL_DICT.key\n        RECURSION_LEVEL_DICT.key -= 1\n    except Exception as e:\n        RECURSION_LEVEL_DICT.key = 0\n        raise e", "response": "A context manager used to guard recursion depth for some function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the first value of predicate applied to list which does not return None.", "response": "def first_match(predicate, lst):\n    \"\"\"\n    returns the first value of predicate applied to list, which\n    does not return None\n\n    >>>\n    >>> def return_if_even(x):\n    ...     if x % 2 is 0:\n    ...         return x\n    ...     return None\n    >>>\n    >>> first_match(return_if_even, [1, 3, 4, 7])\n    4\n    >>> first_match(return_if_even, [1, 3, 5, 7])\n    >>>\n\n    :param predicate: a function that returns None or a value.\n    :param list: A list of items that can serve as input to ``predicate``.\n    :rtype: whatever ``predicate`` returns instead of None. (or None).\n    \"\"\"\n    for item in lst:\n        val = predicate(item)\n        if val is not None:\n            return val\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates through all base classes of cls and yield all base classes that are not base classes.", "response": "def bases_walker(cls):\n    \"\"\"\n    Loop through all bases of cls\n\n    >>> str = u'hai'\n    >>> for base in bases_walker(unicode):\n    ...     isinstance(str, base)\n    True\n    True\n\n    :param cls: The class in which we want to loop through the base classes.\n    \"\"\"\n    for base in cls.__bases__:\n        yield base\n        for more in bases_walker(base):\n            yield more"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd parameters to an url", "response": "def url_add_params(url, **kwargs):\n    \"\"\"\n    Add parameters to an url\n\n    >>> url_add_params('http://example.com/', a=1, b=3)\n    'http://example.com/?a=1&b=3'\n    >>> url_add_params('http://example.com/?c=8', a=1, b=3)\n    'http://example.com/?c=8&a=1&b=3'\n    >>> url_add_params('http://example.com/#/irock', a=1, b=3)\n    'http://example.com/?a=1&b=3#/irock'\n    >>> url_add_params('http://example.com/?id=10#/irock', a=1, b=3)\n    'http://example.com/?id=10&a=1&b=3#/irock'\n    \"\"\"\n    parsed_url = urlparse.urlsplit(url)\n    params = urlparse.parse_qsl(parsed_url.query)\n    parsed_url = list(parsed_url)\n\n    for pair in kwargs.iteritems():\n        params.append(pair)\n\n    parsed_url[3] = urllib.urlencode(params)\n    return urlparse.urlunsplit(parsed_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the cache if needed.", "response": "def process_response(self, request, response):\n        \"\"\"Sets the cache, if needed.\"\"\"\n        if not hasattr(request, '_cache_update_cache') or not request._cache_update_cache:\n            # We don't need to update the cache, just return.\n            return response\n        if request.method != 'GET':\n            # This is a stronger requirement than above. It is needed\n            # because of interactions between this middleware and the\n            # HTTPMiddleware, which throws the body of a HEAD-request\n            # away before this middleware gets a chance to cache it.\n            return response\n        if not response.status_code == 200:\n            return response\n        # Try to get the timeout from the \"max-age\" section of the \"Cache-\n        # Control\" header before reverting to using the default cache_timeout\n        # length.\n        timeout = get_max_age(response)\n        if timeout == None:\n            timeout = self.cache_timeout\n        elif timeout == 0:\n            # max-age was set to 0, don't bother caching.\n            return response\n        patch_response_headers(response, timeout)\n        if timeout:\n            cache_key = learn_cache_key(request, response, timeout, self.key_prefix)\n            cache.set(cache_key, response, timeout)\n            logging.debug(\"UpdateCacheMiddleware: setting %s -> %s params are: %s\" % (cache_key, request.path, get_cache_key_parameters(request)))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether the page is already cached and returns the cached version if available.", "response": "def process_request(self, request):\n        \"\"\"\n        Checks whether the page is already cached and returns the cached\n        version if available.\n        \"\"\"\n        if self.cache_anonymous_only:\n            assert hasattr(request, 'user'), \"The Django cache middleware with CACHE_MIDDLEWARE_ANONYMOUS_ONLY=True requires authentication middleware to be installed. Edit your MIDDLEWARE_CLASSES setting to insert 'django.contrib.auth.middleware.AuthenticationMiddleware' before the CacheMiddleware.\"\n\n        if not request.method in ('GET', 'HEAD') or request.GET:\n            request._cache_update_cache = False\n            return None # Don't bother checking the cache.\n\n        if self.cache_anonymous_only and request.user.is_authenticated():\n            request._cache_update_cache = False\n            return None # Don't cache requests from authenticated users.\n\n        cache_key = get_cache_key(request, self.key_prefix)\n        if cache_key is None:\n            request._cache_update_cache = True\n            return None # No cache information available, need to rebuild.\n\n        response = cache.get(cache_key, None)\n        if response is None:\n            logging.debug(\"FetchFromCacheMiddleware: %s is %s.  paramters(%s)\" % ( cache_key, request.path, get_cache_key_parameters(request)))\n            request._cache_update_cache = True\n            return None # No cache information available, need to rebuild.\n        logging.debug(\"Found %s -> %s in the cache. parameters(%s)\" % (cache_key, request.path, get_cache_key_parameters(request)))\n        request._cache_update_cache = False\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering an object to a response.", "response": "def render_to_response(template, object, params=None, mimetype='text/html'):\n    \"\"\"\n    ``object`` will be converted to xml using :func:`easymode.tree.xml`. The resulting xml \n    will be transformed using ``template``.\n    The result will be a :class:`~django.http.HttpResponse` object,\n    containing the transformed xml as the body.\n    \n    :param template: an xslt template name.\n    :param object: an object that has an ``__xml__`` method. (See :func:`easymode.tree.xml.decorators.toxml`).\n    :param params: A dictionary containing xslt parameters. Use :func:`~easymode.xslt.prepare_string_param`\\\n        on strings you want to pass in.\n    :param mimetype: The mimetype of the :class:`~django.http.HttpResponse`\n    :rtype: :class:`django.http.HttpResponse`\n    \"\"\"\n    xsl_path = find_template_path(template)\n    xml = xmltree.xml(object)\n    \n    result = transform(xml, str(xsl_path), params)\n    return HttpResponse(result, mimetype=mimetype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering an object to a string using a template.", "response": "def render_to_string(template, object, params=None):\n    \"\"\"\n    ``object`` will be converted to xml using :func:`easymode.tree.xml`. The resulting xml \n    will be transformed using ``template``.\n    The result is a unicode string containing the transformed xml.\n    \n    :param template: an xslt template name.\n    :param object: an object that has an ``__xml__`` method. (See :func:`easymode.tree.xml.decorators.toxml`).\n    :param params: A dictionary containing xslt parameters. Use :func:`~easymode.xslt.prepare_string_param`\\\n        on strings you want to pass in.\n    :rtype: :class:`unicode`\n    \"\"\"\n    xsl_path = find_template_path(template)\n    xml = xmltree.xml(object)\n    \n    result = transform(xml, str(xsl_path), params)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_xml_to_string(template, input, params=None):\n    xsl_path = find_template_path(template)\n\n    result = transform(input, str(xsl_path), params)  \n    return result", "response": "Renders input using template."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef standin_for(obj, **attrs):\n    \n    obj_class = obj.__class__\n    if obj_class is bool or obj_class is NoneType:\n        # we can not have a standing for bool or NoneType\n        # because too many code uses a is True or a is None.\n        # Also you can never get isinstance(standin, bool) and\n        # isinstance(standin, NoneType) to work because you can\n        # never extend these types.\n        return obj\n    \n    attr_names  = attrs.keys()\n    attr_names.sort()\n\n    # Contruct __reduce__ method, so the resulting class can be pickled\n    attrs_org = attrs.copy() # Create a copy to be used for the recude method\n    def __reduce__(self, ignore=None):\n        return (_standin_with_dict_for, (obj, attrs_org))\n    attrs['__reduce__'] = __reduce__\n    attrs['__reduce_ex__']= __reduce__\n\n    # create a readable class name eg. unicodeStandinWithTitleAndDescriptionAttributes\n    additions = 'And'.join(map(capfirst, attr_names))\n    id = \"%sStandInWith%sAttributes\" % (obj_class.__name__, additions.encode('ascii', 'ignore'))\n    \n    # if we allready know this type don't create it again.\n    cached_type = _defined_standins.get(id, None)\n    if not cached_type:\n        cls_attrs = dict([(attr_name, None) for attr_name in attr_names])\n        cached_type = type(id, (obj_class, object), cls_attrs)\n        _defined_standins[id] = cached_type\n    \n    # create new object based on original and copy all properties\n    try:\n        stand_in = cached_type(obj)\n    except (AttributeError, TypeError):\n        try:\n            stand_in = cached_type()\n            stand_in.__dict__.update(obj.__dict__)\n        except (AttributeError, TypeError):\n            stand_in = obj\n\n    # add extra attrs\n    try:\n        for (key, value) in attrs.iteritems():\n            setattr(stand_in, key, value)\n    except AttributeError:\n        # if nothing works return original object\n        return obj\n    \n    return stand_in", "response": "Returns a standin object that can be used as a standin for the original object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun TreeLiker with the given settings.", "response": "def run(self, cleanup=True, printOutput=False):\n        '''\n        Runs TreeLiker with the given settings.\n\n            :param cleanup: deletes temporary files after completion\n            :param printOutput: print algorithm output to the terminal\n        '''\n        self._copy_data()\n        self._batch()\n\n        dumpFile = None\n        if not printOutput:\n            dumpFile = tempfile.TemporaryFile()\n\n        p = Popen(['java', '-Xmx3G', '-cp', 'bin/TreeLiker.jar', \n                   'ida.ilp.treeLiker.TreeLikerMain', '-batch', self.batch], \n                   cwd=self.tmpdir,\n                   stdout=dumpFile,\n                   stderr=dumpFile)\n        stdout_str, stderr_str = p.communicate()\n\n        if not self.test_dataset:\n            arff = open('%s/%s.arff' % (self.tmpdir, self.basename)).read()\n            arff_test = None\n        else:\n            arff = open('%s/conversion/train.arff' % self.tmpdir).read()\n            arff_test = open('%s/conversion/test.arff' % self.tmpdir).read()\n\n        if cleanup:\n            self._cleanup()\n        \n        return (arff, arff_test)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _batch(self):\n        '''\n        Creates the batch file to run the experiment.\n        '''\n        self.batch = '%s/%s.treeliker' % (self.tmpdir, self.basename)\n\n        commands = []\n        if not self.test_dataset:\n            commands.append('set(output_type, single)')\n            commands.append(\"set(examples, '%s.txt')\" % self.basename)\n        else:\n            commands.append('set(output_type, train_test)')\n            commands.append(\"set(train_set, '%s.txt')\" % self.basename)\n            commands.append(\"set(test_set, '%s_test.txt')\" % self.basename)\n        commands.append('set(template, %s)' % self.template)\n\n        if not self.test_dataset:\n            commands.append('set(output, %s.arff)' % self.basename)\n        else:\n            commands.append('set(output, conversion)')\n\n        # Optional settings\n        for key, val in self.settings.items():\n            if val not in [None, '']:\n                commands.append('set(%s, %s)' % (key, str(val)))\n\n        commands.append('work(yes)')\n\n        with open(self.batch, 'w') as f:\n            f.write('\\n'.join(commands))", "response": "Creates the batch file to run the experiment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a Julian Day object into a specific format.", "response": "def __to_format(jd: float, fmt: str) -> float:\n    \"\"\"\n    Converts a Julian Day object into a specific format.  For\n    example, Modified Julian Day.\n    Parameters\n    ----------\n    jd: float\n    fmt: str\n\n    Returns\n    -------\n    jd: float\n    \"\"\"\n    if fmt.lower() == 'jd':\n        return jd\n    elif fmt.lower() == 'mjd':\n        return jd - 2400000.5\n    elif fmt.lower() == 'rjd':\n        return jd - 2400000\n    else:\n        raise ValueError('Invalid Format')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __from_format(jd: float, fmt: str) -> (int, float):\n    if fmt.lower() == 'jd':\n        # If jd has a fractional component of 0, then we are 12 hours into\n        # the day\n        return math.floor(jd + 0.5), jd + 0.5 - math.floor(jd + 0.5)\n    elif fmt.lower() == 'mjd':\n        return __from_format(jd + 2400000.5, 'jd')\n    elif fmt.lower() == 'rjd':\n        return __from_format(jd + 2400000, 'jd')\n    else:\n        raise ValueError('Invalid Format')", "response": "Converts a Julian Day format into the standard Julian\n    day format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a given datetime object to Julian date.", "response": "def to_jd(dt: datetime, fmt: str = 'jd') -> float:\n    \"\"\"\n    Converts a given datetime object to Julian date.\n    Algorithm is copied from https://en.wikipedia.org/wiki/Julian_day\n    All variable names are consistent with the notation on the wiki page.\n\n    Parameters\n    ----------\n    fmt\n    dt: datetime\n        Datetime object to convert to MJD\n\n    Returns\n    -------\n    jd: float\n    \"\"\"\n    a = math.floor((14-dt.month)/12)\n    y = dt.year + 4800 - a\n    m = dt.month + 12*a - 3\n\n    jdn = dt.day + math.floor((153*m + 2)/5) + 365*y + math.floor(y/4) - math.floor(y/100) + math.floor(y/400) - 32045\n\n    jd = jdn + (dt.hour - 12) / 24 + dt.minute / 1440 + dt.second / 86400 + dt.microsecond / 86400000000\n\n    return __to_format(jd, fmt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_jd(jd: float, fmt: str = 'jd') -> datetime:\n    jd, jdf = __from_format(jd, fmt)\n\n    l = jd+68569\n    n = 4*l//146097\n    l = l-(146097*n+3)//4\n    i = 4000*(l+1)//1461001\n    l = l-1461*i//4+31\n    j = 80*l//2447\n    k = l-2447*j//80\n    l = j//11\n    j = j+2-12*l\n    i = 100*(n-49)+i+l\n\n    year = int(i)\n    month = int(j)\n    day = int(k)\n\n    # in microseconds\n    frac_component = int(jdf * (1e6*24*3600))\n\n    hours = int(frac_component // (1e6*3600))\n    frac_component -= hours * 1e6*3600\n\n    minutes = int(frac_component // (1e6*60))\n    frac_component -= minutes * 1e6*60\n\n    seconds = int(frac_component // 1e6)\n    frac_component -= seconds*1e6\n\n    frac_component = int(frac_component)\n\n    dt = datetime(year=year, month=month, day=day,\n                  hour=hours, minute=minutes, second=seconds, microsecond=frac_component)\n    return dt", "response": "Converts a Julian Date to a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iterread(self, table):\n    self.log('Reading: %s'%table)\n    # Entity class\n    cls = self.FACTORIES[table]\n    f = self._open(table)\n    # csv reader\n    if unicodecsv:\n      data = unicodecsv.reader(f, encoding='utf-8-sig')\n    else:\n      data = csv.reader(f)\n    header = data.next()\n    headerlen = len(header)\n    ent = collections.namedtuple(\n      'EntityNamedTuple',\n      map(str, header)\n    )\n    for row in data:\n      if len(row) == 0:\n        continue\n      # Get rid of extra spaces.\n      row = [i.strip() for i in row]\n      # pad to length if necessary... :(\n      if len(row) < headerlen:\n        row += ['']*(headerlen-len(row))\n      yield cls.from_row(ent._make(row), self)\n    f.close()", "response": "Iterate over data from a GTFS table. Returns namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, table):\n    # Table exists\n    if table in self.by_id:\n      return self.by_id[table].values()\n    if table in self.cache:\n      return self.cache[table]\n    # Read table\n    cls = self.FACTORIES[table]\n    key = cls.KEY\n    if key:\n      if table not in self.by_id:\n        self.by_id[table] = {}\n      t = self.by_id[table]\n      for item in self.iterread(table):\n        t[item.get(key)] = item\n      return t.values()\n    if table not in self.cache:\n      self.cache[table] = []\n    t = self.cache[table]\n    for item in self.iterread(table):\n      t.append(item)\n    return t", "response": "Reads the data from the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, filename, entities, sortkey=None, columns=None):\n    if os.path.exists(filename):\n      raise IOError('File exists: %s'%filename)\n    # Make sure we have all the entities loaded.\n    if sortkey:\n      entities = sorted(entities, key=lambda x:x[sortkey])\n    if not columns:\n      columns = set()\n      for entity in entities:\n        columns |= set(entity.keys())\n      columns = sorted(columns)\n    # Write the csv file\n    with open(filename, 'wb') as f:\n      writer = unicodecsv.writer(f) # , encoding='utf-8-sig'\n      writer.writerow(columns)\n      for entity in entities:\n        writer.writerow([entity.get(column) for column in columns])", "response": "Write entities to filename in csv format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_zip(self, filename, files=None, path=None, clone=None, compress=True):\n    if filename and os.path.exists(filename):\n      raise IOError('File exists: %s'%filename)\n    files = files or []\n    arcnames = []\n    if path and os.path.isdir(path):\n      files += glob.glob(os.path.join(path, '*.txt'))\n    if compress:\n      compress_level = zipfile.ZIP_DEFLATED\n    else:\n      compress_level = zipfile.ZIP_STORED\n\n    # Write files.\n    self.log(\"Creating zip archive: %s\"%filename)\n    zf = zipfile.ZipFile(filename, 'a', compression=compress_level)\n    for f in files:\n      base = os.path.basename(f)\n      if base in arcnames:\n        self.log('... skipping: %s'%f)\n      else:\n        self.log('... adding: %s'%f)\n        arcnames.append(base)\n        zf.write(f, base)\n\n    # Clone from existing zip archive.\n    if clone and os.path.exists(clone):\n      zc = zipfile.ZipFile(clone)\n      for f in zc.namelist():\n        base = os.path.basename(f)\n        if os.path.splitext(base)[-1] != '.txt':\n          pass\n          # self.log('... skipping from clone: %s'%f)\n        elif base in arcnames:\n          self.log('... skipping from clone: %s'%f)\n        else:\n          self.log('... adding from clone: %s'%f)\n          arcnames.append(base)\n          with zc.open(f) as i:\n            data = i.read()\n          zf.writestr(base, data)\n    zf.close()", "response": "Create a zip archive."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shapes(self):\n    # Todo: Cache?\n    if self._shapes:\n      return self._shapes\n    # Group together by shape_id\n    self.log(\"Generating shapes...\")\n    ret = collections.defaultdict(entities.ShapeLine)\n    for point in self.read('shapes'):\n      ret[point['shape_id']].add_child(point)\n    self._shapes = ret\n    return self._shapes", "response": "Return the route shapes as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, validator=None, skip_relations=False):\n    validator = validation.make_validator(validator)\n    self.log('Loading...')\n    self.preload()\n    # required\n    required = [\n      'agency',\n      'stops',\n      'routes',\n      'trips',\n      'stop_times',\n      'calendar'\n    ]\n    for f in required:\n      self.log(\"Validating required file: %s\"%f)\n      data = self.read(f)\n      for i in data:\n        i.validate(validator=validator)\n        if skip_relations is False:\n          i.validate_feed(validator=validator)\n    # optional\n    optional = [\n      'calendar_dates',\n      'fare_attributes',\n      'fare_rules',\n      'shapes',\n      'frequencies',\n      'transfers',\n      'feed_info'\n    ]\n    for f in optional:\n      self.log(\"Validating optional file: %s\"%f)\n      try:\n        data = self.read(f)\n      except KeyError, e:\n        data = []\n      for i in data:\n        i.validate(validator=validator)\n        if skip_relations is False:\n          i.validate_feed(validator=validator)\n    return validator", "response": "Validate a GTFS\n\n    :param validator: a ValidationReport\n    :param (bool) skip_relations: skip validation of relations between entities (e.g. stop_times to stops)\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nallocate a piece of data that will be included in the shellcode body.", "response": "def alloc_data(self, value):\n        \"\"\"\n        Allocate a piece of data that will be included in the shellcode body.\n\n        Arguments:\n            value(...): The value to add to the shellcode. Can be bytes or\n                string type.\n\n        Returns:\n            ~pwnypack.types.Offset: The offset used to address the data.\n        \"\"\"\n\n        if isinstance(value, six.binary_type):\n            return self._alloc_data(value)\n        elif isinstance(value, six.text_type):\n            return self._alloc_data(value.encode('utf-8') + b'\\0')\n        else:\n            raise TypeError('No idea how to encode %s' % repr(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallocates a buffer (a range of uninitialized memory). Arguments: length(int): The length of the buffer to allocate. Returns: ~pwnypack.types.Buffer: The object used to address this buffer.", "response": "def alloc_buffer(self, length):\n        \"\"\"\n        Allocate a buffer (a range of uninitialized memory).\n\n        Arguments:\n            length(int): The length of the buffer to allocate.\n\n        Returns:\n            ~pwnypack.types.Buffer: The object used to address this buffer.\n        \"\"\"\n\n        buf = Buffer(sum(len(v) for v in six.iterkeys(self.data)) + sum(v.length for v in self.buffers), length)\n        self.buffers.append(buf)\n        return buf"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reg_load(self, reg, value):\n\n        if isinstance(value, (six.text_type, six.binary_type)):\n            value = self.alloc_data(value)\n\n        if value is None:\n            return self.reg_load_imm(reg, 0)\n\n        elif isinstance(value, Register):\n            if reg is not value:\n                return self.reg_load_reg(reg, value)\n            else:\n                return []\n\n        elif isinstance(value, Offset):\n            if value:\n                return self.reg_load_offset(reg, value)\n            else:\n                return self.reg_load(reg, self.OFFSET_REG)\n\n        elif isinstance(value, Buffer):\n            return self.reg_load_offset(reg, sum(len(v) for v in six.iterkeys(self.data)) + value.offset)\n\n        elif isinstance(value, six.integer_types):\n            reg_width = self.REGISTER_WIDTH[reg]\n            if value < -2 ** (reg_width-1):\n                raise ValueError('%d does not fit %s' % (value, reg))\n            elif value >= 2 ** reg_width:\n                raise ValueError('%d does not fit %s' % (value, reg))\n            return self.reg_load_imm(reg, value)\n\n        elif isinstance(value, (list, tuple)):\n            return self.reg_load_array(reg, value)\n\n        elif isinstance(value, SyscallInvoke):\n            return self.syscall(value) + self.reg_load(reg, self.SYSCALL_RET_REG)\n\n        else:\n            raise TypeError('Invalid argument type \"%s\"' % repr(value))", "response": "Load a value into a register."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a value to a register.", "response": "def reg_add(self, reg, value):\n        \"\"\"\n        Add a value to a register. The value can be another :class:`Register`,\n        an :class:`Offset`, a :class:`Buffer`, an integer or ``None``.\n\n        Arguments:\n            reg(pwnypack.shellcode.types.Register): The register to add the\n                value to.\n            value: The value to add to the register.\n\n        Returns:\n            list: A list of mnemonics that will add ``value`` to ``reg``.\n        \"\"\"\n\n        if value is None:\n            return []\n\n        elif isinstance(value, Register):\n            return self.reg_add_reg(reg, value)\n\n        elif isinstance(value, (Buffer, six.integer_types)):\n            if isinstance(reg, Buffer):\n                value = sum(len(v) for v in six.iterkeys(self.data)) + value.offset\n\n            if not value:\n                return []\n\n            reg_width = self.REGISTER_WIDTH[reg]\n            if value < -2 ** (reg_width-1):\n                raise ValueError('%d does not fit %s' % (value, reg))\n            elif value >= 2 ** reg_width:\n                raise ValueError('%d does not fit %s' % (value, reg))\n\n            if value > 0:\n                return self.reg_add_imm(reg, value)\n            else:\n                return self.reg_sub_imm(reg, -value)\n\n        else:\n            raise ValueError('Invalid argument type \"%s\"' % repr(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate a list of operations into its assembler source code.", "response": "def compile(self, ops):\n        \"\"\"\n        Translate a list of operations into its assembler source.\n\n        Arguments:\n            ops(list): A list of shellcode operations.\n\n        Returns:\n            str: The assembler source code that implements the shellcode.\n        \"\"\"\n\n        def _compile():\n            code = []\n\n            for op in ops:\n                if isinstance(op, SyscallInvoke):\n                    code.extend(self.syscall(op))\n                elif isinstance(op, LoadRegister):\n                    code.extend(self.reg_load(op.register, op.value))\n                elif isinstance(op, str):\n                    code.extend(op.split('\\n'))\n                else:\n                    raise ValueError('No idea how to assemble \"%s\"' % repr(op))\n            return ['\\t%s' % line for line in code]\n\n        # We do 2 passes to make sure all data is allocated so buffers point at the right offset.\n        _compile()\n        return '\\n'.join(self.finalize(self.data_finalizer(_compile(), self.data))) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assemble(self, ops):\n\n        return pwnypack.asm.asm(self.compile(ops), target=self.target)", "response": "Assemble a list of operations into executable code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normal_equation(x, y):\n    num_samples = y.size\n    x = np.insert(x, 0, np.ones(num_samples), axis=1)\n\n    return pinv(x)*y", "response": "Normal equation for the Caffe decomposition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading n bytes from the subprocess output channel.", "response": "def read(self, n):\n        \"\"\"\n        Read *n* bytes from the subprocess' output channel.\n\n        Args:\n            n(int): The number of bytes to read.\n\n        Returns:\n            bytes: *n* bytes of output.\n\n        Raises:\n            EOFError: If the process exited.\n        \"\"\"\n\n        d = b''\n        while n:\n            try:\n                block = self._process.stdout.read(n)\n            except ValueError:\n                block = None\n            if not block:\n                self._process.poll()\n                raise EOFError('Process ended')\n            d += block\n            n -= len(block)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, data):\n\n        self._process.poll()\n        if self._process.returncode is not None:\n            raise EOFError('Process ended')\n        self._process.stdin.write(data)", "response": "Writes data to the subprocess input channel."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, n):\n\n        d = b''\n        while n:\n            try:\n                block = self._socket.recv(n)\n            except socket.error:\n                block = None\n            if not block:\n                raise EOFError('Socket closed')\n            d += block\n            n -= len(block)\n        return d", "response": "Reads n bytes from the socket and returns them as a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, data):\n\n        while data:\n            try:\n                n = self._socket.send(data)\n            except socket.error:\n                n = None\n            if not n:\n                raise EOFError('Socket closed')\n            data = data[n:]", "response": "Send data to the socket."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kill(self):\n\n        self._socket.shutdown(socket.SHUT_RDWR)\n        self._socket.close()", "response": "Kill the socket immediately."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, n, echo=None):\n\n        d = self.channel.read(n)\n        if echo or (echo is None and self.echo):\n            sys.stdout.write(d.decode('latin1'))\n            sys.stdout.flush()\n        return d", "response": "Reads n bytes from the channel and returns them as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads until the channel is closed.", "response": "def read_eof(self, echo=None):\n        \"\"\"\n        Read until the channel is closed.\n\n        Args:\n            echo(bool): Whether to write the read data to stdout.\n\n        Returns:\n            bytes: The read data.\n        \"\"\"\n\n        d = b''\n        while True:\n            try:\n                d += self.read(1, echo)\n            except EOFError:\n                return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading until a certain string is encountered.", "response": "def read_until(self, s, echo=None):\n        \"\"\"\n        Read until a certain string is encountered..\n\n        Args:\n            s(bytes): The string to wait for.\n            echo(bool): Whether to write the read data to stdout.\n\n        Returns:\n            bytes: The data up to and including *s*.\n\n        Raises:\n            EOFError: If the channel was closed.\n        \"\"\"\n\n        s_len = len(s)\n        buf = self.read(s_len, echo)\n\n        while buf[-s_len:] != s:\n            buf += self.read(1, echo)\n\n        return buf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread n lines from the channel.", "response": "def readlines(self, n, echo=None):\n        \"\"\"\n        Read *n* lines from channel.\n\n        Args:\n            n(int): The number of lines to read.\n            echo(bool): Whether to write the read data to stdout.\n\n        Returns:\n            list of bytes: *n* lines which include new line characters.\n\n        Raises:\n            EOFError: If the channel was closed before *n* lines were read.\n        \"\"\"\n\n        return [\n            self.until(b'\\n', echo)\n            for _ in range(n)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, data, echo=None):\n\n        if echo or (echo is None and self.echo):\n            sys.stdout.write(data.decode('latin1'))\n            sys.stdout.flush()\n        self.channel.write(data)", "response": "Writes data to the channel."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a list of byte sequences to the channel and terminate them with a separator.", "response": "def writelines(self, lines, sep=b'\\n', echo=None):\n        \"\"\"\n        Write a list of byte sequences to the channel and terminate them\n        with a separator (line feed).\n\n        Args:\n            lines(list of bytes): The lines to send.\n            sep(bytes): The separator to use after each line.\n            echo(bool): Whether to echo the written data to stdout.\n\n        Raises:\n            EOFError: If the channel was closed before all data was sent.\n        \"\"\"\n\n        self.write(sep.join(lines + [b'']), echo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef writeline(self, line=b'', sep=b'\\n', echo=None):\n\n        self.writelines([line], sep, echo)", "response": "Writes a byte sequence to the channel and terminate it with carriage\n        return and line feed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninteracts with the socket.", "response": "def interact(self):\n        \"\"\"\n        Interact with the socket. This will send all keyboard input to the\n        socket and input from the socket to the console until an EOF occurs.\n        \"\"\"\n\n        sockets = [sys.stdin, self.channel]\n        while True:\n            ready = select.select(sockets, [], [])[0]\n\n            if sys.stdin in ready:\n                line = sys.stdin.readline().encode('latin1')\n                if not line:\n                    break\n                self.write(line)\n\n            if self.channel in ready:\n                self.read(1, echo=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(cls, executable, *arguments, **kwargs):\n\n        echo = kwargs.pop('echo', False)\n        return cls(ProcessChannel(executable, *arguments, **kwargs), echo=echo)", "response": "Execute a process on the specified executable and return a Flow instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to a TCP socket and return a Flow instance.", "response": "def connect_tcp(cls, host, port, echo=False):\n        \"\"\"\n        Set up a :class:`TCPClientSocketChannel` and create a :class:`Flow`\n        instance for it.\n\n        Args:\n            host(str): The hostname or IP address to connect to.\n            port(int): The port number to connect to.\n            echo(bool): Whether to echo read/written data to stdout by default.\n\n        Returns:\n            :class:`Flow`: A Flow instance initialised with the TCP socket\n                channel.\n        \"\"\"\n\n        return cls(TCPClientSocketChannel(host, port), echo=echo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listen_tcp(cls, host='', port=0, echo=False):\n\n        return cls(TCPServerSocketChannel(host, port), echo=echo)", "response": "Create a new TCPServerSocketChannel instance and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect_ssh(*args, **kwargs):\n\n        client = SSHClient()\n        client.connect(*args, **kwargs)\n        return client", "response": "Create a new SSHClient instance. All arguments are passed to SSHClient. connect."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a command on a remote server.", "response": "def execute_ssh(cls, command, *args, **kwargs):\n        \"\"\"execute_ssh(command, arguments..., pty=False, echo=False)\n\n        Execute `command` on a remote server. It first calls\n        :meth:`Flow.connect_ssh` using all positional and keyword\n        arguments, then calls :meth:`SSHClient.execute` with the command\n        and pty / echo options.\n\n        Args:\n            command(str): The command to execute on the remote server.\n            arguments...: The options for the SSH connection.\n            pty(bool): Request a pseudo-terminal from the server.\n            echo(bool): Whether to echo read/written data to stdout by default.\n\n        Returns:\n            :class:`Flow`: A Flow instance initialised with the SSH channel.\n        \"\"\"\n\n        pty = kwargs.pop('pty', False)\n        echo = kwargs.pop('echo', False)\n        client = cls.connect_ssh(*args, **kwargs)\n        f = client.execute(command, pty=pty, echo=echo)\n        f.client = client\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invoke_ssh_shell(cls, *args, **kwargs):\n\n        pty = kwargs.pop('pty', True)\n        echo = kwargs.pop('echo', False)\n        client = cls.connect_ssh(*args, **kwargs)\n        f = client.invoke_shell(pty=pty, echo=echo)\n        f.client = client\n        return f", "response": "This method is used to connect to a remote server and invoke a new shell on the remote server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toxml(cls):\n    \n    if cls._meta.abstract:\n        raise Exception(\"You can not use toxml on abstract classes\")\n        \n    def __xml__(self):\n        \"\"\"turn model object into xml recursively\"\"\"\n        ser = RecursiveXmlSerializer()\n        return ser.serialize([self])\n    \n    cls.add_to_class('objects', QuerySetManager(XmlSerializableQuerySet))\n    cls.__xml__ = __xml__\n    return cls", "response": "A decorator that creates a new class that can be used to serialize the object into xml."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all possible importers that can handle the specified files.", "response": "def get_possible_importers(file_uris, current_doc=None):\n    \"\"\"\n    Return all the importer objects that can handle the specified files.\n\n    Possible imports may vary depending on the currently active document\n    \"\"\"\n    importers = []\n    for importer in IMPORTERS:\n        if importer.can_import(file_uris, current_doc):\n            importers.append(importer)\n    return importers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef can_import(self, file_uris, current_doc=None):\n        if len(file_uris) <= 0:\n            return False\n        for uri in file_uris:\n            uri = self.fs.safe(uri)\n            if not self.check_file_type(uri):\n                return False\n        return True", "response": "Check that the specified file looks like a PDF and returns True if it can be imported."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports the specified PDF file and return a ImportResult object.", "response": "def import_doc(self, file_uris, docsearch, current_doc=None):\n        \"\"\"\n        Import the specified PDF file\n        \"\"\"\n        doc = None\n        docs = []\n        pages = []\n\n        file_uris = [self.fs.safe(uri) for uri in file_uris]\n        imported = []\n        for file_uri in file_uris:\n            if docsearch.is_hash_in_index(PdfDoc.hash_file(self.fs, file_uri)):\n                logger.info(\"Document %s already found in the index. Skipped\"\n                            % (file_uri))\n                continue\n\n            doc = PdfDoc(self.fs, docsearch.rootdir)\n            logger.info(\"Importing doc '%s' ...\" % file_uri)\n            error = doc.import_pdf(file_uri)\n            if error:\n                raise Exception(\"Import of {} failed: {}\".format(\n                    file_uri, error\n                ))\n            imported.append(file_uri)\n            docs.append(doc)\n            pages += [p for p in doc.pages]\n\n        return ImportResult(\n            imported_file_uris=imported,\n            select_doc=doc, new_docs=docs,\n            new_docs_pages=pages,\n            stats={\n                _(\"PDF\"): len(imported),\n                _(\"Document(s)\"): len(imported),\n                _(\"Page(s)\"): len(pages),\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that the specified file is a directory containing manyCOOKIE files and return True if it can be imported.", "response": "def can_import(self, file_uris, current_doc=None):\n        \"\"\"\n        Check that the specified file looks like a directory containing many\n        pdf files\n        \"\"\"\n        if len(file_uris) <= 0:\n            return False\n        try:\n            for file_uri in file_uris:\n                file_uri = self.fs.safe(file_uri)\n                for child in self.fs.recurse(file_uri):\n                    if self.check_file_type(child):\n                        return True\n        except GLib.GError:\n            pass\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport the specified PDF files and return a list of the pages and the number of documents imported.", "response": "def import_doc(self, file_uris, docsearch, current_doc=None):\n        \"\"\"\n        Import the specified PDF files\n        \"\"\"\n\n        doc = None\n        docs = []\n        pages = []\n\n        file_uris = [self.fs.safe(uri) for uri in file_uris]\n        imported = []\n        for file_uri in file_uris:\n            logger.info(\"Importing PDF from '%s'\" % (file_uri))\n            idx = 0\n\n            for child in self.fs.recurse(file_uri):\n                gc.collect()\n                if not self.check_file_type(child):\n                    continue\n                h = PdfDoc.hash_file(self.fs, child)\n                if docsearch.is_hash_in_index(h):\n                    logger.info(\n                        \"Document %s already found in the index. Skipped\",\n                        child\n                    )\n                    continue\n                imported.append(child)\n                doc = PdfDoc(self.fs, docsearch.rootdir)\n                error = doc.import_pdf(child)\n                if error:\n                    continue\n                docs.append(doc)\n                pages += [p for p in doc.pages]\n                idx += 1\n        return ImportResult(\n            imported_file_uris=imported,\n            select_doc=doc, new_docs=docs,\n            new_docs_pages=pages,\n            stats={\n                _(\"PDF\"): len(docs),\n                _(\"Document(s)\"): len(docs),\n                _(\"Page(s)\"): sum([d.nb_pages for d in docs]),\n            },\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_doc(self, file_uris, docsearch, current_doc=None):\n        if (current_doc is None or\n                current_doc.is_new or\n                not current_doc.can_edit):\n            if not current_doc or not current_doc.can_edit:\n                current_doc = ImgDoc(self.fs, docsearch.rootdir)\n            new_docs = [current_doc]\n            upd_docs = []\n        else:\n            new_docs = []\n            upd_docs = [current_doc]\n        new_docs_pages = []\n        upd_docs_pages = []\n        page = None\n\n        file_uris = natsorted(file_uris)\n        imported = []\n\n        for file_uri in file_uris:\n            file_uri = self.fs.safe(file_uri)\n            logger.info(\"Importing images from '%s'\" % (file_uri))\n\n            for child in self.fs.recurse(file_uri):\n                if \".thumb.\" in child:\n                    # We are re-importing an old document --> ignore thumbnails\n                    logger.info(\"{} ignored\".format(child))\n                    continue\n                if not self.check_file_type(child):\n                    continue\n                imported.append(child)\n                with self.fs.open(child, \"rb\") as fd:\n                    img = Image.open(fd)\n                    img.load()\n                page = current_doc.add_page(img, [])\n                if new_docs == []:\n                    upd_docs_pages.append(page)\n                else:\n                    new_docs_pages.append(page)\n\n        return ImportResult(\n            imported_file_uris=imported,\n            select_doc=current_doc, select_page=page,\n            new_docs=new_docs, upd_docs=upd_docs,\n            new_docs_pages=new_docs_pages,\n            upd_docs_pages=upd_docs_pages,\n            stats={\n                _(\"Image file(s)\"): len(file_uris),\n                _(\"Document(s)\"): 0 if new_docs == [] else 1,\n                _(\"Page(s)\"): len(new_docs_pages) + len(upd_docs_pages),\n            }\n        )", "response": "Import the specified PDF files and return a ImportResult object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the specified file is a valid image and that the image can be imported.", "response": "def can_import(self, file_uris, current_doc=None):\n        \"\"\"\n        Check that the specified file looks like an image supported by PIL\n        \"\"\"\n        if len(file_uris) <= 0:\n            return False\n        for file_uri in file_uris:\n            file_uri = self.fs.safe(file_uri)\n            if not self.check_file_type(file_uri):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms cyclical exclusive or operations on data.", "response": "def xor(key, data):\n    \"\"\"\n    Perform cyclical exclusive or operations on ``data``.\n\n    The ``key`` can be a an integer *(0 <= key < 256)* or a byte sequence. If\n    the key is smaller than the provided ``data``, the ``key`` will be\n    repeated.\n\n    Args:\n        key(int or bytes): The key to xor ``data`` with.\n        data(bytes): The data to perform the xor operation on.\n\n    Returns:\n        bytes: The result of the exclusive or operation.\n\n    Examples:\n        >>> from pwny import *\n        >>> xor(5, b'ABCD')\n        b'DGFA'\n        >>> xor(5, b'DGFA')\n        b'ABCD'\n        >>> xor(b'pwny', b'ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n        b'15-=51)19=%5=9!)!%=-%!9!)-'\n        >>> xor(b'pwny', b'15-=51)19=%5=9!)!%=-%!9!)-')\n        b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    \"\"\"\n\n    if type(key) is int:\n        key = six.int2byte(key)\n    key_len = len(key)\n\n    return b''.join(\n        six.int2byte(c ^ six.indexbytes(key, i % key_len))\n        for i, c in enumerate(six.iterbytes(data))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef caesar(shift, data, shift_ranges=('az', 'AZ')):\n    alphabet = dict(\n        (chr(c), chr((c - s + shift) % (e - s + 1) + s))\n        for s, e in map(lambda r: (ord(r[0]), ord(r[-1])), shift_ranges)\n        for c in range(s, e + 1)\n    )\n    return ''.join(alphabet.get(c, c) for c in data)", "response": "Apply a caesar cipher to a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enhex(d, separator=''):\n\n    v = binascii.hexlify(d).decode('ascii')\n    if separator:\n        return separator.join(\n            v[i:i+2]\n            for i in range(0, len(v), 2)\n        )\n    else:\n        return v", "response": "Convert bytes to their hexadecimal representation optionally joined by a\n    given separator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef caesar_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('shift', type=int, help='the shift to apply')\n    parser.add_argument('value', help='the value to caesar crypt, read from stdin if omitted', nargs='?')\n    parser.add_argument(\n        '-s', '--shift-range',\n        dest='shift_ranges',\n        action='append',\n        help='specify a character range to shift (defaults to a-z, A-Z)'\n    )\n\n    args = parser.parse_args(args)\n    if not args.shift_ranges:\n        args.shift_ranges = ['az', 'AZ']\n\n    return caesar(args.shift, pwnypack.main.string_value_or_stdin(args.value), args.shift_ranges)", "response": "Caesar crypt a value with a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rot13_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('value', help='the value to rot13, read from stdin if omitted', nargs='?')\n    args = parser.parse_args(args)\n    return rot13(pwnypack.main.string_value_or_stdin(args.value))", "response": "rot13 encrypt a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enb64_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('value', help='the value to base64 encode, read from stdin if omitted', nargs='?')\n    args = parser.parse_args(args)\n    return enb64(pwnypack.main.binary_value_or_stdin(args.value))", "response": "base64 encode a value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enhex_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('value', help='the value to hex encode, read from stdin if omitted', nargs='?')\n    parser.add_argument(\n        '--separator', '-s',\n        default='',\n        help='the separator to place between hex tuples'\n    )\n    args = parser.parse_args(args)\n    return enhex(pwnypack.main.binary_value_or_stdin(args.value), args.separator)", "response": "hex encode a value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dehex_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('value', help='the value to base64 decode, read from stdin if omitted', nargs='?')\n    args = parser.parse_args(args)\n    return dehex(pwnypack.main.string_value_or_stdin(args.value))", "response": "hex decode a value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enurlform_app(parser, cmd, args):  # pragma: no cover\n\n    parser.add_argument('values', help='the key=value pairs to URL encode', nargs='+')\n    args = parser.parse_args(args)\n    return enurlform(dict(v.split('=', 1) for v in args.values))", "response": "Encode a series of key = value pairs into a query string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes a query string into its key value pairs.", "response": "def deurlform_app(parser, cmd, args):  # pragma: no cover\n    \"\"\"\n    decode a query string into its key value pairs.\n    \"\"\"\n\n    parser.add_argument('value', help='the query string to decode')\n    args = parser.parse_args(args)\n    return ' '.join('%s=%s' % (key, value) for key, values in deurlform(args.value).items() for value in values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform frequency analysis on a value.", "response": "def frequency_app(parser, cmd, args):  # pragma: no cover\n    \"\"\"\n    perform frequency analysis on a value.\n    \"\"\"\n\n    parser.add_argument('value', help='the value to analyse, read from stdin if omitted', nargs='?')\n    args = parser.parse_args(args)\n    data = frequency(six.iterbytes(pwnypack.main.binary_value_or_stdin(args.value)))\n    return '\\n'.join(\n        '0x%02x (%c): %d' % (key, chr(key), value)\n        if key >= 32 and chr(key) in string.printable else\n        '0x%02x ---: %d' % (key, value)\n        for key, value in data.items()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the circuit breaker with an error event.", "response": "def error(self, err=None):\n        \"\"\"Update the circuit breaker with an error event.\"\"\"\n        if self.state == 'half-open':\n            self.test_fail_count = min(self.test_fail_count + 1, 16)\n        self.errors.append(self.clock())\n        if len(self.errors) > self.maxfail:\n            time = self.clock() - self.errors.pop(0)\n            if time < self.time_unit:\n                if time == 0:\n                    time = 0.0001\n                self.log.debug('error rate: %f errors per second' % (\n                        float(self.maxfail) / time))\n                self.open(err)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a circuit breaker for the given ID.", "response": "def context(self, id):\n        \"\"\"Return a circuit breaker for the given ID.\"\"\"\n        if id not in self.circuits:\n            self.circuits[id] = self.factory(self.clock, self.log.getChild(id),\n                                             self.error_types, self.maxfail,\n                                             self.reset_timeout,\n                                             self.time_unit,\n                                             backoff_cap=self.backoff_cap,\n                                             with_jitter=self.with_jitter)\n        return self.circuits[id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shell(_parser, cmd, args):  # pragma: no cover\n\n    parser = argparse.ArgumentParser(\n        prog=_parser.prog,\n        description=_parser.description,\n    )\n\n    group = parser.add_mutually_exclusive_group()\n    group.set_defaults(shell=have_bpython and 'bpython' or (have_IPython and 'ipython' or 'python'))\n    if have_bpython:\n        group.add_argument(\n            '--bpython',\n            action='store_const',\n            dest='shell',\n            const='bpython',\n            help='Use the bpython interpreter'\n        )\n    if have_IPython:\n        group.add_argument(\n            '--ipython',\n            action='store_const',\n            dest='shell',\n            const='ipython',\n            help='Use the IPython interpreter'\n        )\n    group.add_argument(\n        '--python',\n        action='store_const',\n        dest='shell',\n        const='python',\n        help='Use the default python interpreter'\n    )\n\n    args = parser.parse_args(args)\n\n    import pwny\n    pwny_locals = dict(\n        (key, getattr(pwny, key))\n        for key in dir(pwny)\n        if not key.startswith('__') and not key == 'shell'\n    )\n\n    if args.shell == 'bpython':\n        from bpython import embed\n        embed(pwny_locals, banner=BANNER)\n    elif args.shell == 'ipython':\n        from IPython import start_ipython\n        start_ipython(\n            argv=['--ext=pwnypack.ipython_ext'],\n        )\n    else:\n        import code\n        code.interact(BANNER, local=pwny_locals)", "response": "Start an interactive python interpreter with pwny imported globally."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of python internals for the requested python version.", "response": "def get_py_internals(version=None, default=None):\n    \"\"\"\n    Given a version specification. It can be any dict which is returned\n    verbatim, an index into :data:`PY_INTERNALS` or ``None``.\n\n    Arguments:\n        version: The python version to return the internals of.\n        default: The python version that will be looked up if ``version`` is\n            None.\n\n    Returns:\n        dict: The python internals for the requested version.\n    \"\"\"\n\n    if version is None:\n        version = default\n\n    if isinstance(version, dict):\n        return version\n    elif version in PY_INTERNALS:\n        return PY_INTERNALS[version]\n    else:\n        return ValueError('Unsupported python version %r requested.' % version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_sequence(self):\n    return sorted(\n      self.stop_times(),\n      key=lambda x:int(x.get('stop_sequence'))\n    )", "response": "Return the sorted StopTimes for this trip."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getGestureAndSegments(points):\n    strokes, strokeSegments = _identifyStrokes(points)\n    return list(zip(strokes, strokeSegments))", "response": "Returns a list of tuples that are the directional stroke and the list of segments that make up the stroke."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the closest gesture in gestureList that matches the given strokes.", "response": "def findClosestMatchingGesture(strokes, gestureList, maxDifference=None):\n    \"\"\"\n    Returns the gesture(s) in `gestureList` that closest matches the gesture in\n    `strokes`. The `maxDifference` is how many differences there can be and still\n    be considered a match.\n    \"\"\"\n    if len(gestureList) == 0:\n        return None\n\n    #gestureList = [list(frozenset(tuple(gesture))) for gesture in gestureList] # make a unique list\n    gestureList = frozenset([tuple(gesture) for gesture in gestureList])\n    distances = {}\n    for g in gestureList:\n        levDist = levenshteinDistance(strokes, g)\n        if maxDifference is None or levDist <= maxDifference:\n            distances.setdefault(levDist, [])\n            distances[levDist].append(g)\n\n    if not distances:\n        return None # No matching gestures are within the tolerance of maxDifference.\n\n    return tuple(distances[min(distances.keys())])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the Levenshtein Distance between two strings s1 and s2 as an an", "response": "def levenshteinDistance(s1, s2):\n    \"\"\"\n    Returns the Levenshtein Distance between two strings, `s1` and `s2` as an\n    integer.\n\n    http://en.wikipedia.org/wiki/Levenshtein_distance\n    The Levenshtein Distance (aka edit distance) is how many changes (i.e.\n    insertions, deletions, substitutions) have to be made to convert one\n    string into another.\n\n    For example, the Levenshtein distance between \"kitten\" and \"sitting\" is\n    3, since the following three edits change one into the other, and there\n    is no way to do it with fewer than three edits:\n      kitten -> sitten -> sittin -> sitting\n    \"\"\"\n    singleLetterMapping = {DOWNLEFT: '1', DOWN:'2', DOWNRIGHT:'3',\n                           LEFT:'4', RIGHT:'6',\n                           UPLEFT:'7', UP:'8', UPRIGHT:'9'}\n\n    len1 = len([singleLetterMapping[letter] for letter in s1])\n    len2 = len([singleLetterMapping[letter] for letter in s2])\n\n    matrix = list(range(len1 + 1)) * (len2 + 1)\n    for i in range(len2 + 1):\n        matrix[i] = list(range(i, i + len1 + 1))\n    for i in range(len2):\n        for j in range(len1):\n            if s1[j] == s2[i]:\n                matrix[i+1][j+1] = min(matrix[i+1][j] + 1, matrix[i][j+1] + 1, matrix[i][j])\n            else:\n                matrix[i+1][j+1] = min(matrix[i+1][j] + 1, matrix[i][j+1] + 1, matrix[i][j] + 1)\n    return matrix[len2][len1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the direction of the line formed by the ( x y ) coordinates.", "response": "def _getDirection(coord1, coord2):\n    \"\"\"\n    Return the direction the line formed by the (x, y)\n    points in `coord1` and `coord2`.\n    \"\"\"\n    x1, y1 = coord1\n    x2, y2 = coord2\n\n    if x1 == x2 and y1 == y2:\n        return None # two coordinates are the same.\n    elif x1 == x2 and y1 > y2:\n        return UP\n    elif x1 == x2 and y1 < y2:\n        return DOWN\n    elif x1 > x2 and y1 == y2:\n        return LEFT\n    elif x1 < x2 and y1 == y2:\n        return RIGHT\n\n    slope = float(y2 - y1) / float(x2 - x1)\n\n    # Figure out which quadrant the line is going in, and then\n    # determine the closest direction by calculating the slope\n    if x2 > x1 and y2 < y1: # up right quadrant\n        if slope > -0.4142:\n            return RIGHT # slope is between 0 and 22.5 degrees\n        elif slope < -2.4142:\n            return UP # slope is between 67.5 and 90 degrees\n        else:\n            return UPRIGHT # slope is between 22.5 and 67.5 degrees\n    elif x2 > x1 and y2 > y1: # down right quadrant\n        if slope > 2.4142:\n            return DOWN\n        elif slope < 0.4142:\n            return RIGHT\n        else:\n            return DOWNRIGHT\n    elif x2 < x1 and y2 < y1: # up left quadrant\n        if slope < 0.4142:\n            return LEFT\n        elif slope > 2.4142:\n            return UP\n        else:\n            return UPLEFT\n    elif x2 < x1 and y2 > y1: # down left quadrant\n        if slope < -2.4142:\n            return DOWN\n        elif slope > -0.4142:\n            return LEFT\n        else:\n            return DOWNLEFT"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _distance(coord1, coord2):\n    xdist = coord1[0] - coord2[0]\n    ydist = coord1[1] - coord2[1]\n    return sqrt(xdist*xdist + ydist*ydist)", "response": "Return the distance between two points coord1 and coord2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_localised_form(model, form, exclude=None):\n    \n    newfields = {}  \n    \n    for localized_field in model.localized_fields:\n        # get the descriptor, which contains the form field\n        default_field_descriptor = getattr(model, localized_field)\n        \n        # See if we've got overridden fields in a custom form.\n        if hasattr(form, 'declared_fields'):\n            form_field = form.declared_fields.get(\n                localized_field, default_field_descriptor.form_field)\n        else:\n            form_field = default_field_descriptor.form_field\n         \n        # wrap the widget to show the origin of the value;\n        # either database, catalog or fallback.\n        if type(form_field.widget) is not WidgetWrapper:\n            form_field.widget = WidgetWrapper(form_field.widget)\n         \n        newfields[localized_field] = form_field\n \n    if hasattr(form, 'Meta'):\n         setattr(form.Meta, 'model', model)\n    else:\n         newfields['Meta'] = type('Meta', tuple(), {'model':model})\n    \n    newfields['localized_fields'] = model.localized_fields\n    \n    return ModelFormMetaclass(model.__name__, (LocalisedForm, form), newfields)", "response": "This function creates a new form for a model with internationalised \n    field. The model should be decorated with the L10N decorater. The form should be a ModelFormMetaclass class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides save method to also save the localised fields.", "response": "def save(self, commit=True):\n        \"\"\"\n        Override save method to also save the localised fields.\n        \"\"\"\n        # set the localised fields\n        for localized_field in self.instance.localized_fields:\n            setattr(self.instance, localized_field, self.cleaned_data[localized_field])\n\n        return super(LocalisedForm, self).save(commit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the uniqueness of fields but also handles the localized_fields.", "response": "def validate_unique(self):\n        \"\"\"\n        Validates the uniqueness of fields, but also handles the localized_fields.\n        \"\"\"\n        form_errors = []\n        try:\n            super(LocalisedForm, self).validate_unique()\n        except ValidationError as e:\n            form_errors += e.messages\n\n        # add unique validation for the localized fields.\n        localized_fields_checks = self._get_localized_field_checks()\n        bad_fields = set()\n\n        field_errors, global_errors = self._perform_unique_localized_field_checks(localized_fields_checks)\n        bad_fields.union(field_errors)\n        form_errors.extend(global_errors)\n        \n        for field_name in bad_fields:\n            del self.cleaned_data[field_name]\n        if form_errors:\n            # Raise the unique together errors since they are considered\n            # form-wide.\n            raise ValidationError(form_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_localized_field_checks(self):\n        localized_fields_checks = []\n        for localized_field in self.instance.localized_fields:\n            if self.cleaned_data.get(localized_field) is None:\n                continue\n            f = getattr(self.instance.__class__, localized_field, None)\n            if f and f.unique:\n                if f.unique:\n                    local_name = get_real_fieldname(localized_field, self.language)\n                    localized_fields_checks.append((localized_field, local_name))\n                    \n        return localized_fields_checks", "response": "Get the checks we must perform for the localized fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms the checks for the localized fields.", "response": "def _perform_unique_localized_field_checks(self, unique_checks):\n        \"\"\"\n        Do the checks for the localized fields.\n        \"\"\"\n        bad_fields = set()\n        form_errors = []\n\n        for (field_name, local_field_name) in unique_checks:\n            \n            lookup_kwargs = {}\n            lookup_value = self.cleaned_data[field_name]\n            # ModelChoiceField will return an object instance rather than\n            # a raw primary key value, so convert it to a pk value before\n            # using it in a lookup.\n            lookup_value = getattr(lookup_value, 'pk', lookup_value)\n            lookup_kwargs[str(local_field_name)] = lookup_value\n\n            qs = self.instance.__class__._default_manager.filter(**lookup_kwargs)\n\n            # Exclude the current object from the query if we are editing an\n            # instance (as opposed to creating a new one)\n            if self.instance.pk is not None:\n                qs = qs.exclude(pk=self.instance.pk)\n\n            # This cute trick with extra/values is the most efficient way to\n            # tell if a particular query returns any results.\n            if qs.extra(select={'a': 1}).values('a').order_by():\n                self._errors[field_name] = ErrorList([self.unique_error_message([field_name])])\n                bad_fields.add(field_name)\n                \n        return bad_fields, form_errors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind missing modules that are not available in the setuptools package.", "response": "def find_missing_modules():\n    \"\"\"\n    look for dependency that setuptools cannot check or that are too painful to\n    install with setuptools\n    \"\"\"\n    missing_modules = []\n\n    for module in MODULES:\n        try:\n            __import__(module[1])\n        except ImportError:\n            missing_modules.append(module)\n    return missing_modules"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(self, locale, app=None, **options):\n        translation.activate(settings.LANGUAGE_CODE)\n        if app:\n            unpack = app.split('.')\n\n            if len(unpack) == 2:\n                models = [get_model(unpack[0], unpack[1])]\n            elif len(unpack) == 1:\n                models = get_models(get_app(unpack[0]))\n        else:\n            models = get_models()\n            \n        for model in models:\n            if hasattr(model, 'localized_fields'):\n                i18n.unregister(model)\n                model_full_name = '%s.%s' % (model._meta.app_label, model._meta.module_name)\n                update_instances = set()\n                messages = []\n                \n                for instance in model.objects.all():\n                    for field in model.localized_fields:\n                        local_field_name = get_real_fieldname(field, locale)\n                        \n                        if  hasattr(instance, local_field_name):\n                                local_field_value = getattr(instance, local_field_name)\n                                if local_field_value not in (None, u''):\n                                    setattr(instance, local_field_name, None)\n                                \n                                    update_instances.add(instance)\n                                    messages.append(u\"%s %s %s : %s will become reset to None\" % (model_full_name, instance, local_field_name, force_unicode(local_field_value)))\n\n                if len(update_instances):\n                    if self.ask_for_confirmation(messages, u'%s.%s' % (model._meta.app_label, model._meta.module_name)):\n                        for update_instance in update_instances:\n                            print u\"resetting %s\" % update_instance\n                            update_instance.save()", "response": "handle the command execution"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the session data and set a session cookie.", "response": "def process_response(self, request, response):\n        \"\"\"\n        If ``request.session was modified``, or if the configuration is to save\n        the session every time, save the changes and set a session cookie.\n        \"\"\"\n        try:\n            modified = request.session.modified\n        except AttributeError:\n            pass\n        else:\n            if modified or settings.SESSION_SAVE_EVERY_REQUEST:\n                if request.session.get_expire_at_browser_close():\n                    max_age = None\n                    expires = None\n                else:\n                    max_age = request.session.get_expiry_age()\n                    expires_time = time.time() + max_age\n                    expires = cookie_date(expires_time)\n                # Save the session data and refresh the client cookie.\n                request.session.save()\n                response.set_cookie(settings.SESSION_COOKIE_NAME,\n                        request.session.session_key, max_age=max_age,\n                        expires=expires, domain=settings.SESSION_COOKIE_DOMAIN,\n                        path=settings.SESSION_COOKIE_PATH,\n                        secure=settings.SESSION_COOKIE_SECURE or None)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle source and target related fields", "response": "def handle(self, source, target, app=None, **options):\n        \"\"\" command execution \"\"\"\n        translation.activate(settings.LANGUAGE_CODE)\n        if app:\n            unpack = app.split('.')\n\n            if len(unpack) == 2:\n                models = [get_model(unpack[0], unpack[1])]\n            elif len(unpack) == 1:\n                models = get_models(get_app(unpack[0]))\n        else:\n            models = get_models()\n            \n        for model in models:\n            if hasattr(model, 'localized_fields'):\n\n                model_full_name = '%s.%s' % (model._meta.app_label, model._meta.module_name)\n                update_instances = set()\n                messages = []\n                \n                for instance in model.objects.all():\n                    for field in model.localized_fields:\n                        source_field = get_real_fieldname(field, source)\n                        target_field = get_real_fieldname(field, target)\n                        \n                        if  hasattr(instance, source_field) and hasattr(instance, target_field):\n                            source_field_value = getattr(instance, source_field)\n                            target_field_value = getattr(instance, target_field)\n\n                            if target_field_value in (None, u'')\\\n                                and source_field_value not in (None, u''):\n                                setattr(instance, target_field, force_unicode(source_field_value))\n                                update_instances.add(instance)\n                                messages.append(u\"%s %s %s will become %s\" % (model_full_name, instance, target_field, force_unicode(source_field_value)))\n\n                if len(update_instances):\n                    if self.ask_for_confirmation(messages, u'%s.%s' % (model._meta.app_label, model._meta.module_name)):\n                        for update_instance in update_instances:\n                            print u\"saving %s\" % update_instance\n                            update_instance.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencrypt the given plaintext using an oracle function that returns True if the oracle function returns False otherwise.", "response": "def padding_oracle_encrypt(oracle, plaintext, block_size=128, pool=None):\n    \"\"\"\n    Encrypt plaintext using an oracle function that returns ``True`` if the\n    provided ciphertext is correctly PKCS#7 padded after decryption. The\n    cipher needs to operate in CBC mode.\n\n    Args:\n        oracle(callable): The oracle function. Will be called repeatedly with\n            a chunk of ciphertext.\n        plaintext(bytes): The plaintext data to encrypt.\n        block_size(int): The cipher's block size in bits.\n        pool(multiprocessing.Pool): A multiprocessing pool to use to\n            parallelize the encryption. This pool is used to call the oracle\n            function. Fairly heavy due to the required inter-process state\n            synchronization. If ``None`` (the default), no multiprocessing\n            will be used.\n\n    Returns:\n        bytes: The encrypted data.\n\n    Raises:\n        RuntimeError: Raised if the oracle behaves unpredictable.\n    \"\"\"\n\n    plaintext = bytearray(plaintext)\n    block_len = block_size // 8\n\n    padding_len = block_len - (len(plaintext) % block_len)\n    plaintext.extend([padding_len] * padding_len)\n\n    ciphertext = bytearray()\n\n    chunk = bytearray(os.urandom(block_len))\n    ciphertext[0:0] = chunk\n\n    for plain_start in range(len(plaintext) - block_len, -1, -block_len):\n        plain = plaintext[plain_start:plain_start + block_len]\n        chunk = ciphertext[0:0] = encrypt_block(oracle, block_len, chunk, plain, pool)\n\n    return bytes(ciphertext)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all documents of the specified collection", "response": "def all(cls, collection, skip=None, limit=None):\n        \"\"\"\n            Returns all documents of the collection\n\n            :param collection Collection instance\n            :param skip  The number of documents to skip in the query\n            :param limit The maximal amount of documents to return. The skip is applied before the limit restriction.\n\n            :returns Document list\n        \"\"\"\n\n        kwargs = {\n            'skip': skip,\n            'limit': limit,\n        }\n\n        return cls._construct_query(name='all', collection=collection, multiple=True,\n                                    **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_by_example(cls, collection, example_data, new_value, keep_null=False, wait_for_sync=None, limit=None):\n\n        kwargs = {\n            'newValue': new_value,\n            'options': {\n                'keepNull': keep_null,\n                'waitForSync': wait_for_sync,\n                'limit': limit,\n            }\n        }\n\n        return cls._construct_query(name='update-by-example',\n                                    collection=collection, example=example_data, result=False,\n                                    **kwargs)", "response": "This method will update all the documents in a collection that match the specified example object and will update the document body with the new value specified."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_by_example(cls, collection, example_data, wait_for_sync=None, limit=None):\n\n        kwargs = {\n            'options': {\n                'waitForSync': wait_for_sync,\n                'limit': limit,\n            }\n        }\n\n        return cls._construct_query(name='remove-by-example',\n                                    collection=collection, example=example_data, result=False,\n                                    **kwargs)", "response": "This will remove all documents in the specified collection that match the specified example object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_by_example_skiplist(cls, collection, index_id, example_data, allow_multiple=True, skip=None, limit=None):\n\n        kwargs = {\n            'index': index_id,\n            'skip': skip,\n            'limit': limit,\n        }\n\n        return cls._construct_query(name='by-example-skiplist',\n                                    collection=collection, example=example_data, multiple=allow_multiple,\n                                    **kwargs)", "response": "This will find all documents matching a given example skiplist index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fulltext(cls, collection, attribute, example_text, index_id, skip=None, limit=None):\n\n        kwargs = {\n            'index': index_id,\n            'attribute': attribute,\n            'query': example_text,\n            'skip': skip,\n            'limit': limit,\n        }\n\n        return cls._construct_query(name='fulltext',\n                                    collection=collection, multiple=True,\n                                    **kwargs)", "response": "This method will search the index for all the documents in the specified collection and attribute with the specified example text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef near(cls, collection, latitude, longitude, index_id, distance=None, skip=None, limit=None):\n\n        kwargs = {\n            'geo': index_id,\n            'latitude': latitude,\n            'longitude': longitude,\n            'distance': distance,\n            'skip': skip,\n            'limit': limit,\n        }\n\n        return cls._construct_query(name='near',\n                                    collection=collection, multiple=True,\n                                    **kwargs)", "response": "This method returns a list of documents near the given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a model instance and whether or not it was created.", "response": "def get_or_create(self, **kwargs):\n        \"\"\"\n            Looks up an object with the given kwargs, creating one if necessary.\n            Returns a tuple of (object, created), where created is a boolean\n            specifying whether an object was created.\n        \"\"\"\n\n        model = self.get(**kwargs)\n\n        is_created = False\n\n        if model is None:\n            is_created = True\n            model = self._model_class()\n\n            for key, value in list(kwargs.items()):\n                setattr(model, key, value)\n\n        return model, is_created"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of all the fields that are set on the class.", "response": "def get_all_fields(cls, class_obj=None, fields=None):\n        \"\"\"\n            TODO: This needs to be properly used\n        \"\"\"\n\n        def return_fields(obj):\n\n            internal_fields = fields\n            if internal_fields is None:\n                internal_fields = {}\n\n            for attribute in dir(obj):\n\n                try:\n                    attr_val = getattr(obj, attribute)\n                    attr_cls = attr_val.__class__\n\n                    # If it is a model field, call on init\n                    if issubclass(attr_cls, ModelField):\n                        internal_fields[attribute] = attr_val\n                except:\n                    pass\n\n            return internal_fields\n\n        if class_obj is None:\n            class_obj = cls\n\n            fields = return_fields(class_obj)\n            for parent_class in cls.__bases__:\n                parent_fields = cls.get_all_fields(parent_class, fields)\n                for field_name, field_value in list(parent_fields.items()):\n                    if not field_name in fields:\n                        fields[field_name] = field_value\n\n            return fields\n\n        else:\n            if not isinstance(class_obj, CollectionModel):\n                return fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the pwm values for a specific state of the led.", "response": "def _get_pwm_values(self, brightness=None, color=None):\n        \"\"\"\n        Get the pwm values for a specific state of the led.\n\n        If a state argument is omitted, current value is used.\n\n        :param brightness: The brightness of the state.\n        :param color: The color of the state.\n        :return: The pwm values.\n        \"\"\"\n        if brightness is None:\n            brightness = self.brightness\n        if color is None:\n            color = self.color\n\n        return [(x / 255) * brightness for x in self._rgb_to_rgbw(color)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a RGB color to a RGBW color.", "response": "def _rgb_to_rgbw(color):\n        \"\"\"\n        Convert a RGB color to a RGBW color.\n\n        :param color: The RGB color.\n        :return: The RGBW color.\n        \"\"\"\n        # Get the maximum between R, G, and B\n        max_value = max(color)\n\n        # If the maximum value is 0, immediately return pure black.\n        if max_value == 0:\n            return [0] * 4\n\n        # Figure out what the color with 100% hue is\n        multiplier = 255 / max_value\n        hue_red = color.R * multiplier\n        hue_green = color.G * multiplier\n        hue_blue = color.B * multiplier\n\n        # Calculate the whiteness (not strictly speaking luminance)\n        max_hue = max(hue_red, hue_green, hue_blue)\n        min_hue = min(hue_red, hue_green, hue_blue)\n        luminance = ((max_hue + min_hue) / 2 - 127.5) * 2 / multiplier\n\n        # Calculate the output values\n        r = max(0, min(255, int(color.R - luminance)))\n        g = max(0, min(255, int(color.G - luminance)))\n        b = max(0, min(255, int(color.B - luminance)))\n        w = max(0, min(255, int(luminance)))\n\n        return [r, g, b, w]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_uri(cls, reactor, uri):\n        uri = URI.fromBytes(uri.encode(), defaultPort=5672)\n        kwargs = {}\n        host = uri.host.decode()\n        if \"@\" in host:\n            auth, host = uri.netloc.decode().split(\"@\")\n            username, password = auth.split(\":\")\n            kwargs.update({\"username\": username, \"password\": password})\n\n        vhost = uri.path.decode()\n        if len(vhost) > 1:\n            vhost = vhost[1:]  # Strip leading \"/\"\n        kwargs[\"vhost\"] = vhost\n\n        params = parse_qs(uri.query)\n        kwargs.update({name.decode(): value[0].decode() for name, value in params.items()})\n\n        if \"heartbeat\" in kwargs:\n            kwargs[\"heartbeat\"] = int(kwargs[\"heartbeat\"])\n        return cls(reactor, host, uri.port, **kwargs)", "response": "Return an instance of AMQEndpoint configured with the given AMQP uri."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self, protocol_factory):\n        # XXX Since AMQClient requires these parameters at __init__ time, we\n        #     need to override them in the provided factory.\n        protocol_factory.set_vhost(self._vhost)\n        protocol_factory.set_heartbeat(self._heartbeat)\n\n        description = \"tcp:{}:{}:timeout={}\".format(\n            self._host, self._port, self._timeout)\n        endpoint = clientFromString(self._reactor, description)\n\n        deferred = endpoint.connect(protocol_factory)\n        return deferred.addCallback(self._authenticate)", "response": "Connect to the broker specified by the\n            URI."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a BlockText from the captured lines and clear _text.", "response": "def _reset_plain(self):\n        '''Create a BlockText from the captured lines and clear _text.'''\n        if self._text:\n            self._blocks.append(BlockText('\\n'.join(self._text)))\n        self._text.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step(self):\n        if self.cancelled or self.finished:\n            return\n\n        if not self.pwm_stages:\n            self._finish()\n            return\n\n        if self.duration == 0:\n            progress = 1\n        else:\n            run_time = time.time() - self._start_time\n            progress = max(0, min(1, run_time / self.duration))\n        self.stage_index = math.ceil((len(self.pwm_stages) - 1) * progress)\n        stage = self.pwm_stages[self.stage_index]\n        self._driver.set_pwm(stage)\n\n        if progress == 1:\n            self._finish()", "response": "Apply the current stage of the transition based on current time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _finish(self):\n        self.finished = True\n        if self._callback:\n            self._callback(self)\n        self._finish_event.set()", "response": "Mark transition as finished and execute callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, message, level=Level.NOTICE):\n    \"Send a syslog message to remote host using UDP or TCP\"\n    data = \"<%d>%s\" % (level + self.facility*8, message)\n    if self.protocol == 'UDP':\n        self.socket.sendto(data.encode('utf-8'), (self.host, self.port))\n    else:\n        self.socket.send(data.encode('utf-8'))", "response": "Send a syslog message to remote host using UDP or TCP"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self, namespace):\n        '''Render #for loop with given namespace.\n\n        Note: we copy the namespace so the parsed variable is only\n              available in nested objects within this #for loop.\n        '''\n        ns = namespace.copy()\n        result = []\n        for item in namespace[self._items]:\n            ns[self._item] = item\n            result.append(self._block.render(ns))\n        return '\\n'.join(result) if result else None", "response": "Render the current namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile the current line and return both variable names used in the for loop in the current line.", "response": "def _compile(cls, lines):\n        '''Return both variable names used in the #for loop in the\n        current line.'''\n        m = cls.RE_FOR.match(lines.current)\n        if m is None:\n            raise DefineBlockError(\n                'Incorrect block definition at line {}, {}\\nShould be '\n                'something like: #for @item in @items:'\n                .format(lines.pos, lines.current))\n        return m.group(1), m.group(2).replace('.', '-')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync(self, graph_commons):\n        if self['id'] is None:\n            return\n\n        remote_graph = graph_commons.graphs(self['id'])\n\n        # TODO: less forceful, more elegant\n        self.edges = remote_graph.edges\n        self.nodes = remote_graph.nodes\n        self.node_types = remote_graph.node_types\n        self.edge_types = remote_graph.edge_types\n        self._edges = dict((edge['id'], edge) for edge in self.edges)\n        self._nodes = dict((node['id'], node) for node in self.nodes)\n        self._node_types = dict((t['id'], t) for t in self.node_types)\n        self._edge_types = dict((t['id'], t) for t in self.edge_types)", "response": "Synchronize local and remote representations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, transition):\n        self._transitions.append(transition)\n        if self._thread is None or not self._thread.isAlive():\n            self._thread = threading.Thread(target=self._transition_loop)\n            self._thread.setDaemon(True)\n            self._thread.start()", "response": "Queue a transition for execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _transition_loop(self):\n        while self._transitions:\n            start = time.time()\n            for transition in self._transitions:\n                transition.step()\n                if transition.finished:\n                    self._transitions.remove(transition)\n\n            time_delta = time.time() - start\n            sleep_time = max(0, self.MIN_STEP_TIME - time_delta)\n            time.sleep(sleep_time)", "response": "Execute all queued transitions step by step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, is_on=None, brightness=None, cancel_transition=True):\n        if cancel_transition:\n            self._cancel_active_transition()\n\n        if is_on is not None:\n            self._is_on = is_on\n\n        if brightness is not None:\n            self._assert_is_brightness(brightness)\n            self._brightness = brightness\n\n        self._update_pwm()", "response": "Set the properties of the led simultaneously before updating pwm values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the pwm values of the driver regarding the current state.", "response": "def _update_pwm(self):\n        \"\"\"Update the pwm values of the driver regarding the current state.\"\"\"\n        if self._is_on:\n            values = self._get_pwm_values()\n        else:\n            values = [0] * len(self._driver.pins)\n\n        self._driver.set_pwm(values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransition to the specified state of the led.", "response": "def transition(self, duration, is_on=None, **kwargs):\n        \"\"\"\n        Transition to the specified state of the led.\n\n        If another transition is already running, it is aborted.\n\n        :param duration: The duration of the transition.\n        :param is_on: The on-off state to transition to.\n        :param kwargs: The state to transition to.\n        \"\"\"\n        self._cancel_active_transition()\n\n        dest_state = self._prepare_transition(is_on, **kwargs)\n        total_steps = self._transition_steps(**dest_state)\n        state_stages = [self._transition_stage(step, total_steps, **dest_state)\n                        for step in range(total_steps)]\n        pwm_stages = [self._get_pwm_values(**stage)\n                      for stage in state_stages]\n        callback = partial(self._transition_callback, is_on)\n        self._active_transition = Transition(self._driver, duration,\n                                             state_stages, pwm_stages,\n                                             callback)\n\n        TransitionManager().execute(self._active_transition)\n\n        return self._active_transition"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _transition_callback(self, is_on, transition):\n        # Update state properties\n        if transition.state_stages:\n            state = transition.state_stages[transition.stage_index]\n            if self.is_on and is_on is False:\n                # If led was turned off, set brightness to initial value\n                # so that the brightness is restored when it is turned on again\n                state['brightness'] = self.brightness\n            self.set(is_on=is_on, cancel_transition=False, **state)\n\n        self._active_transition = None", "response": "Callback that is called when a transition has ended."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_transition(self, is_on=None, **kwargs):\n        # Handle transitions with changing on-off-state\n        dest_state = kwargs.copy()\n        if is_on is not None:\n            if is_on and not self.is_on:\n                if 'brightness' not in kwargs or kwargs['brightness'] is None:\n                    dest_state['brightness'] = self.brightness\n                self.set(brightness=0, cancel_transition=False)\n            elif not is_on and self.is_on:\n                dest_state['brightness'] = 0\n\n        return dest_state", "response": "Perform pre - transition tasks and construct the destination state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transition_steps(self, brightness=None):\n        if brightness is not None:\n            self._assert_is_brightness(brightness)\n            return self._driver.steps(self.brightness, brightness)\n\n        return 0", "response": "Get the maximum number of steps needed for a transition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _transition_stage(self, step, total_steps, brightness=None):\n        if brightness is not None:\n            self._assert_is_brightness(brightness)\n            brightness = self._interpolate(self.brightness, brightness,\n                                           step, total_steps)\n\n        return {'brightness': brightness}", "response": "Get a transition stage at a specific step."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _interpolate(start, end, step, total_steps):\n        diff = end - start\n        progress = step / (total_steps - 1)\n        return start + progress * diff", "response": "Interpolate a value from start to end at a given progress."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a collection with the given name", "response": "def collection(self, name):\n        \"\"\"\n            Returns a collection with the given name\n\n            :param name Collection name\n\n            :returns Collection\n        \"\"\"\n\n        return Collection(\n            name=name,\n            api_resource=self.api.collection(name),\n            api=self.api,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new database and sets itself as the active database.", "response": "def create(cls, name, users=None):\n        \"\"\"\n            Creates database and sets itself as the active database.\n\n            :param name Database name\n\n            :returns Database\n        \"\"\"\n\n        api = Client.instance().api\n\n        database_data = {\n            'name': name,\n            'active': True,\n        }\n\n        if isinstance(users, list) or isinstance(users, tuple):\n            database_data['users'] = users\n\n        data = api.database.post(data=database_data)\n\n        db = Database(\n            name=name,\n            api=api,\n            kwargs=data\n        )\n\n        Client.instance().set_database(name=name)\n\n        return db"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all(cls):\n\n        api = Client.instance().api\n\n        data = api.database.get()\n\n        database_names = data['result']\n        databases = []\n\n        for name in database_names:\n            db = Database(name=name, api=api)\n            databases.append(db)\n\n        return databases", "response": "Returns an array with all databases\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(cls, name):\n\n        client = Client.instance()\n\n        new_current_database = None\n\n        if client.database != name:\n            new_current_database = name\n\n        # Deletions are only possible from the system database\n        client.set_database(name=SYSTEM_DATABASE)\n\n        api = client.api\n        api.database(name).delete()\n\n        if new_current_database:\n            client.set_database(name=new_current_database)", "response": "Removes the entry from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(cls, name, database=SYSTEM_DATABASE, type=2):\n\n        client = Client.instance()\n        api = client.api\n\n        if client.database != database:\n            database = client.database\n\n        collection_data = {\n            'name': name,\n            'type': type,\n        }\n\n        data = api.collection.post(data=collection_data)\n\n        collection = Collection(\n            name=name,\n            database=database,\n            api_resource=api.collection,\n            api=api,\n            kwargs=data\n        )\n\n        return collection", "response": "Creates a new object of type 2 for the given name and database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(cls, name):\n\n        api = Client.instance().api\n\n        api.collection(name).delete()", "response": "Destroys a specific object from the specified collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the properties of this object to the resource.", "response": "def save(self):\n        \"\"\"\n            Updates only waitForSync and journalSize\n        \"\"\"\n\n        data = {\n            'waitForSync': self.waitForSync,\n            'journalSize': self.journalSize,\n        }\n\n        self.resource(self.name).properties.put(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self):\n\n        data = self.resource(self.name).properties.get()\n\n        self.set_data(**data)\n\n        return data", "response": "Retrieves all properties for the current resource and sets the attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the figures about the collection.", "response": "def get_figures(self):\n        \"\"\"\n            Returns figures about the collection.\n        \"\"\"\n\n        data = self.resource(self.name).figures.get()\n        return data['figures']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_edge(self, from_doc, to_doc, edge_data={}):\n\n        return Edge.create(\n            collection=self,\n            from_doc=from_doc,\n            to_doc=to_doc,\n            edge_data=edge_data\n        )", "response": "Creates an edge document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef documents(self):\n\n        document_list = []\n        document_uri_list = self.api.document.get(collection=self.name)['documents']\n        for document_uri in document_uri_list:\n            splitted_uri = document_uri.split('/')\n            document_key = splitted_uri[-1]\n            document_id = \"%s/%s\" % (self.name, document_key)\n\n            doc = Document(\n                id=document_id,\n                key=document_key,\n                collection=self,\n                api=self.api\n            )\n\n            document_list.append(doc)\n\n        return document_list", "response": "Returns a list of all documents of this collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, collection):\n\n        api = Client.instance().api\n\n        doc = Document(\n            id='',\n            key='',\n            collection=collection.name,\n            api=api,\n        )\n\n        return doc", "response": "Creates a new object without really creating it in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve all data for this document and saves it.", "response": "def retrieve(self):\n        \"\"\"\n            Retrieves all data for this document and saves it.\n        \"\"\"\n\n        data = self.resource(self.id).get()\n        self.data = data\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the current object to the database.", "response": "def save(self):\n        \"\"\"\n            If its internal state is loaded than it will only updated the\n            set properties but otherwise it will create a new document.\n        \"\"\"\n\n        # TODO: Add option force_insert\n\n        if not self.is_loaded and self.id is None or self.id == '':\n            data = self.resource.post(data=self.data, collection=self.collection)\n            self.id = data['_id']\n            self.key = data['_key']\n            self.revision = data['_rev']\n            self.is_loaded = True\n        else:\n            data = self.resource(self.id).patch(data=self.data)\n            self.revision = data['_rev']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the attribute with the given key.", "response": "def get(self, key):\n        \"\"\"\n            Returns attribute value.\n\n            :param key\n\n            :returns value\n        \"\"\"\n\n        if not self.is_loaded:\n            self.retrieve()\n\n            self.is_loaded = True\n\n        if self.has(key=key):\n            return self.data[key]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the pwm values on the controlled pins.", "response": "def _set_pwm(self, raw_values):\n        \"\"\"\n        Set pwm values on the controlled pins.\n\n        :param raw_values: Raw values to set (0-255).\n        \"\"\"\n        for i in range(len(self._pins)):\n            self._pi.set_PWM_dutycycle(self._pins[i], raw_values[i])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the filename from the current line.", "response": "def _compile(cls, lines):\n        '''Return the filename from the current line.'''\n        m = cls.RE_EXTEND.match(lines.current)\n        if m is None:\n            raise DefineBlockError('''Incorrect block definition at line {}, {}\nShould be something like: #extend path/foo.html:'''.format(\n                lines.pos, lines.current))\n        return m.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the pwm values on the controlled pins.", "response": "def set_pwm(self, values):\n        \"\"\"\n        Set pwm values on the controlled pins.\n\n        :param values: Values to set (0.0-1.0).\n        :return:\n        \"\"\"\n        if len(values) != len(self._pins):\n            raise ValueError('Number of values has to be identical with '\n                             'the number of pins.')\n        if not all(0 <= v <= 1 for v in values):\n            raise ValueError('Values must be between 0 and 1.')\n\n        for tries in range(self.IO_TRIES):\n            try:\n                self._set_pwm(self._to_raw_pwm(values))\n                break\n            except IOError as error:\n                if tries == self.IO_TRIES - 1:\n                    raise error\n        self._state = values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting uniform pwm values to raw driver - specific values.", "response": "def _to_raw_pwm(self, values):\n        \"\"\"\n        Convert uniform pwm values to raw, driver-specific values.\n\n        :param values: The uniform pwm values (0.0-1.0).\n        :return: Converted, driver-specific pwm values.\n        \"\"\"\n        return [self._to_single_raw_pwm(values[i])\n                for i in range(len(self._pins))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts raw pwm values to uniform values.", "response": "def _to_uniform_pwm(self, values):\n        \"\"\"\n        Convert raw pwm values to uniform values.\n\n        :param values: The raw pwm values.\n        :return: Converted, uniform pwm values (0.0-1.0).\n        \"\"\"\n        return [self._to_single_uniform_pwm(values[i])\n                for i in range(len(self._pins))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef steps(self, start, end):\n        if not 0 <= start <= 1:\n            raise ValueError('Values must be between 0 and 1.')\n        if not 0 <= end <= 1:\n            raise ValueError('Values must be between 0 and 1.')\n\n        raw_start = self._to_single_raw_pwm(start)\n        raw_end = self._to_single_raw_pwm(end)\n        return abs(raw_start - raw_end)", "response": "Get the maximum number of steps the driver needs for a transition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the PWM values on the controlled pins.", "response": "def _set_pwm(self, raw_values):\n        \"\"\"\n        Set pwm values on the controlled pins.\n\n        :param raw_values: Raw values to set (0-4095).\n        \"\"\"\n        for i in range(len(self._pins)):\n            self._device.set_pwm(self._pins[i], 0, raw_values[i])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget size of memory on C { node }.", "response": "def get_node_size(node):\n    \"\"\"\n    Get size of memory on C{node}.\n\n    @param node: node idx\n    @type node: C{int}\n    @return: free memory/total memory\n    @rtype: C{tuple}(C{int}, C{int})\n    \"\"\"\n\n    free = c_longlong()\n\n    if node < 0 or node > get_max_node():\n        raise ValueError(node)\n\n    size = libnuma.numa_node_size64(node, byref(free))\n\n    return (free.value, size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets CPUs available on a node.", "response": "def node_to_cpus(node):\n    \"\"\"\n    Get CPUs available on C{node}.\n\n    @return: set of CPU ids\n    @rtype: C{set}\n    \"\"\"\n\n    result = set()\n\n    if node < 0 or node > get_max_node():\n        raise ValueError(node)\n\n    mask = bitmask_t()\n    mask.maskp = (c_ulong * (NUMA_NUM_NODES/(sizeof(c_ulong)*8)))()\n    mask.size = NUMA_NUM_NODES\n\n    if libnuma.numa_node_to_cpus(node, byref(mask)) < 0:\n        raise RuntimeError(node)\n\n    for i in range(0, NUMA_NUM_NODES / (sizeof(c_ulong) *8)):\n        for j in range(0, sizeof(c_ulong) * 8):\n            if mask.maskp[i] & (1 << j) == (1 << j):\n                result.add(i * sizeof(c_ulong) * 8 + j)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting NUMA nodemask to Python set.", "response": "def numa_nodemask_to_set(mask):\n    \"\"\"\n    Convert NUMA nodemask to Python set.\n    \"\"\"\n    result = set()\n\n    for i in range(0, get_max_node() + 1):\n        if __nodemask_isset(mask, i):\n            result.add(i)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_interleave_mask(nodemask):\n\n    mask = set_to_numa_nodemask(nodemask)\n    tmp = bitmask_t()\n    tmp.maskp = cast(byref(mask), POINTER(c_ulong))\n    tmp.size = sizeof(nodemask_t) * 8\n\n    libnuma.numa_set_interleave_mask(byref(tmp))", "response": "Sets the memory interleave mask for the current thread to nodemask."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting interleave mask for current thread.", "response": "def get_interleave_mask():\n    \"\"\"\n    Get interleave mask for current thread.\n\n    @return: node mask\n    @rtype: C{set}\n    \"\"\"\n\n    nodemask = nodemask_t()\n    bitmask = libnuma.numa_get_interleave_mask()\n    libnuma.copy_bitmask_to_nodemask(bitmask, byref(nodemask))\n    libnuma.numa_bitmask_free(bitmask)\n\n    return numa_nodemask_to_set(nodemask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bind(nodemask):\n    mask = set_to_numa_nodemask(nodemask)\n    bitmask = libnuma.numa_allocate_nodemask()\n    libnuma.copy_nodemask_to_bitmask(byref(mask), bitmask)\n    libnuma.numa_bind(bitmask)\n    libnuma.numa_bitmask_free(bitmask)", "response": "Binds the current thread and its children to the specified nodemask."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the preferred node for the current thread.", "response": "def set_preferred(node):\n    \"\"\"\n    Sets  the preferred node for the current thread to node.\n\n    The preferred node is the node on which memory is preferably allocated before falling back to other\n    nodes. The default is to use the node on which the process is currently running (local policy).\n\n    @param node: node idx\n    @type node: C{int}\n    \"\"\"\n    if node < 0 or node > get_max_node():\n        raise ValueError(node)\n\n    libnuma.numa_set_preferred(node)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_membind(nodemask):\n    mask = set_to_numa_nodemask(nodemask)\n\n    tmp = bitmask_t()\n    tmp.maskp = cast(byref(mask), POINTER(c_ulong))\n    tmp.size = sizeof(nodemask_t) * 8\n\n    libnuma.numa_set_membind(byref(tmp))", "response": "Sets the memory allocation mask."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn \u00d7 the set of nodes from which memory can currently be allocated.", "response": "def get_membind():\n    \"\"\"\n    Returns  the  mask of nodes from which memory can currently be allocated.\n\n    @return: node mask\n    @rtype: C{set}\n    \"\"\"\n    bitmask = libnuma.numa_get_membind()\n    nodemask = nodemask_t()\n    libnuma.copy_bitmask_to_nodemask(bitmask, byref(nodemask))\n    libnuma.numa_bitmask_free(bitmask)\n    return numa_nodemask_to_set(nodemask)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_run_on_node_mask(nodemask):\n    mask = set_to_numa_nodemask(nodemask)\n\n    tmp = bitmask_t()\n    tmp.maskp = cast(byref(mask), POINTER(c_ulong))\n    tmp.size = sizeof(nodemask_t) * 8\n\n    if libnuma.numa_run_on_node_mask(byref(tmp)) < 0:\n        raise RuntimeError()", "response": "Runs the current thread and its children only on nodes specified in nodemask."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_run_on_node_mask():\n    bitmask = libnuma.numa_get_run_node_mask()\n    nodemask = nodemask_t()\n    libnuma.copy_bitmask_to_nodemask(bitmask, byref(nodemask))\n    libnuma.numa_bitmask_free(bitmask)\n\n    return numa_nodemask_to_set(nodemask)", "response": "Returns the node mask that the current thread is allowed to run on."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_distance(node1, node2):\n    if node1 < 0 or node1 > get_max_node():\n        raise ValueError(node1)\n    if node2 < 0 or node2 > get_max_node():\n        raise ValueError(node2)\n\n    return libnuma.numa_distance(node1, node2)", "response": "Returns the distance between two nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the affinity mask of the process whose ID is pid.", "response": "def get_affinity(pid):\n    \"\"\"\n    Returns the affinity mask of the process whose ID is pid.\n\n    @param pid: process PID (0 == current process)\n    @type pid: C{int}\n    @return: set of CPU ids\n    @rtype: C{set}\n    \"\"\"\n\n    cpuset = cpu_set_t()\n    result = set()\n\n    libnuma.sched_getaffinity(pid, sizeof(cpu_set_t), byref(cpuset))\n\n    for i in range(0, sizeof(cpu_set_t)*8):\n        if __CPU_ISSET(i, cpuset):\n            result.add(i)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_affinity(pid, cpuset):\n    _cpuset = cpu_set_t()\n    __CPU_ZERO(_cpuset)\n\n    for i in cpuset:\n        if i in range(0, sizeof(cpu_set_t) * 8):\n            __CPU_SET(i, _cpuset)\n\n    if libnuma.sched_setaffinity(pid, sizeof(cpu_set_t), byref(_cpuset)) < 0:\n        raise RuntimeError()", "response": "Sets the CPU affinity mask of the process whose ID is pid to the value specified by cpuset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the template lines.", "response": "def render(self, namespace):\n        '''Render template lines.\n\n        Note: we only need to parse the namespace if we used variables in\n              this part of the template.\n        '''\n        return self._text.format_map(namespace.dictionary) \\\n            if self._need_format else self._text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line arguments and return a dictionary of options for ttfautohint. ttfautohint function.", "response": "def parse_args(args=None):\n    \"\"\"Parse command line arguments and return a dictionary of options\n    for ttfautohint.ttfautohint function.\n\n    `args` can be either None, a list of strings, or a single string,\n    that is split into individual options with `shlex.split`.\n\n    When `args` is None, the console's default sys.argv are used, and any\n    SystemExit exceptions raised by argparse are propagated.\n\n    If args is a string list or a string, it is assumed that the function\n    was not called from a console script's `main` entry point, but from\n    other client code, and thus the SystemExit exceptions are muted and\n    a `None` value is returned.\n    \"\"\"\n    import argparse\n    from ttfautohint import __version__, libttfautohint\n    from ttfautohint.cli import USAGE, DESCRIPTION, EPILOG\n\n    version_string = \"ttfautohint-py %s (libttfautohint %s)\" % (\n        __version__, libttfautohint.version_string)\n\n    if args is None:\n        capture_sys_exit = False\n    else:\n        capture_sys_exit = True\n        if isinstance(args, basestring):\n            import shlex\n            args = shlex.split(args)\n\n    parser = argparse.ArgumentParser(\n        prog=\"ttfautohint\",\n        usage=USAGE,\n        description=DESCRIPTION,\n        epilog=EPILOG,\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    parser.add_argument(\n        \"in_file\", nargs=\"?\", metavar=\"IN-FILE\", default=\"-\",\n        type=stdin_or_input_path_type,\n        help=\"input file (default: standard input)\")\n    parser.add_argument(\n        \"out_file\", nargs=\"?\", metavar=\"OUT-FILE\", default=\"-\",\n        type=stdout_or_output_path_type,\n        help=\"output file (default: standard output)\")\n    parser.add_argument(\n        \"--debug\", action=\"store_true\", help=\"print debugging information\")\n\n    stem_width_group = parser.add_mutually_exclusive_group(required=False)\n    stem_width_group.add_argument(\n        \"-a\", \"--stem-width-mode\", type=stem_width_mode, metavar=\"S\",\n        default=STEM_WIDTH_MODE_OPTIONS,\n        help=(\"select stem width mode for grayscale, GDI ClearType, and DW \"\n              \"ClearType, where S is a string of three letters with possible \"\n              \"values 'n' for natural, 'q' for quantized, and 's' for strong \"\n              \"(default: qsq)\"))\n    stem_width_group.add_argument(  # deprecated\n        \"-w\", \"--strong-stem-width\", type=strong_stem_width, metavar=\"S\",\n        help=argparse.SUPPRESS)\n\n    parser.add_argument(\n        \"-c\", \"--composites\", dest=\"hint_composites\", action=\"store_true\",\n        help=\"hint glyph composites also\")\n    parser.add_argument(\n        \"-d\", \"--dehint\", action=\"store_true\", help=\"remove all hints\")\n    parser.add_argument(\n        \"-D\", \"--default-script\", metavar=\"SCRIPT\",\n        default=USER_OPTIONS[\"default_script\"],\n        help=\"set default OpenType script (default: %(default)s)\")\n    parser.add_argument(\n        \"-f\", \"--fallback-script\", metavar=\"SCRIPT\",\n        default=USER_OPTIONS[\"fallback_script\"],\n        help=\"set fallback script (default: %(default)s)\")\n    parser.add_argument(\n        \"-F\", \"--family-suffix\", metavar=\"SUFFIX\",\n        help=\"append SUFFIX to the family name string(s) in the `name' table\")\n    parser.add_argument(\n        \"-G\", \"--hinting-limit\", type=int, metavar=\"PPEM\",\n        default=USER_OPTIONS[\"hinting_limit\"],\n        help=(\"switch off hinting above this PPEM value (default: \"\n              \"%(default)s); value 0 means no limit\"))\n    parser.add_argument(\n        \"-H\", \"--fallback-stem-width\", type=int, metavar=\"UNITS\",\n        default=USER_OPTIONS[\"fallback_stem_width\"],\n        help=(\"set fallback stem width (default: %(default)s font units at \"\n              \"2048 UPEM)\"))\n    parser.add_argument(\n        \"-i\", \"--ignore-restrictions\", action=\"store_true\",\n        help=\"override font license restrictions\")\n    parser.add_argument(\n        \"-I\", \"--detailed-info\", action=\"store_true\",\n        help=(\"add detailed ttfautohint info to the version string(s) in \"\n              \"the `name' table\"))\n    parser.add_argument(\n        \"-l\", \"--hinting-range-min\", type=int, metavar=\"PPEM\",\n        default=USER_OPTIONS[\"hinting_range_min\"],\n        help=\"the minimum PPEM value for hint sets (default: %(default)s)\")\n    parser.add_argument(\n        \"-m\", \"--control-file\", metavar=\"FILE\",\n        help=\"get control instructions from FILE\")\n    parser.add_argument(\n        \"-n\", \"--no-info\", action=\"store_true\",\n        help=(\"don't add ttfautohint info to the version string(s) in the \"\n              \"`name' table\"))\n    parser.add_argument(\n        \"-p\", \"--adjust-subglyphs\", action=\"store_true\",\n        help=\"handle subglyph adjustments in exotic fonts\")\n    parser.add_argument(\n        \"-r\", \"--hinting-range-max\", type=int, metavar=\"PPEM\",\n        default=USER_OPTIONS[\"hinting_range_max\"],\n        help=\"the maximum PPEM value for hint sets (default: %(default)s)\")\n    parser.add_argument(\n        \"-R\", \"--reference\", dest=\"reference_file\", metavar=\"FILE\",\n        help=\"derive blue zones from reference font FILE\")\n    parser.add_argument(\n        \"-s\", \"--symbol\", action=\"store_true\",\n        help=\"input is symbol font\")\n    parser.add_argument(\n        \"-S\", \"--fallback-scaling\", action=\"store_true\",\n        help=\"use fallback scaling, not hinting\")\n    parser.add_argument(\n        \"-t\", \"--ttfa-table\", action=\"store_true\", dest=\"TTFA_info\",\n        help=\"add TTFA information table\")\n    parser.add_argument(\n        \"-T\", \"--ttfa-info\", dest=\"show_TTFA_info\", action=\"store_true\",\n        help=\"display TTFA table in IN-FILE and exit\")\n    parser.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\",\n        help=\"show progress information\")\n    parser.add_argument(\n        \"-V\", \"--version\", action=\"version\",\n        version=version_string,\n        help=\"print version information and exit\")\n    parser.add_argument(\n        \"-W\", \"--windows-compatibility\", action=\"store_true\",\n        help=(\"add blue zones for `usWinAscent' and `usWinDescent' to avoid \"\n              \"clipping\"))\n    parser.add_argument(\n        \"-x\", \"--increase-x-height\", type=int, metavar=\"PPEM\",\n        default=USER_OPTIONS[\"increase_x_height\"],\n        help=(\"increase x height for sizes in the range 6<=PPEM<=N; value \"\n              \"0 switches off this feature (default: %(default)s)\"))\n    parser.add_argument(\n        \"-X\", \"--x-height-snapping-exceptions\", metavar=\"STRING\",\n        default=USER_OPTIONS[\"x_height_snapping_exceptions\"],\n        help=('specify a comma-separated list of x-height snapping exceptions'\n              ', for example \"-9, 13-17, 19\" (default: \"%(default)s\")'))\n    parser.add_argument(\n        \"-Z\", \"--reference-index\", type=int, metavar=\"NUMBER\",\n        default=USER_OPTIONS[\"reference_index\"],\n        help=\"face index of reference font (default: %(default)s)\")\n\n    try:\n        options = vars(parser.parse_args(args))\n    except SystemExit:\n        if capture_sys_exit:\n            return None\n        raise\n\n    # if either input/output are interactive, print help and exit\n    if (not capture_sys_exit and\n            (options[\"in_file\"] is None or options[\"out_file\"] is None)):\n        parser.print_help()\n        parser.exit(1)\n\n    # check SOURCE_DATE_EPOCH environment variable\n    source_date_epoch = os.environ.get(\"SOURCE_DATE_EPOCH\")\n    if source_date_epoch:\n        try:\n            options[\"epoch\"] = int(source_date_epoch)\n        except ValueError:\n            import warnings\n            warnings.warn(\n                UserWarning(\"invalid SOURCE_DATE_EPOCH: %r\" % source_date_epoch))\n\n    if options.pop(\"show_TTFA_info\"):\n        # TODO use fonttools to dump TTFA table?\n        raise NotImplementedError()\n\n    stem_width_options = options.pop(\"stem_width_mode\")\n    strong_stem_width_options = options.pop(\"strong_stem_width\")\n    if strong_stem_width_options:\n        import warnings\n        warnings.warn(\n            UserWarning(\"Option '-w' is deprecated! Use option '-a' instead\"))\n        stem_width_options = strong_stem_width_options\n    options.update(stem_width_options)\n\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting properties of the led simultaneously before updating pwm values.", "response": "def set(self, is_on=None, brightness=None, color=None,\n            cancel_transition=True):\n        \"\"\"\n        Set properties of the led simultaneously before updating pwm values.\n\n        :param is_on: On-off state of the led.\n        :param brightness: Brightness of the led.\n        :param color: Color of the led.\n        :param cancel_transition: Cancel active transitions.\n        \"\"\"\n        if cancel_transition:\n            self._cancel_active_transition()\n\n        if color is not None:\n            self._assert_is_color(color)\n            self._color = color\n\n        super().set(is_on, brightness, cancel_transition=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms pre - transition tasks and construct the destination state.", "response": "def _prepare_transition(self, is_on=None, brightness=None, color=None):\n        \"\"\"\n        Perform pre-transition tasks and construct the destination state.\n\n        :param is_on: The on-off state to transition to.\n        :param brightness: The brightness to transition to (0.0-1.0).\n        :param color: The color to transition to.\n        :return: The destination state of the transition.\n        \"\"\"\n        dest_state = super()._prepare_transition(is_on,\n                                                 brightness=brightness,\n                                                 color=color)\n\n        # Handle transitions from off to on and changing color\n        if is_on and not self.is_on and color is not None:\n            self.set(color=color, cancel_transition=False)\n\n        return dest_state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transition_steps(self, brightness=None, color=None):\n        values = []\n        if brightness is not None:\n            self._assert_is_brightness(brightness)\n            values.append((self.brightness, brightness))\n\n        if color is not None:\n            self._assert_is_color(color)\n            values += [(self.color[i] / 255, color[i] / 255) for i in range(3)]\n\n        if not values:\n            return 0\n\n        return max(self._driver.steps(*args) for args in values)", "response": "Get the maximum number of steps needed for a transition."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _transition_stage(self, step, total_steps,\n                          brightness=None, color=None):\n        \"\"\"\n        Get a transition stage at a specific step.\n\n        :param step: The current step.\n        :param total_steps: The total number of steps.\n        :param brightness: The brightness to transition to (0.0-1.0).\n        :param color: The color to transition to.\n        :return: The stage at the specific step.\n        \"\"\"\n        if brightness is not None:\n            self._assert_is_brightness(brightness)\n            brightness = self._interpolate(self.brightness, brightness,\n                                           step, total_steps)\n\n        if color is not None:\n            self._assert_is_color(color)\n            color = Color(*[self._interpolate(self.color[i], color[i],\n                                              step, total_steps)\n                            for i in range(3)])\n\n        return {'brightness': brightness, 'color': color}", "response": "Get a transition stage at a specific step."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassert that the given value is a valid color.", "response": "def _assert_is_color(value):\n        \"\"\"\n        Assert that the given value is a valid brightness.\n\n        :param value: The value to check.\n        \"\"\"\n        if not isinstance(value, tuple) or len(value) != 3:\n            raise ValueError(\"Color must be a RGB tuple.\")\n\n        if not all(0 <= x <= 255 for x in value):\n            raise ValueError(\"RGB values of color must be between 0 and 255.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lambda_from_file(python_file):\n    lambda_function = []\n    with open(python_file, 'r') as f:\n        lambda_function.extend(f.read().splitlines())\n\n    return awslambda.Code(ZipFile=(Join('\\n', lambda_function)))", "response": "Reads a python file and returns a awslambda. Code object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering a true or ( if available ) false block based on a boolean.", "response": "def render(self, namespace):\n        '''Render a 'true' or (if available) 'false' block based on a\n        boolean.'''\n        if (self._isbool and\n            namespace[self._evaluate]) or \\\n            (not self._isbool and\n             namespace[self._evaluate](*[namespace[arg]\n                                         for arg in self._args])):\n            return self._block_true.render(namespace)\n        if self._block_false is not None:\n            return self._block_false.render(namespace)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compile(self, lines):\n        '''Set the correct render method (boolean or function call)\n        and read variables from the current line.\n        '''\n        m = self.__class__.RE_IF.match(lines.current)\n        if m is None:\n            raise DefineBlockError(\n                'Incorrect block definition at line {}, {}\\nShould be '\n                'something like: #if @foo:'.format(lines.pos, lines.current))\n        args = m.group(3)\n        self._evaluate = m.group(2).replace('.', '-')\n        self._isbool = args is None\n        if not self._isbool:\n            args = args.strip('() \\t')\n            self._args = [arg.strip('@ \\t').replace('.', '-')\n                          for arg in args.split(',')]", "response": "Set the correct render method or function call and read variables from the current line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an index with id", "response": "def remove(cls, id):\n        \"\"\"\n            Deletes an index with id\n\n            :param id string/document-handle\n        \"\"\"\n\n        api = Client.instance().api\n        api.index(id).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self):\n\n        api = Client.instance().api\n\n        index_details = {\n            'type': self.index_type_obj.type_name\n        }\n\n        extra_index_attributes = self.index_type_obj.get_extra_attributes()\n\n        for extra_attribute_key in extra_index_attributes:\n            extra_attribute_value = extra_index_attributes[extra_attribute_key]\n            index_details[extra_attribute_key] = extra_attribute_value\n\n        query_parameters = {\n            'collection': self.collection.name,\n        }\n\n        result = api.index.post(data=index_details, **query_parameters)\n\n        self.index_type_obj.is_new = result['isNewlyCreated']\n        self.index_type_obj.id = result['id']", "response": "Creates this index in the collection if it hasn t already been created\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns macro or block name from the current line.", "response": "def _compile(cls, lines):\n        '''Return macro or block name from the current line.'''\n        m = cls.RE_PASTE.match(lines.current)\n        if m is None:\n            raise MacroBlockUsageError(\n                'Incorrect macro or block usage at line {}, {}\\nShould be '\n                'something like: #my_macro'.format(lines.pos, lines.current))\n        return m.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a collection of images as a grid of tiles.", "response": "def tile(imgs, cmap='gray', bar=False, nans=True, clim=None, grid=None, size=9, axis=0, fig=None):\n    \"\"\"\n    Display a collection of images as a grid of tiles\n\n    Parameters\n    ----------\n    img : list or ndarray (2D or 3D)\n        The images to display. Can be a list of either 2D, 3D,\n        or a mix of 2D and 3D numpy arrays. Can also be a single\n        numpy array, in which case the axis parameter will be assumed\n        to index the image list, e.g. a (10, 512, 512) array with axis=0 \n        will be treated as 10 different (512,512) images, and the same\n        array with axis=1 would be treated as 512 (10,512) images.\n\n    cmap : str or Colormap or list, optional, default = 'gray'\n        A colormap to use, for non RGB images, a list can be used to\n        specify a different colormap for each image\n\n    bar : boolean, optional, default = False\n        Whether to append a colorbar to each image\n\n    nans : boolean, optional, deafult = True\n        Whether to replace NaNs, if True, will replace with 0s\n\n    clim : tuple or list of tuples, optional, default = None\n        Limits for scaling image, a list can be used to\n        specify different limits for each image\n\n    grid : tuple, optional, default = None\n        Dimensions of image tile grid, if None, will use a square grid\n        large enough to include all images\n\n    size : scalar, optional, deafult = 11\n        Size of the figure\n\n    axis : int, optional, default = 0\n        Which axis of array indexes images\n\n    fig : matplotlib figure, optional, default = None\n        An existing figure to plot on\n    \"\"\"\n    from matplotlib.pyplot import figure, colorbar\n    from mpl_toolkits.axes_grid1 import ImageGrid\n\n    if not isinstance(imgs, list):\n        if not isinstance(imgs, ndarray):\n            imgs = asarray(imgs)        \n        if (axis < 0) | (axis >= imgs.ndim):\n            raise ValueError(\"Must specify a valid axis to index the images\")\n        imgs = list(rollaxis(imgs, axis, 0))\n\n    imgs = [asarray(im) for im in imgs]\n\n    if (nans is True) and (imgs[0].dtype != bool):\n        imgs = [nan_to_num(im) for im in imgs]\n\n    if fig is None:\n        fig = figure(figsize=(size, size))\n\n    if bar is True:\n        axes_pad = 0.4\n        if sum([im.ndim == 3 for im in imgs]):\n            raise ValueError(\"Cannot show meaningful colorbar for RGB image\")\n        cbar_mode = \"each\"\n    else:\n        axes_pad = 0.2\n        cbar_mode = None\n\n    nimgs = len(imgs)\n\n    if not isinstance(cmap, list):\n        cmap = [cmap for _ in range(nimgs)]\n\n    if not isinstance(clim, list):\n        clim = [clim for _ in range(nimgs)]\n    \n    if len(clim) < nimgs:\n        raise ValueError(\"Number of clim specifications %g too small for number of images %g\"\n                         % (len(clim), nimgs))\n\n    if len(cmap) < nimgs:\n        raise ValueError(\"Number of cmap specifications %g too small for number of images %g\"\n                         % (len(cmap), nimgs))\n\n    if grid is None:\n        c = int(ceil(sqrt(nimgs)))\n        grid = (c, c)\n\n    ngrid = grid[0] * grid[1]\n    if ngrid < nimgs:\n        raise ValueError(\"Total grid count %g too small for number of images %g\" % (ngrid, nimgs))\n\n    g = ImageGrid(fig, 111, nrows_ncols=grid, axes_pad=axes_pad,\n                  cbar_mode=cbar_mode, cbar_size=\"5%\", cbar_pad=\"5%\")\n\n    axes = []\n    for i, im in enumerate(imgs):\n        ax = g[i].imshow(im, cmap=cmap[i], interpolation='nearest', clim=clim[i])\n        g[i].axis('off')\n\n        if bar:\n            cb = colorbar(ax, g[i].cax)\n            rng = abs(cb.vmax - cb.vmin) * 0.05\n            cb.set_ticks([around(cb.vmin + rng, 1), around(cb.vmax - rng, 1)])\n            cb.outline.set_visible(False)\n\n        axes.append(ax)\n\n    if nimgs < ngrid:\n        for i in range(nimgs, ngrid):\n            g[i].axis('off')\n            g[i].cax.axis('off')\n\n    return axes, g"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays an image in a colorbar or figure.", "response": "def image(img, cmap='gray', bar=False, nans=True, clim=None, size=7, ax=None):\n    \"\"\"\n    Streamlined display of images using matplotlib.\n\n    Parameters\n    ----------\n    img : ndarray, 2D or 3D\n        The image to display\n\n    cmap : str or Colormap, optional, default = 'gray'\n        A colormap to use, for non RGB images\n\n    bar : boolean, optional, default = False\n        Whether to append a colorbar\n\n    nans : boolean, optional, deafult = True\n        Whether to replace NaNs, if True, will replace with 0s\n\n    clim : tuple, optional, default = None\n        Limits for scaling image\n\n    size : scalar, optional, deafult = 9\n        Size of the figure\n\n    ax : matplotlib axis, optional, default = None\n        An existing axis to plot into\n    \"\"\"\n    from matplotlib.pyplot import axis, colorbar, figure, gca\n\n    img = asarray(img)\n\n    if (nans is True) and (img.dtype != bool):\n        img = nan_to_num(img)\n\n    if ax is None:\n        f = figure(figsize=(size, size))\n        ax = gca()\n\n    if img.ndim == 3:\n        if bar:\n            raise ValueError(\"Cannot show meaningful colorbar for RGB images\")\n        if img.shape[2] != 3:\n            raise ValueError(\"Size of third dimension must be 3 for RGB images, got %g\" % img.shape[2])\n        mn = img.min()\n        mx = img.max()\n        if mn < 0.0 or mx > 1.0:\n            raise ValueError(\"Values must be between 0.0 and 1.0 for RGB images, got range (%g, %g)\" % (mn, mx))\n        im = ax.imshow(img, interpolation='nearest', clim=clim)\n    else:\n        im = ax.imshow(img, cmap=cmap, interpolation='nearest', clim=clim)\n\n    if bar is True:\n        cb = colorbar(im, fraction=0.046, pad=0.04)\n        rng = abs(cb.vmax - cb.vmin) * 0.05\n        cb.set_ticks([around(cb.vmin + rng, 1), around(cb.vmax - rng, 1)])\n        cb.outline.set_visible(False)\n\n    axis('off')\n\n    return im"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all(cls):\n\n        api = Client.instance().api\n\n        endpoint_list = api.endpoint.get()\n\n        return endpoint_list", "response": "Returns a list of all configured endpoints."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, url, databases):\n\n        api = Client.instance().api\n\n        result = api.endpoint.post(data={\n            'endpoint': url,\n            'databases': databases,\n        })\n\n        return result", "response": "Create a new instance of the class at the specified endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroy(cls, url):\n\n        api = Client.instance().api\n\n        api.endpoint(url).delete()", "response": "This operation deletes an existing endpoint from the list of endpoints and makes the server stop listening on it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for the event to be fired.", "response": "def wait(self):\n        \"\"\"\n        Return a deferred that will be fired when the event is fired.\n        \"\"\"\n        d = defer.Deferred()\n        if self._result is None:\n            self._waiters.append(d)\n        else:\n            self._fire_deferred(d)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when the channel is closed", "response": "def do_close(self, reason):\n        \"\"\"Called when channel_close() is received\"\"\"\n        if self.closed:\n            return\n        self.closed = True\n        self.reason = reason\n        self.incoming.close()\n        self.responses.close()\n        if not self._closing:\n            self.client.channel_failed(self, Failure(reason))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise the appropriate Closed - based error for the given reason.", "response": "def _raise_closed(reason):\n        \"\"\"Raise the appropriate Closed-based error for the given reason.\"\"\"\n        if isinstance(reason, Message):\n            if reason.method.klass.name == \"channel\":\n                raise ChannelClosed(reason)\n            elif reason.method.klass.name == \"connection\":\n                raise ConnectionClosed(reason)\n        raise Closed(reason)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self, reason=None, within=0):\n        if self.closed:\n            return\n\n        if reason is None:\n            reason = ConnectionDone()\n\n        if within > 0:\n            channel0 = yield self.channel(0)\n            deferred = channel0.connection_close()\n            call = self.clock.callLater(within, deferred.cancel)\n            try:\n                yield deferred\n            except defer.CancelledError:\n                pass\n            else:\n                call.cancel()\n\n        self.do_close(reason)", "response": "Explicitely close the connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of this namespace.", "response": "def copy(self):\n        '''Returns a copy of this namespace.\n\n        Note: we truly create a copy of the dictionary but keep\n              _macros and _blocks.\n        '''\n        return Namespace(self.dictionary.copy(), self._macros, self._blocks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _do_tcp_check(self, ip, results):\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(1)\n            sock.connect((ip, self.conf['tcp_check_port']))\n        except:\n            # Any problem during the connection attempt? We won't diagnose it,\n            # we just indicate failure by adding the IP to the list\n            results.append(ip)\n        finally:\n            sock.close()", "response": "Perform a TCP check on the specified IP and store the IP in the results dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_health_checks(self, list_of_ips):\n        threads = []\n        results = []\n\n        # Start the thread for each IP we wish to check.\n        for count, ip in enumerate(list_of_ips):\n            thread = threading.Thread(\n                                target = self._do_tcp_check,\n                                name   = \"%s:%s\" % (self.thread_name, ip),\n                                args   = (ip, results))\n            thread.start()\n            threads.append(thread)\n\n        # ... make sure all threads are done...\n        for thread in threads:\n            thread.join()\n\n        # ... and send back all the failed IPs.\n        return results, []", "response": "Perform a health check on a list of IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        logging.info(\"TCP health monitor plugin: Starting to watch \"\n                     \"instances.\")\n\n        self.monitor_thread = threading.Thread(target = self.start_monitoring,\n                                               name   = self.thread_name)\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()", "response": "Start monitoring thread of the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the monitoring thread of the plugin.", "response": "def stop(self):\n        \"\"\"\n        Stop the monitoring thread of the plugin.\n\n        The super-class will send the stop signal on the monitor-IP queue,\n        which prompts the loop to stop.\n\n        \"\"\"\n        super(Tcp, self).stop()\n        self.monitor_thread.join()\n        logging.info(\"TCP health monitor plugin: Stopped\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_arguments(cls, parser, sys_arg_list=None):\n        parser.add_argument('--tcp_check_interval',\n                            dest='tcp_check_interval',\n                            required=False, default=2, type=float,\n                            help=\"TCP health-test interval in seconds, \"\n                                 \"default 2 \"\n                                 \"(only for 'tcp' health monitor plugin)\")\n        parser.add_argument('--tcp_check_port',\n                            dest='tcp_check_port',\n                            required=False, default=22, type=int,\n                            help=\"Port for TCP health-test, default 22 \"\n                                 \"(only for 'tcp' health monitor plugin)\")\n        return [\"tcp_check_interval\", \"tcp_check_port\"]", "response": "Add the arguments for the TCP health monitor plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_arguments(cls, conf):\n        # Checking the interval\n        if not conf['tcp_check_interval']:\n            raise ArgsError(\"A TCP health-test interval needs to be \"\n                            \"specified (--tcp_check_interval).\")\n\n        if not (1 <= conf['tcp_check_interval'] <= 3600):\n            raise ArgsError(\"Specified TCP health-test interval must be \"\n                            \"between 1 and 3600 seconds\")\n\n        # Checking the port\n        if not conf['tcp_check_port']:\n            raise ArgsError(\"A port for the TCP health-test needs to be \"\n                            \"specified (--tcp_check_port).\")\n\n        if not (1 <= conf['tcp_check_port'] <= 65535):\n            raise ArgsError(\"Specified port for TCP health-test must be \"\n                            \"between 1 and 65535\")", "response": "Check the arguments for the specific TCP health - test plugin options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_negatives(numbers):\n    \"Raise warning for negative numbers.\"\n\n    negatives = filter(lambda x: x < 0, filter(None, numbers))\n    if any(negatives):\n        neg_values = ', '.join(map(str, negatives))\n        msg = 'Found negative value(s): {0!s}. '.format(neg_values)\n        msg += 'While not forbidden, the output will look unexpected.'\n        warnings.warn(msg)", "response": "Raise warning for negative numbers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind index postions in list of numbers to be emphasized according to emph.", "response": "def _check_emphasis(numbers, emph):\n    \"Find index postions in list of numbers to be emphasized according to emph.\"\n\n    pat = '(\\w+)\\:(eq|gt|ge|lt|le)\\:(.+)'\n    # find values to be highlighted\n    emphasized = {} # index: color\n    for (i, n) in enumerate(numbers):\n        if n is None:\n            continue\n        for em in emph:\n            color, op, value = re.match(pat, em).groups()\n            value = float(value)\n            if op == 'eq' and n == value:\n                emphasized[i] = color\n            elif op == 'gt' and n > value:\n                emphasized[i] = color\n            elif op == 'ge' and n >= value:\n                emphasized[i] = color\n            elif op == 'lt' and n < value:\n                emphasized[i] = color\n            elif op == 'le' and n <= value:\n                emphasized[i] = color\n    return emphasized"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscales input numbers to appropriate range.", "response": "def scale_values(numbers, num_lines=1, minimum=None, maximum=None):\n    \"Scale input numbers to appropriate range.\"\n\n    # find min/max values, ignoring Nones\n    filtered = [n for n in numbers if n is not None]\n    min_ = min(filtered) if minimum is None else minimum\n    max_ = max(filtered) if maximum is None else maximum\n    dv = max_ - min_\n\n    # clamp\n    numbers = [max(min(n, max_), min_) if n is not None else None for n in numbers]\n\n    if dv == 0:\n        values = [4 * num_lines if x is not None else None for x in numbers]\n    elif dv > 0:\n        num_blocks = len(blocks) - 1\n\n        min_index = 1.\n        max_index = num_lines * num_blocks\n\n        values = [\n            ((max_index - min_index) * (x - min_)) / dv + min_index\n            if not x is None else None for x in numbers\n        ]\n\n        values = [round(v) or 1 if not v is None else None for v in values]\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sparklines(numbers=[], num_lines=1, emph=None, verbose=False,\n        minimum=None, maximum=None, wrap=None):\n    \"\"\"\n    Return a list of 'sparkline' strings for a given list of input numbers.\n\n    The list of input numbers may contain None values, too, for which the\n    resulting sparkline will contain a blank character (a space).\n\n    Examples:\n\n        sparklines([3, 1, 4, 1, 5, 9, 2, 6])\n        -> ['\u2583\u2581\u2584\u2581\u2584\u2588\u2582\u2585']\n        sparklines([3, 1, 4, 1, 5, 9, 2, 6], num_lines=2)\n        -> [\n            '     \u2588 \u2582',\n            '\u2585\u2581\u2586\u2581\u2588\u2588\u2583\u2588'\n        ]\n    \"\"\"\n\n    assert num_lines > 0\n\n    if len(numbers) == 0:\n        return ['']\n\n    # raise warning for negative numbers\n    _check_negatives(numbers)\n\n    values = scale_values(numbers, num_lines=num_lines, minimum=minimum, maximum=maximum)\n\n    # find values to be highlighted\n    emphasized = _check_emphasis(numbers, emph) if emph else {}\n\n    point_index = 0\n    subgraphs = []\n    for subgraph_values in batch(wrap, values):\n        multi_values = []\n        for i in range(num_lines):\n            multi_values.append([\n                min(v, 8) if not v is None else None\n                for v in subgraph_values\n            ])\n            subgraph_values = [max(0, v-8) if not v is None else None for v in subgraph_values]\n        multi_values.reverse()\n        lines = []\n        for subgraph_values in multi_values:\n            if HAVE_TERMCOLOR and emphasized:\n                tc = termcolor.colored\n                res = [tc(blocks[int(v)], emphasized.get(point_index + i, 'white')) if not v is None else ' ' for (i, v) in enumerate(subgraph_values)]\n            else:\n                res = [blocks[int(v)] if not v is None else ' ' for v in subgraph_values]\n            lines.append(''.join(res))\n        subgraphs.append(lines)\n        point_index += len(subgraph_values)\n\n    return list_join('', subgraphs)", "response": "Returns a list of sparkline strings for a given list of input numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch(batch_size, items):\n    \"Batch items into groups of batch_size\"\n    items = list(items)\n    if batch_size is None:\n        return [items]\n    MISSING = object()\n    padded_items = items + [MISSING] * (batch_size - 1)\n    groups = zip(*[padded_items[i::batch_size] for i in range(batch_size)])\n    return [[item for item in group if item != MISSING] for group in groups]", "response": "Batch items into groups of batch_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef demo(nums=[]):\n    \"Print a few usage examples on stdout.\"\n\n    nums = nums or [3, 1, 4, 1, 5, 9, 2, 6]\n    fmt = lambda num: '{0:g}'.format(num) if isinstance(num, (float, int)) else 'None'\n    nums1 = list(map(fmt, nums))\n\n    if __name__ == '__main__':\n        prog = sys.argv[0]\n    else:\n        prog = 'sparklines'\n\n    result = []\n\n\n    result.append('Usage examples (command-line and programmatic use):')\n    result.append('')\n\n    result.append('- Standard one-line sparkline')\n    result.append('{0!s} {1!s}'.format(prog, ' '.join(nums1)))\n    result.append('>>> print(sparklines([{0!s}])[0])'.format(', '.join(nums1)))\n    result.append(sparklines(nums)[0])\n    result.append('')\n\n    result.append('- Multi-line sparkline (n=2)')\n    result.append('{0!s} -n 2 {1!s}'.format(prog, ' '.join(nums1)))\n    result.append('>>> for line in sparklines([{0!s}], num_lines=2): print(line)'.format(', '.join(nums1)))\n    for line in sparklines(nums, num_lines=2):\n        result.append(line)\n    result.append('')\n\n    result.append('- Multi-line sparkline (n=3)')\n    result.append('{0!s} -n 3 {1!s}'.format(prog, ' '.join(nums1)))\n    result.append('>>> for line in sparklines([{0!s}], num_lines=3): print(line)'.format(', '.join(nums1)))\n    for line in sparklines(nums, num_lines=3):\n        result.append(line)\n    result.append('')\n\n    nums = nums + [None] + list(reversed(nums[:]))\n    result.append('- Standard one-line sparkline with gap')\n    result.append('{0!s} {1!s}'.format(prog, ' '.join(map(str, nums))))\n    result.append('>>> print(sparklines([{0!s}])[0])'.format(', '.join(map(str, nums))))\n    result.append(sparklines(nums)[0])\n    return '\\n'.join(result) + '\\n'", "response": "Print a few usage examples on stdout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all expired entries.", "response": "def _expire_data(self):\n        \"\"\"\n        Remove all expired entries.\n\n        \"\"\"\n        expire_time_stamp = time.time() - self.expire_time\n        self.timed_data   = {d: t for d, t in self.timed_data.items()\n                             if t > expire_time_stamp}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, data_set):\n        now = time.time()\n        for d in data_set:\n            self.timed_data[d] = now\n        self._expire_data()", "response": "Update the time of all specified elements in the supplied data set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_info(self):\n        plugin_infos = {}\n        for pc in self.plugins:\n            plugin_infos.update(pc.get_info())\n        return {\n            self.get_plugin_name() : {\n                \"version\"     : self.get_version(),\n                \"sub-plugins\" : plugin_infos,\n                \"params\" : {\n                    \"multi_plugins\" : self.conf['multi_plugins']\n                },\n            }\n        }", "response": "Return information about the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _accumulate_ips_from_plugins(self, ip_type_name, plugin_queue_lookup,\n                                     ip_accumulator):\n        \"\"\"\n        Retrieve all IPs of a given type from all sub-plugins.\n\n        ip_type_name:        A name of the type of IP we are working with.\n                             Used for nice log messages. Example 'failed',\n                             'questionable'.\n        plugin_queue_lookup: Dictionary to lookup the queues (of a given type)\n                             for a plugins, by plugin name.\n        ip_accumulator:      An expiring data set for this type of IP address.\n\n        Returns either a set of addresses to send out on our own reporting\n        queues, or None.\n\n        \"\"\"\n        all_reported_ips  = set()\n        for pname, q in plugin_queue_lookup.items():\n            # Get all the IPs of the specified type from all the plugins.\n            ips = utils.read_last_msg_from_queue(q)\n            if ips:\n                logging.debug(\"Sub-plugin '%s' reported %d \"\n                              \"%s IPs: %s\" %\n                              (pname, len(ips), ip_type_name,\n                               \",\".join(ips)))\n                all_reported_ips.update(ips)  # merge all the lists\n            else:\n                logging.debug(\"Sub-plugin '%s' reported no \"\n                              \"%s IPs.\" % (pname, ip_type_name))\n\n        # Send out the combined list of reported IPs. The receiver of this\n        # message expects this list to always be the full list of IPs. So, IF\n        # they get a message, it needs to be complete, since otherwise any IP\n        # not mentioned in this update is considered healthy.\n        #\n        # Since different sub-plugins may report different IPs at different\n        # times (and not always at the same time), we need to accumulate those\n        # IPs that are recorded by different sub-plugins over time.\n        #\n        # We use an 'expiring data set' to store those: If any plugin refreshes\n        # an IP as failed then the entry remains, otherwise, it will expire\n        # after some time. The expiring data set therefore, is an accumulation\n        # of recently reported IPs. We always report this set, whenever we send\n        # out an update of IPs.\n        #\n        # Each type of IP (for example, 'failed' or 'questionable') has its own\n        # accumulator, which was passed in to this function.\n        if all_reported_ips:\n            ip_accumulator.update(all_reported_ips)\n            current_ips = ip_accumulator.get()\n            logging.info(\"Multi-plugin health monitor: \"\n                         \"Reporting combined list of %s \"\n                         \"IPs: %s\" %\n                         (ip_type_name,\n                          \",\".join(current_ips)))\n            return current_ips\n        else:\n            logging.debug(\"No failed IPs to report.\")\n            return None", "response": "This function fetches all the IPs of a given type from all sub - plugins and sends them out to the expiring data set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart monitoring the IP lists of all the plugins and the queues of all the plugins.", "response": "def start_monitoring(self):\n        \"\"\"\n        Pass IP lists to monitor sub-plugins and get results from them.\n\n        Override the common definition of this function, since in the multi\n        plugin it's a little different: Instead of monitoring ourselves, we\n        just use a number of other plugins to gather results. The multi plugin\n        just serves as a proxy and (de)multiplexer for those other plugins.\n\n        Note that we don't have to push any updates about failed IPs if nothing\n        new was detected. Therefore, our own updates can be entirely driven by\n        updates from the sub-plugin, which keeps our architecture simple.\n\n        \"\"\"\n        logging.info(\"Multi-plugin health monitor: Started in thread.\")\n        try:\n            while True:\n                # Get new IP addresses and pass them on to the sub-plugins\n                new_ips = self.get_new_working_set()\n                if new_ips:\n                    logging.debug(\"Sending list of %d IPs to %d plugins.\" %\n                                  (len(new_ips), len(self.plugins)))\n                    for q in self.monitor_ip_queues.values():\n                        q.put(new_ips)\n\n                # Get any notifications about failed or questionable IPs from\n                # the plugins.\n                all_failed_ips = self._accumulate_ips_from_plugins(\n                                            \"failed\",\n                                            self.failed_queue_lookup,\n                                            self.report_failed_acc)\n                if all_failed_ips:\n                    self.q_failed_ips.put(all_failed_ips)\n\n                all_questionable_ips = self._accumulate_ips_from_plugins(\n                                            \"questionable\",\n                                            self.questionable_queue_lookup,\n                                            self.report_questionable_acc)\n                if all_questionable_ips:\n                    self.q_questionable_ips.put(all_questionable_ips)\n\n                time.sleep(self.get_monitor_interval())\n\n        except common.StopReceived:\n            # Received the stop signal, just exiting the thread function\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        super(Multi, self).stop()\n        self.monitor_thread.join()\n\n        logging.info(\"Multi-plugin health monitor: Stopping plugins\")\n        for p in self.plugins:\n            p.stop()\n\n        logging.info(\"Multi-plugin health monitor: Stopped\")", "response": "Stop monitoring thread of the Multi - plugin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading sub - plugins from a string.", "response": "def load_sub_plugins_from_str(cls, plugins_str):\n        \"\"\"\n        Load plugin classes based on column separated list of plugin names.\n\n        Returns dict with plugin name as key and class as value.\n\n        \"\"\"\n        plugin_classes = {}\n        if plugins_str:\n            for plugin_name in plugins_str.split(\":\"):\n                pc = load_plugin(plugin_name, MONITOR_DEFAULT_PLUGIN_MODULE)\n                plugin_classes[plugin_name] = pc\n        return plugin_classes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the arguments for the Multi health monitor plugin.", "response": "def add_arguments(cls, parser, sys_arg_list=None):\n        \"\"\"\n        Arguments for the Multi health monitor plugin.\n\n        \"\"\"\n        parser.add_argument('--multi_plugins',\n                            dest='multi_plugins', required=True,\n                            help=\"Column seperated list of health monitor \"\n                                 \"plugins (only for 'multi' health monitor \"\n                                 \"plugin)\")\n\n        arglist = [\"multi_plugins\"]\n\n        # Read the list of the specified sub-plugins ahead of time, so we can\n        # get their classes and add their parameters.\n        sub_plugin_names_str = \\\n                utils.param_extract(sys_arg_list, None, \"--multi_plugins\")\n        sub_plugin_classes = \\\n                cls.load_sub_plugins_from_str(sub_plugin_names_str).values()\n\n        # Store the list of the sub-plugins in the class, so we can iterate\n        # over those during parameter evaluation later on.\n        cls.multi_plugin_classes = sub_plugin_classes\n\n        # Now also add the parameters for the sub-plugins\n        for pc in sub_plugin_classes:\n            arglist.extend(pc.add_arguments(parser, sys_arg_list))\n\n        return arglist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_arguments(cls, conf):\n        # Checking the specified list of basic health monitor plugins, which\n        # should be run by the multi plugin.\n        if not conf.get('multi_plugins'):\n            raise ArgsError(\"A specification of health monitor plugins \"\n                            \"is required (--multi_plugins).\")\n\n        # Now check parameters for all sub-plugins. We use the list of classes\n        # for sub-plugins that we discovered earlier while adding parameters\n        # for those sub-plugins.\n        for mpc in cls.multi_plugin_classes:\n            mpc.check_arguments(conf)", "response": "Check the arguments for the health monitor plugins which are required by the multi - plugin."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_route_spec_config(fname):\n    try:\n        try:\n            f = open(fname, \"r\")\n        except IOError as e:\n            # Cannot open file? Doesn't exist?\n            raise ValueError(\"Cannot open file: \" + str(e))\n        data = json.loads(f.read())\n        f.close()\n        # Sanity checking on the data object\n        data = common.parse_route_spec_config(data)\n\n    except ValueError as e:\n        logging.error(\"Config ignored: %s\" % str(e))\n        data = None\n\n    return data", "response": "Read and parse the route spec config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the configfile change monitoring thread.", "response": "def start(self):\n        \"\"\"\n        Start the configfile change monitoring thread.\n\n        \"\"\"\n        fname = self.conf['file']\n        logging.info(\"Configfile watcher plugin: Starting to watch route spec \"\n                     \"file '%s' for changes...\" % fname)\n\n        # Initial content of file needs to be processed at least once, before\n        # we start watching for any changes to it. Therefore, we will write it\n        # out on the queue right away.\n        route_spec = {}\n        try:\n            route_spec = read_route_spec_config(fname)\n            if route_spec:\n                self.last_route_spec_update = datetime.datetime.now()\n                self.q_route_spec.put(route_spec)\n        except ValueError as e:\n            logging.warning(\"Cannot parse route spec: %s\" % str(e))\n\n        # Now prepare to watch for any changes in that file.  Find the parent\n        # directory of the config file, since this is where we will attach a\n        # watcher to.\n        abspath    = os.path.abspath(fname)\n        parent_dir = os.path.dirname(abspath)\n\n        # Create the file watcher and run in endless loop\n        handler = RouteSpecChangeEventHandler(\n                                    route_spec_fname   = fname,\n                                    route_spec_abspath = abspath,\n                                    q_route_spec       = self.q_route_spec,\n                                    plugin             = self)\n        self.observer_thread = watchdog.observers.Observer()\n        self.observer_thread.name = \"ConfMon\"\n        self.observer_thread.schedule(handler, parent_dir)\n        self.observer_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n        self.observer_thread.stop()\n        self.observer_thread.join()\n        logging.info(\"Configfile watcher plugin: Stopped\")", "response": "Stop the config change monitoring thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding command line arguments for the configfile mode.", "response": "def add_arguments(cls, parser, sys_arg_list=None):\n        \"\"\"\n        Arguments for the configfile mode.\n\n        \"\"\"\n        parser.add_argument('-f', '--file', dest='file', required=True,\n                            help=\"config file for routing groups \"\n                                 \"(only in configfile mode)\")\n        return [\"file\"]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the config file is valid.", "response": "def check_arguments(cls, conf):\n        \"\"\"\n        Sanity checks for options needed for configfile mode.\n\n        \"\"\"\n        try:\n            # Check we have access to the config file\n            f = open(conf['file'], \"r\")\n            f.close()\n        except IOError as e:\n            raise ArgsError(\"Cannot open config file '%s': %s\" %\n                            (conf['file'], e))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_plugin(plugin_name, default_plugin_module):\n    try:\n        if \".\" in plugin_name:\n            # Assume external plugin, full path\n            plugin_mod_name   = plugin_name\n            plugin_class_name = plugin_name.split(\".\")[-1].capitalize()\n        else:\n            # One of the built-in plugins\n            plugin_mod_name   = \"%s.%s\" % (default_plugin_module, plugin_name)\n            plugin_class_name = plugin_name.capitalize()\n\n        plugin_mod        = importlib.import_module(plugin_mod_name)\n        plugin_class      = getattr(plugin_mod, plugin_class_name)\n        return plugin_class\n    except ImportError as e:\n        raise PluginError(\"Cannot load '%s'\" % plugin_mod_name)\n    except AttributeError:\n        raise PluginError(\"Cannot find plugin class '%s' in \"\n                          \"plugin '%s'\" %\n                          (plugin_class_name, plugin_mod_name))\n    except Exception as e:\n        raise PluginError(\"Error while loading plugin '%s': %s\" %\n                          (plugin_mod_name, str(e)))", "response": "Load a plugin from the vpcrouter plugin module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_signal_receiver(self, callback_fn, signal, user_arg):\n        if (signal in self._signal_names):\n            s = Signal(signal, callback_fn, user_arg)\n            self._signals[signal] = s\n            self._bus.add_signal_receiver(s.signal_handler,\n                                          signal,\n                                          dbus_interface=self._dbus_addr)\n        else:\n            raise ConnSignalNameNotRecognisedException", "response": "Adds a signal receiver callback with user argument"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving an installed signal receiver by signal name.", "response": "def remove_signal_receiver(self, signal):\n        \"\"\"\n        Remove an installed signal receiver by signal name.\n\n        See also :py:meth:`add_signal_receiver`\n        :py:exc:`exceptions.ConnSignalNameNotRecognisedException`\n\n        :param str signal:\n            Signal name to uninstall e.g., :py:attr:`SIGNAL_PROPERTY_CHANGED`\n        :return:\n        :raises ConnSignalNameNotRecognisedException:\n            if the signal name is not registered\n        \"\"\"\n        if (signal in self._signal_names):\n            s = self._signals.get(signal)\n            if (s):\n                self._bus.remove_signal_receiver(s.signal_handler,\n                                                 signal,\n                                                 dbus_interface=self._dbus_addr)  # noqa\n                self._signals.pop(signal)\n        else:\n            raise ConnSignalNameNotRecognisedException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_request(self, request, url, **kwargs):\n        \"Actually makes the HTTP request.\"\n        try:\n            response = request(url, stream=True, **kwargs)\n        except RequestException as e:\n            raise RequestError(e)\n        else:\n            if response.status_code >= 400:\n                raise ResponseError(response)\n        # Try to return the response in the most useful fashion given it's\n        # type.\n        if response.headers.get('content-type') == 'application/json':\n            try:\n                # Try to decode as JSON\n                return response.json()\n            except (TypeError, ValueError):\n                # If that fails, return the text.\n                return response.text\n        else:\n            # This might be a file, so return it.\n            if kwargs.get('params', {}).get('raw', True):\n                return response.raw\n            else:\n                return response", "response": "Actually makes the HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles retrying failed requests and error handling.", "response": "def _request(self, method, endpoint, id=None, **kwargs):\n        \"Handles retrying failed requests and error handling.\"\n        request = getattr(requests, method, None)\n        if not callable(request):\n            raise RequestError('Invalid method %s' % method)\n        # Find files, separate them out to correct kwarg for requests.\n        data = kwargs.get('data')\n        if data:\n            files = {}\n            for name, value in list(data.items()):\n                # Value might be a file-like object (with a read method), or it\n                # might be a (filename, file-like) tuple.\n                if hasattr(value, 'read') or isinstance(value, tuple):\n                    files[name] = data.pop(name)\n            if files:\n                kwargs.setdefault('files', {}).update(files)\n        path = ['api', self.version, endpoint]\n        # If we received an ID, append it to the path.\n        if id:\n            path.append(str(id))\n        # Join fragments into a URL\n        path = '/'.join(path)\n        if not path.endswith('/'):\n            path += '/'\n        while '//' in path:\n            path = path.replace('//', '/')\n        url = self.url + path\n        # Add our user agent.\n        kwargs.setdefault('headers', {}).setdefault('User-Agent',\n                                                    HTTP_USER_AGENT)\n        # Now try the request, if we get throttled, sleep and try again.\n        trys, retrys = 0, 3\n        while True:\n            if trys == retrys:\n                raise RequestError('Could not complete request after %s trys.'\n                                   % trys)\n            trys += 1\n            try:\n                return self._do_request(request, url, **kwargs)\n            except ResponseError as e:\n                if self.throttle_wait and e.status_code == 503:\n                    m = THROTTLE_PATTERN.match(\n                        e.response.headers.get('x-throttle', ''))\n                    if m:\n                        time.sleep(float(m.group(1)))\n                        continue\n                # Failed for a reason other than throttling.\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads the data from the specified file to the specified path.", "response": "def download(self, file_to_be_downloaded, perform_download=True, download_to_path=None):\n        \"\"\" file_to_be_downloaded is a file-like object that has already\n        been uploaded, you cannot download folders \"\"\"\n        response = self.get(\n            '/path/data/', file_to_be_downloaded, raw=False)\n        if not perform_download:\n            # The caller can decide how to process the download of the data\n            return response\n        if not download_to_path:\n            download_to_path = file_to_be_downloaded.split(\"/\")[-1]\n        # download uses shutil.copyfileobj to download, which copies\n        # the data in chunks\n        o = open(download_to_path, 'wb')\n        return shutil.copyfileobj(response.raw, o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates notebook under notebook directory.", "response": "def create_notebook(self, data):\n        \"\"\"Create notebook under notebook directory.\"\"\"\n        r = requests.post('http://{0}/api/notebook'.format(self.zeppelin_url),\n                          json=data)\n        self.notebook_id = r.json()['body']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_notebook_to_execute(self):\n        while True:\n            r = requests.get('http://{0}/api/notebook/job/{1}'.format(\n                             self.zeppelin_url, self.notebook_id))\n\n            if r.status_code == 200:\n                try:\n                    data = r.json()['body']\n                    if all(paragraph['status'] in ['FINISHED', 'ERROR'] for paragraph in data):\n                        break\n                    time.sleep(5)\n                    continue\n                except KeyError as e:\n                    print(e)\n                    print(r.json())\n\n            elif r.status_code == 500:\n                print('Notebook is still busy executing. Checking again in 60 seconds...')\n                time.sleep(60)\n                continue\n\n            else:\n                print('ERROR: Unexpected return code: {}'.format(r.status_code))\n                sys.exit(1)", "response": "Wait for notebook to finish executing before continuing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_executed_notebook(self):\n        r = requests.get('http://{0}/api/notebook/{1}'.format(\n                         self.zeppelin_url, self.notebook_id))\n        if r.status_code == 200:\n            return r.json()['body']\n        else:\n            print('ERROR: Could not get executed notebook.', file=sys.stderr)\n            sys.exit(1)", "response": "Return the executed notebook."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving notebook depending on user provided output path.", "response": "def save_notebook(self, body):\n        \"\"\"Save notebook depending on user provided output path.\"\"\"\n        directory = os.path.dirname(self.output_path)\n        full_path = os.path.join(directory, self.notebook_name)\n        try:\n            with open(full_path, 'w') as fh:\n                fh.write(json.dumps(body, indent=2))\n        except ValueError:\n            print('ERROR: Could not save executed notebook to path: ' +\n                  self.output_path +\n                  ' -- Please provide a valid absolute path.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_notebook(self, data):\n        self.create_notebook(data)\n        self.run_notebook()\n        self.wait_for_notebook_to_execute()\n        body = self.get_executed_notebook()\n\n        err = False\n        output = []\n        for paragraph in body['paragraphs']:\n            if 'results' in paragraph and paragraph['results']['code'] == 'ERROR':\n                output.append(paragraph['results']['msg'][0]['data'])\n                err = True\n\n            elif 'result' in paragraph and paragraph['result']['code'] == 'ERROR':\n                output.append(paragraph['result']['msg'])\n                err = True\n\n        [print(e.strip() + '\\n', file=sys.stderr) for e in output if e]\n\n        if err:\n            sys.exit(1)\n\n        if not self.output_path:\n            print(json.dumps(body, indent=2))\n        else:\n            self.save_notebook(body)", "response": "Execute the input notebook and save it to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_arg_parser(args_list, watcher_plugin_class, health_plugin_class):\n    parser = argparse.ArgumentParser(\n                    description=\"VPC router: Manage routes in VPC route table\")\n    # General arguments\n    parser.add_argument('--verbose', dest=\"verbose\", action='store_true',\n                        help=\"produces more output\")\n    parser.add_argument('-l', '--logfile', dest='logfile',\n                        default='-',\n                        help=\"full path name for the logfile, \"\n                             \"or '-' for logging to stdout, \"\n                             \"default: '-' (logging to stdout)\"),\n    parser.add_argument('-r', '--region', dest=\"region_name\",\n                        required=False, default=None,\n                        help=\"the AWS region of the VPC\")\n    parser.add_argument('-v', '--vpc', dest=\"vpc_id\",\n                        required=False, default=None,\n                        help=\"the ID of the VPC in which to operate\")\n    parser.add_argument('--ignore_routes', dest=\"ignore_routes\",\n                        required=False, default=None,\n                        help=\"Comma separated list of CIDRs or IPs for \"\n                             \"routes which vpc-router should ignore.\")\n    parser.add_argument('--route_recheck_interval',\n                        dest=\"route_recheck_interval\",\n                        required=False, default=\"30\", type=int,\n                        help=\"time between regular checks of VPC route \"\n                             \"tables, default: 30\")\n    parser.add_argument('-a', '--address', dest=\"addr\",\n                        default=\"localhost\",\n                        help=\"address to listen on for HTTP requests, \"\n                             \"default: localhost\")\n    parser.add_argument('-p', '--port', dest=\"port\",\n                        default=\"33289\", type=int,\n                        help=\"port to listen on for HTTP requests, \"\n                             \"default: 33289\")\n    parser.add_argument('-m', '--mode', dest='mode', required=True,\n                        help=\"name of the watcher plugin\")\n    parser.add_argument('-H', '--health', dest='health', required=False,\n                        default=monitor.MONITOR_DEFAULT_PLUGIN,\n                        help=\"name of the health-check plugin, \"\n                             \"default: %s\" % monitor.MONITOR_DEFAULT_PLUGIN)\n\n    arglist = [\"logfile\", \"region_name\", \"vpc_id\", \"route_recheck_interval\",\n               \"verbose\", \"addr\", \"port\", \"mode\", \"health\", \"ignore_routes\"]\n\n    # Inform the CurrentState object of the main config parameter names, which\n    # should be rendered in an overview.\n    CURRENT_STATE.main_param_names = list(arglist)\n\n    # Let each watcher and health-monitor plugin add its own arguments.\n    for plugin_class in [watcher_plugin_class, health_plugin_class]:\n        if plugin_class:\n            arglist.extend(plugin_class.add_arguments(parser, args_list))\n\n    return parser, arglist", "response": "Configure and return an argument parser for the command line options."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the command line arguments and returns relevant values in a dict.", "response": "def _parse_args(args_list, watcher_plugin_class, health_plugin_class):\n    \"\"\"\n    Parse command line arguments and return relevant values in a dict.\n\n    Also perform basic sanity checking on some arguments.\n\n    If plugin classes have been provided then a callback into those classes is\n    used to extend the arguments with plugin-specific options.\n\n    Likewise, the sanity checking will then also invoke a callback into the\n    plugins, in order to perform a sanity check on the plugin options.\n\n    \"\"\"\n    conf = {}\n\n    # Setting up the command line argument parser. Note that we pass the\n    # complete list of all plugins, so that their parameter can be added to the\n    # official parameter handling, the help screen, etc. Some plugins may even\n    # add further plugins themselves, but will handle this themselves.\n    parser, arglist = _setup_arg_parser(args_list, watcher_plugin_class,\n                                        health_plugin_class)\n    args            = parser.parse_args(args_list)\n\n    # Transcribe argument values into our own dict\n    for argname in arglist:\n        conf[argname] = getattr(args, argname)\n\n    # Sanity checking of arguments. Let the watcher and health-monitor plugin\n    # class check their own arguments.\n    for plugin_class in [watcher_plugin_class, health_plugin_class]:\n        if plugin_class:\n            try:\n                plugin_class.check_arguments(conf)\n            except ArgsError as e:\n                parser.print_help()\n                raise e\n\n    # Sanity checking of other args\n    if conf['route_recheck_interval'] < 5 and \\\n                        conf['route_recheck_interval'] != 0:\n        raise ArgsError(\"route_recheck_interval argument must be either 0 \"\n                        \"or at least 5\")\n\n    if not 0 < conf['port'] < 65535:\n        raise ArgsError(\"Invalid listen port '%d' for built-in http server.\" %\n                        conf['port'])\n\n    if not conf['addr'] == \"localhost\":\n        # Check if a proper address was specified (already raises a suitable\n        # ArgsError if not)\n        utils.ip_check(conf['addr'])\n\n    if conf['ignore_routes']:\n        # Parse the list of addresses and CIDRs\n        for a in conf['ignore_routes'].split(\",\"):\n            a = a.strip()\n            a = utils.check_valid_ip_or_cidr(a, return_as_cidr=True)\n            CURRENT_STATE.ignore_routes.append(a)\n\n    # Store a reference to the config dict in the current state\n    CURRENT_STATE.conf = conf\n\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures the logging framework.", "response": "def _setup_logging(conf):\n    \"\"\"\n    Configure the logging framework.\n\n    If run in CLI mode then all log output is simply written to stdout.\n\n    \"\"\"\n    if conf['verbose']:\n        level = logging.DEBUG\n    else:\n        level = logging.INFO\n\n    fname = conf['logfile'] if conf['logfile'] != \"-\" else None\n\n    logging.basicConfig(filename=fname, level=level,\n                        format='%(asctime)s - %(levelname)-8s - '\n                               '%(threadName)-15s - %(message)s')\n\n    # Don't want to see all the messages from BOTO and watchdog\n    logging.getLogger('boto').setLevel(logging.CRITICAL)\n    logging.getLogger('watchdog.observers.inotify_buffer'). \\\n                                                setLevel(logging.CRITICAL)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    try:\n        # A bit of a hack: We want to load the plugins (specified via the mode\n        # and health parameter) in order to add their arguments to the argument\n        # parser. But this means we first need to look into the CLI arguments\n        # to find them ... before looking at the arguments. So we first perform\n        # a manual search through the argument list for this purpose only.\n        args = sys.argv[1:]\n\n        # Loading the watcher plugin\n        mode_name = utils.param_extract(args, \"-m\", \"--mode\", default=None)\n        if mode_name:\n            watcher_plugin_class = \\\n                load_plugin(mode_name, watcher.WATCHER_DEFAULT_PLUGIN_MODULE)\n        else:\n            watcher_plugin_class = None\n\n        # Loading the health monitor plugin\n        health_check_name = \\\n            utils.param_extract(args, \"-H\", \"--health\",\n                                default=monitor.MONITOR_DEFAULT_PLUGIN)\n        if health_check_name:\n            health_plugin_class = \\\n                load_plugin(health_check_name,\n                            monitor.MONITOR_DEFAULT_PLUGIN_MODULE)\n        else:\n            health_plugin_class = None\n\n        # Provide complete arg parsing for vpcrouter and all plugin classes.\n        conf = _parse_args(sys.argv[1:],\n                           watcher_plugin_class, health_plugin_class)\n\n        if not health_plugin_class or not watcher_plugin_class:\n            logging.error(\"Watcher plugin or health monitor plugin class \"\n                          \"are missing.\")\n            sys.exit(1)\n\n        _setup_logging(conf)\n\n        # If we are on an EC2 instance then some data is already available to\n        # us. The return data items in the meta data match some of the command\n        # line arguments, so we can pass this through to the parser function to\n        # provide defaults for those parameters. Specifically: VPC-ID and\n        # region name.\n        if not conf['vpc_id'] or not conf['region_name']:\n            meta_data = get_ec2_meta_data()\n            if 'vpc_id' not in meta_data or 'region_name' not in meta_data:\n                logging.error(\"VPC and region were not explicitly specified \"\n                              \"and can't be auto-discovered.\")\n                sys.exit(1)\n            else:\n                conf.update(meta_data)\n\n        try:\n            info_str = \"vpc-router (%s): mode: %s (%s), \" \\\n                       \"health-check: %s (%s)\" % \\\n                       (vpcrouter.__version__,\n                        conf['mode'], watcher_plugin_class.get_version(),\n                        health_check_name, health_plugin_class.get_version())\n            logging.info(\"*** Starting %s ***\" % info_str)\n            CURRENT_STATE.versions = info_str\n\n            http_srv = http_server.VpcRouterHttpServer(conf)\n            CURRENT_STATE._vpc_router_http = http_srv\n\n            watcher.start_watcher(conf,\n                                  watcher_plugin_class, health_plugin_class)\n            http_srv.stop()\n            logging.info(\"*** Stopping vpc-router ***\")\n        except Exception as e:\n            import traceback\n            traceback.print_exc()\n            logging.error(e.message)\n            logging.error(\"*** Exiting\")\n    except Exception as e:\n        print \"\\n*** Error: %s\\n\" % e.message\n\n    sys.exit(1)", "response": "Main entry point of the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_client(self,only_db=False):\n        #database = parse_uri(self.uri).get(\"database\")\n\n        if self.ioloop:\n            if only_db == False:\n                client = AsyncIOMotorClient(\"/\".join(self.uri.split(\"/\")[:-1]), io_loop=self.ioloop)\n            else:\n                client = AsyncIOMotorClient(self.uri, io_loop=self.ioloop)\n\n        else:\n            if only_db == False:\n                client = AsyncIOMotorClient(\"/\".join(self.uri.split(\"/\")[:-1]))\n            else:\n                client = AsyncIOMotorClient(self.uri)\n        return client", "response": "Create a new IOMotorClient object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_app(self, app):\n        if app.config.GRIDFS_SETTINGS and isinstance(app.config.GRIDFS_SETTINGS, dict):\n            self.GRIDFS_SETTINGS = app.config.GRIDFS_SETTINGS\n            self.app = app\n\n        else:\n            raise ValueError(\n                \"nonstandard sanic config GRIDFS_URIS,GRIDFS_URIS must be a Dict[Bucket_name,Tuple[dburl,collection]]\")\n\n        @app.listener(\"before_server_start\")\n        async def init_mongo_connection(app, loop):\n            for bucket_name, (dburl,collection) in app.config.GRIDFS_SETTINGS.items():\n                if isinstance(dburl,str):\n                    bucket = GridFSBucket(dburl,ioloop=loop,collection = collection).bucket\n                else:\n                    bucket = GridFSBucket(ioloop=loop,collection = collection,**dburl).bucket\n                self.GridFSs[bucket_name] = bucket\n\n        @app.listener(\"before_server_stop\")\n        async def sub_close(app, loop):\n            log.info(\"mongo connection {numbr}\".format(numbr=len(self.GridFSs)))\n            for bucket_name,bucket in self.GridFSs.items():\n                bucket.client.close\n                log.info(\"{bucket_name} connection closed\".format(bucket_name=bucket_name))\n\n\n        if \"extensions\" not in app.__dir__():\n            app.extensions = {}\n        app.extensions['SanicGridFS'] = self\n\n        app.GridFS = self.GridFSs\n        return self", "response": "Initialize the application with the given app."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new plugin to the list of plugins.", "response": "def add_plugin(self, plugin):\n        \"\"\"\n        Every plugin (watcher and health) is added so we can later get live\n        info from each plugin.\n\n        \"\"\"\n        self.plugin_by_name[plugin.get_plugin_name()] = plugin\n        self.plugins.append(plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_plugins_info(self):\n        d = {}\n        for p in self.plugins:\n            d.update(p.get_info())\n        return d", "response": "Collect the current live info from all the registered plugins."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_state_repr(self, path):\n        if path == \"ips\":\n            return {\n                \"failed_ips\"       : self.failed_ips,\n                \"questionable_ips\" : self.questionable_ips,\n                \"working_set\"      : self.working_set,\n            }\n\n        if path == \"route_info\":\n            return {\n                \"route_spec\"    : self.route_spec,\n                \"routes\"        : self.routes,\n                \"ignore_routes\" : self.ignore_routes\n            }\n\n        if path == \"plugins\":\n            return self.get_plugins_info()\n\n        if path == \"vpc\":\n            return self.vpc_state\n\n        if path == \"\":\n            return {\n                \"SERVER\"           : {\n                    \"version\"      : self.versions,\n                    \"start_time\"   : self.starttime.isoformat(),\n                    \"current_time\" : datetime.datetime.now().isoformat()\n                },\n                \"params\"     : self.render_main_params(),\n                \"plugins\"    : {\"_href\" : \"/plugins\"},\n                \"ips\"        : {\"_href\" : \"/ips\"},\n                \"route_info\" : {\"_href\" : \"/route_info\"},\n                \"vpc\"        : {\"_href\" : \"/vpc\"}\n            }", "response": "Returns the current state or sub - state depending on the path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a JSON representation of the current state in JSON.", "response": "def as_json(self, path=\"\", with_indent=False):\n        \"\"\"\n        Return a rendering of the current state in JSON.\n\n        \"\"\"\n        if path not in self.top_level_links:\n            raise StateError(\"Unknown path\")\n\n        return json.dumps(self.get_state_repr(path),\n                          indent=4 if with_indent else None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current state in HTML.", "response": "def as_html(self, path=\"\"):\n        \"\"\"\n        Return a rendering of the current state in HTML.\n\n        \"\"\"\n        if path not in self.top_level_links:\n            raise StateError(\"Unknown path\")\n\n        header = \"\"\"\n        <html>\n            <head>\n                <title>VPC-router state</title>\n            </head>\n            <body>\n                <h3>VPC-router state</h3>\n                <hr>\n                <font face=\"courier\">\n        \"\"\"\n\n        footer = \"\"\"\n                </font>\n            </body>\n        </html>\n        \"\"\"\n\n        rep = self.get_state_repr(path)\n\n        def make_links(rep):\n            # Recursively create clickable links for _href elements\n            for e, v in rep.items():\n                if e == \"_href\":\n                    v = '<a href=%s>%s</a>' % (v, v)\n                    rep[e] = v\n                else:\n                    if type(v) == dict:\n                        make_links(v)\n\n        make_links(rep)\n\n        rep_str_lines = json.dumps(rep, indent=4).split(\"\\n\")\n        buf = []\n        for l in rep_str_lines:\n            # Replace leading spaces with '&nbsp;'\n            num_spaces = len(l) - len(l.lstrip())\n            l = \"&nbsp;\" * num_spaces + l[num_spaces:]\n            buf.append(l)\n\n        return \"%s%s%s\" % (header, \"<br>\\n\".join(buf), footer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the exact value of ceil x and y.", "response": "def intdivceil(x, y):\n    \"\"\"\n    Returns the exact value of ceil(x // y).\n    No floating point calculations are used.\n    Requires positive integer types. The result\n    is undefined if at least one of the inputs\n    is floating point.\n    \"\"\"\n    result = x // y\n    if (x % y):\n        result += 1\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields n elements from a list of objects.", "response": "def chunkiter(objs, n=100):\n    \"\"\"\n    Chunk an iterator of unknown size. The optional\n    keyword 'n' sets the chunk size (default 100).\n    \"\"\"\n\n    objs = iter(objs)\n    try:\n        while (1):\n            chunk = []\n            while len(chunk) < n:\n                chunk.append(six.next(objs))\n            yield chunk\n    except StopIteration:\n        pass\n    if len(chunk):\n        yield chunk"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_app(self, app):\n        if app.config.MONGO_URIS and isinstance(app.config.MONGO_URIS, dict):\n            self.MONGO_URIS = app.config.MONGO_URIS\n            self.app = app\n\n        else:\n            raise ValueError(\n                \"nonstandard sanic config MONGO_URIS,MONGO_URIS must be a Dict[dbname,dburl]\")\n\n\n        @app.listener(\"before_server_start\")\n        async def init_mongo_connection(app, loop):\n            for dbname, dburl in app.config.MONGO_URIS.items():\n                if isinstance(dburl,str):\n                    db = MongoConnection(dburl,ioloop=loop).db\n                else:\n                    db = MongoConnection(ioloop=loop,**dburl).db\n                self.mongodbs[dbname] = db\n\n        @app.listener(\"before_server_stop\")\n        async def sub_close(app, loop):\n            log.info(\"mongo connection {numbr}\".format(numbr=len(self.mongodbs)))\n            for dbname,db in self.mongodbs.items():\n                db.client.close\n                log.info(\"{dbname} connection closed\".format(dbname=dbname))\n\n        if \"extensions\" not in app.__dir__():\n            app.extensions = {}\n        app.extensions['SanicMongo'] = self\n\n        app.mongo = self.mongodbs\n        return self", "response": "Initialize the application with the given app."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the config watch thread or process.", "response": "def start(self):\n        \"\"\"\n        Start the config watch thread or process.\n\n        \"\"\"\n        # Normally, we should start a thread or process here, pass the message\n        # queue self.q_route_spec to that thread and let it send route\n        # configurations through that queue. But since we're just sending a\n        # single, fixed configuration, we can just do that right here.\n        # Note that the q_route_spec queue was created by the __init__()\n        # function of the WatcherPlugin base class.\n        logging.info(\"Fixedconf watcher plugin: Started\")\n\n        # The configuration provided on the command line is available to every\n        # plugin. Here we are reading our own parameters.\n        cidr       = self.conf['fixed_cidr']\n        hosts      = self.conf['fixed_hosts'].split(\":\")\n        route_spec = {cidr : hosts}\n        try:\n            # Probably don't really have to parse the route spec (sanity check)\n            # one more time, since we already sanity checked the command line\n            # options.\n            common.parse_route_spec_config(route_spec)\n            self.q_route_spec.put(route_spec)\n        except Exception as e:\n            logging.warning(\"Fixedconf watcher plugin: \"\n                            \"Invalid route spec: %s\" % str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_arguments(cls, parser, sys_arg_list=None):\n        parser.add_argument('--fixed_cidr', dest=\"fixed_cidr\", required=True,\n                            help=\"specify the route CIDR \"\n                                 \"(only in fixedconf mode)\")\n        parser.add_argument('--fixed_hosts', dest=\"fixed_hosts\", required=True,\n                            help=\"list of host IPs, separated by ':' \"\n                                 \"(only in fixedconf mode)\")\n        return [\"fixed_cidr\", \"fixed_hosts\"]", "response": "Add command line options for this plugin to the argparse parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_arguments(cls, conf):\n        # Perform sanity checking on CIDR\n        utils.ip_check(conf['fixed_cidr'], netmask_expected=True)\n\n        # Perform sanity checking on host list\n        for host in conf['fixed_hosts'].split(\":\"):\n            utils.ip_check(host)", "response": "Callback to perform sanity checking on the specific\n        parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a new list of IPs that we can update from the queue. This returns None if there is no update.", "response": "def get_new_working_set(self):\n        \"\"\"\n        Get a new list of IPs to work with from the queue.\n\n        This returns None if there is no update.\n\n        Read all the messages from the queue on which we get the IP addresses\n        that we have to monitor. We will ignore all of them, except the last\n        one, since maybe we received two updates in a row, but each update\n        is a full state, so only the last one matters.\n\n        Raises the StopReceived exception if the stop signal (\"None\") was\n        received on the notification queue.\n\n        \"\"\"\n        new_list_of_ips = None\n        while True:\n            try:\n                new_list_of_ips = self.q_monitor_ips.get_nowait()\n                self.q_monitor_ips.task_done()\n                if type(new_list_of_ips) is MonitorPluginStopSignal:\n                    raise StopReceived()\n            except Queue.Empty:\n                # No more messages, all done reading monitor list for now\n                break\n        if new_list_of_ips is not None:\n            CURRENT_STATE.working_set = new_list_of_ips\n        return new_list_of_ips"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts monitoring the queue for failed IP addresses.", "response": "def start_monitoring(self):\n        \"\"\"\n        Monitor IP addresses and send notifications if one of them has failed.\n\n        This function will continuously monitor q_monitor_ips for new lists of\n        IP addresses to monitor. Each message received there is the full state\n        (the complete lists of addresses to monitor).\n\n        Push out (return) any failed IPs on q_failed_ips. This is also a list\n        of IPs, which may be empty if all instances work correctly.\n\n        If q_monitor_ips receives a 'None' instead of list then this is\n        intepreted as a stop signal and the function exits.\n\n        \"\"\"\n        time.sleep(1)\n\n        # This is our working set. This list may be updated occasionally when\n        # we receive messages on the q_monitor_ips queue. But irrespective of\n        # any received updates, the list of IPs in here is regularly checked.\n        list_of_ips                = []\n\n        currently_failed_ips       = set()\n        currently_questionable_ips = set()\n\n        # Accumulating failed IPs for 10 intervals before rechecking them to\n        # see if they are alive again\n        recheck_failed_interval = 10\n\n        try:\n            interval_count = 0\n            while not CURRENT_STATE._stop_all:\n                start_time = time.time()\n                # See if we should update our working set\n                new_ips = self.get_new_working_set()\n                if new_ips:\n                    list_of_ips = new_ips\n                    # Update the currently-failed-IP list to only include IPs\n                    # that are still in the spec. The list update may have\n                    # removed some of the historical, failed IPs altogether.\n                    currently_failed_ips = \\\n                            set([ip for ip in currently_failed_ips\n                                 if ip in list_of_ips])\n                    # Same for the questionable IPs\n                    currently_questionable_ips = \\\n                            set([ip for ip in currently_questionable_ips\n                                 if ip in list_of_ips])\n\n                # Don't check failed IPs for liveness on every interval. We\n                # keep a list of currently-failed IPs for that purpose.\n                # But we will check questionable IPs, so we don't exclude\n                # those.\n                live_ips_to_check = [ip for ip in list_of_ips if\n                                     ip not in currently_failed_ips]\n                logging.debug(\"Checking live IPs: %s\" %\n                              (\",\".join(live_ips_to_check)\n                               if live_ips_to_check else \"(none alive)\"))\n\n                # Independent of any updates: Perform health check on all IPs\n                # in the working set and send messages out about any failed\n                # ones as necessary.\n                if live_ips_to_check:\n                    failed_ips, questionable_ips = \\\n                                    self.do_health_checks(live_ips_to_check)\n                    if failed_ips:\n                        # Update list of currently failed IPs with any new ones\n                        currently_failed_ips.update(failed_ips)\n                        logging.info('Currently failed IPs: %s' %\n                                     \",\".join(currently_failed_ips))\n                        # Let the main loop know the full set of failed IPs\n                        self.q_failed_ips.put(list(currently_failed_ips))\n\n                    if questionable_ips:\n                        # Update list of currently questionable IPs with any\n                        # new ones\n                        currently_questionable_ips.update(failed_ips)\n                        logging.info('Currently questionable IPs: %s' %\n                                     \",\".join(currently_questionable_ips))\n                        # Let the main loop know the full set of questionable\n                        # IPs\n                        self.q_questionable_ips.put(\n                                            list(currently_questionable_ips))\n\n                if interval_count == recheck_failed_interval:\n                    # Ever now and then clean out our currently failed IP cache\n                    # so that we can recheck them to see if they are still\n                    # failed. We also clear out the questionable IPs, so that\n                    # they don't forever accumulate.\n                    interval_count             = 0\n                    currently_failed_ips       = set()\n                    currently_questionable_ips = set()\n\n                # Wait until next monitoring interval: We deduct the time we\n                # spent in this loop.\n                end_time = time.time()\n                time.sleep(self.get_monitor_interval() -\n                           (end_time - start_time))\n                interval_count += 1\n\n            logging.debug(\"Monitoring loop ended: Global stop\")\n\n        except StopReceived:\n            # Received the stop signal, just exiting the thread function\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_route_spec_config(data):\n    # Sanity checking on the data object\n    if type(data) is not dict:\n        raise ValueError(\"Expected dictionary at top level\")\n    try:\n        for k, v in data.items():\n            utils.ip_check(k, netmask_expected=True)\n            if type(v) is not list:\n                raise ValueError(\"Expect list of IPs as values in dict\")\n            hosts = set(v)   # remove duplicates\n            for ip in hosts:\n                utils.ip_check(ip)\n            clean_host_list = sorted(list(hosts))\n            data[k] = clean_host_list\n\n    except ArgsError as e:\n        raise ValueError(e.message)\n\n    return data", "response": "Parse and sanity check the route spec config."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the health monitor thread with a new list of IP addresses.", "response": "def _update_health_monitor_with_new_ips(route_spec, all_ips,\n                                        q_monitor_ips):\n    \"\"\"\n    Take the current route spec and compare to the current list of known IP\n    addresses. If the route spec mentiones a different set of IPs, update the\n    monitoring thread with that new list.\n\n    Return the current set of IPs mentioned in the route spec.\n\n    \"\"\"\n    # Extract all the IP addresses from the route spec, unique and sorted.\n    new_all_ips = \\\n        sorted(set(itertools.chain.from_iterable(route_spec.values())))\n    if new_all_ips != all_ips:\n        logging.debug(\"New route spec detected. Updating \"\n                      \"health-monitor with: %s\" %\n                      \",\".join(new_all_ips))\n        # Looks like we have a new list of IPs\n        all_ips = new_all_ips\n        q_monitor_ips.put(all_ips)\n    else:\n        logging.debug(\"New route spec detected. No changes in \"\n                      \"IP address list, not sending update to \"\n                      \"health-monitor.\")\n\n    return all_ips"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _event_monitor_loop(region_name, vpc_id,\n                        watcher_plugin, health_plugin,\n                        iterations, sleep_time,\n                        route_check_time_interval=30):\n    \"\"\"\n    Monitor queues to receive updates about new route specs or any detected\n    failed IPs.\n\n    If any of those have updates, notify the health-monitor thread with a\n    message on a special queue and also re-process the entire routing table.\n\n    The 'iterations' argument allows us to limit the running time of the watch\n    loop for test purposes. Not used during normal operation. Also, for faster\n    tests, sleep_time can be set to values less than 1.\n\n    The 'route_check_time_interval' arguments specifies the number of seconds\n    we allow to elapse before forcing a re-check of the VPC routes. This is so\n    that accidentally deleted routes or manually broken route tables can be\n    fixed back up again on their own.\n\n    \"\"\"\n    q_route_spec = watcher_plugin.get_route_spec_queue()\n    q_monitor_ips, q_failed_ips, q_questionable_ips = \\\n                                                health_plugin.get_queues()\n    time.sleep(sleep_time)   # Wait to allow monitor to report results\n\n    current_route_spec = {}  # The last route spec we have seen\n    all_ips = []             # Cache of IP addresses we currently know about\n\n    # Occasionally we want to recheck VPC routes even without other updates.\n    # That way, if a route is manually deleted by someone, it will be\n    # re-created on its own.\n    last_route_check_time    = time.time()\n    while not CURRENT_STATE._stop_all:\n        try:\n            # Get the latest messages from the route-spec monitor and the\n            # health-check monitor. At system start the route-spec queue should\n            # immediately have been initialized with a first message.\n            failed_ips     = utils.read_last_msg_from_queue(q_failed_ips)\n            questnbl_ips   = utils.read_last_msg_from_queue(q_questionable_ips)\n            new_route_spec = utils.read_last_msg_from_queue(q_route_spec)\n\n            if failed_ips:\n                # Store the failed IPs in the shared state\n                CURRENT_STATE.failed_ips = failed_ips\n\n            if questnbl_ips:\n                # Store the questionable IPs in the shared state\n                CURRENT_STATE.questionble_ips = questnbl_ips\n\n            if new_route_spec:\n                # Store the new route spec in the shared state\n                CURRENT_STATE.route_spec = new_route_spec\n                current_route_spec = new_route_spec\n                # Need to communicate a new set of IPs to the health\n                # monitoring thread, in case the list changed. The list of\n                # addresses is extracted from the route spec. Pass in the old\n                # version of the address list, so that this function can\n                # compare to see if there are any changes to the host list.\n                all_ips = _update_health_monitor_with_new_ips(new_route_spec,\n                                                              all_ips,\n                                                              q_monitor_ips)\n\n            # Spec or list of failed or questionable IPs changed? Update\n            # routes...\n            # We pass in the last route spec we have seen, since we are also\n            # here in case we only have failed/questionable IPs, but no new\n            # route spec. This is also called occasionally on its own, so that\n            # we can repair any damaged route tables in VPC.\n            now = time.time()\n            time_for_regular_recheck = \\\n                    (now - last_route_check_time) > route_check_time_interval\n\n            if new_route_spec or failed_ips or questnbl_ips or \\\n                                                time_for_regular_recheck:\n                if not new_route_spec and not (failed_ips or questnbl_ips):\n                    # Only reason we are here is due to expired timer.\n                    logging.debug(\"Time for regular route check\")\n\n                last_route_check_time = now\n                vpc.handle_spec(region_name, vpc_id, current_route_spec,\n                                failed_ips if failed_ips else [],\n                                questnbl_ips if questnbl_ips else [])\n\n            # If iterations are provided, count down and exit\n            if iterations is not None:\n                iterations -= 1\n                if iterations == 0:\n                    break\n\n            time.sleep(sleep_time)\n        except KeyboardInterrupt:\n            # Allow exit via keyboard interrupt, useful during development\n            return\n        except Exception as e:\n            # Of course we should never get here, but if we do, better to log\n            # it and keep operating best we can...\n            import traceback\n            traceback.print_exc()\n            logging.error(\"*** Uncaught exception 1: %s\" % str(e))\n            return\n\n    logging.debug(\"event_monitor_loop ended: Global stop\")", "response": "Monitor queues to receive new route specs and check if they have changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_plugins(conf, watcher_plugin_class, health_plugin_class,\n                  sleep_time):\n    \"\"\"\n    Start the working threads:\n\n    - Health monitor (the health plugin)\n    - Config change monitor (the watcher plugin)\n\n    \"\"\"\n    # No matter what the chosen plugin to watch for config updates: We get a\n    # plugin-handle back. This gives us a start(), stop() and\n    # get_route_spec_queue() function. All watcher plugins provide the same\n    # interface.\n    watcher_plugin = watcher_plugin_class(conf)\n    watcher_plugin.start()\n\n    # Similarly for the health-monitor-plugin. It gives us a get_queues()\n    # function, to get the monitor-ips and failed-ips queues.\n    health_plugin = health_plugin_class(conf)\n    health_plugin.start()\n\n    return watcher_plugin, health_plugin", "response": "Start the working threads:\n\n    - Health monitor (the health plugin)\n    - Config change monitor (the watcher plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_watcher(conf, watcher_plugin_class, health_plugin_class,\n                  iterations=None, sleep_time=1):\n    \"\"\"\n    Start watcher loop, listening for config changes or failed hosts.\n\n    Also starts the various service threads.\n\n    VPC router watches for any changes in the config and updates/adds/deletes\n    routes as necessary. If failed hosts are reported, routes are also updated\n    as needed.\n\n    This function starts a few working threads:\n\n    - The watcher plugin to monitor for updated route specs.\n    - A health monitor plugin for instances mentioned in the route spec.\n\n    It then drops into a loop to receive messages from the health monitoring\n    thread and watcher plugin and re-process the config if any failed IPs are\n    reported.\n\n    The loop itself is in its own function to facilitate easier testing.\n\n    \"\"\"\n    if CURRENT_STATE._stop_all:\n        logging.debug(\"Not starting plugins: Global stop\")\n        return\n\n    # Start the working threads (health monitor, config event monitor, etc.)\n    # and return the thread handles and message queues in a thread-info dict.\n    watcher_plugin, health_plugin = \\\n            start_plugins(conf, watcher_plugin_class, health_plugin_class,\n                          sleep_time)\n    CURRENT_STATE.add_plugin(watcher_plugin)\n    CURRENT_STATE.add_plugin(health_plugin)\n\n    # Start the loop to process messages from the monitoring\n    # threads about any failed IP addresses or updated route specs.\n    _event_monitor_loop(conf['region_name'], conf['vpc_id'],\n                        watcher_plugin, health_plugin,\n                        iterations, sleep_time, conf['route_recheck_interval'])\n\n    # Stopping plugins and collecting all worker threads when we are done\n    stop_plugins(watcher_plugin, health_plugin)", "response": "Start the watcher loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the header for the Markdown file.", "response": "def build_header(self, title):\n        \"\"\"Generate the header for the Markdown file.\"\"\"\n        header = ['---',\n                  'title: ' + title,\n                  'author(s): ' + self.user,\n                  'tags: ',\n                  'created_at: ' + str(self.date_created),\n                  'updated_at: ' + str(self.date_updated),\n                  'tldr: ',\n                  'thumbnail: ',\n                  '---']\n\n        self.out = header + self.out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_code(self, lang, body):\n        self.out.append(\"```\" + lang)\n        self.build_markdown(lang, body)\n        self.out.append(\"```\")", "response": "Wrap text with markdown specific flavour."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_input(self, paragraph):\n        try:\n            lang, body = paragraph.split(None, 1)\n        except ValueError:\n            lang, body = paragraph, None\n\n        if not lang.strip().startswith('%'):\n            lang = 'scala'\n            body = paragraph.strip()\n\n        else:\n            lang = lang.strip()[1:]\n\n        if lang == 'md':\n            self.build_markdown(lang, body)\n        else:\n            self.build_code(lang, body)", "response": "Parse the input paragraph for the language of the code and the code itself."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_md_row(self, row, header=False):\n        if not row:\n            return\n        cols = row.split('\\t')\n        if len(cols) == 1:\n            self.out.append(cols[0])\n        else:\n            col_md = '|'\n            underline_md = '|'\n\n            if cols:\n                for col in cols:\n                    col_md += col + '|'\n                    underline_md += '-|'\n\n            if header:\n                self.out.append(col_md + '\\n' + underline_md)\n            else:\n                self.out.append(col_md)", "response": "Translate row into markdown format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_date_created(self, text):\n        date = parse(text)\n        if self.date_created == 'N/A':\n            self.date_created = date\n        if date < self.date_created:\n            self.date_created = date", "response": "Process the date created text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the date updated text.", "response": "def process_date_updated(self, text):\n        \"\"\"Set date_updated to the most recent date (updated date).\"\"\"\n        date = parse(text)\n        if self.date_updated == 'N/A':\n            self.date_updated = date\n        if date > self.date_updated:\n            self.date_updated = date"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsquash self. out into string and write the result to fout.", "response": "def build_output(self, fout):\n        \"\"\"Squash self.out into string.\n\n        Join every line in self.out with a new line and write the\n        result to the output file.\n        \"\"\"\n        fout.write('\\n'.join([s for s in self.out]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a. json file to markdown format", "response": "def convert(self, json, fout):\n        \"\"\"Convert json to markdown.\n\n        Takes in a .json file as input and convert it to Markdown format,\n        saving the generated .png images into ./images.\n        \"\"\"\n        self.build_markdown_body(json)  # create the body\n        self.build_header(json['name'])  # create the md header\n        self.build_output(fout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_markdown_body(self, text):\n        key_options = {\n            'dateCreated': self.process_date_created,\n            'dateUpdated': self.process_date_updated,\n            'title': self.process_title,\n            'text': self.process_input\n        }\n\n        for paragraph in text['paragraphs']:\n            if 'user' in paragraph:\n                self.user = paragraph['user']\n\n            for key, handler in key_options.items():\n                if key in paragraph:\n                    handler(paragraph[key])\n\n            if self._RESULT_KEY in paragraph:\n                self.process_results(paragraph)", "response": "Generates the markdown body for the notebook."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_table(self, msg):\n        rows = msg.split('\\n')\n        if rows:\n            header_row, *body_rows = rows\n            self.create_md_row(header_row, True)\n            for row in body_rows:\n                self.create_md_row(row)", "response": "Format each row of the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_image(self, msg):\n        result = self.find_message(msg)\n\n        if result is None:\n            return\n\n        self.index += 1\n        images_path = 'images'\n\n        if self.directory:\n            images_path = os.path.join(self.directory, images_path)\n\n        if not os.path.isdir(images_path):\n            os.makedirs(images_path)\n\n        with open('{0}/output_{1}.png'.format(images_path, self.index), 'wb') as fh:\n            self.write_image_to_disk(msg, result, fh)\n\n        self.out.append(\n            '\\n![png]({0}/output_{1}.png)\\n'.format(images_path, self.index))", "response": "Convert base64 encoding to png."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_image_to_disk(self, msg, result, fh):\n        cairosvg.svg2png(bytestring=msg.encode('utf-8'), write_to=fh)", "response": "Decode message to PNG and write to disk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrouting Zeppelin output types to corresponding handlers.", "response": "def process_results(self, paragraph):\n        \"\"\"Route Zeppelin output types to corresponding handlers.\"\"\"\n        if 'result' in paragraph and paragraph['result']['msg']:\n            msg = paragraph['result']['msg']\n            self.output_options[paragraph['result']['type']](msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode message to PNG and write to disk.", "response": "def write_image_to_disk(self, msg, result, fh):\n        \"\"\"Decode message to PNG and write to disk.\"\"\"\n        fh.write(base64.b64decode(result.group(1).encode('utf-8')))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrouting Zeppelin output types to corresponding handlers.", "response": "def process_results(self, paragraph):\n        \"\"\"Routes Zeppelin output types to corresponding handlers.\"\"\"\n        if 'editorMode' in paragraph['config']:\n            mode = paragraph['config']['editorMode'].split('/')[-1]\n            if 'results' in paragraph and paragraph['results']['msg']:\n                msg = paragraph['results']['msg'][0]\n                if mode not in ('text', 'markdown'):\n                    self.output_options[msg['type']](msg['data'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_route_spec_request():\n    try:\n        if bottle.request.method == 'GET':\n            # Just return what we currenty have cached as the route spec\n            data = CURRENT_STATE.route_spec\n            if not data:\n                bottle.response.status = 404\n                msg = \"Route spec not found!\"\n            else:\n                bottle.response.status = 200\n                msg = json.dumps(data)\n        else:\n            # A new route spec is posted\n            raw_data = bottle.request.body.read()\n            new_route_spec = json.loads(raw_data)\n            logging.info(\"New route spec posted\")\n            common.parse_route_spec_config(new_route_spec)\n            _Q_ROUTE_SPEC.put(new_route_spec)\n            bottle.response.status = 200\n            msg = \"Ok\"\n\n    except ValueError as e:\n        logging.error(\"Config ignored: %s\" % str(e))\n        bottle.response.status = 400\n        msg = \"Config ignored: %s\" % str(e)\n\n    except Exception as e:\n        logging.error(\"Exception while processing HTTP request: %s\" % str(e))\n        bottle.response.status = 500\n        msg = \"Internal server error\"\n\n    bottle.response.content_type = 'application/json'\n\n    return msg", "response": "Process request for route spec."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self):\n        # Store reference to message queue in module global variable, so that\n        # our Bottle app handler functions have easy access to it.\n        global _Q_ROUTE_SPEC\n        _Q_ROUTE_SPEC = self.q_route_spec\n\n        logging.info(\"Http watcher plugin: \"\n                     \"Starting to watch for route spec on \"\n                     \"'%s:%s/route_spec'...\" %\n                     (self.conf['addr'], self.conf['port']))", "response": "Start the HTTP change monitoring thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning decorated function that caches the results.", "response": "def cache_results(function):\n    \"\"\"Return decorated function that caches the results.\"\"\"\n    def save_to_permacache():\n        \"\"\"Save the in-memory cache data to the permacache.\n\n        There is a race condition here between two processes updating at the\n        same time. It's perfectly acceptable to lose and/or corrupt the\n        permacache information as each process's in-memory cache will remain\n        in-tact.\n\n        \"\"\"\n        update_from_permacache()\n        try:\n            with open(filename, 'wb') as fp:\n                pickle.dump(cache, fp, pickle.HIGHEST_PROTOCOL)\n        except IOError:\n            pass  # Ignore permacache saving exceptions\n\n    def update_from_permacache():\n        \"\"\"Attempt to update newer items from the permacache.\"\"\"\n        try:\n            with open(filename, 'rb') as fp:\n                permacache = pickle.load(fp)\n        except Exception:  # TODO: Handle specific exceptions\n            return  # It's okay if it cannot load\n        for key, value in permacache.items():\n            if key not in cache or value[0] > cache[key][0]:\n                cache[key] = value\n\n    cache = {}\n    cache_expire_time = 3600\n    try:\n        filename = os.path.join(gettempdir(), 'update_checker_cache.pkl')\n        update_from_permacache()\n    except NotImplementedError:\n        filename = None\n\n    @wraps(function)\n    def wrapped(obj, package_name, package_version, **extra_data):\n        \"\"\"Return cached results if available.\"\"\"\n        now = time.time()\n        key = (package_name, package_version)\n        if not obj.bypass_cache and key in cache:  # Check the in-memory cache\n            cache_time, retval = cache[key]\n            if now - cache_time < cache_expire_time:\n                return retval\n        retval = function(obj, package_name, package_version, **extra_data)\n        cache[key] = now, retval\n        if filename:\n            save_to_permacache()\n        return retval\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to return a human - readable time delta string.", "response": "def pretty_date(the_datetime):\n    \"\"\"Attempt to return a human-readable time delta string.\"\"\"\n    # Source modified from\n    # http://stackoverflow.com/a/5164027/176978\n    diff = datetime.utcnow() - the_datetime\n    if diff.days > 7 or diff.days < 0:\n        return the_datetime.strftime('%A %B %d, %Y')\n    elif diff.days == 1:\n        return '1 day ago'\n    elif diff.days > 1:\n        return '{0} days ago'.format(diff.days)\n    elif diff.seconds <= 1:\n        return 'just now'\n    elif diff.seconds < 60:\n        return '{0} seconds ago'.format(diff.seconds)\n    elif diff.seconds < 120:\n        return '1 minute ago'\n    elif diff.seconds < 3600:\n        return '{0} minutes ago'.format(int(round(diff.seconds / 60)))\n    elif diff.seconds < 7200:\n        return '1 hour ago'\n    else:\n        return '{0} hours ago'.format(int(round(diff.seconds / 3600)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if there is a newer version of the package.", "response": "def check(self, package_name, package_version, **extra_data):\n        \"\"\"Return a UpdateResult object if there is a newer version.\"\"\"\n        data = extra_data\n        data['package_name'] = package_name\n        data['package_version'] = package_version\n        data['python_version'] = sys.version.split()[0]\n        data['platform'] = platform.platform(True) or 'Unspecified'\n\n        try:\n            headers = {'connection': 'close',\n                       'content-type': 'application/json'}\n            response = requests.put(self.url, json.dumps(data), timeout=1,\n                                    headers=headers)\n            if response.status_code == codes.UNPROCESSABLE_ENTITY:\n                return 'update_checker does not support {!r}'.format(\n                    package_name)\n            data = response.json()\n        except (requests.exceptions.RequestException, ValueError):\n            return None\n\n        if not data or not data.get('success') \\\n                or (parse_version(package_version) >=\n                    parse_version(data['data']['version'])):\n            return None\n\n        return UpdateResult(package_name, running=package_version,\n                            available=data['data']['version'],\n                            release_date=data['data']['upload_time'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addMonitor(self, monitorFriendlyName, monitorURL):\n        url = self.baseUrl\n        url += \"newMonitor?apiKey=%s\" % self.apiKey\n        url += \"&monitorFriendlyName=%s\" % monitorFriendlyName\n        url += \"&monitorURL=%s&monitorType=1\" % monitorURL\n        url += \"&monitorAlertContacts=%s\" % monitorAlertContacts\n        url += \"&noJsonCallback=1&format=json\"\n        success, response = self.requestApi(url)\n        if success:\n            return True\n        else:\n            return False", "response": "Adds a Monitor to the cache. Returns True if Monitor was added otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getMonitors(self, response_times=0, logs=0, uptime_ratio=''):\n        url = self.baseUrl\n        url += \"getMonitors?apiKey=%s\" % (self.apiKey)\n        url += \"&noJsonCallback=1&format=json\"\n        # responseTimes - optional (defines if the response time data of each\n        # monitor will be returned. Should be set to 1 for getting them. Default\n        # is 0)\n        if response_times:\n            url += \"&responseTimes=1\"\n        # logs - optional (defines if the logs of each monitor will be returned.\n        # Should be set to 1 for getting the logs. Default is 0)\n        if logs:\n            url += '&logs=1'\n        # customUptimeRatio - optional (defines the number of days to calculate\n        # the uptime ratio(s) for. Ex: customUptimeRatio=7-30-45 to get the\n        # uptime ratios for those periods)\n        if uptime_ratio:\n            url += '&customUptimeRatio=%s' % uptime_ratio\n\n        return self.requestApi(url)", "response": "Get all known monitors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getMonitorById(self, monitorId):\n        url = self.baseUrl\n        url += \"getMonitors?apiKey=%s&monitors=%s\" % (self.apiKey, monitorId)\n        url += \"&noJsonCallback=1&format=json\"\n        success, response = self.requestApi(url)\n        if success:\n            status = response.get('monitors').get('monitor')[0].get('status')\n            alltimeuptimeratio = response.get('monitors').get('monitor')[0].get('alltimeuptimeratio')\n            return status, alltimeuptimeratio\n        return None, None", "response": "Returns monitor status and alltimeuptimeratio for a MonitorId."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getMonitorByName(self, monitorFriendlyName):\n        url = self.baseUrl\n        url += \"getMonitors?apiKey=%s\" % self.apiKey\n        url += \"&noJsonCallback=1&format=json\"\n        success, response = self.requestApi(url)\n        if success:\n            monitors = response.get('monitors').get('monitor')\n            for i in range(len(monitors)):\n                monitor = monitors[i]\n                if monitor.get('friendlyname') == monitorFriendlyName:\n                    status = monitor.get('status')\n                    alltimeuptimeratio = monitor.get('alltimeuptimeratio')\n                    return status, alltimeuptimeratio\n        return None, None", "response": "Returns monitor status and alltimeuptimeratio for a MonitorFriendlyName."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef editMonitor(self, monitorID, monitorStatus=None, monitorFriendlyName=None, monitorURL=None, monitorType=None,\n                    monitorSubType=None, monitorPort=None, monitorKeywordType=None, monitorKeywordValue=None,\n                    monitorHTTPUsername=None, monitorHTTPPassword=None, monitorAlertContacts=None):\n        \"\"\"\n        monitorID is the only required object. All others are optional and must be quoted.\n        Returns Response object from api.\n        \"\"\"\n\n        url = self.baseUrl\n        url += \"editMonitor?apiKey=%s\" % self.apiKey\n        url += \"&monitorID=%s\" % monitorID\n        if monitorStatus:\n            # Pause, Start Montir\n            url += \"&monitorStatus=%s\" % monitorStatus\n        if monitorFriendlyName:\n            # Update their FriendlyName\n            url += \"&monitorFriendlyName=%s\" % monitorFriendlyName\n        if monitorURL:\n            # Edit the MontiorUrl\n            url += \"&monitorURL=%s\" % monitorURL\n        if monitorType:\n            # Edit the type of montior\n            url += \"&monitorType=%s\" % monitorType\n        if monitorSubType:\n            # Edit the SubType\n            url += \"&monitorSubType=%s\" % monitorSubType\n        if monitorPort:\n            # Edit the Port\n            url += \"&monitorPort=%s\" % monitorPort\n        if monitorKeywordType:\n            # Edit the Keyword Type\n            url += \"&monitorKeywordType=%s\" % monitorKeywordType\n        if monitorKeywordValue:\n            # Edit the Keyword Match\n            url += \"&monitorKeywordValue=%s\" % monitorKeywordValue\n        if monitorHTTPUsername:\n            # Edit the HTTP Username\n            url += \"&monitorHTTPUsername=%s\" % monitorHTTPUsername\n        if monitorHTTPPassword:\n            # Edit the HTTP Password\n            url += \"&monitorHTTPPassword=%s\" % monitorHTTPPassword\n        if monitorAlertContacts:\n            # Edit the contacts\n            url += \"&monitorAlertContacts=%s\" % monitorAlertContacts\n        url += \"&noJsonCallback=1&format=json\"\n        success = self.requestApi(url)\n        return success", "response": "Edit the monitor state of a specific entry in the current state of the current state of the current state of the monitor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a monitor by ID. Returns True or False if monitor is deleted otherwise returns False.", "response": "def deleteMonitorById(self, monitorID):\n        \"\"\"\n        Returns True or False if monitor is deleted\n        \"\"\"\n        url = self.baseUrl\n        url += \"deleteMonitor?apiKey=%s\" % self.apiKey\n        url += \"&monitorID=%s\" % monitorID\n        url += \"&noJsonCallback=1&format=json\"\n        success, response = self.requestApi(url)\n        if success:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets alert contacts from the API.", "response": "def getAlertContacts(self, alertContacts=None, offset=None, limit=None):\n            \"\"\"\n            Get Alert Contacts\n            \"\"\"\n            url = self.baseUrl\n            url += \"getAlertContacts?apiKey=%s\" % self.apiKey\n            if alertContacts:\n                url += \"&alertContacts=%s\" % alertContacts\n            if offset:\n                url += \"&offset=%s\" % offset\n            if limit:\n                url += \"&limit=%s\" % limit\n            url += \"&format=json\"\n            return self.requestApi(url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromfile(file_,\n                 threadpool_size=None,\n                 ignore_lock=False):\n        \"\"\"\n        Instantiate BlockStorageRAM device from a file saved in block\n        storage format. The file_ argument can be a file object or a\n        string that represents a filename. If called with a file\n        object, it should be opened in binary mode, and the caller is\n        responsible for closing the file.\n\n        This method returns a BlockStorageRAM instance.\n        \"\"\"\n        close_file = False\n        if not hasattr(file_, 'read'):\n            file_ = open(file_, 'rb')\n            close_file = True\n        try:\n            header_data = file_.read(BlockStorageRAM._index_offset)\n            block_size, block_count, user_header_size, locked = \\\n                struct.unpack(\n                    BlockStorageRAM._index_struct_string,\n                    header_data)\n            if locked and (not ignore_lock):\n                raise IOError(\n                    \"Can not open block storage device because it is \"\n                    \"locked by another process. To ignore this check, \"\n                    \"call this method with the keyword 'ignore_lock' \"\n                    \"set to True.\")\n            header_offset = len(header_data) + \\\n                            user_header_size\n            f = bytearray(header_offset + \\\n                          (block_size * block_count))\n            f[:header_offset] = header_data + file_.read(user_header_size)\n            f[header_offset:] = file_.read(block_size * block_count)\n        finally:\n            if close_file:\n                file_.close()\n\n        return BlockStorageRAM(f,\n                               threadpool_size=threadpool_size,\n                               ignore_lock=ignore_lock)", "response": "Instantiate a new BlockStorageRAM object from a file object or a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tofile(self, file_):\n        close_file = False\n        if not hasattr(file_, 'write'):\n            file_ = open(file_, 'wb')\n            close_file = True\n        file_.write(self._f)\n        if close_file:\n            file_.close()", "response": "Dump all storage data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a bottle request so that a log line is emitted after it s handled.", "response": "def log_to_logger(fn):\n    \"\"\"\n    Wrap a Bottle request so that a log line is emitted after it's handled.\n\n    \"\"\"\n    @wraps(fn)\n    def _log_to_logger(*args, **kwargs):\n        actual_response = fn(*args, **kwargs)\n        # modify this to log exactly what you need:\n        logger.info('%s %s %s %s' % (bottle.request.remote_addr,\n                                     bottle.request.method,\n                                     bottle.request.url,\n                                     bottle.response.status))\n        return actual_response\n    return _log_to_logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_request(path):\n    accept = bottle.request.get_header(\"accept\", default=\"text/plain\")\n\n    bottle.response.status = 200\n\n    try:\n        if \"text/html\" in accept:\n            ret = CURRENT_STATE.as_html(path=path)\n            bottle.response.content_type = \"text/html\"\n\n        elif \"application/json\" in accept:\n            ret = CURRENT_STATE.as_json(path=path)\n            bottle.response.content_type = \"application/json\"\n\n        elif \"text/\" in accept or \"*/*\" in accept:\n            ret = CURRENT_STATE.as_json(path=path, with_indent=True)\n            bottle.response.content_type = \"text/plain\"\n\n        else:\n            bottle.response.status = 407\n            ret = \"Cannot render data in acceptable content type\"\n    except StateError:\n        bottle.response.status = 404\n        ret = \"Requested state component not found\"\n\n    return ret", "response": "Return the current status of the state component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        logging.info(\"HTTP server: \"\n                     \"Starting to listen for requests on '%s:%s'...\" %\n                     (self.conf['addr'], self.conf['port']))\n\n        self.my_server = MyWSGIRefServer(host=self.conf['addr'],\n                                         port=self.conf['port'],\n                                         romana_http=self)\n\n        self.http_thread = threading.Thread(\n                    target = APP.run,\n                    name   = \"HTTP\",\n                    kwargs = {\"quiet\" : True, \"server\" : self.my_server})\n\n        self.http_thread.daemon = True\n        self.http_thread.start()\n        time.sleep(1)\n        if not self.wsgi_server_started:\n            # Set the global flag indicating that everything should stop\n            CURRENT_STATE._stop_all = True", "response": "Start the HTTP server thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop the HTTP server thread.", "response": "def stop(self):\n        \"\"\"\n        Stop the HTTP server thread.\n\n        \"\"\"\n        self.my_server.stop()\n        self.http_thread.join()\n        logging.info(\"HTTP server: Stopped\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_stats(self, responses, no_responses):\n        slowest_rtt = 0.0\n        slowest_ip  = None\n        fastest_rtt = 9999999.9\n        fastest_ip  = None\n        rtt_total   = 0.0\n\n        for ip, rtt in responses.items():\n            rtt_total += rtt\n            if rtt > slowest_rtt:\n                slowest_rtt = rtt\n                slowest_ip  = ip\n            elif rtt < fastest_rtt:\n                fastest_rtt = rtt\n                fastest_ip  = ip\n\n        sorted_rtts = sorted(responses.values())\n        l           = len(sorted_rtts)\n        if l == 0:\n            median_rtt = 0.0\n        elif l % 2 == 1:\n            # Odd number: Median is the middle element\n            median_rtt = sorted_rtts[int(l / 2)]\n        else:\n            # Even number (average between two middle elements)\n            median_rtt = (sorted_rtts[int(l / 2) - 1] +\n                          sorted_rtts[int(l / 2)]) / 2.0\n\n        now = datetime.datetime.now().isoformat()\n        m = {\n            \"time\" : now,\n            \"num_responses\" : len(responses),\n            \"num_no_responses\" : len(no_responses),\n            \"slowest\" : {\n                \"ip\"  : slowest_ip,\n                \"rtt\" : slowest_rtt\n            },\n            \"fastest\" : {\n                \"ip\"  : fastest_ip,\n                \"rtt\" : fastest_rtt\n            },\n            \"average_rtt\" : rtt_total / len(responses),\n            \"median_rtt\" : median_rtt\n        }\n\n        self.measurements.insert(0, m)\n        self.measurements = self.measurements[:self.max_num_measurements]", "response": "Update the stats of the current log entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_health_checks(self, list_of_ips):\n        # Calculate a decent overall timeout time for a ping attempt: 3/4th of\n        # the monitoring interval. That way, we know we're done with this ping\n        # attempt before the next monitoring attempt is started.\n        ping_timeout = self.get_monitor_interval() * 0.75\n\n        # Calculate a decent number of retries. For very short intervals we\n        # shouldn't have any retries, for very long ones, we should have\n        # several ones. Converting the timeout to an integer gives us what we\n        # want: For timeouts less than 1 we have no retry at all.\n        num_retries = int(ping_timeout)\n\n        try:\n            self.ping_count += len(list_of_ips)\n            responses, no_responses = multiping.multi_ping(\n                                        list_of_ips, ping_timeout, num_retries)\n            self.update_stats(responses, no_responses)\n\n        except Exception as e:\n            logging.error(\"Exception while trying to monitor servers: %s\" %\n                          str(e))\n            # Need to assume all IPs failed\n            no_responses = list_of_ips\n\n        return no_responses, []", "response": "Perform a health check on a list of IP addresses using ICMPecho."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self):\n        super(Icmpecho, self).stop()\n        self.monitor_thread.join()\n        logging.info(\"ICMPecho health monitor plugin: Stopped\")", "response": "Stop the monitoring thread of the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds command line arguments for the ICMPecho health monitor plugin.", "response": "def add_arguments(cls, parser, sys_arg_list=None):\n        \"\"\"\n        Arguments for the ICMPecho health monitor plugin.\n\n        \"\"\"\n        parser.add_argument('--icmp_check_interval',\n                            dest='icmp_check_interval',\n                            required=False, default=2, type=float,\n                            help=\"ICMPecho interval in seconds, default 2 \"\n                                 \"(only for 'icmpecho' health monitor plugin)\")\n        return [\"icmp_check_interval\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ip_check(ip, netmask_expected=False):\n    try:\n        if netmask_expected:\n            if \"/\" not in ip:\n                raise netaddr.core.AddrFormatError()\n            netaddr.IPNetwork(ip)\n        else:\n            netaddr.IPAddress(ip)\n    except netaddr.core.AddrFormatError:\n        if netmask_expected:\n            raise ArgsError(\"Not a valid CIDR (%s)\" % ip)\n        else:\n            raise ArgsError(\"Not a valid IP address (%s)\" % ip)\n    except Exception as e:\n        raise ArgsError(\"Invalid format: %s\" % str(e))", "response": "Check that the specified string is indeed an IP address or mask."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the value is a valid IP address or a valid CIDR.", "response": "def check_valid_ip_or_cidr(val, return_as_cidr=False):\n    \"\"\"\n    Checks that the value is a valid IP address or a valid CIDR.\n\n    Returns the specified value.\n\n    If 'return_as_cidr' is set then the return value will always be in the form\n    of a CIDR, even if a plain IP address was specified.\n\n    \"\"\"\n    is_ip = True\n    if \"/\" in val:\n        ip_check(val, netmask_expected=True)\n        is_ip = False\n    else:\n        ip_check(val, netmask_expected=False)\n\n    if return_as_cidr and is_ip:\n        # Convert a plain IP to a CIDR\n        if val == \"0.0.0.0\":\n            # Special case for the default route\n            val = \"0.0.0.0/0\"\n        else:\n            val = \"%s/32\" % val\n\n    try:\n        ipaddress.IPv4Network(unicode(val))\n    except Exception as e:\n        raise ArgsError(\"Not a valid network: %s\" % str(e))\n\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_cidr_in_cidr(small_cidr, big_cidr):\n    # The default route (0.0.0.0/0) is handled differently, since every route\n    # would always be contained in there. Instead, only a small CIDR of\n    # \"0.0.0.0/0\" can match against it. Other small CIDRs will always result in\n    # 'False' (not contained).\n    if small_cidr == \"0.0.0.0/0\":\n        return big_cidr == \"0.0.0.0/0\"\n    else:\n        if big_cidr == \"0.0.0.0/0\":\n            return False\n\n    s = ipaddress.IPv4Network(unicode(small_cidr))\n    b = ipaddress.IPv4Network(unicode(big_cidr))\n    return s.subnet_of(b)", "response": "Return True if the small CIDR is contained in the big CIDR."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the last message from a queue and returns it.", "response": "def read_last_msg_from_queue(q):\n    \"\"\"\n    Read all messages from a queue and return the last one.\n\n    This is useful in many cases where all messages are always the complete\n    state of things. Therefore, intermittent messages can be ignored.\n\n    Doesn't block, returns None if there is no message waiting in the queue.\n\n    \"\"\"\n    msg = None\n    while True:\n        try:\n            # The list of IPs is always a full list.\n            msg = q.get_nowait()\n            q.task_done()\n        except Queue.Empty:\n            # No more messages, all done for now\n            return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef base10_integer_to_basek_string(k, x):\n    if not (2 <= k <= max_k_labeled):\n        raise ValueError(\"k must be in range [2, %d]: %s\"\n                         % (max_k_labeled, k))\n    return ((x == 0) and numerals[0]) or \\\n        (base10_integer_to_basek_string(k, x // k).\\\n         lstrip(numerals[0]) + numerals[x % k])", "response": "Convert an integer into a base k string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef basek_string_to_base10_integer(k, x):\n    assert 1 < k <= max_k_labeled\n    return sum(numeral_index[c]*(k**i)\n               for i, c in enumerate(reversed(x)))", "response": "Convert a base k string into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_bucket_level(k, b):\n    assert k >= 2\n    if k == 2:\n        return log2floor(b+1)\n    v = (k - 1) * (b + 1) + 1\n    h = 0\n    while k**(h+1) < v:\n        h += 1\n    return h", "response": "Calculate the level in which a 0 - based bucket\n    lives inside of a k - ary heap."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the highest level after which the paths from the root to these buckets diverge.", "response": "def calculate_last_common_level(k, b1, b2):\n    \"\"\"\n    Calculate the highest level after which the\n    paths from the root to these buckets diverge.\n    \"\"\"\n    l1 = calculate_bucket_level(k, b1)\n    l2 = calculate_bucket_level(k, b2)\n    while l1 > l2:\n        b1 = (b1-1)//k\n        l1 -= 1\n    while l2 > l1:\n        b2 = (b2-1)//k\n        l2 -= 1\n    while b1 != b2:\n        b1 = (b1-1)//k\n        b2 = (b2-1)//k\n        l1 -= 1\n    return l1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the tree in the dot language format to f.", "response": "def write_as_dot(self, f, data=None, max_levels=None):\n        \"Write the tree in the dot language format to f.\"\n        assert (max_levels is None) or (max_levels >= 0)\n        def visit_node(n, levels):\n            lbl = \"{\"\n            if data is None:\n                if self.k <= max_k_labeled:\n                    lbl = repr(n.label()).\\\n                          replace(\"{\",\"\\{\").\\\n                          replace(\"}\",\"\\}\").\\\n                          replace(\"|\",\"\\|\").\\\n                          replace(\"<\",\"\\<\").\\\n                          replace(\">\",\"\\>\")\n                else:\n                    lbl = str(n)\n            else:\n                s = self.bucket_to_block(n.bucket)\n                for i in xrange(self.blocks_per_bucket):\n                    lbl += \"{%s}\" % (data[s+i])\n                    if i + 1 != self.blocks_per_bucket:\n                        lbl += \"|\"\n            lbl += \"}\"\n            f.write(\"  %s [penwidth=%s,label=\\\"%s\\\"];\\n\"\n                    % (n.bucket, 1, lbl))\n            levels += 1\n            if (max_levels is None) or (levels <= max_levels):\n                for i in xrange(self.k):\n                    cn = n.child_node(i)\n                    if not self.is_nil_node(cn):\n                        visit_node(cn, levels)\n                        f.write(\"  %s -> %s ;\\n\" % (n.bucket, cn.bucket))\n\n        f.write(\"// Created by SizedVirtualHeap.write_as_dot(...)\\n\")\n        f.write(\"digraph heaptree {\\n\")\n        f.write(\"node [shape=record]\\n\")\n\n        if (max_levels is None) or (max_levels > 0):\n            visit_node(self.root_node(), 1)\n        f.write(\"}\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_image_as_pdf(self, filename, data=None, max_levels=None):\n        \"Write the heap as PDF file.\"\n        assert (max_levels is None) or (max_levels >= 0)\n        import os\n        if not filename.endswith('.pdf'):\n            filename = filename+'.pdf'\n        tmpfd, tmpname = tempfile.mkstemp(suffix='dot')\n        with open(tmpname, 'w') as f:\n            self.write_as_dot(f, data=data, max_levels=max_levels)\n        os.close(tmpfd)\n        try:\n            subprocess.call(['dot',\n                             tmpname,\n                             '-Tpdf',\n                             '-o',\n                             ('%s'%filename)])\n        except OSError:\n            sys.stderr.write(\n                \"DOT -> PDF conversion failed. See DOT file: %s\\n\"\n                % (tmpname))\n            return False\n        os.remove(tmpname)\n        return True", "response": "Write the heap as PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef average_cq(seq, efficiency=1.0):\n    denominator = sum( [pow(2.0*efficiency, -Ci) for Ci in seq] )\n    return log(len(seq)/denominator)/log(2.0*efficiency)", "response": "Given a set of Cq values return the Cq value that represents the average expression level of the input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_sample_frame(sample_frame):\n    if not isinstance(sample_frame, pd.core.frame.DataFrame):\n        raise TypeError(\"Expected a pandas DataFrame, received {}\".format(type(sample_frame)))\n    for col in ['Sample', 'Target', 'Cq']:\n        if col not in sample_frame:\n            raise ValueError(\"Missing column {} in sample frame\".format(col))\n    if sample_frame['Cq'].dtype.kind != 'f':\n        raise ValueError(\"Expected Cq column to have float type; has type {} instead\".format(str(sample_frame['Cq'].dtype)))\n    return True", "response": "Makes sure that the sample_frame has the columns we expect."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting rows from the sample data frame that fall earlier than the NTC for that target.", "response": "def censor_background(sample_frame, ntc_samples=['NTC'], margin=log2(10)):\n    \"\"\"Selects rows from the sample data frame that fall `margin` or greater\n    cycles earlier than the NTC for that target. NTC wells are recognized by\n    string matching against the Sample column.\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param iterable ntc_samples: A sequence of strings giving the sample names of your NTC wells, i.e. ['NTC']\n    :param float margin: The number of cycles earlier than the NTC for a \"good\" sample, i.e. log2(10)\n    :return: a view of the sample data frame containing only non-background rows\n    :rtype: DataFrame\n    \"\"\"\n    ntcs = sample_frame.loc[ sample_frame['Sample'].apply(lambda x: x in ntc_samples), ]\n    if ntcs.empty:\n        return sample_frame\n    g = ntcs.groupby('Target')\n    min_ntcs = g['Cq'].min()\n    # if a target has no NTC, min_ntcs.loc[sample] is NaN\n    # we should retain all values from targets with no NTC\n    # all comparisons with NaN are false\n    # so we test for the \"wrong\" condition and invert the result\n    censored = sample_frame.loc[ ~(sample_frame['Cq'] > (min_ntcs.loc[sample_frame['Target']] - margin)) ]\n    return censored"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expression_ddcq(sample_frame, ref_target, ref_sample):\n    # It might be more correct to replace asarray calls (to discard indexes)\n    # with proper joins.\n  \n    ref_target_df = sample_frame.ix[sample_frame['Target'] == ref_target, ['Sample', 'Cq']]\n    ref_target_grouped = ref_target_df.groupby('Sample')\n    ref_target_mean_by_sample = ref_target_grouped['Cq'].aggregate(average_cq)\n    ref_target_mean_list = ref_target_mean_by_sample.ix[sample_frame['Sample']]\n    ref_target_delta = asarray(ref_target_mean_list - ref_target_mean_by_sample[ref_sample])\n\n    ref_sample_df = sample_frame.ix[sample_frame['Sample'] == ref_sample, ['Target', 'Cq']]\n    ref_sample_grouped = ref_sample_df.groupby('Target')\n    ref_sample_mean_by_target = ref_sample_grouped['Cq'].aggregate(average_cq)\n    ref_sample_delta = asarray(sample_frame['Cq'] - asarray(ref_sample_mean_by_target.ix[sample_frame['Target']]))\n\n    rel_exp = pd.Series(\n            power(2, ref_target_delta - ref_sample_delta),\n            index = sample_frame.index)\n\n    return rel_exp", "response": "Calculates the expression of samples in a sample data frame relative to a single reference gene and reference sample using the \u2206\u2206Cq method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the expression of samples in a sample data frame relative to a specific resource.", "response": "def expression_nf(sample_frame, nf_n, ref_sample):\n    \"\"\"Calculates expression of samples in a sample data frame relative to\n    pre-computed normalization factors.\n\n    ref_sample should be defined for all targets or the result will contain\n    many NaNs.\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param Series nf_n: A Series of normalization factors indexed by sample.\n        You probably got this from `compute_nf`.\n    :param string ref_sample: The name of the sample to normalize against,\n        which should match a value in the sample_frame Sample column.\n    :return: a Series of expression values for each row in the sample data\n        frame.\n    :rtype: Series\n    \"\"\"\n    ref_sample_df = sample_frame.ix[sample_frame['Sample'] == ref_sample, ['Target', 'Cq']]\n    ref_sample_cq = ref_sample_df.groupby('Target')['Cq'].aggregate(average_cq)\n\n    delta = -sample_frame['Cq'] + asarray(ref_sample_cq.ix[sample_frame['Target']])\n    rel = power(2, delta) / asarray(nf_n.ix[sample_frame['Sample']])\n    return rel"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the expression of all rows in the sample_frame relative to the base of the ref_targets. Used in rank_targets.", "response": "def collect_expression(sample_frame, ref_targets, ref_sample):\n    \"\"\"Calculates the expression of all rows in the sample_frame relative to\n    each of the ref_targets. Used in rank_targets.\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param iterable ref_targets: A sequence of targets from the Target column of\n        the sample frame.\n    :param string ref_sample: The name of the sample to which expression should\n        be referenced.\n    :return: a DataFrame of relative expression; rows represent rows of the\n        sample_frame and columns represent each of the ref_targets.\n    :rtype: DataFrame\n    \"\"\"\n    by_gene = {'Sample': sample_frame['Sample'], 'Target': sample_frame['Target']}\n    for target in ref_targets:\n        by_gene[target] = expression_ddcq(sample_frame, target, ref_sample)\n    return pd.DataFrame(by_gene)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses geNorm algorithm to determine the most stably expressed genes from amongst ref_targets in your sample.", "response": "def rank_targets(sample_frame, ref_targets, ref_sample):\n    \"\"\"Uses the geNorm algorithm to determine the most stably expressed\n    genes from amongst ref_targets in your sample.\n\n    See Vandesompele et al.'s 2002 Genome Biology paper for information about\n    the algorithm: http://dx.doi.org/10.1186/gb-2002-3-7-research0034\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param iterable ref_targets: A sequence of targets from the Target column\n        of sample_frame to consider for ranking.\n    :param string ref_sample: The name of a sample from the Sample\n        column of sample_frame. It doesn't really matter what it is but it\n        should exist for every target.\n    :return: a sorted DataFrame with two columns, 'Target' and 'M' (the\n        relative stability; lower means more stable).\n    :rtype: DataFrame\n    \"\"\"\n    table = collect_expression(sample_frame, ref_targets, ref_sample)\n    all_samples = sample_frame['Sample'].unique()\n    t = table.groupby(['Sample', 'Target']).mean()\n    logt = log2(t)\n    ref_targets = set(ref_targets)\n\n    worst = []\n    worst_m = []\n    while len(ref_targets) - len(worst) > 1:\n        M = []\n        for test_target in ref_targets:\n            if test_target in worst: continue\n            Vs = []\n            for ref_target in ref_targets:\n                if ref_target == test_target or ref_target in worst: continue\n                A = logt.ix[zip(all_samples, repeat(test_target)), ref_target]\n                Vs.append(A.std())\n            M.append( (sum(Vs)/(len(ref_targets)-len(worst)-1), test_target) )\n        worst.append(max(M)[1])\n        worst_m.append(max(M)[0])\n    best = ref_targets - set(worst)\n    worst.reverse()\n    worst_m.reverse()\n    worst_m = [worst_m[0]] + worst_m\n    return pd.DataFrame({'Target': list(best) + worst, 'M': worst_m}, columns=['Target', 'M'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating all NF_1 NF_2... NF_n for each target in ranked_genes and returns a DataFrame with columns 1 2... n containing NF_1... NF_n for each sample in ranked_genes.", "response": "def calculate_all_nfs(sample_frame, ranked_targets, ref_sample):\n    \"\"\"For a set of n ranked_genes, calculates normalization factors NF_1,\n    NF_2, ..., NF_n. NF_i represents the normalization factor generated by\n    considering the first i targets in ranked_targets.\n    \n    calculate_nf (which returns only NF_n) is probably more\n    useful for routine analysis.\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param iterable ranked_targets: A list or Series of target names, in order\n        of descending stability (ascending M).\n    :param string ref_sample: The name of the sample to normalize against.\n    :return: a DataFrame with columns 1, 2, ..., n containing normalization\n        factors NF_1, ..., NF_n for each sample, indexed by sample name.\n    :rtype: DataFrame\n    \"\"\"\n\n    # Returns a DataFrame, where rows represent samples and columns represent a number of reference genes.\n    grouped = sample_frame.groupby(['Target', 'Sample'])['Cq'].aggregate(average_cq)\n    samples = sample_frame['Sample'].unique()\n    nfs = {}\n    for i in xrange(1, len(ranked_targets)+1):\n        nfs[i] = gmean([pow(2, -grouped.ix[zip(repeat(ref_gene), samples)] + grouped.ix[ref_gene, ref_sample]) for ref_gene in ranked_targets[:i]])\n    return pd.DataFrame(nfs, index=samples)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating a normalization factor from the geometric mean of the expression of all ref_targets normalized to a reference sample.", "response": "def calculate_nf(sample_frame, ref_targets, ref_sample):\n    \"\"\"Calculates a normalization factor from the geometric mean of the\n    expression of all ref_targets, normalized to a reference sample.\n\n    :param DataFrame sample_frame: A sample data frame.\n    :param iterable ref_targets: A list or Series of target names.\n    :param string ref_sample: The name of the sample to normalize against.\n    :return: a Series indexed by sample name containing normalization factors\n        for each sample.\n    \"\"\"\n    grouped = sample_frame.groupby(['Target', 'Sample'])['Cq'].aggregate(average_cq)\n    samples = sample_frame['Sample'].unique()\n    nfs = gmean([pow(2, -grouped.ix[zip(repeat(ref_gene), samples)] + grouped.ix[ref_gene, ref_sample]) for ref_gene in ref_targets])\n    return pd.Series(nfs, index=samples)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the V values for a given n - th NF file.", "response": "def calculate_v(nfs):\n    \"\"\"Calculates V(n+1/n) values. Useful for establishing the quality of\n    your normalization regime. See Vandesompele 2002 for advice on\n    interpretation.\n\n    :param DataFrame nfs: A matrix of all normalization factors, produced by\n       `calculate_all_nfs`.\n    :return: a Series of values [V(2/1), V(3/2), V(4/3), ...].\n    \"\"\"\n    v = []\n    if (nfs.columns != range(1, nfs.columns[-1]+1)).any():\n        raise ValueError(\"Column names invalid in nf_v_frame\")\n    for i in nfs.columns[:-1]:\n        v.append(std(log2(nfs[i]/nfs[i+1]), ddof=1))\n    return pd.Series(v, index=nfs.columns[:-1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', dest='in_filename', required=True,\n                        help='Zeppelin notebook input file (.json)')\n    parser.add_argument('-o', dest='out_filename',\n                        help='Markdown output file (.md) (optional)')\n    args = parser.parse_args()\n    directory = ''\n\n    if args.out_filename:\n        directory = os.path.dirname(args.out_filename)\n        args.out_filename = os.path.basename(args.out_filename)\n        args.out_filename = os.path.splitext(args.out_filename)[0]\n        args.out_filename = args.out_filename if args.out_filename else 'knowledge'\n    else:\n        args.out_filename = 'knowledge'\n\n    with open(args.in_filename, 'rb') as raw:\n        try:\n            t = json.load(raw)\n            full_path = os.path.join(directory, args.out_filename + '.md')\n        except ValueError:\n            print('ERROR: Invalid JSON format')\n            sys.exit(1)\n\n    version = get_version(t)\n    if version == '0.7.1':\n        zeppelin_converter = NewConverter(args.in_filename, args.out_filename,\n                                          directory)\n    elif version == '0.6.2':\n        zeppelin_converter = LegacyConverter(args.in_filename, args.out_filename,\n                                             directory)\n\n    with open(full_path, 'w') as fout:\n        zeppelin_converter.convert(t, fout)", "response": "Entry point for the zeppelin notebook\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets meta data about our EC2 instance.", "response": "def get_ec2_meta_data():\n    \"\"\"\n    Get meta data about ourselves, if we are on an EC2 instance.\n\n    In particular, this returns the VPC ID and region of this instance.\n\n    If we are not on an EC2 instance it returns an empty dict.\n\n    \"\"\"\n    # The timeout is just for the connection attempt, but between retries there\n    # is an exponential back off in seconds. So, too many retries and it can\n    # possibly block for a very long time here. Main contributor to waiting\n    # time here is the number of retries, rather than the timeout time.\n    try:\n        md     = boto.utils.get_instance_metadata(timeout=2, num_retries=2)\n        vpc_id = md['network']['interfaces']['macs'].values()[0]['vpc-id']\n        region = md['placement']['availability-zone'][:-1]\n        return {\"vpc_id\" : vpc_id, \"region_name\" : region}\n    except:\n        # Any problem while getting the meta data? Assume we are not on an EC2\n        # instance.\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_to_region(region_name):\n    logging.debug(\"Connecting to AWS region '%s'\" % region_name)\n    con = boto.vpc.connect_to_region(region_name)\n    if not con:\n        raise VpcRouteSetError(\"Could not establish connection to \"\n                               \"region '%s'.\" % region_name)\n    return con", "response": "Establish connection to AWS API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_ip_subnet_lookup(vpc_info):\n    # We create a reverse lookup from the instances private IP addresses to the\n    # subnets they are associated with. This is used later on in order to\n    # determine whether routes should be set in an RT: Is the RT's subnet\n    # associated with ANY of the IP addresses in the route spec? To make this\n    # easy, we collect the IPs and subnets of all EC2 instances in the VPC.\n    # Once we get a route spec, we create a list of subnets for only the\n    # cluster nodes. The assumption is that not all EC2 instances in the VPC\n    # necessarily belong to the cluster. We really want to narrow it down to\n    # the cluster nodes only. See make_cluster_node_subnet_list().\n    vpc_info['ip_subnet_lookup'] = {}\n    for instance in vpc_info['instances']:\n        for interface in instance.interfaces:\n            subnet_id = interface.subnet_id\n            for priv_addr in interface.private_ip_addresses:\n                vpc_info['ip_subnet_lookup'][priv_addr.private_ip_address] = \\\n                                                                    subnet_id", "response": "Create a lookup for IP - > subnet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting information for a VPC in a given region.", "response": "def get_vpc_overview(con, vpc_id, region_name):\n    \"\"\"\n    Retrieve information for the specified VPC.\n\n    If no VPC ID was specified then just pick the first VPC we find.\n\n    Returns a dict with the VPC's zones, subnets, route tables and\n    instances.\n\n    \"\"\"\n    logging.debug(\"Retrieving information for VPC '%s'\" % vpc_id)\n    d = {}\n    d['zones'] = con.get_all_zones()\n\n    # Find the specified VPC, or just use the first one\n    all_vpcs    = con.get_all_vpcs()\n    if not all_vpcs:\n        raise VpcRouteSetError(\"Cannot find any VPCs.\")\n\n    if not vpc_id:\n        # Just grab the first available VPC and use it, if no VPC specified\n        vpc = all_vpcs[0]\n        vpc_id = vpc.id\n    else:\n        # Search through the list of VPCs for the one with the specified ID\n        vpc = None\n        for v in all_vpcs:\n            if v.id == vpc_id:\n                vpc = v\n                break\n        if not vpc:\n            raise VpcRouteSetError(\"Cannot find specified VPC '%s' \"\n                                   \"in region '%s'.\" % (vpc_id, region_name))\n    d['vpc'] = vpc\n\n    vpc_filter = {\"vpc-id\" : vpc_id}  # Will use this filter expression a lot\n\n    # Now find the subnets, route tables and instances within this VPC\n    d['subnets']      = con.get_all_subnets(filters=vpc_filter)\n    d['route_tables'] = con.get_all_route_tables(filters=vpc_filter)\n\n    # Route tables are associated with subnets. Maintain a lookup table from\n    # RT ID to (list of) subnets. This is necessary later on, because\n    # we only want to set a route in an RT if at least one of the ENIs we are\n    # dealing with is associated with the RT. That way, we don't have to set\n    # the route in all tables all the time.\n    d['rt_subnet_lookup'] = {}\n    for rt in d['route_tables']:\n        for assoc in rt.associations:\n            if hasattr(assoc, 'subnet_id'):\n                subnet_id = assoc.subnet_id\n                if subnet_id:\n                    d['rt_subnet_lookup'].setdefault(rt.id, []). \\\n                                                            append(subnet_id)\n\n    # Get all the cluster instances (all EC2 instances associated with this\n    # VPC).\n    reservations   = con.get_all_reservations(filters=vpc_filter)\n    d['instances'] = []\n    for r in reservations:  # a reservation may have multiple instances\n        d['instances'].extend(r.instances)\n\n    # Add reverse lookup from the instances private IP addresses to the\n    # subnets they are associated with. More info in the doc for that function.\n    _make_ip_subnet_lookup(d)\n\n    # Maintain a quick instance lookup for convenience\n    d['instance_by_id'] = {}\n    for i in d['instances']:\n        d['instance_by_id'][i.id] = i\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a specific IP address find the EC2 instance and ENI.", "response": "def find_instance_and_eni_by_ip(vpc_info, ip):\n    \"\"\"\n    Given a specific IP address, find the EC2 instance and ENI.\n\n    We need this information for setting the route.\n\n    Returns instance and emi in a tuple.\n\n    \"\"\"\n    for instance in vpc_info['instances']:\n        for eni in instance.interfaces:\n            for pa in eni.private_ip_addresses:\n                if pa.private_ip_address == ip:\n                    return instance, eni\n    raise VpcRouteSetError(\"Could not find instance/eni for '%s' \"\n                           \"in VPC '%s'.\" % (ip, vpc_info['vpc'].id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_instance_private_ip_from_route(instance, route):\n    ipaddr = None\n    for eni in instance.interfaces:\n        if eni.id == route.interface_id:\n            ipaddr = eni.private_ip_address\n            break\n    return ipaddr, eni if ipaddr else None", "response": "Find the private IP and ENI of an instance that s pointed to in a route."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _choose_different_host(old_ip, ip_list, failed_ips, questionable_ips):\n    if not ip_list:\n        # We don't have any hosts to choose from.\n        return None\n\n    ip_set           = set(ip_list)\n    failed_set       = set(failed_ips)\n    # Consider only those questionable IPs that aren't also failed and make\n    # sure all of the ones in the questionable list are at least also present\n    # in the overall IP list.\n    questionable_set = set(questionable_ips).intersection(ip_set). \\\n                                             difference(failed_set)\n\n    # Get all healthy IPs that are neither failed, nor questionable\n    healthy_ips = list(ip_set.difference(failed_set, questionable_set))\n\n    if healthy_ips:\n        # Return one of the completely healthy IPs\n        return random.choice(healthy_ips)\n\n    if questionable_set:\n        # Don't have any completely healthy ones, so return one of the\n        # questionable ones. Not perfect, but at least may still provide\n        # routing functionality for some time.\n        if old_ip not in questionable_set:\n            # We may be here because the original address was questionable. If\n            # only other questionable ones are available then there's no point\n            # changing the address. We only change if the old address wasn't\n            # one of the questionable ones already.\n            return random.choice(list(questionable_set))\n\n    # We got nothing...\n    return None", "response": "Randomly choose a different host from a list of hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the current state of a VPC route in the current state.", "response": "def _rt_state_update(route_table_id, dcidr, router_ip=\"(none)\",\n                     instance_id=\"(none)\", eni_id=\"(none)\",\n                     old_router_ip=\"(none)\", msg=\"(none)\"):\n    \"\"\"\n    Store a message about a VPC route in the current state.\n\n    \"\"\"\n    buf = \"inst: %s, eni: %s, r_ip: %-15s, o_r_ip: %-15s, msg: %s\" % \\\n          (instance_id, eni_id, router_ip, old_router_ip, msg)\n    CURRENT_STATE.vpc_state.setdefault('route_tables', {}). \\\n                            setdefault(route_table_id, {})[dcidr] = buf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate an existing route in the route table.", "response": "def _update_route(dcidr, router_ip, old_router_ip,\n                  vpc_info, con, route_table_id, update_reason):\n    \"\"\"\n    Update an existing route entry in the route table.\n\n    \"\"\"\n    instance = eni = None\n    try:\n        instance, eni = find_instance_and_eni_by_ip(vpc_info, router_ip)\n\n        logging.info(\"--- updating existing route in RT '%s' \"\n                     \"%s -> %s (%s, %s) (old IP: %s, reason: %s)\" %\n                     (route_table_id, dcidr, router_ip,\n                      instance.id, eni.id, old_router_ip, update_reason))\n        try:\n            con.replace_route(\n                        route_table_id         = route_table_id,\n                        destination_cidr_block = dcidr,\n                        instance_id            = instance.id,\n                        interface_id           = eni.id)\n        except Exception as e:\n            raise Exception(\"replace_route failed: %s\" % str(e))\n\n        CURRENT_STATE.routes[dcidr] = \\\n                                    (router_ip, str(instance.id), str(eni.id))\n    except Exception as e:\n        msg = \"*** failed to update route in RT '%s' %s -> %s (%s)\" % \\\n              (route_table_id, dcidr, old_router_ip, e.message)\n        update_reason += \" [ERROR update route: %s]\" % e.message\n        logging.error(msg)\n\n    _rt_state_update(route_table_id, dcidr, router_ip,\n                     instance.id if instance else \"(none)\",\n                     eni.id if eni else \"(none)\",\n                     old_router_ip, update_reason)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new route to the route table.", "response": "def _add_new_route(dcidr, router_ip, vpc_info, con, route_table_id):\n    \"\"\"\n    Add a new route to the route table.\n\n    \"\"\"\n    try:\n        instance, eni = find_instance_and_eni_by_ip(vpc_info, router_ip)\n        # Only set the route if the RT is associated with any of the subnets\n        # used for the cluster.\n        rt_subnets           = \\\n                    set(vpc_info['rt_subnet_lookup'].get(route_table_id, []))\n        cluster_node_subnets = \\\n                    set(vpc_info['cluster_node_subnets'])\n        if not rt_subnets or not rt_subnets.intersection(cluster_node_subnets):\n            logging.debug(\"--- skipping adding route in RT '%s' \"\n                          \"%s -> %s (%s, %s) since RT's subnets (%s) are not \"\n                          \"part of the cluster (%s).\" %\n                          (route_table_id, dcidr, router_ip, instance.id,\n                           eni.id,\n                           \", \".join(rt_subnets) if rt_subnets else \"none\",\n                           \", \".join(cluster_node_subnets)))\n            return\n\n        logging.info(\"--- adding route in RT '%s' \"\n                     \"%s -> %s (%s, %s)\" %\n                     (route_table_id, dcidr, router_ip, instance.id, eni.id))\n        con.create_route(route_table_id         = route_table_id,\n                         destination_cidr_block = dcidr,\n                         instance_id            = instance.id,\n                         interface_id           = eni.id)\n        CURRENT_STATE.routes[dcidr] = \\\n                                    (router_ip, str(instance.id), str(eni.id))\n        _rt_state_update(route_table_id, dcidr, router_ip, instance.id, eni.id,\n                         msg=\"Added route\")\n\n    except Exception as e:\n        logging.error(\"*** failed to add route in RT '%s' \"\n                      \"%s -> %s (%s)\" %\n                      (route_table_id, dcidr, router_ip, e.message))\n        _rt_state_update(route_table_id, dcidr,\n                         msg=\"[ERROR add route: %s]\" % e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_real_instance_if_mismatch(vpc_info, ipaddr, instance, eni):\n    # Careful! A route may be a black-hole route, which still has instance and\n    # ENI information for an instance that doesn't exist anymore. If a host was\n    # terminated and a new host got the same IP then this route won't be\n    # updated and will keep pointing to a non-existing node. So we find the\n    # instance by IP and check that the route really points to this instance.\n    inst_id = instance.id if instance else \"\"\n    eni_id  = eni.id if eni else \"\"\n    if ipaddr:\n        real_instance, real_eni = \\\n                        find_instance_and_eni_by_ip(vpc_info, ipaddr)\n        if real_instance.id != inst_id  or real_eni.id != eni_id:\n            return real_instance\n    return None", "response": "Return the real instance for the given IP address if that instance is different than the passed in instance and that instance is different than the passed in eni."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a specific route return information about the instance that points to the route.", "response": "def _get_host_for_route(vpc_info, route, route_table, dcidr):\n    \"\"\"\n    Given a specific route, return information about the instance to which it\n    points.\n\n    Returns 3-tuple: instance-id, ipaddr, eni-id\n\n    Need to take care of scenarios where the instance isn't set anymore in the\n    route (the instance may have disappeared).\n\n    \"\"\"\n    class _CouldNotIdentifyHost(Exception):\n        # If we can't find both the instance as well as an eni for the route,\n        # we will raise this exception. In that case, we'll return None/unknown\n        # values, which indicate to the calling code that a new instance should\n        # be found.\n        pass\n\n    try:\n        # The instance_id in the route may be None. We can get this in case of\n        # a black-hole route.\n        if route.instance_id:\n            instance = vpc_info['instance_by_id'].get(route.instance_id)\n            if not instance:\n                logging.info(\"--- instance in route in RT '%s' can't \"\n                             \"be found: %s -> ... (instance '%s')\" %\n                             (route_table.id, dcidr, route.instance_id))\n                raise _CouldNotIdentifyHost()\n            inst_id = instance.id\n\n            ipaddr, eni = get_instance_private_ip_from_route(instance, route)\n            if not eni:\n                logging.info(\"--- eni in route in RT '%s' can't \"\n                             \"be found: %s -> %s (instance '%s')\" %\n                             (route_table.id, dcidr,\n                              ipaddr if ipaddr else \"(none)\",\n                              inst_id))\n                raise _CouldNotIdentifyHost()\n            eni_id = eni.id\n\n            # If route points to outdated instance, set ipaddr and eni to\n            # None to signal that route needs to be updated\n            real_instance = _get_real_instance_if_mismatch(\n                                        vpc_info, ipaddr, instance, eni)\n            if real_instance:\n                logging.info(\"--- obsoleted route in RT '%s' \"\n                             \"%s -> %s (%s, %s) (new instance with same \"\n                             \"IP address should be used: %s)\" %\n                             (route_table.id, dcidr, ipaddr, inst_id, eni_id,\n                              real_instance.id))\n                # Setting the ipaddr and eni to None signals code further\n                # down that the route must be updated.\n                raise _CouldNotIdentifyHost()\n\n        else:\n            # This route didn't point to an instance anymore, probably\n            # a black hole route\n            logging.info(\"--- obsoleted route in RT '%s' \"\n                         \"%s -> ... (doesn't point to instance anymore)\" %\n                         (route_table.id, dcidr))\n            raise _CouldNotIdentifyHost()\n\n    except _CouldNotIdentifyHost:\n        inst_id = eni_id = \"(unknown)\"\n        ipaddr  = None\n\n    return inst_id, ipaddr, eni_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_cidr_in_ignore_routes(cidr):\n    for ignore_cidr in CURRENT_STATE.ignore_routes:\n        if is_cidr_in_cidr(cidr, ignore_cidr):\n            return True\n    return False", "response": "Checks the CIDR to see if it falls into any CIDRs specified via the ignore_routes parameter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_existing_routes(route_spec, failed_ips, questionable_ips,\n                            vpc_info, con, routes_in_rts):\n    \"\"\"\n    Go over the existing routes and check whether they still match the spec.\n\n    If the chosen router has failed or is questionable or is not in the host\n    list anymore, the route needs to be updated. If the CIDR isn't in the spec\n    at all anymore then it needs to be deleted.\n\n    Keeps track of the routes we have seen in each RT and populates the\n    passed-in routes_in_rts dictionary with that info.\n\n    Returns a dict with the routers chosen for the various routes we\n    encountered.\n\n    \"\"\"\n    chosen_routers = {}              # keep track of chosen routers for CIDRs\n    NONE_HEALTHY   = \"none-healthy\"  # used as marker in chosen_routers\n    for rt in vpc_info['route_tables']:\n        # Check whether this RT is associated with cluster node subnets. If it\n        # is not then we will perform NO operations on this RT. We will also\n        # not collect the routes from this RT.\n        rt_subnets           = \\\n                    set(vpc_info.get('rt_subnet_lookup', {}).get(rt.id, []))\n        cluster_node_subnets = \\\n                    set(vpc_info.get('cluster_node_subnets', []))\n        if cluster_node_subnets and \\\n                        (not rt_subnets or\n                         not rt_subnets.intersection(cluster_node_subnets)):\n            logging.debug(\"Skipping processing of RT '%s' since RT's \"\n                          \"subnets (%s) are not part of cluster (%s).\" %\n                          (rt.id,\n                           \", \".join(rt_subnets) if rt_subnets else \"none\",\n                           \", \".join(cluster_node_subnets)))\n            continue\n\n        routes_in_rts[rt.id] = []\n        # Iterate over all the routes we find in each RT\n        for r in rt.routes:\n            dcidr = r.destination_cidr_block\n\n            if _is_cidr_in_ignore_routes(dcidr):\n                # A list of CIDRs may have been specified on the command line\n                # via the --ignore_routes option. If the destination CIDR of\n                # this route here is contained in any of those specified CIDRs\n                # then we will not touch or change this route. Often this is\n                # used to protect routes to special instances, such as\n                # proxies or NAT instances.\n                _rt_state_update(rt.id, dcidr,\n                                 msg=\"Ignored: Protected CIDR.\")\n                continue\n\n            if r.instance_id is None and r.interface_id is None:\n                # There are some routes already present in the route table,\n                # which we don't need to mess with. Specifically, routes that\n                # aren't attached to a particular instance or interface.\n                # We skip those.\n                _rt_state_update(rt.id, dcidr,\n                                 msg=\"Ignored: Not a route to an instance\")\n                continue\n\n            routes_in_rts[rt.id].append(dcidr)  # remember we've seen the route\n\n            hosts = route_spec.get(dcidr)       # eligible routers for CIDR\n\n            # Current router host for this CIDR/route.\n            inst_id, ipaddr, eni_id = \\\n                                _get_host_for_route(vpc_info, r, rt, dcidr)\n\n            if not hosts:\n                # The route isn't in the spec anymore and should be\n                # deleted.\n                logging.info(\"--- route not in spec, deleting in \"\n                             \"RT '%s': %s -> ... (%s, %s)\" %\n                             (rt.id, dcidr, inst_id, eni_id))\n\n                con.delete_route(route_table_id         = rt.id,\n                                 destination_cidr_block = dcidr)\n                if dcidr in CURRENT_STATE.routes:\n                    del CURRENT_STATE.routes[dcidr]\n\n                continue\n\n            # We have a route and it's still in the spec. Do we need to update\n            # the router? Multiple reasons for that:\n            # - Router is not in the list of eligible hosts anymore\n            # - Router has failed or is questionable\n            # - In a different route table we used a different host as the\n            #   router.\n\n            # Seen this route in another RT before? This will be None if we'be\n            # not seen it before, and will be NONE_HEALTHY, but we couldn't\n            # find a single healthy eligible router host for it.\n            stored_router_ip = chosen_routers.get(dcidr)\n\n            # Has our current router failed or is questionable?\n            ipaddr_should_be_replaced = ipaddr in failed_ips or \\\n                                        ipaddr in questionable_ips\n\n            # Is the host not eligible anymore?\n            ipaddr_not_eligible = ipaddr not in hosts\n\n            shouldnt_use_ipaddr = \\\n                            ipaddr_should_be_replaced or ipaddr_not_eligible\n\n            if (not stored_router_ip or stored_router_ip == ipaddr) and \\\n                                                    not shouldnt_use_ipaddr:\n                # Haven't seen it before, or points to same router AND\n                # router is healthy: All good\n                if not stored_router_ip:\n                    # Remember this IP as a suitable router for CIDR\n                    chosen_routers[dcidr] = ipaddr\n                logging.info(\"--- route exists already in RT '%s': \"\n                             \"%s -> %s (%s, %s)\" %\n                             (rt.id, dcidr,\n                              ipaddr, inst_id, eni_id))\n                CURRENT_STATE.routes[dcidr] = (ipaddr, inst_id, eni_id)\n                _rt_state_update(rt.id, dcidr, ipaddr, inst_id, eni_id,\n                                 msg=\"Current: Route exist and up to date\")\n                continue\n\n            if stored_router_ip == NONE_HEALTHY:\n                # We've tried to set a route for this before, but\n                # couldn't find any healthy hosts. Can't do anything and\n                # need to skip.\n                CURRENT_STATE.routes[dcidr] = (ipaddr, inst_id, eni_id)\n                _rt_state_update(rt.id, dcidr, ipaddr, inst_id, eni_id,\n                                 msg=\"None healthy, black hole: \"\n                                     \"Determined earlier\")\n                continue\n\n            if stored_router_ip:\n                # Just use the router we've seen before. We know that'll work,\n                # because only healthy hosts make it into the chosen_routers\n                # dict.\n                new_router_ip = stored_router_ip\n                update_reason = \"other RT used different IP\"\n            else:\n                # Haven't seen this route in another RT, so we'll\n                # choose a new router\n                new_router_ip = _choose_different_host(ipaddr, hosts,\n                                                       failed_ips,\n                                                       questionable_ips)\n                if new_router_ip is None:\n                    # Couldn't find healthy host to be router, forced\n                    # to skip this one.\n                    CURRENT_STATE.routes[dcidr] = (ipaddr, inst_id, eni_id)\n                    chosen_routers[dcidr] = NONE_HEALTHY\n                    logging.warning(\"--- cannot find available target \"\n                                    \"for route update %s! \"\n                                    \"Nothing I can do...\" % (dcidr))\n                    continue\n\n                chosen_routers[dcidr] = new_router_ip\n                update_reason = \"old IP failed/questionable or \" \\\n                                \"not eligible anymore\"\n\n            _update_route(dcidr, new_router_ip, ipaddr,\n                          vpc_info, con, rt.id, update_reason)\n\n    return chosen_routers", "response": "Update the routes in the given list with the ones that match the given route spec."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_missing_routes(route_spec, failed_ips, questionable_ips,\n                        chosen_routers, vpc_info, con, routes_in_rts):\n    \"\"\"\n    Iterate over route spec and add all the routes we haven't set yet.\n\n    This relies on being told what routes we HAVE already. This is passed\n    in via the routes_in_rts dict.\n\n    Furthermore, some routes may be set in some RTs, but not in others. In that\n    case, we may already have seen which router was chosen for a certain route.\n    This information is passed in via the chosen_routers dict. We should choose\n    routers that were used before.\n\n    \"\"\"\n    for dcidr, hosts in route_spec.items():\n        new_router_ip = chosen_routers.get(dcidr)\n        # Look at the routes we have seen in each of the route tables.\n        for rt_id, dcidr_list in routes_in_rts.items():\n            if dcidr not in dcidr_list:\n                if not new_router_ip:\n                    # We haven't chosen a target host for this CIDR.\n                    new_router_ip = _choose_different_host(None, hosts,\n                                                           failed_ips,\n                                                           questionable_ips)\n                    if not new_router_ip:\n                        logging.warning(\"--- cannot find available target \"\n                                        \"for route addition %s! \"\n                                        \"Nothing I can do...\" % (dcidr))\n                        # Skipping the check on any further RT, breaking out to\n                        # outer most loop over route spec\n                        break\n                _add_new_route(dcidr, new_router_ip, vpc_info, con, rt_id)", "response": "Add missing routes to the route_spec."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_route_spec_config(con, vpc_info, route_spec,\n                              failed_ips, questionable_ips):\n    \"\"\"\n    Look through the route spec and update routes accordingly.\n\n    Idea: Make sure we have a route for each CIDR.\n\n    If we have a route to any of the IP addresses for a given CIDR then we are\n    good. Otherwise, pick one (usually the first) IP and create a route to that\n    IP.\n\n    If a route points at a failed or questionable IP then a new candidate is\n    chosen, if possible.\n\n    \"\"\"\n    if CURRENT_STATE._stop_all:\n        logging.debug(\"Routespec processing. Stop requested, abort operation\")\n        return\n\n    if failed_ips:\n        logging.debug(\"Route spec processing. Failed IPs: %s\" %\n                      \",\".join(failed_ips))\n    else:\n        logging.debug(\"Route spec processing. No failed IPs.\")\n\n    # Iterate over all the routes in the VPC, check they are contained in\n    # the spec, update the routes as needed.\n\n    # Need to remember the routes we saw in different RTs, so that we can later\n    # add them, if needed.\n    routes_in_rts  = {}\n\n    CURRENT_STATE.vpc_state.setdefault(\"time\",\n                                       datetime.datetime.now().isoformat())\n\n    # Passed through the functions and filled in, state accumulates information\n    # about all the routes we encounted in the VPC and what we are doing with\n    # them. This is then available in the CURRENT_STATE\n    chosen_routers = _update_existing_routes(route_spec,\n                                             failed_ips, questionable_ips,\n                                             vpc_info, con, routes_in_rts)\n\n    # Now go over all the routes in the spec and add those that aren't in VPC,\n    # yet.\n    _add_missing_routes(route_spec, failed_ips, questionable_ips,\n                        chosen_routers,\n                        vpc_info, con, routes_in_rts)", "response": "Process a route spec and return a new route."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_cluster_node_subnet_list(vpc_info, route_spec):\n    # VPC-info already contains a lookup between the EC2 instances of the VPC\n    # and their subnets ('ip_subnet_lookup'). This may also contain some\n    # non-cluster nodes, but we can use this to look up the subnet for each IP\n    # address of cluster nodes.\n    subnets = set()\n    for cidr_ignore, hosts in route_spec.items():\n        for host_addr in hosts:\n            subnet_id = vpc_info['ip_subnet_lookup'].get(host_addr)\n            if not subnet_id:\n                logging.warning(\"Did not find subnet associated with \"\n                                \"host address '%s'!\" % host_addr)\n            else:\n                subnets.add(subnet_id)\n\n    return list(subnets)", "response": "Create a list of subnets that are associated with nodes in the current VPC - info."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_spec(region_name, vpc_id, route_spec, failed_ips, questionable_ips):\n    if CURRENT_STATE._stop_all:\n        logging.debug(\"handle_spec: Stop requested, abort operation\")\n        return\n\n    if not route_spec:\n        logging.debug(\"handle_spec: No route spec provided\")\n        return\n\n    logging.debug(\"Handle route spec\")\n\n    try:\n        con      = connect_to_region(region_name)\n        vpc_info = get_vpc_overview(con, vpc_id, region_name)\n        vpc_info['cluster_node_subnets'] = \\\n                        make_cluster_node_subnet_list(vpc_info, route_spec)\n        process_route_spec_config(con, vpc_info, route_spec,\n                                  failed_ips, questionable_ips)\n        con.close()\n    except boto.exception.StandardError as e:\n        logging.warning(\"vpc-router could not set route: %s - %s\" %\n                        (e.message, e.args))\n        raise\n\n    except boto.exception.NoAuthHandlerFound:\n        logging.error(\"vpc-router could not authenticate\")", "response": "Handle a route spec and update the route list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signature(self, block_size=None):\n        \"Calculates signature for local file.\"\n        kwargs = {}\n        if block_size:\n            kwargs['block_size'] = block_size\n        return librsync.signature(open(self.path, 'rb'), **kwargs)", "response": "Calculates signature for local file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying remote delta to local file.", "response": "def patch(self, delta):\n        \"Applies remote delta to local file.\"\n        # Create a temp file in which to store our synced copy. We will handle\n        # deleting it manually, since we may move it instead.\n        with (tempfile.NamedTemporaryFile(prefix='.sync',\n              suffix=os.path.basename(self.path),\n              dir=os.path.dirname(self.path), delete=False)) as output:\n            try:\n                # Open the local file, data may be read from it.\n                with open(self.path, 'rb') as reference:\n                    # Patch the local file into our temporary file.\n                    r = librsync.patch(reference, delta, output)\n                    os.rename(output.name, self.path)\n                    return r\n            finally:\n                try:\n                    os.remove(output.name)\n                except OSError as e:\n                    if e.errno != errno.ENOENT:\n                        raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting a signature for remote file via API.", "response": "def signature(self, block_size=None):\n        \"Requests a signature for remote file via API.\"\n        kwargs = {}\n        if block_size:\n            kwargs['block_size'] = block_size\n        return self.api.get('path/sync/signature', self.path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delta(self, signature):\n        \"Generates delta for remote file via API using local file's signature.\"\n        return self.api.post('path/sync/delta', self.path, signature=signature)", "response": "Generates delta for remote file via API using local file s signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying delta for local file to remote file via API.", "response": "def patch(self, delta):\n        \"Applies delta for local file to remote file via API.\"\n        return self.api.post('path/sync/patch', self.path, delta=delta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync(self, src, dst):\n        return dst.patch(src.delta(dst.signature(block_size=self.block_size)))", "response": "Performs synchronization from source to destination."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload(self, local, remote):\n        self.sync(LocalFile(local), RemoteFile(remote, self.api))", "response": "Performs synchronization from a local file to a remote file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(self, local, remote):\n        self.sync(RemoteFile(remote, self.api), LocalFile(local))", "response": "Performs synchronization from a remote file to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate that the input can be converted to a date. Returns a tuple of start and end dates.", "response": "def to_python(self, value):\n        \"\"\"\n        Validates that the input can be converted to a date. Returns a\n        Python datetime.date object.\n        \"\"\"\n        if value in validators.EMPTY_VALUES:\n            return None\n        if isinstance(value, datetime.datetime):\n            return value.date()\n        if isinstance(value, datetime.date):\n            return value\n        if isinstance(value, list):\n            # Input comes from a 2 SplitDateWidgets, for example. So, it's two\n            # components: start date and end date.\n            if len(value) != 2:\n                raise ValidationError(self.error_messages['invalid'])\n            if value[0] in validators.EMPTY_VALUES and value[1] in \\\n                    validators.EMPTY_VALUES:\n                return None\n\n            start_value = value[0]\n            end_value = value[1]\n\n        start_date = None\n        end_date = None\n\n        for format in self.input_formats or \\\n                formats.get_format('DATE_INPUT_FORMATS'):\n            try:\n                start_date = datetime.datetime(*time.strptime(start_value, \\\n                        format)[:6]).date()\n            except ValueError:\n                continue\n\n        for format in self.input_formats or formats.get_format(\\\n                'DATE_INPUT_FORMATS'):\n            try:\n                end_date = datetime.datetime(\n                    *time.strptime(end_value, format)[:6]\n                ).date()\n            except ValueError:\n                continue\n\n        return (start_date, end_date)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the input can be converted to a datetime. Returns a tuple of start and end dates.", "response": "def to_python(self, value):\n        \"\"\"\n        Validates that the input can be converted to a datetime. Returns a\n        Python datetime.datetime object.\n        \"\"\"\n        if value in validators.EMPTY_VALUES:\n            return None\n        if isinstance(value, datetime.datetime):\n            return value\n        if isinstance(value, datetime.date):\n            return datetime.datetime(value.year, value.month, value.day)\n        if isinstance(value, list):\n            # Input comes from a 2 SplitDateTimeWidgets, for example. So,\n            # it's four components: start date and time, and end date and time.\n            if len(value) != 4:\n                raise ValidationError(self.error_messages['invalid'])\n            if value[0] in validators.EMPTY_VALUES and value[1] in \\\n                    validators.EMPTY_VALUES and value[2] in \\\n                    validators.EMPTY_VALUES and value[3] in \\\n                    validators.EMPTY_VALUES:\n                return None\n            start_value = '%s %s' % tuple(value[:2])\n            end_value = '%s %s' % tuple(value[2:])\n\n        start_datetime = None\n        end_datetime = None\n        for format in self.input_formats or formats.get_format(\\\n                'DATETIME_INPUT_FORMATS'):\n            try:\n                start_datetime = datetime.datetime(*time.strptime(\\\n                        start_value, format)[:6])\n            except ValueError:\n                continue\n\n        for format in self.input_formats or formats.get_format(\\\n                'DATETIME_INPUT_FORMATS'):\n            try:\n                end_datetime = datetime.datetime(*time.strptime(\\\n                        end_value, format)[:6])\n            except ValueError:\n                continue\n\n        return (start_datetime, end_datetime)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_python(self, value):\n        if value in validators.EMPTY_VALUES:\n            return None\n        if isinstance(value, datetime.datetime):\n            return value.time()\n        if isinstance(value, datetime.time):\n            return value\n        if isinstance(value, list):\n            # Input comes from a 2 SplitTimeWidgets, for example. So, it's two\n            # components: start time and end time.\n            if len(value) != 2:\n                raise ValidationError(self.error_messages['invalid'])\n            if value[0] in validators.EMPTY_VALUES and value[1] in \\\n                    validators.EMPTY_VALUES:\n                return None\n\n            start_value = value[0]\n            end_value = value[1]\n\n        start_time = None\n        end_time = None\n\n        for format in self.input_formats or formats.get_format(\\\n                'TIME_INPUT_FORMATS'):\n            try:\n                start_time = datetime.datetime(\n                    *time.strptime(start_value, format)[:6]\n                ).time()\n            except ValueError:\n                if start_time:\n                    continue\n                else:\n                    raise ValidationError(self.error_messages['invalid'])\n\n        for format in self.input_formats or formats.get_format(\\\n                'TIME_INPUT_FORMATS'):\n            try:\n                end_time = datetime.datetime(\n                    *time.strptime(end_value, format)[:6]\n                ).time()\n            except ValueError:\n                if end_time:\n                    continue\n                else:\n                    raise ValidationError(self.error_messages['invalid'])\n\n        return (start_time, end_time)", "response": "Validates that the input can be converted to a time. Returns a tuple of start and end times."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef docs_client(self):\n        if not hasattr(self, '_docs_client'):\n            client = DocsClient()\n            client.ClientLogin(self.google_user, self.google_password,\n                               SOURCE_NAME)\n            self._docs_client = client\n        return self._docs_client", "response": "A DocsClient singleton used to look up spreadsheets\n        by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sheets_service(self):\n        if not hasattr(self, '_sheets_service'):\n            service = SpreadsheetsService()\n            service.email = self.google_user\n            service.password = self.google_password\n            service.source = SOURCE_NAME\n            service.ProgrammaticLogin()\n            self._sheets_service = service\n        return self._sheets_service", "response": "A SpreadsheetsService singleton used to perform\n            operations on the actual spreadsheet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a record s identifiers.", "response": "def recid_fetcher(record_uuid, data):\n    \"\"\"Fetch a record's identifiers.\n\n    :param record_uuid: The record UUID.\n    :param data: The record metadata.\n    :returns: A :data:`invenio_pidstore.fetchers.FetchedPID` instance.\n    \"\"\"\n    pid_field = current_app.config['PIDSTORE_RECID_FIELD']\n    return FetchedPID(\n        provider=RecordIdProvider,\n        pid_type=RecordIdProvider.pid_type,\n        pid_value=str(data[pid_field]),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new column to the table.", "response": "def _add_column(self, label, field):\n        \"\"\" Add a new column to the table. It will have the header\n        text ``label``, but for data inserts and queries, the\n        ``field`` name must be used. If necessary, this will expand\n        the size of the sheet itself to allow for the new column. \"\"\"\n        # Don't call this directly.\n        assert self.headers is not None\n        cols = 0\n        if len(self._headers) > 0:\n            cols = max([int(c.cell.col) for c in self._headers])\n        new_col = cols + 1\n        if int(self._ws.col_count.text) < new_col:\n            self._ws.col_count.text = str(new_col)\n            self._update_metadata()\n\n        cell = self._service.UpdateCell(1, new_col, label,\n                                        self._ss.id, self.id)\n        self._headers.append(cell)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of all headers currently defined for the table.", "response": "def headers(self):\n        \"\"\" Return the name of all headers currently defined for the\n        table. \"\"\"\n        if self._headers is None:\n            query = CellQuery()\n            query.max_row = '1'\n            feed = self._service.GetCellsFeed(self._ss.id, self.id,\n                                              query=query)\n            self._headers = feed.entry\n        return [normalize_header(h.cell.text) for h in self._headers]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a new entry in the log table.", "response": "def insert(self, row):\n        \"\"\" Insert a new row. The row will be added to the end of the\n        spreadsheet. Before inserting, the field names in the given \n        row will be normalized and values with empty field names \n        removed. \"\"\"\n        data = self._convert_value(row)\n        self._service.InsertRow(data, self._ss.id, self.id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all rows matching the current query.", "response": "def remove(self, _query=None, **kwargs):\n        \"\"\" Remove all rows matching the current query. If no query\n        is given, this will truncate the entire table. \"\"\"\n        for entry in self._find_entries(_query=_query, **kwargs):\n            self._service.DeleteRow(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a `class.has_role('role_name')` method for a class. :param class cls: The python class to be modified. :param dict roles: The roles to use for generation. This method is intended to be used by an inheriting class to generate the has_role method based on the roles provided. :class:`FlaskKeystone` uses this to add these methods to a dynamically generated class which inherits from this class.", "response": "def generate_has_role_function(cls, roles):\n        \"\"\"\n        Generate a `class.has_role('role_name')` method for a class.\n\n        :param class cls: The python class to be modified.\n        :param dict roles: The roles to use for generation.\n\n        This method is intended to be used by an inheriting class to\n        generate the has_role method based on the roles provided.\n\n        :class:`FlaskKeystone` uses this to add these methods to a dynamically\n        generated class which inherits from this class.\n        \"\"\"\n        def has_role_func(self, role):\n            \"\"\"\n            Determine if an instance of this class has the configured role.\n\n            :param str role: The role identifier from `oslo.config.cfg` to\n                             against which to evaluate this instance for\n                             membership.\n            :returns: Whether or not the instance has the desired role.\n            :rtype: bool\n\n            Note that the role passed to this function is the role identifier\n            from the :class:`oslo.config.cfg`, rather than a keystone role\n            itself.\n            \"\"\"\n            if role not in roles:\n                msg = \"Evaluating has_role('%s'), Role '%s' does not exist.\"\n                self.logger.warn(msg % (role, self.user_id))\n                return False\n            for group in roles[role]:\n                if self._has_keystone_role(group):\n                    return True\n            return False\n        setattr(cls, \"has_role\", has_role_func)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate is_role methods for a class.", "response": "def generate_is_role_functions(cls, roles):\n        \"\"\"\n        Generate `class.is_{role}()` methods for a class.\n\n        :param class cls: The python class to be modified.\n        :param dict roles: The roles to use for generation.\n\n        This method is intended to be used by an inheriting class to\n        generate `is_{role}()` methods based on the roles provided\n        during generation.\n\n        :class:`FlaskKeystone` uses this to add these methods to a dynamically\n        generated class which inherits from this class.\n        \"\"\"\n\n        for access_role in roles.keys():\n            is_role_func = cls.generate_is_role_function(access_role)\n            setattr(cls, \"is_\" + access_role, is_role_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes the column names to be a lowercase string.", "response": "def normalize_header(name, existing=[]):\n    \"\"\" Try to emulate the way in which Google does normalization\n    on the column names to transform them into headers. \"\"\"\n    name = re.sub('\\W+', '', name, flags=re.UNICODE).lower()\n    # TODO handle multiple columns with the same name.\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns ALL elements of the complete hirarchy as a flat list", "response": "def getAllElementsOfHirarchy(self):\n        \"\"\" returns ALL elements of the complete hirarchy as a flat list\n        \"\"\"\n        allElements=[]\n        for element in self.getAllElements():\n            allElements.append(element)\n            if isinstance(element, BaseElement):\n                allElements.extend(element.getAllElementsOfHirarchy())\n        return allElements"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getElementByID(self, id):\n        pos=0\n        for element in self._subElements:\n            if element.get_id()==id:\n                return (element,pos)\n            pos+=1", "response": "returns an element with the specific id and the position of that element within the svg elements array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getElementsByType(self, type):\n        foundElements=[]\n        for element in self.getAllElementsOfHirarchy():\n            if isinstance(element, type):\n                foundElements.append(element)                \n                \n        return foundElements", "response": "Returns all Elements that are of type type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an XML representation of the current element.", "response": "def getXML(self):\n        \"\"\"\n        Return a XML representation of the current element.\n        This function can be used for debugging purposes. It is also used by getXML in SVG\n    \n        @return:  the representation of the current element as an xml string\n        \"\"\"\n        xml='<'+self._elementName+' '\n        for key,value in list(self._attributes.items()):\n            if value != None:\n                xml+=key+'=\"'+self.quote_attrib(str(value))+'\" '\n        if  len(self._subElements)==0: #self._textContent==None and\n            xml+=' />\\n'\n        else:\n            xml+=' >\\n'\n            #if self._textContent==None:\n            for subelement in self._subElements:\n                s = subelement.getXML()\n                if type(s) != str:\n                    s = str(s)\n                xml+=s\n               # xml+=str(subelement.getXML())\n            #else:\n            #if self._textContent!=None:\n            #    xml+=self._textContent\n            xml+='</'+self._elementName+'>\\n'\n        #print xml\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setKWARGS(self, **kwargs):\n        for key in list(kwargs.keys()):\n            #try:\n            f = getattr(self,'set_' + key)\n            f(kwargs[key])", "response": "Set all attributes given in a kwargs parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, filename, encoding ='ISO-8859-1', standalone='no'):\n        f = codecs.open(filename, 'w', encoding)\n        s = self.wrap_xml(self.getXML(), encoding, standalone)\n        #s = s.replace(\"&\", \"&amp;\")\n        f.write(s)\n        f.close()", "response": "Saves the XML document to a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quote_attrib(self, inStr):\n        s1 = (isinstance(inStr, str) and inStr or\n              '%s' % inStr)\n        s1 = s1.replace('&', '&amp;')\n        s1 = s1.replace('<', '&lt;')\n        s1 = s1.replace('>', '&gt;')\n        if '\"' in s1:\n        #    if \"'\" in s1:\n            s1 = '%s' % s1.replace('\"', \"&quot;\")\n        #    else:\n        #        s1 = \"'%s'\" % s1\n        #else:\n        #    s1 = '\"%s\"' % s1\n        return s1", "response": "Quote the attribute name in the xml notation and python notation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_time(self, time_str):\n        dt = datetime.strptime(time_str, \"%Y-%m-%dT%H:%M:%SZ\")\n        return int(time.mktime(dt.utctimetuple()))", "response": "Convert a string representation of the time into a unix timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_block_info(self, block):\n        url = '{}/block/info/{}'.format(self._url, block)\n        return self.make_request(url)", "response": "Returns basic block data for a specific block number"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the is_role methods for a class.", "response": "def generate_is_role_functions(cls, roles):\n        \"\"\"\n        Generate `class.is_{role}()` methods for a class.\n\n        :param class cls: The python class to be modified.\n        :param dict roles: The roles to use for generation.\n\n        This method is intended to be used by an inheriting class to\n        generate `is_{role}()` methods based on the roles provided\n        during generation.\n\n        :class:`RaxKeystone` uses this to add these methods to a dynamically\n        generated class which inherits from this class.\n\n        Note that as this is an Anonymous user, these functions will always\n        return `False`.\n        \"\"\"\n        for access_role in roles.keys():\n            setattr(cls, \"is_\" + access_role, lambda x: False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(pid_type, pid_value, status, object_type, object_uuid):\n    from .models import PersistentIdentifier\n\n    if bool(object_type) ^ bool(object_uuid):\n        raise click.BadParameter('Speficy both or any of --type and --uuid.')\n\n    new_pid = PersistentIdentifier.create(\n        pid_type,\n        pid_value,\n        status=status,\n        object_type=object_type,\n        object_uuid=object_uuid,\n    )\n    db.session.commit()\n    click.echo(\n        '{0.pid_type} {0.pid_value} {0.pid_provider}'.format(new_pid)\n    )", "response": "Create new persistent identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_object(pid_type, pid_value):\n    from .models import PersistentIdentifier\n\n    obj = PersistentIdentifier.get(pid_type, pid_value)\n    if obj.has_object():\n        click.echo('{0.object_type} {0.object_uuid} {0.status}'.format(obj))", "response": "Get an object behind persistent identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dereference_object(object_type, object_uuid, status):\n    from .models import PersistentIdentifier\n\n    pids = PersistentIdentifier.query.filter_by(\n        object_type=object_type, object_uuid=object_uuid\n    )\n    if status:\n        pids = pids.filter_by(status=status)\n\n    for found_pid in pids.all():\n        click.echo(\n            '{0.pid_type} {0.pid_value} {0.pid_provider}'.format(found_pid)\n        )", "response": "Show linked persistent identifier s."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recid_minter(record_uuid, data):\n    pid_field = current_app.config['PIDSTORE_RECID_FIELD']\n    assert pid_field not in data\n    provider = RecordIdProvider.create(\n        object_type='rec', object_uuid=record_uuid)\n    data[pid_field] = provider.pid.pid_value\n    return provider.pid", "response": "Mint record identifiers.\n\n    This is a minter specific for records.\n    With the help of\n    :class:`invenio_pidstore.providers.recordid.RecordIdProvider`, it creates\n    the PID instance with `rec` as predefined `object_type`.\n\n    Procedure followed: (we will use `control_number` as value of\n    `PIDSTORE_RECID_FIELD` for the simplicity of the documentation.)\n\n    #. If a `control_number` field is already there, a `AssertionError`\n    exception is raised.\n\n    #. The provider is initialized with the help of\n    :class:`invenio_pidstore.providers.recordid.RecordIdProvider`.\n    It's called with default value 'rec' for `object_type` and `record_uuid`\n    variable for `object_uuid`.\n\n    #. The new `id_value` is stored inside `data` as `control_number` field.\n\n    :param record_uuid: The record UUID.\n    :param data: The record metadata.\n    :returns: A fresh `invenio_pidstore.models.PersistentIdentifier` instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef object_formatter(v, c, m, p):\n    endpoint = current_app.config['PIDSTORE_OBJECT_ENDPOINTS'].get(\n        m.object_type)\n\n    if endpoint and m.object_uuid:\n        return Markup('<a href=\"{0}\">{1}</a>'.format(\n            url_for(endpoint, id=m.object_uuid),\n            _('View')))\n    return ''", "response": "Format object view link."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes a transaction into the cache and returns its hash", "response": "def push(self, tx):\n        \"\"\"\n        Args:\n            tx: hex of signed transaction\n        Returns:\n            pushed transaction\n\n        \"\"\"\n        self._service.push_tx(tx)\n        return bitcoin.txhash(tx)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a single transaction from the bitcoind account.", "response": "def get(self, hash, account=\"*\", max_transactions=100, min_confirmations=6, raw=False):\n        \"\"\"\n        Args:\n            hash: can be a bitcoin address or a transaction id. If it's a\n                bitcoin address it will return a list of transactions up to\n                ``max_transactions`` a list of unspents with confirmed\n                transactions greater or equal to ``min_confirmantions``\n            account (Optional[str]): used when using the bitcoind. bitcoind\n                does not provide an easy way to retrieve transactions for a\n                single address. By using account we can retrieve transactions\n                for addresses in a  specific account\n        Returns:\n            transaction\n\n        \"\"\"\n        if len(hash) < 64:\n            txs = self._service.list_transactions(hash, account=account, max_transactions=max_transactions)\n            unspents = self._service.list_unspents(hash, min_confirmations=min_confirmations)\n            return {'transactions': txs, 'unspents': unspents}\n        else:\n            return self._service.get_transaction(hash, raw=raw)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a simple transaction.", "response": "def simple_transaction(self, from_address, to, op_return=None, min_confirmations=6):\n        \"\"\"\n        Args:\n            from_address (str): bitcoin address originating the transaction\n            to: tuple of ``(to_address, amount)`` or list of tuples ``[(to_addr1, amount1), (to_addr2, amount2)]``. Amounts are in *satoshi*\n            op_return (str): ability to set custom ``op_return``\n            min_confirmations (int): minimal number of required confirmations\n\n        Returns:\n            transaction\n\n        \"\"\"\n        to = [to] if not isinstance(to, list) else to\n        amount = sum([amount for addr, amount in to])\n        n_outputs = len(to) + 1     # change\n        if op_return:\n            n_outputs += 1\n\n        # select inputs\n        inputs, change = self._select_inputs(from_address, amount, n_outputs, min_confirmations=min_confirmations)\n        outputs = [{'address': to_address, 'value': amount} for to_address, amount in to]\n        outputs += [{'address': from_address, 'value': change}]\n\n        #add op_return\n        if op_return:\n            outputs += [{'script': self._op_return_hex(op_return), 'value': 0}]\n        tx = self.build_transaction(inputs, outputs)\n        return tx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_transaction(self, inputs, outputs):\n        # prepare inputs and outputs for bitcoin\n        inputs = [{'output': '{}:{}'.format(input['txid'], input['vout']),\n                   'value': input['amount']} for input in inputs]\n        tx = bitcoin.mktx(inputs, outputs)\n        return tx", "response": "This method builds a transaction from inputs and outputs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign_transaction(self, tx, master_password, path=''):\n        netcode = 'XTN' if self.testnet else 'BTC'\n\n        # TODO review\n        # check if its a wif\n        try:\n            BIP32Node.from_text(master_password)\n            return bitcoin.signall(tx, master_password)\n        except (AttributeError, EncodingError):\n            # if its not get the wif from the master secret\n            return bitcoin.signall(tx, BIP32Node.from_master_secret(master_password, netcode=netcode).subkey_for_path(path).wif())", "response": "Signs a hex transaction with the given master password and returns the signed transaction."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self, tx):\n        if not isinstance(self._service, BitcoinBlockrService):\n            raise NotImplementedError('Currently only supported for \"blockr.io\"')\n        return self._service.decode(tx)", "response": "Decodes the given transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new record identifier.", "response": "def create(cls, object_type=None, object_uuid=None, **kwargs):\n        \"\"\"Create a new record identifier.\n\n        Note: if the object_type and object_uuid values are passed, then the\n        PID status will be automatically setted to\n        :attr:`invenio_pidstore.models.PIDStatus.REGISTERED`.\n\n        :param object_type: The object type. (Default: None.)\n        :param object_uuid: The object identifier. (Default: None).\n        :param kwargs: You specify the pid_value.\n        \"\"\"\n        # Request next integer in recid sequence.\n        assert 'pid_value' not in kwargs\n        kwargs['pid_value'] = str(RecordIdentifier.next())\n        kwargs.setdefault('status', cls.default_status)\n        if object_type and object_uuid:\n            kwargs['status'] = PIDStatus.REGISTERED\n        return super(RecordIdProvider, cls).create(\n            object_type=object_type, object_uuid=object_uuid, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new record identifier.", "response": "def create(cls, pid_value, **kwargs):\n        \"\"\"Create a new record identifier.\n\n        For more information about parameters,\n        see :meth:`invenio_pidstore.providers.BaseProvider.create`.\n\n        :param pid_value: Persistent identifier value.\n        :params **kwargs: See\n            :meth:`invenio_pidstore.providers.base.BaseProvider.create` extra\n            parameters.\n        :returns: A :class:`invenio_pidstore.providers.DataCiteProvider`\n            instance.\n        \"\"\"\n        return super(DataCiteProvider, cls).create(\n            pid_value=pid_value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreserve a DOI (amounts to upload metadata, but not to mint). :param doc: Set metadata for DOI. :returns: `True` if is reserved successfully.", "response": "def reserve(self, doc):\n        \"\"\"Reserve a DOI (amounts to upload metadata, but not to mint).\n\n        :param doc: Set metadata for DOI.\n        :returns: `True` if is reserved successfully.\n        \"\"\"\n        # Only registered PIDs can be updated.\n        try:\n            self.pid.reserve()\n            self.api.metadata_post(doc)\n        except (DataCiteError, HttpError):\n            logger.exception(\"Failed to reserve in DataCite\",\n                             extra=dict(pid=self.pid))\n            raise\n        logger.info(\"Successfully reserved in DataCite\",\n                    extra=dict(pid=self.pid))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, url, doc):\n        try:\n            self.pid.register()\n            # Set metadata for DOI\n            self.api.metadata_post(doc)\n            # Mint DOI\n            self.api.doi_post(self.pid.pid_value, url)\n        except (DataCiteError, HttpError):\n            logger.exception(\"Failed to register in DataCite\",\n                             extra=dict(pid=self.pid))\n            raise\n        logger.info(\"Successfully registered in DataCite\",\n                    extra=dict(pid=self.pid))\n        return True", "response": "Register a DOI via the DataCite API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, url, doc):\n        if self.pid.is_deleted():\n            logger.info(\"Reactivate in DataCite\",\n                        extra=dict(pid=self.pid))\n\n        try:\n            # Set metadata\n            self.api.metadata_post(doc)\n            self.api.doi_post(self.pid.pid_value, url)\n        except (DataCiteError, HttpError):\n            logger.exception(\"Failed to update in DataCite\",\n                             extra=dict(pid=self.pid))\n            raise\n\n        if self.pid.is_deleted():\n            self.pid.sync_status(PIDStatus.REGISTERED)\n        logger.info(\"Successfully updated in DataCite\",\n                    extra=dict(pid=self.pid))\n        return True", "response": "Update the metadata associated with a DOI."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        try:\n            if self.pid.is_new():\n                self.pid.delete()\n            else:\n                self.pid.delete()\n                self.api.metadata_delete(self.pid.pid_value)\n        except (DataCiteError, HttpError):\n            logger.exception(\"Failed to delete in DataCite\",\n                             extra=dict(pid=self.pid))\n            raise\n        logger.info(\"Successfully deleted in DataCite\",\n                    extra=dict(pid=self.pid))\n        return True", "response": "Delete a registered DOI."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync_status(self):\n        status = None\n\n        try:\n            try:\n                self.api.doi_get(self.pid.pid_value)\n                status = PIDStatus.REGISTERED\n            except DataCiteGoneError:\n                status = PIDStatus.DELETED\n            except DataCiteNoContentError:\n                status = PIDStatus.REGISTERED\n            except DataCiteNotFoundError:\n                pass\n\n            if status is None:\n                try:\n                    self.api.metadata_get(self.pid.pid_value)\n                    status = PIDStatus.RESERVED\n                except DataCiteGoneError:\n                    status = PIDStatus.DELETED\n                except DataCiteNoContentError:\n                    status = PIDStatus.REGISTERED\n                except DataCiteNotFoundError:\n                    pass\n        except (DataCiteError, HttpError):\n            logger.exception(\"Failed to sync status from DataCite\",\n                             extra=dict(pid=self.pid))\n            raise\n\n        if status is None:\n            status = PIDStatus.NEW\n\n        self.pid.sync_status(status)\n\n        logger.info(\"Successfully synced status from DataCite\",\n                    extra=dict(pid=self.pid))\n        return True", "response": "Synchronize DOI status DataCite MDS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the merkle root of the given list of hashes.", "response": "def merkleroot(hashes):\n    \"\"\"\n    Args:\n        hashes: reversed binary form of transactions hashes, e.g.:\n            ``binascii.unhexlify(h)[::-1] for h in block['tx']]``\n    Returns:\n        merkle root in hexadecimal form\n    \"\"\"\n    if len(hashes) == 1:\n        return binascii.hexlify(bytearray(reversed(hashes[0])))\n    if len(hashes) % 2 == 1:\n        hashes.append(hashes[-1])\n    parent_hashes = []\n    for i in range(0, len(hashes)-1, 2):\n        first_round_hash = hashlib.sha256(hashes[i] + hashes[i+1]).digest()\n        second_round_hash = hashlib.sha256(first_round_hash).digest()\n        parent_hashes.append(second_round_hash)\n    return merkleroot(parent_hashes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the given type and pid.", "response": "def create(cls, pid_type=None, pid_value=None, object_type=None,\n               object_uuid=None, status=None, **kwargs):\n        \"\"\"Create a new instance for the given type and pid.\n\n        :param pid_type: Persistent identifier type. (Default: None).\n        :param pid_value: Persistent identifier value. (Default: None).\n        :param status: Current PID status.\n            (Default: :attr:`invenio_pidstore.models.PIDStatus.NEW`)\n        :param object_type: The object type is a string that identify its type.\n            (Default: None).\n        :param object_uuid: The object UUID. (Default: None).\n        :returns: A :class:`invenio_pidstore.providers.base.BaseProvider`\n            instance.\n        \"\"\"\n        assert pid_value\n        assert pid_type or cls.pid_type\n\n        pid = PersistentIdentifier.create(\n            pid_type or cls.pid_type,\n            pid_value,\n            pid_provider=cls.pid_provider,\n            object_type=object_type,\n            object_uuid=object_uuid,\n            status=status or cls.default_status,\n        )\n        return cls(pid, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a persistent identifier for this provider.", "response": "def get(cls, pid_value, pid_type=None, **kwargs):\n        \"\"\"Get a persistent identifier for this provider.\n\n        :param pid_type: Persistent identifier type. (Default: configured\n            :attr:`invenio_pidstore.providers.base.BaseProvider.pid_type`)\n        :param pid_value: Persistent identifier value.\n        :param kwargs: See\n            :meth:`invenio_pidstore.providers.base.BaseProvider` required\n            initialization properties.\n        :returns: A :class:`invenio_pidstore.providers.base.BaseProvider`\n            instance.\n        \"\"\"\n        return cls(\n            PersistentIdentifier.get(pid_type or cls.pid_type, pid_value,\n                                     pid_provider=cls.pid_provider),\n            **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the Flask_Keystone module in an application factory.", "response": "def init_app(self, app, config_group=\"flask_keystone\"):\n        \"\"\"\n        Iniitialize the Flask_Keystone module in an application factory.\n\n        :param app: `flask.Flask` application to which to connect.\n        :type app: `flask.Flask`\n        :param str config_group: :class:`oslo_config.cfg.OptGroup` to which\n                                 to attach.\n\n        When initialized, the extension will apply the\n        :mod:`keystonemiddleware` WSGI middleware to the flask Application,\n        attach it's own error handler, and generate a User model based on\n        its :mod:`oslo_config` configuration.\n        \"\"\"\n        cfg.CONF.register_opts(RAX_OPTS, group=config_group)\n\n        self.logger = logging.getLogger(__name__)\n        try:\n            logging.register_options(cfg.CONF)\n        except cfg.ArgsAlreadyParsedError:  # pragma: no cover\n            pass\n        logging.setup(cfg.CONF, \"flask_keystone\")\n\n        self.config = cfg.CONF[config_group]\n        self.roles = self._parse_roles()\n        self.User = self._make_user_model()\n        self.Anonymous = self._make_anonymous_model()\n        self.logger.debug(\"Initialized keystone with roles: %s and \"\n                          \"allow_anonymous: %s\" % (\n                              self.roles,\n                              self.config.allow_anonymous_access\n                          ))\n        app.wsgi_app = auth_token.AuthProtocol(app.wsgi_app, {})\n\n        self.logger.debug(\"Adding before_request request handler.\")\n        app.before_request(self._make_before_request())\n        self.logger.debug(\"Registering Custom Error Handler.\")\n        app.register_error_handler(FlaskKeystoneException, handle_exception)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_roles(self):\n        roles = {}\n        for keystone_role, flask_role in self.config.roles.items():\n            roles.setdefault(flask_role, set()).add(keystone_role)\n        return roles", "response": "Generate a dictionary for configured roles from oslo_config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_before_request(self):\n        def before_request():\n            \"\"\"\n            Process invalid identity statuses and attach user to request.\n\n            :raises: :exception:`exceptions.FlaskKeystoneUnauthorized`\n\n            This function guarantees that a bad token will return a 401\n            when :mod:`keystonemiddleware` is configured to\n            defer_auth_decision. Once this is done, it instantiates a user\n            from the generated User model and attaches it to the request\n            context for later access.\n            \"\"\"\n            identity_status = request.headers.get(\n                \"X-Identity-Status\", \"Invalid\"\n            )\n            if identity_status != \"Confirmed\":\n                msg = (\"Couldn't authenticate user '%s' with \"\n                       \"X-Identity-Status '%s'\")\n                self.logger.info(msg % (\n                    request.headers.get(\"X-User-Id\", \"None\"),\n                    request.headers.get(\"X-Identity-Status\", \"None\")\n                ))\n                if not self.config.allow_anonymous_access:\n                    msg = \"Anonymous Access disabled, rejecting %s\"\n                    self.logger.debug(\n                        msg % request.headers.get(\"X-User-Id\", \"None\")\n                    )\n                    raise FlaskKeystoneUnauthorized()\n                else:\n                    self.logger.debug(\"Setting Anonymous user.\")\n                    self._set_anonymous_user()\n                    return\n\n            self._set_user(request)\n\n        return before_request", "response": "Generates the before_request function that will be called before the request is made."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequiring specific configured roles for access to a :mod:`flask` route. :param roles: Role or list of roles to test for access (only one role is required to pass). :type roles: str OR list(str) :raises: FlaskKeystoneForbidden This method will gate a particular endpoint to only be accessed by :class:`FlaskKeystone.User`'s with a particular configured role. If the role given does not exist, or if the user does not have the requested role, a FlaskKeystoneForbidden exception will be thrown, resulting in a 403 response to the client.", "response": "def requires_role(self, roles):\n        \"\"\"\n        Require specific configured roles for access to a :mod:`flask` route.\n\n        :param roles: Role or list of roles to test for access\n                      (only one role is required to pass).\n        :type roles: str OR list(str)\n        :raises: FlaskKeystoneForbidden\n\n        This method will gate a particular endpoint to only be accessed by\n        :class:`FlaskKeystone.User`'s with a particular configured role. If the\n        role given does not exist, or if the user does not have the requested\n        role, a FlaskKeystoneForbidden exception will be thrown, resulting in a\n        403 response to the client.\n        \"\"\"\n        def wrap(f):\n            @wraps(f)\n            def wrapped_f(*args, **kwargs):\n                if isinstance(roles, list):\n                    if any(current_user.has_role(role) for role in roles):\n                        return f(*args, **kwargs)\n\n                elif isinstance(roles, str):\n                    if current_user.has_role(roles):\n                        return f(*args, **kwargs)\n                else:\n                    msg = (\"roles parameter for requires_role on endpoint %s \"\n                           \"should be a list or str, but is type %s.\")\n                    self.logger.error(msg % (\n                        request.path,\n                        type(roles)\n                    ))\n\n                msg = (\"Rejected User '%s' access to '%s' \"\n                       \"due to RBAC. (Requires '%s')\")\n\n                self.logger.info(msg % (\n                    current_user.user_id,\n                    request.path,\n                    roles\n                ))\n\n                raise FlaskKeystoneForbidden()\n\n            return wrapped_f\n        return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequire a user to be validated by Identity to access an endpoint. :raises: FlaskKeystoneUnauthorized This method will gate a particular endpoint to only be accessed by :class:`FlaskKeystone.User`'s. This means that a valid token will need to be passed to grant access. If a User is not authenticated, a FlaskKeystoneUnauthorized will be thrown, resulting in a 401 response to the client.", "response": "def login_required(self, f):\n        \"\"\"\n        Require a user to be validated by Identity to access an endpoint.\n\n        :raises: FlaskKeystoneUnauthorized\n\n        This method will gate a particular endpoint to only be accessed by\n        :class:`FlaskKeystone.User`'s. This means that a valid token will need\n        to be passed to grant access. If a User is not authenticated,\n        a FlaskKeystoneUnauthorized will be thrown, resulting in a 401 response\n        to the client.\n        \"\"\"\n        @wraps(f)\n        def wrapped_f(*args, **kwargs):\n            if current_user.anonymous:\n                msg = (\"Rejected User '%s access to '%s' as user\"\n                       \" could not be authenticated.\")\n                self.logger.warn(msg % (\n                    current_user.user_id,\n                    request.path\n                ))\n                raise FlaskKeystoneUnauthorized()\n            return f(*args, **kwargs)\n        return wrapped_f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a persistent identifier exists.", "response": "def pid_exists(value, pidtype=None):\n    \"\"\"Check if a persistent identifier exists.\n\n    :param value: The PID value.\n    :param pidtype: The pid value (Default: None).\n    :returns: `True` if the PID exists.\n    \"\"\"\n    try:\n        PersistentIdentifier.get(pidtype, value)\n        return True\n    except PIDDoesNotExistError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a new minter.", "response": "def register_minter(self, name, minter):\n        \"\"\"Register a minter.\n\n        :param name: Minter name.\n        :param minter: The new minter.\n        \"\"\"\n        assert name not in self.minters\n        self.minters[name] = minter"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a fetcher. :param name: Fetcher name. :param fetcher: The new fetcher.", "response": "def register_fetcher(self, name, fetcher):\n        \"\"\"Register a fetcher.\n\n        :param name: Fetcher name.\n        :param fetcher: The new fetcher.\n        \"\"\"\n        assert name not in self.fetchers\n        self.fetchers[name] = fetcher"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload minters from an entry point group.", "response": "def load_minters_entry_point_group(self, entry_point_group):\n        \"\"\"Load minters from an entry point group.\n\n        :param entry_point_group: The entrypoint group.\n        \"\"\"\n        for ep in pkg_resources.iter_entry_points(group=entry_point_group):\n            self.register_minter(ep.name, ep.load())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_fetchers_entry_point_group(self, entry_point_group):\n        for ep in pkg_resources.iter_entry_points(group=entry_point_group):\n            self.register_fetcher(ep.name, ep.load())", "response": "Load fetchers from an entry point group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nflask application initialization. Initialize: * The CLI commands. * Initialize the logger (Default: `app.debug`). * Initialize the default admin object link endpoint. (Default: `{\"rec\": \"recordmetadata.details_view\"}` if `invenio-records` is installed, otherwise `{}`). * Register the `pid_exists` template filter. * Initialize extension state. :param app: The Flask application :param minters_entry_point_group: The minters entry point group (Default: None). :param fetchers_entry_point_group: The fetchers entry point group (Default: None). :returns: PIDStore state application.", "response": "def init_app(self, app, minters_entry_point_group=None,\n                 fetchers_entry_point_group=None):\n        \"\"\"Flask application initialization.\n\n        Initialize:\n\n        * The CLI commands.\n\n        * Initialize the logger (Default: `app.debug`).\n\n        * Initialize the default admin object link endpoint.\n            (Default: `{\"rec\": \"recordmetadata.details_view\"}` if\n            `invenio-records` is installed, otherwise `{}`).\n\n        * Register the `pid_exists` template filter.\n\n        * Initialize extension state.\n\n        :param app: The Flask application\n        :param minters_entry_point_group: The minters entry point group\n            (Default: None).\n        :param fetchers_entry_point_group: The fetchers entry point group\n            (Default: None).\n        :returns: PIDStore state application.\n        \"\"\"\n        self.init_config(app)\n        # Initialize CLI\n        app.cli.add_command(cmd)\n\n        # Initialize logger\n        app.config.setdefault('PIDSTORE_APP_LOGGER_HANDLERS', app.debug)\n        if app.config['PIDSTORE_APP_LOGGER_HANDLERS']:\n            for handler in app.logger.handlers:\n                logger.addHandler(handler)\n\n        # Initialize admin object link endpoints.\n        try:\n            pkg_resources.get_distribution('invenio-records')\n            app.config.setdefault('PIDSTORE_OBJECT_ENDPOINTS', dict(\n                rec='recordmetadata.details_view',\n            ))\n        except pkg_resources.DistributionNotFound:\n            app.config.setdefault('PIDSTORE_OBJECT_ENDPOINTS', {})\n\n        # Register template filter\n        app.jinja_env.filters['pid_exists'] = pid_exists\n\n        # Initialize extension state.\n        state = _PIDStoreState(\n            app=app,\n            minters_entry_point_group=minters_entry_point_group,\n            fetchers_entry_point_group=fetchers_entry_point_group,\n        )\n        app.extensions['invenio-pidstore'] = state\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a specific address into the cache", "response": "def import_address(self, address, account=\"*\", rescan=False):\n        \"\"\"\n        param address = address to import\n        param label= account name to use\n        \"\"\"\n        response = self.make_request(\"importaddress\", [address, account, rescan])\n        error = response.get('error')\n        if error is not None:\n            raise Exception(error)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the coordinates of the points at the edge of the rectangle e. g. [ x y x1 y1 x2 y2 )", "response": "def getEdgePoints(self):\n        \"\"\"\n        Returns a list with the coordinates of the points at the edge of the rectangle as tuples.\n        e.g.[(x1,y1),(x2,y2)]\n        The sorting is counterclockwise starting with the lower left corner.\n        Coordinates must be numbers or an exception will be thrown.\n        \"\"\"\n        result = [(float(self.get_x()),float(self.get_y()))]\n        result.append((float(self.get_x())+float(self.get_width()),float(self.get_y())))\n        result.append((float(self.get_x())+float(self.get_width()),float(self.get_y())+float(self.get_height())))\n        result.append((float(self.get_x()),float(self.get_y())+float(self.get_height())))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of the coordinates of the points at the inner edge of a rounded rectangle as tuples.", "response": "def getInnerEdgePoints(self):\n        \"\"\"\n        Returns a list with the coordinates of the points at the inner edge of a rounded rectangle as tuples.\n        e.g.[(x1,y1),(x2,y2)]\n        The sorting is counterclockwise starting with the lower left corner.\n        Coordinates must be numbers or an exception will be thrown.\n        \"\"\"\n        result = []\n        result.append((float(self.get_x()) + float(self.get_rx()), float(self.get_y()) + float(self.get_ry())))\n        result.append((float(self.get_x()) + float(self.get_width()) - float(self.get_rx()), float(self.get_y()) + float(self.get_ry())))\n        result.append((float(self.get_x()) + float(self.get_width()) - float(self.get_rx()), float(self.get_y()) + float(self.get_height()) - float(self.get_ry())))\n        result.append((float(self.get_x()) + float(self.get_rx()), float(self.get_y()) + float(self.get_height()) - float(self.get_ry())))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getBottomRight(self):\n        return (float(self.get_x()) + float(self.get_width()), float(self.get_y()))", "response": "Retrieves a tuple with the x y coordinates of the lower right point of the rect. Requires the width height to be numbers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple with the x y coordinates of the upper left point of the rect. Requires the width height to be numbers", "response": "def getTopLeft(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the upper left point of the rect. \n        Requires the coordinates, width, height to be numbers\n        \"\"\"\n        return (float(self.get_x()), float(self.get_y())+ float(self.get_height()))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple with the x y coordinates of the upper right point of the rect. Requires the width height to be numbers", "response": "def getTopRight(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the upper right point of the rect. \n        Requires the coordinates, width, height to be numbers\n        \"\"\"\n        return (float(self.get_x()) + float(self.get_width()), float(self.get_y()) + float(self.get_height()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef moveToPoint(self, xxx_todo_changeme):\n        (x,y) = xxx_todo_changeme\n        self.set_x(float(self.get_x()) + float(x))\n        self.set_y(float(self.get_y()) + float(y))", "response": "Moves the rect to the point x y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getBottomLeft(self):\n        return (float(self.get_cx()) - float(self.get_r()), float(self.get_cy()) - float(self.get_r()))", "response": "Retrieves a tuple with the x y coordinates of the lower left point of the circle. Requires the radius and the coordinates to be numbers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a tuple with the x y coordinates of the lower right point of the circle. Requires the radius and the coordinates to be numbers", "response": "def getBottomRight(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the lower right point of the circle. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) + float(self.get_r()), float(self.get_cy()) - float(self.get_r()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple with the x y coordinates of the upper left point of the circle. Requires the radius and the coordinates to be numbers", "response": "def getTopLeft(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the upper left point of the circle. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) - float(self.get_r()), float(self.get_cy()) + float(self.get_r()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTopRight(self):\n        return (float(self.get_cx()) + float(self.get_r()), float(self.get_cy()) + float(self.get_r()))", "response": "Returns a tuple with the x y coordinates of the upper right point of the circle. Requires the radius and the coordinates to be numbers"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove the circle to the point x y", "response": "def moveToPoint(self, xxx_todo_changeme1):\n        \"\"\"\n        Moves the circle to the point x,y\n        \"\"\"\n        (x,y) = xxx_todo_changeme1\n        self.set_cx(float(self.get_cx()) + float(x))\n        self.set_cy(float(self.get_cy()) + float(y))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a tuple with the x y coordinates of the lower left point of the ellipse. Requires the radius and the coordinates to be numbers", "response": "def getBottomLeft(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the lower left point of the ellipse. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) - float(self.get_rx()), float(self.get_cy()) - float(self.get_ry()))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a tuple with the x y coordinates of the lower right point of the ellipse. Requires the radius and the coordinates to be numbers", "response": "def getBottomRight(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the lower right point of the ellipse. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) + float(self.get_rx()), float(self.get_cy()) - float(self.get_ry()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a tuple with the x y coordinates of the upper left point of the ellipse. Requires the radius and the coordinates to be numbers", "response": "def getTopLeft(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the upper left point of the ellipse. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) - float(self.get_rx()), float(self.get_cy()) + float(self.get_ry()))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a tuple with the x y coordinates of the upper right point of the ellipse. Requires the radius and the coordinates to be numbers", "response": "def getTopRight(self):\n        \"\"\"\n        Retrieves a tuple with the x,y coordinates of the upper right point of the ellipse. \n        Requires the radius and the coordinates to be numbers\n        \"\"\"\n        return (float(self.get_cx()) + float(self.get_rx()), float(self.get_cy()) + float(self.get_ry()))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getBottomLeft(self):\n        x1 = float(self.get_x1())\n        x2 = float(self.get_x2())\n        y1 = float(self.get_y1())\n        y2 = float(self.get_y2())\n        if x1 < x2:\n            if y1 < y2:\n                return (x1, y1)\n            else:\n                return (x1, y2)\n        else:\n            if y1 < y2:\n                return (x2, y1)\n            else:\n                return (x2, y2)", "response": "Retrieves the bottom left coordinate of the line as tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves the line to the point x y", "response": "def moveToPoint(self, xxx_todo_changeme2):\n        \"\"\"\n        Moves the line to the point x,y\n        \"\"\"\n        (x,y) = xxx_todo_changeme2\n        self.set_x1(float(self.get_x1()) + float(x))\n        self.set_x2(float(self.get_x2()) + float(x))\n        self.set_y1(float(self.get_y1()) + float(y))\n        self.set_y2(float(self.get_y2()) + float(y))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a circle object with the specified attributes", "response": "def createCircle(self, cx, cy, r, strokewidth=1, stroke='black', fill='none'):\n        \"\"\"\n        Creates a circle\n        @type  cx: string or int\n        @param cx:  starting x-coordinate  \n        @type  cy: string or int\n        @param cy:  starting y-coordinate \n        @type  r: string or int\n        @param r:  radius \n        @type  strokewidth: string or int\n        @param strokewidth:  width of the pen used to draw\n        @type  stroke: string (either css constants like \"black\" or numerical values like \"#FFFFFF\")\n        @param stroke:  color with which to draw the outer limits\n        @type  fill: string (either css constants like \"black\" or numerical values like \"#FFFFFF\")\n        @param fill:  color with which to fill the element (default: no filling)\n        @return:  a circle object\n        \"\"\"\n        style_dict = {'fill':fill, 'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        c = Circle(cx, cy, r)\n        c.set_style(myStyle.getStyle())\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createEllipse(self, cx, cy, rx, ry, strokewidth=1, stroke='black', fill='none'):\n        style_dict = {'fill':fill, 'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        e = Ellipse(cx, cy, rx, ry)\n        e.set_style(myStyle.getStyle())\n        return e", "response": "Creates an ellipse object for the current species."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createRect(self, x, y, width, height, rx=None, ry=None, strokewidth=1, stroke='black', fill='none'):\n        style_dict = {'fill':fill, 'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        r = Rect(x, y, width, height, rx, ry)\n        r.set_style(myStyle.getStyle())\n        return r", "response": "Creates a Rectangle object for the given rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a polygon object for the current node.", "response": "def createPolygon(self, points, strokewidth=1, stroke='black', fill='none'):\n        \"\"\"\n        Creates a Polygon\n        @type  points: string in the form \"x1,y1 x2,y2 x3,y3\"\n        @param points:  all points relevant to the polygon\n        @type  strokewidth: string or int\n        @param strokewidth:  width of the pen used to draw\n        @type  stroke: string (either css constants like \"black\" or numerical values like \"#FFFFFF\")\n        @param stroke:  color with which to draw the outer limits\n        @type  fill: string (either css constants like \"black\" or numerical values like \"#FFFFFF\")\n        @param fill:  color with which to fill the element (default: no filling)\n        @return:  a polygon object\n        \"\"\"\n        style_dict = {'fill':fill, 'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        p = Polygon(points=points)\n        p.set_style(myStyle.getStyle())\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a polyline object for the given set of points.", "response": "def createPolyline(self, points, strokewidth=1, stroke='black'):\n        \"\"\"\n        Creates a Polyline\n        @type  points: string in the form \"x1,y1 x2,y2 x3,y3\"\n        @param points:  all points relevant to the polygon\n        @type  strokewidth: string or int\n        @param strokewidth:  width of the pen used to draw\n        @type  stroke: string (either css constants like \"black\" or numerical values like \"#FFFFFF\")\n        @param stroke:  color with which to draw the outer limits\n        @return:  a polyline object\n        \"\"\"\n        style_dict = {'fill':'none', 'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        p = Polyline(points=points)\n        p.set_style(myStyle.getStyle())\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createLine(self, x1, y1, x2, y2, strokewidth=1, stroke=\"black\"):\n        style_dict = {'stroke-width':strokewidth, 'stroke':stroke}\n        myStyle = StyleBuilder(style_dict)\n        l = Line(x1, y1, x2, y2)\n        l.set_style(myStyle.getStyle())\n        return l", "response": "Creates a line object that is a line with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uncolorize(text):\n    match = re.match('(.*)\\033\\[[0-9;]+m(.+?)\\033\\[0m(.*)', text)\n    try:\n        return ''.join(match.groups())\n    except:\n        return text", "response": "uncolorize text into a single color"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tr(text, kword, color):\n    return re.sub(kword, colorize(BgColor.Null, Base.Null, color, kword), text)", "response": "A simple wrapper around tr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cprint(*text, **kwargs):\n    print(\n        colorize(\n            kwargs.get('bg')   or BgColor.Null,\n            kwargs.get('base') or Base.Null,\n            kwargs.get('fg')   or FgColor.Null,\n            *text\n        ),\n        file=kwargs.get('file') or sys.stdout\n    )", "response": "Print text to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode(data, version=0, level=QR_ECLEVEL_L, hint=QR_MODE_8,\n           case_sensitive=True):\n    \"\"\"Creates a QR-Code from string data.\n    \n    Args:\n      data: string: The data to encode in a QR-code. If a unicode string is\n          supplied, it will be encoded in UTF-8.\n      version: int: The minimum version to use. If set to 0, the library picks\n          the smallest version that the data fits in.\n      level: int: Error correction level. Defaults to 'L'.\n      hint: int: The type of data to encode. Either QR_MODE_8 or QR_MODE_KANJI.\n      case_sensitive: bool: Should string data be encoded case-preserving?\n    Returns:\n      A (version, size, image) tuple, where image is a size*size PIL image of\n      the QR-code.\n    \"\"\"\n    if isinstance(data, unicode):\n        data = data.encode('utf8')\n    elif not isinstance(data, basestring):\n        raise ValueError('data argument must be a string.')\n    version = int(version)\n    if level not in levels:\n        raise ValueError('Invalid error-correction level.')\n    if hint not in hints:\n        raise ValueError('Invalid encoding mode.')\n    if case_sensitive:\n        version, size, data = _encode(data, version, level, hint, True)\n    else:\n        version, size, data = _encode(data, version, level, hint, False)\n    \n    im = Image.frombytes('L', (size, size), data)\n    return (version, size, im)", "response": "Encodes a string into a QR - code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a string data to a QR - code with the specified dimensions.", "response": "def encode_scaled(data, size, version=0, level=QR_ECLEVEL_L, hint=QR_MODE_8,\n                  case_sensitive=True):\n    \"\"\"Creates a QR-code from string data, resized to the specified dimensions.\n\n    Args:\n      data: string: The data to encode in a QR-code. If a unicode string is\n          supplied, it will be encoded in UTF-8.\n      size: int: Output size. If this is not an exact multiple of the QR-code's\n          dimensions, padding will be added. If this is smaller than the\n          QR-code's dimensions, it is ignored.\n      version: int: The minimum version to use. If set to 0, the library picks\n          the smallest version that the data fits in.\n      level: int: Error correction level. Defaults to 'L'.\n      hint: int: The type of data to encode. Either QR_MODE_8 or QR_MODE_KANJI.\n      case_sensitive: bool: Should string data be encoded case-preserving?\n    Returns:\n      A (version, size, image) tuple, where image is a size*size PIL image of\n      the QR-code.\n    \"\"\"\n    version, src_size, im = encode(data, version, level, hint, case_sensitive)\n    if size < src_size:\n      size = src_size\n    qr_size = (size / src_size) * src_size\n    im = im.resize((qr_size, qr_size), Image.NEAREST)\n    pad = (size - qr_size) / 2\n    ret = Image.new(\"L\", (size, size), 255)\n    ret.paste(im, (pad, pad))\n    \n    return (version, size, ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rotate(self, angle):\n        perp = Vector(-self.y, self.x)\n        angle = angle * math.pi / 180.0\n        c, s = math.cos(angle), math.sin(angle)\n        return Vector(self.x * c + perp.x * s, self.y * c + perp.y * s)", "response": "Rotates self counterclockwise by angle \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef moveTo(self, vector):\n        self._position = vector\n        if self.isPenDown(): \n            self._pointsOfPolyline.append(self._position)", "response": "Moves the turtle to the new position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise the pen. Any movement will not draw lines till pen is lowered again.", "response": "def penUp(self):\n        \"\"\" Raises the pen. Any movement will not draw lines till pen is lowered again.\n        \"\"\"\n        if self._penDown==True:\n            self._penDown = False\n            self._addPolylineToElements()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving the turtle by distance in the direction of the turtle.", "response": "def _move(self, distance):\n        \"\"\" Moves the turtle by distance in the direction it is facing. \n        If the pen is lowered it will also add to the currently drawn polyline.\n        \"\"\"\n        self._position = self._position + self._orient * distance  \n        if self.isPenDown(): \n            x = round(self._position.x, 2)\n            y = round(self._position.y, 2)\n            self._pointsOfPolyline.append(Vector(x, y))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _addPolylineToElements(self):\n        if (len(self._pointsOfPolyline) > 1):\n            s = ''\n            for point in self._pointsOfPolyline:\n                s += str(point) + ' '#str(point.x) + ',' + str(point.y) + ' '\n            p = Polyline(s)\n            p.set_style('fill:' + self.fill + '; stroke:' + self.stroke + '; stroke-width:' + self.strokeWidth) \n            self._svgElements.append(p)\n        self._pointsOfPolyline = []\n        self._pointsOfPolyline.append(Vector(self._position.x, self._position.y))", "response": "Adds a new Polyline element to the SVG element list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getXML(self):\n        s = ''\n        for element in self._svgElements:\n            s += element.getXML()\n        return s", "response": "Retrieves the pysvg elements that make up the turtles path and returns them as an xml representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the paths of the turtle to an existing svg container.", "response": "def addTurtlePathToSVG(self, svgContainer):\n        \"\"\"Adds the paths of the turtle to an existing svg container.\n        \"\"\"\n        for element in self.getSVGElements():\n            svgContainer.addElement(element)\n        return svgContainer"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the content of the template", "response": "def _get_content(self, context):\n        \"\"\"\n                Add the csrf_token_value because the mixin use render_to_string\n                and not render.\n        \"\"\"\n        self._valid_template()\n        context.update({\n            \"csrf_token_value\": get_token(self.request)\n        })\n        return render_to_string(self.get_template_names(), context)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normpath(path, keep_trailing=False):\n    new_path = k_paths.normpath(path)\n    if keep_trailing and path.endswith(\"/\") and not new_path.endswith(\"/\"):\n        new_path = new_path + \"/\"\n    if not new_path.startswith('/'):\n        return '/' + new_path\n    return new_path", "response": "Really normalize the path by adding a missing leading slash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(*filenames, **kwargs):\n    encoding = kwargs.get('encoding', 'utf-8')\n    sep = kwargs.get('sep', '\\n')\n    buf = []\n    for filename in filenames:\n        if path.splitext(filename)[1] == \".md\":\n            try:\n                import pypandoc\n                buf.append(pypandoc.convert_file(filename, 'rst'))\n                continue\n            except:\n                with io.open(filename, encoding=encoding) as f:\n                    buf.append(f.read())\n        with io.open(filename, encoding=encoding) as f:\n            buf.append(f.read())\n    return sep.join(buf)", "response": "Reads the contents of the files in filenames into a single string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, pid_type, pid_value, pid_provider=None,\n               status=PIDStatus.NEW, object_type=None, object_uuid=None,):\n        \"\"\"Create a new persistent identifier with specific type and value.\n\n        :param pid_type: Persistent identifier type.\n        :param pid_value: Persistent identifier value.\n        :param pid_provider: Persistent identifier provider. (default: None).\n        :param status: Current PID status.\n            (Default: :attr:`invenio_pidstore.models.PIDStatus.NEW`)\n        :param object_type: The object type is a string that identify its type.\n            (default: None).\n        :param object_uuid: The object UUID. (default: None).\n        :returns: A :class:`invenio_pidstore.models.PersistentIdentifier`\n            instance.\n        \"\"\"\n        try:\n            with db.session.begin_nested():\n                obj = cls(pid_type=pid_type,\n                          pid_value=pid_value,\n                          pid_provider=pid_provider,\n                          status=status)\n                if object_type and object_uuid:\n                    obj.assign(object_type, object_uuid)\n                db.session.add(obj)\n            logger.info(\"Created PID {0}:{1}\".format(pid_type, pid_value),\n                        extra={'pid': obj})\n        except IntegrityError:\n            logger.exception(\n                \"PID already exists: {0}:{1}\".format(pid_type, pid_value),\n                extra=dict(\n                    pid_type=pid_type,\n                    pid_value=pid_value,\n                    pid_provider=pid_provider,\n                    status=status,\n                    object_type=object_type,\n                    object_uuid=object_uuid,\n                ))\n            raise PIDAlreadyExists(pid_type=pid_type, pid_value=pid_value)\n        except SQLAlchemyError:\n            logger.exception(\n                \"Failed to create PID: {0}:{1}\".format(pid_type, pid_value),\n                extra=dict(\n                    pid_type=pid_type,\n                    pid_value=pid_value,\n                    pid_provider=pid_provider,\n                    status=status,\n                    object_type=object_type,\n                    object_uuid=object_uuid,\n                ))\n            raise\n        return obj", "response": "Creates a new persistent identifier with specific type and value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a persistent identifier.", "response": "def get(cls, pid_type, pid_value, pid_provider=None):\n        \"\"\"Get persistent identifier.\n\n        :param pid_type: Persistent identifier type.\n        :param pid_value: Persistent identifier value.\n        :param pid_provider: Persistent identifier provider. (default: None).\n        :raises: :exc:`invenio_pidstore.errors.PIDDoesNotExistError` if no\n            PID is found.\n        :returns: A :class:`invenio_pidstore.models.PersistentIdentifier`\n            instance.\n        \"\"\"\n        try:\n            args = dict(pid_type=pid_type, pid_value=six.text_type(pid_value))\n            if pid_provider:\n                args['pid_provider'] = pid_provider\n            return cls.query.filter_by(**args).one()\n        except NoResultFound:\n            raise PIDDoesNotExistError(pid_type, pid_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_object(cls, pid_type, object_type, object_uuid):\n        try:\n            return cls.query.filter_by(\n                pid_type=pid_type,\n                object_type=object_type,\n                object_uuid=object_uuid\n            ).one()\n        except NoResultFound:\n            raise PIDDoesNotExistError(pid_type, None)", "response": "Get a persistent identifier for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current assigned object UUID.", "response": "def get_assigned_object(self, object_type=None):\n        \"\"\"Return the current assigned object UUID.\n\n        :param object_type: If it's specified, returns only if the PID\n            object_type is the same, otherwise returns None. (default: None).\n        :returns: The object UUID.\n        \"\"\"\n        if object_type is not None:\n            if self.object_type == object_type:\n                return self.object_uuid\n            else:\n                return None\n        return self.object_uuid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assign(self, object_type, object_uuid, overwrite=False):\n        if self.is_deleted():\n            raise PIDInvalidAction(\n                \"You cannot assign objects to a deleted/redirected persistent\"\n                \" identifier.\"\n            )\n\n        if not isinstance(object_uuid, uuid.UUID):\n            object_uuid = uuid.UUID(object_uuid)\n\n        if self.object_type or self.object_uuid:\n            # The object is already assigned to this pid.\n            if object_type == self.object_type and \\\n               object_uuid == self.object_uuid:\n                return True\n            if not overwrite:\n                raise PIDObjectAlreadyAssigned(object_type,\n                                               object_uuid)\n            self.unassign()\n\n        try:\n            with db.session.begin_nested():\n                self.object_type = object_type\n                self.object_uuid = object_uuid\n                db.session.add(self)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to assign {0}:{1}\".format(\n                object_type, object_uuid), extra=dict(pid=self))\n            raise\n        logger.info(\"Assigned object {0}:{1}\".format(\n            object_type, object_uuid), extra=dict(pid=self))\n        return True", "response": "Assign this persistent identifier to a given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef redirect(self, pid):\n        if not (self.is_registered() or self.is_redirected()):\n            raise PIDInvalidAction(\"Persistent identifier is not registered.\")\n\n        try:\n            with db.session.begin_nested():\n                if self.is_redirected():\n                    r = Redirect.query.get(self.object_uuid)\n                    r.pid = pid\n                else:\n                    with db.session.begin_nested():\n                        r = Redirect(pid=pid)\n                        db.session.add(r)\n\n                self.status = PIDStatus.REDIRECTED\n                self.object_type = None\n                self.object_uuid = r.id\n                db.session.add(self)\n        except IntegrityError:\n            raise PIDDoesNotExistError(pid.pid_type, pid.pid_value)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to redirect to {0}\".format(\n                pid), extra=dict(pid=self))\n            raise\n        logger.info(\"Redirected PID to {0}\".format(pid), extra=dict(pid=self))\n        return True", "response": "Redirect the persistent identifier to another persistent identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reserve(self):\n        if not (self.is_new() or self.is_reserved()):\n            raise PIDInvalidAction(\n                \"Persistent identifier is not new or reserved.\")\n\n        try:\n            with db.session.begin_nested():\n                self.status = PIDStatus.RESERVED\n                db.session.add(self)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to reserve PID.\", extra=dict(pid=self))\n            raise\n        logger.info(\"Reserved PID.\", extra=dict(pid=self))\n        return True", "response": "Reserve the persistent identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self):\n        if self.is_registered() or self.is_deleted() or self.is_redirected():\n            raise PIDInvalidAction(\n                \"Persistent identifier has already been registered\"\n                \" or is deleted.\")\n\n        try:\n            with db.session.begin_nested():\n                self.status = PIDStatus.REGISTERED\n                db.session.add(self)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to register PID.\", extra=dict(pid=self))\n            raise\n        logger.info(\"Registered PID.\", extra=dict(pid=self))\n        return True", "response": "Registers the persistent identifier with the provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self):\n        removed = False\n        try:\n            with db.session.begin_nested():\n                if self.is_new():\n                    # New persistent identifier which haven't been registered\n                    # yet.\n                    db.session.delete(self)\n                    removed = True\n                else:\n                    self.status = PIDStatus.DELETED\n                    db.session.add(self)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to delete PID.\", extra=dict(pid=self))\n            raise\n\n        if removed:\n            logger.info(\"Deleted PID (removed).\", extra=dict(pid=self))\n        else:\n            logger.info(\"Deleted PID.\", extra=dict(pid=self))\n        return True", "response": "Delete the persistent identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsynchronizing persistent identifier status.", "response": "def sync_status(self, status):\n        \"\"\"Synchronize persistent identifier status.\n\n        Used when the provider uses an external service, which might have been\n        modified outside of our system.\n\n        :param status: The new status to set.\n        :returns: `True` if the PID is successfully sync.\n        \"\"\"\n        if self.status == status:\n            return True\n\n        try:\n            with db.session.begin_nested():\n                self.status = status\n                db.session.add(self)\n        except SQLAlchemyError:\n            logger.exception(\"Failed to sync status {0}.\".format(status),\n                             extra=dict(pid=self))\n            raise\n        logger.info(\"Synced PID status to {0}.\".format(status),\n                    extra=dict(pid=self))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns next available record identifier.", "response": "def next(cls):\n        \"\"\"Return next available record identifier.\"\"\"\n        try:\n            with db.session.begin_nested():\n                obj = cls()\n                db.session.add(obj)\n        except IntegrityError:  # pragma: no cover\n            with db.session.begin_nested():\n                # Someone has likely modified the table without using the\n                # models API. Let's fix the problem.\n                cls._set_sequence(cls.max())\n                obj = cls()\n                db.session.add(obj)\n        return obj.recid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget max record identifier.", "response": "def max(cls):\n        \"\"\"Get max record identifier.\"\"\"\n        max_recid = db.session.query(func.max(cls.recid)).scalar()\n        return max_recid if max_recid else 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a record identifier.", "response": "def insert(cls, val):\n        \"\"\"Insert a record identifier.\n\n        :param val: The `recid` column value to insert.\n        \"\"\"\n        with db.session.begin_nested():\n            obj = cls(recid=val)\n            db.session.add(obj)\n            cls._set_sequence(cls.max())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve(self, pid_value):\n        pid = PersistentIdentifier.get(self.pid_type, pid_value)\n\n        if pid.is_new() or pid.is_reserved():\n            raise PIDUnregistered(pid)\n\n        if pid.is_deleted():\n            obj_id = pid.get_assigned_object(object_type=self.object_type)\n            try:\n                obj = self.object_getter(obj_id) if obj_id else None\n            except NoResultFound:\n                obj = None\n            raise PIDDeletedError(pid, obj)\n\n        if pid.is_redirected():\n            raise PIDRedirectedError(pid, pid.get_redirect())\n\n        obj_id = pid.get_assigned_object(object_type=self.object_type)\n        if not obj_id:\n            raise PIDMissingObjectError(self.pid_type, pid_value)\n\n        return pid, self.object_getter(obj_id)", "response": "Resolve a persistent identifier to an internal object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new sheet with the given title.", "response": "def create_sheet(self, title):\n        \"\"\" Create a sheet with the given title. This does not check if\n        another sheet by the same name already exists. \"\"\"\n        ws = self.conn.sheets_service.AddWorksheet(title, 10, 10, self.id)\n        self._wsf = None\n        return Sheet(self, ws)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the spreadsheet with the given title.", "response": "def open(cls, title, conn=None, google_user=None,\n             google_password=None):\n        \"\"\" Open the spreadsheet named ``title``. If no spreadsheet with\n        that name exists, a new one will be created. \"\"\"\n        spreadsheet = cls.by_title(title, conn=conn, google_user=google_user,\n                                   google_password=google_password)\n        if spreadsheet is None:\n            spreadsheet = cls.create(title, conn=conn, google_user=google_user,\n                                     google_password=google_password)\n        return spreadsheet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, title, conn=None, google_user=None,\n               google_password=None):\n        \"\"\" Create a new spreadsheet with the given ``title``. \"\"\"\n        conn = Connection.connect(conn=conn, google_user=google_user,\n                                  google_password=google_password)\n        res = Resource(type='spreadsheet', title=title)\n        res = conn.docs_client.CreateResource(res)\n        id = res.id.text.rsplit('%3A', 1)[-1]\n        return cls(id, conn, resource=res)", "response": "Create a new spreadsheet with the given title."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a spreadsheet via its resource ID.", "response": "def by_id(cls, id, conn=None, google_user=None,\n              google_password=None):\n        \"\"\" Open a spreadsheet via its resource ID. This is more precise\n        than opening a document by title, and should be used with\n        preference. \"\"\"\n        conn = Connection.connect(conn=conn, google_user=google_user,\n                                  google_password=google_password)\n        return cls(id=id, conn=conn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new object containing the first document with the given title that is returned by document search.", "response": "def by_title(cls, title, conn=None, google_user=None,\n                 google_password=None):\n        \"\"\" Open the first document with the given ``title`` that is\n        returned by document search. \"\"\"\n        conn = Connection.connect(conn=conn, google_user=google_user,\n                                  google_password=google_password)\n        q = DocsQuery(categories=['spreadsheet'], title=title)\n        feed = conn.docs_client.GetResources(q=q)\n        for entry in feed.entry:\n            if entry.title.text == title:\n                id = entry.id.text.rsplit('%3A', 1)[-1]\n                return cls.by_id(id, conn=conn)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npost initialization for UI application.", "response": "def init_ui(state):\n    \"\"\"Post initialization for UI application.\"\"\"\n    app = state.app\n    init_common(app)\n\n    # Register blueprint for templates\n    app.register_blueprint(\n        blueprint, url_prefix=app.config['USERPROFILES_PROFILE_URL'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nviewing for editing a profile.", "response": "def profile():\n    \"\"\"View for editing a profile.\"\"\"\n    # Create forms\n    verification_form = VerificationForm(formdata=None, prefix=\"verification\")\n    profile_form = profile_form_factory()\n\n    # Process forms\n    form = request.form.get('submit', None)\n    if form == 'profile':\n        handle_profile_form(profile_form)\n    elif form == 'verification':\n        handle_verification_form(verification_form)\n\n    return render_template(\n        current_app.config['USERPROFILES_PROFILE_TEMPLATE'],\n        profile_form=profile_form,\n        verification_form=verification_form,)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a profile form.", "response": "def profile_form_factory():\n    \"\"\"Create a profile form.\"\"\"\n    if current_app.config['USERPROFILES_EMAIL_ENABLED']:\n        return EmailProfileForm(\n            formdata=None,\n            username=current_userprofile.username,\n            full_name=current_userprofile.full_name,\n            email=current_user.email,\n            email_repeat=current_user.email,\n            prefix='profile', )\n    else:\n        return ProfileForm(\n            formdata=None,\n            obj=current_userprofile,\n            prefix='profile', )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle email sending verification form.", "response": "def handle_verification_form(form):\n    \"\"\"Handle email sending verification form.\"\"\"\n    form.process(formdata=request.form)\n\n    if form.validate_on_submit():\n        send_confirmation_instructions(current_user)\n        # NOTE: Flash message.\n        flash(_(\"Verification email sent.\"), category=\"success\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_profile_form(form):\n    form.process(formdata=request.form)\n\n    if form.validate_on_submit():\n        email_changed = False\n        with db.session.begin_nested():\n            # Update profile.\n            current_userprofile.username = form.username.data\n            current_userprofile.full_name = form.full_name.data\n            db.session.add(current_userprofile)\n\n            # Update email\n            if current_app.config['USERPROFILES_EMAIL_ENABLED'] and \\\n               form.email.data != current_user.email:\n                current_user.email = form.email.data\n                current_user.confirmed_at = None\n                db.session.add(current_user)\n                email_changed = True\n        db.session.commit()\n\n        if email_changed:\n            send_confirmation_instructions(current_user)\n            # NOTE: Flash message after successful update of profile.\n            flash(_('Profile was updated. We have sent a verification '\n                    'email to %(email)s. Please check it.',\n                    email=current_user.email),\n                  category='success')\n        else:\n            # NOTE: Flash message after successful update of profile.\n            flash(_('Profile was updated.'), category='success')", "response": "Handle profile update form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck for errors on data payload.", "response": "def check_errors(self, data):\n        \"\"\"Check for errors on data payload.\"\"\"\n\n        if (type(data) == dict and 'status' in data.keys()\n            and data['status'] == 'failed'):\n            if data.get('exception_msg') and 'last_id' in data.get('exception_msg'):\n                raise PyBossaServerNoKeysetPagination\n            else:\n                raise Error(data)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_text(self, text):\n        if not self.is_token_set:\n            raise ValueError('TelepythClient: Access token is not set!')\n\n        stream = StringIO()\n        stream.write(text)\n        stream.seek(0)\n\n        return self(stream)", "response": "Send text message to telegram user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender matplotlib figure into temporary bytes buffer and then send it to telegram user.", "response": "def send_figure(self, fig, caption=''):\n        \"\"\"Render matplotlib figure into temporary bytes buffer and then send\n        it to telegram user.\n\n        :param fig: matplotlib figure object.\n        :param caption: text caption of picture.\n        :return: status code on error.\n        \"\"\"\n        if not self.is_token_set:\n            raise ValueError('TelepythClient: Access token is not set!')\n\n        figure = BytesIO()\n        fig.savefig(figure, format='png')\n        figure.seek(0)\n\n        parts = [ContentDisposition('caption', caption),\n                 ContentDisposition('figure', figure, filename=\"figure.png\",\n                                    content_type='image/png')]\n\n        form = MultipartFormData(*parts)\n        content_type = 'multipart/form-data; boundary=%s' % form.boundary\n\n        url = self.base_url + self.access_token\n        req = Request(url, method='POST')\n        req.add_header('Content-Type', content_type)\n        req.add_header('User-Agent', __user_agent__ + '/' + __version__)\n        req.data = form().read()\n\n        res = urlopen(req)\n\n        return res.getcode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prune_clusters(clusters, index, n=3):\n    torem = set(c for c in clusters if c.size < n)\n    pruned_clusters = [c for c in clusters if c.size >= n]\n    terms_torem = []\n    for term, clusters in index.items():\n        index[term] = clusters - torem\n        if len(index[term]) == 0:\n            terms_torem.append(term)\n    for t in terms_torem:\n        del index[t]\n    return pruned_clusters, index", "response": "Delete clusters with fewer than n elements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef monitor(self, field, callback, poll_interval=None):\n        poll_interval = poll_interval or self.api.poll_interval\n\n        monitor = self.monitor_class(\n            resource=self,\n            field=field,\n            callback=callback,\n            poll_interval=poll_interval,\n            event_queue=self.api.event_queue,\n            poll_pool=self.api.poll_pool,\n        )\n        monitor.start()\n        return monitor", "response": "Monitor the state of a specific field for change and execute callback when a change is detected."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_form_factory(Form):\n    class CsrfDisabledProfileForm(ProfileForm):\n        \"\"\"Subclass of ProfileForm to disable CSRF token in the inner form.\n\n        This class will always be a inner form field of the parent class\n        `Form`. The parent will add/remove the CSRF token in the form.\n        \"\"\"\n\n        def __init__(self, *args, **kwargs):\n            \"\"\"Initialize the object by hardcoding CSRF token to false.\"\"\"\n            kwargs = _update_with_csrf_disabled(kwargs)\n            super(CsrfDisabledProfileForm, self).__init__(*args, **kwargs)\n\n    class RegisterForm(Form):\n        \"\"\"RegisterForm extended with UserProfile details.\"\"\"\n\n        profile = FormField(CsrfDisabledProfileForm, separator='.')\n\n    return RegisterForm", "response": "Factory for creating an extended user registration form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_with_csrf_disabled(d=None):\n    if d is None:\n        d = {}\n\n    import flask_wtf\n    from pkg_resources import parse_version\n    supports_meta = parse_version(flask_wtf.__version__) >= parse_version(\n        \"0.14.0\")\n    if supports_meta:\n        d.setdefault('meta', {})\n        d['meta'].update({'csrf': False})\n    else:\n        d['csrf_enabled'] = False\n    return d", "response": "Update the input dict with CSRF disabled depending on WTF - Form version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_username(form, field):\n        try:\n            validate_username(field.data)\n        except ValueError as e:\n            raise ValidationError(e)\n\n        try:\n            user_profile = UserProfile.get_by_username(field.data)\n            if current_userprofile.is_anonymous or \\\n                    (current_userprofile.user_id != user_profile.user_id and\n                     field.data != current_userprofile.username):\n                # NOTE: Form validation error.\n                raise ValidationError(_('Username already exists.'))\n        except NoResultFound:\n            return", "response": "Wrap username validator for WTForms."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_pages(pages, pagenum, pagename):\n    if pagenum:\n        try:\n            pages = [list(pages)[pagenum - 1]]\n        except IndexError:\n            raise IndexError('Invalid page number: %d' % pagenum)\n\n    if pagename:\n        pages = [page for page in pages if page.name == pagename]\n        if pages == []:\n            raise IndexError('Page not found: pagename=%s' % pagename)\n\n    return pages", "response": "Filter the list of Choices pages by pagenum and pagename"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_img(visio_filename, image_filename, pagenum=None, pagename=None):\n    # visio requires absolute path\n    image_pathname = os.path.abspath(image_filename)\n\n    if not os.path.isdir(os.path.dirname(image_pathname)):\n        msg = 'Could not write image file: %s' % image_filename\n        raise IOError(msg)\n\n    with VisioFile.Open(visio_filename) as visio:\n        pages = filter_pages(visio.pages, pagenum, pagename)\n        try:\n            if len(pages) == 1:\n                pages[0].Export(image_pathname)\n            else:\n                digits = int(log(len(pages), 10)) + 1\n                basename, ext = os.path.splitext(image_pathname)\n                filename_format = \"%s%%0%dd%s\" % (basename, digits, ext)\n\n                for i, page in enumerate(pages):\n                    filename = filename_format % (i + 1)\n                    page.Export(filename)\n        except Exception:\n            raise IOError('Could not write image: %s' % image_pathname)", "response": "Exports images from visio file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_options(args):\n    usage = 'usage: %prog [options] visio_filename image_filename'\n    parser = OptionParser(usage=usage)\n    parser.add_option('-p', '--page', action='store',\n                      type='int', dest='pagenum',\n                      help='pick a page by page number')\n    parser.add_option('-n', '--name', action='store',\n                      type='string', dest='pagename',\n                      help='pick a page by page name')\n    options, argv = parser.parse_args(args)\n\n    if options.pagenum and options.pagename:\n        parser.error('options --page and --name are mutually exclusive')\n\n    if len(argv) != 2:\n        parser.print_usage(sys.stderr)\n        parser.exit()\n\n    output_ext = os.path.splitext(argv[1])[1].lower()\n    if output_ext not in ('.gif', '.jpg', '.png'):\n        parser.error('Unsupported image format: %s' % argv[1])\n\n    return options, argv", "response": "Parses command line options and returns options and argv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport providers classes by paths given in SITEMETRICS_PROVIDERS setting.", "response": "def get_custom_providers():\n    \"\"\"Imports providers classes by paths given in SITEMETRICS_PROVIDERS setting.\"\"\"\n\n    providers = getattr(settings, 'SITEMETRICS_PROVIDERS', False)\n\n    if not providers:\n        return []\n\n    p_clss = []\n    for provider_path in providers:\n        path_splitted = provider_path.split('.')\n        mod = import_module('.'.join(path_splitted[:-1]))\n        p_cls = getattr(mod, path_splitted[-1])\n        p_clss.append(p_cls)\n    return p_clss"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __query(cls, url):\n        try:\n            return urllib2.urlopen(url).read().decode('utf-8').replace('\\n', '')\n        except urllib2.HTTPError:\n            _, exception, _ = sys.exc_info()\n            if cls.__debug:\n                print('HTTPError = ' + str(exception.code))\n        except urllib2.URLError:\n            _, exception, _ = sys.exc_info()\n            if cls.__debug:\n                print('URLError = ' + str(exception.reason))\n        except Exception:\n            _, exception, _ = sys.exc_info()\n            if cls.__debug:\n                print('generic exception: ' + str(exception))\n                raise\n            pass\n        return \"inval\"", "response": "Reads a URL and returns the content of it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a valid SID", "response": "def get_sid(self):\n        \"\"\"Returns a valid SID\"\"\"\n        base_url = u'%s/login_sid.lua' % self.__fritz_url\n        get_challenge = None\n        try:\n            get_challenge = urllib2.urlopen(base_url).read().decode('ascii')\n        except urllib2.HTTPError as exception:\n            print('HTTPError = ' + str(exception.code))\n        except urllib2.URLError as  exception:\n            print('URLError = ' + str(exception.reason))\n        except Exception as exception:\n            print('generic exception: ' + str(exception))\n            raise\n\n\n        challenge = get_challenge.split(\n            '<Challenge>')[1].split('</Challenge>')[0]\n        challenge_b = (\n            challenge + '-' + self.__password).encode().decode('iso-8859-1').encode('utf-16le')\n\n        md5hash = hashlib.md5()\n        md5hash.update(challenge_b)\n\n        response_b = challenge + '-' + md5hash.hexdigest().lower()\n        get_sid = urllib2.urlopen('%s?%sresponse=%s' % (base_url, self.__username_query, response_b)).read().decode('utf-8')\n        self.sid = get_sid.split('<SID>')[1].split('</SID>')[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef switch_onoff(self, device, status):\n        if status == 1 or status == True or status == '1':\n            return self.switch_on(device)\n        else:\n            return self.switch_off(device)", "response": "Switch a Socket on or off."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef switch_toggle(self, device):\n        state = self.get_state(device)\n        if(state == '1'):\n            return self.switch_off(device)\n\n        elif(state == '0'):\n            return self.switch_on(device)\n        else:\n            return state", "response": "Toggles the current state of the given device"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the Power in Watt", "response": "def get_power(self):\n        \"\"\"Returns the Power in Watt\"\"\"\n        power_dict = self.get_power_all()\n        for device in power_dict.keys():\n            power_dict[device] = float(power_dict[device]) / 1000.0\n        return power_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_device_names(self):\n        dev_names = {}\n        for device in self.get_device_ids():\n            dev_names[device] = self.get_device_name(device)\n        return dev_names", "response": "Returns a Dict with devicenames"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the temperature in 0. 1 \u00b0C for a single device", "response": "def get_temperature_single(self, device):\n        \"\"\"Returns the temperature in 0.1 \u00b0C for a single device\"\"\"\n        temp_str = self.__query_cmd('gettemperature', device)\n        if temp_str.lstrip('-').isdigit():\n            return float(temp_str) / 10.0\n        return 'inval'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the power in mW for all devices", "response": "def get_power_all(self):\n        \"\"\"Returns the power in mW for all devices\"\"\"\n        power_dict = {}\n        for device in self.get_device_names().keys():\n            power_dict[device] = self.get_power_single(device)\n        return power_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all device states", "response": "def get_state_all(self):\n        \"\"\"Returns all device states\"\"\"\n        state_dict = {}\n        for device in self.get_device_names().keys():\n            state_dict[device] = self.get_state(device)\n        return state_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_entrypoints(entry_point):\n    found_entry_points = {}\n    for dist in working_set:\n        entry_map = dist.get_entry_map()\n        for group_name, entry_points in entry_map.items():\n            # Filter entry points\n            if entry_point is None and \\\n               not group_name.startswith('invenio'):\n                continue\n            if entry_point is not None and \\\n               entry_point != group_name:\n                continue\n\n            # Store entry points.\n            if group_name not in found_entry_points:\n                found_entry_points[group_name] = []\n            for ep in entry_points.values():\n                found_entry_points[group_name].append(str(ep))\n\n    for ep_group in sorted(found_entry_points.keys()):\n        click.secho('{0}'.format(ep_group), fg='green')\n        for ep in sorted(found_entry_points[ep_group]):\n            click.echo('  {0}'.format(ep))", "response": "List defined entry points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef migrate_secret_key(old_key):\n    if 'SECRET_KEY' not in current_app.config or \\\n            current_app.config['SECRET_KEY'] is None:\n        raise click.ClickException(\n            'SECRET_KEY is not set in the configuration.')\n\n    for ep in iter_entry_points('invenio_base.secret_key'):\n        try:\n            ep.load()(old_key=old_key)\n        except Exception:\n            current_app.logger.error(\n                'Failed to initialize entry point: {0}'.format(ep))\n            raise\n    click.secho('Successfully changed secret key.', fg='green')", "response": "Call entry points exposed for the SECRET_KEY change."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of currently available metrics providers suitable for use as model fields choices.", "response": "def get_provider_choices():\n    \"\"\"Returns a list of currently available metrics providers\n    suitable for use as model fields choices.\n\n    \"\"\"\n    choices = []\n    for provider in METRICS_PROVIDERS:\n        choices.append((provider.alias, provider.title))\n    return choices"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(message, api_key=None, secure=None, test=None, **request_args):\n    '''Send a message.\n\n    :param message: Message to send.\n    :type message: `dict` or :class:`Message`\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`SendResponse`\n    '''\n    return _default_pyst_sender.send(message=message, api_key=api_key,\n                                     secure=secure, test=test, **request_args)", "response": "Send a message to a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a message with a template.", "response": "def send_with_template(message,\n                       api_key=None,\n                       secure=None,\n                       test=None,\n                       **request_args):\n    '''Send a message.\n\n    :param message: Message to send.\n    :type message: `dict` or :class:`Message`\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`SendResponse`\n    '''\n    return _default_pyst_template_sender.send(message=message,\n                                              api_key=api_key,\n                                              secure=secure,\n                                              test=test,\n                                              **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a batch of messages.", "response": "def send_batch(messages, api_key=None, secure=None, test=None, **request_args):\n    '''Send a batch of messages.\n\n    :param messages: Messages to send.\n    :type message: A list of `dict` or :class:`Message`\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BatchSendResponse`\n    '''\n    return _default_pyst_batch_sender.send(messages=messages, api_key=api_key,\n                                           secure=secure, test=test,\n                                           **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets delivery stats for your Postmark account.", "response": "def get_delivery_stats(api_key=None, secure=None, test=None, **request_args):\n    '''Get delivery stats for your Postmark account.\n\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`DeliveryStatsResponse`\n    '''\n    return _default_delivery_stats.get(api_key=api_key, secure=secure,\n                                       test=test, **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a paginated list of bounces.", "response": "def get_bounces(api_key=None, secure=None, test=None, **request_args):\n    '''Get a paginated list of bounces.\n\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BouncesResponse`\n    '''\n    return _default_bounces.get(api_key=api_key, secure=secure,\n                                test=test, **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a single bounce.", "response": "def get_bounce(bounce_id, api_key=None, secure=None, test=None,\n               **request_args):\n    '''Get a single bounce.\n\n    :param bounce_id: The bounce's id. Get the id with :func:`get_bounces`.\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BounceResponse`\n    '''\n    return _default_bounce.get(bounce_id, api_key=api_key, secure=secure,\n                               test=test, **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the raw email dump for a single bounce.", "response": "def get_bounce_dump(bounce_id, api_key=None, secure=None, test=None,\n                    **request_args):\n    '''Get the raw email dump for a single bounce.\n\n    :param bounce_id: The bounce's id. Get the id with :func:`get_bounces`.\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BounceDumpResponse`\n    '''\n    return _default_bounce_dump.get(bounce_id, api_key=api_key, secure=secure,\n                                    test=test, **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of tags for bounces associated with your Postmark server.", "response": "def get_bounce_tags(api_key=None, secure=None, test=None, **request_args):\n    '''Get a list of tags for bounces associated with your Postmark server.\n\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BounceTagsResponse`\n    '''\n    return _default_bounce_tags.get(api_key=api_key, secure=secure, test=test,\n                                    **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nactivating a deactivated bounce.", "response": "def activate_bounce(bounce_id, api_key=None, secure=None, test=None,\n                    **request_args):\n    '''Activate a deactivated bounce.\n\n    :param bounce_id: The bounce's id. Get the id with :func:`get_bounces`.\n    :param api_key: Your Postmark API key. Required, if `test` is not `True`.\n    :param secure: Use the https scheme for the Postmark API.\n        Defaults to `True`\n    :param test: Use the Postmark Test API. Defaults to `False`.\n    :param \\*\\*request_args: Keyword arguments to pass to\n        :func:`requests.request`.\n    :rtype: :class:`BounceActivateResponse`\n    '''\n    return _default_bounce_activate.activate(bounce_id, api_key=api_key,\n                                             secure=secure, test=test,\n                                             **request_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning data formatted for a POST request to the Postmark send API.", "response": "def data(self):\n        '''Returns data formatted for a POST request to the Postmark send API.\n\n        :rtype: `dict`\n        '''\n        d = {}\n        for val, key in self._fields.items():\n            val = getattr(self, val)\n            if val is not None:\n                d[key] = val\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_message(self, message, **kwargs):\n        '''Create a :class:`Message` from a message data `dict`.\n\n        :param message: A `dict` of message data.\n        :param \\*\\*kwargs: Additional keyword arguments to construct\n            :class:`Message` with.\n        :rtype: :class:`Message`\n        '''\n        kwargs.update(message)\n        message = kwargs\n        try:\n            message = Message(**message)\n        except TypeError as e:\n            message = self._convert_postmark_to_native(kwargs)\n            if message:\n                message = Message(**message)\n            else:\n                raise e\n        return message", "response": "Create a : class:`Message` from a message data dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new Message by merging self with other.", "response": "def load_from(self, other, **kwargs):\n        '''Create a :class:`Message` by merging `other` with `self`.\n        Values from `other` will be copied to `self` if the value was not\n        set on `self` and is set on `other`.\n\n        :param other: The :class:`Message` to copy defaults from.\n        :type other: :class:`Message`\n        :param \\*\\*kwargs: Additional keyword arguments to construct\n            :class:`Message` with.\n        :rtype: :class:`Message`\n        '''\n        data = self.data()\n        other_data = other.data()\n        for k, v in iteritems(other_data):\n            if data.get(k) is None:\n                data[k] = v\n        return self.load_message(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattaches an email header to send with the message.", "response": "def add_header(self, name, value):\n        '''Attach an email header to send with the message.\n\n        :param name: The name of the header value.\n        :param value: The header value.\n        '''\n        if self.headers is None:\n            self.headers = []\n        self.headers.append(dict(Name=name, Value=value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattach a file to the message given raw binary data.", "response": "def attach_binary(self, data, filename, content_type=None,\n                      content_id=None):\n        '''Attach a file to the message given raw binary data.\n\n        :param data: Raw data to attach to the message.\n        :param filename: Name of the file for the data.\n        :param content_type: mimetype of the data. It will be guessed from the\n            filename if not provided.\n        :param content_id: ContentID URL of the attachment.  A RFC 2392-\n            compliant URL for the attachment that allows it to be referenced\n            from inside the body of the message.  Must start with 'cid:'\n         '''\n        if self.attachments is None:\n            self.attachments = []\n        if content_type is None:\n            content_type = self._detect_content_type(filename)\n        attachment = {\n            'Name': filename,\n            'Content': b64encode(data).decode('utf-8'),\n            'ContentType': content_type\n        }\n        if content_id is not None:\n            if not content_id.startswith('cid:'):\n                raise MessageError('content_id parameter must be an '\n                                   'RFC-2392 URL starting with \"cid:\"')\n            attachment['ContentID'] = content_id\n\n        self.attachments.append(attachment)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attach_file(self, filename, content_type=None,\n                    content_id=None):\n        '''Attach a file to the message given a filename.\n\n        :param filename: Name of the file to attach.\n        :param content_type: mimetype of the data. It will be guessed from the\n            filename if not provided.\n        :param content_id: ContentID URL of the attachment.  A RFC 2392-\n            compliant URL for the attachment that allows it to be referenced\n            from inside the body of the message.  Must start with 'cid:'\n         '''\n        # Open the file, grab the filename, detect content type\n        name = os.path.basename(filename)\n        if not name:\n            err = 'Filename not found in path: {0}'\n            raise MessageError(err.format(filename))\n        with open(filename, 'rb') as f:\n            data = f.read()\n        self.attach_binary(data, name, content_type=content_type,\n                           content_id=content_id)", "response": "Attach a file to the message given a filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying the message data based on rules and restrictions defined by the Postmark API docs.", "response": "def verify(self):\n        '''Verifies the message data based on rules and restrictions defined\n        in the Postmark API docs.  There can be no more than 20 recipients\n        in total. NOTE: This does not check that your attachments total less\n        than 10MB, you must do that yourself.\n        '''\n        if self.to is None:\n            raise MessageError('\"to\" is required')\n        if self.html is None and self.text is None:\n            err = 'At least one of \"html\" or \"text\" must be provided'\n            raise MessageError(err)\n        self._verify_headers()\n        self._verify_attachments()\n        if (MAX_RECIPIENTS_PER_MESSAGE and\n                len(self.recipients) > MAX_RECIPIENTS_PER_MESSAGE):\n            err = 'No more than {0} recipients accepted.'\n            raise MessageError(err.format(MAX_RECIPIENTS_PER_MESSAGE))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to(self, to):\n        '''\n        :param to: Email addresses for the 'To' API field.\n        :type to: :keyword:`list` or `str`\n        '''\n        if isinstance(to, basestring):\n            to = to.split(',')\n        self._to = to", "response": "Set the to field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the Cc field.", "response": "def cc(self, cc):\n        '''\n        :param cc: Email addresses for the 'Cc' API field.\n        :type cc: :keyword:`list` or `str`\n        '''\n        if isinstance(cc, basestring):\n            cc = cc.split(',')\n        self._cc = cc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the Bcc field.", "response": "def bcc(self, bcc):\n        '''\n        :param bcc: Email addresses for the 'Bcc' API field.\n        :type bcc: :keyword:`list` or `str`\n        '''\n        if isinstance(bcc, basestring):\n            bcc = bcc.split(',')\n        self._bcc = bcc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting Postmark message API field names to their corresponding .", "response": "def _convert_postmark_to_native(cls, message):\n        '''Converts Postmark message API field names to their corresponding\n        :class:`Message` attribute names.\n\n        :param message: Postmark message data, with API fields using Postmark\n            API names.\n        :type message: `dict`\n        '''\n        d = {}\n        for dest, src in cls._fields.items():\n            if src in message:\n                d[dest] = message[src]\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects the mimetype for a file.", "response": "def _detect_content_type(self, filename):\n        '''Determine the mimetype for a file.\n\n        :param filename: Filename of file to detect.\n        '''\n        name, ext = os.path.splitext(filename)\n        if not ext:\n            raise MessageError('File requires an extension.')\n        ext = ext.lower()\n        if ext.lstrip('.') in self._banned_extensions:\n            err = 'Extension \"{0}\" is not allowed.'\n            raise MessageError(err.format(ext))\n        if not mimetypes.inited:\n            mimetypes.init()\n        return mimetypes.types_map.get(ext, self._default_content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _verify_attachments(self):\n        '''Verify that attachment values match the format expected by the\n        Postmark API.\n        '''\n        if self.attachments is None:\n            return\n        keys = ('Name', 'Content', 'ContentType')\n        self._verify_dict_list(self.attachments, keys, 'Attachment')", "response": "Verify that the attachments are valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating a list of dict that has specific keys and no others.", "response": "def _verify_dict_list(self, values, keys, name):\n        '''Validate a list of `dict`, ensuring it has specific keys\n        and no others.\n\n        :param values: A list of `dict` to validate.\n        :param keys: A list of keys to validate each `dict` against.\n        :param name: Name describing the values, to show in error messages.\n        '''\n        keys = set(keys)\n        name = name.title()\n        for value in values:\n            if not isinstance(value, Mapping):\n                raise MessageError('Invalid {0} value'.format(name))\n            for key in keys:\n                if key not in value:\n                    err = '{0} must contain \"{1}\"'\n                    raise MessageError(err.format(name, key))\n            if set(value) - keys:\n                err = '{0} must contain only {1}'\n                words = ['\"{0}\"'.format(r) for r in sorted(keys)]\n                words = ' and '.join(words)\n                raise MessageError(err.format(name, words))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve raw email dump for this bounce.", "response": "def dump(self, sender=None, **kwargs):\n        '''Retrieve raw email dump for this bounce.\n\n        :param sender: A :class:`BounceDump` object to get dump with.\n            Defaults to `None`.\n        :param \\*\\*kwargs: Keyword arguments passed to\n            :func:`requests.request`.\n        '''\n        if sender is None:\n            if self._sender is None:\n                sender = _default_bounce_dump\n            else:\n                sender = BounceDump(api_key=self._sender.api_key,\n                                    test=self._sender.test,\n                                    secure=self._sender.secure)\n        return sender.get(self.id, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise the appropriate HTTP errors for the status code.", "response": "def raise_for_status(self):\n        '''Raise Postmark-specific HTTP errors. If there isn't one, the\n        standard HTTP error is raised.\n\n        HTTP 401 raises :class:`UnauthorizedError`\n\n        HTTP 422 raises :class:`UnprocessableEntityError`\n\n        HTTP 500 raises :class:`InternalServerError`\n        '''\n        if self.status_code == 401:\n            raise UnauthorizedError(self._requests_response)\n        elif self.status_code == 422:\n            raise UnprocessableEntityError(self._requests_response)\n        elif self.status_code == 500:\n            raise InternalServerError(self._requests_response)\n        return self._requests_response.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing Postmark API url with optional formatting.", "response": "def _get_api_url(self, secure=None, **formatters):\n        '''Constructs Postmark API url\n\n        :param secure: Use the https Postmark API.\n        :param \\*\\*formatters: :func:`string.format` keyword arguments to\n            format the url with.\n        :rtype: Postmark API url\n        '''\n        if self.endpoint is None:\n            raise NotImplementedError('endpoint must be defined on a subclass')\n        if secure is None:\n            secure = self.secure\n        if secure:\n            api_url = POSTMARK_API_URL_SECURE\n        else:\n            api_url = POSTMARK_API_URL\n        url = urljoin(api_url, self.endpoint)\n        if formatters:\n            url = url.format(**formatters)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct the headers to use for the request.", "response": "def _get_headers(self, api_key=None, test=None, request_args=None):\n        '''Constructs the headers to use for the request.\n\n        :param api_key: Your Postmark API key. Defaults to `None`.\n        :param test: Use the Postmark test API. Defaults to `self.test`.\n        :param request_args: Keyword args to pass to :func:`requests.request`.\n            Defaults to `None`.\n        :rtype: `dict` of header values.\n        '''\n        if request_args is None:\n            request_args = {}\n        headers = {}\n        headers.update(self._headers)\n        headers.update(request_args.pop('headers', {}))\n        if (test is None and self.test) or test:\n            headers[self._api_key_header_name] = POSTMARK_API_TEST_KEY\n        elif api_key is not None:\n            headers[self._api_key_header_name] = api_key\n        else:\n            headers[self._api_key_header_name] = self.api_key\n        if not headers.get(self._api_key_header_name):\n            raise ValueError('Postmark API Key not provided')\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, message=None, api_key=None, secure=None, test=None,\n             **request_args):\n        '''Send request to Postmark API.\n        Returns result of :func:`requests.post`.\n\n        :param message: Your Postmark message data.\n        :type message: `dict` or :class:`Message`\n        :param api_key: Your Postmark API key.\n        :type api_key: `str`\n        :param test: Make a test request to the Postmark API.\n        :param secure: Use the https Postmark API.\n        :param \\*\\*request_args: Passed to :func:`requests.post`\n        :rtype: :class:`requests.Response`\n        '''\n        headers = self._get_headers(api_key=api_key, test=test,\n                                    request_args=request_args)\n        data = self._get_request_content(message)\n        url = self._get_api_url(secure=secure)\n        return self._request(url, data=data, headers=headers, **request_args)", "response": "Send a request to the Postmark API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting message to Message and sets it on self. message", "response": "def _load_initial_message(self, message=None):\n        '''Converts message to :class:`Message` and sets it on `self`'''\n        if message is None:\n            message = Message(verify=False)\n        if isinstance(message, Mapping):\n            message = Message.load_message(message)\n        self.message = message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cast_message(self, message=None):\n        '''Convert message data to :class:`Message` if needed, and\n        merge with the default message.\n\n        :param message: Message to merge with the default message.\n        :rtype: :class:`Message`\n        '''\n        if message is None:\n            message = {}\n        if isinstance(message, Mapping):\n            message = Message.load_message(message)\n        return message.load_from(self.message, verify=True)", "response": "Convert message data to Message if needed and\n        merge with the default message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_request_content(self, message=None):\n        '''Updates message with default message paramaters.\n\n        :param message: Postmark message data\n        :type message: `dict`\n        :rtype: JSON encoded `unicode`\n        '''\n        message = self._cast_message(message=message)\n        return message.json()", "response": "Updates message with default message paramaters.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self, messages=None, api_key=None, secure=None, test=None,\n             **request_args):\n        '''Send batch request to Postmark API.\n        Returns result of :func:`requests.post`.\n\n        :param messages: Batch messages to send to the Postmark API.\n        :type messages: A list of :class:`Message`\n        :param api_key: Your Postmark API key. Defaults to `self.api_key`.\n        :param test: Make a test request to the Postmark API.\n            Defaults to `self.test`.\n        :param secure: Use the https Postmark API. Defaults to `self.secure`.\n        :param \\*\\*request_args: Passed to :func:`requests.request`\n        :rtype: :class:`BatchSendResponse`\n        '''\n        return super(BatchSender, self).send(message=messages, test=test,\n                                             api_key=api_key, secure=secure,\n                                             **request_args)", "response": "Send a batch request to the Postmark API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_request_content(self, message=None):\n        '''Updates all messages in message with default message\n        parameters.\n\n        :param message: A collection of Postmark message data\n        :type message: a collection of message `dict`s\n        :rtype: JSON encoded `str`\n        '''\n        if not message:\n            raise MessageError('No messages to send.')\n        if len(message) > MAX_BATCH_MESSAGES:\n            err = 'Maximum {0} messages allowed in batch'\n            raise MessageError(err.format(MAX_BATCH_MESSAGES))\n        message = [self._cast_message(message=msg) for msg in message]\n        message = [msg.data() for msg in message]\n        return json.dumps(message, ensure_ascii=True)", "response": "Updates all messages in message with default message\n        parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding query string params from inputs. It handles offset and count defaults and validation. :param bounce_type: The type of bounces retrieve. See `bounce_types` for a list of types, or read the Postmark API docs. Defaults to `None`. :param inactive: If `True`, retrieves inactive bounces only. Defaults to `None`. :param email_filter: A string to filter emails by. Defaults to `None`. :param message_id: Retrieve a bounce for a single message's ID. Defaults to `None`. :param count: The number of bounces to retrieve in this request. Defaults to 25 if `message_id` is not provided. :param offset: The page offset for bounces to retrieve. Defaults to 0 if `message_id` is not provided. :param api_key: Your Postmark API key. Defaults to `self.api_key`. :param secure: Use the https scheme for Postmark API. Defaults to `self.secure`. :params test: Use the Postmark test API. Defaults to `self.test`. :rtype: :class:`BouncesResponse`", "response": "def get(self, bounce_type=None, inactive=None, email_filter=None,\n            message_id=None, count=None, offset=None, api_key=None,\n            secure=None, test=None, **request_args):\n        '''Builds query string params from inputs. It handles offset and\n        count defaults and validation.\n\n        :param bounce_type: The type of bounces retrieve. See `bounce_types`\n            for a list of types, or read the Postmark API docs. Defaults to\n            `None`.\n        :param inactive: If `True`, retrieves inactive bounces only.\n            Defaults to `None`.\n        :param email_filter: A string to filter emails by.\n            Defaults to `None`.\n        :param message_id: Retrieve a bounce for a single message's ID.\n            Defaults to `None`.\n        :param count: The number of bounces to retrieve in this request.\n            Defaults to 25 if `message_id` is not provided.\n        :param offset: The page offset for bounces to retrieve. Defaults to 0\n            if `message_id` is not provided.\n        :param api_key: Your Postmark API key. Defaults to `self.api_key`.\n        :param secure: Use the https scheme for Postmark API.\n            Defaults to `self.secure`.\n        :params test: Use the Postmark test API. Defaults to `self.test`.\n        :rtype: :class:`BouncesResponse`\n        '''\n        params = self._construct_params(bounce_type=bounce_type,\n                                        inactive=inactive,\n                                        email_filter=email_filter,\n                                        message_id=message_id,\n                                        count=count,\n                                        offset=offset)\n        url = self._get_api_url(secure=secure)\n        headers = self._get_headers(api_key=api_key, test=test,\n                                    request_args=request_args)\n        response = self._request(url, headers=headers, params=params,\n                                 **request_args)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request(self, url, **kwargs):\n        '''Makes request to :func:`Interface.request` and caches it.\n\n        :param url: endpoint url\n        :params \\*\\*kwargs: kwargs to pass to :func:`requests.request`\n        '''\n        response = super(Bounces, self)._request(url, **kwargs)\n        self._last_response = response\n        return response", "response": "Makes a request to the given url and caches it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs the query string params from inputs. It handles offset count and validation.", "response": "def _construct_params(self, bounce_type=None, inactive=None,\n                          email_filter=None, message_id=None, count=None,\n                          offset=None):\n        '''Builds query string params from inputs. It handles offset and\n        count defaults and validation.\n\n        :param bounce_type: The type of bounces retrieve. See `bounce_types`\n            for a list of types, or read the Postmark API docs. Defaults to\n            `None`.\n        :param inactive: If `True`, retrieves inactive bounces only.\n            Defaults to `None`.\n        :param email_filter: A string to filter emails by.\n            Defaults to `None`.\n        :param message_id: Retrieve a bounce for a single message's ID.\n            Defaults to `None`.\n        :param count: The number of bounces to retrieve in this request.\n            Defaults to 25 if `message_id` is not provided.\n        :param offset: The page offset for bounces to retrieve. Defaults to 0\n            if `message_id` is not provided.\n        '''\n        params = {}\n        if bounce_type is not None:\n            if bounce_type not in bounce_types:\n                err = 'Invalid bounce type \"{0}\".'\n                raise BounceError(err.format(bounce_type))\n            else:\n                params['type'] = bounce_type\n        if inactive is not None:\n            params['inactive'] = inactive\n        if email_filter is not None:\n            params['emailFilter'] = email_filter\n        if message_id is None:\n            # If the message_id is given, count and offset are not\n            # required, so we postpone assigning defaults to here\n            if count is None:\n                count = 25\n            if offset is None:\n                offset = 0\n        else:\n            params['messageID'] = message_id\n        if count is not None:\n            params['count'] = count\n        if offset is not None:\n            params['offset'] = offset\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, bounce_id, api_key=None, secure=None, test=None,\n            **request_args):\n        '''Retrieves a single bounce's data.\n\n        :param bounce_id: A bounce's ID retrieved with :class:`Bounces`.\n        :param api_key: Your Postmark API key. Defaults to `self.api_key`.\n        :param secure: Use the https scheme for Postmark API.\n            Defaults to `self.secure`.\n        :param test: Make a test request to the Postmark API.\n            Defaults to `self.test`.\n        :param \\*\\*request_args: Keyword args to pass to\n            :func:`requests.request`.\n        :rtype: :class:`BounceResponse`\n        '''\n        url = self._get_api_url(secure=secure, bounce_id=bounce_id)\n        headers = self._get_headers(api_key=api_key, test=test,\n                                    request_args=request_args)\n        return self._request(url, headers=headers, **request_args)", "response": "Retrieves a single bounce s data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_app_factory(app_name, config_loader=None,\n                       extension_entry_points=None, extensions=None,\n                       blueprint_entry_points=None, blueprints=None,\n                       converter_entry_points=None, converters=None,\n                       wsgi_factory=None, **app_kwargs):\n    \"\"\"Create a Flask application factory.\n\n    The application factory will load Flask extensions and blueprints specified\n    using both entry points and directly in the arguments. Loading order of\n    entry points are not guaranteed and can happen in any order.\n\n    :param app_name: Flask application name.\n    :param config_loader: Callable which will be invoked on application\n        creation in order to load the Flask configuration. See example below.\n    :param extension_entry_points: List of entry points, which specifies Flask\n        extensions that will be initialized only by passing in the Flask\n        application object\n    :param extensions: List of Flask extensions that can be initialized only by\n        passing in the Flask application object.\n    :param blueprint_entry_points: List of entry points, which specifies\n        Blueprints that will be registered on the Flask application.\n    :param blueprints: List of Blueprints that will be registered on the\n        Flask application.\n    :param converter_entry_points: List of entry points, which specifies\n        Werkzeug URL map converters that will be added to\n        ``app.url_map.converters``.\n    :param converters: Map of Werkzeug URL map converter classes that will\n        be added to ``app.url_map.converters``.\n    :param wsgi_factory: A callable that will be passed the Flask application\n        object in order to overwrite the default WSGI application (e.g. to\n        install ``DispatcherMiddleware``).\n    :param app_kwargs: Keyword arguments passed to :py:meth:`base_app`.\n    :returns: Flask application factory.\n\n    Example of a configuration loader:\n\n    .. code-block:: python\n\n       def my_config_loader(app, **kwargs):\n           app.config.from_module('mysite.config')\n           app.config.update(**kwargs)\n\n    .. note::\n\n       `Invenio-Config <https://pythonhosted.org/invenio-config>`_ provides a\n       factory creating default configuration loader (see\n       :func:`invenio_config.utils.create_config_loader`) which is sufficient\n       for most cases.\n\n    Example of a WSGI factory:\n\n    .. code-block:: python\n\n       def my_wsgi_factory(app):\n           return DispatcherMiddleware(app.wsgi_app, {'/api': api_app})\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    def _create_app(**kwargs):\n        app = base_app(app_name, **app_kwargs)\n        app_created.send(_create_app, app=app)\n\n        debug = kwargs.get('debug')\n        if debug is not None:\n            app.debug = debug\n\n        # Load configuration\n        if config_loader:\n            config_loader(app, **kwargs)\n\n        # Load URL converters.\n        converter_loader(\n            app,\n            entry_points=converter_entry_points,\n            modules=converters,\n        )\n\n        # Load application based on entrypoints.\n        app_loader(\n            app,\n            entry_points=extension_entry_points,\n            modules=extensions,\n        )\n\n        # Load blueprints\n        blueprint_loader(\n            app,\n            entry_points=blueprint_entry_points,\n            modules=blueprints,\n        )\n\n        app_loaded.send(_create_app, app=app)\n\n        # Replace WSGI application using factory if provided (e.g. to install\n        # WSGI middleware).\n        if wsgi_factory:\n            app.wsgi_app = wsgi_factory(app, **kwargs)\n\n        return app\n\n    return _create_app", "response": "Create a Flask application factory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating CLI for Invenio command line interface.", "response": "def create_cli(create_app=None):\n    \"\"\"Create CLI for ``inveniomanage`` command.\n\n    :param create_app: Flask application factory.\n    :returns: Click command group.\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    def create_cli_app(info):\n        \"\"\"Application factory for CLI app.\n\n        Internal function for creating the CLI. When invoked via\n        ``inveniomanage`` FLASK_APP must be set.\n        \"\"\"\n        if create_app is None:\n            # Fallback to normal Flask behavior\n            info.create_app = None\n            app = info.load_app()\n        else:\n            app = create_app(debug=get_debug_flag())\n        return app\n\n    @click.group(cls=FlaskGroup, create_app=create_cli_app)\n    def cli(**params):\n        \"\"\"Command Line Interface for Invenio.\"\"\"\n        pass\n\n    return cli"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef app_loader(app, entry_points=None, modules=None):\n    _loader(app, lambda ext: ext(app), entry_points=entry_points,\n            modules=modules)", "response": "Run default application loader."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns default blueprint loader.", "response": "def blueprint_loader(app, entry_points=None, modules=None):\n    \"\"\"Run default blueprint loader.\n\n    The value of any entry_point or module passed can be either an instance of\n    ``flask.Blueprint`` or a callable accepting a ``flask.Flask`` application\n    instance as a single argument and returning an instance of\n    ``flask.Blueprint``.\n\n    :param entry_points: List of entry points providing to Blueprints.\n    :param modules: List of Blueprints.\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    url_prefixes = app.config.get('BLUEPRINTS_URL_PREFIXES', {})\n\n    def loader_init_func(bp_or_func):\n        bp = bp_or_func(app) if callable(bp_or_func) else bp_or_func\n        app.register_blueprint(bp, url_prefix=url_prefixes.get(bp.name))\n\n    _loader(app, loader_init_func, entry_points=entry_points, modules=modules)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading all converter modules from entry points.", "response": "def converter_loader(app, entry_points=None, modules=None):\n    \"\"\"Run default converter loader.\n\n    :param entry_points: List of entry points providing to Blue.\n    :param modules: Map of coverters.\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    if entry_points:\n        for entry_point in entry_points:\n            for ep in pkg_resources.iter_entry_points(entry_point):\n                try:\n                    app.url_map.converters[ep.name] = ep.load()\n                except Exception:\n                    app.logger.error(\n                        'Failed to initialize entry point: {0}'.format(ep))\n                    raise\n\n    if modules:\n        app.url_map.converters.update(**modules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loader(app, init_func, entry_points=None, modules=None):\n    if entry_points:\n        for entry_point in entry_points:\n            for ep in pkg_resources.iter_entry_points(entry_point):\n                try:\n                    init_func(ep.load())\n                except Exception:\n                    app.logger.error(\n                        'Failed to initialize entry point: {0}'.format(ep))\n                    raise\n    if modules:\n        for m in modules:\n            try:\n                init_func(m)\n            except Exception:\n                app.logger.error('Failed to initialize module: {0}'.format(m))\n                raise", "response": "Run generic loader.\n\n    Used to load and initialize entry points and modules using an custom\n    initialization function.\n\n    .. versionadded: 1.0.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef base_app(import_name, instance_path=None, static_folder=None,\n             static_url_path='/static', template_folder='templates',\n             instance_relative_config=True, app_class=Flask):\n    \"\"\"Invenio base application factory.\n\n    If the instance folder does not exists, it will be created.\n\n    :param import_name: The name of the application package.\n    :param env_prefix: Environment variable prefix.\n    :param instance_path: Instance path for Flask application.\n    :param static_folder: Static folder path.\n    :param app_class: Flask application class.\n    :returns: Flask application instance.\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    configure_warnings()\n\n    # Create the Flask application instance\n    app = app_class(\n        import_name,\n        instance_path=instance_path,\n        instance_relative_config=instance_relative_config,\n        static_folder=static_folder,\n        static_url_path=static_url_path,\n        template_folder=template_folder,\n    )\n\n    # Create instance path if it doesn't exists\n    try:\n        if instance_path and not os.path.exists(instance_path):\n            os.makedirs(instance_path)\n    except Exception:  # pragma: no cover\n        app.logger.exception(\n            'Failed to create instance folder: \"{0}\"'.format(instance_path)\n        )\n\n    return app", "response": "Creates a base application class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring warnings by routing warnings to the logging system.", "response": "def configure_warnings():\n    \"\"\"Configure warnings by routing warnings to the logging system.\n\n    It also unhides ``DeprecationWarning``.\n\n    .. versionadded: 1.0.0\n    \"\"\"\n    if not sys.warnoptions:\n        # Route warnings through python logging\n        logging.captureWarnings(True)\n\n        # DeprecationWarning is by default hidden, hence we force the\n        # 'default' behavior on deprecation warnings which is not to hide\n        # errors.\n        warnings.simplefilter('default', DeprecationWarning)\n        warnings.simplefilter('ignore', PendingDeprecationWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tasks(self, task_id=None, state='completed', json_file=None):\n        if self.project is None:\n            raise ProjectError\n\n        loader = create_tasks_loader(self.project.id, task_id,\n                                     state, json_file, self.all)\n        self.tasks = loader.load()\n\n        self._check_project_has_tasks()\n        self.tasks_df = dataframer.create_data_frame(self.tasks)", "response": "Load all project Tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads all project Task Runs from Tasks.", "response": "def get_task_runs(self, json_file=None):\n        \"\"\"Load all project Task Runs from Tasks.\"\"\"\n        if self.project is None:\n            raise ProjectError\n        loader = create_task_runs_loader(self.project.id, self.tasks,\n                                         json_file, self.all)\n        self.task_runs, self.task_runs_file = loader.load()\n\n        self._check_project_has_taskruns()\n        self.task_runs_df = dataframer.create_task_run_data_frames(self.tasks, self.task_runs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning tasks or task_runs Panda describe.", "response": "def describe(self, element):  # pragma: no cover\n        \"\"\"Return tasks or task_runs Panda describe.\"\"\"\n        if (element == 'tasks'):\n            return self.tasks_df.describe()\n        elif (element == 'task_runs'):\n            return self.task_runs_df.describe()\n        else:\n            return \"ERROR: %s not found\" % element"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_rgb(self, red, green, blue):\n        x, y = rgb_to_xy(red, green, blue)\n        self.xy = [x, y]", "response": "Set the rgb color value of the light\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a WSGI application factory.", "response": "def create_wsgi_factory(mounts_factories):\n    \"\"\"Create a WSGI application factory.\n\n    Usage example:\n\n    .. code-block:: python\n\n       wsgi_factory = create_wsgi_factory({'/api': create_api})\n\n    :param mounts_factories: Dictionary of mount points per application\n        factory.\n\n    .. versionadded:: 1.0.0\n    \"\"\"\n    def create_wsgi(app, **kwargs):\n        mounts = {\n            mount: factory(**kwargs)\n            for mount, factory in mounts_factories.items()\n        }\n        return DispatcherMiddleware(app.wsgi_app, mounts)\n    return create_wsgi"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a WSGI application that will fix the REMOTE_ADDR based on X - Forwarded - For headers.", "response": "def wsgi_proxyfix(factory=None):\n    \"\"\"Fix ``REMOTE_ADDR`` based on ``X-Forwarded-For`` headers.\n\n    .. note::\n\n       You must set ``WSGI_PROXIES`` to the correct number of proxies,\n       otherwise you application is susceptible to malicious attacks.\n\n    .. versionadded:: 1.0.0\n    \"\"\"\n    def create_wsgi(app, **kwargs):\n        wsgi_app = factory(app, **kwargs) if factory else app.wsgi_app\n        if app.config.get('WSGI_PROXIES'):\n            return ProxyFix(wsgi_app, num_proxies=app.config['WSGI_PROXIES'])\n        return wsgi_app\n    return create_wsgi"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_directory(self):\n        exists = os.path.exists(self.directory)\n        if not exists:\n            logger.error(\"No migrations directory found. Check your path or create a migration first.\")\n            logger.error(\"Directory: %s\" % self.directory)\n        return exists", "response": "Check if migrations directory exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows status of unregistered migrations", "response": "def show_status(self):\n        \"\"\"Show status of unregistered migrations\"\"\"\n        if not self.check_directory():\n            return\n\n        migrations = self.get_unregistered_migrations()\n        if migrations:\n            logger.info('Unregistered migrations:')\n            for migration in migrations:\n                logger.info(migration.filename)\n        else:\n            logger.info(self.NO_MIGRATIONS_MSG)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate filename for new migration.", "response": "def get_new_filename(self, name):\n        \"\"\"Generate filename for new migration.\"\"\"\n        name = MigrationFile.normalize_name(name)\n        migrations = self.get_migration_files()\n        migration_id = migrations[-1].id if migrations else 0\n        migration_id += 1\n        return '{:04}_{}.py'.format(migration_id, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new empty migration.", "response": "def create(self, name):\n        \"\"\"Create a new empty migration.\"\"\"\n        if not os.path.exists(self.directory):\n            os.makedirs(self.directory)\n\n        filename = self.get_new_filename(name)\n        with open(os.path.join(self.directory, filename), 'w') as fp:\n            fp.write(\"def up(db): pass\\n\\n\\n\")\n            fp.write(\"def down(db): pass\\n\")\n            logger.info(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading migration file as module.", "response": "def load_migration_file(self, filename):\n        \"\"\"Load migration file as module.\"\"\"\n        path = os.path.join(self.directory, filename)\n        # spec = spec_from_file_location(\"migration\", path)\n        # module = module_from_spec(spec)\n        # spec.loader.exec_module(module)\n        module = imp.load_source(\"migration\", path)\n        return module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding migrations to execute.", "response": "def get_migrations_to_up(self, migration_id=None):\n        \"\"\"Find migrations to execute.\"\"\"\n        if migration_id is not None:\n            migration_id = MigrationFile.validate_id(migration_id)\n            if not migration_id:\n                return []\n\n        migrations = self.get_unregistered_migrations()\n        if not migrations:\n            logger.info(self.NO_MIGRATIONS_MSG)\n            return []\n\n        if migration_id:\n            try:\n                last_migration = [m for m in migrations\n                                  if m.id == migration_id][0]\n            except IndexError:\n                logger.error('Migration is not in unregistered list: %s'\n                             % migration_id)\n                self.show_status()\n                return []\n        else:\n            last_migration = list(migrations)[-1]\n\n        return [m for m in migrations if m.id <= last_migration.id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_migrations_to_down(self, migration_id):\n        migration_id = MigrationFile.validate_id(migration_id)\n        if not migration_id:\n            return []\n\n        migrations = self.get_migration_files()\n        last_migration_id = self.get_last_migrated_id()\n\n        if migration_id in (m.id for m in self.get_unregistered_migrations()):\n            logger.error('Migration is not applied %s' % migration_id)\n            return []\n\n        try:\n            migration = [m for m in migrations if m.id == migration_id][0]\n        except IndexError:\n            logger.error('Migration does not exists %s' % migration_id)\n            return []\n\n        return list(reversed([m for m in migrations\n                              if migration.id <= m.id <= last_migration_id]))", "response": "Find migrations to rollback."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_user_init(target, args, kwargs):\n    profile = kwargs.pop('profile', None)\n    if profile is not None and not isinstance(profile, UserProfile):\n        profile = UserProfile(**profile)\n        if kwargs.get('id'):\n            profile.user_id = kwargs['id']\n        kwargs['profile'] = profile", "response": "Provide hook on Flask - Security. User initialization."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef username(self, username):\n        validate_username(username)\n        self._username = username.lower()\n        self._displayname = username", "response": "Set username.\n\n        .. note:: The username will be converted to lowercase. The display name\n            will contain the original version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_by_username(cls, username):\n        return cls.query.filter(\n            UserProfile._username == username.lower()\n        ).one()", "response": "Get a user profile by username."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender sitemetrics counter. Two notation types are possible: 1. No arguments: {% sitemetrics %} Used to render all metrics counters registered and active for the current site. This requires 'Admin site' and 'Sites' Django contribs. 2. Four arguments: {% sitemetrics by yandex for \"138500\" %} Used to render custom metrics counter by definite counter id. This is a simple template tag with no special requirements.", "response": "def sitemetrics(parser, token):\n    \"\"\"Renders sitemetrics counter.\n    \n    Two notation types are possible:\n\n        1. No arguments:\n           {% sitemetrics %} \n           Used to render all metrics counters registered and active for the current site.\n           This requires 'Admin site' and 'Sites' Django contribs.\n            \n        2. Four arguments:\n           {% sitemetrics by yandex for \"138500\" %}\n           Used to render custom metrics counter by definite counter id.\n           This is a simple template tag with no special requirements.\n    \n    \"\"\"\n    if settings.DEBUG and not ON_DEBUG:\n        return sitemetricsDummyNode()\n\n    tokens = token.split_contents()\n    tokens_num = len(tokens)\n\n    if tokens_num == 1:\n        # Notation Type 1\n        current_site = Site.objects.get_current()\n\n        cached = cache.get('sitemetrics')\n        if not cached or current_site.id not in cached['keycodes']:\n            kcodes = current_site.keycode_set.filter(active=True).values()\n            cache.set('sitemetrics', {'keycodes': {current_site.id: kcodes}}, CACHE_TIMEOUT)\n        else:\n            kcodes = cached['keycodes'][current_site.id]\n        \n    elif tokens_num == 5:\n        # Notation Type 2\n        if tokens[1] == 'by' and tokens[3] == 'for':\n            kcodes = [{'provider': tokens[2], 'keycode': tokens[4].strip('\"')}]\n        else:\n            raise template.TemplateSyntaxError(\n                'Four arguments `sitemetrics` tag notation should look like '\n                '{%% sitemetrics by yandex for \"138500\" %%}.')\n    else:\n        raise template.TemplateSyntaxError(\n            '`sitemetrics` tag requires four or no arguments. '\n            'E.g. {%% sitemetrics by yandex for \"138500\" %%} or {%% sitemetrics %%}.')\n\n    _kcodes = []\n    for kcode_data in kcodes:\n        if kcode_data['provider'] in PROVIDERS_BY_ALIAS:\n            p_cls = PROVIDERS_BY_ALIAS[kcode_data['provider']]\n            kcode_data['tpl'] = p_cls.get_template_name()\n            # Get counter parameters.\n            kcode_data.update(p_cls.get_params())\n            _kcodes.append(kcode_data)\n\n    return sitemetricsNode(_kcodes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nice_classname(obj):\n    if inspect.isclass(obj):\n        cls_name = obj.__name__\n    else:\n        cls_name = obj.__class__.__name__\n    mod = inspect.getmodule(obj)\n    if mod:\n        name = mod.__name__\n        # jython\n        if name.startswith('org.python.core.'):\n            name = name[len('org.python.core.'):]\n        return \"%s.%s\" % (name, cls_name)\n    else:\n        return cls_name", "response": "Returns a nice name for class object or class instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exc_message(exc_info):\n    exc = exc_info[1]\n    if exc is None:\n        # str exception\n        result = exc_info[0]\n    else:\n        try:\n            result = str(exc)\n        except UnicodeEncodeError:\n            try:\n                result = unicode(exc)  # flake8: noqa\n            except UnicodeError:\n                # Fallback to args as neither str nor\n                # unicode(Exception(u'\\xe6')) work in Python < 2.6\n                result = exc.args[0]\n    return result", "response": "Return the exception s message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef options(self, parser, env):\n        Plugin.options(self, parser, env)\n        parser.add_option(\n            '--html-file', action='store',\n            dest='html_file', metavar=\"FILE\",\n            default=env.get('NOSE_HTML_FILE', 'nosetests.html'),\n            help=\"Path to html file to store the report in. \"\n                 \"Default is nosetests.html in the working directory \"\n                 \"[NOSE_HTML_FILE]\")", "response": "Sets additional command line options."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring the xunit plugin.", "response": "def configure(self, options, config):\n        \"\"\"Configures the xunit plugin.\"\"\"\n        Plugin.configure(self, options, config)\n        self.config = config\n        if self.enabled:\n            self.jinja = Environment(\n                loader=FileSystemLoader(os.path.join(os.path.dirname(__file__), 'templates')),\n                trim_blocks=True,\n                lstrip_blocks=True\n            )\n            self.stats = {'errors': 0, 'failures': 0, 'passes': 0, 'skipped': 0}\n            self.report_data = defaultdict(Group)\n            self.report_file = codecs.open(options.html_file, 'w', self.encoding, 'replace')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite an XML file containing the report of test errors and failures.", "response": "def report(self, stream):\n        \"\"\"Writes an Xunit-formatted XML file\n\n        The file includes a report of test errors and failures.\n\n        \"\"\"\n        from collections import OrderedDict\n        self.stats['total'] = sum(self.stats.values())\n        for group in self.report_data.values():\n            group.stats['total'] = sum(group.stats.values())\n        self.report_file.write(self.jinja.get_template('report.html').render(\n            report=OrderedDict(sorted(self.report_data.items())),\n            stats=self.stats,\n        ))\n        self.report_file.close()\n        if self.config.verbosity > 1:\n            stream.writeln(\"-\" * 70)\n            stream.writeln(\"HTML: %s\" % self.report_file.name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addError(self, test, err, capt=None):\n        exc_type, exc_val, tb = err\n        tb = ''.join(traceback.format_exception(\n            exc_type,\n            exc_val if isinstance(exc_val, exc_type) else exc_type(exc_val),\n            tb\n        ))\n        name = id_split(test.id())\n        group = self.report_data[name[0]]\n        if issubclass(err[0], SkipTest):\n            type = 'skipped'\n            self.stats['skipped'] += 1\n            group.stats['skipped'] += 1\n        else:\n            type = 'error'\n            self.stats['errors'] += 1\n            group.stats['errors'] += 1\n        group.tests.append({\n            'name': name[-1],\n            'failed': True,\n            'type': type,\n            'errtype': nice_classname(err[0]),\n            'message': exc_message(err),\n            'tb': tb,\n        })", "response": "Add error output to Xunit report."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get(self, *args, **kwargs):\n        all_messages = []\n        for storage in self.storages:\n            messages, all_retrieved = storage._get()\n            # If the backend hasn't been used, no more retrieval is necessary.\n            if messages is None:\n                break\n            if messages:\n                self._used_storages.add(storage)\n            all_messages.extend(messages)\n            # If this storage class contained all the messages, no further\n            # retrieval is necessary\n            if all_retrieved:\n                break\n        return all_messages, all_retrieved", "response": "Gets a single list of messages from all storage backends."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the messages in the specified storage backend and returns any unstored messages after trying all the available backends.", "response": "def _store(self, messages, response, *args, **kwargs):\n        \"\"\"\n        Stores the messages, returning any unstored messages after trying all\n        backends.\n\n        For each storage backend, any messages not stored are passed on to the\n        next backend.\n        \"\"\"\n        for storage in self.storages:\n            if messages:\n                messages = storage._store(messages, response,\n                    remove_oldest=False)\n            # Even if there are no more messages, continue iterating to ensure\n            # storages which contained messages are flushed.\n            elif storage in self._used_storages:\n                storage._store([], response)\n                self._used_storages.remove(storage)\n        return messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a queryset of all messages for the request user", "response": "def _message_queryset(self, include_read=False):\n        \"\"\"\n        Return a queryset of messages for the request user\n        \"\"\"\n        expire = timezone.now()\n\n\n        qs = PersistentMessage.objects.\\\n        filter(user=self.get_user()).\\\n        filter(Q(expires=None) | Q(expires__gt=expire))\n        if not include_read:\n            qs = qs.exclude(read=True)\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get(self, *args, **kwargs):\n        is_authenticated = self.get_user().is_authenticated\n        if callable(is_authenticated):\n            is_authenticated = is_authenticated()\n        if is_authenticated is not True:\n            return [], False\n        return self._message_queryset(), False", "response": "Internal method that returns a list of stored messages. Returns a tuple of the messages\n and a flag indicating whether or not all the messages originally have been retrieved."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_message(self, message, *args, **kwargs):\n        if not message.level in PERSISTENT_MESSAGE_LEVELS:\n            return message\n\n        user = kwargs.get(\"user\") or self.get_user()\n\n        try:\n            anonymous = user.is_anonymous()\n        except TypeError:\n            anonymous = user.is_anonymous\n        if anonymous:\n            raise NotImplementedError('Persistent message levels cannot be used for anonymous users.')\n        message_persistent = PersistentMessage()\n        message_persistent.level = message.level\n        message_persistent.message = message.message\n        message_persistent.extra_tags = message.extra_tags\n        message_persistent.user = user\n\n        if \"expires\" in kwargs:\n            message_persistent.expires = kwargs[\"expires\"]\n        message_persistent.save()\n        return None", "response": "Process a message and save it to the persistent store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, level, message, extra_tags='', *args, **kwargs):\n        if not message:\n            return\n            # Check that the message level is not less than the recording level.\n        level = int(level)\n        if level < self.level:\n            return\n            # Add the message.\n        self.added_new = True\n        message = Message(level, message, extra_tags=extra_tags)\n        message = self.process_message(message, *args, **kwargs)\n        if message:\n            self._queued_messages.append(message)", "response": "Adds a new message to the record."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _store(self, messages, response, *args, **kwargs):\n        return [message for message in messages if not message.level in STICKY_MESSAGE_LEVELS]", "response": "Store the messages in the storage."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_current_userprofile():\n    if current_user.is_anonymous:\n        return AnonymousUserProfile()\n\n    profile = g.get(\n        'userprofile',\n        UserProfile.get_by_userid(current_user.get_id()))\n\n    if profile is None:\n        profile = UserProfile(user_id=int(current_user.get_id()))\n        g.userprofile = profile\n    return profile", "response": "Get the current user profile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef silence_ibapi_logging(levels=[\"DEBUG\", \"INFO\"]):\n    levels = levels or [\"DEBUG\", \"INFO\"]\n\n    for level in levels:\n        if level not in (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"):\n            raise ValueError(\"unknown log level: {0}\".format(level))\n\n    for _, module_name, _ in pkgutil.iter_modules(ibapi.__path__):\n        module = __import__(\"ibapi.{0}\".format(module_name), fromlist=\"ibapi\")\n        if not hasattr(module, \"logging\"):\n            continue\n\n        for level in levels:\n            setattr(module.logging, level.lower(), noop)", "response": "Silences the excessive ibapi logging to the root logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a message to the request.", "response": "def add_message(request, level, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    \"\"\"\n    Attempts to add a message to the request using the 'messages' app.\n    \"\"\"\n    if hasattr(request, '_messages'):\n        return request._messages.add(level, message, extra_tags, *args, **kwargs)\n    if not fail_silently:\n        raise MessageFailure('You cannot add messages without installing '\n                             'django.contrib.messages.middleware.MessageMiddleware')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef persistant_debug(request, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    add_message(request, DEBUG_PERSISTENT, message, extra_tags=extra_tags,\n                fail_silently=fail_silently, *args, **kwargs)", "response": "Adds a persistant message with the DEBUG level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a persistant message with the INFO level.", "response": "def persistant_info(request, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    \"\"\"\n    Adds a persistant message with the ``INFO`` level.\n    \"\"\"\n    add_message(request, INFO_PERSISTENT, message, extra_tags=extra_tags,\n                fail_silently=fail_silently, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a persistant message with the SUCCESS level.", "response": "def persistant_success(request, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    \"\"\"\n    Adds a persistant message with the ``SUCCESS`` level.\n    \"\"\"\n    add_message(request, SUCCESS_PERSISTENT, message, extra_tags=extra_tags,\n                fail_silently=fail_silently, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a persistant message with the WARNING level.", "response": "def persistant_warning(request, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    \"\"\"\n    Adds a persistant message with the ``WARNING`` level.\n    \"\"\"\n    add_message(request, WARNING_PERSISTENT, message, extra_tags=extra_tags,\n                fail_silently=fail_silently, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef persistant_error(request, message, extra_tags='', fail_silently=False, *args, **kwargs):\n    add_message(request, ERROR_PERSISTENT, message, extra_tags=extra_tags,\n                fail_silently=fail_silently, *args, **kwargs)", "response": "Adds a persistant message with the ERROR level."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _chunks(self, items, limit):\n        for i in range(0, len(items), limit):\n            yield items[i:i + limit]", "response": "Yield successive chunks from list items with a minimum size \\ a limit \\ a limit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a GCM message for one or more devices using json data", "response": "def send(self, data, registration_ids=None, **kwargs):\n        \"\"\"\n        Send a GCM message for one or more devices, using json data\n        registration_ids: A list with the devices which will be receiving a message\n        data: The dict data which will be send\n        Optional params e.g.:\n            collapse_key: A string to group messages\n        For more info see the following documentation:\n        https://developer.android.com/google/gcm/server-ref.html#send-downstream\n        \"\"\"\n\n        if not isinstance(data, dict):\n            data = {'msg': data}\n\n        registration_ids = registration_ids or []\n\n        if len(registration_ids) > conf.GCM_MAX_RECIPIENTS:\n            ret = []\n            for chunk in self._chunks(\n                    registration_ids, conf.GCM_MAX_RECIPIENTS):\n                ret.append(self.send(data, registration_ids=chunk, **kwargs))\n            return ret\n\n        values = {\n            'data': data,\n            'collapse_key': 'message'}\n        if registration_ids:\n            values.update({'registration_ids': registration_ids})\n        values.update(kwargs)\n\n        values = json.dumps(values)\n\n        headers = {\n            'UserAgent': \"GCM-Server\",\n            'Content-Type': 'application/json',\n            'Authorization': 'key=' + self.api_key}\n\n        response = requests.post(\n            url=\"https://gcm-http.googleapis.com/gcm/send\",\n            data=values, headers=headers)\n\n        response.raise_for_status()\n        return registration_ids, json.loads(force_text(response.content))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the week corresponding to the proleptic Gregorian ordinal.", "response": "def fromordinal(cls, ordinal):\n        \"\"\"Return the week corresponding to the proleptic Gregorian ordinal,\n        where January 1 of year 1 starts the week with ordinal 1.\n        \"\"\"\n        if ordinal < 1:\n            raise ValueError(\"ordinal must be >= 1\")\n        return super(Week, cls).__new__(cls, *(date.fromordinal((ordinal-1) * 7 + 1).isocalendar()[:2]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a week initialized from an ISO formatted string like 2011W08 or 2011 - W08.", "response": "def fromstring(cls, isostring):\n        \"\"\"Return a week initialized from an ISO formatted string like \"2011W08\" or \"2011-W08\".\"\"\"\n        if isinstance(isostring, basestring) and len(isostring) == 7 and isostring[4] == 'W':\n           return cls(int(isostring[0:4]), int(isostring[5:7]))\n        elif isinstance(isostring, basestring) and len(isostring) == 8 and isostring[4:6] == '-W':\n           return cls(int(isostring[0:4]), int(isostring[6:8]))\n        else:\n            raise ValueError(\"Week.tostring argument must be on the form <yyyy>W<ww>; got %r\" % (isostring,))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef weeks_of_year(cls, year):\n        w = cls(year, 1)\n        while w.year == year:\n            yield w\n            w += 1", "response": "Return an iterator over the weeks of the given year."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef last_week_of_year(cls, year):\n        if year == cls.max.year:\n            return cls.max\n        return cls(year+1, 0)", "response": "Return the last week of the given year."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the given day of week as a date object. Day 0 is the Monday. Day 4 is the Sunday. Day 4 is the Sunday. Day 0 is the Sunday. Day 4 is the Sunday. Day 0 is the Sunday. Day 4 is the Sunday. Day 0 is the Sunday. Day 4 is the Sunday. Day 0 is the Sunday. Day 4 is the Sunday. Day 0 is the Sunday. Day 4 is the Sunday.", "response": "def day(self, num):\n        \"\"\"Return the given day of week as a date object.  Day 0 is the Monday.\"\"\"\n        d = date(self.year, 1, 4)  # The Jan 4th must be in week 1 according to ISO\n        return d + timedelta(weeks=self.week-1, days=-d.weekday() + num)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef days(self):\n        monday = self.day(0)\n        return [monday + timedelta(days=i) for i in range(7)]", "response": "Return the 7 days of the week as a list of datetime. date objects"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a Week with either the year or week attribute value replaced", "response": "def replace(self, year=None, week=None):\n        \"\"\"Return a Week with either the year or week attribute value replaced\"\"\"\n        return self.__class__(self.year if year is None else year,\n                              self.week if week is None else week)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse alert timestamp return UTC datetime object to maintain Python 2 compatibility.", "response": "def _ts_parse(ts):\n    \"\"\"Parse alert timestamp, return UTC datetime object to maintain Python 2 compatibility.\"\"\"\n    dt = datetime.strptime(ts[:19],\"%Y-%m-%dT%H:%M:%S\")\n    if ts[19] == '+':\n        dt -= timedelta(hours=int(ts[20:22]),minutes=int(ts[23:]))\n    elif ts[19] == '-':\n        dt += timedelta(hours=int(ts[20:22]),minutes=int(ts[23:]))\n    return dt.replace(tzinfo=pytz.UTC)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprovide a sanitized & serializeable dict of the alert mainly for forward & backwards compatibility", "response": "def _serialized(self):\n        \"\"\"Provides a sanitized & serializeable dict of the alert mainly for forward & backwards compatibility\"\"\"\n        return {'title': self.title,\n                'summary': self.summary,\n                'areadesc': self.areadesc,\n                'event': self.event,\n                'samecodes': self.samecodes,\n                'zonecodes': self.zonecodes,\n                'expiration': self.expiration,\n                'updated': self.updated,\n                'effective': self.effective,\n                'published': self.published,\n                'severity': self.severity,\n                'category': self.category,\n                'urgency': self.urgency,\n                'msgtype': self.msgtype,\n                'link': self.link,\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_buf(self, prefix):\n\n        kind = \"{prefix}buf\".format(prefix=prefix)\n        private_name = \"_\" + kind\n        buf = getattr(self, private_name)\n\n        if buf:\n            return buf\n\n        try:\n            buf_string = self.raw_data[\"result\"][kind]\n        except KeyError:\n            buf_string = self.ensure(kind, str)\n        if buf_string:\n            message = Message(\n                buf_string,\n                self.raw_data,\n                parse_buf=self._parse_buf,\n                on_error=self._on_error,\n                on_malformation=self._on_malformation\n            )\n            if message.is_error:\n                self._handle_error(message.error_message)\n            setattr(self, private_name, message)\n        return getattr(self, private_name)", "response": "Lazy read - only accessor for the a |qbuf. A |q| object is cached for subsequent requests."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the list of DNS measurement responses for the current entry.", "response": "def build_responses(self):\n        \"\"\"\n        DNS measurement results are a little wacky.  Sometimes you get a single\n        response, other times you get a set of responses (result set).  In order\n        to establish a unified interface, we conform all results to the same\n        format: a list of response objects.\n\n        Additionally, the qbuf property is weird too.  In the case of multiple\n        responses, there's one qbuf for every response, but for single results,\n        it's not stored in the result, but rather the outer result data.  Again,\n        for the purposes of uniformity, we shoehorn the qbuf into the first (and\n        only) response in the latter case.\n        \"\"\"\n\n        responses = []\n        part_of_set = True\n\n        # Account for single results\n        if \"result\" in self.raw_data:\n            if \"qbuf\" in self.raw_data:\n                if \"qbuf\" not in self.raw_data[\"result\"]:\n                    self.raw_data[\"result\"][\"qbuf\"] = self.raw_data.pop(\"qbuf\")\n            responses.append(self.raw_data[\"result\"])\n            part_of_set = False\n\n        try:\n            self.responses_total = int(self.raw_data[\"result\"][\"submax\"])\n        except (KeyError, ValueError):\n            pass  # The value wasn't there, not much we can do about it\n\n        try:\n            responses += self.raw_data[\"resultset\"]\n        except KeyError:\n            pass  # self.responses remains the same\n\n        return part_of_set, responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_protocol(self, protocol):\n        if protocol is not None:\n            try:\n                return self.PROTOCOL_MAP[protocol]\n            except KeyError:\n                self._handle_malformation(\n                    '\"{protocol}\" is not a recognised protocol'.format(\n                        protocol=protocol\n                    )\n                )", "response": "Clean the protocol value for a specific record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(cls, data, **kwargs):\n\n        raw_data = data\n        if isinstance(data, string):\n            raw_data = Json.loads(data)\n\n        try:\n            kind = raw_data[\"type\"].lower()\n        except KeyError:\n            raise ResultParseError(\"No type value was found in the JSON input\")\n\n        if kind == \"ping\":\n            from .ping import PingResult\n            return PingResult(raw_data, **kwargs)\n        elif kind == \"traceroute\":\n            from .traceroute import TracerouteResult\n            return TracerouteResult(raw_data, **kwargs)\n        elif kind == \"dns\":\n            from .dns import DnsResult\n            return DnsResult(raw_data, **kwargs)\n        elif kind == \"sslcert\":\n            from .ssl import SslResult\n            return SslResult(raw_data, **kwargs)\n        elif kind == \"http\":\n            from .http import HttpResult\n            return HttpResult(raw_data, **kwargs)\n        elif kind == \"ntp\":\n            from .ntp import NtpResult\n            return NtpResult(raw_data, **kwargs)\n        elif kind == \"wifi\":\n            from .wifi import WiFiResult\n            return WiFiResult(raw_data, **kwargs)\n\n        raise ResultParseError(\"Unknown type value was found in the JSON input\")", "response": "Return a new instance of the appropriate class based on the type of the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_median(given_list):\n        median = None\n\n        if not given_list:\n            return median\n\n        given_list = sorted(given_list)\n        list_length = len(given_list)\n\n        if list_length % 2:\n            median = given_list[int(list_length / 2)]\n        else:\n            median = (given_list[int(list_length / 2)] + given_list[int(list_length / 2) - 1]) / 2.0\n\n        return median", "response": "Calculates the median of values in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an x509. Name. A name attribute to a string.", "response": "def _name_attribute_to_string(self, name):\n        \"\"\"\n        Build a /-separated string from an x509.Name.\n        \"\"\"\n        return \"\".join(\n            \"/{}={}\".format(\n                self._get_oid_name(attr.oid),\n                attr.value,\n            )\n            for attr in name\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_subject_alternative_names(self, ext):\n        values = []\n        for san in ext.value:\n            if isinstance(san.value, string):\n                # Pass on simple string SAN values\n                values.append(san.value)\n            elif isinstance(san.value, x509.Name):\n                # In theory there there could be >1 RDN here...\n                values.extend(\n                    self._name_attribute_to_string(rdn) for rdn in san.value.rdns\n                )\n        return values", "response": "Returns a list of Subject Alternative Name values for the given x509 extension object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checksum_chain(self):\n\n        checksums = []\n        for certificate in self.certificates:\n            checksums.append(certificate.checksum)\n\n        return \"::\".join(checksums)", "response": "Returns a list of checksums joined with \"::\"."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures the USB - ISS controller with the SPI mode and operating frequency", "response": "def configure(self):\n        \"\"\"\n        Configure SPI controller with the SPI mode and operating frequency\n        \"\"\"\n\n        # Convert standard SPI sheme to USBISS scheme\n        lookup_table = [0, 2, 1, 3]\n        mode = lookup_table[self._mode]\n\n        # Add signal for SPI switch\n        iss_mode = self._usbiss.SPI_MODE + mode\n\n        # Configure USB-ISS\n        self._usbiss.mode = [iss_mode, self.sck_divisor]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the USBISS SPI divisor value from the input SPI clock speed and returns it.", "response": "def iss_spi_divisor(self, sck):\n        \"\"\"\n        Calculate a USBISS SPI divisor value from the input SPI clock speed\n\n        :param sck: SPI clock frequency\n        :type sck: int\n        :returns: ISS SCK divisor\n        :rtype: int\n        \"\"\"\n        _divisor = (6000000 / sck) - 1\n        divisor = int(_divisor)\n\n        if divisor != _divisor:\n            raise ValueError('Non-integer SCK divisor.')\n\n        if not 1 <= divisor < 256:\n            error = (\n                \"The value of sck_divisor, {}, \"\n                \"is not between 0 and 255\".format(divisor)\n            )\n            raise ValueError(error)\n        return divisor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exchange(self, data):\n        self._usbiss.write_data([self._usbiss.SPI_CMD] + data)\n        response = self._usbiss.read_data(1 + len(data))\n        if len(response) != 0:\n            response = self._usbiss.decode(response)\n            status = response.pop(0)\n            if status == 0:\n                raise USBISSError('SPI Transmission Error')\n            return response\n        else:\n            raise USBISSError('SPI Transmission Error: No bytes received!')", "response": "Perform SPI transaction.\n\n        The first received byte is either ACK or NACK.\n\n        :TODO: enforce rule that up to 63 bytes of data can be sent.\n        :TODO: enforce rule that there is no gaps in data bytes (what define a gap?)\n\n        :param data: List of bytes\n        :returns: List of bytes\n        :rtype: List of bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_feed_cache(self):\n        feed_cache = None\n        if os.path.exists(self._feed_cache_file):\n            maxage = datetime.now() - timedelta(minutes=self._cachetime)\n            file_ts = datetime.fromtimestamp(os.stat(self._feed_cache_file).st_mtime)\n            if file_ts > maxage:\n                try:\n                    with open(self._feed_cache_file, 'rb') as cache:\n                        feed_cache = cache.read()\n                finally:\n                    pass\n        return feed_cache", "response": "Returns the most recent cache if it exists else return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raw_cap(self, refresh=False):\n        if refresh is True:\n            self._raw = self.refresh()\n        if self._raw is None:\n            self._raw = self._get_feed_cache()\n        if self._raw is None:\n            self._raw = self.refresh()\n        return self._raw", "response": "Get the raw xml of the feed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh(self):\n        self._raw = self._get_nws_feed()\n        self._save_feed_cache(self._raw)\n        return self._raw", "response": "Refreshes the feed cache and returns the new feed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget nws alert feed and cache it", "response": "def _get_nws_feed(self):\n        \"\"\"get nws alert feed, and cache it\"\"\"\n        url = '''http://alerts.weather.gov/cap/%s.php?x=0''' % (str(self._state).lower())\n        # pylint: disable=E1103\n        xml = requests.get(url).content\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_medians_and_extremes(self):\n\n        rtts = sorted([p.rtt for p in self.packets if p.rtt is not None])\n        if rtts:\n            self.rtt_min = rtts[0]\n            self.rtt_max = rtts[-1]\n            self.rtt_median = self.calculate_median(rtts)\n\n        offsets = sorted(\n            [p.offset for p in self.packets if p.offset is not None]\n        )\n        if offsets:\n            self.offset_min = offsets[0]\n            self.offset_max = offsets[-1]\n            self.offset_median = self.calculate_median(offsets)", "response": "Sets the median values for rtt and offset of result packets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the list of alerts from the Alerts feed and stores it into self. _alerts", "response": "def load_alerts(self):\n        \"\"\"\n        NOTE: use refresh() instead of this, if you are just needing to refresh the alerts list\n        Gets raw xml (cap) from the Alerts feed, throws it into the parser\n        and ends up with a list of alerts object, which it stores to self._alerts\n        \"\"\"\n        self._feed = AlertsFeed(state=self.scope, maxage=self.cachetime)\n        parser = CapParser(self._feed.raw_cap(), geo=self.geo)\n        self._alerts = parser.get_alerts()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self, force=False):\n        if force is True:\n            self._feed.refresh()\n        self._alerts = CapParser(self._feed.raw_cap(), geo=self.geo).get_alerts()", "response": "Refresh the alerts list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alerts(self):\n        if self.samecodes is not None:\n            temp = []\n            for alert in self._alerts:\n                for code in alert.samecodes:\n                    if code in self.samecodes:\n                        temp.append(alert)\n            return temp\n        else:\n            return self._alerts", "response": "returns the list of alerts for the current state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef samecode_alerts(self, samecode):\n        return [x for x in self._alerts if samecode in x.samecodes]", "response": "Returns alerts for a ( single ) SAME geocode. Only useful if you didn t specify samecodes when the WeatherAlerts\n        object was created."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef county_state_alerts(self, county, state):\n        samecode = self.geo.lookup_samecode(county, state)\n        return self.samecode_alerts(samecode)", "response": "Given a county and state return a list of alerts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an event type and state and counties", "response": "def event_state_counties(self):\n        \"\"\"DEPRECATED: this will be moved elsewhere or dropped in the near future, stop using it.\n        Return an event type and it's state(s) and counties (consolidated)\"\"\"\n        # FIXME: most of this logic should be moved to the alert instance and refactored\n        counties = ''\n        state = ''\n        for alert in self._alerts:\n            locations = []\n            states = []\n            for samecode in alert.samecodes:\n                county, state = self.geo.lookup_county_state(samecode)\n                locations.append((county, state))\n                if state not in states:\n                    states.append(state)\n            for state in states:\n                counties = [x for x, y in locations if y == state]\n            counties_clean = str(counties).strip(\"[']\")\n            print(\"{0}: {1} - {2}\".format(alert.event, state, counties_clean))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_request(req, collect=False, collector_addr='tcp://127.0.0.2:2345', prefix='my_app'):\n\n    if collect:\n        collector = get_context().socket(zmq.PUSH)\n\n        collector.connect(collector_addr)\n        collector.send_multipart([prefix, ''])\n        collector.close()\n\n    requests[hash(req)] = time()", "response": "register a request in the internal request table optionally sends it to the collector"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef end_request(req, collector_addr='tcp://127.0.0.2:2345', prefix='my_app'):\n\n    req_end = time()\n    hreq = hash(req)\n\n    if hreq in requests:\n        req_time = req_end - requests[hreq]\n        req_time *= 1000\n\n        del requests[hreq]\n\n        collector = get_context().socket(zmq.PUSH)\n\n        collector.connect(collector_addr)\n        collector.send_multipart([prefix, str(req_time)])\n        collector.close()\n\n        return req_time", "response": "This function is used to end a request in a node. It is used to send the request to the collector."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_target_areas(entry):\n    target_areas = []\n    areas = str(entry['cap:areaDesc']).split(';')\n    for area in areas:\n        target_areas.append(area.strip())\n    return target_areas", "response": "Cleanup the raw target areas description string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_alerts(self):\n        emptyfeed = \"There are no active watches, warnings or advisories\"\n        alerts = []\n        if emptyfeed in str(self._raw_cap):\n            pass\n        else:\n            main_dom = minidom.parseString(self._raw_cap)\n            xml_entries = main_dom.getElementsByTagName('entry')\n            # title is currently first so we can detect an empty cap feed\n\n            for dom in xml_entries:\n                # parse the entry to a temp 'entry' dict\n                entry = self._parse_entry(dom)\n\n                # perform some cleanup before creating an object\n                # entry['locations'] = self.build_locations(entry) # FIXME: remove?\n                entry['target_areas'] = build_target_areas(entry)\n\n                alert = Alert(entry)\n                alerts.append(alert)\n                del entry\n                del alert\n\n        return alerts", "response": "Public method that parses the raw cap feed and returns a list of alerts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the entry from the VTEC and return it as a dictionary.", "response": "def _parse_entry(self, dom):\n        \"\"\"Sigh....\"\"\"\n        entry = {}\n        for tag in self._cap_tags:\n            # we need to handle the geocodes a bit differently\n            if tag == 'cap:geocode':\n                try:\n                    geotypes = []\n                    # FIXME: this will parse VTEC and add it to the feed as well, that's both a feature and a bug\n                    for item in dom.getElementsByTagName('valueName'):\n                        geotypes.append(str(item.firstChild.data))\n                    n = 0\n                    for geotype in geotypes:\n                        try:\n                            entry[geotype] = str(dom.getElementsByTagName('value')[n].firstChild.data).split(' ')\n                        except AttributeError:\n                            pass\n                        n = n + 1\n                finally:\n                    try:\n                        entry['samecodes'] = [x for x in entry['FIPS6'] if str(x).isdigit()]  # handle bad nws data\n                    except Exception:\n                        entry['samecodes'] = []\n            else:\n                try:\n                    entry[tag] = dom.getElementsByTagName(tag)[0].firstChild.data\n                except AttributeError:\n                    entry[tag] = ''\n        return entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds a notebook given its fully qualified name and an optional path", "response": "def find_notebook(fullname, path=None):\n    \"\"\"find a notebook, given its fully qualified name and an optional path\n\n    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n    does not exist.\n    \"\"\"\n    name = fullname.rsplit('.', 1)[-1]\n    if not path:\n        path = ['']\n    for d in path:\n        nb_path = os.path.join(d, name + \".ipynb\")\n        if os.path.isfile(nb_path):\n            return nb_path\n        # let import Notebook_Name find \"Notebook Name.ipynb\"\n        nb_path = nb_path.replace(\"_\", \" \")\n        if os.path.isfile(nb_path):\n            return nb_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting a notebook as a module", "response": "def load_module(self, fullname):\n        \"\"\"import a notebook as a module\"\"\"\n        path = find_notebook(fullname, self.path)\n\n        print (\"importing Jupyter notebook from %s\" % path)\n\n        # load the notebook object\n        with io.open(path, 'r', encoding='utf-8') as f:\n            nb = read(f, 4)\n\n\n        # create the module and add it to sys.modules if name in sys.modules:\n        #    return sys.modules[name]\n        mod = types.ModuleType(fullname)\n        mod.__file__ = path\n        mod.__loader__ = self\n        mod.__dict__['get_ipython'] = get_ipython\n        sys.modules[fullname] = mod\n\n        # extra work to ensure that magics that would affect the user_ns\n        # actually affect the notebook module's ns\n        save_user_ns = self.shell.user_ns\n        self.shell.user_ns = mod.__dict__\n\n        try:\n          for cell in nb.cells:\n            if cell.cell_type == 'code':\n                # transform the input to executable Python\n                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n                # run the code in themodule\n                exec(code, mod.__dict__)\n        finally:\n            self.shell.user_ns = save_user_ns\n        return mod"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning full location given samecode or county and state. Returns False if not valid.", "response": "def location_lookup(self, req_location):\n        \"\"\"\n        returns full location given samecode or county and state. Returns False if not valid.\n\n        *currently locations are a dictionary, once other geo data is added, they will move to a location class/obj*\n        \"\"\"\n        location = False\n        try:\n            location = self.samecodes[req_location['code']]\n        except Exception:\n            pass\n        try:\n            location = self.lookup_samecode(req_location['local'], req_location['state'])\n        except Exception:\n            pass\n        return location"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup_samecode(self, local, state):\n        for location in self.samecodes:\n            if state.lower() == self.samecodes[location]['state'].lower():\n                if local.lower() == self.samecodes[location]['local'].lower():\n                    return self.samecodes[location]\n        return False", "response": "Given County state return the SAME code for specified location. Return False if not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getfeedscope(self, geocodes):\n        states = self._get_states_from_samecodes(geocodes)\n        if len(states) >= 2:\n            return 'US'\n        else:\n            return states[0]", "response": "Given a list of SAME codes return the state that needs to be parsed to determine if they are all in one state. Otherwise return US."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_states_from_samecodes(self, geocodes):\n        states = []\n        for code in geocodes:\n            if not isinstance(geocodes, list):\n                raise Exception(\"specified geocodes must be list\")\n            try:\n                state = self.samecodes[code]['state']\n            except KeyError:\n                raise Exception(\"Samecode Not Found\")\n            else:\n                if state not in states:\n                    states.append(state)\n        return states", "response": "Returns all states for a given list of SAME codes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_same_codes(self, refresh=False):\n        if refresh is True:\n            self._get_same_codes()\n        else:\n            self._cached_same_codes()", "response": "Loads the Same Codes into this object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting SAME codes load into a dict and cache", "response": "def _get_same_codes(self):\n        \"\"\"get SAME codes, load into a dict and cache\"\"\"\n        same = {}\n        url = '''http://www.nws.noaa.gov/nwr/data/SameCode.txt'''\n        # pylint: disable=E1103\n        raw = requests.get(url).content.decode('utf-8')  # py3 compatibility\n        for row in raw.split('\\n'):\n            try:\n                code, local, state = str(row).strip().split(',')\n                location = {'code': code, 'local': local, 'state': state.strip()}\n                # when I contacted the nws to add a missing same code\n                # they added a space before the state in the samecodes file\n                # stripping it out\n                same[code] = location\n            finally:\n                pass\n        cache = open(self._same_cache_file, 'wb')\n        cPickle.dump(same, cache)\n        cache.close()\n        return same"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if a cached copy is available and return it", "response": "def _cached_same_codes(self):\n        \"\"\"If a cached copy is available, return it\"\"\"\n        cache_file = self._same_cache_file\n        if os.path.exists(cache_file):\n            maxage = datetime.now() - timedelta(minutes=4320)\n            file_ts = datetime.fromtimestamp(os.stat(cache_file).st_mtime)\n            if file_ts > maxage:\n                try:\n                    cache = open(cache_file, 'rb')\n                    self._samecodes = cPickle.load(cache)\n                    cache.close()\n                    return True\n                finally:\n                    pass\n        self.reload()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate nreq requests taking a random amount of time between 0 and 0. 5 seconds", "response": "def run(self):\n        \"\"\"\n        generate <nreq> requests taking a random amount of time between 0 and 0.5 seconds\n        \"\"\"\n        for i in xrange(self.nreq):\n            req = '%s_%s' % (self.ident, i)\n            pre_request(None, req)\n            sleep(random() / 2)\n            post_request(None, req)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_destination_ip_responded(self, last_hop):\n        if not self.destination_address:\n            return\n\n        for packet in last_hop.packets:\n            if packet.origin and \\\n                    self.destination_address == packet.origin:\n                self.destination_ip_responded = True\n                break", "response": "Sets the flag if destination IP responded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_last_hop_responded(self, last_hop):\n        for packet in last_hop.packets:\n            if packet.rtt:\n                self.last_hop_responded = True\n                break", "response": "Sets the flag if last hop responded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the flag if traceroute result is successful or not.", "response": "def set_is_success(self, last_hop):\n        \"\"\"Sets the flag if traceroute result is successful or not.\"\"\"\n        for packet in last_hop.packets:\n            if packet.rtt and not packet.is_error:\n                self.is_success = True\n                break\n        else:\n            self.set_last_hop_errors(last_hop)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_last_hop_errors(self, last_hop):\n        if last_hop.is_error:\n            self.last_hop_errors.append(last_hop.error_message)\n            return\n\n        for packet in last_hop.packets:\n            if packet.is_error:\n                self.last_hop_errors.append(packet.error_message)", "response": "Sets the last hop s errors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ip_path(self):\n        r = []\n        for hop in self.hops:\n            r.append([packet.origin for packet in hop.packets])\n        return r", "response": "Returns just the IPs from the traceroute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(cls, buf, options=None):\n\n        error = []\n        do_header = True\n        do_question = True\n        do_answer = True\n        do_authority = True\n        do_additional = True\n        do_options = True\n\n        if options and isinstance(options, dict):\n            if 'DO_Header' in options and not options['DO_Header']:\n                do_header = options['DO_Header']\n            if 'DO_Question' in options and not options['DO_Question']:\n                do_question = options['DO_Question']\n            if 'DO_Answer' in options and not options['DO_Answer']:\n                do_answer = options['DO_Answer']\n            if 'DO_Authority' in options and not options['DO_Authority']:\n                do_authority = options['DO_Authority']\n            if 'DO_Additional' in options and not options['DO_Additional']:\n                do_additional = options['DO_Additional']\n            if 'DO_Options' in options and not options['DO_Options']:\n                do_options = options['DO_Options']\n\n        dnsres = {}\n        offset = 0\n        offset, hdr = cls._parse_header(buf, offset, error)\n        if do_header:\n            dnsres['HEADER'] = hdr\n        for i in range(hdr['QDCOUNT']):\n            res = cls._do_query(buf, offset, error)\n            if res is None:\n                e = ('additional', offset, ('_do_query failed, additional record %d' % i))\n                error.append(e)\n                dnsres['ERROR'] = error\n                return dnsres\n            offset, qry = res\n            if do_question:\n                if i == 0:\n                    dnsres['QuestionSection'] = [qry]\n                else:\n                    dnsres['QuestionSection'].append(qry)\n        for i in range(hdr['ANCOUNT']):\n            res = cls._do_rr(buf, offset, error, hdr)\n            if res is None:\n                e = ('additional', offset, ('_do_rr failed, additional record %d' % i))\n                error.append(e)\n                dnsres['ERROR'] = error\n                return dnsres\n            offset, rr = res\n            if do_answer:\n                if i == 0:\n                    dnsres['AnswerSection'] = [rr]\n                else:\n                    dnsres['AnswerSection'].append(rr)\n        for i in range(hdr['NSCOUNT']):\n            res = cls._do_rr(buf, offset, error, hdr)\n            if res is None:\n                e = ('additional', offset, ('_do_rr failed, additional record %d' % i))\n                error.append(e)\n                dnsres['ERROR'] = error\n                return dnsres\n            offset, rr = res\n            if do_authority:\n                if i == 0:\n                    dnsres['AuthoritySection'] = [rr]\n                else:\n                    dnsres['AuthoritySection'].append(rr)\n        for i in range(hdr['ARCOUNT']):\n            res = cls._do_rr(buf, offset, error, hdr)\n            if res is None:\n                e = ('additional', offset, ('_do_rr failed, additional record %d' % i))\n                error.append(e)\n                dnsres['ERROR'] = error\n                return dnsres\n            offset, rr = res\n            if do_options:\n                if \"EDNS0\" in rr:\n                    dnsres['EDNS0'] = rr['EDNS0']\n                    continue\n            if do_additional:\n                if 'AdditionalSection' in dnsres:\n                    dnsres['AdditionalSection'].append(rr)\n                else:\n                    dnsres['AdditionalSection'] = [rr]\n        hdr['ReturnCode'] = cls._rcode_to_text(hdr['ReturnCode'])\n\n        if offset < len(buf):\n            e = ('end', offset, 'trailing garbage, buf size = %d' % len(buf))\n            error.append(e)\n            #result['decodedabufs_with_ERROR'] += 1\n            dnsres['ERROR'] = error\n\n        return dnsres", "response": "Parse an internal record from a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget information about the USB - ISS.", "response": "def get_iss_info(self):\n        \"\"\"\n        Get information about the USB-ISS\n\n        Querying will return three bytes;\n        - the module ID (7),\n        - firmware version (currently 2),\n        - the current operating mode.\n        \"\"\"\n        self.write_data([self.ISS_CMD, self.ISS_VERSION])\n        response = self.read_data(3)\n        if len(response) == 3:\n            response = self.decode(response)\n            self.module = response[0]\n            self.firmware = response[1]\n            self._mode = response[2]\n        else:\n            raise USBISSError(\"Could not get version details\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the serial number of the USB - ISS module.", "response": "def get_iss_serial_no(self):\n        \"\"\" Get serial number of USB-ISS module\n        \"\"\"\n        self.write_data([self.ISS_CMD, self.ISS_SER_NUM])\n        # Return 8 bytes serial number\n        self.iss_sn = self.read_data(8)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the operating protocol of the USB - ISS with additional additional parameters for the USB - ISS.", "response": "def mode(self, set_bytes):\n        \"\"\"Set the operating protocol of the USB-ISS with additional\n        parameters for the  protocol\n        \"\"\"\n        self._mode = set_bytes\n        data = [self.ISS_CMD, self.ISS_SET_MODE] + set_bytes\n        self.write_data(data)\n        response = self.read_data(2)\n        if response[0] == 0:\n            error_dict = {\n                0x05: 'Unknown Command',\n                0x06: 'Internal Error 1',\n                0x07: 'Internal Error 2'\n            }\n            try:\n                raise USBISSError(error_dict[response(1)])\n            except KeyError:\n                raise USBISSError('Undocumented Error')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keys_to_datetime(obj, *keys):\n    if not keys:\n        return obj\n    for k in keys:\n        if k not in obj:\n            continue\n        v = obj[k]\n        if not isinstance(v, string_types):\n            continue\n        obj[k] = parse_datetime(v)\n    return obj", "response": "Converts all the keys in an object to DateTime instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a time - string into a valid .", "response": "def parse_datetime(s, **kwargs):\n    \"\"\" Converts a time-string into a valid\n    :py:class:`~datetime.datetime.DateTime` object.\n\n        Args:\n            s (str): string to be formatted.\n\n        ``**kwargs`` is passed directly to :func:`.dateutil_parser`.\n\n        Returns:\n            :py:class:`~datetime.datetime.DateTime`\n    \"\"\"\n    if not s:\n        return None\n    try:\n        ret = dateutil_parser(s, **kwargs)\n    except (OverflowError, TypeError, ValueError) as e:\n        logger.exception(e, exc_info=True)\n        reraise('datetime parsing error from %s' % s, e)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of directories matching the given glob pattern.", "response": "def browse(self, path=None):\n        \"\"\" Returns a list of directories matching the path given.\n\n        Args:\n            path (str): glob pattern.\n\n        Returns:\n            List[str]\n        \"\"\"\n        params = None\n        if path:\n            assert isinstance(path, string_types)\n            params = {'current': path}\n        return self.get('browse', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_config(self, config, and_restart=False):\n        assert isinstance(config, dict)\n        self.post('config', data=config)\n        if and_restart:\n            self.restart()", "response": "Post the full contents of the configuration dictionary to disk\n        and restart Syncthing to hold the activate flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether the running configuration is in sync.", "response": "def config_insync(self):\n        \"\"\" Returns whether the config is in sync, i.e. whether the running\n            configuration is the same as that on disk.\n\n            Returns:\n                bool\n        \"\"\"\n        status = self.get('config/insync').get('configInSync', False)\n        if status is None:\n            status = False\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of recent errors.", "response": "def errors(self):\n        \"\"\" Returns the list of recent errors.\n\n            Returns:\n                list: of :obj:`.ErrorEvent` tuples.\n        \"\"\"\n        ret_errs = list()\n        errors = self.get('error').get('errors', None) or list()\n        assert isinstance(errors, list)\n        for err in errors:\n            when = parse_datetime(err.get('when', None))\n            msg = err.get('message', '')\n            e = ErrorEvent(when, msg)\n            ret_errs.append(e)\n        return ret_errs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_error(self, message):\n        assert isinstance(message, string_types)\n        self.post('error', data=message)", "response": "Send an error message to the active client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npause the given device.", "response": "def pause(self, device):\n        \"\"\" Pause the given device.\n\n            Args:\n                device (str): Device ID.\n\n            Returns:\n                dict: with keys ``success`` and ``error``.\n        \"\"\"\n        resp = self.post('pause', params={'device': device},\n                         return_response=True)\n        error = resp.text\n        if not error:\n            error = None\n        return {'success': resp.status_code == requests.codes.ok,\n                'error': error}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nerases the database index from a given folder and restart Syncthing.", "response": "def reset_folder(self, folder):\n        \"\"\" Erase the database index from a given folder and restart Syncthing.\n\n            Args:\n                folder (str): Folder ID.\n\n            Returns:\n                None\n        \"\"\"\n        warnings.warn('This is a destructive action that cannot be undone.')\n        self.post('reset', data={}, params={'folder': folder})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the directory tree of the global model.", "response": "def browse(self, folder, levels=None, prefix=None):\n        \"\"\" Returns the directory tree of the global model.\n\n            Directories are always JSON objects (map/dictionary), and files are\n            always arrays of modification time and size. The first integer is\n            the files modification time, and the second integer is the file\n            size.\n\n            Args:\n                folder (str): The root folder to traverse.\n                levels (int): How deep within the tree we want to dwell down.\n                    (0 based, defaults to unlimited depth)\n                prefix (str): Defines a prefix within the tree where to start\n                    building the structure.\n\n            Returns:\n                dict\n        \"\"\"\n        assert isinstance(levels, int) or levels is None\n        assert isinstance(prefix, string_types) or prefix is None\n        return self.get('browse', params={'folder': folder,\n                                          'levels': levels,\n                                          'prefix': prefix})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef completion(self, device, folder):\n        return self.get(\n            'completion',\n            params={'folder': folder, 'device': device}\n        ).get('completion', None)", "response": "Returns the completion percentage of a given device and folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying patterns to folder s. stignore file. Returns a dictionary with the response", "response": "def set_ignores(self, folder, *patterns):\n        \"\"\" Applies ``patterns`` to ``folder``'s ``.stignore`` file.\n\n            Args:\n                folder (str):\n                patterns (str):\n\n            Returns:\n                dict\n        \"\"\"\n        if not patterns:\n            return {}\n        data = {'ignore': list(patterns)}\n        return self.post('ignores', params={'folder': folder}, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef need(self, folder, page=None, perpage=None):\n        assert isinstance(page, int) or page is None\n        assert isinstance(perpage, int) or perpage is None\n        return self.get('need', params={'folder': folder,\n                                 'page': page,\n                                 'perpage': perpage})", "response": "Returns a list of files which are needed by this device in order\n            for it to become in sync."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrequest immediate rescan of a folder or a specific path within a folder.", "response": "def scan(self, folder, sub=None, next_=None):\n        \"\"\" Request immediate rescan of a folder, or a specific path within a\n        folder.\n\n            Args:\n                folder (str): Folder ID.\n                sub (str): Path relative to the folder root. If sub is omitted\n                    the entire folder is scanned for changes, otherwise only\n                    the given path children are scanned.\n                next_ (int): Delays Syncthing's automated rescan interval for\n                    a given amount of seconds.\n\n            Returns:\n                str\n        \"\"\"\n        if not sub:\n            sub = ''\n        assert isinstance(sub, string_types)\n        assert isinstance(next_, int) or next_ is None\n        return self.post('scan', params={'folder': folder,\n                                         'sub': sub,\n                                         'next': next_})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _events(self, using_url, filters=None, limit=None):\n\n        # coerce\n        if not isinstance(limit, (int, NoneType)):\n            limit = None\n\n        # coerce\n        if filters is None:\n            filters = []\n\n        # format our list into the correct expectation of string with commas\n        if isinstance(filters, string_types):\n            filters = filters.split(',')\n\n        # reset the state if the loop was broken with `stop`\n        if not self.blocking:\n            self.blocking = True\n\n        # block/long-poll for updates to the events api\n        while self.blocking:\n            params = {\n                'since': self._last_seen_id,\n                'limit': limit,\n            }\n\n            if filters:\n                params['events'] = ','.join(map(str, filters))\n\n            try:\n                data = self.get(using_url, params=params, raw_exceptions=True)\n            except (ConnectTimeout, ConnectionError) as e:\n                # swallow timeout errors for long polling\n                data = None\n            except Exception as e:\n                reraise('', e)\n\n            if data:\n                # update our last_seen_id to move our event counter forward\n                self._last_seen_id = data[-1]['id']\n                for event in data:\n                    # handle potentially multiple events returned in a list\n                    self._count += 1\n                    yield event", "response": "A long - polling method that queries Syncthing for events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the ID of each node in a discourse graph as a label attribute.", "response": "def add_node_ids_as_labels(discoursegraph):\n    \"\"\"\n    Adds the ID of each node of a discourse graph as a label (an attribute\n    named ``label`` with the value of the node ID) to itself. This will\n    ignore nodes whose ID isn't a string or which already have a label\n    attribute.\n\n    Parameters\n    ----------\n    discoursegraph : DiscourseDocumentGraph\n    \"\"\"\n    for node_id, properties in discoursegraph.nodes_iter(data=True):\n        if 'label' not in properties and isinstance(node_id, (str, unicode)):\n            discoursegraph.node[node_id]['label'] = ensure_utf8(node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_to_geoff(discoursegraph):\n    dg_copy = deepcopy(discoursegraph)\n    layerset2list(dg_copy)\n    add_node_ids_as_labels(dg_copy)\n    return graph2geoff(dg_copy, 'LINKS_TO')", "response": "Convert a discourse document graph into a GEOFF string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_geoff(discoursegraph, output_file):\n    if isinstance(output_file, str):\n        with open(output_file, 'w') as outfile:\n            outfile.write(convert_to_geoff(discoursegraph))\n    else:  # output_file is a file object\n        output_file.write(convert_to_geoff(discoursegraph))", "response": "Converts a DiscourseDocumentGraph into a Geoff file and writes it to the given file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef redirect_to_sudo(next_url, sudo_url=None):\n    if sudo_url is None:\n        sudo_url = URL\n\n    sudo_url_parts = list(urlparse(resolve_url(sudo_url)))\n\n    querystring = QueryDict(sudo_url_parts[4], mutable=True)\n    querystring[REDIRECT_FIELD_NAME] = next_url\n    sudo_url_parts[4] = querystring.urlencode(safe='/')\n\n    return HttpResponseRedirect(urlunparse(sudo_url_parts))", "response": "Redirects the user to the login page passing the given next url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns tree positions of all leaves of a subtree.", "response": "def subtree_leaf_positions(subtree):\n    \"\"\"Return tree positions of all leaves of a subtree.\"\"\"\n    relative_leaf_positions = subtree.treepositions('leaves')\n    subtree_root_pos = subtree.treeposition()\n    absolute_leaf_positions = []\n    for rel_leaf_pos in relative_leaf_positions:\n        absolute_leaf_positions.append( subtree_root_pos + rel_leaf_pos)\n    return absolute_leaf_positions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_span(parented_tree):\n    all_leaves = all_leaf_positions(parented_tree)\n    if is_root(parented_tree):\n        return t('span', ['1', str(len(all_leaves))])\n    \n    subtree_leaves = subtree_leaf_positions(parented_tree)\n    if len(subtree_leaves) == 1:\n        edu_id = all_leaves.index(subtree_leaves[0]) + 1\n        return t('leaf', [str(edu_id)])\n    elif len(subtree_leaves) > 1:\n        first_edu_id = all_leaves.index(subtree_leaves[0]) + 1\n        last_edu_id = all_leaves.index(subtree_leaves[-1]) + 1\n        return t('span', [str(first_edu_id), str(last_edu_id)])\n    else:\n        raise NotImplementedError('Subtree has no leaves')", "response": "Create a span or leaf subtree for dis / lisp - formatted trees."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all direct children of the given tree that are either a nucleus satellite or a leaf node.", "response": "def get_nucsat_subtrees(parented_tree):\n    \"\"\"Return all direct children of the given tree, that are either\n    a nucleus, satellite or a leaf node (i.e. all children except\n    for relation nodes.)\n    \"\"\"\n    if is_leaf(parented_tree):\n        return [parented_tree]\n    \n    nucsat_children = []\n    for child in parented_tree:\n        if  is_leaf(child) or child.label() in ('N', 'S'):\n            nucsat_children.append(child)\n        else:\n            nucsat_children.extend( get_nucsat_subtrees(child) )\n    return nucsat_children"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dis_format(self):\n        dis_raw_str = self.disfiletree.pformat()\n        return re.sub('_!(.*?)_!', join_lines, dis_raw_str, flags=re.DOTALL)", "response": "Return a string representation of the tree in. dis format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_graphml(docgraph, output_file):\n    dg_copy = deepcopy(docgraph)\n    layerset2str(dg_copy)\n    attriblist2str(dg_copy)\n    remove_root_metadata(dg_copy)\n    nx_write_graphml(dg_copy, output_file)", "response": "Converts a document graph into GraphML format and writes it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reset_corpus_iterator(self):\n        self.__context = etree.iterparse(self.exportxml_file, events=('end',),\n                                         tag='text', recover=True)", "response": "Create an iterator over all the corpus XML elements in the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over all the text elements in an iterparse context and yield ExportXMLDocumentGraphs for each of them.", "response": "def text_iter(self, context):\n        \"\"\"\n        Iterates over all the elements in an iterparse context\n        (here: <text> elements) and yields an ExportXMLDocumentGraph instance\n        for each of them. For efficiency, the elements are removed from the\n        DOM / main memory after processing them.\n\n        If ``self.debug`` is set to ``True`` (in the ``__init__`` method),\n        this method will yield <text> elements, which can be used to construct\n        ``ExportXMLDocumentGraph``s manually.\n        \"\"\"\n        for _event, elem in context:\n            if not self.debug:\n                yield ExportXMLDocumentGraph(elem, name=elem.attrib[add_ns('id')])\n            else:\n                yield elem\n            # removes element (and references to it) from memory after processing it\n            elem.clear()\n            while elem.getprevious() is not None:\n                del elem.getparent()[0]\n        del context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses all children of an etree element", "response": "def parse_child_elements(self, element):\n        '''parses all children of an etree element'''\n        for child in element.iterchildren():\n            self.parsers[child.tag](child)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse all descendants of an etree element", "response": "def parse_descedant_elements(self, element):\n        '''parses all descendants of an etree element'''\n        for descendant in element.iterdescendants():\n            self.parsers[descendant.tag](descendant)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_connective(self, connective):\n        word_node_id = self.get_element_id(connective)\n        # add a key 'connective' to the token with add rel1/rel2 attributes as a dict and\n        # add the token to the namespace:connective layer\n        connective_attribs = {key: val for (key, val) in connective.attrib.items() if key != 'konn'}\n        word_node = self.node[word_node_id]\n        word_node['layers'].add(self.ns+':connective')\n        word_node.update({'connective': connective_attribs})", "response": "Adds a key connective to the word node with the namespace connective layer as a dict and the word node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a discourse relation to the document graph.", "response": "def add_discrel(self, discrel):\n        \"\"\"\n        Add a discourse relation to the document graph.\n\n        Parameters\n        ----------\n        add_discrel : etree.Element\n            etree representation of a <discRel> element which describes the\n            relation between two EDUs.\n            The ID of the other EDU is given in the arg2 attribute.\n            Note, that arg2 can either reference an EDU (e.g. edu_9_3_2\n            or an EDU range, e.g. edus9_3_1-5_0).\n\n        Example\n        -------\n\n           <edu xml:id=\"edu_9_3_0\">\n            <discRel relation=\"Explanation-Speechact\" marking=\"-\" arg2=\"edus9_3_1-5_0\"/>\n            <node xml:id=\"s128_504\" cat=\"SIMPX\" func=\"--\">\n            ...\n            </node>\n            <word xml:id=\"s128_3\" form=\":\" pos=\"$.\" lemma=\":\" func=\"--\" deprel=\"ROOT\"/>\n           </edu>\n\n             <edu xml:id=\"edu_9_3_1\">\n              <discRel relation=\"Continuation\" marking=\"-\" arg2=\"edu_9_3_2\"/>\n              <node xml:id=\"s128_506\" cat=\"VF\" func=\"-\" parent=\"s128_525\">\n              ...\n              </node>\n              ...\n             </edu>\n        \"\"\"\n        if self.ignore_relations is False:\n            arg1_id = self.get_element_id(discrel)\n            arg2_id = discrel.attrib['arg2']\n            reltype = discrel.attrib['relation']\n            discrel_attribs = self.element_attribs_to_dict(discrel)\n            self.node[arg1_id].update(discrel_attribs)\n            self.add_layer(arg1_id, self.ns+':discourse')\n            self.add_layer(arg1_id, self.ns+':relation')\n            self.add_edge(arg1_id, arg2_id,\n                          layers={self.ns, self.ns+':discourse', self.ns+':relation'},\n                          edge_type=dg.EdgeTypes.pointing_relation,\n                          relation=reltype,\n                          label='discourse:'+reltype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an edurange to the internal list of internal data structures.", "response": "def add_edurange(self, edurange):\n        \"\"\"\n        Parameters\n        ----------\n        edurange : etree.Element\n            etree representation of a <edurange> element\n            (annotation that groups a number of EDUs)\n            <edu-range> seems to glue together a number of `<edu> elements,\n            which may be scattered over a number of sentences\n            <edu-range> may or may not contain a span attribute\n            (it seems that the span attribute is present, when <edu-range> is\n            a descendent of <sentence>)\n\n        Example\n        -------\n\n           <edu-range xml:id=\"edus9_3_1-5_0\" span=\"s128_4..s130_7\">\n            <node xml:id=\"s128_525\" cat=\"SIMPX\" func=\"--\">\n             <edu xml:id=\"edu_9_3_1\">\n              <discRel relation=\"Continuation\" marking=\"-\" arg2=\"edu_9_3_2\"/>\n              <node xml:id=\"s128_506\" cat=\"VF\" func=\"-\" parent=\"s128_525\">\n               <node xml:id=\"s128_505\" cat=\"NX\" func=\"ON\" parent=\"s128_506\">\n                <relation type=\"expletive\"/>\n                <word xml:id=\"s128_4\" form=\"Es\" pos=\"PPER\" morph=\"nsn3\" lemma=\"es\" func=\"HD\" parent=\"s128_505\" dephead=\"s128_5\" deprel=\"SUBJ\"/>\n               </node>\n              </node>\n\n            ...\n\n          <edu-range xml:id=\"edus37_8_0-8_1\">\n           <discRel relation=\"Restatement\" marking=\"-\" arg2=\"edu_37_9_0\"/>\n           <sentence xml:id=\"s660\">\n        \"\"\"\n        edurange_id = self.get_element_id(edurange)\n        edurange_attribs = self.element_attribs_to_dict(edurange) # contains 'span' or nothing\n        self.add_node(edurange_id, layers={self.ns, self.ns+':edu:range'}, attr_dict=edurange_attribs)\n        for edu in edurange.iterdescendants('edu'):\n            edu_id = self.get_element_id(edu)\n            self.add_edge(edurange_id, edu_id, layers={self.ns, self.ns+':edu:range'},\n                          edge_type=dg.EdgeTypes.spanning_relation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_ne(self, ne):\n        ne_id = self.get_element_id(ne)\n        ne_label = 'ne:'+ne.attrib['type']\n        self.add_node(ne_id, layers={self.ns, self.ns+':ne'},\n                      attr_dict=self.element_attribs_to_dict(ne),\n                      label=ne_label)\n        # possible children: [('word', 78703), ('node', 11152), ('ne', 49)]\n        for child in ne.iterchildren():\n            child_id = self.get_element_id(child)\n            self.add_edge(ne_id, child_id, layers={self.ns, self.ns+':ne'},\n                          edge_type=dg.EdgeTypes.spanning_relation,\n                          label=ne_label)", "response": "Adds a new ne element to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a node element to the document graph.", "response": "def add_node_element(self, node):\n        \"\"\"Add a (syntax category) <node> to the document graph.\n\n        Parameters\n        ----------\n        node : etree.Element\n            etree representation of a <node> element\n            A <node> describes an element of a syntax tree.\n            The root <node> element does not have a parent attribute,\n            while non-root nodes do\n\n        Example\n        -------\n        <node xml:id=\"s1_505\" cat=\"SIMPX\" func=\"--\">\n            <node xml:id=\"s1_501\" cat=\"LK\" func=\"-\" parent=\"s1_505\">\n\n            # this is the root of the syntax tree of the sentence, but\n            # it is not the root node of the sentence, since there might\n            # be nodes outside of the tree which are children of the\n            # sentence root node (e.g. <word> elements representing a\n            # quotation mark)\n\n        \"\"\"\n        node_id = self.get_element_id(node)\n        if 'parent' in node.attrib:\n            parent_id = self.get_parent_id(node)\n        else:\n            # <node> is the root of the syntax tree of a sentence,\n            # but it might be embedded in a <edu> or <edu-range>.\n            # we want to attach it directly to the <sentence> element\n            parent_id = self.get_sentence_id(node)\n        self.add_node(node_id, layers={self.ns, self.ns+':syntax'},\n                      attr_dict=self.element_attribs_to_dict(node),\n                      label=node.attrib['cat'])\n        self.add_edge(parent_id, node_id, edge_type=dg.EdgeTypes.dominance_relation)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a relation to the internal node list.", "response": "def add_relation(self, relation):\n        \"\"\"\n        Parameters\n        ----------\n        relation : etree.Element\n            etree representation of a <relation> element\n            A <relation> always has a type attribute and inherits\n            its ID from its parent element. In the case of a non-expletive\n            relation, it also has a target attribute.\n\n        Example\n        -------\n\n          <node xml:id=\"s29_501\" cat=\"NX\" func=\"ON\" parent=\"s29_523\">\n           <relation type=\"expletive\"/>\n           <word xml:id=\"s29_2\" form=\"es\" pos=\"PPER\" morph=\"nsn3\" lemma=\"es\"\n                 func=\"HD\" parent=\"s29_501\" dephead=\"s29_14\" deprel=\"SUBJ\"/>\n          </node>\n\n          ...\n\n         <node xml:id=\"s4_507\" cat=\"NX\" func=\"ON\" parent=\"s4_513\">\n          <relation type=\"coreferential\" target=\"s1_502\"/>\n          <node xml:id=\"s4_505\" cat=\"NX\" func=\"HD\" parent=\"s4_507\">\n          ...\n          </node>\n         </node>\n        \"\"\"\n        if self.ignore_relations is False:\n            parent_node_id = self.get_parent_id(relation)\n            reltype = relation.attrib['type']\n            # add relation type information to parent node\n            self.node[parent_node_id].update({'relation': reltype})\n            self.add_layer(parent_node_id, self.ns+':'+reltype)\n            if 'target' in relation.attrib:\n                # if the relation has no target, it is either 'expletive' or\n                # 'inherent_reflexive', both of which should not be part of the\n                # 'markable' layer\n                self.add_layer(parent_node_id, self.ns+':markable')\n                target_id = relation.attrib['target']\n                self.add_edge(parent_node_id, target_id,\n                              layers={self.ns, self.ns+':'+reltype,\n                                      self.ns+':coreference'},\n                              label=reltype,\n                              edge_type=dg.EdgeTypes.pointing_relation)\n                self.add_layer(target_id, self.ns+':markable')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a secondary edge to the tree - like representation of a secedge element.", "response": "def add_secedge(self, secedge):\n        \"\"\"\n        Parameters\n        ----------\n        secedge : etree.Element\n            etree representation of a <secedge> element\n        A <secEdge> element has a cat and a parent attribute,\n        but inherits its ID from its parent element.\n        It describes a secondary edge in a tree-like syntax representation.\n\n        Example\n        -------\n           <node xml:id=\"s10_505\" cat=\"VXINF\" func=\"OV\" parent=\"s10_507\">\n            <secEdge cat=\"refvc\" parent=\"s10_504\"/>\n            <word xml:id=\"s10_6\" form=\"worden\" pos=\"VAPP\" lemma=\"werden%passiv\" func=\"HD\" parent=\"s10_505\" dephead=\"s10_7\" deprel=\"AUX\"/>\n           </node>\n        \"\"\"\n        if self.ignore_secedges is False:\n            edge_source = self.get_parent_id(secedge)\n            edge_target = self.get_element_id(secedge)\n            self.add_edge(edge_source, edge_target,\n                          layers={self.ns, self.ns+':secedge'},\n                          label='secedge:'+secedge.attrib['cat'],\n                          edge_type=dg.EdgeTypes.pointing_relation)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a sentence to the internal list of token IDs.", "response": "def add_sentence(self, sentence):\n        \"\"\"\n        Parameters\n        ----------\n        sentence : etree.Element\n            etree representation of a sentence\n            (syntax tree with coreference annotation)\n        \"\"\"\n        sent_root_id = sentence.attrib[add_ns('id')]\n        # add edge from document root to sentence root\n        self.add_edge(self.root, sent_root_id, edge_type=dg.EdgeTypes.dominance_relation)\n        self.sentences.append(sent_root_id)\n\n        sentence_token_ids = []\n\n        if 'span' in sentence.attrib:\n            # the sentence element looks like this:\n            # <sentence xml:id=\"s144\" span=\"s144_1..s144_23\">, which means that\n            # there might be <word> elements which belong to this sentence but\n            # occur after the closing </sentence> element\n            span_str = sentence.attrib['span']\n            sentence_token_ids.extend(convert_spanstring(span_str))\n        else:  # a normal sentence element, i.e. <sentence xml:id=\"s143\">\n            for descendant in sentence.iterdescendants('word'):\n                sentence_token_ids.append(self.get_element_id(descendant))\n\n        self.node[sent_root_id]['tokens'] = sentence_token_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a splitrelation element to the internal log file.", "response": "def add_splitrelation(self, splitrelation):\n        \"\"\"\n        Parameters\n        ----------\n        splitrelation : etree.Element\n            etree representation of a <splitRelation> element\n            A <splitRelation> annotates its parent element (e.g. as an anaphora).\n            Its parent can be either a <word> or a <node>.\n            A <splitRelation> has a target attribute, which describes\n            the targets (plural! e.g. antecedents) of the relation.\n\n        Example\n        -------\n            <node xml:id=\"s2527_528\" cat=\"NX\" func=\"-\" parent=\"s2527_529\">\n             <splitRelation type=\"split_antecedent\" target=\"s2527_504 s2527_521\"/>\n             <word xml:id=\"s2527_32\" form=\"beider\" pos=\"PIDAT\" morph=\"gpf\" lemma=\"beide\" func=\"-\" parent=\"s2527_528\" dephead=\"s2527_33\" deprel=\"DET\"/>\n             <word xml:id=\"s2527_33\" form=\"Firmen\" pos=\"NN\" morph=\"gpf\" lemma=\"Firma\" func=\"HD\" parent=\"s2527_528\" dephead=\"s2527_31\" deprel=\"GMOD\"/>\n            </node>\n\n            <word xml:id=\"s3456_12\" form=\"ihr\" pos=\"PPOSAT\" morph=\"nsm\" lemma=\"ihr\" func=\"-\" parent=\"s3456_507\" dephead=\"s3456_14\" deprel=\"DET\">\n             <splitRelation type=\"split_antecedent\" target=\"s3456_505 s3456_9\"/>\n            </word>\n        \"\"\"\n        if self.ignore_relations is False and self.ignore_splitrelations is False:\n            source_id = self.get_element_id(splitrelation)\n            # the target attribute looks like this: target=\"s2527_504 s2527_521\"\n            target_node_ids = splitrelation.attrib['target'].split()\n            # we'll create an additional node which spans all target nodes\n            target_span_id = '__'.join(target_node_ids)\n            reltype = splitrelation.attrib['type']\n            self.add_node(source_id,\n                          layers={self.ns, self.ns+':relation', self.ns+':'+reltype, self.ns+':markable'})\n            self.add_node(target_span_id,\n                          layers={self.ns, self.ns+':targetspan', self.ns+':'+reltype, self.ns+':markable'})\n            self.add_edge(source_id, target_span_id,\n                          layers={self.ns, self.ns+':coreference', self.ns+':splitrelation', self.ns+':'+reltype},\n                          edge_type=dg.EdgeTypes.pointing_relation)\n\n            for target_node_id in target_node_ids:\n                self.add_edge(target_span_id, target_node_id,\n                              layers={self.ns, self.ns+':'+reltype},\n                              edge_type=dg.EdgeTypes.spanning_relation)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_topic(self, topic):\n        topic_id = self.get_element_id(topic)\n        self.add_node(topic_id, layers={self.ns, self.ns+':topic'},\n                      description=topic.attrib['description'])\n        topic_tokens = []\n        for word in topic.iterdescendants('word'):\n            word_id = self.get_element_id(word)\n            topic_tokens.append(word_id)\n            self.add_edge(topic_id, word_id, layers={self.ns, self.ns+':topic'},\n                          edge_type=dg.EdgeTypes.spanning_relation)\n        self.node[topic_id]['tokens'] = topic_tokens", "response": "Adds a topic to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a word to the internal list of tokens and edge sets.", "response": "def add_word(self, word):\n        \"\"\"\n        Parameters\n        ----------\n        word : etree.Element\n            etree representation of a <word> element\n            (i.e. a token, which might contain child elements)\n        \"\"\"\n        word_id = self.get_element_id(word)\n        if word.getparent().tag in ('node', 'sentence'):\n            parent_id = self.get_parent_id(word)\n        else:\n            # ExportXML is an inline XML format. Therefore, a <word>\n            # might be embedded in weird elements. If this is the case,\n            # attach it directly to the closest <node> or <sentence> node\n            try:\n                parent = word.iterancestors(tag=('node', 'sentence')).next()\n                parent_id = self.get_element_id(parent)\n            except StopIteration as e:\n                # there's at least one weird edge case, where a <word> is\n                # embedded like this: (text (topic (edu (word))))\n                # here, we guess the sentence ID from the\n                parent_id = self.get_element_id(word).split('_')[0]\n\n        self.tokens.append(word_id)\n        # use all attributes except for the ID\n        word_attribs = self.element_attribs_to_dict(word)\n        # add the token string under the key namespace:token\n        token_str = word_attribs[self.ns+':form']\n        word_attribs.update({self.ns+':token': token_str, 'label': token_str})\n        self.add_node(word_id, layers={self.ns, self.ns+':token'},\n                      attr_dict=word_attribs)\n        self.add_edge(parent_id, word_id, edge_type=dg.EdgeTypes.dominance_relation)\n        self.parse_child_elements(word)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element_attribs_to_dict(self, element):\n        return {self.ns+':'+key: val for (key, val) in element.attrib.items()\n                if key != add_ns('id')}", "response": "Convert the. attrib attributes of an etree element into a dict leaving out the xml : id attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the ID of an element or an error if the element doesn t have one.", "response": "def get_element_id(element):\n        \"\"\"\n        Returns the ID of an element (or, if the element doesn't have one:\n        the ID of its parent). Returns an error, if both elements have no ID.\n        \"\"\"\n        id_attrib_key = add_ns('id')\n        if id_attrib_key in element.attrib:\n            return element.attrib[id_attrib_key]\n        try:\n            return element.getparent().attrib[id_attrib_key]\n        except KeyError as e:\n            raise KeyError(\n                'Neither the element \"{0}\" nor its parent \"{1}\" '\n                'have an ID'.format(element, element.getparent()))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_parent_id(element):\n        if 'parent' in element.attrib:\n            return element.attrib['parent']\n        else:\n            return element.getparent().attrib[add_ns('id')]", "response": "returns the ID of the parent of the given element"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sentence_id(self, element):\n        try:\n            sentence_elem = element.iterancestors('sentence').next()\n        except StopIteration as e:\n            warnings.warn(\"<{}> element is not a descendant of a <sentence> \"\n                          \"We'll try to extract the sentence ID from the \"\n                          \"prefix of the element ID\".format(element.tag))\n            return self.get_element_id(element).split('_')[0]\n        return self.get_element_id(sentence_elem)", "response": "returns the ID of the sentence the given element belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_node_type(dgtree):\n    if is_leaf(dgtree):\n        return TreeNodeTypes.leaf_node\n\n    root_label = dgtree.label()\n    if root_label == '':\n        assert dgtree == DGParentedTree('', []), \\\n            \"The tree has no root label, but isn't empty: {}\".format(dgtree)\n        return TreeNodeTypes.empty_tree\n    elif root_label in NUCLEARITY_LABELS:\n        return TreeNodeTypes.nuclearity_node\n    else:\n        assert isinstance(dgtree, (RSTTree, DGParentedTree)), type(dgtree)\n        return TreeNodeTypes.relation_node", "response": "Returns the type of the root node of a DGParentedTree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a treeposition return the treepositions of its children.", "response": "def get_children_treepos(self, treepos):\n        \"\"\"Given a treeposition, return the treepositions of its children.\"\"\"\n        children_treepos = []\n        for i, child in enumerate(self.dgtree[treepos]):\n            if isinstance(child, nltk.Tree):\n                children_treepos.append(child.treeposition())\n            elif is_leaf(child):\n                # we can't call .treeposition() on a leaf node\n                treepos_list = list(treepos)\n                treepos_list.append(i)\n                leaf_treepos = tuple(treepos_list)\n                children_treepos.append(leaf_treepos)\n        return children_treepos"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_siblings_treepos(self, treepos):\n        parent_pos = self.get_parent_treepos(treepos)\n        siblings_treepos = []\n\n        if parent_pos is not None:\n            for child_treepos in self.get_children_treepos(parent_pos):\n                if child_treepos != treepos:\n                    siblings_treepos.append(child_treepos)\n        return siblings_treepos", "response": "Given a treeposition return the treepositions of its siblings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cousins_treepos(self, treepos):\n        cousins_pos = []\n\n        mother_pos = self.get_parent_treepos(treepos)\n        if mother_pos is not None:\n            aunts_pos = self.get_siblings_treepos(mother_pos)\n            for aunt_pos in aunts_pos:\n                cousins_pos.extend( self.get_children_treepos(aunt_pos) )\n        return cousins_pos", "response": "Given a treeposition return the treeposition of its siblings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive the treeposition of a node return the label of its parent. Returns None if the tree has no parent.", "response": "def get_parent_label(self, treepos):\n        \"\"\"Given the treeposition of a node, return the label of its parent.\n        Returns None, if the tree has no parent.\n        \"\"\"\n        parent_pos = self.get_parent_treepos(treepos)\n        if parent_pos is not None:\n            parent = self.dgtree[parent_pos]\n            return parent.label()\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_children_labels(self, treepos):\n        children_labels = []\n        node = self.dgtree[treepos]\n        for child in node:\n            if is_leaf(child):\n                # we can't call .label() on a leaf node\n                children_labels.append(child)\n            else:\n                children_labels.append(child.label())\n        return children_labels", "response": "Given the treeposition of a node return the labels of its children."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_etree(self):\n        relations_elem = self.gen_relations()\n        header = E('header')\n        header.append(relations_elem)\n\n        self.gen_body()\n\n        tree = E('rst')\n        tree.append(header)\n\n        # The <body> contains both <segment>, as well as <group> elements.\n        # While the order of the elements should theoretically be irrelevant,\n        # rs3 files usually list the segments before the groups.\n        body = E('body')\n        for segment in self.body['segments']:\n            body.append(segment)\n        for group in self.body['groups']:\n            body.append(group)\n\n        tree.append(body)\n        return tree", "response": "generate an RST tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the relations element of an RS3 file.", "response": "def gen_relations(self):\n        \"\"\"Create the <relations> etree element of an RS3 file.\n        This represents all relation types (both 'rst' and 'multinuc').\n\n        Example relation:\n            <rel name=\"circumstance\" type=\"rst\" />\n        \"\"\"\n        relations_elem = E('relations')\n        for relname in sorted(self.relations):\n            relations_elem.append(\n                E('rel', OrderedDict([('name', relname), ('type', self.relations[relname])])))\n        return relations_elem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the body element of an RS3 file.", "response": "def gen_body(self):\n        \"\"\"Create the <body> etree element of an RS3 file (contains segments\n        and groups) given a DGParentedTree.\n        \"\"\"\n        # We need to sort the treepositions, as RSTTool relies on <segment>\n        # elements to be in linear order of the EDUs in the text.\n        for treepos in sorted(self.treepositions):\n            node = self.dgtree[treepos]\n            node_id = self.get_node_id(treepos)\n            node_type = get_node_type(node)\n\n            if node_type in (TreeNodeTypes.leaf_node,\n                             TreeNodeTypes.relation_node):\n                relname, parent_id = self.get_relname_and_parent(treepos)\n\n                attrib_list = [('id', node_id)]\n                if parent_id is not None:\n                    attrib_list.extend([('parent', parent_id), ('relname', relname)])\n\n                if node_type == TreeNodeTypes.leaf_node:\n                    self.body['segments'].append(E('segment', node, OrderedDict(attrib_list)))\n\n                else:  # node_type == TreeNodeTypes.relation_node:\n                    group_type = self.get_group_type(treepos)\n                    # insert 'type' attrib between 'id' and 'parent'\n                    attrib_list.insert(1, ('type', group_type))\n                    self.body['groups'].append(E('group', OrderedDict(attrib_list)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the relation name and parent ID tuple that a node is in.", "response": "def get_relname_and_parent(self, treepos):\n        \"\"\"Return the (relation name, parent ID) tuple that a node is in.\n        Return None if this node is not in a relation.\n        \"\"\"\n        node = self.dgtree[treepos]\n        node_type = get_node_type(node)\n        assert node_type in (TreeNodeTypes.relation_node, TreeNodeTypes.leaf_node)\n\n        parent_pos = self.get_parent_treepos(treepos)\n        if parent_pos is None:  # a root node has no upward relation\n            return None, None\n        else:\n            parent_label = self.get_parent_label(treepos)\n            grandparent_pos = self.get_parent_treepos(parent_pos)\n\n            if grandparent_pos is None:\n                # a tree with only one EDU/leaf and a 'N' parent but no relation\n                return None, None\n            else:\n                grandparent_id = self.get_node_id(grandparent_pos)\n                grandparent_label = self.get_parent_label(parent_pos)\n                reltype = self.get_reltype(grandparent_label)\n\n                if reltype == 'rst':\n                    if parent_label == 'N':\n                        return 'span', grandparent_id\n                    elif parent_label == 'S':\n                        cousins_pos = self.get_cousins_treepos(treepos)\n                        assert len(cousins_pos) == 1\n                        cousin_id = self.get_node_id(cousins_pos[0])\n                        return grandparent_label, cousin_id\n                elif reltype == 'multinuc':\n                    return grandparent_label, grandparent_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to build a comprehensive json document for this process.", "response": "def events_to_json(self, segment_limit=None):\n        \"\"\"Attempt to build a comprehensive json document for this process.\n        Note: This can be problematic for excessivly large processes. \n\n        :param int segment_limit: Stop building the document after this many process segments.\n        :return: A dictionary of process events and details.\n        \"\"\"\n        process_raw_sum_data = self.proc._cb.get_object(\"/api/v1/process/{0}\".format(self.proc.id))\n        process_summary = process_raw_sum_data['process']\n        process_summary['parent'] = process_raw_sum_data['parent']\n        start_time = process_summary['start'].replace('T', ' ')\n        start_time = start_time.replace('Z','')\n        try:\n            start_time = datetime.datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S.%f')\n        except ValueError as e:\n            logging.info(\"Unexpected result. Probably incomplete process data.\")\n        process_summary['start'] = (start_time)\n        process_summary['filemods'] = []\n        process_summary['regmods'] = []\n        process_summary['unsigned_modloads'] = []\n        process_summary['netconns'] = []\n        process_summary['crossprocs'] = []\n        process_summary['children'] = []\n        process_summary['segment_count'] = len(self.proc.get_segments())\n\n        if segment_limit and not isinstance(segment_limit, int):\n            raise TypeError(\"segment_limit is not an integer.\")\n       \n        process_summary['segments_processed'] = 0\n        for segment in self.proc.get_segments():\n            if segment_limit:\n                if process_summary['segments_processed'] > segment_limit:\n                    break\n\n            self.proc.current_segment = segment\n\n            for nc in self.proc.netconns:\n                nc_dict = { 'timestamp': str((nc.timestamp)), 'domain': nc.domain,\n                            'remote_ip': nc.remote_ip, 'remote_port': nc.remote_port,\n                            'proto': nc.proto, 'direction': nc.direction, 'local_ip': nc.local_ip,\n                            'local_port': nc.local_port, 'proxy_ip': nc.proxy_ip,\n                            'proxy_port': nc.proxy_port, 'segment': segment }\n                process_summary['netconns'].append(nc_dict)\n\n            for child in self.proc.children:\n                child = { 'timestamp': str((child.timestamp)), 'procguid': child.procguid,\n                          'pid': child.pid, 'path': child.path, 'md5': child.md5, 'segment': segment }\n                process_summary['children'].append(child)\n\n            for fm in self.proc.filemods:\n                fm_dict = { 'timestamp': str((fm.timestamp)), 'type': fm.type, 'path': fm.path,\n                            'filetype': fm.filetype, 'md5': fm.md5, 'segment': segment }\n                # note we can also cb.select the md5 and see if it's signed, etc.\n                process_summary['filemods'].append(fm_dict)\n\n            for rm in self.proc.regmods:\n                rm_dict = { 'timestamp': str((rm.timestamp)), 'type': rm.type,\n                            'path': rm.path, 'segment': segment }\n                process_summary['regmods'].append(rm_dict)\n\n            for ml in self.proc.unsigned_modloads:\n                unsml_dict = { 'timestamp': str((ml.timestamp)), 'md5': ml.md5,\n                               'path': ml.path, 'segment': segment }\n                process_summary['unsigned_modloads'].append(unsml_dict)\n\n            for crossp in self.proc.crossprocs:\n                cp_dict = { 'timestamp': str((crossp.timestamp)), 'type': crossp.type,\n                            'privileges': crossp.privileges, 'target_md5': crossp.target_md5,\n                            'target_path': crossp.target_path, 'segment': segment,\n                            'source_path': crossp.source_path, 'source_web_link': crossp.source_proc.webui_link,\n                            'target_web_link': crossp.target_proc.webui_link, 'source_proc_guid': crossp.source_proc.id,\n                            'target_proc_guid': crossp.target_proc.id, 'source_md5': crossp.source_md5}\n                process_summary['crossprocs'].append(cp_dict)\n\n            process_summary['segments_processed'] += 1\n\n        return process_summary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_segment_token_offsets(segment_token_list, token_map):\n    token_indices = [token_map[token_id] for token_id in segment_token_list]\n    # we need to foolproof this for nasty RS3 files or other input formats\n    # with unordered or wrongly orderd IDs\n    return min(token_indices), max(token_indices)", "response": "returns the index of the first and last token node elements in a segment"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a key that can be used in sort functions.", "response": "def natural_sort_key(s):\n    \"\"\"\n    returns a key that can be used in sort functions.\n\n    Example:\n\n    >>> items = ['A99', 'a1', 'a2', 'a10', 'a24', 'a12', 'a100']\n\n    The normal sort function will ignore the natural order of the\n    integers in the string:\n\n    >>> print sorted(items)\n    ['A99', 'a1', 'a10', 'a100', 'a12', 'a2', 'a24']\n\n    When we use this function as a key to the sort function,\n    the natural order of the integer is considered.\n\n    >>> print sorted(items, key=natural_sort_key)\n    ['A99', 'a1', 'a2', 'a10', 'a12', 'a24', 'a100']\n    \"\"\"\n    return [int(text) if text.isdigit() else text\n            for text in re.split(INTEGER_RE, str(s))]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure that the input is str or unicode.", "response": "def ensure_unicode(str_or_unicode):\n    \"\"\"\n    tests, if the input is ``str`` or ``unicode``. if it is ``str``, it\n    will be decoded from ``UTF-8`` to unicode.\n    \"\"\"\n    if isinstance(str_or_unicode, str):\n        return str_or_unicode.decode('utf-8')\n    elif isinstance(str_or_unicode, unicode):\n        return str_or_unicode\n    else:\n        raise ValueError(\"Input '{0}' should be a string or unicode, \"\n                         \"but its of type {1}\".format(str_or_unicode,\n                                                      type(str_or_unicode)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_utf8(str_or_unicode):\n    if isinstance(str_or_unicode, str):\n        return str_or_unicode\n    elif isinstance(str_or_unicode, unicode):\n        return str_or_unicode.encode('utf-8')\n    else:\n        raise ValueError(\n            \"Input '{0}' should be a string or unicode, but it is of \"\n            \"type {1}\".format(str_or_unicode, type(str_or_unicode)))", "response": "Ensures that the input string is utf - 8 encoded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_ascii(str_or_unicode):\n    if isinstance(str_or_unicode, str):\n        return str_or_unicode.decode('utf-8').encode('ascii',\n                                                     'xmlcharrefreplace')\n    elif isinstance(str_or_unicode, unicode):\n        return str_or_unicode.encode('ascii', 'xmlcharrefreplace')\n    else:\n        raise ValueError(\n            \"Input '{0}' should be a string or unicode, but it is of \"\n            \"type {1}\".format(str_or_unicode, type(str_or_unicode)))", "response": "Ensures that the input string is ASCII."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_xpointer_compatibility(node_id):\n    assert isinstance(node_id, (int, str, unicode)),\\\n        \"node ID must be an int, str or unicode, not\".format(type(node_id))\n    if isinstance(node_id, (str, unicode)):\n        return FORBIDDEN_XPOINTER_RE.sub('_', node_id)\n    else:\n        return node_id", "response": "Ensures that the given node ID xpointer identifiers are compatible."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_prefix(dict_like, prefix):\n    if not isinstance(dict_like, dict):\n        try:\n            dict_like = dict(dict_like)\n        except Exception as e:\n            raise ValueError(\"{0}\\nCan't convert container to dict: \"\n                             \"{1}\".format(e, dict_like))\n    return {prefix + k: v for (k, v) in dict_like.items()}", "response": "Returns a dict that has all keys prefixed with prefix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a directory. Warns, if the directory can't be accessed. Passes, if the directory already exists. modified from http://stackoverflow.com/a/600612 Parameters ---------- path : str path to the directory to be created", "response": "def create_dir(path):\n    \"\"\"\n    Creates a directory. Warns, if the directory can't be accessed. Passes,\n    if the directory already exists.\n\n    modified from http://stackoverflow.com/a/600612\n\n    Parameters\n    ----------\n    path : str\n        path to the directory to be created\n    \"\"\"\n    import sys\n    import errno\n\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST:\n            if os.path.isdir(path):\n                pass\n            else: # if something exists at the path, but it's not a dir\n                raise\n        elif exc.errno == errno.EACCES:\n            sys.stderr.write(\"Cannot create [{0}]! Check Permissions\".format(path))\n            raise\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_files(dir_or_filelist, pattern='*'):\n    import os\n    import fnmatch\n\n    if isinstance(dir_or_filelist, str):\n        directory = dir_or_filelist\n\n        abspath = os.path.abspath(os.path.expanduser(directory))\n        for root, dirs, files in os.walk(abspath):\n            for basename in files:\n                if fnmatch.fnmatch(basename, pattern):\n                    filename = os.path.join(root, basename)\n                    yield filename\n    else:\n        filelist = dir_or_filelist\n        for filepath in filelist:\n            if fnmatch.fnmatch(filepath, pattern):\n                yield filepath", "response": "Yields all files that match the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize_string(string_or_unicode):\n    if isinstance(string_or_unicode, unicode):\n        return string_or_unicode.strip()\n    elif isinstance(string_or_unicode, str):\n        return string_or_unicode.decode('utf-8').strip()\n    else:  # e.g. if input is None\n        return u''", "response": "Sanitize a string for use in a log file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new DiscourseDocumentGraph with explicit node and edge labels appended.", "response": "def make_labels_explicit(docgraph):\n    \"\"\"\n    Appends the node ID to each node label and appends the edge type to each\n    edge label in the given document graph. This can be used to debug a\n    graph visually with ``write_dot``.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        document graph from which the nodes will be extracted\n\n    Returns\n    -------\n    explicit_docgraph : DiscourseDocumentGraph\n        document graph with explicit node and edge labels\n    \"\"\"\n    def make_nodelabels_explicit(docgraph):\n        for node_id, node_attribs in docgraph.nodes(data=True):\n            if 'label' in docgraph.node[node_id]:\n                docgraph.node[node_id]['label'] =  \\\n                    u\"{0}_{1}\".format(node_attribs['label'], node_id)\n        return docgraph\n\n    def make_edgelabels_explicit(docgraph):\n        for from_id, to_id, edge_attribs in docgraph.edges(data=True):\n            for edge_num in docgraph.edge[from_id][to_id]:\n                if 'label' in docgraph.edge[from_id][to_id][edge_num]:\n                    docgraph.edge[from_id][to_id][edge_num]['label'] = \\\n                        u\"{0}_{1}\".format(edge_attribs['label'],\n                                          edge_attribs['edge_type'])\n                else:\n                    docgraph.edge[from_id][to_id][edge_num]['label'] = \\\n                        edge_attribs['edge_type']\n        return docgraph\n    return make_edgelabels_explicit(make_nodelabels_explicit(docgraph))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and prints a barplot for all values that can be counted for all token nodes in the given elements and attribute.", "response": "def plot_attribute_distribution(docgraph, elements, attribute,\n                                ignore_missing=True):\n    '''\n    creates and prints a barplot (using matplotlib) for all values that an\n    attribute can have, e.g. counts of POS tags for all token nodes in a\n    document graph.\n\n    docgraph : DiscourseDocumentGraph\n        the document graph from which we'll extract node/edge attributes\n    elements : collections.Iterable\n        an iterable of nodes or edges\n    attribute : str\n        name of the attribute to count (e.g. ``penn:pos``)\n    ignore_missing : bool\n        If True, doesn't count all those elements that don't have the given\n        attribute. If False, counts them using the attribute ``NOT_PRESENT``.\n    '''\n    value_counts = Counter()\n\n    if isinstance(elements, GeneratorType):\n        elements = list(elements)\n\n    if isinstance(elements[0], (str, unicode, int)):\n        element_type = 'node'\n    elif isinstance(elements[0], tuple):\n        element_type = 'edge'\n    else:\n        raise ValueError('Unknown element type: '.format(element[0]))\n\n    if element_type == 'node':\n        # count all nodes with the given attribute\n        for element in elements:\n            try:\n                value_counts[docgraph.node[element][attribute]] += 1\n            except KeyError:\n                if not ignore_missing:\n                    value_counts['NOT_PRESENT'] += 1\n    else: # element_type == 'edge':\n        # count all edges with the given attribute\n        for element in elements:\n            source, target = element\n            try:\n                for edge in docgraph.edge[source][target]: # multidigraph\n                    value_counts[docgraph.edge[source][target][edge][attribute]] += 1\n            except KeyError:\n                if not ignore_missing:\n                    value_counts['NOT_PRESENT'] += 1\n\n    sorted_value_counts = sorted(value_counts.iteritems(), key=itemgetter(1),\n                                 reverse=True)\n\n    # generate plot\n    x = np.arange(len(sorted_value_counts))\n    plt.bar(x, [attrib_count for attrib_name, attrib_count in sorted_value_counts])\n    # set positions of the attribute value labels on the x-axis\n    # (shifted to the right, words arranged upwards)\n    _xticks = plt.xticks(\n        x + 0.5,\n        [attrib_name for attrib_name, attrib_count in sorted_value_counts],\n        rotation=90)\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a function that replaces multiple patterns with a single - pass.", "response": "def create_multiple_replace_func(*args, **kwds):\n    \"\"\"\n    You can call this function and pass it a dictionary, or any other\n    combination of arguments you could pass to built-in dict in order to\n    construct a dictionary. The function will return a xlat closure that\n    takes as its only argument text the string on which the substitutions\n    are desired and returns a copy of text with all the substitutions\n    performed.\n\n    Source: Python Cookbook 2nd ed, Chapter 1.18. Replacing Multiple Patterns\n    in a Single Pass.\n    https://www.safaribooksonline.com/library/view/python-cookbook-2nd/0596007973/ch01s19.html\n    \"\"\"\n    adict = dict(*args, **kwds)\n    rx = re.compile('|'.join(map(re.escape, adict)))\n    def one_xlat(match):\n        return adict[match.group(0)]\n    def xlat(text):\n        return rx.sub(one_xlat, text)\n    return xlat"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator that yields all Conano units that occur in the given document graph.", "response": "def get_conano_units(docgraph, data=True, conano_namespace='conano'):\n    \"\"\"\n    yield all Conano units that occur in the given document graph,\n    sorted by their unit ID. int(ernal) and ext(ernal) count as distinct units.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph which contains Conano annotations\n    data : bool\n        If True (default), yields (node ID, list of tokens)\n        tuples. If False, yields just unit IDs.\n    conano_namespace : str\n        The namespace that the Conano annotations use (default: conano)\n\n    Yields\n    ------\n    relations : str or (str, str, list of str) tuples\n        If data=False, this will just yield node IDs of the nodes that\n        directly dominate an RST relation. If data=True, this yields\n        tuples of the form: (node ID, relation name, list of tokens that this\n        relation spans).\n    \"\"\"\n    for unit_id in sorted(select_nodes_by_layer(docgraph, conano_namespace+':unit'),\n                          key=natural_sort_key):\n        yield (unit_id, get_span(docgraph, unit_id)) if data else (unit_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the lowercased string of the connective used in the given Conano unit.", "response": "def get_connective(docgraph, unit_id):\n    \"\"\"\n    returns the lowercased string of the connective used in the given Conano unit.\n    \"\"\"\n    unit_index, _unit_type = unit_id.split(':')\n    connective_id = unit_index+':connective'\n    return ' '.join(docgraph.get_token(tok_id).lower()\n                    for tok_id in get_span(docgraph, connective_id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an element to the docgraph.", "response": "def _add_element(self, element, parent_node):\n        \"\"\"\n        add an element (i.e. a unit/connective/discourse or modifier)\n        to the docgraph.\n        \"\"\"\n        if element.tag == 'unit':\n            element_node_id = element.attrib['id']+':'+element.attrib['type']\n            node_layers = {self.ns, self.ns+':unit', self.ns+':'+element.attrib['type']}\n        elif element.tag == 'connective':\n            element_node_id = element.attrib['id']+':connective'\n            node_layers = {self.ns, self.ns+':connective'}\n        elif element.tag == 'discourse':\n            element_node_id = 'discourse'\n            node_layers = {self.ns}\n        else:  # <modifier>\n            element_node_id = element.getparent().attrib['id']+':'+element.tag\n            node_layers = {self.ns, self.ns+':modifier'}\n\n        self.add_node(element_node_id, layers=node_layers)\n        self.add_edge(parent_node, element_node_id, layers={self.ns},\n                      edge_type=EdgeTypes.dominance_relation)\n\n        if element.text:\n            if self.tokenize:\n                for token in element.text.split():\n                    self._add_token(token, element_node_id)\n            else:\n                element_text = sanitize_string(element.text)\n                self.node[element_node_id].update(\n                    {'label': u\"{0}: {1}...\".format(element_node_id,\n                                                   element_text[:20])})\n\n\n        for child_element in element.iterchildren():\n            self._add_element(child_element, element_node_id)\n\n        if element.tail:  # tokens _after_ the </element> closes\n            if self.tokenize:\n                for token in element.tail.split():\n                    self._add_token(token, parent_node)\n            else:\n                tail_text = sanitize_string(element.tail)\n                self.node[parent_node].update(\n                    {'label': u\"{0}: {1}...\".format(parent_node,\n                                                    tail_text[:20])})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_token(self, token, parent_node='root'):\n        if parent_node == 'root':\n            parent_node = self.root\n\n        token_node_id = 'token:{}'.format(self.token_count)\n        self.add_node(token_node_id, layers={self.ns, self.ns+':token'},\n                      attr_dict={self.ns+':token': token})\n        self.add_edge(parent_node, token_node_id,\n                      layers={self.ns},\n                      edge_type=EdgeTypes.spanning_relation)\n        self.tokens.append(token_node_id)\n        self.token_count += 1", "response": "add a token to this docgraph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid(self, tree):\n        conano_plaintext = etree.tostring(tree, encoding='utf8', method='text')\n        token_str_list = conano_plaintext.split()\n        for i, plain_token in enumerate(token_str_list):\n            graph_token = self.node[self.tokens[i]][self.ns+':token']\n            if ensure_unicode(plain_token) != graph_token:\n                sys.stderr.write(\n                    \"Conano tokenizations don't match: {0} vs. {1} \"\n                    \"({2})\".format(plain_token, graph_token))\n                return False\n        return True", "response": "Returns true iff the order of the tokens in the Conano file is the same as in the Conano file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a token to the document graph as a node with the given ID.", "response": "def __add_token_to_document(self, token, token_id, connected):\n        \"\"\"\n        adds a token to the document graph as a node with the given ID.\n\n        Parameters\n        ----------\n        token : str\n            the token to be added to the document graph\n        token_id : int\n            the node ID of the token to be added, which must not yet\n            exist in the document graph\n        connected : bool\n            Make the graph connected, i.e. add an edge from root this token.\n        \"\"\"\n        regex_match = ANNOTATED_ANAPHORA_REGEX.search(token)\n        if regex_match:  # token is annotated\n            unannotated_token = regex_match.group('token')\n            unicode_token = ensure_unicode(unannotated_token)\n            annotation = regex_match.group('annotation')\n            anno_type = ANNOTATION_TYPES[annotation]\n            certainty = \"1.0\" if not regex_match.group('uncertain') else \"0.5\"\n            self.add_node(\n                token_id,\n                layers={self.ns, self.ns+':token', self.ns+':annotated'},\n                attr_dict={\n                    self.ns+':annotation': anno_type,\n                    self.ns+':certainty': certainty,\n                    self.ns+':token': unicode_token,\n                    'label': u\"{0}_{1}\".format(unicode_token, anno_type)})\n        else:  # token is not annotated\n            self.add_node(\n                token_id,\n                layers={self.ns, self.ns+':token'},\n                attr_dict={self.ns+':token': ensure_unicode(token),\n                           'label': ensure_unicode(token)})\n\n        if connected:\n            self.add_edge(self.root, token_id,\n                          layers={self.ns, self.ns+':token'})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quote_for_pydot(string):\n    if isinstance(string, int):\n        string = str(string)\n    escaped_str = QUOTE_RE.sub(r'\\\\\"', string)\n    return u'\"{}\"'.format(escaped_str)", "response": "Quote a string for Python dot notation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _preprocess_nodes_for_pydot(nodes_with_data):\n    for (node_id, attrs) in nodes_with_data:\n        if 'label' in attrs:\n            yield (quote_for_pydot(node_id),\n                   {'label': quote_for_pydot(attrs['label'])})\n        else:\n            yield (quote_for_pydot(node_id), {})", "response": "return a generator of nodes that can be used to create a node from a list of nodes with data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _preprocess_edges_for_pydot(edges_with_data):\n    for (source, target, attrs) in edges_with_data:\n        if 'label' in attrs:\n            yield (quote_for_pydot(source), quote_for_pydot(target),\n                   {'label': quote_for_pydot(attrs['label'])})\n        else:\n            yield (quote_for_pydot(source), quote_for_pydot(target), {})", "response": "return a generator of edges that can be used to generate a new version of the xml file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a discourse document graph and strips all the information that aren t necessary for visualizing it with graphviz.", "response": "def preprocess_for_pydot(docgraph):\n    \"\"\"\n    takes a document graph and strips all the information that aren't\n    necessary for visualizing it with graphviz. ensures that all\n    node/edge names and labels are properly quoted.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph\n    Returns\n    -------\n    stripped_graph : networkx.MultiDiGraph\n        a graph containing only information that is needed for graphviz\n    \"\"\"\n    stripped_graph = nx.MultiDiGraph()\n    stripped_graph.name = docgraph.name\n\n    nodes = _preprocess_nodes_for_pydot(docgraph.nodes_iter(data=True))\n    edges = _preprocess_edges_for_pydot(docgraph.edges_iter(data=True))\n\n    stripped_graph.add_nodes_from(nodes)\n    stripped_graph.add_edges_from(edges)\n    return stripped_graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_dot(docgraph):\n    stripped_graph = preprocess_for_pydot(docgraph)\n    return nx.drawing.nx_pydot.to_pydot(stripped_graph).to_string()", "response": "Converts a document graph into a dot file and returns it as a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relabel_nodes(G, mapping, copy=True):\n    # you can pass a function f(old_label)->new_label\n    # but we'll just make a dictionary here regardless\n    if not hasattr(mapping, \"__getitem__\"):\n        m = dict((n, mapping(n)) for n in G)\n    else:\n        m = mapping\n    if copy:\n        return _relabel_copy(G, m)\n    else:\n        return _relabel_inplace(G, m)", "response": "Relabel the nodes of the graph G with the given mapping."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_node_labels_to_integers(G, first_label=0, ordering=\"default\",\n                                    label_attribute=None):\n    \"\"\"Return a copy of the graph G with the nodes relabeled with integers.\n\n    Parameters\n    ----------\n    G : graph\n       A NetworkX graph\n\n    first_label : int, optional (default=0)\n       An integer specifying the offset in numbering nodes.\n       The n new integer labels are numbered first_label, ..., n-1+first_label.\n\n    ordering : string\n       \"default\" : inherit node ordering from G.nodes()\n       \"sorted\"  : inherit node ordering from sorted(G.nodes())\n       \"increasing degree\" : nodes are sorted by increasing degree\n       \"decreasing degree\" : nodes are sorted by decreasing degree\n\n    label_attribute : string, optional (default=None)\n       Name of node attribute to store old label.  If None no attribute\n       is created.\n\n    Notes\n    -----\n    Node and edge attribute data are copied to the new (relabeled) graph.\n\n    See Also\n    --------\n    relabel_nodes\n    \"\"\"\n    N = G.number_of_nodes() + first_label\n    if ordering == \"default\":\n        mapping = dict(zip(G.nodes(), range(first_label, N)))\n    elif ordering == \"sorted\":\n        nlist = G.nodes()\n        nlist.sort()\n        mapping = dict(zip(nlist, range(first_label, N)))\n    elif ordering == \"increasing degree\":\n        dv_pairs = [(d, n) for (n, d) in G.degree_iter()]\n        dv_pairs.sort()  # in-place sort from lowest to highest degree\n        mapping = dict(zip([n for d, n in dv_pairs], range(first_label, N)))\n    elif ordering == \"decreasing degree\":\n        dv_pairs = [(d, n) for (n, d) in G.degree_iter()]\n        dv_pairs.sort()  # in-place sort from lowest to highest degree\n        dv_pairs.reverse()\n        mapping = dict(zip([n for d, n in dv_pairs], range(first_label, N)))\n    else:\n        raise nx.NetworkXError('Unknown node ordering: {0}'.format(ordering))\n    H = relabel_nodes(G, mapping)\n    H.name = \"(\" + G.name + \")_with_int_labels\"\n    # create node attribute with the old label\n    if label_attribute is not None:\n        nx.set_node_attributes(H, label_attribute,\n                               dict((v, k) for k, v in mapping.items()))\n    return H", "response": "Returns a copy of the graph G with the nodes relabeled with integers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a DiscourseDocumentGraph into an Exmaralda. exb file and writes it to the given file.", "response": "def write_exb(docgraph, output_file):\n    \"\"\"\n    converts a DiscourseDocumentGraph into an Exmaralda ``*.exb`` file and\n    writes it to the given file (or file path).\n    \"\"\"\n    exmaralda_file = ExmaraldaFile(docgraph)\n    assert isinstance(output_file, (str, file))\n    if isinstance(output_file, str):\n        path_to_file = os.path.dirname(output_file)\n        if not os.path.isdir(path_to_file):\n            create_dir(path_to_file)\n        exmaralda_file.write(output_file)\n    else:  # output_file is a file object\n        output_file.write(exmaralda_file.__str__())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes the ExmaraldaFile instance and write it to a file.", "response": "def write(self, output_filepath):\n        \"\"\"\n        serialize the ExmaraldaFile instance and write it to a file.\n\n        Parameters\n        ----------\n        output_filepath : str\n            relative or absolute path to the Exmaralda file to be created\n        \"\"\"\n        with open(output_filepath, 'w') as out_file:\n            out_file.write(self.__str__())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an empty XML document header for an Exmaralda *. exb file.", "response": "def __create_document_header(self):\n        \"\"\"\n        Look, mum! XML generation without string concatenation!1!!\n\n        This creates an empty, but functional header for an Exmaralda *.exb\n        file.\n        \"\"\"\n        E = self.E\n        root = E('basic-transcription')\n        head = E('head')\n\n        meta = E('meta-information')\n        project = E('project-name')\n        tname = E('transcription-name')\n        ref_file = E('referenced-file', url=\"\")\n        ud = E('ud-meta-information')\n        comment = E('comment')\n        tconvention = E('transcription-convention')\n        meta.append(project)\n        meta.append(tname)\n        meta.append(ref_file)\n        meta.append(ud)\n        meta.append(comment)\n        meta.append(tconvention)\n\n        speakers = E('speakertable')\n        head.append(meta)\n        head.append(speakers)\n        root.append(head)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an Exmaralda XML etree representation a docgraph", "response": "def __add_document_structure(self, docgraph,\n                                 remove_redundant_layers=True):\n        \"\"\"return an Exmaralda XML etree representation a docgraph\"\"\"\n        E = self.E\n        root = self.__create_document_header()\n\n        body = E('basic-body')\n        timeline = E('common-timeline')\n\n        # for n tokens we need to create n+1 timeline indices\n        for i in xrange(len(docgraph.tokens)+1):\n            idx = str(i)\n            # example: <tli id=\"T0\" time=\"0\"/>\n            timeline.append(E('tli', {'id': 'T'+idx, 'time': idx}))\n\n        body.append(timeline)\n        body = self.__add_token_tiers(docgraph, body)\n\n        annotation_layers = get_annotation_layers(docgraph)\n        for layer in annotation_layers:\n            if not remove_redundant_layers:  # add all layers\n                self.__add_annotation_tier(docgraph, body, layer)\n            elif is_informative(layer):  # only add informative layers\n                self.__add_annotation_tier(docgraph, body, layer)\n\n        self.__add_coreference_chain_tiers(docgraph, body)\n        root.append(body)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a span - based annotation layer as a new tier to the Exmaralda body.", "response": "def __add_annotation_tier(self, docgraph, body, annotation_layer):\n        \"\"\"\n        adds a span-based annotation layer as a <tier> to the Exmaralda <body>.\n\n        Parameter\n        ---------\n        docgraph : DiscourseDocumentGraph\n            the document graph from which the chains will be extracted\n        body : etree._Element\n            an etree representation of the <basic_body> element (and all its\n            descendants) of the Exmaralda file\n        annotation_layer : str\n            the name of a layer, e.g. 'tiger', 'tiger:token' or 'mmax:sentence'\n        \"\"\"\n        layer_cat = annotation_layer.split(':')[-1]\n        temp_tier = self.E('tier',\n                           {'id': \"TIE{}\".format(self.tier_count),\n                            'category': layer_cat, 'type': \"t\",\n                            'display-name': \"[{}]\".format(annotation_layer)})\n        self.tier_count += 1\n\n        for node_id in select_nodes_by_layer(docgraph, annotation_layer):\n            span_node_ids = get_span(docgraph, node_id)\n            if span_node_ids:\n                start_id, end_id = self.__span2event(span_node_ids)\n                event_label = docgraph.node[node_id].get('label', '')\n                event = self.E('event',\n                               {'start': \"T{}\".format(start_id),\n                                'end': \"T{}\".format(end_id)},\n                               event_label)\n                temp_tier.append(event)\n        body.append(temp_tier)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd coreference chain tiers to the body.", "response": "def __add_coreference_chain_tiers(self, docgraph, body,\n                                      min_chain_length=3):\n        \"\"\"\n        Parameters\n        ----------\n        docgraph : DiscourseDocumentGraph\n            the document graph from which the chains will be extracted\n        body : etree._Element\n            an etree representation of the <basic_body> element (and all its\n            descendants) of the Exmaralda file\n        min_chain_length : int\n            don't add tiers for chains with less than N elements (default: 3)\n\n        TODO: this method assumes that each pointing relation chains signifies\n        a coreference chain.\n        \"\"\"\n        E = self.E\n\n        for i, chain in enumerate(get_pointing_chains(docgraph)):\n            chain_tier = E('tier',\n                           {'id': \"TIE{}\".format(self.tier_count),\n                            'category': \"chain\", 'type': \"t\",\n                            'display-name': \"[coref-chain-{}]\".format(i)})\n            self.tier_count += 1\n\n            chain_length = len(chain)\n            if chain_length < min_chain_length:\n                continue  # ignore short chains\n\n            for j, node_id in enumerate(chain):\n                span_node_ids = get_span(docgraph, node_id)\n                if span_node_ids:\n                    start_id, end_id = self.__span2event(span_node_ids)\n                    element_str = \"chain_{0}: {1}/{2}\".format(\n                        i, chain_length-j, chain_length)\n                    chain_tier.append(\n                        E('event', {'start': \"T{}\".format(start_id),\n                                    'end': \"T{}\".format(end_id)}, element_str))\n            body.append(chain_tier)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding all tiers that annotate single tokens to the XML file.", "response": "def __add_token_tiers(self, docgraph, body):\n        \"\"\"\n        adds all tiers that annotate single tokens (e.g. token string, lemma,\n        POS tag) to the etree representation of the Exmaralda XML file.\n\n        Parameters\n        ----------\n        docgraph : DiscourseDocumentGraph\n            the document graph to be converted\n        body : etree._Element\n            an etree representation of the <basic_body> element (and all its\n            descendants) of the Exmaralda file\n        \"\"\"\n        E = self.E\n        token_tier = E('tier',\n                       {'id': \"TIE{}\".format(self.tier_count),\n                        'category': \"tok\", 'type': \"t\",\n                        'display-name': \"[tok]\"})\n        self.tier_count += 1\n\n        token_attribs = defaultdict(lambda: defaultdict(str))\n        for token_node_id in docgraph.tokens:\n            for attrib in docgraph.node[token_node_id]:\n                is_boring_attrib = attrib in ('layers', 'label')\n                is_boring_cat = attrib.split(':')[-1] in ('token',\n                                                          'id', 'word',\n                                                          'morph', 'lemma')\n                if not is_boring_attrib and not is_boring_cat:\n                    token_attribs[attrib][token_node_id] = \\\n                        docgraph.node[token_node_id][attrib]\n\n        for i, (_tok_id, token_str) in enumerate(docgraph.get_tokens()):\n            # example: <event start=\"T0\" end=\"T1\">Zum</event>\n            token_tier.append(\n                E('event', {'start': \"T{}\".format(i),\n                            'end': \"T{}\".format(i+1)}, token_str))\n        body.append(token_tier)\n\n        for anno_tier in token_attribs:\n            category = anno_tier.split(':')[-1]\n            temp_tier = E(\n                'tier', {'id': \"TIE{}\".format(self.tier_count),\n                         'category': category, 'type': \"t\",\n                         'display-name': \"[{}]\".format(anno_tier)})\n            self.tier_count += 1\n            for token_node_id in token_attribs[anno_tier]:\n                token_tier_id = self.toknode2id[token_node_id]\n                token_attrib = token_attribs[anno_tier][token_node_id]\n                temp_tier.append(\n                    E('event', {'start': \"T{}\".format(token_tier_id),\n                                'end': \"T{}\".format(token_tier_id+1)},\n                      token_attrib))\n            body.append(temp_tier)\n        return body"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __add_tokenization(self, tree):\n        for token_id in self.get_token_ids(tree):\n            self.add_node(token_id, layers={self.ns})\n            self.tokens.append(token_id)", "response": "adds a node for each token ID in the document"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __add_tier(self, tier, token_tier_name):\n        if tier.attrib['category'] == token_tier_name:\n            self.__add_tokens(tier)\n        else:\n            if self.is_token_annotation_tier(tier):\n                self.__add_token_annotation_tier(tier)\n\n            else:\n                self.__add_span_tier(tier)", "response": "Adds a tier to the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __add_tokens(self, token_tier):\n        for event in token_tier.iter('event'):\n            assert len(self.gen_token_range(event.attrib['start'],\n                       event.attrib['end'])) == 1, \\\n                \"Events in the token tier must not span more than one token.\"\n            token_id = event.attrib['start']\n            self.node[token_id][self.ns+':token'] = event.text", "response": "Adds all tokens to the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_token_annotation_tier(self, tier):\n        for i, event in enumerate(tier.iter('event')):\n            if self.indexdelta(event.attrib['end'], event.attrib['start']) != 1:\n                return False\n        return True", "response": "Returns True if all events in the given tier annotate exactly one tier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a tier to the document graph in which each event annotates exactly one token.", "response": "def __add_token_annotation_tier(self, tier):\n        \"\"\"\n        adds a tier to the document graph, in which each event annotates\n        exactly one token.\n        \"\"\"\n        for i, event in enumerate(tier.iter('event')):\n            anno_key = '{0}:{1}'.format(self.ns, tier.attrib['category'])\n            anno_val = event.text if event.text else ''\n            self.node[event.attrib['start']][anno_key] = anno_val"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __add_span_tier(self, tier):\n        tier_id = tier.attrib['id']\n        # add the tier's root node with an inbound edge from the document root\n        self.add_node(\n            tier_id, layers={self.ns, self.ns+':tier'},\n            attr_dict={self.ns+':category': tier.attrib['category'],\n                       self.ns+':type': tier.attrib['type'],\n                       self.ns+':display-name': tier.attrib['display-name']})\n        self.add_edge(self.root, tier_id, edge_type=EdgeTypes.dominance_relation)\n\n        # add a node for each span, containing an annotation.\n        # add an edge from the tier root to each span and an edge from each\n        # span to the tokens it represents\n        for i, event in enumerate(tier.iter('event')):\n            span_id = '{}_{}'.format(tier_id, i)\n            span_tokens = self.gen_token_range(event.attrib['start'], event.attrib['end'])\n            annotation = event.text if event.text else ''\n            self.add_node(\n                span_id, layers={self.ns, self.ns+':span'},\n                attr_dict={self.ns+':annotation': annotation,\n                           'label': annotation})\n            self.add_edge(tier_id, span_id, edge_type=EdgeTypes.dominance_relation)\n\n            for token_id in span_tokens:\n                self.add_edge(span_id, token_id,\n                              edge_type=EdgeTypes.spanning_relation)", "response": "Adds a tier to the document graph in which each event annotates a span\n            of one or more tokens."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_token_ids(tree):\n        def tok2time(token_element):\n            '''\n            extracts the time (float) of a <tli> element\n            (i.e. the absolute position of a token in the document)\n            '''\n            return float(token_element.attrib['time'])\n\n        timeline = tree.find('//common-timeline')\n        return (tok.attrib['id']\n                for tok in sorted((tli for tli in timeline.iterchildren()),\n                                  key=tok2time))", "response": "Returns a list of all token IDs occuring the given exmaralda file sorted by their time stamp in ascending order."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the distance between start_id and stop_id", "response": "def indexdelta(self, stop_id, start_id):\n        \"\"\"returns the distance (int) between to idices.\n\n        Two consecutive tokens must have a delta of 1.\n        \"\"\"\n        return self.tokenid2index(stop_id) - self.tokenid2index(start_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all token IDs in the given left - closed interval and right - open interval.", "response": "def gen_token_range(self, start_id, stop_id):\n        \"\"\"\n        returns a list of all token IDs in the given, left-closed,\n        right-open interval (i.e. includes start_id, but excludes stop_id)\n\n        >>> gen_token_range('T0', 'T1')\n        ['T0']\n\n        >>> gen_token_range('T1', 'T5')\n        ['T1', 'T2', 'T3', 'T4']\n        \"\"\"\n        index_range = range(self.tokenid2index(start_id), self.tokenid2index(stop_id))\n        return [\"T{}\".format(index) for index in index_range]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rename_tokens(docgraph_with_old_names, docgraph_with_new_names, verbose=False):\n    old2new = create_token_mapping(docgraph_with_old_names,\n                                   docgraph_with_new_names, verbose=verbose)\n\n    # save the mappings from old to new token node IDs in the `renamed_nodes`\n    # attribute of the merged graph\n    if hasattr(docgraph_with_new_names, 'renamed_nodes'):\n        docgraph_with_new_names.renamed_nodes.update(old2new)\n    else:\n        docgraph_with_new_names.renamed_nodes = old2new\n\n    relabel_nodes(docgraph_with_old_names, old2new, copy=False)\n    new_token_ids = old2new.values()\n\n    # new_token_ids could be empty (if docgraph_with_new_names is still empty)\n    if new_token_ids:\n        docgraph_with_old_names.tokens = new_token_ids", "response": "Renames the tokens of a document graph in - place using the token names of another document graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_token_mapping(docgraph_with_old_names, docgraph_with_new_names,\n                         verbose=False):\n    \"\"\"\n    given two document graphs which annotate the same text and which use the\n    same tokenization, creates a dictionary with a mapping from the token\n    IDs used in the first graph to the token IDs used in the second graph.\n\n    Parameters\n    ----------\n    docgraph_with_old_names : DiscourseDocumentGraph\n        a document graph with token IDs that will be replaced later on\n    docgraph_with_new_names : DiscourseDocumentGraph\n        a document graph with token IDs that will replace the token IDs\n        used in ``docgraph_with_old_names`` later on\n\n    Returns\n    -------\n    old2new : dict\n        maps from a token ID used in ``docgraph_with_old_names`` to the token\n        ID used in ``docgraph_with_new_names`` to reference the same token\n    \"\"\"\n    def kwic_string(docgraph, keyword_index):\n        tokens = [tok for (tokid, tok) in list(docgraph.get_tokens())]\n        before, keyword, after = get_kwic(tokens, keyword_index)\n        return \"{0} (Index: {1}): {2} [[{3}]] {4}\\n\".format(\n            docgraph.name, keyword_index, ' '.join(before), keyword,\n            ' '.join(after))\n\n    # generators of (token ID, token) tuples\n    old_token_gen = docgraph_with_old_names.get_tokens()\n    new_token_gen = docgraph_with_new_names.get_tokens()\n\n    old2new = {}\n    for i, (new_tok_id, new_tok) in enumerate(new_token_gen):\n        old_tok_id, old_tok = old_token_gen.next()\n        if new_tok != old_tok:  # token mismatch\n            if verbose:\n                raise ValueError(u\"Tokenization mismatch:\\n{0}{1}\".format(\n                    kwic_string(docgraph_with_old_names, i),\n                    kwic_string(docgraph_with_new_names, i)))\n            raise ValueError(\n                u\"Tokenization mismatch: {0} ({1}) vs. {2} ({3})\\n\"\n                \"\\t{4} != {5}\".format(\n                    docgraph_with_new_names.name, docgraph_with_new_names.ns,\n                    docgraph_with_old_names.name, docgraph_with_old_names.ns,\n                    new_tok, old_tok).encode('utf-8'))\n        else:\n            old2new[old_tok_id] = new_tok_id\n    return old2new", "response": "Creates a dictionary with a mapping from a token ID used in the first graph to a token ID used in the second graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the before and after lists of tokens that are part of the keyword at the given index.", "response": "def get_kwic(tokens, index, context_window=5):\n    \"\"\"\n    keyword in context\n\n    Parameters\n    ----------\n    tokens : list of str\n        a text represented as a list of tokens\n    index : int\n        the index of the keyword in the token list\n    context_window : int\n        the number of preceding/succeding words of the keyword to be\n        retrieved\n\n    Returns\n    -------\n    before : list of str\n        the tokens preceding the keyword\n    keyword : str\n        the token at the index position\n    after : list of str\n        the tokens succeding the keyword\n    \"\"\"\n    text_length = len(tokens)\n    start_before = max(0, index-context_window)\n    end_before = max(0, index)\n    before = tokens[start_before:end_before]\n    start_after = min(text_length, index+1)\n    end_after = min(text_length, index+context_window+1)\n    after = tokens[start_after:end_after]\n    return before, tokens[index], after"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the set of all annotation layers used for annotating nodes in the given docgraph.", "response": "def get_node_annotation_layers(docgraph):\n    \"\"\"\n    WARNING: this is higly inefficient!\n    Fix this via Issue #36.\n\n    Returns\n    -------\n    all_layers : set or dict\n        the set of all annotation layers used for annotating nodes in the given\n        graph\n    \"\"\"\n    all_layers = set()\n    for node_id, node_attribs in docgraph.nodes_iter(data=True):\n        for layer in node_attribs['layers']:\n            all_layers.add(layer)\n    return all_layers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_edge_annotation_layers(docgraph):\n    all_layers = set()\n    for source_id, target_id, edge_attribs in docgraph.edges_iter(data=True):\n        for layer in edge_attribs['layers']:\n            all_layers.add(layer)\n    return all_layers", "response": "Returns the set of all annotation layers used for annotating edges in a given node graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the character start and end positions of the span of text that the given node spans or dominates.", "response": "def get_span_offsets(docgraph, node_id):\n    \"\"\"\n    returns the character start and end position of the span of text that\n    the given node spans or dominates.\n\n    Returns\n    -------\n    offsets : tuple(int, int)\n        character onset and offset of the span\n    \"\"\"\n    try:\n        span = get_span(docgraph, node_id)\n        # workaround for issue #138\n        # TODO: when #138 is fixed, just take the first onset / last offset\n        onsets, offsets = zip(*[docgraph.get_offsets(tok_node)\n                                for tok_node in span])\n        return (min(onsets), max(offsets))\n    except KeyError as _:\n        raise KeyError(\"Node '{}' doesn't span any tokens.\".format(node_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all the tokens that are dominated or in a span relation with the given node.", "response": "def get_span(docgraph, node_id, debug=False):\n    \"\"\"\n    returns all the tokens that are dominated or in a span relation with\n    the given node. If debug is set to True, you'll get a warning if the\n    graph is cyclic.\n\n    Returns\n    -------\n    span : list of str\n        sorted list of token nodes (token node IDs)\n    \"\"\"\n    if debug is True and is_directed_acyclic_graph(docgraph) is False:\n        warnings.warn(\n            (\"Can't reliably extract span '{0}' from cyclical graph'{1}'.\"\n            \"Maximum recursion depth may be exceeded.\").format(node_id,\n                                                                   docgraph))\n    span = []\n    if docgraph.ns+':token' in docgraph.node[node_id]:\n        span.append(node_id)\n\n    for src_id, target_id, edge_attribs in docgraph.out_edges_iter(node_id,\n                                                                data=True):\n        if src_id == target_id:\n            continue  # ignore self-loops\n        # ignore pointing relations\n        if edge_attribs['edge_type'] != EdgeTypes.pointing_relation:\n            span.extend(get_span(docgraph, target_id))\n    return sorted(span, key=natural_sort_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the text that the given node dominates the current node or spans.", "response": "def get_text(docgraph, node_id=None):\n    \"\"\"\n    returns the text (joined token strings) that the given node dominates\n    or spans. If no node ID is given, returns the complete text of the\n    document\n    \"\"\"\n    if node_id:\n        tokens = (docgraph.node[node_id][docgraph.ns+':token']\n                  for node_id in get_span(docgraph, node_id))\n    else:\n        tokens = (docgraph.node[token_id][docgraph.ns+':token']\n                  for token_id in docgraph.tokens)\n    return ' '.join(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a list of token node IDs returns a their string representation.", "response": "def tokens2text(docgraph, token_ids):\n    \"\"\"\n    given a list of token node IDs, returns a their string representation\n    (concatenated token strings).\n    \"\"\"\n    return ' '.join(docgraph.node[token_id][docgraph.ns+':token']\n                    for token_id in token_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef istoken(docgraph, node_id, namespace=None):\n    if namespace is None:\n        namespace = docgraph.ns\n    return namespace+':token' in docgraph.node[node_id]", "response": "returns true iff the given node ID belongs to a token node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the tokens dominated by the given node are all adjacent", "response": "def is_continuous(docgraph, dominating_node):\n    \"\"\"return True, if the tokens dominated by the given node are all adjacent\"\"\"\n    first_onset, last_offset = get_span_offsets(docgraph, dominating_node)\n    span_range = xrange(first_onset, last_offset+1)\n\n    token_offsets = (docgraph.get_offsets(tok)\n                     for tok in get_span(docgraph, dominating_node))\n    char_positions = set(itertools.chain.from_iterable(xrange(on, off+1)\n                         for on, off in token_offsets))\n    for item in span_range:\n        if item not in char_positions:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator of neighbors of a given node in a given layer.", "response": "def select_neighbors_by_layer(docgraph, node, layer, data=False):\n    \"\"\"\n    Get all neighboring nodes belonging to (any of) the given layer(s),\n    A neighboring node is a node that the given node connects to with an\n    outgoing edge.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        document graph from which the nodes will be extracted\n    layer : str or collection of str\n        name(s) of the layer(s)\n    data : bool\n        If True, results will include node attributes.\n\n    Yields\n    ------\n    nodes : generator of str or generator of (str, dict) tuple\n        If data is False (default), a generator of neighbor node IDs\n        that are present in the given layer. If data is True,\n        a generator of (node ID, node attrib dict) tuples.\n    \"\"\"\n    for node_id in docgraph.neighbors_iter(node):\n        node_layers = docgraph.node[node_id]['layers']\n        if isinstance(layer, (str, unicode)):\n            condition = layer in node_layers\n        else:  # ``layer`` is a list/set/dict of layers\n            condition = any(l in node_layers for l in layer)\n\n        if condition:\n            yield (node_id, docgraph.node[node_id]) if data else (node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_neighbors_by_edge_attribute(docgraph, source,\n                                       attribute=None, value=None, data=False):\n    \"\"\"Get all neighbors with the given edge attribute value(s).\"\"\"\n    assert isinstance(docgraph, MultiGraph)\n    for neighbor_id in docgraph.neighbors_iter(source):\n        edges = docgraph[source][neighbor_id].values()\n\n        if attribute is None:\n            has_attrib = True # don't filter neighbors\n        else:\n            has_attrib = any(attribute in edge for edge in edges)\n\n        if has_attrib:\n            if value is None:\n                has_value = True\n            elif isinstance(value, basestring):\n                has_value = any(edge.get(attribute) == value\n                                for edge in edges)\n            else:  # ``value`` is a list/set/dict of values\n                has_value = any(edge.get(attribute) == v\n                                for edge in edges\n                                for v in value)\n\n            if has_value:\n                if data:\n                    yield (neighbor_id, docgraph.node[neighbor_id])\n                else:\n                    yield neighbor_id", "response": "Get all neighbors with the given edge attribute value ( s )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a generator of nodes that are in the given layer.", "response": "def select_nodes_by_layer(docgraph, layer=None, data=False):\n    \"\"\"\n    Get all nodes belonging to (any of) the given layer(s).\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        document graph from which the nodes will be extracted\n    layer : str or collection of str or None\n        name(s) of the layer(s) to select nodes from. If None, returns all\n        nodes\n    data : bool\n        If True, results will include node attributes.\n\n    Yields\n    ------\n    nodes : generator of str or generator of (str, dict) tuple\n        If data is False (default), a generator of node IDs that are present in\n        the given layer. If data is True, a generator of (node ID, node attrib\n        dict) tuples.\n    \"\"\"\n    for node_id, node_attribs in docgraph.nodes_iter(data=True):\n        if layer is None:\n            condition = True # don't filter nodes\n        elif isinstance(layer, (str, unicode)):\n            condition = layer in node_attribs['layers']\n        else:  # ``layer`` is a list/set/dict of layers\n            condition = any(l in node_attribs['layers'] for l in layer)\n        if condition:\n            if data:\n                yield (node_id, node_attribs)\n            else:\n                yield node_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all nodes with the given attribute and value.", "response": "def select_nodes_by_attribute(docgraph, attribute=None, value=None, data=False):\n    \"\"\"\n    Get all nodes with the given attribute (and attribute value).\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        document graph from which the nodes will be extracted\n    attribute : str or None\n        Name of the node attribute that all nodes must posess.\n        If None, returns all nodes.\n    value : str or collection of str or None\n        Value of the node attribute that all nodes must posess.\n        If None, returns all nodes with the given node attribute key    .\n    data : bool\n        If True, results will include node attributes.\n\n    Yields\n    ------\n    nodes : generator of str or generator of (str, dict) tuple\n        If data is False (default), a generator of node (IDs) that posess\n        the given attribute. If data is True, a generator of (node ID,\n        node attrib dict) tuples.\n    \"\"\"\n    for node_id, node_attribs in docgraph.nodes_iter(data=True):\n        if attribute is None:\n            has_attrib = True # don't filter nodes\n        else:\n            has_attrib = attribute in node_attribs\n\n        if has_attrib:\n            if value is None:\n                has_value = True\n            elif isinstance(value, basestring):\n                has_value = node_attribs.get(attribute) == value\n            else:  # ``value`` is a list/set/dict of values\n                has_value = any(node_attribs.get(attribute) == v for v in value)\n\n            if has_value:\n                if data:\n                    yield (node_id, node_attribs)\n                else:\n                    yield node_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_edges(docgraph, conditions, data):\n    for (src_id, target_id, edge_attribs) in docgraph.edges(data=True):\n        # if all conditions are fulfilled\n        # we need to add edge_attribs to the namespace eval is working in\n        if all((eval(cond, {'edge_attribs': edge_attribs})\n                for cond in conditions)):\n            if data:\n                yield (src_id, target_id, edge_attribs)\n            else:\n                yield (src_id, target_id)", "response": "yields all edges that meet the conditions given as eval strings"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_edges_by_attribute(docgraph, attribute=None, value=None, data=False):\n    if attribute:\n        attrib_key_eval = \"'{}' in edge_attribs\".format(attribute)\n\n        if value is not None:\n            if isinstance(value, basestring):\n                attrib_val_eval = \\\n                    \"edge_attribs['{0}'] == '{1}'\".format(attribute, value)\n                return select_edges(\n                    docgraph, data=data,\n                    conditions=[attrib_key_eval, attrib_val_eval])\n\n            else:  # ``value`` is a list/set/dict of values\n                attrib_val_evals = \\\n                    [\"edge_attribs['{0}'] == '{1}'\".format(attribute, v)\n                     for v in value]\n                results = \\\n                    [select_edges(docgraph, data=data,\n                                  conditions=[attrib_key_eval, val_eval])\n                     for val_eval in attrib_val_evals]\n                # results is a list of generators\n                return itertools.chain(*results)\n\n        else:  # yield all edges with the given attribute, regardless of value\n            return select_edges(docgraph, data=data, conditions=[attrib_key_eval])\n\n    else:  # don't filter edges at all\n        return docgraph.edges_iter(data=data)", "response": "Returns a generator of discourse. DiscourseDocumentGraphEdge objects representing the edges of the given attribute and value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator of all edges in a document graph that are contained in the given edge type and layer.", "response": "def select_edges_by(docgraph, layer=None, edge_type=None, data=False):\n    \"\"\"\n    get all edges with the given edge type and layer.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        document graph from which the nodes will be extracted\n    layer : str\n        name of the layer\n    edge_type : str\n        Type of the edges to be extracted (Edge types are defined in the\n        Enum ``EdgeTypes``).\n    data : bool\n        If True, results will include edge attributes.\n\n    Returns\n    -------\n    edges : generator of str\n        a container/list of edges (represented as (source node ID, target\n        node ID) tuples). If data is True, edges are represented as\n        (source node ID, target node ID, edge attribute dict) tuples.\n    \"\"\"\n    edge_type_eval = \"edge_attribs['edge_type'] == '{}'\".format(edge_type)\n    layer_eval = \"'{}' in edge_attribs['layers']\".format(layer)\n\n    if layer is not None:\n        if edge_type is not None:\n            return select_edges(docgraph, data=data,\n                                conditions=[edge_type_eval, layer_eval])\n        else:  # filter by layer, but not by edge type\n            return select_edges(docgraph, conditions=[layer_eval], data=data)\n\n    else:  # don't filter layers\n        if edge_type is not None:  # filter by edge type, but not by layer\n            return select_edges(docgraph, data=data,\n                                conditions=[edge_type_eval])\n        else:  # neither layer, nor edge type is filtered\n            return docgraph.edges_iter(data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a dict of pointing relations and a start node, this function will return a list of paths (each path is represented as a list of node IDs -- from the first node of the path to the last). Parameters ---------- rel_dict : dict a dictionary mapping from an edge source node (node ID str) to a set of edge target nodes (node ID str) src_id : str Returns ------- paths_starting_with_id : list of list of str each list constains a list of strings (i.e. a list of node IDs, which represent a chain of pointing relations)", "response": "def __walk_chain(rel_dict, src_id):\n    \"\"\"\n    given a dict of pointing relations and a start node, this function\n    will return a list of paths (each path is represented as a list of\n    node IDs -- from the first node of the path to the last).\n\n    Parameters\n    ----------\n    rel_dict : dict\n        a dictionary mapping from an edge source node (node ID str)\n        to a set of edge target nodes (node ID str)\n    src_id : str\n\n    Returns\n    -------\n    paths_starting_with_id : list of list of str\n        each list constains a list of strings (i.e. a list of node IDs,\n        which represent a chain of pointing relations)\n    \"\"\"\n    paths_starting_with_id = []\n    for target_id in rel_dict[src_id]:\n        if target_id in rel_dict:\n            for tail in __walk_chain(rel_dict, target_id):\n                paths_starting_with_id.append([src_id] + tail)\n        else:\n            paths_starting_with_id.append([src_id, target_id])\n    return paths_starting_with_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_pointing_chains(docgraph, layer=None):\n    pointing_relations = select_edges_by(docgraph, layer=layer,\n                                         edge_type=EdgeTypes.pointing_relation)\n\n    # a markable can point to more than one antecedent, cf. Issue #40\n    rel_dict = defaultdict(set)\n    for src_id, target_id in pointing_relations:\n        rel_dict[src_id].add(target_id)\n\n    all_chains = [__walk_chain(rel_dict, src_id)\n                  for src_id in rel_dict.iterkeys()]\n\n    # don't return partial chains, i.e. instead of returning [a,b], [b,c] and\n    # [a,b,c,d], just return [a,b,c,d]\n    unique_chains = []\n    for i, src_id_chains in enumerate(all_chains):\n        # there will be at least one chain in this list and\n        # its first element is the from ID\n        src_id = src_id_chains[0][0]\n\n        # chain lists not starting with src_id\n        other_chainlists = all_chains[:i] + all_chains[i+1:]\n        if not any((src_id in chain\n                    for chain_list in other_chainlists\n                    for chain in chain_list)):\n                        unique_chains.extend(src_id_chains)\n    return unique_chains", "response": "Returns a list of chained pointing relations in the given document graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the onset and offset to each token in the document graph i. e. the character position where each token starts and ends.", "response": "def add_offsets(self, offset_ns=None):\n        \"\"\"\n        adds the onset and offset to each token in the document graph, i.e.\n        the character position where each token starts and ends.\n        \"\"\"\n        if offset_ns is None:\n            offset_ns = self.ns\n\n        onset = 0\n        offset = 0\n\n        for token_id, token_str in self.get_tokens():\n            offset = onset + len(token_str)\n            self.node[token_id]['{0}:{1}'.format(offset_ns, 'onset')] = onset\n            self.node[token_id]['{0}:{1}'.format(offset_ns, 'offset')] = offset\n            onset = offset + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_offsets(self, token_node_id=None, offset_ns=None):\n        if offset_ns is None:\n            offset_ns = self.ns\n\n        try:\n            if token_node_id is not None:\n                assert istoken(self, token_node_id), \\\n                    \"'{}' is not a token node.\".format(token_node_id)\n                onset = self.node[token_node_id]['{0}:{1}'.format(offset_ns, 'onset')]\n                offset = self.node[token_node_id]['{0}:{1}'.format(offset_ns, 'offset')]\n                return (onset, offset)\n            else:  # return offsets for all tokens in the document\n                return self._get_all_offsets(offset_ns)\n\n        # if the document doesn't have offsets: add them and rerun this method\n        except KeyError as e:\n            self.add_offsets(offset_ns)\n            return self.get_offsets(token_node_id, offset_ns)", "response": "This method returns the starting and ending positions of all the tokens occurring in the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_all_offsets(self, offset_ns=None):\n        for token_id, _token_str in self.get_tokens():\n            onset = self.node[token_id]['{0}:{1}'.format(offset_ns, 'onset')]\n            offset = self.node[token_id]['{0}:{1}'.format(offset_ns, 'offset')]\n            yield (token_id, onset, offset)", "response": "Returns a generator of all token offsets of this document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_phrases(self, ns=None, layer='syntax', cat_key='cat', cat_val='NP'):\n        if not ns:\n            ns = self.ns\n\n        for node_id in select_nodes_by_layer(self, '{0}:{1}'.format(ns, layer)):\n            if self.node[node_id][self.ns+':'+cat_key] == cat_val:\n                yield node_id", "response": "yield all node IDs that dominate the given phrase type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_node(self, n, layers=None, attr_dict=None, **attr):\n        if not layers:\n            layers = {self.ns}\n        assert isinstance(layers, set), \\\n            \"'layers' parameter must be given as a set of strings.\"\n        assert all((isinstance(layer, str) for layer in layers)), \\\n            \"All elements of the 'layers' set must be strings.\"\n        # add layers to keyword arguments dict\n        attr.update({'layers': layers})\n\n        # set up attribute dict\n        if attr_dict is None:\n            attr_dict = attr\n        else:\n            assert isinstance(attr_dict, dict), \\\n                \"attr_dict must be a dictionary, not a '{}'\".format(type(attr_dict))\n            attr_dict.update(attr)\n\n        # if there's no node with this ID in the graph, yet\n        if n not in self.succ:\n            self.succ[n] = {}\n            self.pred[n] = {}\n            self.node[n] = attr_dict\n        else:  # update attr even if node already exists\n            # if a node exists, its attributes will be updated, except\n            # for the layers attribute. the value of 'layers' will\n            # be the union of the existing layers set and the new one.\n            existing_layers = self.node[n]['layers']\n            all_layers = existing_layers.union(layers)\n            attrs_without_layers = {k: v for (k, v) in attr_dict.items()\n                                    if k != 'layers'}\n            self.node[n].update(attrs_without_layers)\n            self.node[n].update({'layers': all_layers})", "response": "Add a single node n and update node attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd multiple nodes to the current node set.", "response": "def add_nodes_from(self, nodes, **attr):\n        \"\"\"Add multiple nodes.\n\n        Parameters\n        ----------\n        nodes : iterable container\n            A container of nodes (list, dict, set, etc.).\n            OR\n            A container of (node, attribute dict) tuples.\n            Node attributes are updated using the attribute dict.\n        attr : keyword arguments, optional (default= no attributes)\n            Update attributes for all nodes in nodes.\n            Node attributes specified in nodes as a tuple\n            take precedence over attributes specified generally.\n\n        See Also\n        --------\n        add_node\n\n        Examples\n        --------\n        >>> from discoursegraphs import DiscourseDocumentGraph\n        >>> d = DiscourseDocumentGraph()\n        >>> d.add_nodes_from([(1, {'layers':{'token'}, 'word':'hello'}), \\\n                (2, {'layers':{'token'}, 'word':'world'})])\n        >>> d.nodes(data=True)\n        [(1, {'layers': {'token'}, 'word': 'hello'}),\n         (2, {'layers': {'token'}, 'word': 'world'})]\n\n        Use keywords to update specific node attributes for every node.\n\n        >>> d.add_nodes_from(d.nodes(data=True), weight=1.0)\n        >>> d.nodes(data=True)\n        [(1, {'layers': {'token'}, 'weight': 1.0, 'word': 'hello'}),\n         (2, {'layers': {'token'}, 'weight': 1.0, 'word': 'world'})]\n\n        Use (node, attrdict) tuples to update attributes for specific\n        nodes.\n\n        >>> d.add_nodes_from([(1, {'layers': {'tiger'}})], size=10)\n        >>> d.nodes(data=True)\n        [(1, {'layers': {'tiger', 'token'}, 'size': 10, 'weight': 1.0,\n              'word': 'hello'}),\n         (2, {'layers': {'token'}, 'weight': 1.0, 'word': 'world'})]\n        \"\"\"\n        additional_attribs = attr  # will be added to each node\n        for n in nodes:\n            try:  # check, if n is a node_id or a (node_id, attrib dict) tuple\n                newnode = n not in self.succ  # is node in the graph, yet?\n            except TypeError:  # n is a (node_id, attribute dict) tuple\n                node_id, ndict = n\n\n                if not 'layers' in ndict:\n                    ndict['layers'] = {self.ns}\n\n                layers = ndict['layers']\n                assert isinstance(layers, set), \\\n                    \"'layers' must be specified as a set of strings.\"\n                assert all((isinstance(layer, str) for layer in layers)), \\\n                    \"All elements of the 'layers' set must be strings.\"\n\n                if node_id not in self.succ:  # node doesn't exist, yet\n                    self.succ[node_id] = {}\n                    self.pred[node_id] = {}\n                    newdict = additional_attribs.copy()\n                    newdict.update(ndict)  # all given attribs incl. layers\n                    self.node[node_id] = newdict\n                else:  # node already exists\n                    existing_layers = self.node[node_id]['layers']\n                    all_layers = existing_layers.union(layers)\n\n                    self.node[node_id].update(ndict)\n                    self.node[node_id].update(additional_attribs)\n                    self.node[node_id].update({'layers': all_layers})\n                continue  # process next node\n\n            # newnode check didn't raise an exception\n            if newnode:  # n is a node_id and it's not in the graph, yet\n                self.succ[n] = {}\n                self.pred[n] = {}\n                self.node[n] = attr.copy()\n                # since the node isn't represented as a\n                # (node_id, attribute dict) tuple, we don't know which layers\n                # it is part of. Therefore, we'll add the namespace of the\n                # graph as the node layer\n                self.node[n].update({'layers': set([self.ns])})\n            else:  # n is a node_id and it's already in the graph\n                self.node[n].update(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_edge(self, u, v, layers=None, key=None, attr_dict=None, **attr):\n        if not layers:\n            layers = {self.ns}\n        assert isinstance(layers, set), \\\n            \"'layers' parameter must be given as a set of strings.\"\n        assert all((isinstance(layer, str) for layer in layers)), \\\n            \"All elements of the 'layers' set must be strings.\"\n        # add layers to keyword arguments dict\n        attr.update({'layers': layers})\n\n        # set up attribute dict\n        if attr_dict is None:\n            attr_dict = attr\n        else:\n            try:\n                attr_dict.update(attr)\n            except AttributeError as e:\n                raise AttributeError(\"The attr_dict argument must be \"\n                                     \"a dictionary: \".format(e))\n        for node in (u, v):  # u = source, v = target\n            if node not in self.nodes_iter():\n                self.add_node(node, layers={self.ns})\n\n        if v in self.succ[u]:  # if there's already an edge from u to v\n            keydict = self.adj[u][v]\n            if key is None:  # creating additional edge\n                # find a unique integer key\n                # other methods might be better here?\n                key = len(keydict)\n                while key in keydict:\n                    key += 1\n            datadict = keydict.get(key, {})  # works for existing & new edge\n            existing_layers = datadict.get('layers', set())\n            all_layers = existing_layers.union(layers)\n\n            datadict.update(attr_dict)\n            datadict.update({'layers': all_layers})\n            keydict[key] = datadict\n\n        else:  # there's no edge between u and v, yet\n            # selfloops work this way without special treatment\n            if key is None:\n                key = 0\n            datadict = {}\n            datadict.update(attr_dict)  # includes layers\n            keydict = {key: datadict}\n            self.succ[u][v] = keydict\n            self.pred[v][u] = keydict", "response": "Add an edge between nodes u and v."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd all the edges from the given container of edges.", "response": "def add_edges_from(self, ebunch, attr_dict=None, **attr):\n        \"\"\"Add all the edges in ebunch.\n\n        Parameters\n        ----------\n        ebunch : container of edges\n            Each edge given in the container will be added to the\n            graph. The edges can be:\n\n                - 3-tuples (u,v,d) for an edge attribute dict d, or\n                - 4-tuples (u,v,k,d) for an edge identified by key k\n\n            Each edge must have a layers attribute (set of str).\n        attr_dict : dictionary, optional  (default= no attributes)\n            Dictionary of edge attributes.  Key/value pairs will\n            update existing data associated with each edge.\n        attr : keyword arguments, optional\n            Edge data (or labels or objects) can be assigned using\n            keyword arguments.\n\n\n        See Also\n        --------\n        add_edge : add a single edge\n\n        Notes\n        -----\n        Adding the same edge twice has no effect but any edge data\n        will be updated when each duplicate edge is added.\n\n        An edge can only be added if the source and target nodes are\n        already present in the graph. This decision was taken to ensure\n        that all edges are associated with at least one (meaningful)\n        layer.\n\n        Edge attributes specified in edges as a tuple (in ebunch) take\n        precedence over attributes specified otherwise (in attr_dict or\n        attr). Layers can only be added (via a 'layers' edge attribute),\n        but not overwritten.\n\n        Examples\n        --------\n        >>> d = DiscourseDocumentGraph()\n        >>> d.add_node(1, {'int'})\n        >>> d.add_node(2, {'int'})\n\n        >>> d.add_edges_from([(1, 2, {'layers': {'int'}, 'weight': 23})])\n        >>> d.add_edges_from([(1, 2, {'layers': {'int'}, 'weight': 42})])\n\n        >>> d.edges(data=True) # multiple edges between the same nodes\n        [(1, 2, {'layers': {'int'}, 'weight': 23}),\n         (1, 2, {'layers': {'int'}, 'weight': 42})]\n\n        Associate data to edges\n\n        We update the existing edge (key=0) and overwrite its 'weight'\n        value. Note that we can't overwrite the 'layers' value, though.\n        Instead, they are added to the set of existing layers\n\n        >>> d.add_edges_from([(1, 2, 0, {'layers':{'number'}, 'weight':66})])\n        [(1, 2, {'layers': {'int', 'number'}, 'weight': 66}),\n         (1, 2, {'layers': {'int'}, 'weight': 42})]\n        \"\"\"\n        # set up attribute dict\n        if attr_dict is None:\n            attr_dict = attr\n        else:\n            try:\n                attr_dict.update(attr)\n            except AttributeError as e:\n                raise AttributeError(\"The attr_dict argument must be \"\n                                     \"a dictionary: \".format(e))\n        # process ebunch\n        for e in ebunch:\n            ne = len(e)\n            if ne == 4:\n                u, v, key, dd = e\n            elif ne == 3:\n                u, v, dd = e\n                key = None\n            else:\n                raise AttributeError(\n                    \"Edge tuple {0} must be a 3-tuple (u,v,attribs) \"\n                    \"or 4-tuple (u,v,key,attribs).\".format(e))\n\n            if not 'layers' in dd:\n                dd['layers'] = {self.ns}\n\n            layers = dd['layers']\n            assert isinstance(layers, set), \\\n                \"'layers' must be specified as a set of strings.\"\n            assert all((isinstance(layer, str)\n                        for layer in layers)), \\\n                \"All elements of the 'layers' set must be strings.\"\n            additional_layers = attr_dict.get('layers', {})\n            if additional_layers:\n                assert isinstance(additional_layers, set), \\\n                    \"'layers' must be specified as a set of strings.\"\n                assert all((isinstance(layer, str)\n                            for layer in additional_layers)), \\\n                    \"'layers' set must only contain strings.\"\n            # union of layers specified in ebunch tuples,\n            # attr_dict and **attr\n            new_layers = layers.union(additional_layers)\n\n            if u in self.adj:  # edge with u as source already exists\n                keydict = self.adj[u].get(v, {})\n            else:\n                keydict = {}\n            if key is None:\n                # find a unique integer key\n                # other methods might be better here?\n                key = len(keydict)\n                while key in keydict:\n                    key += 1\n            datadict = keydict.get(key, {})  # existing edge attribs\n            existing_layers = datadict.get('layers', set())\n            datadict.update(attr_dict)\n            datadict.update(dd)\n            updated_attrs = {k: v for (k, v) in datadict.items()\n                             if k != 'layers'}\n\n            all_layers = existing_layers.union(new_layers)\n            # add_edge() checks if u and v exist, so we don't need to\n            self.add_edge(u, v, layers=all_layers, key=key,\n                          attr_dict=updated_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a layer to an existing node or edge.", "response": "def add_layer(self, element, layer):\n        \"\"\"\n        add a layer to an existing node or edge\n\n        Parameters\n        ----------\n        element : str, int, (str/int, str/int)\n            the ID of a node or edge (source node ID, target node ID)\n        layer : str\n            the layer that the element shall be added to\n        \"\"\"\n        assert isinstance(layer, str), \"Layers must be strings!\"\n        if isinstance(element, tuple): # edge repr. by (source, target)\n            assert len(element) == 2\n            assert all(isinstance(node, (str, int)) for node in element)\n            source_id, target_id = element\n            # this class is based on a multi-digraph, so we'll have to iterate\n            # over all edges between the two nodes (even if there's just one)\n            edges = self.edge[source_id][target_id]\n            for edge in edges:\n                existing_layers = edges[edge]['layers']\n                existing_layers.add(layer)\n                edges[edge]['layers'] = existing_layers\n        if isinstance(element, (str, int)): # node\n            existing_layers = self.node[element]['layers']\n            existing_layers.add(layer)\n            self.node[element]['layers'] = existing_layers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the token unicode string given a token node ID and a token attribute name.", "response": "def get_token(self, token_node_id, token_attrib='token'):\n        \"\"\"\n        given a token node ID, returns the token unicode string.\n\n        Parameters\n        ----------\n        token_node_id : str\n            the ID of the token node\n        token_attrib : str\n            name of the node attribute that contains the token string as its\n            value (default: token).\n\n        Returns\n        -------\n        token : unicode\n            the token string\n        \"\"\"\n        return self.node[token_node_id][self.ns+':'+token_attrib]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tokens(self, token_attrib='token', token_strings_only=False):\n        if token_strings_only:\n            for token_id in self.tokens:\n                yield self.get_token(token_id, token_attrib)\n        else:\n            for token_id in self.tokens:\n                yield (token_id, self.get_token(token_id, token_attrib))", "response": "Returns a list of tuples of token node ID and token string which represent the tokens\n            of the input document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge_graphs(self, other_docgraph, verbose=False):\n        # keep track of all merged/old root nodes in case we need to\n        # delete them or their attributes (e.g. 'metadata')\n        if hasattr(self, 'merged_rootnodes'):\n            self.merged_rootnodes.append(other_docgraph.root)\n        else:\n            self.merged_rootnodes = [other_docgraph.root]\n\n        # renaming the tokens of the other graph to match this one\n        rename_tokens(other_docgraph, self, verbose=verbose)\n        self.add_nodes_from(other_docgraph.nodes(data=True))\n\n        # copy token node attributes to the current namespace\n        for node_id, node_attrs in other_docgraph.nodes(data=True):\n            if istoken(other_docgraph, node_id) and \\\n                self.ns+':token' not in self.node[node_id]:\n                    self.node[node_id].update({self.ns+':token': other_docgraph.get_token(node_id)})\n        self.add_edges_from(other_docgraph.edges(data=True))\n\n        # workaround for issues #89 and #96\n        # copy the token node IDs / sentence node IDs from the other graph,\n        # if this graph doesn't have such lists, yet\n        if other_docgraph.name and not self.name:\n            self.name = other_docgraph.name\n        if other_docgraph.tokens and not self.tokens:\n            self.tokens = other_docgraph.tokens\n        if other_docgraph.sentences and not self.sentences:\n            self.sentences = other_docgraph.sentences\n\n        # there should be no dangling, unused root nodes in a merged graph\n        self.merge_rootnodes(other_docgraph)", "response": "Merges the other document graph into this one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_rootnodes(self, other_docgraph):\n        # copy metadata from other graph, cf. #136\n        if 'metadata' in other_docgraph.node[other_docgraph.root]:\n            other_meta = other_docgraph.node[other_docgraph.root]['metadata']\n            self.node[self.root]['metadata'].update(other_meta)\n\n        assert not other_docgraph.in_edges(other_docgraph.root), \\\n            \"root node in graph '{}' must not have any ingoing edges\".format(\n                other_docgraph.name)\n\n        for (root, target, attrs) in other_docgraph.out_edges(\n            other_docgraph.root, data=True):\n                self.add_edge(self.root, target, attr_dict=attrs)\n        self.remove_node(other_docgraph.root)", "response": "Merge all the root nodes of the other graph into this one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_precedence_relations(self):\n        assert len(self.tokens) > 1, \\\n            \"There are no tokens to add precedence relations to.\"\n        self.add_edge(self.root, self.tokens[0],\n                      layers={self.ns, self.ns+':precedence'},\n                      edge_type=EdgeTypes.precedence_relation)\n        for i, token_node_id in enumerate(self.tokens[1:]):\n            # edge from token_n to token_n+1\n            self.add_edge(self.tokens[i], token_node_id,\n                          layers={self.ns, self.ns+':precedence'},\n                          edge_type=EdgeTypes.precedence_relation)", "response": "Adds the precedence relations to the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef paula_etree_to_string(tree, dtd_filename):\n    return etree.tostring(\n        tree, pretty_print=True, xml_declaration=True,\n        encoding=\"UTF-8\", standalone='no',\n        doctype='<!DOCTYPE paula SYSTEM \"{0}\">'.format(dtd_filename))", "response": "convert a PAULA etree into an XML string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an empty PAULA XML file", "response": "def gen_paula_etree(paula_id):\n    \"\"\"\n    creates an element tree representation of an empty PAULA XML file.\n    \"\"\"\n    E = ElementMaker(nsmap=NSMAP)\n    tree = E('paula', version='1.1')\n    tree.append(E('header', paula_id=paula_id))\n    return E, tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator of tuples that yields onsets for the given list of tokens.", "response": "def get_onsets(token_tuples):\n    \"\"\"\n    Parameters\n    ----------\n    token_tuples : list of (str, unicode)\n        a list/generator of (token ID, token string) tuples\n\n    Returns\n    -------\n    onset_tuples : generator of (str, int, int)\n        A list/generator of (token ID, onset, token length) tuples.\n        Note that PAULA starts counting string onsets with 1!\n    \"\"\"\n    onset = 1\n    for (token_id, token) in token_tuples:\n        yield (token_id, onset, len(token))\n        onset += (len(token) + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a DiscourseDocumentGraph into a set of PAULA XML files representing the same document.", "response": "def write_paula(docgraph, output_root_dir, human_readable=False):\n    \"\"\"\n    converts a DiscourseDocumentGraph into a set of PAULA XML files\n    representing the same document.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        the document graph to be converted\n    \"\"\"\n    paula_document = PaulaDocument(docgraph, human_readable=human_readable)\n    error_msg = (\"Please specify an output directory.\\nPaula documents consist\"\n                 \" of multiple files, so we can't just pipe them to STDOUT.\")\n    assert isinstance(output_root_dir, str), error_msg\n    document_dir = os.path.join(output_root_dir, paula_document.name)\n    if not os.path.isdir(document_dir):\n        create_dir(document_dir)\n    for paula_id in paula_document.files:\n        with open(os.path.join(document_dir, paula_id+'.xml'), 'w') as outfile:\n            outfile.write(\n                paula_etree_to_string(paula_document.files[paula_id],\n                                      paula_document.file2dtd[paula_id]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __gen_primary_text_file(self):\n        paula_id = '{0}.{1}.text'.format(self.corpus_name, self.name)\n        E, tree = gen_paula_etree(paula_id)\n        tree.append(E.body(get_text(self.dg)))\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.text\n        return paula_id", "response": "Generate the PAULA file that contains the primary text of the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __gen_tokenization_file(self):\n        paula_id = '{0}.{1}.tok'.format(self.corpus_name, self.name)\n        E, tree = gen_paula_etree(paula_id)\n        self.paulamap['tokenization'] = paula_id\n\n        base_paula_id = '{0}.{1}.text'.format(self.corpus_name, self.name)\n        mlist = E('markList',\n                  {'type': 'tok',\n                   XMLBASE: base_paula_id+'.xml'})\n        tok_tuples = self.dg.get_tokens()\n        for (tid, onset, tlen) in get_onsets(tok_tuples):\n            # even SaltNPepper still uses xpointers for string-ranges!\n            xp = \"#xpointer(string-range(//body,'',{0},{1}))\".format(onset, tlen)\n            mlist.append(E('mark', {'id': tid,\n                                    XLINKHREF: xp}))\n        tree.append(mlist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.mark\n        return paula_id", "response": "Generate the PAULA file that contains the tokenization of the document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a span markable file for the given layer.", "response": "def __gen_span_markables_file(self, layer, saltnpepper_compatible=True):\n        \"\"\"\n        <mark> elements are used to group tokens (continuous or discontinuos\n        spans) for further annotation.\n        A span markable file (*_seg.xml) contains a list of spans and the type\n        of annotation that is applied to them\n        (stored in <markList type=\"annotation type...\"). As a consequence,\n        each span markable file contains only spans of a single type\n        (in discoursegraph: spans from a single namespace, e.g. syntax\n        categories or entity mentions).\n\n        Note: The annotations themselves are stored in other files, using\n        <feat> or <multiFeat> elements.\n        \"\"\"\n        paula_id = '{0}.{1}.{2}_{3}_seg'.format(layer, self.corpus_name,\n                                            self.name, layer)\n        E, tree = gen_paula_etree(paula_id)\n        base_paula_id = '{0}.{1}.tok'.format(self.corpus_name, self.name)\n        mlist = E('markList',\n                  {'type': layer,\n                   XMLBASE: base_paula_id+'.xml'})\n\n        span_dict = defaultdict(lambda: defaultdict(str))\n        edges = select_edges_by(self.dg, layer=layer,\n                                edge_type=EdgeTypes.spanning_relation,\n                                data=True)\n        for source_id, target_id, edge_attrs in edges:\n            span_dict[source_id][target_id] = edge_attrs\n\n        target_dict = defaultdict(list)\n        for source_id in span_dict:\n            targets = sorted(span_dict[source_id], key=natural_sort_key)\n            if saltnpepper_compatible:  # SNP doesn't like xpointer ranges\n                xp = ' '.join('#{0}'.format(target_id)\n                              for target_id in targets)\n            else:  # PAULA XML 1.1 specification\n                xp = '#xpointer(id({0})/range-to(id({1})))'.format(targets[0],\n                                                                 targets[-1])\n            mark = E('mark', {XLINKHREF: xp})\n            if self.human_readable:\n                # add <!-- comments --> containing the token strings\n                mark.append(Comment(tokens2text(self.dg, targets)))\n                target_dict[targets[0]].append(mark)\n            else:\n                mlist.append(mark)\n\n        if self.human_readable:  # order <mark> elements by token ordering\n            for target in sorted(target_dict, key=natural_sort_key):\n                for mark in target_dict[target]:\n                    mlist.append(mark)\n\n        tree.append(mlist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.mark\n        return paula_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate an annotation file for each token in the corpus.", "response": "def __gen_token_anno_file(self, top_level_layer):\n        \"\"\"\n        creates an etree representation of a <multiFeat> file that describes\n        all the annotations that only span one token (e.g. POS, lemma etc.).\n\n        Note: discoursegraphs will create one token annotation file for each\n        top level layer (e.g. conano, tiger etc.).\n        \"\"\"\n        base_paula_id = '{0}.{1}.tok'.format(self.corpus_name, self.name)\n        paula_id = '{0}.{1}.{2}.tok_multiFeat'.format(top_level_layer,\n                                                   self.corpus_name,\n                                                   self.name)\n        E, tree = gen_paula_etree(paula_id)\n        mflist = E('multiFeatList',\n                   {XMLBASE: base_paula_id+'.xml'})\n\n        for token_id in self.dg.tokens:\n            mfeat = E('multiFeat',\n                      {XLINKHREF: '#{0}'.format(token_id)})\n            token_dict = self.dg.node[token_id]\n            for feature in token_dict:\n                # TODO: highly inefficient! refactor!1!!\n                if feature not in IGNORED_TOKEN_ATTRIBS \\\n                   and feature.startswith(top_level_layer):\n                    mfeat.append(E('feat',\n                                   {'name': feature,\n                                    'value': token_dict[feature]}))\n\n            if self.human_readable:  # adds token string as a <!-- comment -->\n                mfeat.append(Comment(token_dict[self.dg.ns+':token']))\n            mflist.append(mfeat)\n\n        tree.append(mflist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.multifeat\n        return paula_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __gen_hierarchy_file(self, layer):\n        paula_id = '{0}.{1}.{2}_{3}'.format(layer, self.corpus_name, self.name,\n                                        layer)\n        self.paulamap['hierarchy'][layer] = paula_id\n        E, tree = gen_paula_etree(paula_id)\n\n        dominance_edges = select_edges_by(\n            self.dg, layer=layer, edge_type=EdgeTypes.dominance_relation,\n            data=True)\n        span_edges = select_edges_by(\n            self.dg, layer=layer, edge_type=EdgeTypes.spanning_relation,\n            data=True)\n        dominance_dict = defaultdict(lambda: defaultdict(str))\n        for source_id, target_id, edge_attrs in dominance_edges:\n            if source_id != layer+':root_node':\n                dominance_dict[source_id][target_id] = edge_attrs\n\n        # in PAULA XML, token spans are also part of the hierarchy\n        for source_id, target_id, edge_attrs in span_edges:\n            if istoken(self.dg, target_id):\n                dominance_dict[source_id][target_id] = edge_attrs\n\n        # NOTE: we don't add a base file here, because the nodes could be\n        # tokens or structural nodes\n        slist = E('structList', {'type': layer})\n        for source_id in dominance_dict:\n            struct = E('struct',\n                       {'id': str(source_id)})\n            if self.human_readable:\n                struct.append(Comment(self.dg.node[source_id].get('label')))\n\n            for target_id in dominance_dict[source_id]:\n                if istoken(self.dg, target_id):\n                    href = '{0}.xml#{1}'.format(self.paulamap['tokenization'],\n                                              target_id)\n                else:\n                    href = '#{0}'.format(target_id)\n\n                rel = E(\n                    'rel',\n                    {'id': 'rel_{0}_{1}'.format(source_id, target_id),\n                     'type': dominance_dict[source_id][target_id]['edge_type'],\n                     XLINKHREF: href})\n                struct.append(rel)\n                if self.human_readable:\n                    struct.append(\n                        Comment(self.dg.node[target_id].get('label')))\n            slist.append(struct)\n        tree.append(slist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.struct\n        return paula_id", "response": "Generate a hierarchy file for the given top level annotation graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __gen_struct_anno_files(self, top_level_layer):\n        paula_id = '{0}.{1}.{2}_{3}_struct'.format(top_level_layer,\n                                               self.corpus_name, self.name,\n                                               top_level_layer)\n        E, tree = gen_paula_etree(paula_id)\n\n        base_paula_id = self.paulamap['hierarchy'][top_level_layer]\n        mflist = E('multiFeatList',\n                   {XMLBASE: base_paula_id+'.xml'})\n\n        for node_id in select_nodes_by_layer(self.dg, top_level_layer):\n            if not istoken(self.dg, node_id):\n                mfeat = E('multiFeat',\n                          {XLINKHREF: '#{0}'.format(node_id)})\n                node_dict = self.dg.node[node_id]\n                for attr in node_dict:\n                    if attr not in IGNORED_NODE_ATTRIBS:\n                        mfeat.append(\n                            E('feat',\n                              {'name': attr, 'value': node_dict[attr]}))\n                if self.human_readable:  # adds node label as a <!--comment-->\n                    mfeat.append(Comment(node_dict.get('label')))\n                mflist.append(mfeat)\n        tree.append(mflist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.multifeat\n        return paula_id", "response": "Generate the annotation file for a struct."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an annotation file for a specific top - level relation.", "response": "def __gen_rel_anno_file(self, top_level_layer):\n        \"\"\"\n        A rel annotation file contains edge (rel)\n        attributes. It is e.g. used to annotate the type of a dependency\n        relation (subj, obj etc.).\n\n        See also: __gen_hierarchy_file()\n        \"\"\"\n        paula_id = '{0}.{1}.{2}_{3}_rel'.format(top_level_layer, self.corpus_name,\n                                            self.name, top_level_layer)\n        E, tree = gen_paula_etree(paula_id)\n\n        dominance_edges = select_edges_by(\n            self.dg, layer=top_level_layer,\n            edge_type=EdgeTypes.dominance_relation, data=True)\n        dominance_dict = defaultdict(lambda: defaultdict(str))\n        for source_id, target_id, edge_attrs in dominance_edges:\n            if source_id != top_level_layer+':root_node':\n                dominance_dict[source_id][target_id] = edge_attrs\n\n        base_paula_id = self.paulamap['hierarchy'][top_level_layer]\n        mflist = E('multiFeatList',\n                   {XMLBASE: base_paula_id+'.xml'})\n        for source_id in dominance_dict:\n            for target_id in dominance_dict[source_id]:\n                rel_href = '#rel_{0}_{1}'.format(source_id, target_id)\n                mfeat = E('multiFeat',\n                          {XLINKHREF: rel_href})\n                edge_attrs = dominance_dict[source_id][target_id]\n                for edge_attr in edge_attrs:\n                    if edge_attr not in IGNORED_EDGE_ATTRIBS:\n                        mfeat.append(E('feat',\n                                       {'name': edge_attr,\n                                        'value': edge_attrs[edge_attr]}))\n\n                if self.human_readable:  # adds edge label as a <!--comment-->\n                    source_label = self.dg.node[source_id].get('label')\n                    target_label = self.dg.node[target_id].get('label')\n                    mfeat.append(Comment(u'{0} - {1}'.format(source_label,\n                                                           target_label)))\n                mflist.append(mfeat)\n\n        tree.append(mflist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.multifeat\n        return paula_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __gen_pointing_file(self, top_level_layer):\n        paula_id = '{0}.{1}.{2}_{3}_pointing'.format(top_level_layer,\n                                                 self.corpus_name, self.name,\n                                                 top_level_layer)\n        self.paulamap['pointing'][top_level_layer] = paula_id\n        E, tree = gen_paula_etree(paula_id)\n\n        pointing_edges = select_edges_by(self.dg, layer=top_level_layer,\n                                         edge_type=EdgeTypes.pointing_relation,\n                                         data=True)\n        pointing_dict = defaultdict(lambda: defaultdict(str))\n        for source_id, target_id, edge_attrs in pointing_edges:\n            pointing_dict[source_id][target_id] = edge_attrs\n\n        # NOTE: we don't add a base file here, because the nodes could be\n        # tokens or structural nodes\n        rlist = E('relList')\n        for source_id in pointing_dict:\n            for target_id in pointing_dict[source_id]:\n                source_href = self.__gen_node_href(top_level_layer, source_id)\n                target_href = self.__gen_node_href(top_level_layer, target_id)\n                rel = E('rel',\n                        {'id': 'rel_{0}_{1}'.format(source_id, target_id),\n                         XLINKHREF: source_href,\n                         'target': target_href})\n\n                # adds source/target node labels as a <!-- comment -->\n                if self.human_readable:\n                    source_label = self.dg.node[source_id].get('label')\n                    target_label = self.dg.node[target_id].get('label')\n                    rel.append(Comment(u'{0} - {1}'.format(source_label,\n                                                         target_label)))\n                rlist.append(rel)\n        tree.append(rlist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.rel\n        return paula_id", "response": "Generates the PAULA XML file representation of a pointing node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate an annoSet file for this corpus.", "response": "def __gen_annoset_file(self):\n        \"\"\"\n        An ``annoSet`` file describes the set of annotations contained in a\n        document (i.e. it lists all annotation files that belong to a PAULA\n        document). Each PAULA document must contain an annoSet file.\n\n        An ``annoSet`` file can also be used to list the contents of a\n        (sub)corpus, but we're not using this feature in discoursegraphs, yet.\n        \"\"\"\n        paula_id = '{0}.{1}.anno'.format(self.corpus_name, self.name)\n        E, tree = gen_paula_etree(paula_id)\n\n        slist = E('structList', {'type': 'annoSet'})\n        # NOTE: we could group all the annotations into different structs\n        # but I don't see the point. We're already using namespaces, after all\n        struct = E('struct', {'id': 'anno_all_annotations'})\n        for i, file_id in enumerate(self.files):\n            struct.append(E('rel',\n                            {'id': 'rel_{0}'.format(i),\n                             XLINKHREF: file_id+'.xml'}))\n        slist.append(struct)\n        tree.append(slist)\n        self.files[paula_id] = tree\n        self.file2dtd[paula_id] = PaulaDTDs.struct\n        return paula_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a complete xlink : href for any node in the docgraph.", "response": "def __gen_node_href(self, layer, node_id):\n        \"\"\"\n        generates a complete xlink:href for any node (token node,\n        structure node etc.) in the docgraph. This will only work AFTER\n        the corresponding PAULA files have been created (and their file names\n        are registered in ``self.paulamap``).\n        \"\"\"\n        if istoken(self.dg, node_id):\n            base_paula_id = self.paulamap['tokenization']\n        else:\n            base_paula_id = self.paulamap['hierarchy'][layer]\n        return '{0}.xml#{1}'.format(base_paula_id, node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_choices(timezones, grouped=False):\n\n    # Created a namedtuple to store the \"key\" for the choices_dict\n    TZOffset = namedtuple('TZOffset', 'value offset_string')\n\n    choices_dict = defaultdict(list)\n\n    # Iterate through the timezones and populate the timezone choices\n    for tz in iter(timezones):\n        # Retrieve a datetime object in this time zone\n        now = datetime.now(pytz.timezone(tz))\n\n        # Retrieve the timezone offset (\"-0500\" / \"+0500\")\n        offset = now.strftime(\"%z\")\n\n        # Retrieve the offset string (\"GMT-12:00\" / \"GMT+12:00\")\n        timezone_offset_string = 'GMT{plus_minus}{hours}:{minutes}'.format(\n            **TIMEZONE_OFFSET_REGEX.match(offset).groupdict()\n        )\n\n        if not grouped:\n            # Format the timezone display string\n            display_string = '({timezone_offset_string}) {tz}'.format(\n                timezone_offset_string=timezone_offset_string,\n                tz=tz,\n            )\n        else:\n            display_string = tz\n\n        choices_dict[\n            TZOffset(value=int(offset), offset_string=timezone_offset_string)\n        ].append(\n            (tz, display_string)\n        )\n\n    choices = []\n\n    for tz_offset in sorted(choices_dict, key=attrgetter('value')):\n        if not grouped:\n            choices.extend(\n                tuple(choices_dict[tz_offset])\n            )\n        else:\n            choices.append(\n                (\n                    tz_offset.offset_string,\n                    tuple(choices_dict[tz_offset])\n                )\n            )\n\n    # Cast the timezone choices to a tuple and return\n    return tuple(choices)", "response": "Retrieves the timezone choices from any iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_etree(cls, etree_element):\n        return cls(name=etree_element.attrib['name'],\n                   value=etree_element.attrib['valueString'],\n                   xsi_type=get_xsi_type(etree_element),\n                   namespace=etree_element.attrib.get('namespace'),\n                   hexvalue=etree_element.attrib['value'])", "response": "Creates a SaltLabel object from an lxml. etree. _Element containing a label\n            element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_etree(self):\n        attribs = {\n            '{{{pre}}}type'.format(pre=NAMESPACES['xsi']): self.xsi_type,\n            'namespace': self.namespace, 'name': self.name,\n            'value': self.hexvalue, 'valueString': self.value}\n        non_empty_attribs = {key: val for (key, val) in attribs.items()\n                             if val is not None}\n        E = ElementMaker()\n        return E('labels', non_empty_attribs)", "response": "Creates an etree element that mimicks a SaltXMI\n        element"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gen_bracket_mappings(docgraph, layer=None):\n    # we can't rely on the .ns attribute of a merged graph\n    if layer:\n        namespace = dg.layer2namespace(layer)\n    else:\n        namespace = docgraph.ns\n\n    pointing_chains = dg.get_pointing_chains(docgraph, layer=layer)\n    markables = sorted(itertools.chain(*pointing_chains),\n                       key=dg.util.natural_sort_key)\n\n    markable2chain = {}\n    for chain in pointing_chains:\n        chain_id = chain[0] # first markable in a chain\n        for markable in chain:\n            markable2chain[markable] = chain_id\n\n    opening = defaultdict(list)\n    closing = defaultdict(list)\n    for markable in markables:\n        if namespace+':span' in docgraph.node[markable]:\n            span_tokens = spanstring2tokens(\n                docgraph, docgraph.node[markable][namespace+':span'])\n            opening[span_tokens[0]].append(markable)\n            closing[span_tokens[-1]].append(markable)\n    return opening, closing, markable2chain", "response": "Generates a dictionary describing the opening and closing tokens of all pointing chains in a document graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_brackets(docgraph, output_file, layer='mmax'):\n    bracketed_str = gen_bracketed_output(docgraph, layer=layer)\n    assert isinstance(output_file, (str, file))\n    if isinstance(output_file, str):\n        path_to_file = os.path.dirname(output_file)\n        if not os.path.isdir(path_to_file):\n            create_dir(path_to_file)\n        with codecs.open(output_file, 'w', 'utf-8') as outfile:\n            outfile.write(bracketed_str)\n\n    else:  # output_file is a file object\n        output_file.write(bracketed_str)", "response": "Converts a document graph into a plain text file with brackets."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a NetworkX node into a Geoff string.", "response": "def node2geoff(node_name, properties, encoder):\n    \"\"\"converts a NetworkX node into a Geoff string.\n\n    Parameters\n    ----------\n    node_name : str or int\n        the ID of a NetworkX node\n    properties : dict\n        a dictionary of node attributes\n    encoder : json.JSONEncoder\n        an instance of a JSON encoder (e.g. `json.JSONEncoder`)\n\n    Returns\n    -------\n    geoff : str\n        a Geoff string\n    \"\"\"\n    if properties:\n        return '({0} {1})'.format(node_name,\n                                  encoder.encode(properties))\n    else:\n        return '({0})'.format(node_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edge2geoff(from_node, to_node, properties, edge_relationship_name, encoder):\n    edge_string = None\n    if properties:\n        args = [from_node, edge_relationship_name,\n                encoder.encode(properties), to_node]\n        edge_string = '({0})-[:{1} {2}]->({3})'.format(*args)\n    else:\n        args = [from_node, edge_relationship_name, to_node]\n        edge_string = '({0})-[:{1}]->({2})'.format(*args)\n\n    return edge_string", "response": "converts a NetworkX edge into a Geoff string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a NetworkX Graph to a geoff string.", "response": "def graph2geoff(graph, edge_rel_name, encoder=None):\n    \"\"\" Get the `graph` as Geoff string. The edges between the nodes\n    have relationship name `edge_rel_name`. The code\n    below shows a simple example::\n\n        # create a graph\n        import networkx as nx\n        G = nx.Graph()\n        G.add_nodes_from([1, 2, 3])\n        G.add_edge(1, 2)\n        G.add_edge(2, 3)\n\n        # get the geoff string\n        geoff_string = graph2geoff(G, 'LINKS_TO')\n\n    If the properties are not json encodable, please pass a custom JSON encoder\n    class. See `JSONEncoder\n    <http://docs.python.org/2/library/json.html#json.JSONEncoder/>`_.\n\n    Parameters\n    ----------\n    graph : Graph or DiGraph\n        a NetworkX Graph or a DiGraph\n    edge_rel_name : str\n        relationship name between the nodes\n    encoder: JSONEncoder or None\n        JSONEncoder object. Defaults to JSONEncoder.\n\n    Returns\n    -------\n    geoff : str\n        a Geoff string\n    \"\"\"\n    if encoder is None:\n        encoder = json.JSONEncoder()\n    is_digraph = isinstance(graph, nx.DiGraph)\n\n    lines = []\n    lapp = lines.append\n    for node_name, properties in graph.nodes(data=True):\n        lapp(node2geoff(node_name, properties, encoder))\n\n    for from_node, to_node, properties in graph.edges(data=True):\n        lapp(edge2geoff(from_node, to_node, properties, edge_rel_name, encoder))\n        if not is_digraph:\n            lapp(edge2geoff(to_node, from_node, properties, edge_rel_name,\n                          encoder))\n\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the capitalized relation name from a tree s satellite subtree label e. g. satellite : contrast becomes Contrast.", "response": "def get_capitalized_relname(tree, subtree_index):\n    \"\"\"Returns the capitalized relation name from a tree's satellite\n    subtree label, e.g. 'satellite:contrast' becomes 'Contrast'.\n    \"\"\"\n    match = HS2015_REL_RE.match(tree[subtree_index].label())\n    relname = match.group('relname')\n    return relname.capitalize()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_hs2015(heilman_filepath):\n    with open(heilman_filepath, 'r') as parsed_file:\n        heilman_json = json.load(parsed_file)\n\n    edus = heilman_json['edu_tokens']\n\n    # the Heilman/Sagae parser can theoretically produce more than one parse,\n    # but I've never seen more than one, so we'll just the that.\n    scored_rst_tree = heilman_json['scored_rst_trees'][0]\n    tree_str = scored_rst_tree['tree']\n\n    parented_tree = nltk.ParentedTree.fromstring(tree_str)\n    _add_edus_to_tree(parented_tree, edus)\n    return parented_tree, edus", "response": "parse the output of the Heilman and Sagae 2015 discourse parser\n    into a nltk. ParentedTree instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_edu_text(text_subtree):\n    assert text_subtree.label() == SubtreeType.text\n    return u' '.join(word.decode('utf-8') for word in text_subtree.leaves())", "response": "return the text of the given EDU subtree"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tree_type(tree):\n    if is_leaf_node(tree):\n        return SubtreeType.leaf\n\n    tree_type = tree.label().lower().split(':')[0]\n    assert tree_type in SUBTREE_TYPES\n    return tree_type", "response": "Return the tree type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a tree and check what types of children it has. Returns a map from child tree type to the indices of all children with that type.", "response": "def get_child_types(tree):\n    \"\"\"Take a tree and check what types of children (i.e. 'nucleus' or\n    'satellite') it has. Returns a map from child tree type to the indices of\n    all children with that type.\n    \"\"\"\n    child_types = defaultdict(list)\n    for i, child in enumerate(tree):\n        child_types[get_tree_type(child)].append(i)\n    return child_types"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nuclearity_type(child_types):\n    if 'text' in child_types and len(child_types) == 1:\n        return NucType.edu\n\n    assert 'nucleus' in child_types, \\\n        \"This is not a relational node. child_types: {}\".format(child_types)\n\n    if 'satellite' not in child_types:\n        assert len(child_types['nucleus']) > 1\n        return NucType.multinuc\n\n    else:  # 'satellite' in child_types\n        assert len(child_types['nucleus']) == 1\n        if len(child_types['satellite']) == 1:\n            return NucType.nucsat\n        else:\n            assert len(child_types['satellite']) > 1\n            return NucType.multisat", "response": "Returns the nuclearity type of an RST relation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds EDUs to the parented tree.", "response": "def _add_edus_to_tree(parented_tree, edus):\n    \"\"\"replace EDU indices with the text of the EDUs\n    in a parented tree.\n\n    Parameters\n    ----------\n    parented_tree : nltk.ParentedTree\n        a parented tree that only contains EDU indices\n        as leaves\n    edus : list(list(unicode))\n        a list of EDUs, where each EDU is represented as\n        a list of tokens\n    \"\"\"\n    for i, child in enumerate(parented_tree):\n        if isinstance(child, nltk.Tree):\n            _add_edus_to_tree(child, edus)\n        else:\n            edu_index = int(child)\n            edu_tokens = edus[edu_index]\n            parented_tree[i] = u\" \".join(edu_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hs2015tree2dgparentedtree(self):\n        def transform(hs2015_tree):\n            \"\"\"Transform a HS2015 parse tree into a more conventional parse tree.\n\n            The input tree::\n\n                                 ROOT\n                        __________|________\n                satellite:contra      nucleus:span\n                       st                  |\n                       |                   |\n                      text                text\n                       |                   |\n                    Although              they\n                    they did            accepted\n                    n't like           the offer\n                      it ,                 .\n\n                                  Contrast\n                         ____________|___________\n                        S                        N\n                        |                        |\n                  Although they            they accepted\n                did n't like it ,           the offer .\n            \"\"\"\n            if is_leaf_node(hs2015_tree):\n                return hs2015_tree\n\n            tree_type = get_tree_type(hs2015_tree)\n            if tree_type in (SubtreeType.root, SubtreeType.nucleus, SubtreeType.satellite):\n                child_types = get_child_types(hs2015_tree)\n                rel_nuc_type = get_nuclearity_type(child_types)\n                if rel_nuc_type == NucType.nucsat:\n                    nuc_id = child_types['nucleus'][0]\n                    sat_id = child_types['satellite'][0]\n                    return get_nucsat_subtree(hs2015_tree, nuc_id, sat_id)\n\n                elif rel_nuc_type == NucType.multinuc:\n                    transformed_subtrees = [Tree('N', [transform(st)]) for st in hs2015_tree]\n                    # in a multinuc, all nucs will carry the relation name\n                    relname = get_capitalized_relname(hs2015_tree, 0)\n                    return Tree(relname, transformed_subtrees)\n\n                elif rel_nuc_type == NucType.multisat:\n                    # In RST, multiple satellites (at least adjacent ones)\n                    # can be in a relation with the same nucleus.\n                    # To express this in a tree, we convert this schema to\n                    # a left-branching structure, e.g. (((N S) S) S).\n                    nuc_id = child_types['nucleus'][0]\n                    first_sat_id in child_types['satellite'][0]\n\n                    multisat_subtree = get_nucsat_subtree(hs2015_tree, nuc_id, first_sat_id)\n                    for sat_id in child_types['satellite'][1:]:\n                        sat_subtree = hs2015_tree[sat_id]\n                        relname = get_capitalized_relname(hs2015_tree, sat_id)\n                        multisat_subtree = Tree(relname, [\n                            Tree('N', [multisat_subtree]),\n                            Tree('S', [transform(sat_subtree)])\n                        ])\n                    return multisat_subtree\n\n                elif rel_nuc_type == NucType.edu:\n                    # return the EDU text string\n                    return hs2015_tree[0][0]\n\n                else:\n                    raise ValueError(\"Unknown nuclearity type: {}\".format(rel_nuc_type))\n\n            else:\n                assert tree_type == SubtreeType.text\n\n        def get_nucsat_subtree(tree, nuc_id, sat_id):\n            nuc_subtree = tree[nuc_id]\n            sat_subtree = tree[sat_id]\n            relname = get_capitalized_relname(tree, sat_id)\n\n            # determine order of subtrees\n            if nuc_id < sat_id:\n                return Tree(relname, [\n                    Tree('N', [transform(nuc_subtree)]),\n                    Tree('S', [transform(sat_subtree)])\n                ])\n            else:\n                return Tree(relname, [\n                    Tree('S', [transform(sat_subtree)]),\n                    Tree('N', [transform(nuc_subtree)])\n                ])\n\n        tree = transform(self.hs2015file_tree)\n        return DGParentedTree.convert(tree)", "response": "Convert a HS2015 tree into a more conventional binary tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate an appropriate node label for a segment.", "response": "def get_segment_label(segment, segment_type, segment_text, ns, tokenized):\n    \"\"\"\n    generates an appropriate node label for a segment (useful for dot\n    visualization).\n    \"\"\"\n    segment_prefix = segment_type[0] if segment_type else '_'\n    if tokenized:\n        segment_label = u'[{0}]:{1}:segment:{2}'.format(\n            segment_prefix, ns, segment.attrib['id'])\n    else:\n        # if the graph is not tokenized, put (the beginning of) the\n        # segment's text into its label\n        segment_label = u'[{0}]:{1}: {2}...'.format(\n            segment_prefix, segment.attrib['id'], segment_text[:20])\n    return segment_label"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, controller_id, command, *args, **kwargs):\n        controller_instance = self.controllers[controller_id]\n        controller_instance.last_command_at = self.last_command_at\n        ret_val = getattr(controller_instance, command)(*args, **kwargs)\n        self.last_command_at = controller_instance.last_command_at\n        return ret_val", "response": "Execute a single command on the specified controller and sets sleep times properly."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the bulb type for the specified group.", "response": "def set_group_type(self, group, bulb_type):\n        \"\"\" Set bulb type for specified group.\n\n        Group must be int between 1 and 4.\n\n        Type must be \"rgbw\" or \"white\".\n\n        Alternatively, use constructor keywords group_1, group_2 etc. to set bulb types.\n        \"\"\"\n        if bulb_type not in (\"rgbw\", \"white\"):\n            raise AttributeError(\"Bulb type must be either rgbw or white\")\n\n        self.group[group] = bulb_type\n        self.has_white = \"white\" in self.group.values()\n        self.has_rgbw = \"rgbw\" in self.group.values()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_command(self, input_command):\n        if input_command is None:\n            return\n        time_since_last_command = time.time() - self.last_command_at\n        if time_since_last_command < self.pause_between_commands:\n            # Wifi gateway requires 100ms pause between commands to function at least somewhat reliably.\n            time.sleep(self.pause_between_commands - time_since_last_command)\n        self.last_command_at = time.time()\n        command = b\"\"\n        for item in input_command:\n            command = command + item\n        if len(command) == 1:\n            command = command + b\"\\x00\"\n        if len(command) == 2:\n            command = command + b\"\\x55\"\n\n        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        sock.sendto(command, (self.gateway_ip, self.gateway_port))\n        sock.close()\n        return command", "response": "Send a command to the Wifi gateway."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a single command to specific group.", "response": "def _send_to_group(self, group, **kwargs):\n        \"\"\" You shouldn't use this method directly.\n\n        Send a single command to specific group.\n\n        Handles automatically sending command to white or rgbw group.\n        \"\"\"\n        retries = kwargs.get(\"retries\", self.repeat_commands)\n        for _ in range(retries):\n            if kwargs.get(\"send_on\", True):\n                self.on(group)\n            if group is None or group == 0:\n                self._send_to_all_groups(**kwargs)\n                continue\n\n            if group < 1 or group > 4:\n                raise AttributeError(\"Group must be between 1 and 4 (was %s)\" % group)\n\n            if kwargs.get(\"per_group\"):\n                self._send_command(kwargs.get(\"%s_cmd\" % self.get_group_type(group), [None, None, None, None])[group - 1])\n                continue\n            if self.get_group_type(group) == \"white\":\n                command = self.WHITE_COMMANDS.get(kwargs[\"command\"])\n            elif self.get_group_type(group) == \"rgbw\":\n                if kwargs[\"command\"] == \"color_by_int\":\n                    command = (self.RGBW_COMMANDS[\"color_by_int\"], struct.pack(\"B\", kwargs[\"color\"]))\n                else:\n                    command = self.RGBW_COMMANDS.get(kwargs[\"command\"])\n            self._send_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on(self, group=None):  # pylint: disable=invalid-name\n        if group is None or group == 0:\n            self._send_to_group(group, send_on=False, command=\"all_on\")\n            return\n        self._send_to_group(group, per_group=True, white_cmd=self.WHITE_GROUP_X_ON, rgbw_cmd=self.RGBW_GROUP_X_ON, send_on=False)", "response": "Switch lights on. If group (1-4) is not specified,\n            all four groups will be switched on."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nswitches lights off. If group (1-4) is not specified, all four groups will be switched off.", "response": "def off(self, group=None):\n        \"\"\" Switch lights off. If group (1-4) is not specified,\n            all four groups will be switched off. \"\"\"\n        if group is None or group == 0:\n            self._send_to_group(group, send_on=False, command=\"all_off\")\n            return\n        self._send_to_group(group, per_group=True, send_on=False, rgbw_cmd=self.RGBW_GROUP_X_OFF, white_cmd=self.WHITE_GROUP_X_OFF)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswitch lights on and change color to white.", "response": "def white(self, group=None):\n        \"\"\" Switch lights on and change color to white.\n            If group (1-4) is not specified, all four groups\n            will be switched on and to white. \"\"\"\n        if group is None or group == 0:\n            self._send_to_group(group, command=\"all_white\")\n            return\n        self._send_to_group(group, per_group=True, rgbw_cmd=self.RGBW_GROUP_X_TO_WHITE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_color(self, color, group=None):\n        if color == \"white\":  # hack, as commands for setting color to white differ from other colors.\n            self.white(group)\n        elif isinstance(color, int):\n            if color < 0 or color > 255:\n                raise AttributeError(\"Color must be color keyword or 0-255\")\n            self._send_to_group(group, command=\"color_by_int\", color=color)\n        else:\n            color_command = \"color_to_%s\" % color\n            if color_command not in self.RGBW_COMMANDS:\n                raise AttributeError(\"'%s' is not a valid color.\" % color)\n            self._send_to_group(group, command=color_command)\n        return color", "response": "Switch lights on and change color."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts percents to bulbs internal range.", "response": "def get_brightness_level(cls, percent):\n        \"\"\" Convert percents to bulbs internal range.\n\n            percent should be integer from 0 to 100.\n            Return value is 2 (minimum brightness) - 27 (maximum brightness)\n        \"\"\"\n        # Clamp to appropriate range.\n        percent = min(100, max(0, percent))\n\n        # Map 0-100 to 2-27\n        value = int(2 + ((float(percent) / 100) * 25))\n        return percent, value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_brightness(self, percent, group=None):\n        # If input is float, assume it is percent value from 0 to 1.\n        if isinstance(percent, float):\n            if percent > 1:\n                percent = int(percent)\n            else:\n                percent = int(percent * 100)\n        percent, value = self.get_brightness_level(percent)\n        self.on(group)\n        self._send_command((b\"\\x4e\", struct.pack(\"B\", value)))\n        return percent", "response": "Set the brightness of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenable nightmode for the given night .", "response": "def nightmode(self, group=None):\n        \"\"\" Enable nightmode (very dim white light).\n\n            The command is sent only once, as multiple commands would blink lights rapidly.\n            There is no way to automatically detect whether transmitting the command succeeded or not.\n\n            This does not work with wifi gateway v3.\n\n            Contrary to limitlessled documentation, this works with RGBW bulbs.\n            \"\"\"\n        self.off(group)\n        if group is None or group == 0:\n            if self.has_rgbw:\n                self._send_command(self.RGBW_COMMANDS[\"all_nightmode\"])\n            if self.has_white:\n                self._send_command(self.WHITE_COMMANDS[\"all_nightmode\"])\n        else:\n            self._send_to_group(group, per_group=True, rgbw_cmd=self.RGBW_GROUP_X_NIGHTMODE, white_cmd=self.WHITE_GROUP_X_NIGHTMODE, send_on=False, retries=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_run(self, *commands):\n        original_retries = self.repeat_commands\n        self.repeat_commands = 1\n        for _ in range(original_retries):\n            for command in commands:\n                cmd = command[0]\n                args = command[1:]\n                cmd(*args)\n        self.repeat_commands = original_retries", "response": "Runs a batch of commands in sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, msg_dict):\n        message = ejson.dumps(msg_dict)\n        super(DDPSocket, self).send(message)\n        self._debug_log('<<<{}'.format(message))", "response": "Send a message through the websocket client and wait for the answer if the message contains an id attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _debug_log(self, msg):\n        if not self.debug:\n            return\n        sys.stderr.write('{}\\n'.format(msg))", "response": "Debug log messages if debug = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_socket(self):\n        # destroy the connection if it already exists\n        if self.ddpsocket:\n            self.ddpsocket.remove_all_listeners('received_message')\n            self.ddpsocket.remove_all_listeners('closed')\n            self.ddpsocket.remove_all_listeners('opened')\n            self.ddpsocket.close_connection()\n            self.ddpsocket = None\n\n        # create a ddp socket and subscribe to events\n        self.ddpsocket = DDPSocket(self.url, self.debug)\n        self.ddpsocket.on('received_message', self.received_message)\n        self.ddpsocket.on('closed', self.closed)\n        self.ddpsocket.on('opened', self.opened)", "response": "Initialize the ddp socket"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _recover_network_failure(self):\n        if self.auto_reconnect and not self._is_closing:\n            connected = False\n            while not connected:\n                log_msg = \"* ATTEMPTING RECONNECT\"\n                if self._retry_new_version:\n                    log_msg = \"* RETRYING DIFFERENT DDP VERSION\"\n                self.ddpsocket._debug_log(log_msg)\n                time.sleep(self.auto_reconnect_timeout)\n                self._init_socket()\n                try:\n                    self.connect()\n                    connected = True\n                    if self._retry_new_version:\n                        self._retry_new_version = False\n                    else:\n                        self._is_reconnecting = True\n                except (socket.error, WebSocketException):\n                    pass", "response": "Recover from a network failure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef opened(self):\n        # give up if there are no more ddp versions to try\n        if self._ddp_version_index == len(DDP_VERSIONS):\n            self.ddpsocket._debug_log('* DDP VERSION MISMATCH')\n            self.emit('version_mismatch', DDP_VERSIONS)\n            return\n\n        # use server recommended version if we support it\n        if self._retry_new_version in DDP_VERSIONS:\n            self._ddp_version_index = [i for i, x in enumerate(DDP_VERSIONS)\n                                       if x == self._retry_new_version][0]\n\n        connect_msg = {\n            \"msg\": \"connect\",\n            \"version\": DDP_VERSIONS[self._ddp_version_index],\n            \"support\": DDP_VERSIONS\n        }\n\n        # if we've already got a session token then reconnect\n        if self._session:\n            connect_msg[\"session\"] = self._session\n\n        self.send(connect_msg)", "response": "Send the connect message to the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef closed(self, code, reason=None):\n        self.emit('socket_closed', code, reason)\n        self._recover_network_failure()", "response": "Called when the socket is closed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef received_message(self, data):\n        data = ejson.loads(str(data))\n        if not data.get('msg'):\n            return\n\n        elif data['msg'] == 'failed':\n            self._ddp_version_index += 1\n            self._retry_new_version = data.get('version', True)\n            self.emit('failed', data)\n\n        elif data['msg'] == 'connected':\n            self._session = data.get('session')\n            if self._is_reconnecting:\n                self.ddpsocket._debug_log(\"* RECONNECTED\")\n                self.emit('reconnected')\n                self._is_reconnecting = False\n            else:\n                self.ddpsocket._debug_log(\"* CONNECTED\")\n                self.emit('connected')\n                self._retry_new_version = False\n\n        # method result\n        elif data['msg'] == 'result':\n            # call the optional callback\n            callback = self._callbacks.get(data['id'])\n            if callback:\n                callback(data.get('error'), data.get('result'))\n                self._callbacks.pop(data['id'])\n\n        # missing subscription\n        elif data['msg'] == 'nosub':\n            callback = self._callbacks.get(data['id'])\n            if callback:\n                callback(data.get('error'), data['id'])\n                self._callbacks.pop(data['id'])\n\n        # document added to collection\n        elif data['msg'] == 'added':\n            self.emit('added', data['collection'],\n                      data['id'], data.get('fields', {}))\n\n        # document changed in collection\n        elif data['msg'] == 'changed':\n            self.emit('changed', data['collection'], data['id'],\n                       data.get('fields', {}), data.get('cleared', {}))\n\n        # document removed from collection\n        elif data['msg'] == 'removed':\n            self.emit('removed', data['collection'], data['id'])\n\n        # subcription ready\n        elif data['msg'] == 'ready':\n            for sub_id in data.get('subs', []):\n                callback = self._callbacks.get(sub_id)\n                if callback:\n                    callback(data.get('error'), sub_id)\n                    self._callbacks.pop(sub_id)\n\n        elif data['msg'] == 'ping':\n            msg = {'msg': 'pong'}\n            id = data.get('id')\n            if id is not None:\n                msg['id'] = id\n            self.ddpsocket.send(msg)\n\n        else:\n            pass", "response": "Handle incoming message from the DDP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call(self, method, params, callback=None):\n        cur_id = self._next_id()\n        if callback:\n            self._callbacks[cur_id] = callback\n        self.send({'msg': 'method', 'id': cur_id, 'method': method, 'params': params})", "response": "Call a method on the server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subscribe(self, name, params, callback=None):\n        cur_id = self._next_id()\n        if callback:\n            self._callbacks[cur_id] = callback\n        self.send({'msg': 'sub', 'id': cur_id, 'name': name, 'params': params})\n        return cur_id", "response": "Subscribes to add change remove events for a collection of publication types"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_input(self, input_filepath):\n        with open(input_filepath, 'r') as input_file:\n            input_file_str = input_file.read()\n            merge_file_str, parsetree_str = input_file_str.split('ParentedTree', 1)\n            return merge_file_str, 'ParentedTree' + parsetree_str", "response": "Splits the input file into the merge file which contains\n        the EDUs and the parsetree file which contains\n        the EDUs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting EDUs from DPLPs. merge output files.", "response": "def extract_edus(merge_file_str):\n        \"\"\"Extract EDUs from DPLPs .merge output files.\n\n        Returns\n        -------\n        edus : dict from EDU IDs (int) to words (list(str))\n        \"\"\"\n        lines = merge_file_str.splitlines()\n\n        edus = defaultdict(list)\n        for line in lines:\n            if line.strip():  # ignore empty lines\n                token = line.split('\\t')[2]\n                edu_id = int(line.split('\\t')[9])\n                edus[edu_id].append(token)\n        return edus"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dplptree2dgparentedtree(self):\n        def transform(dplp_tree):\n            \"\"\"Transform a DPLP parse tree into a more conventional parse tree.\"\"\"\n            if isinstance(dplp_tree, basestring) or not hasattr(dplp_tree, 'label'):\n                return dplp_tree\n            assert len(dplp_tree) == 2, \"We can only handle binary trees.\"\n\n            match = DPLP_REL_RE.match(dplp_tree.label())\n            assert match, \"Relation '{}' does not match regex '{}'\".format(dplp_tree.label(), DPLP_REL_RE)\n            left_child_nuc, right_child_nuc, relname = match.groups()\n            dplp_tree._label = relname\n\n            for i, child_nuclearity in enumerate([left_child_nuc, right_child_nuc]):\n                child = dplp_tree[i]\n                dplp_tree[i] = Tree(child_nuclearity, [transform(child)])\n            return dplp_tree\n\n        tree = transform(self.parsetree)\n        return DGParentedTree.convert(tree)", "response": "Convert the tree from DPLP s format into a conventional binary tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a TigerSentenceGraph returns a sorted list of terminal node IDs and a sorted list of nonterminal node IDs.", "response": "def _get_terminals_and_nonterminals(sentence_graph):\n    \"\"\"\n    Given a TigerSentenceGraph, returns a sorted list of terminal node\n    IDs, as well as a sorted list of nonterminal node IDs.\n\n    Parameters\n    ----------\n    sentence_graph : TigerSentenceGraph\n        a directed graph representing one syntax annotated sentence from\n        a TigerXML file\n\n    Returns\n    -------\n    terminals, nonterminals : list of str\n        a sorted list of terminal node IDs and a sorted list of\n        nonterminal node IDs\n    \"\"\"\n    terminals = set()\n    nonterminals = set()\n    for node_id in sentence_graph.nodes_iter():\n        if sentence_graph.out_degree(node_id) > 0:\n            # all nonterminals (incl. root)\n            nonterminals.add(node_id)\n        else:  # terminals\n            terminals.add(node_id)\n    return sorted(list(terminals), key=natural_sort_key), \\\n        sorted(list(nonterminals), key=natural_sort_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a TigerSentenceGraph and returns a list of node IDs of unconnected nodes.", "response": "def get_unconnected_nodes(sentence_graph):\n    \"\"\"\n    Takes a TigerSentenceGraph and returns a list of node IDs of\n    unconnected nodes.\n\n    A node is unconnected, if it doesn't have any in- or outgoing edges.\n    A node is NOT considered unconnected, if the graph only consists of\n    that particular node.\n\n    Parameters\n    ----------\n    sentence_graph : TigerSentenceGraph\n        a directed graph representing one syntax annotated sentence from\n        a TigerXML file\n\n    Returns\n    -------\n    unconnected_node_ids : list of str\n        a list of node IDs of unconnected nodes\n    \"\"\"\n    return [node for node in sentence_graph.nodes_iter()\n            if sentence_graph.degree(node) == 0 and\n            sentence_graph.number_of_nodes() > 1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of node IDs of nodes representing subordinate clauses in a TIGER syntax tree.", "response": "def get_subordinate_clauses(tiger_docgraph):\n    \"\"\"\n    given a document graph of a TIGER syntax tree, return all\n    node IDs of nodes representing subordinate clause constituents.\n\n    Parameters\n    ----------\n    tiger_docgraph : DiscourseDocumentGraph or TigerDocumentGraph\n        document graph from which subordinate clauses will be extracted\n\n    Returns\n    -------\n    subord_clause_nodes : list(str)\n        list of node IDs of nodes directly dominating subordinate clauses\n    \"\"\"\n    subord_clause_rels = \\\n        dg.select_edges_by_attribute(\n            tiger_docgraph, attribute='tiger:label',\n            value=['MO', 'RC', 'SB'])\n\n    subord_clause_nodes = []\n    for src_id, target_id in subord_clause_rels:\n        src_cat = tiger_docgraph.node[src_id].get('tiger:cat')\n        if src_cat == 'S' and not dg.istoken(tiger_docgraph, target_id):\n            subord_clause_nodes.append(target_id)\n    return subord_clause_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a TigerXML document into a TigerSentenceGraph and adds all the nodes edges and features to the self. sentences list.", "response": "def __add_sentence_to_document(self, sentence):\n        \"\"\"\n        Converts a sentence into a TigerSentenceGraph and adds all\n        its nodes, edges (and their features) to this document graph.\n\n        This also adds a ``dominance_relation`` edge from the root node of this\n        document graph to the root node of the sentence and appends the\n        sentence root node ID to ``self.sentences``.\n\n        Parameters\n        ----------\n        sentence : lxml.etree._Element\n            a sentence from a TigerXML file in etree element format\n        \"\"\"\n        sentence_graph = TigerSentenceGraph(sentence)\n        self.tokens.extend(sentence_graph.tokens)\n        sentence_root_node_id = sentence_graph.root\n\n        self.add_nodes_from(sentence_graph.nodes(data=True))\n        self.add_edges_from(sentence_graph.edges(data=True))\n        self.add_edge(self.root, sentence_root_node_id,\n                      layers={self.ns, self.ns+':sentence'},\n                      edge_type=EdgeTypes.dominance_relation)\n        self.sentences.append(sentence_root_node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __tigersentence2graph(self, sentence):\n        # add sentence root to graph\n        self.add_node(self.root,\n                      layers={self.ns, self.ns+':sentence',\n                              self.ns+':sentence:root',\n                              self.ns+':syntax'})\n\n        token_ids = []\n        # add terminals to graph (tokens)\n        for t in sentence.iterfind('./graph/terminals/t'):\n            terminal_id = t.attrib['id']\n            token_ids.append(terminal_id)\n            # all token attributes shall belong to the tiger namespace\n            terminal_features = add_prefix(t.attrib, self.ns+':')\n            # convert tokens to unicode\n            terminal_features[self.ns+':token'] = ensure_unicode(\n                terminal_features[self.ns+':word'])\n            self.add_node(terminal_id, layers={self.ns, self.ns+':token'},\n                          attr_dict=terminal_features,\n                          label=terminal_features[self.ns+':token'])\n\n            # add secedge pointing relations from tokens to other tokens or\n            # syntactic categories\n            for secedge in t.iterfind('./secedge'):\n                to_id = secedge.attrib['idref']\n                secedge_attribs = add_prefix(secedge.attrib, self.ns+':')\n                if to_id not in self:  # if graph doesn't contain to-node, yet\n                    self.add_node(to_id, layers={self.ns, self.ns+':secedge'})\n                self.add_edge(terminal_id, to_id,\n                              layers={self.ns, self.ns+':secedge'},\n                              attr_dict=secedge_attribs,\n                              edge_type=EdgeTypes.pointing_relation)\n\n        # add sorted list of all token node IDs to sentence root node\n        # to make queries simpler/faster\n        sorted_token_ids = sorted(token_ids, key=natural_sort_key)\n        self.node[self.root].update({'tokens': sorted_token_ids})\n        self.tokens = sorted_token_ids\n\n        # add nonterminals (syntax categories) to graph\n        for nt in sentence.iterfind('./graph/nonterminals/nt'):\n            from_id = nt.attrib['id']\n            nt_feats = add_prefix(nt.attrib, self.ns+':')\n            nt_feats['label'] = nt_feats[self.ns+':cat']\n            # root node already exists, but doesn't have a cat value\n            if from_id in self:\n                self.node[from_id].update(nt_feats)\n            else:\n                self.add_node(from_id, layers={self.ns, self.ns+':syntax'},\n                              attr_dict=nt_feats)\n\n            # add edges to graph (syntax cat dominances token/other cat)\n            for edge in nt.iterfind('./edge'):\n                to_id = edge.attrib['idref']\n                if to_id not in self:  # if graph doesn't contain to-node, yet\n                    self.add_node(to_id, layers={self.ns, self.ns+':secedge'})\n                edge_attribs = add_prefix(edge.attrib, self.ns+':')\n\n                # add a spanning relation from a syntax cat to a token\n                if self.ns+':token' in self.node[to_id]['layers']:\n                    edge_type = EdgeTypes.spanning_relation\n                else:  # add a dominance relation between two syntax categories\n                    edge_type = EdgeTypes.dominance_relation\n\n                self.add_edge(from_id, to_id,\n                              layers={self.ns, self.ns+':edge'},\n                              attr_dict=edge_attribs,\n                              label=edge_attribs[self.ns+':label'],\n                              edge_type=edge_type)\n\n            # add secondary edges to graph (cat points to other cat/token)\n            for secedge in nt.iterfind('./secedge'):\n                to_id = secedge.attrib['idref']\n                if to_id not in self:  # if graph doesn't contain to-node, yet\n                    self.add_node(to_id, layers={self.ns, self.ns+':secedge'})\n                secedge_attribs = add_prefix(secedge.attrib, self.ns+':')\n                self.add_edge(from_id, to_id,\n                              layers={self.ns, self.ns+':secedge'},\n                              attr_dict=secedge_attribs,\n                              label=edge_attribs[self.ns+':label'],\n                              edge_type=EdgeTypes.pointing_relation)", "response": "Reads a TigerXML sentence into a directed graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __repair_unconnected_nodes(self):\n        unconnected_node_ids = get_unconnected_nodes(self)\n        if dg.istoken(self, self.root):\n            # This sentence has no hierarchical structure, i.e. the root\n            # node is also a terminal / token node.\n            # We will add a virtual root node to compensate for this.\n            self.root = self.ns+':VROOT'\n            self.add_node(self.root,\n                layers={'tiger', 'tiger:syntax', 'tiger:sentence',\n                        'tiger:sentence:root'})\n\n        for unconnected_node_id in unconnected_node_ids:\n            self.add_edge(self.root, unconnected_node_id,\n                          layers={self.ns, self.ns+':sentence',\n                                  self.ns+':unconnected'},\n                          edge_type=EdgeTypes.dominance_relation)", "response": "Repair the unconnected nodes of the current sentence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_etree(cls, etree_element):\n        ins = SaltElement.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        # convert SaltElement into SaltLayer\n        ins.__class__ = SaltLayer.mro()[0]\n\n        # add nodes and edges that belong to this layer (if any)\n        for element in ('nodes', 'edges'):\n            elem_list = []\n            xpath_result = etree_element.xpath('@'+element)\n            if xpath_result:\n                val_str = xpath_result[0]\n                elem_list.extend(int(elem_id)\n                                 for elem_id in DIGITS.findall(val_str))\n            setattr(ins, element, elem_list)\n        return ins", "response": "Creates a SaltElement instance from an etree representation of an an\n        element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_etree(self):\n        nodes_attrib_val = ' '.join('//@nodes.{}'.format(node_id)\n                                    for node_id in self.nodes)\n        edges_attrib_val = ' '.join('//@edges.{}'.format(edge_id)\n                                    for edge_id in self.edges)\n\n        attribs = {\n            '{{{pre}}}type'.format(pre=NAMESPACES['xsi']): self.xsi_type,\n            'nodes': nodes_attrib_val, 'edges': edges_attrib_val}\n        # a layer might have no nodes or edges attributed to it\n        non_empty_attribs = {key: val for (key, val) in attribs.items()\n                             if val is not None}\n\n        E = ElementMaker()\n        layer = E('layers', non_empty_attribs)\n        label_elements = (label.to_etree() for label in self.labels)\n        layer.extend(label_elements)\n        return layer", "response": "Creates an etree element of a SaltXMI\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the decour XML file and adds the relevant attributes to the internal list.", "response": "def _parse_decour(self, tree):\n        \"\"\"\n        <!ELEMENT hearing (header, intro, turn+, conclu?)>\n        # <!ELEMENT turn (act?|utterance+)*>\n        # <!ELEMENT utterance (#PCDATA|token|lemma|pos)*>\n        \"\"\"\n        self._add_dominance_relation(self.root, 'intro')\n        self._add_token_span_to_document(tree.find('/intro'))\n\n        for turn in tree.iterfind('/turn'):\n            turn_id = 'turn_{}'.format(turn.attrib['nrgen'])\n            self._add_dominance_relation(self.root, turn_id)\n            self.turns.append(turn_id)\n            act = turn.find('./act')\n            if act is not None:\n                self._add_dominance_relation(turn_id,\n                                             'act_{}'.format(self.act_count))\n                self._add_token_span_to_document(act)\n\n            for utter in turn.iterfind('./utterance'):\n                    utter_id = 'utterance_{}'.format(utter.attrib['nrgen'])\n                    self._add_dominance_relation(turn_id, utter_id)\n                    self._add_utterance_to_document(utter)\n\n        conclu = tree.find('/conclu')\n        if conclu is not None:\n            self._add_dominance_relation(self.root, 'conclu')\n            self._add_token_span_to_document(conclu)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a token node to this document graph", "response": "def _add_token_to_document(self, token_string, token_attrs=None):\n        \"\"\"add a token node to this document graph\"\"\"\n        token_feat = {self.ns+':token': token_string}\n        if token_attrs:\n            token_attrs.update(token_feat)\n        else:\n            token_attrs = token_feat\n        token_id = 'token_{}'.format(self.token_count)\n        self.add_node(token_id, layers={self.ns, self.ns+':token'},\n                      attr_dict=token_attrs)\n        self.token_count += 1\n        self.tokens.append(token_id)\n        return token_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_utterance_to_document(self, utterance):\n        utter_id = 'utterance_{}'.format(utterance.attrib['nrgen'])\n        norm, lemma, pos = [elem.text.split()\n                            for elem in utterance.iterchildren()]\n        for i, word in enumerate(utterance.text.split()):\n            token_id = self._add_token_to_document(\n                word, token_attrs={self.ns+':norm': norm[i],\n                                   self.ns+':lemma': lemma[i],\n                                   self.ns+':pos': pos[i]})\n            self._add_spanning_relation(utter_id, token_id)\n        self.utterances.append(utter_id)", "response": "add an utterance to this docgraph as a spanning relation"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an element with a token span to the document.", "response": "def _add_token_span_to_document(self, span_element):\n        \"\"\"\n        adds an <intro>, <act> or <conclu> token span to the document.\n        \"\"\"\n        for token in span_element.text.split():\n            token_id = self._add_token_to_document(token)\n            if span_element.tag == 'act':  # doc can have 0+ acts\n                self._add_spanning_relation('act_{}'.format(self.act_count),\n                                            token_id)\n            else:  # <intro> or <conclu>\n                self._add_spanning_relation(span_element.tag, token_id)\n        if span_element.tag == 'act':\n            self.act_count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_dominance_relation(self, source, target):\n        # TODO: fix #39, so we don't need to add nodes by hand\n        self.add_node(target, layers={self.ns, self.ns+':unit'})\n        self.add_edge(source, target,\n                      layers={self.ns, self.ns+':discourse'},\n                      edge_type=EdgeTypes.dominance_relation)", "response": "add a dominance relation to this docgraph"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a spanning relation to this docgraph", "response": "def _add_spanning_relation(self, source, target):\n        \"\"\"add a spanning relation to this docgraph\"\"\"\n        self.add_edge(source, target, layers={self.ns, self.ns+':unit'},\n                      edge_type=EdgeTypes.spanning_relation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup_codra_edus(self):\n        for leafpos in self.tree.treepositions('leaves'):\n            edu_str = self.tree[leafpos]\n\n            edu_str = EDU_START_RE.sub(\"\", edu_str)\n            edu_str = TRIPLE_ESCAPE_RE.sub('\"', edu_str)\n            edu_str = EDU_END_RE.sub(\"\", edu_str)\n\n            self.tree[leafpos] = edu_str", "response": "Remove leading and trailing _! from CODRA EDUs and unescape its double quotes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(data):\n    if not isinstance(data, dict):\n        error('Data must be a dictionary.')\n    for value in data.values():\n        if not isinstance(value, basestring):\n            error('Values must be strings.')", "response": "Validate that the data is a dictionary and result data has keys who s values are strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef terraform_external_data(function):\n    @wraps(function)\n    def wrapper(*args, **kwargs):\n        query = json.loads(sys.stdin.read())\n        validate(query)\n        try:\n            result = function(query, *args, **kwargs)\n        except Exception as e:\n            # Terraform wants one-line errors so we catch all exceptions and trim down to just the message (no trace).\n            error('{}: {}'.format(type(e).__name__, e))\n        validate(result)\n        sys.stdout.write(json.dumps(result))\n    return wrapper", "response": "Decorator for Terraform external data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_rs3_data(rs3_file, word_wrap=0):\n    rs3_etree = etree.parse(rs3_file)\n    reltypes = extract_relationtypes(rs3_etree)\n\n    elements = defaultdict(lambda: defaultdict(str))\n    children = defaultdict(list)\n    ordered_edus = []\n\n    for elem in rs3_etree.iter('segment', 'group'):\n        elem_id = elem.attrib['id']\n        parent_id = elem.attrib.get('parent')\n        elements[elem_id]['parent'] = parent_id\n        children[parent_id].append(elem_id)\n\n        relname = elem.attrib.get('relname')\n        elements[elem_id]['relname'] = relname\n        if relname is None:\n            # Nodes without a parent have no relname attribute.\n            # They might well the N of a relation.\n            elements[elem_id]['nuclearity'] = 'root'\n        else:\n            reltype = reltypes.get(relname, 'span')\n            elements[elem_id]['reltype'] = reltype\n            if reltype == 'rst':\n                # this elem is the S of an N-S relation, its parent is the N\n                elements[elem_id]['nuclearity'] = 'satellite'\n            elif reltype == 'multinuc':\n                # this elem is one of several Ns of a multinuc relation.\n                # its parent is the multinuc relation node.\n                elements[elem_id]['nuclearity'] = 'nucleus'\n            elif reltype == 'span':\n                # this elem is the N of an N-S relation, its parent is a span\n                elements[elem_id]['nuclearity'] = 'nucleus'\n            else:\n                raise NotImplementedError(\"Unknown reltype: {}\".format(reltypes[relname]))\n\n        elem_type = elem.tag\n        elements[elem_id]['element_type'] = elem_type\n\n        if elem_type == 'segment':\n            edu_text = normalize_edu_string(elem.text)\n            if word_wrap != 0:\n                dedented_text = textwrap.dedent(edu_text).strip()\n                edu_text = textwrap.fill(dedented_text, width=word_wrap)\n\n            elements[elem_id]['text'] = edu_text\n            ordered_edus.append(elem_id)\n\n        else:  # elem_type == 'group':\n            elements[elem_id]['group_type'] = elem.attrib.get('type')\n\n    if len(elements) > 0:\n        # add VIRTUAL_ROOT to reltypes dict for export, but only if the\n        # rs3 file is not empty\n        reltypes[VIRTUAL_ROOT] = 'multinuc'\n\n    return children, elements, ordered_edus, reltypes", "response": "helper function to build RSTTrees data on parent - child relations and node attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef n_wrap(tree, debug=False, root_id=None):\n    root_label = tree.label()\n\n    expected_n_root = debug_root_label('N', debug=debug, root_id=tree.root_id)\n    expected_s_root = debug_root_label('S', debug=debug, root_id=tree.root_id)\n\n    if root_label == expected_n_root:\n        return tree\n    elif root_label == expected_s_root:\n        tree.set_label(expected_n_root)\n        return tree\n    else:\n        return t('N', [tree], debug=debug, root_id=root_id)", "response": "Ensure the given tree has a nucleus as its root."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting relations from a DGParentedTree.", "response": "def extract_relations(dgtree, relations=None):\n    \"\"\"Extracts relations from a DGParentedTree.\n\n    Given a DGParentedTree, returns a (relation name, relation type) dict\n    of all the RST relations occurring in that tree.\n    \"\"\"\n    if hasattr(dgtree, 'reltypes'):\n        # dgtree is an RSTTree or a DisTree that contains a DGParentedTree\n        return dgtree.reltypes\n\n    if relations is None:\n        relations = {}\n\n    if is_leaf(dgtree):\n        return relations\n\n    root_label = dgtree.label()\n    if root_label == '':\n        assert dgtree == DGParentedTree('', []), \\\n            \"The tree has no root label, but isn't empty: {}\".format(dgtree)\n        return relations\n    elif root_label in NUCLEARITY_LABELS:\n        for child in dgtree:\n            relations.update(extract_relations(child, relations))\n    else:  # dgtree is a 'relation' node\n        child_labels = [child.label() for child in dgtree]\n        assert all(label in NUCLEARITY_LABELS for label in child_labels)\n        if 'S' in child_labels:\n            relations[root_label] = 'rst'\n        else:\n            relations[root_label] = 'multinuc'\n        for child in dgtree:\n            relations.update(extract_relations(child, relations))\n\n    return relations"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromstring(cls, rs3_string):\n        temp = tempfile.NamedTemporaryFile(delete=False)\n        temp.write(rs3_string)\n        temp.close()\n        rst_tree = cls(rs3_file=temp.name)\n        os.unlink(temp.name)\n        return rst_tree", "response": "Create an RSTTree instance from a string content an *. rs3 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_schema(self, nuc_tuple, inner_sat_tuples, outer_sat_tuples):\n        nuc_tree, nuc_pos = nuc_tuple\n        sat_tuples = inner_sat_tuples + outer_sat_tuples\n        last_sat_tuple_pos = len(sat_tuples)-1\n\n        for i, (sat_tree, sat_pos) in enumerate(sat_tuples):\n            relname = self.get_relname(sat_tree.root_id)\n            if sat_pos < nuc_pos:\n                ordered_trees = [sat_tree, nuc_tree]\n            else:\n                ordered_trees = [nuc_tree, sat_tree]\n\n            if i == last_sat_tuple_pos:\n                nuc_tree = t(relname, ordered_trees, debug=self.debug, root_id=nuc_tree.root_id)\n            else:\n                nuc_tree = t('N', [(relname, ordered_trees)], debug=self.debug, root_id=nuc_tree.root_id)\n        return nuc_tree", "response": "converts a schema into a tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsorts the given subtrees based on their linear position in this RSTTree", "response": "def sort_subtrees(self, *subtrees):\n        \"\"\"sort the given subtrees (of type DGParentedTree) based on their\n        linear position in this RSTTree. If two subtrees have the same\n        linear position in the RSTTree (i.e. one is a child of the other),\n        they are sorted by their height in reverse order (i.e. the child\n        appears before its parent).\n        \"\"\"\n        subtrees_desc_height = sorted(subtrees,\n                                      key=methodcaller('node_height', self),\n                                      reverse=True)\n        return sorted(subtrees_desc_height,\n                      key=methodcaller('get_position', self))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a DGParentedTree and puts a nucleus or satellite on top", "response": "def elem_wrap(self, tree, debug=False, root_id=None):\n        \"\"\"takes a DGParentedTree and puts a nucleus or satellite on top,\n        depending on the nuclearity of the root element of the tree.\n        \"\"\"\n        if root_id is None:\n            root_id = tree.root_id\n\n        elem = self.elem_dict[root_id]\n        if elem['nuclearity'] == 'nucleus':\n            return n_wrap(tree, debug=debug, root_id=root_id)\n        else:\n            return s_wrap(tree, debug=debug, root_id=root_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncut a new release", "response": "def release():\n    \"Cut a new release\"\n    version = run('python setup.py --version').stdout.strip()\n    assert version, 'No version found in setup.py?'\n\n    print('### Releasing new version: {0}'.format(version))\n    run('git tag {0}'.format(version))\n    run('git push --tags')\n\n    run('python setup.py sdist bdist_wheel')\n    run('twine upload -s dist/*')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bgwrite(fileObj, data, closeWhenFinished=False, chainAfter=None, ioPrio=4):\n    '''\n        bgwrite - Start a background writing process\n\n            @param fileObj <stream> - A stream backed by an fd\n\n            @param data    <str/bytes/list> - The data to write. If a list is given, each successive element will be written to the fileObj and flushed. If a string/bytes is provided, it will be chunked according to the #BackgroundIOPriority chosen. If you would like a different chunking than the chosen ioPrio provides, use #bgwrite_chunk function instead.\n\n               Chunking makes the data available quicker on the other side, reduces iowait on this side, and thus increases interactivity (at penalty of throughput).\n\n            @param closeWhenFinished <bool> - If True, the given fileObj will be closed after all the data has been written. Default False.\n\n            @param chainAfter  <None/BackgroundWriteProcess> - If a BackgroundWriteProcess object is provided (the return of bgwrite* functions), this data will be held for writing until the data associated with the provided object has completed writing.\n            Use this to queue several background writes, but retain order within the resulting stream.\n\n\n            @return - BackgroundWriteProcess - An object representing the state of this operation. @see BackgroundWriteProcess\n    '''\n        \n    thread = BackgroundWriteProcess(fileObj, data, closeWhenFinished, chainAfter, ioPrio)\n    thread.start()\n\n    return thread", "response": "This function starts a background writing process for the given fileObj and writes the given data to the fileObj."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchunking a string into a list of string / bytes each member up to chunkSize in length.", "response": "def chunk_data(data, chunkSize):\n    '''\n        chunk_data - Chunks a string/bytes into a list of string/bytes, each member up to #chunkSize in length.\n\n        e.x.    chunk_data(\"123456789\", 2) = [\"12\", \"34\", \"56\", \"78\", \"9\"]\n    '''\n    chunkSize = int(chunkSize)\n    return [data[i : i + chunkSize] for i in range(0, len(data), chunkSize)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns - Starts the thread. bgwrite and bgwrite_chunk automatically start the thread.", "response": "def run(self):\n        '''\n            run - Starts the thread. bgwrite and bgwrite_chunk automatically start the thread.\n        '''\n\n        # If we are chaining after another process, wait for it to complete.\n        #   We use a flag here instead of joining the thread for various reasons\n        chainAfter = self.chainAfter\n        if chainAfter is not None:\n            chainPollTime = self.backgroundIOPriority.chainPollTime\n            while chainAfter.finished is False:\n                time.sleep(chainPollTime)\n\n\n        # Pull class data into locals\n        fileObj = self.fileObj\n        bandwidthPct = self.backgroundIOPriority.bandwidthPct\n        bandwidthPctDec = bandwidthPct / 100.0\n\n\n        # Number of blocks, total\n        numBlocks = len(self.remainingData)\n        # Bytes written\n        dataWritten = 0\n\n        # Mark that we have started writing data\n        self.startedWriting = True\n\n        # Create a conditional lambda for flushing. I'd rather just only support flushable streams, but\n        #   some unfortunatly just aren't. This should be cheaper than testing with hasattr at each iteration\n        if hasattr(fileObj, 'flush'):\n            doFlush = lambda obj : obj.flush()\n        else:\n            doFlush = lambda obj : 1\n\n\n        # numChunksRateSmoothing - How often we stop for a short bit to be gracious to other running tasks.\n        #  float for division below\n        numChunksRateSmoothing = float(self.backgroundIOPriority.numChunksRateSmoothing)\n\n        # i will be the counter from 1 to numChunksRateSmoothing, and then reset\n        i = 1\n\n        # We start with using max bandwidth until we hit #numChunksRateSmoothing , at which case we recalculate\n        #  sleepTime. We sleep after every block written to maintain a desired average throughput based on\n        #  bandwidthPct\n        sleepTime = 0\n\n        # Before represents the \"start\" time. When we sleep, we will increment this value\n        #  such that [ delta = (after - before) ] only accounts for time we've spent writing,\n        #  not in charity.\n        before = time.time()\n\n        # timeSlept - Amount of time slept, which must be subtracted from total time spend\n        #  to get an accurate picture of throughput.\n        timeSlept = 0\n\n        # firstPass - Mark the first pass through, so we can get a rough calculation\n        #  of speed from the first write, and recalculate after #numChunksRateSmoothing\n        firstPass = True\n\n        if bandwidthPct == 100:\n            shouldRecalculate = lambda i, numChunksRateSmoothing, firstPass : False\n        else:\n            shouldRecalculate = lambda i, numChunksRateSmoothing, firstPass : firstPass or i == numChunksRateSmoothing\n            \n\n        while len(self.remainingData) > 0:\n\n            # pop, write, flush\n            nextData = self.remainingData.popleft()\n            fileObj.write(nextData)\n            doFlush(fileObj)\n            \n            dataWritten += len(nextData)\n            if sleepTime:\n                sleepBefore = time.time()\n\n                time.sleep(sleepTime)\n\n                sleepAfter = time.time()\n                timeSlept += (sleepAfter - sleepBefore)\n \n            if shouldRecalculate(i, numChunksRateSmoothing, firstPass) is True:\n                # if not sleeptime, we are on first \n                # We've completed a full period, time for charity\n                after = time.time()\n\n                delta = after - before - timeSlept\n\n                rate = dataWritten / delta\n\n#                if DEBUG is True:\n#                    sys.stdout.write('\\t  I have written %d bytes in %3.3f seconds and slept %3.3f sec (%4.5f M/s over %3.3fs)\\n' %(dataWritten, delta, timeSlept, (rate) / (1024*1024), delta + timeSlept  ))\n#                    sys.stdout.flush()\n\n                # Calculate how much time we should give up on each block to other tasks\n                sleepTime = delta * (1.00 - bandwidthPctDec)\n                sleepTime /= numChunksRateSmoothing\n\n#                if DEBUG is True:\n#                    sys.stdout.write('Calculated new sleepTime to be: %f\\n' %(sleepTime,))\n\n                timeSlept = 0\n                before = time.time()\n                i = 0\n#            elif DEBUG is True and i == numChunksRateSmoothing:\n#                # When bandwidth pct is 100 (prio=1), the above DEBUG will never be hit.\n#                after = time.time()\n#\n#                delta = after - before - timeSlept\n#\n#                rate = dataWritten / delta\n#\n#                sys.stdout.write('\\t  I have written %d bytes in %3.3f seconds and slept %3.3f sec (%4.5f M/s over %3.3fs)\\n' %(dataWritten, delta, timeSlept, (rate) / (1024*1024), delta + timeSlept  ))\n#                sys.stdout.flush()\n#\n#                timeSlept = 0\n#                before = time.time()\n#                i = 0\n\n            firstPass = False\n\n            i += 1\n\n        if self.closeWhenFinished is True:\n            fileObj.close()\n\n        self.finished = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the type of an XML tree element.", "response": "def get_xsi_type(element):\n    \"\"\"\n    returns the type of an element of the XML tree (incl. its namespace),\n    i.e. nodes, edges, layers etc.), raises an exception if the element has no\n    'xsi:type' attribute.\n    \"\"\"\n    nsdict = NAMESPACES\n    #.xpath() always returns a list, so we need to select the first element\n    try:\n        return element.xpath('@xsi:type', namespaces=nsdict)[0]\n    except IndexError:  # xpath result is empty\n        raise ValueError(\"The '{0}' element has no 'xsi:type' but has these \"\n                         \"attribs:\\n{1}\").format(element.tag, element.attrib)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a *. dis ParentedTree into this document graph", "response": "def parse_dis_tree(self, dis_tree, indent=0):\n        \"\"\"parse a *.dis ParentedTree into this document graph\"\"\"\n        tree_type = get_tree_type(dis_tree)\n        assert tree_type in SUBTREE_TYPES\n        if tree_type == 'Root':\n            # replace generic root node with tree root\n            old_root_id = self.root\n            root_id = get_node_id(dis_tree, self.ns)\n            self.root = root_id\n            self.add_node(root_id)\n            self.remove_node(old_root_id)\n\n            children = dis_tree[1:]\n            for child in children:\n                child_id = get_node_id(child, self.ns)\n                self.add_edge(\n                    root_id, child_id,\n                    #~ attr_dict={self.ns+':rel_type': relation_type},\n                    edge_type=EdgeTypes.dominance_relation)\n\n                self.parse_dis_tree(child, indent=indent+1)\n\n        else: # tree_type in ('Nucleus', 'Satellite')\n            node_id = get_node_id(dis_tree, self.ns)\n            node_type = get_node_type(dis_tree)\n            relation_type = get_relation_type(dis_tree)\n            if node_type == 'leaf':\n                edu_text = get_edu_text(dis_tree[-1])\n                self.add_node(node_id, attr_dict={\n                    self.ns+':text': edu_text,\n                    'label': u'{0}: {1}'.format(node_id, edu_text[:20])})\n                if self.tokenized:\n                    edu_tokens = edu_text.split()\n                    for i, token in enumerate(edu_tokens):\n                        token_node_id = '{0}_{1}'.format(node_id, i)\n                        self.tokens.append(token_node_id)\n                        self.add_node(token_node_id, attr_dict={self.ns+':token': token,\n                                                                'label': token})\n                        self.add_edge(node_id, '{0}_{1}'.format(node_id, i))\n\n            else: # node_type == 'span'\n                self.add_node(node_id, attr_dict={self.ns+':rel_type': relation_type,\n                                                  self.ns+':node_type': node_type})\n                children = dis_tree[3:]\n                child_types = get_child_types(children)\n\n                expected_child_types = set(['Nucleus', 'Satellite'])\n                unexpected_child_types = set(child_types).difference(expected_child_types)\n                assert not unexpected_child_types, \\\n                    \"Node '{0}' contains unexpected child types: {1}\\n\".format(\n                        node_id, unexpected_child_types)\n\n                if 'Satellite' not in child_types:\n                    # span only contains nucleii -> multinuc\n                    for child in children:\n                        child_node_id = get_node_id(child, self.ns)\n                        self.add_edge(node_id, child_node_id, attr_dict={\n                            self.ns+':rel_type': relation_type})\n\n                elif len(child_types['Satellite']) == 1 and len(children) == 1:\n                    if tree_type == 'Nucleus':\n                        child = children[0]\n                        child_node_id = get_node_id(child, self.ns)\n                        self.add_edge(\n                            node_id, child_node_id,\n                            attr_dict={self.ns+':rel_type': relation_type},\n                            edge_type=EdgeTypes.dominance_relation)\n                    else:\n                        assert tree_type == 'Satellite'\n                        raise NotImplementedError(\"I don't know how to combine two satellites\")\n\n                elif len(child_types['Satellite']) == 1 and len(child_types['Nucleus']) == 1:\n                    # standard RST relation, where one satellite is dominated by one nucleus\n                    nucleus_index = child_types['Nucleus'][0]\n                    satellite_index = child_types['Satellite'][0]\n\n                    nucleus_node_id = get_node_id(children[nucleus_index], self.ns)\n                    satellite_node_id = get_node_id(children[satellite_index], self.ns)\n                    self.add_edge(node_id, nucleus_node_id, attr_dict={self.ns+':rel_type': 'span'},\n                                  edge_type=EdgeTypes.spanning_relation)\n                    self.add_edge(nucleus_node_id, satellite_node_id,\n                                  attr_dict={self.ns+':rel_type': relation_type},\n                                  edge_type=EdgeTypes.dominance_relation)\n                else:\n                    raise ValueError(\"Unexpected child combinations: {}\\n\".format(child_types))\n\n                for child in children:\n                    self.parse_dis_tree(child, indent=indent+1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_sorted_counter(counter, tab=1):\n    for key, count in sorted(counter.items(), key=itemgetter(1), reverse=True):\n        print \"{0}{1} - {2}\".format('\\t'*tab, key, count)", "response": "print all elements of a counter in descending order"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the most common elements of a sequence", "response": "def print_most_common(counter, number=5, tab=1):\n    \"\"\"print the most common elements of a counter\"\"\"\n    for key, count in counter.most_common(number):\n        print \"{0}{1} - {2}\".format('\\t'*tab, key, count)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints basic statistics about a node", "response": "def node_statistics(docgraph):\n    \"\"\"print basic statistics about a node, e.g. layer/attribute counts\"\"\"\n    print \"Node statistics\\n===============\"\n    layer_counts = Counter()\n    attrib_counts = Counter()\n    for node_id, node_attrs in docgraph.nodes_iter(data=True):\n        for layer in node_attrs['layers']:\n            layer_counts[layer] += 1\n        for attrib in node_attrs:\n            attrib_counts[attrib] += 1\n\n    print \"\\nnumber of nodes with layers\"\n    print_sorted_counter(layer_counts)\n    print \"\\nnumber of nodes with attributes\"\n    print_sorted_counter(attrib_counts)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting basic statistics about an edge", "response": "def edge_statistics(docgraph):\n    \"\"\"print basic statistics about an edge, e.g. layer/attribute counts\"\"\"\n    print \"Edge statistics\\n===============\"\n    layer_counts = Counter()\n    attrib_counts = Counter()\n    source_counts = Counter()\n    target_counts = Counter()\n    for source, target, edge_attrs in docgraph.edges_iter(data=True):\n        for layer in edge_attrs['layers']:\n            layer_counts[layer] += 1\n        for attrib in edge_attrs:\n            attrib_counts[attrib] += 1\n        source_counts[source] += 1\n        target_counts[target] += 1\n\n    print \"\\nnumber of edges with layers\"\n    print_sorted_counter(layer_counts)\n    print \"\\nnumber of edges with attributes\"\n    print_sorted_counter(attrib_counts)\n\n    print \"\\nmost common source edges\"\n    print_most_common(source_counts)\n    print \"\\nmost common target edges\"\n    print_most_common(target_counts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef info(docgraph):\n    print networkx.info(docgraph), '\\n'\n    node_statistics(docgraph)\n    print\n    edge_statistics(docgraph)", "response": "print node and edge statistics of a document graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsum the total number of cycles over a list of tokens.", "response": "def _sum_cycles_from_tokens(self, tokens: List[str]) -> int:\n        \"\"\"Sum the total number of cycles over a list of tokens.\"\"\"\n        return sum((int(self._nonnumber_pattern.sub('', t)) for t in tokens))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef skip_cycles(self) -> int:\n        return sum((int(re.sub(r'\\D', '', op)) for op in self.skip_tokens))", "response": "The number of cycles dedicated to skips."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef total_cycles(self) -> int:\n        return sum((int(re.sub(r'\\D', '', op)) for op in self.tokens))", "response": "The number of total number of cycles in the structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the properties of this : class : Sample as JSON serializable.", "response": "def to_json(self) -> Mapping:\n        \"\"\"Return the properties of this :class:`Sample` as JSON serializable.\n\n        \"\"\"\n        return {str(x): str(y) for x, y in self.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a section to the SampleSheet.", "response": "def add_section(self, section_name: str) -> None:\n        \"\"\"Add a section to the :class:`SampleSheet`.\"\"\"\n        section_name = self._whitespace_re.sub('_', section_name)\n        self._sections.append(section_name)\n        setattr(self, section_name, Section())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_sample_keys(self) -> List[str]:\n        all_keys: List[str] = []\n        for key in chain.from_iterable([sample.keys() for sample in self]):\n            if key not in all_keys:\n                all_keys.append(key)\n        return all_keys", "response": "Return the unique keys of all samples in this : class : SampleSheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef experimental_design(self) -> Any:\n        if not self.samples:\n            raise ValueError('No samples in sample sheet')\n\n        markdown = tabulate(\n            [[getattr(s, h, '') for h in DESIGN_HEADER] for s in self.samples],\n            headers=DESIGN_HEADER,\n            tablefmt='pipe',\n        )\n\n        return maybe_render_markdown(markdown)", "response": "Return a markdown summary of the samples on this sample sheet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_sample(self, sample: Sample) -> None:\n        # Do not allow samples without Sample_ID defined.\n        if sample.Sample_ID is None:\n            raise ValueError('Sample must have \"Sample_ID\" defined.')\n\n        # Set whether the samples will have ``index`` or ``index2``.\n        if len(self.samples) == 0:\n            self.samples_have_index = sample.index is not None\n            self.samples_have_index2 = sample.index2 is not None\n\n        if (\n            len(self.samples) == 0\n            and sample.Read_Structure is not None\n            and self.Read_Structure is None\n        ):\n            # If this is the first sample added to the sample sheet then\n            # assume the ``SampleSheet.Read_Structure`` inherits the\n            # ``sample.Read_Structure`` only if ``SampleSheet.Read_Structure``\n            # has not already been defined. If ``SampleSheet.reads`` has been\n            # defined then validate the new read_structure against it.\n            if (\n                self.is_paired_end\n                and not sample.Read_Structure.is_paired_end\n                or self.is_single_end  # noqa\n                and not sample.Read_Structure.is_single_end\n            ):\n                raise ValueError(\n                    f'Sample sheet pairing has been set with '\n                    f'Reads:\"{self.Reads}\" and is not compatible with sample '\n                    f'read structure: {sample.Read_Structure}'\n                )\n\n            # Make a copy of this samples read_structure for the sample sheet.\n            self.Read_Structure = sample.Read_Structure.copy()\n\n        # Validate this sample against the ``SampleSheet.Read_Structure``\n        # attribute, which can be None, to ensure they are the same.\n        if self.Read_Structure != sample.Read_Structure:\n            raise ValueError(\n                f'Sample read structure ({sample.Read_Structure}) different '\n                f'than read structure in samplesheet ({self.Read_Structure}).'\n            )\n\n        # Compare this sample against all those already defined to ensure none\n        # have equal ``Sample_ID``, ``Library_ID``, and ``Lane`` attributes.\n        # Ensure that all samples have attributes ``index``, ``index2``, or\n        # both if they have been defined.\n        for other in self.samples:\n            if sample == other:\n                message = (\n                    f'Two equivalent samples added:'\n                    f'\\n\\n1): {sample.__repr__()}\\n2): {other.__repr__()}\\n'\n                )\n                # TODO: Look into if this is truly illegal or not.\n                warnings.warn(UserWarning(message))\n            if sample.index is None and self.samples_have_index:\n                raise ValueError(\n                    f'Cannot add a sample without attribute `index` if a '\n                    f'previous sample has `index` set: {sample})'\n                )\n            if sample.index2 is None and self.samples_have_index2:\n                raise ValueError(\n                    f'Cannot add a sample without attribute `index2` if a '\n                    f'previous sample has `index2` set: {sample})'\n                )\n\n            # Prevent index collisions when samples are dual-indexed\n            if (\n                self.samples_have_index\n                and self.samples_have_index2\n                and sample.index == other.index\n                and sample.index2 == other.index2\n                and sample.Lane == other.Lane\n            ):\n                raise ValueError(\n                    f'Sample index combination for {sample} has already been '\n                    f'added on this lane or flowcell: {other}'\n                )\n\n            # Prevent index collisions when samples are single-indexed (index)\n            if (\n                self.samples_have_index\n                and not self.samples_have_index2\n                and sample.index == other.index\n                and sample.Lane == other.Lane\n            ):\n                raise ValueError(\n                    f'First sample index for {sample} has already been '\n                    f'added on this lane or flowcell: {other}'\n                )\n\n            # Prevent index collisions when samples are single-indexed (index2)\n            if (\n                not self.samples_have_index\n                and self.samples_have_index2\n                and sample.index2 == other.index2\n                and sample.Lane == other.Lane\n            ):\n                raise ValueError(\n                    f'Second sample index for {sample} has already been '\n                    f'added on this lane or flowcell: {other}'\n                )\n\n        sample.sample_sheet = self\n        self._samples.append(sample)", "response": "Adds a sample to the sample sheet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_samples(self, samples: Iterable[Sample]) -> None:\n        for sample in samples:\n            self.add_sample(sample)", "response": "Add samples in an iterable to this : class : SampleSheet."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting this : class : SampleSheet to JSON.", "response": "def to_json(self, **kwargs: Mapping) -> str:\n        \"\"\"Write this :class:`SampleSheet` to JSON.\n\n        Returns:\n            str: The JSON dump of all entries in this sample sheet.\n\n        \"\"\"\n        content = {\n            'Header': dict(self.Header),\n            'Reads': self.Reads,\n            'Settings': dict(self.Settings),\n            'Data': [sample.to_json() for sample in self.samples],\n            **{title: dict(getattr(self, title)) for title in self._sections},\n        }\n        return json.dumps(content, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting sample and library parameters to a set of files for a given set of basecalling parameters.", "response": "def to_picard_basecalling_params(\n        self,\n        directory: Union[str, Path],\n        bam_prefix: Union[str, Path],\n        lanes: Union[int, List[int]],\n    ) -> None:\n        \"\"\"Writes sample and library information to a set of files for a given\n        set of lanes.\n\n        **BARCODE PARAMETERS FILES**: Store information regarding the sample\n        index sequences, sample index names, and, optionally, the library name.\n        These files are used by Picard's `CollectIlluminaBasecallingMetrics`\n        and Picard's `ExtractIlluminaBarcodes`. The output tab-seperated files\n        are formatted as:\n\n            ``<directory>/barcode_params.<lane>.txt``\n\n        **LIBRARY PARAMETERS FILES**: Store information regarding the sample\n        index sequences, sample index names, and optionally sample library and\n        descriptions. A path to the resulting demultiplexed BAM file is also\n        stored which is used by Picard's `IlluminaBasecallsToSam`. The output\n        tab-seperated files are formatted as:\n\n            ``<directory>/library_params.<lane>.txt``\n\n        The format of the BAM file output paths in the library parameter files\n        are formatted as:\n\n            ``<bam_prefix>/<Sample_Name>.<Sample_Library>/<Sample_Name>.<index><index2>.<lane>.bam``\n\n        Two files will be written to ``directory`` for all ``lanes`` specified.\n        If the path to ``directory`` does not exist, it will be created.\n\n        Args:\n            directory: File path to the directory to write the parameter files.\n            bam_prefix: Where the demultiplexed BAMs should be written.\n            lanes: The lanes to write basecalling parameters for.\n\n        \"\"\"\n        if len(self.samples) == 0:\n            raise ValueError('No samples in sample sheet')\n        if not (\n            isinstance(lanes, int)\n            or isinstance(lanes, (list, tuple))\n            and len(lanes) > 0\n            and all(isinstance(lane, int) for lane in lanes)\n        ):\n            raise ValueError(f'Lanes must be an int or list of ints: {lanes}')\n        if len(set(len(sample.index or '') for sample in self.samples)) != 1:\n            raise ValueError('I7 indexes have differing lengths.')\n        if len(set(len(sample.index2 or '') for sample in self.samples)) != 1:\n            raise ValueError('I5 indexes have differing lengths.')\n        for attr in ('Sample_Name', 'Library_ID', 'index'):\n            if any(getattr(sample, attr) is None for sample in self.samples):\n                raise ValueError(\n                    'Samples must have at least `Sample_Name`, '\n                    '`Sample_Library`, and `index` attributes'\n                )\n\n        # Make lanes iterable if only an int was provided.\n        lanes = [lanes] if isinstance(lanes, int) else lanes\n\n        # Resolve path to basecalling parameter files.\n        prefix = Path(directory).expanduser().resolve()\n        prefix.mkdir(exist_ok=True, parents=True)\n\n        # Promote bam_prefix to Path object.\n        bam_prefix = Path(bam_prefix).expanduser().resolve()\n\n        # Both headers are one column larger if an ``index2`` attribute is\n        # present on all samples. Use list splatting to unpack the options.\n        barcode_header = [\n            *(\n                ['barcode_sequence_1']\n                if not self.samples_have_index2\n                else ['barcode_sequence_1', 'barcode_sequence_2']\n            ),\n            'barcode_name',\n            'library_name',\n        ]\n        # TODO: Remove description if none is provided on all samples.\n        library_header = [\n            *(\n                ['BARCODE_1']\n                if not self.samples_have_index2\n                else ['BARCODE_1', 'BARCODE_2']\n            ),\n            'OUTPUT',\n            'SAMPLE_ALIAS',\n            'LIBRARY_NAME',\n            'DS',\n        ]\n\n        for lane in lanes:\n            barcode_out = prefix / f'barcode_params.{lane}.txt'\n            library_out = prefix / f'library_params.{lane}.txt'\n\n            # Enter into a writing context for both library and barcode params.\n            with ExitStack() as stack:\n                barcode_writer = csv.writer(\n                    stack.enter_context(barcode_out.open('w')), delimiter='\\t'\n                )\n                library_writer = csv.writer(\n                    stack.enter_context(library_out.open('w')), delimiter='\\t'\n                )\n\n                barcode_writer.writerow(barcode_header)\n                library_writer.writerow(library_header)\n\n                for sample in self.samples:\n                    # The long name of a sample is a combination of the sample\n                    # ID and the sample library.\n                    long_name = '.'.join(\n                        [sample.Sample_Name, sample.Library_ID]\n                    )\n\n                    # The barcode name is all sample indexes concatenated.\n                    barcode_name = sample.index + (sample.index2 or '')\n                    library_name = sample.Library_ID or ''\n\n                    # Assemble the path to the future BAM file.\n                    bam_file = (\n                        bam_prefix\n                        / long_name\n                        / f'{sample.Sample_Name}.{barcode_name}.{lane}.bam'\n                    )\n\n                    # Use list splatting to build the contents of the library\n                    # and barcodes parameter files.\n                    barcode_line = [\n                        *(\n                            [sample.index]\n                            if not self.samples_have_index2\n                            else [sample.index, sample.index2]\n                        ),\n                        barcode_name,\n                        library_name,\n                    ]\n\n                    library_line = [\n                        *(\n                            [sample.index]\n                            if not self.samples_have_index2\n                            else [sample.index, sample.index2]\n                        ),\n                        bam_file,\n                        sample.Sample_Name,\n                        sample.Library_ID,\n                        sample.Description or '',\n                    ]\n\n                    barcode_writer.writerow(map(str, barcode_line))\n                    library_writer.writerow(map(str, library_line))\n\n                # Dempultiplexing relys on an umatched file so append that,\n                # but only to the library parameters file.\n                unmatched_file = bam_prefix / f'unmatched.{lane}.bam'\n                library_line = [\n                    *(['N'] if not self.samples_have_index2 else ['N', 'N']),\n                    unmatched_file,\n                    'unmatched',\n                    'unmatchedunmatched',\n                    '',\n                ]\n                library_writer.writerow(map(str, library_line))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites this SampleSheet to a file - like object.", "response": "def write(self, handle: TextIO, blank_lines: int = 1) -> None:\n        \"\"\"Write this :class:`SampleSheet` to a file-like object.\n\n        Args:\n            handle: Object to wrap by csv.writer.\n            blank_lines: Number of blank lines to write between sections.\n\n        \"\"\"\n        if not isinstance(blank_lines, int) or blank_lines <= 0:\n            raise ValueError('Number of blank lines must be a positive int.')\n\n        writer = csv.writer(handle)\n        csv_width: int = max([len(self.all_sample_keys), 2])\n\n        section_order = ['Header', 'Reads'] + self._sections + ['Settings']\n\n        def pad_iterable(\n            iterable: Iterable, size: int = csv_width, padding: str = ''\n        ) -> List[str]:\n            return list(islice(chain(iterable, repeat(padding)), size))\n\n        def write_blank_lines(\n            writer: Any, n: int = blank_lines, width: int = csv_width\n        ) -> None:\n            for i in range(n):\n                writer.writerow(pad_iterable([], width))\n\n        for title in section_order:\n            writer.writerow(pad_iterable([f'[{title}]'], csv_width))\n            section = getattr(self, title)\n            if title == 'Reads':\n                for read in self.Reads:\n                    writer.writerow(pad_iterable([read], csv_width))\n            else:\n                for key, value in section.items():\n                    writer.writerow(pad_iterable([key, value], csv_width))\n            write_blank_lines(writer)\n\n        writer.writerow(pad_iterable(['[Data]'], csv_width))\n        writer.writerow(pad_iterable(self.all_sample_keys, csv_width))\n\n        for sample in self.samples:\n            line = [getattr(sample, key) for key in self.all_sample_keys]\n            writer.writerow(pad_iterable(line, csv_width))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a summary of this sample sheet in a TTY compatible codec.", "response": "def _repr_tty_(self) -> str:\n        \"\"\"Return a summary of this sample sheet in a TTY compatible codec.\"\"\"\n        header_description = ['Sample_ID', 'Description']\n        header_samples = [\n            'Sample_ID',\n            'Sample_Name',\n            'Library_ID',\n            'index',\n            'index2',\n        ]\n\n        header = SingleTable([], 'Header')\n        setting = SingleTable([], 'Settings')\n        sample_main = SingleTable([header_samples], 'Identifiers')\n        sample_desc = SingleTable([header_description], 'Descriptions')\n\n        # All key:value pairs found in the [Header] section.\n        max_header_width = max(MIN_WIDTH, sample_desc.column_max_width(-1))\n        for key in self.Header.keys():\n            if 'Description' in key:\n                value = '\\n'.join(\n                    wrap(getattr(self.Header, key), max_header_width)\n                )\n            else:\n                value = getattr(self.Header, key)\n            header.table_data.append([key, value])\n\n        # All key:value pairs found in the [Settings] and [Reads] sections.\n        for key in self.Settings.keys():\n            setting.table_data.append((key, getattr(self.Settings, key) or ''))\n        setting.table_data.append(('Reads', ', '.join(map(str, self.Reads))))\n\n        # Descriptions are wrapped to the allowable space remaining.\n        description_width = max(MIN_WIDTH, sample_desc.column_max_width(-1))\n        for sample in self.samples:\n            # Add all key:value pairs for this sample\n            sample_main.table_data.append(\n                [getattr(sample, title) or '' for title in header_samples]\n            )\n            # Wrap and add the sample descrption\n            sample_desc.table_data.append(\n                (\n                    sample.Sample_ID,\n                    '\\n'.join(\n                        wrap(sample.Description or '', description_width)\n                    ),\n                )\n            )\n\n        # These tables do not have horizontal headers so remove the frame.\n        header.inner_heading_row_border = False\n        setting.inner_heading_row_border = False\n\n        table = '\\n'.join(\n            [header.table, setting.table, sample_main.table, sample_desc.table]\n        )\n\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating value and throws ValidationError.", "response": "def validate(self, value, model_instance):\n        \"\"\"\n        Validates value and throws ValidationError. Subclasses should override\n        this to provide validation logic.\n        \"\"\"\n        # pylint: disable=newstyle\n        super(TimeZoneField, self).validate(\n            value=self.get_prep_value(value),\n            model_instance=model_instance\n        )\n\n        # Insure the value is can be converted to a timezone\n        self.to_python(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert timezone instances to strings for db storage.", "response": "def get_prep_value(self, value):\n        \"\"\"Converts timezone instances to strings for db storage.\"\"\"\n        # pylint: disable=newstyle\n        value = super(TimeZoneField, self).get_prep_value(value)\n\n        if isinstance(value, tzinfo):\n            return value.zone\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_python(self, value):\n        # pylint: disable=newstyle\n        value = super(TimeZoneField, self).to_python(value)\n\n        if not value:\n            return value\n\n        try:\n            return pytz.timezone(str(value))\n        except pytz.UnknownTimeZoneError:\n            raise ValidationError(\n                message=self.error_messages['invalid'],\n                code='invalid',\n                params={'value': value}\n            )", "response": "Returns a datetime. tzinfo instance for the value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a custom form field for the TimeZoneField.", "response": "def formfield(self, **kwargs):\n        \"\"\"Returns a custom form field for the TimeZoneField.\"\"\"\n\n        defaults = {'form_class': forms.TimeZoneField}\n        defaults.update(**kwargs)\n        return super(TimeZoneField, self).formfield(**defaults)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(self, **kwargs):  # pragma: no cover\n\n        errors = super(TimeZoneField, self).check(**kwargs)\n        errors.extend(self._check_timezone_max_length_attribute())\n        errors.extend(self._check_choices_attribute())\n        return errors", "response": "Calls the TimeZoneField s custom checks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_timezone_max_length_attribute(self):     # pragma: no cover\n\n        # Retrieve the maximum possible length for the time zone string\n        possible_max_length = max(map(len, pytz.all_timezones))\n\n        # Make sure that the max_length attribute will handle the longest time\n        #   zone string\n        if self.max_length < possible_max_length:   # pragma: no cover\n            return [\n                checks.Error(\n                    msg=(\n                        \"'max_length' is too short to support all possible \"\n                        \"pytz time zones.\"\n                    ),\n                    hint=(\n                        \"pytz {version}'s longest time zone string has a \"\n                        \"length of {value}, although it is recommended that \"\n                        \"you leave room for longer time zone strings to be \"\n                        \"added in the future.\".format(\n                            version=pytz.VERSION,\n                            value=possible_max_length\n                        )\n                    ),\n                    obj=self,\n                )\n            ]\n\n        # When no error, return an empty list\n        return []", "response": "Checks that the max_length attribute covers all possible time zones and returns a list of exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks to make sure that the choices attribute contains valid timezone choices.", "response": "def _check_choices_attribute(self):   # pragma: no cover\n        \"\"\"Checks to make sure that choices contains valid timezone choices.\"\"\"\n\n        if self.choices:\n            warning_params = {\n                'msg': (\n                    \"'choices' contains an invalid time zone value '{value}' \"\n                    \"which was not found as a supported time zone by pytz \"\n                    \"{version}.\"\n                ),\n                'hint': \"Values must be found in pytz.all_timezones.\",\n                'obj': self,\n            }\n\n            for option_key, option_value in self.choices:\n                if isinstance(option_value, (list, tuple)):\n                    # This is an optgroup, so look inside the group for\n                    # options.\n                    for optgroup_key in map(lambda x: x[0], option_value):\n                        if optgroup_key not in pytz.all_timezones:\n                            # Make sure we don't raise this error on empty\n                            #   values\n                            if optgroup_key not in self.empty_values:\n                                # Update the error message by adding the value\n                                warning_params.update({\n                                    'msg': warning_params['msg'].format(\n                                        value=optgroup_key,\n                                        version=pytz.VERSION\n                                    )\n                                })\n\n                                # Return the warning\n                                return [\n                                    checks.Warning(**warning_params)\n                                ]\n\n                elif option_key not in pytz.all_timezones:\n                    # Make sure we don't raise this error on empty\n                    #   values\n                    if option_key not in self.empty_values:\n                        # Update the error message by adding the value\n                        warning_params.update({\n                            'msg': warning_params['msg'].format(\n                                value=option_key,\n                                version=pytz.VERSION\n                            )\n                        })\n\n                        # Return the warning\n                        return [\n                            checks.Warning(**warning_params)\n                        ]\n\n        # When no error, return an empty list\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_python(self, value):\n        # pylint: disable=newstyle\n        value = super(LinkedTZDateTimeField, self).to_python(value)\n\n        if not value:\n            return value\n\n        return value.astimezone(self.timezone)", "response": "Convert the value to the appropriate timezone."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pre_save(self, model_instance, add):\n        # pylint: disable=newstyle\n        # Retrieve the currently entered datetime\n        value = super(\n            LinkedTZDateTimeField,\n            self\n        ).pre_save(\n            model_instance=model_instance,\n            add=add\n        )\n\n        # Convert the value to the correct time/timezone\n        value = self._convert_value(\n            value=value,\n            model_instance=model_instance,\n            add=add\n        )\n\n        setattr(model_instance, self.attname, value)\n\n        return value", "response": "Converts the value being saved based on populate_from and time_override"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deconstruct(self):  # pragma: no cover\n        # pylint: disable=newstyle\n        name, path, args, kwargs = super(\n            LinkedTZDateTimeField,\n            self\n        ).deconstruct()\n\n        # Only include kwarg if it's not the default\n        if self.populate_from is not None:\n            # Since populate_from requires a model instance and Django does\n            #   not allow lambda, we hope that we have been provided a\n            #   function that can be parsed\n            kwargs['populate_from'] = self.populate_from\n\n        # Only include kwarg if it's not the default\n        if self.time_override is not None:\n            if hasattr(self.time_override, '__call__'):\n                # Call the callable datetime.time instance\n                kwargs['time_override'] = self.time_override()\n            else:\n                kwargs['time_override'] = self.time_override\n\n        return name, path, args, kwargs", "response": "Add our custom keyword arguments for migrations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the timezone or None from the populate_from attribute.", "response": "def _get_populate_from(self, model_instance):\n        \"\"\"\n        Retrieves the timezone or None from the `populate_from` attribute.\n        \"\"\"\n\n        if hasattr(self.populate_from, '__call__'):\n            tz = self.populate_from(model_instance)\n        else:\n            from_attr = getattr(model_instance, self.populate_from)\n            tz = callable(from_attr) and from_attr() or from_attr\n\n        try:\n            tz = pytz.timezone(str(tz))\n        except pytz.UnknownTimeZoneError:\n            # It was a valiant effort. Resistance is futile.\n            raise\n\n        # If we have a timezone, set the instance's timezone attribute\n        self.timezone = tz\n\n        return tz"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the datetime. time or None from the time_override attribute.", "response": "def _get_time_override(self):\n        \"\"\"\n        Retrieves the datetime.time or None from the `time_override` attribute.\n        \"\"\"\n\n        if callable(self.time_override):\n            time_override = self.time_override()\n        else:\n            time_override = self.time_override\n\n        if not isinstance(time_override, datetime_time):\n            raise ValueError(\n                'Invalid type. Must be a datetime.time instance.'\n            )\n\n        return time_override"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the value to the appropriate timezone and time as declared by the time_override and populate_from attributes.", "response": "def _convert_value(self, value, model_instance, add):\n        \"\"\"\n        Converts the value to the appropriate timezone and time as declared by\n        the `time_override` and `populate_from` attributes.\n        \"\"\"\n\n        if not value:\n            return value\n\n        # Retrieve the default timezone as the default\n        tz = get_default_timezone()\n\n        # If populate_from exists, override the default timezone\n        if self.populate_from is not None:\n            tz = self._get_populate_from(model_instance)\n\n        if is_naive(value):\n            value = make_aware(value=value, timezone=tz)\n\n        # Convert the value to a datetime object in the correct timezone. This\n        #   insures that we will have the correct date if we are performing a\n        #   time override below.\n        value = value.astimezone(tz)\n\n        # Do not convert the time to the time override if auto_now or\n        #   auto_now_add is set\n        if self.time_override is not None and not (\n            self.auto_now or (self.auto_now_add and add)\n        ):\n            # Retrieve the time override\n            time_override = self._get_time_override()\n\n            # Convert the value to the date/time with the appropriate timezone\n            value = make_aware(\n                value=datetime.combine(\n                    date=value.date(),\n                    time=time_override\n                ),\n                timezone=tz\n            )\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef LR_collection(hyper_lr, args):\n\n    # Get configuration items\n    config = ConfigParser()\n    config.read(CONFIG_PATH)\n    lr_analysis_path = config['ID-LR']['lr_package_path']\n    if not os.path.exists(lr_analysis_path):\n        LOGGER.info(\"LR package not defined\")\n        return None\n    lr_filename = lr_analysis_path[lr_analysis_path.rfind('/')+1:]\n    lr_dirname = lr_filename[:lr_filename.rfind('.')]\n    sensor_dir = config['ID-LR']['sensor_path']\n    if not sensor_dir:\n        LOGGER.info(\"sensor_dir not defined in configuration. Using C:\\\\\")\n        sensor_dir = \"C:\\\\\" # Default\n    streamline_path = config['ID-LR']['streamline_path']\n    if not os.path.exists(streamline_path):\n        LOGGER.info(\"Path to streamline.py doesn't exist.\")\n        return None    \n    collect_cmd = config['ID-LR']['collect_cmd']\n    if not collect_cmd:\n        LOGGER.info(\"Collection command missing\")\n        return None\n\n    lr_session = hyper_lr.go_live()\n\n    def lr_cleanup(lr_session):\n        # delete our LR tools\n        try:\n            dir_output = lr_session.list_directory(sensor_dir)\n            for dir_item in dir_output:\n                if 'DIRECTORY' in dir_item['attributes'] and dir_item['filename'] == lr_dirname:\n                    print(\"[+] Found existing LR directory.. deleting\")\n                    command_str = \"powershell.exe Remove-Item {} -Force -Recurse\".format(sensor_dir + lr_dirname)\n                    result = lr_session.create_process(command_str)\n                    if result != b'':\n                        LOGGER.warn(\" ! Problem  deleting {}\".format(sensor_dir + lr_dirname))\n                if 'ARCHIVE' in dir_item['attributes'] and dir_item['filename'] == lr_filename:\n                    print(\"[+] Existing LR package found.. deleting..\")\n                    try:\n                        lr_session.delete_file(sensor_dir + dir_item['filename'])\n                    except TypeError as e:\n                        if 'startswith first arg must be bytes' in e: # might be fixed in newer cbapi versions\n                            LOGGER.warn(\"Error deleting {}.. trying to move on\".format(lr_filename))\n        except live_response_api.LiveResponseError as e:\n            if 'ERROR_PATH_NOT_FOUND' not in str(e):\n                print(\"[ERROR] LiveResponseError: {}\".format(e))\n                return False\n\n    # LR remnants already on host?\n    lr_cleanup(lr_session)\n\n    print(\"[+] Dropping latest LR on host..\")\n    filedata = None\n    with open(lr_analysis_path, 'rb') as f: \n        filedata = f.read()\n    try:\n        lr_session.put_file(filedata, sensor_dir + lr_filename)\n    except Exception as e:\n        # If 'ERROR_FILE_EXISTS' in errmsg, log the error, but try to continue with existing package\n        if 'ERROR_FILE_EXISTS' not in str(e):\n            LOGGER.error(\"Unknown Error: {}\".format(str(e)))\n            return False\n    \n    # execute lr.exe to extract files\n    # unzip = \"C:\\\\lr.exe -o \\'C:\\\\' -y\"\n    extract_cmd = \" -o \\'\" + sensor_dir + \"' -y\"\n    unzip = sensor_dir + lr_filename + extract_cmd\n    print(\"[+] Extracting LR ..\")\n    lr_session.create_process(unzip)\n    \n    # execute collection\n    #collect = \"C:\\\\lr\\\\win32\\\\tools\\\\collect.bat\"\n    collect = sensor_dir + lr_dirname + collect_cmd\n    collect_filename = collect_cmd[collect_cmd.rfind('\\\\')+1:]\n    time.sleep(1)\n    print(\"[+] Executing collect.bat..\")\n    start_time = time.time()\n    lr_session.create_process(collect, wait_for_output=False, wait_for_completion=False) #, wait_timeout=900)\n    hyper_lr.wait_for_process_to_finish(collect_filename)\n    collect_duration = datetime.timedelta(minutes=(time.time() - start_time))\n    print(\"[+] Collect completed in {}\".format(collect_duration))\n\n    # Collect resulting output file\n    outputdir = sensor_dir + lr_dirname + \"\\\\win32\\\\output\\\\\"\n    localfile = None\n    for dir_item in lr_session.list_directory(outputdir):\n        if 'ARCHIVE' in dir_item['attributes'] and  dir_item['filename'].endswith('7z'):\n            # use lerc, if available\n            if hyper_lr.lerc_session:\n                lerc = hyper_lr.lerc_session.get_host(hyper_lr.hostname)\n                command = lerc.Upload(outputdir+dir_item['filename'])\n                #command = hyper_lr.lerc_session.check_command()\n                # wait for client to complete the command\n                print(\" ~ Issued upload command to lerc. Waiting for command to finish..\")\n                if command.wait_for_completion():\n                    print(\" ~ lerc command complete. Streaming LR from lerc server..\")\n                    command.get_results(file_path=dir_item['filename'])\n                    if command:\n                        print(\"[+] lerc command results: \")\n                        print(command)\n                        file_path = command.server_file_path\n                        filename = file_path[file_path.rfind('/')+1:]\n                        print()\n                        print(\"[+] Wrote {}\".format(dir_item['filename']))\n                        localfile = dir_item['filename']\n                else:\n                    LOGGER.error(\"problem waiting for lerc client to complete command\")\n            else:\n                localfile = hyper_lr.getFile_with_timeout(outputdir+dir_item['filename'], localfname=dir_item['filename'])\n\n    # Delete leftovers from sensor\n    lr_cleanup(lr_session)\n \n    # Call steamline on the 7z lr package\n    print(\"[+] Starting streamline on {}\".format(localfile))\n    args = shlex.split(streamline_path + \" \" + localfile)\n    subprocess.call(args, stdout=subprocess.PIPE)\n    print(\"[+] Streamline complete\")\n    return True", "response": "This function is used to create a live response collection package. It is used to create a live response collection package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n\n    parser = argparse.ArgumentParser(description=\"An interface to CarbonBlack environments\")\n\n    #profiles = auth.CredentialStore(\"response\").get_profiles()\n    parser.add_argument('-e', '--environment', choices=auth.CredentialStore(\"response\").get_profiles(),\n                        help='specify a specific instance you want to work with. If not defined \\'-t production\\' will be used implicitly.')\n    parser.add_argument('-t', '--envtypes', type=str, \n                        help='specify any combination of envtypes. Default=All \\'production\\' envtypes. Ignored if -e is set.',\n                        default='production')\n    #parser.add_argument('--debug', action='store_true', help='print debugging info')\n    #parser.add_argument('--warnings', action='store_true',\n    #                         help=\"Warn before printing large executions\")\n\n    subparsers = parser.add_subparsers(dest='command') #title='subcommands', help='additional help')\n    cbinterface_commands = [ 'query', 'proc', 'collect', 'remediate', 'enumerate_usb', 'vxdetect']\n\n    parser_vx = subparsers.add_parser('vxdetect', help=\"search cbsandbox for processes in vxstream report, show detections\")\n    parser_vx.add_argument('vxstream_report', help='path to vxstream report')\n    parser_vx.add_argument('-p', '--print-process-tree', action='store_true', help='print the process tree')\n\n    parser_usb = subparsers.add_parser('enumerate_usb', help=\"Show recent removable drive activity on the sensor\")\n    parser_usb.add_argument('sensor', help='hostname of the sensor')\n    parser_usb.add_argument('-s', '--start-time', action='store',\n                            help='how far back to query (default:ALL time)')\n\n    parser_proc = subparsers.add_parser('proc', help=\"analyze a process GUID. 'proc -h' for more\")\n    parser_proc.add_argument('process', help=\"the process GUID to analyze\")\n    parser_proc.add_argument('--warnings', action='store_true',\n                             help=\"Warn before printing large executions\")\n    parser_proc.add_argument('-w', '--walk-tree', action='store_true',\n                             help=\"walk and analyze the process tree\")\n    parser_proc.add_argument('-wp', '--walk-parents', action='store_true',\n                             help=\"print details on the process ancestry\")\n    #parser_proc.add_argument('-d', '--detection', action='store_true',\n    #                         help=\"show detections that would result in ACE alerts\")\n    parser_proc.add_argument('-i', '--proc-info', action='store_true',\n                             help=\"show binary and process information\")\n    parser_proc.add_argument('-c','--show-children', action='store_true',\n                             help=\"only print process children event details\")\n    parser_proc.add_argument('-nc', '--netconns', action='store_true',\n                             help=\"print network connections\")\n    parser_proc.add_argument('-fm', '--filemods', action='store_true',\n                             help=\"print file modifications\")\n    parser_proc.add_argument('-rm', '--regmods', action='store_true',\n                             help=\"print registry modifications\")\n    parser_proc.add_argument('-um', '--unsigned-modloads', action='store_true',\n                             help=\"print unsigned modloads\")\n    parser_proc.add_argument('-ml', '--modloads', action='store_true',\n                             help=\"print modloads\")\n    parser_proc.add_argument('-cp', '--crossprocs', action='store_true',\n                             help=\"print crossprocs\")\n    #parser_proc.add_argument('-intel', '--intel-hits', action='store_true',\n    #                         help=\"show intel (feed/WL) hits that do not result in ACE alerts\")\n    parser_proc.add_argument('--no-analysis', action='store_true',\n                             help=\"Don't fetch and print process activity\")\n    parser_proc.add_argument('--json', action='store_true', help='output process summary in json')\n    parser_proc.add_argument('--segment-limit', action='store', type=int, default=None,\n                             help='stop processing events into json after this many process segments')\n\n    facet_args = [\n        'process_name', 'childproc_name', 'username', 'parent_name', 'path', 'hostname',\n        'parent_pid', 'comms_ip', 'process_md5', 'start', 'group', 'interface_ip',\n        'modload_count', 'childproc_count', 'cmdline', 'regmod_count', 'process_pid',\n        'parent_id', 'os_type', 'rocessblock_count', 'crossproc_count', 'netconn_count',\n        'parent_md5', 'host_type', 'last_update', 'filemod_count'\n        ]\n \n    parser_query = subparsers.add_parser('query',\n                                         help=\"execute a process search query. 'query -h' for more\")\n    parser_query.add_argument('query', help=\"the process search query you'd like to execute\")\n    parser_query.add_argument('-s', '--start-time', action='store',\n                              help=\"Only return processes with events after given date/time stamp\\\n (server\u2019s clock). Format:'Y-m-d H:M:S' eastern time\")\n    parser_query.add_argument('-e', '--end-time', action='store',\n                              help=\"Set the maximum last update time. Format:'Y-m-d H:M:S' eastern time\")\n    parser_query.add_argument('--facet', action='store', choices=facet_args,\n                              help='stats info on single field accross query results (ex. process_name)')\n    parser_query.add_argument('--no-warnings', action='store_true',\n                             help=\"Don't warn before printing large query results\")\n    parser_query.add_argument('-lh', '--logon-history', action='store_true', help=\"Display available logon history for given username or hostname\")\n\n    parser_collect = subparsers.add_parser('collect', help='perform LR collection tasks on a host')\n    parser_collect.add_argument('sensor', help=\"the hostname/sensor to collect from\")\n    parser_collect.add_argument('-f', '--filepath', action='store', help='collect file')\n    parser_collect.add_argument('-c', '--command-exec', action='store', help='command to execute')\n    parser_collect.add_argument('-p', '--process-list', action='store_true', \n                                help='show processes running on sensor')\n    parser_collect.add_argument('-m', '--memdump', action='store', const='ALLMEM', nargs='?',\n                                help='dump memory on a specific process-id')\n    parser_collect.add_argument('-lr', '--regkeypath', action='store',\n                                help='List all registry values from the specified registry key.')\n    parser_collect.add_argument('-r', '--regkeyvalue', action='store',\n                                help='Returns the associated value of the specified registry key.')\n    parser_collect.add_argument('-i', '--info', action='store_true', help='print sensor information')\n    parser_collect.add_argument('-gst', '--get-task', action='store_true', help='get scheduled tasks or specifc task')\n    parser_collect.add_argument('-mc', '--multi-collect', action='store', help='path to ini file listing files and regs to collect')\n\n    remediate_file_example = \"\"\"Example remediate ini file:\n    [files]\n    file1=C:\\\\Users\\\\user\\\\Desktop\\\\testfile.txt \n\n    [process_names]\n    proc1=cmd.exe\n    proc2=notepad++.exe\n     \n    [directories]\n    directory1=C:\\\\Users\\\\user\\\\Desktop\\\\nanocore\n     \n    [scheduled_tasks]\n    task1=\\\\monkey_task\n    task1=\\\\Microsoft\\\\windows\\\\some\\\\flake\\\\task\n\n    [pids]\n    pid1=10856\n     \n    [registry_paths]\n    reg1=HKLM\\\\Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\\\\calc\n    reg2=HKLM\\\\Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\\\\hippo\"\"\"\n\n    parser_remediate = subparsers.add_parser('remediate', help='remediate a host')\n    parser_remediate.add_argument('sensor', help=\"the hostname/sensor needing remediation\")\n    parser_remediate.add_argument('-i', '--isolate', help='toggle host isolation', default=False, action='store_true')\n    parser_remediate.add_argument('-f', '--remediation-filepath',\n                                  help=\"path to the remediation ini file; 'help' as the filepath for example\")\n    parser_remediate.add_argument('-dst', '--delete-scheduled-task',\n                                  help=\"path of scheduled task to delete\")\n    parser_remediate.add_argument('-kpname', '--kill-process-name', help=\"kill all processes with this name\")\n    parser_remediate.add_argument('-kpid', '--kill-pid', help=\"a process id to kill\")\n    parser_remediate.add_argument('-df', '--delete-file', help=\"path to file needing deletion\")\n    parser_remediate.add_argument('-dr', '--delete-regkey', help=\"path to regkey value needing deletion\")\n    parser_remediate.add_argument('-dd', '--delete-directory', help=\"path to directory needing deletion\")\n    args = parser.parse_args()\n\n    if args.command == 'remediate' and args.remediation_filepath == 'help':\n        print(remediate_file_example)\n        parser.parse_args(['remediate', '-h'])\n\n    if args.command is None:\n        print(\"\\n\\n*****\")\n        print(\"You must specify one of the following commands:\\n\")\n        print(cbinterface_commands)\n        print(\"\\n*****\\n\\n\")\n        parser.parse_args(['-h'])\n\n    #args.debug = True\n    #if args.debug:\n    # configure some more logging\n    root = logging.getLogger()\n    root.addHandler(logging.StreamHandler())\n    logging.getLogger(\"cbapi\").setLevel(logging.ERROR)\n    logging.getLogger(\"lerc_api\").setLevel(logging.WARNING)\n\n    ''' All VxStream related stuff may be removed in a future version '''\n    if args.command == 'vxdetect':\n        cb = CbResponseAPI(profile='vxstream')\n        process_list = parse_vxstream_report(cb, args.vxstream_report)\n        if args.print_process_tree:\n            print()\n            print(process_list)\n        print()\n        return 0\n\n\n    # Set up environment profiles\n    profile = None\n    profiles = []\n    if args.environment: \n        print(\"Using {} environment ..\".format(args.environment))\n        profiles.append(args.environment)\n    else:\n        # a little hack for getting our environment type variable defined\n        default_profile = auth.default_profile\n        default_profile['envtype'] = 'production'\n        query_envtype = set(args.envtypes.lower().split(','))\n        for profile in auth.CredentialStore(\"response\").get_profiles():\n            credentials = auth.CredentialStore(\"response\").get_credentials(profile=profile)\n            profile_envtype = set(credentials['envtype'].lower().split(','))\n            if(query_envtype.issubset(profile_envtype)):\n                profiles.append(profile)\n        \n        \n\n\n    # Process Quering #\n    if args.command == 'query':\n        for profile in profiles:\n            handle_proxy(profile)\n            print(\"\\nSearching {} environment..\".format(profile))\n            q = CBquery(profile=profile)\n            q.process_query(args)\n        return 0\n\n\n    # Select correct environment by sensor hostname and get the sensor object\n    sensor = None\n    if args.command == 'collect' or args.command == 'remediate' or args.command == 'enumerate_usb':\n        cb_results = sensor_search(profiles, args.sensor)\n        if not isinstance(cb_results, list):\n            # an error occured\n            return cb_results\n        else:\n            if not cb_results:\n                LOGGER.info(\"A sensor with hostname {} wasn't found in any environments\".format(args.sensor))\n                return 0\n            elif len(cb_results) > 1:\n                LOGGER.error(\"A sensor by hostname {} was found in multiple environments\".format(args.sensor))\n                for r in cb_results:\n                    print(\"Results:\")\n                    print(\"Profile {}: {} (SID:{})\".format(r[1],r[0].hostname,r[0].id))\n                return 1\n            results = cb_results[0]\n            profile = results[1]\n            sensor = results[0]\n\n\n    # Show USB Regmod activity\n    if args.command == 'enumerate_usb':\n        enumerate_usb(sensor, args.start_time)\n\n\n    # lerc install arguments can differ by company/environment\n    # same lazy hack to define in cb config\n    config = {}\n    try:\n        default_profile = auth.default_profile\n        default_profile['lerc_install_cmd'] = None\n        config = auth.CredentialStore(\"response\").get_credentials(profile=profile)\n    except:\n        pass\n\n\n    # Collection #\n    if args.command == 'collect':\n        hyper_lr = hyperLiveResponse(sensor)\n\n        if args.info:\n            print(hyper_lr)\n            return True\n\n        # start a cb lr session\n        lr_session = hyper_lr.go_live()\n\n        if args.multi_collect:\n            filepaths = regpaths = full_collect = None\n            config = ConfigParser()\n            config.read(args.multi_collect)\n            try:\n                filepaths = config.items(\"files\")\n            except:\n                filepaths = []\n            try:\n                regpaths = config.items(\"registry_paths\")\n            except:\n                regpaths = []\n            try:\n                full_collect = config.get('full_collect', 'action')\n            except:\n                pass\n\n            if regpaths is not None:\n                for regpath in regpaths:\n                    if isinstance(regpath, tuple):\n                        regpath = regpath[1]\n                    print(\"~ Trying to get {}\".format(regpath))\n                    try:\n                        result = lr_session.get_registry_value(regpath)\n                        if result:\n                            localfname = args.sensor + '_regkey_' + result['value_name'] + \".txt\"\n                            with open(localfname,'wb') as f:\n                                f.write(bytes(result['value_data'], 'UTF-8'))\n                            print(\"\\t+ Data written to: {}\".format(localfname))\n                    except Exception as e:\n                        print(\"[!] Error: {}\".format(str(e)))\n            if filepaths is not None:\n                for filepath in filepaths:\n                    try:\n                        hyper_lr.getFile_with_timeout(filepath[1])\n                    except Exception as e:\n                        print(\"[!] Error: {}\".format(str(e)))\n            if full_collect == 'True':\n               return False #LR_collection(hyper_lr, args)\n            return True\n\n        elif args.filepath:\n            hyper_lr.getFile_with_timeout(args.filepath)\n\n        elif args.process_list:\n            hyper_lr.print_processes()\n\n        elif args.memdump:\n            # get config items\n            config = ConfigParser()\n            config.read(CONFIG_PATH)\n            #if config.has_section('memory'):\n            #    if \n            cb_compress = config['memory'].getboolean('cb_default_compress')\n            custom_compress = config['memory'].getboolean('custom_compress')\n            custom_compress_file = config['memory']['custom_compress_file']\n            auto_collect_mem = config['memory'].getboolean('auto_collect_mem_file')\n            lerc_collect_mem = config['memory'].getboolean('lerc_collect_mem')\n            path_to_procdump = config['memory']['path_to_procdump']\n            \n            if args.memdump == \"ALLMEM\":\n                return hyper_lr.dump_sensor_memory(cb_compress=cb_compress, custom_compress=custom_compress,\n                                                   custom_compress_file=custom_compress_file,\n                                                   auto_collect_result=auto_collect_mem)\n            else:\n                return hyper_lr.dump_process_memory(args.memdump, path_to_procdump=path_to_procdump)\n\n        elif args.command_exec:\n            print(\"executing '{}' on {}\".format(args.command_exec, args.sensor))\n            result = lr_session.create_process(args.command_exec, wait_timeout=60, wait_for_output=True)\n            print(\"\\n-------------------------\")\n            result = result.decode('utf-8')\n            print(result + \"\\n-------------------------\")\n            print()\n\n        elif args.regkeypath:\n            print(\"\\n\\t{}\".format(args.regkeypath))\n            results = lr_session.list_registry_keys(args.regkeypath)\n            for result in results:\n                print(\"\\t-------------------------\")\n                print(\"\\tName: {}\".format(result['value_name']))\n                print(\"\\tType: {}\".format(result['value_type']))\n                print(\"\\tData: {}\".format(result['value_data']))\n                print()\n\n        elif args.regkeyvalue:\n            print(\"\\n\\t{}\".format(args.regkeyvalue))\n            result = lr_session.get_registry_value(args.regkeyvalue)\n            print(\"\\t-------------------------\")\n            print(\"\\tName: {}\".format(result['value_name']))\n            print(\"\\tType: {}\".format(result['value_type']))\n            print(\"\\tData: {}\".format(result['value_data']))\n            print()\n\n        elif args.get_task:\n            return hyper_lr.get_scheduled_tasks()\n\n        else:\n            # perform full live response collection\n            if config['lerc_install_cmd']:\n                result = hyper_lr.get_lerc_status()\n                if not result or result == 'UNINSTALLED' or result == 'UNKNOWN':\n                   if not hyper_lr.deploy_lerc(config['lerc_install_cmd']):\n                       LOGGER.warn(\"LERC deployment failed\")\n            else:\n                LOGGER.info(\"{} environment is not configrued for LERC deployment\".format(profile))\n            return LR_collection(hyper_lr, args)\n\n    # Remediation #\n    if args.command == 'remediate':\n        return Remediation(sensor, args)\n\n\n    # Process Investigation #\n    process_tree = None\n    if args.command == 'proc':\n        proc = proc_search_environments(profiles, args.process)\n        if not proc:\n            return 1\n        sp = SuperProcess(proc)\n        if args.proc_info:\n            print(sp)\n        elif args.walk_tree:\n            sp.walk_process_tree()\n            print()\n            print(sp.process_tree)\n\n            for process in sp.process_tree:\n                if process.is_suppressed:\n                    print(\"+  [DATA SUPPRESSED] {} (PID:{}) - {}\".format(process.name, process.pid,\n                                                                         process.id))\n                    continue\n\n                print(\"+  {} (PID:{}) - {}\".format(process.name, process.pid, process.id))\n                if args.filemods:\n                    process.print_filemods()\n                    args.no_analysis = True\n                if args.netconns:\n                    process.print_netconns()\n                    args.no_analysis = True\n                if args.regmods:\n                    process.print_regmods()\n                    args.no_analysis = True\n                if args.unsigned_modloads:\n                    process.print_unsigned_modloads()\n                    args.no_analysis = True\n                if args.modloads:\n                    process.print_modloads()\n                    args.no_analysis = True\n                if args.crossprocs:\n                    process.print_crossprocs()\n                    args.no_analysis = True\n                if args.walk_parents:\n                    sp.show_ancestry()\n                    args.no_analysis = True\n                if args.no_analysis != True:\n                    if args.json:\n                        if args.segment_limit:\n                            print(process.events_to_json(segment_limit=args.segment_limit))\n                        else:\n                            print(process.events_to_json())\n                    else:\n                        process.default_print()\n        else:\n            print()\n            print(sp.process_tree)\n            if args.walk_parents:\n                sp.show_ancestry()\n                args.no_analysis = True\n            if args.filemods:\n                sp.print_filemods()\n                args.no_analysis = True\n            if args.netconns:\n                sp.print_netconns()\n                args.no_analysis = True\n            if args.regmods:\n                sp.print_regmods()\n                args.no_analysis = True\n            if args.unsigned_modloads:\n                sp.print_unsigned_modloads()\n                args.no_analysis = True\n            if args.modloads:\n                sp.print_modloads()\n                args.no_analysis = True\n            if args.crossprocs:\n                sp.print_crossprocs()\n                args.no_analysis = True\n            if args.show_children:\n                sp.print_child_events()\n                args.no_analysis = True\n\n            if args.no_analysis != True:\n                if args.json:\n                    if args.segment_limit:\n                        print(sp.events_to_json(segment_limit=args.segment_limit))\n                    else:\n                        print(sp.events_to_json())\n                else:\n                    sp.default_print()\n\n        \n    print()\n    return True", "response": "This function is the main function of the main function. It is used to create a new instance of a CarbonBlack environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the type of the root node of the given RST tree", "response": "def get_node_type(tree):\n    \"\"\"Returns the type of the root node of the given RST tree\n    (one of 'N', 'S', 'relation' or 'edu'.)\n    \"\"\"\n    if isinstance(tree, (RSTTree, nltk.tree.Tree)):\n        if tree.label() in ('N', 'S'):\n            return tree.label()\n        else:\n            return 'relation'\n    elif isinstance(tree, basestring):\n        return 'edu'\n    else:\n        raise ValueError(\"Unknown tree/node type: {}\".format(type(tree)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_nucsat(relname, nuc_types, elements):\n    assert len(elements) == 2 and len(nuc_types) == 2, \\\n        \"A nucsat relation must have two elements.\"\n    assert set(nuc_types) == set(['N', 'S']), \\\n        \"A nucsat relation must consist of one nucleus and one satellite.\"\n \n    result = \"\\dirrel\"\n    for i, nuc_type in enumerate(nuc_types):\n        if nuc_type == 'N':\n            result += '\\n\\t' + NUC_TEMPLATE.substitute(nucleus=elements[i])    \n        else:\n            result += '\\n\\t' + SAT_TEMPLATE.substitute(satellite=elements[i], relation=relname)\n    return result", "response": "Creates a rst. sty Latex string representation of a standard RST relation containing nucleus and satellite nucleus and satellite nucsat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_multinuc(relname, nucleii):\n    nuc_strings = []\n    for nucleus in nucleii:\n        nuc_strings.append( MULTINUC_ELEMENT_TEMPLATE.substitute(nucleus=nucleus) )\n    nucleii_string = \"\\n\\t\" + \"\\n\\t\".join(nuc_strings)\n    return MULTINUC_TEMPLATE.substitute(relation=relname, nucleus_segments=nucleii_string)", "response": "Creates a rst. sty Latex string representation of a multi - nuclear RST relation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a multi - satellite RST string representation of a set of nucleus - satellite relations.", "response": "def make_multisat(nucsat_tuples):\n    \"\"\"Creates a rst.sty Latex string representation of a multi-satellite RST subtree\n    (i.e. a set of nucleus-satellite relations that share the same nucleus.\n    \"\"\"\n    nucsat_tuples = [tup for tup in nucsat_tuples]  # unpack the iterable, so we can check its length\n    assert len(nucsat_tuples) > 1, \\\n        \"A multisat relation bundle must contain more than one relation\"\n\n    result = \"\\dirrel\\n\\t\"\n    first_relation, remaining_relations = nucsat_tuples[0], nucsat_tuples[1:]\n    \n    relname, nuc_types, elements = first_relation\n    first_nucleus_pos = current_nucleus_pos = nuc_types.index('N')\n    result_segments = []\n    \n    for i, nuc_type in enumerate(nuc_types):\n        if nuc_type == 'N':\n            result_segments.append(NUC_TEMPLATE.substitute(nucleus=elements[i]))\n        else:\n            result_segments.append(SAT_TEMPLATE.substitute(satellite=elements[i], relation=relname))\n    \n    for (relname, nuc_types, elements) in remaining_relations:\n        for i, nuc_type in enumerate(nuc_types):\n            if nuc_type == 'N':  # all relations share the same nucleus, so we don't need to reprocess it.\n                continue\n            else:\n                result_segment = SAT_TEMPLATE.substitute(satellite=elements[i], relation=relname)\n                if i < first_nucleus_pos:  # satellite comes before the nucleus\n                    result_segments.insert(current_nucleus_pos, result_segment)\n                    current_nucleus_pos += 1\n                else:\n                    result_segments.append(result_segment)\n    \n    return result + '\\n\\t'.join(result_segments)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindent a string by the given amount of characters.", "response": "def indent(text, amount, ch=' '):\n    \"\"\"Indents a string by the given amount of characters.\"\"\"\n    padding = amount * ch\n    return ''.join(padding+line for line in text.splitlines(True))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef document_ids(self):\n        matches = [PCC_DOCID_RE.match(os.path.basename(fname))\n                   for fname in pcc.tokenization]\n        return sorted(match.groups()[0] for match in matches)", "response": "returns a list of document IDs used in the PCC"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_document(self, doc_id):\n        layer_graphs = []\n        for layer_name in self.layers:\n            layer_files, read_function = self.layers[layer_name]\n            for layer_file in layer_files:\n                if fnmatch.fnmatch(layer_file, '*{}.*'.format(doc_id)):\n                    layer_graphs.append(read_function(layer_file))\n\n        if not layer_graphs:\n            raise TypeError(\"There are no files with that document ID.\")\n        else:\n            doc_graph = layer_graphs[0]\n            for layer_graph in layer_graphs[1:]:\n                doc_graph.merge_graphs(layer_graph)\n        return doc_graph", "response": "Returns a merged document graph containing all available annotation layers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_files_by_layer(self, layer_name, file_pattern='*'):\n        layer_path = os.path.join(self.path, layer_name)\n        return list(dg.find_files(layer_path, file_pattern))", "response": "returns a list of all files in the given PCC annotation layer_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_files_by_document_id(self, document_id):\n        assert isinstance(document_id, basestring), \\\n            \"The document ID must be given as a string, e.g. 'maz-1423'\"\n        return list(dg.find_files(self._all_files, '*{}.*'.format(document_id)))", "response": "Returns a list of all files in the current directory that match the given document ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a string as Markdown only if in an IPython interpreter.", "response": "def maybe_render_markdown(string: str) -> Any:\n    \"\"\"Render a string as Markdown only if in an IPython interpreter.\"\"\"\n    if is_ipython_interpreter():  # pragma: no cover\n        from IPython.display import Markdown  # type: ignore # noqa: E501\n\n        return Markdown(string)\n    else:\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generic_converter_cli(docgraph_class, file_descriptor=''):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('input_file',\n                        help='{} file to be converted'.format(file_descriptor))\n    parser.add_argument('output_file', nargs='?', default=sys.stdout)\n    args = parser.parse_args(sys.argv[1:])\n\n    assert os.path.isfile(args.input_file), \\\n        \"'{}' isn't a file\".format(args.input_file)\n    docgraph = docgraph_class(args.input_file)\n    write_dot(docgraph, args.output_file)", "response": "generic command line interface for importers. Will convert the file\n    corresponding to the file_descriptor and write the output to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntypecasting all layers set to lists to make the graph exportable ( e. g. into the geoff format.", "response": "def layerset2list(discoursegraph):\n    \"\"\"\n    typecasts all `layers` sets to lists to make the graph\n    exportable (e.g. into the `geoff` format).\n\n    Parameters\n    ----------\n    discoursegraph : DiscourseDocumentGraph\n    \"\"\"\n    for node_id in discoursegraph:\n        discoursegraph.node[node_id]['layers'] = \\\n            list(discoursegraph.node[node_id]['layers'])\n    for (from_id, to_id) in discoursegraph.edges_iter():\n        # there might be multiple edges between 2 nodes\n        edge_dict = discoursegraph.edge[from_id][to_id]\n        for edge_id in edge_dict:\n            edge_dict[edge_id]['layers'] = \\\n                list(edge_dict[edge_id]['layers'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef layerset2str(discoursegraph):\n    for node_id in discoursegraph:\n        discoursegraph.node[node_id]['layers'] = \\\n            str(discoursegraph.node[node_id]['layers'])\n    for (from_id, to_id) in discoursegraph.edges_iter():\n        # there might be multiple edges between 2 nodes\n        edge_dict = discoursegraph.edge[from_id][to_id]\n        for edge_id in edge_dict:\n            edge_dict[edge_id]['layers'] = \\\n                str(edge_dict[edge_id]['layers'])", "response": "typecasts all layers from sets of strings into a single string to make\n    the graph exportable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting all node/edge attributes whose values are lists into string values (e.g. to export them into the `gexf` and `graphml` formats). WARNING: This function iterates over all nodes and edges! You can speed up conversion by writing a custom function that only fixes those attributes that have lists (of strings) as values. Parameters ---------- discoursegraph : DiscourseDocumentGraph", "response": "def attriblist2str(discoursegraph):\n    \"\"\"\n    converts all node/edge attributes whose values are lists into string\n    values (e.g. to export them into the `gexf` and `graphml` formats).\n\n    WARNING: This function iterates over all nodes and edges! You can speed up\n    conversion by writing a custom function that only fixes those attributes\n    that have lists (of strings) as values.\n\n    Parameters\n    ----------\n    discoursegraph : DiscourseDocumentGraph\n    \"\"\"\n    for node_id in discoursegraph:\n        node_dict = discoursegraph.node[node_id]\n        for attrib in node_dict:\n            if isinstance(node_dict[attrib], list):\n                node_dict[attrib] = str(node_dict[attrib])\n    for (from_id, to_id) in discoursegraph.edges_iter():\n        # there might be multiple edges between 2 nodes\n        edge_dict = discoursegraph.edge[from_id][to_id]\n        for edge_id in edge_dict:\n            for attrib in edge_dict[edge_id]:\n                if isinstance(edge_dict[edge_id][attrib], list):\n                    edge_dict[edge_id][attrib] \\\n                        = str(edge_dict[edge_id][attrib])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_root_metadata(docgraph):\n    docgraph.node[docgraph.root].pop('metadata', None)\n    # delete metadata from the generic root node (which probably only exists\n    # when we merge graphs on the command line, cf. issue #89\n    if 'discoursegraph:root_node' in docgraph.node:\n        docgraph.node['discoursegraph:root_node'].pop('metadata', None)\n    # delete the metadata from all former root nodes which have been merged\n    # into this graph\n    if hasattr(docgraph, 'merged_rootnodes'):\n        for merged_rootnode in docgraph.merged_rootnodes:\n            try:  # some of these nodes may not exist any longer\n                docgraph.node[merged_rootnode].pop('metadata', None)\n            except KeyError as e:\n                pass", "response": "Removes the metadata attribute of the root node of a document graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_spanstring(span_string):\n    prefix_err = \"All tokens must share the same prefix: {0} vs. {1}\"\n\n    tokens = []\n    if not span_string:\n        return tokens\n\n    spans = span_string.split(',')\n    for span in spans:\n        span_elements = span.split('..')\n        if len(span_elements) == 1:\n            tokens.append(span_elements[0])\n        elif len(span_elements) == 2:\n            start, end = span_elements\n            start_prefix, start_id_str = start.split('_')\n            end_prefix, end_id_str = end.split('_')\n            assert start_prefix == end_prefix, prefix_err.format(\n                start_prefix, end_prefix)\n            tokens.extend(\"{0}_{1}\".format(start_prefix, token_id)\n                          for token_id in range(int(start_id_str),\n                                                int(end_id_str)+1))\n\n        else:\n            raise ValueError(\"Can't parse span '{}'\".format(span_string))\n\n    first_prefix = tokens[0].split('_')[0]\n    for token in tokens:\n        token_parts = token.split('_')\n        assert len(token_parts) == 2, \\\n            \"All token IDs must use the format prefix + '_' + number\"\n        assert token_parts[0] == first_prefix, prefix_err.format(\n            token_parts[0], first_prefix)\n    return tokens", "response": "Convert a string of spans into a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncustomize function for dumping sensor memory. :arguments cb_compress: If True, use CarbonBlack's built-in compression. :arguments custom_compress_file: Supply path to lr_tools/compress_file.bat to fork powershell compression :collect_mem_file: If True, wait for memdump + and compression to complete, then use cbapi to collect", "response": "def dump_sensor_memory(self, cb_compress=False, custom_compress=False, custom_compress_file=None, auto_collect_result=False):\n        \"\"\"Customized function for dumping sensor memory.\n\n        :arguments cb_compress: If True, use CarbonBlack's built-in compression.\n        :arguments custom_compress_file: Supply path to lr_tools/compress_file.bat to fork powershell compression\n        :collect_mem_file: If True, wait for memdump + and compression to complete, then use cbapi to collect\n        \"\"\"\n\n        print(\"~ dumping contents of memory on {}\".format(self.sensor.computer_name))\n        local_file = remote_file = \"{}.memdmp\".format(self.sensor.computer_name)\n        if not self.lr_session:\n            self.go_live()\n        try:\n            if cb_compress and auto_collect_result:\n                logging.info(\"CB compression and auto-collection set\")\n                self.lr_session.memdump(remote_filename=remote_file, compress=cb_compress)\n                return True\n            dump_object = self.lr_session.start_memdump(remote_filename=remote_file, compress=cb_compress)\n            dump_object.wait()\n            if cb_compress:\n               print(\"+ Memory dump compressed at -> C:\\windows\\carbonblack\\{}.zip\".format(remote_file))\n               if auto_collect_result:\n                   self.getFile_with_timeout(\"C:\\\\Windows\\\\CarbonBlack\\\\{}.zip\".format(remote_file))\n               return True\n            print(\"+ Memory dump complete on host -> C:\\windows\\carbonblack\\{}\".format(remote_file))\n        except LiveResponseError as e:\n            raise Exception(\"LiveResponseError: {}\".format(e))\n\n        if custom_compress: # compress with powershell?\n            if not os.path.exists(custom_compress_file):\n                logging.debug(\"{} not found.\".format(custom_compress_file))\n                HOME_DIR = os.path.abspath(os.path.join(os.path.realpath(__file__),'..','..'))\n                custom_compress_file = os.path.join(HOME_DIR, 'lr_tools', 'compress_file.bat')\n                if not os.path.exists(custom_compress_file):\n                    logging.error(\"{} not found.\".format(custom_compress_file))\n                    return False\n            logging.info(\"Using {}\".format(custom_compress_file))\n\n            bat_filename = custom_compress_file[custom_compress_file.rfind('/')+1:]\n            filedata = None\n            with open(custom_compress_file, 'rb') as f:\n                filedata = f.read()\n            try:\n                self.lr_session.put_file(filedata, \"C:\\\\Windows\\\\CarbonBlack\\\\\" + bat_filename)\n            except LiveResponseError as e:\n                if 'ERROR_FILE_EXISTS' not in str(e):\n                    logging.error(\"Error puting compress_file.bat\")\n                    return False\n                else:\n                    self.lr_session.delete_file(\"C:\\\\Windows\\\\CarbonBlack\\\\\" + bat_filename)\n                    self.lr_session.put_file(filedata, \"C:\\\\Windows\\\\CarbonBlack\\\\\" + bat_filename)\n            print(\"~ Launching \"+ bat_filename +\" to create C:\\\\windows\\\\carbonblack\\\\_memdump.zip\")\n            compress_cmd = \"C:\\\\Windows\\\\CarbonBlack\\\\\" + bat_filename  + \" \" + remote_file\n            self.lr_session.create_process(compress_cmd, wait_for_output=False, wait_for_completion=False)\n            if auto_collect_result:\n                print(\"~ waiting for {} to complete.\".format(bat_filename))\n                self.wait_for_process_to_finish(bat_filename)\n                self.getFile_with_timeout(\"C:\\\\windows\\\\carbonblack\\\\_memdump.zip\")\n            print(\"[!] If compression successful, _memdump.zip will exist, and {} should be deleted.\".format(remote_file))\n        # here, they didn't want to use cb or custom compression, but they did want to auto collect results\n        if auto_collect_result:\n            self.getFile_with_timeout(\"C:\\\\Windows\\\\CarbonBlack\\\\{}\".format(remote_file))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump the memory of a specific process.", "response": "def dump_process_memory(self, pid, working_dir=\"c:\\\\windows\\\\carbonblack\\\\\", path_to_procdump=None):\n        \"\"\"Use sysinternals procdump to dump process memory on a specific process. If only the pid is specified, the default\n        behavior is to use the version of ProcDump supplied with cbinterface's pip3 installer.\n\n        :requires: SysInternals ProcDump v9.0 included with cbinterface==1.1.0\n        :arguments pid: Process id to dump memory for\n        :arguments working_dir: Specify a directoy on the windows sensor to work out of. Default: C:\\\\Windows\\\\CarbonBlack\\\\\n        :arguments path_to_procdump: Specify the path to a version of procdump you want to use. Default is included copy\n        \"\"\"\n\n        self.go_live()\n\n        print(\"~ dumping memory where pid={} for {}\".format(pid, self.sensor.computer_name))\n        # need to make sure procdump.exe is on the sensor\n        procdump_host_path = None\n        dir_output = self.lr_session.list_directory(working_dir)\n        for dir_item in dir_output:\n            if dir_item['filename'] == 'procdump.exe':\n                logging.info(\"procdump.exe already on host.\")\n                procdump_host_path = working_dir + \"procdump.exe\"\n                break\n        else:\n            logging.info(\"Dropping procdump.exe on host.\")\n\n        if not procdump_host_path:\n            if not os.path.exists(path_to_procdump):\n                HOME_DIR = os.path.abspath(os.path.join(os.path.realpath(__file__),'..','..'))\n                path_to_procdump = os.path.join(HOME_DIR, 'lr_tools', 'procdump.exe')\n                if not os.path.exists(path_to_procdump):\n                    logging.warn(\"{} not found\".format(path_to_procdump))\n                    return False\n\n            print(\"~ dropping procdump.exe on host.\")\n            filedata = None\n            with open(path_to_procdump, 'rb') as f:\n                filedata = f.read()\n            try:\n                self.lr_session.create_directory(working_dir)\n            except LiveResponseError:\n                logging.debug(\"working directory already exists\")\n            self.lr_session.put_file(filedata, working_dir + \"procdump.exe\")\n            procdump_host_path = working_dir + \"procdump.exe\"\n\n        print(\"~ Executing procdump..\")\n        command_str = procdump_host_path + \" -accepteula -ma \" + str(pid)\n        result = self.lr_session.create_process(command_str)\n        time.sleep(1)\n        print(\"+ procdump output:\\n-------------------------\")\n        result = result.decode('utf-8')\n        print(result + \"\\n-------------------------\")\n\n        # cut off the carriage return and line feed from filename \n        dumpfile_name = result[result.rfind('\\\\')+1:result.rfind('.dmp')+4]\n        while True:\n            if 'procdump.exe' not in str(self.lr_session.list_processes()):\n                break\n            else:\n                time.sleep(1)\n        # download dumpfile to localdir\n        self.getFile_with_timeout(working_dir + dumpfile_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_relationtypes(urml_xml_tree):\n    return {rel.attrib['name']: rel.attrib['type']\n            for rel in urml_xml_tree.iterfind('//header/reltypes/rel')\n            if 'type' in rel.attrib}", "response": "Extracts the allowed RST relation names and relation types from an URML XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_segment_types(urml_document_element, namespace):\n    segment_types = \\\n        {namespace+':'+seg.attrib['id']: seg.tag\n         for seg in urml_document_element.iter('nucleus', 'satellite')}\n\n    for seg in urml_document_element.iter('segment'):\n        seg_id = namespace+':'+seg.attrib['id']\n        if seg_id not in segment_types:\n            segment_types[seg_id] = 'isolated'\n    return segment_types", "response": "Extract the types of segments from an URML document element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the iterator for all the corpus entries", "response": "def _reset_corpus_iterator(self):\n        \"\"\"\n        create an iterator over all documents in the file (i.e. all\n        <text> elements).\n\n        Once you have iterated over all documents, call this method again\n        if you want to iterate over them again.\n        \"\"\"\n        self.__context = etree.iterparse(self.urml_file, events=('end',),\n                                         tag='document', recover=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of documents in an URML file.", "response": "def _get_num_of_documents(self):\n        '''\n        counts the number of documents in an URML file.\n        adapted from Listing 2 on\n        http://www.ibm.com/developerworks/library/x-hiperfparse/\n        '''\n        parser = etree.XMLParser(target=XMLElementCountTarget('document'))\n        # When iterated over, 'results' will contain the output from\n        # target parser's close() method\n        num_of_documents = etree.parse(self.urml_file, parser)\n        self._num_of_documents = num_of_documents\n        return num_of_documents"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef document_iter(self, context):\n        for _event, elem in context:\n            if not self.debug:\n                yield URMLDocumentGraph(elem, tokenize=self.tokenize,\n                                        precedence=self.precedence)\n            else:\n                yield elem\n            # removes element (and references to it) from memory after processing it\n            elem.clear()\n            while elem.getprevious() is not None:\n                del elem.getparent()[0]\n        del context", "response": "Iterate over all the document elements in an iterparse context and yield an URMLDocumentGraph instance for each of them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading an RST tree and adds all segments and relations to the current document graph.", "response": "def __urml2graph(self, document_elem):\n        \"\"\"\n        Reads an RST tree (from an ElementTree representation of an URML\n        XML file) and adds all segments (nodes representing text) and\n        relations (nonterminal nodes in an RST tree as well as the\n        relationships that hold between them) to this\n        URMLDocumentGraph.\n\n        Parameters\n        ----------\n        document_elem : lxml.etree._Element\n            etree representation of a <document> element of a URML XML file\n        tokenize : bool\n            If True, the RST segments (i.e. nuclei and satellites) will\n            be tokenized and added as additonal token nodes to the\n            document graph (with edges from the respective RST segments).\n            If False, each RST segment will be labeled with the text it\n            represents.\n        \"\"\"\n        for segment in document_elem.iter('segment'):\n            self.__add_segment(segment)\n        for relation in document_elem.iter('parRelation', 'hypRelation'):\n            self.__add_relation(relation)\n\n        # each discourse docgraphs has a default root node, but we will\n        # overwrite it here\n        old_root_id = self.root\n        # the easiest way to find the root node of a URML graph is to find the\n        # origin of the longest path\n        root_id = nx.algorithms.dag_longest_path(self)[0]\n        self.root = root_id\n        # copy metadata from old root node\n        self.node[root_id]['metadata'] = self.node[old_root_id]['metadata']\n        # finally, remove the old root node\n        self.remove_node(old_root_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __add_segment(self, segment):\n        segment_id = self.ns+':'+segment.attrib['id']\n        self.edus.append(segment_id)  # store RST segment in list of EDUs\n\n        # A URML file can be tokenized, partially tokenized or not tokenized\n        # at all. The \"tokenized tokens\" in the URML file will always be added\n        # to the graph as nodes. The \"untokenized tokens\" will only be added,\n        # if ``self.tokenize`` is ``True``.\n\n        if is_segment_tokenized(segment):\n            self.tokenized = True\n            segment_text = sanitize_string(\n                ' '.join(e.text for e in segment if e.text is not None))\n\n            for i, tok_elem in enumerate(segment):\n                tok = tok_elem.text\n                self.__add_token(segment_id, i, tok)\n\n        else:  # is_segment_tokenized(segment) is False\n            segment_text = sanitize_string(segment.text)\n            segment_toks = segment_text.split()\n\n            if self.tokenize:\n                self.tokenized = True\n                for i, tok in enumerate(segment_toks):\n                    self.__add_token(segment_id, i, tok)\n\n        segment_type = self.segment_types[segment_id]\n        segment_label = get_segment_label(\n            segment, segment_type, segment_text, self.ns, self.tokenize)\n        self.add_node(\n            segment_id, layers={self.ns, self.ns+':segment'},\n            attr_dict={self.ns+':text' : segment_text,\n                       'label':  segment_label})", "response": "add attributes to nodes and edges to other segments and groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __add_relation(self, relation):\n        rel_id = self.ns + ':' + relation.attrib['id']\n        rel_name = relation.attrib['type']\n        rel_type = relation.tag\n        self.add_node(rel_id, layers={self.ns, self.ns+':relation'},\n                      attr_dict={self.ns+':rel_name': rel_name,\n                                 self.ns+':rel_type': rel_type})\n\n        rel_attrs = {self.ns+':rel_name': rel_name,\n                     self.ns+':rel_type': rel_type,\n                     'label': self.ns+':'+rel_name}\n\n        if rel_type == 'parRelation':  # relation between two or more nucleii\n            for nucleus in relation:\n                nucleus_id = self.ns + ':' + nucleus.attrib['id']\n                self.add_edge(rel_id, nucleus_id, layers={self.ns},\n                              attr_dict=rel_attrs,\n                              edge_type=EdgeTypes.spanning_relation)\n\n        elif rel_type == 'hypRelation': # between nucleus and satellite\n            hyp_error = (\"<hypRelation> can only contain one nucleus and one\"\n                         \"satellite: {}\".format(etree.tostring(relation)))\n\n            rel_elems = {elem.tag: elem.attrib['id'] for elem in relation}\n            assert len(relation) == 2, hyp_error\n            assert set(rel_elems.keys()) == {'nucleus', 'satellite'}, hyp_error\n\n            # add dominance from relation root node to nucleus\n            nucleus_id = self.ns + ':' + rel_elems['nucleus']\n            self.add_edge(rel_id, nucleus_id, layers={self.ns},\n                          attr_dict=rel_attrs,\n                          edge_type=EdgeTypes.dominance_relation)\n\n            # add dominance from nucleus to satellite\n            satellite_id = self.ns + ':' + rel_elems['satellite']\n            self.add_edge(nucleus_id, satellite_id,\n                          layers={self.ns}, attr_dict=rel_attrs,\n                          edge_type=EdgeTypes.dominance_relation)\n\n        else:  # <relation>, <span>\n            raise NotImplementedError", "response": "Add a relation between two nucleus and one satellite."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenforces a view to have elevated privileges. Should likely be paired with ``@login_required``. >>> @sudo_required >>> def secure_page(request): >>> ...", "response": "def sudo_required(func):\n    \"\"\"\n    Enforces a view to have elevated privileges.\n    Should likely be paired with ``@login_required``.\n\n    >>> @sudo_required\n    >>> def secure_page(request):\n    >>>     ...\n    \"\"\"\n    @wraps(func)\n    def inner(request, *args, **kwargs):\n        if not request.is_sudo():\n            return redirect_to_sudo(request.get_full_path())\n        return func(request, *args, **kwargs)\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromstring(cls, dis_string):\n        temp = tempfile.NamedTemporaryFile(delete=False)\n        temp.write(dis_string)\n        temp.close()\n        dis_tree = cls(dis_filepath=temp.name)\n        os.unlink(temp.name)\n        return dis_tree", "response": "Create a DisRSTTree instance from a string containing a *. dis parse."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filters(self):\n        if self._filters is None:\n            self._filters, self._attributes = self._fetch_configuration()\n        return self._filters", "response": "List of filters available for the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists of attributes available for the dataset.", "response": "def attributes(self):\n        \"\"\"List of attributes available for the dataset (cached).\"\"\"\n        if self._attributes is None:\n            self._filters, self._attributes = self._fetch_configuration()\n        return self._attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist of default attributes for the dataset.", "response": "def default_attributes(self):\n        \"\"\"List of default attributes for the dataset.\"\"\"\n        if self._default_attributes is None:\n            self._default_attributes = {\n                name: attr\n                for name, attr in self.attributes.items()\n                if attr.default is True\n            }\n        return self._default_attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting available attributes in a readable DataFrame format.", "response": "def list_attributes(self):\n        \"\"\"Lists available attributes in a readable DataFrame format.\n\n        Returns:\n            pd.DataFrame: Frame listing available attributes.\n        \"\"\"\n\n        def _row_gen(attributes):\n            for attr in attributes.values():\n                yield (attr.name, attr.display_name, attr.description)\n\n        return pd.DataFrame.from_records(\n            _row_gen(self.attributes),\n            columns=['name', 'display_name', 'description'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist available filters in a readable DataFrame format.", "response": "def list_filters(self):\n        \"\"\"Lists available filters in a readable DataFrame format.\n\n        Returns:\n            pd.DataFrame: Frame listing available filters.\n        \"\"\"\n\n        def _row_gen(attributes):\n            for attr in attributes.values():\n                yield (attr.name, attr.type, attr.description)\n\n        return pd.DataFrame.from_records(\n            _row_gen(self.filters), columns=['name', 'type', 'description'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self,\n              attributes=None,\n              filters=None,\n              only_unique=True,\n              use_attr_names=False,\n              dtypes = None\n              ):\n        \"\"\"Queries the dataset to retrieve the contained data.\n\n        Args:\n            attributes (list[str]): Names of attributes to fetch in query.\n                Attribute names must correspond to valid attributes. See\n                the attributes property for a list of valid attributes.\n            filters (dict[str,any]): Dictionary of filters --> values\n                to filter the dataset by. Filter names and values must\n                correspond to valid filters and filter values. See the\n                filters property for a list of valid filters.\n            only_unique (bool): Whether to return only rows containing\n                unique values (True) or to include duplicate rows (False).\n            use_attr_names (bool): Whether to use the attribute names\n                as column names in the result (True) or the attribute\n                display names (False).\n            dtypes (dict[str,any]): Dictionary of attributes --> data types\n                to describe to pandas how the columns should be handled\n\n        Returns:\n            pandas.DataFrame: DataFrame containing the query results.\n\n        \"\"\"\n\n        # Example query from Ensembl biomart:\n        #\n        # <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        # <!DOCTYPE Query>\n        # <Query  virtualSchemaName = \"default\" formatter = \"TSV\" header = \"0\"\n        #  uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" >\n        #   <Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" >\n        #       <Filter name = \"chromosome_name\" value = \"1,2\"/>\n        #       <Filter name = \"end\" value = \"10000000\"/>\n        #       <Filter name = \"start\" value = \"1\"/>\n        #       <Attribute name = \"ensembl_gene_id\" />\n        #       <Attribute name = \"ensembl_transcript_id\" />\n        #   </Dataset>\n        # </Query>\n\n        # Setup query element.\n        root = ElementTree.Element('Query')\n        root.set('virtualSchemaName', self._virtual_schema)\n        root.set('formatter', 'TSV')\n        root.set('header', '1')\n        root.set('uniqueRows', native_str(int(only_unique)))\n        root.set('datasetConfigVersion', '0.6')\n\n        # Add dataset element.\n        dataset = ElementTree.SubElement(root, 'Dataset')\n        dataset.set('name', self.name)\n        dataset.set('interface', 'default')\n\n        # Default to default attributes if none requested.\n        if attributes is None:\n            attributes = list(self.default_attributes.keys())\n\n        # Add attribute elements.\n        for name in attributes:\n            try:\n                attr = self.attributes[name]\n                self._add_attr_node(dataset, attr)\n            except KeyError:\n                raise BiomartException(\n                    'Unknown attribute {}, check dataset attributes '\n                    'for a list of valid attributes.'.format(name))\n\n        if filters is not None:\n            # Add filter elements.\n            for name, value in filters.items():\n                try:\n                    filter_ = self.filters[name]\n                    self._add_filter_node(dataset, filter_, value)\n                except KeyError:\n                    raise BiomartException(\n                        'Unknown filter {}, check dataset filters '\n                        'for a list of valid filters.'.format(name))\n\n        # Fetch response.\n        response = self.get(query=ElementTree.tostring(root))\n\n        # Raise exception if an error occurred.\n        if 'Query ERROR' in response.text:\n            raise BiomartException(response.text)\n\n        # Parse results into a DataFrame.\n        try:\n            result = pd.read_csv(StringIO(response.text), sep='\\t', dtype=dtypes)\n        # Type error is raised of a data type is not understood by pandas\n        except TypeError as err:\n            raise ValueError(\"Non valid data type is used in dtypes\")\n\n        if use_attr_names:\n            # Rename columns with attribute names instead of display names.\n            column_map = {\n                self.attributes[attr].display_name: attr\n                for attr in attributes\n            }\n            result.rename(columns=column_map, inplace=True)\n\n        return result", "response": "Queries the ensembl dataset to retrieve the contained data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_filter_node(root, filter_, value):\n        filter_el = ElementTree.SubElement(root, 'Filter')\n        filter_el.set('name', filter_.name)\n\n        # Set filter value depending on type.\n        if filter_.type == 'boolean':\n            # Boolean case.\n            if value is True or value.lower() in {'included', 'only'}:\n                filter_el.set('excluded', '0')\n            elif value is False or value.lower() == 'excluded':\n                filter_el.set('excluded', '1')\n            else:\n                raise ValueError('Invalid value for boolean filter ({})'\n                                 .format(value))\n        elif isinstance(value, list) or isinstance(value, tuple):\n            # List case.\n            filter_el.set('value', ','.join(map(str, value)))\n        else:\n            # Default case.\n            filter_el.set('value', str(value))", "response": "Adds filter xml node to root."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a discourse document graph with pointing chains into a string representation of a brat. ann file.", "response": "def brat_output(docgraph, layer=None, show_relations=True):\n    \"\"\"\n    converts a document graph with pointing chains into a string representation\n    of a brat *.ann file.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph which might contain pointing chains (e.g. coreference links)\n    layer : str or None\n        the name of the layer that contains the pointing chains (e.g. 'mmax' or 'pocores').\n        If unspecified, all pointing chains in the document will be considered\n\n    Returns\n    -------\n    ret_str : unicode\n        the content of a brat *.ann file\n    \"\"\"\n    # we can't rely on the .ns attribute of a merged graph\n    if layer:\n        namespace = dg.layer2namespace(layer)\n    else:\n        namespace = docgraph.ns\n\n    ret_str = u''\n    pointing_chains = dg.get_pointing_chains(docgraph, layer=layer)\n\n    # a token can be part of 1+ markable(s)\n    first_token2markables = defaultdict(list)\n    markable_dict = {}\n    markable_index = 1\n\n    for pointing_chain in pointing_chains:\n        for markable in sorted(pointing_chain, key=dg.util.natural_sort_key):\n            span_tokens = spanstring2tokens(docgraph, docgraph.node[markable][namespace+':span'])\n            span_text = dg.tokens2text(docgraph, span_tokens)\n            first_token2markables[span_tokens[0]].append(markable)\n            markable_dict[markable] = (markable_index, span_text, len(span_text))\n            markable_index += 1\n\n    onset = 0\n    for token_id in docgraph.tokens:\n        tok_len = len(docgraph.get_token(token_id))\n        if token_id in first_token2markables:\n            for markable in first_token2markables[token_id]:\n                mark_index, mark_text, mark_len = markable_dict[markable]\n                ret_str += u\"T{0}\\tMarkable {1} {2}\\t{3}\\n\".format(\n                    mark_index, onset, onset+mark_len, mark_text)\n        onset += tok_len+1\n\n    if show_relations:\n        relation = 1\n        for pointing_chain in pointing_chains:\n            last_to_first_mention = sorted(pointing_chain, key=dg.util.natural_sort_key, reverse=True)\n            for i in xrange(0, len(pointing_chain)-1):\n                chain_element = markable_dict[last_to_first_mention[i]][0]\n                prev_chain_element = markable_dict[last_to_first_mention[i+1]][0]\n                ret_str += u\"R{0}\\tCoreference Arg1:T{1} Arg2:T{2}\\n\".format(\n                    relation, chain_element, prev_chain_element)\n                relation += 1\n    return ret_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a visual. conf file for the given document graph.", "response": "def create_visual_conf(docgraph, pointing_chains):\n    \"\"\"\n    creates a visual.conf file (as a string)\n    for the given document graph.\n    \"\"\"\n    num_of_entities = len(pointing_chains)\n    mapsize = max(3, min(12, num_of_entities)) # 3 <= mapsize <= 12\n    colormap = brewer2mpl.get_map(name='Paired', map_type='Qualitative', number=mapsize)\n    colors = range(mapsize) * int(math.ceil(num_of_entities / float(mapsize)))\n    # recycle colors if we need more than 12\n    endless_color_cycle = itertools.cycle(colors)\n\n    ret_str = u'[drawing]\\n\\n'\n    for chain in pointing_chains:\n        background_color = colormap.hex_colors[endless_color_cycle.next()]\n        for markable in chain:\n            span_tokens = spanstring2tokens(docgraph, docgraph.node[markable][docgraph.ns+':span'])\n            span_text = dg.tokens2text(docgraph, span_tokens)\n            ascii_markable = unidecode(span_text)\n            ret_str += u'{0}\\tbgColor:{1}\\n'.format(ascii_markable,\n                                                  background_color)\n    ret_str += '\\n[labels]'\n    return ret_str"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spanstring2tokens(docgraph, span_string):\n    tokens = convert_spanstring(span_string)\n    existing_nodes = set(docgraph.nodes())\n\n    existing_tokens = []\n    for tok in tokens:\n        if tok in existing_nodes:\n            existing_tokens.append(tok)\n        else: # we're trying to catch all token IDs that have been\n              # renamed during merging of document graphs / annotation layers\n            if hasattr(docgraph, 'renamed_nodes'):\n                renamed_token_id = docgraph.renamed_nodes.get(tok)\n                if renamed_token_id in existing_nodes:\n                    existing_tokens.append(renamed_token_id)\n            # else: there was no merging /renaming going on, so the\n            # token is missing because it's <word> element was removed\n            # from the associated *_words.xml file.\n            # This is another 'bug' in the PCC corpus, cf. issue #134\n    return existing_tokens", "response": "Converts a string representing a MMAX2 annotated document graph into a list of token IDs that are represented by the given span string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spanstring2text(docgraph, span_string):\n    token_node_ids = spanstring2tokens(docgraph, span_string)\n    return u' '.join(docgraph.node[tok_node_id][docgraph.ns+':token']\n                     for tok_node_id in token_node_ids)", "response": "Converts a span of tokens into a string containing the tokens itself."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a list of sentence markables (i.e. sentence root nodes) and a list of lists of token markables (one list per sentence), returns a list of (sentence root node, token nodes) tuples. The result is sorted by the order in which the tokens occur in the text. Parameters ---------- sentence_root_nodes : list of str a list of all sentence root node IDs token_nodes : list of list of str a list of lists. each list represents a sentence and contains token node IDs (in the order they occur in the text) Returns ------- sorted_sentence_tuples : list of (str, list of str) tuples a list of all sentences in the order they occur in the text. each sentence is represented by an list of ordered token node IDs", "response": "def sort_sentences_by_token_order(sentence_root_nodes, token_nodes):\n    \"\"\"\n    Given a list of sentence markables (i.e. sentence root nodes) and a list of\n    lists of token markables (one list per sentence), returns a list of\n    (sentence root node, token nodes) tuples. The result is sorted by the\n    order in which the tokens occur in the text.\n\n    Parameters\n    ----------\n    sentence_root_nodes : list of str\n        a list of all sentence root node IDs\n    token_nodes : list of list of str\n        a list of lists. each list represents a sentence and contains\n        token node IDs (in the order they occur in the text)\n\n    Returns\n    -------\n    sorted_sentence_tuples : list of (str, list of str) tuples\n        a list of all sentences in the order they occur in the text. each\n        sentence is represented by an list of ordered token node IDs\n    \"\"\"\n    def sentence_sort_key(sentence_token_tuple):\n        \"\"\"\n        extracts a sortable key from the first token node ID of a sentence\n        \"\"\"\n        return natural_sort_key(sentence_token_tuple[1][0])\n\n    sentence_token_tuples = zip(sentence_root_nodes, token_nodes)\n    return sorted(sentence_token_tuples, key=sentence_sort_key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all NPs and PPs in the given document graph.", "response": "def get_potential_markables(docgraph):\n    \"\"\"\n    returns a list of all NPs and PPs in the given docgraph.\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph that (at least) contains syntax trees\n        (imported from Tiger XML files)\n\n    Returns\n    -------\n    potential_markables : list of str or int\n        Node IDs of all nodes that represent an NP/PP syntactical category/phrase\n        in the input document. If an NP is embedded in a PP, only the node\n        ID of the PP is returned.\n    \"\"\"\n    potential_markables = []\n\n    for node_id, nattr in dg.select_nodes_by_layer(docgraph, 'tiger:syntax', data=True):\n        if nattr['tiger:cat'] == 'NP':\n            # if an NP is embedded into a PP, only print the PP\n            pp_parent = False\n            for source, target in docgraph.in_edges(node_id):\n                parent_node = docgraph.node[source]\n                if 'tiger:cat' in parent_node and parent_node['tiger:cat'] == 'PP':\n                    potential_markables.append(source) # add parent PP phrase\n                    pp_parent = True\n            if not pp_parent:\n                potential_markables.append(node_id) # add NP phrase\n\n        elif nattr['tiger:cat'] == 'PP':\n            potential_markables.append(node_id) # add PP phrase\n    return potential_markables"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a common_paths. xml file and returns a dictionary of paths annotations and filename.", "response": "def _parse_common_paths_file(project_path):\n        \"\"\"\n        Parses a common_paths.xml file and returns a dictionary of paths,\n        a dictionary of annotation level descriptions and the filename\n        of the style file.\n\n        Parameters\n        ----------\n        project_path : str\n            path to the root directory of the MMAX project\n\n        Returns\n        -------\n        paths : dict\n            maps from MMAX file types (str, e.g. 'basedata' or 'markable')\n            to the relative path (str) containing files of this type\n        annotations : dict\n            maps from MMAX annotation level names (str, e.g. 'sentence',\n            'primmark') to a dict of features.\n            The features are: 'schemefile' (maps to a file),\n            'customization_file' (ditto) and 'file_extension' (maps to the\n            file name ending used for all annotations files of this level)\n        stylefile : str\n            name of the (default) style file used in this MMAX project\n        \"\"\"\n        common_paths_file = os.path.join(project_path, 'common_paths.xml')\n        tree = etree.parse(common_paths_file)\n\n        paths = {}\n        path_vars = ['basedata', 'scheme', 'style', 'style', 'customization',\n                     'markable']\n        for path_var in path_vars:\n            specific_path = tree.find('//{}_path'.format(path_var)).text\n            paths[path_var] = specific_path if specific_path else project_path\n        paths['project_path'] = project_path\n\n        annotations = {}\n        for level in tree.iterfind('//level'):\n            annotations[level.attrib['name']] = {\n                'schemefile': level.attrib['schemefile'],\n                'customization_file': level.attrib['customization_file'],\n                'file_extension': level.text[1:]}\n\n        stylesheet = tree.find('//stylesheet').text\n        return paths, annotations, stylesheet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sentences_and_token_nodes(self):\n        token_nodes = []\n        # if sentence annotations were ignored during MMAXDocumentGraph\n        # construction, we need to extract sentence/token node IDs manually\n        if self.ignore_sentence_annotations:\n            mp = self.mmax_project\n            layer_dict = mp.annotations['sentence']\n            file_id = self.get_file_id(self.name)\n            sentence_anno_file = os.path.join(mp.project_path,\n                mp.paths['markable'], file_id+layer_dict['file_extension'])\n            tree = etree.parse(sentence_anno_file)\n            root = tree.getroot()\n            sentence_root_nodes = []\n            for markable in root.iterchildren():\n                sentence_root_nodes.append(markable.attrib['id'])\n\n                sentence_token_nodes = []\n                for token_id in spanstring2tokens(self, markable.attrib['span']):\n                    # ignore token IDs that aren't used in the *_words.xml file\n                    # NOTE: we only need this filter for broken files in the PCC corpus\n                    if token_id in self.tokens:\n                        sentence_token_nodes.append(token_id)\n                        self.add_node(markable.attrib['id'], layers={self.ns, self.ns+':sentence'})\n                token_nodes.append(sentence_token_nodes)\n        else:\n            sentence_root_nodes = list(select_nodes_by_layer(self, self.ns+':sentence'))\n            for sent_node in sentence_root_nodes:\n                sentence_token_nodes = []\n                for token_id in self.get_token_nodes_from_sentence(sent_node):\n                    # ignore token IDs that aren't used in the *_words.xml file\n                    # NOTE: we only need this filter for broken files in the PCC corpus\n                    if token_id in self.tokens:\n                        sentence_token_nodes.append(token_id)\n                token_nodes.append(sentence_token_nodes)\n        return sentence_root_nodes, token_nodes", "response": "Returns a list of sentence root node IDs and a list of token node IDs that are part of that sentence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of token node IDs belonging to the given sentence", "response": "def get_token_nodes_from_sentence(self, sentence_root_node):\n        \"\"\"returns a list of token node IDs belonging to the given sentence\"\"\"\n        return spanstring2tokens(self, self.node[sentence_root_node][self.ns+':span'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an MMAX base file and returns the path to the _words. xml file which contains the tokens of the document.", "response": "def get_word_file(self, mmax_base_file):\n        \"\"\"\n        parses an MMAX base file (``*.mmax``) and returns the path\n        to the corresponding ``_words.xml`` file (which contains\n        the tokens of the document).\n        \"\"\"\n        return os.path.join(self.mmax_project.paths['project_path'],\n                            self.mmax_project.paths['basedata'],\n                            etree.parse(mmax_base_file).find('//words').text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_token_layer(self, words_file, connected):\n        for word in etree.parse(words_file).iterfind('//word'):\n            token_node_id = word.attrib['id']\n            self.tokens.append(token_node_id)\n            token_str = ensure_unicode(word.text)\n            self.add_node(token_node_id,\n                          layers={self.ns, self.ns+':token'},\n                          attr_dict={self.ns+':token': token_str,\n                                     'label': token_str})\n            if connected:\n                self.add_edge(self.root, token_node_id,\n                              layers={self.ns, self.ns+':token'})", "response": "Parses a _words. xml file and adds every token to the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_annotation_layer(self, annotation_file, layer_name):\n        assert os.path.isfile(annotation_file), \\\n            \"Annotation file doesn't exist: {}\".format(annotation_file)\n        tree = etree.parse(annotation_file)\n        root = tree.getroot()\n\n        default_layers = {self.ns, self.ns+':markable', self.ns+':'+layer_name}\n\n        # avoids eml.org namespace handling\n        for markable in root.iterchildren():\n            markable_node_id = markable.attrib['id']\n            markable_attribs = add_prefix(markable.attrib, self.ns+':')\n            self.add_node(markable_node_id,\n                          layers=default_layers,\n                          attr_dict=markable_attribs,\n                          label=markable_node_id+':'+layer_name)\n\n            for target_node_id in spanstring2tokens(self, markable.attrib['span']):\n                # manually add to_node if it's not in the graph, yet\n                # cf. issue #39\n                if target_node_id not in self:\n                    self.add_node(target_node_id,\n                                  # adding 'mmax:layer_name' here could be\n                                  # misleading (e.g. each token would be part\n                                  # of the 'mmax:sentence' layer\n                                  layers={self.ns, self.ns+':markable'},\n                                  label=target_node_id)\n\n                self.add_edge(markable_node_id, target_node_id,\n                              layers=default_layers,\n                              edge_type=EdgeTypes.spanning_relation,\n                              label=self.ns+':'+layer_name)\n\n            # this is a workaround for Chiarcos-style MMAX files\n            if has_antecedent(markable):\n                antecedent_pointer = markable.attrib['anaphor_antecedent']\n                # mmax2 supports weird double antecedents,\n                # e.g. \"markable_1000131;markable_1000132\", cf. Issue #40\n                #\n                # handling these double antecendents increases the number of\n                # chains, cf. commit edc28abdc4fd36065e8bbf5900eeb4d1326db153\n                for antecedent in antecedent_pointer.split(';'):\n                    ante_split = antecedent.split(\":\")\n                    if len(ante_split) == 2:\n                        # mark group:markable_n or secmark:markable_n as such\n                        edge_label = '{}:antecedent'.format(ante_split[0])\n                    else:\n                        edge_label = ':antecedent'\n\n                    # handles both 'markable_n' and 'layer:markable_n'\n                    antecedent_node_id = ante_split[-1]\n                    if len(ante_split) == 2:\n                        antecedent_layer = ante_split[0]\n                        default_layers.add('{0}:{1}'.format(self.ns, antecedent_layer))\n\n                    # manually add antecedent node if it's not yet in the graph\n                    # cf. issue #39\n                    if antecedent_node_id not in self:\n                        self.add_node(antecedent_node_id,\n                                      layers=default_layers)\n\n                    self.add_edge(markable_node_id, antecedent_node_id,\n                                  layers=default_layers,\n                                  edge_type=EdgeTypes.pointing_relation,\n                                  label=self.ns+edge_label)", "response": "Adds all markables from the given annotation file to the discourse graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_edu_text(text_subtree):\n    assert text_subtree.label() == 'text', \"text_subtree: {}\".format(text_subtree)\n    edu_str = u' '.join(word for word in text_subtree.leaves())\n    return re.sub('_!(.*?)_!', '\\g<1>', edu_str)", "response": "return the text of the given EDU subtree with _! - delimiters removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the type of the tree", "response": "def get_tree_type(tree):\n    \"\"\"\n    returns the type of the (sub)tree: Root, Nucleus or Satellite\n\n    Parameters\n    ----------\n    tree : nltk.tree.ParentedTree\n        a tree representing a rhetorical structure (or a part of it)\n    \"\"\"\n    tree_type = tree.label()\n    assert tree_type in SUBTREE_TYPES, \"tree_type: {}\".format(tree_type)\n    return tree_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_node_type(tree):\n    node_type = tree[0].label()\n    assert node_type in NODE_TYPES, \"node_type: {}\".format(node_type)\n    return node_type", "response": "Returns the node type of a tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_node_id(nuc_or_sat, namespace=None):\n    node_type = get_node_type(nuc_or_sat)\n    if node_type == 'leaf':\n        leaf_id = nuc_or_sat[0].leaves()[0]\n        if namespace is not None:\n            return '{0}:{1}'.format(namespace, leaf_id)\n        else:\n            return string(leaf_id)\n\n    #else: node_type == 'span'\n    span_start = nuc_or_sat[0].leaves()[0]\n    span_end = nuc_or_sat[0].leaves()[1]\n    if namespace is not None:\n        return '{0}:span:{1}-{2}'.format(namespace, span_start, span_end)\n    else:\n        return 'span:{0}-{1}'.format(span_start, span_end)", "response": "return the node ID of the given nucleus or satellite"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_parens_in_rst_tree_str(rst_tree_str):\n    '''\n    This converts '(' and ')' brackets the EDUs of the RST into PTB-style\n    tokens (e.g., -LRB-) to escape them for nltk.\n    '''\n    def replace_brackets(matchobj):\n        edu = matchobj.group(0)\n        for (br, br_repl) in DIS_ESCAPES:\n            edu = re.sub(\"\\{}\".format(br), br_repl, edu)\n        return edu\n\n    return re.sub('_!(.*?)_!', replace_brackets, rst_tree_str)", "response": "This function converts parentheses in the RST tree string into PTB - style\n    tokens."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread any data from the given stream without blocking.", "response": "def nonblock_read(stream, limit=None, forceMode=None):\n    '''\n        nonblock_read - Read any data available on the given stream (file, socket, etc) without blocking and regardless of newlines.\n\n            @param stream <object> - A stream (like a file object or a socket)\n            @param limit <None/int> - Max number of bytes to read. If None or 0, will read as much data is available.\n            @param forceMode <None/mode string> - Default None. Will be autodetected if None. If you want to explicitly force a mode, provide 'b' for binary (bytes) or 't' for text (Str). This determines the return type.\n\n            @return <str or bytes depending on stream's mode> - Any data available on the stream, or \"None\" if the stream was closed on the other side and all data has already been read.\n    '''\n    bytesRead = 0\n    ret = []\n\n    if forceMode:\n        if 'b' in forceMode:\n            streamMode = bytes\n        elif 't' in forceMode:\n            streamMode = str\n        else:\n            streamMode = detect_stream_mode(stream)\n    else:\n        streamMode = detect_stream_mode(stream)\n\n    emptyStr = streamMode()\n\n    # Determine if our function is \"read\" (file-like objects) or \"recv\" (socket-like objects)\n    if hasattr(stream, 'read'):\n        readByte = lambda : stream.read(1)\n    elif hasattr(stream, 'recv'):\n        readByte = lambda : stream.recv(1)\n    else:\n        raise ValueError('Cannot determine how to read from provided stream, %s.' %(repr(stream),))\n\n    while True:\n        # Check if data on stream is immediately available\n        (readyToRead, junk1, junk2) = select.select([stream], [], [], .000001)\n\n        if not readyToRead:\n            break\n\n        c = readByte()\n        if c == emptyStr:\n            # Stream has been closed\n            if not ret:\n                # All data already read, so return None\n                return None\n            # Otherwise, return data collected. Next call will return None.\n            break\n\n        bytesRead += 1\n        ret.append(c)\n\n        if limit and bytesRead >= limit:\n            break\n\n    return emptyStr.join(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist of datasets in this mart.", "response": "def datasets(self):\n        \"\"\"List of datasets in this mart.\"\"\"\n        if self._datasets is None:\n            self._datasets = self._fetch_datasets()\n        return self._datasets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting available datasets in a readable DataFrame format.", "response": "def list_datasets(self):\n        \"\"\"Lists available datasets in a readable DataFrame format.\n\n        Returns:\n            pd.DataFrame: Frame listing available datasets.\n        \"\"\"\n        def _row_gen(attributes):\n            for attr in attributes.values():\n                yield (attr.name, attr.display_name)\n\n        return pd.DataFrame.from_records(\n            _row_gen(self.datasets),\n            columns=['name', 'display_name'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the allowed RST relation names and relation types from an RS3 XML file.", "response": "def extract_relationtypes(rs3_xml_tree):\n    \"\"\"\n    extracts the allowed RST relation names and relation types from\n    an RS3 XML file.\n\n    Parameters\n    ----------\n    rs3_xml_tree : lxml.etree._ElementTree\n        lxml ElementTree representation of an RS3 XML file\n\n    Returns\n    -------\n    relations : dict of (str, str)\n        Returns a dictionary with RST relation names as keys (str)\n        and relation types (either 'rst' or 'multinuc') as values\n        (str).\n    \"\"\"\n    return {rel.attrib['name']: rel.attrib['type']\n            for rel in rs3_xml_tree.iter('rel')\n            if 'type' in rel.attrib}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the source or target node id of an edge depending on the node_type given.", "response": "def get_node_id(edge, node_type):\n    \"\"\"\n    returns the source or target node id of an edge, depending on the\n    node_type given.\n    \"\"\"\n    assert node_type in ('source', 'target')\n    _, node_id_str = edge.attrib[node_type].split('.')  # e.g. //@nodes.251\n    return int(node_id_str)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_string_onset(edge):\n    onset_label = edge.find('labels[@name=\"SSTART\"]')\n    onset_str = onset_label.xpath('@valueString')[0]\n    return int(onset_str)", "response": "return the onset of a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the offset of a string", "response": "def get_string_offset(edge):\n    \"\"\"return the offset (int) of a string\"\"\"\n    onset_label = edge.find('labels[@name=\"SEND\"]')\n    onset_str = onset_label.xpath('@valueString')[0]\n    return int(onset_str)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a SaltEdge instance from the etree representation of an element.", "response": "def from_etree(cls, etree_element):\n        \"\"\"\n        creates a ``SaltEdge`` instance from the etree representation of an\n        <edges> element from a SaltXMI file.\n        \"\"\"\n        ins = SaltElement.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        ins.__class__ = SaltEdge.mro()[0]  # convert SaltElement into SaltEdge\n        ins.layers = get_layer_ids(etree_element)\n        ins.source = get_node_id(etree_element, 'source')\n        ins.target = get_node_id(etree_element, 'target')\n        return ins"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_etree(self):\n        layers_attrib_val = ' '.join('//@layers.{}'.format(layer_id)\n                                     for layer_id in self.layers)\n\n        attribs = {\n            '{{{pre}}}type'.format(pre=NAMESPACES['xsi']): self.xsi_type,\n            'source': \"//@nodes.{}\".format(self.source),\n            'target': \"//@nodes.{}\".format(self.target),\n            'layers': layers_attrib_val}\n        # an edge might belong to one or more layers\n        non_empty_attribs = {key: val for (key, val) in attribs.items()\n                             if val is not None}\n\n        E = ElementMaker()\n        edge = E('edges', non_empty_attribs)\n        label_elements = (label.to_etree() for label in self.labels)\n        edge.extend(label_elements)\n        return edge", "response": "Creates an etree element of a SaltXMI\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_etree(cls, etree_element):\n        ins = SaltEdge.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        # convert SaltEdge into TextualRelation\n        ins.__class__ = TextualRelation.mro()[0]\n        ins.onset = get_string_onset(etree_element)\n        ins.offset = get_string_offset(etree_element)\n        return ins", "response": "create a TextualRelation instance from an etree element representing an XML element with xsi : type\n        sDocumentStructure : STextualRelation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a DominanceRelation instance from an etree element representing an <edges > element with xsi : type sDocumentStructure : SDominanceRelation.", "response": "def from_etree(cls, etree_element):\n        \"\"\"\n        create a ``DominanceRelation`` instance from an etree element\n        representing an <edges> element with xsi:type\n        'sDocumentStructure:SDominanceRelation'.\n        \"\"\"\n        ins = SaltEdge.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        # convert SaltEdge into DominanceRelation\n        ins.__class__ = DominanceRelation.mro()[0]\n        ins.features = get_annotations(etree_element)\n        return ins"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef traverse_dependencies_up(docgraph, node_id, node_attr=None):\n    # there's only one, but we're in a multidigraph\n    source, target = docgraph.in_edges(node_id)[0]\n    traverse_attr = node_attr if node_attr else docgraph.lemma_attr\n\n    attrib_value = docgraph.node[source].get(traverse_attr)\n    if attrib_value:\n        yield attrib_value\n\n    if istoken(docgraph, source) is True:\n        for attrib_value in traverse_dependencies_up(docgraph, source,\n                                                     traverse_attr):\n            yield attrib_value", "response": "Traverse the given node_id and return the given node attribute from all the nodes visited\n    along the way."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_conll(docgraph, output_file, coreference_layer=None,\n                markable_layer=None):\n    \"\"\"\n    converts a DiscourseDocumentGraph into a tab-separated CoNLL 2009 file and\n    writes it to the given file (or file path).\n    \"\"\"\n    if markable_layer is None:\n        markable_layer = docgraph.ns+':markable'\n    conll_file = Conll2009File(docgraph,\n                               coreference_layer=coreference_layer,\n                               markable_layer=markable_layer)\n    assert isinstance(output_file, (str, file))\n    if isinstance(output_file, str):\n        path_to_file = os.path.dirname(output_file)\n        if not os.path.isdir(path_to_file):\n            create_dir(path_to_file)\n        conll_file.write(output_file)\n    else:  # output_file is a file object\n        output_file.write(conll_file.__str__())", "response": "Converts a DiscourseDocumentGraph into a CoNLL 2009 file and writes it to the given file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_conll(self, conll_filepath):\n        assert self.conll_format in ('2009', '2010'), \\\n            \"We only support CoNLL2009 and CoNLL2010 format.\"\n        if self.conll_format == '2009':\n            word_class = Conll2009Word\n        else:\n            word_class = Conll2010Word\n\n        def parse_conll_file(conll_file, encoding=None):\n            conll_str = conll_file.read().decode(encoding) if encoding else conll_file.read()\n            sentences = conll_str.strip().split(\"\\n\\n\")\n            for i, sentence in enumerate(sentences, 1):\n                sent_id = self.__add_sentence_root_node(i)\n                for word in self.__parse_conll_sentence(sentence, word_class):\n                    self.__add_token(word, sent_id)\n                    self.__add_dependency(word, sent_id)\n\n        if isinstance(conll_filepath, str):\n            with codecs.open(conll_filepath, 'r', 'utf-8') as conll_file:\n                parse_conll_file(conll_file)\n        else:  # conll_filepath is a file object (e.g. stdin)\n            parse_conll_file(conll_filepath, encoding='utf-8')", "response": "Parses a CoNLL file into a multidigraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the root node of a sentence to the graph and adds the edge of the root node of the sentence to the list of sentences .", "response": "def __add_sentence_root_node(self, sent_number):\n        \"\"\"\n        adds the root node of a sentence to the graph and the list of sentences\n        (``self.sentences``). the node has a ``tokens` attribute, which\n        contains a list of the tokens (token node IDs) of this sentence.\n\n        Parameters\n        ----------\n        sent_number : int\n            the index of the sentence within the document\n\n        Results\n        -------\n        sent_id : str\n            the ID of the sentence\n        \"\"\"\n        sent_id = 's{}'.format(sent_number)\n        self.add_node(sent_id, layers={self.ns, self.ns+':sentence'},\n                      tokens=[])\n        self.add_edge(self.root, sent_id,\n                      layers={self.ns, self.ns+':sentence'},\n                      edge_type=EdgeTypes.dominance_relation)\n        self.sentences.append(sent_id)\n        return sent_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __add_token(self, word, sent_id, feat_format='unknown'):\n        token_id = '{0}_t{1}'.format(sent_id, word.word_id)\n        feats = word._asdict()\n        # dicts can't be generated and updated at once\n        feats.update({self.ns+':token': word.token, 'label': word.token,\n                      'word_pos': int(word.word_id)})\n        self.__add_morph_features(feats, feats[self.feat_attr], feat_format)\n        self.add_node(token_id, layers={self.ns, self.ns+':token'},\n                      attr_dict=feats, sent_pos=int(sent_id[1:]))\n        self.tokens.append(token_id)\n        self.node[sent_id]['tokens'].append(token_id)\n        return token_id", "response": "Adds a token to the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __add_dependency(self, word_instance, sent_id):\n        # 'head_attr': (projected) head\n        head = word_instance.__getattribute__(self.head_attr)\n        deprel = word_instance.__getattribute__(self.deprel_attr)\n        if head == '0':\n            # word represents the sentence root\n            source_id = sent_id\n        else:\n            source_id = '{0}_t{1}'.format(sent_id, head)\n            # TODO: fix issue #39, so we don't have to add nodes explicitly\n            if source_id not in self.node:\n                self.add_node(source_id, layers={self.ns})\n\n        target_id = '{0}_t{1}'.format(sent_id, word_instance.word_id)\n        # 'pdeprel': projected dependency relation\n        try:\n            self.add_edge(source_id, target_id,\n                          layers={self.ns, self.ns+':dependency'},\n                          relation_type=deprel,\n                          label=deprel,\n                          edge_type=EdgeTypes.dominance_relation)\n        except AssertionError:\n            print \"source: {0}, target: {1}\".format(source_id, target_id)", "response": "Adds an ingoing dependency relation from the projected head of a token\n            to the token itself."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd morphological features to the node attribute dict.", "response": "def __add_morph_features(self, token_dict, feature_string,\n                             feature_format='unknown'):\n        \"\"\"\n        Parameters\n        ----------\n        token_dict : dict\n            the node attribute dict belonging to a token node\n        feature_string : str\n            a string representing the (grammatical) features of a token\n        feature_format : str\n            Format of the feature string (i.e. ``attrib_val``, ``val_only`` or\n            ``unknown``). A ``val_only`` string contains only the attribute\n            values, e.g. ``Pos|Dat|Sg|Fem``. An ``attrib_val`` string contains\n            both the attribute's name and its value, e.g.\n            ``case=dat|number=sg|gender=fem|degree=pos``.\n        \"\"\"\n        assert feature_format in ('attrib_val', 'val_only', 'unknown')\n\n        def add_val_only_features(token_dict, feature_string):\n            feature_values = feature_string.split('|')\n            for feat_val in feature_values:\n                for morph_cat in MORPHOLOGICAL_FEATURES:\n                    if feat_val in MORPHOLOGICAL_FEATURES[morph_cat]:\n                        feat_name = self.ns+':'+morph_cat\n                        if morph_cat == 'person':\n                            token_dict[feat_name] = int(feat_val)\n                        else:\n                            token_dict[feat_name] = feat_val.lower()\n\n        def add_attrib_val_features(token_dict, feature_string):\n            for attrib_val_str in feature_string.split('|'):\n                try:\n                    attrib, val = attrib_val_str.split('=')\n                    if attrib == 'person':\n                        val = int(val)\n                    if val != '*':\n                        token_dict.update({self.ns+':'+attrib: val})\n                # TODO: check, if these exceptions really occur\n                except ValueError:  # if there are no attrib-val pairs\n                    continue\n\n        if feature_format == 'attrib_val':\n            add_attrib_val_features(token_dict, feature_string)\n\n        elif feature_format == 'val_only':\n            add_val_only_features(token_dict, feature_string)\n\n        else:  # if feature string contains '=', it is an attrib_val string\n            if ATTRIB_VAL_REGEX.search(feature_string):\n                add_attrib_val_features(token_dict, feature_string)\n            else:\n                add_val_only_features(token_dict, feature_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __build_markable_token_mapper(self, coreference_layer=None,\n                                      markable_layer=None):\n        \"\"\"\n        Creates mappings from tokens to the markable spans they belong to\n        and the coreference chains these markables are part of.\n\n        Returns\n        -------\n        tok2markables : dict (str -> set of str)\n            Maps from a token (node ID) to all the markables (node IDs)\n            it is part of.\n        markable2toks : dict (str -> list of str)\n            Maps from a markable (node ID) to all the tokens (node IDs)\n            that belong to it.\n        markable2chains : dict (str -> list of int)\n            Maps from a markable (node ID) to all the chains (chain ID) it\n            belongs to.\n        \"\"\"\n        tok2markables = defaultdict(set)\n        markable2toks = defaultdict(list)\n        markable2chains = defaultdict(list)\n\n        coreference_chains = get_pointing_chains(self.docgraph,\n                                                 layer=coreference_layer)\n        for chain_id, chain in enumerate(coreference_chains):\n            for markable_node_id in chain:\n                markable2chains[markable_node_id].append(chain_id)\n\n        # ID of the first singleton (if there are any)\n        singleton_id = len(coreference_chains)\n\n        # markable2toks/tok2markables shall contains all markables, not only\n        # those which are part of a coreference chain\n        for markable_node_id in select_nodes_by_layer(self.docgraph,\n                                                      markable_layer):\n            span = get_span(self.docgraph, markable_node_id)\n            markable2toks[markable_node_id] = span\n            for token_node_id in span:\n                tok2markables[token_node_id].add(markable_node_id)\n\n            # singletons each represent their own chain (with only one element)\n            if markable_node_id not in markable2chains:\n                markable2chains[markable_node_id] = [singleton_id]\n                singleton_id += 1\n\n        return tok2markables, markable2toks, markable2chains", "response": "Builds a mapping from tokens to markables spans they belong to and the coreference chains they belong to."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the string that represents the markables and coreference chains that a token is part of.", "response": "def __gen_coref_str(self, token_id, markable_id, target_id):\n        \"\"\"\n        generates the string that represents the markables and coreference\n        chains that a token is part of.\n\n        Parameters\n        ----------\n        token_id : str\n            the node ID of the token\n        markable_id : str\n            the node ID of the markable span\n        target_id : int\n            the ID of the target (either a singleton markable or a coreference\n            chain)\n\n        Returns\n        -------\n        coref_str : str\n            a string representing the token's position in a markable span\n            and its membership in one (or more) coreference chains\n        \"\"\"\n        span = self.markable2toks[markable_id]\n        coref_str = str(target_id)\n        if span.index(token_id) == 0:\n            # token is the first element of a markable span\n            coref_str = '(' + coref_str\n        if span.index(token_id) == len(span)-1:\n            # token is the last element of a markable span\n            coref_str += ')'\n        return coref_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a list of SaltNode \\ s returns a list of lists where each list contains the indices of the nodes belonging to that sentence.", "response": "def extract_sentences(nodes, token_node_indices):\n    \"\"\"\n    given a list of ``SaltNode``\\s, returns a list of lists, where each list\n    contains the indices of the nodes belonging to that sentence.\n    \"\"\"\n    sents = []\n    tokens = []\n    for i, node in enumerate(nodes):\n        if i in token_node_indices:\n            if node.features['tiger.pos'] != '$.':\n                tokens.append(i)\n            else:  # start a new sentence, if 'tiger.pos' is '$.'\n                tokens.append(i)\n                sents.append(tokens)\n                tokens = []\n    return sents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_etree(cls, etree_element):\n        ins = SaltElement.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        ins.__class__ = SaltNode.mro()[0]  # convert SaltElement into SaltNode\n        ins.layers = get_layer_ids(etree_element)\n        ins.features = get_annotations(etree_element)\n        return ins", "response": "Creates a SaltNode instance from an etree representation of an\n        element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_etree(self):\n        layers_attrib_val = ' '.join('//@layers.{}'.format(layer_id)\n                                     for layer_id in self.layers)\n\n        attribs = {\n            '{{{pre}}}type'.format(pre=NAMESPACES['xsi']): self.xsi_type,\n            'layers': layers_attrib_val}\n\n        E = ElementMaker()\n        node = E('nodes', attribs)\n        label_elements = (label.to_etree() for label in self.labels)\n        node.extend(label_elements)\n        return node", "response": "Creates an etree element of a SaltXMI\n        object that mimicks a SaltXMI\n        element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_etree(cls, etree_element):\n        ins = SaltNode.from_etree(etree_element)\n        # TODO: this looks dangerous, ask Stackoverflow about it!\n        # convert SaltNode into PrimaryTextNode\n        ins.__class__ = PrimaryTextNode.mro()[0]\n        ins.text = extract_primary_text(etree_element)\n        return ins", "response": "Creates a PrimaryTextNode instance from the etree representation of\n        a <nodes > element from a SaltXMI file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a document graph into GEXF format and writes it to a file.", "response": "def write_gexf(docgraph, output_file):\n    \"\"\"\n    takes a document graph, converts it into GEXF format and writes it to\n    a file.\n    \"\"\"\n    dg_copy = deepcopy(docgraph)\n    remove_root_metadata(dg_copy)\n    layerset2str(dg_copy)\n    attriblist2str(dg_copy)\n    nx_write_gexf(dg_copy, output_file)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef t(root, children=None, debug=False, root_id=None):\n    \"Create (DGParented)Tree from a root (str) and a list of (str, list) tuples.\"\n    if isinstance(root, Tree):\n        if children is None:\n            return root\n        return root.__class__(root, children, root_id)\n\n    elif isinstance(root, basestring):\n        root = debug_root_label(root, debug, root_id)\n\n        # Beware: (DGParented)Tree is a subclass of list!\n        if isinstance(children, Tree):\n            child_trees = [children]\n\n        elif isinstance(children, list):\n            child_trees = []\n            for child in children:\n                if isinstance(child, Tree):\n                    child_trees.append(child)\n                elif isinstance(child, list):\n                    child_trees.extend(child)\n                elif isinstance(child, tuple):\n                    child_trees.append(t(*child))\n                elif isinstance(child, basestring):\n                    child_trees.append(child)\n                else:\n                    raise NotImplementedError\n\n        elif isinstance(children, basestring):\n            # this tree does only have one child, a leaf node\n            # TODO: this is a workaround for the following problem:\n            # Tree('foo', [Tree('bar', [])]) != Tree('foo', ['bar'])\n            child_trees = [Tree(children, [])]\n\n        else:\n            # this tree only consists of one leaf node\n            assert children is None\n            child_trees = []\n\n        return DGParentedTree(root, child_trees, root_id)\n\n    else:\n        raise NotImplementedError", "response": "Create ( DGParented ) Tree from a root ( str ) and a list of ( str list ) tuples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield all nodes that the given node dominates or spans.", "response": "def get_child_nodes(docgraph, parent_node_id, data=False):\n    \"\"\"Yield all nodes that the given node dominates or spans.\"\"\"\n    return select_neighbors_by_edge_attribute(\n        docgraph=docgraph,\n        source=parent_node_id,\n        attribute='edge_type',\n        value=[EdgeTypes.dominance_relation],\n        data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_parents(docgraph, child_node, strict=True):\n    parents = []\n    for src, _, edge_attrs in docgraph.in_edges(child_node, data=True):\n        if edge_attrs['edge_type'] == EdgeTypes.dominance_relation:\n            parents.append(src)\n\n    if strict and len(parents) > 1:\n        raise ValueError((\"In a syntax tree, a node can't be \"\n                          \"dominated by more than one parent\"))\n    return parents", "response": "Return a list of parent nodes that dominate this child node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef horizontal_positions(docgraph, sentence_root=None):\n    # calculate positions for the whole graph\n    root_cond = (sentence_root is None) or (sentence_root == docgraph.root)\n    if root_cond or ('tokens' not in docgraph.node[sentence_root]):\n        sentence_root = docgraph.root\n        token_nodes = docgraph.tokens\n        path = {}\n    else:  # calculate positions only for the given sentence subgraph\n        token_nodes = docgraph.node[sentence_root]['tokens']\n        path = {sentence_root: 0}\n\n    for i, token_node in enumerate(token_nodes):\n        start_node = token_node\n        while get_parents(docgraph, start_node, strict=True):\n            if start_node not in path:\n                path[start_node] = i\n            start_node = get_parents(docgraph, start_node, strict=True)[0]\n    return path", "response": "return map of node ID - > first token index it covers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_bfs_edges(G, source=None):\n    if source is None:\n        source = G.root\n\n    xpos = horizontal_positions(G, source)\n    visited = set([source])\n    source_children = get_child_nodes(G, source)\n    queue = deque([(source, iter(sorted(source_children,\n                                        key=lambda x: xpos[x])))])\n    while queue:\n        parent, children = queue[0]\n        try:\n            child = next(children)\n            if child not in visited:\n                yield parent, child\n                visited.add(child)\n                grandchildren = get_child_nodes(G, child)\n                queue.append((child, iter(sorted(grandchildren,\n                                                 key=lambda x: xpos[x]))))\n        except StopIteration:\n            queue.popleft()", "response": "Returns a generator of edges in a breadth - first search starting at source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sorted_bfs_successors(G, source=None):\n    if source is None:\n        source = G.root\n\n    successors = defaultdict(list)\n    for src, target in sorted_bfs_edges(G, source):\n        successors[src].append(target)\n    return dict(successors)", "response": "Returns a dictionary of successors in breadth - first - search from source."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a docgraph node into a PTB - style string.", "response": "def node2bracket(docgraph, node_id, child_str=''):\n    \"\"\"convert a docgraph node into a PTB-style string.\"\"\"\n    node_attrs = docgraph.node[node_id]\n    if istoken(docgraph, node_id):\n        pos_str = node_attrs.get(docgraph.ns+':pos', '')\n        token_str = node_attrs[docgraph.ns+':token']\n        return u\"({pos}{space1}{token}{space2}{child})\".format(\n            pos=pos_str, space1=bool(pos_str)*' ', token=token_str,\n            space2=bool(child_str)*' ', child=child_str)\n\n    #else: node is not a token\n    label_str = node_attrs.get('label', '')\n    return u\"({label}{space}{child})\".format(\n        label=label_str, space=bool(label_str and child_str)*' ',\n        child=child_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tree2bracket(docgraph, root=None, successors=None):\n    if root is None:\n        root = docgraph.root\n    if successors is None:\n        successors = sorted_bfs_successors(docgraph, root)\n\n    if root in successors:\n        embed_str = u\" \".join(tree2bracket(docgraph, child, successors)\n                              for child in successors[root])\n        return node2bracket(docgraph, root, embed_str)\n    return node2bracket(docgraph, root)", "response": "convert a docgraph into a PTB - style string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlining - wrap an NLTK ParentedTree for pretty - printing", "response": "def word_wrap_tree(parented_tree, width=0):\n    \"\"\"line-wrap an NLTK ParentedTree for pretty-printing\"\"\"\n    if width != 0:\n        for i, leaf_text in enumerate(parented_tree.leaves()):\n            dedented_text = textwrap.dedent(leaf_text).strip()\n            parented_tree[parented_tree.leaf_treeposition(i)] = textwrap.fill(dedented_text, width=width)\n    return parented_tree"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the linear position of an element of this DGParentedTree in an RSTTree.", "response": "def get_position(self, rst_tree, node_id=None):\n        \"\"\"Get the linear position of an element of this DGParentedTree in an RSTTree.\n\n        If ``node_id`` is given, this will return the position of the subtree\n        with that node ID. Otherwise, the position of the root of this\n        DGParentedTree in the given RSTTree is returned.\n        \"\"\"\n        if node_id is None:\n            node_id = self.root_id\n\n        if node_id in rst_tree.edu_set:\n            return rst_tree.edus.index(node_id)\n\n        return min(self.get_position(rst_tree, child_node_id)\n                   for child_node_id in rst_tree.child_dict[node_id])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a get request to the biomart service.", "response": "def get(self, **params):\n        \"\"\"Performs get request to the biomart service.\n\n        Args:\n            **params (dict of str: any): Arbitrary keyword arguments, which\n                are added as parameters to the get request to biomart.\n\n        Returns:\n            requests.models.Response: Response from biomart for the request.\n\n        \"\"\"\n        if self._use_cache:\n            r = requests.get(self.url, params=params)\n        else:\n            with requests_cache.disabled():\n                r = requests.get(self.url, params=params)\n        r.raise_for_status()\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromstring(cls, ptb_string, namespace='ptb', precedence=False,\n                  ignore_traces=True):\n        \"\"\"create a PTBDocumentGraph from a string containing PTB parses.\"\"\"\n        temp = tempfile.NamedTemporaryFile(delete=False)\n        temp.write(ptb_string)\n        temp.close()\n        ptb_docgraph = cls(ptb_filepath=temp.name, namespace=namespace,\n                           precedence=precedence, ignore_traces=ignore_traces)\n        os.unlink(temp.name)\n        return ptb_docgraph", "response": "create a PTBDocumentGraph from a string containing PTB parses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_sentence(self, sentence, ignore_traces=True):\n        self.sentences.append(self._node_id)\n        # add edge from document root to sentence root\n        self.add_edge(self.root, self._node_id, edge_type=dg.EdgeTypes.dominance_relation)\n        self._parse_sentencetree(sentence, ignore_traces=ignore_traces)\n        self._node_id += 1", "response": "add a sentence from the input document to the document graph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a sentence Tree into this document graph", "response": "def _parse_sentencetree(self, tree, parent_node_id=None, ignore_traces=True):\n        \"\"\"parse a sentence Tree into this document graph\"\"\"\n        def get_nodelabel(node):\n            if isinstance(node, nltk.tree.Tree):\n                return node.label()\n            elif isinstance(node, unicode):\n                return node.encode('utf-8')\n            else:\n                raise ValueError(\"Unexpected node type: {0}, {1}\".format(type(node), node))\n\n        root_node_id = self._node_id\n        self.node[root_node_id]['label'] = get_nodelabel(tree)\n\n        for subtree in tree:\n            self._node_id += 1\n            node_label = get_nodelabel(subtree)\n            # unescape the node label, if necessary\n            node_label = PTB_BRACKET_UNESCAPE.get(node_label, node_label)\n            # TODO: refactor this, so we don't need to query this all the time\n            if ignore_traces and node_label == '-NONE-': # ignore tokens annotated for traces\n                continue\n            if isinstance(subtree, nltk.tree.Tree):\n                if len(subtree) > 1: # subtree is a syntactic category\n                    node_attrs = {'label': node_label,\n                                  self.ns+':cat': node_label}\n                    layers = {self.ns, self.ns+':syntax'}\n                else:  # subtree represents a token and its POS tag\n                    node_attrs = {'label': node_label}\n                    layers = {self.ns}\n\n                edge_type = dg.EdgeTypes.dominance_relation\n                self.add_node(self._node_id, layers=layers,\n                              attr_dict=node_attrs)\n                self.add_edge(root_node_id, self._node_id, edge_type=edge_type)\n\n            else: # isinstance(subtree, unicode); subtree is a token\n                # we'll have to modify the parent node of a token, since\n                # in NLTK Trees, even a leaf node (with its POS tag) is\n                # represented as a Tree (an iterator over a single unicode\n                # string), e.g. ``Tree('NNS', ['prices'])``\n                pos_tag = self.node[parent_node_id]['label']\n                token_attrs = {\n                    'label': node_label, self.ns+':token': node_label,\n                    self.ns+':pos': pos_tag}\n                self.node[parent_node_id].update(token_attrs)\n                self.tokens.append(parent_node_id)\n\n            if isinstance(subtree, nltk.tree.Tree):\n                self._parse_sentencetree(subtree, parent_node_id=self._node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_class_instance(element, element_id, doc_id):\n    xsi_type = get_xsi_type(element)\n    element_class = XSI_TYPE_CLASSES[xsi_type]\n    return element_class.from_etree(element)", "response": "Given an XML element returns a corresponding SaltElement class instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subtype_ids(elements, subtype):\n    return [i for (i, element) in enumerate(elements)\n            if isinstance(element, subtype)]", "response": "returns the ids of all elements of a certain type"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tree_statistics(tree):\n    all_elements = tree.findall('//')\n    tag_counter = defaultdict(int)\n    for element in all_elements:\n        tag_counter[element.tag] += 1\n    for (tag, counts) in tag_counter.items():\n        print \"{0}: {1}\".format(tag, counts)", "response": "Prints the types and counts of elements present in a SaltDocument tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef abslistdir(directory):\n    abs_dir = os.path.abspath(directory)\n    filenames = os.listdir(abs_dir)\n    return [os.path.join(abs_dir, filename) for filename in filenames]", "response": "returns a list of absolute filepaths for all files found in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting all elements of type element_type from the _ElementTree object tree and adds them to the corresponding SaltDocument attributes i. e. self. nodes and self. edges and self. layers.", "response": "def _extract_elements(self, tree, element_type):\n        \"\"\"\n        extracts all element of type `element_type from the `_ElementTree`\n        representation of a SaltXML document and adds them to the corresponding\n        `SaltDocument` attributes, i.e. `self.nodes`, `self.edges` and\n        `self.layers`.\n\n        Parameters\n        ----------\n        tree : lxml.etree._ElementTree\n            an ElementTree that represents a complete SaltXML document\n        element_type : str\n            the tag name of a SaltXML element, e.g. `nodes` or `edges`\n        \"\"\"\n        # creates a new attribute, e.g. 'self.nodes' and assigns it an\n        # empty list\n        setattr(self, element_type, [])\n        etree_elements = get_elements(tree, element_type)\n        for i, etree_element in enumerate(etree_elements):\n            # create an instance of an element class (e.g. TokenNode)\n            salt_element = create_class_instance(etree_element, i, self.doc_id)\n            # and add it to the corresponding element type list,\n            # e.g. 'self.nodes'\n            getattr(self, element_type).append(salt_element)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the string representation of a sentence", "response": "def print_sentence(self, sent_index):\n        \"\"\"\n        returns the string representation of a sentence.\n\n        :param sent_index: the index of a sentence (from ``self.sentences``)\n        :type sent_index: int\n        :return: the sentence string\n        :rtype: str\n        \"\"\"\n        tokens = [self.print_token(tok_idx)\n                  for tok_idx in self.sentences[sent_index]]\n        return ' '.join(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the string representation of a token node.", "response": "def print_token(self, token_node_index):\n        \"\"\"returns the string representation of a token.\"\"\"\n        err_msg = \"The given node is not a token node.\"\n        assert isinstance(self.nodes[token_node_index], TokenNode), err_msg\n        onset = self.nodes[token_node_index].onset\n        offset = self.nodes[token_node_index].offset\n        return self.text[onset:offset]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting the mode of a given stream object.", "response": "def detect_stream_mode(stream):\n    '''\n        detect_stream_mode - Detect the mode on a given stream\n\n            @param stream <object> - A stream object\n\n            If \"mode\" is present, that will be used.\n\n        @return <type> - \"Bytes\" type or \"str\" type\n    '''\n    # If \"Mode\" is present, pull from that\n    if hasattr(stream, 'mode'):\n        if 'b' in stream.mode:\n            return bytes\n        elif 't' in stream.mode:\n            return str\n\n    # Read a zero-length string off the device \n    if hasattr(stream, 'read'):\n        zeroStr = stream.read(0)\n        if type(zeroStr) is str:\n            return str\n        return bytes\n    elif hasattr(stream, 'recv'):\n        zeroStr = stream.recv(0)\n        if type(zeroStr) is str:\n            return str\n        return bytes\n\n    # Cannot figure it out, assume bytes.\n    return bytes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gen_data_files(src_dir):\n    fpaths = []\n    base = os.path.dirname(src_dir)\n    for root, dir, files in os.walk(src_dir):\n        if len(files) != 0:\n            for f in files:\n                fpaths.append(os.path.relpath(os.path.join(root, f), base))\n    return fpaths", "response": "Generates a list of files contained in the given directory and its\n    subdirectories in the format required by the package_data parameter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node2freqt(docgraph, node_id, child_str='', include_pos=False,\n               escape_func=FREQT_ESCAPE_FUNC):\n    \"\"\"convert a docgraph node into a FREQT string.\"\"\"\n    node_attrs = docgraph.node[node_id]\n    if istoken(docgraph, node_id):\n        token_str = escape_func(node_attrs[docgraph.ns+':token'])\n        if include_pos:\n            pos_str = escape_func(node_attrs.get(docgraph.ns+':pos', ''))\n            return u\"({pos}({token}){child})\".format(\n                pos=pos_str, token=token_str, child=child_str)\n        else:\n            return u\"({token}{child})\".format(token=token_str, child=child_str)\n\n    else:  # node is not a token\n        label_str=escape_func(node_attrs.get('label', node_id))\n        return u\"({label}{child})\".format(label=label_str, child=child_str)", "response": "convert a docgraph node into a FREQT string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sentence2freqt(docgraph, root, successors=None, include_pos=False,\n                   escape_func=FREQT_ESCAPE_FUNC):\n    \"\"\"convert a sentence subgraph into a FREQT string.\"\"\"\n    if successors is None:\n        successors = sorted_bfs_successors(docgraph, root)\n\n    if root in successors:  # root node has children / subgraphs\n        embed_str = u\"\".join(sentence2freqt(docgraph, child, successors,\n                                            include_pos=include_pos,\n                                            escape_func=escape_func)\n                             for child in successors[root])\n        return node2freqt(\n            docgraph, root, embed_str, include_pos=include_pos,\n            escape_func=escape_func)\n    else:  # root node has no children / subgraphs\n        return node2freqt(docgraph, root, include_pos=include_pos,\n                          escape_func=escape_func)", "response": "convert a sentence subgraph into a FREQT string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a docgraph into a FREQT string.", "response": "def docgraph2freqt(docgraph, root=None, include_pos=False,\n                   escape_func=FREQT_ESCAPE_FUNC):\n    \"\"\"convert a docgraph into a FREQT string.\"\"\"\n    if root is None:\n        return u\"\\n\".join(\n            sentence2freqt(docgraph, sentence, include_pos=include_pos,\n                           escape_func=escape_func)\n            for sentence in docgraph.sentences)\n    else:\n        return sentence2freqt(docgraph, root, include_pos=include_pos,\n                              escape_func=escape_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_freqt(docgraph, output_filepath, include_pos=False):\n    path_to_file = os.path.dirname(output_filepath)\n    if not os.path.isdir(path_to_file):\n        create_dir(path_to_file)\n    with codecs.open(output_filepath, 'w', 'utf-8') as output_file:\n        for sentence in docgraph.sentences:\n            output_file.write(docgraph2freqt(docgraph, sentence,\n                              include_pos=include_pos)+'\\n')", "response": "convert a docgraph into a FREQT input file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef options(self, parser, env):\n        Plugin.options(self, parser, env)\n        parser.add_option('--xcoverage-file', action='store',\n                          default=env.get('NOSE_XCOVER_FILE', 'coverage.xml'),\n                          dest='xcoverage_file',\n                          metavar=\"FILE\",\n                          help='Path to xml coverage report.'\n                          'Default is coverage.xml in the working directory. '\n                          '[NOSE_XCOVERAGE_FILE]')\n        parser.add_option('--xcoverage-to-stdout', action='store',\n                          default=env.get('NOSE_XCOVER_TO_STDOUT', True),\n                          dest='xcoverage_to_stdout',\n                          help='Print coverage information to stdout.'\n                          'Default is True (output coverage information to stdout). '\n                          '[NOSE_XCOVER_TO_STDOUT]')", "response": "Add options to command line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreport code coverage for this XCoverage instance.", "response": "def report(self, stream):\n        \"\"\"\n        Output code coverage report.\n        \"\"\"\n        if not self.xcoverageToStdout:\n            # This will create a false stream where output will be ignored\n            stream = StringIO()\n            \n        super(XCoverage, self).report(stream)\n        if not hasattr(self, 'coverInstance'):\n            # nose coverage plugin 1.0 and earlier\n            import coverage\n            self.coverInstance = coverage._the_coverage\n\n        modules = [module\n                    for name, module in sys.modules.items()\n                    if self.wantModuleCoverage(name, module)]\n        log.debug(\"Coverage report will cover modules: %s\", modules)\n        morfs = [m.__file__ for m in modules if hasattr(m, '__file__')]\n        self.coverInstance.xml_report(morfs, outfile=self.xcoverageFile)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of all the annotation features of an element", "response": "def get_annotations(element):\n    \"\"\"\n    returns a dictionary of all the annotation features of an element,\n    e.g. tiger.pos = ART or coref.type = anaphoric.\n    \"\"\"\n    from labels import get_annotation\n    annotations = {}\n    for label in element.getchildren():\n        if get_xsi_type(label) == 'saltCore:SAnnotation':\n            annotations.update([get_annotation(label)])\n    return annotations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_layer_ids(element):\n    layers = []\n    if element.xpath('@layers'):\n        layers_string = element.xpath('@layers')[0]\n        for layer_string in layers_string.split():\n            _prefix, layer = layer_string.split('.')  # '//@layers.0' -> '0'\n            layers.append(int(layer))\n    return layers", "response": "Returns the layer ids from a SaltElement."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef element_statistics(tree, element_type):\n    elements = get_elements(tree, element_type)\n    stats = defaultdict(int)\n    for i, element in enumerate(elements):\n        stats[get_xsi_type(element)] += 1\n    for (etype, count) in stats.items():\n        print \"{0}: {1}\".format(etype, count)", "response": "Prints the names and counts of all elements present in an analyzed element tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_etree(cls, etree_element):\n        label_elements = get_subelements(etree_element, 'labels')\n        labels = [SaltLabel.from_etree(elem) for elem in label_elements]\n        return cls(name=get_element_name(etree_element),\n                   element_id=get_graph_element_id(etree_element),\n                   xsi_type=get_xsi_type(etree_element),\n                   labels=labels,\n                   xml=etree_element)", "response": "Creates a SaltElement from an etree. _Element representing\n        an element in a SaltXMI file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grant_sudo_privileges(request, max_age=COOKIE_AGE):\n    user = getattr(request, 'user', None)\n\n    # If there's not a user on the request, just noop\n    if user is None:\n        return\n\n    if not user.is_authenticated():\n        raise ValueError('User needs to be logged in to be elevated to sudo')\n\n    # Token doesn't need to be unique,\n    # just needs to be unpredictable and match the cookie and the session\n    token = get_random_string()\n    request.session[COOKIE_NAME] = token\n    request._sudo = True\n    request._sudo_token = token\n    request._sudo_max_age = max_age\n    return token", "response": "Assign a random token to the user s session and that they have elevated permissions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrevokes sudo privileges from a request explicitly", "response": "def revoke_sudo_privileges(request):\n    \"\"\"\n    Revoke sudo privileges from a request explicitly\n    \"\"\"\n    request._sudo = False\n    if COOKIE_NAME in request.session:\n        del request.session[COOKIE_NAME]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a request is allowed to perform sudo actions", "response": "def has_sudo_privileges(request):\n    \"\"\"\n    Check if a request is allowed to perform sudo actions\n    \"\"\"\n    if getattr(request, '_sudo', None) is None:\n        try:\n            request._sudo = (\n                request.user.is_authenticated() and\n                constant_time_compare(\n                    request.get_signed_cookie(COOKIE_NAME, salt=COOKIE_SALT, max_age=COOKIE_AGE),\n                    request.session[COOKIE_NAME]\n                )\n            )\n        except (KeyError, BadSignature):\n            request._sudo = False\n    return request._sudo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the given url is a safe redirection.", "response": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    if six.PY2:  # pragma: nocover\n        try:\n            url = force_text(url)\n        except UnicodeDecodeError:\n            return False\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hildatree2dgparentedtree(self):\n        def transform(hilda_tree):\n            \"\"\"Transform a HILDA parse tree into a more conventional parse tree.\n\n            The input tree::\n\n                                  Contrast[S][N]\n                         _______________|______________\n                  Although they                  they accepted\n                did n't like it ,                 the offer .\n\n            is converted into::\n\n                                  Contrast\n                         ____________|___________\n                        S                        N\n                        |                        |\n                  Although they            they accepted\n                did n't like it ,           the offer .\n            \"\"\"\n            if isinstance(hilda_tree, basestring) or not hasattr(hilda_tree, 'label'):\n                return hilda_tree\n            assert len(hilda_tree) == 2, \"We can only handle binary trees.\"\n\n            match = HILDA_REL_RE.match(hilda_tree.label())\n            assert match, \"Relation '{}' does not match regex '{}'\".format(hilda_tree.label(), HILDA_REL_RE)\n            relname, left_child_nuc, right_child_nuc = match.groups()\n            hilda_tree._label = relname\n\n            for i, child_nuclearity in enumerate([left_child_nuc, right_child_nuc]):\n                child = hilda_tree[i]\n                hilda_tree[i] = Tree(child_nuclearity, [transform(child)])\n            return hilda_tree\n\n        tree = transform(self.hildafile_tree)\n        return DGParentedTree.convert(tree)", "response": "Convert the HILDA s format into a conventional binary tree which can be easily converted into output formats like RS3."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting of available marts.", "response": "def marts(self):\n        \"\"\"List of available marts.\"\"\"\n        if self._marts is None:\n            self._marts = self._fetch_marts()\n        return self._marts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting available marts in a readable DataFrame format.", "response": "def list_marts(self):\n        \"\"\"Lists available marts in a readable DataFrame format.\n\n        Returns:\n            pd.DataFrame: Frame listing available marts.\n        \"\"\"\n\n        def _row_gen(attributes):\n            for attr in attributes.values():\n                yield (attr.name, attr.display_name)\n\n        return pd.DataFrame.from_records(\n            _row_gen(self.marts), columns=['name', 'display_name'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator that yields all nodes that dominate one or more RST relations in the given document graph.", "response": "def get_rst_relation_root_nodes(docgraph, data=True, rst_namespace='rst'):\n    \"\"\"\n    yield all nodes that dominate one or more RST relations in the given\n    document graph (in no particular order).\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph which contains RST annotations\n    data : bool\n        If True (default), yields (node ID, relation name, list of tokens)\n        tuples. If False, yields just node IDs.\n    rst_namespace : str\n        The namespace that the RST annotations use (default: rst)\n\n    Yields\n    ------\n    relations : str or (str, str, list of str) tuples\n        If data=False, this will just yield node IDs of the nodes that\n        directly dominate an RST relation. If data=True, this yields\n        tuples of the form: (node ID, relation name, list of tokens that this\n        relation spans).\n    \"\"\"\n    rel_attr = rst_namespace+':rel_name'\n    for node_id, node_attrs in docgraph.nodes_iter(data=True):\n        if rel_attr in node_attrs and node_attrs[rel_attr] != 'span':\n            yield (node_id, node_attrs[rel_attr], get_span(docgraph, node_id)) \\\n                if data else (node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_rst_relations(docgraph):\n    rst_relations = defaultdict(lambda: defaultdict(str))\n\n    for dom_node, _, _ in get_rst_relation_root_nodes(docgraph):\n        neighbors = \\\n            list(select_neighbors_by_layer(docgraph, dom_node,\n                                           layer={'rst:segment', 'rst:group'}))\n        multinuc_nuc_count = 1\n        directly_dominated_tokens = sorted([node for node in docgraph.neighbors(dom_node)\n                                            if istoken(docgraph, node)], key=natural_sort_key)\n        if directly_dominated_tokens:\n            rst_relations[dom_node]['tokens'] = directly_dominated_tokens\n\n        for neighbor in neighbors:\n            for edge in docgraph[dom_node][neighbor]:  # multidigraph\n                edge_attrs = docgraph[dom_node][neighbor][edge]\n\n                if edge_attrs['edge_type'] == EdgeTypes.spanning_relation:\n                    # a span always signifies the nucleus of a relation\n                    # there can be only one\n                    rst_relations[dom_node]['nucleus'] = (neighbor, get_span(docgraph, neighbor))\n                elif edge_attrs['rst:rel_type'] == 'rst':\n                    # a segment/group nucleus can dominate multiple satellites\n                    # (in different RST relations)\n                    satellite = (neighbor, edge_attrs['rst:rel_name'], get_span(docgraph, neighbor))\n                    if 'satellites' in rst_relations[dom_node]:\n                        rst_relations[dom_node]['satellites'].append(satellite)\n                    else:\n                        rst_relations[dom_node]['satellites'] = [satellite]\n                elif edge_attrs['rst:rel_type'] == 'multinuc':\n                    nucleus = (neighbor, edge_attrs['rst:rel_name'], get_span(docgraph, neighbor))\n                    if 'multinuc' in rst_relations[dom_node]:\n                        rst_relations[dom_node]['multinuc'].append(nucleus)\n                    else:\n                        rst_relations[dom_node]['multinuc'] = [nucleus]\n                    multinuc_nuc_count += 1\n                else:\n                    raise NotImplementedError(\"unknown type of RST segment domination\")\n    return rst_relations", "response": "Returns a dictionary with RST relations describing the RST relations in the document graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of 5 - tuples describing each RST span in the document graph.", "response": "def get_rst_spans(rst_graph):\n    \"\"\"\n    Returns a list of 5-tuples describing each RST span (i.e. the nucleus\n    or satellite of a relation) in the document. (This function is meant for\n    people who prefer to work with R / DataFrames / CSV files instead of\n    graphs.)\n\n    Parameters\n    ----------\n    docgraph : DiscourseDocumentGraph\n        a document graph which contains RST annotations\n\n    Returns\n    -------\n    all_spans : list of (str, str, str, int, int)\n        each list element represents an RST span (i.e. the nucleus or satellite)\n        as a 5-tuple\n        (relation string, span type, relation type, token onset, token offset).\n        In the example ('rst:16-rst:2', 'N', 'evaluation-s', 9, 24), the\n        relation string 'rst:16-rst:2' consists of two parts, the relation root\n        node ID and the node ID of its nucleus (span type 'N').\n        In the example ('rst:16-rst:4-rst:3', 'N1', 'list', 20, 24), the\n        relation string consists of 3 parts, the relation root\n        node ID and the node IDs of its nucleii (span type 'N1', 'N2').\n\n    Examples\n    --------\n        [('rst:16-rst:4-rst:3', 'N1', 'list', 20, 24),\n        ('rst:16-rst:4-rst:3', 'N2', 'list', 9, 19),\n        ('rst:16-rst:2', 'N', 'evaluation-s', 9, 24),\n        ('rst:16-rst:2', 'S', 'evaluation-s', 4, 8)]\n    \"\"\"\n    token_map = TokenMapper(rst_graph).id2index\n    rst_relations = get_rst_relations(rst_graph)\n    all_spans = []\n    for dom_node in rst_relations:\n        if 'multinuc' in rst_relations[dom_node]:\n            nuc_count = 1\n            multinuc_start, multinuc_end = sys.maxint, 0\n            multinuc_spans = rst_relations[dom_node]['multinuc']\n            multinuc_rel_id = \"{0}-{1}\".format(\n                dom_node, '-'.join(target for target, _rel, _toks in multinuc_spans))\n\n            for _, relname, toks in multinuc_spans:\n                nuc_start, nuc_end = get_segment_token_offsets(toks, token_map)\n                multinuc_span = (multinuc_rel_id, \"N{}\".format(nuc_count),\n                                 relname, nuc_start, nuc_end)\n                all_spans.append(multinuc_span)\n                nuc_count += 1\n                # determine the token offsets of the whole multinuc relation iteratively\n                if nuc_start < multinuc_start:\n                    multinuc_start = nuc_start\n                if nuc_end > multinuc_end:\n                    multinuc_end = nuc_end\n\n        if 'satellites' in rst_relations[dom_node]:\n            # find the nucleus\n            if 'nucleus' in rst_relations[dom_node]:\n                nuc_id, nuc_toks = rst_relations[dom_node]['nucleus']\n                nuc_start, nuc_end = get_segment_token_offsets(nuc_toks, token_map)\n            elif 'multinuc' in rst_relations[dom_node]:\n                nuc_id = dom_node # multinuc as a whole is the nucleus\n                nuc_start, nuc_end = multinuc_start, multinuc_end\n            elif 'tokens' in rst_relations[dom_node]:\n                nuc_id = dom_node # dominating segment node directly dominates these tokens\n                nuc_start, nuc_end = get_segment_token_offsets(\n                    rst_relations[dom_node]['tokens'], token_map)\n            else:\n                raise ValueError(\n                    \"Can't find a nucleus for these satellites: {}\".format(\n                        rst_relations[dom_node]['satellites']))\n\n            sat_spans = rst_relations[dom_node]['satellites']\n            for satellite, relname, sat_toks in sat_spans:\n                sat_start, sat_end = get_segment_token_offsets(sat_toks, token_map)\n                nucleus_span = (\"{0}-{1}\".format(nuc_id, satellite), 'N',\n                                relname, nuc_start, nuc_end)\n                all_spans.append(nucleus_span)\n                satellite_span = (\"{0}-{1}\".format(nuc_id, satellite), 'S',\n                                  relname, sat_start, sat_end)\n                all_spans.append(satellite_span)\n    return all_spans"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __rst2graph(self, rs3_xml_tree):\n        doc_root = rs3_xml_tree.getroot()\n\n        for segment in doc_root.iter('segment'):\n            self.__add_segment(segment)\n        for group in doc_root.iter('group'):\n            self.__add_group(group)", "response": "Reads an RST tree and adds all segments groups and relationships that hold between them and the corresponding nodes in the RST tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __add_segment(self, segment):\n        segment_id = self.ns+':'+segment.attrib['id']\n        self.segments.append(segment_id)\n        segment_type, parent_segment_type = self.__get_segment_types(segment)\n        segment_text = sanitize_string(segment.text)\n        segment_label = get_segment_label(\n            segment, segment_type, segment_text, self.ns, self.tokenized)\n\n        self.add_node(\n            segment_id, layers={self.ns, self.ns+':segment'},\n            attr_dict={'label': segment_label,\n                       self.ns+':text' : segment_text,\n                       self.ns+':segment_type': segment_type})\n\n        # store RST segment in list of EDUs\n        self.edus.append(segment_id)\n\n        if 'parent' in segment.attrib:\n            self.__add_parent_relation(segment, segment_id, segment_type,\n                                       parent_segment_type)", "response": "add attributes to segment nodes and edges to other segments and groups"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __add_group(self, group):\n        group_id = self.ns+':'+group.attrib['id']\n        group_type = group.attrib['type']  # 'span' or 'multinuc'\n        group_layers = {self.ns, self.ns+':group'}\n        segment_type, parent_segment_type = self.__get_segment_types(group)\n\n        group_attrs = \\\n            {self.ns+':group_type': group_type,\n             'label': '{0}:group:{1}:{2}'.format(self.ns, group_type,\n                                                 group.attrib['id'])}\n\n        if group_id not in self:  # group node doesn't exist, yet\n            group_attrs[self.ns+':segment_type'] = segment_type\n            self.add_node(group_id, layers=group_layers,\n                          attr_dict=group_attrs)\n        else: # group node does already exist\n            if segment_type != 'span':  # if it is an RST relation\n                group_attrs[self.ns+':segment_type'] = segment_type\n            else: # segment_type == 'span'\n                # if the group already has a segment type, we won't overwrite\n                # it, since 'span' is not very informative\n                if not self.ns+':segment_type' in self.node[group_id]:\n                    group_attrs[self.ns+':segment_type'] = segment_type\n            self.node[group_id].update(group_attrs,\n                                       layers={self.ns, self.ns+':group'})\n\n        if 'parent' not in group.attrib:  # mark group as RST root node\n            # each discourse docgraphs has a default root node, but we will\n            # overwrite it here\n            old_root_id = self.root\n            self.root = group_id\n            # workaround for #141: the layers attribute is append-only,\n            # but here we're updating it as a part of the attribute dict\n            #\n            # root segment type: always span\n            root_attrs = {'layers': {self.ns, self.ns+':root'},\n                          self.ns+':segment_type': 'span'}\n            self.node[group_id].update(root_attrs)\n            # copy metadata from old root node\n            self.node[group_id]['metadata'] = self.node[old_root_id]['metadata']\n            # finally, remove the old root node\n            self.remove_node(old_root_id)\n        else:  # the group node is dominated by another group or segment\n            self.__add_parent_relation(group, group_id, segment_type,\n                                       parent_segment_type)", "response": "Add attributes to the group nodes and in - edges from other\n        groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a parent relation to the current element.", "response": "def __add_parent_relation(self, element, element_id, segment_type, parent_segment_type):\n        \"\"\"\n        - add parent node (if not there, yet) w/ segment type\n        - add edge from parent node to current element\n        \"\"\"\n        relname = element.attrib['relname'] # name of RST relation or 'span'\n        reltype = self.relations.get(relname, '') # 'span', 'multinuc' or ''\n\n        parent_id = self.ns+':'+element.attrib['parent']\n\n        if parent_segment_type:\n            parent_attrs = {self.ns+':rel_name': relname,\n                            self.ns+':segment_type': parent_segment_type}\n        else: # e.g. if the parent is a root node of a multinuc, we don't\n              # know what its segment type is\n            parent_attrs = {self.ns+':rel_name': relname}\n\n        if parent_id not in self:\n            self.add_node(parent_id, layers={self.ns}, attr_dict=parent_attrs)\n        else:\n            if segment_type != 'span':\n                self.node[parent_id].update(parent_attrs)\n\n        if segment_type == 'span':\n            edge_type = EdgeTypes.spanning_relation\n        else:\n            edge_type = EdgeTypes.dominance_relation\n\n        rel_attrs = {self.ns+':rel_name': relname, self.ns+':rel_type': reltype,\n                     'label': self.ns+':'+relname}\n        self.add_edge(parent_id, element_id, layers={self.ns},\n                      attr_dict=rel_attrs, edge_type=edge_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a segment or group element returns its segment type and the segment type of its parent.", "response": "def __get_segment_types(self, element):\n        \"\"\"\n        given a <segment> or <group> element, returns its segment type and the\n        segment type of its parent (i.e. its dominating node)\n\n        Parameters\n        ----------\n        element : ??? etree Element\n\n        Returns\n        -------\n        segment_type : str\n            'nucleus', 'satellite' or 'isolated' (unconnected segment, e.g. a\n            news headline) or 'span' (iff the segment type is currently\n            unknown -- i.e. ``relname`` is ``span``)\n        parent_segment_type : str or None\n            'nucleus', 'satellite' or None (e.g. for the root group node)\n        \"\"\"\n        if not 'parent' in element.attrib:\n            if element.tag == 'segment':\n                segment_type = 'isolated'\n                parent_segment_type = None\n            else:  # element.tag == 'group'\n                segment_type = 'span'\n                parent_segment_type = None\n            return segment_type, parent_segment_type\n\n        # ``relname`` either contains the name of an RST relation or\n        # the string ``span`` (iff the segment is dominated by a span\n        # node -- a horizontal line spanning one or more segments/groups\n        # in an RST diagram). ``relname`` is '', if the segment is\n        # unconnected.\n        relname = element.attrib.get('relname', '')\n        # we look up, if ``relname`` represents a regular, binary RST\n        # relation or a multinucular relation. ``reltype`` is '',\n        # if ``relname`` is ``span`` (i.e. a span isn't an RST relation).\n        reltype = self.relations.get(relname, '')\n\n        if reltype == 'rst':\n            segment_type = 'satellite'\n            parent_segment_type = 'nucleus'\n        elif reltype == 'multinuc':\n            segment_type = 'nucleus'\n            parent_segment_type = None # we don't know it's type, yet\n        else:  # reltype == ''\n            # the segment is of unknown type, it is dominated by\n            # a span group node\n            segment_type = 'span'\n            parent_segment_type = 'span'\n        return segment_type, parent_segment_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __tokenize_segments(self):\n        for seg_node_id in self.segments:\n            segment_toks = self.node[seg_node_id][self.ns+':text'].split()\n            for i, tok in enumerate(segment_toks):\n                tok_node_id = '{0}:{1}_{2}'.format(self.ns, seg_node_id, i)\n                self.add_node(tok_node_id, layers={self.ns, self.ns+':token'},\n                              attr_dict={self.ns+':token': tok, 'label': tok})\n                self.tokens.append(tok_node_id)\n                self.add_edge(seg_node_id, tok_node_id,\n                              layers={'rst', 'rst:token'},\n                              edge_type=EdgeTypes.spanning_relation)", "response": "Tokenizes every segment in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_theme(request):\n    next = request.POST.get('next', request.GET.get('next'))\n\n    if not is_safe_url(url=next, host=request.get_host()):\n        next = request.META.get('HTTP_REFERER')\n\n        if not is_safe_url(url=next, host=request.get_host()):\n            next = '/'\n\n    response = http.HttpResponseRedirect(next)\n\n    if request.method == 'POST':\n        theme = request.POST.get('theme', None)\n\n        if theme:\n            if hasattr(request, 'session'):\n                request.session['DJANGO_BOOTSTRAP_UI_THEME'] = theme\n            else:\n                response.set_cookie('DJANGO_BOOTSTRAP_UI_THEME', theme)\n\n    return response", "response": "Redirect to a given url while setting the chosen theme in the session or cookie."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_ui(self, path='hgwebdir.config'):\n    #propagated from mercurial documentation\n    sections = [\n                'alias',\n                'auth',\n                'decode/encode',\n                'defaults',\n                'diff',\n                'email',\n                'extensions',\n                'format',\n                'merge-patterns',\n                'merge-tools',\n                'hooks',\n                'http_proxy',\n                'smtp',\n                'patch',\n                'paths',\n                'profiling',\n                'server',\n                'trusted',\n                'ui',\n                'web',\n                ]\n\n    repos = path\n    baseui = ui.ui()\n    cfg = config.config()\n    cfg.read(repos)\n    self.paths = cfg.items('paths')\n    self.base_path = self.paths[0][1].replace('*', '')\n    self.check_repo_dir(self.paths)\n    self.set_statics(cfg)\n\n    for section in sections:\n        for k, v in cfg.items(section):\n            baseui.setconfig(section, k, v)\n\n    return baseui", "response": "A funcion that will read python rc files and make an ui from read options"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning modified added removed deleted files for current changeset", "response": "def status(self):\n        \"\"\"\n        Returns modified, added, removed, deleted files for current changeset\n        \"\"\"\n        return self.repository._repo.status(self._ctx.p1().node(),\n                                            self._ctx.node())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parents(self):\n        return [self.repository.get_changeset(parent.rev())\n                for parent in self._ctx.parents() if parent.rev() >= 0]", "response": "Returns a list of parents changesets."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of children changesets.", "response": "def children(self):\n        \"\"\"\n        Returns list of children changesets.\n        \"\"\"\n        return [self.repository.get_changeset(child.rev())\n                for child in self._ctx.children() if child.rev() >= 0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fix_path(self, path):\n        if path.endswith('/'):\n            path = path.rstrip('/')\n\n        return safe_str(path)", "response": "Fixes the path to be a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of Changesets for a given file at given path as reversed list of Changesets objects for which file at given path has been modified.", "response": "def get_file_history(self, path, limit=None):\n        \"\"\"\n        Returns history of file as reversed list of ``Changeset`` objects for\n        which file at given ``path`` has been modified.\n        \"\"\"\n        fctx = self._get_filectx(path)\n        hist = []\n        cnt = 0\n        for cs in reversed([x for x in fctx.filelog()]):\n            cnt += 1\n            hist.append(hex(fctx.filectx(cs).node()))\n            if limit and cnt == limit:\n                break\n\n        return [self.repository.get_changeset(node) for node in hist]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator of four element tuples withwith lineno sha changeset lazy loader and line", "response": "def get_file_annotate(self, path):\n        \"\"\"\n        Returns a generator of four element tuples with\n            lineno, sha, changeset lazy loader and line\n        \"\"\"\n\n        fctx = self._get_filectx(path)\n        for i, annotate_data in enumerate(fctx.annotate()):\n            ln_no = i + 1\n            sha = hex(annotate_data[0].node())\n            yield (ln_no, sha, lambda: self.repository.get_changeset(sha), annotate_data[1],)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_archive(self, stream=None, kind='tgz', prefix=None,\n                     subrepos=False):\n        \"\"\"\n        Fills up given stream.\n\n        :param stream: file like object.\n        :param kind: one of following: ``zip``, ``tgz`` or ``tbz2``.\n            Default: ``tgz``.\n        :param prefix: name of root directory in archive.\n            Default is repository name and changeset's raw_id joined with dash\n            (``repo-tip.<KIND>``).\n        :param subrepos: include subrepos in this archive.\n\n        :raise ImproperArchiveTypeError: If given kind is wrong.\n        :raise VcsError: If given stream is None\n        \"\"\"\n\n        allowed_kinds = settings.ARCHIVE_SPECS.keys()\n        if kind not in allowed_kinds:\n            raise ImproperArchiveTypeError('Archive kind not supported use one'\n                'of %s', allowed_kinds)\n\n        if stream is None:\n            raise VCSError('You need to pass in a valid stream for filling'\n                           ' with archival data')\n\n        if prefix is None:\n            prefix = '%s-%s' % (self.repository.name, self.short_id)\n        elif prefix.startswith('/'):\n            raise VCSError(\"Prefix cannot start with leading slash\")\n        elif prefix.strip() == '':\n            raise VCSError(\"Prefix cannot be empty\")\n\n        archival.archive(self.repository._repo, stream, self.raw_id,\n                         kind, prefix=prefix, subrepos=subrepos)\n\n        if stream.closed and hasattr(stream, 'name'):\n            stream = open(stream.name, 'rb')\n        elif hasattr(stream, 'mode') and 'r' not in stream.mode:\n            stream = open(stream.name, 'rb')\n        else:\n            stream.seek(0)", "response": "Fill up archive with changeset s raw_id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_nodes(self, path):\n\n        if self._get_kind(path) != NodeKind.DIR:\n            raise ChangesetError(\"Directory does not exist for revision %s at \"\n                \" '%s'\" % (self.revision, path))\n        path = self._fix_path(path)\n\n        filenodes = [FileNode(f, changeset=self) for f in self._file_paths\n            if os.path.dirname(f) == path]\n        dirs = path == '' and '' or [d for d in self._dir_paths\n            if d and posixpath.dirname(d) == path]\n        dirnodes = [DirNode(d, changeset=self) for d in dirs\n            if os.path.dirname(d) == path]\n\n        als = self.repository.alias\n        for k, vals in self._extract_submodules().iteritems():\n            #vals = url,rev,type\n            loc = vals[0]\n            cs = vals[1]\n            dirnodes.append(SubModuleNode(k, url=loc, changeset=cs,\n                                          alias=als))\n        nodes = dirnodes + filenodes\n        # cache nodes\n        for node in nodes:\n            self.nodes[node.path] = node\n        nodes.sort()\n\n        return nodes", "response": "Returns a list of DirNode and FileNode objects representing the state of changeset at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Node object at the given path.", "response": "def get_node(self, path):\n        \"\"\"\n        Returns ``Node`` object from the given ``path``. If there is no node at\n        the given ``path``, ``ChangesetError`` would be raised.\n        \"\"\"\n\n        path = self._fix_path(path)\n\n        if not path in self.nodes:\n            if path in self._file_paths:\n                node = FileNode(path, changeset=self)\n            elif path in self._dir_paths or path in self._dir_paths:\n                if path == '':\n                    node = RootNode(changeset=self)\n                else:\n                    node = DirNode(path, changeset=self)\n            else:\n                raise NodeDoesNotExistError(\"There is no file nor directory \"\n                    \"at the given path: '%s' at revision %s\"\n                    % (path, self.short_id))\n            # cache node\n            self.nodes[path] = node\n        return self.nodes[path]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn lazily - set mode of the FileNode.", "response": "def mode(self):\n        \"\"\"\n        Returns lazily mode of the FileNode. If ``changeset`` is not set, would\n        use value given at initialization or 0100644 (default).\n        \"\"\"\n        if self.changeset:\n            mode = self.changeset.get_file_mode(self.path)\n        else:\n            mode = self._mode\n        return mode"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning lazily content of the FileNode.", "response": "def content(self):\n        \"\"\"\n        Returns lazily content of the FileNode. If possible, would try to\n        decode content from UTF-8.\n        \"\"\"\n        content = self._get_content()\n\n        if bool(content and '\\0' in content):\n            return content\n        return safe_unicode(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the mimetype of the file.", "response": "def get_mimetype(self):\n        \"\"\"\n        Mimetype is calculated based on the file's content. If ``_mimetype``\n        attribute is available, it will be returned (backends which store\n        mimetypes or can easily recognize them, should set this private\n        attribute to indicate that type should *NOT* be calculated).\n        \"\"\"\n        if hasattr(self, '_mimetype'):\n            if (isinstance(self._mimetype, (tuple, list,)) and\n                len(self._mimetype) == 2):\n                return self._mimetype\n            else:\n                raise NodeError('given _mimetype attribute must be an 2 '\n                               'element list or tuple')\n\n        mtype, encoding = mimetypes.guess_type(self.name)\n\n        if mtype is None:\n            if self.is_binary:\n                mtype = 'application/octet-stream'\n                encoding = None\n            else:\n                mtype = 'text/plain'\n                encoding = None\n        return mtype, encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lexer(self):\n\n        try:\n            lexer = lexers.guess_lexer_for_filename(self.name, self.content, stripnl=False)\n        except lexers.ClassNotFound:\n            lexer = lexers.TextLexer(stripnl=False)\n        # returns first alias\n        return lexer", "response": "Returns pygment s lexer class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef history(self):\n        if self.changeset is None:\n            raise NodeError('Unable to get changeset for this FileNode')\n        return self.changeset.get_file_history(self.path)", "response": "Returns a list of changeset for this file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef annotate(self):\n        if self.changeset is None:\n            raise NodeError('Unable to get changeset for this FileNode')\n        return self.changeset.get_file_annotate(self.path)", "response": "Returns a list of three element tuples with lineno changeset and line"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a node from within this particular DirNode so it is now allowed to fetch.", "response": "def get_node(self, path):\n        \"\"\"\n        Returns node from within this particular ``DirNode``, so it is now\n        allowed to fetch, i.e. node located at 'docs/api/index.rst' from node\n        'docs'. In order to access deeper nodes one must fetch nodes between\n        them first - this would work::\n\n           docs = root.get_node('docs')\n           docs.get_node('api').get_node('index.rst')\n\n        :param: path - relative to the current node\n\n        .. note::\n           To access lazily (as in example above) node have to be initialized\n           with related changeset object - without it node is out of\n           context and may know nothing about anything else than nearest\n           (located at same level) nodes.\n        \"\"\"\n        try:\n            path = path.rstrip('/')\n            if path == '':\n                raise NodeError(\"Cannot retrieve node without path\")\n            self.nodes  # access nodes first in order to set _nodes_dict\n            paths = path.split('/')\n            if len(paths) == 1:\n                if not self.is_root():\n                    path = '/'.join((self.path, paths[0]))\n                else:\n                    path = paths[0]\n                return self._nodes_dict[path]\n            elif len(paths) > 1:\n                if self.changeset is None:\n                    raise NodeError(\"Cannot access deeper \"\n                                    \"nodes without changeset\")\n                else:\n                    path1, path2 = paths[0], '/'.join(paths[1:])\n                    return self.get_node(path1).get_node(path2)\n            else:\n                raise KeyError\n        except KeyError:\n            raise NodeError(\"Node does not exist at %s\" % path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef name(self):\n        org = safe_unicode(self.path.rstrip('/').split('/')[-1])\n        return u'%s @ %s' % (org, self.changeset.short_id)", "response": "Returns the name of the node so only last part is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X, y, likelihood_args=()):\n        X, y = check_X_y(X, y)\n\n        # Batch magnification factor\n        N, _ = X.shape\n        self.B_ = X.shape[0] / self.batch_size\n        self.D_ = self.basis.get_dim(X)\n\n        # Pack data\n        likelihood_args = _reshape_likelihood_args(likelihood_args, N)\n        data = (X, y) + likelihood_args\n\n        # Pack params\n        params = [Parameter(WGTRND, Bound(), shape=(self.D_, self.K)),\n                  Parameter(COVRND, Positive(), shape=(self.D_, self.K)),\n                  self.basis.regularizer,\n                  self.likelihood.params,\n                  self.basis.params]\n\n        log.info(\"Optimising parameters...\")\n        self.__it = -self.nstarts  # Keeping track of iterations for logging\n        nsgd = structured_sgd(logtrick_sgd(sgd))\n        res = nsgd(self._elbo,\n                   params,\n                   data,\n                   eval_obj=True,\n                   maxiter=self.maxiter,\n                   updater=self.updater,\n                   batch_size=self.batch_size,\n                   random_state=self.random_,\n                   nstarts=self.nstarts\n                   )\n\n        # Unpack params\n        (self.weights_,\n         self.covariance_,\n         self.regularizer_,\n         self.like_hypers_,\n         self.basis_hypers_\n         ) = res.x\n\n        log.info(\"Finished! reg = {}, likelihood_hypers = {}, \"\n                 \"basis_hypers = {}, message: {}.\"\n                 .format(self.regularizer_,\n                         self.like_hypers_,\n                         self.basis_hypers_,\n                         res.message))\n\n        return self", "response": "r Fit a Bayesian generalized linear model to the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, X, nsamples=200, likelihood_args=()):\n        Ey, _ = self.predict_moments(X, nsamples, likelihood_args)\n\n        return Ey", "response": "Predict target values from Bayesian generalized linear regression."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_logpdf(self, X, y, nsamples=200, likelihood_args=()):\n        X, y = check_X_y(X, y)\n\n        # Get latent function samples\n        N = X.shape[0]\n        ps = np.empty((N, nsamples))\n        fsamples = self._sample_func(X, nsamples)\n\n        # Push samples though likelihood pdf\n        llargs = tuple(chain(atleast_list(self.like_hypers_), likelihood_args))\n        for i, f in enumerate(fsamples):\n            ps[:, i] = self.likelihood.loglike(y, f, *llargs)\n\n        # Average transformed samples (MC integration)\n        logp = ps.mean(axis=1)\n        logp_min = ps.min(axis=1)\n        logp_max = ps.max(axis=1)\n\n        return logp, logp_min, logp_max", "response": "r Predictive log - probability density function of a Bayesian GLM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict_cdf(self, X, quantile, nsamples=200, likelihood_args=()):\n        # Get latent function samples\n        N = X.shape[0]\n        ps = np.empty((N, nsamples))\n        fsamples = self._sample_func(X, nsamples)\n\n        # Push samples though likelihood cdf\n        cdfarg = tuple(chain(atleast_list(self.like_hypers_), likelihood_args))\n        for i, f in enumerate(fsamples):\n            ps[:, i] = self.likelihood.cdf(quantile, f, *cdfarg)\n\n        # Average transformed samples (MC integration)\n        p = ps.mean(axis=1)\n        p_min = ps.min(axis=1)\n        p_max = ps.max(axis=1)\n\n        return p, p_min, p_max", "response": "r Predictive cumulative density function of a Bayesian GLM."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the interval of the current state of the object.", "response": "def predict_interval(self, X, percentile, nsamples=200, likelihood_args=(),\n                         multiproc=True):\n        \"\"\"\n        Predictive percentile interval (upper and lower quantiles).\n\n        Parameters\n        ----------\n        X : ndarray\n            (N*,d) array query input dataset (N* samples, D dimensions).\n        percentile : float\n            The percentile confidence interval (e.g. 95%) to return.\n        nsamples : int, optional\n            Number of samples for sampling the predictive percentiles.\n        likelihood_args : sequence, optional\n            sequence of arguments to pass to the likelihood function. These are\n            non-learnable parameters. They can be scalars or arrays of length\n            N*.\n        multiproc : bool, optional\n            Use multiprocessing to paralellise this prediction computation.\n\n        Returns\n        -------\n        ql : ndarray\n            The lower end point of the interval with shape (N*,)\n        qu : ndarray\n            The upper end point of the interval with shape (N*,)\n        \"\"\"\n        N = X.shape[0]\n\n        # Generate latent function samples per observation (n in N)\n        fsamples = self._sample_func(X, nsamples, genaxis=0)\n\n        # Make sure likelihood_args is consistent with work\n        if len(likelihood_args) > 0:\n            likelihood_args = _reshape_likelihood_args(likelihood_args, N)\n\n        # Now create work for distrbuted workers\n        like_hypers = atleast_list(self.like_hypers_)\n        work = ((f[0], self.likelihood, like_hypers, f[1:], percentile)\n                for f in zip(fsamples, *likelihood_args))\n\n        # Distribute sampling and rootfinding\n        if multiproc:\n            pool = Pool()\n            res = pool.map(_star_rootfinding, work)\n            pool.close()\n            pool.join()\n        else:\n            res = [_rootfinding(*w) for w in work]\n\n        # Get results of work\n        ql, qu = zip(*res)\n        return np.array(ql), np.array(qu)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate samples from the posterior latent function mixtures of the GLM and the regularizer.", "response": "def _sample_func(self, X, nsamples, genaxis=1):\n        \"\"\"\n        Generate samples from the posterior latent function mixtures of the GLM\n        for query inputs, X*.\n\n        Parameters\n        ----------\n        X : ndarray\n            (N*, d) array query input dataset (N* samples, D dimensions).\n        nsamples : int\n            Number of samples for sampling the latent function.\n        genaxis : int\n            Axis to return samples from, i.e.\n            - ``genaxis=1`` will give you one sample at a time of f for ALL\n                observations (so it will iterate over nsamples).\n            - ``genaxis=0`` will give you all samples of f for ONE\n                observation at a time (so it will iterate through X*, row by\n                row)\n\n        Yields\n        ------\n        fsamples : ndarray\n            of shape (N*,) if ``genaxis=1`` with each call being a sample\n            from the mixture of latent functions over all N*. Or of shape\n            (nsamples,) if ``genaxis=0``, with each call being a all\n            samples for an observation, n in N*.\n        \"\"\"\n        check_is_fitted(self, ['weights_', 'covariance_', 'basis_hypers_',\n                               'like_hypers_', 'regularizer_'])\n        X = check_array(X)\n        D, K = self.weights_.shape\n\n        # Generate weight samples from all mixture components\n        k = self.random_.randint(0, K, size=(nsamples,))\n        w = self.weights_[:, k] + self.random_.randn(D, nsamples) \\\n            * np.sqrt(self.covariance_[:, k])\n\n        # Do this here for *massive* speed improvements\n        Phi = self.basis.transform(X, *atleast_list(self.basis_hypers_))\n\n        # Now generate latent functions samples either colwise or rowwise\n        if genaxis == 1:\n            fs = (Phi.dot(ws) for ws in w.T)\n        elif genaxis == 0:\n            fs = (phi_n.dot(w) for phi_n in Phi)\n        else:\n            raise ValueError(\"Invalid axis to generate samples from\")\n\n        return fs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_arg_parser(parent):\n\n    arg1 = parent.add_subparsers(dest='command')\n\n    arg2 = arg1.add_parser('create')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-o', '--output',\n                      default=None,\n                      help='output file (default: stdout)')\n    arg2.add_argument('input', nargs='*',\n                      help='input file')\n\n    arg2 = arg1.add_parser('update')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-o', '--output',\n                      default=None,\n                      help='output file (default: rewrite state file)')\n    arg2.add_argument('state',\n                      help='state file')\n    arg2.add_argument('input', nargs='*',\n                      help='input file')\n\n    arg2 = arg1.add_parser('settings')\n    arg2.add_argument('state',\n                      help='state file')\n\n    arg2 = arg1.add_parser('generate')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-ss', '--state-size',\n                      type=int, nargs='+', default=None,\n                      help='generator state sizes')\n    arg2.add_argument('-S', '--size', metavar=('WIDTH', 'HEIGHT'),\n                      type=int, nargs=2, default=None,\n                      help='image size (default: <scanner.resize>)')\n    arg2.add_argument('-l', '--level',\n                      type=int, default=None,\n                      help='image levels (default: <scanner.levels>)')\n    arg2.add_argument('-c', '--count',\n                      type=int, default=1,\n                      help='generated image count (default: %(default)s)')\n    arg2.add_argument('state',\n                      help='state file')\n    arg2.add_argument('output',\n                      help='output file name format string')\n\n    arg2 = arg1.add_parser('filter')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-t', '--type',\n                      choices=('json', 'sqlite'), default='json',\n                      help='generator type (default: %(default)s)')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-S', '--state',\n                      default=None,\n                      help='state file')\n    arg2.add_argument('-ss', '--state-size',\n                      type=int, nargs='+', default=None,\n                      help='generator state sizes')\n    arg2.add_argument('-l', '--level',\n                      type=int, default=1,\n                      help='filter start level (default: %(default)s)')\n    arg2.add_argument('-c', '--count',\n                      type=int, default=1,\n                      help='generated image count (default: %(default)s)')\n    arg2.add_argument('input',\n                      help='input image')\n    arg2.add_argument('output',\n                      help='output file name format string')", "response": "Create command subparsers.\n\n    Parameters\n    ----------\n    parent : `argparse.ArgumentParser`\n        Command parser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading data files and update a generator.", "response": "def read(fnames, markov, progress, leave=True):\n    \"\"\"Read data files and update a generator.\n\n    Parameters\n    ----------\n    fnames : `list` of `str`\n        File paths.\n    markov : `markovchain.base.MarkovBase`\n        Generator to update.\n    progress : `bool`\n        Show progress bar.\n    leave : `bool`, optional\n        Leave progress bars (default: `True`).\n    \"\"\"\n    pbar = None\n    channels = markov.imgtype.channels\n\n    tr = markov.scanner.traversal\n    if progress and not isinstance(tr[0], TraversalProgressWrapper):\n        tr[0] = TraversalProgressWrapper(tr[0], channels)\n    tr = tr[0]\n\n    try:\n        with infiles(fnames, progress, leave) as fnames:\n            for fname in fnames:\n                if progress:\n                    title = truncate(fname, BAR_DESC_SIZE - 1, False)\n                    pbar = tqdm(\n                        total=markov.levels * len(channels),\n                        desc=title, leave=False, unit='lvl',\n                        bar_format=BAR_FORMAT, dynamic_ncols=True\n                    )\n                    tr.pbar_parent = pbar\n                markov.data(Image.open(fname), False)\n                if progress:\n                    pbar.close()\n    finally:\n        if pbar is not None:\n            pbar.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding nfiles output files in a single order.", "response": "def outfiles(markov, fmt, nfiles, progress, start=0):\n    \"\"\"Get output file paths.\n\n    Parameters\n    ----------\n    markov : `markovchain.base.MarkovBase`\n        Markov chain generator.\n    fmt : `str`\n        File path format string.\n    nfiles : `int`\n        Number of files.\n    progress : `bool`\n        Show progress bars.\n    start : `int`, optional\n        Initial image level (default: 0).\n\n    Returns\n    -------\n    `generator` of `str`\n        Output file paths.\n    \"\"\"\n    pbar = None\n    channels = markov.imgtype.channels\n\n    tr = markov.scanner.traversal\n    if progress and not isinstance(tr[0], TraversalProgressWrapper):\n        tr[0] = TraversalProgressWrapper(tr[0], channels)\n    tr = tr[0]\n\n    try:\n        with _outfiles(fmt, nfiles, progress) as fnames:\n            for fname in fnames:\n                if progress:\n                    title = truncate(fname, BAR_DESC_SIZE - 1, False)\n                    pbar = tqdm(\n                        initial=start * len(channels),\n                        total=markov.levels * len(channels),\n                        desc=title, leave=False, unit='lvl',\n                        bar_format=BAR_FORMAT, dynamic_ncols=True\n                    )\n                    tr.pbar_parent = pbar\n                yield fname\n                if progress:\n                    pbar.close()\n                    pbar = None\n    finally:\n        if pbar is not None:\n            pbar.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating images. Parameters ---------- args : argparse. Namespace", "response": "def cmd_generate(args):\n    \"\"\"Generate images.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n    check_output_format(args.output, args.count)\n\n    markov = load(MarkovImage, args.state, args)\n\n    if args.size is None:\n        if markov.scanner.resize is None:\n            print('Unknown output image size', file=stderr)\n            exit(1)\n        width, height = markov.scanner.resize\n    else:\n        width, height = args.size\n\n    if args.level is None:\n        scale = markov.scanner.min_size\n    else:\n        scale = reduce(\n            lambda x, y: x * y,\n            islice(markov.scanner.level_scale, 0, args.level - 1),\n            1\n        )\n\n    width, height = width // scale, height // scale\n\n    markov.scanner.traversal[0].show_progress = args.progress\n\n    for fname in outfiles(markov, args.output, args.count, args.progress):\n        img = markov(\n            width, height,\n            state_size=args.state_size,\n            levels=args.level\n        )\n        save_image(img, fname)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter an image. Parameters ---------- args : `argparse.Namespace` Command arguments.", "response": "def cmd_filter(args):\n    \"\"\"Filter an image.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n    check_output_format(args.output, args.count)\n\n    img = Image.open(args.input)\n    width, height = img.size\n\n    if args.state is not None:\n        markov = load(MarkovImage, args.state, args)\n    else:\n        args.state = ()\n        if args.type == JSON:\n            storage = JsonStorage(settings=args.settings)\n        else:\n            storage = SqliteStorage(settings=args.settings)\n        markov = MarkovImage.from_storage(storage)\n        read([args.input], markov, args.progress, False)\n\n    args.level = min(args.level, markov.levels - 1) - 1\n\n    if args.level < 0:\n        args.level = -1\n        scale = markov.scanner.min_size\n        width, height = width // scale, height // scale\n        start = None\n    else:\n        scale = reduce(\n            lambda x, y: x * y,\n            islice(markov.scanner.level_scale, args.level, markov.levels),\n            1\n        )\n        width, height = width // scale, height // scale\n        start = img.resize((width, height), markov.scanner.scale)\n\n    for fname in outfiles(markov, args.output,\n                          args.count, args.progress, args.level + 1):\n        img = markov(\n            width, height,\n            state_size=args.state_size,\n            start_level=args.level,\n            start_image=start\n        )\n        save_image(img, fname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lstrip_ws_and_chars(string, chars):\n    res = string.lstrip().lstrip(chars)\n    while len(res) != len(string):\n        string = res\n        res = string.lstrip().lstrip(chars)\n    return res", "response": "Remove leading whitespace and characters from a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef capitalize(string):\n    if not string:\n        return string\n    if len(string) == 1:\n        return string.upper()\n    return string[0].upper() + string[1:].lower()", "response": "Capitalize a sentence.\n\n    Parameters\n    ----------\n    string : `str`\n        String to capitalize.\n\n    Returns\n    -------\n    `str`\n        Capitalized string.\n\n    Examples\n    --------\n    >>> capitalize('worD WORD WoRd')\n    'Word word word'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef re_flags(flags, custom=ReFlags):\n    re_, custom_ = 0, 0\n    for flag in flags.upper():\n        try:\n            re_ |= getattr(re, flag)\n        except AttributeError:\n            if custom is not None:\n                try:\n                    custom_ |= getattr(custom, flag)\n                except AttributeError:\n                    raise ValueError('Invalid custom flag \"%s\"' % flag)\n            else:\n                raise ValueError('Invalid regexp flag \"%s\"' % flag)\n    return re_, custom_", "response": "Parse regexp flag string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef re_flags_str(flags, custom_flags):\n    res = ''\n    for flag in RE_FLAGS:\n        if flags & getattr(re, flag):\n            res += flag\n    for flag in RE_CUSTOM_FLAGS:\n        if custom_flags & getattr(ReFlags, flag):\n            res += flag\n    return res", "response": "Convert regexp flags to string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace regular expression. Parameters ---------- pattern : `str` or `_sre.SRE_Pattern` Compiled regular expression. repl : `str` or `function` Replacement. string : `str` Input string. count: `int` Maximum number of pattern occurrences. flags : `int` Flags. custom_flags : `int` Custom flags.", "response": "def re_sub(pattern, repl, string, count=0, flags=0, custom_flags=0):\n    \"\"\"Replace regular expression.\n\n    Parameters\n    ----------\n    pattern : `str` or `_sre.SRE_Pattern`\n        Compiled regular expression.\n    repl : `str` or `function`\n        Replacement.\n    string : `str`\n        Input string.\n    count: `int`\n        Maximum number of pattern occurrences.\n    flags : `int`\n        Flags.\n    custom_flags : `int`\n        Custom flags.\n    \"\"\"\n    if custom_flags & ReFlags.OVERLAP:\n        prev_string = None\n        while string != prev_string:\n            prev_string = string\n            string = re.sub(pattern, repl, string, count, flags)\n        return string\n    return re.sub(pattern, repl, string, count, flags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a copy of string converted to case.", "response": "def convert(self, string):\n        \"\"\"Return a copy of string converted to case.\n\n        Parameters\n        ----------\n        string : `str`\n\n        Returns\n        -------\n        `str`\n\n        Examples\n        --------\n        >>> CharCase.LOWER.convert('sTr InG')\n        'str ing'\n        >>> CharCase.UPPER.convert('sTr InG')\n        'STR ING'\n        >>> CharCase.TITLE.convert('sTr InG')\n        'Str ing'\n        >>> CharCase.PRESERVE.convert('sTr InG')\n        'sTr InG'\n        \"\"\"\n        if self == self.__class__.TITLE:\n            return capitalize(string)\n        if self == self.__class__.UPPER:\n            return string.upper()\n        if self == self.__class__.LOWER:\n            return string.lower()\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an endless sequence of random integers from permutations of the set [ 0... N )", "response": "def endless_permutations(N, random_state=None):\n    \"\"\"\n    Generate an endless sequence of random integers from permutations of the\n    set [0, ..., N).\n\n    If we call this N times, we will sweep through the entire set without\n    replacement, on the (N+1)th call a new permutation will be created, etc.\n\n    Parameters\n    ----------\n    N: int\n        the length of the set\n    random_state: int or RandomState, optional\n        random seed\n\n    Yields\n    ------\n    int:\n        a random int from the set [0, ..., N)\n    \"\"\"\n    generator = check_random_state(random_state)\n    while True:\n        batch_inds = generator.permutation(N)\n        for b in batch_inds:\n            yield b"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_repo(path=None, alias=None, create=False):\n    if create:\n        if not (path or alias):\n            raise TypeError(\"If create is specified, we need path and scm type\")\n        return get_backend(alias)(path, create=True)\n    if path is None:\n        path = abspath(os.path.curdir)\n    try:\n        scm, path = get_scm(path, search_up=True)\n        path = abspath(path)\n        alias = scm\n    except VCSError:\n        raise VCSError(\"No scm found at %s\" % path)\n    if alias is None:\n        alias = get_scm(path)[0]\n\n    backend = get_backend(alias)\n    repo = backend(path, create=create)\n    return repo", "response": "Returns a Repository object of type linked with given alias at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_backend(alias):\n    if alias not in settings.BACKENDS:\n        raise VCSError(\"Given alias '%s' is not recognized! Allowed aliases:\\n\"\n            \"%s\" % (alias, pformat(settings.BACKENDS.keys())))\n    backend_path = settings.BACKENDS[alias]\n    klass = import_class(backend_path)\n    return klass", "response": "Returns the backend class identified by the given alias."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_scm(path, search_up=False, explicit_alias=None):\n    if not os.path.isdir(path):\n        raise VCSError(\"Given path %s is not a directory\" % path)\n\n    def get_scms(path):\n        return [(scm, path) for scm in get_scms_for_path(path)]\n\n    found_scms = get_scms(path)\n    while not found_scms and search_up:\n        newpath = abspath(path, '..')\n        if newpath == path:\n            break\n        path = newpath\n        found_scms = get_scms(path)\n\n    if len(found_scms) > 1:\n        for scm in found_scms:\n            if scm[0] == explicit_alias:\n                return scm\n        raise VCSError('More than one [%s] scm found at given path %s'\n                       % (','.join((x[0] for x in found_scms)), path))\n\n    if len(found_scms) is 0:\n        raise VCSError('No scm found at given path %s' % path)\n\n    return found_scms[0]", "response": "Returns the scm that is found at the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_scms_for_path(path):\n    from vcs.backends import get_backend\n    if hasattr(path, '__call__'):\n        path = path()\n    if not os.path.isdir(path):\n        raise VCSError(\"Given path %r is not a directory\" % path)\n\n    result = []\n    for key in ALIASES:\n        dirname = os.path.join(path, '.' + key)\n        if os.path.isdir(dirname):\n            result.append(key)\n            continue\n        # We still need to check if it's not bare repository as\n        # bare repos don't have working directories\n        try:\n            get_backend(key)(path)\n            result.append(key)\n            continue\n        except RepositoryError:\n            # Wrong backend\n            pass\n        except VCSError:\n            # No backend at all\n            pass\n    return result", "response": "Returns all scm s found at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of paths to directories which seems to be a repository.", "response": "def get_repo_paths(path):\n    \"\"\"\n    Returns path's subdirectories which seems to be a repository.\n    \"\"\"\n    repo_paths = []\n    dirnames = (os.path.abspath(dirname) for dirname in os.listdir(path))\n    for dirname in dirnames:\n        try:\n            get_scm(dirname)\n            repo_paths.append(dirname)\n        except VCSError:\n            pass\n    return repo_paths"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_command(cmd, *args):\n    command = ' '.join((cmd, args))\n    p = Popen(command, shell=True, stdout=PIPE, stderr=PIPE)\n    stdout, stderr = p.communicate()\n    return p.retcode, stdout, stderr", "response": "Runs command on the system with given args."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the code that is highlighted by pygments.", "response": "def get_highlighted_code(name, code, type='terminal'):\n    \"\"\"\n    If pygments are available on the system\n    then returned output is colored. Otherwise\n    unchanged content is returned.\n    \"\"\"\n    import logging\n    try:\n        import pygments\n        pygments\n    except ImportError:\n        return code\n    from pygments import highlight\n    from pygments.lexers import guess_lexer_for_filename, ClassNotFound\n    from pygments.formatters import TerminalFormatter\n\n    try:\n        lexer = guess_lexer_for_filename(name, code)\n        formatter = TerminalFormatter()\n        content = highlight(code, lexer, formatter)\n    except ClassNotFound:\n        logging.debug(\"Couldn't guess Lexer, will not use pygments.\")\n        content = code\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_changesets(text):\n    text = text.strip()\n    CID_RE = r'[a-zA-Z0-9]+'\n    if not '..' in text:\n        m = re.match(r'^(?P<cid>%s)$' % CID_RE, text)\n        if m:\n            return {\n                'start': None,\n                'main': text,\n                'end': None,\n            }\n    else:\n        RE = r'^(?P<start>%s)?\\.{2,3}(?P<end>%s)?$' % (CID_RE, CID_RE)\n        m = re.match(RE, text)\n        if m:\n            result = m.groupdict()\n            result['main'] = None\n            return result\n    raise ValueError(\"IDs not recognized\")", "response": "Parses a string containing a list of all the changesets in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_datetime(text):\n\n    text = text.strip().lower()\n\n    INPUT_FORMATS = (\n        '%Y-%m-%d %H:%M:%S',\n        '%Y-%m-%d %H:%M',\n        '%Y-%m-%d',\n        '%m/%d/%Y %H:%M:%S',\n        '%m/%d/%Y %H:%M',\n        '%m/%d/%Y',\n        '%m/%d/%y %H:%M:%S',\n        '%m/%d/%y %H:%M',\n        '%m/%d/%y',\n    )\n    for format in INPUT_FORMATS:\n        try:\n            return datetime.datetime(*time.strptime(text, format)[:6])\n        except ValueError:\n            pass\n\n    # Try descriptive texts\n    if text == 'tomorrow':\n        future = datetime.datetime.now() + datetime.timedelta(days=1)\n        args = future.timetuple()[:3] + (23, 59, 59)\n        return datetime.datetime(*args)\n    elif text == 'today':\n        return datetime.datetime(*datetime.datetime.today().timetuple()[:3])\n    elif text == 'now':\n        return datetime.datetime.now()\n    elif text == 'yesterday':\n        past = datetime.datetime.now() - datetime.timedelta(days=1)\n        return datetime.datetime(*past.timetuple()[:3])\n    else:\n        days = 0\n        matched = re.match(\n            r'^((?P<weeks>\\d+) ?w(eeks?)?)? ?((?P<days>\\d+) ?d(ays?)?)?$', text)\n        if matched:\n            groupdict = matched.groupdict()\n            if groupdict['days']:\n                days += int(matched.groupdict()['days'])\n            if groupdict['weeks']:\n                days += int(matched.groupdict()['weeks']) * 7\n            past = datetime.datetime.now() - datetime.timedelta(days=days)\n            return datetime.datetime(*past.timetuple()[:3])\n\n    raise ValueError('Wrong date: \"%s\"' % text)", "response": "Parses given text and returns a datetime. datetime instance or raises ValueError."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns dictionary for each attribute from given obj.", "response": "def get_dict_for_attrs(obj, attrs):\n    \"\"\"\n    Returns dictionary for each attribute from given ``obj``.\n    \"\"\"\n    data = {}\n    for attr in attrs:\n        data[attr] = getattr(obj, attr)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loglike(self, y, f):\n        # way faster than calling bernoulli.logpmf\n        y, f = np.broadcast_arrays(y, f)\n        ll = y * f - softplus(f)\n        return ll", "response": "r Bernoulli log likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loglike(self, y, f, n):\n        ll = binom.logpmf(y, n=n, p=expit(f))\n        return ll", "response": "r Binomial log likelihood of each target y given each latent function f under this object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef df(self, y, f, var):\n        var = self._check_param(var)\n        y, f = np.broadcast_arrays(y, f)\n        return (y - f) / var", "response": "r Returns the derivative of the log likelihood w. r. t."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dp(self, y, f, var):\n        var = self._check_param(var)\n        y, f = np.broadcast_arrays(y, f)\n        ivar = 1. / var\n        return 0.5 * (((y - f) * ivar)**2 - ivar)", "response": "r Returns the derivative of Gaussian log likelihood w. r. t."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Ey(self, f):\n        return np.exp(f) if self.tranfcn == 'exp' else softplus(f)", "response": "r Returns the expected value of the Poisson likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting parser state. Parameters ---------- state_size_changed : `bool`, optional `True` if maximum state size changed (default: `False`).", "response": "def reset(self, state_size_changed=False):\n        \"\"\"Reset parser state.\n\n        Parameters\n        ----------\n        state_size_changed : `bool`, optional\n            `True` if maximum state size changed (default: `False`).\n        \"\"\"\n        if state_size_changed:\n            self.state = deque(repeat('', self.state_size),\n                               maxlen=self.state_size)\n        else:\n            self.state.extend(repeat('', self.state_size))\n        self.end = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert to JSON. JSON data.", "response": "def save(self):\n        \"\"\"Convert to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        data = super().save()\n        data['state_sizes'] = self.state_sizes\n        data['reset_on_sentence_end'] = self.reset_on_sentence_end\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self):\n        data = super().save()\n        data['levels'] = self.levels\n        if self.parsers is None:\n            data['parsers'] = None\n        else:\n            data['parsers'] = [parser.save() for parser in self.parsers]\n        return data", "response": "Convert to JSON.\n        Returns\n        -------\n            JSON data.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a palette for a set of resources.", "response": "def palette(hues, saturations, values):\n    \"\"\"Generate a palette.\n\n    Parameters\n    ----------\n    hues : `int`\n        Number of hues.\n    saturations : `int`\n        Number of saturations.\n    values : `int`\n        Number of values.\n\n    Raises\n    ------\n    ValueError\n        If `hues` * `saturations` * `values` > 256\n        or min(`hues`, `saturations`, `values`) < 1.\n\n    Returns\n    -------\n    `list` of `int`\n        Palette for `PIL.Image.putpalette`.\n    \"\"\"\n    size = hues * saturations * values\n    if size > 256:\n        raise ValueError('palette size > 256: {0}'.format(size))\n    if min(hues, saturations, values) < 1:\n        raise ValueError('invalid palette size: {0} {1} {2}'\n                         .format(hues, saturations, values))\n\n    ret = []\n    if hues == 1 and saturations == 1:\n        if values == 1:\n            size = 0\n        else:\n            nvalues = values - 1\n            for value in range(values):\n                value1 = value * 255 // nvalues\n                ret.extend((value1, value1, value1))\n    else:\n        for saturation in range(1, saturations + 1):\n            saturation1 = saturation / saturations\n            for hue in range(1, hues + 1):\n                hue1 = hue / hues\n                for value in range(1, values + 1):\n                    value1 = value / values\n                    ret.extend(floor(x * 255)\n                               for x in hsv_to_rgb(hue1, saturation1, value1))\n\n    ret.extend(0 for _ in range((256 - size) * 3))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an image to a specific type.", "response": "def convert(ctype, img, palette_img, dither=False):\n    \"\"\"Convert an image to palette type.\n\n    Parameters\n    ----------\n    ctype : `int`\n        Conversion type.\n    img : `PIL.Image`\n        Image to convert.\n    palette_img : `PIL.Image`\n        Palette source image.\n    dither : `bool`, optional\n        Enable dithering (default: `False`).\n\n    Raises\n    ------\n    ValueError\n        If palette_img has no palette.\n\n    Returns\n    -------\n    `PIL.Image`\n        Converted image.\n    \"\"\"\n    if ctype == 0:\n        img2 = img.convert(mode='P')\n        img2.putpalette(palette_img.getpalette())\n        return img2\n\n    img.load()\n    palette_img.load()\n    if palette_img.palette is None:\n        raise ValueError('invalid palette image')\n    im = img.im.convert('P', int(dither), palette_img.im)\n    return img._new(im)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a configuration setting as boolean.", "response": "def get_boolean(self, section, name, default=None):\n        \"\"\"Retrieve a configuration setting as boolean.\n\n        :param section: Tuple with section name and optional subsection namee\n        :param name: Name of the setting, including section and possible\n            subsection.\n        :return: Contents of the setting\n        :raise KeyError: if the value is not set\n        \"\"\"\n        try:\n            value = self.get(section, name)\n        except KeyError:\n            return default\n        if value.lower() == \"true\":\n            return True\n        elif value.lower() == \"false\":\n            return False\n        raise ValueError(\"not a valid boolean string: %r\" % value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(cls, f):\n        ret = cls()\n        section = None\n        setting = None\n        for lineno, line in enumerate(f.readlines()):\n            line = line.lstrip()\n            if setting is None:\n                if _strip_comments(line).strip() == \"\":\n                    continue\n                if line[0] == \"[\":\n                    line = _strip_comments(line).rstrip()\n                    if line[-1] != \"]\":\n                        raise ValueError(\"expected trailing ]\")\n                    key = line.strip()\n                    pts = key[1:-1].split(\" \", 1)\n                    pts[0] = pts[0].lower()\n                    if len(pts) == 2:\n                        if pts[1][0] != \"\\\"\" or pts[1][-1] != \"\\\"\":\n                            raise ValueError(\n                                \"Invalid subsection \" + pts[1])\n                        else:\n                            pts[1] = pts[1][1:-1]\n                        if not _check_section_name(pts[0]):\n                            raise ValueError(\"invalid section name %s\" %\n                                             pts[0])\n                        section = (pts[0], pts[1])\n                    else:\n                        if not _check_section_name(pts[0]):\n                            raise ValueError(\"invalid section name %s\" %\n                                    pts[0])\n                        pts = pts[0].split(\".\", 1)\n                        if len(pts) == 2:\n                            section = (pts[0], pts[1])\n                        else:\n                            section = (pts[0], )\n                    ret._values[section] = {}\n                else:\n                    if section is None:\n                        raise ValueError(\"setting %r without section\" % line)\n                    try:\n                        setting, value = line.split(\"=\", 1)\n                    except ValueError:\n                        setting = line\n                        value = \"true\"\n                    setting = setting.strip().lower()\n                    if not _check_variable_name(setting):\n                        raise ValueError(\"invalid variable name %s\" % setting)\n                    if value.endswith(\"\\\\\\n\"):\n                        value = value[:-2]\n                        continuation = True\n                    else:\n                        continuation = False\n                    value = _parse_string(value)\n                    ret._values[section][setting] = value\n                    if not continuation:\n                        setting = None\n            else:  # continuation line\n                if line.endswith(\"\\\\\\n\"):\n                    line = line[:-2]\n                    continuation = True\n                else:\n                    continuation = False\n                value = _parse_string(line)\n                ret._values[section][setting] += value\n                if not continuation:\n                    setting = None\n        return ret", "response": "Read a configuration from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread configuration from a file on disk.", "response": "def from_path(cls, path):\n        \"\"\"Read configuration from a file on disk.\"\"\"\n        f = GitFile(path, 'rb')\n        try:\n            ret = cls.from_file(f)\n            ret.path = path\n            return ret\n        finally:\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_to_path(self, path=None):\n        if path is None:\n            path = self.path\n        f = GitFile(path, 'wb')\n        try:\n            self.write_to_file(f)\n        finally:\n            f.close()", "response": "Write configuration to a file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites configuration to a file - like object.", "response": "def write_to_file(self, f):\n        \"\"\"Write configuration to a file-like object.\"\"\"\n        for section, values in self._values.iteritems():\n            try:\n                section_name, subsection_name = section\n            except ValueError:\n                (section_name, ) = section\n                subsection_name = None\n            if subsection_name is None:\n                f.write(\"[%s]\\n\" % section_name)\n            else:\n                f.write(\"[%s \\\"%s\\\"]\\n\" % (section_name, subsection_name))\n            for key, value in values.iteritems():\n                f.write(\"%s = %s\\n\" % (key, _escape_value(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the default configuration.", "response": "def default_backends(cls):\n        \"\"\"Retrieve the default configuration.\n\n        This will look in the repository configuration (if for_path is\n        specified), the users' home directory and the system\n        configuration.\n        \"\"\"\n        paths = []\n        paths.append(os.path.expanduser(\"~/.gitconfig\"))\n        paths.append(\"/etc/gitconfig\")\n        backends = []\n        for path in paths:\n            try:\n                cf = ConfigFile.from_path(path)\n            except (IOError, OSError), e:\n                if e.errno != errno.ENOENT:\n                    raise\n                else:\n                    continue\n            backends.append(cf)\n        return backends"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_regression(func, n_samples=100, n_features=1, bias=0.0, noise=0.0,\n                    random_state=None):\n    \"\"\"\n    Make dataset for a regression problem.\n\n    Examples\n    --------\n    >>> f = lambda x: 0.5*x + np.sin(2*x)\n    >>> X, y = make_regression(f, bias=.5, noise=1., random_state=1)\n    >>> X.shape\n    (100, 1)\n    >>> y.shape\n    (100,)\n    >>> X[:5].round(2)\n    array([[ 1.62],\n           [-0.61],\n           [-0.53],\n           [-1.07],\n           [ 0.87]])\n    >>> y[:5].round(2)\n    array([ 0.76,  0.48, -0.23, -0.28,  0.83])\n    \"\"\"\n    generator = check_random_state(random_state)\n\n    X = generator.randn(n_samples, n_features)\n    # unpack the columns of X\n    y = func(*X.T) + bias\n\n    if noise > 0.0:\n        y += generator.normal(scale=noise, size=y.shape)\n\n    return X, y", "response": "Make a regression problem."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_polynomial(degree=3, n_samples=100, bias=0.0, noise=0.0,\n                    return_coefs=False, random_state=None):\n    \"\"\"\n    Generate a noisy polynomial for a regression problem\n\n    Examples\n    --------\n    >>> X, y, coefs = make_polynomial(degree=3, n_samples=200, noise=.5,\n    ...                               return_coefs=True, random_state=1)\n    \"\"\"\n    generator = check_random_state(random_state)\n\n    # TODO: Add arguments to support other priors\n    coefs = generator.randn(degree + 1)\n    pows = np.arange(degree + 1)\n    poly = np.vectorize(lambda x: np.sum(coefs * x ** pows))\n    X, y = make_regression(poly, n_samples=n_samples, bias=bias, noise=noise,\n                           random_state=random_state)\n    if return_coefs:\n        return X, y, coefs\n\n    return X, y", "response": "Generate a noisy polynomial for a regression problem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path of the revrand data dir.", "response": "def get_data_home(data_home=None):\n    \"\"\"\n    Return the path of the revrand data dir.\n\n    This folder is used by some large dataset loaders to avoid\n    downloading the data several times.\n\n    By default the data dir is set to a folder named 'revrand_data'\n    in the user home folder.\n\n    Alternatively, it can be set by the 'REVRAND_DATA' environment\n    variable or programmatically by giving an explicit folder path. The\n    '~' symbol is expanded to the user home folder.\n\n    If the folder does not already exist, it is automatically created.\n    \"\"\"\n    data_home_default = Path(__file__).ancestor(3).child('demos',\n                                                         '_revrand_data')\n\n    if data_home is None:\n        data_home = os.environ.get('REVRAND_DATA', data_home_default)\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_gpml_sarcos_data(transpose_data=True, data_home=None):\n    train_src_url = \"http://www.gaussianprocess.org/gpml/data/sarcos_inv.mat\"\n    test_src_url = (\"http://www.gaussianprocess.org/gpml/data/sarcos_inv_test\"\n                    \".mat\")\n\n    data_home = get_data_home(data_home=data_home)\n\n    train_filename = os.path.join(data_home, 'sarcos_inv.mat')\n    test_filename = os.path.join(data_home, 'sarcos_inv_test.mat')\n\n    if not os.path.exists(train_filename):\n        urllib.request.urlretrieve(train_src_url, train_filename)\n\n    if not os.path.exists(test_filename):\n        urllib.request.urlretrieve(test_src_url, test_filename)\n\n    train_data = loadmat(train_filename).get('sarcos_inv')\n    test_data = loadmat(test_filename).get('sarcos_inv_test')\n\n    train_bunch = Bunch(data=train_data[:, :21],\n                        targets=train_data[:, 21])\n\n    test_bunch = Bunch(data=test_data[:, :21],\n                       targets=test_data[:, 21])\n\n    return Bunch(train=train_bunch, test=test_bunch)", "response": "Fetch the SARCOS dataset from the internet and parse appropriately into a Bunch of arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_gpml_usps_resampled_data(transpose_data=True, data_home=None):\n    data_home = get_data_home(data_home=data_home)\n    data_filename = os.path.join(data_home,\n                                 'usps_resampled/usps_resampled.mat')\n\n    if not os.path.exists(data_filename):\n\n        r = requests.get('http://www.gaussianprocess.org/gpml/data/'\n                         'usps_resampled.tar.bz2')\n\n        with tarfile.open(fileobj=BytesIO(r.content)) as tar_infile:\n            tar_infile.extract('usps_resampled/usps_resampled.mat',\n                               path=data_home)\n\n    matlab_dict = loadmat(data_filename)\n\n    train_data = matlab_dict['train_patterns']\n    test_data = matlab_dict['test_patterns']\n\n    if transpose_data:\n        train_data = train_data.T\n        test_data = test_data.T\n\n    train_targets = matlab_dict['train_labels'].T\n    train_targets = np.argwhere(train_targets == 1)[:, 1]\n\n    test_targets = matlab_dict['test_labels'].T\n    test_targets = np.argwhere(test_targets == 1)[:, 1]\n\n    train_bunch = Bunch(data=train_data,\n                        targets=train_targets)\n\n    test_bunch = Bunch(data=test_data,\n                       targets=test_targets)\n\n    return Bunch(train=train_bunch, test=test_bunch)", "response": "Fetch the USPS handwritten digits dataset from the internet and parse them appropriately into python arrays"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a random set of train test and ftest.", "response": "def gen_gausprocess_se(ntrain, ntest, noise=1., lenscale=1., scale=1.,\n                       xmin=-10, xmax=10):\n    \"\"\"\n    Generate a random (noisy) draw from a Gaussian Process with a RBF kernel.\n    \"\"\"\n\n    # Xtrain = np.linspace(xmin, xmax, ntrain)[:, np.newaxis]\n    Xtrain = np.random.rand(ntrain)[:, np.newaxis] * (xmin - xmax) - xmin\n    Xtest = np.linspace(xmin, xmax, ntest)[:, np.newaxis]\n    Xcat = np.vstack((Xtrain, Xtest))\n\n    K = scale * np.exp(-cdist(Xcat, Xcat, metric='sqeuclidean') /\n                       (2 * lenscale**2))\n    U, S, V = np.linalg.svd(K)\n    L = U.dot(np.diag(np.sqrt(S))).dot(V)\n    f = np.random.randn(ntrain + ntest).dot(L)\n\n    ytrain = f[0:ntrain] + np.random.randn(ntrain) * noise\n    ftest = f[ntrain:]\n\n    return Xtrain, ytrain, Xtest, ftest"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit state string. Parameters ---------- state : `str` Returns ------- `list` of `str`", "response": "def split_state(self, state):\n        \"\"\"Split state string.\n\n        Parameters\n        ----------\n        state : `str`\n\n        Returns\n        -------\n        `list` of `str`\n        \"\"\"\n        if self.state_separator:\n            return state.split(self.state_separator)\n        return list(state)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random link.", "response": "def random_link(self, dataset, state, backward=False):\n        \"\"\"Get a random link.\n\n        Parameters\n        ----------\n        dataset : `object`\n            Dataset from `self.get_dataset()`.\n        state : `object`\n            Link source.\n        backward : `bool`, optional\n            Link direction.\n\n        Raises\n        ------\n        ValueError\n            If link count is invalid.\n\n        Returns\n        -------\n        (`str` or `None`, `object` or `None`)\n            Link value and next state.\n        \"\"\"\n        links = self.get_links(dataset, state, backward)\n        if not links:\n            return None, None\n        x = randint(0, sum(link[0] for link in links) - 1)\n        for link in links:\n            count = link[0]\n            if x < count:\n                return link[1], self.follow_link(link, state, backward)\n            x -= count\n        raise RuntimeError('invalid link sum')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self, state, size, dataset, backward=False):\n        if isinstance(state, str):\n            state = self.split_state(state)\n        state = self.get_state(state, size)\n        dataset = self.get_dataset(dataset)\n        while True:\n            link, state = self.random_link(dataset, state, backward)\n            if link is None or backward and link == '':\n                return\n            yield link", "response": "Generate a sequence of nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates settings JSON data and save to file.", "response": "def save(self, fp=None):\n        \"\"\"Update settings JSON data and save to file.\n\n        Parameters\n        ----------\n        fp : `file` or `str`, optional\n            Output file.\n        \"\"\"\n        self.settings['storage'] = {\n            'state_separator': self.state_separator\n        }\n        self.do_save(fp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommit a new changeset.", "response": "def commit(self, message, author, parents=None, branch=None, date=None,\n            **kwargs):\n        \"\"\"\n        Performs in-memory commit (doesn't check workdir in any way) and\n        returns newly created ``Changeset``. Updates repository's\n        ``revisions``.\n\n        :param message: message of the commit\n        :param author: full username, i.e. \"Joe Doe <joe.doe@example.com>\"\n        :param parents: single parent or sequence of parents from which commit\n          would be derieved\n        :param date: ``datetime.datetime`` instance. Defaults to\n          ``datetime.datetime.now()``.\n        :param branch: branch name, as string. If none given, default backend's\n          branch would be used.\n\n        :raises ``CommitError``: if any error occurs while committing\n        \"\"\"\n        self.check_integrity(parents)\n\n        from .repository import MercurialRepository\n        if not isinstance(message, unicode) or not isinstance(author, unicode):\n            raise RepositoryError('Given message and author needs to be '\n                                  'an <unicode> instance got %r & %r instead'\n                                  % (type(message), type(author)))\n\n        if branch is None:\n            branch = MercurialRepository.DEFAULT_BRANCH_NAME\n        kwargs['branch'] = branch\n\n        def filectxfn(_repo, memctx, path):\n            \"\"\"\n            Marks given path as added/changed/removed in a given _repo. This is\n            for internal mercurial commit function.\n            \"\"\"\n\n            # check if this path is removed\n            if path in (node.path for node in self.removed):\n                # Raising exception is a way to mark node for removal\n                raise IOError(errno.ENOENT, '%s is deleted' % path)\n\n            # check if this path is added\n            for node in self.added:\n                if node.path == path:\n                    return memfilectx(path=node.path,\n                        data=(node.content.encode('utf8')\n                              if not node.is_binary else node.content),\n                        islink=False,\n                        isexec=node.is_executable,\n                        copied=False)\n\n            # or changed\n            for node in self.changed:\n                if node.path == path:\n                    return memfilectx(path=node.path,\n                        data=(node.content.encode('utf8')\n                              if not node.is_binary else node.content),\n                        islink=False,\n                        isexec=node.is_executable,\n                        copied=False)\n\n            raise RepositoryError(\"Given path haven't been marked as added,\"\n                                  \"changed or removed (%s)\" % path)\n\n        parents = [None, None]\n        for i, parent in enumerate(self.parents):\n            if parent is not None:\n                parents[i] = parent._ctx.node()\n\n        if date and isinstance(date, datetime.datetime):\n            date = date.ctime()\n\n        commit_ctx = memctx(repo=self.repository._repo,\n            parents=parents,\n            text='',\n            files=self.get_paths(),\n            filectxfn=filectxfn,\n            user=author,\n            date=date,\n            extra=kwargs)\n\n        loc = lambda u: tolocal(u.encode('utf-8'))\n\n        # injecting given _repo params\n        commit_ctx._text = loc(message)\n        commit_ctx._user = loc(author)\n        commit_ctx._date = date\n\n        # TODO: Catch exceptions!\n        n = self.repository._repo.commitctx(commit_ctx)\n        # Returns mercurial node\n        self._commit_ctx = commit_ctx  # For reference\n        # Update vcs repository object & recreate mercurial _repo\n        # new_ctx = self.repository._repo[node]\n        # new_tip = self.repository.get_changeset(new_ctx.hex())\n        new_id = hex(n)\n        self.repository.revisions.append(new_id)\n        self._repo = self.repository._get_repo(create=False)\n        self.repository.branches = self.repository._get_branches()\n        tip = self.repository.get_changeset()\n        self.reset()\n        return tip"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting the size in bytes as a human - readable file size.", "response": "def filesizeformat(bytes, sep=' '):\n    \"\"\"\n    Formats the value like a 'human-readable' file size (i.e. 13 KB, 4.1 MB,\n    102 B, 2.3 GB etc).\n\n    Grabbed from Django (http://www.djangoproject.com), slightly modified.\n\n    :param bytes: size in bytes (as integer)\n    :param sep: string separator between number and abbreviation\n    \"\"\"\n    try:\n        bytes = float(bytes)\n    except (TypeError, ValueError, UnicodeDecodeError):\n        return '0%sB' % sep\n\n    if bytes < 1024:\n        size = bytes\n        template = '%.0f%sB'\n    elif bytes < 1024 * 1024:\n        size = bytes / 1024\n        template = '%.0f%sKB'\n    elif bytes < 1024 * 1024 * 1024:\n        size = bytes / 1024 / 1024\n        template = '%.1f%sMB'\n    else:\n        size = bytes / 1024 / 1024 / 1024\n        template = '%.2f%sGB'\n    return template % (size, sep)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef colorize(text='', opts=(), **kwargs):\n    code_list = []\n    if text == '' and len(opts) == 1 and opts[0] == 'reset':\n        return '\\x1b[%sm' % RESET\n    for k, v in kwargs.iteritems():\n        if k == 'fg':\n            code_list.append(foreground[v])\n        elif k == 'bg':\n            code_list.append(background[v])\n    for o in opts:\n        if o in opt_dict:\n            code_list.append(opt_dict[o])\n    if 'noreset' not in opts:\n        text = text + '\\x1b[%sm' % RESET\n    return ('\\x1b[%sm' % ';'.join(code_list)) + text", "response": "Colorizes a text string with ANSI graphics codes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_color_setting(config_string):\n    if not config_string:\n        return PALETTES[DEFAULT_PALETTE]\n\n    # Split the color configuration into parts\n    parts = config_string.lower().split(';')\n    palette = PALETTES[NOCOLOR_PALETTE].copy()\n    for part in parts:\n        if part in PALETTES:\n            # A default palette has been specified\n            palette.update(PALETTES[part])\n        elif '=' in part:\n            # Process a palette defining string\n            definition = {}\n\n            # Break the definition into the role,\n            # plus the list of specific instructions.\n            # The role must be in upper case\n            role, instructions = part.split('=')\n            role = role.upper()\n\n            styles = instructions.split(',')\n            styles.reverse()\n\n            # The first instruction can contain a slash\n            # to break apart fg/bg.\n            colors = styles.pop().split('/')\n            colors.reverse()\n            fg = colors.pop()\n            if fg in color_names:\n                definition['fg'] = fg\n            if colors and colors[-1] in color_names:\n                definition['bg'] = colors[-1]\n\n            # All remaining instructions are options\n            opts = tuple(s for s in styles if s in opt_dict.keys())\n            if opts:\n                definition['opts'] = opts\n\n            # The nocolor palette has all available roles.\n            # Use that palette as the basis for determining\n            # if the role is valid.\n            if role in PALETTES[NOCOLOR_PALETTE] and definition:\n                palette[role] = definition\n\n    # If there are no colors specified, return the empty palette.\n    if palette == PALETTES[NOCOLOR_PALETTE]:\n        return None\n    return palette", "response": "Parse a DJANGO_COLORS environment variable to produce the system palette."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninverses operation of couple.", "response": "def decouple(fn):\n    \"\"\"\n    Inverse operation of couple.\n\n    Create two functions of one argument and one return from a function that\n    takes two arguments and has two returns\n\n    Examples\n    --------\n    >>> h = lambda x: (2*x**3, 6*x**2)\n    >>> f, g = decouple(h)\n\n    >>> f(5)\n    250\n\n    >>> g(5)\n    150\n    \"\"\"\n    def fst(*args, **kwargs):\n        return fn(*args, **kwargs)[0]\n\n    def snd(*args, **kwargs):\n        return fn(*args, **kwargs)[1]\n\n    return fst, snd"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nwise(iterable, n):\n    iters = tee(iterable, n)\n    for i, it in enumerate(iters):\n        for _ in range(i):\n            next(it, None)\n    return zip(*iters)", "response": "r Returns an iterator that creates n - n sliding windows over the given iterable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scalar_reshape(a, newshape, order='C'):\n    if newshape == ():\n        return np.asscalar(a)\n\n    if newshape == (0,):\n        return []\n\n    return np.reshape(a, newshape, order)", "response": "Reshape a numpy array to newshape."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nflattens a potentially recursive list of multidimensional objects.", "response": "def flatten(arys, returns_shapes=True, hstack=np.hstack, ravel=np.ravel,\n            shape=np.shape):\n    \"\"\"\n    Flatten a potentially recursive list of multidimensional objects.\n\n    .. note::\n\n       Not to be confused with `np.ndarray.flatten()` (a more befitting\n       might be `chain` or `stack` or maybe something else entirely\n       since this function is more than either `concatenate` or\n       `np.flatten` itself. Rather, it is the composition of the former\n       with the latter.\n\n    Parameters\n    ----------\n    arys : list of objects\n        One or more input arrays of possibly heterogenous shapes and\n        sizes.\n    returns_shapes : bool, optional\n        Default is `True`. If `True`, the tuple `(flattened, shapes)` is\n        returned, otherwise only `flattened` is returned.\n    hstack : callable, optional\n        a function that implements horizontal stacking\n    ravel : callable, optional\n        a function that flattens the object\n    shape : callable, optional\n        a function that returns the shape of the object\n\n    Returns\n    -------\n    flattened,[shapes] : {1dobject, list of tuples}\n        Return the flat (1d) object resulting from the concatenation of\n        flattened multidimensional objects. When `returns_shapes` is `True`,\n        return a list of tuples containing also the shapes of each array as the\n        second element.\n\n    See Also\n    --------\n    revrand.utils.unflatten : its inverse\n\n    Examples\n    --------\n    >>> a = 9\n    >>> b = np.array([4, 7, 4, 5, 2])\n    >>> c = np.array([[7, 3, 1],\n    ...               [2, 6, 6]])\n    >>> d = np.array([[[6, 5, 5],\n    ...                [1, 6, 9]],\n    ...               [[3, 9, 1],\n    ...                [9, 4, 1]]])\n\n    >>> flatten([a, b, c, d]) # doctest: +NORMALIZE_WHITESPACE\n    (array([9, 4, 7, 4, 5, 2, 7, 3, 1, 2, 6, 6, 6, 5, 5, 1, 6, 9, 3, 9,\n            1, 9, 4, 1]), [(), (5,), (2, 3), (2, 2, 3)])\n\n    Note that scalars and 0-dimensional arrays are treated differently\n    from 1-dimensional singleton arrays.\n\n    >>> flatten([3.14, np.array(2.71), np.array([1.61])])\n    ... # doctest: +NORMALIZE_WHITESPACE\n    (array([ 3.14,  2.71,  1.61]), [(), (), (1,)])\n\n    >>> flatten([a, b, c, d], returns_shapes=False)\n    ... # doctest: +NORMALIZE_WHITESPACE\n    array([9, 4, 7, 4, 5, 2, 7, 3, 1, 2, 6, 6, 6, 5, 5, 1, 6, 9, 3, 9,\n           1, 9, 4, 1])\n\n    >>> w, x, y, z = unflatten(*flatten([a, b, c, d]))\n\n    >>> w == a\n    True\n\n    >>> np.array_equal(x, b)\n    True\n\n    >>> np.array_equal(y, c)\n    True\n\n    >>> np.array_equal(z, d)\n    True\n\n    >>> flatten([3.14, [np.array(2.71), np.array([1.61])]])\n    ... # doctest: +NORMALIZE_WHITESPACE\n    (array([ 3.14,  2.71,  1.61]), [(), [(), (1,)]])\n\n    \"\"\"\n    if issequence(arys) and len(arys) > 0:\n\n        flat = partial(flatten,\n                       returns_shapes=True,\n                       hstack=hstack,\n                       ravel=ravel,\n                       shape=shape\n                       )\n\n        flat_arys, shapes = zip(*map(flat, arys))\n        flat_ary = hstack(flat_arys)\n        shapes = list(shapes)\n\n    else:\n\n        flat_ary = ravel(arys)\n        shapes = shape(arys)\n\n    return (flat_ary, shapes) if returns_shapes else flat_ary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sumprod(seq):\n    if isinstance(seq, tuple):\n        # important to make sure dtype is int\n        # since prod on empty tuple is a float (1.0)\n        return np.prod(seq, dtype=int)\n    else:\n        return np.sum((sumprod(s) for s in seq), dtype=int)", "response": "Returns the product of input tuples or sum of products of lists of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_recursive(fn, iterable, output_type=None):\n    def applyormap(it):\n        if issequence(it):\n            return map_recursive(fn, it, output_type)\n        else:\n            return fn(it)\n\n    applied = map(applyormap, iterable)\n    return output_type(applied) if output_type else applied", "response": "Returns a function that applies a function to each element of each list and returns a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_indices(fn, iterable, indices):\n    index_set = set(indices)\n    for i, arg in enumerate(iterable):\n        if i in index_set:\n            yield fn(arg)\n        else:\n            yield arg", "response": "r Map a function across indices of an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_archiver(self, kind):\n\n    archivers = {\n        'tar': TarArchiver,\n        'tbz2': Tbz2Archiver,\n        'tgz': TgzArchiver,\n        'zip': ZipArchiver,\n    }\n\n    return archivers[kind]()", "response": "Returns instance of archiver class specific to given kind"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_grad(fun, grad):\n    if issequence(grad):\n        fgrad = [apply_grad(fun, g) for g in grad]\n        return fgrad if len(fgrad) != 1 else fgrad[0]\n    elif len(grad) == 0:\n        return []\n    elif (grad.ndim == 1) or (grad.ndim == 2):\n        return fun(grad)\n    elif grad.ndim == 3:\n        return np.array([fun(grad[:, :, i]) for i in range(grad.shape[2])])\n    else:\n        raise ValueError(\"Only up to 3d gradients allowed!\")", "response": "Apply a function that takes a gradient matrix to a sequence of 2 or 3 dimensional gradients."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dim(self, X):\n        # Cache\n        if not hasattr(self, '_D'):\n            self._D = self.transform(X[[0]], *self.params_values()).shape[1]\n        return self._D", "response": "Get the output dimensionality of this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef params_values(self):\n        return [p.value for p in atleast_list(self.params) if p.has_value]", "response": "Get a list of the parameter values if they have a value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, X):\n        N = len(X)\n        return np.ones((N, 1)) * self.offset", "response": "Return this basis applied to X."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, X):\n        N, D = X.shape\n        return np.hstack((np.ones((N, 1)), X)) if self.onescol else X", "response": "Returns this basis applied to X."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(self, X):\n        N, D = X.shape\n\n        pow_arr = np.arange(self.order) + 1\n\n        # Polynomial terms\n        Phi = X[:, :, np.newaxis] ** pow_arr\n\n        # Flatten along last axes\n        Phi = Phi.reshape(N, D * self.order)\n\n        # Prepend intercept\n        if self.include_bias:\n            Phi = np.hstack((np.ones((N, 1)), Phi))\n\n        # TODO: Using np.hstack is about 4x slower than initializing, say,\n        # an N by d*order+1 ndarray of ones and assigning the remaining\n        # N by d*order values. May want to revisit this implementation.\n\n        return Phi", "response": "Return this basis applied to X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the RBF to X.", "response": "def transform(self, X, lenscale=None):\n        \"\"\"\n        Apply the RBF to X.\n\n        Parameters\n        ----------\n        X: ndarray\n            (N, d) array of observations where N is the number of samples, and\n            d is the dimensionality of X.\n        lenscale: scalar or ndarray, optional\n            scalar or array of shape (d,) length scales (one for each dimension\n            of X). If not input, this uses the value of the initial length\n            scale.\n\n        Returns\n        -------\n        ndarray:\n            of shape (N, D) where D is number of RBF centres.\n        \"\"\"\n        N, d = X.shape\n        lenscale = self._check_dim(d, lenscale)\n\n        den = (2 * lenscale**2)\n        return np.exp(- cdist(X / den, self.C / den, 'sqeuclidean'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grad(self, X, lenscale=None):\n        N, d = X.shape\n        lenscale = self._check_dim(d, lenscale)\n\n        Phi = self.transform(X, lenscale)\n        dPhi = []\n        for i, l in enumerate(lenscale):\n            ldist = cdist(X[:, [i]] / l**3, self.C[:, [i]] / l**3,\n                          'sqeuclidean')\n            dPhi.append(Phi * ldist)\n\n        return np.dstack(dPhi) if len(lenscale) != 1 else dPhi[0]", "response": "r Returns the gradients of this basis w. r. t.. the length scale."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, X, lenscale=None):\n        N, D = X.shape\n        lenscale = self._check_dim(D, lenscale)[:, np.newaxis]\n\n        WX = np.dot(X, self.W / lenscale)\n\n        return np.hstack((np.cos(WX), np.sin(WX))) / np.sqrt(self.n)", "response": "Apply the random basis to X."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grad(self, X, lenscale=None):\n        N, D = X.shape\n        lenscale = self._check_dim(D, lenscale)[:, np.newaxis]\n\n        WX = np.dot(X, self.W / lenscale)\n        sinWX = - np.sin(WX)\n        cosWX = np.cos(WX)\n\n        dPhi = []\n        for i, l in enumerate(lenscale):\n            dWX = np.outer(X[:, i], - self.W[i, :] / l**2)\n            dPhi.append(np.hstack((dWX * sinWX, dWX * cosWX)) /\n                        np.sqrt(self.n))\n\n        return np.dstack(dPhi) if len(lenscale) != 1 else dPhi[0]", "response": "r Returns the gradients of this basis w. r. t.. the length scales."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies the Fast Food RBF basis to X.", "response": "def transform(self, X, lenscale=None):\n        \"\"\"\n        Apply the Fast Food RBF basis to X.\n\n        Parameters\n        ----------\n        X: ndarray\n            (N, d) array of observations where N is the number of samples, and\n            d is the dimensionality of X.\n        lenscale: scalar or ndarray, optional\n            scalar or array of shape (d,) length scales (one for each dimension\n            of X).If not input, this uses the value of the initial length\n            scale.\n\n\n        Returns\n        -------\n        ndarray:\n            of shape (N, 2*nbases) where nbases is number of random bases to\n            use, given in the constructor (to nearest larger two power).\n        \"\"\"\n        lenscale = self._check_dim(X.shape[1], lenscale)\n\n        VX = self._makeVX(X / lenscale)\n        Phi = np.hstack((np.cos(VX), np.sin(VX))) / np.sqrt(self.n)\n        return Phi"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply the spectral mixture component basis to X.", "response": "def transform(self, X, mean=None, lenscale=None):\n        \"\"\"\n        Apply the spectral mixture component basis to X.\n\n        Parameters\n        ----------\n        X: ndarray\n            (N, d) array of observations where N is the number of samples, and\n            d is the dimensionality of X.\n        mean: ndarray, optional\n            array of shape (d,) frequency means (one for each dimension of X).\n            If not input, this uses the value of the initial mean.\n        lenscale: ndarray, optional\n            array of shape (d,) length scales (one for each dimension of X). If\n            not input, this uses the value of the initial length scale.\n\n        Returns\n        -------\n        ndarray:\n            of shape (N, 4*nbases) where nbases is number of random bases to\n            use, given in the constructor (to nearest larger two power).\n        \"\"\"\n        mean = self._check_dim(X.shape[1], mean, paramind=0)\n        lenscale = self._check_dim(X.shape[1], lenscale, paramind=1)\n\n        VX = self._makeVX(X / lenscale)\n        mX = X.dot(mean)[:, np.newaxis]\n        Phi = np.hstack((np.cos(VX + mX), np.sin(VX + mX),\n                         np.cos(VX - mX), np.sin(VX - mX))) / \\\n            np.sqrt(2 * self.n)\n\n        return Phi"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grad(self, X, mean=None, lenscale=None):\n        d = X.shape[1]\n        mean = self._check_dim(d, mean, paramind=0)\n        lenscale = self._check_dim(d, lenscale, paramind=1)\n\n        VX = self._makeVX(X / lenscale)\n        mX = X.dot(mean)[:, np.newaxis]\n\n        sinVXpmX = - np.sin(VX + mX)\n        sinVXmmX = - np.sin(VX - mX)\n        cosVXpmX = np.cos(VX + mX)\n        cosVXmmX = np.cos(VX - mX)\n\n        dPhi_len = []\n        dPhi_mean = []\n        for i, l in enumerate(lenscale):\n\n            # Means\n            dmX = X[:, [i]]\n            dPhi_mean.append(np.hstack((dmX * sinVXpmX, dmX * cosVXpmX,\n                                        -dmX * sinVXmmX, -dmX * cosVXmmX)) /\n                             np.sqrt(2 * self.n))\n\n            # Lenscales\n            indlen = np.zeros(d)\n            indlen[i] = 1. / l**2\n            dVX = - self._makeVX(X * indlen)  # FIXME make this more efficient?\n            dPhi_len.append(np.hstack((dVX * sinVXpmX, dVX * cosVXpmX,\n                                       dVX * sinVXmmX, dVX * cosVXmmX)) /\n                            np.sqrt(2 * self.n))\n\n        dPhi_mean = np.dstack(dPhi_mean) if d != 1 else dPhi_mean[0]\n        dPhi_len = np.dstack(dPhi_len) if d != 1 else dPhi_len[0]\n        return dPhi_mean, dPhi_len", "response": "r Returns the gradients of the basis w. r. t. the mean and length scales of the random rbf bases."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the basis function applied to X.", "response": "def transform(self, X, *params):\n        \"\"\"\n        Return the basis function applied to X.\n\n        I.e. Phi(X, params), where params can also optionally be used and\n        learned.\n\n        Parameters\n        ----------\n        X : ndarray\n            (N, d) array of observations where N is the number of samples, and\n            d is the dimensionality of X.\n        *params : optional\n            parameter aguments, these are the parameters of the concatenated\n            bases `in the order` they were concatenated.\n\n        Returns\n        -------\n        ndarray :\n            of shape (N, D) where D is the number of basis functions.\n        \"\"\"\n        Phi = []\n        args = list(params)\n\n        for base in self.bases:\n            phi, args = base._transform_popargs(X, *args)\n            Phi.append(phi)\n\n        return np.hstack(Phi)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grad(self, X, *params):\n        # Establish a few dimensions\n        N = X.shape[0]\n        D = self.get_dim(X)\n        endinds = self.__base_locations(X)  # for the Padding indices\n        args = list(params)\n\n        # Generate structured gradients with appropriate zero padding\n        def make_dPhi(i, g):\n\n            # Pad the gradient with respect to the total basis dimensionality\n            dPhi_dim = (N, D) if g.ndim < 3 else (N, D, g.shape[2])\n            dPhi = np.zeros(dPhi_dim)\n            dPhi[:, endinds[i]:endinds[i + 1]] = g\n\n            return dPhi\n\n        # Get gradients from each basis\n        for i, base in enumerate(self.bases):\n\n            # evaluate gradient and deal with multiple parameter gradients by\n            # keeping track of the basis index\n            g, args, sargs = base._grad_popargs(X, *args)\n\n            for gg in atleast_tuple(g):\n                if len(gg) == 0:\n                    continue\n                yield make_dPhi(i, gg)", "response": "Returns the gradient of the basis function for each parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all of the Parameter objects.", "response": "def params(self):\n        \"\"\"\n        Return a list of all of the ``Parameter`` objects.\n\n        Or a just a single ``Parameter`` is there is only one, and single empty\n        ``Parameter`` if there are no parameters.\n        \"\"\"\n        paramlist = [b.params for b in self.bases if b.params.has_value]\n\n        if len(paramlist) == 0:\n            return Parameter()\n        else:\n            return paramlist if len(paramlist) > 1 else paramlist[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_udiff(filenode_old, filenode_new, show_whitespace=True):\n    try:\n        filenode_old_date = filenode_old.changeset.date\n    except NodeError:\n        filenode_old_date = None\n\n    try:\n        filenode_new_date = filenode_new.changeset.date\n    except NodeError:\n        filenode_new_date = None\n\n    for filenode in (filenode_old, filenode_new):\n        if not isinstance(filenode, FileNode):\n            raise VCSError(\"Given object should be FileNode object, not %s\"\n                % filenode.__class__)\n\n    if filenode_old_date and filenode_new_date:\n        if not filenode_old_date < filenode_new_date:\n            logging.debug(\"Generating udiff for filenodes with not increasing \"\n                \"dates\")\n\n    vcs_udiff = unified_diff(filenode_old.content.splitlines(True),\n                               filenode_new.content.splitlines(True),\n                               filenode_old.name,\n                               filenode_new.name,\n                               filenode_old_date,\n                               filenode_old_date)\n    return vcs_udiff", "response": "Returns unified diff between given filenode_old and filenode_new."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_gitdiff(filenode_old, filenode_new, ignore_whitespace=True):\n\n    for filenode in (filenode_old, filenode_new):\n        if not isinstance(filenode, FileNode):\n            raise VCSError(\"Given object should be FileNode object, not %s\"\n                % filenode.__class__)\n\n    old_raw_id = getattr(filenode_old.changeset, 'raw_id', '0' * 40)\n    new_raw_id = getattr(filenode_new.changeset, 'raw_id', '0' * 40)\n\n    repo = filenode_new.changeset.repository\n    vcs_gitdiff = repo.get_diff(old_raw_id, new_raw_id, filenode_new.path,\n                                 ignore_whitespace)\n\n    return vcs_gitdiff", "response": "Returns git style diff between given filenode_old and filenode_new."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_iterator(self):\n        self.__udiff, iterator_copy = itertools.tee(self.__udiff)\n        return iterator_copy", "response": "make a fresh copy of the generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_rev(self, line1, line2):\n\n        try:\n            if line1.startswith('--- ') and line2.startswith('+++ '):\n                l1 = line1[4:].split(None, 1)\n                old_filename = l1[0].lstrip('a/') if len(l1) >= 1 else None\n                old_rev = l1[1] if len(l1) == 2 else 'old'\n\n                l2 = line2[4:].split(None, 1)\n                new_filename = l2[0].lstrip('b/') if len(l1) >= 1 else None\n                new_rev = l2[1] if len(l2) == 2 else 'new'\n\n                filename = old_filename if (old_filename !=\n                                            'dev/null') else new_filename\n\n                return filename, new_rev, old_rev\n        except (ValueError, IndexError):\n            pass\n\n        return None, None, None", "response": "Extract the filename and revision hint from a line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _highlight_line_difflib(self, line, next):\n\n        if line['action'] == 'del':\n            old, new = line, next\n        else:\n            old, new = next, line\n\n        oldwords = re.split(r'(\\W)', old['line'])\n        newwords = re.split(r'(\\W)', new['line'])\n\n        sequence = difflib.SequenceMatcher(None, oldwords, newwords)\n\n        oldfragments, newfragments = [], []\n        for tag, i1, i2, j1, j2 in sequence.get_opcodes():\n            oldfrag = ''.join(oldwords[i1:i2])\n            newfrag = ''.join(newwords[j1:j2])\n            if tag != 'equal':\n                if oldfrag:\n                    oldfrag = '<del>%s</del>' % oldfrag\n                if newfrag:\n                    newfrag = '<ins>%s</ins>' % newfrag\n            oldfragments.append(oldfrag)\n            newfragments.append(newfrag)\n\n        old['line'] = \"\".join(oldfragments)\n        new['line'] = \"\".join(newfragments)", "response": "Highlight inline changes in both lines."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhighlighting inline changes in both lines.", "response": "def _highlight_line_udiff(self, line, next):\n        \"\"\"\n        Highlight inline changes in both lines.\n        \"\"\"\n        start = 0\n        limit = min(len(line['line']), len(next['line']))\n        while start < limit and line['line'][start] == next['line'][start]:\n            start += 1\n        end = -1\n        limit -= start\n        while -end <= limit and line['line'][end] == next['line'][end]:\n            end -= 1\n        end += 1\n        if start or end:\n            def do(l):\n                last = end + len(l['line'])\n                if l['action'] == 'add':\n                    tag = 'ins'\n                else:\n                    tag = 'del'\n                l['line'] = '%s<%s>%s</%s>%s' % (\n                    l['line'][:start],\n                    tag,\n                    l['line'][start:last],\n                    tag,\n                    l['line'][last:]\n                )\n            do(line)\n            do(next)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the diff and return a list of dictionaries.", "response": "def _parse_udiff(self):\n        \"\"\"\n        Parse the diff an return data for the template.\n        \"\"\"\n        lineiter = self.lines\n        files = []\n        try:\n            line = lineiter.next()\n            # skip first context\n            skipfirst = True\n            while 1:\n                # continue until we found the old file\n                if not line.startswith('--- '):\n                    line = lineiter.next()\n                    continue\n\n                chunks = []\n                filename, old_rev, new_rev = \\\n                    self._extract_rev(line, lineiter.next())\n                files.append({\n                    'filename':         filename,\n                    'old_revision':     old_rev,\n                    'new_revision':     new_rev,\n                    'chunks':           chunks\n                })\n\n                line = lineiter.next()\n                while line:\n                    match = self._chunk_re.match(line)\n                    if not match:\n                        break\n\n                    lines = []\n                    chunks.append(lines)\n\n                    old_line, old_end, new_line, new_end = \\\n                        [int(x or 1) for x in match.groups()[:-1]]\n                    old_line -= 1\n                    new_line -= 1\n                    context = len(match.groups()) == 5\n                    old_end += old_line\n                    new_end += new_line\n\n                    if context:\n                        if not skipfirst:\n                            lines.append({\n                                'old_lineno': '...',\n                                'new_lineno': '...',\n                                'action': 'context',\n                                'line': line,\n                            })\n                        else:\n                            skipfirst = False\n\n                    line = lineiter.next()\n                    while old_line < old_end or new_line < new_end:\n                        if line:\n                            command, line = line[0], line[1:]\n                        else:\n                            command = ' '\n                        affects_old = affects_new = False\n\n                        # ignore those if we don't expect them\n                        if command in '#@':\n                            continue\n                        elif command == '+':\n                            affects_new = True\n                            action = 'add'\n                        elif command == '-':\n                            affects_old = True\n                            action = 'del'\n                        else:\n                            affects_old = affects_new = True\n                            action = 'unmod'\n\n                        old_line += affects_old\n                        new_line += affects_new\n                        lines.append({\n                            'old_lineno':   affects_old and old_line or '',\n                            'new_lineno':   affects_new and new_line or '',\n                            'action':       action,\n                            'line':         line\n                        })\n                        line = lineiter.next()\n\n        except StopIteration:\n            pass\n\n        # highlight inline changes\n        for file in files:\n            for chunk in chunks:\n                lineiter = iter(chunk)\n                #first = True\n                try:\n                    while 1:\n                        line = lineiter.next()\n                        if line['action'] != 'unmod':\n                            nextline = lineiter.next()\n                            if nextline['action'] == 'unmod' or \\\n                               nextline['action'] == line['action']:\n                                continue\n                            self.differ(line, nextline)\n                except StopIteration:\n                    pass\n\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a string safe for including in an id attribute.", "response": "def _safe_id(self, idstring):\n        \"\"\"Make a string safe for including in an id attribute.\n\n        The HTML spec says that id attributes 'must begin with\n        a letter ([A-Za-z]) and may be followed by any number\n        of letters, digits ([0-9]), hyphens (\"-\"), underscores\n        (\"_\"), colons (\":\"), and periods (\".\")'. These regexps\n        are slightly over-zealous, in that they remove colons\n        and periods unnecessarily.\n\n        Whitespace is transformed into underscores, and then\n        anything which is not a hyphen or a character that\n        matches \\w (alphanumerics and underscore) is removed.\n\n        \"\"\"\n        # Transform all whitespace to underscore\n        idstring = re.sub(r'\\s', \"_\", '%s' % idstring)\n        # Remove everything that is not a hyphen or a member of \\w\n        idstring = re.sub(r'(?!-)\\W', \"\", idstring).lower()\n        return idstring"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string of the raw diff of the current object as udiff", "response": "def raw_diff(self):\n        \"\"\"\n        Returns raw string as udiff\n        \"\"\"\n        udiff_copy = self.copy_iterator()\n        if self.__format == 'gitdiff':\n            udiff_copy = self._parse_gitdiff(udiff_copy)\n        return u''.join(udiff_copy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_html(self, table_class='code-difftable', line_class='line',\n                new_lineno_class='lineno old', old_lineno_class='lineno new',\n                code_class='code'):\n        \"\"\"\n        Return udiff as html table with customized css classes\n        \"\"\"\n        def _link_to_if(condition, label, url):\n            \"\"\"\n            Generates a link if condition is meet or just the label if not.\n            \"\"\"\n\n            if condition:\n                return '''<a href=\"%(url)s\">%(label)s</a>''' % {'url': url,\n                                                                'label': label}\n            else:\n                return label\n        diff_lines = self.prepare()\n        _html_empty = True\n        _html = []\n        _html.append('''<table class=\"%(table_class)s\">\\n''' \\\n                                            % {'table_class': table_class})\n        for diff in diff_lines:\n            for line in diff['chunks']:\n                _html_empty = False\n                for change in line:\n                    _html.append('''<tr class=\"%(line_class)s %(action)s\">\\n''' \\\n                        % {'line_class': line_class,\n                           'action': change['action']})\n                    anchor_old_id = ''\n                    anchor_new_id = ''\n                    anchor_old = \"%(filename)s_o%(oldline_no)s\" % \\\n                                {'filename': self._safe_id(diff['filename']),\n                                 'oldline_no': change['old_lineno']}\n                    anchor_new = \"%(filename)s_n%(oldline_no)s\" % \\\n                                {'filename': self._safe_id(diff['filename']),\n                                 'oldline_no': change['new_lineno']}\n                    cond_old = change['old_lineno'] != '...' and \\\n                                                        change['old_lineno']\n                    cond_new = change['new_lineno'] != '...' and \\\n                                                        change['new_lineno']\n                    if cond_old:\n                        anchor_old_id = 'id=\"%s\"' % anchor_old\n                    if cond_new:\n                        anchor_new_id = 'id=\"%s\"' % anchor_new\n                    ###########################################################\n                    # OLD LINE NUMBER\n                    ###########################################################\n                    _html.append('''\\t<td %(a_id)s class=\"%(old_lineno_cls)s\">''' \\\n                                    % {'a_id': anchor_old_id,\n                                       'old_lineno_cls': old_lineno_class})\n\n                    _html.append('''<pre>%(link)s</pre>''' \\\n                        % {'link':\n                        _link_to_if(cond_old, change['old_lineno'], '#%s' \\\n                                                                % anchor_old)})\n                    _html.append('''</td>\\n''')\n                    ###########################################################\n                    # NEW LINE NUMBER\n                    ###########################################################\n\n                    _html.append('''\\t<td %(a_id)s class=\"%(new_lineno_cls)s\">''' \\\n                                    % {'a_id': anchor_new_id,\n                                       'new_lineno_cls': new_lineno_class})\n\n                    _html.append('''<pre>%(link)s</pre>''' \\\n                        % {'link':\n                        _link_to_if(cond_new, change['new_lineno'], '#%s' \\\n                                                                % anchor_new)})\n                    _html.append('''</td>\\n''')\n                    ###########################################################\n                    # CODE\n                    ###########################################################\n                    _html.append('''\\t<td class=\"%(code_class)s\">''' \\\n                                                % {'code_class': code_class})\n                    _html.append('''\\n\\t\\t<pre>%(code)s</pre>\\n''' \\\n                                                % {'code': change['line']})\n                    _html.append('''\\t</td>''')\n                    _html.append('''\\n</tr>\\n''')\n        _html.append('''</table>''')\n        if _html_empty:\n            return None\n        return ''.join(_html)", "response": "Return udiff as html table with customized css classes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cache(self, link, nav):\n        '''Stores a navigator in the identity map for the current\n        api. Can take a link or a bare uri'''\n        if link is None:\n            return  # We don't cache navigators without a Link\n        elif hasattr(link, 'uri'):\n            self.id_map[link.uri] = nav\n        else:\n            self.id_map[link] = nav", "response": "Stores a navigator in the identity map for the current\n        api. Can take a link or bare uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cached(self, link, default=None):\n        '''Retrieves a cached navigator from the id_map.\n\n        Either a Link object or a bare uri string may be passed in.'''\n        if hasattr(link, 'uri'):\n            return self.id_map.get(link.uri, default)\n        else:\n            return self.id_map.get(link, default)", "response": "Retrieves a cached navigator from the id_map."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns whether the current navigator is cached. Intended to be overwritten by subclasses.", "response": "def is_cached(self, link):\n        '''Returns whether the current navigator is cached. Intended\n        to be overwritten and customized by subclasses.\n        '''\n        if link is None:\n            return False\n        elif hasattr(link, 'uri'):\n            return link.uri in self.id_map\n        else:\n            return link in self.id_map"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the template uri expanded with the current arguments", "response": "def expand_uri(self, **kwargs):\n        '''Returns the template uri expanded with the current arguments'''\n        kwargs = dict([(k, v if v != 0 else '0') for k, v in kwargs.items()])\n        return uritemplate.expand(self.link.uri, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpanding with the given arguments and returns a new untemplated Link object", "response": "def expand_link(self, **kwargs):\n        '''Expands with the given arguments and returns a new\n        untemplated Link object\n        '''\n        props = self.link.props.copy()\n        del props['templated']\n        return Link(\n            uri=self.expand_uri(**kwargs),\n            properties=props,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hal(root, \n            apiname=None, \n            default_curie=None,\n            auth=None, \n            headers=None, \n            session=None,\n            ):\n        '''Create a HALNavigator'''\n        root = utils.fix_scheme(root)\n        halnav = HALNavigator(\n            link=Link(uri=root),\n            core=APICore(\n                root=root,\n                nav_class=HALNavigator,\n                apiname=apiname,\n                default_curie=default_curie,\n                session=session,\n            )\n        )\n        if auth:\n            halnav.authenticate(auth)\n        halnav.headers.update(DEFAULT_HEADERS)\n        if headers is not None:\n            halnav.headers.update(headers)\n        return halnav", "response": "Create a HALNavigator object from a root URI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the documentation for a link relation. Opens in a webbrowser window.", "response": "def docsfor(self, rel):  # pragma: nocover\n        '''Obtains the documentation for a link relation. Opens in a webbrowser\n        window'''\n        prefix, _rel = rel.split(':')\n        if prefix in self.curies:\n            doc_url = uritemplate.expand(self.curies[prefix], {'rel': _rel})\n        else:\n            doc_url = rel\n        print('opening', doc_url)\n        webbrowser.open(doc_url)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_links_from(self, body):\n        '''Creates linked navigators from a HAL response body'''\n        ld = utils.CurieDict(self._core.default_curie, {})\n        for rel, link in body.get('_links', {}).items():\n            if rel != 'curies':\n                if isinstance(link, list):\n                    ld[rel] = utils.LinkList(\n                        (self._navigator_or_thunk(lnk), lnk) for lnk in link)\n                else:\n                    ld[rel] = self._navigator_or_thunk(link)\n        return ld", "response": "Creates linked navigators from a HAL response body"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate embedded navigators from a HAL response doc", "response": "def _make_embedded_from(self, doc):\n        '''Creates embedded navigators from a HAL response doc'''\n        ld = utils.CurieDict(self._core.default_curie, {})\n        for rel, doc in doc.get('_embedded', {}).items():\n            if isinstance(doc, list):\n                ld[rel] = [self._recursively_embed(d) for d in doc]\n            else:\n                ld[rel] = self._recursively_embed(doc)\n        return ld"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _recursively_embed(self, doc, update_state=True):\n        '''Crafts a navigator from a hal-json embedded document'''\n        self_link = None\n        self_uri = utils.getpath(doc, '_links.self.href')\n        if self_uri is not None:\n            uri = urlparse.urljoin(self.uri, self_uri)\n            self_link = Link(\n                uri=uri,\n                properties=utils.getpath(doc, '_links.self')\n            )\n        curies = utils.getpath(doc, '_links.curies')\n        state = utils.getstate(doc)\n        if self_link is None:\n            nav = OrphanHALNavigator(\n                link=None,\n                response=None,\n                parent=self,\n                core=self._core,\n                curies=curies,\n                state=state,\n            )\n        else:\n            nav = HALNavigator(\n                link=self_link,\n                response=None,\n                core=self._core,\n                curies=curies,\n                state=state,\n            )\n        if update_state:\n            nav.state = state\n\n        links = self._make_links_from(doc)\n        if links is not None:\n            nav._links = links\n        embedded = self._make_embedded_from(doc)\n        if embedded is not None:\n            nav._embedded = embedded\n        return nav", "response": "Creates a navigator from a hal - json embedded document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncrafting a navigator or from a hal - json link dict.", "response": "def _navigator_or_thunk(self, link):\n        '''Crafts a navigator or from a hal-json link dict.\n\n        If the link is relative, the returned navigator will have a\n        uri that relative to this navigator's uri.\n\n        If the link passed in is templated, a PartialNavigator will be\n        returned instead.\n        '''\n        # resolve relative uris against the current uri\n        uri = urlparse.urljoin(self.uri, link['href'])\n        link_obj = Link(uri=uri, properties=link)\n        if link.get('templated'):\n            # Can expand into a real HALNavigator\n            return PartialNavigator(link_obj, core=self._core)\n        else:\n            return HALNavigator(link_obj, core=self._core)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the content - type matches one of the types specifiedby the Accept header of the request.", "response": "def _can_parse(self, content_type):\n        '''Whether this navigator can parse the given content-type.\n        Checks that the content_type matches one of the types specified\n        in the 'Accept' header of the request, if supplied.\n        If not supplied, matches against the default'''\n        content_type, content_subtype, content_param = utils.parse_media_type(content_type)\n        for accepted in self.headers.get('Accept', self.DEFAULT_CONTENT_TYPE).split(','):\n            type, subtype, param = utils.parse_media_type(accepted)\n            # if either accepted_type or content_type do not\n            # contain a parameter section, then it will be\n            # optimistically ignored\n            matched = (type == content_type) \\\n                      and (subtype == content_subtype) \\\n                      and (param == content_param or not (param and content_param))\n            if matched:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the content of a response doc into the correct format for. state.", "response": "def _parse_content(self, text):\n        '''Parses the content of a response doc into the correct\n        format for .state.\n        '''\n        try:\n            return json.loads(text)\n        except ValueError:\n            raise exc.UnexpectedlyNotJSON(\n                \"The resource at {.uri} wasn't valid JSON\", self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_self_link(self, link, headers):\n        '''Update the self link of this navigator'''\n        self.self.props.update(link)\n        # Set the self.type to the content_type of the returned document\n        self.self.props['type'] = headers.get(\n            'Content-Type', self.DEFAULT_CONTENT_TYPE)\n        self.self.props", "response": "Update the self link of this navigator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ingest_response(self, response):\n        '''Takes a response object and ingests state, links, embedded\n        documents and updates the self link of this navigator to\n        correspond. This will only work if the response is valid\n        JSON\n        '''\n        self.response = response\n        if self._can_parse(response.headers['Content-Type']):\n            hal_json = self._parse_content(response.text)\n        else:\n            raise exc.HALNavigatorError(\n                message=\"Unexpected content type! Wanted {0}, got {1}\"\n                .format(self.headers.get('Accept', self.DEFAULT_CONTENT_TYPE),\n                        self.response.headers['content-type']),\n                nav=self,\n                status=self.response.status_code,\n                response=self.response,\n            )\n        self._links = self._make_links_from(hal_json)\n        self._embedded = self._make_embedded_from(hal_json)\n        # Set properties from new document's self link\n        self._update_self_link(\n            hal_json.get('_links', {}).get('self', {}),\n            response.headers,\n        )\n        # Set curies if available\n        self.curies = dict(\n            (curie['name'], curie['href'])\n            for curie in\n            hal_json.get('_links', {}).get('curies', []))\n        # Set state by removing HAL attributes\n        self.state = utils.getstate(hal_json)", "response": "Takes a response object and ingests state links embedded\n            documents and updates the self link of this navigator to\n        correspond."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the appropriate navigator from an api response", "response": "def _create_navigator(self, response, raise_exc=True):\n        '''Create the appropriate navigator from an api response'''\n        method = response.request.method\n        # TODO: refactor once hooks in place\n        if method in (POST, PUT, PATCH, DELETE) \\\n           and response.status_code in (\n                http_client.CREATED,\n                http_client.FOUND,\n                http_client.SEE_OTHER,\n                http_client.NO_CONTENT) \\\n           and 'Location' in response.headers:\n            uri = urlparse.urljoin(self._core.root, response.headers['Location'])\n            nav = HALNavigator(\n                link=Link(uri=uri),\n                core=self._core\n            )\n            # We don't ingest the response because we haven't fetched\n            # the newly created resource yet\n        elif method in (POST, PUT, PATCH, DELETE):\n            nav = OrphanHALNavigator(\n                link=None,\n                core=self._core,\n                response=response,\n                parent=self,\n            )\n            nav._ingest_response(response)\n        elif method == GET:\n            nav = self\n            nav._ingest_response(response)\n        else: # pragma: nocover\n            assert False, \"This shouldn't happen\"\n\n        return nav"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching HTTP response using the passed http method. Raises HALNavigatorError if response is in the 400 - 500 range.", "response": "def _request(self, method, body=None, raise_exc=True, headers=None, files=None):\n        '''Fetches HTTP response using the passed http method. Raises\n        HALNavigatorError if response is in the 400-500 range.'''\n        headers = headers or {}\n        if body and 'Content-Type' not in headers:\n            headers.update({'Content-Type': 'application/json'})\n        response = self._core.session.request(\n            method,\n            self.uri,\n            data=body if not isinstance(body, dict) else None,\n            json=body if isinstance(body, dict) else None,\n            files=files,\n            headers=headers,\n            allow_redirects=False,\n        )\n        nav = self._create_navigator(response, raise_exc=raise_exc)\n        if raise_exc and not response:\n            raise exc.HALNavigatorError(\n                message=response.text,\n                status=response.status_code,\n                nav=nav,  # may be self\n                response=response,\n            )\n        else:\n            return nav"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(self, raise_exc=True):\n        '''Performs a GET request to the uri of this navigator'''\n        self._request(GET, raise_exc=raise_exc)  # ingests response\n        self.fetched = True\n        return self.state.copy()", "response": "Performs a GET request to the uri of this navigator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, body=None, raise_exc=True, headers=None, **kwargs):\n        '''Performs an HTTP POST to the server, to create a\n        subordinate resource. Returns a new HALNavigator representing\n        that resource.\n\n        `body` may either be a string or a dictionary representing json\n        `headers` are additional headers to send in the request\n        '''\n        return self._request(POST, body, raise_exc, headers, **kwargs)", "response": "Creates a new HALNavigator representing the a\n        subordinate resource. Returns a new HALNavigator representing the a\n        subordinate resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, raise_exc=True, headers=None, files=None):\n        '''Performs an HTTP DELETE to the server, to delete resource(s).\n\n        `headers` are additional headers to send in the request'''\n\n        return self._request(DELETE, None, raise_exc, headers, files)", "response": "Performs an HTTP DELETE to the server to delete resource ( s )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform an HTTP PUT to the server.", "response": "def upsert(self, body, raise_exc=True, headers=False, files=None):\n        '''Performs an HTTP PUT to the server. This is an idempotent\n        call that will create the resource this navigator is pointing\n        to, or will update it if it already exists.\n\n        `body` may either be a string or a dictionary representing json\n        `headers` are additional headers to send in the request\n        '''\n        return self._request(PUT, body, raise_exc, headers, files)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch(self, body, raise_exc=True, headers=False, files=None):\n        '''Performs an HTTP PATCH to the server. This is a\n        non-idempotent call that may update all or a portion of the\n        resource this navigator is pointing to. The format of the\n        patch body is up to implementations.\n\n        `body` may either be a string or a dictionary representing json\n        `headers` are additional headers to send in the request\n        '''\n        return self._request(PATCH, body, raise_exc, headers, files)", "response": "Performs an HTTP PATCH to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to parse as HAL but on failure use an empty dict", "response": "def _parse_content(self, text):\n        '''Try to parse as HAL, but on failure use an empty dict'''\n        try:\n            return super(OrphanHALNavigator, self)._parse_content(text)\n        except exc.UnexpectedlyNotJSON:\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs - sum - exp trick for matrix X for summation along a specified axis.", "response": "def logsumexp(X, axis=0):\n    \"\"\"\n    Log-sum-exp trick for matrix X for summation along a specified axis.\n\n    This performs the following operation in a stable fashion,\n\n    .. math::\n\n        \\log \\sum^K_{k=1} \\exp\\{x_k\\}\n\n    Parameters\n    ----------\n        X: ndarray\n            2D array of shape (N, D) to apply the log-sum-exp trick.\n        axis: int, optional\n            Axis to apply the summation along (works the same as axis in\n            numpy.sum).\n\n    Returns\n    -------\n        lseX: ndarray\n            results of applying the log-sum-exp trick, this will be shape (D,)\n            if :code:`axis=0` or shape (N,) if :code:`axis=1`.\n    \"\"\"\n\n    mx = X.max(axis=axis)\n    if (X.ndim > 1):\n        mx = np.atleast_2d(mx).T if axis == 1 else np.atleast_2d(mx)\n\n    return np.log(np.exp(X - mx).sum(axis=axis)) + np.ravel(mx)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef softmax(X, axis=0):\n\n    if axis == 1:\n        return np.exp(X - logsumexp(X, axis=1)[:, np.newaxis])\n    elif axis == 0:\n        return np.exp(X - logsumexp(X, axis=0))\n    else:\n        raise ValueError(\"This only works on 2D arrays for now.\")", "response": "This function calculates the softmax of a 2D array X along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef softplus(X):\n\n    if np.isscalar(X):\n        return logsumexp(np.vstack((np.zeros(1), [X])).T, axis=1)[0]\n\n    N = X.shape[0]\n\n    if X.ndim == 1:\n        return logsumexp(np.vstack((np.zeros(N), X)).T, axis=1)\n    elif X.ndim == 2:\n        sftX = np.empty(X.shape, dtype=float)\n        for d in range(X.shape[1]):\n            sftX[:, d] = logsumexp(np.vstack((np.zeros(N), X[:, d])).T, axis=1)\n        return sftX\n    else:\n        raise ValueError(\"This only works on up to 2D arrays.\")", "response": "Pass X through a numerically - available soft - plus function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if credit card number fits the visa format.", "response": "def is_visa(n):\n    \"\"\"Checks if credit card number fits the visa format.\"\"\"\n    n, length = str(n), len(str(n))\n\n    if length >= 13 and length <= 16:\n        if n[0] == '4':\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_visa_electron(n):\n    n, length = str(n), len(str(n))\n    form = ['026', '508', '844', '913', '917']\n\n    if length == 16:\n        if n[0] == '4':\n            if ''.join(n[1:4]) in form or ''.join(n[1:6]) == '17500':\n                return True\n    return False", "response": "Checks if credit card number fits the visa electron format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if credit card number fits the mastercard format.", "response": "def is_mastercard(n):\n    \"\"\"Checks if credit card number fits the mastercard format.\"\"\"\n    n, length = str(n), len(str(n))\n\n    if length >= 16 and length <= 19:\n        if ''.join(n[:2]) in strings_between(51, 56):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_amex(n):\n    n, length = str(n), len(str(n))\n\n    if length == 15:\n        if n[0] == '3' and (n[1] == '4' or n[1] == '7'):\n            return True\n    return False", "response": "Checks if credit card number fits the american express format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if credit card number fits the discover card format.", "response": "def is_discover(n):\n    \"\"\"Checks if credit card number fits the discover card format.\"\"\"\n    n, length = str(n), len(str(n))\n\n    if length == 16:\n        if n[0] == '6':\n            if ''.join(n[1:4]) == '011' or n[1] == '5':\n                return True\n            elif n[1] == '4' and n[2] in strings_between(4, 10):\n                return True\n            elif ''.join(n[1:6]) in strings_between(22126, 22926):\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_format(n):\n    formats = []\n\n    if is_visa(n):\n        formats.append('visa')\n    if is_visa_electron(n):\n        formats.append('visa electron')\n    if is_mastercard(n):\n        formats.append('mastercard')\n    if is_amex(n):\n        formats.append('amex')\n    if is_maestro(n):\n        formats.append('maestro')\n    if is_discover(n):\n        formats.append('discover')\n\n    return formats", "response": "Gets a list of the formats a credit card number fits."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unvectorize_args(fn):\n\n    \"\"\"\n    See Also\n    --------\n    revrand.utils.decorators.vectorize_args\n\n    Examples\n    --------\n    The Rosenbrock function is commonly used as a performance test \n    problem for optimization algorithms. It and its derivatives are \n    included in `scipy.optimize` and is implemented as expected by the \n    family of optimization methods in `scipy.optimize`.\n\n        def rosen(x):\n            return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n\n    This representation makes it unwieldy to perform operations such as \n    plotting since it is less straightforward to evaluate the function \n    on a `meshgrid`. This decorator helps reconcile the differences \n    between these representations.\n\n    >>> from scipy.optimize import rosen\n\n    >>> rosen(np.array([0.5, 1.5]))\n    156.5\n\n    >>> unvectorize_args(rosen)(0.5, 1.5) \n    ... # doctest: +NORMALIZE_WHITESPACE\n    156.5    \n\n    The `rosen` function is implemented in such a way that it \n    generalizes to the Rosenbrock function of any number of variables. \n    This decorator supports can support any functions defined in a \n    similar manner.\n\n    The function with any number of arguments are well-defined:\n\n    >>> rosen(np.array([0.5, 1.5, 1., 0., 0.2]))\n    418.0\n\n    >>> unvectorize_args(rosen)(0.5, 1.5, 1., 0., 0.2)\n    ... # can accept any variable number of arguments!\n    418.0\n\n    Make it easier to work with for other operations\n\n    >>> rosen_ = unvectorize_args(rosen)\n    >>> y, x = np.mgrid[0:2.1:0.05, -1:1.2:0.05]\n    >>> z = rosen_(x, y)\n    >>> z.round(2)\n    array([[ 104.  ,   85.25,   69.22, ...,  121.55,  146.42,  174.92],\n           [  94.25,   76.48,   61.37, ...,  110.78,  134.57,  161.95],\n           [  85.  ,   68.2 ,   54.02, ...,  100.5 ,  123.22,  149.47],\n           ..., \n           [  94.25,  113.53,  133.57, ...,   71.83,   54.77,   39.4 ],\n           [ 104.  ,  124.25,  145.22, ...,   80.55,   62.42,   45.92],\n           [ 114.25,  135.48,  157.37, ...,   89.78,   70.57,   52.95]])\n\n    Now this can be directly plotted with `mpl_toolkits.mplot3d.Axes3D` \n    and `ax.plot_surface`.\n\n    \"\"\"\n    @wraps(fn)\n    def new_fn(*args):\n        return fn(np.asarray(args))\n    return new_fn", "response": "This function unvectorizes the arguments of a Rosenbrock function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns full name of member", "response": "def full_name(self):\n        \"\"\"Return full name of member\"\"\"\n        if self.prefix is not None:\n            return '.'.join([self.prefix, self.member])\n        return self.member"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a signature string into a DotNetSignature object.", "response": "def parse_signature(cls, signature):\n        \"\"\"Parse signature declartion string\n\n        Uses :py:attr:`signature_pattern` to parse out pieces of constraint\n        signatures. Pattern should provide the following named groups:\n\n            prefix\n                Object prefix, such as a namespace\n\n            member\n                Object member name\n\n            arguments\n                Declaration arguments, if this is a callable constraint\n\n        :param signature: construct signature\n        :type signature: string\n        \"\"\"\n        assert cls.signature_pattern is not None\n        pattern = re.compile(cls.signature_pattern, re.VERBOSE)\n        match = pattern.match(signature)\n        if match:\n            groups = match.groupdict()\n            arguments = None\n            if 'arguments' in groups and groups['arguments'] is not None:\n                arguments = re.split(r'\\,\\s+', groups['arguments'])\n            return DotNetSignature(\n                prefix=groups.get('prefix', None),\n                member=groups.get('member', None),\n                arguments=arguments\n            )\n        raise ValueError('Could not parse signature: {0}'.format(signature))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_signature(self, sig, signode):\n        try:\n            sig = self.parse_signature(sig.strip())\n        except ValueError:\n            self.env.warn(self.env.docname,\n                          'Parsing signature failed: \"{}\"'.format(sig),\n                          self.lineno)\n            raise\n\n        prefix = self.env.ref_context.get('dn:prefix', None)\n\n        if prefix is not None:\n            sig.prefix = prefix\n\n        signode['object'] = sig.member\n        signode['prefix'] = sig.prefix\n        signode['fullname'] = sig.full_name()\n\n        # Prefix modifiers\n        if self.display_prefix:\n            signode += addnodes.desc_annotation(self.display_prefix,\n                                                self.display_prefix)\n        for prefix in ['public', 'protected', 'static']:\n            if prefix in self.options:\n                signode += addnodes.desc_annotation(prefix + ' ',\n                                                    prefix + ' ')\n\n        # Show prefix only on shorter declarations\n        if sig.prefix is not None and not self.has_arguments:\n            signode += addnodes.desc_addname(sig.prefix + '.', sig.prefix + '.')\n\n        signode += addnodes.desc_name(sig.member, sig.member)\n        if self.has_arguments:\n            if not sig.arguments:\n                signode += addnodes.desc_parameterlist()\n            else:\n                # TODO replace this\n                _pseudo_parse_arglist(signode, ', '.join(sig.arguments))\n\n        if isinstance(self, DotNetObjectNested):\n            return sig.full_name(), sig.full_name()\n        return sig.full_name(), sig.prefix", "response": "Parses out pieces from construct signatures and returns a dict with the full name and the full name of the class and class as keys and the list of attributes as values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd objects to the domain list of objects that are type and name unique.", "response": "def add_target_and_index(self, name, sig, signode):\n        \"\"\"Add objects to the domain list of objects\n\n        This uses the directive short name along with the full object name to\n        create objects and nodes that are type and name unique.\n        \"\"\"\n        full_name = name[0]\n        target_name = '{0}-{1}'.format(self.short_name, full_name)\n        if target_name not in self.state.document.ids:\n            signode['names'].append(target_name)\n            signode['ids'].append(target_name)\n            signode['first'] = not self.names\n            self.state.document.note_explicit_target(signode)\n\n            # Update domain objects\n            objects = self.env.domaindata['dn']['objects']\n            try:\n                found_obj = objects[full_name]\n                (found_doc, found_type) = found_obj\n                self.state_machine.reporter.warning(\n                    ('duplicate object definition of {obj_type} {obj_name}'\n                     'other instance in {path}'\n                     .format(obj_type=found_type, obj_name=full_name,\n                             path=self.env.doc2path(found_doc))),\n                    line=self.lineno)\n            except KeyError:\n                pass\n            finally:\n                objects[full_name] = (self.env.docname, self.objtype)\n\n        index_text = self.get_index_text(None, name)\n        if index_text:\n            entry = ('single', index_text, full_name, '')\n            if SPHINX_VERSION_14:\n                entry = ('single', index_text, full_name, '', None)\n            self.indexnode['entries'].append(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nproduce index text by directive attributes", "response": "def get_index_text(self, prefix, name_obj):\n        \"\"\"Produce index text by directive attributes\"\"\"\n        (name, _) = name_obj\n        msg = '{name} ({obj_type})'\n        parts = {\n            'name': name,\n            'prefix': prefix,\n            'obj_type': self.long_name,\n        }\n        try:\n            (obj_ns, obj_name) = name.rsplit('.', 1)\n            parts['name'] = obj_name\n            parts['namespace'] = obj_ns\n            msg = '{name} ({namespace} {obj_type})'\n        except ValueError:\n            pass\n\n        return msg.format(**parts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        nodes = super(DotNetObjectNested, self).run()\n        if 'hidden' in self.options:\n            for node in nodes:\n                if isinstance(node, addnodes.desc):\n                    for (m, child) in enumerate(node.children):\n                        if isinstance(child, addnodes.desc_signature):\n                            node.children.pop(m)\n        return nodes", "response": "Drop the desc_signature node from the list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef before_content(self):\n        super(DotNetObjectNested, self).before_content()\n        if self.names:\n            (_, prefix) = self.names.pop()\n            try:\n                self.env.ref_context['dn:prefixes'].append(prefix)\n            except (AttributeError, KeyError):\n                self.env.ref_context['dn:prefixes'] = [prefix]\n            finally:\n                self.env.ref_context['dn:prefix'] = prefix", "response": "Build up prefix history for nested elements\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_link(self, env, refnode, has_explicit_title, title, target):\n        result = super(DotNetXRefRole, self).process_link(env, refnode,\n                                                          has_explicit_title,\n                                                          title, target)\n        (title, target) = result\n        if not has_explicit_title:\n            # If the first character is a tilde, don't display the parent name\n            title = title.lstrip('.')\n            target = target.lstrip('~')\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot + 1:]\n        else:\n            if title != target:\n                target = title = '{title}<{target}>'.format(title=title,\n                                                            target=target)\n        return title, target", "response": "This method handles some special cases for reference links in.NET."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind object in the object store.", "response": "def find_obj(self, env, prefix, name, obj_type, searchorder=0):\n        \"\"\"Find object reference\n\n        :param env: Build environment\n        :param prefix: Object prefix\n        :param name: Object name\n        :param obj_type: Object type\n        :param searchorder: Search for exact match\n        \"\"\"\n        # Skip parens\n        if name[-2:] == '()':\n            name = name[:-2]\n\n        if not name:\n            return []\n\n        object_types = list(self.object_types)\n        if obj_type is not None:\n            object_types = self.objtypes_for_role(obj_type)\n\n        objects = self.data['objects']\n        newname = None\n        fullname = name\n        if prefix is not None:\n            fullname = '.'.join([prefix, name])\n\n        if searchorder == 1:\n            if prefix and fullname in objects and objects[fullname][1] in object_types:\n                newname = fullname\n            elif name in objects and objects[name][1] in object_types:\n                newname = name\n            else:\n                try:\n                    matches = [obj_name for obj_name in objects\n                               if obj_name.endswith('.' + name)]\n                    newname = matches.pop()\n                except IndexError:\n                    pass\n        else:\n            if name in objects:\n                newname = name\n            elif prefix and fullname in objects:\n                newname = fullname\n\n        if newname is None:\n            return None\n        return newname, objects.get(newname, (None, None))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlooks for any references without object type \ufffdNode This always searches in refspecific mode", "response": "def resolve_any_xref(self, env, fromdocname, builder, target,\n                         node, contnode):\n        \"\"\"Look for any references, without object type\n\n        This always searches in \"refspecific\" mode\n        \"\"\"\n        prefix = node.get('dn:prefix')\n        results = []\n\n        match = self.find_obj(env, prefix, target, None, 1)\n        if match is not None:\n            (name, obj) = match\n            results.append(('dn:' + self.role_for_objtype(obj[1]),\n                            make_refnode(builder, fromdocname, obj[0], name, contnode,\n                                         name)))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an image of type.", "response": "def create(self, width, height):\n        \"\"\"Create an image of type.\n\n        Parameters\n        ----------\n        width: `int`\n            Image width.\n        height: `int`\n            Image height.\n\n        Returns\n        -------\n        `PIL.Image.Image`\n        \"\"\"\n        return Image.new(self.mode, (width, height))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a channel. Parameters ---------- width: `int` Image width. height: `int` Image height. Returns ------- `PIL.Image.Image`", "response": "def create_channel(self, width, height):\n        \"\"\"Create a channel.\n\n        Parameters\n        ----------\n        width: `int`\n            Image width.\n        height: `int`\n            Image height.\n\n        Returns\n        -------\n        `PIL.Image.Image`\n        \"\"\"\n        if self.channel_mode is None:\n            return self.create(width, height)\n        return Image.new(self.channel_mode, (width, height))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges image channels. Parameters ---------- imgs : `list` of `PIL.Image.Image` Returns ------- `PIL.Image.Image` Raises ------ ValueError If image channel list is empty.", "response": "def merge(self, imgs):\n        \"\"\"Merge image channels.\n\n        Parameters\n        ----------\n        imgs : `list` of `PIL.Image.Image`\n\n        Returns\n        -------\n        `PIL.Image.Image`\n\n        Raises\n        ------\n        ValueError\n            If image channel list is empty.\n        \"\"\"\n        if not imgs:\n            raise ValueError('empty channel list')\n        if len(imgs) == 1:\n            return imgs[0]\n        return Image.merge(self.mode, imgs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef solve_posdef(A, b):\n    # Try cholesky for speed\n    try:\n        lower = False\n        L = cholesky(A, lower=lower)\n        if any(L.diagonal() < CHOLTHRESH):\n            raise LinAlgError(\"Unstable cholesky factor detected\")\n        X = cho_solve((L, lower), b)\n        logdet = cho_log_det(L)\n\n    # Failed cholesky, use svd to do the inverse\n    except LinAlgError:\n\n        U, s, V = svd(A)\n        X = svd_solve(U, s, V, b)\n        logdet = svd_log_det(s)\n\n    return X, logdet", "response": "Solve the system A X = b for A positive semi - definite matrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsolve the system A for the singular value system A = b for the system A = s for the singular value system A = s for the system A = b for the system A = s for the singular value system A = s for the system A = b for the system A = s for the system A = s for the system A = b for A = s for A = s for A = s for A = s for A = s for A = s for A = b", "response": "def svd_solve(U, s, V, b, s_tol=1e-15):\n    \"\"\"\n    Solve the system :math:`A X = b` for :math:`X`.\n\n    Here :math:`A` is a positive semi-definite matrix using the singular value\n    decomposition. This truncates the SVD so only dimensions corresponding to\n    non-negative and sufficiently large singular values are used.\n\n    Parameters\n    ----------\n    U: ndarray\n        The :code:`U` factor of :code:`U, s, V = svd(A)` positive\n        semi-definite matrix.\n    s: ndarray\n        The :code:`s` factor of :code:`U, s, V = svd(A)` positive\n        semi-definite matrix.\n    V: ndarray\n        The :code:`V` factor of :code:`U, s, V = svd(A)` positive\n        semi-definite matrix.\n    b: ndarray\n        An array or matrix\n    s_tol: float\n        Cutoff for small singular values. Singular values smaller than\n        :code:`s_tol` are clamped to :code:`s_tol`.\n\n    Returns\n    -------\n    X: ndarray\n        The result of :math:`X = A^-1 b`\n    okind: ndarray\n        The indices of :code:`s` that are kept in the factorisation\n    \"\"\"\n    # Test shapes for efficient computations\n    n = U.shape[0]\n    assert(b.shape[0] == n)\n    m = b.shape[1] if np.ndim(b) > 1 else 1\n\n    # Auto clamp SVD based on threshold\n    sclamp = np.maximum(s, s_tol)\n\n    # Inversion factors\n    ss = 1. / np.sqrt(sclamp)\n    U2 = U * ss[np.newaxis, :]\n    V2 = ss[:, np.newaxis] * V\n\n    if m < n:\n        # Few queries\n        X = U2.dot(V2.dot(b))  # O(n^2 (2m))\n    else:\n        X = U2.dot(V2).dot(b)  # O(n^2 (m + n))\n\n    return X"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_siblings(\n        start, end, new_,\n        keep_start_boundary=False,\n        keep_end_boundary=False\n):\n    \"\"\"a helper function that will replace a start/end node pair\n    by a new containing element, effectively moving all in-between siblings\n    This is particularly helpful to replace for /for loops in tables\n    with the content resulting from the iteration\n\n    This function call returns None. The parent xml tree is modified in place\n\n    @param start: the starting xml node\n    @type start: lxml.etree.Element\n\n    @param end: the ending xml node\n    @type end: lxml.etree.Element\n\n    @param new_: the new xml element that will replace the start/end pair\n    @type new_: lxlm.etree.Element\n\n    @param keep_start_boundary: Flag to let the function know if it copies\n    your start tag to the new_ node or not, Default value is False\n    @type keep_start_boundary: bool\n\n    @param keep_end_boundary: Flag to let the function know if it copies\n    your end tag to the new_ node or not, Default value is False\n    @type keep_end_boundary: bool\n\n    @returns: None\n    \"\"\"\n    old_ = start.getparent()\n    if keep_start_boundary:\n        new_.append(copy(start))\n\n    else:\n        if start.tail:\n            # copy the existing tail as text\n            new_.text = start.tail\n\n    # get all siblings\n    for node in start.itersiblings():\n        if node is not end:\n            new_.append(node)\n\n        elif node is end:\n            # if this is already the end boundary, then we are done\n            if keep_end_boundary:\n                new_.append(copy(node))\n\n            break\n\n    # replace start boundary with new node\n    old_.replace(start, new_)\n\n    # remove ending boundary we already copied it if needed\n    old_.remove(end)", "response": "a helper function that moves all siblings of a node pair into a new xml element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_list_transformer(namespaces):\n    return Transformer(\n        '//list[namespace-uri()=\"%s\"]' % namespaces.get(\n            'text'\n        )\n    ).attr(\n        '{0}id'.format(XML_NS),\n        lambda *args: \"list{0}\".format(uuid4().hex)\n    )", "response": "returns a transformer to find all list elements and recompute their xml : id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __prepare_namespaces(self):\n        # create needed namespaces\n        self.namespaces = dict(\n            text=\"urn:text\",\n            draw=\"urn:draw\",\n            table=\"urn:table\",\n            office=\"urn:office\",\n            xlink=\"urn:xlink\",\n            svg=\"urn:svg\",\n            manifest=\"urn:manifest\",\n        )\n\n        # copy namespaces from original docs\n        for tree_root in self.tree_roots:\n            self.namespaces.update(tree_root.nsmap)\n\n        # remove any \"root\" namespace as lxml.xpath do not support them\n        self.namespaces.pop(None, None)\n\n        # declare the genshi namespace\n        self.namespaces['py'] = GENSHI_URI\n        # declare our own namespace\n        self.namespaces['py3o'] = PY3O_URI", "response": "create proper namespaces for our document\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_instructions(self):\n        res = []\n        # TODO: Check if instructions can be stored in other content_trees\n        for e in get_instructions(self.content_trees[0], self.namespaces):\n            childs = e.getchildren()\n            if childs:\n                res.extend([c.text for c in childs])\n            else:\n                res.append(e.text)\n        return res", "response": "Public method to help report engine to find all instructions in the user s content tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform a py3o link into a proper Genshi statement", "response": "def handle_link(self, link, py3o_base, closing_link):\n        \"\"\"transform a py3o link into a proper Genshi statement\n        rebase a py3o link at a proper place in the tree\n        to be ready for Genshi replacement\n        \"\"\"\n        # OLD open office version\n        if link.text is not None and link.text.strip():\n            if not link.text == py3o_base:\n                msg = \"url and text do not match in '%s'\" % link.text\n                raise TemplateException(msg)\n\n        # new open office version\n        elif len(link):\n            if not link[0].text == py3o_base:\n                msg = \"url and text do not match in '%s'\" % link.text\n                raise TemplateException(msg)\n        else:\n            raise TemplateException(\"Link text not found\")\n\n        # find out if the instruction is inside a table\n        parent = link.getparent()\n        keep_start_boundary = False\n        keep_end_boundary = False\n\n        if parent.getparent() is not None and parent.getparent().tag == (\n            \"{%s}table-cell\" % self.namespaces['table']\n        ):\n            # we are in a table\n            opening_paragraph = parent\n            opening_cell = opening_paragraph.getparent()\n\n            # same for closing\n            closing_paragraph = closing_link.getparent()\n            closing_cell = closing_paragraph.getparent()\n\n            if opening_cell == closing_cell:\n                # block is fully in a single cell\n                opening_row = opening_paragraph\n                closing_row = closing_paragraph\n            else:\n                opening_row = opening_cell.getparent()\n                closing_row = closing_cell.getparent()\n\n        elif parent.tag == \"{%s}p\" % self.namespaces['text']:\n            # if we are using text we want to keep start/end nodes\n            keep_start_boundary, keep_end_boundary = detect_keep_boundary(\n                link, closing_link, self.namespaces\n            )\n            # we are in a text paragraph\n            opening_row = parent\n            closing_row = closing_link.getparent()\n\n        else:\n            raise NotImplementedError(\n                \"We handle urls in tables or text paragraph only\"\n            )\n\n        # max split is one\n        instruction, instruction_value = py3o_base.split(\"=\", 1)\n        instruction_value = instruction_value.strip('\"')\n\n        attribs = dict()\n        attribs['{%s}strip' % GENSHI_URI] = 'True'\n        attribs['{%s}%s' % (GENSHI_URI, instruction)] = instruction_value\n\n        genshi_node = lxml.etree.Element(\n            'span',\n            attrib=attribs,\n            nsmap={'py': GENSHI_URI},\n        )\n\n        link.getparent().remove(link)\n        closing_link.getparent().remove(closing_link)\n\n        try:\n            move_siblings(\n                opening_row, closing_row, genshi_node,\n                keep_start_boundary=keep_start_boundary,\n                keep_end_boundary=keep_end_boundary,\n            )\n        except ValueError as e:\n            log.exception(e)\n            raise TemplateException(\"Could not move siblings for '%s'\" %\n                                    py3o_base)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces user-type text fields that start with \"py3o.\" with genshi instructions.", "response": "def __prepare_usertexts(self):\n        \"\"\"Replace user-type text fields that start with \"py3o.\" with genshi\n        instructions.\n        \"\"\"\n\n        field_expr = \"//text:user-field-get[starts-with(@text:name, 'py3o.')]\"\n\n        for content_tree in self.content_trees:\n\n            for userfield in content_tree.xpath(\n                field_expr,\n                namespaces=self.namespaces\n            ):\n                parent = userfield.getparent()\n                value = userfield.attrib[\n                    '{%s}name' % self.namespaces['text']\n                ][5:]\n                value_type = self.field_info[value]['value_type']\n\n                # we try to override global var type with local settings\n                value_type_attr = '{%s}value-type' % self.namespaces['office']\n                rec = 0\n                parent_node = parent\n\n                # special case for float which has a value info on top level\n                # overriding local value\n                found_node = False\n                while rec <= 5:\n                    if parent_node is None:\n                        break\n\n                    # find an ancestor with an  office:value-type attribute\n                    # this is the case when you are inside a table\n                    if value_type_attr in parent_node.attrib:\n                        value_type = parent_node.attrib[value_type_attr]\n                        found_node = True\n                        break\n\n                    rec += 1\n                    parent_node = parent_node.getparent()\n\n                if value_type == 'float':\n                    value_attr = '{%s}value' % self.namespaces['office']\n                    rec = 0\n\n                    if found_node:\n                        parent_node.attrib[value_attr] = \"${%s}\" % value\n                    else:\n                        parent_node = userfield\n                        while rec <= 7:\n                            if parent_node is None:\n                                break\n\n                            if value_attr in parent_node.attrib:\n                                parent_node.attrib[value_attr] = \"${%s}\" % value\n                                break\n\n                            rec += 1\n                            parent_node = parent_node.getparent()\n\n                    value = \"format_float(%s)\" % value\n\n                if value_type == 'percentage':\n                    del parent_node.attrib[value_attr]\n                    value = \"format_percentage(%s)\" % value\n                    parent_node.attrib[value_type_attr] = \"string\"\n\n                attribs = dict()\n                attribs['{%s}strip' % GENSHI_URI] = 'True'\n                attribs['{%s}content' % GENSHI_URI] = value\n\n                genshi_node = lxml.etree.Element(\n                    'span',\n                    attrib=attribs,\n                    nsmap={'py': GENSHI_URI}\n                )\n\n                if userfield.tail:\n                    genshi_node.tail = userfield.tail\n\n                parent.replace(userfield, genshi_node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces links of placeholder images with xlink links.", "response": "def __replace_image_links(self):\n        \"\"\"Replace links of placeholder images (the name of which starts with\n        \"py3o.\") to point to a file saved the \"Pictures\" directory of the\n        archive.\n        \"\"\"\n\n        image_expr = \"//draw:frame[starts-with(@draw:name, 'py3o.')]\"\n\n        for content_tree in self.content_trees:\n\n            # Find draw:frame tags.\n            for draw_frame in content_tree.xpath(\n                image_expr,\n                namespaces=self.namespaces\n            ):\n                # Find the identifier of the image (py3o.[identifier]).\n                image_id = draw_frame.attrib[\n                    '{%s}name' % self.namespaces['draw']\n                ][5:]\n                if image_id not in self.images:\n                    if not self.ignore_undefined_variables:\n                        raise TemplateException(\n                            \"Can't find data for the image named 'py3o.%s'; \"\n                            \"make sure it has been added with the \"\n                            \"set_image_path or set_image_data methods.\"\n                            % image_id\n                        )\n                    else:\n                        continue\n\n                # Replace the xlink:href attribute of the image to point to\n                # ours.\n                image = draw_frame[0]\n                image.attrib[\n                    '{%s}href' % self.namespaces['xlink']\n                ] = PY3O_IMAGE_PREFIX + image_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd entries for py3o images into the manifest file.", "response": "def __add_images_to_manifest(self):\n        \"\"\"Add entries for py3o images into the manifest file.\"\"\"\n\n        xpath_expr = \"//manifest:manifest[1]\"\n\n        for content_tree in self.content_trees:\n\n            # Find manifest:manifest tags.\n            manifest_e = content_tree.xpath(\n                xpath_expr,\n                namespaces=self.namespaces\n            )\n            if not manifest_e:\n                continue\n\n            for identifier in self.images.keys():\n                # Add a manifest:file-entry tag.\n                lxml.etree.SubElement(\n                    manifest_e[0],\n                    '{%s}file-entry' % self.namespaces['manifest'],\n                    attrib={\n                        '{%s}full-path' % self.namespaces['manifest']: (\n                            PY3O_IMAGE_PREFIX + identifier\n                        ),\n                        '{%s}media-type' % self.namespaces['manifest']: '',\n                    }\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the flows without saving to file", "response": "def render_tree(self, data):\n        \"\"\"prepare the flows without saving to file\n        this method has been decoupled from render_flow to allow better\n        unit testing\n        \"\"\"\n        # TODO: find a way to make this localization aware...\n        # because ATM it formats texts using French style numbers...\n        # best way would be to let the user inject its own vars...\n        # but this would not work on fusion servers...\n        # so we must find a way to localize this a bit... or remove it and\n        # consider our caller must pre - render its variables to the desired\n        # locale...?\n        new_data = dict(\n            decimal=decimal,\n            format_float=(\n                lambda val: (\n                    isinstance(\n                        val, decimal.Decimal\n                    ) or isinstance(\n                        val, float\n                    )\n                ) and str(val).replace('.', ',') or val\n            ),\n            format_percentage=(\n                lambda val: (\"%0.2f %%\" % val).replace('.', ',')\n            )\n        )\n\n        # Soft page breaks are hints for applications for rendering a page\n        # break. Soft page breaks in for loops may compromise the paragraph\n        # formatting especially the margins. Open-/LibreOffice will regenerate\n        # the page breaks when displaying the document. Therefore it is save to\n        # remove them.\n        self.remove_soft_breaks()\n\n        # first we need to transform the py3o template into a valid\n        # Genshi template.\n        starting_tags, closing_tags = self.handle_instructions(\n            self.content_trees,\n            self.namespaces\n        )\n        parents = [tag[0].getparent() for tag in starting_tags]\n        linknum = len(parents)\n        parentnum = len(set(parents))\n        if not linknum == parentnum:\n            raise TemplateException(\n                \"Every py3o link instruction should be on its own line\"\n            )\n\n        for link, py3o_base in starting_tags:\n            self.handle_link(\n                link,\n                py3o_base,\n                closing_tags[id(link)]\n            )\n\n        self.__prepare_userfield_decl()\n        self.__prepare_usertexts()\n\n        self.__replace_image_links()\n        self.__add_images_to_manifest()\n\n        for fnum, content_tree in enumerate(self.content_trees):\n            content = lxml.etree.tostring(content_tree.getroot())\n            if self.ignore_undefined_variables:\n                template = MarkupTemplate(content, lookup='lenient')\n            else:\n                template = MarkupTemplate(content)\n\n            # then we need to render the genshi template itself by\n            # providing the data to genshi\n\n            template_dict = {}\n            template_dict.update(data.items())\n            template_dict.update(new_data.items())\n\n            self.output_streams.append(\n                (\n                    self.templated_files[fnum],\n                    template.generate(**template_dict)\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_flow(self, data):\n\n        self.render_tree(data)\n\n        # then reconstruct a new ODT document with the generated content\n        for status in self.__save_output():\n            yield status", "response": "render the OpenDocument with the user data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_image_path(self, identifier, path):\n\n        f = open(path, 'rb')\n        self.set_image_data(identifier, f.read())\n        f.close()", "response": "Set the data for an image mentioned in the template."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __save_output(self):\n        out = zipfile.ZipFile(self.outputfilename, 'w')\n\n        for info_zip in self.infile.infolist():\n\n            if info_zip.filename in self.templated_files:\n                # Template file - we have edited these.\n\n                # get a temp file\n                streamout = open(get_secure_filename(), \"w+b\")\n                fname, output_stream = self.output_streams[\n                    self.templated_files.index(info_zip.filename)\n                ]\n\n                transformer = get_list_transformer(self.namespaces)\n                remapped_stream = output_stream | transformer\n\n                # write the whole stream to it\n                for chunk in remapped_stream.serialize():\n                    streamout.write(chunk.encode('utf-8'))\n                    yield True\n\n                # close the temp file to flush all data and make sure we get\n                # it back when writing to the zip archive.\n                streamout.close()\n\n                # write the full file to archive\n                out.write(streamout.name, fname)\n\n                # remove temp file\n                os.unlink(streamout.name)\n\n            else:\n                # Copy other files straight from the source archive.\n                out.writestr(info_zip, self.infile.read(info_zip.filename))\n\n        # Save images in the \"Pictures\" sub-directory of the archive.\n        for identifier, data in self.images.items():\n            out.writestr(PY3O_IMAGE_PREFIX + identifier, data)\n\n        # close the zipfile before leaving\n        out.close()\n        yield True", "response": "Save the output into a native OOo document format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_arg_parser(parent):\n\n    arg1 = parent.add_subparsers(dest='command')\n\n    arg2 = arg1.add_parser('create')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-o', '--output',\n                      default=None,\n                      help='output file (default: stdout)')\n    arg2.add_argument('input', nargs='*',\n                      help='input file (default: stdin)')\n\n    arg2 = arg1.add_parser('update')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-o', '--output',\n                      default=None,\n                      help='output file (default: rewrite state file)')\n    arg2.add_argument('state',\n                      help='state file')\n    arg2.add_argument('input', nargs='*',\n                      help='input file (default: stdin)')\n\n    arg2 = arg1.add_parser('settings')\n    arg2.add_argument('state',\n                      help='state file')\n\n    arg2 = arg1.add_parser('generate')\n    arg2.add_argument('-P', '--progress',\n                      action='store_true',\n                      help='show progress bar')\n    arg2.add_argument('-nf', '--no-format',\n                      dest='format',\n                      action='store_false',\n                      help='do not format text')\n    arg2.add_argument('-s', '--settings',\n                      type=FileType('r'), default=None,\n                      help='settings json file')\n    arg2.add_argument('-ss', '--state-size',\n                      type=int, default=None,\n                      help='generator state size')\n    arg2.add_argument('-S', '--start',\n                      default=None,\n                      help='text start')\n    arg2.add_argument('-E', '--end',\n                      default=None,\n                      help='text end')\n    arg2.add_argument('-R', '--reply',\n                      default=None,\n                      help='reply to text')\n    arg2.add_argument('-w', '--words',\n                      type=int, default=256,\n                      help='max text size (default: %(default)s)')\n    arg2.add_argument('-c', '--count',\n                      type=int, default=1,\n                      help='number of generated texts (default: %(default)s)')\n    arg2.add_argument('-o', '--output',\n                      type=FileType('w'), default=None,\n                      help='output file (default: stdout)')\n    arg2.add_argument('state',\n                      help='state file')\n\n    arg2.set_defaults(format=True)", "response": "Create command subparsers.\n\n    Parameters\n    ----------\n    parent : `argparse.ArgumentParser`\n        Command parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread data files and update a generator.", "response": "def read(fnames, markov, progress):\n    \"\"\"Read data files and update a generator.\n\n    Parameters\n    ----------\n    fnames : `list` of `str`\n        File paths.\n    markov : `markovchain.base.MarkovBase`\n        Generator to update.\n    progress : `bool`\n        Show progress bar.\n    \"\"\"\n    with infiles(fnames, progress) as fnames:\n        for fname in fnames:\n            with open(fname, 'r') as fp:\n                if progress:\n                    fp.seek(0, SEEK_END)\n                    total = fp.tell()\n                    title = truncate(fname, BAR_DESC_SIZE - 1, False)\n                    pbar = tqdm(total=total, desc=title,\n                                leave=False, unit='byte',\n                                bar_format=BAR_FORMAT, dynamic_ncols=True)\n                    fp.seek(0, SEEK_SET)\n                    prev = 0\n                else:\n                    pbar = None\n\n                try:\n                    line = fp.readline()\n                    while line:\n                        markov.data(line, True)\n                        if pbar is not None:\n                            pos = fp.tell()\n                            if pos <= total:\n                                pbar.update(pos - prev)\n                                prev = pos\n                        line = fp.readline()\n                finally:\n                    if pbar is not None:\n                        pbar.close()\n\n                markov.data('', False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd_create(args):\n    if args.type == SQLITE:\n        if args.output is not None and path.exists(args.output):\n            remove(args.output)\n        storage = SqliteStorage(db=args.output, settings=args.settings)\n    else:\n        storage = JsonStorage(settings=args.settings)\n    markov = MarkovText.from_storage(storage)\n    read(args.input, markov, args.progress)\n    save(markov, args.output, args)", "response": "Create a generator.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a generator. Parameters ---------- args : argparse. Namespace", "response": "def cmd_update(args):\n    \"\"\"Update a generator.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n    #args.output = None\n\n    markov = load(MarkovText, args.state, args)\n    read(args.input, markov, args.progress)\n    if args.output is None:\n        if args.type == SQLITE:\n            save(markov, None, args)\n        elif args.type == JSON:\n            name, ext = path.splitext(args.state)\n            tmp = name + '.tmp' + ext\n            save(markov, tmp, args)\n            replace(tmp, args.state)\n    else:\n        save(markov, args.output, args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates text. Parameters ---------- args : `argparse.Namespace` Command arguments.", "response": "def cmd_generate(args):\n    \"\"\"Generate text.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n\n    if args.start:\n        if args.end or args.reply:\n            raise ValueError('multiple input arguments')\n        args.reply_to = args.start\n        args.reply_mode = ReplyMode.END\n    elif args.end:\n        if args.reply:\n            raise ValueError('multiple input arguments')\n        args.reply_to = args.end\n        args.reply_mode = ReplyMode.START\n    elif args.reply:\n        args.reply_to = args.reply\n        args.reply_mode = ReplyMode.REPLY\n    else:\n        args.reply_to = None\n        args.reply_mode = ReplyMode.END\n\n    markov = load(MarkovText, args.state, args)\n\n    ss = range(args.count)\n    if args.progress:\n        title = truncate(args.output.name, BAR_DESC_SIZE - 1, False)\n        ss = tqdm(ss, desc=title,\n                  bar_format=BAR_FORMAT, dynamic_ncols=True)\n\n    if not args.format:\n        markov.formatter = lambda x: x\n\n    for _ in ss:\n        data = markov(\n            args.words,\n            state_size=args.state_size,\n            reply_to=args.reply_to,\n            reply_mode=args.reply_mode\n        )\n        if data:\n            print(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(args=None):\n    parser = ArgumentParser()\n    parser.add_argument('-v', '--version',\n                        action='version', version=CLI_VERSION)\n\n    parsers = parser.add_subparsers(dest='dtype')\n\n    text.create_arg_parser(parsers.add_parser('text'))\n    if image is not None:\n        image.create_arg_parser(parsers.add_parser('image'))\n\n    if len(sys.argv if args is None else args) <= 1:\n        parser.print_help()\n        sys.exit(1)\n\n    args = parser.parse_args(args)\n    dtype = globals()[args.dtype]\n    try:\n        set_args(args)\n        cmd = getattr(dtype, 'cmd_' + args.command)\n        cmd(args)\n    except ValueError as err:\n        print(str(err), file=sys.stderr)\n        sys.exit(1)", "response": "Main function of the\nTaxonomy CLI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the check digit of the card number", "response": "def get_check_digit(unchecked):\n    \"\"\"returns the check digit of the card number.\"\"\"\n    digits = digits_of(unchecked)\n    checksum = sum(even_digits(unchecked)) + sum([\n        sum(digits_of(2 * d)) for d in odd_digits(unchecked)])\n    return 9 * checksum % 10"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid(number):\n    n = str(number)\n    if not n.isdigit():\n        return False\n    return int(n[-1]) == get_check_digit(n[:-1])", "response": "determines whether the card number is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(length):\n    if not isinstance(length, int) or length < 2:\n        raise TypeError('length must be a positive integer greater than 1.')\n\n    # first digit cannot be 0\n    digits = [random.randint(1, 9)]\n\n    for i in range(length-2):\n        digits.append(random.randint(0, 9))\n    digits.append(get_check_digit(''.join(map(str, digits))))\n\n    return ''.join(map(str, digits))", "response": "Generates random and valid card number which is returned as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert to JSON. JSON data.", "response": "def save(self):\n        \"\"\"Convert to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        data = super().save()\n        data['reverse'] = self.reverse\n        data['line_sentences'] = self.line_sentences\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreverse spiral generator. Parameters ---------- width : `int` Spiral width. height : `int` Spiral height. Returns ------- `generator` of (`int`, `int`) Points.", "response": "def _rspiral(width, height):\n        \"\"\"Reversed spiral generator.\n\n        Parameters\n        ----------\n        width : `int`\n            Spiral width.\n        height : `int`\n            Spiral height.\n\n        Returns\n        -------\n        `generator` of (`int`, `int`)\n            Points.\n        \"\"\"\n\n        x0 = 0\n        y0 = 0\n        x1 = width - 1\n        y1 = height - 1\n\n        while x0 < x1 and y0 < y1:\n            for x in range(x0, x1):\n                yield x, y0\n            for y in range(y0, y1):\n                yield x1, y\n            for x in range(x1, x0, -1):\n                yield x, y1\n            for y in range(y1, y0, -1):\n                yield x0, y\n\n            x0 += 1\n            y0 += 1\n            x1 -= 1\n            y1 -= 1\n\n        if x0 == x1:\n            for y in range(y0, y1 + 1):\n                yield x0, y\n        elif y0 == y1:\n            for x in range(x0, x1 + 1):\n                yield x, y0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nspiral generator. Parameters ---------- width : `int` Spiral width. height : `int` Spiral height. Returns ------- `generator` of (`int`, `int`) Points.", "response": "def _spiral(width, height):\n        \"\"\"Spiral generator.\n\n        Parameters\n        ----------\n        width : `int`\n            Spiral width.\n        height : `int`\n            Spiral height.\n\n        Returns\n        -------\n        `generator` of (`int`, `int`)\n            Points.\n        \"\"\"\n\n        if width == 1:\n            for y in range(height - 1, -1, -1):\n                yield 0, y\n            return\n        if height == 1:\n            for x in range(width - 1, -1, -1):\n                yield x, 0\n            return\n\n        if width <= height:\n            x0 = width // 2\n            if width % 2:\n                for y in range(height - 1 - x0, x0 - 1, -1):\n                    yield x0, y\n            x0 -= 1\n            y0 = x0\n        else:\n            y0 = height // 2\n            if height % 2:\n                for x in range(width - 1 - y0, y0 - 1, -1):\n                    yield x, y0\n            y0 -= 1\n            x0 = y0\n\n        while x0 >= 0:\n            x1 = width - x0 - 1\n            y1 = height - y0 - 1\n\n            for y in range(y0 + 1, y1):\n                yield x0, y\n            for x in range(x0, x1):\n                yield x, y1\n            for y in range(y1, y0, -1):\n                yield x1, y\n            for x in range(x1, x0 - 1, -1):\n                yield x, y0\n\n            x0 -= 1\n            y0 -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting point coordinates in next block.", "response": "def get_point_in_block(cls, x, y, block_idx, block_size):\n        \"\"\"Get point coordinates in next block.\n\n        Parameters\n        ----------\n        x : `int`\n            X coordinate in current block.\n        y : `int`\n            Y coordinate in current block.\n        block_index : `int`\n            Current block index in next block.\n        block_size : `int`\n            Current block size.\n\n        Raises\n        ------\n        IndexError\n            If block index is out of range.\n\n        Returns\n        -------\n        (`int`, `int`)\n            Point coordinates.\n        \"\"\"\n        if block_idx == 0:\n            return y, x\n        if block_idx == 1:\n            return x, y + block_size\n        if block_idx == 2:\n            return x + block_size, y + block_size\n        if block_idx == 3:\n            x, y = block_size - 1 - y, block_size - 1 - x\n            return x + block_size, y\n        raise IndexError('block index out of range: %d' % block_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_point(cls, idx, size):\n        x, y = cls.POSITION[idx % 4]\n        idx //= 4\n        block_size = 2\n        while block_size < size:\n            block_idx = idx % 4\n            x, y = cls.get_point_in_block(x, y, block_idx, block_size)\n            idx //= 4\n            block_size *= 2\n        return x, y", "response": "Get curve point coordinates by index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self):\n        data = super().save()\n        data['block_size'] = list(self.block_size)\n        data['block_sentences'] = self.block_sentences\n        data['traverse_image'] = self.traverse_image.save()\n        data['traverse_block'] = self.traverse_block.save()\n        return data", "response": "Convert to JSON.\n            JSON data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(for_lists, global_vars, data_dict):\n        res = {}\n\n        # The first level is a little bit special\n        # Manage global variables\n        for a in global_vars:\n            a_list = a.split('.')\n            tmp = res\n            for i in a_list[:-1]:\n                if not i in tmp:\n                    tmp[i] = {}\n                tmp = tmp[i]\n            tmp[a_list[-1]] = reduce(getattr, a_list[1:], data_dict[a_list[0]])\n        # Then manage for lists recursively\n        for for_list in for_lists:\n            it = for_list.name.split('.')\n            tmp = res\n            for i in it[:-1]:\n                if not i in tmp:\n                    tmp[i] = {}\n                tmp = tmp[i]\n            if not it[-1] in tmp:\n                tmp[it[-1]] = []\n            tmp = tmp[it[-1]]\n            if not it[0] in data_dict:\n                continue\n            if len(it) == 1:\n                loop = enumerate(data_dict[it[0]])\n            else:\n                loop = enumerate(reduce(getattr, it[-1:], data_dict[it[0]]))\n            for i, val in loop:\n                new_data_dict = {for_list.var_from: val}\n                # We append a new dict only if we need\n                if len(tmp) <= i:\n                    tmp.append({})\n                # Call myself with new context, and get result\n                tmp[i] = ForList.__recur_to_dict(\n                    for_list, new_data_dict, tmp[i]\n                )\n\n        return res", "response": "This function takes a list of ForList objects and a dictionary of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logout(request, redirect_url=settings.LOGOUT_REDIRECT_URL):\n    django_logout(request)\n    return HttpResponseRedirect(request.build_absolute_uri(redirect_url))", "response": "Logs a user out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef begin_auth(request):\n    # Instantiate Twython with the first leg of our trip.\n    twitter = Twython(settings.TWITTER_KEY, settings.TWITTER_SECRET)\n\n    # Request an authorization url to send the user to...\n    callback_url = request.build_absolute_uri(reverse('twython_django_oauth.views.thanks'))\n    auth_props = twitter.get_authentication_tokens(callback_url)\n\n    # Then send them over there, durh.\n    request.session['request_token'] = auth_props\n\n    request.session['next_url'] = request.GET.get('next',None)\n    \n    return HttpResponseRedirect(auth_props['auth_url'])", "response": "The view function that initiates the entire handshake."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef thanks(request, redirect_url=settings.LOGIN_REDIRECT_URL):\n    # Now that we've got the magic tokens back from Twitter, we need to exchange\n    # for permanent ones and store them...\n    oauth_token = request.session['request_token']['oauth_token']\n    oauth_token_secret = request.session['request_token']['oauth_token_secret']\n    twitter = Twython(settings.TWITTER_KEY, settings.TWITTER_SECRET,\n                      oauth_token, oauth_token_secret)\n\n    # Retrieve the tokens we want...\n    authorized_tokens = twitter.get_authorized_tokens(request.GET['oauth_verifier'])\n\n    # If they already exist, grab them, login and redirect to a page displaying stuff.\n    try:\n        user = User.objects.get(username=authorized_tokens['screen_name'])\n    except User.DoesNotExist:\n        # We mock a creation here; no email, password is just the token, etc.\n        user = User.objects.create_user(authorized_tokens['screen_name'], \"fjdsfn@jfndjfn.com\", authorized_tokens['oauth_token_secret'])\n        profile = TwitterProfile()\n        profile.user = user\n        profile.oauth_token = authorized_tokens['oauth_token']\n        profile.oauth_secret = authorized_tokens['oauth_token_secret']\n        profile.save()\n\n    user = authenticate(\n        username=authorized_tokens['screen_name'],\n        password=authorized_tokens['oauth_token_secret']\n    )\n    login(request, user)\n    redirect_url = request.session.get('next_url', redirect_url)\n\n    HttpResponseRedirect(redirect_url)", "response": "This function is used to get the user s data from Twitter and store them in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing data into a set of related objects.", "response": "def data(self, data, part=False, dataset=''):\n        \"\"\"\n        Parameters\n        ----------\n        data : `PIL.Image`\n            Image to parse.\n        part : `bool`, optional\n            True if data is partial (default: `False`).\n        dataset : `str`, optional\n            Dataset key prefix (default: '').\n        \"\"\"\n        #if self.parser is None:\n        #    raise ValueError('no parser')\n        imgs = self.imgtype.convert(data)\n        for channel, data in zip(self.imgtype.channels, imgs):\n            key = dataset + channel\n            data = self.scanner(data, part)\n            if isinstance(self.parser, LevelParser):\n                self.storage.add_links(self.parser(data, part, key))\n            else:\n                for level, level_data in enumerate(data):\n                    level_key = key + level_dataset(level)\n                    level_data = self.parser(level_data, part, level_key)\n                    self.storage.add_links(level_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating image pixels. Parameters ---------- width : `int` Image width. height : `int` Image height. state_size : `int` or `None`, optional State size to use for generation (default: `None`). start : `str`, optional Initial state (default: ''). dataset : `str`, optional Dataset key prefix (default: ''). Raises ------ RuntimeError If generator is empty. Returns ------- `generator` of `int` Pixel generator.", "response": "def _imgdata(self, width, height,\n                 state_size=None, start='', dataset=''):\n        \"\"\"Generate image pixels.\n\n        Parameters\n        ----------\n        width : `int`\n            Image width.\n        height : `int`\n            Image height.\n        state_size : `int` or `None`, optional\n            State size to use for generation (default: `None`).\n        start : `str`, optional\n            Initial state (default: '').\n        dataset : `str`, optional\n            Dataset key prefix (default: '').\n\n        Raises\n        ------\n        RuntimeError\n            If generator is empty.\n\n        Returns\n        -------\n        `generator` of `int`\n            Pixel generator.\n        \"\"\"\n        size = width * height\n        if size > 0 and start:\n            yield state_to_pixel(start)\n            size -= 1\n\n        while size > 0:\n            prev_size = size\n\n            pixels = self.generate(state_size, start, dataset)\n            pixels = islice(pixels, 0, size)\n\n            for pixel in pixels:\n                yield state_to_pixel(pixel)\n                size -= 1\n\n            if prev_size == size:\n                if start:\n                    yield from repeat(state_to_pixel(start), size)\n                else:\n                    raise RuntimeError('empty generator')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_imgdata(img, data, tr, x=0, y=0):\n        for pixel, (x1, y1) in zip(data, tr):\n            img.putpixel((x + x1, y + y1), pixel)\n        return img", "response": "Write image data.\n\n        Parameters\n        ----------\n        img : `PIL.Image.Image`\n            Image.\n        data : `iterable` of `int`\n            Image data.\n        tr : `markovchain.image.traversal.Traversal`\n            Image traversal.\n        x : `int`\n            X offset.\n        y : `int`\n            Y offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _channel(self, width, height, state_sizes,\n                 start_level, start_image, dataset):\n        \"\"\"Generate a channel.\n\n        Parameters\n        ----------\n        width : `int`\n            Image width.\n        height : `int`\n            Image height.\n        state_sizes : `list` of (`int` or `None`)\n            Level state sizes.\n        start_level : `int`\n            Initial level.\n        start_image : `PIL.Image` or `None`\n            Initial level image.\n        dataset : `str`\n            Dataset key prefix.\n\n        Returns\n        -------\n        `PIL.Image`\n            Generated image.\n        \"\"\"\n        ret = start_image\n        for level, state_size in enumerate(state_sizes, start_level + 1):\n            key = dataset + level_dataset(level)\n            if start_image is not None:\n                scale = self.scanner.level_scale[level - 1]\n                width *= scale\n                height *= scale\n            ret = self.imgtype.create_channel(width, height)\n            if start_image is None:\n                tr = self.scanner.traversal[0](width, height, ends=False)\n                data = self._imgdata(width, height, state_size, '', key)\n                self._write_imgdata(ret, data, tr)\n            else:\n                tr = self.scanner.traversal[0](\n                    start_image.size[0],\n                    start_image.size[1],\n                    ends=False\n                )\n                for xy in tr:\n                    start = pixel_to_state(start_image.getpixel(xy))\n                    data = self._imgdata(scale, scale, state_size, start, key)\n                    blk = self.scanner.traversal[level](scale, scale, False)\n                    x, y = xy\n                    x *= scale\n                    y *= scale\n                    self._write_imgdata(ret, data, blk, x, y)\n            start_image = ret\n        return ret", "response": "Generate a channel.\n\n        Parameters\n        ----------\n        width : `int`\n            Image width.\n        height : `int`\n            Image height.\n        state_sizes : `list` of (`int` or `None`)\n            Level state sizes.\n        start_level : `int`\n            Initial level.\n        start_image : `PIL.Image` or `None`\n            Initial level image.\n        dataset : `str`\n            Dataset key prefix.\n\n        Returns\n        -------\n        `PIL.Image`\n            Generated image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nflatten a Parameter object into a flattened array.", "response": "def ravel(parameter, random_state=None):\n    \"\"\"\n    Flatten a ``Parameter``.\n\n    Parameters\n    ----------\n    parameter: Parameter\n        A ``Parameter`` object\n\n    Returns\n    -------\n    flatvalue: ndarray\n        a flattened array of shape ``(prod(parameter.shape),)``\n    flatbounds: list\n        a list of bound tuples of length ``prod(parameter.shape)``\n    \"\"\"\n    flatvalue = np.ravel(parameter.rvs(random_state=random_state))\n    flatbounds = [parameter.bounds\n                  for _ in range(np.prod(parameter.shape, dtype=int))]\n\n    return flatvalue, flatbounds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hstack(tup):\n    vals, bounds = zip(*tup)\n    stackvalue = np.hstack(vals)\n    stackbounds = list(chain(*bounds))\n\n    return stackvalue, stackbounds", "response": "Horizontally stack a sequence of value bounds pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a value falls within a bound.", "response": "def check(self, value):\n        \"\"\"\n        Check a value falls within a bound.\n\n        Parameters\n        ----------\n        value : scalar or ndarray\n            value to test\n\n        Returns\n        -------\n        bool:\n            If all values fall within bounds\n\n        Example\n        -------\n        >>> bnd = Bound(1, 2)\n        >>> bnd.check(1.5)\n        True\n        >>> bnd.check(3)\n        False\n        >>> bnd.check(np.ones(10))\n        True\n        >>> bnd.check(np.array([1, 3, 1.5]))\n        False\n        \"\"\"\n        if self.lower:\n            if np.any(value < self.lower):\n                return False\n\n        if self.upper:\n            if np.any(value > self.upper):\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclips a value to a bound.", "response": "def clip(self, value):\n        \"\"\"\n        Clip a value to a bound.\n\n        Parameters\n        ----------\n        value : scalar or ndarray\n            value to clip\n\n        Returns\n        -------\n        scalar or ndarray :\n            of the same shape as value, bit with each element clipped to fall\n            within the specified bounds\n\n        Example\n        -------\n        >>> bnd = Bound(1, 2)\n        >>> bnd.clip(1.5)\n        1.5\n        >>> bnd.clip(3)\n        2\n        >>> bnd.clip(np.array([1, 3, 1.5]))\n        array([ 1. ,  2. ,  1.5])\n        >>> bnd = Bound(None, None)\n        >>> bnd.clip(np.array([1, 3, 1.5]))\n        array([ 1. ,  3. ,  1.5])\n        \"\"\"\n        if not self.lower and not self.upper:\n            return value\n\n        return np.clip(value, self.lower, self.upper)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new changeset and returns it.", "response": "def commit(self, message, author, parents=None, branch=None, date=None,\n               **kwargs):\n        \"\"\"\n        Performs in-memory commit (doesn't check workdir in any way) and\n        returns newly created ``Changeset``. Updates repository's\n        ``revisions``.\n\n        :param message: message of the commit\n        :param author: full username, i.e. \"Joe Doe <joe.doe@example.com>\"\n        :param parents: single parent or sequence of parents from which commit\n          would be derieved\n        :param date: ``datetime.datetime`` instance. Defaults to\n          ``datetime.datetime.now()``.\n        :param branch: branch name, as string. If none given, default backend's\n          branch would be used.\n\n        :raises ``CommitError``: if any error occurs while committing\n        \"\"\"\n        self.check_integrity(parents)\n\n        from .repository import GitRepository\n        if branch is None:\n            branch = GitRepository.DEFAULT_BRANCH_NAME\n\n        repo = self.repository._repo\n        object_store = repo.object_store\n\n        ENCODING = \"UTF-8\"\n        DIRMOD = 040000\n\n        # Create tree and populates it with blobs\n        commit_tree = self.parents[0] and repo[self.parents[0]._commit.tree] or\\\n            objects.Tree()\n        for node in self.added + self.changed:\n            # Compute subdirs if needed\n            dirpath, nodename = posixpath.split(node.path)\n            dirnames = dirpath and dirpath.split('/') or []\n            parent = commit_tree\n            ancestors = [('', parent)]\n\n            # Tries to dig for the deepest existing tree\n            while dirnames:\n                curdir = dirnames.pop(0)\n                try:\n                    dir_id = parent[curdir][1]\n                except KeyError:\n                    # put curdir back into dirnames and stops\n                    dirnames.insert(0, curdir)\n                    break\n                else:\n                    # If found, updates parent\n                    parent = self.repository._repo[dir_id]\n                    ancestors.append((curdir, parent))\n            # Now parent is deepest existing tree and we need to create subtrees\n            # for dirnames (in reverse order) [this only applies for nodes from added]\n            new_trees = []\n\n            if not node.is_binary:\n                content = node.content.encode(ENCODING)\n            else:\n                content = node.content\n            blob = objects.Blob.from_string(content)\n\n            node_path = node.name.encode(ENCODING)\n            if dirnames:\n                # If there are trees which should be created we need to build\n                # them now (in reverse order)\n                reversed_dirnames = list(reversed(dirnames))\n                curtree = objects.Tree()\n                curtree[node_path] = node.mode, blob.id\n                new_trees.append(curtree)\n                for dirname in reversed_dirnames[:-1]:\n                    newtree = objects.Tree()\n                    #newtree.add(DIRMOD, dirname, curtree.id)\n                    newtree[dirname] = DIRMOD, curtree.id\n                    new_trees.append(newtree)\n                    curtree = newtree\n                parent[reversed_dirnames[-1]] = DIRMOD, curtree.id\n            else:\n                parent.add(name=node_path, mode=node.mode, hexsha=blob.id)\n\n            new_trees.append(parent)\n            # Update ancestors\n            for parent, tree, path in reversed([(a[1], b[1], b[0]) for a, b in\n                zip(ancestors, ancestors[1:])]):\n                parent[path] = DIRMOD, tree.id\n                object_store.add_object(tree)\n\n            object_store.add_object(blob)\n            for tree in new_trees:\n                object_store.add_object(tree)\n        for node in self.removed:\n            paths = node.path.split('/')\n            tree = commit_tree\n            trees = [tree]\n            # Traverse deep into the forest...\n            for path in paths:\n                try:\n                    obj = self.repository._repo[tree[path][1]]\n                    if isinstance(obj, objects.Tree):\n                        trees.append(obj)\n                        tree = obj\n                except KeyError:\n                    break\n            # Cut down the blob and all rotten trees on the way back...\n            for path, tree in reversed(zip(paths, trees)):\n                del tree[path]\n                if tree:\n                    # This tree still has elements - don't remove it or any\n                    # of it's parents\n                    break\n\n        object_store.add_object(commit_tree)\n\n        # Create commit\n        commit = objects.Commit()\n        commit.tree = commit_tree.id\n        commit.parents = [p._commit.id for p in self.parents if p]\n        commit.author = commit.committer = safe_str(author)\n        commit.encoding = ENCODING\n        commit.message = safe_str(message)\n\n        # Compute date\n        if date is None:\n            date = time.time()\n        elif isinstance(date, datetime.datetime):\n            date = time.mktime(date.timetuple())\n\n        author_time = kwargs.pop('author_time', date)\n        commit.commit_time = int(date)\n        commit.author_time = int(author_time)\n        tz = time.timezone\n        author_tz = kwargs.pop('author_timezone', tz)\n        commit.commit_timezone = tz\n        commit.author_timezone = author_tz\n\n        object_store.add_object(commit)\n\n        ref = 'refs/heads/%s' % branch\n        repo.refs[ref] = commit.id\n\n        # Update vcs repository object & recreate dulwich repo\n        self.repository.revisions.append(commit.id)\n        # invalidate parsed refs after commit\n        self.repository._parsed_refs = self.repository._get_parsed_refs()\n        tip = self.repository.get_changeset()\n        self.reset()\n        return tip"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of missing trees for the given path.", "response": "def _get_missing_trees(self, path, root_tree):\n        \"\"\"\n        Creates missing ``Tree`` objects for the given path.\n\n        :param path: path given as a string. It may be a path to a file node\n          (i.e. ``foo/bar/baz.txt``) or directory path - in that case it must\n          end with slash (i.e. ``foo/bar/``).\n        :param root_tree: ``dulwich.objects.Tree`` object from which we start\n          traversing (should be commit's root tree)\n        \"\"\"\n        dirpath = posixpath.split(path)[0]\n        dirs = dirpath.split('/')\n        if not dirs or dirs == ['']:\n            return []\n\n        def get_tree_for_dir(tree, dirname):\n            for name, mode, id in tree.iteritems():\n                if name == dirname:\n                    obj = self.repository._repo[id]\n                    if isinstance(obj, objects.Tree):\n                        return obj\n                    else:\n                        raise RepositoryError(\"Cannot create directory %s \"\n                        \"at tree %s as path is occupied and is not a \"\n                        \"Tree\" % (dirname, tree))\n            return None\n\n        trees = []\n        parent = root_tree\n        for dirname in dirs:\n            tree = get_tree_for_dir(parent, dirname)\n            if tree is None:\n                tree = objects.Tree()\n                dirmode = 040000\n                parent.add(dirmode, dirname, tree.id)\n                parent = tree\n            # Always append tree\n            trees.append(tree)\n        return trees"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a value to a list.", "response": "def to_list(x):\n    \"\"\"Convert a value to a list.\n\n    Parameters\n    ----------\n    x\n        Value.\n\n    Returns\n    -------\n    `list`\n\n    Examples\n    --------\n    >>> to_list(0)\n    [0]\n    >>> to_list({'x': 0})\n    [{'x': 0}]\n    >>> to_list(x ** 2 for x in range(3))\n    [0, 1, 4]\n    >>> x = [1, 2, 3]\n    >>> to_list(x)\n    [1, 2, 3]\n    >>> _ is x\n    True\n    \"\"\"\n    if isinstance(x, list):\n        return x\n    if not isinstance(x, dict):\n        try:\n            return list(x)\n        except TypeError:\n            pass\n    return [x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill(xs, length, copy=False):\n    if isinstance(xs, list) and len(xs) == length:\n        return xs\n\n    if length <= 0:\n        return []\n\n    try:\n        xs = list(islice(xs, 0, length))\n        if not xs:\n            raise ValueError('empty input')\n    except TypeError:\n        xs = [xs]\n\n    if len(xs) < length:\n        if copy:\n            last = xs[-1]\n            xs.extend(deepcopy(last) for _ in range(length - len(xs)))\n        else:\n            xs.extend(islice(repeat(xs[-1]), 0, length - len(xs)))\n\n    return xs", "response": "Convert a value to a list of specified length."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef int_enum(cls, val):\n    if isinstance(val, str):\n        val = val.upper()\n        try:\n            return getattr(cls, val)\n        except AttributeError:\n            raise ValueError('{0}.{1}'.format(cls, val))\n    return cls(val)", "response": "Get int enum value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(obj, cls, default_factory):\n    if obj is None:\n        return default_factory()\n    if isinstance(obj, dict):\n        return cls.load(obj)\n    return obj", "response": "Create or load an object if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntruncating a string. Parameters ---------- string : `str` String to truncate. maxlen : `int` Maximum string length. end : `boolean`, optional Remove characters from the end (default: `True`). Raises ------ ValueError If `maxlen` <= 3. Returns ------- `str` Truncated string. Examples -------- >>> truncate('str', 6) 'str' >>> truncate('long string', 8) 'long ...' >>> truncate('long string', 8, False) '...tring'", "response": "def truncate(string, maxlen, end=True):\n    \"\"\"Truncate a string.\n\n    Parameters\n    ----------\n    string : `str`\n        String to truncate.\n    maxlen : `int`\n        Maximum string length.\n    end : `boolean`, optional\n        Remove characters from the end (default: `True`).\n\n    Raises\n    ------\n    ValueError\n        If `maxlen` <= 3.\n\n    Returns\n    -------\n    `str`\n        Truncated string.\n\n    Examples\n    --------\n    >>> truncate('str', 6)\n    'str'\n    >>> truncate('long string', 8)\n    'long ...'\n    >>> truncate('long string', 8, False)\n    '...tring'\n    \"\"\"\n    if maxlen <= 3:\n        raise ValueError('maxlen <= 3')\n\n    if len(string) <= maxlen:\n        return string\n\n    if end:\n        return string[:maxlen - 3] + '...'\n\n    return '...' + string[3 - maxlen:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd classes to the group.", "response": "def add_class(cls, *args):\n        \"\"\"Add classes to the group.\n\n        Parameters\n        ----------\n        *args : `type`\n            Classes to add.\n        \"\"\"\n        for cls2 in args:\n            cls.classes[cls2.__name__] = cls2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_class(cls, *args):\n        for cls2 in args:\n            try:\n                del cls.classes[cls2.__name__]\n            except KeyError:\n                pass", "response": "Removes classes from the group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(cls, data):\n        ret = cls.classes[data['__class__']]\n        data_cls = data['__class__']\n        del data['__class__']\n        try:\n            ret = ret(**data)\n        finally:\n            data['__class__'] = data_cls\n        return ret", "response": "Load an object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_oauth_client(self, consumer_key, consumer_secret):\n        self.oauth_client = oauth1.Client(consumer_key, consumer_secret)", "response": "Sets the oauth_client attribute"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the request body and headers of the signed request", "response": "def prepare_request(self, method, url, body=''):\n        \"\"\"Prepare the request body and headers\n\n        :returns: headers of the signed request\n        \"\"\"\n        headers = {\n            'Content-type': 'application/json',\n        }\n        # Note: we don't pass body to sign() since it's only for bodies that\n        # are form-urlencoded. Similarly, we don't care about the body that\n        # sign() returns.\n        uri, signed_headers, signed_body = self.oauth_client.sign(\n            url, http_method=method, headers=headers)\n        if body:\n            if method == 'GET':\n                body = urllib.urlencode(body)\n            else:\n                body = json.dumps(body)\n        headers.update(signed_headers)\n        return {\"headers\": headers, \"data\": body}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts error reason from the response.", "response": "def _get_error_reason(response):\n        \"\"\"Extract error reason from the response. It might be either\n        the 'reason' or the entire response\n        \"\"\"\n        try:\n            body = response.json()\n            if body and 'reason' in body:\n                return body['reason']\n        except ValueError:\n            pass\n        return response.content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing the headers encode data call API and provide data it returns", "response": "def fetch(self, method, url, data=None, expected_status_code=None):\n        \"\"\"Prepare the headers, encode data, call API and provide\n        data it returns\n        \"\"\"\n        kwargs = self.prepare_request(method, url, data)\n        log.debug(json.dumps(kwargs))\n        response = getattr(requests, method.lower())(url, **kwargs)\n        log.debug(json.dumps(response.content))\n        if response.status_code >= 400:\n            response.raise_for_status()\n        if (expected_status_code\n                and response.status_code != expected_status_code):\n            raise NotExpectedStatusCode(self._get_error_reason(response))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_json(self, method, url, data=None, expected_status_code=None):\n        return self.fetch(method, url, data, expected_status_code).json()", "response": "Fetch json data from fetch\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef structured_minimizer(minimizer):\n    @wraps(minimizer)\n    def new_minimizer(fun, parameters, jac=True, args=(), nstarts=0,\n                      random_state=None, **minimizer_kwargs):\n\n        (array1d, fbounds), shapes = flatten(\n            parameters,\n            hstack=bt.hstack,\n            shape=bt.shape,\n            ravel=partial(bt.ravel, random_state=random_state)\n        )\n\n        # Find best random starting candidate if we are doing random starts\n        if nstarts > 0:\n            array1d = _random_starts(\n                fun=fun,\n                parameters=parameters,\n                jac=jac,\n                args=args,\n                nstarts=nstarts,\n                random_state=random_state\n            )\n\n        # Wrap function calls to work with wrapped minimizer\n        flatten_args_dec = flatten_args(shapes)\n        new_fun = flatten_args_dec(fun)\n\n        # Wrap gradient calls to work with wrapped minimizer\n        if callable(jac):\n            new_jac = flatten_args_dec(jac)\n        else:\n            new_jac = jac\n            if bool(jac):\n                new_fun = flatten_func_grad(new_fun)\n\n        result = minimizer(new_fun, array1d, jac=new_jac, args=args,\n                           bounds=fbounds, **minimizer_kwargs)\n        result['x'] = tuple(unflatten(result['x'], shapes))\n\n        if bool(jac):\n            result['jac'] = tuple(unflatten(result['jac'], shapes))\n\n        return result\n\n    return new_minimizer", "response": "r A function that returns a pair of two - element cost function and a gradient of the optimal parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flatten_grad(func):\n    @wraps(func)\n    def new_func(*args, **kwargs):\n        return flatten(func(*args, **kwargs), returns_shapes=False)\n\n    return new_func", "response": "r Decorator to flatten structured gradients."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatten_args(shapes):\n    def flatten_args_dec(func):\n\n        @wraps(func)\n        def new_func(array1d, *args, **kwargs):\n            args = tuple(unflatten(array1d, shapes)) + args\n            return func(*args, **kwargs)\n\n        return new_func\n\n    return flatten_args_dec", "response": "r Flatten structured arguments to a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate and evaluate random starts for Parameter objects.", "response": "def _random_starts(fun,\n                   parameters,\n                   jac,\n                   args,\n                   nstarts,\n                   random_state,\n                   data_gen=None):\n    \"\"\"Generate and evaluate random starts for Parameter objects.\"\"\"\n    if nstarts < 1:\n        raise ValueError(\"nstarts has to be greater than or equal to 1\")\n\n    # Check to see if there are any random parameter types\n    anyrand = any(flatten(map_recursive(lambda p: p.is_random, parameters),\n                  returns_shapes=False))\n\n    if not anyrand:\n        log.info(\"No random parameters, not doing any random starts\")\n        params = map_recursive(lambda p: p.value, parameters, output_type=list)\n        return params\n\n    log.info(\"Evaluating random starts...\")\n\n    # Deal with gradient returns from objective function\n    if jac is True:\n        call_fun = lambda *fargs: fun(*fargs)[0]\n    else:  # No gradient returns or jac is callable\n        call_fun = fun\n\n    # Randomly draw parameters and evaluate function\n    def fun_eval():\n        batch = next(data_gen) if data_gen else ()\n        params = map_recursive(lambda p: p.rvs(random_state), parameters,\n                               output_type=list)\n        obj = call_fun(*chain(params, batch, args))\n        return obj, params\n\n    # Test randomly drawn parameters\n    sample_gen = (fun_eval() for _ in range(nstarts))\n    obj, params = min(sample_gen, key=lambda t: t[0])\n\n    log.info(\"Best start found with objective = {}\".format(obj))\n\n    return flatten(params, returns_shapes=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate warping functions and new bounds for the log trick.", "response": "def _logtrick_gen(bounds):\n    \"\"\"Generate warping functions and new bounds for the log trick.\"\"\"\n    # Test which parameters we can apply the log trick too\n    ispos = np.array([isinstance(b, bt.Positive) for b in bounds], dtype=bool)\n    nispos = ~ispos\n\n    # Functions that implement the log trick\n    def logx(x):\n        xwarp = np.empty_like(x)\n        xwarp[ispos] = np.log(x[ispos])\n        xwarp[nispos] = x[nispos]\n        return xwarp\n\n    def expx(xwarp):\n        x = np.empty_like(xwarp)\n        x[ispos] = np.exp(xwarp[ispos])\n        x[nispos] = xwarp[nispos]\n        return x\n\n    def gradx(grad, xwarp):\n        gwarp = np.empty_like(grad)\n        gwarp[ispos] = grad[ispos] * np.exp(xwarp[ispos])\n        gwarp[nispos] = grad[nispos]\n        return gwarp\n\n    # Redefine bounds as appropriate for new ranges for numerical stability\n    for i, (b, pos) in enumerate(zip(bounds, ispos)):\n        if pos:\n            upper = EXPMAX if b.upper is None else np.log(b.upper)\n            bounds[i] = bt.Bound(lower=LOGMINPOS, upper=upper)\n\n    return logx, expx, gradx, bounds"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning given git command and returns tuple of stdout and stderr.", "response": "def _run_git_command(cls, cmd, **opts):\n        \"\"\"\n        Runs given ``cmd`` as git command and returns tuple\n        (stdout, stderr).\n\n        :param cmd: git command to be executed\n        :param opts: env options to pass into Subprocess command\n        \"\"\"\n\n        if '_bare' in opts:\n            _copts = []\n            del opts['_bare']\n        else:\n            _copts = ['-c', 'core.quotepath=false', ]\n        safe_call = False\n        if '_safe' in opts:\n            #no exc on failure\n            del opts['_safe']\n            safe_call = True\n\n        _str_cmd = False\n        if isinstance(cmd, basestring):\n            cmd = [cmd]\n            _str_cmd = True\n\n        gitenv = os.environ\n        # need to clean fix GIT_DIR !\n        if 'GIT_DIR' in gitenv:\n            del gitenv['GIT_DIR']\n        gitenv['GIT_CONFIG_NOGLOBAL'] = '1'\n\n        _git_path = settings.GIT_EXECUTABLE_PATH\n        cmd = [_git_path] + _copts + cmd\n        if _str_cmd:\n            cmd = ' '.join(cmd)\n        try:\n            _opts = dict(\n                env=gitenv,\n                shell=False,\n            )\n            _opts.update(opts)\n            p = subprocessio.SubprocessIOChunker(cmd, **_opts)\n        except (EnvironmentError, OSError), err:\n            tb_err = (\"Couldn't run git command (%s).\\n\"\n                      \"Original error was:%s\\n\" % (cmd, err))\n            if safe_call:\n                return '', err\n            else:\n                raise RepositoryError(tb_err)\n\n        return ''.join(p.output), ''.join(p.error)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if given url is a valid mercurial url.", "response": "def _check_url(cls, url):\n        \"\"\"\n        Functon will check given url and try to verify if it's a valid\n        link. Sometimes it may happened that mercurial will issue basic\n        auth request that can cause whole API to hang when used from python\n        or other external calls.\n\n        On failures it'll raise urllib2.HTTPError\n        \"\"\"\n\n        # check first if it's not an local url\n        if os.path.isdir(url) or url.startswith('file:'):\n            return True\n\n        if('+' in url[:url.find('://')]):\n            url = url[url.find('+') + 1:]\n\n        handlers = []\n        test_uri, authinfo = hg_url(url).authinfo()\n        if not test_uri.endswith('info/refs'):\n            test_uri = test_uri.rstrip('/') + '/info/refs'\n        if authinfo:\n            #create a password manager\n            passmgr = urllib2.HTTPPasswordMgrWithDefaultRealm()\n            passmgr.add_password(*authinfo)\n\n            handlers.extend((httpbasicauthhandler(passmgr),\n                             httpdigestauthhandler(passmgr)))\n\n        o = urllib2.build_opener(*handlers)\n        o.addheaders = [('User-Agent', 'git/1.7.8.0')]  # fake some git\n\n        q = {\"service\": 'git-upload-pack'}\n        qs = '?%s' % urllib.urlencode(q)\n        cu = \"%s%s\" % (test_uri, qs)\n        req = urllib2.Request(cu, None, {})\n\n        try:\n            resp = o.open(req)\n            return resp.code == 200\n        except Exception, e:\n            # means it cannot be cloned\n            raise urllib2.URLError(\"[%s] %s\" % (url, e))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_revision(self, revision):\n\n        is_null = lambda o: len(o) == revision.count('0')\n\n        try:\n            self.revisions[0]\n        except (KeyError, IndexError):\n            raise EmptyRepositoryError(\"There are no changesets yet\")\n\n        if revision in (None, '', 'tip', 'HEAD', 'head', -1):\n            return self.revisions[-1]\n\n        is_bstr = isinstance(revision, (str, unicode))\n        if ((is_bstr and revision.isdigit() and len(revision) < 12)\n            or isinstance(revision, int) or is_null(revision)):\n            try:\n                revision = self.revisions[int(revision)]\n            except Exception:\n                raise ChangesetDoesNotExistError(\"Revision %s does not exist \"\n                    \"for this repository\" % (revision))\n\n        elif is_bstr:\n            # get by branch/tag name\n            _ref_revision = self._parsed_refs.get(revision)\n            if _ref_revision:  # and _ref_revision[1] in ['H', 'RH', 'T']:\n                return _ref_revision[0]\n\n            _tags_shas = self.tags.values()\n            # maybe it's a tag ? we don't have them in self.revisions\n            if revision in _tags_shas:\n                return _tags_shas[_tags_shas.index(revision)]\n\n            elif not SHA_PATTERN.match(revision) or revision not in self.revisions:\n                raise ChangesetDoesNotExistError(\"Revision %s does not exist \"\n                    \"for this repository\" % (revision))\n\n        # Ensure we return full id\n        if not SHA_PATTERN.match(str(revision)):\n            raise ChangesetDoesNotExistError(\"Given revision %s not recognized\"\n                % revision)\n        return revision", "response": "Get the revision of a changset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn normalized url. If schema is not given, would fall to filesystem (``file:///``) schema.", "response": "def _get_url(self, url):\n        \"\"\"\n        Returns normalized url. If schema is not given, would fall to\n        filesystem (``file:///``) schema.\n        \"\"\"\n        url = str(url)\n        if url != 'default' and not '://' in url:\n            url = ':///'.join(('file', url))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_hook_location(self):\n        loc = os.path.join(self.path, 'hooks')\n        if not self.bare:\n            loc = os.path.join(self.path, '.git', 'hooks')\n        return loc", "response": "returns absolute path to location where hooks are stored\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and returns a new tag for the given revision.", "response": "def tag(self, name, user, revision=None, message=None, date=None,\n            **kwargs):\n        \"\"\"\n        Creates and returns a tag for the given ``revision``.\n\n        :param name: name for new tag\n        :param user: full username, i.e.: \"Joe Doe <joe.doe@example.com>\"\n        :param revision: changeset id for which new tag would be created\n        :param message: message of the tag's commit\n        :param date: date of tag's commit\n\n        :raises TagAlreadyExistError: if tag with same name already exists\n        \"\"\"\n        if name in self.tags:\n            raise TagAlreadyExistError(\"Tag %s already exists\" % name)\n        changeset = self.get_changeset(revision)\n        message = message or \"Added tag %s for commit %s\" % (name,\n            changeset.raw_id)\n        self._repo.refs[\"refs/tags/%s\" % name] = changeset._commit.id\n\n        self._parsed_refs = self._get_parsed_refs()\n        self.tags = self._get_tags()\n        return changeset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_tag(self, name, user, message=None, date=None):\n        if name not in self.tags:\n            raise TagDoesNotExistError(\"Tag %s does not exist\" % name)\n        tagpath = posixpath.join(self._repo.refs.path, 'refs', 'tags', name)\n        try:\n            os.remove(tagpath)\n            self._parsed_refs = self._get_parsed_refs()\n            self.tags = self._get_tags()\n        except OSError, e:\n            raise RepositoryError(e.strerror)", "response": "Removes a tag with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_changeset(self, revision=None):\n        if isinstance(revision, GitChangeset):\n            return revision\n        revision = self._get_revision(revision)\n        changeset = GitChangeset(repository=self, revision=revision)\n        return changeset", "response": "Returns a GitChangeset object representing the revision at the given revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator of git changesets in the given date range.", "response": "def get_changesets(self, start=None, end=None, start_date=None,\n           end_date=None, branch_name=None, reverse=False):\n        \"\"\"\n        Returns iterator of ``GitChangeset`` objects from start to end (both\n        are inclusive), in ascending date order (unless ``reverse`` is set).\n\n        :param start: changeset ID, as str; first returned changeset\n        :param end: changeset ID, as str; last returned changeset\n        :param start_date: if specified, changesets with commit date less than\n          ``start_date`` would be filtered out from returned set\n        :param end_date: if specified, changesets with commit date greater than\n          ``end_date`` would be filtered out from returned set\n        :param branch_name: if specified, changesets not reachable from given\n          branch would be filtered out from returned set\n        :param reverse: if ``True``, returned generator would be reversed\n          (meaning that returned changesets would have descending date order)\n\n        :raise BranchDoesNotExistError: If given ``branch_name`` does not\n            exist.\n        :raise ChangesetDoesNotExistError: If changeset for given ``start`` or\n          ``end`` could not be found.\n\n        \"\"\"\n        if branch_name and branch_name not in self.branches:\n            raise BranchDoesNotExistError(\"Branch '%s' not found\" \\\n                                          % branch_name)\n        # %H at format means (full) commit hash, initial hashes are retrieved\n        # in ascending date order\n        cmd_template = 'log --date-order --reverse --pretty=format:\"%H\"'\n        cmd_params = {}\n        if start_date:\n            cmd_template += ' --since \"$since\"'\n            cmd_params['since'] = start_date.strftime('%m/%d/%y %H:%M:%S')\n        if end_date:\n            cmd_template += ' --until \"$until\"'\n            cmd_params['until'] = end_date.strftime('%m/%d/%y %H:%M:%S')\n        if branch_name:\n            cmd_template += ' $branch_name'\n            cmd_params['branch_name'] = branch_name\n        else:\n            rev_filter = settings.GIT_REV_FILTER\n            cmd_template += ' %s' % (rev_filter)\n\n        cmd = string.Template(cmd_template).safe_substitute(**cmd_params)\n        revs = self.run_git_command(cmd)[0].splitlines()\n        start_pos = 0\n        end_pos = len(revs)\n        if start:\n            _start = self._get_revision(start)\n            try:\n                start_pos = revs.index(_start)\n            except ValueError:\n                pass\n\n        if end is not None:\n            _end = self._get_revision(end)\n            try:\n                end_pos = revs.index(_end)\n            except ValueError:\n                pass\n\n        if None not in [start, end] and start_pos > end_pos:\n            raise RepositoryError('start cannot be after end')\n\n        if end_pos is not None:\n            end_pos += 1\n\n        revs = revs[start_pos:end_pos]\n        if reverse:\n            revs = reversed(revs)\n        return CollectionGenerator(self, revs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_diff(self, rev1, rev2, path=None, ignore_whitespace=False,\n                 context=3):\n        \"\"\"\n        Returns (git like) *diff*, as plain text. Shows changes introduced by\n        ``rev2`` since ``rev1``.\n\n        :param rev1: Entry point from which diff is shown. Can be\n          ``self.EMPTY_CHANGESET`` - in this case, patch showing all\n          the changes since empty state of the repository until ``rev2``\n        :param rev2: Until which revision changes should be shown.\n        :param ignore_whitespace: If set to ``True``, would not show whitespace\n          changes. Defaults to ``False``.\n        :param context: How many lines before/after changed lines should be\n          shown. Defaults to ``3``.\n        \"\"\"\n        flags = ['-U%s' % context, '--full-index', '--binary', '-p', '-M', '--abbrev=40']\n        if ignore_whitespace:\n            flags.append('-w')\n\n        if hasattr(rev1, 'raw_id'):\n            rev1 = getattr(rev1, 'raw_id')\n\n        if hasattr(rev2, 'raw_id'):\n            rev2 = getattr(rev2, 'raw_id')\n\n        if rev1 == self.EMPTY_CHANGESET:\n            rev2 = self.get_changeset(rev2).raw_id\n            cmd = ' '.join(['show'] + flags + [rev2])\n        else:\n            rev1 = self.get_changeset(rev1).raw_id\n            rev2 = self.get_changeset(rev2).raw_id\n            cmd = ' '.join(['diff'] + flags + [rev1, rev2])\n\n        if path:\n            cmd += ' -- \"%s\"' % path\n\n        stdout, stderr = self.run_git_command(cmd)\n        # If we used 'show' command, strip first few lines (until actual diff\n        # starts)\n        if rev1 == self.EMPTY_CHANGESET:\n            lines = stdout.splitlines()\n            x = 0\n            for line in lines:\n                if line.startswith('diff'):\n                    break\n                x += 1\n            # Append new line just like 'diff' command do\n            stdout = '\\n'.join(lines[x:]) + '\\n'\n        return stdout", "response": "Returns git like diff as plain text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to clone changes from external location.", "response": "def clone(self, url, update_after_clone=True, bare=False):\n        \"\"\"\n        Tries to clone changes from external location.\n\n        :param update_after_clone: If set to ``False``, git won't checkout\n          working directory\n        :param bare: If set to ``True``, repository would be cloned into\n          *bare* git repository (no working directory at all).\n        \"\"\"\n        url = self._get_url(url)\n        cmd = ['clone']\n        if bare:\n            cmd.append('--bare')\n        elif not update_after_clone:\n            cmd.append('--no-checkout')\n        cmd += ['--', '\"%s\"' % url, '\"%s\"' % self.path]\n        cmd = ' '.join(cmd)\n        # If error occurs run_git_command raises RepositoryError already\n        self.run_git_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to pull changes from external location.", "response": "def pull(self, url):\n        \"\"\"\n        Tries to pull changes from external location.\n        \"\"\"\n        url = self._get_url(url)\n        cmd = ['pull']\n        cmd.append(\"--ff-only\")\n        cmd.append(url)\n        cmd = ' '.join(cmd)\n        # If error occurs run_git_command raises RepositoryError already\n        self.run_git_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch(self, url):\n        url = self._get_url(url)\n        so, se = self.run_git_command('ls-remote -h %s' % url)\n        refs = []\n        for line in (x for x in so.splitlines()):\n            sha, ref = line.split('\\t')\n            refs.append(ref)\n        refs = ' '.join(('+%s:%s' % (r, r) for r in refs))\n        cmd = '''fetch %s -- %s''' % (url, refs)\n        self.run_git_command(cmd)", "response": "Tries to pull changes from external location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_config_value(self, section, name, config_file=None):\n        if config_file is None:\n            config_file = []\n        elif isinstance(config_file, basestring):\n            config_file = [config_file]\n\n        def gen_configs():\n            for path in config_file + self._config_files:\n                try:\n                    yield ConfigFile.from_path(path)\n                except (IOError, OSError, ValueError):\n                    continue\n\n        for config in gen_configs():\n            try:\n                return config.get(section, name)\n            except KeyError:\n                continue\n        return None", "response": "Retrieves the value of a given section and name from a given config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an html portion of the given file node with annotated lines.", "response": "def annotate_highlight(filenode, annotate_from_changeset_func=None,\n        order=None, headers=None, **options):\n    \"\"\"\n    Returns html portion containing annotated table with 3 columns: line\n    numbers, changeset information and pygmentized line of code.\n\n    :param filenode: FileNode object\n    :param annotate_from_changeset_func: function taking changeset and\n      returning single annotate cell; needs break line at the end\n    :param order: ordered sequence of ``ls`` (line numbers column),\n      ``annotate`` (annotate column), ``code`` (code column); Default is\n      ``['ls', 'annotate', 'code']``\n    :param headers: dictionary with headers (keys are whats in ``order``\n      parameter)\n    \"\"\"\n    options['linenos'] = True\n    formatter = AnnotateHtmlFormatter(filenode=filenode, order=order,\n        headers=headers,\n        annotate_from_changeset_func=annotate_from_changeset_func, **options)\n    lexer = filenode.lexer\n    highlighted = highlight(filenode.content, lexer, formatter)\n    return highlighted"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef annotate_from_changeset(self, changeset):\n        if self.annotate_from_changeset_func:\n            return self.annotate_from_changeset_func(changeset)\n        else:\n            return ''.join((changeset.id, '\\n'))", "response": "Returns full html line for single changeset per annotated line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap the inner tablelinenos in a single line.", "response": "def _wrap_tablelinenos(self, inner):\n        dummyoutfile = StringIO.StringIO()\n        lncount = 0\n        for t, line in inner:\n            if t:\n                lncount += 1\n            dummyoutfile.write(line)\n\n        fl = self.linenostart\n        mw = len(str(lncount + fl - 1))\n        sp = self.linenospecial\n        st = self.linenostep\n        la = self.lineanchors\n        aln = self.anchorlinenos\n        if sp:\n            lines = []\n\n            for i in range(fl, fl + lncount):\n                if i % st == 0:\n                    if i % sp == 0:\n                        if aln:\n                            lines.append('<a href=\"#%s-%d\" class=\"special\">'\n                                         '%*d</a>' %\n                                         (la, i, mw, i))\n                        else:\n                            lines.append('<span class=\"special\">'\n                                         '%*d</span>' % (mw, i))\n                    else:\n                        if aln:\n                            lines.append('<a href=\"#%s-%d\">'\n                                         '%*d</a>' % (la, i, mw, i))\n                        else:\n                            lines.append('%*d' % (mw, i))\n                else:\n                    lines.append('')\n            ls = '\\n'.join(lines)\n        else:\n            lines = []\n            for i in range(fl, fl + lncount):\n                if i % st == 0:\n                    if aln:\n                        lines.append('<a href=\"#%s-%d\">%*d</a>' \\\n                                     % (la, i, mw, i))\n                    else:\n                        lines.append('%*d' % (mw, i))\n                else:\n                    lines.append('')\n            ls = '\\n'.join(lines)\n\n        annotate_changesets = [tup[1] for tup in self.filenode.annotate]\n        # If pygments cropped last lines break we need do that too\n        ln_cs = len(annotate_changesets)\n        ln_ = len(ls.splitlines())\n        if  ln_cs > ln_:\n            annotate_changesets = annotate_changesets[:ln_ - ln_cs]\n        annotate = ''.join((self.annotate_from_changeset(changeset)\n            for changeset in annotate_changesets))\n        # in case you wonder about the seemingly redundant <div> here:\n        # since the content in the other cell also is wrapped in a div,\n        # some browsers in some configurations seem to mess up the formatting.\n        '''\n        yield 0, ('<table class=\"%stable\">' % self.cssclass +\n                  '<tr><td class=\"linenos\"><div class=\"linenodiv\"><pre>' +\n                  ls + '</pre></div></td>' +\n                  '<td class=\"code\">')\n        yield 0, dummyoutfile.getvalue()\n        yield 0, '</td></tr></table>'\n\n        '''\n        headers_row = []\n        if self.headers:\n            headers_row = ['<tr class=\"annotate-header\">']\n            for key in self.order:\n                td = ''.join(('<td>', self.headers[key], '</td>'))\n                headers_row.append(td)\n            headers_row.append('</tr>')\n\n        body_row_start = ['<tr>']\n        for key in self.order:\n            if key == 'ls':\n                body_row_start.append(\n                    '<td class=\"linenos\"><div class=\"linenodiv\"><pre>' +\n                    ls + '</pre></div></td>')\n            elif key == 'annotate':\n                body_row_start.append(\n                    '<td class=\"annotate\"><div class=\"annotatediv\"><pre>' +\n                    annotate + '</pre></div></td>')\n            elif key == 'code':\n                body_row_start.append('<td class=\"code\">')\n        yield 0, ('<table class=\"%stable\">' % self.cssclass +\n                  ''.join(headers_row) +\n                  ''.join(body_row_start)\n                  )\n        yield 0, dummyoutfile.getvalue()\n        yield 0, '</td></tr></table>'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _obtain_lock_or_raise(self):\n        if self._has_lock():\n            return\n        lock_file = self._lock_file_path()\n        if os.path.isfile(lock_file):\n            raise IOError(\"Lock for file %r did already exist, delete %r in case the lock is illegal\" % (self._file_path, lock_file))\n\n        try:\n            fd = os.open(lock_file, os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0)\n            os.close(fd)\n        except OSError,e:\n            raise IOError(str(e))\n\n        self._owns_lock = True", "response": "Create a lock file as flag for other instances mark our instance as lock - holder\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _release_lock(self):\n        if not self._has_lock():\n            return\n\n        # if someone removed our file beforhand, lets just flag this issue\n        # instead of failing, to make it more usable.\n        lfp = self._lock_file_path()\n        try:\n            # on bloody windows, the file needs write permissions to be removable.\n            # Why ...\n            if os.name == 'nt':\n                os.chmod(lfp, 0777)\n            # END handle win32\n            os.remove(lfp)\n        except OSError:\n            pass\n        self._owns_lock = False", "response": "Release our lock if we have one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_getitem_args(args):\n    '''Turns the arguments to __getitem__ magic methods into a uniform\n    list of tuples and strings\n    '''\n    if not isinstance(args, tuple):\n        args = (args,)\n    return_val = []\n    for arg in args:\n        if isinstance(arg, six.string_types + (int, )):\n            return_val.append(arg)\n        elif isinstance(arg, slice):\n            return_val.append((arg.start, arg.stop))\n        else:\n            raise TypeError(\n                'Brackets cannot contain objects of type {0.__name__}'\n                .format(type(arg)))\n    return return_val", "response": "Turns the arguments to __getitem__ magic methods into a uniform\n    list of tuples and strings\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn a root uri into a less noisy representation that will probably make sense in most circumstances. Used by Navigator s __repr__ but can be overridden if the Navigator is created with a name parameter.", "response": "def namify(root_uri):\n    '''Turns a root uri into a less noisy representation that will probably\n    make sense in most circumstances. Used by Navigator's __repr__, but can be\n    overridden if the Navigator is created with a 'name' parameter.'''\n\n    root_uri = unidecode.unidecode(decode(unquote(root_uri), 'utf-8'))\n\n    generic_domains = set(['localhost', 'herokuapp', 'appspot'])\n    urlp = urlparse.urlparse(fix_scheme(root_uri))\n    formatargs = collections.defaultdict(list)\n\n    netloc = urlp.netloc.lower()\n    if ']' in netloc:\n        domain = netloc.rsplit(']:', 1)[0]  # don't need port\n    elif ':' in netloc:\n        domain = netloc.rsplit(':', 1)[0]  # don't need port\n    else:\n        domain = netloc\n\n    if not translate(domain,\"abcdef:.[]\").isdigit():\n        if '.' in domain:\n            domain, tld = domain.rsplit('.', 1)\n        else:\n            tld = ''\n        if '.' in domain:\n            subdomain, domain = domain.rsplit('.', 1)\n        else:\n            subdomain = ''\n\n        if subdomain != 'www':\n            formatargs['subdomain'] = subdomain.split('.')\n        if domain not in generic_domains:\n            formatargs['domain'].append(domain)\n        if len(tld) == 2:\n            formatargs['tld'].append(tld.upper())\n        elif tld != 'com':\n            formatargs['tld'].append(tld)\n\n    formatargs['path'].extend(p for p in urlp.path.lower().split('/') if p)\n    formatargs['qargs'].extend(r for q in urlp.query.split(',')\n                               for r in q.split('=') if q and r)\n\n    def capify(s):\n        '''Capitalizes the first letter of a string, but doesn't downcase the\n        rest like .title()'''\n        return s if not s else s[0].upper() + s[1:]\n\n    def piece_filter(piece):\n        if piece.lower() == 'api':\n            formatargs['api'] = True\n            return ''\n        elif re.match(r'v[\\d.]+', piece):\n            formatargs['version'].extend(['.', piece])\n            return ''\n        elif 'api' in piece:\n            return piece.replace('api', 'API')\n        else:\n            return piece\n\n    chain = itertools.chain\n    pieces = map(capify, map(piece_filter, chain(\n        formatargs['subdomain'],\n        formatargs['domain'],\n        formatargs['tld'],\n        formatargs['path'],\n        formatargs['qargs'],\n    )))\n    return '{pieces}{api}{vrsn}'.format(pieces=''.join(pieces),\n                                        api='API' if formatargs['api'] else '',\n                                        vrsn=''.join(formatargs['version']),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objectify_uri(relative_uri):\n    '''Converts uris from path syntax to a json-like object syntax.\n    In addition, url escaped characters are unescaped, but non-ascii\n    characters a romanized using the unidecode library.\n\n    Examples:\n       \"/blog/3/comments\" becomes \"blog[3].comments\"\n       \"car/engine/piston\" becomes \"car.engine.piston\"\n    '''\n    def path_clean(chunk):\n        if not chunk:\n            return chunk\n        if re.match(r'\\d+$', chunk):\n            return '[{0}]'.format(chunk)\n        else:\n            return '.' + chunk\n\n    if six.PY2:\n        byte_arr = relative_uri.encode('utf-8')\n    else:\n        byte_arr = relative_uri\n    unquoted = decode(unquote(byte_arr), 'utf-8')\n    nice_uri = unidecode.unidecode(unquoted)\n    return ''.join(path_clean(c) for c in nice_uri.split('/'))", "response": "Converts uris from path syntax to a json - like object syntax."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a media type into a type subtype and parameter tuple.", "response": "def parse_media_type(media_type):\n    '''Returns type, subtype, parameter tuple from an http media_type.\n    Can be applied to the 'Accept' or 'Content-Type' http header fields.\n    '''\n    media_type, sep, parameter = str(media_type).partition(';')\n    media_type, sep, subtype = media_type.partition('/')\n    return tuple(x.strip() or None for x in (media_type, subtype, parameter))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a value nested in dictionaries containing dictionaries.", "response": "def getpath(d, json_path, default=None, sep='.'):\n    '''Gets a value nested in dictionaries containing dictionaries.\n    Returns the default if any key in the path doesn't exist.\n    '''\n    for key in json_path.split(sep):\n        try:\n            d = d[key]\n        except (KeyError, TypeError):\n            return default\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getstate(d):\n    '''Deep copies a dict, and returns it without the keys _links and\n    _embedded\n    '''\n    if not isinstance(d, dict):\n        raise TypeError(\"Can only get the state of a dictionary\")\n    cpd = copy.deepcopy(d)\n    cpd.pop('_links', None)\n    cpd.pop('_embedded', None)\n    return cpd", "response": "Deep copies a dict and returns it without the keys _links and _embedded"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an item to the dictionary with the given metadata properties", "response": "def append_with(self, obj, **properties):\n        '''Add an item to the dictionary with the given metadata properties'''\n        for prop, val in properties.items():\n            val = self.serialize(val)\n            self._meta.setdefault(prop, {}).setdefault(val, []).append(obj)\n        self.append(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve an item from the dictionary with the given metadata properties.", "response": "def get_by(self, prop, val, raise_exc=False):\n        '''Retrieve an item from the dictionary with the given metadata\n        properties. If there is no such item, None will be returned, if there\n        are multiple such items, the first will be returned.'''\n        try:\n            val = self.serialize(val)\n            return self._meta[prop][val][0]\n        except (KeyError, IndexError):\n            if raise_exc:\n                raise\n            else:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getall_by(self, prop, val):\n        '''Retrieves all items from the dictionary with the given metadata'''\n        try:\n            val = self.serialize(val)\n            return self._meta[prop][val][:]  # return a copy of the list\n        except KeyError:\n            return []", "response": "Retrieves all items from the dictionary with the given metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef named(self, name):\n        '''Returns .get_by('name', name)'''\n        name = self.serialize(name)\n        return self.get_by('name', name)", "response": "Returns a named entry in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_replace_state_separator(data, old, new):\n        for key, dataset in data.items():\n            data[key] = dict(\n                (k.replace(old, new), v)\n                for k, v in dataset.items()\n            )", "response": "Replace state separator.\n\n        Parameters\n        ----------\n        data : `dict` of `dict` of ([`int`, `str`] or [`list` of `int`, `list` of `str`])\n            Data.\n        old : `str`\n            Old separator.\n        new : `str`\n            New separator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_get_dataset(data, key, create=False):\n        if data is None:\n            return None\n        try:\n            return data[key]\n        except KeyError:\n            if create:\n                dataset = {}\n                data[key] = dataset\n                return dataset\n            else:\n                raise", "response": "Get a dataset.\n\n        Parameters\n        ----------\n        data : `None` or `dict` of `dict` of ([`int`, `str`] or [`list` of `int`, `list` of `str`])\n            Data.\n        key : `str`\n            Dataset key.\n        create : `bool`, optional\n            Create a dataset if it does not exist.\n\n        Returns\n        -------\n        `None` or `dict` of ([`int`, `str`] or [`list` of `int`, `list` of `str`])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_link(dataset, source, target, count=1):\n        try:\n            node = dataset[source]\n            values, links = node\n            if isinstance(links, list):\n                try:\n                    idx = links.index(target)\n                    values[idx] += count\n                except ValueError:\n                    links.append(target)\n                    values.append(count)\n            elif links == target:\n                node[0] += count\n            else:\n                node[0] = [values, count]\n                node[1] = [links, target]\n        except KeyError:\n            dataset[source] = [count, target]", "response": "Adds a link to the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_links(self, dataset, state, backward=False):\n        if backward and self.backward is None:\n            raise ValueError('no backward nodes')\n        try:\n            node = dataset[int(backward)][self.join_state(state)]\n            if not isinstance(node[0], list):\n                return [(node[0], node[1])]\n            return list(zip(*node))\n        except KeyError:\n            return []", "response": "Returns a list of links to the current node in the given state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_save(self, fp=None):\n        if fp is None:\n            fp = sys.stdout\n        data = {\n            'settings': self.settings,\n            'nodes': self.nodes,\n            'backward': self.backward\n        }\n        json.dump(data, fp, ensure_ascii=False)", "response": "Save to file.\n\n        Parameters\n        ----------\n        fp : `file` or `str`, optional\n            Output file (default: stdout)."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntags to return a truncated chain of user names.", "response": "def chain_user_names(users, exclude_user, truncate=35):\n    \"\"\"Tag to return a truncated chain of user names.\"\"\"\n    if not users or not isinstance(exclude_user, get_user_model()):\n        return ''\n    return truncatechars(\n        ', '.join(u'{}'.format(u) for u in users.exclude(pk=exclude_user.pk)),\n        truncate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url(self, key):\n        return urlunparse((self.protocol, '%s:%s' % (self.domain, self.port),\n                           '%s/api/v1%s' % (self.prefix, URLS[key]),\n                           '', '', ''))", "response": "Creates a full URL to the API using the urls dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_manifest_valid(self, manifest_id):\n        response = self.get_manifest_validation_result(manifest_id)\n        if response.status_code != 200:\n            raise Exception(response.status_code)\n        content = json.loads(response.content)\n        if not content['processed']:\n            return None\n        if content['valid']:\n            return True\n        return content['validation']", "response": "Check if manifest is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, app_id, data):\n        assert ('name' in data\n                and data['name']\n                and 'summary' in data\n                and 'categories' in data\n                and data['categories']\n                and 'support_email' in data\n                and data['support_email']\n                and 'device_types' in data\n                and data['device_types']\n                and 'payment_type' in data\n                and data['payment_type']\n                and 'privacy_policy' in data\n                and data['privacy_policy'])\n        return self.conn.fetch('PUT', self.url('app') % app_id, data)", "response": "Update an app identified by app_id with data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_screenshot(self, app_id, filename, position=1):\n        # prepare file for upload\n        with open(filename, 'rb') as s_file:\n            s_content = s_file.read()\n        s_encoded = b64encode(s_content)\n        url = self.url('create_screenshot') % app_id\n\n        mtype, encoding = mimetypes.guess_type(filename)\n        if mtype is None:\n            mtype = 'image/jpeg'\n\n        data = {'position': position,\n                'file': {'type': mtype,\n                         'data': s_encoded}}\n        return self.conn.fetch('POST', url, data)", "response": "Add a screenshot to the web app identified by app_id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_content_ratings(self, app_id, submission_id, security_code):\n        url = self.url('content_ratings') % app_id\n        return self.conn.fetch('POST', url,\n                               {'submission_id': '%s' % submission_id,\n                                'security_code': '%s' % security_code\n                                })", "response": "Adds content ratings to the web app identified by app_id using the specified submission id and security code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef app_state(self, app_id, status=None, disabled_by_user=None):\n        assert status is not None or disabled_by_user is not None\n        data = {}\n        if status:\n            data['status'] = status\n        if disabled_by_user:\n            data['disabled_by_user'] = disabled_by_user\n\n        return self.conn.fetch('PATCH', self.url('enable') % app_id, data)", "response": "Enable or disable an app."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a module with given name and path.", "response": "def create_module(name, path):\n    \"\"\"\n    Returns module created *on the fly*. Returned module would have name same\n    as given ``name`` and would contain code read from file at the given\n    ``path`` (it may also be a zip or package containing *__main__* module).\n    \"\"\"\n    module = imp.new_module(name)\n    module.__file__ = path\n    execfile(path, module.__dict__)\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans a string. Parameters ---------- data : `str` String to scan. part : `bool` True if data is partial. Returns ------- `generator` of (`str` or `markovchain.scanner.Scanner.END`) Token generator.", "response": "def scan(self, data, part):\n        \"\"\"Scan a string.\n\n        Parameters\n        ----------\n        data : `str`\n            String to scan.\n        part : `bool`\n            True if data is partial.\n\n        Returns\n        -------\n        `generator` of (`str` or `markovchain.scanner.Scanner.END`)\n            Token generator.\n        \"\"\"\n        if not self.end_chars:\n            yield from data\n            self.start = self.start or bool(data)\n            self.end = False\n        else:\n            for char in data:\n                if char in self.end_chars:\n                    if not self.start:\n                        continue\n                    self.end = True\n                else:\n                    if self.end:\n                        yield self.END\n                        self.end = False\n                    self.start = True\n                yield char\n\n        if not part and self.start:\n            if not self.end and self.default_end is not None:\n                yield self.default_end\n            yield self.END\n            self.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts to JSON. JSON data.", "response": "def save(self):\n        \"\"\"Convert to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        data = super().save()\n        data['end_chars'] = self.end_chars\n        data['default_end'] = self.default_end\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan(self, data, part):\n        if not self.expr.groups:\n            for match in self.expr.finditer(data):\n                yield match.group()\n\n            self.end = self.end and not bool(data)\n        else:\n            for match in self.expr.finditer(data):\n                group = self.get_group(match, 'end')\n                if group is not None:\n                    if not self.end:\n                        yield group\n                        yield self.END\n                        self.end = True\n                else:\n                    self.end = False\n                    group = self.get_group(match, 'word')\n                    if group is not None:\n                        yield group\n                    else:\n                        yield match.group()\n\n        if not part and not self.end:\n            if self.default_end is not None:\n                yield self.default_end\n            yield self.END\n            self.reset()", "response": "Scan a string.\n\n        Parameters\n        ----------\n        data : `str`\n            String to scan.\n        part : `bool`\n            `True` if data is partial.\n\n        Returns\n        -------\n        `generator` of (`str` or `markovchain.scanner.Scanner.END`)\n            Token generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the scanner to JSON. JSON data.", "response": "def save(self):\n        \"\"\"Convert the scanner to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        data = super().save()\n        data['expr'] = self.expr.pattern\n        data['default_end'] = self.default_end\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport the class specified by the path.", "response": "def import_class(class_path):\n    \"\"\"\n    Returns class from the given path.\n\n    For example, in order to get class located at\n    ``vcs.backends.hg.MercurialRepository``:\n\n        try:\n            hgrepo = import_class('vcs.backends.hg.MercurialRepository')\n        except VCSError:\n            # hadle error\n    \"\"\"\n    splitted = class_path.split('.')\n    mod_path = '.'.join(splitted[:-1])\n    class_name = splitted[-1]\n    try:\n        class_mod = __import__(mod_path, {}, {}, [class_name])\n    except ImportError, err:\n        msg = \"There was problem while trying to import backend class. \"\\\n            \"Original error was:\\n%s\" % err\n        raise VCSError(msg)\n    cls = getattr(class_mod, class_name)\n\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_branches(self, closed=False):\n\n        if self._empty:\n            return {}\n\n        def _branchtags(localrepo):\n            \"\"\"\n            Patched version of mercurial branchtags to not return the closed\n            branches\n\n            :param localrepo: locarepository instance\n            \"\"\"\n\n            bt = {}\n            bt_closed = {}\n            for bn, heads in localrepo.branchmap().iteritems():\n                tip = heads[-1]\n                if 'close' in localrepo.changelog.read(tip)[5]:\n                    bt_closed[bn] = tip\n                else:\n                    bt[bn] = tip\n\n            if closed:\n                bt.update(bt_closed)\n            return bt\n\n        sortkey = lambda ctx: ctx[0]  # sort by name\n        _branches = [(safe_unicode(n), hex(h),) for n, h in\n                     _branchtags(self._repo).items()]\n\n        return OrderedDict(sorted(_branches, key=sortkey, reverse=False))", "response": "Get a list of branches for this repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and returns a new tag for the given revision.", "response": "def tag(self, name, user, revision=None, message=None, date=None,\n            **kwargs):\n        \"\"\"\n        Creates and returns a tag for the given ``revision``.\n\n        :param name: name for new tag\n        :param user: full username, i.e.: \"Joe Doe <joe.doe@example.com>\"\n        :param revision: changeset id for which new tag would be created\n        :param message: message of the tag's commit\n        :param date: date of tag's commit\n\n        :raises TagAlreadyExistError: if tag with same name already exists\n        \"\"\"\n        if name in self.tags:\n            raise TagAlreadyExistError(\"Tag %s already exists\" % name)\n        changeset = self.get_changeset(revision)\n        local = kwargs.setdefault('local', False)\n\n        if message is None:\n            message = \"Added tag %s for changeset %s\" % (name,\n                changeset.short_id)\n\n        if date is None:\n            date = datetime.datetime.now().ctime()\n\n        try:\n            self._repo.tag(name, changeset._ctx.node(), message, local, user,\n                date)\n        except Abort, e:\n            raise RepositoryError(e.message)\n\n        # Reinitialize tags\n        self.tags = self._get_tags()\n        tag_id = self.tags[name]\n\n        return self.get_changeset(revision=tag_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a tag with the given name.", "response": "def remove_tag(self, name, user, message=None, date=None):\n        \"\"\"\n        Removes tag with the given ``name``.\n\n        :param name: name of the tag to be removed\n        :param user: full username, i.e.: \"Joe Doe <joe.doe@example.com>\"\n        :param message: message of the tag's removal commit\n        :param date: date of tag's removal commit\n\n        :raises TagDoesNotExistError: if tag with given name does not exists\n        \"\"\"\n        if name not in self.tags:\n            raise TagDoesNotExistError(\"Tag %s does not exist\" % name)\n        if message is None:\n            message = \"Removed tag %s\" % name\n        if date is None:\n            date = datetime.datetime.now().ctime()\n        local = False\n\n        try:\n            self._repo.tag(name, nullid, message, local, user, date)\n            self.tags = self._get_tags()\n        except Abort, e:\n            raise RepositoryError(e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a git like diff string for the given revision.", "response": "def get_diff(self, rev1, rev2, path='', ignore_whitespace=False,\n                  context=3):\n        \"\"\"\n        Returns (git like) *diff*, as plain text. Shows changes introduced by\n        ``rev2`` since ``rev1``.\n\n        :param rev1: Entry point from which diff is shown. Can be\n          ``self.EMPTY_CHANGESET`` - in this case, patch showing all\n          the changes since empty state of the repository until ``rev2``\n        :param rev2: Until which revision changes should be shown.\n        :param ignore_whitespace: If set to ``True``, would not show whitespace\n          changes. Defaults to ``False``.\n        :param context: How many lines before/after changed lines should be\n          shown. Defaults to ``3``.\n        \"\"\"\n        if hasattr(rev1, 'raw_id'):\n            rev1 = getattr(rev1, 'raw_id')\n\n        if hasattr(rev2, 'raw_id'):\n            rev2 = getattr(rev2, 'raw_id')\n\n        # Check if given revisions are present at repository (may raise\n        # ChangesetDoesNotExistError)\n        if rev1 != self.EMPTY_CHANGESET:\n            self.get_changeset(rev1)\n        self.get_changeset(rev2)\n        if path:\n            file_filter = match(self.path, '', [path])\n        else:\n            file_filter = None\n\n        return ''.join(patch.diff(self._repo, rev1, rev2, match=file_filter,\n                          opts=diffopts(git=True,\n                                        ignorews=ignore_whitespace,\n                                        context=context)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning will check for mercurial repository in given path and return a localrepo object. If there is no repository in that path it will raise an exception unless ``create`` parameter is set to True - in that case repository would be created and returned. If ``src_url`` is given, would try to clone repository from the location at given clone_point. Additionally it'll make update to working copy accordingly to ``update_after_clone`` flag", "response": "def _get_repo(self, create, src_url=None, update_after_clone=False):\n        \"\"\"\n        Function will check for mercurial repository in given path and return\n        a localrepo object. If there is no repository in that path it will\n        raise an exception unless ``create`` parameter is set to True - in\n        that case repository would be created and returned.\n        If ``src_url`` is given, would try to clone repository from the\n        location at given clone_point. Additionally it'll make update to\n        working copy accordingly to ``update_after_clone`` flag\n        \"\"\"\n\n        try:\n            if src_url:\n                url = str(self._get_url(src_url))\n                opts = {}\n                if not update_after_clone:\n                    opts.update({'noupdate': True})\n                try:\n                    MercurialRepository._check_url(url)\n                    clone(self.baseui, url, self.path, **opts)\n#                except urllib2.URLError:\n#                    raise Abort(\"Got HTTP 404 error\")\n                except Exception:\n                    raise\n\n                # Don't try to create if we've already cloned repo\n                create = False\n            return localrepository(self.baseui, self.path, create=create)\n        except (Abort, RepoError), err:\n            if create:\n                msg = \"Cannot create repository at %s. Original error was %s\"\\\n                    % (self.path, err)\n            else:\n                msg = \"Not valid repository at %s. Original error was %s\"\\\n                    % (self.path, err)\n            raise RepositoryError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting s an ID revision given as str. This will always return a fill 40 char revision number", "response": "def _get_revision(self, revision):\n        \"\"\"\n        Get's an ID revision given as str. This will always return a fill\n        40 char revision number\n\n        :param revision: str or int or None\n        \"\"\"\n\n        if self._empty:\n            raise EmptyRepositoryError(\"There are no changesets yet\")\n\n        if revision in [-1, 'tip', None]:\n            revision = 'tip'\n\n        try:\n            revision = hex(self._repo.lookup(revision))\n        except (IndexError, ValueError, RepoLookupError, TypeError):\n            raise ChangesetDoesNotExistError(\"Revision %s does not \"\n                                    \"exist for this repository\"\n                                    % (revision))\n        return revision"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn normalized url. If schema is not given, would fall to filesystem (``file:///``) schema.", "response": "def _get_url(self, url):\n        \"\"\"\n        Returns normalized url. If schema is not given, would fall\n        to filesystem\n        (``file:///``) schema.\n        \"\"\"\n        url = str(url)\n        if url != 'default' and not '://' in url:\n            url = \"file:\" + urllib.pathname2url(url)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_changeset(self, revision=None):\n        revision = self._get_revision(revision)\n        changeset = MercurialChangeset(repository=self, revision=revision)\n        return changeset", "response": "Returns a MercurialChangeset object representing the revision at the given revision."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator of MercurialChangeset objects from start to end.", "response": "def get_changesets(self, start=None, end=None, start_date=None,\n                       end_date=None, branch_name=None, reverse=False):\n        \"\"\"\n        Returns iterator of ``MercurialChangeset`` objects from start to end\n        (both are inclusive)\n\n        :param start: None, str, int or mercurial lookup format\n        :param end:  None, str, int or mercurial lookup format\n        :param start_date:\n        :param end_date:\n        :param branch_name:\n        :param reversed: return changesets in reversed order\n        \"\"\"\n\n        start_raw_id = self._get_revision(start)\n        start_pos = self.revisions.index(start_raw_id) if start else None\n        end_raw_id = self._get_revision(end)\n        end_pos = self.revisions.index(end_raw_id) if end else None\n\n        if None not in [start, end] and start_pos > end_pos:\n            raise RepositoryError(\"Start revision '%s' cannot be \"\n                                  \"after end revision '%s'\" % (start, end))\n\n        if branch_name and branch_name not in self.allbranches.keys():\n            raise BranchDoesNotExistError('Branch %s not found in'\n                                  ' this repository' % branch_name)\n        if end_pos is not None:\n            end_pos += 1\n        #filter branches\n        filter_ = []\n        if branch_name:\n            filter_.append('branch(\"%s\")' % (branch_name))\n\n        if start_date:\n            filter_.append('date(\">%s\")' % start_date)\n        if end_date:\n            filter_.append('date(\"<%s\")' % end_date)\n        if filter_:\n            revisions = scmutil.revrange(self._repo, [\" and \".join(filter_)])\n        else:\n            revisions = self.revisions\n\n        revs = revisions[start_pos:end_pos]\n        if reverse:\n            revs = reversed(revs)\n\n        return CollectionGenerator(self, revs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pull(self, url):\n        url = self._get_url(url)\n        try:\n            pull(self.baseui, self._repo, url)\n        except Abort, err:\n            # Propagate error but with vcs's type\n            raise RepositoryError(str(err))", "response": "Pulls changes from external location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the value of a given section and name from a given config file.", "response": "def get_config_value(self, section, name=None, config_file=None):\n        \"\"\"\n        Returns configuration value for a given [``section``] and ``name``.\n\n        :param section: Section we want to retrieve value from\n        :param name: Name of configuration we want to retrieve\n        :param config_file: A path to file which should be used to retrieve\n          configuration from (might also be a list of file paths)\n        \"\"\"\n        if config_file is None:\n            config_file = []\n        elif isinstance(config_file, basestring):\n            config_file = [config_file]\n\n        config = self._repo.ui\n        for path in config_file:\n            config.readconfig(path)\n        return config.config(section, name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data(self, data, part=False, dataset=''):\n        return super().data(data, part)", "response": "Parse the data into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat generated text. Text parts.", "response": "def format(self, parts):\n        \"\"\"Format generated text.\n\n        Parameters\n        ----------\n        parts : `iterable` of `str`\n            Text parts.\n        \"\"\"\n        text = self.storage.state_separator.join(parts)\n        return self.formatter(text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_cont_state(self, string, backward=False):\n        if string is None:\n            return ()\n        for _ in self.parser(self.scanner(string, True), True):\n            if backward and len(self.parser.state[0]):\n                break\n        state = tuple(self.parser.state)\n        self.scanner.reset()\n        self.parser.reset()\n        return state", "response": "Get initial states from input string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget initial states from input string.", "response": "def get_reply_states(self, string, dataset):\n        \"\"\"Get initial states from input string.\n\n        Parameters\n        ----------\n        string : `str`\n            Input string.\n        dataset : `str`\n            Dataset key.\n\n        Returns\n        -------\n        `list` of `list` of `str`\n        \"\"\"\n        words = get_words(string)\n        if not words:\n            return []\n        long_word = 4\n        long_words = [word for word in words if len(word) >= long_word]\n        short_words = [word for word in words if len(word) < long_word]\n        for words in (long_words, short_words):\n            ret = [\n                states\n                for states in (\n                    self.storage.get_states(dataset, word)\n                    for word in words\n                )\n                if states\n            ]\n            if ret:\n                return ret\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating texts from start and end of a sequence of tokens.", "response": "def generate_cont(self, max_length, state_size,\n                      reply_to, backward, dataset):\n        \"\"\"Generate texts from start/end.\n\n        Parameters\n        ----------\n        max_length : `int` or `None`\n            Maximum sentence length.\n        state_size : `int`\n            State size.\n        reply_to : `str` or `None`\n            Input string.\n        backward : `bool`\n            `True` to generate text start.\n        dataset: `str`\n            Dataset key prefix.\n\n        Returns\n        -------\n        `generator` of `str`\n            Generated texts.\n        \"\"\"\n        state = self.get_cont_state(reply_to, backward)\n        while True:\n            parts = self.generate(state_size, state, dataset, backward)\n            if reply_to is not None:\n                if backward:\n                    parts = chain(reversed(list(parts)), (reply_to,))\n                else:\n                    parts = chain((reply_to,), parts)\n            parts = islice(parts, 0, max_length)\n            yield self.format(parts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_replies(self, max_length, state_size, reply_to, dataset):\n        state_sets = self.get_reply_states(\n            reply_to,\n            dataset + state_size_dataset(state_size)\n        )\n\n        if not state_sets:\n            yield from self.generate_cont(max_length, state_size,\n                                          None, False, dataset)\n            return\n\n        random.shuffle(state_sets)\n\n        generate = lambda state, backward: self.generate(\n            state_size, state,\n            dataset, backward\n        )\n\n        for states in cycle(state_sets):\n            state = random.choice(states)\n            parts = chain(\n                reversed(list(generate(state, True))),\n                (state,),\n                generate(state, False)\n            )\n            parts = islice(parts, 0, max_length)\n            yield self.format(parts)", "response": "Generate replies.\n\n        Parameters\n        ----------\n        max_length : `int` or `None`\n            Maximum sentence length.\n        state_size : `int`\n            State size.\n        reply_to : `str`\n            Input string.\n        dataset: `str`\n            Dataset key prefix.\n\n        Returns\n        -------\n        `generator` of `str`\n            Generated texts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef size(self):\n\n        size = 0\n        try:\n            tip = self.get_changeset()\n            for topnode, dirs, files in tip.walk('/'):\n                for f in files:\n                    size += tip.get_file_size(f.path)\n                for dir in dirs:\n                    for f in files:\n                        size += tip.get_file_size(f.path)\n\n        except RepositoryError:\n            pass\n        return size", "response": "Returns the size of all files in the repository"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_changesets(self, start=None, end=None, start_date=None,\n                       end_date=None, branch_name=None, reverse=False):\n        \"\"\"\n        Returns iterator of ``MercurialChangeset`` objects from start to end\n        not inclusive This should behave just like a list, ie. end is not\n        inclusive\n\n        :param start: None or str\n        :param end: None or str\n        :param start_date:\n        :param end_date:\n        :param branch_name:\n        :param reversed:\n        \"\"\"\n        raise NotImplementedError", "response": "Returns an iterator over all changeset objects in the specified date range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an iterable of the available entry class names in a chunked archive.", "response": "def get_chunked_archive(self, **kwargs):\n        \"\"\"\n        Returns iterable archive. Tiny wrapper around ``fill_archive`` method.\n\n        :param chunk_size: extra parameter which controls size of returned\n            chunks. Default:8k.\n        \"\"\"\n\n        chunk_size = kwargs.pop('chunk_size', 8192)\n        stream = kwargs.get('stream')\n        self.fill_archive(**kwargs)\n        while True:\n            data = stream.read(chunk_size)\n            if not data:\n                break\n            yield data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef walk(self, topurl=''):\n        topnode = self.get_node(topurl)\n        yield (topnode, topnode.dirs, topnode.files)\n        for dirnode in topnode.dirs:\n            for tup in self.walk(dirnode.path):\n                yield tup", "response": "A generator function that returns tuples of tuples containing the topnode directories and files and changeset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_filenodes_generator(self):\n        for topnode, dirs, files in self.walk():\n            for node in files:\n                yield node", "response": "Returns generator that yields all file nodes in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary with changeset s attributes and their values.", "response": "def as_dict(self):\n        \"\"\"\n        Returns dictionary with changeset's attributes and their values.\n        \"\"\"\n        data = get_dict_for_attrs(self, ['id', 'raw_id', 'short_id',\n            'revision', 'date', 'message'])\n        data['author'] = {'name': self.author_name, 'email': self.author_email}\n        data['added'] = [node.path for node in self.added]\n        data['changed'] = [node.path for node in self.changed]\n        data['removed'] = [node.path for node in self.removed]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd given file nodes to the list of added file nodes.", "response": "def add(self, *filenodes):\n        \"\"\"\n        Marks given ``FileNode`` objects as *to be committed*.\n\n        :raises ``NodeAlreadyExistsError``: if node with same path exists at\n          latest changeset\n        :raises ``NodeAlreadyAddedError``: if node with same path is already\n          marked as *added*\n        \"\"\"\n        # Check if not already marked as *added* first\n        for node in filenodes:\n            if node.path in (n.path for n in self.added):\n                raise NodeAlreadyAddedError(\"Such FileNode %s is already \"\n                    \"marked for addition\" % node.path)\n        for node in filenodes:\n            self.added.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change(self, *filenodes):\n        for node in filenodes:\n            if node.path in (n.path for n in self.removed):\n                raise NodeAlreadyRemovedError(\"Node at %s is already marked \"\n                    \"as removed\" % node.path)\n        try:\n            self.repository.get_changeset()\n        except EmptyRepositoryError:\n            raise EmptyRepositoryError(\"Nothing to change - try to *add* new \"\n                \"nodes rather than changing them\")\n        for node in filenodes:\n            if node.path in (n.path for n in self.changed):\n                raise NodeAlreadyChangedError(\"Node at '%s' is already \"\n                    \"marked as changed\" % node.path)\n            self.changed.append(node)", "response": "Mark given file nodes as changed in next commit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, *filenodes):\n        for node in filenodes:\n            if node.path in (n.path for n in self.removed):\n                raise NodeAlreadyRemovedError(\"Node is already marked to \"\n                    \"for removal at %s\" % node.path)\n            if node.path in (n.path for n in self.changed):\n                raise NodeAlreadyChangedError(\"Node is already marked to \"\n                    \"be changed at %s\" % node.path)\n            # We only mark node as *removed* - real removal is done by\n            # commit method\n            self.removed.append(node)", "response": "Removes given file nodes from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the internal state of the object to its initial state.", "response": "def reset(self):\n        \"\"\"\n        Resets this instance to initial state (cleans ``added``, ``changed``\n        and ``removed`` lists).\n        \"\"\"\n        self.added = []\n        self.changed = []\n        self.removed = []\n        self.parents = []"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns generator of paths from nodes marked as added changed or removed.", "response": "def get_ipaths(self):\n        \"\"\"\n        Returns generator of paths from nodes marked as added, changed or\n        removed.\n        \"\"\"\n        for node in itertools.chain(self.added, self.changed, self.removed):\n            yield node.path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking in - memory changeset s integrity.", "response": "def check_integrity(self, parents=None):\n        \"\"\"\n        Checks in-memory changeset's integrity. Also, sets parents if not\n        already set.\n\n        :raises CommitError: if any error occurs (i.e.\n          ``NodeDoesNotExistError``).\n        \"\"\"\n        if not self.parents:\n            parents = parents or []\n            if len(parents) == 0:\n                try:\n                    parents = [self.repository.get_changeset(), None]\n                except EmptyRepositoryError:\n                    parents = [None, None]\n            elif len(parents) == 1:\n                parents += [None]\n            self.parents = parents\n\n        # Local parents, only if not None\n        parents = [p for p in self.parents if p]\n\n        # Check nodes marked as added\n        for p in parents:\n            for node in self.added:\n                try:\n                    p.get_node(node.path)\n                except NodeDoesNotExistError:\n                    pass\n                else:\n                    raise NodeAlreadyExistsError(\"Node at %s already exists \"\n                        \"at %s\" % (node.path, p))\n\n        # Check nodes marked as changed\n        missing = set(self.changed)\n        not_changed = set(self.changed)\n        if self.changed and not parents:\n            raise NodeDoesNotExistError(str(self.changed[0].path))\n        for p in parents:\n            for node in self.changed:\n                try:\n                    old = p.get_node(node.path)\n                    missing.remove(node)\n                    if old.content != node.content:\n                        not_changed.remove(node)\n                except NodeDoesNotExistError:\n                    pass\n        if self.changed and missing:\n            raise NodeDoesNotExistError(\"Node at %s is missing \"\n                \"(parents: %s)\" % (node.path, parents))\n\n        if self.changed and not_changed:\n            raise NodeNotChangedError(\"Node at %s wasn't actually changed \"\n                \"since parents' changesets: %s\" % (not_changed.pop().path,\n                    parents)\n            )\n\n        # Check nodes marked as removed\n        if self.removed and not parents:\n            raise NodeDoesNotExistError(\"Cannot remove node at %s as there \"\n                \"were no parents specified\" % self.removed[0].path)\n        really_removed = set()\n        for p in parents:\n            for node in self.removed:\n                try:\n                    p.get_node(node.path)\n                    really_removed.add(node)\n                except ChangesetError:\n                    pass\n        not_removed = set(self.removed) - really_removed\n        if not_removed:\n            raise NodeDoesNotExistError(\"Cannot remove node at %s from \"\n                \"following parents: %s\" % (not_removed[0], parents))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parents(self):\n        return [self.repository.get_changeset(parent)\n                for parent in self._commit.parents]", "response": "Returns a list of parents changesets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef children(self):\n        rev_filter = settings.GIT_REV_FILTER\n        cmd = \"rev-list %s --children | grep '^%s'\" % (rev_filter, self.raw_id)\n        so, se = self.repository.run_git_command(cmd)\n\n        children = []\n        for l in so.splitlines():\n            childs = l.split(' ')[1:]\n            children.extend(childs)\n        return [self.repository.get_changeset(cs) for cs in children]", "response": "Returns list of children changesets."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the content of the file at given path.", "response": "def get_file_content(self, path):\n        \"\"\"\n        Returns content of the file at given ``path``.\n        \"\"\"\n        id = self._get_id_for_path(path)\n        blob = self.repository._repo[id]\n        return blob.as_pretty_string()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the size of the file at given path.", "response": "def get_file_size(self, path):\n        \"\"\"\n        Returns size of the file at given ``path``.\n        \"\"\"\n        id = self._get_id_for_path(path)\n        blob = self.repository._repo[id]\n        return blob.raw_length()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of Changesets for a given file at given path.", "response": "def get_file_history(self, path, limit=None):\n        \"\"\"\n        Returns history of file as reversed list of ``Changeset`` objects for\n        which file at given ``path`` has been modified.\n\n        TODO: This function now uses os underlying 'git' and 'grep' commands\n        which is generally not good. Should be replaced with algorithm\n        iterating commits.\n        \"\"\"\n        self._get_filectx(path)\n        cs_id = safe_str(self.id)\n        f_path = safe_str(path)\n\n        if limit:\n            cmd = 'log -n %s --pretty=\"format: %%H\" -s -p %s -- \"%s\"' % (\n                      safe_int(limit, 0), cs_id, f_path\n                   )\n\n        else:\n            cmd = 'log --pretty=\"format: %%H\" -s -p %s -- \"%s\"' % (\n                      cs_id, f_path\n                   )\n        so, se = self.repository.run_git_command(cmd)\n        ids = re.findall(r'[0-9a-fA-F]{40}', so)\n        return [self.repository.get_changeset(id) for id in ids]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn history of file at given path as reversed list of Changeset objects for which file at given path has been modified.", "response": "def get_file_history_2(self, path):\n        \"\"\"\n        Returns history of file as reversed list of ``Changeset`` objects for\n        which file at given ``path`` has been modified.\n\n        \"\"\"\n        self._get_filectx(path)\n        from dulwich.walk import Walker\n        include = [self.id]\n        walker = Walker(self.repository._repo.object_store, include,\n                        paths=[path], max_entries=1)\n        return [self.repository.get_changeset(sha)\n                for sha in (x.commit.id for x in walker)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_file_annotate(self, path):\n        cmd = 'blame -l --root -r %s -- \"%s\"' % (self.id, path)\n        # -l     ==> outputs long shas (and we need all 40 characters)\n        # --root ==> doesn't put '^' character for bounderies\n        # -r sha ==> blames for the given revision\n        so, se = self.repository.run_git_command(cmd)\n\n        for i, blame_line in enumerate(so.split('\\n')[:-1]):\n            ln_no = i + 1\n            sha, line = re.split(r' ', blame_line, 1)\n            yield (ln_no, sha, lambda: self.repository.get_changeset(sha), line)", "response": "Returns a generator of four element tuples with with\n            lineno sha changeset lazy loader and line\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfill up the archive with the changeset s raw_id.", "response": "def fill_archive(self, stream=None, kind='tgz', prefix=None,\n                     subrepos=False):\n        \"\"\"\n        Fills up given stream.\n\n        :param stream: file like object.\n        :param kind: one of following: ``zip``, ``tgz`` or ``tbz2``.\n            Default: ``tgz``.\n        :param prefix: name of root directory in archive.\n            Default is repository name and changeset's raw_id joined with dash\n            (``repo-tip.<KIND>``).\n        :param subrepos: include subrepos in this archive.\n\n        :raise ImproperArchiveTypeError: If given kind is wrong.\n        :raise VcsError: If given stream is None\n\n        \"\"\"\n        allowed_kinds = settings.ARCHIVE_SPECS.keys()\n        if kind not in allowed_kinds:\n            raise ImproperArchiveTypeError('Archive kind not supported use one'\n                'of %s', allowed_kinds)\n\n        if prefix is None:\n            prefix = '%s-%s' % (self.repository.name, self.short_id)\n        elif prefix.startswith('/'):\n            raise VCSError(\"Prefix cannot start with leading slash\")\n        elif prefix.strip() == '':\n            raise VCSError(\"Prefix cannot be empty\")\n\n        if kind == 'zip':\n            frmt = 'zip'\n        else:\n            frmt = 'tar'\n        _git_path = settings.GIT_EXECUTABLE_PATH\n        cmd = '%s archive --format=%s --prefix=%s/ %s' % (_git_path,\n                                                frmt, prefix, self.raw_id)\n        if kind == 'tgz':\n            cmd += ' | gzip -9'\n        elif kind == 'tbz2':\n            cmd += ' | bzip2 -9'\n\n        if stream is None:\n            raise VCSError('You need to pass in a valid stream for filling'\n                           ' with archival data')\n        popen = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True,\n            cwd=self.repository.path)\n\n        buffer_size = 1024 * 8\n        chunk = popen.stdout.read(buffer_size)\n        while chunk:\n            stream.write(chunk)\n            chunk = popen.stdout.read(buffer_size)\n        # Make sure all descriptors would be read\n        popen.communicate()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef affected_files(self):\n        added, modified, deleted = self._changes_cache\n        return list(added.union(modified).union(deleted))", "response": "Get a fast accessible file changes for given changeset\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_paths_for_status(self, status):\n        added, modified, deleted = self._changes_cache\n        return sorted({\n            'added': list(added),\n            'modified': list(modified),\n            'deleted': list(deleted)}[status]\n        )", "response": "Returns sorted list of paths for given status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning list of added FileNode objects.", "response": "def added(self):\n        \"\"\"\n        Returns list of added ``FileNode`` objects.\n        \"\"\"\n        if not self.parents:\n            return list(self._get_file_nodes())\n        return AddedFileNodesGenerator([n for n in\n                                self._get_paths_for_status('added')], self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator that returns all the changed files in this node.", "response": "def changed(self):\n        \"\"\"\n        Returns list of modified ``FileNode`` objects.\n        \"\"\"\n        if not self.parents:\n            return []\n        return ChangedFileNodesGenerator([n for n in\n                                self._get_paths_for_status('modified')], self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef removed(self):\n        if not self.parents:\n            return []\n        return RemovedFileNodesGenerator([n for n in\n                                self._get_paths_for_status('deleted')], self)", "response": "Returns list of removed FileNode objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sgd(fun, x0, data, args=(), bounds=None, batch_size=10, maxiter=5000,\n        updater=None, eval_obj=False, random_state=None):\n    \"\"\"\n    Stochastic Gradient Descent.\n\n    Parameters\n    ----------\n    fun : callable\n        the function to *minimize*, this must have the signature ``[obj,]``\n        grad = fun(x, data, ...)`, where the ``eval_obj`` argument tells\n        ``sgd`` if an objective function value is going to be returned by\n        ``fun``.\n    x0 : ndarray\n        a sequence/1D array of initial values for the parameters to learn.\n    data : ndarray\n        a numpy array or sequence of data to input into ``fun``. This will\n        be split along the first axis (axis=0), and then input into\n        ``fun``.\n    args : sequence, optional\n        an optional sequence of arguments to give to fun.\n    bounds : sequence, optional\n        Bounds for variables, (min, max) pairs for each element in x, defining\n        the bounds on that parameter.  Use None for one of min or max when\n        there is no bound in that direction.\n    batch_size : int, optional\n        The number of observations in an SGD batch.\n    maxiter : int, optional\n        Number of mini-batch iterations before optimization terminates.\n    updater : SGDUpdater, optional\n        The type of gradient update to use, by default this is Adam.\n    eval_obj : bool, optional\n        This indicates whether or not ``fun`` also evaluates and returns\n        the objective function value. If this is true, ``fun`` must return\n        ``(obj, grad)`` and then a list of objective function values is\n        also returned.\n    random_state : int or RandomState, optional\n        random seed\n\n    Returns\n    -------\n    res : OptimizeResult\n        x : narray\n            the final result\n        norms : list\n            the list of gradient norms\n        message : str\n            the convergence condition ('maxiter reached' or error)\n        objs : list\n            the list of objective function evaluations if ``eval_obj``\n            is True.\n        fun : float\n            the final objective function evaluation if ``eval_obj`` is\n            True.\n    \"\"\"\n    if updater is None:\n        updater = Adam()\n\n    # Make sure we aren't using a recycled updater\n    updater.reset()\n\n    N = _len_data(data)\n    x = np.array(x0, copy=True, dtype=float)\n    D = x.shape[0]\n\n    # Make sure we have a valid batch size\n    batch_size = min(batch_size, N)\n\n    # Process bounds\n    if bounds is not None:\n        if len(bounds) != D:\n            raise ValueError(\"The dimension of the bounds does not match x0!\")\n\n        lower, upper = zip(*map(normalize_bound, bounds))\n        lower = np.array(lower)\n        upper = np.array(upper)\n\n    # Learning Records\n    obj = None\n    objs = []\n    norms = []\n\n    for batch in gen_batch(data, batch_size, maxiter, random_state):\n\n        if not eval_obj:\n            grad = fun(x, *chain(batch, args))\n        else:\n            obj, grad = fun(x, *chain(batch, args))\n            objs.append(obj)\n\n        norms.append(np.linalg.norm(grad))\n\n        # Truncate gradients if bounded\n        if bounds is not None:\n            xlower = x <= lower\n            grad[xlower] = np.minimum(grad[xlower], 0)\n            xupper = x >= upper\n            grad[xupper] = np.maximum(grad[xupper], 0)\n\n        # perform update\n        x = updater(x, grad)\n\n        # Trucate steps if bounded\n        if bounds is not None:\n            x = np.clip(x, lower, upper)\n\n    # Format results\n    res = OptimizeResult(\n        x=x,\n        norms=norms,\n        message='maxiter reached',\n        fun=obj,\n        objs=objs\n    )\n\n    return res", "response": "This function returns the SGD objective function value for a set of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates random batches for Stochastic gradients.", "response": "def gen_batch(data, batch_size, maxiter=np.inf, random_state=None):\n    \"\"\"\n    Create random batches for Stochastic gradients.\n\n    Batch index generator for SGD that will yeild random batches for a\n    a defined number of iterations, which can be infinite. This generator makes\n    consecutive passes through the data, drawing without replacement on each\n    pass.\n\n    Parameters\n    ----------\n    data : ndarray or sequence of ndarrays\n        The data, can be a matrix X, (X,y) tuples etc\n    batch_size : int\n        number of data points in each batch.\n    maxiter : int, optional\n        The number of iterations\n    random_state : int or RandomState, optional\n        random seed\n\n    Yields\n    ------\n    ndarray or sequence :\n        with each array length ``batch_size``, i.e. a subset of data.\n    \"\"\"\n    perms = endless_permutations(_len_data(data), random_state)\n\n    it = 0\n    while it < maxiter:\n        it += 1\n        ind = np.array([next(perms) for _ in range(batch_size)])\n        yield _split_data(data, ind)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self):\n        self.__init__(self.alpha, self.beta1, self.beta2, self.epsilon)", "response": "Reset the state of this updater for a new optimisation problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef aslist(obj, sep=None, strip=True):\n    if isinstance(obj, (basestring)):\n        lst = obj.split(sep)\n        if strip:\n            lst = [v.strip() for v in lst]\n        return lst\n    elif isinstance(obj, (list, tuple)):\n        return obj\n    elif obj is None:\n        return []\n    else:\n        return [obj]", "response": "Returns given string separated by sep as list\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_int(val, default=None):\n\n    try:\n        val = int(val)\n    except (ValueError, TypeError):\n        val = default\n\n    return val", "response": "Returns val if val is not convertable to int use default\n    instead"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsafing unicode function. Does few trick to turn str_ into unicode In case of UnicodeDecode error we try to return it with encoding detected by chardet library if it fails fallback to unicode with errors replaced :param str_: string to decode :rtype: unicode :returns: unicode object", "response": "def safe_unicode(str_, from_encoding=None):\n    \"\"\"\n    safe unicode function. Does few trick to turn str_ into unicode\n\n    In case of UnicodeDecode error we try to return it with encoding detected\n    by chardet library if it fails fallback to unicode with errors replaced\n\n    :param str_: string to decode\n    :rtype: unicode\n    :returns: unicode object\n    \"\"\"\n    if isinstance(str_, unicode):\n        return str_\n\n    if not from_encoding:\n        from vcs.conf import settings\n        from_encoding = settings.DEFAULT_ENCODINGS\n\n    if not isinstance(from_encoding, (list, tuple)):\n        from_encoding = [from_encoding]\n\n    try:\n        return unicode(str_)\n    except UnicodeDecodeError:\n        pass\n\n    for enc in from_encoding:\n        try:\n            return unicode(str_, enc)\n        except UnicodeDecodeError:\n            pass\n\n    try:\n        import chardet\n        encoding = chardet.detect(str_)['encoding']\n        if encoding is None:\n            raise Exception()\n        return str_.decode(encoding)\n    except (ImportError, UnicodeDecodeError, Exception):\n        return unicode(str_, from_encoding[0], 'replace')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef safe_str(unicode_, to_encoding=None):\n\n    # if it's not basestr cast to str\n    if not isinstance(unicode_, basestring):\n        return str(unicode_)\n\n    if isinstance(unicode_, str):\n        return unicode_\n\n    if not to_encoding:\n        from vcs.conf import settings\n        to_encoding = settings.DEFAULT_ENCODINGS\n\n    if not isinstance(to_encoding, (list, tuple)):\n        to_encoding = [to_encoding]\n\n    for enc in to_encoding:\n        try:\n            return unicode_.encode(enc)\n        except UnicodeEncodeError:\n            pass\n\n    try:\n        import chardet\n        encoding = chardet.detect(unicode_)['encoding']\n        if encoding is None:\n            raise UnicodeEncodeError()\n\n        return unicode_.encode(encoding)\n    except (ImportError, UnicodeEncodeError):\n        return unicode_.encode(to_encoding[0], 'replace')\n\n    return safe_str", "response": "safe str function. Does few trick to turn unicode_ into string\n\n    In case of UnicodeEncodeError we try to return it with encoding detected\n    by chardet library if it fails fallback to string with errors replaced\n\n    :param unicode_: unicode to encode\n    :rtype: str\n    :returns: str object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the email address of given author", "response": "def author_email(author):\n    \"\"\"\n    returns email address of given author.\n    If any of <,> sign are found, it fallbacks to regex findall()\n    and returns first found result or empty string\n\n    Regex taken from http://www.regular-expressions.info/email.html\n    \"\"\"\n    import re\n    r = author.find('>')\n    l = author.find('<')\n\n    if l == -1 or r == -1:\n        # fallback to regex match of email out of a string\n        email_re = re.compile(r\"\"\"[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!\"\"\"\n                              r\"\"\"#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z\"\"\"\n                              r\"\"\"0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]\"\"\"\n                              r\"\"\"*[a-z0-9])?\"\"\", re.IGNORECASE)\n        m = re.findall(email_re, author)\n        return m[0] if m else ''\n\n    return author[l + 1:r].strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef author_name(author):\n\n    if not '@' in author:\n        return author\n    else:\n        return author.replace(author_email(author), '').replace('<', '')\\\n            .replace('>', '').strip()", "response": "get name of author"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit(self, X, y):\n        X, y = check_X_y(X, y)\n\n        self.obj_ = -np.inf\n\n        # Make list of parameters and decorate optimiser to undestand this\n        params = [self.var, self.basis.regularizer, self.basis.params]\n        nmin = structured_minimizer(logtrick_minimizer(minimize))\n\n        # Close over objective and learn parameters\n        elbo = partial(StandardLinearModel._elbo, self, X, y)\n        res = nmin(elbo,\n                   params,\n                   method='L-BFGS-B',\n                   jac=True,\n                   tol=self.tol,\n                   options={'maxiter': self.maxiter, 'maxcor': 100},\n                   random_state=self.random_,\n                   nstarts=self.nstarts\n                   )\n\n        # Upack learned parameters and report\n        self.var_, self.regularizer_, self.hypers_ = res.x\n\n        log.info(\"Done! ELBO = {}, var = {}, reg = {}, hypers = {}, \"\n                 \"message = {}.\"\n                 .format(-res['fun'],\n                         self.var_,\n                         self.regularizer_,\n                         self.hypers_,\n                         res.message)\n                 )\n\n        return self", "response": "Fits a Bayesian linear regressor to obtain the hyperparameters of a full posterior convariance matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_moments(self, X):\n        check_is_fitted(self, ['var_', 'regularizer_', 'weights_',\n                               'covariance_', 'hypers_'])\n        X = check_array(X)\n\n        Phi = self.basis.transform(X, *atleast_list(self.hypers_))\n        Ey = Phi.dot(self.weights_)\n        Vf = (Phi.dot(self.covariance_) * Phi).sum(axis=1)\n\n        return Ey, Vf + self.var_", "response": "Full predictive distribution from Bayesian linear regression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef linewrap(chunks, width=None, sep=' ', preamble='', line_prefix=''):\n    r'''Takes an iterator of strings, and attempts to wrap them in whole chunks\n    to fit within width. Takes an optional preamble which is prepended before\n    the first line, and an optional per-line prefix (which is appended to every\n    line but the first). If return_gen is true, this function returns a\n    generator that will produce the lines of output as needed, otherwise it\n    returns a single joined string'''\n    sep_len = len(sep)\n\n    if isinstance(chunks, basestring):\n        chunks = chunks.split()\n    if preamble:\n        chunks[0] = preamble + chunks[0]\n\n    def line_len(line):\n        r'Gets the full length of a line passed a list of strings'\n        word_len = sum(len(l) for l in line)\n        seps_len = sep_len * (len(line) - 1)\n        return word_len + seps_len if seps_len >= 0 else 0\n\n    def gen():\n        r'The generator to incrementally create lines from the input'\n        sep_len = len(sep)\n        line = []\n        for chunk in chunks:\n            if line_len(line) + len(chunk) + sep_len > width:\n                yield sep.join(line)\n                line = [line_prefix + chunk]\n            else:\n                line.append(chunk)\n        if line:\n            yield sep.join(line)\n\n    return gen()", "response": "r Returns a generator that yields the lines of input that are longer than width."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit_iana_rels(rels_url):\n    '''Fetches the IANA link relation registry'''\n    text = requests.get(rels_url).text.encode('ascii', 'ignore')\n    xml = objectify.fromstring(text)\n    iana_rels = {str(rec.value): str(rec.description)\n                 for rec in xml.registry.record}\n    keys = sorted(iana_rels)\n    print('# IANA link relation registry last updated on:', xml.updated)\n    print('# Obtained from', rels_url)\n    print()\n    print('iana_rels = {')\n    for key in keys:\n        print('    {0!r}: ('.format(key))\n        desc_list = list(linewrap(iana_rels[key], width=68))\n        for i, line in enumerate(desc_list):\n            line_ = line.replace('\"', '\\\\\"')  # escape double quotes\n            if i < len(desc_list) - 1:\n                print('        \"{0} \"'.format(line_))\n            else:\n                print('        \"{0}\"'.format(line_))\n        print('    ),')\n    print('}')", "response": "Fetches the IANA link relation registry and emits it as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of directories including intermediate.", "response": "def get_dirs_for_path(*paths):\n    \"\"\"\n    Returns list of directories, including intermediate.\n    \"\"\"\n    for path in paths:\n        head = path\n        while head:\n            head, tail = os.path.split(head)\n            if head:\n                yield head\n            else:\n                # We don't need to yield empty path\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all table names. Returns ------- `set` of `str`", "response": "def get_tables(self):\n        \"\"\"Get all table names.\n\n        Returns\n        -------\n        `set` of `str`\n        \"\"\"\n        self.cursor.execute(\n            'SELECT name FROM sqlite_master WHERE type=\"table\"'\n        )\n        return set(x[0] for x in self.cursor.fetchall())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a node ID by value.", "response": "def get_node(self, value):\n        \"\"\"Get node ID by value.\n\n        If a node with the specified value does not exist,\n        create it and return its ID.\n\n        Parameters\n        ----------\n        value : `str`\n            Node value.\n\n        Returns\n        -------\n        `int`\n            Node ID.\n        \"\"\"\n        while True:\n            self.cursor.execute(\n                'SELECT id FROM nodes WHERE value=?',\n                (value,)\n            )\n            node = self.cursor.fetchone()\n            if node is not None:\n                return node[0]\n            self.cursor.execute(\n                'INSERT INTO nodes (value) VALUES (?)',\n                (value,)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_main_table(self):\n        data = (json.dumps(self.settings),)\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS main (\n                settings TEXT NOT NULL DEFAULT \"{}\"\n            )\n        ''')\n        self.cursor.execute('SELECT * FROM main')\n        if self.cursor.fetchall() == []:\n            self.cursor.execute('INSERT INTO main (settings) VALUES (?)', data)\n        else:\n            self.cursor.execute('UPDATE main SET settings=?', data)", "response": "Write generator settings to database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating node and link tables if they don t exist.", "response": "def create_node_tables(self):\n        \"\"\"Create node and link tables if they don't exist.\n        \"\"\"\n        self.cursor.execute('PRAGMA foreign_keys=1')\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS datasets (\n                id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n                key TEXT NOT NULL\n            )\n        ''')\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS nodes (\n                id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n                value TEXT NOT NULL\n            )\n        ''')\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS links (\n                dataset REFERENCES datasets (id),\n                source REFERENCES nodes (id),\n                target REFERENCES nodes (id),\n                value TEXT,\n                bvalue TEXT,\n                count INTEGER NOT NULL DEFAULT 1\n            )\n        ''')\n        self.cursor.execute(\n            'CREATE UNIQUE INDEX IF NOT EXISTS node ON nodes (value)'\n        )\n        self.cursor.execute(\n            'CREATE INDEX IF NOT EXISTS link_source ON links (source, dataset)'\n        )\n        self.cursor.execute(\n            'CREATE INDEX IF NOT EXISTS link_target ON links (target, dataset)'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the current set of items in the main table.", "response": "def do_save(self, fp=None):\n        \"\"\"Save.\n\n        Parameters\n        ----------\n        fp : `None`, optional\n        \"\"\"\n        if fp is not None:\n            raise NotImplementedError()\n        self.update_main_table()\n        self.db.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning in - memory created module pointing at user s configuration and extra code / commands. By default tries to create module from VCSRC_PATH. By default tries to create module from settings. VCSRC_PATH.", "response": "def get_vcsrc(self):\n        \"\"\"\n        Returns in-memory created module pointing at user's configuration\n        and extra code/commands. By default tries to create module from\n        :setting:`VCSRC_PATH`.\n        \"\"\"\n        try:\n            vimrc = create_module('vcsrc', settings.VCSRC_PATH)\n        except IOError:\n            self.stderr.write(\"No module or package at %s\\n\"\n                % settings.VCSRC_PATH)\n            vimrc = None\n        return vimrc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the arguments that would be passed into the command.", "response": "def get_argv_for_command(self):\n        \"\"\"\n        Returns stripped arguments that would be passed into the command.\n        \"\"\"\n        argv = [a for a in self.argv]\n        argv.insert(0, self.prog_name)\n        return argv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute whole process of parsing and running command.", "response": "def execute(self):\n        \"\"\"\n        Executes whole process of parsing and running command.\n        \"\"\"\n        self.autocomplete()\n        if len(self.argv):\n            cmd = self.argv[0]\n            cmd_argv = self.get_argv_for_command()\n            self.run_command(cmd, cmd_argv)\n        else:\n            self.show_help()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the command class from the registry for a given command.", "response": "def get_command_class(self, cmd):\n        \"\"\"\n        Returns command class from the registry for a given ``cmd``.\n\n        :param cmd: command to run (key at the registry)\n        \"\"\"\n        try:\n            cmdpath = self.registry[cmd]\n        except KeyError:\n            raise CommandError(\"No such command %r\" % cmd)\n        if isinstance(cmdpath, basestring):\n            Command = import_class(cmdpath)\n        else:\n            Command = cmdpath\n        return Command"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_command(self, cmd, argv):\n        try:\n            Command = self.get_command_class(cmd)\n        except CommandError, e:\n            self.stderr.write(str(e) + '\\n')\n            self.show_help()\n            sys.exit(-1)\n        command = Command(stdout=self.stdout, stderr=self.stderr)\n        command.run_from_argv(argv)", "response": "Runs command.\n\n        :param cmd: command to run (key at the registry)\n        :param argv: arguments passed to the command"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint help text about available commands.", "response": "def show_help(self):\n        \"\"\"\n        Prints help text about available commands.\n        \"\"\"\n        output = [\n            'Usage %s subcommand [options] [args]' % self.prog_name,\n            '',\n            'Available commands:',\n            '',\n        ]\n        for cmd in self.get_commands():\n            output.append('  %s' % cmd)\n        output += ['', '']\n        self.stdout.write(u'\\n'.join(output))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef usage(self, subcommand):\n        usage = ' '.join(['%prog', subcommand, '[options]'])\n        if self.args:\n            usage = '%s %s' % (usage, str(self.args))\n        return usage", "response": "Returns the usage text for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a OptionParser object for given prog_name and subcommand.", "response": "def get_parser(self, prog_name, subcommand):\n        \"\"\"\n        Returns parser for given ``prog_name`` and ``subcommand``.\n\n        :param prog_name: vcs main script name\n        :param subcommand: command name\n        \"\"\"\n        parser = OptionParser(\n            prog=prog_name,\n            usage=self.usage(subcommand),\n            version=self.get_version(),\n            option_list=sorted(self.get_option_list()))\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_help(self, prog_name, subcommand):\n        parser = self.get_parser(prog_name, subcommand)\n        parser.print_help()", "response": "Prints parser s help."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns command for given arguments.", "response": "def run_from_argv(self, argv):\n        \"\"\"\n        Runs command for given arguments.\n\n        :param argv: arguments\n        \"\"\"\n        parser = self.get_parser(argv[0], argv[1])\n        options, args = parser.parse_args(argv[2:])\n        self.execute(*args, **options.__dict__)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, *args, **options):\n        try:\n            self.handle(*args, **options)\n        except CommandError, e:\n            if options['debug']:\n                try:\n                    import ipdb\n                    ipdb.set_trace()\n                except ImportError:\n                    import pdb\n                    pdb.set_trace()\n            sys.stderr.write(colorize('ERROR: ', fg='red'))\n            self.stderr.write('%s\\n' % e)\n            sys.exit(1)\n        except Exception, e:\n            if isinstance(e, IOError) and getattr(e, 'errno') == errno.EPIPE:\n                sys.exit(0)\n            if options['debug']:\n                try:\n                    import ipdb\n                    ipdb.set_trace()\n                except ImportError:\n                    import pdb\n                    pdb.set_trace()\n            if options.get('traceback'):\n                import traceback\n                self.stderr.write(u'\\n'.join((\n                    '=========',\n                    'TRACEBACK',\n                    '=========', '', '',\n                )))\n                traceback.print_exc(file=self.stderr)\n            sys.stderr.write(colorize('ERROR: ', fg='red'))\n            self.stderr.write('%s\\n' % e)\n            sys.exit(1)", "response": "Executes the command and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning pre_process and handle_repo methods in that order.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Runs ``pre_process``, ``handle_repo`` and ``post_process`` methods, in\n        that order.\n        \"\"\"\n        self.pre_process(self.repo)\n        self.handle_repo(self.repo, *args, **options)\n        self.post_process(self.repo, **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_changesets(self, repo, **options):\n        branch_name = None\n        if not options.get('all', None):\n            branch_name = options.get('branch') or repo.workdir.get_branch()\n        if options.get('start_date'):\n            options['start_date'] = parse_datetime(options['start_date'])\n        if options.get('end_date'):\n            options['end_date'] = parse_datetime(options['end_date'])\n        changesets = repo.get_changesets(\n            start=options.get('start'),\n            end=options.get('end', options.get('main')),\n            start_date=options.get('start_date'),\n            end_date=options.get('end_date'),\n            branch_name=branch_name,\n            reverse=not options.get('reversed', False),\n        )\n        try:\n            limit = int(options.get('limit'))\n        except (ValueError, TypeError):\n            limit = None\n\n        count = 0\n        for changeset in changesets:\n            if self.show_changeset(changeset, **options):\n                yield changeset\n                count += 1\n                if count == limit:\n                    break", "response": "Returns a generator of changeset objects from given repository instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a ColoredProgressBar instance for a given total number of clicks .", "response": "def get_progressbar(self, total, **options):\n        \"\"\"\n        Returns progress bar instance for a given ``total`` number of clicks\n        it should do.\n        \"\"\"\n        progressbar = ColoredProgressBar(total)\n        progressbar.steps_label = 'Commit'\n        progressbar.elements += ['eta', 'time']\n        return progressbar"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_changeset(self, **options):\n        cid = options.get('changeset_id', None)\n        return self.repo.get_changeset(cid)", "response": "Returns changeset for given options."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(cls, fname, args):\n\n    if args.type == JSON:\n        if fname.endswith('.bz2'):\n            open_ = bz2.open\n        else:\n            open_ = open\n\n        if args.progress:\n            print('Loading JSON data...')\n\n        with open_(fname, 'rt') as fp:\n            storage = JsonStorage.load(fp)\n    else:\n        storage = SqliteStorage.load(fname)\n\n    if args.settings is not None:\n        extend(storage.settings, args.settings)\n\n    return cls.from_storage(storage)", "response": "Load a generator from a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave a generator to a file.", "response": "def save(markov, fname, args):\n    \"\"\"Save a generator.\n\n    Parameters\n    ----------\n    markov : `markovchain.Markov`\n        Generator to save.\n    fname : `str`\n        Output file path.\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n    if isinstance(markov.storage, JsonStorage):\n        if fname is None:\n            markov.save(sys.stdout)\n        else:\n            if fname.endswith('.bz2'):\n                open_ = bz2.open\n            else:\n                open_ = open\n            if args.progress:\n                print('Saving JSON data...')\n            with open_(fname, 'wt') as fp:\n                markov.save(fp)\n    else:\n        markov.save()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_image(img, fname):\n    _, ext = os.path.splitext(fname)\n    ext = ext[1:] or 'png'\n    with open(fname, 'wb') as fp:\n        img.save(fp, ext)", "response": "Save an image to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting computed command arguments. Parameters ---------- args : `argparse.Namespace` Command arguments. base : `iterable` of `type` Generator mixins. Raises ------ ValueError If output file is stdout and progress bars are enabled.", "response": "def set_args(args):\n    \"\"\"Set computed command arguments.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    base : `iterable` of `type`\n        Generator mixins.\n\n    Raises\n    ------\n    ValueError\n        If output file is stdout and progress bars are enabled.\n    \"\"\"\n    try:\n        if args.output is sys.stdout and args.progress:\n            raise ValueError('args.output is stdout and args.progress')\n    except AttributeError:\n        pass\n\n    try:\n        fname = '.' + args.type\n    except AttributeError:\n        try:\n            fname = args.state\n        except AttributeError:\n            try:\n                fname = args.output\n            except AttributeError:\n                fname = '.json'\n\n    if fname is None or fname.endswith('.json') or fname.endswith('.json.bz2'):\n        args.type = JSON\n    else:\n        args.type = SQLITE\n\n    settings = {}\n    try:\n        if args.settings is not None:\n            settings = json.load(args.settings)\n            args.settings.close()\n    except AttributeError:\n        pass\n    args.settings = settings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_output_format(fmt, nfiles):\n    if nfiles < 0:\n        raise ValueError('Invalid file count: ' + str(nfiles))\n    if nfiles == 1:\n        return\n    try:\n        fmt % nfiles\n    except TypeError as err:\n        raise ValueError(''.join(\n            ('Invalid file format string: ', fmt, ': ', str(err))\n        ))", "response": "Validate the output format string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef infiles(fnames, progress, leave=True):\n    if progress:\n        if fnames:\n            fnames = tqdm(fnames, desc='Loading', unit='file',\n                          bar_format=BAR_FORMAT,\n                          leave=leave, dynamic_ncols=True)\n        else:\n            progress = False\n\n    yield fnames\n\n    if progress:\n        fnames.close()", "response": "Get input file paths."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating nfiles output files.", "response": "def outfiles(fmt, nfiles, progress, leave=True):\n    \"\"\"Get output file paths.\n\n    Parameters\n    ----------\n    fmt : `str`\n        File path format string.\n    nfiles : `int`\n        Number of files.\n    progress : `bool`\n        Show progress bars.\n    leave : `bool`, optional\n        Leave progress bar (default: True).\n\n    Raises\n    ------\n    ValueError\n        If nfiles <= 0.\n\n    Returns\n    -------\n    `generator` of `str`\n        Output file paths.\n    \"\"\"\n    if nfiles > 1:\n        fnames = (fmt % i for i in range(nfiles))\n    elif nfiles == 1:\n        fnames = (fmt,)\n    else:\n        raise ValueError('output file count <= 0')\n\n    if progress:\n        fnames = tqdm(fnames, total=nfiles,\n                      desc='Generating', unit='file',\n                      bar_format=BAR_FORMAT,\n                      leave=leave, dynamic_ncols=True)\n\n    yield fnames\n\n    if progress:\n        fnames.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints generator settings. Parameters ---------- args : `argparse.Namespace` Command arguments.", "response": "def cmd_settings(args):\n    \"\"\"Print generator settings.\n\n    Parameters\n    ----------\n    args : `argparse.Namespace`\n        Command arguments.\n    \"\"\"\n    if args.type == SQLITE:\n        storage = SqliteStorage\n    else:\n        storage = JsonStorage\n    storage = storage.load(args.state)\n    data = storage.settings\n    try:\n        del data['markov']['nodes']\n    except KeyError:\n        pass\n    pprint(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a missing progress bar warning if it was not printed.", "response": "def print_warning(cls):\n        \"\"\"Print a missing progress bar warning if it was not printed.\n        \"\"\"\n        if not cls.warning:\n            cls.warning = True\n            print('Can\\'t create progress bar:', str(TQDM_IMPORT_ERROR),\n                  file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data(self, data, part=False, dataset=''):\n        links = self.parser(self.scanner(data, part), part, dataset)\n        self.storage.add_links(links)", "response": "Parse data and update links."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a sequence of unique keys.", "response": "def generate(self, state_size=None, start=(), dataset='', backward=False):\n        \"\"\"Generate a sequence.\n\n        Parameters\n        ----------\n        state_size : `int`, optional\n            State size (default: parser.state_sizes[0]).\n        start : `str` or `iterable` of `str`, optional\n            Initial state (default: ()).\n        dataset : `str`, optional\n            Dataset key prefix.\n        backward : `bool`, optional\n            Link direction.\n\n        Returns\n        -------\n        `generator` of `str`\n            State generator.\n        \"\"\"\n        if state_size is None:\n            try:\n                state_size = next(iter(self.parser.state_sizes))\n            except StopIteration:\n                return\n        #elif (self.parser is not None\n        #      and state_size not in self.parser.state_sizes):\n        #    raise ValueError('invalid state size: {0}: not in {1}'\n        #                     .format(state_size, self.parser.state_sizes))\n        dataset += state_size_dataset(state_size)\n        return self.storage.generate(start, state_size, dataset, backward)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert generator settings to JSON.", "response": "def get_settings_json(self):\n        \"\"\"Convert generator settings to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        return {\n            'scanner': None if self.scanner is None else self.scanner.save(),\n            'parser': None if self.parser is None else self.parser.save()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave to file. Parameters ---------- fp : `file`, optional Output file.", "response": "def save(self, fp=None):\n        \"\"\"Save to file.\n\n        Parameters\n        ----------\n        fp : `file`, optional\n            Output file.\n        \"\"\"\n        self.storage.settings['markov'] = self.get_settings_json()\n        self.storage.save(fp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_storage(cls, storage):\n        args = dict(storage.settings.get('markov', {}))\n        args['storage'] = storage\n        return cls(**args)", "response": "Load from storage.\n\n        Parameters\n        ----------\n        storage : `markovchain.storage.Storage`\n\n        Returns\n        -------\n        `markovchain.Markov`"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_file(cls, fp, storage=None):\n        if storage is None:\n            storage = cls.DEFAULT_STORAGE\n        return cls.from_storage(storage.load(fp))", "response": "Load from file.\n\n        Parameters\n        ----------\n        fp : `str` or `file`\n            File or path.\n        storage : `type`, optional\n            Storage class (default: cls.DEFAULT_STORAGE)\n\n        Returns\n        -------\n        `markovchain.Markov`"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate from settings. Parameters ---------- settings : `dict`, optional Settings (default: None). storage : `type`, optional Storage class (default: cls.DEFAULT_STORAGE) Returns ------- `markovchain.Markov`", "response": "def from_settings(cls, settings=None, storage=None):\n        \"\"\"Create from settings.\n\n        Parameters\n        ----------\n        settings : `dict`, optional\n            Settings (default: None).\n        storage : `type`, optional\n            Storage class (default: cls.DEFAULT_STORAGE)\n\n        Returns\n        -------\n        `markovchain.Markov`\n        \"\"\"\n        if storage is None:\n            storage = cls.DEFAULT_STORAGE\n        return cls.from_storage(storage(settings=settings))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef input(self, img):\n        img_width, img_height = img.size\n\n        if self.resize:\n            width, height = self.resize\n            scale = min(width / img_width, height / img_height)\n            img = img.resize((floor(img_width * scale),\n                              floor(img_height * scale)))\n            img_width, img_height = img.size\n\n        if img_width < self.min_size or img_height < self.min_size:\n            raise ValueError('input image is too small: {0} x {1} < {2} x {2}'\n                             .format(img_width, img_height, self.min_size))\n\n        return img", "response": "Resizes input image if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget image level. Parameters ---------- img : `PIL.Image` Input image. level : `int` Level number. Returns ------- `PIL.Image` Converted image.", "response": "def level(self, img, level):\n        \"\"\"Get image level.\n\n        Parameters\n        ----------\n        img : `PIL.Image`\n            Input image.\n        level : `int`\n            Level number.\n\n        Returns\n        -------\n        `PIL.Image`\n            Converted image.\n        \"\"\"\n        if level < self.levels - 1:\n            width, height = img.size\n            scale = reduce(lambda x, y: x * y,\n                           islice(self.level_scale, level, self.levels))\n            img = img.resize((width // scale, height // scale), self.scale)\n        return img"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscans a level. Parameters ---------- level : `int` Level number. prev : `PIL.Image` or None Previous level image or None if level == 0. img : `PIL.Image` Current level image. Returns ------- `generator` of (`str` or `markovchain.scanner.Scanner.END` or (`markovchain.scanner.Scanner.START`, `str`)) Token generator.", "response": "def _scan_level(self, level, prev, img):\n        \"\"\"Scan a level.\n\n        Parameters\n        ----------\n        level : `int`\n            Level number.\n        prev : `PIL.Image` or None\n            Previous level image or None if level == 0.\n        img : `PIL.Image`\n            Current level image.\n\n        Returns\n        -------\n        `generator` of (`str` or `markovchain.scanner.Scanner.END` or (`markovchain.scanner.Scanner.START`, `str`))\n            Token generator.\n        \"\"\"\n        if level == 0:\n            width, height = img.size\n        else:\n            width, height = prev.size\n\n        tr = self.traversal[0](width, height, ends=(level == 0))\n        if level == 0:\n            for xy in tr:\n                if xy is None:\n                    yield self.END\n                else:\n                    yield pixel_to_state(img.getpixel(xy))\n            yield self.END\n        else:\n            scale = self.level_scale[level - 1]\n            for xy in tr:\n                x0 = xy[0] * scale\n                y0 = xy[1] * scale\n                start = (\n                    self.START,\n                    pixel_to_state(prev.getpixel(xy))\n                )\n                yield start\n                for dxy in self.traversal[level](scale, scale, True):\n                    if dxy is None:\n                        yield start\n                    yield pixel_to_state(\n                        img.getpixel((x0 + dxy[0], y0 + dxy[1]))\n                    )\n                yield self.END"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts to JSON. Returns ------- dict JSON data.", "response": "def save(self):\n        \"\"\"Convert to JSON.\n\n        Returns\n        -------\n        `dict`\n            JSON data.\n        \"\"\"\n        data = super().save()\n        data['resize'] = list(self.resize) if self.resize is not None else None\n        data['traversal'] = [t.save() for t in self.traversal]\n        data['levels'] = self.levels\n        data['level_scale'] = self.level_scale\n        data['scale'] = self.scale\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smse(y_true, y_pred):\n\n    N = y_true.shape[0]\n    return ((y_true - y_pred)**2).sum() / (N * y_true.var())", "response": "Standardised mean squared error."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mll(y_true, y_pred, y_var):\n\n    return - norm.logpdf(y_true, loc=y_pred, scale=np.sqrt(y_var)).mean()", "response": "Returns the mean negative log loss under a Gaussian distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the mean standardised log loss under a Gaussian distribution.", "response": "def msll(y_true, y_pred, y_var, y_train):\n    \"\"\"\n    Mean standardised log loss under a Gaussian distribution.\n\n    Parameters\n    ----------\n    y_true: ndarray\n        vector of true targets\n    y_pred: ndarray\n        vector of predicted targets\n    y_var: float or ndarray\n        predicted variances\n    y_train: ndarray\n        vector of *training* targets by which to standardise\n\n    Returns\n    -------\n    float:\n        The negative mean standardised log loss (negative log likelihood)\n\n    Example\n    -------\n    >>> y_true = np.random.randn(100)\n    >>> msll(y_true, y_true, 1, y_true) < 0  # Should be good predictor\n    True\n    >>> msll(y_true, np.random.randn(100), 1, y_true) >= 0  # naive predictor\n    True\n    \"\"\"\n\n    var = y_train.var()\n    mu = y_train.mean()\n\n    ll_naive = norm.logpdf(y_true, loc=mu, scale=np.sqrt(var))\n    ll_mod = norm.logpdf(y_true, loc=y_pred, scale=np.sqrt(y_var))\n\n    return - (ll_mod - ll_naive).mean()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_data_response(self):\n        if self.middleware_interrupt_exc:\n            ## the middleware raised an exception, re-raise it here so\n            ## get_concrete_response (defined in subclasses) can catch it.\n            raise self.middleware_interrupt_exc\n\n        if self.middleware_control:\n            ## this redirect object came from middleware but return it as if it\n            ## came from a view.\n            return {'body': self.middleware_control}\n\n        if self.model_mock and self.program.has_mock_defined():\n            model_data = self.program.get_model_mock()\n        else:\n            args, kwargs = self.program.get_model_args_kwargs()\n            data = self.get_data_for_model(args, kwargs)\n            self.display_data = data # just for displaying in __repr__\n\n            if self.program.cache and not self.errors:\n                key = self.get_cache_key(data)\n                hit = self.cache.get(key)\n                if hit:\n                    return hit\n        \n            model_data = self.program.execute_model(data)\n        \n        response = self.program.execute_view(model_data, self.mimetype, self.errors)\n\n        if self.program.cache and not self.errors and not self.model_mock:\n            self.cache.set(key, response, self.program.cache)\n\n        if 'persist' in response:\n            self.persist_data = response['persist']\n\n        return response", "response": "Execute the model and view and handle the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_data_for_model(self, args, kwargs):\n        kwargs_from_invocation = self.get_raw_data()\n        args_from_invocation = deque(self.path_args)\n\n        defaults = kwargs\n        values = args + list(kwargs.keys())\n\n        output = {}\n\n        raw = False\n        for i, field in enumerate(values):\n            ## going through each bit of data that the model needs\n            ## `field` here is the name of each needed var.\n\n            # the 'default' value that may be defined in the model.\n            # this variable might be a string or int or might even be a primitive object.\n            # NotImplemented here is used as to preserve if a default value is None.\n            # it is used here as a sort of MetaNone.\n            default_defined_in_model = defaults.get(field, NotImplemented)\n            \n            # the value in kwarg arguments such as --values and GET params\n            from_data_kwargs = kwargs_from_invocation.get(field, None)\n\n            # The value that will end up being used.\n            value_to_use = None\n\n            if default_defined_in_model == RAW_INVOCATION_ARGS:\n                # flag that the RAW_INVOCATION_ARGS primitive has been invoked\n                # used later to suppress errors for unused program args\n                # when this primitive is invoked, all positional args are invalid. \n                raw = True\n\n            if type(default_defined_in_model) == GiottoPrimitive:\n                value_to_use = self.get_primitive(default_defined_in_model.name)\n            elif from_data_kwargs:\n                value_to_use = from_data_kwargs\n            elif not raw and args_from_invocation:\n                value_to_use = args_from_invocation.popleft()\n            elif default_defined_in_model is not NotImplemented:\n                value_to_use = default_defined_in_model\n            else:\n                raise InvalidInvocation(\"Data Missing For Program. Missing: %s\" % field)\n            \n            output[field] = value_to_use\n\n        if args_from_invocation and not raw:\n            msg = \"Too many arguments. Program `%s` takes %s arguments, %s given\" % (\n                self.program.name, len(args) + len(kwargs), len(args_from_invocation)\n            )\n            raise InvalidInvocation(msg)\n\n        return output", "response": "This function returns the data that is expected for the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallows for defining virtual columns and collectors on models -- these are objects that are defined in code and not directly in a data store. :param cls: :param options: :return:", "response": "def virtual(cls, **options):\n    \"\"\"\n    Allows for defining virtual columns and collectors on models -- these\n    are objects that are defined in code and not directly in a data store.\n\n    :param cls:\n    :param options:\n    :return:\n    \"\"\"\n    def wrapped(func):\n        param_name = inflection.underscore(func.__name__)\n        options.setdefault('name', param_name)\n\n        if 'flags' in options:\n            if isinstance(options['flags'], set):\n                options['flags'].add('Virtual')\n                options['flags'].add('ReadOnly')\n            else:\n                options['flags'] |= (cls.Flags.Virtual | cls.Flags.ReadOnly)\n        else:\n            options['flags'] = {'Virtual', 'ReadOnly'}\n\n        def define_setter():\n            def setter_wrapped(setter_func):\n                func.__orb__.setFlags(func.__orb__.flags() & ~cls.Flags.ReadOnly)\n                func.__orb__.setter()(setter_func)\n                return setter_func\n            return setter_wrapped\n\n        def define_query_filter():\n            def shortcut_wrapped(shortcut_func):\n                func.__orb__.queryFilter(shortcut_func)\n                return shortcut_func\n            return shortcut_wrapped\n\n        func.__orb__ = cls(**options)\n        func.__orb__.getter()(func)\n        func.setter = define_setter\n        func.queryFilter = define_query_filter\n        return func\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the given node is defined as an inner function or class or inner function.", "response": "def _isInner(node):\n    \"\"\"\n    Determine whether the given node is, at any point in its syntactic\n    parentage, defined within a function.\n\n    @param node: The node to inspect.\n    @type node: L{logilab.astng.bases.NodeNG}\n\n    @return: a boolean indicating if the given node is defined as an inner\n        class or inner function.\n    \"\"\"\n    while node:\n        node = node.parent\n        if isinstance(node, scoped_nodes.FunctionDef):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getDecoratorsName(node):\n    # For setter properties pylint fails so we use a custom code.\n    decorators = []\n    if not node.decorators:\n        return decorators\n\n    for decorator in node.decorators.nodes:\n        decorators.append(decorator.as_string())\n    return decorators", "response": "Returns a list with names of decorators attached to this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _isSetter(node_type, node):\n    if node_type not in ['function', 'method']:\n        return False\n\n    for name in _getDecoratorsName(node):\n        if '.setter' in name:\n            return True\n    return False", "response": "Determines whether the given node is a setter property."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets line number of the docstring.", "response": "def _getDocstringLineno(self, node_type, node):\n        \"\"\"\n        Get line number of the docstring.\n\n        @param node_type: type of node_type\n        @param node: node of currently checking\n        @return: line number\n        \"\"\"\n        docstringStriped = node.as_string().strip()\n        linenoDocstring = (node.lineno + docstringStriped\n                           .count(\"\\n\", 0, docstringStriped.index('\"\"\"')))\n        if node_type == \"module\":\n            # Module starts from line 0.\n            linenoDocstring += 1\n        return linenoDocstring"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_docstring(self, node_type, node, report_missing=True,\n                         confidence=None):\n        \"\"\"\n        Check whether the opening and the closing of docstring\n        on a line by themselves.\n        Then check for epytext markups for function or method.\n\n        @param node_type: type of node\n        @param node: current node of pylint\n        \"\"\"\n        docstring = node.doc\n        if docstring is None:\n            # The node does not have a docstring.\n            if _isInner(node):\n                # Do not check things inside a function or method.\n                return\n\n            if _isSetter(node_type, node):\n                # Setters don't need a docstring as they are documented in\n                # the getter.\n                return\n\n            self.add_message('W9208', node=node)\n            return\n        elif not docstring.strip():\n            # Empty docstring.\n            self.add_message('W9209', node=node)\n            return\n        # Get line number of docstring.\n        linenoDocstring = self._getDocstringLineno(node_type, node)\n        self._checkDocstringFormat(node_type, node, linenoDocstring)\n        self._checkEpytext(node_type, node, linenoDocstring)\n        self._checkBlankLineBeforeEpytext(node_type, node, linenoDocstring)", "response": "Check whether the docstring of a node is documented."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether a docstring has consistent indentations.", "response": "def _checkIndentationIssue(self, node, node_type, linenoDocstring):\n        \"\"\"\n        Check whether a docstring have consistent indentations.\n\n        @param node: the node currently checks by pylint\n        @param node_type: type of given node\n        @param linenoDocstring: line number the docstring begins\n        \"\"\"\n        indentDocstring = node.col_offset and node.col_offset or 0\n        indentDocstring += len(re.findall(r'\\n( *)\"\"\"',\n                                          node.as_string())[0])\n        linesDocstring = node.doc.lstrip(\"\\n\").split(\"\\n\")\n        for nline, lineDocstring in enumerate(linesDocstring):\n            if (nline < len(linesDocstring) - 1\n                and not lineDocstring.strip()):\n                # It's a blank line.\n                continue\n            if indentDocstring != self._getLineIndent(lineDocstring):\n                if node_type == \"module\":\n                    lineno = linenoDocstring\n                else:\n                    lineno = linenoDocstring + nline + 1\n                self.add_message('W9206', line=lineno, node=node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the docstring format.", "response": "def _checkDocstringFormat(self, node_type, node, linenoDocstring):\n        \"\"\"\n        Check opening/closing of docstring.\n\n        @param node_type: type of node\n        @param node: current node of pylint\n        @param linenoDocstring: linenumber of docstring\n        \"\"\"\n        # Check the opening/closing of docstring.\n        docstringStrippedSpaces = node.doc.strip(\" \")\n        if (not docstringStrippedSpaces.startswith(\"\\n\")\n            or not docstringStrippedSpaces.endswith(\"\\n\")):\n            # If the docstring is in one line, then do not check indentations.\n            self.add_message('W9201', line=linenoDocstring, node=node)\n        else:\n            # If the docstring's opening and closing quotes are on separate\n            # lines, then we check its indentation.\n            # Generating warnings about indentation when the quotes aren't\n            # done right only clutters the output.\n            self._checkIndentationIssue(node, node_type, linenoDocstring)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining whether the given method or function has a return statement.", "response": "def _hasReturnValue(self, node):\n        \"\"\"\n        Determine whether the given method or function has a return statement.\n\n        @param node: the node currently checks\n        \"\"\"\n        returnFound = False\n        for subnode in node.body:\n            if type(subnode) == node_classes.Return and subnode.value:\n                returnFound = True\n                break\n        return returnFound"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _checkEpytext(self, node_type, node, linenoDocstring):\n        if node_type not in ['function', 'method']:\n            return\n        # Check for arguments.\n        # If current node is method,\n        # then first argument could not have a epytext markup.\n        # The first argument usually named 'self'.\n        argnames = (node.argnames()[1:] if node_type == 'method'\n                    else node.argnames())\n\n        if _isSetter(node_type, node):\n            # For setter methods we remove the `value` argument as it\n            # does not need to be documented.\n            try:\n                argnames.remove('value')\n            except ValueError:\n                # No `value` in arguments.\n                pass\n\n        for argname in argnames:\n            if node.name.startswith('opt_'):\n                # The docstring for option methods is presented as user-facing\n                # documentation.  Avoid requiring epytext in them.\n                return\n            if not re.search(r\"@param\\s+%s\\s*:\" % argname, node.doc):\n                self.add_message('W9202', line=linenoDocstring,\n                                 node=node, args=argname)\n            if not re.search(r\"@type\\s+%s\\s*:\" % argname, node.doc):\n                self.add_message('W9203', line=linenoDocstring,\n                                 node=node, args=argname)\n\n        self._checkReturnValueEpytext(node, linenoDocstring)", "response": "Check epytext of docstring."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _checkReturnValueEpytext(self, node, linenoDocstring):\n        # Getter properties don't need to document their return value,\n        # but then need to have a return value.\n        if 'property' in _getDecoratorsName(node):\n            if self._hasReturnValue(node):\n                # Getter properties don't need a docstring.\n                return\n\n        # Check for return value.\n        if self._hasReturnValue(node):\n            if node.name.startswith('test_'):\n                # Ignore return documentation for test methods.\n                return\n            if not re.search(r\"@return[s]{0,1}\\s*:\", node.doc):\n                self.add_message('W9204', line=linenoDocstring, node=node)\n            if not re.search(r\"@rtype\\s*:\", node.doc):\n                self.add_message('W9205', line=linenoDocstring, node=node)", "response": "Check if return value is documented."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether there is a blank line before epytext markups.", "response": "def _checkBlankLineBeforeEpytext(self, node_type, node, linenoDocstring):\n        \"\"\"\n        Check whether there is a blank line before epytext.\n\n        @param node_type: type of node\n        @param node: current node of pylint\n        @param linenoDocstring: linenumber of docstring\n        \"\"\"\n        # Check whether there is a blank line before epytext markups.\n        patternEpytext = (r\"\\n *@(param|type|return|returns|rtype|ivar|cvar\"\n                          r\"|raises|raise)\"\n                          r\"\\s*[a-zA-Z0-9_]*\\s*\\:\")\n        matchedEpytext = re.search(patternEpytext, node.doc)\n        if matchedEpytext:\n            # This docstring have epytext markups,\n            # then check the blank line before them.\n            posEpytext = matchedEpytext.start() + 1\n            if not re.search(r\"\\n\\s*\\n\\s*$\", node.doc[:posEpytext]):\n                self.add_message('W9207', line=linenoDocstring, node=node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inherits_modelpermissions_serializer(cls):\n    def is_modelperms():\n        return 'ModelPermissionsSerializer' in [\n            ser.__name__ for ser in cls.__bases__\n        ]\n    is_serializer = type(cls).__name__ == 'SerializerMetaclass'\n\n    return inspect.isclass(cls) and is_serializer and is_modelperms()", "response": "Verify that serializer is a ModelPermissionsSerializer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_user_allowed_fields(self):\n        model_name = self.Meta.model.__name__.lower()\n        app_label = self.Meta.model._meta.app_label\n        full_model_name = '%s.%s' % (app_label, model_name)\n        permissions = self.cached_allowed_fields.get(full_model_name)\n\n        if not permissions:\n            permissions = FieldPermission.objects.filter(\n                user_field_permissions__user=self.user,\n                content_type__model=model_name,\n                content_type__app_label=app_label\n            )\n            self.cached_allowed_fields[full_model_name] = permissions\n        return permissions", "response": "Retrieve all allowed field names ofr authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of all fields that can be accessed by authenticated user.", "response": "def get_fields(self):\n        \"\"\" Calculate fields that can be accessed by authenticated user. \"\"\"\n        ret = OrderedDict()\n\n        # no rights to see anything\n        if not self.user:\n            return ret\n\n        # all fields that can be accessed through serializer\n        fields = super(ModelPermissionsSerializer, self).get_fields()\n\n        # superuser can see all the fields\n        if self.user.is_superuser:\n            return fields\n\n        # fields that can be accessed by auhtenticated user\n        allowed_fields = self._get_user_allowed_fields()\n        for allowed_field in allowed_fields:\n            field = fields[allowed_field.name]\n\n            # subfields are NestedModelSerializer\n            if isinstance(field, ModelPermissionsSerializer):\n                # no rights on subfield's fields\n                # calculate how the relation should be retrieved\n                if not field.get_fields():\n                    field_cls = field._related_class\n                    kwargs = get_relation_kwargs(allowed_field.name,\n                                                 field.info)\n                    if not issubclass(field_cls,\n                                      serializers.HyperlinkedRelatedField):\n                        kwargs.pop('view_name', None)\n                    field = field_cls(**kwargs)\n\n            ret[allowed_field.name] = field\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn default field names for serializer.", "response": "def _get_default_field_names(self, declared_fields, model_info):\n        \"\"\" Return default field names for serializer. \"\"\"\n        return (\n            [model_info.pk.name] +\n            list(declared_fields.keys()) +\n            list(model_info.fields.keys()) +\n            list(model_info.relations.keys())\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndefining the serializer class for a nested field.", "response": "def _get_nested_class(self, nested_depth, relation_info):\n        \"\"\" Define the serializer class for a relational field. \"\"\"\n        class NestedModelPermissionSerializer(ModelPermissionsSerializer):\n\n            \"\"\" Default nested class for relation. \"\"\"\n\n            class Meta:\n                model = relation_info.related_model\n                depth = nested_depth - 1\n                nested_context = self.context\n                fields = '__all__'\n\n        return NestedModelPermissionSerializer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict_factory(cursor, row):\n    out = {}\n    for i, col in enumerate(cursor.description):\n        out[col[0]] = row[i]\n    return out", "response": "Converts the cursor information from a SQLite query to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the command and returns the result.", "response": "def _execute(self,\n                 native,\n                 command,\n                 data=None,\n                 returning=True,\n                 mapper=dict):\n        \"\"\"\n        Executes the inputted command into the current \\\n        connection cursor.\n        \n        :param      command    | <str>\n                    data       | <dict> || None\n                    autoCommit | <bool> | commit database changes immediately\n                    autoClose  | <bool> | closes connections immediately\n        \n        :return     [{<str> key: <variant>, ..}, ..], <int> count\n        \"\"\"\n        if data is None:\n            data = {}\n\n        # check to make sure the connection hasn't been reset or lost\n        cursor = native.cursor()\n\n        # determine if we're executing multiple statements at once\n        commands = [cmd for cmd in command.split(';') if cmd]\n        if len(commands) > 1:\n            native.isolation_level = 'IMMEDIATE'\n            commands.insert(0, 'BEGIN TRANSACTION')\n        else:\n            native.isolation_level = None\n\n        def _gen_sub_value(val):\n            output = []\n            replace = []\n\n            for sub_value in val:\n                if isinstance(sub_value, (list, tuple, set)):\n                    cmd, vals = _gen_sub_value(sub_value)\n                    replace.append(cmd)\n                    output += vals\n                else:\n                    replace.append('?')\n                    output.append(sub_value)\n\n                return '({0})'.format(','.join(replace)), output\n\n        rowcount = 0\n        for cmd in commands:\n            if not cmd.endswith(';'):\n                cmd += ';'\n\n            # map the dictionary keywords to the param based for sqlite\n            # (sqlite requires ordered options vs. keywords)\n            args = []\n            for grp, key in FORMAT_EXPR.findall(cmd):\n                value = data[key]\n                if isinstance(value, (list, tuple, set)):\n                    replace, values = _gen_sub_value(value)\n                    cmd = cmd.replace(grp, replace)\n                    args += values\n                else:\n                    cmd = cmd.replace(grp, '?')\n                    args.append(value)\n\n\n            log.debug('***********************')\n            log.debug(command)\n            log.debug(args)\n            log.debug('***********************')\n\n            try:\n                cursor.execute(cmd, tuple(args))\n\n                if cursor.rowcount != -1:\n                    rowcount += cursor.rowcount\n\n            # look for a cancelled query\n            except sqlite.OperationalError as err:\n                if err == 'interrupted':\n                    raise orb.errors.Interruption()\n                else:\n                    log.exception('Unkown query error.')\n                    raise orb.errors.QueryFailed(cmd, args, nstr(err))\n\n            # look for duplicate entries\n            except sqlite.IntegrityError as err:\n                duplicate_error = re.search('UNIQUE constraint failed: (.*)', nstr(err))\n                if duplicate_error:\n                    result = duplicate_error.group(1)\n                    msg = '{value} is already being used.'.format(value=result)\n                    raise orb.errors.DuplicateEntryFound(msg)\n                else:\n                    # unknown error\n                    log.exception('Unknown query error.')\n                    raise orb.errors.QueryFailed(command, data, nstr(err))\n\n            # look for any error\n            except Exception as err:\n                log.exception('Unknown query error.')\n                raise orb.errors.QueryFailed(cmd, args, nstr(err))\n\n        if returning:\n            results = [mapper(record) for record in cursor.fetchall()]\n            rowcount = len(results)  # for some reason, rowcount in sqlite3 returns -1 for selects...\n        else:\n            results = []\n\n        native.isolation_level = None\n        native.commit()\n\n        return results, rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle simple SQL specific connection creation.", "response": "def _open(self, db, writeAccess=False):\n        \"\"\"\n        Handles simple, SQL specific connection creation.  This will not\n        have to manage thread information as it is already managed within\n        the main open method for the SQLBase class.\n        \n        :param      db | <orb.Database>\n        \n        :return     <variant> | backend specific database connection\n        \"\"\"\n        if not sqlite:\n            raise orb.errors.BackendNotFound('sqlite is not installed.')\n\n        dbname = db.name()\n\n        try:\n            sqlite_db = sqlite.connect(dbname)\n            sqlite_db.create_function('REGEXP', 2, matches)\n            sqlite_db.row_factory = dict_factory\n            sqlite_db.text_factory = unicode\n\n            self.__threaded_connections[sqlite_db] = threading.current_thread().ident\n\n            return sqlite_db\n        except sqlite.Error:\n            log.exception('Failed to connect to sqlite')\n            raise orb.errors.ConnectionFailed()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a user and session and return the session_key and user.", "response": "def basic_register(username, password, password2):\n    \"\"\"\n    Register a user and session, and then return the session_key and user.\n    \"\"\"\n    if password != password2:\n        raise InvalidInput(password={'message': \"Passwords do not match\"},\n                           username={'value': username})\n    user = User.objects.create_user(username, password)\n    return create_session(user.username, password)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a session for the user and return the key.", "response": "def create_session(username, password):\n    \"\"\"\n    Create a session for the user, and then return the key.\n    \"\"\"\n    user = User.objects.get_user_by_password(username, password)\n    auth_session_engine = get_config('auth_session_engine')\n    if not user:\n        raise InvalidInput('Username or password incorrect')\n    session_key = random_string(15)\n    while auth_session_engine.get(session_key):\n        session_key = random_string(15)\n    auth_session_engine.set(session_key, user.username, get_config('auth_session_expire'))\n    return {'session_key': session_key, 'user': user}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the given Python source for flakes.", "response": "def check(codeString, filename, reporter=None):\n    \"\"\"\n    Check the Python source given by C{codeString} for flakes.\n\n    @param codeString: The Python source to check.\n    @type codeString: C{str}\n\n    @param filename: The name of the file the source came from, used to report\n        errors.\n    @type filename: C{str}\n\n    @param reporter: A L{Reporter} instance, where errors and warnings will be\n        reported.\n\n    @return: The number of warnings emitted.\n    @rtype: C{int}\n    \"\"\"\n    if reporter is None:\n        reporter = modReporter._makeDefaultReporter()\n    # First, compile into an AST and handle syntax errors.\n    try:\n        tree = compile(codeString, filename, \"exec\", _ast.PyCF_ONLY_AST)\n    except SyntaxError:\n        value = sys.exc_info()[1]\n        msg = value.args[0]\n\n        (lineno, offset, text) = value.lineno, value.offset, value.text\n\n        # If there's an encoding problem with the file, the text is None.\n        if text is None:\n            # Avoid using msg, since for the only known case, it contains a\n            # bogus message that claims the encoding the file declared was\n            # unknown.\n            reporter.unexpectedError(filename, 'problem decoding source')\n        else:\n            reporter.syntaxError(filename, msg, lineno, offset, text)\n        return 1\n    except Exception:\n        reporter.unexpectedError(filename, 'problem decoding source')\n        return 1\n    # Okay, it's syntactically valid.  Now check it.\n    w = checker.Checker(tree, filename)\n    w.messages.sort(key=lambda m: m.lineno)\n    for warning in w.messages:\n        reporter.flake(warning)\n    return len(w.messages)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterSourceCode(paths):\n    for path in paths:\n        if os.path.isdir(path):\n            for dirpath, dirnames, filenames in os.walk(path):\n                for filename in filenames:\n                    if filename.endswith('.py'):\n                        yield os.path.join(dirpath, filename)\n        else:\n            yield path", "response": "Iterate over all Python source files in C { paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef checkRecursive(paths, reporter):\n    warnings = 0\n    for sourcePath in iterSourceCode(paths):\n        if re.search(RE_EXCLUDE, sourcePath):\n            continue\n        warnings += checkPath(sourcePath, reporter)\n    return warnings", "response": "Recursively checks all source files in C { paths."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the db_value provided back from the database.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Extracts the db_value provided back from the database.\n\n        :param db_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if isinstance(db_value, (str, unicode)) and db_value.startswith('{'):\n            try:\n                db_value = projex.text.safe_eval(db_value)\n            except StandardError:\n                log.exception('Invalid reference found')\n                raise orb.errors.OrbError('Invalid reference found.')\n\n        if isinstance(db_value, dict):\n            cls = self.referenceModel()\n            if not cls:\n                raise orb.errors.ModelNotFound(schema=self.reference())\n            else:\n                load_event = orb.events.LoadEvent(data=db_value)\n\n                # update the expansion information to not propagate to references\n                if context:\n                    context = context.copy()\n                    expand = context.expandtree(cls)\n                    sub_expand = expand.pop(self.name(), {})\n                    context.expand = context.raw_values['expand'] = sub_expand\n\n                db_value = cls(loadEvent=load_event, context=context)\n\n        return super(ReferenceColumn, self).dbRestore(db_value, context=context)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadJSON(self, jdata):\n        super(ReferenceColumn, self).loadJSON(jdata)\n\n        # load additional information\n        self.__reference = jdata.get('reference') or self.__reference\n        self.__removeAction = jdata.get('removeAction') or self.__removeAction", "response": "Loads the given JSON information for this column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef referenceModel(self):\n        model = orb.system.model(self.__reference)\n        if not model:\n            raise orb.errors.ModelNotFound(schema=self.__reference)\n        return model", "response": "Returns the model that this column references."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore(self, value, context=None):\n        context = context or orb.Context()\n        value = super(ReferenceColumn, self).restore(value, context=context)\n\n        # check to make sure that we're processing the right values\n        if self.testFlag(self.Flags.I18n) and context.locale == 'all':\n            return {locale: self._restore(val, context) for locale, val in value.items()}\n        else:\n            return self._restore(value, context)", "response": "Returns the inflated value state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, value):\n        ref_model = self.referenceModel()\n        if isinstance(value, orb.Model):\n            expected_schema = ref_model.schema().name()\n            received_schema = value.schema().name()\n\n            if expected_schema != received_schema:\n                raise orb.errors.InvalidReference(self.name(),\n                                                  expects=expected_schema,\n                                                  received=received_schema)\n\n        return super(ReferenceColumn, self).validate(value)", "response": "Checks that the value is a valid reference for the current column instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef valueFromString(self, value, context=None):\n        model = self.referenceModel()\n        return model(value, context=context)", "response": "Re - implements the orb. Column. valueFromString method toget a reference object based on the given value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate(self, manager=None):\n        manager = manager or orb.system\n        manager.activate(self)\n        return True", "response": "Activates this database within the given manager."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addNamespace(self, namespace, **context):\n        self.connection().addNamespace(namespace, orb.Context(**context))", "response": "Adds a new namespace within this database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interrupt(self, threadId=None):\n        back = self.backend()\n        if back:\n            back.interrupt(threadId)", "response": "Interrupts the thread at the given id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the backend connection for this database instance.", "response": "def setConnection(self, connection):\n        \"\"\"\n        Assigns the backend connection for this database instance.\n\n        :param connection: <str> || <orb.Connection>\n        \"\"\"\n        # define custom properties\n        if not isinstance(connection, orb.Connection):\n            conn = orb.Connection.byName(connection)\n            if not conn:\n                raise orb.errors.BackendNotFound(connection)\n            connection = conn(self)\n        else:\n            connection.setDatabase(self)\n\n        self.__connection = connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sync(self, models=None, **context):\n        context = orb.Context(**context)\n\n        # collect the information for this database\n        conn = self.__connection\n        all_models = orb.system.models(orb.Model).values()\n        all_models.sort(cmp=lambda x,y: cmp(x.schema(), y.schema()))\n\n        tables = [model for model in all_models if issubclass(model, orb.Table) and\n                  not model.schema().testFlags(orb.Schema.Flags.Abstract) and\n                  (not models or model.schema().name() in models)]\n        views = [model for model in all_models if issubclass(model, orb.View) and\n                  not model.schema().testFlags(orb.Schema.Flags.Abstract) and\n                  (not models or model.schema().name() in models)]\n\n        # initialize the database\n        event = orb.events.SyncEvent(context=context)\n        self.__connection.onSync(event)\n\n        namespaces = set()\n        info = conn.schemaInfo(context)\n\n        # create new models\n        for model in tables:\n            if model.schema().dbname() not in info:\n                namespace = model.schema().namespace()\n                if namespace and namespace not in namespaces:\n                    conn.addNamespace(namespace, context)\n                    namespaces.add(namespace)\n\n                conn.createModel(model, context, includeReferences=False, owner=self.username())\n\n        # update after any newly created tables get generated\n        info = conn.schemaInfo(context)\n\n        for model in tables:\n            try:\n                model_info = info[model.schema().dbname()]\n            except KeyError:\n                continue\n            else:\n                # collect the missing columns and indexes\n                add = defaultdict(list)\n                for col in model.schema().columns(recurse=False).values():\n                    if col.field() not in (model_info['fields'] or []) and not col.testFlag(col.Flags.Virtual):\n                        add['fields'].append(col)\n\n                for index in model.schema().indexes(recurse=False).values():\n                    if index.dbname() not in (model_info['indexes'] or []):\n                        add['indexes'].append(index)\n\n                # alter the model with the new indexes\n                if add['fields'] or add['indexes']:\n                    conn.alterModel(model, context, add=add, owner=self.username())\n\n        for model in tables:\n            # call the sync event\n            event = orb.events.SyncEvent(model=model)\n            if model.processEvent(event):\n                model.onSync(event)\n\n        # sync views last\n        for view in views:\n            conn.createModel(view, context)\n            event = orb.events.SyncEvent(model=view)\n            if view.processEvent(event):\n                view.onSync(event)", "response": "Syncs the database by calling its schema sync method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random value that fits this column s parameters.", "response": "def random(self):\n        \"\"\"\n        Returns a random value that fits this column's parameters.\n\n        :return: <variant>\n        \"\"\"\n        minimum = self.minimum() or 0\n        maximum = self.maximum() or 100\n        return random.randint(minimum, maximum)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the inputted string text to a value that matches the type from this column type.", "response": "def valueFromString(self, value, extra=None, db=None):\n        \"\"\"\n        Converts the inputted string text to a value that matches the type from\n        this column type.\n\n        :param      value | <str>\n                    extra | <variant>\n        \"\"\"\n        try:\n            return projex.text.safe_eval(value)\n        except ValueError:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds patterns of exceptions in a file.", "response": "def findPatternsInFile(codes, patternFinder):\n    \"\"\"\n    Find patterns of exceptions in a file.\n\n    @param codes: code of the file to check\n    @param patternFinder: a visitor for pattern checking and save results\n    \"\"\"\n    tree = ast.parse(codes)\n    patternFinder.visit(tree)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findAllExceptions(pathToCheck):\n    finder = PatternFinder()\n    if os.path.isfile(pathToCheck):\n        with open(pathToCheck) as f:\n            findPatternsInFile(f.read(), finder)\n    else:\n        for path, dirs, files in os.walk(pathToCheck):\n            for file in files:\n                _, extname = os.path.splitext(file)\n                if extname == \".py\":\n                    pathFile = os.path.join(path, file)\n                    with open(pathFile) as f:\n                        findPatternsInFile(f.read(), finder)\n    return finder.patternsFunc, finder.patternsClass", "response": "Find patterns of exceptions in a file or folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Call(self, nodeCall):\n        super(PatternFinder, self).generic_visit(nodeCall)\n        # Capture assignment like 'f = getattr(...)'.\n        if hasattr(nodeCall.func, \"func\"):\n            # In this case, the statement should be\n            # 'f = getattr(...)()'.\n            nodeCall = nodeCall.func\n        # Make sure the function's name is 'getattr'.\n        if not hasattr(nodeCall.func, \"id\"):\n            return\n        if nodeCall.func.id != \"getattr\":\n            return\n\n        # Capture 'f = getattr(foo, \"bar_%s\" % baz )' or\n        # 'f = getattr(foo, \"bar_\" + baz )'.\n        nodeArgument = nodeCall.args[1]\n        if not isinstance(nodeArgument, ast.BinOp):\n            return\n        operation = nodeArgument.op\n        if type(operation) not in [ast.Mod, ast.Add]:\n            return\n        nodePattern = nodeArgument.left\n        if not isinstance(nodePattern, ast.Str):\n            return\n        pattern = nodePattern.s\n        if not ((type(operation) == ast.Add and pattern.endswith(\"_\")) or\n                (pattern.count(\"%s\") == 1 and pattern.endswith(\"_%s\"))):\n            return\n        pattern = pattern.replace(\"%s\", \"\")\n        if pattern[:1].isalpha() and not pattern[:1].islower():\n            self.patternsClass.add(pattern)\n        else:\n            self.patternsFunc.add(pattern)", "response": "A generic method that checks if a node is a function call and if so adds the pattern to the list of patterns that match the function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_module(self, node):\n        if not node.file_stream:\n            # Failed to open the module\n            return\n        isFirstLineOfComment = True\n        isDocString = False\n        lines = node.stream().readlines()\n        for linenum, line in enumerate(lines):\n            if line.strip().startswith(b'\"\"\"'):\n                # This is a simple assumption than docstring are delimited\n                # with triple double quotes on a single line.\n                # Should do the job for Twisted code.\n                isDocString = not isDocString\n\n            if isDocString:\n                # We ignore comments in docstrings.\n                continue\n\n            matchedComment = COMMENT_RGX.search(line)\n            if matchedComment:\n                if isFirstLineOfComment:\n                    # Check for W9401\n                    comment = matchedComment.group()\n                    if (comment.startswith(b\"#  \") or\n                        not comment.startswith(b\"# \")):\n                        self.add_message('W9401', line=linenum + 1, node=node)\n                    # Check for W9402\n                    strippedComment = comment.lstrip(b\"#\").lstrip()\n                    if strippedComment:\n                        firstLetter = strippedComment[0:1]\n                        if (firstLetter.isalpha() and\n                            not firstLetter.isupper()):\n                            self.add_message('W9402', line=linenum + 1, node=node)\n                    isFirstLineOfComment = False\n            else:\n                isFirstLineOfComment = True", "response": "A method that checks if the module is in the file stream and if so checks if the comment is a comment and if so adds a message for the module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef after(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.After)\n        newq.setValue(value)\n        return newq", "response": "Returns a copy of this Query with the operator set to Query. Op. After and sets the value to \n        the amount that this query should be lower than."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef and_(self, other):\n        if not isinstance(other, (Query, QueryCompound)) or other.isNull():\n            return self.copy()\n        elif not self:\n            return other.copy()\n        else:\n            return orb.QueryCompound(self, other, op=orb.QueryCompound.Op.And)", "response": "Creates a new compound query using the \n        type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asString(self):\n        q = self.copy()\n        q.addFunction(Query.Function.AsString)\n        return q", "response": "Returns this query with an AsString function added to it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef before(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.Before)\n        newq.setValue(value)\n        return newq", "response": "Returns a copy of this Query with the operator set to Query. Op. Before and sets the value to \n        the amount that this query should be lower than value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef between(self, low, high):\n        newq = self.copy()\n        newq.setOp(Query.Op.Between)\n        newq.setValue((low, high))\n        return newq", "response": "Returns a new Query object with the values between low and high."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the column instance for this query.", "response": "def column(self, model=None):\n        \"\"\"\n        Returns the column instance for this query.\n        \n        :return     <orb.Column>\n        \"\"\"\n        try:\n            schema = (self.__model or model).schema()\n        except AttributeError:\n            return None\n        else:\n            return schema.column(self.__column)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator that loops through the columns that are associated with this query.", "response": "def columns(self, model=None):\n        \"\"\"\n        Returns a generator that loops through the columns that are associated with this query.\n        \n        :return     <generator>(orb.Column)\n        \"\"\"\n        column = self.column(model=model)\n        if column:\n            yield column\n\n        check = self.__value\n        if not isinstance(check, (list, set, tuple)):\n            check = (check,)\n\n        for val in check:\n            if isinstance(val, (Query, QueryCompound)):\n                for col in val.columns(model):\n                    yield col"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contains(self, value, caseSensitive=False):\n        newq = self.copy()\n        newq.setOp(Query.Op.Contains)\n        newq.setValue(value)\n        newq.setCaseSensitive(caseSensitive)\n        return newq", "response": "Returns a copy of the object with the specified value set to True if the inputted value is contained in the comments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        options = {\n            'op': self.__op,\n            'caseSensitive': self.__caseSensitive,\n            'value': copy.copy(self.__value),\n            'inverted': self.__inverted,\n            'functions': copy.copy(self.__functions),\n            'math': copy.copy(self.__math)\n        }\n        return orb.Query(self.__model, self.__column, **options)", "response": "Returns a copy of this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a copy of the current object with the operator type to Query. Op. DoesNotContain and sets the value to the inputted value.", "response": "def doesNotContain(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.DoesNotContain and sets the\n        value to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     self    (useful for chaining)\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('comments').doesNotContain('test')\n                    |>>> print query\n                    |comments does_not_contain test\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.DoesNotContain)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of the object with the operator type set to Query. Op. DoesNotMatch and sets the value to the inputted value.", "response": "def doesNotMatch(self, value, caseSensitive=True):\n        \"\"\"\n        Sets the operator type to Query.Op.DoesNotMatch and sets the \\\n        value to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     self    (useful for chaining)\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('comments').doesNotMatch('test')\n                    |>>> print query\n                    |comments does_not_contain test\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.DoesNotMatch)\n        newq.setValue(value)\n        newq.setCaseSensitive(caseSensitive)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a copy of the current object with the operator type set to Query. Op. Endswith and sets the value to the inputted value.", "response": "def endswith(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.Endswith and sets \\\n        the value to the inputted value.  This method will only work on text \\\n        based fields.\n        \n        :param      value       <str>\n        \n        :return     <Query>\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').endswith('blah')\n                    |>>> print query\n                    |test startswith blah\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.Endswith)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand(self, model=None, ignoreFilter=False):\n        model = self.__model or model\n        if not model:\n            raise orb.errors.QueryInvalid('Could not traverse: {0}'.format(self.__column))\n\n        schema = model.schema()\n        parts = self.__column.split('.')\n\n        # expand the current column\n        lookup = schema.column(parts[0], raise_=False) or schema.collector(parts[0])\n\n        if lookup:\n            # utilize query filters to generate\n            # a new filter based on this object\n            query_filter = lookup.queryFilterMethod()\n            if callable(query_filter) and not ignoreFilter:\n                new_q = query_filter(model, self)\n                if new_q:\n                    return new_q.expand(model, ignoreFilter=True)\n                else:\n                    return None\n\n            # otherwise, check to see if the lookup\n            # has a shortcut to look through\n            elif isinstance(lookup, orb.Column) and lookup.shortcut():\n                parts = lookup.shortcut().split('.')\n                lookup = schema.column(parts[0], raise_=False)\n\n        if len(parts) == 1:\n            return self\n        else:\n            if isinstance(lookup, orb.Collector):\n                return orb.Query(model).in_(lookup.collectExpand(self, parts))\n\n            elif isinstance(lookup, orb.ReferenceColumn):\n                rmodel = lookup.referenceModel()\n                sub_q = self.copy()\n                sub_q._Query__column = '.'.join(parts[1:])\n                sub_q._Query__model = rmodel\n                records = rmodel.select(columns=[rmodel.schema().idColumn()], where=sub_q)\n                return orb.Query(model, parts[0]).in_(records)\n\n            else:\n                raise orb.errors.QueryInvalid('Could not traverse: {0}'.format(self.__column))", "response": "Expand any shortcuts that were created for this object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the operator type to Query. Op. Is and sets the value to the inputted value.", "response": "def is_(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.Is and sets the\n        value to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     <Query>\n        \n        :sa         __eq__\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').is_(1)\n                    |>>> print query\n                    |test is 1\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.Is)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the current object with the operator type set to Query. Op. GreaterThan and sets the value to the inputted value.", "response": "def greaterThan(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.GreaterThan and sets the\n        value to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     <Query>\n        \n        :sa         __gt__\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').greaterThan(1)\n                    |>>> print query\n                    |test greater_than 1\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.GreaterThan)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef greaterThanOrEqual(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.GreaterThanOrEqual)\n        newq.setValue(value)\n        return newq", "response": "Returns a copy of the current object with the value greater than or equal to the inputted value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an inverted copy of this query.", "response": "def inverted(self):\n        \"\"\"\n        Returns an inverted copy of this query.\n\n        :return     <orb.Query>\n        \"\"\"\n        out = self.copy()\n        out.setInverted(not self.isInverted())\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isNot(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.IsNot)\n        newq.setValue(value)\n        return newq", "response": "Sets the operator type to Query. Op. IsNot and returns a copy of the current Query object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.IsIn)\n\n        if isinstance(value, orb.Collection):\n            newq.setValue(value)\n        elif not isinstance(value, (set, list, tuple)):\n            newq.setValue((value,))\n        else:\n            newq.setValue(tuple(value))\n\n        return newq", "response": "Sets the operator type to Query. Op. IsIn and sets the value\n        to the inputted value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the operator type to Query. Op. IsNotIn and sets the value to the inputted value.", "response": "def notIn(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.IsNotIn and sets the value\n        to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     <Query>\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').not_in([1,2])\n                    |>>> print query\n                    |test is_not_in [1,2]\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.IsNotIn)\n\n        if isinstance(value, orb.Collection):\n            newq.setValue(value)\n        elif not isinstance(value, (set, list, tuple)):\n            newq.setValue((value,))\n        else:\n            newq.setValue(tuple(value))\n\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lessThan(self, value):\n        newq = self.copy()\n        newq.setOp(Query.Op.LessThan)\n        newq.setValue(value)\n        return newq", "response": "Sets the operator type to Query. Op. LessThan and returns a copy of the current Query object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the operator type to Query. Op. LessThanOrEqual and returns a copy of the current object.", "response": "def lessThanOrEqual(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.LessThanOrEqual and sets \n        the value to the inputted value.\n        \n        :param      value       <variant>\n        \n        :return     <Query>\n        \n        :sa         lessThanOrEqual\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').lessThanOrEqual(1)\n                    |>>> print query\n                    |test less_than_or_equal 1\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.LessThanOrEqual)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lower(self):\n        q = self.copy()\n        q.addFunction(Query.Function.Lower)\n        return q", "response": "Returns a copy of this query with the function lower applied to the key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the current object with the given value and the operator type set to Query. Op. Matches and sets the value to the inputted regex expression.", "response": "def matches(self, value, caseSensitive=True):\n        \"\"\"\n        Sets the operator type to Query.Op.Matches and sets \\\n        the value to the inputted regex expression.  This method will only work \\\n        on text based fields.\n        \n        :param      value       <str>\n        \n        :return     <Query>\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').matches('^\\d+-\\w+$')\n                    |>>> print query\n                    |test matches ^\\d+-\\w+$\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.Matches)\n        newq.setValue(value)\n        newq.setCaseSensitive(caseSensitive)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new instance with the negated state for this query.", "response": "def negated(self):\n        \"\"\"\n        Negates the current state for this query.\n        \n        :return     <self>\n        \"\"\"\n        query = self.copy()\n        op = self.op()\n        query.setOp(self.NegatedOp.get(op, op))\n        query.setValue(self.value())\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef or_(self, other):\n        if not isinstance(other, (Query, QueryCompound)) or other.isNull():\n            return self.copy()\n        elif not self:\n            return other.copy()\n        else:\n            return orb.QueryCompound(self, other, op=orb.QueryCompound.Op.Or)", "response": "Creates a new compound query using the \n        or operator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the value that will be used for this query instance.", "response": "def setValue(self, value):\n        \"\"\"\n        Sets the value that will be used for this query instance.\n        \n        :param      value       <variant>\n        \"\"\"\n        self.__value = projex.text.decoded(value) if isinstance(value, (str, unicode)) else value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a copy of the current object with the first occurrence of the given value.", "response": "def startswith(self, value):\n        \"\"\"\n        Sets the operator type to Query.Op.Startswith and sets \\\n        the value to the inputted value.  This method will only work on text \\\n        based fields.\n        \n        :param      value       <str>\n        \n        :return     <Query>\n        \n        :usage      |>>> from orb import Query as Q\n                    |>>> query = Q('test').startswith('blah')\n                    |>>> print query\n                    |test startswith blah\n        \"\"\"\n        newq = self.copy()\n        newq.setOp(Query.Op.Startswith)\n        newq.setValue(value)\n        return newq"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upper(self):\n        q = self.copy()\n        q.addFunction(Query.Function.Upper)\n        return q", "response": "Returns this query with the Upper function added to its list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Query object from the given JSON data.", "response": "def fromJSON(jdata):\n        \"\"\"\n        Creates a new Query object from the given JSON data.\n\n        :param      jdata | <dict>\n\n        :return     <orb.Query> || <orb.QueryCompound>\n        \"\"\"\n        if jdata['type'] == 'compound':\n            queries = [orb.Query.fromJSON(jquery) for jquery in jdata['queries']]\n            out = orb.QueryCompound(*queries)\n            out.setOp(orb.QueryCompound.Op(jdata['op']))\n            return out\n        else:\n            if jdata.get('model'):\n                model = orb.schema.model(jdata.get('model'))\n                if not model:\n                    raise orb.errors.ModelNotFound(schema=jdata.get('model'))\n                else:\n                    column = (model, jdata['column'])\n            else:\n                column = (jdata['column'],)\n\n            query = orb.Query(*column)\n            query.setOp(orb.Query.Op(jdata.get('op', 'Is')))\n            query.setInverted(jdata.get('inverted', False))\n            query.setCaseSensitive(jdata.get('caseSensitive', False))\n            query.setValue(jdata.get('value'))\n\n            # restore the function information\n            for func in jdata.get('functions', []):\n                query.addFunction(orb.Query.Function(func))\n\n            # restore the math information\n            for entry in jdata.get('math', []):\n                query.addMath(orb.Query.Math(entry.get('op')), entry.get('value'))\n            return query"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn any columns used within this query.", "response": "def columns(self, model=None):\n        \"\"\"\n        Returns any columns used within this query.\n\n        :return     [<orb.Column>, ..]\n        \"\"\"\n        for query in self.__queries:\n            for column in query.columns(model=model):\n                yield column"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand(self, model=None, ignoreFilter=False):\n        queries = []\n        current_records = None\n\n        for query in self.__queries:\n            sub_q = query.expand(model)\n            if not sub_q:\n                continue\n\n            # chain together joins into sub-queries\n            if ((isinstance(sub_q, orb.Query) and isinstance(sub_q.value(), orb.Query)) and\n                 sub_q.value().model(model) != sub_q.model(model)):\n                sub_model = sub_q.value().model(model)\n                sub_col = sub_q.value().column()\n                new_records = sub_model.select(columns=[sub_col])\n\n                sub_q = sub_q.copy()\n                sub_q.setOp(sub_q.Op.IsIn)\n                sub_q.setValue(new_records)\n\n                if current_records is not None and current_records.model() == sub_q.model(model):\n                    new_records = new_records.refine(createNew=False, where=sub_q)\n                else:\n                    queries.append(sub_q)\n\n                current_records = new_records\n\n            # update the existing recordset in the chain\n            elif (current_records is not None and\n                 (\n                    (isinstance(sub_q, orb.Query) and current_records.model() == query.model(model)) or\n                    (isinstance(sub_q, orb.QueryCompound) and current_records.model() in sub_q.models(model))\n                 )):\n                current_records.refine(createNew=False, where=sub_q)\n\n            # clear out the chain and move on to the next query set\n            else:\n                current_records = None\n                queries.append(query)\n\n        return QueryCompound(*queries, op=self.op())", "response": "Expands any shortcuts that were created for this query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef negated(self):\n        op = QueryCompound.Op.And if self.__op == QueryCompound.Op.Or else QueryCompound.Op.Or\n        return QueryCompound(*self.__queries, op=op)", "response": "Returns a new QueryCompound instance with the same operation as this one but not the other."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef or_(self, other):\n        if not isinstance(other, (Query, QueryCompound)) or other.isNull():\n            return self.copy()\n        elif self.isNull():\n            return other.copy()\n        else:\n            # grow this if the operators are the same\n            if self.__op == QueryCompound.Op.And:\n                queries = list(self.__queries) + [other]\n                return QueryCompound(*queries, op=QueryCompound.Op.Or)\n            else:\n                return QueryCompound(self, other, op=QueryCompound.Op.Or)", "response": "Creates a new compound query using the specified operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef models(self, model=None):\n        for query in self.__queries:\n            if isinstance(query, orb.Query):\n                yield query.model(model)\n            else:\n                for model in query.models(model):\n                    yield model", "response": "Returns the models that this query is referencing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_handlers(self):\n        handlers = []\n        self.static_root = self.application.get_app_component(\n        ).get_component_path()\n        if self.conf:\n            if 'maps' in self.conf:\n                if self.conf['maps'] is None:\n                    logger.warning(\"Maps configuration is empty. Finish the\"\n                                   \"static maps configuration.\")\n                    return handlers\n                for map_item in self.conf['maps']:\n                    logger.debug(\"Mapping %s handlers.\" % map_item['name'])\n                    self.static_maps[map_item['name']] = {}\n                    self.static_maps[\n                        map_item['name']]['root'] = self.static_root\n                    if 'root' in map_item:\n                        if os.path.isabs(map_item['root']):\n                            self.static_maps[\n                                map_item['name']]['root'] = map_item['root']\n                        else:\n                            self.static_maps[\n                                map_item['name']]['root'] = os.path.abspath(\n                                os.path.join(self.static_root,\n                                             map_item['root']))\n                    if 'handlers' in map_item:\n                        if map_item['handlers'] is None:\n                            logger.warning(\"There is no handles mapped in the\"\n                                           \" static maps config file.\")\n                        else:\n                            handlers = handlers + self.get_static_handlers(\n                                map_item)\n        else:\n            logger.warning(\"No static maps configurations were provided.\")\n        return handlers", "response": "Returns the handlers defined on the static_maps. yml file located\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_binop(self, node):\n        if node.op != \"%\":\n            return\n        pattern = node.left.as_string()\n        # If the pattern's not a constant string, we don't know whether a\n        # dictionary or a tuple makes sense, so don't try to guess.\n        if not pattern.startswith(\"'\") or pattern.startswith('\"'):\n            return\n        # If the pattern has things like %(foo)s, then the values can't be a\n        # tuple, so don't check for it.\n        if \"%(\" in pattern:\n            return\n        valueString = node.right.as_string()\n        tupleUsed = valueString.startswith('(')\n        if tupleUsed:\n            return\n        self.add_message('W9501', node=node)", "response": "Called when a binary operation is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_module(self, node):\n        modulename = node.name.split(\".\")[-1]\n        if isTestModule(node.name) and self.moduleContainsTestCase(node):\n            self._checkTestModuleName(modulename, node)", "response": "Check if the node is a test module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getMethodNamePrefix(self, node):\n        targetName = node.name\n        for sibling in node.parent.nodes_of_class(type(node)):\n            if sibling is node:\n                # We are on the same node in parent so we skip it.\n                continue\n            prefix = self._getCommonStart(targetName, sibling.name)\n            if not prefix.rstrip('_'):\n                # We ignore prefixes which are just underscores.\n                continue\n            return prefix\n\n        return ''", "response": "Returns the prefix of this method based on sibling methods."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getCommonStart(self, left, right):\n        prefix = []\n        for a, b in zip(left, right):\n            if a == b:\n                prefix.append(a)\n            else:\n                break\n\n        return ''.join(prefix)", "response": "Return the common prefix of the 2 strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlisten for new manifest and config", "response": "def listen(manifest, config, model_mock=False):\n    \"\"\"\n    IRC listening process.\n    \"\"\"\n    config['manifest'] = manifest\n    config['model_mock'] = model_mock\n    IRC = IrcBot(config)\n    try:\n        IRC.start()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a username and a raw unhashed password get the corresponding user", "response": "def get_user_by_password(self, username, password):\n        \"\"\"\n        Given a username and a raw, unhashed password, get the corresponding\n        user, retuns None if no match is found.\n        \"\"\"\n        try:\n            user = self.get(username=username)\n        except User.DoesNotExist:\n            return None\n        \n        if bcrypt.hashpw(password, user.pass_hash) == user.pass_hash:\n            return user\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AuthenticatedOrRedirect(invocation):\n    class AuthenticatedOrRedirect(GiottoInputMiddleware):\n        def http(self, request):\n            if request.user:\n                return request\n            return Redirection(invocation)\n\n        def cmd(self, request):\n            if request.user:\n                return request\n            return Redirection(invocation)\n\n    return AuthenticatedOrRedirect", "response": "Returns a middleware that redirects if the user is not logged in."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef queryFilter(self, function=None):\n        if function is not None:\n            self.__query_filter = function\n            return function\n\n        def wrapper(func):\n            self.__query_filter = func\n            return func\n        return wrapper", "response": "Defines a decorator that can be used to filter the objects by the given function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_auth_manifest(**kwargs):\n    class AuthProgram(Program):\n        pre_input_middleware = [AuthenticationMiddleware]\n\n    def register(username, password, password2):\n        \"\"\"\n        Decorated version of basic_register with a callback added.\n        \"\"\"\n        result = basic_register(username, password, password2)\n        callback = kwargs.get('post_register_callback', None)\n        if callback:\n            user = User.objects.get(username=username)\n            callback(user)\n        return result\n\n    return Manifest({\n        'login': [\n            AuthProgram(\n                \"\"\"\n                Prints out the HTML form for logging in.\n                \"\"\",\n                name=\"Login (form)\",\n                input_middleware=[NotAuthenticatedOrRedirect('/')],\n                view=BasicView(\n                    html=jinja_template('login.html'),\n                ),\n            ),\n            AuthProgram(\n                \"\"\"\n                Matches up the username/password against the database, and adds the auth cookies.\n                \"\"\",\n                name=\"Login (post)\",\n                input_middleware=[NotAuthenticatedOrDie],\n                controllers=['http-post', 'cmd'],\n                model=[create_session, {'username': 'mock_user', 'session_key': 'XXXXXXXXXXXXXXX'}],\n                view=BasicView(\n                    persist=lambda m: {'giotto_session': m['session_key']},\n                    html=lambda m: Redirection('/'),\n                ),\n            ),\n        ],\n        'logout': AuthProgram(\n            \"\"\"\n            Send the user here to log them out. Removes their cookies and deletes the auth session.\n            \"\"\",\n            name=\"Logout\",\n            view=BasicView(\n                html=Redirection('/'),\n            ),\n            output_middleware=[LogoutMiddleware],\n        ),\n        'register': [\n            AuthProgram(\n                \"\"\"\n                This program returns the HTML page with the form for registering a new account.\n                HTTP-get only.\n                \"\"\",\n                name=\"Register (form)\",\n                input_middleware=[NotAuthenticatedOrRedirect('/')],\n                view=BasicView(\n                    html=jinja_template('register.html'),\n                ),\n            ),\n            AuthProgram(\n                \"\"\"\n                When you POST the register form, this program handles creating the new user, then redirecting you to '/'\n                \"\"\",\n                name=\"Register (post)\",\n                controllers=['http-post'],\n                model=[register],\n                view=BasicView(\n                    persist=lambda m: {'giotto_session': m['session_key']},\n                    html=lambda m: Redirection('/'),\n                ),\n            ),\n        ],\n    })", "response": "Creates a manifest that can be used to create a basic authentication manifest for logging in and logging out."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Function(\n    library: CDLL,\n    name_or_ordinal: 'Union[str, int, None]'=None,\n    proto_factory: ('Union[ctypes.CFUNCTYPE, ctypes.WINFUNCTYPE,'\n                    ' ctypes.PYFUNCTYPE]')=CFUNCTYPE,\n    use_errno: bool=False,\n    use_last_error: bool=False,\n) -> 'Callable':\n    \"\"\"\n    Decorator factory for creating callables for native functions.\n\n    Decorator factory for constructing relatively-nicely-looking callables that\n    call into existing native functions exposed from a dynamically-linkable\n    library.\n\n    :param library:\n        The library to look at\n    :param name_or_ordinal:\n        Typically the name of the symbol to load from the library.  In rare\n        cases it may also be the index of the function inside the library.\n    :param proto_factory:\n        The prototype factory.\n    :param use_last_error:\n        Passed directly to the prototype factory.\n    :param use_last_error:\n        Passed directly to the prototype factory.\n    :returns:\n        A decorator for a function with particular, special annotations.\n\n    .. note::\n        Since nested functions have hard-to-reach documentation, the\n        documentation of the function returned from ``native()`` is documented\n        below.\n    \"\"\"\n    def decorator(fn: 'Callable') -> 'Callable':\n        metadata = _ctypes_metadata(fn)\n        prototype = proto_factory(\n            metadata.restype, *metadata.argtypes,\n            use_errno=use_errno, use_last_error=use_last_error)\n        func_spec = (name_or_ordinal or fn.__name__, library)\n        return prototype(func_spec, metadata.paramflags)\n    return decorator", "response": "Returns a function decorator that creates a function that returns a copy of the passed in object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the application component.", "response": "def run(self, make):\n        \"\"\"\n        Run the application component.\n        :param make: A factory that produces instances of :class:`autobahn.asyncio.wamp.ApplicationSession`\n           when called with an instance of :class:`autobahn.wamp.types.ComponentConfig`.\n        :type make: callable\n        \"\"\"\n\n        def _create_app_session():\n            cfg = ComponentConfig(self._realm, self._extra)\n            try:\n                session = make(cfg)\n            except Exception as e:\n                # the app component could not be created .. fatal\n                asyncio.get_event_loop().stop()\n                raise e\n            else:\n                session.debug_app = self._debug_app\n                return session\n\n        self._transport_factory = WampWebSocketClientFactory(_create_app_session, url=self._url, serializers=self._serializers)\n\n        if self._auto_ping_interval is not None and self._auto_ping_timeout is not None:\n            self._transport_factory.setProtocolOptions(openHandshakeTimeout=self._open_handshake_timeout, autoPingInterval=self._auto_ping_interval, autoPingTimeout=self._auto_ping_timeout)\n\n        txaio.use_asyncio()\n        txaio.config.loop = self._loop\n\n        asyncio.async(self._connect(), loop=self._loop)\n\n        try:\n            self._loop.add_signal_handler(signal.SIGTERM, self.stop)\n        except NotImplementedError:\n             # Ignore if not implemented. Means this program is running in windows.\n            pass\n\n        try:\n            self._loop.run_forever()\n        except KeyboardInterrupt:\n            # wait until we send Goodbye if user hit ctrl-c\n            # (done outside this except so SIGTERM gets the same handling)\n            pass\n\n        self._closing = True\n\n        if self._active_protocol and self._active_protocol._session:\n            self._loop.run_until_complete(self._active_protocol._session.leave())\n        self._loop.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lookup_device_name(self, vendor_id, device_id):\n        buf = ctypes.create_string_buffer(1024)\n        _logger.debug(\"Performing the lookup on vendor:device %#06x:%#06x\",\n                      vendor_id, device_id)\n        flags = self._flags | pci_lookup_mode.PCI_LOOKUP_DEVICE\n        pci_lookup_name2(self._access, buf, ctypes.sizeof(buf), flags,\n                         vendor_id, device_id)\n        return buf.value.decode(\"utf-8\")", "response": "Lookup the name of a given device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the name of a given subsystem device.", "response": "def lookup_subsystem_device_name(\n            self, vendor_id, device_id, subvendor_id, subdevice_id):\n        \"\"\"\n        Lookup the name of a given subsystem device.\n\n        :param vendor_id:\n            PCI vendor identifier\n        :ptype vendor_id:\n            int\n        :param device_id:\n            PCI device identifier\n        :ptype device_id:\n            int\n        :param subvendor_id:\n            PCI subvendor identifier\n        :ptype subvendor_id:\n            int\n        :param device_id:\n            PCI subdevice identifier\n        :ptype subdevice_id:\n            int\n        :returns:\n            Name of the PCI subsystem device.\n\n        .. note::\n            Lookup respects various flag properties that impact the behavior\n            in case the name cannot be found in the local database. Refer to\n            the documentation of each of the ``flag_`` properties.\n        \"\"\"\n        buf = ctypes.create_string_buffer(1024)\n        _logger.debug(\"Performing the lookup on vendor:device \"\n                      \"subvendor:subdevice %#06x:%#06x %#06x:%#06x\",\n                      vendor_id, device_id, subvendor_id, subdevice_id)\n        flags = self._flags | pci_lookup_mode.PCI_LOOKUP_SUBSYSTEM\n        flags = self._flags | pci_lookup_mode.PCI_LOOKUP_DEVICE\n        pci_lookup_name4(self._access, buf, ctypes.sizeof(buf), flags,\n                         vendor_id, device_id, subvendor_id, subdevice_id)\n        return buf.value.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserves a wsgi application through with werkzeug s runserver .", "response": "def serve(ip, port, application, ssl=None, processes=1, **kwargs):\n    \"\"\"\n    Serve a wsgi app (any wsgi app) through with either werkzeug's runserver\n    or the one that comes with python. Setting `processes` to anything other than 1\n    will prevent the debigger from working.\n    \"\"\"\n\n    try:\n        # use werkzeug if its there\n        from werkzeug.serving import run_simple\n        print(\"Using Werkzeug run_simple\")\n        run_simple(ip, port, application, ssl_context=ssl, processes=processes, **kwargs)\n        return\n    except ImportError:\n        pass\n\n    # otherwise just use python's built in wsgi webserver\n    from wsgiref.simple_server import make_server\n    server = make_server(ip, port, application)\n    print(\"Serving on %s:%s, using built in Python server\" % (ip, port))\n    try:\n        server.serve_forever()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_url(invocation, args=[], kwargs={}):\n    if not invocation.endswith('/'):\n        invocation += '/'\n    if not invocation.startswith('/'):\n        invocation = '/' + invocation\n\n    url = invocation\n\n    for arg in args:\n        url += str(arg) + \"/\"\n\n    if kwargs:\n        url = url[:-1]\n        url += \"?\" + urlencode(kwargs)\n    \n    return url", "response": "Make URL for a given invocation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_duplicate_request(request):\n    class FakeRequest(object):\n        method = 'GET'\n        path = request.path\n        headers = request.headers\n        GET = request.GET\n        POST = request.POST\n        user = getattr(request, 'user', None)\n        cookies = request.cookies\n        is_xhr = request.is_xhr\n    return FakeRequest()", "response": "Create a new request object that is identical to the passed in request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sig_handler(self, sig, _):\n        import tornado.ioloop\n        from tornado.process import task_id\n        tid = task_id()\n        pid = os.getpid()\n        if tid is None:\n            logger.warning(\"main process (pid %s) caught signal: %s\" %\n                           (pid, sig))\n        else:\n            logger.warning(\"child %s (pid %s) caught signal: %s\" %\n                           (tid, pid, sig))\n        tornado.ioloop.IOLoop.current().add_callback(self.shutdown)", "response": "Handle the signal sent to the process\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random value that fits this column s parameters.", "response": "def random(self):\n        \"\"\"\n        Returns a random value that fits this column's parameters.\n\n        :return: <variant>\n        \"\"\"\n        utc_now = datetime.datetime.utcnow()\n        return self.valueFromString(utc_now.strftime(self.defaultFormat()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a stored database value to Python.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Converts a stored database value to Python.\n\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if db_value is None:\n            return None\n        elif isinstance(db_value, (str, unicode)):\n            return self.valueFromString(db_value, context=context)\n        else:\n            return super(AbstractDatetimeColumn, self).dbRestore(db_value, context=context)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore the value of the n - ary column for the backend database.", "response": "def dbStore(self, typ, py_value, context=None):\n        \"\"\"\n        Prepares to store this column for the a particular backend database.\n\n        :param backend: <orb.Database>\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if py_value is None:\n            return None\n        return self.valueToString(py_value, context=context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the inputted string text to a value that matches the type from this column type.", "response": "def valueFromString(self, value, context=None):\n        \"\"\"\n        Converts the inputted string text to a value that matches the type from\n        this column type.\n\n        :param      value | <str>\n        \"\"\"\n        if value in ('today', 'now'):\n            return datetime.date.today()\n        elif dateutil_parser:\n            return dateutil_parser.parse(value).date()\n        else:\n            time_struct = time.strptime(value, self.defaultFormat())\n            return datetime.date(time_struct.tm_year,\n                                 time_struct.tm_month,\n                                 time_struct.tm_day)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstoring the value of the record in the backend database.", "response": "def dbStore(self, typ, py_value):\n        \"\"\"\n        Prepares to store this column for the a particular backend database.\n\n        :param backend: <orb.Database>\n        :param py_value: <variant>\n\n        :return: <variant>\n        \"\"\"\n        if isinstance(py_value, datetime.datetime):\n            # ensure we have some timezone information before converting to UTC time\n            if py_value.tzinfo is None:\n                # match the server information\n                tz = pytz.timezone(orb.system.settings().server_timezone)\n                py_value = tz.localize(py_value)\n            return py_value.astimezone(pytz.utc).replace(tzinfo=None)\n        else:\n            return super(DatetimeWithTimezoneColumn, self).dbStore(typ, py_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestores the value from a table cache for usage.", "response": "def restore(self, value, context=None):\n        \"\"\"\n        Restores the value from a table cache for usage.\n\n        :param      value   | <variant>\n                    context | <orb.Context> || None\n        \"\"\"\n        value = super(DatetimeWithTimezoneColumn, self).restore(value, context)\n\n        if value in ('today', 'now'):\n            value = datetime.date.now()\n\n        if isinstance(value, datetime.datetime):\n            tz = pytz.timezone(context.timezone)\n\n            if tz is not None:\n                if value.tzinfo is None:\n                    base_tz = pytz.timezone(orb.system.settings().server_timezone)\n\n                    # the machine timezone and preferred timezone match, so create off utc time\n                    if base_tz == tz:\n                        value = tz.fromutc(value)\n\n                    # convert the server timezone to a preferred timezone\n                    else:\n                        value = base_tz.fromutc(value).astimezone(tz)\n                else:\n                    value = value.astimezone(tz)\n            else:\n                log.warning('No local timezone defined')\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store(self, value, context=None):\n        if isinstance(value, datetime.datetime):\n            # ensure we have some timezone information before converting to UTC time\n            if value.tzinfo is None:\n                # match the server information\n                tz = pytz.timezone(orb.system.settings().server_timezone)\n                value = tz.localize(value)\n            value = value.astimezone(pytz.utc).replace(tzinfo=None)\n        return super(DatetimeWithTimezoneColumn, self).store(value, context=context)", "response": "Converts the value to one that is safe to store on a record within\n        the record values dictionary contains the record ID and the record ID of the record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dbRestore(self, db_value, context=None):\n        if isinstance(db_value, datetime.timedelta):\n            hours, remain = divmod(db_value.seconds, 3600)\n            minutes, seconds = divmod(remain, 60)\n            return datetime.time(hours, minutes, seconds)\n        else:\n            return super(TimeColumn, self).dbRestore(db_value, context=context)", "response": "Converts a stored database value to Python."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the inputted string text to a value that matches the type from this column type.", "response": "def valueFromString(self, value, context=None):\n        \"\"\"\n        Converts the inputted string text to a value that matches the type from\n        this column type.\n\n        :param      value | <str>\n        \"\"\"\n        if value == 'now':\n            return datetime.datetime.now().time()\n        elif dateutil_parser:\n            return dateutil_parser.parse(value).time()\n        else:\n            time_struct = time.strptime(value, self.defaultFormat())\n            return datetime.time(time_struct.tm_hour,\n                                 time_struct.tm_min,\n                                 time_struct.tm_sec)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef valueFromString(self, value, context=None):\n        if value in ('today', 'now'):\n            return datetime.datetime.utcnow()\n        elif dateutil_parser:\n            return dateutil_parser.parse(value)\n        else:\n            time_struct = time.strptime(value, self.defaultFormat())\n            return datetime.datetime(time_struct.tm_year,\n                                     time_struct.tm_month,\n                                     time_struct.tm_day,\n                                     time_struct.tm_hour,\n                                     time_struct.tm_minute,\n                                     time_struct.tm_sec)", "response": "Converts the inputted string text to a value that matches the type from\n        this column type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrestore the value from a table cache for usage.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Restores the value from a table cache for usage.\n\n        :param      value   | <variant>\n                    context | <orb.Context> || None\n        \"\"\"\n        if isinstance(db_value, (int, long, float)):\n            return datetime.datetime.fromtimestamp(db_value)\n        else:\n            return super(UTC_TimestampColumn, self).dbRestore(db_value, context=context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the value to one that is safe to store on a record within the record within the specified record.", "response": "def dbStore(self, typ, py_value):\n        \"\"\"\n        Converts the value to one that is safe to store on a record within\n        the record values dictionary\n\n        :param      value | <variant>\n\n        :return     <variant>\n        \"\"\"\n        if isinstance(py_value, datetime.datetime):\n            return time.mktime(py_value.timetuple())\n        else:\n            return super(UTC_TimestampColumn, self).dbStore(typ, py_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valueFromString(self, value, context=None):\n        if value in ('today', 'now'):\n            return datetime.date.utcnow()\n\n        try:\n            return datetime.datetime.fromtimestamp(float(value))\n        except StandardError:\n            if dateutil_parser:\n                return dateutil_parser.parse(value)\n            else:\n                return datetime.datetime.min()", "response": "Converts the inputted string text to a value that matches the type from\n        this column type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the given user agent is mobile.", "response": "def is_mobile(user_agent):\n    \"\"\" Checks if the user browser from the given user agent is mobile.\n\n    Args:\n        user_agent: A given user agent.\n\n    Returns: True if the browser from the user agent is mobile.\n\n    \"\"\"\n    if user_agent:\n        b = reg_b.search(user_agent)\n        v = reg_v.search(user_agent[0:4])\n        return b or v\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of command arguments to be executed in the specified invocation.", "response": "def make_cmd_invocation(invocation, args, kwargs):\n    \"\"\"\n    >>> make_cmd_invocation('path/program', ['arg1', 'arg2'], {'darg': 4})\n    ['./giotto-cmd', '/path/program/arg1/arg2/', '--darg=4']\n    \"\"\"\n    if not invocation.endswith('/'):\n        invocation += '/'\n    if not invocation.startswith('/'):\n        invocation = '/' + invocation\n\n    cmd = invocation\n\n    for arg in args:\n        cmd += str(arg) + \"/\"\n\n    rendered_kwargs = []\n    for k, v in kwargs.items():\n        rendered_kwargs.append(\"--%s=%s\" % (k,v))\n    \n    return ['./giotto-cmd', cmd] + rendered_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_raw_data(self):\n        arguments = self.request.argv[1:]\n        if not arguments[0].startswith('--'):\n            # first argument is the program name\n            arguments = arguments[1:]\n        return parse_kwargs(arguments)", "response": "Parse the raw commandline arguments to a dictionary containing the key - value pairs that can be used to identify the class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        properties = {}\n        for key, value in self.raw_values.items():\n            if key in self.UnhashableOptions:\n                properties[key] = value\n            else:\n                properties[key] = copy.copy(value)\n\n        return Context(**properties)", "response": "Returns a copy of this database option set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expandtree(self, model=None):\n        if model and not self.columns:\n            schema = model.schema()\n            defaults = schema.columns(flags=orb.Column.Flags.AutoExpand).keys()\n            defaults += schema.collectors(flags=orb.Collector.Flags.AutoExpand).keys()\n        else:\n            defaults = []\n\n        expand = self.expand or defaults\n        if not expand:\n            return {}\n\n        def build_tree(parts, tree):\n            tree.setdefault(parts[0], {})\n            if len(parts) > 1:\n                build_tree(parts[1:], tree[parts[0]])\n\n        tree = {}\n        for branch in expand:\n            build_tree(branch.split('.'), tree)\n\n        return tree", "response": "Returns a trie of data for this context and the given model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether or not this option set has been modified.", "response": "def isNull(self):\n        \"\"\"\n        Returns whether or not this option set has been modified.\n\n        :return     <bool>\n        \"\"\"\n        check = self.raw_values.copy()\n        scope = check.pop('scope', {})\n        return len(check) == 0 and len(scope) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, other_context):\n        # convert a context instance into a dictionary\n        if isinstance(other_context, orb.Context):\n            other_context = copy.copy(other_context.raw_values)\n\n        ignore = ('where', 'columns', 'scope')\n        inherit_kwds = {}\n        inherit_scope = {}\n        inherit_columns = []\n        inherit_where = orb.Query()\n\n        # update from the base context\n        base_context = other_context.pop('context', None)\n        if base_context is not None:\n            inherit_kwds = base_context.raw_values\n\n        # use the default contexts\n        else:\n            for default in self.defaultContexts():\n                if default is not None:\n                    # extract expandable information\n                    for k, v in default.raw_values.items():\n                        if k not in ignore:\n                            inherit_kwds[k] = copy.copy(v)\n\n                    # merge where queries\n                    where = default.where\n                    if where is not None:\n                        inherit_where &= where\n\n                    # merge column queries\n                    columns = default.columns\n                    if columns is not None:\n                        inherit_columns += list(columns)\n\n                    # merge scope\n                    scope = default.scope\n                    if scope:\n                        inherit_scope.update(scope)\n\n        # update the inherited kwds\n        for k, v in inherit_kwds.items():\n            other_context.setdefault(k, v)\n\n        # update the inherited query\n        if inherit_where:\n            other_context.setdefault('where', orb.Query())\n            other_context['where'] &= inherit_where\n\n        # update the inherited columns\n        if inherit_columns:\n            other_context['columns'] = inherit_columns + (other_context.get('columns') or [])\n\n        # update the inherited scope\n        if inherit_scope:\n            new_scope = {}\n            new_scope.update(inherit_scope)\n            new_scope.update(other_context.get('scope') or {})\n            other_context['scope'] = new_scope\n\n        # convert the columns to a list\n        if 'columns' in other_context and isinstance(other_context['columns'], (str, unicode)):\n            other_context['columns'] = other_context['columns'].split(',')\n\n        # convert where to query\n        where = other_context.get('where')\n        if isinstance(where, dict):\n            other_context['where'] = orb.Query.fromJSON(where)\n\n        if isinstance(where, (orb.Query, orb.QueryCompound)):\n            other_context['where'] &= self.where\n\n        # validate values\n        if other_context.get('start') is not None and (type(other_context['start']) != int or other_context['start'] < 0):\n            msg = 'Start needs to be a positive number, got {0} instead'\n            raise orb.errors.ContextError(msg.format(other_context.get('start)')))\n        if other_context.get('page') is not None and (type(other_context['page']) != int or other_context['page'] < 1):\n            msg = 'Page needs to be a number equal to or greater than 1, got {0} instead'\n            raise orb.errors.ContextError(msg.format(other_context.get('page')))\n        if other_context.get('limit') is not None and (type(other_context['limit']) != int or other_context['limit'] < 1):\n            msg = 'Limit needs to be a number equal to or greater than 1, got {0} instead'\n            raise orb.errors.ContextError(msg.format(other_context.get('limit')))\n        if other_context.get('pageSize') is not None and (type(other_context['pageSize']) != int or other_context['pageSize'] < 1):\n            msg = 'Page size needs to be a number equal to or greater than 1, got {0} instead'\n            raise orb.errors.ContextError(msg.format(other_context.get('pageSize')))\n\n        # update the raw values\n        self.raw_values.update({k: v for k, v in other_context.items() if k in self.Defaults})", "response": "Updates this lookup set with the inputted options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_module(module, target):\n    module_x = module.split('.')\n    cur_path = ''\n    for path in module_x:\n        cur_path = os.path.join(cur_path, path)\n        if not os.path.isdir(os.path.join(target, cur_path)):\n            os.mkdir(os.path.join(target, cur_path))\n        if not os.path.exists(os.path.join(target, cur_path, '__init__.py')):\n            touch(os.path.join(target, cur_path, '__init__.py'))\n    return cur_path", "response": "Create a module directory structure into the target directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_file_extension(filename):\n    filename_x = filename.split('.')\n    if len(filename_x) > 1:\n        if filename_x[-1].strip() is not '':\n            return filename_x[-1]\n    return None", "response": "Returns the extension of the file if it has one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(path, data, binary=False):\n    mode = \"w\"\n    if binary:\n        mode = \"wb\"\n    with open(path, mode) as f:\n        f.write(data)\n    f.close()", "response": "Writes a given data to a file located at the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a file located at the given path.", "response": "def read(path):\n    \"\"\" Reads a file located at the given path. \"\"\"\n    data = None\n    with open(path, 'r') as f:\n        data = f.read()\n    f.close()\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef touch(path):\n    with open(path, 'a') as f:\n        os.utime(path, None)\n    f.close()", "response": "Creates a file located at the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valueFromString(self, value, extra=None, db=None):\n        return projex.text.nativestring(value).lower() == 'true'", "response": "Converts the inputted string text to a value that matches the type from\n        this column type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclean the value before storing it.", "response": "def clean(self, py_value):\n        \"\"\"\n        Cleans the value before storing it.\n\n        :param:     py_value : <str>\n\n        :return:    <str>\n        \"\"\"\n        try:\n            from webhelpers.text import strip_tags\n            return strip_tags(py_value)\n        except ImportError:\n            warnings.warn('Unable to clean string column without webhelpers installed.')\n            return py_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dbStore(self, typ, py_value):\n        if py_value is not None:\n            py_value = projex.text.decoded(py_value)\n\n            if self.cleaned():\n                py_value = self.clean(py_value)\n\n            if self.escaped():\n                py_value = self.escape(py_value)\n\n            return py_value\n        else:\n            return py_value", "response": "Stores the value of the n - ary column for the given backend database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore(self, value, context=None):\n        # ensure this value is a string type\n        if isinstance(value, (str, unicode)):\n            value = projex.text.decoded(value)\n\n        return super(AbstractStringColumn, self).restore(value, context)", "response": "Restores the value from a table cache for usage."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store(self, value, context=None):\n        if isinstance(value, (str, unicode)) and self.testFlag(self.Flags.Encrypted):\n            value = orb.system.security().encrypt(value)\n\n        return super(AbstractStringColumn, self).store(value, context=context)", "response": "Converts the value to one that is safe to store on a record within the record values dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the JSON data for this column type.", "response": "def loadJSON(self, jdata):\n        \"\"\"\n        Loads JSON data for this column type.\n\n        :param jdata: <dict>\n        \"\"\"\n        super(StringColumn, self).loadJSON(jdata)\n\n        # load additional info\n        self.__maxLength = jdata.get('maxLength') or self.__maxLength"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random(self):\n        return '#' + random.randrange(256).encode('hex') + \\\n               random.randrange(256).encode('hex') + random.randrange(256).encode('hex')", "response": "Returns a random value that fits this column s parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, value):\n        if isinstance(value, (str, unicode)) and not re.match(self.__pattern, value):\n            raise orb.errors.ColumnValidationError(self, 'The email provided is not valid.')\n        else:\n            return super(EmailColumn, self).validate(value)", "response": "Validates the value provided is a valid email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean(self, py_value):\n        try:\n            import bleach\n            return bleach.clean(py_value, **self.__bleachOptions)\n        except ImportError:\n            warnings.warn('Unable to clean string column without webhelpers installed.')\n            return py_value", "response": "Cleans the value before storing it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the rules for this password based on the configured options.", "response": "def rules(self):\n        \"\"\"\n        Returns the rules for this password based on the configured\n        options.\n\n        :return: <str>\n        \"\"\"\n        rules = ['Passwords need to be at least {0} characters long'.format(self.__minlength)]\n\n        if self.__requireUppercase:\n            rules.append('have at least one uppercase letter')\n        if self.__requireLowercase:\n            rules.append('have at least one lowercase letter')\n        if self.__requireNumber:\n            rules.append('have at least one number')\n        if self.__requireWildcard:\n            rules.append('have at least one non alpha-number character')\n\n        if len(rules) == 1:\n            return rules[0]\n        else:\n            return ', '.join(rules[:-1]) + ' and ' + rules[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the password follows the following criteria.", "response": "def validate(self, value):\n        \"\"\"\n        Ensures that the password follows the following criteria:\n\n        :param value: <str>\n\n        :return: True\n        \"\"\"\n        if not isinstance(value, (str, unicode)):\n            raise orb.errors.ColumnValidationError(self, 'Invalid password.')\n\n        elif not self.__allowUnicode and value != projex.text.toAscii(value):\n            raise orb.errors.ColumnValidationError(self, 'Only ASCII characters are allowed for your password.')\n\n        elif len(value) < self.__minlength or \\\n                (self.__requireUppercase and not re.search('[A-Z]', value)) or \\\n                (self.__requireLowercase and not re.search('[a-z]', value)) or \\\n                (self.__requireNumber and not re.search('[0-9]', value)) or \\\n                (self.__requireWildcard and not re.search('[^a-zA-Z0-9]', value)):\n            raise orb.errors.ColumnValidationError(self, self.rules())\n\n        # check for invalid characters\n        elif self.__invalidCharacters and re.search(self.__invalidCharacters, value):\n            raise orb.errors.ColumnValidationError(self, self.__invalidCharactersRule)\n\n        else:\n            return super(PasswordColumn, self).validate(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate(self):\n        try:\n            model = self.schema().model()\n        except AttributeError:\n            return os.urandom(self.__bits).encode('hex')\n        else:\n            while True:\n                token = os.urandom(self.__bits).encode('hex')\n                if model.select(where=orb.Query(self) == token).count() == 0:\n                    return token", "response": "Generates a new token for this column based on its bit length."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart monitoring for hanging threads.", "response": "def start_monitoring(seconds_frozen=SECONDS_FROZEN,\n                     test_interval=TEST_INTERVAL):\n    \"\"\"Start monitoring for hanging threads.\n\n    seconds_frozen - How much time should thread hang to activate\n    printing stack trace - default(10)\n\n    tests_interval - Sleep time of monitoring thread (in milliseconds) \n    - default(100)\n    \"\"\"\n    \n    thread = StoppableThread(target=monitor, args=(seconds_frozen,\n                                                   test_interval))\n    thread.daemon = True\n    thread.start()\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef monitor(seconds_frozen, test_interval):\n    current_thread = threading.current_thread()\n    hanging_threads = set()\n    old_threads = {}  # Threads found on previous iteration.\n\n    while not current_thread.is_stopped():\n        new_threads = get_current_frames()\n\n        # Report died threads.\n        for thread_id in old_threads.keys():\n            if thread_id not in new_threads and thread_id in hanging_threads:\n                log_died_thread(thread_id)\n\n        # Process live threads.\n        time.sleep(test_interval/1000.)\n        now = time.time()\n        then = now - seconds_frozen\n        for thread_id, thread_data in new_threads.items():\n            # Don't report the monitor thread.\n            if thread_id == current_thread.ident:\n                continue\n            frame = thread_data['frame']\n            # If thread is new or it's stack is changed then update time.\n            if (thread_id not in old_threads or\n                    frame != old_threads[thread_id]['frame']):\n                thread_data['time'] = now\n                # If the thread was hanging then report awaked thread.\n                if thread_id in hanging_threads:\n                    hanging_threads.remove(thread_id)\n                    log_awaked_thread(thread_id)\n            else:\n                # If stack is not changed then keep old time.\n                last_change_time = old_threads[thread_id]['time']\n                thread_data['time'] = last_change_time\n                # Check if this is a new hanging thread.\n                if (thread_id not in hanging_threads and\n                        last_change_time < then):\n                    # Gotcha!\n                    hanging_threads.add(thread_id)\n                    # Report the hanged thread.\n                    log_hanged_thread(thread_id, frame)\n        old_threads = new_threads", "response": "Monitoring thread function.\n\n    Checks if thread is hanging for time defined by\n    ``seconds_frozen`` parameter every ``test_interval`` milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn current threads prepared for further processing.", "response": "def get_current_frames():\n    \"\"\"Return current threads prepared for \n    further processing.\n    \"\"\"\n    return dict(\n        (thread_id, {'frame': thread2list(frame), 'time': None})\n        for thread_id, frame in sys._current_frames().items()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frame2string(frame):\n\n    lineno = frame.f_lineno  # or f_lasti\n    co = frame.f_code\n    filename = co.co_filename\n    name = co.co_name\n    s = '\\tFile \"{0}\", line {1}, in {2}'.format(filename, lineno, name)\n    line = linecache.getline(filename, lineno, frame.f_globals).lstrip()\n    return s + '\\n\\t\\t' + line", "response": "Return info about frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns list with string frame representation of each frame of thread.", "response": "def thread2list(frame):\n    \"\"\"Return list with string frame representation of each frame of \n    thread.\n    \"\"\"\n    l = []\n    while frame:\n        l.insert(0, frame2string(frame))\n        frame = frame.f_back\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites formatted log message to stderr.", "response": "def write_log(title, message=''):\n    \"\"\"Write formatted log message to stderr.\"\"\"\n\n    sys.stderr.write(''.join([\n        title.center(40).center(60, '-'), '\\n', message\n    ]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle(self, *args, **options):\n\n        def get_user(username):\n            try:\n                return User.objects.get(username=username)\n            except ObjectDoesNotExist as e:\n                raise CommandError(\"This user doesn't exist in the database\")\n\n        def add_permissions(user_field_permissions, content_type, name):\n\n            p = None\n            try:\n                p = FieldPermission.objects.get(content_type=content_type, name=name)\n            except ObjectDoesNotExist:\n                p = FieldPermission(content_type=content_type, name=name)\n                p.save()\n            finally:\n                user_field_permissions.permissions.add(p)\n\n\n\n        if len(args) !=1:\n             raise CommandError(\"Specifies a json file created by the fine_permissions_dump command\")\n        else:\n            try:\n\n\n                with open(args[0], 'r') as json_file:\n                    myjson = json.load(json_file)\n\n                    user = get_user(options.get('user')) if options['user'] else get_user(myjson['username'])\n                    fields_permissions = myjson['fields_permissions']\n\n                    user_field_permissions = UserFieldPermissions(user=user)\n                    user_field_permissions.save()\n\n                    for f in fields_permissions:\n                        content_type = ContentType.objects.get(app_label=f[\"app_label\"], model=f[\"model\"])\n                        add_permissions(user_field_permissions, content_type, f['name'])\n\n\n            except Exception as e:\n                raise CommandError(e)", "response": "Dump fields permissions for a user"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninspect the model and return the args and kwargs.", "response": "def get_model_args_kwargs(self):\n        \"\"\"\n        Inspect the model (or view in the case of no model) and return the args\n        and kwargs. This functin is necessary because argspec returns in a silly format\n        by default.\n        \"\"\"\n        source = self.get_model()\n        if not source:\n            return [], {}\n\n        argspec = inspect.getargspec(source)\n        \n        kk = list(zip(*[reversed(l) for l in (argspec.args, argspec.defaults or [])]))\n        kk.reverse()\n        kwargs = OrderedDict(kk)\n        args = [x for x in argspec.args if x not in kwargs.keys()]\n        if args and args[0] == 'cls':\n            args = args[1:]\n        return args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes input middleware stream.", "response": "def execute_input_middleware_stream(self, request, controller):\n        \"\"\"\n        Request comes from the controller. Returned is a request.\n        controller arg is the name of the controller.\n        \"\"\"\n        start_request = request\n        # either 'http' or 'cmd' or 'irc'\n        controller_name = \"\".join(controller.get_controller_name().split('-')[:1])\n        middlewares = list(self.pre_input_middleware) + list(self.input_middleware)\n        for m in middlewares:\n            to_execute = getattr(m(controller), controller_name)\n            if to_execute:\n                result = to_execute(request)\n                if GiottoControl in type(result).mro():\n                    # a middleware class returned a control object (redirection, et al.)\n                    # ignore all other middleware classes\n                    return request, result\n                request = result\n        return start_request, request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all valid urls for this manifest.", "response": "def get_urls(self, controllers=None, prefix_path=''):\n        \"\"\"\n        Return a list of all valid urls (minus args and kwargs, just the program paths)\n        for this manifest. If a single program has two urls, both will be returned.\n        \"\"\"\n        tag_match = lambda program: set(program.controllers) & set(controllers or [])\n        urls = set()\n\n        for key, value in self.manifest.items():\n\n            path = \"%s/%s\" % (prefix_path, key)\n\n            if path.endswith('/') and prefix_path:\n                path = path[:-1]\n\n            if hasattr(value, 'lower'):\n                # is a string redirect\n                urls.add(path)\n\n            elif isinstance(value, Manifest):\n                # is manifest\n                pp = '' if path == '/' else path # for 'stacked' root programs.\n                new_urls = value.get_urls(controllers=controllers, prefix_path=pp)\n                urls.update(new_urls)\n\n            elif isinstance(value, Program):\n                # make a list so we can iterate through it in the next `if` block\n                value = [value]\n\n            if hasattr(value, 'append'):\n                # defined is multiple programs, get the one for this controller tag.\n                for program in value:\n                    if not program.controllers or not controllers:\n                        # no controllers defined on program. Always add.\n                        # or no tags defined for this get_urls call. Always add.\n                        urls.add(path)\n                    elif tag_match(program):\n                        urls.add(path)\n\n        return urls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_suggestions(self, filter_word=None):\n        keys = self.manifest.keys()\n        words = []\n        for key in keys:            \n            if isinstance(self.manifest[key], Manifest):\n                # if this key is another manifest, append a slash to the \n                # suggestion so the user knows theres more items under this key\n                words.append(key + '/')\n            else:\n                words.append(key)\n\n        if filter_word:\n            words = [x for x in words if x.startswith(filter_word)]\n\n        return words", "response": "This method returns a list of all the suggestions that are available in the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning suggestions for a path. Used in tab completion from the commandline line.", "response": "def get_suggestion(self, front_path):\n        \"\"\"\n        Returns suggestions for a path. Used in tab completion from the command\n        line.\n        \"\"\"\n        if '/' in front_path:\n            # transverse the manifest, return the new manifest, then\n            # get those suggestions with the remaining word\n            splitted = front_path.split('/')\n            new_manifest = self.manifest\n            pre_path = ''\n            for item in splitted:\n                try:\n                    new_manifest = new_manifest[item]\n                except KeyError:\n                    partial_word = item\n                    break\n                else:\n                    pre_path += item + '/'\n\n            if isinstance(new_manifest, Program):\n                return []\n            matches = new_manifest._get_suggestions(partial_word)\n            return [pre_path + match for match in matches]\n        else:\n            return self._get_suggestions(front_path or None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the program that matches the given path.", "response": "def get_program(self, program_path, controller=None):\n        \"\"\"\n        Find the program within this manifest. If key is found, and it contains\n        a list, iterate over the list and return the program that matches\n        the controller tag. NOTICE: program_path must have a leading slash.\n        \"\"\"\n        if not program_path or program_path[0] != '/':\n            raise ValueError(\"program_path must be a full path with leading slash\")\n\n        items = program_path[1:].split('/')\n        result = self\n        for item in items:\n            result = result[item]\n\n        if hasattr(result, \"lower\"):\n            # string redirect\n            return self.get_program(result)\n\n        elif type(result) is Manifest:\n            return result.get_program('/')\n\n        elif hasattr(result, 'append'):\n            matching_blank = []\n            for program in result:\n                if controller in program.controllers:\n                    return program\n            \n                if not program.controllers or not controller:\n                    # no exact matching controllers for this program.\n                    # Use the first controller with no\n                    matching_blank.append(program)\n            if matching_blank:\n                return matching_blank[0]\n            else:\n                raise ProgramNotFound(\"No matcning program for %s controller\" % controller)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_invocation(self, invocation, controller_tag):\n        if invocation.endswith('/'):\n            invocation = invocation[:-1]\n        if not invocation.startswith('/'):\n            invocation = '/' + invocation\n        if invocation == '':\n            invocation = '/'\n\n        all_programs = self.get_urls(controllers=[controller_tag])\n\n        matching_paths = set()\n        for program_path in sorted(all_programs):\n            if invocation.startswith(program_path):\n                matching_paths.add(program_path)\n\n        longest = \"\"\n        for path in matching_paths:\n            longest = path if len(path) > len(longest) else longest\n\n        matching_path = longest\n\n        program = self.get_program(matching_path, controller=controller_tag)\n\n        if not matching_path:\n            raise ProgramNotFound(\"Can't find %s\" % invocation)\n\n        program_name = matching_path.split('/')[-1]\n        path = \"/\".join(matching_path.split('/')[:-1]) + '/'\n        args_fragment = invocation[len(matching_path):]\n\n        superformat = None\n        if args_fragment.startswith('.'):\n            # args_fragment will be something like \".html/arg1/arg2\" or just \".html\"\n            superformat = args_fragment.split('/')[0][1:]\n            args = args_fragment.split('/')[1:]\n            args_fragment = '/'.join(args)\n        else:\n            args = args_fragment.split(\"/\")[1:] if args_fragment else []\n            args_fragment = args_fragment[1:] if (args_fragment and args_fragment[0] =='/') else args_fragment\n\n        return {\n            'program': program,\n            'program_name': program_name,\n            'superformat': superformat,\n            'superformat_mime': super_accept_to_mimetype(superformat),\n            'args': args,\n            'raw_args': args_fragment,\n            'path': path,\n            'invocation': invocation,\n        }", "response": "Given an invocation string determine which part is the path the program name the args and the raw_args."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self):\n        out = type(self)(\n            name=self.__name,\n            field=self.__field,\n            display=self.__display,\n            flags=self.__flags,\n            default=self.__default,\n            defaultOrder=self.__defaultOrder,\n            getter=self.__gettermethod,\n            setter=self.__settermethod,\n            queryFilter=self.__query_filter,\n            shortcut=self.__shortcut,\n            readPermit=self.__readPermit,\n            writePermit=self.__writePermit,\n            order=self.__order\n        )\n\n        return out", "response": "Returns a copy of this column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a stored database value to Python.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Converts a stored database value to Python.\n\n        :param typ: <str>\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        # restore translatable column\n        if self.testFlag(self.Flags.I18n):\n            if isinstance(db_value, (str, unicode)):\n                if db_value.startswith('{'):\n                    try:\n                        value = projex.text.safe_eval(db_value)\n                    except StandardError:\n                        value = {context.locale: db_value}\n                else:\n                    value = {context.locale: db_value}\n            else:\n                value = db_value\n\n            return value\n        else:\n            return db_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform some database math on the given field. This will be database specific implementations and should return the resulting database operation. :param field: <str> :param op: <orb.Query.Math> :param target: <variant> :param context: <orb.Context> || None :return: <str>", "response": "def dbMath(self, typ, field, op, value):\n        \"\"\"\n        Performs some database math on the given field.  This will be database specific\n        implementations and should return the resulting database operation.\n\n        :param field: <str>\n        :param op: <orb.Query.Math>\n        :param target: <variant>\n        :param context: <orb.Context> || None\n\n        :return: <str>\n        \"\"\"\n        ops = orb.Query.Math(op)\n        format = self.MathMap.get(typ, {}).get(ops) or self.MathMap.get('Default').get(ops) or '{field}'\n        return format.format(field=field, value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dbStore(self, typ, py_value):\n        # convert base types to work in the database\n        if isinstance(py_value, (list, tuple, set)):\n            py_value = tuple((self.dbStore(x) for x in py_value))\n        elif isinstance(py_value, orb.Collection):\n            py_value = py_value.ids()\n        elif isinstance(py_value, orb.Model):\n            py_value = py_value.id()\n\n        return py_value", "response": "Stores the base types of the database for the given backend and context."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the database object type based on the given connection type.", "response": "def dbType(self, typ):\n        \"\"\"\n        Returns the database object type based on the given connection type.\n\n        :param typ:  <str>\n\n        :return: <str>\n        \"\"\"\n        return self.TypeMap.get(typ, self.TypeMap.get('Default'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default(self):\n        if isinstance(self.__default, (str, unicode)):\n            return self.valueFromString(self.__default)\n        else:\n            return self.__default", "response": "Returns the default value for this column to return\n        when generating new instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the name of the column that this column will have inside the database.", "response": "def field(self):\n        \"\"\"\n        Returns the field name that this column will have inside the database.\n\n        :return     <str>\n        \"\"\"\n        if not self.__field:\n            default_field = inflection.underscore(self.__name)\n            if isinstance(self, orb.ReferenceColumn):\n                default_field += '_id'\n            self.__field = default_field\n\n        return self.__field or default_field"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the first schema in the list that this column is a member of.", "response": "def firstMemberSchema(self, schemas):\n        \"\"\"\n        Returns the first schema within the list that this column is a member\n        of.\n\n        :param      schemas | [<orb.TableSchema>, ..]\n\n        :return     <orb.TableSchema> || None\n        \"\"\"\n        for schema in schemas:\n            if schema.hasColumn(self):\n                return schema\n        return self.schema()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef isMemberOf(self, schemas):\n        if type(schemas) not in (tuple, list, set):\n            schemas = (schemas,)\n\n        for schema in schemas:\n            if schema.hasColumn(self):\n                return True\n        return False", "response": "Returns whether or not this column is a member of any of the given schemas."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadJSON(self, jdata):\n        # required params\n        self.__name = jdata['name']\n        self.__field = jdata['field']\n\n        # optional fields\n        self.__display = jdata.get('display') or self.__display\n        self.__flags = jdata.get('flags') or self.__flags\n        self.__defaultOrder = jdata.get('defaultOrder') or self.__defaultOrder\n        self.__default = jdata.get('default') or self.__default", "response": "Initializes the information for this class from the given JSON data blob."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestores the value from a table cache for usage.", "response": "def restore(self, value, context=None, inflated=True):\n        \"\"\"\n        Restores the value from a table cache for usage.\n\n        :param      value   | <variant>\n                    context | <orb.Context> || None\n        \"\"\"\n        context = context or orb.Context()\n\n        # check to see if this column is translatable before restoring\n        if self.testFlag(self.Flags.I18n):\n            locales = context.locale.split(',')\n\n            if not isinstance(value, dict):\n                default_locale = locales[0]\n                if default_locale == 'all':\n                    default_locale = orb.system.settings().default_locale\n                value = {default_locale: value}\n\n            if 'all' in locales:\n                return value\n\n            if len(locales) == 1:\n                return value.get(locales[0])\n            else:\n                return {locale: value.get(locale) for locale in locales}\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the value to one that is safe to store on a record within the record values dictionary containing the internationalized property.", "response": "def store(self, value, context=None):\n        \"\"\"\n        Converts the value to one that is safe to store on a record within\n        the record values dictionary\n\n        :param      value | <variant>\n\n        :return     <variant>\n        \"\"\"\n        if isinstance(value, (str, unicode)):\n            value = self.valueFromString(value)\n\n        # store the internationalized property\n        if self.testFlag(self.Flags.I18n):\n            if not isinstance(value, dict):\n                context = context or orb.Context()\n                return {context.locale: value}\n            else:\n                return value\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setFlag(self, flag, state=True):\n        if state:\n            self.__flags |= flag\n        else:\n            self.__flags &= ~flag", "response": "Sets whether or not this flag should be on."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(self, value):\n        # check for the required flag\n        if self.testFlag(self.Flags.Required) and not self.testFlag(self.Flags.AutoAssign):\n            if self.isNull(value):\n                msg = '{0} is a required column.'.format(self.name())\n                raise orb.errors.ColumnValidationError(self, msg)\n\n        # otherwise, we're good\n        return True", "response": "Validates the inputted value against this columns rules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new column from the given json data.", "response": "def fromJSON(cls, jdata):\n        \"\"\"\n        Generates a new column from the given json data.  This should\n        be already loaded into a Python dictionary, not a JSON string.\n\n        :param      jdata | <dict>\n\n        :return     <orb.Column> || None\n        \"\"\"\n        cls_type = jdata.get('type')\n        col_cls = cls.byName(cls_type)\n\n        if not col_cls:\n            raise orb.errors.ColumnTypeNotFound(cls_type)\n        else:\n            col = col_cls()\n            col.loadJSON(jdata)\n            return col"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ancestry(self):\n        if not self.inherits():\n            return []\n\n        schema = orb.system.schema(self.inherits())\n        if not schema:\n            return []\n\n        return schema.ancestry() + [schema]", "response": "Returns the list of tables that this instance is ancestry of."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addColumn(self, column):\n        column.setSchema(self)\n        self.__columns[column.name()] = column", "response": "Adds the inputted column to this table schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the inputted index to this table schema.", "response": "def addIndex(self, index):\n        \"\"\"\n        Adds the inputted index to this table schema.\n\n        :param      index   | <orb.Index>\n        \"\"\"\n        index.setSchema(self)\n        self.__indexes[index.name()] = index"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the inputted collector reference to this table schema.", "response": "def addCollector(self, collector):\n        \"\"\"\n        Adds the inputted collector reference to this table schema.\n\n        :param      collector | <orb.Collector>\n        \"\"\"\n        collector.setSchema(self)\n        self.__collectors[collector.name()] = collector"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collector(self, name, recurse=True):\n        return self.collectors(recurse=recurse).get(name)", "response": "Returns the collector that matches the inputted name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collectors(self, recurse=True, flags=0):\n        output = {}\n        if recurse and self.inherits():\n            schema = orb.system.schema(self.inherits())\n            if not schema:\n                raise orb.errors.ModelNotFound(schema=self.inherits())\n            else:\n                iflags = (flags & ~orb.Collector.Flags.Virtual) if flags else ~orb.Collector.Flags.Virtual\n                output.update(schema.collectors(recurse=recurse, flags=iflags))\n        output.update({c.name(): c for c in self.__collectors.values() if not flags or c.testFlag(flags)})\n        return output", "response": "Returns a list of the collectors for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef column(self, key, recurse=True, flags=0, raise_=True):\n        if isinstance(key, orb.Column):\n            return key\n        else:\n            cache_key = (key, recurse, flags)\n            try:\n                last_column = self.__cache[cache_key]\n            except KeyError:\n\n                parts = key.split('.')\n                schema = self\n                last_column = None\n\n                for part in parts:\n                    cols = schema.columns(recurse=recurse, flags=flags)\n                    found = None\n\n                    for column in cols.values():\n                        if part in (column.name(), column.field()):\n                            found = column\n                            break\n\n                    if found is None:\n                        break\n\n                    elif isinstance(found, orb.ReferenceColumn):\n                        schema = found.referenceModel().schema()\n\n                    last_column = found\n\n                self.__cache[cache_key] = last_column\n\n            # return the column response\n            if last_column is not None:\n                return last_column\n            elif raise_:\n                raise orb.errors.ColumnNotFound(schema=self, column=key)\n            else:\n                return None", "response": "Returns the column instance based on its name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of column instances that are defined by this table instance.", "response": "def columns(self, recurse=True, flags=0):\n        \"\"\"\n        Returns the list of column instances that are defined\n        for this table schema instance.\n        \n        :param      recurse | <bool>\n                    flags   | <orb.Column.Flags>\n                    kind    | <orb.Column.Kind>\n        \n        :return     {<str> column name: <orb.Column>, ..}\n        \"\"\"\n        key = (recurse, flags)\n        try:\n            return self.__cache[key]\n        except KeyError:\n\n            output = odict()\n\n            if recurse:\n                inherits = self.inherits()\n                if inherits:\n                    schema = orb.system.schema(inherits)\n                    if not schema:\n                        raise orb.errors.ModelNotFound(schema=inherits)\n                    else:\n                        # lookup ancestor columns (don't care about virtual columns)\n                        iflags = (flags & ~orb.Column.Flags.Virtual) if flags else ~orb.Column.Flags.Virtual\n                        ancest_columns = schema.columns(recurse=recurse, flags=iflags)\n                        dups = set(ancest_columns.keys()).intersection(output.keys())\n                        if dups:\n                            raise orb.errors.DuplicateColumnFound(schema=self, column=','.join(dups))\n                        else:\n                            output.update(ancest_columns)\n\n            output.update(odict(\n                (col.name(), col) for col\n                in sorted(self.__columns.values(), key=lambda x: x.order())\n                if (not flags or col.testFlag(flags))\n            ))\n\n            self.__cache[key] = output\n            return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether or not this column exists within the list of columns for this schema.", "response": "def hasColumn(self, column, recurse=True, flags=0):\n        \"\"\"\n        Returns whether or not this column exists within the list of columns\n        for this schema.\n        \n        :return     <bool>\n        \"\"\"\n        return column in self.columns(recurse=recurse, flags=flags)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of indexes that are associated with this schema.", "response": "def indexes(self, recurse=True):\n        \"\"\"\n        Returns the list of indexes that are associated with this schema.\n        \n        :return     [<orb.Index>, ..]\n        \"\"\"\n        output = self.__indexes.copy()\n        if recurse and self.inherits():\n            schema = orb.system.schema(self.inherits())\n            if not schema:\n                raise orb.errors.ModelNotFound(schema=self.inherits())\n            else:\n                output.update(schema.indexes(recurse=recurse))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the inheritance tree for this schema.", "response": "def inheritanceTree(self):\n        \"\"\"\n        Returns the inheritance tree for this schema, traversing up the hierarchy for the inherited schema instances.\n\n        :return: <generator>\n        \"\"\"\n        inherits = self.inherits()\n        while inherits:\n            ischema = orb.system.schema(inherits)\n            if not ischema:\n                raise orb.errors.ModelNotFound(schema=inherits)\n\n            yield ischema\n            inherits = ischema.inherits()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef model(self, autoGenerate=False):\n        if self.__model is None and autoGenerate:\n            self.__model = orb.system.generateModel(self)\n            self.setModel(self.__model)\n        return self.__model", "response": "Returns the default Table class that is associated with this schema instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the namespace that should be used for this schema when specified.", "response": "def namespace(self, **context):\n        \"\"\"\n        Returns the namespace that should be used for this schema, when specified.\n\n        :return: <str>\n        \"\"\"\n        context = orb.Context(**context)\n        if context.forceNamespace:\n            return context.namespace or self.__namespace\n        else:\n            return self.__namespace or context.namespace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a new orb object to this schema.", "response": "def register(self, item):\n        \"\"\"\n        Registers a new orb object to this schema.  This could be a column, index, or collector -- including\n        a virtual object defined through the orb.virtual decorator.\n\n        :param item: <variant>\n\n        :return:\n        \"\"\"\n        if callable(item) and hasattr(item, '__orb__'):\n            item = item.__orb__\n\n        key = item.name()\n        model = self.__model\n\n        # create class methods for indexes\n        if isinstance(item, orb.Index):\n            self.__indexes[key] = item\n            item.setSchema(self)\n\n            if model and not hasattr(model, key):\n                setattr(model, key, classmethod(item))\n\n        # create instance methods for collectors\n        elif isinstance(item, orb.Collector):\n            self.__collectors[key] = item\n            item.setSchema(self)\n\n        # create instance methods for columns\n        elif isinstance(item, orb.Column):\n            self.__columns[key] = item\n            item.setSchema(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setColumns(self, columns):\n        self.__columns = {}\n        for name, column in columns.items():\n            self.__columns[name] = column\n            column.setSchema(self)", "response": "Sets the columns that this schema uses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setIndexes(self, indexes):\n        self.__indexes = {}\n        for name, index in indexes.items():\n            self.__indexes[name] = index\n            index.setSchema(self)", "response": "Sets the list of indexed lookups for this schema to the inputted list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setCollectors(self, collectors):\n        self.__collectors = {}\n        for name, collector in collectors.items():\n            self.__collectors[name] = collector\n            collector.setSchema(self)", "response": "Sets the collectors that will be used for this schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a list of kwargs into a dictionary. Duplicates of the same keyword get added to an list within the dictionary.", "response": "def parse_kwargs(kwargs):\n    \"\"\"\n    Convert a list of kwargs into a dictionary. Duplicates of the same keyword\n    get added to an list within the dictionary.\n\n    >>> parse_kwargs(['--var1=1', '--var2=2', '--var1=3']\n    {'var1': [1, 3], 'var2': 2}\n    \"\"\"\n    \n    d = defaultdict(list)\n    for k, v in ((k.lstrip('-'), v) for k,v in (a.split('=') for a in kwargs)):\n        d[k].append(v)\n\n    ret = {}\n    for k, v in d.items():\n        # replace single item lists with just the item.\n        if len(v) == 1 and type(v) is list:\n            ret[k] = v[0]\n        else:\n            ret[k] = v\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef htmlize_list(items):\n    out = [\"<ul>\"]\n    for item in items:\n        out.append(\"<li>\" + htmlize(item) + \"</li>\")\n    out.append(\"</ul>\")\n    return \"\\n\".join(out)", "response": "Turn a python list into an html list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the error page", "response": "def render_error_page(code, exc, mimetype='text/html', traceback=''):\n    \"\"\"\n    Render the error page\n    \"\"\"\n    from giotto.views import get_jinja_template\n\n    if 'json' in mimetype:\n        return json.dumps({\n            'code': code,\n            'exception': exc.__class__.__name__,\n            'message': str(exc),\n        })\n\n    et = get_config('error_template')\n    if not et:\n        return \"%s %s\\n%s\" % (code, str(exc), traceback)\n    template = get_jinja_template(et)\n    return template.render(\n        code=code,\n        exception=exc.__class__.__name__,\n        message=str(exc),\n        traceback=traceback\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slugify(value):\n    if six.PY3:\n        value = str(value)\n    else:\n        value = unicode(value)\n\n    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = to_remove.sub('', value).strip().lower()\n    return remove_dup.sub('-', value)", "response": "Converts to lowercase removes non - word characters underscores and spaces to hyphens and removes leading and trailing whitespace from leading and trailing whitespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the giotto object.", "response": "def initialize(module_name=None):\n    \"\"\"\n    Build the giotto settings object. This function gets called\n    at the very begining of every request cycle.\n    \"\"\"\n    import giotto\n    from giotto.utils import random_string, switchout_keyvalue\n    from django.conf import settings\n\n    setattr(giotto, '_config', GiottoSettings())\n\n    if not module_name:\n        # For testing. No settings will be set.\n        return\n\n    project_module = importlib.import_module(module_name)\n    project_path = os.path.dirname(project_module.__file__)\n    setattr(giotto._config, 'project_path', project_path)\n\n    try:\n        secrets = importlib.import_module(\"%s.controllers.secrets\" % module_name)\n    except ImportError:\n        secrets = None\n\n    try:\n        machine = importlib.import_module(\"%s.controllers.machine\" % module_name)\n    except ImportError:\n        machine = None\n\n    config = importlib.import_module(\"%s.controllers.config\" % module_name)\n\n    if config:\n        for item in dir(config):\n            setting_value = getattr(config, item)\n            setattr(giotto._config, item, setting_value)\n\n    if secrets:\n        for item in dir(secrets):\n            setting_value = getattr(secrets, item)\n            setattr(giotto._config, item, setting_value)\n    else:\n        logging.warning(\"No secrets.py found\")\n\n    if machine:\n        for item in dir(machine):\n            setting_value = getattr(machine, item)\n            setattr(giotto._config, item, setting_value)\n    else:\n        logging.warning(\"No machine.py found\")\n\n    settings.configure(\n        SECRET_KEY=random_string(32),\n        DATABASES=get_config('DATABASES'),\n        INSTALLED_APPS=(module_name, 'giotto')\n    )\n\n    ss = get_config('session_store', None)\n    if ss:\n        class_ = switchout_keyvalue(ss)\n        setattr(giotto._config, \"session_store\", class_())\n\n    cache_engine = get_config(\"cache\", None)\n    if hasattr(cache_engine, 'lower'):\n        # session engine was passed in as string, exchange for engine object.\n        class_ = switchout_keyvalue(cache_engine)\n        e = class_(host=get_config(\"cache_host\", \"localhost\"))\n        setattr(giotto._config, \"cache_engine\", e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a value from the config object.", "response": "def get_config(item, default=None):\n    \"\"\"\n    Use this function to get values from the config object.\n    \"\"\"\n    import giotto\n    return getattr(giotto._config, item, default) or default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(self, *args, **options):\n\n        def get_user(username):\n            try:\n                return User.objects.get(username=username)\n            except ObjectDoesNotExist as e:\n                raise CommandError(\"This user doesn't exist in the database\")\n\n        def get_fields_permissions(user):\n            try:\n                return UserFieldPermissions.objects.get(user=user)\n            except ObjectDoesNotExist as e:\n                raise CommandError(\"This user doesn't have fields permissions\")\n\n\n\n        if len(args) !=1:\n            raise CommandError(\"Specifies a user\")\n        else:\n            try:\n                self.stdout.ending = None\n                user = get_user(args[0])\n                fields_permissions  = get_fields_permissions(user)\n                permissions = fields_permissions.permissions.all()\n\n                jsoneatthat = {'username': user.username, \n                    'fields_permissions' : [ {'app_label': permission.content_type.app_label, 'model' : permission.content_type.model, 'name': permission.name } for permission in permissions]}\n\n                self.stdout.write(json.dumps(jsoneatthat))\n\n            except:\n                raise", "response": "Dump fields permissions for a user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay help message of twistedchecker.", "response": "def displayHelp(self):\n        \"\"\"\n        Output help message of twistedchecker.\n        \"\"\"\n        self.outputStream.write(self.linter.help())\n        sys.exit(32)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef registerCheckers(self):\n        # We patch the default pylint format checker.\n        patch_pylint_format.patch()\n\n        # register checkers\n        allowedMessages = list(self.allowedMessagesFromPylint)\n        for strChecker in self.checkers:\n            modname, classname = strChecker.split(\".\")\n            strModule = \"twistedchecker.checkers.%s\" % modname\n            checker = getattr(__import__(strModule,\n                                        fromlist=[\"twistedchecker.checkers\"]),\n                             classname)\n            instanceChecker = checker(self.linter)\n            allowedMessages += list(instanceChecker.msgs.keys())\n            self.linter.register_checker(instanceChecker)\n\n        self.restrictCheckers(allowedMessages)\n        return set(allowedMessages)", "response": "Register all checkers of TwistedChecker to C { PyLinter.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a checker from the list of registered checkers.", "response": "def unregisterChecker(self, checker):\n        \"\"\"\n        Remove a checker from the list of registered checkers.\n\n        @param checker: the checker to remove\n        \"\"\"\n        self.linter._checkers[checker.name].remove(checker)\n        if checker in self.linter._reports:\n            del self.linter._reports[checker]\n        if checker in self.linter.options_providers:\n            self.linter.options_providers.remove(checker)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding checkers which generate no allowed messages.", "response": "def findUselessCheckers(self, allowedMessages):\n        \"\"\"\n        Find checkers which generate no allowed messages.\n\n        @param allowedMessages: allowed messages\n        @return: useless checkers, remove them from pylint\n        \"\"\"\n        uselessCheckers = []\n        for checkerName in self.linter._checkers:\n            for checker in list(self.linter._checkers[checkerName]):\n                messagesOfChecker = set(checker.msgs)\n                if not messagesOfChecker.intersection(allowedMessages):\n                    uselessCheckers.append(checker)\n        return uselessCheckers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrestrict the checkers to the ones that are allowed in the twistedchecker.", "response": "def restrictCheckers(self, allowedMessages):\n        \"\"\"\n        Unregister useless checkers to speed up twistedchecker.\n\n        @param allowedMessages: output messages allowed in twistedchecker\n        \"\"\"\n        uselessCheckers = self.findUselessCheckers(allowedMessages)\n        # Unregister these checkers\n        for checker in uselessCheckers:\n            self.unregisterChecker(checker)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a checker by name.", "response": "def getCheckerByName(self, checkerType):\n        \"\"\"\n        Get checker by given name.\n\n        @checkerType: type of the checker\n        \"\"\"\n        for checker in sum(list(self.linter._checkers.values()), []):\n            if isinstance(checker, checkerType):\n                return checker\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nallow name exceptions by given patterns.", "response": "def allowPatternsForNameChecking(self, patternsFunc, patternsClass):\n        \"\"\"\n        Allow name exceptions by given patterns.\n\n        @param patternsFunc: patterns of special function names\n        @param patternsClass: patterns of special class names\n        \"\"\"\n        cfgParser = self.linter.cfgfile_parser\n        nameChecker = self.getCheckerByName(NameChecker)\n        if not nameChecker:\n            return\n        if patternsFunc:\n            regexFuncAdd = \"|((%s).+)$\" % \"|\".join(patternsFunc)\n        else:\n            regexFuncAdd = \"\"\n        if patternsClass:\n            regexClassAdd = \"|((%s).+)$\" % \"|\".join(patternsClass)\n        else:\n            regexClassAdd = \"\"\n        # Modify regex for function, method and class name.\n        regexMethod = cfgParser.get(\"BASIC\", \"method-rgx\") + regexFuncAdd\n        regexFunction = cfgParser.get(\"BASIC\", \"function-rgx\") + regexFuncAdd\n        regexClass = cfgParser.get(\"BASIC\", \"class-rgx\") + regexClassAdd\n        # Save to config parser.\n        cfgParser.set(\"BASIC\", \"method-rgx\", regexMethod)\n        cfgParser.set(\"BASIC\", \"function-rgx\", regexFunction)\n        cfgParser.set(\"BASIC\", \"class-rgx\", regexClass)\n        # Save to name checker.\n        nameChecker.config.method_rgx = re.compile(regexMethod)\n        nameChecker.config.function_rgx = re.compile(regexFunction)\n        nameChecker.config.class_rgx = re.compile(regexClass)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a list of modules to path.", "response": "def getPathList(self, filesOrModules):\n        \"\"\"\n        Transform a list of modules to path.\n\n        @param filesOrModules: a list of modules (may be foo/bar.py or\n        foo.bar)\n        \"\"\"\n        pathList = []\n        for fileOrMod in filesOrModules:\n            if not os.path.exists(fileOrMod):\n                # May be given module is not not a path,\n                # then transform it to a path.\n                try:\n                    filepath = file_from_modpath(fileOrMod.split('.'))\n                except (ImportError, SyntaxError):\n                    # Could not load this module.\n                    continue\n                if not os.path.exists(filepath):\n                    # Could not find this module in file system.\n                    continue\n                if os.path.basename(filepath) == \"__init__.py\":\n                    filepath = os.path.dirname(filepath)\n            else:\n                filepath = fileOrMod\n            pathList.append(filepath)\n        return pathList"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind name exceptions in codes and allow them to be ignored in checking.", "response": "def setNameExceptions(self, filesOrModules):\n        \"\"\"\n        Find name exceptions in codes and allow them to be ignored\n        in checking.\n\n        @param filesOrModules: a list of modules (may be foo/bar.py or\n        foo.bar)\n        \"\"\"\n        pathList = self.getPathList(filesOrModules)\n        for path in pathList:\n            patternsFunc, patternsClass = findAllExceptions(path)\n            self.allowPatternsForNameChecking(patternsFunc, patternsClass)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, args):\n        # set output stream.\n        if self.outputStream:\n            self.linter.reporter.set_output(self.outputStream)\n        try:\n            args = self.linter.load_command_line_configuration(args)\n        except SystemExit as exc:\n            if exc.code == 2:  # bad options\n                exc.code = 32\n            raise\n        if not args:\n            self.displayHelp()\n        # Check for 'strict-epydoc' option.\n        if self.allowOptions and not self.linter.option_value(\"strict-epydoc\"):\n            for msg in [\"W9203\", \"W9205\"]:\n                self.linter.disable(msg)\n\n        # insert current working directory to the python path to have a correct\n        # behaviour.\n        sys.path.insert(0, os.getcwd())\n        # set exceptions for name checking.\n        self.setNameExceptions(args)\n\n        # check for diff option.\n        self.diffOption = self.linter.option_value(\"diff\")\n        if self.diffOption:\n            self.prepareDiff()\n\n        # check codes.\n        self.linter.check(args)\n\n        # show diff of warnings if diff option on.\n        if self.diffOption:\n            diffCount = self.showDiffResults()\n            exitCode = 1 if diffCount else 0\n            sys.exit(exitCode)\n\n        sys.exit(self.linter.msg_status)", "response": "Setup the environment and run pylint."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare to run the checker and get diff results.", "response": "def prepareDiff(self):\n        \"\"\"\n        Prepare to run the checker and get diff results.\n        \"\"\"\n        self.streamForDiff = NativeStringIO()\n        self.linter.reporter.set_output(self.streamForDiff)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing results when diff option on.", "response": "def showDiffResults(self):\n        \"\"\"\n        Show results when diff option on.\n        \"\"\"\n        try:\n            oldWarnings = self.parseWarnings(self._readDiffFile())\n        except:\n            sys.stderr.write(self.errorResultRead % self.diffOption)\n            return 1\n\n        newWarnings = self.parseWarnings(self.streamForDiff.getvalue())\n\n        diffWarnings = self.generateDiff(oldWarnings, newWarnings)\n\n        if diffWarnings:\n            diffResult = self.formatWarnings(diffWarnings)\n            self.outputStream.write(diffResult + \"\\n\")\n            return len(diffWarnings)\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _readDiffFile(self):\n        with open(self.diffOption) as f:\n            content = f.read()\n        return content", "response": "Read content of diff file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generateDiff(self, oldWarnings, newWarnings):\n        diffWarnings = {}\n\n        for modulename in newWarnings:\n            diffInModule = (\n                newWarnings[modulename] -\n                oldWarnings.get(modulename, set()))\n            if diffInModule:\n                diffWarnings[modulename] = diffInModule\n\n        return diffWarnings", "response": "Generate diff between two lists of warnings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parseWarnings(self, result):\n        warnings = {}\n        currentModule = None\n        warningsCurrentModule = []\n        for line in result.splitlines():\n            if line.startswith(self.prefixModuleName):\n                # Save results for previous module\n                if currentModule:\n                    warnings[currentModule] = set(warningsCurrentModule)\n                # Initial results for current module\n                moduleName = line.replace(self.prefixModuleName, \"\")\n                currentModule = moduleName\n                warningsCurrentModule = []\n            elif re.search(self.regexLineStart, line):\n                warningsCurrentModule.append(line)\n            else:\n                if warningsCurrentModule:\n                    warningsCurrentModule[-1] += \"\\n\" + line\n        # Save warnings for last module\n        if currentModule:\n            warnings[currentModule] = set(warningsCurrentModule)\n        return warnings", "response": "Transform result in string to a dict object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats warnings to a list of results.", "response": "def formatWarnings(self, warnings):\n        \"\"\"\n        Format warnings to a list of results.\n\n        @param warnings: a dict of warnings produced by parseWarnings\n        @return: a list of warnings in string\n        \"\"\"\n        lines = []\n        for modulename in sorted(warnings):\n            lines.append(self.prefixModuleName + modulename)\n            lines.extend(sorted(warnings[modulename],\n                         key=lambda x: x.split(\":\")[1]))\n\n        return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates read length N50.", "response": "def get_N50(readlengths):\n    \"\"\"Calculate read length N50.\n\n    Based on https://github.com/PapenfussLab/Mungo/blob/master/bin/fasta_stats.py\n    \"\"\"\n    return readlengths[np.where(np.cumsum(readlengths) >= 0.5 * np.sum(readlengths))[0][0]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_length_outliers(df, columnname):\n    return df[df[columnname] < (np.median(df[columnname]) + 3 * np.std(df[columnname]))]", "response": "Remove records with length - outliers above 3 standard deviations from the median."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ave_qual(quals, qround=False, tab=errs_tab(128)):\n    if quals:\n        mq = -10 * log(sum([tab[q] for q in quals]) / len(quals), 10)\n        if qround:\n            return round(mq)\n        else:\n            return mq\n    else:\n        return None", "response": "Calculate the average basecall quality of a read and return the average basecall quality for that read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_stats(datadfs, outputfile, names=[]):\n    if outputfile == 'stdout':\n        output = sys.stdout\n    else:\n        output = open(outputfile, 'wt')\n\n    stats = [Stats(df) for df in datadfs]\n    features = {\n        \"Number of reads\": \"number_of_reads\",\n        \"Total bases\": \"number_of_bases\",\n        \"Total bases aligned\": \"number_of_bases_aligned\",\n        \"Median read length\": \"median_read_length\",\n        \"Mean read length\": \"mean_read_length\",\n        \"Read length N50\": \"n50\",\n        \"Average percent identity\": \"average_identity\",\n        \"Median percent identity\": \"median_identity\",\n        \"Active channels\": \"active_channels\",\n        \"Mean read quality\": \"mean_qual\",\n        \"Median read quality\": \"median_qual\",\n    }\n    max_len = max([len(k) for k in features.keys()])\n    try:\n        max_num = max(max([len(str(s.number_of_bases)) for s in stats]),\n                      max([len(str(n)) for n in names])) + 6\n    except ValueError:\n        max_num = max([len(str(s.number_of_bases)) for s in stats]) + 6\n    output.write(\"{:<{}}{}\\n\".format('General summary:', max_len,\n                                     \" \".join(['{:>{}}'.format(n, max_num) for n in names])))\n    for f in sorted(features.keys()):\n        try:\n            output.write(\"{f:{pad}}{v}\\n\".format(\n                f=f + ':',\n                pad=max_len,\n                v=feature_list(stats, features[f], padding=max_num)))\n        except KeyError:\n            pass\n    if all([\"quals\" in df for df in datadfs]):\n        long_features = {\n            \"Top 5 longest reads and their mean basecall quality score\":\n            [\"top5_lengths\", range(1, 6)],\n            \"Top 5 highest mean basecall quality scores and their read lengths\":\n            [\"top5_quals\", range(1, 6)],\n            \"Number, percentage and megabases of reads above quality cutoffs\":\n            [\"reads_above_qual\", [\">Q\" + str(q) for q in stats[0].qualgroups]],\n        }\n        for lf in sorted(long_features.keys()):\n            output.write(lf + \"\\n\")\n            for i in range(5):\n                output.write(\"{}:\\t{}\\n\".format(\n                    long_features[lf][1][i], feature_list(stats, long_features[lf][0], index=i)))", "response": "Call calculation functions and write stats file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef errorRecorder(self, lineNumber, offset, text, check):\n        code = text.split(\" \")[0]\n        lineOffset = self.report.line_offset\n\n        self.warnings.append((lineOffset + lineNumber,\n                              offset + 1, code, text))", "response": "A function to override report_error in pycodestyle.\n        And record output warnings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning pycodestyle checker and record warnings.", "response": "def run(self):\n        \"\"\"\n        Run pycodestyle checker and record warnings.\n        \"\"\"\n        # Set a stream to replace stdout, and get results in it\n        stdoutBak = sys.stdout\n        streamResult = StringIO()\n        sys.stdout = streamResult\n        try:\n            pycodestyle.Checker.check_all(self)\n        finally:\n            sys.stdout = stdoutBak"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _outputMessages(self, warnings, node):\n        if not warnings:\n            # No warnings were found\n            return\n        for warning in warnings:\n            linenum, offset, msgidInPyCodeStyle, text = warning\n\n            if text.startswith(msgidInPyCodeStyle):\n                # If the PyCodeStyle code is at the start of the text, trim it out\n                text = text[len(msgidInPyCodeStyle) + 1:]\n\n            if msgidInPyCodeStyle in self.mapPyCodeStyleMessages:\n                msgid, patternArguments = self.mapPyCodeStyleMessages[msgidInPyCodeStyle]\n                if (not self.pycodestyleEnabled and\n                    msgid in self.standardPyCodeStyleMessages):\n                    continue\n\n                arguments = []\n                if patternArguments:\n                    matchResult = re.search(patternArguments, text)\n                    if matchResult:\n                        arguments = matchResult.groups()\n                self.add_message(msgid, line=linenum, args=arguments, node=node)", "response": "Map pycodestyle results to messages in pylint then output them."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the given command into the current database connection cursor.", "response": "def _execute(self,\n                 native,\n                 command,\n                 data=None,\n                 returning=True,\n                 mapper=dict):\n        \"\"\"\n        Executes the inputted command into the current \\\n        connection cursor.\n        \n        :param      command    | <str>\n                    data       | <dict> || None\n                    autoCommit | <bool> | commit database changes immediately\n                    autoClose  | <bool> | closes connections immediately\n        \n        :return     [{<str> key: <variant>, ..}, ..], <int> count\n        \"\"\"\n        if data is None:\n            data = {}\n\n        cursor = native.cursor(cursor_factory=DictCursor)\n\n        # register the hstore option\n        try:\n            register_hstore(cursor, unicode=True)\n        except pg.ProgrammingError:\n            log.warning('HSTORE is not supported in this version of Postgres!')\n\n        # register the json option\n        try:\n            register_json(cursor)\n        except pg.ProgrammingError:\n            log.warning('JSON is not supported in this version of Postgres!')\n\n        start = datetime.datetime.now()\n\n        log.debug('***********************')\n        log.debug(command % data)\n        log.debug('***********************')\n\n        try:\n            cursor.execute(command, data)\n            rowcount = cursor.rowcount\n\n        # look for a cancelled query\n        except pg_ext.QueryCanceledError as cancelled:\n            try:\n                native.rollback()\n            except StandardError as err:\n                log.error('Rollback error: {0}'.format(err))\n            log.critical(command)\n            if data:\n                log.critical(str(data))\n\n            # raise more useful errors\n            if 'statement timeout' in str(cancelled):\n                raise orb.errors.QueryTimeout(command, (datetime.datetime.now() - start).total_seconds())\n            else:\n                raise orb.errors.Interruption()\n\n        # look for a disconnection error\n        except pg.InterfaceError:\n            raise orb.errors.ConnectionLost()\n\n        # look for integrity errors\n        except (pg.IntegrityError, pg.OperationalError) as err:\n            try:\n                native.rollback()\n            except StandardError:\n                pass\n\n            # look for a duplicate error\n            duplicate_error = re.search('Key (.*) already exists.', nstr(err))\n            if duplicate_error:\n                key = duplicate_error.group(1)\n                result = re.match('^\\(lower\\((?P<column>[^\\)]+)::text\\)\\)=\\((?P<value>[^\\)]+)\\)$', key)\n                if not result:\n                    result = re.match('^(?P<column>\\w+)=(?P<value>\\w+)', key)\n\n                if result:\n                    msg = '{value} is already being used.'.format(**result.groupdict())\n                    raise orb.errors.DuplicateEntryFound(msg)\n                else:\n                    raise orb.errors.DuplicateEntryFound(duplicate_error.group())\n\n            # look for a reference error\n            reference_error = re.search('Key .* is still referenced from table \".*\"', nstr(err))\n            if reference_error:\n                msg = 'Cannot remove this record, it is still being referenced.'\n                raise orb.errors.CannotDelete(msg)\n\n            # unknown error\n            log.debug(traceback.print_exc())\n            raise orb.errors.QueryFailed(command, data, nstr(err))\n\n        # connection has closed underneath the hood\n        except (pg.Error, pg.ProgrammingError) as err:\n            try:\n                native.rollback()\n            except StandardError:\n                pass\n\n            log.error(traceback.print_exc())\n            raise orb.errors.QueryFailed(command, data, nstr(err))\n\n        try:\n            results = [mapper(record) for record in cursor.fetchall()]\n        except pg.ProgrammingError:\n            results = []\n\n        return results, rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling simple SQL specific connection creation.", "response": "def _open(self, db, writeAccess=False):\n        \"\"\"\n        Handles simple, SQL specific connection creation.  This will not\n        have to manage thread information as it is already managed within\n        the main open method for the SQLBase class.\n        \n        :param      db | <orb.Database>\n        \n        :return     <variant> | backend specific database connection\n        \"\"\"\n        if not pg:\n            raise orb.errors.BackendNotFound('psycopg2 is not installed.')\n\n        if db.timeout():\n            os.environ['PGOPTIONS'] = '-c statement_timeout={0}'.format(db.timeout())\n\n        # create the python connection\n        try:\n            return pg.connect(database=db.name(),\n                              user=db.username(),\n                              password=db.password(),\n                              host=db.writeHost() if writeAccess else db.host(),\n                              port=db.port(),\n                              connect_timeout=3)\n        except pg.OperationalError as err:\n            log.exception('Failed to connect to postgres')\n            raise orb.errors.ConnectionFailed()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log_level_from_string(str_level):\n    levels = {\n        'CRITICAL': logging.CRITICAL,\n        'ERROR': logging.ERROR,\n        'WARNING': logging.WARNING,\n        'INFO': logging.INFO,\n        'DEBUG': logging.DEBUG,\n    }\n    try:\n        return levels[str_level.upper()]\n    except KeyError:\n        pass\n    except AttributeError:\n        if str_level in [logging.DEBUG, logging.INFO, logging.WARNING,\n                         logging.ERROR, logging.CRITICAL]:\n            return str_level\n    return logging.NOTSET", "response": "Returns the proper log level core based on a given string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_config_from_package(package):\n    package_x = package.split('.')\n    package_conf = {}\n    package_conf['class'] = package_x[-1]\n    package_conf['module'] = '.'.join(package_x[:-1][:])\n    return package_conf", "response": "Breaks a package string into module and class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_class_from_module(module, class_name):\n    import importlib\n    module = importlib.import_module(module)\n    return getattr(module, class_name)", "response": "Returns a class from a module and a class name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_yaml_config_file(path):\n    result = None\n    with open(path, 'r') as steam:\n        result = yaml.safe_load(steam)\n    return result", "response": "Loads a yaml config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopulating the config with data from the configuration data dict.", "response": "def process_config(config, config_data):\n    \"\"\" Populates config with data from the configuration data dict. It handles\n    components, data, log, management and session sections from the\n    configuration data.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param config_data: The configuration data loaded from a configuration\n    file.\n    \"\"\"\n    if 'components' in config_data:\n        process_components_config_section(config, config_data['components'])\n    if 'data' in config_data:\n        process_data_config_section(config, config_data['data'])\n    if 'log' in config_data:\n        process_log_config_section(config, config_data['log'])\n    if 'management' in config_data:\n        process_management_config_section(config, config_data['management'])\n    if 'session' in config_data:\n        process_session_config_section(config, config_data['session'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the app config data dict.", "response": "def process_app_config(config, config_data):\n    \"\"\" Populates config with data from the configuration data dict. It handles\n    everything that process_config does plus application section.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param config_data: The configuration data loaded from a configuration\n    file.\n    \"\"\"\n    process_config(config, config_data)\n\n    # If apps is on config data, this is running o multi app mode\n    if 'apps' in config_data:\n        config.app['multi'] = True\n        process_apps_config_session(config, config_data['apps'])\n    else:\n        # If not the app definition is on the firenado config file\n        if 'app' in config_data:\n            process_app_config_section(config, config_data['app'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the app section from a configuration data dict.", "response": "def process_app_config_section(config, app_config):\n    \"\"\" Processes the app section from a configuration data dict.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param app_config: App section from a config data dict.\n    \"\"\"\n    if 'addresses' in app_config:\n        config.app['addresses'] = app_config['addresses']\n    if 'component' in app_config:\n        config.app['component'] = app_config['component']\n    if 'data' in app_config:\n        if 'sources' in app_config['data']:\n            config.app['data']['sources'] = app_config['data']['sources']\n    if 'id' in app_config:\n        config.app['id'] = app_config['id']\n    if 'login' in app_config:\n        if 'urls' in app_config['login']:\n            for url in app_config['login']['urls']:\n                config.app['login']['urls'][url['name']] = url['value']\n    if 'pythonpath' in app_config:\n        config.app['pythonpath'] = app_config['pythonpath']\n    if 'port' in app_config:\n        config.app['port'] = app_config['port']\n    if 'process' in app_config:\n        if 'num_processes' in app_config['process']:\n            config.app['process']['num_processes'] = app_config[\n                'process']['num_processes']\n    if 'url_root_path' in app_config:\n        root_url = app_config['url_root_path'].strip()\n        if root_url[0] == \"/\":\n            root_url = root_url[1:]\n        if root_url == \"\":\n            root_url = None\n        config.app['url_root_path'] = root_url\n    if 'settings' in app_config:\n        config.app['settings'] = app_config['settings']\n    if 'socket' in app_config:\n        config.app['socket'] = app_config['socket']\n    if 'static_path' in app_config:\n        config.app['static_path'] = app_config['static_path']\n    if 'static_url_prefix' in app_config:\n        config.app['static_url_prefix'] = app_config['static_url_prefix']\n    if 'type' in app_config:\n        config.app['type'] = app_config['type']\n    if 'types' in app_config:\n        for app_type in app_config['types']:\n            app_type['launcher'] = get_config_from_package(\n                app_type['launcher'])\n            config.app['types'][app_type['name']] = app_type\n    if 'wait_before_shutdown' in app_config:\n        config.app['wait_before_shutdown'] = app_config['wait_before_shutdown']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_components_config_section(config, components_config):\n    for component_config in components_config:\n        if 'id' not in component_config:\n            raise Exception('The component %s was defined without an id.' %\n                            component_config)\n        component_id = component_config['id']\n        if component_id not in config.components:\n            config.components[component_id] = {}\n            config.components[component_id]['enabled'] = False\n            config.components[component_id]['config'] = {}\n        if 'class' in component_config:\n            class_config_x = component_config['class'].split('.')\n            config.components[component_id]['class'] = class_config_x[-1]\n            config.components[component_id]['module'] = '.'.join(\n                class_config_x[:-1])\n        if 'enabled' in component_config:\n            config.components[component_id]['enabled'] = bool(\n                component_config['enabled'])", "response": "Processes the components section from a configuration data dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the data configuration section from the configuration data dict.", "response": "def process_data_config_section(config, data_config):\n    \"\"\" Processes the data configuration section from the configuration\n    data dict.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param data_config: Data configuration section from a config data dict.\n    \"\"\"\n    if 'connectors' in data_config:\n        for connector in data_config['connectors']:\n            config.data['connectors'][\n                connector['name']] = get_config_from_package(\n                connector['class'])\n    if 'sources' in data_config:\n        if data_config['sources']:\n            for source in data_config['sources']:\n                config.data['sources'][source['name']] = source\n                del config.data['sources'][source['name']]['name']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the log section from a configuration data dict.", "response": "def process_log_config_section(config, log_config):\n    \"\"\" Processes the log section from a configuration  data dict.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param log_config: Log section from a config data dict.\n    \"\"\"\n    if 'format' in log_config:\n        config.log['format'] = log_config['format']\n    if 'level' in log_config:\n        config.log['level'] = log_level_from_string(log_config['level'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_management_config_section(config, management_config):\n    if 'commands' in management_config:\n        for command in management_config['commands']:\n            config.management['commands'].append(command)", "response": "Processes the management section from a configuration data dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the session section from the config data dict.", "response": "def process_session_config_section(config, session_config):\n    \"\"\" Processes the session section from the configuration data dict.\n\n    :param config: The config reference of the object that will hold the\n    configuration data from the config_data.\n    :param session_config: Session configuration section from a config data\n    dict.\n    \"\"\"\n    # Setting session type as file by default\n    config.session['type'] = 'file'\n    if 'enabled' in session_config:\n        config.session['enabled'] = session_config['enabled']\n    if 'type' in session_config:\n        config.session['type'] = session_config['type']\n        if config.session['type'] == 'file':\n            if 'path' in session_config:\n                config.session['file']['path'] = session_config['path']\n        if config.session['type'] == 'redis':\n            if 'data' in session_config:\n                if 'source' in session_config['data']:\n                    config.session['redis']['data']['source'] = session_config[\n                        'data']['source']\n    if 'handlers' in session_config:\n        for handler in session_config['handlers']:\n            handler_class_x = handler['class'].split('.')\n            handler['class'] = handler_class_x[-1]\n            handler['module'] = '.'.join(handler_class_x[:-1][:])\n            config.session['handlers'][handler['name']] = handler\n            del config.session['handlers'][handler['name']]['name']\n    if 'encoders' in session_config:\n        for encoder in session_config['encoders']:\n            encoder_class_x = encoder['class'].split('.')\n            encoder['encoder'] = encoder_class_x[-1]\n            encoder['class'] = encoder_class_x[-1]\n            encoder['module'] = '.'.join(encoder_class_x[:-1][:])\n            config.session['encoders'][encoder['name']] = encoder\n            del config.session['encoders'][encoder['name']]['name']\n    if 'id_generators' in session_config:\n        for generator in session_config['id_generators']:\n            generator_ref_x = generator['function'].split('.')\n            generator['function'] = generator_ref_x[-1]\n            generator['module'] = '.'.join(generator_ref_x[:-1][:])\n            config.session['id_generators'][generator['name']] = generator\n            del config.session['id_generators'][generator['name']]['name']\n    if 'name' in session_config:\n        config.session['name'] = session_config['name']\n    if 'life_time' in session_config:\n        config.session['life_time'] = session_config['life_time']\n    if 'callback_hiccup' in session_config:\n        config.session['callback_hiccup'] = session_config['callback_hiccup']\n    if 'callback_time' in session_config:\n        config.session['callback_time'] = session_config['callback_time']\n    if 'purge_limit' in session_config:\n        config.session['purge_limit'] = session_config['purge_limit']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the given command into the current database cursor.", "response": "def _execute(self,\n                 native,\n                 command,\n                 data=None,\n                 returning=True,\n                 mapper=dict):\n        \"\"\"\n        Executes the inputted command into the current \\\n        connection cursor.\n\n        :param      command    | <str>\n                    data       | <dict> || None\n\n        :return     [{<str> key: <variant>, ..}, ..], <int> count\n        \"\"\"\n        if data is None:\n            data = {}\n\n        with native.cursor() as cursor:\n            log.debug('***********************')\n            log.debug(command % data)\n            log.debug('***********************')\n\n            try:\n                rowcount = 0\n                for cmd in command.split(';'):\n                    cmd = cmd.strip()\n                    if cmd:\n                        cursor.execute(cmd.strip(';') + ';', data)\n                        rowcount += cursor.rowcount\n\n            # look for a disconnection error\n            except pymysql.InterfaceError:\n                raise orb.errors.ConnectionLost()\n\n            # look for integrity errors\n            except (pymysql.IntegrityError, pymysql.OperationalError) as err:\n                native.rollback()\n\n                # look for a duplicate error\n                if err[0] == 1062:\n                    raise orb.errors.DuplicateEntryFound(err[1])\n\n                # look for a reference error\n                reference_error = re.search('Key .* is still referenced from table \".*\"', nstr(err))\n                if reference_error:\n                    msg = 'Cannot remove this record, it is still being referenced.'\n                    raise orb.errors.CannotDelete(msg)\n\n                # unknown error\n                log.debug(traceback.print_exc())\n                raise orb.errors.QueryFailed(command, data, nstr(err))\n\n            # connection has closed underneath the hood\n            except pymysql.Error as err:\n                native.rollback()\n                log.error(traceback.print_exc())\n                raise orb.errors.QueryFailed(command, data, nstr(err))\n\n            try:\n                raw = cursor.fetchall()\n                results = [mapper(record) for record in raw]\n            except pymysql.ProgrammingError:\n                results = []\n\n            return results, rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles simple SQL specific connection creation.", "response": "def _open(self, db, writeAccess=False):\n        \"\"\"\n        Handles simple, SQL specific connection creation.  This will not\n        have to manage thread information as it is already managed within\n        the main open method for the SQLBase class.\n\n        :param      db | <orb.Database>\n\n        :return     <variant> | backend specific database connection\n        \"\"\"\n        if not pymysql:\n            raise orb.errors.BackendNotFound('psycopg2 is not installed.')\n\n        # create the python connection\n        try:\n            return pymysql.connect(db=db.name(),\n                                   user=db.username(),\n                                   passwd=db.password(),\n                                   host=(db.writeHost() if writeAccess else db.host()) or 'localhost',\n                                   port=db.port() or 3306,\n                                   cursorclass=pymysql.cursors.DictCursor)\n        except pymysql.OperationalError as err:\n            log.exception('Failed to connect to postgres')\n            raise orb.errors.ConnectionFailed()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_script(script_path, session, handle_command=None, handle_line=None):\n    logger.debug(\"Opening script %s.\" % script_path)\n    with open(script_path, \"r\") as stream:\n        sql_command = \"\"\n        for line in stream:\n            # Ignore commented lines\n            if not line.startswith(\"--\") and line.strip(\"\\n\"):\n                # Append line to the command string\n                if handle_line is not None:\n                    logger.debug(\"Calling the handle line function for: \"\n                                 \"%s.\" % line)\n                    line = handle_line(line)\n                sql_command = \"%s%s\" % (sql_command, line.strip(\"\\n\"))\n                # If the command string ends with \";\", it is a full statement\n                if sql_command.endswith(\";\"):\n                    # Try to execute statement and commit it\n                    try:\n                        if handle_command is not None:\n                            logger.debug(\"Calling the handle command function \"\n                                         \"for: %s.\" % sql_command)\n                            sql_command = handle_command(sql_command)\n                        session.execute(text(sql_command))\n                    # Assert in case of error\n                    except Exception as e:\n                        session.rollback()\n                        raise e\n                    # Finally, clear command string\n                    finally:\n                        sql_command = \"\"\n    session.commit()", "response": "Runs a script file and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_from_command_line():\n    for commands_conf in firenado.conf.management['commands']:\n        logger.debug(\"Loading %s commands from %s.\" % (\n            commands_conf['name'],\n            commands_conf['module']\n        ))\n        exec('import %s' % commands_conf['module'])\n    command_index = 1\n    for arg in sys.argv[1:]:\n        command_index += 1\n        if arg[0] != \"-\":\n            break\n    parser = FirenadoArgumentParser(prog=os.path.split(sys.argv[0])[1],\n                                    add_help=False)\n    parser.add_argument(\"-h\", \"--help\", default=argparse.SUPPRESS)\n    parser.add_argument(\"command\", default=\"help\", help=\"Command to executed\")\n\n    try:\n        namespace = parser.parse_args(sys.argv[1:command_index])\n        if not command_exists(namespace.command):\n            show_command_line_usage(parser)\n        else:\n            run_command(namespace.command, sys.argv[command_index-1:])\n    except FirenadoArgumentError:\n        show_command_line_usage(parser, True)", "response": "Runs Firenado s management commands from a command line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the command line header", "response": "def get_command_header(parser, usage_message=\"\", usage=False):\n    \"\"\" Return the command line header\n\n    :param parser:\n    :param usage_message:\n    :param usage:\n    :return: The command header\n    \"\"\"\n    loader = template.Loader(os.path.join(\n        firenado.conf.ROOT, 'management', 'templates', 'help'))\n    return loader.load(\"header.txt\").generate(\n        parser=parser, usage_message=usage_message, usage=usage,\n        firenado_version=\".\".join(map(str, firenado.__version__))).decode(\n        sys.stdout.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_command_line_usage(parser, usage=False):\n    help_header_message = get_command_header(parser, \"command\", usage)\n    loader = template.Loader(os.path.join(\n        firenado.conf.ROOT, 'management', 'templates', 'help'))\n    command_template = \"  {0.name:15}{0.description:40}\"\n    help_message = loader.load(\"main_command_help.txt\").generate(\n        command_categories=command_categories,\n        command_template=command_template\n    ).decode(sys.stdout.encoding)\n    # TODO: This print has to go. Use proper stream instead(stdout or stderr)\n    print(''.join([help_header_message, help_message]))", "response": "Show the command line help"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the given command exists in another words if it exists.", "response": "def command_exists(command):\n    \"\"\" Check if the given command was registered. In another words if it\n    exists.\n    \"\"\"\n    for category, commands in iteritems(command_categories):\n        for existing_command in commands:\n            if existing_command.match(command):\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning all tasks registered in a command.", "response": "def run_command(command, args):\n    \"\"\" Run all tasks registered in a command.\n    \"\"\"\n    for category, commands in iteritems(command_categories):\n        for existing_command in commands:\n            if existing_command.match(command):\n                existing_command.run(args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if subtype is possible subclass of supertype.", "response": "def _is_possible_subclass(self, subtype, supertype):\n        \"\"\"\n        Like issubclass(subtype, supertype) except that TypeVars\n        are not taken into account.\n        \"\"\"\n        subparams = getattr(subtype, \"__parameters__\", None)\n        if subparams is None:\n            return issubclass(subtype, supertype)  # a non-generic actual type\n        # It is surprisingly difficult to ignore the type variables in a\n        # subclass check. We therefore compare __name__ (along mro) only.\n        # This can produce false positives in principle.\n        # (previous \"nullify __parameters__\" logic deleted 2016-01-24 14:52)\n        for subtype_super in subtype.mro():\n            if subtype_super.__name__ == supertype.__name__:\n                # squeeze your thumbs this is not just by accident\n                return True  # TODO: ensure __parameters__ are compatible\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check(self, value, namespace):\n        return namespace.is_compatible(self.typevar, type(value))", "response": "Check whether the value is compatible with the TypeVar bound for the first time\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the value is a valid record type.", "response": "def check(self, value, namespace):\n        \"\"\"\n        Attribute _field_types is a dict from field name to type.\n        \"\"\"\n        if (not issubclass(type(value), self._cls) or\n            len(value) != len(self._cls._fields)):\n            return False\n        for i, check in enumerate(self._checks):\n            if not check(value[i], namespace):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the value is in the specified namespace.", "response": "def check(self, value, namespace):\n        \"\"\"\n        Attribute _field_types is a dict from field name to type.\n        \"\"\"\n        for i, check in enumerate(self._checks):\n            if check(value, namespace):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dbRestore(self, db_value, context=None):\n        if db_value is not None:\n            try:\n                return pickle.loads(str(db_value))\n            except StandardError:\n                log.exception('Failed to restore pickle')\n                raise orb.errors.DataStoreError('Failed to restore pickle.')\n        else:\n            return None", "response": "Converts a stored database value to Python."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a stored database value to Python.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Converts a stored database value to Python.\n\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if db_value is not None:\n            try:\n                return rest.unjsonify(db_value)\n            except StandardError:\n                log.exception('Failed to restore json')\n                raise orb.errors.DataStoreError('Failed to restore json.')\n        else:\n            return db_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a stored database value to Python.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Converts a stored database value to Python.\n\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if db_value is not None:\n            jdata = super(QueryColumn, self).dbRestore(db_value, context=context)\n            return orb.Query.fromJSON(jdata)\n        else:\n            return db_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a stored database value to Python.", "response": "def dbRestore(self, db_value, context=None):\n        \"\"\"\n        Converts a stored database value to Python.\n\n        :param py_value: <variant>\n        :param context: <orb.Context>\n\n        :return: <variant>\n        \"\"\"\n        if db_value is not None:\n            return yaml.load(projex.text.nativestring(db_value))\n        else:\n            return db_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a line is longer than a maximum number of characters.", "response": "def check_lines(self, lines, i):\n    \"\"\"\n    check lines have less than a maximum number of characters.\n\n    It ignored lines with long URLs.\n    \"\"\"\n    maxChars = self.config.max_line_length\n    for line in lines.splitlines():\n        if len(line) > maxChars:\n            if 'http://' in line or 'https://' in line:\n                continue\n            self.add_message('C0301', line=i, args=(len(line), maxChars))\n        i += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pci_lookup_name1(\n    access: (IN, ctypes.POINTER(pci_access)),\n    buf: (IN, ctypes.c_char_p),\n    size: (IN, ctypes.c_int),\n    flags: (IN, ctypes.c_int),\n    arg1: (IN, ctypes.c_int),\n) -> ctypes.c_char_p:\n    \"\"\"\n    Conversion of PCI ID's to names (according to the pci.ids file).\n\n    char *pci_lookup_name(\n        struct pci_access *a, char *buf, int size, int flags, ...\n    ) PCI_ABI;\n\n    This is a variant of pci_lookup_name() that gets called with one argument.\n    It is required because ctypes doesn't support varadic functions.\n    \"\"\"\n    pass", "response": "A wrapper for pci_lookup_name that converts PCI ID s to names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pci_lookup_name2(\n    access: (IN, ctypes.POINTER(pci_access)),\n    buf: (IN, ctypes.c_char_p),\n    size: (IN, ctypes.c_int),\n    flags: (IN, ctypes.c_int),\n    arg1: (IN, ctypes.c_int),\n    arg2: (IN, ctypes.c_int),\n) -> ctypes.c_char_p:\n    \"\"\"\n    Conversion of PCI ID's to names (according to the pci.ids file).\n\n    char *pci_lookup_name(\n        struct pci_access *a, char *buf, int size, int flags, ...\n    ) PCI_ABI;\n\n    This is a variant of pci_lookup_name() that gets called with two arguments.\n    It is required because ctypes doesn't support varadic functions.\n    \"\"\"\n    pass", "response": "A wrapper for pci_lookup_name that converts PCI ID s to names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef LoginView(http_redirect=None):\n    class LoginView(GiottoView):\n        \"\"\"\n        ``result`` is the session that was newly created. consult the\n        ``create_session`` model for reference.\n        \"\"\"\n        @renders('text/html')\n        def html(self, result):\n            ty = type(http_redirect)\n            if ty == list or ty == tuple:\n                assert len(http_redirect) == 3, \"http_redirect must be three items\"\n                return Redirection(http_redirect[0], args=http_redirect[1], kwargs=http_redirect[2])\n            else:\n                # assume a string was passed in.\n                return Redirection(http_redirect)\n    return LoginView", "response": "Return a login view that redirects the user to the http_redirect program."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_representation(self, obj):\n        many = isinstance(obj, collections.Iterable) \\\n            or isinstance(obj, models.Manager) \\\n            and not isinstance(obj, dict)\n\n        assert self.serializer is not None \\\n            and issubclass(self.serializer, serializers.ModelSerializer), (\n                \"Bad serializer defined %s\" % self.serializer\n            )\n\n        extra_params = {}\n        if issubclass(self.serializer, ModelPermissionsSerializer):\n            extra_params['cached_allowed_fields'] =\\\n                self.parent.cached_allowed_fields\n\n        ser = self.serializer(obj, context=self.context, many=many,\n                              **extra_params)\n        return ser.data", "response": "Represent data for the field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the remove action that should be taken when a model is removed from the collection generated by this reverse lookup.", "response": "def setRemoveAction(self, action):\n        \"\"\"\n        Sets the remove action that should be taken when a model is removed from the collection generated by\n        this reverse lookup.  Valid actions are \"unset\" or \"delete\", any other values will raise an exception.\n\n        :param action: <str>\n        \"\"\"\n        if action not in ('unset', 'delete'):\n            raise orb.errors.ValidationError('The remove action must be either \"unset\" or \"delete\"')\n        else:\n            self.__removeAction = action"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bind(self, typevar, its_type):\n        assert type(typevar) == tg.TypeVar\n        if self.is_generic_in(typevar):\n            self.bind_to_instance(typevar, its_type)\n        else:\n            self._ns[typevar] = its_type", "response": "Binds typevar to the type its_type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binding_of(self, typevar):\n        if typevar in self._ns:\n            return self._ns[typevar]\n        if self._instance_ns and typevar in self._instance_ns:\n            return self._instance_ns[typevar]\n        return None", "response": "Returns the type the typevar is bound to or None if the typevar is not bound to an instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether the typevar conforms to its_type.", "response": "def is_compatible(self, typevar, its_type):\n        \"\"\"\n        Checks whether its_type conforms to typevar.\n        If the typevar is not yet bound, it will be bound to its_type.\n        The covariance/contravariance checking described in the respective section\n        of PEP484 applies to declared types, but here we have actual types;\n        therefore, (1) subtypes are always compatible, (2) we may have to\n        rebind the type variable to supertypes of the current binding several\n        times until the required most general binding is found.\n        \"\"\"\n        result = True\n        binding = self.binding_of(typevar)  # may or may not exist\n        if binding is None:\n            self.bind(typevar, its_type)  # initial binding, OK\n        elif issubclass(binding, its_type):\n            self.bind(typevar, its_type)  # rebind to supertype, OK\n        elif not issubclass(its_type, binding):  # accept like TypeChecker\n            return False\n        binding = self.binding_of(typevar)  # will now exist\n        if (typevar.__bound__ and\n                not issubclass(binding, typevar.__bound__)):\n            return False  # bound violation\n        if (len(typevar.__constraints__) > 0 and\n                not issubclass(binding, tg.Union[typevar.__constraints__])):\n            return False  # constraint violation\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering another typecheck annotation with the framework.", "response": "def register(cls, predicate, factory, prepend=False):\n        \"\"\"\n        Adds another type X of typecheck annotations to the framework.\n        predicate(annot) indicates whether annot has annotation type X;\n        factory(annot) creates the appropriate typechecker instance.\n        The checker type is normally added after the existing ones,\n        but 'prepend' makes it come first.\n        \"\"\"\n        if prepend:\n            cls._registered.insert(0, (predicate, factory))\n        else:\n            cls._registered.append((predicate, factory))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given values are valid for this type of entry.", "response": "def check(self, values, namespace):\n        \"\"\"specifying a plain tuple allows arguments that are tuples or lists;\n        specifying a specialized (subclassed) tuple allows only that type;\n        specifying a list allows only that list type.\"\"\"\n        is_tuplish_type = (issubclass(self._cls, tg.Tuple) or\n                           issubclass(type(values), self._cls))\n        if (not _is_sequence(values) or not is_tuplish_type or\n                len(values) != len(self._checks)):\n            return False\n        for thischeck, thisvalue in zip(self._checks, values):\n            if not thischeck(thisvalue, namespace):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a requirements. txt file and handles PyPI index URLs", "response": "def read_requirements_file(path):\n    \"\"\"\n    reads requirements.txt file and handles PyPI index URLs\n    :param path: (str) path to requirements.txt file\n    :return: (tuple of lists)\n    \"\"\"\n    last_pypi_url = None\n    with open(path) as f:\n        requires = []\n        pypi_urls = []\n        for line in f.readlines():\n            if not line:\n                continue\n            if '--' in line:\n                match = re.match(r'--index-url\\s+([\\w\\d:/.-]+)\\s', line)\n                if match:\n                    last_pypi_url = match.group(1)\n                    if not last_pypi_url.endswith(\"/\"):\n                        last_pypi_url += \"/\"\n            else:\n                if last_pypi_url:\n                    pypi_urls.append(last_pypi_url + line.strip().lower())\n                requires.append(line)\n    return requires, pypi_urls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_module(self, node):\n        if not node.file_stream:\n            # failed to open the module\n            return\n        text = node.file_stream.read()\n        self._checkCopyright(text, node)\n        if not isTestModule(node.name) and moduleNeedsTests:\n            self._checkTestReference(text, node)", "response": "A module has been visited and we need to check that the module has the right license and test reference."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether the module has copyright header.", "response": "def _checkCopyright(self, text, node):\n        \"\"\"\n        Check whether the module has copyright header.\n\n        @param text: codes of the module\n        @param node: node of the module\n        \"\"\"\n        if not re.search(br\"%s\\s*\\n\\s*%s\" % self.commentsCopyright, text):\n            self.add_message('W9001', node=node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a message that is not allowed by the user.", "response": "def handle_message(self, msg):\n        \"\"\"\n        Manage message of different type and in the context of path.\n        \"\"\"\n        if msg.msg_id in self.messagesAllowed:\n            super(LimitedReporter, self).handle_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(self, scope):\n        schemas = self.schemas().values()\n        for schema in schemas:\n            scope[schema.name()] = schema.model()", "response": "Initializes the internal state of the orb system into the inputted scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a particular database or schema.", "response": "def register(self, obj, force=False):\n        \"\"\"\n        Registers a particular database.\n        \n        :param      obj     | <orb.Database> || <orb.Schema>\n        \"\"\"\n        if isinstance(obj, orb.Database):\n            scope = self.__databases\n            key = obj.code()\n        elif isinstance(obj, orb.Schema):\n            scope = self.__schemas\n            key = obj.name()\n        else:\n            raise orb.errors.OrbError('Unknown object to register: {0}'.format(obj))\n\n        try:\n            existing = self.__schemas[obj.name()]\n        except KeyError:\n            pass\n        else:\n            if existing != obj and not force:\n                raise orb.errors.DuplicateEntryFound('{0} is already a registered {1}.'.format(key, typ))\n\n        scope[key] = obj\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef page(self, number, **context):\n        size = max(0, self.context(**context).pageSize)\n        if not size:\n            return self.copy()\n        else:\n            return self.copy(page=number, pageSize=size)", "response": "Returns the records for the current page or the specified page number."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load(self, event):\n        if not event.data:\n            return\n\n        context = self.context()\n        schema = self.schema()\n        dbname = schema.dbname()\n        clean = {}\n\n        for col, value in event.data.items():\n            try:\n                model_dbname, col_name = col.split('.')\n            except ValueError:\n                col_name = col\n                model_dbname = dbname\n\n            # make sure the value we're setting is specific to this model\n            try:\n                column = schema.column(col_name)\n            except orb.errors.ColumnNotFound:\n                column = None\n\n            if model_dbname != dbname or (column in clean and isinstance(clean[column], Model)):\n                continue\n\n            # look for preloaded reverse lookups and pipes\n            elif not column:\n                self.__preload[col_name] = value\n\n            # extract the value from the database\n            else:\n                value = column.dbRestore(value, context=context)\n                clean[column] = value\n\n        # update the local values\n        with WriteLocker(self.__dataLock):\n            for col, val in clean.items():\n                default = val if not isinstance(val, dict) else val.copy()\n                self.__values[col.name()] = (default, val)\n                self.__loaded.add(col)\n\n        if self.processEvent(event):\n            self.onLoad(event)", "response": "Processes a load event by setting the properties of this record with the data restored from the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of changes that have been made to the data from this record.", "response": "def changes(self, columns=None, recurse=True, flags=0, inflated=False):\n        \"\"\"\n        Returns a dictionary of changes that have been made\n        to the data from this record.\n\n        :return     { <orb.Column>: ( <variant> old, <variant> new), .. }\n        \"\"\"\n        output = {}\n        is_record = self.isRecord()\n        schema = self.schema()\n        columns = [schema.column(c) for c in columns] if columns else \\\n                   schema.columns(recurse=recurse, flags=flags).values()\n\n        context = self.context(inflated=inflated)\n        with ReadLocker(self.__dataLock):\n            for col in columns:\n                old, curr = self.__values.get(col.name(), (None, None))\n                if col.testFlag(col.Flags.ReadOnly):\n                    continue\n                elif not is_record:\n                    old = None\n\n                check_old = col.restore(old, context)\n                check_curr = col.restore(curr, context)\n                try:\n                    different = check_old != check_curr\n                except StandardError:\n                    different = True\n\n                if different:\n                    output[col] = (check_old, check_curr)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef context(self, **context):\n        output = orb.Context(context=self.__context) if self.__context is not None else orb.Context()\n        output.update(context)\n        return output", "response": "Returns the lookup options for this record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, **context):\n        if not self.isRecord():\n            return 0\n\n        event = orb.events.DeleteEvent(record=self, context=self.context(**context))\n        if self.processEvent(event):\n            self.onDelete(event)\n\n        if event.preventDefault:\n            return 0\n\n        if self.__delayed:\n            self.__delayed = False\n            self.read()\n\n        with WriteLocker(self.__dataLock):\n            self.__loaded.clear()\n\n        context = self.context(**context)\n        conn = context.db.connection()\n        _, count = conn.delete([self], context)\n\n        # clear out the old values\n        if count == 1:\n            col = self.schema().column(self.schema().idColumn())\n            with WriteLocker(self.__dataLock):\n                self.__values[col.name()] = (None, None)\n\n        return count", "response": "Removes this record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, column, useMethod=True, **context):\n\n        # look for shortcuts (dot-noted path)\n        if isinstance(column, (str, unicode)) and '.' in column:\n            # create the sub context\n            base_context = context.copy()\n            base_context['inflated'] = True\n\n            # generate the expansion to avoid unnecessary lookups\n            parts = column.split('.')\n\n            # include the target if it is a reference\n            if isinstance(self.schema().column(column), orb.ReferenceColumn):\n                expand_path_index = None\n\n            # otherwise, just get to the end column\n            else:\n                expand_path_index = -1\n\n            value = self\n            for i, part in enumerate(parts[:-1]):\n                sub_context = base_context.copy()\n                expand_path = '.'.join(parts[i+1:expand_path_index])\n\n                try:\n                    sub_expand = sub_context['expand']\n                except KeyError:\n                    sub_context['expand'] = expand_path\n                else:\n                    if isinstance(sub_expand, basestring):\n                        sub_context['expand'] += ',{0}'.format(expand_path)\n                    elif isinstance(sub_expand, list):\n                        sub_expand.append(expand_path)\n                    elif isinstance(sub_expand, dict):\n                        curr = {}\n                        for x in xrange(len(parts) - 1 + (expand_path_index or 0), i, -1):\n                            curr = {parts[x]: curr}\n                        sub_expand.update(curr)\n\n                value = value.get(part, useMethod=useMethod, **sub_context)\n                if value is None:\n                    return None\n\n            return value.get(parts[-1], useMethod=useMethod, **context)\n\n        # otherwise, lookup a column\n        else:\n            my_context = self.context()\n\n            for k, v in my_context.raw_values.items():\n                if k not in orb.Context.QueryFields:\n                    context.setdefault(k, v)\n\n            sub_context = orb.Context(**context)\n\n            # normalize the given column\n            if isinstance(column, orb.Column):\n                col = column\n            else:\n                col = self.schema().column(column, raise_=False)\n\n                if not col:\n                    if isinstance(column, orb.Collector):\n                        collector = column\n                    else:\n                        collector = self.schema().collector(column)\n\n                    if collector:\n                        try:\n                            return self.__cache[collector][sub_context]\n                        except KeyError:\n                            records = collector(self, useMethod=useMethod, context=sub_context)\n                            self.__cache[collector][sub_context] = records\n                            return records\n                    else:\n                        raise errors.ColumnNotFound(schema=self.schema(), column=column)\n\n            # don't inflate if the requested value is a field\n            if sub_context.inflated is None and isinstance(col, orb.ReferenceColumn):\n                sub_context.inflated = column != col.field()\n\n            # lookup the shortuct value vs. the local one (bypass for views\n            # since they define tables for shortcuts)\n            if col.shortcut() and not isinstance(self, orb.View):\n                return self.get(col.shortcut(), **context)\n\n            # call the getter method fot this record if one exists\n            elif useMethod and col.gettermethod():\n                return col.gettermethod()(self, context=sub_context)\n\n            else:\n                # ensure content is actually loaded\n                if self.isRecord() and self.__delayed:\n                    self.__delayed = False\n                    self.read()\n\n                # grab the current value\n                with ReadLocker(self.__dataLock):\n                    old_value, value = self.__values.get(col.name(), (None, None))\n\n                # return a reference when desired\n                out_value = col.restore(value, sub_context)\n                if isinstance(out_value, orb.Model) and not isinstance(value, orb.Model):\n                    with WriteLocker(self.__dataLock):\n                        self.__values[col.name()] = (old_value, out_value)\n\n                return out_value", "response": "Returns the value for the column for this record."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmarks the given columns as though they had been loaded from the database.", "response": "def markLoaded(self, *columns):\n        \"\"\"\n        Tells the model to treat the given columns as though they had been loaded from the database.\n\n        :param columns: (<str>, ..)\n        \"\"\"\n        schema = self.schema()\n\n        columns = {schema.column(col) for col in columns}\n        column_names = {col.name() for col in columns}\n\n        with WriteLocker(self.__dataLock):\n            for key, (old_value, new_value) in self.__values.items():\n                if key in column_names:\n                    self.__values[key] = (new_value, new_value)\n\n            self.__loaded.update(columns)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether or not this database table record exists in the database.", "response": "def isRecord(self, db=None):\n        \"\"\"\n        Returns whether or not this database table record exists\n        in the database.\n\n        :return     <bool>\n        \"\"\"\n        if db is not None:\n            same_db = db == self.context().db\n\n        if db is None or same_db:\n            col = self.schema().idColumn()\n            with ReadLocker(self.__dataLock):\n                return (col in self.__loaded) and (self.__values[col.name()][0] is not None)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the current change set information to the database.", "response": "def save(self, values=None, after=None, before=None, **context):\n        \"\"\"\n        Commits the current change set information to the database,\n        or inserts this object as a new record into the database.\n        This method will only update the database if the record\n        has any local changes to it, otherwise, no commit will\n        take place.  If the dryRun flag is set, then the SQL\n        will be logged but not executed.\n\n        :param values: None or dictionary of values to update before save\n        :param after: <orb.Model> || None (optional)\n                      if provided, this save call will be delayed\n                      until after the given record has been saved,\n                      triggering a PostSaveEvent callback\n        :param before: <orb.Model> || None (optional)\n                      if provided, this save call will be delayed\n                      until before the given record is about to be\n                      saved, triggering a PreSaveEvent callback\n\n\n        :note       From version 0.6.0 on, this method now accepts a mutable\n                    keyword dictionary of values.  You can supply any member\n                    value for either the <orb.LookupOptions> or\n                    <orb.Context>, 'options' for\n                    an instance of the <orb.Context>\n\n        :return     <bool> success\n        \"\"\"\n        # specify that this save call should be performed after the save of\n        # another record, useful for chaining events\n        if after is not None:\n            callback = orb.events.Callback(self.save, values=values, **context)\n            after.addCallback(orb.events.PostSaveEvent, callback, record=after, once=True)\n            return callback\n\n        # specify that this save call should be performed before the save\n        # of another record, useful for chaining events\n        elif before is not None:\n            callback = orb.events.Callback(self.save, values=values, **context)\n            after.addCallback(orb.events.PreSaveEvent, callback, record=after, once=True)\n            return callback\n\n        if values is not None:\n            self.update(values, **context)\n\n        # create the commit options\n        context = self.context(**context)\n        new_record = not self.isRecord()\n\n        # create the pre-commit event\n        changes = self.changes(columns=context.columns)\n        event = orb.events.PreSaveEvent(record=self, context=context, newRecord=new_record, changes=changes)\n        if self.processEvent(event):\n            self.onPreSave(event)\n\n        if event.preventDefault:\n            return event.result\n\n        # check to see if we have any modifications to store\n        if not (self.isModified() and self.validate()):\n            return False\n\n        conn = context.db.connection()\n        if not self.isRecord():\n            records, _ = conn.insert([self], context)\n            if records:\n                event = orb.events.LoadEvent(record=self, data=records[0])\n                self._load(event)\n        else:\n            conn.update([self], context)\n\n        # mark all the data as committed\n        cols = [self.schema().column(c).name() for c in context.columns or []]\n        with WriteLocker(self.__dataLock):\n            for col_name, (_, value) in self.__values.items():\n                if not cols or col_name in cols:\n                    self.__values[col_name] = (value, value)\n\n        # create post-commit event\n        event = orb.events.PostSaveEvent(record=self, context=context, newRecord=new_record, changes=changes)\n        if self.processEvent(event):\n            self.onPostSave(event)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, column, value, useMethod=True, **context):\n        col = self.schema().column(column, raise_=False)\n\n        if col is None:\n            # allow setting of collections as well\n            collector = self.schema().collector(column)\n            if collector:\n                my_context = self.context()\n\n                for k, v in my_context.raw_values.items():\n                    if k not in orb.Context.QueryFields:\n                        context.setdefault(k, v)\n\n                sub_context = orb.Context(**context)\n                method = collector.settermethod()\n                if method and useMethod:\n                    return method(self, value, context=sub_context)\n                else:\n                    records = self.get(collector.name(), context=sub_context)\n                    records.update(value,\n                                   useMethod=useMethod,\n                                   context=sub_context)\n\n                    # remove any preloaded values from the collector\n                    self.__preload.pop(collector.name(), None)\n\n                    return records\n            else:\n                raise errors.ColumnNotFound(schema=self.schema(), column=column)\n\n        elif col.testFlag(col.Flags.ReadOnly):\n            raise errors.ColumnReadOnly(schema=self.schema(), column=column)\n\n        context = self.context(**context)\n        if useMethod:\n            method = col.settermethod()\n            if method:\n                keywords = list(funcutil.extract_keywords(method))\n                if 'locale' in keywords:\n                    return method(self, value, locale=context.locale)\n                else:\n                    return method(self, value)\n\n        if self.isRecord() and self.__delayed:\n            self.__delayed = False\n            self.read()\n\n        with WriteLocker(self.__dataLock):\n            orig, curr = self.__values.get(col.name(), (None, None))\n            value = col.store(value, context)\n\n            # update the context based on the locale value\n            if col.testFlag(col.Flags.I18n) and isinstance(curr, dict) and isinstance(value, dict):\n                new_value = curr.copy()\n                new_value.update(value)\n                value = new_value\n\n            try:\n                change = curr != value\n            except TypeError:\n                change = True\n\n            if change:\n                self.__values[col.name()] = (orig, value)\n\n        # broadcast the change event\n        if change:\n            if col.testFlag(col.Flags.I18n) and context.locale != 'all':\n                old_value = curr.get(context.locale) if isinstance(curr, dict) else curr\n                new_value = value.get(context.locale) if isinstance(value, dict) else value\n            else:\n                old_value = curr\n                new_value = value\n\n            event = orb.events.ChangeEvent(record=self, column=col, old=old_value, value=new_value)\n            if self.processEvent(event):\n                self.onChange(event)\n            if event.preventDefault:\n                with WriteLocker(self.__dataLock):\n                    orig, _ = self.__values.get(col.name(), (None, None))\n                    self.__values[col.name()] = (orig, curr)\n                return False\n            else:\n                return change\n        else:\n            return False", "response": "Sets the value for this record at the inputted column."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, values, **context):\n        schema = self.schema()\n        column_updates = {}\n        other_updates = {}\n        for key, value in values.items():\n            try:\n                column_updates[schema.column(key)] = value\n            except orb.errors.ColumnNotFound:\n                other_updates[key] = value\n\n        # update the columns in order\n        for col in sorted(column_updates.keys(), key=lambda x: x.order()):\n            self.set(col, column_updates[col], **context)\n\n        # update the other values\n        for key, value in other_updates.items():\n            try:\n                self.set(key, value, **context)\n            except orb.errors.ColumnValidationError:\n                pass\n\n        return len(values)", "response": "Updates the model with the given dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self, columns=None):\n        schema = self.schema()\n        if not columns:\n            ignore_flags = orb.Column.Flags.Virtual | orb.Column.Flags.ReadOnly\n            columns = schema.columns(flags=~ignore_flags).values()\n            use_indexes = True\n        else:\n            use_indexes = False\n\n        # validate the column values\n        values = self.values(key='column', columns=columns)\n        for col, value in values.items():\n            if not col.validate(value):\n                return False\n\n        # valide the index values\n        if use_indexes:\n            for index in self.schema().indexes().values():\n                if not index.validate(self, values):\n                    return False\n\n        return True", "response": "Validates the current record object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef values(self,\n               columns=None,\n               recurse=True,\n               flags=0,\n               mapper=None,\n               key='name',\n               **get_options):\n        \"\"\"\n        Returns a dictionary grouping the columns and their\n        current values.  If the inflated value is set to True,\n        then you will receive any foreign keys as inflated classes (if you\n        have any values that are already inflated in your class, then you\n        will still get back the class and not the primary key value).  Setting\n        the mapper option will map the value by calling the mapper method.\n\n        :param      useFieldNames | <bool>\n                    inflated | <bool>\n                    mapper | <callable> || None\n\n        :return     { <str> key: <variant>, .. }\n        \"\"\"\n        output = {}\n        schema = self.schema()\n\n        for column in columns or schema.columns(recurse=recurse, flags=flags).values():\n            column = column if isinstance(column, orb.Column) else schema.column(column)\n            try:\n                val_key = column if key == 'column' else getattr(column, key)()\n            except AttributeError:\n                raise errors.OrbError(\n                    'Invalid key used in data collection.  Must be name, field, or column.'\n                )\n            else:\n                value = self.get(column, **get_options)\n                output[val_key] = mapper(value) if mapper else value\n\n        return output", "response": "Returns a dictionary grouping the columns and their\n        current values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a callback method to the class.", "response": "def addCallback(cls, eventType, func, record=None, once=False):\n        \"\"\"\n        Adds a callback method to the class.  When an event of the given type is triggered, any registered\n        callback will be executed.\n\n        :param  eventType: <str>\n        :param  func: <callable>\n        \"\"\"\n        callbacks = cls.callbacks()\n        callbacks.setdefault(eventType, [])\n        callbacks[eventType].append((func, record, once))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of callback methods that can be invoked whenever an event is processed.", "response": "def callbacks(cls, eventType=None):\n        \"\"\"\n        Returns a list of callback methods that can be invoked whenever an event is processed.\n\n        :return: {subclass of <Event>: <list>, ..}\n        \"\"\"\n        key = '_{0}__callbacks'.format(cls.__name__)\n        try:\n            callbacks = getattr(cls, key)\n        except AttributeError:\n            callbacks = {}\n            setattr(cls, key, callbacks)\n\n        return callbacks.get(eventType, []) if eventType is not None else callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(cls, values, **context):\n        schema = cls.schema()\n        model = cls\n\n        # check for creating inherited classes from a sub class\n        polymorphic_columns = schema.columns(flags=orb.Column.Flags.Polymorphic)\n        if polymorphic_columns:\n            polymorphic_column = polymorphic_columns.values()[0]\n            schema_name = values.get(polymorphic_column.name(), schema.name())\n            if schema_name and schema_name != schema.name():\n                schema = orb.system.schema(schema_name)\n                if not schema:\n                    raise orb.errors.ModelNotFound(schema=schema_name)\n                else:\n                    model = schema.model()\n\n        column_values = {}\n        collector_values = {}\n\n        for key, value in values.items():\n            obj = schema.collector(key) or schema.column(key)\n            if isinstance(obj, orb.Collector):\n                collector_values[key] = value\n            else:\n                column_values[key] = value\n\n        # create the new record with column values (values stored on this record)\n        record = model(context=orb.Context(**context))\n        record.update(column_values)\n        record.save()\n\n        # save any collector values after the model is generated (values stored on other records)\n        record.update(collector_values)\n\n        return record", "response": "Returns a new record for this table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensureExists(cls, values, defaults=None, **context):\n        # require at least some arguments to be set\n        if not values:\n            return cls()\n\n        # lookup the record from the database\n        q = orb.Query()\n\n        for key, value in values.items():\n            column = cls.schema().column(key)\n            if not column:\n                raise orb.errors.ColumnNotFound(schema=cls.schema(), column=key)\n            elif column.testFlag(column.Flags.Virtual):\n                continue\n\n            if (isinstance(column, orb.AbstractStringColumn) and\n                not column.testFlag(column.Flags.CaseSensitive) and\n                not column.testFlag(column.Flags.I18n) and\n                isinstance(value, (str, unicode))):\n                q &= orb.Query(key).lower() == value.lower()\n            else:\n                q &= orb.Query(key) == value\n\n        record = cls.select(where=q).first()\n        if record is None:\n            record = cls(context=orb.Context(**context))\n            record.update(values)\n            record.update(defaults or {})\n            record.save()\n\n        return record", "response": "Ensures that a record for the given class exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess the given event by dispatching it to any waiting callbacks.", "response": "def processEvent(cls, event):\n        \"\"\"\n        Processes the given event by dispatching it to any waiting callbacks.\n\n        :param event: <orb.Event>\n        \"\"\"\n        callbacks = cls.callbacks(type(event))\n        keep_going = True\n        remove_callbacks = []\n\n        for callback, record, once in callbacks:\n            if record is not None and record != event.record:\n                continue\n\n            callback(event)\n            if once:\n                remove_callbacks.append((callback, record))\n\n            if event.preventDefault:\n                keep_going = False\n                break\n\n        for callback, record in remove_callbacks:\n            cls.removeCallback(type(event), callback, record=record)\n\n        return keep_going"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlook up a record based on the given key.", "response": "def fetch(cls, key, **context):\n        \"\"\"\n        Looks up a record based on the given key.  This will use the\n        default id field, as well as any keyable properties if the\n        given key is a string.\n\n        :param key: <variant>\n        :param context: <orb.Context>\n        :return: <orb.Model> || None\n        \"\"\"\n        # include any keyable columns for lookup\n        if isinstance(key, basestring) and not key.isdigit():\n            keyable_columns = cls.schema().columns(flags=orb.Column.Flags.Keyable)\n            if keyable_columns:\n                base_q = orb.Query()\n                for col in keyable_columns:\n                    base_q |= orb.Query(col) == key\n                context.setdefault('where', base_q)\n            else:\n                context.setdefault('where', orb.Query(cls) == key)\n        else:\n            context.setdefault('where', orb.Query(cls) == key)\n\n        # don't have slicing for lookup by id\n        context['page'] = None\n        context['pageSize'] = None\n        context['start'] = None\n        context['limit'] = None\n\n        return cls.select(**context).first()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new record instance for the given class with the values from the database.", "response": "def inflate(cls, values, **context):\n        \"\"\"\n        Returns a new record instance for the given class with the values\n        defined from the database.\n\n        :param      cls     | <subclass of orb.Table>\n                    values  | <dict> values\n\n        :return     <orb.Table>\n        \"\"\"\n        context = orb.Context(**context)\n\n        # inflate values from the database into the given class type\n        if isinstance(values, Model):\n            record = values\n            values = dict(values)\n        else:\n            record = None\n\n        schema = cls.schema()\n        polymorphs = schema.columns(flags=orb.Column.Flags.Polymorphic).values()\n        column = polymorphs[0] if polymorphs else None\n\n        # attempt to expand the class to its defined polymorphic type\n        if column and column.field() in values:\n            morph_cls_name = values.get(column.name(), values.get(column.field()))\n            morph_cls = orb.system.model(morph_cls_name)\n            id_col = schema.idColumn().name()\n            if morph_cls and morph_cls != cls:\n                try:\n                    record = morph_cls(values[id_col], context=context)\n                except KeyError:\n                    raise orb.errors.RecordNotFound(schema=morph_cls.schema(),\n                                                    column=values.get(id_col))\n\n        if record is None:\n            event = orb.events.LoadEvent(record=record, data=values)\n            record = cls(loadEvent=event, context=context)\n\n        return record"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a callback from the model s event callbacks.", "response": "def removeCallback(cls, eventType, func, record=None):\n        \"\"\"\n        Removes a callback from the model's event callbacks.\n\n        :param  eventType: <str>\n        :param  func: <callable>\n        \"\"\"\n        callbacks = cls.callbacks()\n        callbacks.setdefault(eventType, [])\n        for i in xrange(len(callbacks[eventType])):\n            my_func, my_record, _ = callbacks[eventType][i]\n            if func == my_func and record == my_record:\n                del callbacks[eventType][i]\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select(cls, **context):\n        rset_type = getattr(cls, 'Collection', orb.Collection)\n        return rset_type(model=cls, **context)", "response": "Select records for the given class based on the inputted options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jinja_template(template_name, name='data', mimetype=\"text/html\"):\n    def jinja_renderer(result, errors):\n        template = get_jinja_template(template_name)\n        context = {name: result or Mock(), 'errors': errors, 'enumerate': enumerate}\n        rendered = template.render(**context)\n        return {'body': rendered, 'mimetype': mimetype}\n    return jinja_renderer", "response": "Returns a function that renders a jinja template."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef partial_jinja_template(template_name, name='data', mimetype=\"text/html\"):\n    def partial_jinja_renderer(result, errors):\n        template = get_jinja_template(template_name)\n        old = template.environment.undefined\n        template.environment.undefined = DebugUndefined\n        context = {name: result or Mock(), 'errors': errors}\n        rendered = template.render(**context)\n        template.environment.undefined = old\n        return {'body': rendered, 'mimetype': mimetype}\n    return partial_jinja_renderer", "response": "Returns a function that renders a jinja template with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lazy_jinja_template(template_name, name='data', mimetype='text/html'):\n    def lazy_jinja_renderer(result, errors):\n        template = get_jinja_template(template_name)\n        context = {name: result or Mock(), 'errors': errors}\n        data = ('jinja2', template, context)\n        return {'body': data, 'mimetype': mimetype}\n    return lazy_jinja_renderer", "response": "Returns a Jinja template renderer that does not render the template at all."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters all renderers that are defined on this object.", "response": "def _register_renderers(self, attrs):\n        \"\"\"\n        Go through the passed in list of attributes and register those renderers\n        in the render map.\n        \"\"\"\n        for method in attrs:\n            func = getattr(self, method)\n            mimetypes = getattr(func, 'mimetypes', [])\n            for mimetype in mimetypes:\n                if not '/' in mimetype:\n                    self.reject_map[mimetype] = func\n                if mimetype not in self.render_map:\n                    self.render_map[mimetype] = func\n                else:\n                    # about to redefine an already defined renderer.\n                    # make sure this new render method is not on a base class.\n                    base_classes = self.__class__.mro()[1:]\n                    from_baseclass = any([x for x in base_classes if func.__name__ in dir(x)])\n                    if not from_baseclass:\n                        self.render_map[mimetype] = func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can_render(self, partial_mimetype):\n        for mime in self.render_map.keys():\n            if mime == '*/*':\n                return True\n            if partial_mimetype in mime:\n                return True\n        return False", "response": "Returns True if the view can render that type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, result, mimetype, errors=None):\n        available_mimetypes = [x for x in self.render_map.keys() if '/' in x]\n        render_func = None\n\n        if '/' not in mimetype:\n            # naked superformat (does not correspond to a mimetype)\n            render_func = self.reject_map.get(mimetype, None)\n            if not render_func:\n                raise NoViewMethod(\"Unknown Superformat: %s\" % mimetype)\n\n        if not render_func and available_mimetypes:\n            target_mimetype = mimeparse.best_match(available_mimetypes, mimetype)\n            render_func = self.render_map.get(target_mimetype, None)\n\n        if not render_func:\n            raise NoViewMethod(\"%s not supported for this program\" % mimetype)\n\n        principle_mimetype = render_func.mimetypes[0]\n\n        if GiottoControl in render_func.__class__.mro():\n            # redirection defined as view (not wrapped in lambda)\n            return {'body': render_func, 'persist': render_func.persist}\n\n        if callable(self.persist):\n            # persist (cookie data) can be either an object, or a callable)\n            persist = self.persist(result)\n        else:\n            persist = self.persist\n\n        # render functins can take either one or two arguments, both are\n        # supported by the API\n        arg_names = inspect.getargspec(render_func).args\n        num_args = len(set(arg_names) - set(['self', 'cls']))\n        if num_args == 2:\n            data = render_func(result, errors or Mock())\n        else:\n            # if the renderer only has one argument, don't pass in the 2nd arg.\n            data = render_func(result)\n\n        if GiottoControl in data.__class__.mro():\n            # render function returned a control object\n            return {'body': data, 'persist': persist}\n\n        if not hasattr(data, 'items'):\n            # view returned string\n            data = {'body': data, 'mimetype': principle_mimetype}\n        else:\n            # result is a dict in for form {body: XX, mimetype: xx}\n            if not 'mimetype' in data and target_mimetype == '*/*':\n                data['mimetype'] = ''\n\n            if not 'mimetype' in data:\n                data['mimetype'] = target_mimetype\n\n        data['persist'] = persist\n        return data", "response": "Render a model result into mimetype format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generic_html(self, result, errors):\n        h1 = htmlize(type(result))\n        out = []\n        result = pre_process_json(result)\n\n        if not hasattr(result, 'items'):\n            # result is a non-container\n            header = \"<tr><th>Value</th></tr>\"\n            if type(result) is list:\n                result = htmlize_list(result)\n            else:\n                result = htmlize(result)\n            out = [\"<tr><td>\" + result + \"</td></tr>\"]\n        elif hasattr(result, 'lower'):\n            out = [\"<tr><td>\" + result + \"</td></tr>\"]\n        else:\n            # object is a dict\n            header = \"<tr><th>Key</th><th>Value</th></tr>\"\n            for key, value in result.items():\n                v = htmlize(value)\n                row = \"<tr><td>{0}</td><td>{1}</td></tr>\".format(key, v)\n                out.append(row)\n\n        env = Environment(loader=PackageLoader('giotto'))\n        template = env.get_template('generic.html')\n        rendered = template.render({'header': h1, 'table_header': header, 'table_body': out})\n        return {'body': rendered, 'mimetype': 'text/html'}", "response": "Display any object in sensible HTML."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plaintext(self, result):\n        from PIL import Image\n\n        ascii_chars = ['#', 'A', '@', '%', 'S', '+', '<', '*', ':', ',', '.']\n\n        def image_to_ascii(image):\n            image_as_ascii = []\n            all_pixels = list(image.getdata())\n            for pixel_value in all_pixels:\n                index = pixel_value / 25 # 0 - 10\n                image_as_ascii.append(ascii_chars[index])\n            return image_as_ascii   \n\n        img = Image.open(result)\n        width, heigth = img.size\n        new_width = 80 \n        new_heigth = int((heigth * new_width) / width)\n        new_image = img.resize((new_width, new_heigth))\n        new_image = new_image.convert(\"L\") # convert to grayscale\n\n        # now that we have a grayscale image with some fixed width we have to convert every pixel\n        # to the appropriate ascii character from \"ascii_chars\"\n        img_as_ascii = image_to_ascii(new_image)\n        img_as_ascii = ''.join(ch for ch in img_as_ascii)\n        out = []\n        for c in range(0, len(img_as_ascii), new_width):\n            out.append(img_as_ascii[c:c+new_width])\n\n        return \"\\n\".join(out)", "response": "Converts the image object into an ascii representation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_twisted():\n    global emit, _call_partial\n    try:\n        from twisted.internet import defer\n        emit = _emit_twisted\n        _call_partial = defer.maybeDeferred\n        return True\n    except ImportError:\n        _call_partial = lambda fn, *a, **kw: fn(*a, **kw)\n        return False", "response": "Installs twisted if twisted is available make emit return a DeferredList\n    This has been successfully tested with Twisted 14. 0 and later."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit(signal, *args, **kwargs):\n    for callback in set(receivers[signal]):  # Make a copy in case of any ninja signals\n        _call(callback, args=args, kwargs=kwargs)", "response": "Emits a single signal to call callbacks registered to respond to that signal."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nemits a single signal to call callbacks registered to respond to that signal.", "response": "def _emit_twisted(signal, *args, **kwargs):\n    \"\"\"\n    Emits a single signal to call callbacks registered to respond to that signal.\n    Optionally accepts args and kwargs that are passed directly to callbacks.\n\n    :param signal: Signal to send\n    \"\"\"\n    errback = kwargs.pop('errback', lambda f: f)\n\n    dl = []\n    for callback in set(receivers[signal]):  # Make a copy in case of any ninja signals\n        d = _call(callback, args=args, kwargs=kwargs)\n        if d is not None:\n            dl.append(d.addErrback(errback))\n\n    def simplify(results):\n        return [x[1] for x in results]\n\n    from twisted.internet.defer import DeferredList\n    return DeferredList(dl).addCallback(simplify)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(callback, args=[], kwargs={}):\n    if not hasattr(callback, '_max_calls'):\n        callback._max_calls = None\n\n    # None implies no callback limit\n    if callback._max_calls is None:\n        return _call_partial(callback, *args, **kwargs)\n\n    # Should the signal be disconnected?\n    if callback._max_calls <= 0:\n        return disconnect(callback)\n\n    callback._max_calls -= 1\n\n    return _call_partial(callback, *args, **kwargs)", "response": "Calls a callback with optional args and keyword args lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a single callback for receiving an event or event list. Optionally a callback can be passed as a function that will be called with the args and kwargs as keyword arguments.", "response": "def on(signals, callback=None, max_calls=None):\n    \"\"\"\n    Registers a single callback for receiving an event (or event list). Optionally,\n    can specify a maximum number of times the callback should receive a signal. This\n    method works as both a function and a decorator::\n\n        smokesignal.on('foo', my_callback)\n\n        @smokesignal.on('foo')\n        def my_callback():\n            pass\n\n    :param signals: A single signal or list/tuple of signals that callback should respond to\n    :param callback: A callable that should repond to supplied signal(s)\n    :param max_calls: Integer maximum calls for callback. None for no limit.\n    \"\"\"\n    if isinstance(callback, int) or callback is None:\n        # Decorated\n        if isinstance(callback, int):\n            # Here the args were passed arg-style, not kwarg-style\n            callback, max_calls = max_calls, callback\n        return partial(_on, signals, max_calls=max_calls)\n    elif isinstance(callback, types.MethodType):\n        # callback is a bound instance method, so we need to wrap it in a function\n        def _callback(*args, **kwargs):\n            return callback(*args, **kwargs)\n        return _on(signals, _callback, max_calls=max_calls)\n    else:\n        # Function call\n        return _on(signals, callback, max_calls=max_calls)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a callback from the specified signal registries and prevents it from responding to any emitted signal.", "response": "def disconnect_from(callback, signals):\n    \"\"\"\n    Removes a callback from specified signal registries and prevents it from responding\n    to any emitted signal.\n\n    :param callback: A callable registered with smokesignal\n    :param signals: A single signal or list/tuple of signals\n    \"\"\"\n    # Support for lists of signals\n    if not isinstance(signals, (list, tuple)):\n        signals = [signals]\n\n    # Remove callback from receiver list if it responds to the signal\n    for signal in signals:\n        if responds_to(callback, signal):\n            receivers[signal].remove(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear(*signals):\n    signals = signals if signals else receivers.keys()\n\n    for signal in signals:\n        receivers[signal].clear()", "response": "Clears all callbacks for a particular signal or all signals."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef columns(self):\n        schema = self.schema()\n        return [schema.column(col) for col in self.__columns]", "response": "Returns the list of column names that this index expects as \\\n        \n        inputs when it is called."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate whether or not this index s requirements are satisfied by the inputted record and values.", "response": "def validate(self, record, values):\n        \"\"\"\n        Validates whether or not this index's requirements are satisfied by the inputted record and\n        values.  If this index fails validation, a ValidationError will be raised.\n\n        :param      record | subclass of <orb.Table>\n                    values | {<orb.Column>: <variant>, ..}\n\n        :return     <bool>\n        \"\"\"\n        schema = record.schema()\n        columns = self.columns()\n        try:\n            column_values = [values[col] for col in columns]\n        except KeyError as err:\n            msg = 'Missing {0} from {1}.{2} index'.format(err[0].name(),\n                                                          record.schema().name(),\n                                                          self.name())\n            raise errors.InvalidIndexArguments(self.schema(), msg=msg)\n\n        # # ensure a unique record is preserved\n        # if self.unique():\n        #     lookup = getattr(record, self.name())\n        #     other = lookup(*column_values)\n        #     if other and other != record:\n        #         msg = 'A record already exists with the same {0} combination.'.format(', '.join(self.columnNames()))\n        #         raise errors.IndexValidationError(self, msg=msg)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef onSync(self, event):\n        SETUP = self.statement('SETUP')\n        if SETUP:\n            sql, data = SETUP(self.database())\n            if event.context.dryRun:\n                print sql % data\n            else:\n                self.execute(sql, data, writeAccess=True)", "response": "Initializes the database by defining any additional structures that are required during selection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        for pool in self.__pool.values():\n            while not pool.empty():\n                conn = pool.get_nowait()\n                try:\n                    self._close(conn)\n                except Exception:\n                    pass\n\n        # reset the pool size after closing all connections\n        self.__poolSize.clear()", "response": "Closes the connection to the database for this entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count(self, model, context):\n        SELECT_COUNT = self.statement('SELECT COUNT')\n\n        try:\n            sql, data = SELECT_COUNT(model, context)\n        except orb.errors.QueryIsNull:\n            return 0\n        else:\n            if context.dryRun:\n                print sql % data\n                return 0\n            else:\n                try:\n                    rows, _ = self.execute(sql, data)\n                except orb.errors.EmptyCommand:\n                    rows = []\n\n                return sum([row['count'] for row in rows])", "response": "Returns the number of records loaded for the inputted\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commit(self):\n        with self.native(writeAccess=True) as conn:\n            if not self._closed(conn):\n                return self._commit(conn)", "response": "Commits the changes to the current database connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createModel(self, model, context, owner='', includeReferences=True):\n        CREATE = self.statement('CREATE')\n        sql, data = CREATE(model, includeReferences=includeReferences, owner=owner)\n        if not sql:\n            log.error('Failed to create {0}'.format(model.schema().dbname()))\n            return False\n        else:\n            if context.dryRun:\n                print sql % data\n            else:\n                self.execute(sql, data, writeAccess=True)\n\n            log.info('Created {0}'.format(model.schema().dbname()))\n            return True", "response": "Creates a new table in the database based cff the inputted\n        schema information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, records, context):\n        # include various schema records to remove\n        DELETE = self.statement('DELETE')\n        sql, data = DELETE(records, context)\n\n        if context.dryRun:\n            print sql % data\n            return 0\n        else:\n            return self.execute(sql, data, writeAccess=True)", "response": "Removes the inputted record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the specified command into the current connection cursor.", "response": "def execute(self,\n                command,\n                data=None,\n                returning=True,\n                mapper=dict,\n                writeAccess=False,\n                dryRun=False,\n                locale=None):\n        \"\"\"\n        Executes the inputted command into the current \\\n        connection cursor.\n\n        :param      command    | <str>\n                    data       | <dict> || None\n                    autoCommit | <bool> | commit database changes immediately\n                    autoClose  | <bool> | closes connections immediately\n                    returning  | <bool>\n                    mapper     | <variant>\n                    retries    | <int>\n\n        :return     [{<str> key: <variant>, ..}, ..], <int> rowcount\n        \"\"\"\n        command = command.strip()\n\n        if not command:\n            raise orb.errors.EmptyCommand()\n        elif dryRun:\n            print command % data\n            raise orb.errors.DryRun()\n\n        # define properties for execution\n        data = data or {}\n        command = command.strip()\n        data.setdefault('locale', locale or orb.Context().locale)\n        start = datetime.datetime.now()\n\n        try:\n            with self.native(writeAccess=writeAccess) as conn:\n                results, rowcount = self._execute(conn,\n                                                  command,\n                                                  data,\n                                                  returning,\n                                                  mapper)\n\n        # always raise interruption errors as these need to be handled\n        # from a thread properly\n        except orb.errors.Interruption:\n            delta = datetime.datetime.now() - start\n            log.critical('Query took: %s' % delta)\n            raise\n\n        # handle any known a database errors with feedback information\n        except orb.errors.DatabaseError as err:\n            delta = datetime.datetime.now() - start\n            log.error(u'{0}: \\n {1}'.format(err, command))\n            log.error('Query took: %s' % delta)\n            raise\n\n        # always raise any unknown issues for the developer\n        except StandardError as err:\n            delta = datetime.datetime.now() - start\n            log.error(u'{0}: \\n {1}'.format(err, command))\n            log.error('Query took: %s' % delta)\n            raise\n\n        delta = (datetime.datetime.now() - start).total_seconds()\n        if delta * 1000 < 3000:\n            lvl = logging.DEBUG\n        elif delta * 1000 < 6000:\n            lvl = logging.WARNING\n        else:\n            lvl = logging.CRITICAL\n\n        log.log(lvl, 'Query took: %s' % delta)\n\n        return results, rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, records, context):\n        INSERT = self.statement('INSERT')\n        sql, data = INSERT(records)\n        if context.dryRun:\n            print sql, data\n            return [], 0\n        else:\n            return self.execute(sql, data, writeAccess=True)", "response": "Inserts the given records into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether or not this connection is currently connected to a specific instance of the class.", "response": "def isConnected(self):\n        \"\"\"\n        Returns whether or not this connection is currently\n        active.\n\n        :return     <bool> connected\n        \"\"\"\n        for pool in self.__pool.values():\n            if not pool.empty():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef native(self, writeAccess=False, isolation_level=None):\n        host = self.database().writeHost() if writeAccess else self.database().host()\n        conn = self.open(writeAccess=writeAccess)\n        try:\n            if isolation_level is not None:\n                if conn.isolation_level == isolation_level:\n                    isolation_level = None\n                else:\n                    conn.set_isolation_level(isolation_level)\n            yield conn\n        except Exception:\n            if self._closed(conn):\n                conn = None\n                self.close()\n            else:\n                conn = self._rollback(conn)\n            raise\n        else:\n            if not self._closed(conn):\n                self._commit(conn)\n        finally:\n            if conn is not None and not self._closed(conn):\n                if isolation_level is not None:\n                    conn.set_isolation_level(isolation_level)\n                self.__pool[host].put(conn)", "response": "Returns a new native connection to the database defined by the inputted database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open(self, writeAccess=False):\n        host = self.database().writeHost() if writeAccess else self.database().host()\n        pool = self.__pool[host]\n\n        if self.__poolSize[host] >= self.__maxSize or pool.qsize():\n            if pool.qsize() == 0:\n                log.warning('Waiting for connection to database!!!')\n            return pool.get()\n        else:\n            db = self.database()\n\n            # process a pre-connect event\n            event = orb.events.ConnectionEvent()\n            db.onPreConnect(event)\n\n            self.__poolSize[host] += 1\n            try:\n                conn = self._open(self.database(), writeAccess=writeAccess)\n            except Exception:\n                self.__poolSize[host] -= 1\n                raise\n            else:\n                event = orb.events.ConnectionEvent(success=conn is not None, native=conn)\n                db.onPostConnect(event)\n                return conn", "response": "Returns the sqlite database for the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nroll back changes to this database.", "response": "def rollback(self):\n        \"\"\"\n        Rolls back changes to this database.\n        \"\"\"\n        with self.native(writeAccess=True) as conn:\n            return self._rollback(conn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the modified data for the current record.", "response": "def update(self, records, context):\n        \"\"\"\n        Updates the modified data in the database for the\n        inputted record.  If the dryRun flag is specified then\n        the command will be logged but not executed.\n\n        :param      record   | <orb.Table>\n                    lookup   | <orb.LookupOptions>\n                    options  | <orb.Context>\n\n        :return     <dict> changes\n        \"\"\"\n        UPDATE = self.statement('UPDATE')\n        sql, data = UPDATE(records)\n        if context.dryRun:\n            print sql, data\n            return [], 0\n        else:\n            return self.execute(sql, data, writeAccess=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the type of a valid object.", "response": "def type(self):\n        \"\"\"\n        Type of a valid object.\n\n        Type may be a JSON type name or a list of such names. Valid JSON type\n        names are ``string``, ``number``, ``integer``, ``boolean``, ``object``,\n        ``array``, ``any`` (default).\n        \"\"\"\n        value = self._schema.get(\"type\", \"any\")\n        if not isinstance(value, (basestring, dict, list)):\n            raise SchemaError(\n                \"type value {0!r} is not a simple type name, nested \"\n                \"schema nor a list of those\".format(value))\n        if isinstance(value, list):\n            type_list = value\n            # Union types have to have at least two alternatives\n            if len(type_list) < 2:\n                raise SchemaError(\n                    \"union type {0!r} is too short\".format(value))\n        else:\n            type_list = [value]\n        seen = set()\n        for js_type in type_list:\n            if isinstance(js_type, dict):\n                # no nested validation here\n                pass\n            elif isinstance(js_type, list):\n                # no nested validation here\n                pass\n            else:\n                if js_type in seen:\n                    raise SchemaError(\n                        (\"type value {0!r} contains duplicate element\"\n                         \" {1!r}\").format(value, js_type))\n                else:\n                    seen.add(js_type)\n                if js_type not in (\n                    \"string\", \"number\", \"integer\", \"boolean\", \"object\",\n                    \"array\", \"null\", \"any\"):\n                    raise SchemaError(\n                        \"type value {0!r} is not a simple type \"\n                        \"name\".format(js_type))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef properties(self):\n        value = self._schema.get(\"properties\", {})\n        if not isinstance(value, dict):\n            raise SchemaError(\n                \"properties value {0!r} is not an object\".format(value))\n        return value", "response": "Schema for particular properties of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef items(self):\n        value = self._schema.get(\"items\", {})\n        if not isinstance(value, (list, dict)):\n            raise SchemaError(\n                \"items value {0!r} is neither a list nor an object\".\n                format(value))\n        return value", "response": "Return the items of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optional(self):\n        value = self._schema.get(\"optional\", False)\n        if value is not False and value is not True:\n            raise SchemaError(\n                \"optional value {0!r} is not a boolean\".format(value))\n        return value", "response": "Flag indicating an optional property."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef additionalProperties(self):\n        value = self._schema.get(\"additionalProperties\", {})\n        if not isinstance(value, dict) and value is not False:\n            raise SchemaError(\n                \"additionalProperties value {0!r} is neither false nor\"\n                \" an object\".format(value))\n        return value", "response": "Schema for all additional properties or False."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maximum(self):\n        value = self._schema.get(\"maximum\", None)\n        if value is None:\n            return\n        if not isinstance(value, NUMERIC_TYPES):\n            raise SchemaError(\n                \"maximum value {0!r} is not a numeric type\".format(\n                    value))\n        return value", "response": "Maximum value of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflags indicating if maximum value is inclusive or exclusive.", "response": "def minimumCanEqual(self):\n        \"\"\"Flag indicating if maximum value is inclusive or exclusive.\"\"\"\n        if self.minimum is None:\n            raise SchemaError(\"minimumCanEqual requires presence of minimum\")\n        value = self._schema.get(\"minimumCanEqual\", True)\n        if value is not True and value is not False:\n            raise SchemaError(\n                \"minimumCanEqual value {0!r} is not a boolean\".format(\n                    value))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maximumCanEqual(self):\n        if self.maximum is None:\n            raise SchemaError(\"maximumCanEqual requires presence of maximum\")\n        value = self._schema.get(\"maximumCanEqual\", True)\n        if value is not True and value is not False:\n            raise SchemaError(\n                \"maximumCanEqual value {0!r} is not a boolean\".format(\n                    value))\n        return value", "response": "Flag indicating if the minimum value is inclusive or exclusive."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pattern(self):\n        value = self._schema.get(\"pattern\", None)\n        if value is None:\n            return\n        try:\n            return re.compile(value)\n        except re.error as ex:\n            raise SchemaError(\n                \"pattern value {0!r} is not a valid regular expression:\"\n                \" {1}\".format(value, str(ex)))", "response": "Returns a compiled regular expression describing the valid object s keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef maxLength(self):\n        value = self._schema.get(\"maxLength\", None)\n        if value is None:\n            return\n        if not isinstance(value, int):\n            raise SchemaError(\n                \"maxLength value {0!r} is not an integer\".format(value))\n        return value", "response": "Maximum length of object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enum(self):\n        value = self._schema.get(\"enum\", None)\n        if value is None:\n            return\n        if not isinstance(value, list):\n            raise SchemaError(\n                \"enum value {0!r} is not a list\".format(value))\n        if len(value) == 0:\n            raise SchemaError(\n                \"enum value {0!r} does not contain any\"\n                \" elements\".format(value))\n        seen = set()\n        for item in value:\n            if item in seen:\n                raise SchemaError(\n                    \"enum value {0!r} contains duplicate element\"\n                    \" {1!r}\".format(value, item))\n            else:\n                seen.add(item)\n        return value", "response": "Return the enumeration of allowed object values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the title of the object.", "response": "def title(self):\n        \"\"\"\n        Title of the object.\n\n        This schema element is purely informative.\n        \"\"\"\n        value = self._schema.get(\"title\", None)\n        if value is None:\n            return\n        if not isinstance(value, basestring):\n            raise SchemaError(\n                \"title value {0!r} is not a string\".format(value))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format(self):\n        value = self._schema.get(\"format\", None)\n        if value is None:\n            return\n        if not isinstance(value, basestring):\n            raise SchemaError(\n                \"format value {0!r} is not a string\".format(value))\n        if value in [\n            'date-time',\n            'regex',\n        ]:\n            return value\n        raise NotImplementedError(\n            \"format value {0!r} is not supported\".format(value))", "response": "Format of the ( string ) object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef divisibleBy(self):\n        value = self._schema.get(\"divisibleBy\", 1)\n        if value is None:\n            return\n        if not isinstance(value, NUMERIC_TYPES):\n            raise SchemaError(\n                \"divisibleBy value {0!r} is not a numeric type\".\n                format(value))\n        if value < 0:\n            raise SchemaError(\n                \"divisibleBy value {0!r} cannot be\"\n                \" negative\".format(value))\n        return value", "response": "Integer that divides the object without reminder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disallow(self):\n        value = self._schema.get(\"disallow\", None)\n        if value is None:\n            return\n        if not isinstance(value, (basestring, dict, list)):\n            raise SchemaError(\n                \"disallow value {0!r} is not a simple type name, nested \"\n                \"schema nor a list of those\".format(value))\n        if isinstance(value, list):\n            disallow_list = value\n        else:\n            disallow_list = [value]\n        seen = set()\n        for js_disallow in disallow_list:\n            if isinstance(js_disallow, dict):\n                # no nested validation here\n                pass\n            else:\n                if js_disallow in seen:\n                    raise SchemaError(\n                        \"disallow value {0!r} contains duplicate element\"\n                        \" {1!r}\".format(value, js_disallow))\n                else:\n                    seen.add(js_disallow)\n                if js_disallow not in (\n                    \"string\", \"number\", \"integer\", \"boolean\", \"object\",\n                    \"array\", \"null\", \"any\"):\n                    raise SchemaError(\n                        \"disallow value {0!r} is not a simple type\"\n                        \" name\".format(js_disallow))\n        return disallow_list", "response": "Description of disallowed objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates specified JSON text with specified schema.", "response": "def validate(schema_text, data_text, deserializer=_default_deserializer):\n    \"\"\"\n    Validate specified JSON text with specified schema.\n\n    Both arguments are converted to JSON objects with :func:`simplejson.loads`,\n    if present, or :func:`json.loads`.\n\n    :param schema_text:\n        Text of the JSON schema to check against\n    :type schema_text:\n        :class:`str`\n    :param data_text:\n        Text of the JSON object to check\n    :type data_text:\n        :class:`str`\n    :param deserializer:\n        Function to convert the schema and data to JSON objects\n    :type deserializer:\n        :class:`callable`\n    :returns:\n        Same as :meth:`json_schema_validator.validator.Validator.validate`\n    :raises:\n        Whatever may be raised by simplejson (in particular\n        :class:`simplejson.decoder.JSONDecoderError`, a subclass of\n        :class:`ValueError`) or json\n    :raises:\n        Whatever may be raised by\n        :meth:`json_schema_validator.validator.Validator.validate`. In particular\n        :class:`json_schema_validator.errors.ValidationError` and\n        :class:`json_schema_validator.errors.SchemaError`\n    \"\"\"\n    schema = Schema(deserializer(schema_text))\n    data = deserializer(data_text)\n    return Validator.validate(schema, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef activate_user(activation_key):\n    # Make sure the key we're trying conforms to the pattern of a\n    # SHA1 hash; if it doesn't, no point trying to look it up in\n    # the database.\n    if SHA1_RE.search(activation_key):\n        try:\n            profile = RegistrationProfile.objects.get(\n                activation_key=activation_key)\n        except RegistrationProfile.DoesNotExist:\n            return False\n        if not profile.activation_key_expired():\n            user = profile.user\n            user.is_active = True\n            user.save()\n            profile.activation_key = RegistrationProfile.ACTIVATED\n            profile.save()\n            return user\n    return False", "response": "Validate an activation key and activate the corresponding User."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends an activation email to the user.", "response": "def send_activation_email(user, site):\n    \"\"\"\n    Send an activation email to the ``user``.\n    The activation email will make use of two templates:\n\n    ``registration/activation_email_subject.txt``\n    This template will be used for the subject line of the\n    email. Because it is used as the subject line of an email,\n    this template's output **must** be only a single line of\n    text; output longer than one line will be forcibly joined\n    into only a single line.\n\n    ``registration/activation_email.txt``\n    This template will be used for the body of the email.\n\n    These templates will each receive the following context\n    variables:\n\n    ``activation_key``\n    The activation key for the new account.\n\n    ``expiration_days``\n    The number of days remaining during which the account may\n    be activated.\n\n    ``site``\n    An object representing the site on which the user\n    registered; depending on whether ``django.contrib.sites``\n    is installed, this may be an instance of either\n    ``django.contrib.sites.models.Site`` (if the sites\n    application is installed) or\n    ``django.contrib.sites.models.RequestSite`` (if\n    not). Consult the documentation for the Django sites\n    framework for details regarding these objects' interfaces.\n\n    \"\"\"\n    ctx_dict = {'activation_key': user.api_registration_profile.activation_key,\n                'expiration_days': get_settings('REGISTRATION_API_ACCOUNT_ACTIVATION_DAYS'),\n                'site': site}\n    subject = render_to_string('registration_api/activation_email_subject.txt',\n                               ctx_dict)\n    # Email subject *must not* contain newlines\n    subject = ''.join(subject.splitlines())\n    message = render_to_string('registration_api/activation_email.txt',\n                               ctx_dict)\n    user.email_user(subject, message, settings.DEFAULT_FROM_EMAIL)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, start, end):\n        return [self.read_byte(addr) for addr in range(start, end)]", "response": "Get a list of bytes from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprograms control is returned from the subroutine to the calling program. The return address is pulled from the stack. source code forms: RTS CC bits \"HNZVC\": -----", "response": "def instruction_RTS(self, opcode):\n        \"\"\"\n        Program control is returned from the subroutine to the calling program.\n        The return address is pulled from the stack.\n\n        source code forms: RTS\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        ea = self.pull_word(self.system_stack_pointer)\n#        log.info(\"%x|\\tRTS to $%x \\t| %s\" % (\n#            self.last_op_address,\n#            ea,\n#            self.cfg.mem_info.get_shortest(ea)\n#        ))\n        self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef instruction_BSR_JSR(self, opcode, ea):\n#        log.info(\"%x|\\tJSR/BSR to $%x \\t| %s\" % (\n#            self.last_op_address,\n#            ea, self.cfg.mem_info.get_shortest(ea)\n#        ))\n        self.push_word(self.system_stack_pointer, self.program_counter.value)\n        self.program_counter.set(ea)", "response": "This instruction handles the BSR and JSR instruction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting the state of the Z (zero) bit and causes a branch if it is set. When used after a subtract or compare operation, this instruction will branch if the compared values, signed or unsigned, were exactly the same. source code forms: BEQ dd; LBEQ DDDD CC bits \"HNZVC\": -----", "response": "def instruction_BEQ(self, opcode, ea):\n        \"\"\"\n        Tests the state of the Z (zero) bit and causes a branch if it is set.\n        When used after a subtract or compare operation, this instruction will\n        branch if the compared values, signed or unsigned, were exactly the\n        same.\n\n        source code forms: BEQ dd; LBEQ DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if self.Z == 1:\n#            log.info(\"$%x BEQ branch to $%x, because Z==1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncause a branch if the N (negative) bit and the V (overflow) bit are either both set or both clear. That is, branch if the sign of a valid twos complement result is, or would be, positive. When used after a subtract or compare operation on twos complement values, this instruction will branch if the register was greater than or equal to the memory register. source code forms: BGE dd; LBGE DDDD CC bits \"HNZVC\": -----", "response": "def instruction_BGE(self, opcode, ea):\n        \"\"\"\n        Causes a branch if the N (negative) bit and the V (overflow) bit are\n        either both set or both clear. That is, branch if the sign of a valid\n        twos complement result is, or would be, positive. When used after a\n        subtract or compare operation on twos complement values, this\n        instruction will branch if the register was greater than or equal to the\n        memory register.\n\n        source code forms: BGE dd; LBGE DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        # Note these variantes are the same:\n        #    self.N == self.V\n        #    (self.N ^ self.V) == 0\n        #    not operator.xor(self.N, self.V)\n        if self.N == self.V:\n#            log.info(\"$%x BGE branch to $%x, because N XOR V == 0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_BGT(self, opcode, ea):\n        # Note these variantes are the same:\n        #    not ((self.N ^ self.V) == 1 or self.Z == 1)\n        #    not ((self.N ^ self.V) | self.Z)\n        #    self.N == self.V and self.Z == 0\n        # ;)\n        if not self.Z and self.N == self.V:\n#            log.info(\"$%x BGT branch to $%x, because (N==V and Z==0) \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)", "response": "Branch the branch if the N and V bits are set and the Z bits are set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_BHI(self, opcode, ea):\n        if self.C == 0 and self.Z == 0:\n#            log.info(\"$%x BHI branch to $%x, because C==0 and Z==0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)", "response": "Branch to the next binary value of the entry in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbranch to the next binary value of the entry in the memory.", "response": "def instruction_BLS(self, opcode, ea):\n        \"\"\"\n        Causes a branch if the previous operation caused either a carry or a\n        zero result. When used after a subtract or compare operation on unsigned\n        binary values, this instruction will branch if the register was lower\n        than or the same as the memory register.\n\n        Generally not useful after INC/DEC, LD/ST, and TST/CLR/COM instructions.\n\n        source code forms: BLS dd; LBLS DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n#         if (self.C|self.Z) == 0:\n        if self.C == 1 or self.Z == 1:\n#            log.info(\"$%x BLS branch to $%x, because C|Z==1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbranching to the next binary value of the entry in the cache.", "response": "def instruction_BLT(self, opcode, ea):\n        \"\"\"\n        Causes a branch if either, but not both, of the N (negative) or V\n        (overflow) bits is set. That is, branch if the sign of a valid twos\n        complement result is, or would be, negative. When used after a subtract\n        or compare operation on twos complement binary values, this instruction\n        will branch if the register was less than the memory register.\n\n        source code forms: BLT dd; LBLT DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if (self.N ^ self.V) == 1: # N xor V\n#            log.info(\"$%x BLT branch to $%x, because N XOR V == 1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbranch to the appropriate entry in the cache.", "response": "def instruction_BMI(self, opcode, ea):\n        \"\"\"\n        Tests the state of the N (negative) bit and causes a branch if set. That\n        is, branch if the sign of the twos complement result is negative.\n\n        When used after an operation on signed binary values, this instruction\n        will branch if the result is minus. It is generally preferred to use the\n        LBLT instruction after signed operations.\n\n        source code forms: BMI dd; LBMI DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if self.N == 1:\n#            log.info(\"$%x BMI branch to $%x, because N==1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_BNE(self, opcode, ea):\n        if self.Z == 0:\n#            log.info(\"$%x BNE branch to $%x, because Z==0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)", "response": "Branch the memory register at the specified address ea."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbranching to the next binary entry in the memory.", "response": "def instruction_BPL(self, opcode, ea):\n        \"\"\"\n        Tests the state of the N (negative) bit and causes a branch if it is\n        clear. That is, branch if the sign of the twos complement result is\n        positive.\n\n        When used after an operation on signed binary values, this instruction\n        will branch if the result (possibly invalid) is positive. It is\n        generally preferred to use the BGE instruction after signed operations.\n\n        source code forms: BPL dd; LBPL DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if self.N == 0:\n#            log.info(\"$%x BPL branch to $%x, because N==0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbranching to the next binary value in the memory.", "response": "def instruction_BVC(self, opcode, ea):\n        \"\"\"\n        Tests the state of the V (overflow) bit and causes a branch if it is\n        clear. That is, branch if the twos complement result was valid. When\n        used after an operation on twos complement binary values, this\n        instruction will branch if there was no overflow.\n\n        source code forms: BVC dd; LBVC DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if self.V == 0:\n#            log.info(\"$%x BVC branch to $%x, because V==0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbranch to the next binary value in the memory.", "response": "def instruction_BVS(self, opcode, ea):\n        \"\"\"\n        Tests the state of the V (overflow) bit and causes a branch if it is\n        set. That is, branch if the twos complement result was invalid. When\n        used after an operation on twos complement binary values, this\n        instruction will branch if there was an overflow.\n\n        source code forms: BVS dd; LBVS DDDD\n\n        CC bits \"HNZVC\": -----\n        \"\"\"\n        if self.V == 1:\n#            log.info(\"$%x BVS branch to $%x, because V==1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instruction_BLO(self, opcode, ea):\n        if self.C == 1:\n#            log.info(\"$%x BLO/BCS/LBLO/LBCS branch to $%x, because C==1 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)", "response": "Branch to the next BLO branch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instruction_BHS(self, opcode, ea):\n        if self.C == 0:\n#            log.info(\"$%x BHS/BCC/LBHS/LBCC branch to $%x, because C==0 \\t| %s\" % (\n#                self.program_counter, ea, self.cfg.mem_info.get_shortest(ea)\n#            ))\n            self.program_counter.set(ea)", "response": "Branch BHS branch to the appropriate location."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes a datetime. timedelta instance to a string", "response": "def to_json(cls, obj):\n        \"\"\"\n        Serialize wrapped datetime.timedelta instance to a string the\n        with the following format:\n            [DAYS]d [SECONDS]s [MICROSECONDS]us\n        \"\"\"\n        return \"{0}d {1}s {2}us\".format(\n                obj.days, obj.seconds, obj.microseconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_json(cls, doc):\n        if not isinstance(doc, basestring):\n            raise TypeError(\"JSON document must be a string\")\n        match = cls.PATTERN.match(doc)\n        if not match:\n            raise ValueError(\"JSON document must match expected pattern\")\n        days, seconds, microseconds = map(int, match.groups())\n        return timedelta(days, seconds, microseconds)", "response": "Deserialize a JSON string to datetime. timedelta instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the contents of the memory location M to the designated value.", "response": "def instruction_LD16(self, opcode, m, register):\n        \"\"\"\n        Load the contents of the memory location M:M+1 into the designated\n        16-bit register.\n\n        source code forms: LDD P; LDX P; LDY P; LDS P; LDU P\n\n        CC bits \"HNZVC\": -aa0-\n        \"\"\"\n#        log.debug(\"$%x LD16 set %s to $%x \\t| %s\" % (\n#            self.program_counter,\n#            register.name, m,\n#            self.cfg.mem_info.get_shortest(m)\n#        ))\n        register.set(m)\n        self.clear_NZV()\n        self.update_NZ_16(m)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef instruction_LD8(self, opcode, m, register):\n#        log.debug(\"$%x LD8 %s = $%x\" % (\n#            self.program_counter,\n#            register.name, m,\n#        ))\n        register.set(m)\n        self.clear_NZV()\n        self.update_NZ_8(m)", "response": "Load the contents of memory location M into the designated register."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the contents of a 16-bit register into two consecutive memory locations. source code forms: STD P; STX P; STY P; STS P; STU P CC bits \"HNZVC\": -aa0-", "response": "def instruction_ST16(self, opcode, ea, register):\n        \"\"\"\n        Writes the contents of a 16-bit register into two consecutive memory\n        locations.\n\n        source code forms: STD P; STX P; STY P; STS P; STU P\n\n        CC bits \"HNZVC\": -aa0-\n        \"\"\"\n        value = register.value\n#        log.debug(\"$%x ST16 store value $%x from %s at $%x \\t| %s\" % (\n#             self.program_counter,\n#             value, register.name, ea,\n#             self.cfg.mem_info.get_shortest(ea)\n#         ))\n        self.clear_NZV()\n        self.update_NZ_16(value)\n        return ea, value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the contents of an 8-bit register into a memory location. source code forms: STA P; STB P CC bits \"HNZVC\": -aa0-", "response": "def instruction_ST8(self, opcode, ea, register):\n        \"\"\"\n        Writes the contents of an 8-bit register into a memory location.\n\n        source code forms: STA P; STB P\n\n        CC bits \"HNZVC\": -aa0-\n        \"\"\"\n        value = register.value\n#        log.debug(\"$%x ST8 store value $%x from %s at $%x \\t| %s\" % (\n#             self.program_counter,\n#             value, register.name, ea,\n#             self.cfg.mem_info.get_shortest(ea)\n#         ))\n        self.clear_NZV()\n        self.update_NZ_8(value)\n        return ea, value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_native(self, obj):\n        ret = super(UserSerializer, self).to_native(obj)\n        del ret['password']\n        return ret", "response": "Remove password field when serializing an object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serve_websocket(request, port):\n    env = request.environ\n\n    # Send HTTP response 101 Switch Protocol downstream\n    uwsgi.websocket_handshake(env['HTTP_SEC_WEBSOCKET_KEY'], env.get('HTTP_ORIGIN', ''))\n\n    # Map the websocket URL to the upstream localhost:4000x Notebook instance\n    parts = urlparse(request.url)\n    parts = parts._replace(scheme=\"ws\", netloc=\"localhost:{}\".format(port))\n    url = urlunparse(parts)\n\n    # Proxy initial connection headers\n    headers = [(header, value) for header, value in request.headers.items() if header.lower() in CAPTURE_CONNECT_HEADERS]\n\n    logger.info(\"Connecting to upstream websockets: %s, headers: %s\", url, headers)\n\n    ws = ProxyClient(url, headers=headers)\n    ws.connect()\n\n    # TODO: Will complain loudly about already send headers - how to abort?\n    return httpexceptions.HTTPOk()", "response": "Start UWSGI websocket loop and proxy."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of headers appropriate for the upgrade.", "response": "def handshake_headers(self):\n        \"\"\"\n        List of headers appropriate for the upgrade\n        handshake.\n        \"\"\"\n        headers = [\n            ('Host', self.host),\n            ('Connection', 'Upgrade'),\n            ('Upgrade', 'WebSocket'),\n            ('Sec-WebSocket-Key', self.key.decode('utf-8')),\n            # Origin is proxyed from the downstream server, don't set it twice\n            # ('Origin', self.url),\n            ('Sec-WebSocket-Version', str(max(WS_VERSION)))\n        ]\n\n        if self.protocols:\n            headers.append(('Sec-WebSocket-Protocol', ','.join(self.protocols)))\n\n        if self.extra_headers:\n            headers.extend(self.extra_headers)\n\n        logger.info(\"Handshake headers: %s\", headers)\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef received_message(self, m):\n\n        # TODO: No support for binary messages\n        m = str(m)\n        logger.debug(\"Incoming upstream WS: %s\", m)\n        uwsgi.websocket_send(m)\n        logger.debug(\"Send ok\")", "response": "Push upstream messages to downstream."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n\n        self.sock.setblocking(False)\n        try:\n            while not self.terminated:\n                logger.debug(\"Doing nothing\")\n                time.sleep(0.050)\n\n                logger.debug(\"Asking for downstream msg\")\n                msg = uwsgi.websocket_recv_nb()\n                if msg:\n                    logger.debug(\"Incoming downstream WS: %s\", msg)\n                    self.send(msg)\n\n                s = self.stream\n\n                self.opened()\n\n                logger.debug(\"Asking for upstream msg {s}\".format(s=s))\n                try:\n                    bytes = self.sock.recv(self.reading_buffer_size)\n                    if bytes:\n                        self.process(bytes)\n                except BlockingIOError:\n                    pass\n\n        except Exception as e:\n            logger.exception(e)\n        finally:\n            logger.info(\"Terminating WS proxy loop\")\n            self.terminate()", "response": "This function is called by the main thread. It loops through the socket and processes the messages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the content of a cached resource.", "response": "def get_content(self, url):\n        \"\"\"Returns the content of a cached resource.\n\n        Args:\n            url: The url of the resource\n\n        Returns:\n            The content of the cached resource or None if not in the cache\n        \"\"\"\n        cache_path = self._url_to_path(url)\n        try:\n            with open(cache_path, 'rb') as f:\n                return f.read()\n        except IOError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_path(self, url):\n        cache_path = self._url_to_path(url)\n        if os.path.exists(cache_path):\n            return cache_path\n\n        return None", "response": "Returns the path to the resource in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstoring the content of a resource into the disk cache.", "response": "def put_content(self, url, content):\n        \"\"\"Stores the content of a resource into the disk cache.\n\n        Args:\n            url: The url of the resource\n            content: The content of the resource\n\n        Raises:\n            CacheError: If the content cannot be put in cache\n        \"\"\"\n        cache_path = self._url_to_path(url)\n\n        # Ensure that cache directories exist\n        try:\n            dir = os.path.dirname(cache_path)\n            os.makedirs(dir)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise Error('Failed to create cache directories for ' % cache_path)\n\n        try:\n            with open(cache_path, 'wb') as f:\n                f.write(content)\n        except IOError:\n            raise Error('Failed to cache content as %s for %s' % (cache_path, url))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nput a resource already on disk into the cache.", "response": "def put_path(self, url, path):\n        \"\"\"Puts a resource already on disk into the disk cache.\n\n        Args:\n            url: The original url of the resource\n            path: The resource already available on disk\n\n        Raises:\n            CacheError: If the file cannot be put in cache\n        \"\"\"\n        cache_path = self._url_to_path(url)\n\n        # Ensure that cache directories exist\n        try:\n            dir = os.path.dirname(cache_path)\n            os.makedirs(dir)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise Error('Failed to create cache directories for ' % cache_path)\n\n        # Remove the resource already exist\n        try:\n            os.unlink(cache_path)\n        except OSError:\n            pass\n\n        try:\n            # First try hard link to avoid wasting disk space & overhead\n            os.link(path, cache_path)\n        except OSError:\n            try:\n                # Use file copy as fallaback\n                shutil.copyfile(path, cache_path)\n            except IOError:\n                raise Error('Failed to cache %s as %s for %s' % (path, cache_path, url))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef size(self):\n        total_size = 0\n        for dir_path, dir_names, filenames in os.walk(self.dir):\n            for f in filenames:\n                fp = os.path.join(dir_path, f)\n                total_size += os.path.getsize(fp)\n        return total_size", "response": "Returns the size of the cache in bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_named_notebook(fname, context):\n\n    if os.path.exists(fname):\n        return\n\n    from nbformat import v4 as nbf\n\n    # Courtesy of http://nbviewer.ipython.org/gist/fperez/9716279\n    text = \"Welcome to *pyramid_notebook!* Use *File* *>* *Shutdown* to close this.\"\n    cells = [nbf.new_markdown_cell(text)]\n\n    greeting = context.get(\"greeting\")\n    if greeting:\n        cells.append(nbf.new_markdown_cell(greeting))\n\n    cells.append(nbf.new_code_cell(''))\n\n    nb = nbf.new_notebook(cells=cells)\n\n    with open(fname, 'w') as f:\n        writer = JSONWriter()\n        writer.write(nb, f)", "response": "Create a named notebook if one doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        if self.pidfile is None:\n            raise DaemonError('Cannot stop daemon without PID file')\n\n        pid = self._read_pidfile()\n        if pid is None:\n            # I don't think this should be a fatal error\n            self._emit_warning('{prog} is not running'.format(prog=self.prog))\n            return\n\n        self._emit_message('Stopping {prog} ... '.format(prog=self.prog))\n\n        try:\n            # Try to terminate the process\n            os.kill(pid, signal.SIGTERM)\n        except OSError as ex:\n            self._emit_failed()\n            self._emit_error(str(ex))\n            sys.exit(1)\n\n        _, alive = psutil.wait_procs([psutil.Process(pid)], timeout=self.stop_timeout)\n        if alive:\n            # The process didn't terminate for some reason\n            os.kill(pid, signal.SIGKILL)\n            time.sleep(0.5)\n            # Hahahaha. Do you feel alive now?\n\n        self._emit_ok()", "response": "Stop the daemon.\n\n        IPython Notebook tends to hang on exit 1) on certain Linux servers 2) sometimes.\n        I am not sure why, but here is the traceback back when gdb was attached to the process::\n\n            #0  0x00007fa7632c912d in poll () at ../sysdeps/unix/syscall-template.S:81\n            #1  0x00007fa75e6d2f6a in poll (__timeout=<optimized out>, __nfds=2, __fds=0x7fffd2c60940) at /usr/include/x86_64-linux-gnu/bits/poll2.h:46\n            #2  zmq_poll (items_=items_@entry=0x2576f00, nitems_=nitems_@entry=2, timeout_=timeout_@entry=2997) at bundled/zeromq/src/zmq.cpp:736\n            #3  0x00007fa75d0d7c0b in __pyx_pf_3zmq_7backend_6cython_5_poll_zmq_poll (__pyx_self=<optimized out>, __pyx_v_timeout=2997, __pyx_v_sockets=0x7fa75b82c848) at zmq/backend/cython/_poll.c:1552\n            #4  __pyx_pw_3zmq_7backend_6cython_5_poll_1zmq_poll (__pyx_self=<optimized out>, __pyx_args=<optimized out>, __pyx_kwds=<optimized out>) at zmq/backend/cython/_poll.c:1023\n            #5  0x000000000057bf33 in PyEval_EvalFrameEx ()\n            #6  0x000000000057d3d3 in PyEval_EvalCodeEx ()\n\n        Smells like pyzmq bug. In any it would take pretty extensive debugging to find out why it doesn't always quit cleanly, so we just SIGKILL the process after certain timeout.\n\n        Related bug, but this should be apparently fixed: https://github.com/zeromq/pyzmq/pull/618"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating a ZIP 32 - bit CRC from data in memory.", "response": "def crc32(self, data):\n        \"\"\"\n        Calculate a ZIP 32-bit CRC from data in memory.\n        Origin code by Johann E. Klasek, j AT klasek at\n        \"\"\"\n        data_address = 0x1000 # position of the test data\n        self.cpu.memory.load(data_address, data)  # write test data into RAM\n        self.cpu.index_x.set(data_address + len(data)) # end address\n        addr_hi, addr_lo = divmod(data_address, 0x100) # start address\n\n        self.cpu_test_run(start=0x0100, end=None, mem=bytearray([\n            #                              0100|           .ORG  $100\n            0x10, 0xCE, 0x40, 0x00, #      0100|           LDS   #$4000\n            #                              0104|    CRCHH: EQU   $ED\n            #                              0104|    CRCHL: EQU   $B8\n            #                              0104|    CRCLH: EQU   $83\n            #                              0104|    CRCLL: EQU   $20\n            #                              0104| CRCINITH: EQU   $FFFF\n            #                              0104| CRCINITL: EQU   $FFFF\n            #                              0104|                            ; CRC 32 bit in DP (4 bytes)\n            #                              0104|      CRC: EQU   $80\n            0xCE, addr_hi, addr_lo, #      0104|           LDU   #....      ; start address in u\n            0x34, 0x10, #                  010C|           PSHS  x          ; end address +1 to TOS\n            0xCC, 0xFF, 0xFF, #            010E|           LDD   #CRCINITL\n            0xDD, 0x82, #                  0111|           STD   crc+2\n            0x8E, 0xFF, 0xFF, #            0113|           LDX   #CRCINITH\n            0x9F, 0x80, #                  0116|           STX   crc\n            #                              0118|                            ; d/x contains the CRC\n            #                              0118|       BL:\n            0xE8, 0xC0, #                  0118|           EORB  ,u+        ; XOR with lowest byte\n            0x10, 0x8E, 0x00, 0x08, #      011A|           LDY   #8         ; bit counter\n            #                              011E|       RL:\n            0x1E, 0x01, #                  011E|           EXG   d,x\n            #                              0120|      RL1:\n            0x44, #                        0120|           LSRA             ; shift CRC right, beginning with high word\n            0x56, #                        0121|           RORB\n            0x1E, 0x01, #                  0122|           EXG   d,x\n            0x46, #                        0124|           RORA             ; low word\n            0x56, #                        0125|           RORB\n            0x24, 0x12, #                  0126|           BCC   cl\n            #                              0128|                            ; CRC=CRC XOR polynomic\n            0x88, 0x83, #                  0128|           EORA  #CRCLH     ; apply CRC polynomic low word\n            0xC8, 0x20, #                  012A|           EORB  #CRCLL\n            0x1E, 0x01, #                  012C|           EXG   d,x\n            0x88, 0xED, #                  012E|           EORA  #CRCHH     ; apply CRC polynomic high word\n            0xC8, 0xB8, #                  0130|           EORB  #CRCHL\n            0x31, 0x3F, #                  0132|           LEAY  -1,y       ; bit count down\n            0x26, 0xEA, #                  0134|           BNE   rl1\n            0x1E, 0x01, #                  0136|           EXG   d,x        ; CRC: restore correct order\n            0x27, 0x04, #                  0138|           BEQ   el         ; leave bit loop\n            #                              013A|       CL:\n            0x31, 0x3F, #                  013A|           LEAY  -1,y       ; bit count down\n            0x26, 0xE0, #                  013C|           BNE   rl         ; bit loop\n            #                              013E|       EL:\n            0x11, 0xA3, 0xE4, #            013E|           CMPU  ,s         ; end address reached?\n            0x26, 0xD5, #                  0141|           BNE   bl         ; byte loop\n            0xDD, 0x82, #                  0143|           STD   crc+2      ; CRC low word\n            0x9F, 0x80, #                  0145|           STX   crc        ; CRC high word\n        ]))\n        d = self.cpu.accu_d.value\n        x = self.cpu.index_x.value\n        crc32 = x * 0x10000 + d\n        return crc32 ^ 0xFFFFFFFF"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npushing the interrupt registers on the stack pointer", "response": "def push_irq_registers(self):\n        \"\"\"\n        push PC, U, Y, X, DP, B, A, CC on System stack pointer\n        \"\"\"\n        self.cycles += 1\n        self.push_word(self.system_stack_pointer, self.program_counter.value) # PC\n        self.push_word(self.system_stack_pointer, self.user_stack_pointer.value) # U\n        self.push_word(self.system_stack_pointer, self.index_y.value) # Y\n        self.push_word(self.system_stack_pointer, self.index_x.value) # X\n        self.push_byte(self.system_stack_pointer, self.direct_page.value) # DP\n        self.push_byte(self.system_stack_pointer, self.accu_b.value) # B\n        self.push_byte(self.system_stack_pointer, self.accu_a.value) # A\n        self.push_byte(self.system_stack_pointer, self.get_cc_value())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npushes PC and CC on System stack pointer.", "response": "def push_firq_registers(self):\n        \"\"\"\n        FIRQ - Fast Interrupt Request\n        push PC and CC on System stack pointer\n        \"\"\"\n        self.cycles += 1\n        self.push_word(self.system_stack_pointer, self.program_counter.value) # PC\n        self.push_byte(self.system_stack_pointer, self.get_cc_value())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef instruction_RTI(self, opcode):\n        cc = self.pull_byte(self.system_stack_pointer) # CC\n        self.set_cc(cc)\n        if self.E:\n            self.accu_a.set(\n                self.pull_byte(self.system_stack_pointer) # A\n            )\n            self.accu_b.set(\n                self.pull_byte(self.system_stack_pointer) # B\n            )\n            self.direct_page.set(\n                self.pull_byte(self.system_stack_pointer) # DP\n            )\n            self.index_x.set(\n                self.pull_word(self.system_stack_pointer) # X\n            )\n            self.index_y.set(\n                self.pull_word(self.system_stack_pointer) # Y\n            )\n            self.user_stack_pointer.set(\n                self.pull_word(self.system_stack_pointer) # U\n            )\n\n        self.program_counter.set(\n            self.pull_word(self.system_stack_pointer) # PC\n        )", "response": "This instruction handles the RTI instruction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of features of a given character in given sentence.", "response": "def char2features(sentence, i):\n    '''\n    Returns features of char at position `i` in given sentence\n    When it possible, result features list also includes features for 2 characters\n    ahead and behind current position (like bigrams, or something like it)\n    Currently, used features is:\n    1. lower-cased value of character\n    2. result of calling `character.isupper()` method\n    3. result of calling `character.isnumeric()` method\n    '''\n    char = sentence[i]\n    length = len(sentence)\n\n    features = [\n        'lower={0}'.format(char.lower()),\n        'isupper={0}'.format(char.isupper()),\n        'isnumeric={0}'.format(char.isnumeric()),\n    ]\n\n    if i == 0:\n        features.extend(['BOS'])\n\n    if i > 0:\n        char = sentence[i - 1]\n        features.extend([\n            '-1:lower={0}'.format(char.lower()),\n            '-1:isupper={0}'.format(char.isupper()),\n            '-1:isnumeric={0}'.format(char.isnumeric()),\n        ])\n\n    if i > 1:\n        char = sentence[i - 2]\n        features.extend([\n            '-2:lower={0}'.format(char.lower()),\n            '-2:isupper={0}'.format(char.isupper()),\n            '-2:isnumeric={0}'.format(char.isnumeric()),\n        ])\n\n    if i < length - 1:\n        char = sentence[i + 1]\n        features.extend([\n            '+1:lower={0}'.format(char.lower()),\n            '+1:isupper={0}'.format(char.isupper()),\n            '+1:isnumeric={0}'.format(char.isnumeric()),\n        ])\n\n    if i < length - 2:\n        char = sentence[i + 2]\n        features.extend([\n            '+2:lower={0}'.format(char.lower()),\n            '+2:isupper={0}'.format(char.isupper()),\n            '+2:isnumeric={0}'.format(char.isnumeric()),\n        ])\n\n    if i == length - 1:\n        features.extend(['EOS'])\n\n    return features"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text2labels(text, sents):\n    '''\n    Marks all characters in given `text`, that doesn't exists within any\n    element of `sents` with `1` character, other characters (within sentences)\n    will be marked with `0`\n    Used in training process\n    >>> text = '\u043f\u0440\u0438\u0432\u0435\u0442. \u043c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0430\u043d\u044f.'\n    >>> sents = ['\u043f\u0440\u0438\u0432\u0435\u0442.', '\u043c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0430\u043d\u044f.']\n    >>> labels = text2labels(text, sents)\n    >>> ' '.join(text)\n    >>> '\u043f \u0440 \u0438 \u0432 \u0435 \u0442 .   \u043c \u0435 \u043d \u044f   \u0437 \u043e \u0432 \u0443 \u0442   \u0430 \u043d \u044f .'\n    >>> ' '.join(labels)\n    >>> '0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n    '''\n    labels = [c for c in text]\n    for sent in sents:\n        start = text.index(sent)\n        finish = start + len(sent)\n        labels[start:finish] = '0' * len(sent)\n    for i, c in enumerate(labels):\n        if c != '0':\n            labels[i] = '1'\n    return labels", "response": "Convert a text into a list of labels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef text2sentences(text, labels):\n    '''\n    Splits given text at predicted positions from `labels`\n    '''\n    sentence = ''\n    for i, label in enumerate(labels):\n        if label == '1':\n            if sentence:\n                yield sentence\n            sentence = ''\n        else:\n            sentence += text[i]\n    if sentence:\n        yield sentence", "response": "Splits given text at predicted positions from labels and yields a sequence of sentences."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrain a new CVV dataset.", "response": "def train(X_train, X_test, y_train, y_test, **kwargs):\n    '''\n    >>> corpus = CorpusReader('annot.opcorpora.xml')\n    >>> X_train, x_test, y_train, y_test = get_train_data(corpus, test_size=0.33, random_state=42)\n    >>> crf = train(X_train, X_test, y_train, y_test)\n    '''\n    crf = Trainer()\n    crf.set_params({\n        'c1': 1.0,\n        'c2': 0.001,\n        'max_iterations': 200,\n    })\n\n    for xseq, yseq in zip(X_train, y_train):\n        crf.append(xseq, yseq)\n    crf.train(model_name)\n    return crf"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reconstruct_url(environ, port):\n    # From WSGI spec, PEP 333\n    url = environ.get('PATH_INFO', '')\n    if not url.startswith(('http://', 'https://')):\n        url = '%s://%s%s' % (\n            environ['wsgi.url_scheme'],\n            environ['HTTP_HOST'],\n            url\n        )\n    # Fix ;arg=value in url\n    if '%3B' in url:\n        url, arg = url.split('%3B', 1)\n        url = ';'.join([url, arg.replace('%3D', '=')])\n    # Stick query string back in\n    try:\n        query_string = environ['QUERY_STRING']\n    except KeyError:\n        pass\n    else:\n        url += '?' + query_string\n\n    parsed = urlparse(url)\n    replaced = parsed._replace(netloc=\"localhost:{}\".format(port))\n    url = urlunparse(replaced)\n    environ['reconstructed_url'] = url\n    return url", "response": "Reconstructs the remote url from the given WSGI environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the WSGI request.", "response": "def handler(self, environ, start_response):\n        \"\"\"Proxy for requests to the actual http server\"\"\"\n        logger = logging.getLogger(__name__ + '.WSGIProxyApplication.handler')\n        url = urlparse(reconstruct_url(environ, self.port))\n\n        # Create connection object\n        try:\n            connection = self.connection_class(url.netloc)\n            # Build path\n            path = url.geturl().replace('%s://%s' % (url.scheme, url.netloc),\n                                        '')\n        except Exception:\n            start_response('501 Gateway Error', [('Content-Type', 'text/html')])\n            logger.exception('Could not Connect')\n            yield '<H1>Could not connect</H1>'\n            return\n\n        # Read in request body if it exists\n        body = length = None\n        try:\n            length = int(environ['CONTENT_LENGTH'])\n        except (KeyError, ValueError):\n\n            # This is a situation where client HTTP POST is missing content-length.\n            # This is also situation where (WebOb?) may screw up encoding and isert extranous = in the body.\n            # https://github.com/ipython/ipython/issues/8416\n            if environ[\"REQUEST_METHOD\"] == \"POST\":\n                if environ.get(\"CONTENT_TYPE\") == 'application/x-www-form-urlencoded; charset=UTF-8':\n                    body = environ['wsgi.input'].read()\n                    try:\n                        body = unquote_plus(body.decode(\"utf-8\"))\n\n                        # Fix extra = at end of JSON payload\n                        if body.startswith(\"{\") and body.endswith(\"}=\"):\n                            body = body[0:len(body) - 1]\n\n                    except Exception as e:\n                        logger.exception(e)\n                        logger.error(\"Could not decode body: %s\", body)\n\n                    length = len(body)\n        else:\n            body = environ['wsgi.input'].read(length)\n\n        # Build headers\n        logger.debug('environ = %r', environ)\n        headers = dict(\n            (key, value)\n            for key, value in (\n                # This is a hacky way of getting the header names right\n                (key[5:].lower().replace('_', '-'), value)\n                for key, value in environ.items()\n                # Keys that start with HTTP_ are all headers\n                if key.startswith('HTTP_')\n            )\n            if not is_hop_by_hop(key)\n        )\n\n        # Handler headers that aren't HTTP_ in environ\n        try:\n            headers['content-type'] = environ['CONTENT_TYPE']\n        except KeyError:\n            pass\n\n        # Add our host if one isn't defined\n        if 'host' not in headers:\n            headers['host'] = environ['SERVER_NAME']\n\n        # Make the remote request\n        try:\n\n            logger.debug('%s %s %r',\n                         environ['REQUEST_METHOD'], path, headers)\n            connection.request(environ['REQUEST_METHOD'], path,\n                               body=body, headers=headers)\n        except Exception as e:\n            # We need extra exception handling in the case the server fails\n            # in mid connection, it's an edge case but I've seen it\n            if isinstance(e, ConnectionRefusedError):\n                # The notebook was shutdown by the user\n                pass\n            else:\n                # This might be a genuine error\n                logger.exception(e)\n\n            start_response('501 Gateway Error', [('Content-Type', 'text/html')])\n            yield '<H1>Could not proxy IPython Notebook running localhost:{}</H1>'.format(self.port).encode(\"utf-8\")\n            return\n\n        try:\n            response = connection.getresponse()\n        except ConnectionResetError:\n            # Notebook shutdown\n            start_response('501 Gateway Error', [('Content-Type', 'text/html')])\n            yield '<H1>Could not proxy IPython Notebook running localhost:{}</H1>'.format(self.port).encode(\"utf-8\")\n            return\n\n        hopped_headers = response.getheaders()\n        headers = [(key, value)\n                   for key, value in hopped_headers\n                   if not is_hop_by_hop(key)]\n\n        start_response('{0.status} {0.reason}'.format(response), headers)\n        while True:\n            chunk = response.read(4096)\n            if chunk:\n                yield chunk\n            else:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntraining a tokenization model on the corpus.", "response": "def train(X_train, y_train, **kwargs):\n    '''\n    >>> corpus = CorpusReader('annot.opcorpora.xml')\n    >>> X_train, x_test, y_train, y_test = get_train_data(corpus, test_size=0.33, random_state=42)\n    >>> crf = train(X_train, y_train)\n    '''\n    crf = Trainer()\n    crf.set_params({\n        'c1': 1.0,\n        'c2': 0.001,\n        'max_iterations': 200,\n        'feature.possible_transitions': True,\n    })\n\n    for xseq, yseq in zip(X_train, y_train):\n        crf.append(xseq, yseq)\n    crf.train(TOKENIZATION_MODEL_PATH)\n    return crf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating presentation summaries in a reverse chronological order.", "response": "def get_summaries(client, filter=None):\n    \"\"\" Generate presentation summaries in a reverse chronological order.\n\n     A filter class can be supplied to filter summaries or bound the fetching process.\n    \"\"\"\n    try:\n        index = 0\n        while True:\n            rb = _RightBarPage(client, index)\n\n            summaries = rb.summaries()\n            if filter is not None:\n                summaries = filter.filter(summaries)\n\n            for summary in summaries:\n                    yield summary\n\n            index += len(summaries)\n    except StopIteration:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fetch(self):\n        url = client.get_url(\"/presentations/\" + self.id)\n        content = self.client.fetch_no_cache(url).decode('utf-8')\n        return bs4.BeautifulSoup(content, \"html.parser\")", "response": "Download the page and create the soup"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload the page and create the soup", "response": "def soup(self):\n        \"\"\"Download the page and create the soup\"\"\"\n        try:\n            return self._soup\n        except AttributeError:\n            url = client.get_url(\"/presentations/%s\" % self.index)\n            content = self.client.fetch_no_cache(url).decode('utf-8')\n            self._soup = bs4.BeautifulSoup(content, \"html.parser\")\n\n            return self._soup"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all the presentation summaries contained in this page", "response": "def summaries(self):\n        \"\"\"Return a list of all the presentation summaries contained in this page\"\"\"\n        def create_summary(div):\n            def get_id(div):\n                return get_url(div).rsplit('/')[-1]\n\n            def get_url(div):\n                return client.get_url(div.find('h2', class_='itemtitle').a['href'])\n\n            def get_desc(div):\n                return div.p.get_text(strip=True)\n\n            def get_auth(div):\n                return div.find('span', class_='author').a['title']\n\n            def get_date(div):\n                str = div.find('span', class_='author').get_text()\n                str = str.replace('\\n',   ' ')\n                str = str.replace(six.u('\\xa0'), ' ')\n                match = re.search(r'on\\s+(\\w{3} [0-9]{1,2}, 20[0-9]{2})', str)\n                return datetime.datetime.strptime(match.group(1), \"%b %d, %Y\")\n\n            def get_title(div):\n                return div.find('h2', class_='itemtitle').a['title']\n\n            return {\n                'id':    get_id(div),\n                'url':   get_url(div),\n                'desc':  get_desc(div),\n                'auth':  get_auth(div),\n                'date':  get_date(div),\n                'title': get_title(div),\n            }\n\n        videos = self.soup.findAll('div', {'class': 'news_type_video'})\n        return [create_summary(div) for div in videos]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering js tagging_ext tag_autocomplete_js. html", "response": "def tag_autocomplete_js(format_string=None):\n    \"\"\"format_string should be ``app_label model counts``\n    \n    renders 'tagging_ext/tag_autocomplete_js.html\"\"\"\n    if format_string:\n        context_list = format_string.split(' ')\n        context = {\n            'app_label':context_list[0],'model':context_list[1], 'counts':context_list[2]\n        }\n    else:\n        context = {}\n    return render_to_string('tagging_ext/tagging_autocomplete_js.html', context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_startup(notebook_context, config_file, bootstrap_py=PYRAMID_BOOSTRAP, bootstrap_greeting=PYRAMID_GREETING, cwd=\"\"):\n\n    # Set up some default imports and variables\n\n    nc = notebook_context\n\n    add_greeting(nc, \"\\nAvailable variables and functions:\")\n\n    # http://docs.pylonsproject.org/projects/pyramid/en/1.1-branch/narr/commandline.html#writing-a-script\n\n    if config_file is not None:\n        assert type(config_file) == str, \"Got bad config_file {}\".format(config_file)\n        config_file = os.path.abspath(config_file)\n        assert os.path.exists(config_file), \"Passed in bad config file: {}\".format(config_file)\n        add_script(nc, bootstrap_py.format(config_uri=config_file, cwd=cwd))\n        add_greeting(nc, bootstrap_greeting)\n\n    add_script(nc, \"import datetime\")\n    add_greeting(nc, \"* **datetime** - Python [datetime module](https://docs.python.org/3.5/library/datetime.html)\")\n\n    add_script(nc, \"import time\")\n    add_greeting(nc, \"* **time** - Python [time module](https://docs.python.org/3.5/library/time.html)\")\n\n    try:\n        # Commonly used with Pyramid applications\n        import transaction  # noQA\n        add_script(nc, \"import transaction\\n\")\n        add_greeting(nc, \"* **transaction** - Zope [transaction manager](http://zodb.readthedocs.org/en/latest/transactions.html), e.g. `transaction.commit()`\")\n    except ImportError:\n        pass", "response": "Populate the notebook context with startup. py initialization file skeleton and greeting."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninclude all SQLAlchemy models in the script context.", "response": "def include_sqlalchemy_models(nc, Base):\n    \"\"\"Include all SQLAlchemy models in the script context.\n\n    :param nc: notebook_context dictionary\n    :param Base: SQLAlchemy model Base class from where the all models inherit.\n    \"\"\"\n\n    from sqlalchemy.ext.declarative.clsregistry import _ModuleMarker\n\n    # Include all SQLAlchemy models in the local namespace\n    for name, klass in Base._decl_class_registry.items():\n        print(name, klass)\n        if isinstance(klass, _ModuleMarker):\n            continue\n\n        add_script(nc, get_import_statement(klass))\n        add_greeting(nc, \"* **{}** - {}\".format(klass.__name__, get_dotted_path(klass)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding one - liner script or several lines", "response": "def add_script(nc, line):\n    \"\"\"Add one-liner script or several lines (newline separated)\"\"\"\n\n    assert type(nc) == dict\n\n    nc[\"startup\"] = nc.get(\"startup\") or \"\"\n\n    if not nc[\"startup\"].endswith(\"\\n\"):\n        nc[\"startup\"] += \"\\n\"\n    nc[\"startup\"] += line + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_greeting(nc, line):\n\n    assert type(nc) == dict\n\n    nc[\"greeting\"] = nc.get(\"greeting\") or \"\"\n\n    # Markdown hard line break is two new lines\n    if not nc[\"greeting\"].endswith(\"\\n\"):\n        nc[\"greeting\"] += \"\\n\"\n    nc[\"greeting\"] += line + \"\\n\"", "response": "Add one - liner script or several lines ( newline separated"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the new count of the current node based on the given value and trigger.", "response": "def calc_new_count(min_value, value, max_value, trigger, target):\n    \"\"\"\n    change 'value' between 'min_value' and 'max_value'\n    so that 'trigger' will be match 'target'\n    \n    >>> calc_new_count(min_value=0, value=100, max_value=200, trigger=30, target=30)\n    100\n\n    >>> calc_new_count(min_value=0, value=100, max_value=200, trigger=50, target=5)\n    55\n    >>> calc_new_count(min_value=60, value=100, max_value=200, trigger=50, target=5)\n    60\n\n    >>> calc_new_count(min_value=0, value=100, max_value=200, trigger=20, target=40)\n    150\n    >>> calc_new_count(min_value=0, value=100, max_value=125, trigger=20, target=40)\n    125\n    \"\"\"\n    try:\n        new_value = float(value) / float(trigger) * target\n    except ZeroDivisionError:\n        return value * 2\n\n    if new_value > max_value:\n        return max_value\n\n    new_value = int((value + new_value) / 2)\n    if new_value < min_value:\n        return min_value\n    return new_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_OR(self, opcode, m, register):\n        a = register.value\n        r = a | m\n        register.set(r)\n        self.clear_NZV()\n        self.update_NZ_8(r)", "response": "Perform an inclusive OR operation between accumulator A and accumulator B and the contents of memory location M and the result is stored in the register M."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a logical AND between the condition code register and the immediate byte specified in the instruction and places the result in the condition code register. source code forms: ANDCC #xx CC bits \"HNZVC\": ddddd", "response": "def instruction_ANDCC(self, opcode, m, register):\n        \"\"\"\n        Performs a logical AND between the condition code register and the\n        immediate byte specified in the instruction and places the result in the\n        condition code register.\n\n        source code forms: ANDCC #xx\n\n        CC bits \"HNZVC\": ddddd\n        \"\"\"\n        assert register == self.cc_register\n\n        old_cc = self.get_cc_value()\n        new_cc = old_cc & m\n        self.set_cc(new_cc)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef LSL(self, a):\n        r = a << 1\n        self.clear_NZVC()\n        self.update_NZVC_8(a, a, r)\n        return r", "response": "Shifts all bits of accumulator A or B or memory location M into the left."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the value of the LSL memory location.", "response": "def instruction_LSL_memory(self, opcode, ea, m):\n        \"\"\"\n        Logical shift left memory location / Arithmetic shift of memory left\n        \"\"\"\n        r = self.LSL(m)\n#        log.debug(\"$%x LSL memory value $%x << 1 = $%x and write it to $%x \\t| %s\" % (\n#            self.program_counter,\n#            m, r, ea,\n#            self.cfg.mem_info.get_shortest(ea)\n#        ))\n        return ea, r & 0xff"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_LSL_register(self, opcode, register):\n        a = register.value\n        r = self.LSL(a)\n#        log.debug(\"$%x LSL %s value $%x << 1 = $%x\" % (\n#            self.program_counter,\n#            register.name, a, r\n#        ))\n        register.set(r)", "response": "Shifts the logarithm of the specified register."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a logical shift right on the register. Shifts a zero into bit seven and bit zero into the C (carry) bit. source code forms: LSR Q; LSRA; LSRB CC bits \"HNZVC\": -0a-s", "response": "def LSR(self, a):\n        \"\"\"\n        Performs a logical shift right on the register. Shifts a zero into bit\n        seven and bit zero into the C (carry) bit.\n\n        source code forms: LSR Q; LSRA; LSRB\n\n        CC bits \"HNZVC\": -0a-s\n        \"\"\"\n        r = a >> 1\n        self.clear_NZC()\n        self.C = get_bit(a, bit=0) # same as: self.C |= (a & 1)\n        self.set_Z8(r)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instruction_LSR_register(self, opcode, register):\n        a = register.value\n        r = self.LSR(a)\n#        log.debug(\"$%x LSR %s value $%x >> 1 = $%x\" % (\n#            self.program_counter,\n#            register.name, a, r\n#        ))\n        register.set(r)", "response": "Logical shift right accumulator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instruction_ASR_memory(self, opcode, ea, m):\n        r = self.ASR(m)\n#        log.debug(\"$%x ASR memory value $%x >> 1 | Carry = $%x and write it to $%x \\t| %s\" % (\n#            self.program_counter,\n#            m, r, ea,\n#            self.cfg.mem_info.get_shortest(ea)\n#        ))\n        return ea, r & 0xff", "response": "Arithmetic shift memory right"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrotates all bits of the register one place left through the C (carry) bit. This is a 9-bit rotation. source code forms: ROL Q; ROLA; ROLB CC bits \"HNZVC\": -aaas", "response": "def ROL(self, a):\n        \"\"\"\n        Rotates all bits of the register one place left through the C (carry)\n        bit. This is a 9-bit rotation.\n\n        source code forms: ROL Q; ROLA; ROLB\n\n        CC bits \"HNZVC\": -aaas\n        \"\"\"\n        r = (a << 1) | self.C\n        self.clear_NZVC()\n        self.update_NZVC_8(a, a, r)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ea_indexed(self):\n        addr, postbyte = self.read_pc_byte()\n#        log.debug(\"\\tget_ea_indexed(): postbyte: $%02x (%s) from $%04x\",\n#             postbyte, byte2bit_string(postbyte), addr\n#         )\n\n        rr = (postbyte >> 5) & 3\n        try:\n            register_str = self.INDEX_POSTBYTE2STR[rr]\n        except KeyError:\n            raise RuntimeError(\"Register $%x doesn't exists! (postbyte: $%x)\" % (rr, postbyte))\n\n        register_obj = self.register_str2object[register_str]\n        register_value = register_obj.value\n#        log.debug(\"\\t%02x == register %s: value $%x\",\n#             rr, register_obj.name, register_value\n#         )\n\n        if not is_bit_set(postbyte, bit=7): # bit 7 == 0\n            # EA = n, R - use 5-bit offset from post-byte\n            offset = signed5(postbyte & 0x1f)\n            ea = register_value + offset\n#             log.debug(\n#                 \"\\tget_ea_indexed(): bit 7 == 0: reg.value: $%04x -> ea=$%04x + $%02x = $%04x\",\n#                 register_value, register_value, offset, ea\n#             )\n            return ea\n\n        addr_mode = postbyte & 0x0f\n        self.cycles += 1\n        offset = None\n        # TODO: Optimized this, maybe use a dict mapping...\n        if addr_mode == 0x0:\n#             log.debug(\"\\t0000 0x0 | ,R+ | increment by 1\")\n            ea = register_value\n            register_obj.increment(1)\n        elif addr_mode == 0x1:\n#             log.debug(\"\\t0001 0x1 | ,R++ | increment by 2\")\n            ea = register_value\n            register_obj.increment(2)\n            self.cycles += 1\n        elif addr_mode == 0x2:\n#             log.debug(\"\\t0010 0x2 | ,R- | decrement by 1\")\n            register_obj.decrement(1)\n            ea = register_obj.value\n        elif addr_mode == 0x3:\n#             log.debug(\"\\t0011 0x3 | ,R-- | decrement by 2\")\n            register_obj.decrement(2)\n            ea = register_obj.value\n            self.cycles += 1\n        elif addr_mode == 0x4:\n#             log.debug(\"\\t0100 0x4 | ,R | No offset\")\n            ea = register_value\n        elif addr_mode == 0x5:\n#             log.debug(\"\\t0101 0x5 | B, R | B register offset\")\n            offset = signed8(self.accu_b.value)\n        elif addr_mode == 0x6:\n#             log.debug(\"\\t0110 0x6 | A, R | A register offset\")\n            offset = signed8(self.accu_a.value)\n        elif addr_mode == 0x8:\n#             log.debug(\"\\t1000 0x8 | n, R | 8 bit offset\")\n            offset = signed8(self.read_pc_byte()[1])\n        elif addr_mode == 0x9:\n#             log.debug(\"\\t1001 0x9 | n, R | 16 bit offset\")\n            offset = signed16(self.read_pc_word()[1])\n            self.cycles += 1\n        elif addr_mode == 0xa:\n#             log.debug(\"\\t1010 0xa | illegal, set ea=0\")\n            ea = 0\n        elif addr_mode == 0xb:\n#             log.debug(\"\\t1011 0xb | D, R | D register offset\")\n            # D - 16 bit concatenated reg. (A + B)\n            offset = signed16(self.accu_d.value) # FIXME: signed16() ok?\n            self.cycles += 1\n        elif addr_mode == 0xc:\n#             log.debug(\"\\t1100 0xc | n, PCR | 8 bit offset from program counter\")\n            __, value = self.read_pc_byte()\n            value_signed = signed8(value)\n            ea = self.program_counter.value + value_signed\n#             log.debug(\"\\tea = pc($%x) + $%x = $%x (dez.: %i + %i = %i)\",\n#                 self.program_counter, value_signed, ea,\n#                 self.program_counter, value_signed, ea,\n#             )\n        elif addr_mode == 0xd:\n#             log.debug(\"\\t1101 0xd | n, PCR | 16 bit offset from program counter\")\n            __, value = self.read_pc_word()\n            value_signed = signed16(value)\n            ea = self.program_counter.value + value_signed\n            self.cycles += 1\n#             log.debug(\"\\tea = pc($%x) + $%x = $%x (dez.: %i + %i = %i)\",\n#                 self.program_counter, value_signed, ea,\n#                 self.program_counter, value_signed, ea,\n#             )\n        elif addr_mode == 0xe:\n#             log.error(\"\\tget_ea_indexed(): illegal address mode, use 0xffff\")\n            ea = 0xffff # illegal\n        elif addr_mode == 0xf:\n#             log.debug(\"\\t1111 0xf | [n] | 16 bit address - extended indirect\")\n            __, ea = self.read_pc_word()\n        else:\n            raise RuntimeError(\"Illegal indexed addressing mode: $%x\" % addr_mode)\n\n        if offset is not None:\n            ea = register_value + offset\n#             log.debug(\"\\t$%x + $%x = $%x (dez: %i + %i = %i)\",\n#                 register_value, offset, ea,\n#                 register_value, offset, ea\n#             )\n\n        ea = ea & 0xffff\n\n        if is_bit_set(postbyte, bit=4): # bit 4 is 1 -> Indirect\n#             log.debug(\"\\tIndirect addressing: get new ea from $%x\", ea)\n            ea = self.memory.read_word(ea)\n#             log.debug(\"\\tIndirect addressing: new ea is $%x\", ea)\n\n#        log.debug(\"\\tget_ea_indexed(): return ea=$%x\", ea)\n        return ea", "response": "Calculate the EA for all indexed addressing modes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the width of the source register into the corresponding value in the destination register.", "response": "def convert_differend_width(src_reg, dst_reg):\n    \"\"\"\n    e.g.:\n     8bit   $cd TFR into 16bit, results in: $ffcd\n    16bit $1234 TFR into  8bit, results in:   $34\n\n    >>> reg8 = ValueStorage8Bit(name=\"bar\", initial_value=0xcd)\n    >>> reg16 = ValueStorage16Bit(name=\"foo\", initial_value=0x0000)\n    >>> hex(convert_differend_width(src_reg=reg8, dst_reg=reg16))\n    '0xffcd'\n\n    >>> reg16 = ValueStorage16Bit(name=\"foo\", initial_value=0x1234)\n    >>> reg8 = ValueStorage8Bit(name=\"bar\", initial_value=0xcd)\n    >>> hex(convert_differend_width(src_reg=reg16, dst_reg=reg8))\n    '0x34'\n\n    TODO: verify this behaviour on real hardware\n    see: http://archive.worldofdragon.org/phpBB3/viewtopic.php?f=8&t=4886\n    \"\"\"\n    src_value = src_reg.value\n    if src_reg.WIDTH == 8 and dst_reg.WIDTH == 16:\n        # e.g.: $cd -> $ffcd\n        src_value += 0xff00\n    elif src_reg.WIDTH == 16 and dst_reg.WIDTH == 8:\n        # This not not really needed, because all 8Bit register will\n        # limit the value, too.\n        # e.g.: $1234 -> $34\n        src_value = src_value & 0xff\n    return src_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discover_python(self):\n        python = sys.executable\n\n        #: XXX fix this hack, uwsgi sets itself as Python\n        #: Make better used Python interpreter autodiscovery\n        if python.endswith(\"/uwsgi\"):\n            python = python.replace(\"/uwsgi\", \"/python\")\n        return python", "response": "Get the Python interpreter we need to run our Notebook daemon."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pid(self, name):\n        pid_file = os.path.join(self.get_work_folder(name), \"notebook.pid\")\n        return pid_file", "response": "Get PID file name for a named notebook."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_manager_cmd(self):\n        cmd = os.path.abspath(os.path.join(os.path.dirname(__file__), \"server\", \"notebook_daemon.py\"))\n        assert os.path.exists(cmd)\n        return cmd", "response": "Get our daemon script path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npick a random TCP port.", "response": "def pick_port(self):\n        \"\"\"Pick open TCP/IP port.\"\"\"\n        ports = set(range(self.min_port, self.min_port + self.port_range))\n        return port_for.select_random(ports)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the command to be passed to the Notebook daemon.", "response": "def get_notebook_daemon_command(self, name, action, port=0, *extra):\n        \"\"\"\n        Assume we launch Notebook with the same Python which executed us.\n        \"\"\"\n\n        return [self.python, self.cmd, action, self.get_pid(name), self.get_work_folder(name), port, self.kill_timeout] + list(extra)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exec_notebook_daemon_command(self, name, cmd, port=0):\n        cmd = self.get_notebook_daemon_command(name, cmd, port)\n\n        # Make all arguments explicit strings\n        cmd = [str(arg) for arg in cmd]\n\n        logger.info(\"Running notebook command: %s\", \" \".join(cmd))\n        # print(\"XXX - DEBUG - Running notebook command:\", \" \".join(cmd))\n\n        # Add support for traceback dump on stuck\n        env = os.environ.copy()\n        env[\"PYTHONFAULTHANDLER\"] = \"true\"\n\n        p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, env=env)\n        time.sleep(0.2)\n        stdout, stderr = p.communicate()\n\n        if b\"already running\" in stderr:\n            raise RuntimeError(\"Looks like notebook_daemon is already running. Please kill it manually pkill -f notebook_daemon. Was: {}\".format(stderr.decode(\"utf-8\")))\n\n        if p.returncode != 0:\n            logger.error(\"STDOUT: %s\", stdout)\n            logger.error(\"STDERR: %s\", stderr)\n\n            raise RuntimeError(\"Could not execute notebook command. Exit code: {} cmd: {}\".format(p.returncode, \" \".join(cmd)))\n\n        return stdout", "response": "Execute a daemon script command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the running named Notebook status.", "response": "def get_notebook_status(self, name):\n        \"\"\"Get the running named Notebook status.\n\n        :return: None if no notebook is running, otherwise context dictionary\n        \"\"\"\n        context = comm.get_context(self.get_pid(name))\n        if not context:\n            return None\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_notebook(self, name, context: dict, fg=False):\n        assert context\n        assert type(context) == dict\n        assert \"context_hash\" in context\n        assert type(context[\"context_hash\"]) == int\n\n        http_port = self.pick_port()\n        assert http_port\n        context = context.copy()\n        context[\"http_port\"] = http_port\n\n        # We can't proxy websocket URLs, so let them go directly through localhost or have front end server to do proxying (nginx)\n        if \"websocket_url\" not in context:\n            context[\"websocket_url\"] = \"ws://localhost:{port}\".format(port=http_port)\n\n        if \"{port}\" in context[\"websocket_url\"]:\n            # Do port substitution for the websocket URL\n            context[\"websocket_url\"] = context[\"websocket_url\"].format(port=http_port)\n\n        pid = self.get_pid(name)\n        assert \"terminated\" not in context\n\n        comm.set_context(pid, context)\n\n        if fg:\n            self.exec_notebook_daemon_command(name, \"fg\", port=http_port)\n        else:\n            self.exec_notebook_daemon_command(name, \"start\", port=http_port)", "response": "Start a new IPython Notebook daemon."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting notebook if not yet running.", "response": "def start_notebook_on_demand(self, name, context):\n        \"\"\"Start notebook if not yet running with these settings.\n\n        Return the updated settings with a port info.\n\n        :return: (context dict, created flag)\n        \"\"\"\n        if self.is_running(name):\n\n            last_context = self.get_context(name)\n            logger.info(\"Notebook context change detected for %s\", name)\n            if not self.is_same_context(context, last_context):\n                self.stop_notebook(name)\n                # Make sure we don't get race condition over context.json file\n                time.sleep(2.0)\n            else:\n                return last_context, False\n\n        err_log = os.path.join(self.get_work_folder(name), \"notebook.stderr.log\")\n        logger.info(\"Launching new Notebook named %s, context is %s\", name, context)\n        logger.info(\"Notebook log is %s\", err_log)\n\n        self.start_notebook(name, context)\n        time.sleep(1)\n        context = self.get_context(name)\n        if \"notebook_name\" not in context:\n            # Failed to launch within timeout\n            raise RuntimeError(\"Failed to launch IPython Notebook, see {}\".format(err_log))\n\n        return context, True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps an app factory to provide a fallback in case of import errors. Takes a factory function to generate a Flask app. If there is an error creating the app, it will return a dummy app that just returns the Flask error page for the exception. This works with the Flask code reloader so that if the app fails during initialization it will still monitor those files for changes and reload the app.", "response": "def failsafe(func):\n    \"\"\"\n    Wraps an app factory to provide a fallback in case of import errors.\n\n    Takes a factory function to generate a Flask app. If there is an error\n    creating the app, it will return a dummy app that just returns the Flask\n    error page for the exception.\n\n    This works with the Flask code reloader so that if the app fails during\n    initialization it will still monitor those files for changes and reload\n    the app.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        extra_files = []\n\n        try:\n            return func(*args, **kwargs)\n        except:\n            exc_type, exc_val, exc_tb = sys.exc_info()\n            traceback.print_exc()\n\n        tb = exc_tb\n        while tb:\n            filename = tb.tb_frame.f_code.co_filename\n            extra_files.append(filename)\n            tb = tb.tb_next\n\n        if isinstance(exc_val, SyntaxError):\n            extra_files.append(exc_val.filename)\n\n        app = _FailSafeFlask(extra_files)\n        app.debug = True\n\n        @app.route('/')\n        @app.route('/<path:path>')\n        def index(path='/'):\n            reraise(exc_type, exc_val, exc_tb)\n\n        return app\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating specified JSON object obj with specified schema.", "response": "def validate(cls, schema, obj):\n        \"\"\"\n        Validate specified JSON object obj with specified schema.\n\n        :param schema:\n            Schema to validate against\n        :type schema:\n            :class:`json_schema_validator.schema.Schema`\n        :param obj:\n            JSON object to validate\n        :rtype:\n            bool\n        :returns:\n            True on success\n        :raises `json_schema_validator.errors.ValidationError`:\n            if the object does not match schema.\n        :raises `json_schema_validator.errors.SchemaError`:\n            if the schema itself is wrong.\n        \"\"\"\n        if not isinstance(schema, Schema):\n            raise ValueError(\n                \"schema value {0!r} is not a Schema\"\n                \" object\".format(schema))\n        self = cls()\n        self.validate_toplevel(schema, obj)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _report_error(self, legacy_message, new_message=None,\n                      schema_suffix=None):\n        \"\"\"\n        Report an error during validation.\n\n        There are two error messages. The legacy message is used for backwards\n        compatibility and usually contains the object (possibly very large)\n        that failed to validate. The new message is much better as it contains\n        just a short message on what went wrong. User code can inspect\n        object_expr and schema_expr to see which part of the object failed to\n        validate against which part of the schema.\n\n        The schema_suffix, if provided, is appended to the schema_expr.  This\n        is quite handy to specify the bit that the validator looked at (such as\n        the type or optional flag, etc). object_suffix serves the same purpose\n        but is used for object expressions instead.\n        \"\"\"\n        object_expr = self._get_object_expression()\n        schema_expr = self._get_schema_expression()\n        if schema_suffix:\n            schema_expr += schema_suffix\n        raise ValidationError(legacy_message, new_message, object_expr,\n                              schema_expr)", "response": "Report an error during validation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _push_property_schema(self, prop):\n        schema = Schema(self._schema.properties[prop])\n        self._push_schema(schema, \".properties.\" + prop)", "response": "Construct a sub - schema from a property of the current schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the context of running notebook.", "response": "def set_context(pid_file, context_info):\n    \"\"\"Set context of running notebook.\n\n    :param context_info: dict of extra context parameters, see comm.py comments\n    \"\"\"\n    assert type(context_info) == dict\n\n    port_file = get_context_file_name(pid_file)\n    with open(port_file, \"wt\") as f:\n        f.write(json.dumps(context_info))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_context(pid_file, daemon=False):\n    port_file = get_context_file_name(pid_file)\n\n    if not os.path.exists(port_file):\n        return None\n\n    with open(port_file, \"rt\") as f:\n        json_data = f.read()\n        try:\n            data = json.loads(json_data)\n        except ValueError as e:\n\n            logger.error(\"Damaged context json data %s\", json_data)\n            return None\n\n        if not daemon:\n            pid = data.get(\"pid\")\n            if pid and not check_pid(int(pid)):\n                # The Notebook daemon has exited uncleanly, as the PID does not point to any valid process\n                return None\n\n        return data", "response": "Get the context of running notebook."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_context(pid_file):\n    return\n    raise RuntimeError(\"Should not happen\")\n    fname = get_context_file_name(pid_file)\n    shutil.move(fname, fname.replace(\"context.json\", \"context.old.json\"))\n\n    data = {}\n    data[\"terminated\"] = str(datetime.datetime.now(datetime.timezone.utc))\n    set_context(pid_file, data)", "response": "Called at exit. Delete the context file to signal there is no active notebook."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a boolean value indicating whether the activation key has expired.", "response": "def activation_key_expired(self):\n        \"\"\"\n        Determine whether this ``RegistrationProfile``'s activation\n        key has expired, returning a boolean -- ``True`` if the key\n        has expired.\n        Key expiration is determined by a two-step process:\n        1. If the user has already activated, the key will have been\n        reset to the string constant ``ACTIVATED``. Re-activating\n        is not permitted, and so this method returns ``True`` in\n        this case.\n\n        2. Otherwise, the date the user signed up is incremented by\n        the number of days specified in the setting\n        ``REGISTRATION_API_ACCOUNT_ACTIVATION_DAYS`` (which should be\n        the number of days after signup during which a user is allowed\n        to activate their account); if the result is less than or\n        equal to the current date, the key has expired and this method\n        returns ``True``.\n\n        \"\"\"\n\n        # utils imported here to avoid circular import\n        import utils\n\n        expiration_date = datetime.timedelta(\n            days=utils.get_settings('REGISTRATION_API_ACCOUNT_ACTIVATION_DAYS'))\n        return self.activation_key == self.ACTIVATED or \\\n            (self.user.date_joined + expiration_date <= datetime_now())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning CPU not faster than given speedlimit", "response": "def delayed_burst_run(self, target_cycles_per_sec):\n        \"\"\" Run CPU not faster than given speedlimit \"\"\"\n        old_cycles = self.cycles\n        start_time = time.time()\n\n        self.burst_run()\n\n        is_duration = time.time() - start_time\n        new_cycles = self.cycles - old_cycles\n        try:\n            is_cycles_per_sec = new_cycles / is_duration\n        except ZeroDivisionError:\n            pass\n        else:\n            should_burst_duration = is_cycles_per_sec / target_cycles_per_sec\n            target_duration = should_burst_duration * is_duration\n            delay = target_duration - is_duration\n            if delay > 0:\n                if delay > self.max_delay:\n                    self.delay = self.max_delay\n                else:\n                    self.delay = delay\n                time.sleep(self.delay)\n\n        self.call_sync_callbacks()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all tags in the tagging_taggeditem table.", "response": "def index(request, template_name=\"tagging_ext/index.html\", min_size=0,limit=10):\n    \"\"\"\n        min_size: Smallest size count accepted for a tag\n        order_by: asc or desc by count\n        limit: maximum number of tags to display \n        \n        TODO: convert the hand-written query to an ORM call. Right now I know\n                this works with Sqlite3 and PostGreSQL.\n    \"\"\"\n    query = \"\"\"\n        SELECT tag_item.tag_id as tag_id, COUNT(tag_item.tag_id) as counter \n        FROM tagging_taggeditem as tag_item \n        GROUP BY tag_id\n        HAVING COUNT(tag_item.tag_id) > %s\n        ORDER BY counter desc\n        LIMIT %s\n    \"\"\"\n\n    cursor = connection.cursor()\n    cursor.execute(query, [min_size, limit])\n    \n    results = []\n    \n    for row in cursor.fetchall():\n        try:\n            tag=Tag.objects.get(id=row[0])\n        except ObjectDoesNotExist:\n            continue\n            \n        if ' ' in tag.name:\n            continue\n        \n        record = dict(\n            tag=tag,\n            count=row[1]\n        )\n        results.append(record)    \n        \n    dictionary = {\n        'tags':results\n    \n    }\n    \n\n    return render_to_response(template_name, dictionary,\n        context_instance=RequestContext(request))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string that can be used to autocomplete the user s user s content type.", "response": "def autocomplete(request, app_label=None, model=None):\n    \"\"\"returns ``\\\\n`` delimited strings in the form <tag>||(#)\n\n    GET params are ``q``, ``limit``, ``counts``, ``q`` is what the user\n    has typed, ``limit`` defaults to 10, and ``counts`` can be \"model\", \"all\"\n    or, if absent, will default to all - ie a site-wide count.\n    \"\"\"\n\n    # get the relevent model if applicable\n    if app_label and model:\n        try:\n            model = ContentType.objects.get(app_label=app_label, model=model)\n        except:\n            raise Http404\n    else:\n        model = None\n    \n    if not request.GET.has_key(\"q\"):\n        raise Http404\n    else:\n        q = request.GET[\"q\"]\n    \n    # counts can be 'all', 'model' or 'None'\n    counts = request.GET.get(\"counts\", \"all\")\n    limit = request.GET.get(\"limit\", 10)\n    \n    if model:\n        tags = Tag.objects.filter(\n            items__content_type = model,\n            name__istartswith = q\n        ).distinct()[:limit]\n    else:\n        tags = Tag.objects.filter(\n            name__istartswith = q\n        ).distinct()[:limit]\n\n    if counts == \"all\":\n        l = sorted(list(tags),\n            lambda x, y: cmp(y.items.all().count(), x.items.all().count())\n        )\n        tag_list = \"\\n\".join([ '%s||(%s)' % (tag.name, tag.items.all().count() ) for tag in l if tag])\n\n    elif counts == \"model\":\n        if model:\n            l = sorted(list(tags),\n                lambda x, y:\n                    cmp(y.items.filter(content_type=model).count(), x.items.filter(content_type=model).count())\n            )\n            tag_list = \"\\n\".join(\n                [\"%s||(%s)\" % (tag.name, tag.items.filter(content_type=model).count()) for tag in l if tag]\n            )\n        else:\n            raise Exception(\n                'You asked for a model with GET but did not pass one to the url'\n            )\n    else:\n        tag_list = \"\\n\".join([tag.name for tag in tags if tag])\n    return HttpResponse(tag_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap all termui functions with a custom decorator.", "response": "def patch_ui_functions(wrapper):\n    '''Wrap all termui functions with a custom decorator.'''\n    NONE = object()\n    import click\n\n    saved = []\n\n    for name, info in sorted(_ui_functions.items()):\n        f = getattr(click, name, NONE)\n        if f is NONE:\n            continue\n\n        new_f = wrapper(_copy_fn(f), info)\n\n        argspec = getargspec(f)\n        signature = inspect.formatargspec(*argspec) \\\n            .lstrip('(') \\\n            .rstrip(')')\n        args = ', '.join(arg.split('=')[0].split(':')[0].strip()\n                         for arg in signature.split(','))\n\n        stub_f = eval('lambda {s}: {n}._real_click_fn({a})'\n                      .format(n=f.__name__, s=signature, a=args))\n\n        if PY2:\n            saved.append((f, f.func_code))\n            f.func_code = stub_f.func_code\n        else:\n            saved.append((f, f.__code__))\n            f.__code__ = stub_f.__code__\n\n        f._real_click_fn = new_f\n\n    try:\n        yield\n    finally:\n        for f, code in saved:\n            if PY2:\n                f.func_code = code\n            else:\n                f.__code__ = code\n\n            del f._real_click_fn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_region_border(start, end):\n    cells = defaultdict(Cell)\n\n    start_row = row_number(start)\n    end_row = row_number(end)\n    if end % 0x10 == 0:\n        end_row -= 1\n\n    ## topmost cells\n    if start_row == end_row:\n        for i in range(start, end):\n            cells[i].top = True\n    else:\n        for i in range(start, row_end_index(start) + 1):\n            cells[i].top = True\n    # cells on second row, top left\n    if start_row != end_row:\n        next_row_start = row_start_index(start) + 0x10\n        for i in range(next_row_start, next_row_start + column_number(start)):\n            cells[i].top = True\n\n    ## bottommost cells\n    if start_row == end_row:\n        for i in range(start, end):\n            cells[i].bottom = True\n    else:\n        for i in range(row_start_index(end), end):\n            cells[i].bottom = True\n    # cells on second-to-last row, bottom right\n    if start_row != end_row:\n        prev_row_end = row_end_index(end) - 0x10\n        for i in range(prev_row_end - (0x10 - column_number(end) - 1), prev_row_end + 1):\n            cells[i].bottom = True\n\n    ## leftmost cells\n    if start_row == end_row:\n        cells[start].left = True\n    else:\n        second_row_start = row_start_index(start) + 0x10\n        for i in range(second_row_start, row_start_index(end) + 0x10, 0x10):\n            cells[i].left = True\n    # cells in first row, top left\n    if start_row != end_row:\n        cells[start].left = True\n\n    ## rightmost cells\n    if start_row == end_row:\n        cells[end - 1].right = True\n    else:\n        penultimate_row_end = row_end_index(end) - 0x10\n        for i in range(row_end_index(start), penultimate_row_end + 0x10, 0x10):\n            cells[i].right = True\n    # cells in last row, bottom right\n    if start_row != end_row:\n        cells[end - 1].right = True\n\n    # convert back to standard dict\n    # trick from: http://stackoverflow.com/a/20428703/87207\n    cells.default_factory = None\n    return cells", "response": "Compute the border edges of a region."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert SWF slides into PNG image.", "response": "def swf2png(swf_path, png_path, swfrender_path=\"swfrender\"):\n    \"\"\"Convert SWF slides into a PNG image\n\n    Raises:\n        OSError is raised if swfrender is not available.\n        ConversionError is raised if image cannot be created.\n    \"\"\"\n    # Currently rely on swftools\n    #\n    # Would be great to have a native python dependency to convert swf into png or jpg.\n    # However it seems that pyswf  isn't flawless. Some graphical elements (like the text!) are lost during\n    # the export.\n    try:\n        cmd = [swfrender_path, swf_path, '-o', png_path]\n        subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        raise ConversionError(\"Failed to convert SWF file %s.\\n\"\n                              \"\\tCommand: %s\\n\"\n                              \"\\tExit status: %s.\\n\"\n                              \"\\tOutput:\\n%s\"\n                              % (swf_path, \" \".join(cmd), e.returncode, e.output))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the presentation. The audio track is mixed with the slides. The resulting file is saved as self.output DownloadError is raised if some resources cannot be fetched. ConversionError is raised if the final video cannot be created.", "response": "def create_presentation(self):\n        \"\"\" Create the presentation.\n\n        The audio track is mixed with the slides. The resulting file is saved as self.output\n\n        DownloadError is raised if some resources cannot be fetched.\n        ConversionError is raised if the final video cannot be created.\n        \"\"\"\n        # Avoid wasting time and bandwidth if we known that conversion will fail.\n        if not self.overwrite and os.path.exists(self.output):\n            raise ConversionError(\"File %s already exist and --overwrite not specified\" % self.output)\n\n        video = self.download_video()\n        raw_slides = self.download_slides()\n\n        # ffmpeg does not support SWF\n        png_slides = self._convert_slides(raw_slides)\n        # Create one frame per second using the time code information\n        frame_pattern = self._prepare_frames(png_slides)\n\n        return self._assemble(video, frame_pattern)"}
