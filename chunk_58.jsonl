{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prt_ver_n_key(self, prt, verbose):\n        pre = '# '\n        prt.write('# ----------------------------------------------------------------\\n')\n        prt.write('# - Description of GO ID fields\\n')\n        prt.write('# ----------------------------------------------------------------\\n')\n        prt.write(\"# Versions:\\n#    {VER}\\n\".format(VER=\"\\n#    \".join(self.objgrpd.ver_list)))\n        prt.write('\\n# Marker keys:\\n')\n        for ntgos in self.go_ntsets:\n            prt.write('#     X -> GO is present in {HDR}\\n'.format(HDR=ntgos.hdr))\n        if verbose:\n            prt.write('\\n# Markers for header GO IDs and user GO IDs:\\n')\n            prt.write(\"#     '**' -> GO term is both a header and a user GO ID\\n\")\n            prt.write(\"#     '* ' -> GO term is a header, but not a user GO ID\\n\")\n            prt.write(\"#     '  ' -> GO term is a user GO ID\\n\")\n        prt.write('\\n# GO Namspaces:\\n')\n        prt.write('#     BP -> Biological Process\\n')\n        prt.write('#     MF -> Molecular Function\\n')\n        prt.write('#     CC -> Cellualr Component\\n')\n        if verbose:\n            prt.write('\\n# Example fields: 5 uGOs   362  47 L04 D04 R04\\n')\n            prt.write('#     N uGOs         -> number of user GO IDs under this GO header\\n')\n            prt.write('#     First integer  -> number of GO descendants\\n')\n            prt.write('#     Second integer -> number of GO children for the current GO ID\\n')\n        prt.write('\\n# Depth information:\\n')\n        if not verbose:\n            prt.write('#     int -> number of GO descendants\\n')\n        if verbose:\n            prt.write('#     Lnn -> level (minimum distance from root to node)\\n')\n        prt.write('#     Dnn -> depth (maximum distance from root to node)\\n')\n        if verbose:\n            prt.write('#     Rnn -> depth accounting for relationships\\n\\n')\n            RelationshipStr().prt_keys(prt, pre)\n        if verbose:\n            prt.write('\\n')\n            objd1 = GoDepth1LettersWr(self.gosubdag.rcntobj)\n            objd1.prt_header(prt, 'DEPTH-01 GO terms and their aliases', pre)\n            objd1.prt_txt(prt, pre)", "response": "Print version and key indicating presence of GO ID in a list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a TermCounts object if the user provides an annotation file otherwise None.", "response": "def get_tcntobj(self, go_all, **kws):\n        \"\"\"Get a TermCounts object if the user provides an annotation file, otherwise None.\"\"\"\n        # kws: gaf (gene2go taxid)\n        if 'gaf' in kws or 'gene2go' in kws:\n            # Get a reduced go2obj set for TermCounts\n            _gosubdag = GoSubDag(go_all, self.godag, rcntobj=False, prt=None)\n            return get_tcntobj(_gosubdag.go2obj, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_go2ntpresent(go_ntsets, go_all, gosubdag):\n        go2ntpresent = {}\n        ntobj = namedtuple('NtPresent', \" \".join(nt.hdr for nt in go_ntsets))\n        # Get present marks for GO sources\n        for goid_all in go_all:\n            present_true = [goid_all in nt.go_set for nt in go_ntsets]\n            present_str = ['X' if tf else '.' for tf in present_true]\n            go2ntpresent[goid_all] = ntobj._make(present_str)\n        # Get present marks for all other GO ancestors\n        goids_ancestors = set(gosubdag.go2obj).difference(go2ntpresent)\n        assert not goids_ancestors.intersection(go_all)\n        strmark = ['.' for _ in range(len(go_ntsets))]\n        for goid in goids_ancestors:\n            go2ntpresent[goid] = ntobj._make(strmark)\n        return go2ntpresent", "response": "Initialize the GO2NT present field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_go_sets(self, go_fins):\n        go_sets = []\n        assert go_fins, \"EXPECTED FILES CONTAINING GO IDs\"\n        assert len(go_fins) >= 2, \"EXPECTED 2+ GO LISTS. FOUND: {L}\".format(\n            L=' '.join(go_fins))\n        obj = GetGOs(self.godag)\n        for fin in go_fins:\n            assert os.path.exists(fin), \"GO FILE({F}) DOES NOT EXIST\".format(F=fin)\n            go_sets.append(obj.get_usrgos(fin, sys.stdout))\n        return go_sets", "response": "Get lists of GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the letters representing all parent terms which are depth - 01 GO terms.", "response": "def get_parents_letters(self, goobj):\n        \"\"\"Get the letters representing all parent terms which are depth-01 GO terms.\"\"\"\n        parents_all = set.union(self.go2parents[goobj.id])\n        parents_all.add(goobj.id)\n        # print \"{}({}) D{:02}\".format(goobj.id, goobj.name, goobj.depth), parents_all\n        parents_d1 = parents_all.intersection(self.gos_depth1)\n        return [self.goone2ntletter[g].D1 for g in parents_d1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets D1 - string representing all parent terms which are depth - 01 GO terms.", "response": "def get_d1str(self, goobj, reverse=False):\n        \"\"\"Get D1-string representing all parent terms which are depth-01 GO terms.\"\"\"\n        return \"\".join(sorted(self.get_parents_letters(goobj), reverse=reverse))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_most_specific_dcnt(goids, go2nt):\n    # go2nt_usr = {go:go2nt[go] for go in goids}\n    # return min(go2nt_usr.items(), key=lambda t: t[1].dcnt)[0]\n    return min(_get_go2nt(goids, go2nt), key=lambda t: t[1].dcnt)[0]", "response": "Get the GO ID with the lowest descendants count."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_most_specific_tinfo(goids, go2nt):\n    # go2nt_usr = {go:go2nt[go] for go in goids}\n    # return max(go2nt_usr.items(), key=lambda t: t[1].tinfo)[0]\n    return max(_get_go2nt(goids, go2nt), key=lambda t: t[1].tinfo)[0]", "response": "Get the GO ID with the highest GO term annotation information value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the GO ID with the highest GO term annotation information value.", "response": "def get_most_specific_tinfo_dcnt(goids, go2nt):\n    \"\"\"Get the GO ID with the highest GO term annotation information value.\"\"\"\n    # go2nt_usr = {go:go2nt[go] for go in goids}\n    # return max(go2nt_usr.items(), key=lambda t: [t[1].tinfo, t[1].dcnt])[0]\n    return max(_get_go2nt(goids, go2nt), key=lambda t: [t[1].tinfo, t[1].dcnt])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_go2nt(goids, go2nt_all):\n    go_nt_list = []\n    goids_seen = set()\n    for goid_usr in goids:\n        ntgo = go2nt_all[goid_usr]\n        goid_main = ntgo.id\n        if goid_main not in goids_seen:\n            goids_seen.add(goid_main)\n            go_nt_list.append((goid_main, ntgo))\n    return go_nt_list", "response": "Get user GO2NT using main GO IDs not alt IDs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting full GO report without grouping.", "response": "def prt_report_grp0(self, prt=sys.stdout):\n        \"\"\"Print full GO/gene report without grouping.\"\"\"\n        summaryline = self.str_summaryline()\n        kws_grp = {'use_sections':False,\n                   'hdrgo_prt':False,\n                   'sortby':lambda nt: [-1*nt.dcnt, nt.depth]}\n        # Print grouped GO IDs\n        prt.write(\"{SUMMARY}\\n\".format(SUMMARY=summaryline))\n        self.prt_gos_grouped(sys.stdout, **kws_grp)\n        # genes\n        genes = sorted(self.gene2gos.keys())\n        prt.write(\"\\n\\n{SUMMARY}\\n\\n\".format(SUMMARY=summaryline))\n        self.prt_gene_aart(genes, prt)\n        # Sort genes\n        prt.write(\"\\n\\n{SUMMARY}\\n\\n\".format(SUMMARY=summaryline))\n        self.prt_gene_aart_details(genes, prt)\n        return (self.name, self.get_section_marks())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prt_report_grp1(self, prt=sys.stdout, **kws_grp):\n        summaryline = self.str_summaryline()\n        # Print grouped GO IDs\n        prt.write(\"{SUMMARY}\\n\".format(SUMMARY=summaryline))\n        self.prt_gos_grouped(prt, **kws_grp)\n        # genes\n        genes = sorted(self.gene2gos.keys())\n        prt.write(\"\\n\\n{SUMMARY}\\n\\n\".format(SUMMARY=summaryline))\n        self.prt_section_key(prt)\n        self.prt_gene_aart(genes, prt)\n        # Sort genes\n        prt.write(\"\\n\\n{SUMMARY}\\n\\n\".format(SUMMARY=summaryline))\n        self.prt_gene_aart_details(genes, prt)\n        return (self.name, self.get_section_marks())", "response": "Print full GO report with grouping."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints 47 GOs 262 genes described by 10 of 19 sections consistent_increase.", "response": "def str_summaryline(self):\n        \"\"\"Print: 47 GOs, 262 genes described by 10 of 19 sections consistent_increase.\"\"\"\n        return \"{N} GOs, {M} genes described by {X} of {Y} sections {NM}\".format(\n            N=len(self.go2nt), M=len(self.gene2gos),\n            X=len(self.sec2chr), Y=len(self.datobj.sec2chr), NM=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prt_gos_grouped(self, prt, **kws_grp):\n        prtfmt = self.datobj.kws['fmtgo']\n        wrobj = WrXlsxSortedGos(self.name, self.sortobj)\n        # Keyword arguments: control content: hdrgo_prt section_prt top_n use_sections\n        desc2nts = self.sortobj.get_desc2nts(**kws_grp)\n        wrobj.prt_txt_desc2nts(prt, desc2nts, prtfmt)", "response": "Print grouped GO list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prt_gos_flat(self, prt):\n        prtfmt = self.datobj.kws['fmtgo']\n        _go2nt = self.sortobj.grprobj.go2nt\n        go2nt = {go:_go2nt[go] for go in self.go2nt}\n        prt.write(\"\\n{N} GO IDs:\\n\".format(N=len(go2nt)))\n        _sortby = self._get_sortgo()\n        for ntgo in sorted(go2nt.values(), key=_sortby):\n            prt.write(prtfmt.format(**ntgo._asdict()))", "response": "Print flat GO list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget function for sorting GO terms in a list of namedtuples.", "response": "def _get_sortgo(self):\n        \"\"\"Get function for sorting GO terms in a list of namedtuples.\"\"\"\n        if 'sortgo' in self.datobj.kws:\n            return self.datobj.kws['sortgo']\n        return self.datobj.grprdflt.gosubdag.prt_attr['sort'] + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint ASCII art which represents its associated GO IDs.", "response": "def prt_gene_aart(self, geneids, prt=sys.stdout):\n        \"\"\"For each gene, print ASCII art which represents its associated GO IDs.\"\"\"\n        patgene = self.datobj.kws[\"fmtgene\"]\n        itemid2name = self.datobj.kws.get(\"itemid2name\")\n        prt.write(\"\\n{HDR}\\n\".format(HDR=self.str_hdr()))\n        for geneid in geneids:\n            symbol = \"\" if itemid2name is None else itemid2name.get(geneid, \"\")\n            prt.write(patgene.format(AART=self.gene2aart[geneid], ID=geneid, NAME=symbol))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting ASCII art which represents its associated GO IDs.", "response": "def prt_gene_aart_details(self, geneids, prt=sys.stdout):\n        \"\"\"For each gene, print ASCII art which represents its associated GO IDs.\"\"\"\n        _go2nt = self.sortobj.grprobj.go2nt\n        patgene = self.datobj.kws[\"fmtgene2\"]\n        patgo = self.datobj.kws[\"fmtgo2\"]\n        itemid2name = self.datobj.kws.get(\"itemid2name\")\n        chr2i = self.datobj.get_chr2idx()\n        for geneid in geneids:\n            gos_gene = self.gene2gos[geneid]\n            symbol = \"\" if itemid2name is None else itemid2name.get(geneid, \"\")\n            prt.write(\"\\n\")\n            prt.write(patgene.format(AART=self.gene2aart[geneid], ID=geneid, NAME=symbol))\n            go2nt = {go:(_go2nt[go], \"\".join(self.go2chrs[go])) for go in gos_gene}\n            for ntgo, abc in sorted(go2nt.values(),\n                                    key=lambda t: [chr2i[t[1][:1]], t[0].NS, -1*t[0].dcnt]):\n                prt.write(\"{ABC} \".format(ABC=abc))\n                prt.write(patgo.format(**ntgo._asdict()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the section name and its alias.", "response": "def prt_section_key(self, prt=sys.stdout):\n        \"\"\"Print the section name and its alias.\"\"\"\n        for section_name, letter in self.datobj.sec2chr.items():\n            mrk = '*' if section_name in self.sec2chr else \"\"\n            prt.write(\"{M:1} {ABC} {SECT}\\n\".format(M=mrk, ABC=letter, SECT=section_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a boolean vector for each gene representing GO section membership.", "response": "def get_gene2binvec(self):\n        \"\"\"Return a boolean vector for each gene representing GO section membership.\"\"\"\n        _sec2chr = self.sec2chr\n        return {g:[s in s2gos for s in _sec2chr] for g, s2gos in self.gene2section2gos.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_go2nt(self, goea_results):\n        go2obj = self.objaartall.grprdflt.gosubdag.go2obj\n        # Add string version of P-values\n        goea_nts = MgrNtGOEAs(goea_results).get_nts_strpval()\n        return {go2obj[nt.GO].id:nt for nt in goea_nts if nt.GO in go2obj}", "response": "Return go2nt with added formatted string versions of the P - values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_gene2gos(go2nt):\n        gene2gos = cx.defaultdict(set)\n        nt0 = next(iter(go2nt.values()))\n        b_str = isinstance(nt0.study_items, str)\n        # print(\"NNNNTTTT\", nt0)\n        for goid, ntgo in go2nt.items():\n            study_items = ntgo.study_items.split(', ') if b_str else ntgo.study_items\n            for geneid in study_items:\n                gene2gos[geneid].add(goid)\n        if b_str:\n          b_set = set(isinstance(g.isdigit(), int) for g in nt0.study_items.split(', '))\n          if b_set == set([True]):\n            return {int(g):gos for g, gos in gene2gos.items()}\n        return {g:gos for g, gos in gene2gos.items()}", "response": "Create a gene product to GO set dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a GO return a set of letters representing it s section membership", "response": "def get_go2chrs(sec2gos, sec2chr):\n        \"\"\"Dict: given a GO return a set of letters representing it's section membership(s).\"\"\"\n        go2chrs = {}\n        for goid, sections in get_b2aset(sec2gos).items():\n            go2chrs[goid] = set(sec2chr[s] for s in sections)\n        return go2chrs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_gene2aart(gene2section2gos, sec2chr):\n        geneid2str = {}\n        for geneid, section2gos_gene in gene2section2gos.items():\n            letters = [abc if s in section2gos_gene else \".\" for s, abc in sec2chr.items()]\n            geneid2str[geneid] = \"\".join(letters)\n        return geneid2str", "response": "Return a string for each gene representing GO section membership."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_gene2section2gos(gene2gos, sec2gos):\n        gene2section2gos = {}\n        for geneid, gos_gene in gene2gos.items():\n            section2gos = {}\n            for section_name, gos_sec in sec2gos.items():\n                gos_secgene = gos_gene.intersection(gos_sec)\n                if gos_secgene:\n                    section2gos[section_name] = gos_secgene\n            gene2section2gos[geneid] = section2gos\n        return gene2section2gos", "response": "Get a list of section aliases for each gene product ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning user - created Go2Color object or create one.", "response": "def _init_objcolor(self, node_opts, **kwu):\n        \"\"\"Return user-created Go2Color object or create one.\"\"\"\n        objgoea = node_opts.kws['dict'].get('objgoea', None)\n        # kwu: go2color go2bordercolor dflt_bordercolor key2col\n        return Go2Color(self.gosubdag, objgoea, **kwu)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize a GO Node plot options object and GoNodeOpts.", "response": "def _init_gonodeopts(self, **kws_usr):\n        \"\"\"Initialize a GO Node plot options object, GoNodeOpts.\"\"\"\n        options = GoNodeOpts(self.gosubdag, **self.kws['node_go'])\n        # Add parent edge count if either is in kws: parentcnt, prt_pcnt\n        if not options.kws['set'].isdisjoint(['parentcnt', 'prt_pcnt']):\n            options.kws['dict']['c2ps'] = self.edgesobj.get_c2ps()\n        # GoeaResults(kws['goea_results'], **self.kws['goea']) if 'goea_results' in kws else None\n        if 'goea_results' in kws_usr:\n            objgoea = GoeaResults(kws_usr['goea_results'], **self.kws['goea'])\n            options.kws['dict']['objgoea'] = objgoea\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_goids(self, prt):\n        fmt = self.gosubdag.prt_attr['fmta']\n        nts = sorted(self.gosubdag.go2nt.values(), key=lambda nt: [nt.NS, nt.depth, nt.alt])\n        _get_color = self.pydotnodego.go2color.get\n        for ntgo in nts:\n            gostr = fmt.format(**ntgo._asdict())\n            col = _get_color(ntgo.GO, \"\")\n            prt.write(\"{COLOR:7} {GO}\\n\".format(COLOR=col, GO=gostr))", "response": "Print all GO IDs in the plot plus their color."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict containing user - specified plotting options.", "response": "def _init_kws(self, **kws_usr):\n        \"\"\"Return a dict containing user-specified plotting options.\"\"\"\n        kws_self = {}\n        user_keys = set(kws_usr)\n        for objname, expset in self.exp_keys.items():\n            usrkeys_curr = user_keys.intersection(expset)\n            kws_self[objname] = get_kwargs(kws_usr, usrkeys_curr, usrkeys_curr)\n        dpi = str(kws_self['dag'].get('dpi', self.dflts['dpi']))\n        kws_self['dag']['dpi'] = dpi\n        return kws_self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plt_dag(self, fout_img, engine=\"pydot\"):\n        if engine == \"pydot\":\n            self._plt_pydot(fout_img)\n        else:\n            raise RuntimeError(\"ENGINE NOT IMPLEMENTED({E})\".format(E=engine))", "response": "Plot using pydot graphviz or GML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting using the pydot graphics engine.", "response": "def _plt_pydot(self, fout_img):\n        \"\"\"Plot using the pydot graphics engine.\"\"\"\n        dag = self.get_pydot_graph()\n        self.wr_pydot_dag(fout_img, dag)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a pydot plot of the current set of GOs.", "response": "def wr_pydot_dag(self, fout_img, dag):\n        \"\"\"Plot using the pydot graphics engine.\"\"\"\n        img_fmt = os.path.splitext(fout_img)[1][1:]\n        dag.write(fout_img, format=img_fmt)\n        self.log.write(\"  {GO_USR:>3} usr {GO_ALL:>3} GOs  WROTE: {F}\\n\".format(\n            F=fout_img,\n            GO_USR=len(self.gosubdag.go_sources),\n            GO_ALL=len(dag.obj_dict['nodes'])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a DAG return a pydot digraph object.", "response": "def get_pydot_graph(self):\n        \"\"\"Given a DAG, return a pydot digraph object.\"\"\"\n        rel = \"is_a\"\n        # Initialize empty dag\n        dag = pydot.Dot(graph_type='digraph', **self.kws['dag'])\n        # Initialize nodes\n        go2node = self._get_go2pydotnode()\n        # Add nodes to graph\n        for node in go2node.values():\n            dag.add_node(node)\n        # Add edges to graph\n        rel2edgekws = self.rel2edgekws\n        self.edgesobj.chk_edges()\n        edgekws = rel2edgekws.get(rel)\n        self._add_edges(self.edgesobj.edges, go2node, dag, **edgekws)\n        for reltype, edges_list in self.edgesobj.edges_rel.items():\n            edgekws = rel2edgekws.get(reltype)\n            self._add_edges(edges_list, go2node, dag, **edgekws)\n        return dag"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_edges(self):\n        edge_from_to = []\n        for parent, children in self.p_from_cs.items():\n            for child in children:\n                edge_from_to.append((child, parent))\n        for parent, children in self.c_from_ps.items():\n            for child in children:\n                edge_from_to.append((child, parent))\n        return edge_from_to", "response": "Get the directed edges from GO term to GO term."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints decriptive info about each GO Term.", "response": "def prt_goids(self, goids=None, prtfmt=None, sortby=True, prt=sys.stdout):\n        \"\"\"Given GO IDs, print decriptive info about each GO Term.\"\"\"\n        if goids is None:\n            goids = self.go_sources\n        nts = self.get_nts(goids, sortby)\n        if prtfmt is None:\n            prtfmt = self.prt_attr['fmta']\n        for ntgo in nts:\n            key2val = ntgo._asdict()\n            prt.write(\"{GO}\\n\".format(GO=prtfmt.format(**key2val)))\n        return nts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives GO IDs get a list of namedtuples.", "response": "def get_nts(self, goids=None, sortby=None):\n        \"\"\"Given GO IDs, get a list of namedtuples.\"\"\"\n        nts = []\n        # User GO IDs\n        if goids is None:\n            goids = self.go_sources\n        else:\n            chk_goids(goids, \"GoSubDag::get_nts\")\n        if goids:\n            ntobj = cx.namedtuple(\"NtGo\", \" \".join(self.prt_attr['flds']))\n            go2nt = self.get_go2nt(goids)\n            for goid, ntgo in self._get_sorted_go2nt(go2nt, sortby):\n                assert ntgo is not None, \"{GO} NOT IN go2nt\".format(GO=goid)\n                if goid == ntgo.GO:\n                    nts.append(ntgo)\n                else:\n                    fld2vals = ntgo._asdict()\n                    fld2vals['GO'] = goid\n                    nts.append(ntobj(**fld2vals))\n        return nts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn sorted list of tuples.", "response": "def _get_sorted_go2nt(self, go2nt, sortby):\n        \"\"\"Return sorted list of tuples.\"\"\"\n        if sortby is True:\n            _fnc = self.get_fncsortnt()\n            return sorted(go2nt.items(), key=lambda t: _fnc(t[1]))\n        if sortby:\n            return sorted(go2nt.items(), key=lambda t: sortby(t[1]))\n        return go2nt.items()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_fncsortnt(self):\n        if 'dcnt' in self.prt_attr['flds']:\n            if 'D1' in self.prt_attr['flds']:\n                return lambda ntgo: [ntgo.NS, ntgo.depth, -1*ntgo.dcnt, ntgo.D1, ntgo.alt]\n            else:\n                return lambda ntgo: [ntgo.NS, ntgo.depth, -1*ntgo.dcnt, ntgo.alt]\n        else:\n            return lambda ntgo: [ntgo.NS, -1*ntgo.depth, ntgo.alt]", "response": "Return sorted list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_go2nt(self, goids):\n        get_nt = self.go2nt\n        goids_present = set(goids).intersection(self.go2obj)\n        if len(goids_present) != len(goids):\n            print(\"GO IDs NOT FOUND IN DAG: {GOs}\".format(\n                GOs=\" \".join(set(goids).difference(goids_present))))\n        return {g:get_nt[g] for g in goids_present}", "response": "Return dict of GO ID as key and GO object information in namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_go2obj(self, goids):\n        go2obj = self.go2obj\n        return {go:go2obj[go] for go in goids}", "response": "Return a go2obj dict for just the user goids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_vals(self, field, goids=None):\n        go2nt = self.go2nt\n        if goids is None:\n            goids = set(go2nt)\n        return [getattr(go2nt[go], field) for go in goids]", "response": "Return a go2obj dict for just the user goids."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving GO IDs return key GO IDs.", "response": "def get_key_goids(self, goids):\n        \"\"\"Given GO IDs, return key GO IDs.\"\"\"\n        go2obj = self.go2obj\n        return set(go2obj[go].id for go in goids)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngroups GO IDs by namespace.", "response": "def get_ns2goids(self, goids):\n        \"\"\"Group GO IDs by namespace.\"\"\"\n        ns2goids = cx.defaultdict(set)\n        go2nt = self.go2nt\n        for goid in goids:\n            ns2goids[go2nt[goid].NS].add(goid)\n        return {ns:gos for ns, gos in ns2goids.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn description of this GoSubDag object.", "response": "def prt_objdesc(self, prt):\n        \"\"\"Return description of this GoSubDag object.\"\"\"\n        txt = \"INITIALIZING GoSubDag: {N:3} sources in {M:3} GOs rcnt({R}). {A} alt GO IDs\\n\"\n        alt2obj = {go:o for go, o in self.go2obj.items() if go != o.id}\n        prt.write(txt.format(\n            N=len(self.go_sources),\n            M=len(self.go2obj),\n            R=self.rcntobj is not None,\n            A=len(alt2obj)))\n        prt.write(\"             GoSubDag: namedtuple fields: {FLDS}\\n\".format(\n            FLDS=\" \".join(self.prt_attr['flds'])))\n        prt.write(\"             GoSubDag: relationships: {RELS}\\n\".format(RELS=self.relationships))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the taxid set", "response": "def _init_taxids(taxid, taxids):\n        \"\"\"Return taxid set\"\"\"\n        ret = set()\n        if taxids is not None:\n            if taxids is True:\n                return True\n            if isinstance(taxids, int):\n                ret.add(taxids)\n            else:\n                ret.update(taxids)\n        if taxid is not None:\n            ret.add(taxid)\n        if not ret:\n            ret.add(9606)\n            # pylint: disable=superfluous-parens\n            print('**NOTE: DEFAULT TAXID STORED FROM gene2go IS 9606 (human)\\n')\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_associations(self, fin_anno, taxids=None):\n        nts = []\n        if fin_anno is None:\n            return nts\n        tic = timeit.default_timer()\n        lnum = -1\n        line = \"\\t\"*len(self.flds)\n        try:\n            with open(fin_anno) as ifstrm:\n                category2ns = {'Process':'BP', 'Function':'MF', 'Component':'CC'}\n                ntobj = cx.namedtuple('ntanno', self.flds)\n                # Get: 1) Specified taxids, default taxid(human), or all taxids\n                get_all = taxids is True\n                taxids = self.taxids\n                for lnum, line in enumerate(ifstrm, 1):\n                    # Read data\n                    if line[0] != '#':\n                        vals = line.split('\\t')\n                        taxid = int(vals[0])\n                        if get_all or taxid in taxids:\n                            # assert len(vals) == 8\n                            ntd = ntobj(\n                                tax_id=taxid,\n                                DB_ID=int(vals[1]),\n                                GO_ID=vals[2],\n                                Evidence_Code=vals[3],\n                                Qualifier=self._get_qualifiers(vals[4]),\n                                GO_term=vals[5],\n                                DB_Reference=self._get_pmids(vals[6]),\n                                NS=category2ns[vals[7].rstrip()])\n                            #self._chk_qualifiers(qualifiers, lnum, ntd)\n                            nts.append(ntd)\n                    # Read header\n                    elif line[0] == '#':\n                        assert line[1:-1].split('\\t') == self.hdrs\n        # pylint: disable=broad-except\n        except Exception as inst:\n            import traceback\n            traceback.print_exc()\n            sys.stderr.write(\"\\n  **FATAL: {MSG}\\n\\n\".format(MSG=str(inst)))\n            sys.stderr.write(\"**FATAL: {FIN}[{LNUM}]:\\n{L}\".format(FIN=fin_anno, L=line, LNUM=lnum))\n            self._prt_line_detail(sys.stdout, line, lnum)\n            sys.exit(1)\n        print('HMS:{HMS} {N:7,} annotations READ: {ANNO}'.format(\n            N=len(nts), ANNO=fin_anno,\n            HMS=str(datetime.timedelta(seconds=(timeit.default_timer()-tic)))))\n        return nts", "response": "Read annotation file. Store annotation data in a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting each field and its value.", "response": "def _prt_line_detail(self, prt, line, lnum=\"\"):\n        \"\"\"Print each field and its value.\"\"\"\n        data = zip(self.flds, line.split('\\t'))\n        txt = [\"{:2}) {:13} {}\".format(i, hdr, val) for i, (hdr, val) in enumerate(data)]\n        prt.write(\"{LNUM}\\n{TXT}\\n\".format(LNUM=lnum, TXT='\\n'.join(txt)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the fields are legal in GAF", "response": "def chk_associations(self, fout_err=\"gaf.err\"):\n        \"\"\"Check that fields are legal in GAF\"\"\"\n        obj = GafData(\"2.1\")\n        return obj.chk(self.associations, fout_err)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread annotation file and store a list of namedtuples.", "response": "def _init_associations(self, fin_gaf, hdr_only, prt, allow_missing_symbol):\n        \"\"\"Read annotation file and store a list of namedtuples.\"\"\"\n        ini = InitAssc()\n        nts = ini.init_associations(fin_gaf, hdr_only, prt, allow_missing_symbol)\n        self.hdr = ini.hdr\n        return nts"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns source GO IDs.", "response": "def get_go_color(self, **kws):\n        \"\"\"Return source GO IDs .\"\"\"\n        ret = {'GOs':set(), 'go2color':{}}\n        if 'GO' in kws:\n            self._goargs(ret, kws['GO'])\n        if 'go_file' in kws:\n            self._rdtxt_gos(ret, kws['go_file'])\n        if 'draw-children' in kws:\n            ret['GOs'].update(get_leaf_children(ret['GOs'], self.go2obj))\n        # If there have been no GO IDs explicitly specified by the user\n        if not ret['GOs']:\n            # If the GO-DAG is sufficiently small, print all GO IDs\n            if len(self.go2obj) < self.max_gos:\n                main_gos = set(o.id for go, o in self.go2obj.items() if go != o.id)\n                go_leafs = set(go for go, o in self.go2obj.items() if not o.children)\n                ret['GOs'] = go_leafs.difference(main_gos)\n            else:\n                raise RuntimeError(\"GO IDs NEEDED\")\n        go2obj = {go:self.go2obj[go] for go in ret['GOs']}\n        ret['GOs'] = set(get_go2obj_unique(go2obj))\n        return [ret['GOs'], ret['go2color']]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _goargs(self, ret, go_args):\n        goids = set()\n        go2color = {}\n        # Match on \"GO ID\" or \"GO ID and color\"\n        re_gocolor = re.compile(r'(GO:\\d{7})((?:#[0-9a-fA-F]{6})?)')\n        for go_arg in go_args:\n            mtch = re_gocolor.match(go_arg)\n            if mtch:\n                goid, color = mtch.groups()\n                goids.add(goid)\n                if color:\n                    go2color[goid] = color\n            else:\n                print(\"WARNING: UNRECOGNIZED ARG({})\".format(go_arg))\n        self._update_ret(ret, goids, go2color)", "response": "Get GO IDs and colors from the GO ID runtime arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading GO IDs from a file.", "response": "def _rdtxt_gos(self, ret, go_file):\n        \"\"\"Read GO IDs from a file.\"\"\"\n        if not os.path.exists(go_file):\n            raise RuntimeError(\"CAN NOT READ: {FILE}\\n\".format(FILE=go_file))\n        goids = set()\n        go2color = {}\n        with open(go_file) as ifstrm:\n            for line in ifstrm:\n                goids_found = self.re_goids.findall(line)\n                if goids_found:\n                    goids.update(goids_found)\n                    colors = self.re_color.findall(line)\n                    if colors:\n                        if len(goids_found) == len(colors):\n                            for goid, color in zip(goids_found, colors):\n                                go2color[goid] = color\n                        else:\n                            print(\"IGNORING: {L}\".format(L=line),)\n        self._update_ret(ret, goids, go2color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the dict with goids and go2color.", "response": "def _update_ret(ret, goids, go2color):\n        \"\"\"Update 'GOs' and 'go2color' in dict with goids and go2color.\"\"\"\n        if goids:\n            ret['GOs'].update(goids)\n        if go2color:\n            for goid, color in go2color.items():\n                ret['go2color'][goid] = color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommand - line interface for go_draw script.", "response": "def cli(self):\n        \"\"\"Command-line interface for go_draw script.\"\"\"\n        kws_all = self.get_docargs(prt=None)\n        optional_attrs = self._get_optional_attrs(kws_all)\n        go2obj = GODag(kws_all['obo'], optional_attrs)\n        # GO kws_all: GO go_file draw-children\n        goids, go2color = GetGOs(go2obj).get_go_color(**kws_all)\n        relationships = 'relationship' in optional_attrs\n        #### self.gosubdag = GoSubDag(goids, go2obj, relationships, tcntobj=tcntobj)\n        kws_dag = self._get_kwsdag(goids, go2obj, **kws_all)\n        self.gosubdag = GoSubDag(goids, go2obj, relationships, **kws_dag)\n\n        if 'sections' in kws_all:\n            return self._plt_gogrouped(goids, go2color, **kws_all)\n        else:\n            return self._plt_gosubdag(goids, go2color, **kws_all)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _plt_gogrouped(self, goids, go2color_usr, **kws):\n        fout_img = self.get_outfile(kws['outfile'], goids)\n        sections = read_sections(kws['sections'], exclude_ungrouped=True)\n        # print (\"KWWSSSSSSSS\", kws)\n        # kws_plt = {k:v for k, v in kws.items if k in self.kws_plt}\n        grprobj_cur = self._get_grprobj(goids, sections)\n        # GO: purple=hdr-only, green=hdr&usr, yellow=usr-only\n        # BORDER: Black=hdr Blu=hdr&usr\n        grpcolor = GrouperColors(grprobj_cur)  # get_bordercolor get_go2color_users\n        grp_go2color = grpcolor.get_go2color_users()\n        grp_go2bordercolor = grpcolor.get_bordercolor()\n        for goid, color in go2color_usr.items():\n            grp_go2color[goid] = color\n        objcolor = Go2Color(self.gosubdag, objgoea=None,\n                            go2color=grp_go2color, go2bordercolor=grp_go2bordercolor)\n        go2txt = GrouperPlot.get_go2txt(grprobj_cur, grp_go2color, grp_go2bordercolor)\n        objplt = GoSubDagPlot(self.gosubdag, Go2Color=objcolor, go2txt=go2txt, **kws)\n        objplt.prt_goids(sys.stdout)\n        objplt.plt_dag(fout_img)\n        sys.stdout.write(\"{N:>6} sections read\\n\".format(\n            N=\"NO\" if sections is None else len(sections)))\n        return fout_img", "response": "Plot grouped GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget Grouper given GO IDs and sections.", "response": "def _get_grprobj(self, goids, sections):\n        \"\"\"Get Grouper, given GO IDs and sections.\"\"\"\n        grprdflt = GrouperDflts(self.gosubdag, \"goslim_generic.obo\")\n        hdrobj = HdrgosSections(self.gosubdag, grprdflt.hdrgos_dflt, sections)\n        return Grouper(\"sections\", goids, hdrobj, self.gosubdag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_kwsdag(self, goids, go2obj, **kws_all):\n        kws_dag = {}\n        # Term Counts for GO Term information score\n        tcntobj = self._get_tcntobj(goids, go2obj, **kws_all)  # TermCounts or None\n        if tcntobj is not None:\n            kws_dag['tcntobj'] = tcntobj\n        # GO letters specified by the user\n        if 'go_aliases' in kws_all:\n            fin_go_aliases = kws_all['go_aliases']\n            if os.path.exists(fin_go_aliases):\n                go2letter = read_d1_letter(fin_go_aliases)\n                if go2letter:\n                    kws_dag['go2letter'] = go2letter\n        return kws_dag", "response": "Get keyword args for a GoSubDag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparing down docopt. Return a minimal dictionary and a set containing runtime arg values.", "response": "def get_docargs(self, args=None, prt=None):\n        \"\"\"Pare down docopt. Return a minimal dictionary and a set containing runtime arg values.\"\"\"\n        # docargs = self.objdoc.get_docargs(args, exp_letters=set(['o', 't', 'p', 'c']))\n        docargs = self.objdoc.get_docargs(args, prt)\n        self._chk_docopts(docargs)\n        return docargs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _chk_docopts(self, kws):\n        # outfile should contain .png, .png, etc.\n        outfile = kws['outfile']\n        if len(kws) == 2 and os.path.basename(kws['obo']) == \"go-basic.obo\" and \\\n            kws['outfile'] == self.dflt_outfile:\n            self._err(\"NO GO IDS SPECFIED\", err=False)\n        if 'obo' in outfile:\n            self._err(\"BAD outfile({O})\".format(O=outfile))\n        if 'gaf' in kws and 'gene2go' in kws:\n            self._err(\"SPECIFY ANNOTAIONS FROM ONE FILE\")\n        if 'gene2go' in kws:\n            if 'taxid' not in kws:\n                self._err(\"SPECIFIY taxid WHEN READ NCBI'S gene2go FILE\")", "response": "Check for common user command - line errors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint useage and error before exiting.", "response": "def _err(self, msg, err=True):\n        \"\"\"Print useage and error before exiting.\"\"\"\n        severity = \"FATAL\" if err else \"NOTE\"\n        txt = \"\".join([self.objdoc.doc,\n                       \"User's command-line:\\n\\n\",\n                       \"  % go_plot.py {ARGS}\\n\\n\".format(ARGS=\" \".join(sys.argv[1:])),\n                       \"**{SEV}: {MSG}\\n\".format(SEV=severity, MSG=msg)])\n        if err:\n            raise RuntimeError(txt)\n        sys.stdout.write(txt)\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_outfile(self, outfile, goids=None):\n        # 1. Use the user-specfied output filename for the GO Term plot\n        if outfile != self.dflt_outfile:\n            return outfile\n        # 2. If only plotting 1 GO term, use GO is in plot name\n        if goids is not None and len(goids) == 1:\n            goid = next(iter(goids))\n            goobj = self.gosubdag.go2obj[goid]\n            fout = \"GO_{NN}_{NM}\".format(NN=goid.replace(\"GO:\", \"\"), NM=goobj.name)\n            return \".\".join([re.sub(r\"[\\s#'()+,-./:<=>\\[\\]_}]\", '_', fout), 'png'])\n        # 3. Return default name\n        return self.dflt_outfile", "response": "Return output file for a single GO Term plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives keyword args return optional_attributes to be loaded into the GODag.", "response": "def _get_optional_attrs(kws):\n        \"\"\"Given keyword args, return optional_attributes to be loaded into the GODag.\"\"\"\n        vals = OboOptionalAttrs.attributes.intersection(kws.keys())\n        if 'sections' in kws:\n            vals.add('relationship')\n        if 'norel' in kws:\n            vals.discard('relationship')\n        return vals"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommand - line interface for go_draw script.", "response": "def cli(self, prt=sys.stdout):\n        \"\"\"Command-line interface for go_draw script.\"\"\"\n        kws = self.objdoc.get_docargs(prt=None)\n        godag = get_godag(kws['obo'], prt=None, loading_bar=False, optional_attrs=['relationship'])\n        usrgos = GetGOs(godag, max_gos=200).get_usrgos(kws.get('GO_FILE'), prt)\n        tcntobj = self._get_tcntobj(usrgos, godag, **kws)  # Gets TermCounts or None\n        self.gosubdag = GoSubDag(usrgos, godag, relationships=True, tcntobj=tcntobj, prt=None)\n        grprdflt = GrouperDflts(self.gosubdag, kws['slims'])\n        ver_list = [godag.version, grprdflt.ver_goslims]\n        prt.write(\"{VER}\\n\".format(VER=\"\\n\".join(ver_list)))\n        sections = self._read_sections(kws['ifile'])\n        # print(\"SECSECSEC\", sections)\n        hdrobj = HdrgosSections(self.gosubdag, grprdflt.hdrgos_dflt, sections)\n        grprobj = Grouper(\"init\", usrgos, hdrobj, self.gosubdag)\n        # Write sections\n        objsecwr = WrSectionsTxt(grprobj, ver_list)\n        if not os.path.exists(kws['ifile']):\n            objsecwr.wr_txt_section_hdrgos(kws['ifile'])\n        objsecwr.wr_txt_section_hdrgos(kws['ofile'])\n        objsecpy = WrSectionsPy(grprobj, ver_list)\n        if 'py' in kws:\n            objsecpy.wr_py_sections(kws['py'], sections, doc=godag.version)\n        # Write user GO IDs in sections\n        sortobj = Sorter(grprobj)\n        objgowr = WrXlsxSortedGos(\"init\", sortobj, ver_list)\n        objgowr.wr_txt_gos(kws['txt'], sortby=objsecpy.fncsortnt)\n        #objwr.wr_txt_section_hdrgos(kws['ofile'], sortby=objwr.fncsortnt)\n        self._prt_cnt_usrgos(usrgos, sys.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_sections(ifile):\n        if os.path.exists(ifile):\n            return read_sections(ifile, exclude_ungrouped=True, prt=None)", "response": "Read sections_in. txt file if it exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a TermCounts object if the user provides an annotation file otherwise None.", "response": "def _get_tcntobj(goids, go2obj, **kws):\n        \"\"\"Get a TermCounts object if the user provides an annotation file, otherwise None.\"\"\"\n        # kws: gaf (gene2go taxid)\n        if 'gaf' in kws or 'gene2go' in kws:\n            # Get a reduced go2obj set for TermCounts\n            _gosubdag = GoSubDag(goids, go2obj, rcntobj=False, prt=None)\n            return get_tcntobj(_gosubdag.go2obj, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_paths_goobjs(go_objs, go_top=None, go2obj=None):\n    go_paths = []  # Collect all paths for go_objs\n    go_all = set() # Collect all GO terms in all paths\n    pathobj = GoPaths()\n    for go_obj in go_objs:\n        #print \"?FIND PATHS FOR {}?\".format(go_obj.id)\n        if go_obj.id not in go_all: # GO not yet seen in paths already found\n            #print \"!FIND PATHS FOR {}!\".format(go_obj.id)\n            paths_curr = pathobj.get_paths_from_to(go_obj, go_top, True)\n            if paths_curr:\n                for path_goobjs in paths_curr:\n                    for path_goobj in path_goobjs:\n                        goid = path_goobj.id\n                        if goid not in go_all:\n                            go_all.add(goid)\n                            go2obj[goid] = path_goobj\n                # go_all.update(GO.id for path in paths_curr for GO in path)\n                go_paths.extend(path for path in paths_curr)\n    return go_paths, go_all", "response": "Given a list of GO objects return a list of paths user GOs as ints all GO terms paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list of paths return a set of edges that are connected to them.", "response": "def paths2edges(paths):\n    \"\"\"[8079, 8135, 3723, 3676, 1901363, 5488, 3674] \"\"\"\n    edges_all = set()\n    for path in paths:\n        for edge in path2edges(path):\n            edges_all.add(edge)\n    return edges_all"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef path2edges(path):\n    node_a, node_b = tee(path)\n    next(node_b, None)\n    return zip(node_a, node_b)", "response": "Given a path return a set of edges."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of paths from goobj_start to either top or goid_end.", "response": "def get_paths_from_to(self, goobj_start, goid_end=None, dn0_up1=True):\n        \"\"\"Get a list of paths from goobj_start to either top or goid_end.\"\"\"\n        paths = []\n        # Queue of terms to be examined (and storage for their paths)\n        working_q = cx.deque([[goobj_start]])\n        # Loop thru GO terms until we have examined all needed GO terms\n        adjfnc = self.adjdir[dn0_up1]\n        while working_q:\n            #print \"WORKING QUEUE LEN({})\".format(len(working_q))\n            path_curr = working_q.popleft()\n            goobj_curr = path_curr[-1]\n            go_adjlst = adjfnc(goobj_curr)\n            #print 'END', goid_end, goobj_curr\n            # If this GO term is the endpoint, Stop. Store path.\n            if (goid_end is not None and goobj_curr.id == goid_end) or \\\n               (goid_end is None and not go_adjlst):\n                paths.append(path_curr)\n            # Else if this GO term is the not the end, add neighbors to path\n            else:\n                for go_neighbor in go_adjlst:\n                    if go_neighbor not in path_curr:\n                        #print \"{}'s NEIGHBOR IS {}\".format(goobj_curr.id, go_neighbor.id)\n                        new_path = path_curr + [go_neighbor]\n                        #sys.stdout.write(\" {}'s {} {}\\n\".format(goobj_curr, up_dn, go_neighbor))\n                        working_q.append(new_path)\n        #self.prt_paths(paths)\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting list of paths.", "response": "def prt_paths(paths, prt=sys.stdout):\n        \"\"\"Print list of paths.\"\"\"\n        pat = \"PATHES: {GO} L{L:02} D{D:02}\\n\"\n        for path in paths:\n            for go_obj in path:\n                prt.write(pat.format(GO=go_obj.id, L=go_obj.level, D=go_obj.depth))\n            prt.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef str_rel_short(self, goobj):\n        if not goobj.relationship:\n            return ''\n        rel_cur = goobj.relationship\n        return \"\".join([self.rel2chr.get(r, '?') for r in self.rels if r in rel_cur])", "response": "Return a string representing the presence of absence of relationships. Ex : P"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef str_relationships_rev(self, goobj):\n        rel_cur = goobj.relationship_rev\n        return \"\".join([self.rev2chr[r] if r in rel_cur else '.' for r in self.rels])", "response": "Return a string representing the presence of absence of relationships. Ex : pr.."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the alias for a relationship and its alias.", "response": "def prt_keys(self, prt, pre):\n        \"\"\"Print the alias for a relationship and its alias.\"\"\"\n        prt.write('{PRE}Relationship to parent: {ABC}\\n'.format(\n            PRE=pre, ABC=''.join(self.rel2chr.values())))\n        for rel, alias in self.rel2chr.items():\n            prt.write('{PRE}    {A} {DESC}\\n'.format(PRE=pre, A=alias, DESC=rel))\n        prt.write('\\n{PRE}Relationship to child: {ABC}\\n'.format(\n            PRE=pre, ABC=''.join(self.rev2chr.values())))\n        for rel, alias in self.rev2chr.items():\n            prt.write('{PRE}    {A} {DESC}\\n'.format(PRE=pre, A=alias, DESC=rel))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting annotation and evidence code summary.", "response": "def prt_summary_anno2ev(self, prt=sys.stdout):\n        \"\"\"Print annotation/evidence code summary.\"\"\"\n        self.evobj.prt_summary_anno2ev(self.associations, prt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets database IDs given a set of GO IDs.", "response": "def get_ids_g_goids(self, goids):\n        \"\"\"Get database IDs (DB_IDs), given a set of GO IDs.\"\"\"\n        return set(nt.DB_ID for nt in self.associations if nt.GO_ID in goids)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_id2gos(self, associations, **kws):\n        options = AnnoOptions(self.evobj, **kws)\n        # Default reduction is to remove. For all options, see goatools/anno/opts.py:\n        #   * Evidence_Code == ND -> No biological data No biological Data available\n        #   * Qualifiers contain NOT\n        assc = self.reduce_annotations(associations, options)\n        return self._get_dbid2goids(assc) if options.b_geneid2gos else self._get_goid2dbids(assc)", "response": "Return given associations in a dict id2gos"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints qualifier for the current class.", "response": "def prt_qualifiers(self, prt=sys.stdout):\n        \"\"\"Print Qualifiers: 1,462 colocalizes_with; 1,454 contributes_to; 1,157 not\"\"\"\n        # 13 not colocalizes_with   (TBD: CHK - Seen in gene2go, but not gafs)\n        #  4 not contributes_to     (TBD: CHK - Seen in gene2go, but not gafs)\n        self._prt_qualifiers(self.associations, prt)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prt_qualifiers(associations, prt=sys.stdout):\n        prt.write('QUALIFIERS:\\n')\n        for fld, cnt in cx.Counter(q for nt in associations for q in nt.Qualifier).most_common():\n            prt.write('    {N:6,} {FLD}\\n'.format(N=cnt, FLD=fld))", "response": "Print Qualifiers found in the annotations."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreduce annotations to ones used to identify enrichment ( normally exclude ND and NOT", "response": "def reduce_annotations(self, annotations, options):\n        \"\"\"Reduce annotations to ones used to identify enrichment (normally exclude ND and NOT).\"\"\"\n        getfnc_qual_ev = options.getfnc_qual_ev()\n        return [nt for nt in annotations if getfnc_qual_ev(nt.Qualifier, nt.Evidence_Code)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn gene2go data for user - specified taxids.", "response": "def _get_dbid2goids(associations):\n        \"\"\"Return gene2go data for user-specified taxids.\"\"\"\n        id2gos = cx.defaultdict(set)\n        for ntd in associations:\n            id2gos[ntd.DB_ID].add(ntd.GO_ID)\n        return dict(id2gos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_goid2dbids(associations):\n        go2ids = cx.defaultdict(set)\n        for ntd in associations:\n            go2ids[ntd.GO_ID].add(ntd.DB_ID)\n        return dict(go2ids)", "response": "Return gene2go data for user - specified taxids."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_date_yyyymmdd(yyyymmdd):\n        return date(int(yyyymmdd[:4]), int(yyyymmdd[4:6], base=10), int(yyyymmdd[6:], base=10))", "response": "Return datetime. date given string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hms(self, msg, tic=None, prt=sys.stdout):\n        if tic is None:\n            tic = self.tic\n        now = timeit.default_timer()\n        hms = str(datetime.timedelta(seconds=(now-tic)))\n        prt.write('{HMS}: {MSG}\\n'.format(HMS=hms, MSG=msg))\n        return now", "response": "Print elapsed time and message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck format of qualifier", "response": "def chk_qualifiers(self):\n        \"\"\"Check format of qualifier\"\"\"\n        if self.name == 'id2gos':\n            return\n        for ntd in self.associations:\n            # print(ntd)\n            qual = ntd.Qualifier\n            assert isinstance(qual, set), '{NAME}: QUALIFIER MUST BE A LIST: {NT}'.format(\n                NAME=self.name, NT=ntd)\n            assert qual != set(['']), ntd\n            assert qual != set(['-']), ntd\n            assert 'always' not in qual, 'SPEC SAID IT WOULD BE THERE'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _has_not_qual(ntd):\n        for qual in ntd.Qualifier:\n            if 'not' in qual:\n                return True\n            if 'NOT' in qual:\n                return True\n        return False", "response": "Return True if the qualifiers contain a NOT"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sorted_nts_keep_section(self, hdrgo_prt):\n        section_nts = []\n        # print(\"SSSS SorterNts:get_sorted_nts_keep_section(hdrgo_prt={})\".format(hdrgo_prt))\n        hdrgos_actual = self.sortgos.grprobj.get_hdrgos()\n        hdrgos_secs = set()\n        hdrgo_sort = False if self.section_sortby is False else True\n        secname_dflt = self.sortgos.grprobj.hdrobj.secdflt\n        for section_name, section_hdrgos_all in self.sections:\n            #section_hdrgos_act = set(section_hdrgos_all).intersection(hdrgos_actual)\n            section_hdrgos_act = [h for h in section_hdrgos_all if h in hdrgos_actual]\n            hdrgos_secs |= set(section_hdrgos_act)\n            nts_section = self.sortgos.get_nts_sorted(hdrgo_prt, section_hdrgos_act, hdrgo_sort)\n            if nts_section:\n                nts_section = self._get_sorted_section(nts_section)\n                section_nts.append((section_name, nts_section))\n        remaining_hdrgos = hdrgos_actual.difference(hdrgos_secs)\n        # Add GO group headers not yet used under new section, Misc.\n        if remaining_hdrgos:\n            nts_section = self.sortgos.get_nts_sorted(hdrgo_prt, remaining_hdrgos, hdrgo_sort)\n            if nts_section:\n                nts_section = self._get_sorted_section(nts_section)\n                section_nts.append((secname_dflt, nts_section))\n        return section_nts", "response": "Get 2 - D list of sections and sorted namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a flat list of sections with GO terms grouped and sorted.", "response": "def get_sorted_nts_omit_section(self, hdrgo_prt, hdrgo_sort):\n        \"\"\"Return a flat list of sections (wo/section names) with GO terms grouped and sorted.\"\"\"\n        nts_flat = []\n        # print(\"SSSS SorterNts:get_sorted_nts_omit_section(hdrgo_prt={}, hdrgo_sort={})\".format(\n        #     hdrgo_prt, hdrgo_sort))\n        hdrgos_seen = set()\n        hdrgos_actual = self.sortgos.grprobj.get_hdrgos()\n        for _, section_hdrgos_all in self.sections:\n            #section_hdrgos_act = set(section_hdrgos_all).intersection(hdrgos_actual)\n            section_hdrgos_act = [h for h in section_hdrgos_all if h in hdrgos_actual]\n            hdrgos_seen |= set(section_hdrgos_act)\n            self.sortgos.get_sorted_hdrgo2usrgos(\n                section_hdrgos_act, nts_flat, hdrgo_prt, hdrgo_sort)\n        remaining_hdrgos = set(self.sortgos.grprobj.get_hdrgos()).difference(hdrgos_seen)\n        self.sortgos.get_sorted_hdrgo2usrgos(remaining_hdrgos, nts_flat, hdrgo_prt, hdrgo_sort)\n        return nts_flat"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts GO IDs in each section if requested by user.", "response": "def _get_sorted_section(self, nts_section):\n        \"\"\"Sort GO IDs in each section, if requested by user.\"\"\"\n        #pylint: disable=unnecessary-lambda\n        if self.section_sortby is True:\n            return sorted(nts_section, key=lambda nt: self.sortgos.usrgo_sortby(nt))\n        if self.section_sortby is False or self.section_sortby is None:\n            return nts_section\n        # print('SORT GO IDS IN A SECTION')\n        return sorted(nts_section, key=lambda nt: self.section_sortby(nt))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all parent item IDs for each item in dict keys.", "response": "def get_id2parents(objs):\n    \"\"\"Get all parent item IDs for each item in dict keys.\"\"\"\n    id2parents = {}\n    for obj in objs:\n        _get_id2parents(id2parents, obj.item_id, obj)\n    return id2parents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_id2children(objs):\n    id2children = {}\n    for obj in objs:\n        _get_id2children(id2children, obj.item_id, obj)\n    return id2children", "response": "Get all parent item IDs for each item in dict keys."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_id2upper(objs):\n    id2upper = {}\n    for obj in objs:\n        _get_id2upper(id2upper, obj.item_id, obj)\n    return id2upper", "response": "Get all parent item IDs for each item in dict keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_id2lower(objs):\n    id2lower = {}\n    for obj in objs:\n        _get_id2lower(id2lower, obj.item_id, obj)\n    return id2lower", "response": "Get all parent item IDs for each item in dict keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets item ID set of item IDs in a relationship target set.", "response": "def get_relationship_targets(item_ids, relationships, id2rec):\n    \"\"\"Get item ID set of item IDs in a relationship target set.\"\"\"\n    # Requirements to use this function:\n    #     1) item Terms must have been loaded with 'relationships'\n    #     2) item IDs in 'item_ids' arguement must be present in id2rec\n    #     3) Arg, 'relationships' must be True or an iterable\n    reltgt_objs_all = set()\n    for goid in item_ids:\n        obj = id2rec[goid]\n        for reltype, reltgt_objs_cur in obj.relationship.items():\n            if relationships is True or reltype in relationships:\n                reltgt_objs_all.update(reltgt_objs_cur)\n    return reltgt_objs_all"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the parent item IDs for one item object and their parents.", "response": "def _get_id2parents(id2parents, item_id, item_obj):\n    \"\"\"Add the parent item IDs for one item object and their parents.\"\"\"\n    if item_id in id2parents:\n        return id2parents[item_id]\n    parent_ids = set()\n    for parent_obj in item_obj.parents:\n        parent_id = parent_obj.item_id\n        parent_ids.add(parent_id)\n        parent_ids |= _get_id2parents(id2parents, parent_id, parent_obj)\n    id2parents[item_id] = parent_ids\n    return parent_ids"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_id2children(id2children, item_id, item_obj):\n    if item_id in id2children:\n        return id2children[item_id]\n    child_ids = set()\n    for child_obj in item_obj.children:\n        child_id = child_obj.item_id\n        child_ids.add(child_id)\n        child_ids |= _get_id2children(id2children, child_id, child_obj)\n    id2children[item_id] = child_ids\n    return child_ids", "response": "Add the child item IDs for one item object and their children."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_id2upper(id2upper, item_id, item_obj):\n    if item_id in id2upper:\n        return id2upper[item_id]\n    upper_ids = set()\n    for upper_obj in item_obj.get_goterms_upper():\n        upper_id = upper_obj.item_id\n        upper_ids.add(upper_id)\n        upper_ids |= _get_id2upper(id2upper, upper_id, upper_obj)\n    id2upper[item_id] = upper_ids\n    return upper_ids", "response": "Add the parent item IDs for one item object and their upper."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the lower item IDs for one item object and the objects below them.", "response": "def _get_id2lower(id2lower, item_id, item_obj):\n    \"\"\"Add the lower item IDs for one item object and the objects below them.\"\"\"\n    if item_id in id2lower:\n        return id2lower[item_id]\n    lower_ids = set()\n    for lower_obj in item_obj.get_goterms_lower():\n        lower_id = lower_obj.item_id\n        lower_ids.add(lower_id)\n        lower_ids |= _get_id2lower(id2lower, lower_id, lower_obj)\n    id2lower[item_id] = lower_ids\n    return lower_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget id2obj containing id_srcs and parents.", "response": "def get_id2obj_cur_n_high(self, id2obj_user, id_sources):\n        \"\"\"Get id2obj containing: id_srcs and parents.\"\"\"\n        if not self.relationships:\n            self._get_id2obj_high(id2obj_user, id_sources, self.fill_parentidid2obj_r0)\n        else:\n            self._get_id2obj_high(id2obj_user, id_sources, self.fill_parentidid2obj_r1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_id2obj_high(self, id2obj_user, id_sources, fnc_fill):\n        for idid_user in id_sources:\n            idobj_user = self.id2obj_all[idid_user]\n            fnc_fill(id2obj_user, idobj_user)\n            id2obj_user[idobj_user.item_id] = idobj_user\n            if idid_user != idobj_user.item_id:\n                id2obj_user[idid_user] = idobj_user", "response": "Get id2obj containing id_srcs and parents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfilling id2obj with all parent key item IDs and their objects.", "response": "def fill_parentidid2obj_r0(self, id2obj, child_obj):\n        \"\"\"Fill id2obj with all parent key item IDs and their objects.\"\"\"\n        for parent_obj in child_obj.parents:\n            if parent_obj.item_id not in id2obj:\n                id2obj[parent_obj.item_id] = parent_obj\n                self.fill_parentidid2obj_r0(id2obj, parent_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fill_parentidid2obj_r1(self, id2obj_user, child_obj):\n        for higher_obj in self._getobjs_higher(child_obj):\n            if higher_obj.item_id not in id2obj_user:\n                id2obj_user[higher_obj.item_id] = higher_obj\n                self.fill_parentidid2obj_r1(id2obj_user, higher_obj)", "response": "Fill id2obj_user with all parent / relationship key item IDs and their objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getobjs_higher(self, idobj):\n        idobjs_higher = set(idobj.parents)\n        for reltyp, relidobjs in idobj.relationship.items():\n            if self.relationships is True or reltyp in self.relationships:\n                idobjs_higher.update(relidobjs)\n        return idobjs_higher", "response": "Get all parents and relationships on this GOTerm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prt_ver(self, prt):\n        if self.ver_list is not None:\n            prt.write(\"# Versions:\\n#    {VER}\\n\\n\".format(VER=\"\\n#    \".join(self.ver_list)))", "response": "Print version of GO - DAG for the GO and for GO slims."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a sections list containing sorted lists of namedtuples.", "response": "def get_sections_2dnt(self, sec2d_go):\n        \"\"\"Return a sections list containing sorted lists of namedtuples.\"\"\"\n        return [(nm, self.get_ntgos_sorted(gos)) for nm, gos in sec2d_go]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ntgos_sorted(self, hdrgos):\n        go2nt = self.grprobj.go2nt\n        return sorted([go2nt[go] for go in hdrgos if go in go2nt], key=self.fncsortnt)", "response": "Return sorted Grouper namedtuples if there are user GO IDs underneath."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prt_ntgos(self, prt, ntgos):\n        for ntgo in ntgos:\n            key2val = ntgo._asdict()\n            prt.write(\"{GO_LINE}\\n\".format(GO_LINE=self.prtfmt.format(**key2val)))", "response": "Print the Grouper namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns print format for Grouper which includes hdr1usr01 and num_usrgos.", "response": "def _init_prtfmt(self, key=\"fmta\"):\n        \"\"\"Return print format for Grouper, which includes hdr1usr01 and num_usrgos.\"\"\"\n        prtfmt = self.gosubdag.prt_attr[key]\n        return prtfmt.replace(\"{NS}\", \"{NS} {hdr1usr01:2} {num_usrgos:>4} uGOs\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_summary_data(self, sec2d_nt):\n        grouped = set()\n        ungrouped = set()\n        sections = set()\n        secdflt = self.grprobj.hdrobj.secdflt\n        for section_name, nts in sec2d_nt:\n            if section_name != secdflt:\n                if nts:\n                    grouped.update(set(nt.GO for nt in nts))\n                    sections.add(section_name)\n                else:\n                    ungrouped.update(set(nt.GO for nt in nts))\n        return {'grouped':grouped, 'ungrouped':ungrouped, 'sections':sections}", "response": "Get placed unplaced GO IDs and sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_summary_str(self, sec2d_nt):\n        data = self.get_summary_data(sec2d_nt)\n        return \"{M} GO IDs placed into {N} sections; {U} unplaced GO IDs\".format(\n            N=len(data['sections']), M=len(data['grouped']), U=len(data['ungrouped']))", "response": "Get string describing counts of placed and unplaced GO IDs and count of sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_fncsortnt(flds):\n        if 'tinfo' in flds:\n            if 'D1' in flds:\n                return lambda ntgo: [ntgo.NS, -1*ntgo.tinfo, ntgo.depth, ntgo.D1, ntgo.alt]\n            else:\n                return lambda ntgo: [ntgo.NS, -1*ntgo.tinfo, ntgo.depth, ntgo.alt]\n        if 'dcnt' in flds:\n            if 'D1' in flds:\n                return lambda ntgo: [ntgo.NS, -1*ntgo.dcnt, ntgo.depth, ntgo.D1, ntgo.alt]\n            else:\n                return lambda ntgo: [ntgo.NS, -1*ntgo.dcnt, ntgo.depth, ntgo.alt]\n        else:\n            return lambda ntgo: [ntgo.NS, -1*ntgo.depth, ntgo.alt]", "response": "Return a sort function for sorting header GO IDs found in sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wr_py_sections_new(self, fout_py, doc=None):\n        sections = self.grprobj.get_sections_2d()\n        return self.wr_py_sections(fout_py, sections, doc)", "response": "Write the first sections file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wr_py_sections(self, fout_py, sections, doc=None):\n        if sections is None:\n            sections = self.grprobj.get_sections_2d()\n        sec2d_nt = self.get_sections_2dnt(sections)  # lists of GO Grouper namedtuples\n        with open(fout_py, 'w') as prt:\n            self._prt_py_sections(sec2d_nt, prt, doc)\n            dat = SummarySec2dHdrGos().summarize_sec2hdrgos(sections)\n            sys.stdout.write(self.grprobj.fmtsum.format(\n                GO_DESC='hdr', SECs=len(dat['S']), GOs=len(dat['G']),\n                UNGRP=len(dat['U']), undesc=\"unused\",\n                ACTION=\"WROTE:\", FILE=fout_py))", "response": "Write sections 2 - D list into a Python format list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint sections 2 - D list into a Python format list.", "response": "def _prt_py_sections(self, sec2d_nt, prt=sys.stdout, doc=None):\n        \"\"\"Print sections 2-D list into a Python format list.\"\"\"\n        if doc is None:\n            doc = 'Sections variable'\n        prt.write('\"\"\"{DOC}\"\"\"\\n\\n'.format(DOC=doc))\n        self.prt_ver(prt)\n        prt.write(\"# pylint: disable=line-too-long\\n\")\n        strcnt = self.get_summary_str(sec2d_nt)\n        prt.write(\"SECTIONS = [ # {CNTS}\\n\".format(CNTS=strcnt))\n        prt.write('    # (\"New Section\", [\\n')\n        prt.write('    # ]),\\n')\n        for section_name, nthdrgos in sec2d_nt:\n            self._prt_py_section(prt, section_name, nthdrgos)\n        prt.write(\"]\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prt_py_section(self, prt, section_name, ntgos):\n        prt.write('    (\"{SEC}\", [ # {N} GO-headers\\n'.format(SEC=section_name, N=len(ntgos)))\n        self.prt_ntgos(prt, ntgos)\n        prt.write(\"    ]),\\n\")", "response": "Print one section and its GO headers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint GO namedtuples in their sections.", "response": "def prt_sections(prt, sections, prtfmt, secspc=False):\n        \"\"\"Print GO namedtuples in their sections.\"\"\"\n        num_goids = 0\n        for section, nts_flat in sections:\n            # Add an empty line between sections, if desired\n            if secspc:\n                prt.write(\"\\n\")\n            prt.write(\"{SECTION}\\n\".format(SECTION=section))\n            num_nts = len(nts_flat)\n            num_goids += num_nts\n            prt_txt(prt, nts_flat, prtfmt=prtfmt)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prt_info(self, prt, sections=None):\n        if sections is None:\n            sections = self.grprobj.get_sections_2d()\n        num_goids = 0\n        for section_name, nts_flat in sections:\n            num_nts = len(nts_flat)\n            num_goids += num_nts\n            prt.write(\"{N:3} GO IDs in section({SEC})\\n\".format(N=num_nts, SEC=section_name))\n        prt.write(\"{N:3} GO IDs\\n\".format(N=num_goids))", "response": "Print GO namedtuples in their sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_goid_cnt(self, prt=sys.stdout):\n        for section_name, hdrgos_sec in self.grprobj.get_sections_2d():\n            prt.write(\"{NAME} {Us:5,} {Hs:5,} {SEC}\\n\".format(\n                NAME=self.grprobj.grpname,\n                Us=len(self.grprobj.get_usrgos_g_hdrgos(hdrgos_sec)),\n                Hs=len(hdrgos_sec),\n                SEC=section_name))", "response": "Print number of hdrgos and usrgos in each section."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting one file per group of GO IDs.", "response": "def wr_txt_grouping_gos(self):\n        \"\"\"Write one file per GO group.\"\"\"\n        prt_goids = self.grprobj.gosubdag.prt_goids\n        for hdrgo, usrgos in self.grprobj.hdrgo2usrgos.items():\n            keygos = usrgos.union([hdrgo])\n            fout_txt = \"{BASE}.txt\".format(BASE=self.grprobj.get_fout_base(hdrgo))\n            with open(fout_txt, 'w') as prt:\n                prt_goids(keygos, prt=prt)\n                sys.stdout.write(\"  {N:5,} GO IDs WROTE: {TXT}\\n\".format(\n                    N=len(keygos), TXT=fout_txt))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wr_txt_section_hdrgos(self, fout_txt, sortby=None, prt_section=True):\n        sec2d_go = self.grprobj.get_sections_2d()    # lists of GO IDs\n        sec2d_nt = self.get_sections_2dnt(sec2d_go)  # lists of GO Grouper namedtuples\n        if sortby is None:\n            sortby = self.fncsortnt\n        with open(fout_txt, 'w') as prt:\n            self.prt_ver(prt)\n            prt.write(\"# GROUP NAME: {NAME}\\n\".format(NAME=self.grprobj.grpname))\n            for section_name, nthdrgos_actual in sec2d_nt:\n                if prt_section:\n                    prt.write(\"# SECTION: {SECTION}\\n\".format(SECTION=section_name))\n                self.prt_ntgos(prt, nthdrgos_actual)\n                if prt_section:\n                    prt.write(\"\\n\")\n            dat = SummarySec2dHdrGos().summarize_sec2hdrgos(sec2d_go)\n            sys.stdout.write(self.grprobj.fmtsum.format(\n                GO_DESC='hdr', SECs=len(dat['S']), GOs=len(dat['G']),\n                UNGRP=len(dat['U']), undesc=\"unused\",\n                ACTION=\"WROTE:\", FILE=fout_txt))\n        return sec2d_nt", "response": "Write high GO IDs that are actually used to group current set of GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites namedtuples into an Excel spreadsheet.", "response": "def wr_xlsx(self, fout_xlsx, nts):\n        \"\"\"Write specified namedtuples into an Excel spreadsheet.\"\"\"\n        wr_xlsx(fout_xlsx, nts, prt_flds=self.prt_flds, fld2col_widths=self.fld2col_widths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_mdtbl(self, nts, prt_flds=None, prt=sys.stdout):\n        if prt_flds is None:\n            prt_flds = self.prt_flds\n        prtfmt = \"|{DATA}|\\n\".format(DATA=\"|\".join(self.fld2prtfmt[f] for f in prt_flds))\n        prt_txt(prt, nts, prtfmt=prtfmt)", "response": "Write specified namedtuples into an Excel spreadsheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prt_num_sig(self, prt=sys.stdout, alpha=0.05):\n        ctr = self.get_num_sig(alpha)\n        prt.write(\"{N:6,} TOTAL: {TXT}\\n\".format(N=len(self.nts), TXT=\" \".join([\n            \"FDR({FDR:4})\".format(FDR=ctr['FDR']),\n            \"Bonferroni({B:4})\".format(B=ctr['Bonferroni']),\n            \"Benjamini({B:4})\".format(B=ctr['Benjamini']),\n            \"PValue({P:4})\".format(P=ctr['PValue']),\n            os.path.basename(self.fin_davidchart)])))", "response": "Print the number of significant GO terms."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_num_sig(self, alpha=0.05):\n        # Get the number of significant GO terms\n        ctr = cx.Counter()\n        flds = set(['FDR', 'Bonferroni', 'Benjamini', 'PValue'])\n        for ntd in self.nts:\n            for fld in flds:\n                if getattr(ntd, fld) < alpha:\n                    ctr[fld] += 1\n        return ctr", "response": "Print the number of significant results using various metrics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_nts(self, fin_davidchart):\n        nts = []\n        with open(fin_davidchart) as ifstrm:\n            hdr_seen = False\n            for line in ifstrm:\n                line = line.rstrip()\n                flds = line.split('\\t')\n                if hdr_seen:\n                    ntd = self._init_nt(flds)\n                    nts.append(ntd)\n                else:\n                    if line[:8] == 'Category':\n                        assert len(flds) == 13, len(flds)\n                        hdr_seen = True\n\n            sys.stdout.write(\"  READ {N:5} GO IDs from DAVID Chart: {TSV}\\n\".format(\n                N=len(nts), TSV=fin_davidchart))\n        return nts", "response": "Read DAVID Chart file. Store each line in a namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives string fields from a DAVID chart file return namedtuple.", "response": "def _init_nt(self, flds):\n        \"\"\"Given string fields from a DAVID chart file, return namedtuple.\"\"\"\n        term = flds[1]\n        genes_str = flds[5]\n        # pylint: disable=bad-whitespace\n        return self.ntobj(\n            Category   =       flds[0],\n            GO         =       term[:10], #  1  GO:0045202~synapse\n            name       =       term[10:], #  1  GO:0045202~synapse\n            Count      =   int(flds[2]),  #  2  94\n            Perc       = float(flds[3]),  #  3  9.456740442655935\n            PValue     = float(flds[4]),  #  4  6.102654380458156E-20\n            Genes      =      genes_str, # 5 ['ENSMUSG00000052613', ...]\n            Genes_set  = self.get_genes(genes_str), # 5 ['ENSMUSG00000052613', ...]\n            List_Total =   int(flds[6]),  #  6  920\n            Pop_Hits   =   int(flds[7]),  #  7  444\n            Pop_Total  =   int(flds[8]),  #  8  12002\n            Fold_Enrichment = float(flds[9]), # 9 2.7619173521347435\n            Bonferroni = float(flds[10]), # 10  3.3930758355347344E-17\n            Benjamini  = float(flds[11]), # 11  3.3930758355347344E-17\n            FDR        = float(flds[12]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_genes(genes_str):\n        gene_set = genes_str.split(', ')\n        if gene_set and gene_set[0].isdigit():\n            gene_set = set(int(g) for g in gene_set)\n        return gene_set", "response": "Given a string containng genes return a list of integers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning zero or greater Annotation Extensions given a line of text.", "response": "def get_extensions(extstr):\n    \"\"\"Return zero or greater Annotation Extensions, given a line of text.\"\"\"\n    # Extension examples:\n    #   has_direct_input(UniProtKB:P37840),occurs_in(GO:0005576)\n    #   part_of(UBERON:0006618),part_of(UBERON:0002302)\n    #   occurs_in(CL:0000988)|occurs_in(CL:0001021)\n    if not extstr:\n        return None\n    exts = []\n    for ext_lst in extstr.split('|'):\n        grp = []\n        for ext in ext_lst.split(','):\n            idx = ext.find('(')\n            if idx != -1 and ext[-1] == ')':\n                grp.append(AnnotationExtension(ext[:idx], ext[idx+1:-1]))\n            else:\n                # Ignore improperly formatted Extensions\n                sys.stdout.write('BAD Extension({E})\\n'.format(E=ext))\n        exts.append(grp)\n    return AnnotationExtensions(exts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparing down docopt. Return a minimal dictionary and a set containing runtime arg values.", "response": "def get_docargs(self, args=None, prt=None, **kws):\n        \"\"\"Pare down docopt. Return a minimal dictionary and a set containing runtime arg values.\"\"\"\n        args_user = sys.argv[1:] if args is None else args\n        arg_kws = self._get_docargs(args_user, prt)\n        if 'intvals' in kws:\n            self._set_intvals(arg_kws, kws['intvals'])\n        return arg_kws"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npare down docopt. Return a minimal dictionary and a set containing runtime arg values.", "response": "def _get_docargs(self, args_user, prt):\n        \"\"\"Pare down docopt. Return a minimal dictionary and a set containing runtime arg values.\"\"\"\n        if prt is not None:\n            print(\"DocOptParse BEFORE docopt: {}\".format(args_user))\n        docargs = docopt(self.doc, args_user)\n        if prt is not None:\n            print(\"DocOptParse AFTER  docopt: {}\".format(docargs))\n        kwargs_doc = {re.sub(r'^-{1,2}', '', k):v for k, v in docargs.items()}\n        self._chk_docopt_kws(kwargs_doc, args_user)\n        kwargs_usr = get_kwargs(kwargs_doc, self.exp_keys, self.exp_elems)\n        if prt is not None:\n            print(\"DocOptParse AFTER  pared: {}\".format(kwargs_usr))\n        for key in ['taxid']:\n            if key in kwargs_usr:\n                kwargs_usr[key] = int(kwargs_usr[key])\n        if prt is not None:\n            print(\"DocOptParse AFTER  edited/checked: {}\".format(kwargs_usr))\n        return kwargs_usr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_intvals(kws, keys):\n        for key in keys:\n            if key in kws:\n                kws[key] = int(kws[key])", "response": "Convert keyword values to int."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if docopt exit was for an unknown argument.", "response": "def _chk_docopt_exit(self, args, exp_letters):\n        \"\"\"Check if docopt exit was for an unknown argument.\"\"\"\n        if args is None:\n            args = sys.argv[1:]\n        keys_all = self.exp_keys.union(self.exp_elems)\n        if exp_letters:\n            keys_all |= exp_letters\n        unknown_args = self._chk_docunknown(args, keys_all)\n        if unknown_args:\n            raise RuntimeError(\"{USAGE}\\n    **FATAL: UNKNOWN ARGS: {UNK}\".format(\n                USAGE=self.doc, UNK=\" \".join(unknown_args)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _chk_docopt_kws(self, docdict, exp):\n        for key, val in docdict.items():\n            if isinstance(val, str):\n                assert '=' not in val, self._err(\"'=' FOUND IN VALUE\", key, val, exp)\n            elif key != 'help' and key not in self.exp_keys and key not in self.exp_elems:\n                raise RuntimeError(self._err(\"UNKNOWN KEY\", key, val, exp))", "response": "Check for common user errors when running from the command - line."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns any unknown args.", "response": "def _chk_docunknown(args, exp):\n        \"\"\"Return any unknown args.\"\"\"\n        unknown = []\n        for arg in args:\n            if arg[:2] == '--':\n                val = arg[2:]\n                if val not in exp:\n                    unknown.append(arg)\n            elif arg[:1] == '-':\n                val = arg[1:]\n                if val not in exp:\n                    unknown.append(arg)\n        if '-h' in unknown or '--help' in unknown:\n            return []\n        return unknown"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dnld_goa(self, species, ext='gaf', item=None, fileout=None):\n        basename = self.get_basename(species, ext, item)\n        src = os.path.join(self.ftp_src_goa, species.upper(), \"{F}.gz\".format(F=basename))\n        dst = os.path.join(os.getcwd(), basename) if fileout is None else fileout\n        dnld_file(src, dst, prt=sys.stdout, loading_bar=None)\n        return dst", "response": "Download GOA source file name on EMBL - EEBI ftp server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_basename(self, species, ext='gaf', item=None):\n        assert ext in self.exts, \" \".join(self.exts)\n        if species == 'uniprot':\n            species = 'uniprot_all' if item != 'gcrp' else 'uniprot_gcrp'\n        if item is None:\n            return 'goa_{SPECIES}.{EXT}'.format(SPECIES=species, EXT=ext)\n        assert item in self.species_items\n        return 'goa_{SPECIES}_{ITEM}.{EXT}'.format(SPECIES=species, ITEM=item, EXT=ext)", "response": "Get a GOA basename for a specific species. Ex : goa_human. gaf"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dnld_assc(assc_name, go2obj=None, prt=sys.stdout):\n    # Example assc_name: \"tair.gaf\"\n    # Download the Association\n    dirloc, assc_base = os.path.split(assc_name)\n    if not dirloc:\n        dirloc = os.getcwd()\n    assc_locfile = os.path.join(dirloc, assc_base) if not dirloc else assc_name\n    dnld_annotation(assc_locfile, prt)\n    # Read the downloaded association\n    assc_orig = read_gaf(assc_locfile, prt)\n    if go2obj is None:\n        return assc_orig\n    # If a GO DAG is provided, use only GO IDs present in the GO DAG\n    assc = {}\n    goids_dag = set(go2obj.keys())\n    for gene, goids_cur in assc_orig.items():\n        assc[gene] = goids_cur.intersection(goids_dag)\n    return assc", "response": "Download association from http://geneontology. org / gene - associations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading gaf gpad or gpi from http://current. geneontology. org annotations folder", "response": "def dnld_annotation(assc_file, prt=sys.stdout):\n    \"\"\"Download gaf, gpad, or gpi from http://current.geneontology.org/annotations/\"\"\"\n    if not os.path.isfile(assc_file):\n        # assc_http = \"http://geneontology.org/gene-associations/\"\n        assc_http = \"http://current.geneontology.org/annotations/\"\n        _, assc_base = os.path.split(assc_file)\n        src = os.path.join(assc_http, \"{ASSC}.gz\".format(ASSC=assc_base))\n        dnld_file(src, assc_file, prt, loading_bar=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_associations(assoc_fn, anno_type='id2gos', **kws):\n    # kws get_objanno: taxids hdr_only prt allow_missing_symbol\n    obj = get_objanno(assoc_fn, anno_type, **kws)\n    # kws get_id2gos: ev_include ev_exclude keep_ND keep_NOT b_geneid2gos go2geneids\n    return obj.get_id2gos(**kws)", "response": "Return associatinos in id2gos format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_assoc_ncbi_taxids(taxids, force_dnld=False, loading_bar=True, **kws):\n    fin = kws['gene2go'] if 'gene2go' in kws else os.path.join(os.getcwd(), \"gene2go\")\n    dnld_ncbi_gene_file(fin, force_dnld, loading_bar=loading_bar)\n    return read_ncbi_gene2go(fin, taxids, **kws)", "response": "Download NCBI s gene2go. Return annotations for user - specified taxid ( s )."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a file from NCBI Gene s ftp server.", "response": "def dnld_ncbi_gene_file(fin, force_dnld=False, log=sys.stdout, loading_bar=True):\n    \"\"\"Download a file from NCBI Gene's ftp server.\"\"\"\n    if not os.path.exists(fin) or force_dnld:\n        import gzip\n        fin_dir, fin_base = os.path.split(fin)\n        fin_gz = \"{F}.gz\".format(F=fin_base)\n        fin_gz = os.path.join(fin_dir, fin_gz)\n        if os.path.exists(fin_gz):\n            os.remove(fin_gz)\n        fin_ftp = \"ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/{F}.gz\".format(F=fin_base)\n        ## if log is not None:\n        ##     log.write(\"  DOWNLOADING GZIP: {GZ}\\n\".format(GZ=fin_ftp))\n        ## if loading_bar:\n        ##     loading_bar = wget.bar_adaptive\n        ## wget.download(fin_ftp, bar=loading_bar)\n        ## rsp = wget(fin_ftp)\n        ftp_get(fin_ftp, fin_gz)\n        with gzip.open(fin_gz, 'rb') as zstrm:\n            if log is not None:\n                log.write(\"\\n  READ GZIP:  {F}\\n\".format(F=fin_gz))\n            with open(fin, 'wb') as ostrm:\n                ostrm.write(zstrm.read())\n                if log is not None:\n                    log.write(\"  WROTE UNZIPPED: {F}\\n\".format(F=fin))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads annotation file if needed", "response": "def dnld_annofile(fin_anno, anno_type):\n    \"\"\"Download annotation file, if needed\"\"\"\n    if os.path.exists(fin_anno):\n        return\n    anno_type = get_anno_desc(fin_anno, anno_type)\n    if anno_type == 'gene2go':\n        dnld_ncbi_gene_file(fin_anno)\n    if anno_type in {'gaf', 'gpad'}:\n        dnld_annotation(fin_anno)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread NCBI s gene2go. Return gene2go data for user - specified taxids.", "response": "def read_ncbi_gene2go(fin_gene2go, taxids=None, **kws):\n    \"\"\"Read NCBI's gene2go. Return gene2go data for user-specified taxids.\"\"\"\n    obj = Gene2GoReader(fin_gene2go, taxids=taxids)\n    # By default, return id2gos. User can cause go2geneids to be returned by:\n    #   >>> read_ncbi_gene2go(..., go2geneids=True\n    if 'taxid2asscs' not in kws:\n        if len(obj.taxid2asscs) == 1:\n            taxid = next(iter(obj.taxid2asscs))\n            kws_ncbi = {k:v for k, v in kws.items() if k in AnnoOptions.keys_exp}\n            kws_ncbi['taxid'] = taxid\n            return obj.get_id2gos(**kws_ncbi)\n    # Optional detailed associations split by taxid and having both ID2GOs & GO2IDs\n    # e.g., taxid2asscs = defaultdict(lambda: defaultdict(lambda: defaultdict(set))\n    t2asscs_ret = obj.get_taxid2asscs(taxids, **kws)\n    t2asscs_usr = kws.get('taxid2asscs', defaultdict(lambda: defaultdict(lambda: defaultdict(set))))\n    if 'taxid2asscs' in kws:\n        obj.fill_taxid2asscs(t2asscs_usr, t2asscs_ret)\n    return obj.get_id2gos_all(t2asscs_ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads GAF file. Return data.", "response": "def read_gaf(fin_gaf, prt=sys.stdout, hdr_only=False, allow_missing_symbol=False, **kws):\n    \"\"\"Read Gene Association File (GAF). Return data.\"\"\"\n    return GafReader(fin_gaf, hdr_only,\n                     prt=prt, allow_missing_symbol=allow_missing_symbol).get_id2gos(**kws)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_assc_pruned(assc_geneid2gos, min_genecnt=None, max_genecnt=None, prt=sys.stdout):\n    # DEFN WAS: get_assc_pruned(assc_geneid2gos, max_genecnt=None, prt=sys.stdout):\n    #      ADDED min_genecnt argument and functionality\n    if max_genecnt is None and min_genecnt is None:\n        return assc_geneid2gos, set()\n    go2genes_orig = get_b2aset(assc_geneid2gos)\n    # go2genes_prun = {go:gs for go, gs in go2genes_orig.items() if len(gs) <= max_genecnt}\n    go2genes_prun = {}\n    for goid, genes in go2genes_orig.items():\n        num_genes = len(genes)\n        if (min_genecnt is None or num_genes >= min_genecnt) and \\\n           (max_genecnt is None or num_genes <= max_genecnt):\n            go2genes_prun[goid] = genes\n    num_was = len(go2genes_orig)\n    num_now = len(go2genes_prun)\n    gos_rm = set(go2genes_orig.keys()).difference(set(go2genes_prun.keys()))\n    assert num_was-num_now == len(gos_rm)\n    if prt is not None:\n        if min_genecnt is None:\n            min_genecnt = 1\n        if max_genecnt is None:\n            max_genecnt = \"Max\"\n        prt.write(\"{N:4} GO IDs pruned. Kept {NOW} GOs assc w/({m} to {M} genes)\\n\".format(\n            m=min_genecnt, M=max_genecnt, N=num_was-num_now, NOW=num_now))\n    return get_b2aset(go2genes_prun), gos_rm", "response": "Remove GO IDs associated with large numbers of genes. Used in stochastic simulations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads annotations from either a GAF file or NCBI s gene2go file.", "response": "def read_annotations(**kws):\n    \"\"\"Read annotations from either a GAF file or NCBI's gene2go file.\"\"\"\n    if 'gaf' not in kws and 'gene2go' not in kws:\n        return\n    gene2gos = None\n    if 'gaf' in kws:\n        gene2gos = read_gaf(kws['gaf'], prt=sys.stdout)\n        if not gene2gos:\n            raise RuntimeError(\"NO ASSOCIATIONS LOADED FROM {F}\".format(F=kws['gaf']))\n    elif 'gene2go' in kws:\n        assert 'taxid' in kws, 'taxid IS REQUIRED WHEN READING gene2go'\n        gene2gos = read_ncbi_gene2go(kws['gene2go'], taxids=[kws['taxid']])\n        if not gene2gos:\n            raise RuntimeError(\"NO ASSOCIATIONS LOADED FROM {F} FOR TAXID({T})\".format(\n                F=kws['gene2go'], T=kws['taxid']))\n    return gene2gos"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a TermCounts object if the user provides an annotation file otherwise None.", "response": "def get_tcntobj(go2obj, **kws):\n    \"\"\"Return a TermCounts object if the user provides an annotation file, otherwise None.\"\"\"\n    # kws: gaf gene2go\n    annots = read_annotations(**kws)\n    if annots:\n        return TermCounts(go2obj, annots)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hdrs(flds_all, **kws):\n    # Return Headers if the user explicitly lists them.\n    hdrs = kws.get('hdrs', None)\n    if hdrs is not None:\n        return hdrs\n    # User may specify a subset of fields or a column order using prt_flds\n    if 'prt_flds' in kws:\n        return kws['prt_flds']\n    # All fields in the namedtuple will be in the headers\n    return flds_all", "response": "Return headers given user - specified key - word args."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges all columns and place text string in widened cell.", "response": "def wr_row_mergeall(self, worksheet, txtstr, fmt, row_idx):\n        \"\"\"Merge all columns and place text string in widened cell.\"\"\"\n        hdridxval = len(self.hdrs) - 1\n        worksheet.merge_range(row_idx, 0, row_idx, hdridxval, txtstr, fmt)\n        return row_idx + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint row of column headers", "response": "def wr_hdrs(self, worksheet, row_idx):\n        \"\"\"Print row of column headers\"\"\"\n        for col_idx, hdr in enumerate(self.hdrs):\n            # print(\"ROW({R}) COL({C}) HDR({H}) FMT({F})\\n\".format(\n            #     R=row_idx, C=col_idx, H=hdr, F=self.fmt_hdr))\n            worksheet.write(row_idx, col_idx, hdr, self.fmt_hdr)\n        row_idx += 1\n        return row_idx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting data into xlsx file.", "response": "def wr_data(self, xlsx_data, row_i, worksheet):\n        \"\"\"Write data into xlsx worksheet.\"\"\"\n        fld2fmt = self.vars.fld2fmt\n        # User may specify to skip rows based on values in row\n        prt_if = self.vars.prt_if\n        # User may specify a subset of columns to print or\n        # a column ordering different from the _fields seen in the namedtuple\n        prt_flds = self.wbfmtobj.get_prt_flds()\n        get_wbfmt = self.wbfmtobj.get_wbfmt\n        if self.vars.sort_by is not None:\n            xlsx_data = sorted(xlsx_data, key=self.vars.sort_by)\n        try:\n            for data_nt in xlsx_data:\n                if prt_if is None or prt_if(data_nt):\n                    wbfmt = get_wbfmt(data_nt)  # xlsxwriter.format.Format created w/add_format\n                    # Print an xlsx row by printing each column in order.\n                    for col_i, fld in enumerate(prt_flds):\n                        try:\n                            # If fld \"format_txt\" present, use val for formatting, but don't print.\n                            val = getattr(data_nt, fld, \"\")\n                            # Optional user-formatting of specific fields, eg, pval: \"{:8.2e}\"\n                            # If field value is empty (\"\"), don't use fld2fmt\n                            if fld2fmt is not None and fld in fld2fmt and val != \"\" and val != \"*\":\n                                val = fld2fmt[fld].format(val)\n                            worksheet.write(row_i, col_i, val, wbfmt)\n                        except:\n                            raise RuntimeError(self._get_err_msg(row_i, col_i, fld, val, prt_flds))\n                    row_i += 1\n        except RuntimeError as inst:\n            import traceback\n            traceback.print_exc()\n            sys.stderr.write(\"\\n  **FATAL in wr_data: {MSG}\\n\\n\".format(MSG=str(inst)))\n            sys.exit(1)\n        return row_i"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an informative message with details of xlsx write attempt.", "response": "def _get_err_msg(row, col, fld, val, prt_flds):\n        \"\"\"Return an informative message with details of xlsx write attempt.\"\"\"\n        import traceback\n        traceback.print_exc()\n        err_msg = (\n            \"ROW({R}) COL({C}) FIELD({F}) VAL({V})\\n\".format(R=row, C=col, F=fld, V=val),\n            \"PRINT FIELDS({N}): {F}\".format(N=len(prt_flds), F=\" \".join(prt_flds)))\n        return \"\\n\".join(err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new worksheet to the workbook.", "response": "def add_worksheet(self):\n        \"\"\"Add a worksheet to the workbook.\"\"\"\n        wsh = self.workbook.add_worksheet()\n        if self.vars.fld2col_widths is not None:\n            self.set_xlsx_colwidths(wsh, self.vars.fld2col_widths, self.wbfmtobj.get_prt_flds())\n        return wsh"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting xlsx column widths using fld2col_widths.", "response": "def set_xlsx_colwidths(worksheet, fld2col_widths, fldnames):\n        \"\"\"Set xlsx column widths using fld2col_widths.\"\"\"\n        for col_idx, fld in enumerate(fldnames):\n            col_width = fld2col_widths.get(fld, None)\n            if col_width is not None:\n                worksheet.set_column(col_idx, col_idx, col_width)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_wbfmt(self, data_nt=None):\n        if data_nt is None or self.b_plain:\n            return self.fmtname2wbfmtobj.get('plain')\n        # User namedtuple field/value for color\n        if self.ntfld_wbfmt is not None:\n            return self.__get_wbfmt_usrfld(data_nt)\n        # namedtuple format_txt for color/bold/border\n        if self.b_format_txt:\n            wbfmt = self.__get_wbfmt_format_txt(data_nt)\n            if wbfmt is not None:\n                return wbfmt\n        # 'ntfld_wbfmt': namedtuple field which contains a value used as a key for a xlsx format\n        # 'ntval2wbfmtdict': namedtuple value and corresponding xlsx format dict.\n        return self.fmtname2wbfmtobj.get('plain')", "response": "Return format for text cell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_wbfmt_usrfld(self, data_nt):\n        if self.ntfld_wbfmt is not None:\n            if isinstance(self.ntfld_wbfmt, str):\n                ntval = getattr(data_nt, self.ntfld_wbfmt, None) # Ex: 'section'\n                if ntval is not None:\n                    return self.fmtname2wbfmtobj.get(ntval, None)", "response": "Return format for text cell from namedtuple field specified by ntfld_wbfmt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning format for text cell from namedtuple field format_txt", "response": "def __get_wbfmt_format_txt(self, data_nt):\n        \"\"\"Return format for text cell from namedtuple field, 'format_txt'.\"\"\"\n        format_txt_val = getattr(data_nt, \"format_txt\")\n        if format_txt_val == 1:\n            return self.fmtname2wbfmtobj.get(\"very light grey\")\n        if format_txt_val == 2:\n            return self.fmtname2wbfmtobj.get(\"light grey\")\n        return self.fmtname2wbfmtobj.get(format_txt_val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngreys if printing header GOs and plain if not printing header GOs and plain if printing header GOs and plain if not printing header GOs and light grey if printing header GOs and light grey if printing header GOs and plain if printing header GOs and not printing header GOs.", "response": "def get_fmt_section(self):\n        \"\"\"Grey if printing header GOs and plain if not printing header GOs.\"\"\"\n        if self.b_format_txt:\n            return self.fmtname2wbfmtobj.get(\"light grey\")\n        return self.fmtname2wbfmtobj.get(\"plain bold\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn geneid2gos or optionally go2geneids.", "response": "def get_id2gos(self, **kws):\n    #### def get_annotations_dct(self, taxid, options):\n        \"\"\"Return geneid2gos, or optionally go2geneids.\"\"\"\n        if len(self.taxid2asscs) == 1:\n            taxid = next(iter(self.taxid2asscs.keys()))\n            return self._get_id2gos(self.taxid2asscs[taxid], **kws)\n        assert 'taxid' in kws, \"**FATAL: 'taxid' NOT FOUND IN Gene2GoReader::get_id2gos({KW})\".format(KW=kws)\n        taxid = kws['taxid']\n        assert taxid in self.taxid2asscs, '**FATAL: TAXID({T}) DATA MISSING'.format(T=taxid)\n        return self._get_id2gos(self.taxid2asscs[taxid], **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_name(self):\n        if len(self.taxid2asscs) == 1:\n            return '{BASE}_{TAXID}'.format(\n                BASE=self.name, TAXID=next(iter(self.taxid2asscs.keys())))\n        return '{BASE}_various'.format(BASE=self.name)", "response": "Get name using taxid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_taxid(self):\n        return next(iter(self.taxid2asscs.keys())) if len(self.taxid2asscs) == 1 else True", "response": "Return taxid if one was provided. Other wise return all taxids"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread Gene Association File. Return data.", "response": "def get_taxid2asscs(self, taxids=None, **kws):\n        \"\"\"Read Gene Association File (GAF). Return data.\"\"\"\n        # WAS: get_annotations_taxid2dct\n        taxid2asscs = cx.defaultdict(lambda: cx.defaultdict(lambda: cx.defaultdict(set)))\n        options = AnnoOptions(self.evobj, **kws)\n        for taxid in self._get_taxids(taxids):\n            nts = self.taxid2asscs[taxid]\n            assc = self.reduce_annotations(nts, options)\n            taxid2asscs[taxid]['ID2GOs'] = self._get_dbid2goids(assc)\n            taxid2asscs[taxid]['GO2IDs'] = self._get_goid2dbids(assc)\n        return taxid2asscs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fill_taxid2asscs(taxid2asscs_usr, taxid2asscs_ret):\n        for taxid, ab_ret in taxid2asscs_ret.items():\n            taxid2asscs_usr[taxid]['ID2GOs'] = ab_ret['ID2GOs']\n            taxid2asscs_usr[taxid]['GO2IDs'] = ab_ret['GO2IDs']", "response": "Fill user taxid2asscs for backward compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_id2gos_all(taxid2asscs_a2b):\n        id2gos_all = {}\n        for a2b in taxid2asscs_a2b.values():\n            for geneid, gos in a2b['ID2GOs'].items():\n                id2gos_all[geneid] = gos\n        return id2gos_all", "response": "Get associations for all stored species taxid2asscs_a2b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_taxids(self, taxids=None):\n        taxid_keys = set(self.taxid2asscs.keys())\n        return taxid_keys if taxids is None else set(taxids).intersection(taxid_keys)", "response": "Return user - specified taxids or taxids in self. taxid2asscs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_associations(fin_anno, taxid=None, taxids=None):\n        return InitAssc(taxid, taxids).init_associations(fin_anno, taxids)", "response": "Read annotation file and store a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _init_taxid2asscs(self):\n        taxid2asscs = cx.defaultdict(list)\n        for ntanno in self.associations:\n            taxid2asscs[ntanno.tax_id].append(ntanno)\n        assert len(taxid2asscs) != 0, \"**FATAL: NO TAXIDS: {F}\".format(F=self.filename)\n        # \"\"\"Print the number of taxids stored.\"\"\"\n        prt = sys.stdout\n        num_taxids = len(taxid2asscs)\n        prt.write('{N} taxids stored'.format(N=num_taxids))\n        if num_taxids < 5:\n            prt.write(': {Ts}'.format(Ts=' '.join(sorted(str(t) for t in taxid2asscs))))\n        prt.write('\\n')\n        return dict(taxid2asscs)", "response": "Create dict with taxid keys and annotation namedtuple list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a copy of go2color with GO group header colored.", "response": "def get_go2color_inst(self, hdrgo):\n        \"\"\"Get a copy of go2color with GO group header colored.\"\"\"\n        go2color = self.go2color.copy()\n        go2color[hdrgo] = self.hdrgo_dflt_color\n        return go2color"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets keyword args for GoSubDagPlot from self unless they are None.", "response": "def get_kws_plt(self):\n        \"\"\"Get keyword args for GoSubDagPlot from self unless they are None.\"\"\"\n        kws_plt = {}\n        for key_plt in self.keys_plt:\n            key_val = getattr(self, key_plt, None)\n            if key_val is not None:\n                kws_plt[key_plt] = key_val\n            elif key_plt in self.kws:\n                kws_plt[key_plt] = self.kws[key_plt]\n        return kws_plt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize go2bordercolor with default to make hdrgos bright blue.", "response": "def _init_go2bordercolor(objcolors, **kws):\n        \"\"\"Initialize go2bordercolor with default to make hdrgos bright blue.\"\"\"\n        go2bordercolor_ret = objcolors.get_bordercolor()\n        if 'go2bordercolor' not in kws:\n            return go2bordercolor_ret\n        go2bordercolor_usr = kws['go2bordercolor']\n        goids = set(go2bordercolor_ret).intersection(go2bordercolor_usr)\n        for goid in goids:\n            go2bordercolor_usr[goid] = go2bordercolor_ret[goid]\n        return go2bordercolor_usr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_sections(self, fout_dir=\".\", **kws_pltargs):\n        hdrgos = self.grprobj.hdrobj.get_section_hdrgos()\n        pltargs = PltGroupedGosArgs(self.grprobj, fout_dir=fout_dir, **kws_pltargs)\n        return self._plot_groups_hdrgos(hdrgos, pltargs)", "response": "Plot GO DAGs for all sections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting GO DAGs for all groups of user GOs.", "response": "def plot_groups_all(self, fout_dir=\".\", **kws_pltargs): # GrouperUserGos\n        \"\"\"Plot GO DAGs for all groups of user GOs.\"\"\"\n        hdrgos = self.grprobj.get_hdrgos()\n        pltargs = PltGroupedGosArgs(self.grprobj, fout_dir=fout_dir, **kws_pltargs)\n        return self._plot_groups_hdrgos(hdrgos, pltargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_groups_unplaced(self, fout_dir=\".\", **kws_pltargs):\n        hdrgos = self.grprobj.get_hdrgos_unplaced()\n        pltargs = PltGroupedGosArgs(self.grprobj, fout_dir=fout_dir, **kws_pltargs)\n        return self._plot_groups_hdrgos(hdrgos, pltargs)", "response": "Plot GO DAGs for groups of user GOs which are not in a section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pltdotstrs(self, **kws): # GrouperUserGos\n        hdrgos = self.grprobj.get_hdrgos()\n        return self._get_pltdotstrs(hdrgos, **kws)", "response": "Plot GO DAGs for all groups of user GOs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_plt_data(self, hdrgos_usr):\n        hdrgo2usrgos = self.grprobj.get_hdrgo2usrgos(hdrgos_usr)\n        usrgos_actual = set([u for us in hdrgo2usrgos.values() for u in us])\n        go2obj = self.gosubdag.get_go2obj(usrgos_actual.union(hdrgo2usrgos.keys()))\n        return hdrgo2usrgos, go2obj", "response": "Given User GO IDs return their GO headers and other GO info."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the list of GO DAGs for each group found under a specfied header GO.", "response": "def _get_pltdotstrs(self, hdrgos_usr, **kws):\n        \"\"\"Plot GO DAGs for each group found under a specfied header GO.\"\"\"\n        import datetime\n        import timeit\n        dotstrs_all = []\n        tic = timeit.default_timer()\n        # Loop through GO groups. Each group of GOs is formed under a single \"header GO\"\n        hdrgo2usrgos, go2obj = self._get_plt_data(hdrgos_usr)\n        # get dot strings with _get_dotstrs_curs\n        for hdrgo, usrgos in hdrgo2usrgos.items():\n            dotstrs_cur = self._get_dotgraphs(\n                hdrgo, usrgos,\n                pltargs=PltGroupedGosArgs(self.grprobj, **kws),\n                go2parentids=get_go2parents_go2obj(go2obj))\n            dotstrs_all.extend(dotstrs_cur)\n        sys.stdout.write(\"\\nElapsed HMS: {HMS} to write \".format(\n            HMS=str(datetime.timedelta(seconds=(timeit.default_timer()-tic)))))\n        sys.stdout.write(\"{P:5,} GO DAG plots for {H:>5,} GO grouping headers\\n\".format(\n            H=len(hdrgo2usrgos), P=len(dotstrs_all)))\n        return sorted(set(dotstrs_all))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _plot_groups_hdrgos(self, hdrgos_usr, pltargs):\n        import datetime\n        import timeit\n        pngs = []\n        tic = timeit.default_timer()\n        # Loop through GO groups. Each group of GOs is formed under a single \"header GO\"\n        hdrgo2usrgos, go2obj = self._get_plt_data(hdrgos_usr)\n        for hdrgo, usrgos in hdrgo2usrgos.items():\n            pngs.extend(self._plot_go_group(\n                hdrgo, usrgos,\n                pltargs=pltargs,\n                go2parentids=get_go2parents_go2obj(go2obj)))\n        sys.stdout.write(\"\\nElapsed HMS: {HMS} to write \".format(\n            HMS=str(datetime.timedelta(seconds=(timeit.default_timer()-tic)))))\n        sys.stdout.write(\"{P:5,} GO DAG plots for {H:>5,} GO grouping headers\\n\".format(\n            H=len(hdrgo2usrgos), P=len(pngs)))\n        return sorted(set(pngs))", "response": "Plot GO DAGs for each group found under a specfied header GO."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _plot_go_group(self, hdrgo, usrgos, pltargs, go2parentids):\n        gosubdagplotnts = self._get_gosubdagplotnts(hdrgo, usrgos, pltargs, go2parentids)\n        # Create pngs and return png names\n        pngs = [obj.wrplt(pltargs.fout_dir, pltargs.plt_ext) for obj in gosubdagplotnts]\n        return pngs", "response": "Plot an exploratory GO DAG for a single Group of user GOs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_dotgraphs(self, hdrgo, usrgos, pltargs, go2parentids):\n        gosubdagplotnts = self._get_gosubdagplotnts(hdrgo, usrgos, pltargs, go2parentids)\n        # Create DAG graphs as dot language strings. Loop through GoSubDagPlotNt list\n        dotstrs = [obj.get_dotstr() for obj in gosubdagplotnts]\n        return dotstrs", "response": "Get a GO DAG in a dot - language string for a single Group of user GOs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting list of GoSubDagPlotNt for plotting an exploratory GODAG for 1 Group of user GOs.", "response": "def _get_gosubdagplotnts(self, hdrgo, usrgos, pltargs, go2parentids):\n        \"\"\"Get list of GoSubDagPlotNt for plotting an exploratory GODAG for 1 Group of user GOs.\"\"\"\n        dotgraphs = []\n        go2color = pltargs.get_go2color_inst(hdrgo)\n        # namedtuple fields: hdrgo gosubdag tot_usrgos parentcnt desc\n        ntpltgo0 = self._get_pltdag_ancesters(hdrgo, usrgos, desc=\"\")\n        ntpltgo1 = self._get_pltdag_path_hdr(hdrgo, usrgos, desc=\"pruned\")\n        num_go0 = len(ntpltgo0.gosubdag.go2obj)\n        num_go1 = len(ntpltgo1.gosubdag.go2obj)\n        title = \"{GO} {NAME}; {N} GO sources\".format(\n            GO=hdrgo,\n            NAME=self.gosubdag.go2obj[hdrgo].name,\n            N=len(ntpltgo0.gosubdag.go_sources))\n        # print(\"PltGroupedGos::_get_gosubdagplotnts TITLE\", title)\n        if num_go0 < pltargs.max_gos:\n            # print(\"PltGroupedGos::_get_gosubdagplotnts ntpltgo0 ALWAYS IF NOT TOO BIG\")\n            dotgraphs.append(self._get_gosubdagplotnt(ntpltgo0, title, go2color, pltargs))\n        # PLOT A: Plot the entire GO ID group under GO header, hdrgo, if not too big\n        if num_go0 < pltargs.max_gos and \\\n            ntpltgo0.tot_usrgos == ntpltgo1.tot_usrgos:\n            # print(\"PltGroupedGos::_get_gosubdagplotnts ntpltgo0 AAAAAAAAAAAAAAAAA\")\n            dotgraphs.append(self._get_gosubdagplotnt(ntpltgo0, title, go2color, pltargs))\n        # PLOT B: Plot only the GO ID group passing thru the GO header, hdrgo, if not too big\n        elif num_go1 < pltargs.max_gos and ntpltgo0.tot_usrgos != ntpltgo1.tot_usrgos:\n            # print(\"PltGroupedGos::_get_gosubdagplotnts ntpltgo1(pruned) BBBBBBBBBBBBBBBBB\")\n            dotgraphs.append(self._get_gosubdagplotnt(ntpltgo1, title, go2color, pltargs))\n        # PLOT C: If DAG is large, just print upper portion\n        # PLOT D: If DAG is large, just print upper portion passing through the GO header\n        elif num_go1 >= pltargs.upper_trigger:\n            # print(\"PltGroupedGos::_get_gosubdagplotnts upper_pruned CCCCCCCCCCCCCCCCC\")\n            gos_upper = self._get_gos_upper(ntpltgo1, pltargs.max_upper, go2parentids)\n            #ntpltgo2 = self._get_pltdag_ancesters(hdrgo, gos_upper, \"{BASE}_upper.png\")\n            ntpltgo3 = self._get_pltdag_path_hdr(hdrgo, gos_upper, \"upper_pruned\")\n            # Middle GO terms chosen to be start points will be green unless reset back\n            for goid in gos_upper:\n                if goid not in go2color:\n                    go2color[goid] = 'white'\n            dotgraphs.append(self._get_gosubdagplotnt(ntpltgo3, title, go2color, pltargs))\n        else:\n            # print(\"PltGroupedGos::_get_gosubdagplotnts EEEEEEEEEEEEEEEEE\")\n            self._no_ntplt(ntpltgo0)\n        return dotgraphs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_gos_upper(self, ntpltgo1, max_upper, go2parentids):\n        # Get GO IDs which are in the hdrgo path\n        goids_possible = ntpltgo1.gosubdag.go2obj.keys()\n        # Get upper GO IDs which have the most descendants\n        return self._get_gosrcs_upper(goids_possible, max_upper, go2parentids)", "response": "Plot a GO DAG for the upper portion of a single Group of user GOs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_gosrcs_upper(self, goids, max_upper, go2parentids):\n        gosrcs_upper = set()\n        get_nt = self.gosubdag.go2nt.get\n        go2nt = {g:get_nt(g) for g in goids}\n        # Sort by descending order of descendant counts to find potential new hdrgos\n        go_nt = sorted(go2nt.items(), key=lambda t: -1*t[1].dcnt)\n        goids_upper = set()\n        for goid, _ in go_nt: # Loop through GO ID, GO nt\n            goids_upper.add(goid)\n            if goid in go2parentids:\n                goids_upper |= go2parentids[goid]\n            #print \"{} {:3} {}\".format(goid, len(goids_upper), gont.GO_name)\n            if len(goids_upper) < max_upper:\n                gosrcs_upper.add(goid)\n            else:\n                break\n        return gosrcs_upper", "response": "Get the upper portion of the GO DAG."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a GoSubDagPlotNt which contains both a GoSubDagPlot object and ntobj.", "response": "def _get_gosubdagplotnt(self, ntplt, title, go2color, pltargs):\n        \"\"\"Return GoSubDagPlotNt, which contains both a GoSubDagPlot object and ntobj.\"\"\"\n        kws_plt = pltargs.get_kws_plt()\n        kws_plt['id'] = '\"{ID}\"'.format(ID=ntplt.hdrgo)\n        kws_plt['title'] = \"{TITLE} of {M} user GOs\".format(TITLE=title, M=ntplt.tot_usrgos)\n        kws_plt['go2color'] = go2color\n        kws_plt['go2bordercolor'] = pltargs.go2bordercolor\n        if ntplt.parentcnt:\n            kws_plt[\"parentcnt\"] = True\n        gosubdagplot = GoSubDagPlot(ntplt.gosubdag, **kws_plt)\n        return GoSubDagPlotNt(self.grprobj, gosubdagplot, ntplt)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a message about the GO DAG Plot we are not plotting.", "response": "def _no_ntplt(self, ntplt):\n        \"\"\"Print a message about the GO DAG Plot we are NOT plotting.\"\"\"\n        sys.stdout.write(\"  {GO_USR:>6,} usr {GO_ALL:>6,} GOs  DID NOT WRITE: {B} {D}\\n\".format(\n            B=self.grprobj.get_fout_base(ntplt.hdrgo),\n            D=ntplt.desc,\n            GO_USR=len(ntplt.gosubdag.go_sources),\n            GO_ALL=len(ntplt.gosubdag.go2obj)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets GoSubDag containing hdrgo and all usrgos and their ancesters.", "response": "def _get_pltdag_ancesters(self, hdrgo, usrgos, desc=\"\"):\n        \"\"\"Get GoSubDag containing hdrgo and all usrgos and their ancesters.\"\"\"\n        go_srcs = usrgos.union([hdrgo])\n        gosubdag = GoSubDag(go_srcs,\n                            self.gosubdag.get_go2obj(go_srcs),\n                            relationships=self.gosubdag.relationships,\n                            rcntobj=self.gosubdag.rcntobj,\n                            go2nt=self.gosubdag.go2nt)\n        tot_usrgos = len(set(gosubdag.go2obj.keys()).intersection(self.usrgos))\n        return self.ntpltgo(\n            hdrgo=hdrgo,\n            gosubdag=gosubdag,\n            tot_usrgos=tot_usrgos,\n            parentcnt=False,\n            desc=desc)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_pltdag_path_hdr(self, hdrgo, usrgos, desc=\"pruned\"):\n        go_sources = usrgos.union([hdrgo])\n        gosubdag = GoSubDag(go_sources,\n                            self.gosubdag.get_go2obj(go_sources),\n                            relationships=self.gosubdag.relationships,\n                            rcntobj=self.gosubdag.rcntobj,\n                            go2nt=self.gosubdag.go2nt,\n                            dst_srcs_list=[(hdrgo, usrgos), (None, set([hdrgo]))])\n        tot_usrgos = len(set(gosubdag.go2obj.keys()).intersection(self.usrgos))\n        return self.ntpltgo(\n            hdrgo=hdrgo,\n            gosubdag=gosubdag,\n            tot_usrgos=tot_usrgos,\n            parentcnt=True,\n            desc=desc)", "response": "Get GoSubDag with paths from usrgos through hdrgo."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites png containing plot of GoSubDag.", "response": "def wrplt(self, fout_dir, plt_ext=\"png\"):\n        \"\"\"Write png containing plot of GoSubDag.\"\"\"\n        # Ex basename\n        basename = self.grprobj.get_fout_base(self.ntplt.hdrgo)\n        plt_pat = self.get_pltpat(plt_ext)\n        fout_basename = plt_pat.format(BASE=basename)\n        fout_plt = os.path.join(fout_dir, fout_basename)\n        self.gosubdagplot.plt_dag(fout_plt) # Create Plot\n        return fout_plt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dotstr(self):\n        dotobj = self.gosubdagplot.get_pydot_graph() # pydot.Dot\n        dotstr = dotobj.create_dot()\n        return dotstr", "response": "Return a string containing the DAG graph in Grpahviz s dot language."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns png pattern for the current locale.", "response": "def get_pltpat(self, plt_ext=\"svg\"):\n        \"\"\"Return png pattern: {BASE}.png {BASE}_pruned.png {BASE}_upper_pruned.png\"\"\"\n        if self.ntplt.desc == \"\":\n            return \".\".join([\"{BASE}\", plt_ext])\n        return \"\".join([\"{BASE}_\", self.ntplt.desc, \".\", plt_ext])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prt_hier_all(self, prt=sys.stdout):\n        # Print: [biological_process, molecular_function, and cellular_component]\n        items_list = set()\n        for goid in ['GO:0008150', 'GO:0003674', 'GO:0005575']:\n            items_list.update(self.prt_hier_down(goid, prt))\n        return items_list", "response": "Write hierarchy for all GO Terms in obo file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prt_hier_down(self, goid, prt=sys.stdout):\n        wrhiercfg = self._get_wrhiercfg()\n        obj = WrHierPrt(self.gosubdag.go2obj, self.gosubdag.go2nt, wrhiercfg, prt)\n        obj.prt_hier_rec(goid)\n        return obj.items_list", "response": "Write hierarchy for all items below GO ID in arg goid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prt_hier_up(self, goids, prt=sys.stdout):\n        go2goterm_all = {go:self.gosubdag.go2obj[go] for go in goids}\n        objp = GoPaths()\n        items_list = []\n        for namespace, go2term_ns in self._get_namespace2go2term(go2goterm_all).items():\n            goids_all = set()  # GO IDs from user-specfied GO to root\n            for goid_usr, goterm in go2term_ns.items():\n                goids_all.add(goid_usr)\n                paths = objp.get_paths_from_to(goterm, goid_end=None, dn0_up1=True)\n                goids_all.update(set(o.id for p in paths for o in p))\n            # Only include GO IDs from user-specified GO to the root\n            if 'include_only' not in self.usrdct:\n                self.usrdct['include_only'] = set()\n            self.usrdct['include_only'].update(goids_all)\n            # Mark the user-specfied GO term\n            if 'item_marks' not in self.usrdct:\n                self.usrdct['item_marks'] = {}\n            for goid_usr in go2term_ns.keys():\n                if goid_usr not in self.usrdct['item_marks']:\n                    self.usrdct['item_marks'][goid_usr] = '*'\n            # Write the hierarchy\n            wrhiercfg = self._get_wrhiercfg()\n            obj = WrHierPrt(self.gosubdag.go2obj, self.gosubdag.go2nt, wrhiercfg, prt)\n            go_root = self._get_goroot(goids_all, namespace)\n            obj.prt_hier_rec(go_root)\n            items_list.extend(obj.items_list)\n        return items_list", "response": "Write hierarchy for all GO IDs below GO ID in arg goid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngroup GO IDs by namespace.", "response": "def _get_namespace2go2term(go2terms):\n        \"\"\"Group GO IDs by namespace.\"\"\"\n        namespace2go2term = cx.defaultdict(dict)\n        for goid, goterm in go2terms.items():\n            namespace2go2term[goterm.namespace][goid] = goterm\n        return namespace2go2term"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_goroot(self, goids_all, namespace):\n        root_goid = self.consts.NAMESPACE2GO[namespace]\n        if root_goid in goids_all:\n            return root_goid\n        root_goids = set()\n        for goid in goids_all:\n            goterm = self.gosubdag.go2obj[goid]\n            if goterm.depth == 0:\n                root_goids.add(goterm.id)\n        if len(root_goids) == 1:\n            return next(iter(root_goids))\n        raise RuntimeError(\"UNEXPECTED NUMBER OF ROOTS: {R}\".format(R=root_goids))", "response": "Get the top GO for the set of goids_all."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all study items ( e. g. geneids.", "response": "def get_set(self, fieldname):\n        \"\"\"Get all study items (e.g., geneids).\"\"\"\n        set_items = set()\n        for ntdata in self.nts:\n            set_items |= getattr(ntdata, fieldname)\n        return set_items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding information from add_dct to a new copy of namedtuples stored in nts.", "response": "def mknts(self, add_dct):\n        \"\"\"Add information from add_dct to a new copy of namedtuples stored in nts.\"\"\"\n        nts = []\n        assert len(add_dct) == len(self.nts)\n        flds = list(next(iter(self.nts))._fields) + list(next(iter(add_dct)).keys())\n        ntobj = cx.namedtuple(\"ntgoea\", \" \".join(flds))\n        for dct_new, ntgoea in zip(add_dct, self.nts):\n            dct_curr = ntgoea._asdict()\n            for key, val in dct_new.items():\n                dct_curr[key] = val\n            nts.append(ntobj(**dct_curr))\n        return nts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_f2str(self, dcts, srcfld, dstfld, dstfmt):\n        # Example: f2str = objntmgr.add_f2str(dcts, \"p_fdr_bh\", \"s_fdr_bh\", \"{:8.2e}\")\n        # ntobj = self.get_ntobj()\n        # print(ntobj)\n        assert len(dcts) == len(self.nts)\n        for dct, ntgoea in zip(dcts, self.nts):\n            valorig = getattr(ntgoea, srcfld)\n            valstr = dstfmt.format(valorig)\n            dct[dstfld] = valstr", "response": "Add a namedtuple field of type string generated from an existing namedtuple field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ntobj(self):\n        if self.nts:\n            return cx.namedtuple(\"ntgoea\", \" \".join(vars(next(iter(self.nts))).keys()))", "response": "Create namedtuple object with GOEA fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the information content of a GO term.", "response": "def get_info_content(go_id, termcounts):\n    '''\n        Calculates the information content of a GO term.\n    '''\n    # Get the observed frequency of the GO term\n    freq = termcounts.get_term_freq(go_id)\n\n    # Calculate the information content (i.e., -log(\"freq of GO term\")\n    return -1.0 * math.log(freq) if freq else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the similarity measure between two GO IDs.", "response": "def resnik_sim(go_id1, go_id2, godag, termcounts):\n    '''\n        Computes Resnik's similarity measure.\n    '''\n    goterm1 = godag[go_id1]\n    goterm2 = godag[go_id2]\n    if goterm1.namespace == goterm2.namespace:\n        msca_goid = deepest_common_ancestor([go_id1, go_id2], godag)\n        return get_info_content(msca_goid, termcounts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lin_sim(goid1, goid2, godag, termcnts):\n    '''\n        Computes Lin's similarity measure.\n    '''\n    sim_r = resnik_sim(goid1, goid2, godag, termcnts)\n    return lin_sim_calc(goid1, goid2, sim_r, termcnts)", "response": "Computes the similarity measure between two Goids."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes Lin s similarity measure using pre - calculated Resnik s similarities.", "response": "def lin_sim_calc(goid1, goid2, sim_r, termcnts):\n    '''\n        Computes Lin's similarity measure using pre-calculated Resnik's similarities.\n    '''\n    if sim_r is not None:\n        info = get_info_content(goid1, termcnts) + get_info_content(goid2, termcnts)\n        if info != 0:\n            return (2*sim_r)/info"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef min_branch_length(go_id1, go_id2, godag, branch_dist):\n    '''\n        Finds the minimum branch length between two terms in the GO DAG.\n    '''\n    # First get the deepest common ancestor\n    goterm1 = godag[go_id1]\n    goterm2 = godag[go_id2]\n    if goterm1.namespace == goterm2.namespace:\n        dca = deepest_common_ancestor([go_id1, go_id2], godag)\n\n        # Then get the distance from the DCA to each term\n        dca_depth = godag[dca].depth\n        depth1 = goterm1.depth - dca_depth\n        depth2 = goterm2.depth - dca_depth\n\n        # Return the total distance - i.e., to the deepest common ancestor and back.\n        return depth1 + depth2\n\n    elif branch_dist is not None:\n        return goterm1.depth + goterm2.depth + branch_dist", "response": "Find the minimum branch length between two GO terms in the GO DAG."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the semantic distance between two GO terms.", "response": "def semantic_distance(go_id1, go_id2, godag, branch_dist=None):\n    '''\n        Finds the semantic distance (minimum number of connecting branches)\n        between two GO terms.\n    '''\n    return min_branch_length(go_id1, go_id2, godag, branch_dist)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the semantic similarity between two GO IDs.", "response": "def semantic_similarity(go_id1, go_id2, godag, branch_dist=None):\n    '''\n        Finds the semantic similarity (inverse of the semantic distance)\n        between two GO terms.\n    '''\n    dist = semantic_distance(go_id1, go_id2, godag, branch_dist)\n    if dist is not None:\n        return 1.0 / float(dist)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfilling in the counts and overall aspect counts.", "response": "def _init_count_terms(self, annots):\n        '''\n            Fills in the counts and overall aspect counts.\n        '''\n        gonotindag = set()\n        gocnts = self.gocnts\n        go2obj = self.go2obj\n        # Fill gocnts with GO IDs in annotations and their corresponding counts\n        for terms in annots.values(): # key is 'gene'\n            # Make a union of all the terms for a gene, if term parents are\n            # propagated but they won't get double-counted for the gene\n            allterms = set()\n            for go_id in terms:\n                goobj = go2obj.get(go_id, None)\n                if goobj is not None:\n                    allterms.add(go_id)\n                    allterms |= goobj.get_all_parents()\n                else:\n                    gonotindag.add(go_id)\n            for parent in allterms:\n                gocnts[parent] += 1\n        if gonotindag:\n            print(\"{N} Assc. GO IDs not found in the GODag\\n\".format(N=len(gonotindag)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding missing alternate GO IDs to term counts.", "response": "def _init_add_goid_alt(self):\n        '''\n            Add alternate GO IDs to term counts.\n        '''\n        # Fill aspect_counts. Find alternate GO IDs that may not be on gocnts\n        goid_alts = set()\n        go2cnt_add = {}\n        aspect_counts = self.aspect_counts\n        gocnts = self.gocnts\n        go2obj = self.go2obj\n        for go_id, cnt in gocnts.items():\n            goobj = go2obj[go_id]\n            assert cnt, \"NO TERM COUNTS FOR {GO}\".format(GO=goobj.item_id)\n            # Was the count set using an alternate GO?\n            if go_id != goobj.item_id:\n                go2cnt_add[goobj.item_id] = cnt\n            goid_alts |= goobj.alt_ids\n            # Group by namespace\n            aspect_counts[goobj.namespace] += cnt\n        # If alternate GO used to set count, add main GO ID\n        for goid, cnt in go2cnt_add.items():\n            gocnts[goid] = cnt\n        # Add missing alt GO IDs to gocnts\n        for alt_goid in goid_alts.difference(gocnts):\n            goobj = go2obj[alt_goid]\n            cnt = gocnts[goobj.item_id]\n            assert cnt, \"NO TERM COUNTS FOR ALT_ID({GOa}) ID({GO}): {NAME}\".format(\n                GOa=alt_goid, GO=goobj.item_id, NAME=goobj.name)\n            gocnts[alt_goid] = cnt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the frequency at which a particular GO term has been observed in the annotations.", "response": "def get_term_freq(self, go_id):\n        '''\n            Returns the frequency at which a particular GO term has\n            been observed in the annotations.\n        '''\n        num_ns = float(self.get_total_count(self.go2obj[go_id].namespace))\n        return float(self.get_count(go_id))/num_ns if num_ns != 0 else 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a header GO return the sections that contain it.", "response": "def get_sections(self, hdrgo, dflt_section=True):\n        \"\"\"Given a header GO, return the sections that contain it.\"\"\"\n        dflt_list = []\n        # If the hdrgo is not in a section, return the default name for a section\n        if dflt_section:\n            dflt_list = [self.secdflt]\n        return self.hdrgo2sections.get(hdrgo, dflt_list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the GO group headers explicitly listed in sections.", "response": "def get_section_hdrgos(self):\n        \"\"\"Get the GO group headers explicitly listed in sections.\"\"\"\n        return set([h for _, hs in self.sections for h in hs]) if self.sections else set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking format of user - provided sections variable", "response": "def _chk_sections(sections):\n        \"\"\"Check format of user-provided 'sections' variable\"\"\"\n        if sections:\n            assert len(sections[0]) == 2, \\\n                \"SECTIONS DATA MUST BE A 2-D LIST. FOUND: {S}\".format(S=sections)\n            for _, hdrgos in sections:\n                chk_goids(hdrgos, \"HdrgosSections::_chk_sections()\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_hdrgo2sections(self):\n        hdrgo2sections = cx.defaultdict(list)\n        for section_name, hdrgos in self.sections:\n            for hdrgo in hdrgos:\n                hdrgo2sections[hdrgo].append(section_name)\n        return hdrgo2sections", "response": "Return a dict with GO group headers as keys and section names as values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize GO high headers.", "response": "def _init_hdrgos(self, hdrgos_dflt, hdrgos_usr=None, add_dflt=True):\n        \"\"\"Initialize GO high\"\"\"\n        # Use default GO group header values\n        if (hdrgos_usr is None or hdrgos_usr is False) and not self.sections:\n            return set(hdrgos_dflt)\n        # Get GO group headers provided by user\n        hdrgos_init = set()\n        if hdrgos_usr:\n            chk_goids(hdrgos_usr, \"User-provided GO group headers\")\n            hdrgos_init |= set(hdrgos_usr)\n        if self.sections:\n            self._chk_sections(self.sections)\n            hdrgos_sec = set([hg for _, hdrgos in self.sections for hg in hdrgos])\n            chk_goids(hdrgos_sec, \"User-provided GO group headers in sections\")\n            hdrgos_init |= hdrgos_sec\n        # Add default depth-01 GOs to headers, if desired\n        if add_dflt:\n            return set(hdrgos_init).union(hdrgos_dflt)\n        # Return user-provided GO grouping headers\n        return hdrgos_init"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_parents(go_objs):\n    go_parents = set()\n    for go_obj in go_objs:\n        go_parents |= go_obj.get_all_parents()\n    return go_parents", "response": "Return a set containing all GO Term parents of multiple GO Term objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prt_hdr(self, prt=sys.stdout, name=\"name       \"):\n        hdr = \"{NAME} | # {ITEMS:11} | range                | 25th percentile | \" \\\n              \"  median | 75th percentile |     mean | stddev\\n\".format(NAME=name, ITEMS=self.desc)\n        div = \"{DASHES}|---------------|----------------------|\" \\\n              \"-----------------|----------|-----------------|----------|-------\\n\".format(\n                  DASHES='-'*(len(name)))\n        prt.write(hdr)\n        prt.write(div)", "response": "Print stats header in markdown style."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting stats data in markdown style.", "response": "def prt_data(self, name, vals, prt=sys.stdout):\n        \"\"\"Print stats data in markdown style.\"\"\"\n        fld2val = self.get_fld2val(name, vals)\n        prt.write(self.fmt.format(**fld2val))\n        return fld2val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning stats data string in markdown style.", "response": "def getstr_data(self, name, vals):\n        \"\"\"Return stats data string in markdown style.\"\"\"\n        fld2val = self.get_fld2val(name, vals)\n        return self.fmt.format(**fld2val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_fld2val(self, name, vals):\n        if vals:\n            return self._init_fld2val_stats(name, vals)\n        return self._init_fld2val_null(name)", "response": "Describe summary statistics for a list of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn statistics on values.", "response": "def _init_fld2val_stats(self, name, vals):\n        \"\"\"Return statistics on values.\"\"\"\n        vals_stats = stats.describe(vals)\n        stddev = math.sqrt(vals_stats[3]) # stats variance\n        p25 = np.percentile(vals, 25)\n        p50 = np.percentile(vals, 50) # median\n        p75 = np.percentile(vals, 75)\n        fld2val = {\n            'name':name,\n            'qty'.format(ITEMS=self.desc):vals_stats[0], # stats nobs\n            'range':self._get_str_range(vals_stats),\n            '25th percentile':p25,\n            'median':p50,\n            '75th percentile':p75,\n            'mean':vals_stats[2], # stats mean\n            'stddev':stddev}\n        fmtflds = set(['25th percentile', 'median', '75th percentile', 'mean', 'stddev'])\n        mkint = \",\" in self.fmtstr\n        for key, val in fld2val.items():\n            if key in fmtflds:\n                if mkint:\n                    val = int(round(val))\n                fld2val[key] = self.fmtstr.format(val)\n        return fld2val"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string containing the range of values.", "response": "def _get_str_range(self, vals_stats):\n        \"\"\"Return a string containing the range of values.\"\"\"\n        minmax = vals_stats[1] # stats minmax\n        minval = self.fmtstr.format(minmax[0])\n        maxval = self.fmtstr.format(minmax[1])\n        return '{A} to {B:6>}'.format(A=minval, B=maxval)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget counts of header GO IDs and sections.", "response": "def summarize_sec2hdrgos(self, sec2d_hdrgos):\n        \"\"\"Get counts of header GO IDs and sections.\"\"\"\n        hdrgos_all = set([])\n        hdrgos_grouped = set()\n        hdrgos_ungrouped = set()\n        sections_grouped = set()\n        for sectionname, hdrgos in sec2d_hdrgos:\n            self._chk_hdrgoids(hdrgos)\n            hdrgos_all.update(hdrgos)\n            if sectionname != HdrgosSections.secdflt:\n                hdrgos_grouped.update(hdrgos)\n                sections_grouped.add(sectionname)\n            else:\n                hdrgos_ungrouped.update(hdrgos)\n        return {'G': hdrgos_grouped,\n                'S': sections_grouped,\n                'U': hdrgos_all.difference(hdrgos_grouped)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summarize_sec2hdrnts(self, sec2d_hdrnts):\n        sec2d_hdrgos = [(s, set(nt.GO for nt in nts)) for s, nts in sec2d_hdrnts]\n        return self.summarize_sec2hdrgos(sec2d_hdrgos)", "response": "Given namedtuples in each sectin get counts of header GO IDs and sections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that hdrgo set is a set of GO IDs.", "response": "def _chk_hdrgoids(hdrgos):\n        \"\"\"Check that hdrgo set is a set of GO IDs.\"\"\"\n        goid = next(iter(hdrgos))\n        if isinstance(goid, str) and goid[:3] == \"GO:\":\n            return\n        assert False, \"HDRGOS DO NOT CONTAIN GO IDs: {E}\".format(E=goid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all GOs which match the user regex pattern.", "response": "def get_matching_gos(self, compiled_pattern, **kws):\n        \"\"\"Return all GOs which match the user regex pattern.\"\"\"\n        # kws: prt gos\n        matching_gos = []\n        obo_dag = self.obo_dag\n        prt = kws['prt'] if 'prt' in kws else self.log\n        prt.write('\\nPATTERN SEARCH: \"{P}\"\\n'.format(P=compiled_pattern.pattern))\n        # Only look through GOs in annotation or user-specified GOs\n        srchgos = kws['gos'] if 'gos' in kws else self.go2items.keys()\n        for go_id in srchgos:\n            go_obj = obo_dag.get(go_id, None)\n            if go_obj is not None:\n                for hdr in self.goa_srch_hdrs:\n                    if hdr in go_obj.__dict__:\n                        fld_val = getattr(go_obj, hdr)\n                        matches = self._search_vals(compiled_pattern, fld_val)\n                        for mtch in matches:\n                            prt.write(\"MATCH {go_id}({NAME}) {FLD}: {M}\\n\".format(\n                                FLD=hdr, go_id=go_obj.id, NAME=go_obj.name, M=mtch))\n                        if matches:\n                            matching_gos.append(go_id)\n            else:\n                prt.write(\"**WARNING: {GO} found in annotation is not found in obo\\n\".format(\n                    GO=go_id))\n        matching_gos = set(matching_gos)\n        # Print summary message\n        self._summary_matching_gos(prt, compiled_pattern.pattern, matching_gos, srchgos)\n        return matching_gos"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint summary for get_matching_gos.", "response": "def _summary_matching_gos(prt, pattern, matching_gos, all_gos):\n        \"\"\"Print summary for get_matching_gos.\"\"\"\n        msg = 'Found {N} GO(s) out of {M} matching pattern(\"{P}\")\\n'\n        num_gos = len(matching_gos)\n        num_all = len(all_gos)\n        prt.write(msg.format(N=num_gos, M=num_all, P=pattern))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _search_vals(self, compiled_pattern, fld_val):\n        matches = []\n        if isinstance(fld_val, set):\n            for val in fld_val:\n                self._search_val(matches, compiled_pattern, val)\n        elif isinstance(fld_val, str):\n            self._search_val(matches, compiled_pattern, fld_val)\n        return matches", "response": "Search for user - regex in scalar or iterable data values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _search_val(matches, compiled_pattern, fld_val):\n        mtch = compiled_pattern.search(fld_val)\n        if mtch:\n            matches.append(fld_val)", "response": "Search for user - regex in scalar data values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning children of input gos plus input gos.", "response": "def add_children_gos(self, gos):\n        \"\"\"Return children of input gos plus input gos.\"\"\"\n        lst = []\n        obo_dag = self.obo_dag\n        get_children = lambda go_obj: list(go_obj.get_all_children()) + [go_obj.id]\n        for go_id in gos:\n            go_obj = obo_dag[go_id]\n            lst.extend(get_children(go_obj))\n        return set(lst)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive GO terms return genes or gene products for the GOs.", "response": "def get_items(self, gos):\n        \"\"\"Given GO terms, return genes or gene products for the GOs.\"\"\"\n        items = []\n        for go_id in gos:\n            items.extend(self.go2items.get(go_id, []))\n        return set(items)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prt_summary(self, prt=sys.stdout):\n        desc = \"NtGoeaResults\" if self.is_goterm else \"namedtuple\"\n        prt.write(\"{N} GOEA results from {O}. P-values stored in {P}.\\n\".format(\n            N=len(self.go2res), O=desc, P=self.pval_name))", "response": "Print summary of GOEA plotting object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_study_txt(self, goid):\n        if goid in self.go2res:\n            res = self.go2res[goid]\n            if res.study_items is not None:\n                return self._get_item_str(res)\n            else:\n                return self.fmtres.format(study_count=res.study_count)", "response": "Get GO text from GOEA study."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_goid2color_pval(self, goid2color):\n        alpha2col = self.alpha2col\n        if self.pval_name is not None:\n            pval_name = self.pval_name\n            for goid, res in self.go2res.items():\n                pval = getattr(res, pval_name, None)\n                if pval is not None:\n                    for alpha, color in alpha2col.items():\n                        if pval <= alpha and res.study_count != 0:\n                            if goid not in goid2color:\n                                goid2color[goid] = color", "response": "Fill missing colors based on p - value of an enriched GO term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_goid2color_pval(self):\n        go2color = {}\n        self.set_goid2color_pval(go2color)\n        color_dflt = self.alpha2col[1.000]\n        for goid in self.go2res:\n            if goid not in go2color:\n                go2color[goid] = color_dflt\n        return go2color", "response": "Return a dict containing GO colors determined by P - value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string representation of the items in the item list.", "response": "def _get_item_str(self, res):\n        \"\"\"Return genes in any of these formats:\n              1. 19264, 17319, 12520, 12043, 74131, 22163, 12575\n              2. Ptprc, Mif, Cd81, Bcl2, Sash3, Tnfrsf4, Cdkn1a\n              3. 7: Ptprc, Mif, Cd81, Bcl2, Sash3...\n        \"\"\"\n        ipl = self.items_p_line\n        prt_items = sorted([self._get_genestr(itemid) for itemid in res.study_items])\n        prt_multiline = [prt_items[i:i+ipl] for i in range(0, len(prt_items), ipl)]\n        num_items = len(prt_items)\n        if self.study_items_max is None:\n            genestr = \"\\n\".join([\", \".join(str(e) for e in sublist) for sublist in prt_multiline])\n            return \"{N}) {GENES}\".format(N=num_items, GENES=genestr)\n        else:\n            if num_items <= self.study_items_max:\n                gene_lines = [\", \".join(str(e) for e in sublist) for sublist in prt_multiline]\n                genestr = \"\\n\".join(gene_lines)\n                return genestr\n            else:\n                short_list = prt_items[:self.study_items_max]\n                short_mult = [short_list[i:i+ipl] for i in range(0, len(short_list), ipl)]\n                short_lines = [\", \".join(str(e) for e in sublist) for sublist in short_mult]\n                short_str = \"\\n\".join(short_lines)\n                return \"\".join([\"{N} genes; \".format(N=num_items), short_str, \"...\"])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a geneid return the string geneid or a gene symbol.", "response": "def _get_genestr(self, itemid):\n        \"\"\"Given a geneid, return the string geneid or a gene symbol.\"\"\"\n        if itemid in self.id2symbol:\n            symbol = self.id2symbol[itemid]\n            if symbol is not None:\n                return symbol\n        if isinstance(itemid, int):\n            return str(itemid)\n        return itemid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize pvalue attribute name.", "response": "def _init_pval_name(self, **kws):\n        \"\"\"Initialize pvalue attribute name.\"\"\"\n        if 'pval_name' in kws:\n            return kws['pval_name']\n        # If go2res contains GO Terms\n        if self.is_goterm:\n            return \"p_{M}\".format(M=next(iter(self.go2res.values())).get_method_name())\n        # If go2res contains GO namedtuples\n        for fld in next(iter(self.go2res.values()))._fields:\n            if fld[:2] == 'p_' and fld != 'p_uncorrected':\n                return fld"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wr_xlsx(self, fout_xlsx):\n        from goatools.wr_tbl import wr_xlsx\n        kws = {\n            'title' : self.title,\n            'hdrs' :[\"Dep/Lev\",\n                     \"BP Depth\", \"MF Depth\", \"CC Depth\",\n                     \"BP Level\", \"MF Level\", \"CC Level\"]}\n        wr_xlsx(fout_xlsx, self.get_data(), **kws)", "response": "Write counts of GO terms at all levels and depths."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wr_txt(self, fout_txt):\n        from goatools.wr_tbl import prt_txt\n        data = self.get_data()\n        with open(fout_txt, 'w') as prt:\n            prtfmt = \"{Depth_Level:>7} \" \\\n                     \"{BP_D:6,} {MF_D:6,} {CC_D:>6,} \" \\\n                     \"{BP_L:>6,} {MF_L:>6,} {CC_L:>6,}\\n\"\n            prt.write(\"{TITLE}\\n\\n\".format(TITLE=self.title))\n            prt.write(\"         |<---- Depth ---->|  |<---- Level ---->|\\n\")\n            prt.write(\"Dep/Lev     BP     MF     CC     BP     MF     CC\\n\")\n            prt.write(\"-------  -----  -----  -----  -----  -----  -----\\n\")\n            prt_txt(prt, data, prtfmt=prtfmt, title=self.title)\n            sys.stdout.write(\"  {N:>5,} items WROTE: {TXT}\\n\".format(\n                N=len(data), TXT=fout_txt))", "response": "Write counts of GO terms at all levels and depths."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prttex_summary_cnts_all(self, prt=sys.stdout):\n        cnts = self.get_cnts_levels_depths_recs(set(self.obo.values()))\n        self._prttex_summary_cnts(prt, cnts)", "response": "Print LaTeX format summary of level and depth counts for all active GO Terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_summary_cnts_all(self):\n        cnts = self.get_cnts_levels_depths_recs(set(self.obo.values()))\n        self._write_summary_cnts(cnts)", "response": "Write summary of level and depth counts for all active GO Terms."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite summary of level and depth counts for specific GO ids.", "response": "def write_summary_cnts(self, go_ids):\n        \"\"\"Write summary of level and depth counts for specific GO ids.\"\"\"\n        obo = self.obo\n        cnts = self.get_cnts_levels_depths_recs([obo.get(GO) for GO in go_ids])\n        self._write_summary_cnts(cnts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites summary of level and depth counts for a list of GO Terms.", "response": "def write_summary_cnts_goobjs(self, goobjs):\n        \"\"\"Write summary of level and depth counts for active GO Terms.\"\"\"\n        cnts = self.get_cnts_levels_depths_recs(goobjs)\n        self._write_summary_cnts(cnts)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting summary of level and depth counts for active GO Terms.", "response": "def _prttex_summary_cnts(self, prt, cnts):\n        \"\"\"Write summary of level and depth counts for active GO Terms.\"\"\"\n        # Count level(shortest path to root) and depth(longest path to root)\n        # values for all unique GO Terms.\n        prt.write(\"\\n\\n% LaTeX Table for GO counts at each level and depth in the GO DAG\\n\")\n        prt.write(r\"\\begin{table}[bt]\" \"\\n\")\n        prt.write(r\"\\begin{tabular}{|r |r |r |r |r |r |r|}\" \"\\n\")\n\n        title = self.title.replace('_', r'\\_')\n        prt.write(r\"\\hline\" \"\\n\")\n        prt.write(r\"\\rowcolor{gray!10}\" \"\\n\")\n        prt.write(\" \".join([r\"\\multicolumn{7}{|l|}{\", title, r\"} \\\\\", \"\\n\"]))\n        prt.write(r\"\\hline\" \"\\n\")\n        prt.write(r\"\\rowcolor{gray!10}\" \"\\n\")\n        prt.write(r\"Depth &\" \"\\n\")\n        prt.write(r\"\\multicolumn{3}{c|}{Depth} &\" \"\\n\")\n        prt.write(r\"\\multicolumn{3}{c|}{Level} \\\\\" \"\\n\")\n        prt.write(r\"\\cline{2-7}\" \"\\n\")\n        prt.write(r\"\\rowcolor{gray!10}\" \"\\n\")\n        prt.write(r\"or Level & BP & MF & CC & BP & MF & CC \\\\\" \"\\n\")\n        prt.write(r\"\\hline\" \"\\n\")\n\n        max_val = max(max(dep for dep in cnts['depth']), max(lev for lev in cnts['level']))\n        for i in range(max_val+1):\n            vals = ['{:>5}'.format(cnts[desc][i][ns]) for desc in cnts for ns in self.nss]\n            self.log.write('{:>02} & {} \\\\\\\\\\n'.format(i, ' & '.join(vals)))\n            if i%2 == 0:\n                prt.write(r\"\\rowcolor{gray!7}\" \"\\n\")\n        prt.write(r\"\\hline\" \"\\n\")\n        prt.write(r\"\\end{tabular}\" \"\\n\")\n        prt.write(r\"\\end{table}\" \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite summary of level and depth counts for active GO Terms.", "response": "def _write_summary_cnts(self, cnts):\n        \"\"\"Write summary of level and depth counts for active GO Terms.\"\"\"\n        # Count level(shortest path to root) and depth(longest path to root)\n        # values for all unique GO Terms.\n        max_val = max(max(dep for dep in cnts['depth']),\n                      max(lev for lev in cnts['level']))\n        self.log.write('Dep <-Depth Counts->  <-Level Counts->\\n')\n        self.log.write('Lev   BP    MF    CC    BP    MF    CC\\n')\n        self.log.write('--- ----  ----  ----  ----  ----  ----\\n')\n        for i in range(max_val+1):\n            vals = ['{:>5}'.format(cnts[desc][i][ns]) for desc in sorted(cnts) for ns in self.nss]\n            self.log.write('{:>02} {}\\n'.format(i, ' '.join(vals)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect counts of levels and depths in a Group of GO Terms.", "response": "def get_cnts_levels_depths_recs(recs):\n        \"\"\"Collect counts of levels and depths in a Group of GO Terms.\"\"\"\n        cnts = cx.defaultdict(lambda: cx.defaultdict(cx.Counter))\n        for rec in recs:\n            if rec is not None and not rec.is_obsolete:\n                cnts['level'][rec.level][rec.namespace] += 1\n                cnts['depth'][rec.depth][rec.namespace] += 1\n        return cnts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects counts of GO terms at all levels and depths.", "response": "def get_data(self):\n        \"\"\"Collect counts of GO terms at all levels and depths.\"\"\"\n        # Count level(shortest path to root) and depth(longest path to root)\n        # values for all unique GO Terms.\n        data = []\n        ntobj = cx.namedtuple(\"NtGoCnt\", \"Depth_Level BP_D MF_D CC_D BP_L MF_L CC_L\")\n        cnts = self.get_cnts_levels_depths_recs(set(self.obo.values()))\n        max_val = max(max(dep for dep in cnts['depth']), max(lev for lev in cnts['level']))\n        for i in range(max_val+1):\n            vals = [i] + [cnts[desc][i][ns] for desc in cnts for ns in self.nss]\n            data.append(ntobj._make(vals))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    # Load study, population, associations, and GoDag. Run GOEA.\n    obj = GoeaCliFnc(GoeaCliArgs().args)\n    # Reduce results to significant results (pval<value)\n    results_specified = obj.get_results()\n    # Print results in a flat list\n    obj.prt_results(results_specified)", "response": "Run gene enrichment analysis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_objanno(fin_anno, anno_type=None, **kws):\n    # kws get_objanno: taxids hdr_only prt allow_missing_symbol\n    anno_type = get_anno_desc(fin_anno, anno_type)\n    if anno_type is not None:\n        if anno_type == 'gene2go':\n            # kws: taxid taxids\n            return Gene2GoReader(fin_anno, **kws)\n        if anno_type == 'gaf':\n            return GafReader(fin_anno,\n                             hdr_only=kws.get('hdr_only', False),\n                             prt=kws.get('prt', sys.stdout),\n                             allow_missing_symbol=kws.get('allow_missing_symbol', False))\n        if anno_type == 'gpad':\n            hdr_only = kws.get('hdr_only', False)\n            return GpadReader(fin_anno, hdr_only)\n        if anno_type == 'id2gos':\n            return IdToGosReader(fin_anno)\n    raise RuntimeError('UNEXPECTED ANNOTATION FILE FORMAT: {F} {D}'.format(\n        F=fin_anno, D=anno_type))", "response": "Read annotations in GAF GPAD Entrez gene2go or text format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a Counter containing all relations contained in the Annotation Extensions.", "response": "def get_relation_cnt(self):\n        \"\"\"Return a Counter containing all relations contained in the Annotation Extensions.\"\"\"\n        ctr = cx.Counter()\n        for ntgpad in self.associations:\n            if ntgpad.Extension is not None:\n                ctr += ntgpad.Extension.get_relations_cnt()\n        return ctr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads annotation file and store a list of namedtuples.", "response": "def _init_associations(self, fin_gpad, hdr_only=False):\n        \"\"\"Read annotation file and store a list of namedtuples.\"\"\"\n        ini = InitAssc(fin_gpad, self.godag)\n        nts = ini.init_associations(hdr_only)\n        self.hdr = ini.hdr\n        return nts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_args(self):\n\n        #pylint: disable=invalid-name\n        p = argparse.ArgumentParser(__doc__,\n                                    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\n        p.add_argument('filenames', type=str, nargs=3,\n                       help='data/study data/population data/association')\n        p.add_argument('--annofmt', default=None, type=str,\n                       help=('Annotation file format. '\n                             'Not needed if type can be determined using filename'),\n                       choices=['gene2go', 'gaf', 'gpad', 'id2gos'])\n        p.add_argument('--taxid', default=9606, type=int,\n                       help=\"When using NCBI's gene2go annotation file, specify desired taxid\")\n        p.add_argument('--alpha', default=0.05, type=float,\n                       help='Test-wise alpha for multiple testing')\n        p.add_argument('--pval', default=.05, type=float,\n                       help='Only print results with uncorrected p-value < PVAL.')\n        p.add_argument('--pval_field', type=str,\n                       help='Only print results when PVAL_FIELD < PVAL.')\n        p.add_argument('--outfile', default=None, type=str,\n                       help='Write enrichment results into xlsx or tsv file')\n        p.add_argument('--id2sym', default=None, type=str,\n                       help='ASCII file containing one geneid and its symbol per line')\n        p.add_argument('--sections', default=None, type=str,\n                       help=('Use sections file for printing grouped GOEA results. '\n                             'Example SECTIONS values:\\n'\n                             'goatools.test_data.sections.gjoneska_pfenning \\n'\n                             'goatools/test_data/sections/gjoneska_pfenning.py \\n'\n                             'data/gjoneska_pfenning/sections_in.txt\\n'))\n        p.add_argument('--outfile_detail', type=str,\n                       help=('Write enrichment results into a text file \\n'\n                             'containing the following information: \\n'\n                             '1) GOEA GO terms, grouped into sections \\n\\n'\n                             '2) List of genes and ASCII art showing section membership \\n'\n                             '3) Detailed list of each gene and GO terms w/their P-values \\n'))\n        p.add_argument('--compare', dest='compare', default=False,\n                       action='store_true',\n                       help=\"the population file as a comparison group. if this \"\n                       \"flag is specified, the population is used as the study \"\n                       \"plus the `population/comparison`\")\n        p.add_argument('--ratio', dest='ratio', type=float, default=None,\n                       help=\"only show values where the difference between study \"\n                       \"and population ratios is greater than this. useful for \"\n                       \"excluding GO categories with small differences, but \"\n                       \"containing large numbers of genes. should be a value \"\n                       \"between 1 and 2. \")\n        p.add_argument('--indent', dest='indent', default=False,\n                       action='store_true', help=\"indent GO terms\")\n        p.add_argument('--obo', default=\"go-basic.obo\", type=str,\n                       help=\"Specifies location and name of the obo file\")\n        p.add_argument('--no_propagate_counts', default=False, action='store_true',\n                       help=\"Do not propagate counts to parent terms\")\n        p.add_argument('--method', default=\"bonferroni,sidak,holm,fdr_bh\", type=str,\n                       help=Methods().getmsg_valid_methods())\n        p.add_argument('--pvalcalc', default=\"fisher\", type=str,\n                       help=str(FisherFactory()))\n        p.add_argument('--min_overlap', default=0.7, type=float,\n                       help=\"Check that a minimum amount of study genes are in the population\")\n        p.add_argument('--goslim', default='goslim_generic.obo', type=str,\n                       help=\"The GO slim file is used when grouping GO terms.\")\n        p.add_argument('--ev_inc', type=str,\n                       help=\"Include specified evidence codes and groups separated by commas\")\n        p.add_argument('--ev_exc', type=str,\n                       help=\"Exclude specified evidence codes and groups separated by commas\")\n        p.add_argument('--ev_help', dest='ev_help', action='store_false',\n                       help=\"Print all Evidence codes\")\n\n        if len(sys.argv) == 1:\n            sys.exit(not p.print_help())\n        if '--ev_help' in sys.argv:\n            print('\\nEVIDENCE CODE HELP: --ev_exc --ev_inc')\n            print('Use any of these group names, ')\n            print('like Experimental or Similarity or Experimental,Similarity,')\n            print('or evidence codes, like IEA or ISS,ISO,ISA in --ev_exc or --ev_inc:\\n')\n            obj = EvidenceCodes()\n            obj.prt_details()\n            sys.exit(0)\n\n        args = p.parse_args()  # Namespace object from argparse\n        self._check_input_files(args, p)\n        return args", "response": "Initialize the arguments for the get_enrichment_argparser call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_input_files(nspc, parser):\n        if not len(nspc.filenames) == 3:\n            parser.print_help()\n            msg = \"\"\"\n      3 Expected files; Expected content: study population association\",\n      {} Actual   files: {}\"\"\".format(len(nspc.filenames), ' '.join(nspc.filenames))\n            raise Exception(msg)\n        for fin in nspc.filenames:\n            if not os.path.exists(fin):\n                return \"*{}* does not exist\".format(fin)\n\n        return False", "response": "check if input files exist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning annotations as id2gos", "response": "def _get_id2gos(self):\n        \"\"\"Return annotations as id2gos\"\"\"\n        kws = {}\n        if self.args.ev_inc is not None:\n            kws['ev_include'] = set(self.args.ev_inc.split(','))\n        if self.args.ev_exc is not None:\n            kws['ev_exclude'] = set(self.args.ev_exc.split(','))\n        return self.objanno.get_id2gos(**kws)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an annotation object from an annotation file", "response": "def _get_objanno(self, assoc_fn):\n        \"\"\"Get an annotation object\"\"\"\n        # Determine annotation file format from filename, if possible\n        anno_type = get_anno_desc(assoc_fn, None)\n        # Default annotation file format is id2gos\n        if anno_type is None:\n            anno_type = self.args.annofmt if self.args.annofmt else 'id2gos'\n        kws = {'taxid': self.args.taxid} if anno_type == 'gene2go' else {}\n        return get_objanno(assoc_fn, anno_type, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _init_itemid2name(self):\n        if not hasattr(self.args, 'id2sym'):\n            return None\n        fin_id2sym = self.args.id2sym\n        if fin_id2sym is not None and os.path.exists(fin_id2sym):\n            id2sym = {}\n            cmpl = re.compile(r'^\\s*(\\S+)[\\s,;]+(\\S+)')\n            with open(fin_id2sym) as ifstrm:\n                for line in ifstrm:\n                    mtch = cmpl.search(line)\n                    if mtch:\n                        id2sym[mtch.group(1)] = mtch.group(2)\n            return id2sym", "response": "Print gene symbols instead of gene IDs if provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prt_results(self, goea_results):\n        # objaart = self.prepgrp.get_objaart(goea_results) if self.prepgrp is not None else None\n        if self.args.outfile is None:\n            self._prt_results(goea_results)\n        else:\n            # Users can print to both tab-separated file and xlsx file in one run.\n            outfiles = self.args.outfile.split(\",\")\n            grpwr = self.prepgrp.get_objgrpwr(goea_results) if self.prepgrp else None\n            if grpwr is None:\n                self.prt_outfiles_flat(goea_results, outfiles)\n            else:\n                grpwr.prt_outfiles_grouped(outfiles)", "response": "Print GOEA results to the screen or to a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prt_results(self, goea_results):\n        min_ratio = self.args.ratio\n        if min_ratio is not None:\n            assert 1 <= min_ratio <= 2\n        self.objgoea.print_date(min_ratio=min_ratio, pval=self.args.pval)\n        results_adj = self.objgoea.get_adj_records(goea_results, min_ratio, self.args.pval)\n        if results_adj:\n            if not self.prepgrp:\n                self.objgoea.print_results_adj(results_adj, indent=self.args.indent)\n            else:\n                grpwr = self.prepgrp.get_objgrpwr(results_adj)\n                grpwr.prt_txt(sys.stdout)", "response": "Print GOEA results to the screen."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_objgoea(self, pop, assoc):\n        propagate_counts = not self.args.no_propagate_counts\n        return GOEnrichmentStudy(pop, assoc, self.godag,\n                                 propagate_counts=propagate_counts,\n                                 relationships=False,\n                                 alpha=self.args.alpha,\n                                 pvalcalc=self.args.pvalcalc,\n                                 methods=self.methods)", "response": "Run gene ontology enrichment analysis (GOEA)."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the user - specified field for determining significant results.", "response": "def get_pval_field(self):\n        \"\"\"Get 'p_uncorrected' or the user-specified field for determining significant results.\"\"\"\n        pval_fld = self.args.pval_field\n        # If --pval_field [VAL] was specified\n        if pval_fld is not None:\n            if pval_fld[:2] != 'p_':\n                pval_fld = 'p_' + pval_fld\n        # If only one method was used, use that instead of the uncorrected pvalue\n        elif len(self.methods) == 1:\n            pval_fld = 'p_' + self.methods[0]\n        # Use 'uncorrected pvalue' if there are many methods & none chosen using --pval_field\n        else:\n            pval_fld = 'p_uncorrected'\n        if self.results_all:\n            assert hasattr(next(iter(self.results_all)), pval_fld), \\\n                'NO PVAL({P}). EXPECTED ONE OF: {E}'.format(\n                    P=self.args.pval_field,\n                    E=\" \".join([k for k in dir(next(iter(self.results_all))) if k[:2] == 'p_']))\n        return pval_fld"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rd_files(self, study_fn, pop_fn):\n        study, pop = self._read_geneset(study_fn, pop_fn)\n        print(\"Study: {0} vs. Population {1}\\n\".format(len(study), len(pop)))\n        return study, pop", "response": "Read files and return study and population."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_geneset(self, study_fn, pop_fn):\n        pop = set(_.strip() for _ in open(pop_fn) if _.strip())\n        study = frozenset(_.strip() for _ in open(study_fn) if _.strip())\n        if next(iter(pop)).isdigit():\n            pop = set(int(g) for g in pop)\n            study = frozenset(int(g) for g in study)\n        # some times the pop is a second group to compare, rather than the\n        # population in that case, we need to make sure the overlapping terms\n        # are removed first\n        if self.args.compare:\n            common = pop & study\n            pop |= study\n            pop -= common\n            study -= common\n            sys.stderr.write(\"removed %d overlapping items\\n\" % (len(common)))\n            sys.stderr.write(\"Set 1: {0}, Set 2: {1}\\n\".format(\n                len(study), len(pop)))\n        return study, pop", "response": "Open files containing genes. Return study genes and population genes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a GrpWr object to write grouped GOEA results.", "response": "def get_objgrpwr(self, goea_results):\n        \"\"\"Get a GrpWr object to write grouped GOEA results.\"\"\"\n        sortobj = self.get_sortobj(goea_results)\n        return GrpWr(sortobj, self.pval_fld, ver_list=self.ver_list)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sortobj(self, goea_results, **kws):\n        nts_goea = MgrNtGOEAs(goea_results).get_goea_nts_prt(**kws)\n        goids = set(nt.GO for nt in nts_goea)\n        go2nt = {nt.GO:nt for nt in nts_goea}\n        grprobj = Grouper(\"GOEA\", goids, self.hdrobj, self.grprdflt.gosubdag, go2nt=go2nt)\n        grprobj.prt_summary(sys.stdout)\n        # hdrgo_prt\", \"section_prt\", \"top_n\", \"use_sections\"\n        sortobj = Sorter(grprobj, section_sortby=lambda nt: getattr(nt, self.pval_fld))\n        return sortobj", "response": "Return a Grouper object given a list of GOEnrichmentRecord objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_objaartall(self):\n        kws = {\n            'sortgo':lambda nt: [nt.NS, nt.dcnt],\n            # fmtgo=('{p_fdr_bh:8.2e} {GO} '\n            # Formatting for GO terms in grouped GO list\n            'fmtgo':('{hdr1usr01:2} {NS} {GO} {s_fdr_bh:8} '\n                     '{dcnt:5} {childcnt:3} R{reldepth:02} '\n                     '{D1:5} {GO_name} ({study_count} study genes)\\n'),\n            # Formatting for GO terms listed under each gene\n            'fmtgo2':('{hdr1usr01:2} {NS} {GO} {s_fdr_bh:8} '\n                      '{dcnt:5} R{reldepth:02} '\n                      '{GO_name} ({study_count} study genes)\\n'),\n            # itemid2name=ensmusg2symbol}\n            }\n        return AArtGeneProductSetsAll(self.grprdflt, self.hdrobj, **kws)", "response": "Get background database info for making ASCII art."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_outfiles_grouped(self, outfiles):\n        for outfile in outfiles:\n            if outfile.endswith(\".xlsx\"):\n                self.wr_xlsx(outfile)\n            elif outfile.endswith(\".txt\"):\n                self.wr_txt(outfile)\n            else:\n                self.wr_tsv(outfile)", "response": "Write to outfiles grouped by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wr_xlsx(self, fout_xlsx):\n        objwr = WrXlsxSortedGos(\"GOEA\", self.sortobj)\n        #### fld2fmt['ratio_in_study'] = '{:>8}'\n        #### fld2fmt['ratio_in_pop'] = '{:>12}'\n        #### ntfld2wbfmtdict = {\n        # ntfld_wbfmt = {\n        #     'ratio_in_study': {'align':'right'},\n        #     'ratio_in_pop':{'align':'right'}}\n        kws_xlsx = {\n            'title': self.ver_list,\n            'fld2fmt': {f:'{:8.2e}' for f in self.flds_cur if f[:2] == 'p_'},\n            #'ntfld_wbfmt': ntfld_wbfmt,\n            #### 'ntval2wbfmtdict': ntval2wbfmtdict,\n            #'hdrs': [],\n            'prt_flds': self.flds_cur}\n        objwr.wr_xlsx_nts(fout_xlsx, self.desc2nts, **kws_xlsx)", "response": "Print grouped GOEA results into an xlsx file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wr_tsv(self, fout_tsv):\n        with open(fout_tsv, 'w') as prt:\n            kws_tsv = {\n                'fld2fmt': {f:'{:8.2e}' for f in self.flds_cur if f[:2] == 'p_'},\n                'prt_flds':self.flds_cur}\n            prt_tsv_sections(prt, self.desc2nts['sections'], **kws_tsv)\n            print(\"  WROTE: {TSV}\".format(TSV=fout_tsv))", "response": "Print grouped GOEA results into a tab - separated file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wr_txt(self, fout_txt):\n        with open(fout_txt, 'w') as prt:\n            for line in self.ver_list:\n                prt.write(\"{LINE}\\n\".format(LINE=line))\n            self.prt_txt(prt)\n            print(\"  WROTE: {TXT}\".format(TXT=fout_txt))", "response": "Write to a file GOEA results in an ASCII text format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prt_tsv(self, prt=sys.stdout):\n        prtfmt = self.objprt.get_prtfmt_str(self.flds_cur)\n        prt.write(\"{FLDS}\\n\".format(FLDS=\" \".join(self.flds_cur)))\n        WrSectionsTxt.prt_sections(prt, self.desc2nts['sections'], prtfmt, secspc=True)", "response": "Print an ASCII text format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchoosing fields to print from a multitude of available fields.", "response": "def _init_flds_cur(self):\n        \"\"\"Choose fields to print from a multitude of available fields.\"\"\"\n        flds = []\n        # ('GO', 'NS', 'enrichment', 'name', 'ratio_in_study', 'ratio_in_pop', 'depth',\n        # 'p_uncorrected', 'p_bonferroni', 'p_sidak', 'p_holm', 'p_fdr_bh',\n        # 'pop_n', 'pop_count', 'pop_items'\n        # 'study_n', 'study_count', 'study_items',\n        # 'is_ratio_different', 'level', 'is_obsolete',\n        # 'namespace', 'reldepth', 'alt_ids', 'format_txt', 'hdr_idx',\n        # 'is_hdrgo', 'is_usrgo', 'num_usrgos', 'hdr1usr01', 'alt', 'GO_name',\n        # 'dcnt', 'D1', 'tcnt', 'tfreq', 'tinfo', 'childcnt', 'REL',\n        # 'REL_short', 'rel', 'id')\n        flds0 = ['GO', 'NS', 'enrichment', self.pval_fld, 'dcnt', 'tinfo', 'depth',\n                 'ratio_in_study', 'ratio_in_pop', 'name']\n        flds_p = [f for f in self.flds_all if f[:2] == 'p_' and f != self.pval_fld]\n        flds.extend(flds0)\n        if flds_p:\n            flds.extend(flds_p)\n        flds.append('study_count')\n        flds.append('study_items')\n        return flds"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand - line interface to print specified GO Terms from the DAG source.", "response": "def cli(self, prt=sys.stdout):\n        \"\"\"Command-line interface to print specified GO Terms from the DAG source .\"\"\"\n        kws = self.objdoc.get_docargs(prt=None)\n        print(\"KWS\", kws)\n        goids = GetGOs().get_goids(kws.get('GO'), kws.get('GO_FILE'), sys.stdout)\n        if not goids and 'name' in kws:\n            goids = self.objsub.get_goids(kws['obo'], kws['name'])\n        self.objsub.prt_goterms(kws['obo'], goids, prt, b_prt=False)\n        print(\"Printing {N:6} GO IDs: {GOs}\".format(N=len(goids), GOs=goids))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the header file and return specified data in a list of lists.", "response": "def get_h2i(self, hdrs_usr):\n        \"\"\"Read csv/tsv file and return specified data in a list of lists.\"\"\"\n        with open(self.fin) as fin_stream:\n            for line in fin_stream:\n                line = line.rstrip('\\r\\n') # chomp\n                if not self.hdr2idx:\n                    if self.do_hdr(line, hdrs_usr):\n                        return self.hdr2idx\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, fnc_name, hdrs_usr):\n        fnc = self.fncs[fnc_name]\n        with open(self.fin) as fin_stream:\n            for lnum, line in enumerate(fin_stream):\n                line = line.rstrip('\\r\\n') # chomp\n                # Obtain Data if headers have been collected from the first line\n                if self.hdr2idx:\n                    self._init_data_line(fnc, lnum, line)\n                # Obtain the header\n                else:\n                    self.do_hdr(line, hdrs_usr)\n            if self.log is not None:\n                self.log.write(\"  {:9} data READ:  {}\\n\".format(len(self.ret_list), self.fin))\n        return self.ret_list, self.hdr2idx", "response": "Read csv file and return specified data in a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_nts(self):\n        data = []\n        nt_obj = None\n        with open(self.fin) as fin_stream:\n            for lnum, line in enumerate(fin_stream, 1):\n                try:\n                    line = line.rstrip('\\r\\n') # chomp\n                    # Obtain Data if headers have been collected from the first line\n                    if nt_obj is not None:\n                        flds = re.split(self.sep, line)\n                        self.convert_ints_floats(flds)\n                        flds[6] = [s.strip() for s in flds[6].split(',')]\n                        ntdata = nt_obj._make(flds)\n                        data.append(ntdata)\n                    # Obtain the header\n                    else:\n                        nt_obj = self._init_nt_hdr(line)\n                except RuntimeError:\n                    # Print headers\n                    #if nt_obj is not None:\n                    #  sys.stdout.write(\"{HDRS}\\n\".format(HDRS='\\n'.join(nt_obj._fields)))\n                    flds = re.split(self.sep, line)\n                    print(len(flds), \"FIELDS\")\n                    print(flds)\n                    #raise Exception(\"{FIN}({LNUM}): {LINE}\\n\".format(\n                    #  FIN=self.fin, LNUM=lnum, LINE=line))\n                    # JUST SKIP LINES WITH INCOMPLETE DATA, BUT PRINT ERROR MESSAGE\n                    sys.stdout.write(\"**ERROR: {FIN}({LNUM}): {LINE}\\n\".format(\n                        FIN=self.fin, LNUM=lnum, LINE=line))\n            if self.log is not None:\n                self.log.write(\"  {:9} lines READ:  {}\\n\".format(len(data), self.fin))\n        return data", "response": "Read the CSV file and return specified data in a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform NCBI Gene header fields into valid namedtuple fields.", "response": "def hdr_xform(self, hdrs):\n        \"\"\"Transform NCBI Gene header fields into valid namedtuple fields.\"\"\"\n        xform = []\n        hdrs = self.replace_nulls(hdrs)\n        for hdr in hdrs:\n            hdr = hdr.replace('.', '_')\n            hdr = hdr.replace(' ', '_')\n            hdr = hdr.replace('#', 'N')\n            hdr = hdr.replace('-', '_')\n            hdr = hdr.replace('\"', '')\n            xform.append(hdr)\n        return xform"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_nt_hdr(self, line):\n        line = line.replace('.', '_')\n        line = line.replace(' ', '_')\n        line = line.replace('#', 'N')\n        line = line.replace('-', '_')\n        line = line.replace('\"', '')\n        #line = re.sub(r\"_$\", r\"\", line)\n        hdrs = re.split(self.sep, line)\n        if '' in hdrs:\n            hdrs = NCBIgeneFileReader.replace_nulls(hdrs)\n        # Init indexes which will be converted to int or float\n        self.idxs_int = [idx for idx, hdr in enumerate(hdrs) if hdr in self.int_hdrs]\n        self.idxs_float = [idx for idx, hdr in enumerate(hdrs) if hdr in self.float_hdrs]\n        assert hdrs[6] == 'Aliases'\n        return namedtuple('ntncbi', ' '.join(hdrs))", "response": "Convert headers into valid namedtuple fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_nulls(hdrs):\n        ret = []\n        idx = 0\n        for hdr in hdrs:\n            if hdr == '':\n                ret.append(\"no_hdr{}\".format(idx))\n            else:\n                ret.append(hdr)\n        return ret", "response": "Replace null in hdrs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a single data line.", "response": "def _init_data_line(self, fnc, lnum, line):\n        \"\"\"Process Data line.\"\"\"\n        fld = re.split(self.sep, line)\n        # Lines may contain different numbers of items.\n        # The line should have all columns requested by the user.\n        if self.usr_max_idx < len(fld):\n            self.convert_ints_floats(fld)\n            fnc(fld)\n        else:\n            for fld in enumerate(zip(self.hdr2idx.keys(), fld)):\n                print(fld)\n            for hdr in self.hdrs_usr:\n                print(hdr)\n            print('# ITEMS ON A LINE:', len(fld))\n            print('MAX USR IDX:', self.usr_max_idx)\n            raise Exception(\"ERROR ON LINE {} IN {}\".format(lnum+1, self.fin))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_ints_floats(self, flds):\n        for idx in self.idxs_float:\n            flds[idx] = float(flds[idx])\n        for idx in self.idxs_int:\n            dig = flds[idx]\n            #print 'idx={} ({}) {}'.format(idx, flds[idx], flds) # DVK\n            flds[idx] = int(flds[idx]) if dig.isdigit() else dig\n        for idx in self.idxs_strpat:\n            hdr = self.hdr2idx.items()[idx][0]\n            pat = self.strpat_hdrs[hdr]\n            flds[idx] = pat.format(flds[idx])", "response": "Convert strings to ints and floats if so specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes self. hdr2idx self. len self. usr_max_idx self. hdr2idx self. hdr2idx self. len self. idxs_float and self. idxs_int", "response": "def _init_hdr(self, line, hdrs_usr):\n        \"\"\"Initialize self.hdr2idx, self.len, self.idxs_float, and self.idxs_int\"\"\"\n        self.hdr2idx = OrderedDict([(v.strip(), i) for i, v in enumerate(re.split(self.sep, line))])\n        self.len = len(self.hdr2idx)\n        # If user is requesting specific data fields...\n        if hdrs_usr is not None:\n            # Loop through the user headers\n            for usr_hdr in hdrs_usr:\n                # If the user header is contained in the file....\n                if usr_hdr in self.hdr2idx:\n                    # Add the user header and the field index to a list\n                    self.hdrs_usr.append([usr_hdr, self.hdr2idx[usr_hdr]])\n                else:\n                    raise Exception(\"NO COLUMN({}) FOUND:\\n  HDR={}\\n\".format(\n                        hdrs_usr, '\\n  HDR='.join(self.hdr2idx.keys())))\n        usr_hdrs = [E[0] for E in self.hdrs_usr] if self.hdrs_usr else self.hdr2idx\n        self._init_idxs_float(usr_hdrs)\n        self._init_idxs_int(usr_hdrs)\n        self._init_idxs_strpat(usr_hdrs)\n        self.usr_max_idx = max(E[1] for E in self.hdrs_usr) if self.hdrs_usr else len(self.hdr2idx)-1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists of indexes whose values will be floats.", "response": "def _init_idxs_float(self, usr_hdrs):\n        \"\"\"List of indexes whose values will be floats.\"\"\"\n        self.idxs_float = [\n            Idx for Hdr, Idx in self.hdr2idx.items() if Hdr in usr_hdrs and Hdr in self.float_hdrs]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists of indexes whose values will be ints.", "response": "def _init_idxs_int(self, usr_hdrs):\n        \"\"\"List of indexes whose values will be ints.\"\"\"\n        self.idxs_int = [\n            Idx for Hdr, Idx in self.hdr2idx.items() if Hdr in usr_hdrs and Hdr in self.int_hdrs]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_idxs_strpat(self, usr_hdrs):\n        strpat = self.strpat_hdrs.keys()\n        self.idxs_strpat = [\n            Idx for Hdr, Idx in self.hdr2idx.items() if Hdr in usr_hdrs and Hdr in strpat]", "response": "List of indexes whose values will be strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(self, prt=sys.stdout):\n        kws = self.objdoc.get_docargs(prt=None)\n        if os.path.exists(kws['i']):\n            obj = NCBIgeneFileReader(kws['i'])\n            nts = obj.get_nts()\n            if nts:\n                geneid2nt = self._get_geneid2nt(nts)\n                self._wrpy_ncbi_gene_nts(kws['o'], geneid2nt, prt)\n        else:\n            raise RuntimeError(\"\\n{DOC}\\n**ERROR: NO FILE FOUND: {NCBI}\".format(\n                NCBI=kws['i'], DOC=__doc__))", "response": "Command - line interface to print specified GO Terms from the DAG source."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget geneid2nt given a list of namedtuples.", "response": "def _get_geneid2nt(nts):\n        \"\"\"Get geneid2nt given a list of namedtuples.\"\"\"\n        geneid2nt = {}\n        for ntd in nts:\n            geneid = ntd.GeneID\n            if geneid not in geneid2nt:\n                geneid2nt[geneid] = ntd\n            else:\n                print(\"DUPLICATE GeneID FOUND {N:9} {SYM}\".format(N=geneid, SYM=ntd.Symbol))\n        return geneid2nt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites namedtuples to a Python module.", "response": "def _wrpy_ncbi_gene_nts(fout_py, geneid2nt, log):\n        \"\"\"Write namedtuples to a dict in a Python module.\"\"\"\n        num_genes = len(geneid2nt)\n        with open(fout_py, 'w') as ofstrm:\n            docstr = \"Data downloaded from NCBI Gene converted into Python namedtuples.\"\n            ofstrm.write('\"\"\"{PYDOC}\"\"\"\\n\\n'.format(PYDOC=docstr))\n            ofstrm.write(\"from collections import namedtuple\\n\\n\")\n            ofstrm.write('WRITTEN = \"{DATE}\"'.format(\n                DATE=re.sub('-', '_', str(datetime.date.today()))))\n            ofstrm.write(' # {N} items\\n\\n'.format(N=num_genes))\n            ntd = next(iter(geneid2nt.values())) # Access one dictionary value in Python 2\n            ofstrm.write(\"#pylint: disable=line-too-long,too-many-lines,invalid-name\\n\")\n            ofstrm.write(\"{NtName} = namedtuple('{NtName}', '{FLDS}')\\n\\n\".format(\n                NtName=type(ntd).__name__, FLDS=' '.join(ntd._fields)))\n            ofstrm.write(\"GENEID2NT = {{ # {N:,} items\\n\".format(N=num_genes))\n            for geneid, ntd in sorted(geneid2nt.items(), key=lambda t: t[0]):\n                ofstrm.write(\"    {GeneID} : {NT},\\n\".format(GeneID=geneid, NT=ntd))\n            ofstrm.write(\"}\\n\")\n            log.write(\"  {N:9} geneids WROTE: {PY}\\n\".format(N=num_genes, PY=fout_py))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the association with GO IDs that are in the association.", "response": "def update_association(assc_gene2gos, go2obj):\n    \"\"\"Add the GO parents of a gene's associated GO IDs to the gene's association.\"\"\"\n    # Replaces update_association in GODag\n    goids_avail = set(go2obj)\n    # Get all assc GO IDs that are current\n    goid_sets = assc_gene2gos.values()\n    goids_assoc_all = set.union(*goid_sets)\n    goids_assoc_cur = goids_assoc_all.intersection(goids_avail)\n    # Get the subset of GO objects in the association\n    go2obj_assc = {go:go2obj[go] for go in goids_assoc_cur}\n    go2parents = get_go2parents_go2obj(go2obj_assc)\n    # Update the association: update the GO set for each gene\n    for goids_cur in goid_sets:\n        parents = set()\n        for goid in goids_cur.intersection(goids_avail):\n            parents.update(go2parents[goid])\n        goids_cur.update(parents)\n    goids_bad = goids_assoc_all.difference(goids_avail)\n    if goids_bad:\n        sys.stderr.write(\"{N} GO IDs NOT FOUND IN ASSOCIATION: {GOs}\\n\".format(\n            N=len(goids_bad), GOs=\" \".join(goids_bad)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a set of GO IDs that are unique in a GO2Object.", "response": "def get_go2obj_unique(go2obj):\n    \"\"\"If GO keys point to the same GOTerm, return new go2obj w/no duplicates.\"\"\"\n    # Find the unique GO Terms that are represented for each GO in go2obj\n    goid2gokeys = cx.defaultdict(set)\n    for goid, goobj in go2obj.items():\n        goid2gokeys[goobj.id].add(goid)\n    go_unique = set()\n    for goid, gos_seen in goid2gokeys.items():\n        # Return main GO ID, if it is present in the go2obj keys\n        if goid in gos_seen:\n            go_unique.add(goid)\n        # Otherwise return an alternate GO ID\n        else:\n            go_unique.add(next(iter(gos_seen)))\n    return go_unique"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_go2parents_go2obj(go2obj):\n    goobjs, altgo2goobj = get_goobjs_altgo2goobj(go2obj)\n    go2parents = get_id2parents(goobjs)\n    add_alt_goids(go2parents, altgo2goobj)\n    return go2parents", "response": "Return set of parent GO IDs for all GO IDs keys in go2obj."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_go2children_go2obj(go2obj):\n    goobjs, altgo2goobj = get_goobjs_altgo2goobj(go2obj)\n    go2children = get_id2children(goobjs)\n    add_alt_goids(go2children, altgo2goobj)\n    return go2children", "response": "Return go2children for all GO IDs keys in go2obj."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nseparating alt GO IDs and key GO IDs.", "response": "def get_goobjs_altgo2goobj(go2obj):\n    \"\"\"Separate alt GO IDs and key GO IDs.\"\"\"\n    goobjs = set()\n    altgo2goobj = {}\n    for goid, goobj in go2obj.items():\n        goobjs.add(goobj)\n        if goid != goobj.id:\n            altgo2goobj[goid] = goobj\n    return goobjs, altgo2goobj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_alt_goids(go2values, altgo2goobj):\n    for goobj_key in altgo2goobj.values():\n        values_curr = go2values[goobj_key.id]\n        for goid_alt in goobj_key.alt_ids:\n            go2values[goid_alt] = values_curr\n    return go2values", "response": "Add alternate source GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring main GO IDs are included in go2obj.", "response": "def fill_main_goids(go2obj, goids):\n    \"\"\"Ensure main GO IDs are included in go2obj.\"\"\"\n    # User GO IDs (goids) may be either main GO IDs or alternate GO IDs.\n    for goid in goids:\n        goobj = go2obj[goid]\n        # If a user specified an ALT GO ID and main GO ID not in go2obj:\n        if goid != goobj.id and goobj.id not in go2obj:\n            # Add main GO ID to go2obj\n            go2obj[goobj.id] = goobj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fill_altgoids(go2obj):\n    alt2obj = {altgo:goobj for goobj in go2obj.values() for altgo in goobj.alt_ids}\n    for goid, goobj in alt2obj.items():\n        go2obj[goid] = goobj", "response": "Given a go2obj containing key GO IDs fill with all alternate GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds GO IDs to go2obj that are involved in relationships.", "response": "def fill_relationshipobjs(go2obj, relationships):\n    \"\"\"Add GO IDs to go2obj that are involved in relationships.\"\"\"\n    # Get all GO Term record objects that have relationships\n    obj = RelationshipFill(go2obj, relationships)\n    for goobj in go2obj.values():\n        if goobj.relationship:\n            obj.fill_relationshipgo2obj(goobj)\n        if goobj.relationship_rev:\n            obj.fill_relationshiprevgo2obj(goobj)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fill_childgoid2obj(childgoid2obj, parent_obj):\n    for child_obj in parent_obj.children:\n        if child_obj.id not in childgoid2obj:\n            childgoid2obj[child_obj.id] = child_obj\n            fill_childgoid2obj(childgoid2obj, child_obj)", "response": "Fill childgoid2obj with all child key GO IDs and their objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds all the GO descendants under all user GO IDs. Return leaf - level GO IDs.", "response": "def get_leaf_children(gos_user, go2obj_arg):\n    \"\"\"Find all the GO descendants under all user GO IDs. Return leaf-level GO IDs.\"\"\"\n    childgoid2obj = {}\n    for goid_usr in gos_user:\n        goobj_usr = go2obj_arg[goid_usr]\n        fill_childgoid2obj(childgoid2obj, goobj_usr)\n    return set(go for go, o in childgoid2obj.items() if not o.children)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that all GO IDs have the proper format.", "response": "def chk_goids(goids, msg=None, raise_except=True):\n    \"\"\"check that all GO IDs have the proper format.\"\"\"\n    for goid in goids:\n        if not goid_is_valid(goid):\n            if raise_except:\n                raise RuntimeError(\"BAD GO({GO}): {MSG}\".format(GO=goid, MSG=msg))\n            else:\n                return goid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraversing GO Terms above the current GO Term. Then add current GO Term to sorted.", "response": "def _get_sorted_relationships(self, goterm):\n        \"\"\"Traverse GO Terms above the current GO Term. Then add current GO Term to sorted.\"\"\"\n        if goterm.id in self.goids_seen:\n            return\n        self.goids_seen.add(goterm.id)\n        for goterm_upper in goterm.get_goterms_upper():\n            self._get_sorted_relationships(goterm_upper)\n        self.goterms_sorted.append(goterm)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfill go2obj with all GO IDs and their objects.", "response": "def fill_relationshipgo2obj(self, goobj):\n        \"\"\"Fill go2obj with all relationship key GO IDs and their objects.\"\"\"\n        for reltyp, relgoobjs in goobj.relationship.items():\n            if reltyp in self.relationships:\n                for relgoobj in relgoobjs:\n                    if relgoobj.id not in self.go2obj:\n                        self.go2obj[relgoobj.id] = relgoobj\n                        self.fill_relationshipgo2obj(relgoobj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfill go2obj with all GO IDs and their objects.", "response": "def fill_relationshiprevgo2obj(self, goobj):\n        \"\"\"Fill go2obj with all relationship key GO IDs and their objects.\"\"\"\n        for reltyp, relgoobjs in goobj.relationship_rev.items():\n            if reltyp in self.relationships:\n                for relgoobj in relgoobjs:\n                    if relgoobj.id not in self.go2obj:\n                        self.go2obj[relgoobj.id] = relgoobj\n                        self.fill_relationshiprevgo2obj(relgoobj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread sections and GO IDs from file.", "response": "def read_sections(sections_file, exclude_ungrouped=False, prt=sys.stdout):\n    \"\"\"Get sections and GO grouping hdrgos from file, if sections exist.\"\"\"\n    if sections_file is None:\n        return None\n    assert isinstance(sections_file, str), \"BAD SECTIONS FILENAME({S})\".format(\n        S=sections_file)\n    if os.path.exists(sections_file):\n        return ReadGoids().read_sections(sections_file, False, exclude_ungrouped)\n    # Is 'sections_file' a module string?\n    if '/' not in sections_file and r'\\\\' not in sections_file and \\\n            pkgutil.find_loader(sections_file) is not None:\n        mod = importlib.import_module(sections_file)\n        var = getattr(mod, 'SECTIONS', None)\n        if var is not None:\n            dat = SummarySec2dHdrGos().summarize_sec2hdrgos(var)\n            print(Grouper.fmtsum.format(\n                GO_DESC='hdr', SECs=len(dat['S']), GOs=len(dat['G']),\n                UNGRP=\"N/A\", undesc=\"unused\", ACTION=\"IMPORTED: \", FILE=sections_file))\n            return var\n        raise RuntimeError(\"NO 'SECTIONS' VARIABLE FOUND IN MODULE({M})\".format(M=sections_file))\n    if prt:\n        prt.write(\"CANNOT READ: {SEC}\\n\".format(SEC=sections_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_goids(fin_txt, get_goids_only=False, exclude_ungrouped=False, prt=sys.stdout):\n    return ReadGoids().read_txt(fin_txt, get_goids_only, exclude_ungrouped, prt)", "response": "Read user list of GO IDs from a text file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_txt(self, fin_txt, get_goids_only, exclude_ungrouped, prt=sys.stdout):\n        goids_fin = self._read_txt(fin_txt, get_goids_only, exclude_ungrouped)\n        sections = self._read_finish(goids_fin, prt)\n        # Print summary of GO IDs read\n        if prt is not None:\n            self._prt_read_msg(prt, fin_txt, exclude_ungrouped)\n        return sections", "response": "Read user list of GO IDs from a text file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_py(self, fin_txt, get_goids_only, exclude_ungrouped, prt=sys.stdout):\n        goids_fin = self._read_py(fin_txt, get_goids_only, exclude_ungrouped)\n        sections = self._read_finish(goids_fin, prt)\n        # Print summary of GO IDs read\n        if prt is not None:\n            self._prt_read_msg(prt, fin_txt, exclude_ungrouped)\n        return sections", "response": "Read GO IDs or sections from a Python file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading sections variable from a text file of from a Python file.", "response": "def read_sections(self, sections_file, get_goids_only, exclude_ungrouped):\n        \"\"\"Read sections variable from a text file of from a Python file.\"\"\"\n        ext = os.path.splitext(sections_file)[1]\n        file_contents = None\n        if ext == '.py':\n            file_contents = self.read_py(sections_file, get_goids_only, exclude_ungrouped)\n        else:\n            file_contents = self.read_txt(sections_file, get_goids_only, exclude_ungrouped)\n        if file_contents:\n            return file_contents.get('sections', None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget one of goids or sections from reading a file.", "response": "def _read_finish(self, goids_fin, prt):\n        \"\"\"Get one of: {'goids':...} or {'sections':...} from reading a file.\"\"\"\n        # Report unused sections, if any\n        if len(self.section2goids) != len(self.sections_seen):\n            self._rpt_unused_sections(prt)\n        # If there are no sections, then goids_fin holds all GO IDs in file\n        if not self.sections_seen:\n            self.goids_fin = goids_fin\n\n        if goids_fin:\n            return self.internal_get_goids_or_sections()  # {'goids':...} or {'sections':...}\n        else:\n            sys.stdout.write(\n                \"\\n**WARNING: GO IDs MUST BE THE FIRST 10 CHARACTERS OF EACH LINE\\n\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads GO file. Store results in section2goids sections_seen. Return goids_fin.", "response": "def _read_txt(self, fin_txt, get_goids_only, exclude_ungrouped):\n        \"\"\"Read GO file. Store results in: section2goids sections_seen. Return goids_fin.\"\"\"\n        goids_sec = []\n        with open(fin_txt) as istrm:\n            # Lines starting with a GO ID will have that GO ID read and stored.\n            #   * Lines that do not start with a GO ID will be ignored.\n            #   * Text after the 10 characters in a GO ID will be ignored.\n            section_name = None\n            for line in istrm:\n                if line[:3] == \"GO:\":\n                    goids_sec.append(line[:10])\n                elif not get_goids_only and \":\" in line:\n                    mtch = self.srch_section.match(line)\n                    if mtch:\n                        secstr = mtch.group(1)\n                        if section_name is not None and goids_sec:\n                            self.section2goids[section_name] = goids_sec\n                        if not exclude_ungrouped or secstr != HdrgosSections.secdflt:\n                            section_name = secstr\n                            self.sections_seen.append(section_name)\n                        else:\n                            section_name = None\n                        goids_sec = []\n            if section_name is not None and goids_sec:\n                self.section2goids[section_name] = goids_sec\n        return goids_sec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_py(self, fin_py, get_goids_only, exclude_ungrouped):\n        goids_sec = []\n        with open(fin_py) as istrm:\n            section_name = None\n            for line in istrm:\n                mgo = self.srch_py_goids.search(line)     # Matches GO IDs in sections\n                if mgo:\n                    goids_sec.append(mgo.group(2))\n                elif not get_goids_only and \"[\" in line:\n                    msec = self.srch_py_section.search(line)  # Matches sections\n                    if msec:\n                        secstr = msec.group(3)\n                        if section_name is not None and goids_sec:\n                            self.section2goids[section_name] = goids_sec\n                        if not exclude_ungrouped or secstr != HdrgosSections.secdflt:\n                            section_name = secstr\n                            self.sections_seen.append(section_name)\n                        else:\n                            section_name = None\n                        goids_sec = []\n            if section_name is not None and goids_sec:\n                self.section2goids[section_name] = goids_sec\n        return goids_sec", "response": "Read Python sections file. Store section2goids sections_seen. Return goids_fin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef internal_get_goids_or_sections(self):\n        if self.goids_fin:\n            chk_goids(self.goids_fin, \"read_goids\")\n            return {'goids' : self.goids_fin}\n        else:\n            # Convert dict into 2D list retaining original section order\n            sections_2d = []\n            for section_name in self.sections_seen:\n                if section_name in self.section2goids:\n                    goids = self.section2goids.get(section_name)\n                    chk_goids(goids, \"GO IDs IN SECTION({S})\".format(S=section_name))\n                    sections_2d.append((section_name, goids))\n            return {'sections' : sections_2d}", "response": "Return GO IDs Sections or GOs or None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prt_read_msg(self, prt, fin_txt, exclude_ungrouped):\n        if self.sections_seen or exclude_ungrouped:\n            # dat = Grouper.get_summary_data(self.section2goids.items(), HdrgosSections.secdflt)\n            dat = SummarySec2dHdrGos().summarize_sec2hdrgos(self.section2goids.items())\n            sys.stdout.write(Grouper.fmtsum.format(\n                GO_DESC='hdr', SECs=len(dat['S']), GOs=len(dat['G']),\n                UNGRP=\"N/A\", undesc=\"unused\", ACTION=\"READ: \", FILE=fin_txt))\n        elif self.goids_fin:\n            prt.write(\"  {G} GO IDs READ: {FIN}\\n\".format(G=len(self.goids_fin), FIN=fin_txt))", "response": "Print which file was read and the number of GO IDs found."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a GoSubDag initialization object.", "response": "def get_edgesobj(gosubdag, **kws):\n    \"\"\"Return specfied GoSubDag initialization object.\"\"\"\n    # Keyword args (kws):\n    #     1. dst_srcs_list  Used for edges pruned such that only GO terms\n    #                       are retained which are between the sets of dst & srcs.\n    #     2  traverse_parent & traverse_child\n    #                       Used to generate a GoSubDag with all parent terms and/or\n    #                       all child terms, without pruning any paths.\n    # Call function, get_edgesobj, with:\n    #     get_edgesobj(go2obj, dst_srcs_list=...)\n    # Or any of:\n    #     get_edgesobj(go2obj, go_sources=...)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_parent=...,)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_child=...,)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_parent=..., traverse_child=...,)\n    edgeobj = _get_edgesobj(gosubdag, **kws)\n    rm_gos = kws.get('rm_gos')\n    if rm_gos is not None:\n        edgeobj.rm_gos(rm_gos)\n    return edgeobj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_edgesobj(gosubdag, **kws):\n    # Keyword args (kws):\n    #     1. dst_srcs_list  Used for edges pruned such that only GO terms\n    #                       are retained which are between the sets of dst & srcs.\n    #     2  traverse_parent & traverse_child\n    #                       Used to generate a GoSubDag with all parent terms and/or\n    #                       all child terms, without pruning any paths.\n    # Call function, get_edgesobj, with:\n    #     get_edgesobj(go2obj, dst_srcs_list=...)\n    # Or any of:\n    #     get_edgesobj(go2obj, go_sources=...)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_parent=...,)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_child=...,)\n    #     get_edgesobj(go2obj, go_sources=..., traverse_parent=..., traverse_child=...,)\n    dst_srcs_list = kws.get('dst_srcs_list', None)\n    if dst_srcs_list is not None:\n        return EdgesPath(gosubdag, dst_srcs_list)\n    return EdgesRelatives(gosubdag,\n                          kws.get('traverse_parent', True),\n                          kws.get('traverse_child', False))", "response": "Return a GoSubDag initialization object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rm_gos(self, rm_goids):\n        self.edges = self._rm_gos_edges(rm_goids, self.edges)\n        self.edges_rel = self._rm_gos_edges_rel(rm_goids, self.edges_rel)", "response": "Remove any edges that contain user - specified edges."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _rm_gos_edges_rel(self, rm_goids, edges_rel):\n        edges_ret = {}\n        for rname, edges_cur in edges_rel.items():\n            edges_new = self._rm_gos_edges(rm_goids, edges_cur)\n            if edges_new:\n                edges_ret[rname] = edges_new\n        return edges_ret", "response": "Remove any relationship that contains user - specified edges."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove any is_a edges that contain user - specified edges.", "response": "def _rm_gos_edges(rm_goids, edges_all):\n        \"\"\"Remove any is_a edges that contain user-specified edges.\"\"\"\n        edges_reduced = []\n        for goid_child, goid_parent in sorted(edges_all, key=lambda t: t[1]):\n            if goid_child not in rm_goids and goid_parent not in rm_goids:\n                edges_reduced.append((goid_child, goid_parent))\n        return edges_reduced"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all GO IDs that are connected to edges.", "response": "def get_all_edge_nodes(self):\n        \"\"\"Return a list of all GO IDs that are connected to edges.\"\"\"\n        edge_nodes = set(e for es in self.edges for e in es)\n        for edges in self.edges_rel.values():\n            rel_nodes = set(e for es in edges for e in es)\n            edge_nodes.update(rel_nodes)\n        return edge_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that all edge nodes exist in local subset.", "response": "def chk_edges(self):\n        \"\"\"Check that all edge nodes exist in local subset.\"\"\"\n        goids = set(self.go2obj)\n        self.chk_edges_nodes(self.edges, goids, \"is_a\")\n        for reltype, edges in self.edges_rel.items():\n            self.chk_edges_nodes(edges, goids, reltype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that user specified edges have a node which exists.", "response": "def chk_edges_nodes(edges, nodes, name):\n        \"\"\"Check that user specified edges have a node which exists.\"\"\"\n        edge_nodes = set(e for es in edges for e in es)\n        missing_nodes = edge_nodes.difference(nodes)\n        assert not missing_nodes, \"MISSING: {GOs}\\n{NM} EDGES MISSING {N} NODES (OF {T})\".format(\n            NM=name, N=len(missing_nodes), T=len(edge_nodes), GOs=missing_nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_c2ps(self):\n        c2ps = defaultdict(set)\n        for goid_child, goid_parent in self.edges:\n            c2ps[goid_child].add(goid_parent)\n        return c2ps", "response": "Set child2parents dict for all parents used in this set of edges."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getobjs_higher(self, goobj):\n        goobjs_higher = set(goobj.parents)\n        for reltyp, relgoobjs in goobj.relationship.items():\n            if reltyp in self.relationships:\n                goobjs_higher.update(relgoobjs)\n        return goobjs_higher", "response": "Get all GO objects that are higher GO objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_edges(p2cs, c2ps):\n        edge_from_to = []\n        for parent, children in p2cs.items():\n            for child in children:\n                # if child in goids_present and parent in goids_present:\n                edge_from_to.append((child, parent))\n        for parent, children in c2ps.items():\n            for child in children:\n                # if child in goids_present and parent in goids_present:\n                edge_from_to.append((child, parent))\n        return edge_from_to", "response": "Get the directed edges from GO term to GO term."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_edges_relationships(rel2src2dsts, rel2dst2srcs):\n        edge_rel2fromto = {}\n        relationships = set(rel2src2dsts).union(rel2dst2srcs)\n        for reltype in relationships:\n            edge_from_to = []\n            if reltype in rel2src2dsts:\n                for parent, children in rel2src2dsts[reltype].items():\n                    for child in children:\n                        edge_from_to.append((child, parent))\n            if reltype in rel2dst2srcs:\n                for parent, children in rel2dst2srcs[reltype].items():\n                    for child in children:\n                        edge_from_to.append((child, parent))\n            edge_rel2fromto[reltype] = edge_from_to\n        return edge_rel2fromto", "response": "Get the directed edges from GO term to GO term using relationships."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_rel2src2dsts(self, go_sources, traverse_parent):\n        if not traverse_parent or not self.relationships:\n            return {}\n        rel2src2dsts = {r:defaultdict(set) for r in self.relationships}\n        goids_seen = set()\n        go2obj = self.go2obj\n        for goid_src in go_sources:\n            goobj_src = go2obj[goid_src]\n            if goobj_src.relationship and goid_src not in goids_seen:\n                self._traverse_relationship_objs(rel2src2dsts, goobj_src, goids_seen)\n        return rel2src2dsts", "response": "Traverse up parents and return a dict of GO IDs to GO IDs that are referenced by GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _traverse_relationship_objs(self, rel2src2dsts, goobj_child, goids_seen):\n        child_id = goobj_child.id\n        goids_seen.add(child_id)\n        ##A self.go2obj[child_id] = goobj_child\n        # Update goids_seen and go2obj with child alt_ids\n        for goid_altid in goobj_child.alt_ids:\n            goids_seen.add(goid_altid)\n            ##A self.go2obj[goid_altid] = goobj_child\n        # Loop through relationships of child object\n        for reltype, recs in goobj_child.relationship.items():\n            if reltype in self.relationships:\n                for relationship_obj in recs:\n                    relationship_id = relationship_obj.id\n                    rel2src2dsts[reltype][relationship_id].add(child_id)\n                    # If relationship has not been seen, traverse\n                    if relationship_id not in goids_seen:\n                        self._traverse_relationship_objs(rel2src2dsts, relationship_obj, goids_seen)", "response": "Traverse from source GO up relationships."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_rel2dst2srcs(self, go_sources, traverse_child):\n        if not traverse_child or not self.relationships:\n            return {}\n        rel2dst2srcs = {r:defaultdict(set) for r in self.relationships}\n        goids_seen = set()\n        go2obj = self.go2obj\n        for goid_src in go_sources:\n            goobj_src = go2obj[goid_src]\n            if goid_src not in goids_seen:\n                self._traverse_relationship_rev_objs(rel2dst2srcs, goobj_src, goids_seen)\n        return rel2dst2srcs", "response": "Traverse through reverse relationships."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses from source GO down children.", "response": "def _traverse_relationship_rev_objs(self, rel2dst2srcs, goobj_parent, goids_seen):\n        \"\"\"Traverse from source GO down children.\"\"\"\n        parent_id = goobj_parent.id\n        goids_seen.add(parent_id)\n        ##A self.go2obj[parent_id] = goobj_parent\n        # Update goids_seen and go2obj with parent alt_ids\n        for goid_altid in goobj_parent.alt_ids:\n            goids_seen.add(goid_altid)\n            ##A self.go2obj[goid_altid] = goobj_parent\n        # Loop through children\n        for reltype, recs in goobj_parent.relationship.items():\n            if reltype in self.relationships:\n                for relrev_obj in recs:\n                    relrev_id = relrev_obj.id\n                    rel2dst2srcs[relrev_id].add(parent_id)\n                    # If child has not been seen, traverse\n                    if relrev_id not in goids_seen:\n                        ##F self._traverse_relrev_objs(rel2dst2srcs, relrev_obj, go2obj, goids_seen)\n                        self._traverse_relationship_rev_objs(rel2dst2srcs, relrev_obj, goids_seen)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntraverse up parent GO IDs and return a dict of p2c entries.", "response": "def _init_p2cs(self, go_sources, traverse_parent):\n        \"\"\"Traverse up parents.\"\"\"\n        if not traverse_parent:\n            return {}\n        p2cs = defaultdict(set)\n        goids_seen = set()\n        go2obj = self.go2obj\n        for goid_src in go_sources:\n            goobj_src = go2obj[goid_src]\n            if goid_src not in goids_seen:\n                ##F self._traverse_parent_objs(p2cs, goobj_src, go2obj, goids_seen)\n                self._traverse_parent_objs(p2cs, goobj_src, goids_seen)\n        return p2cs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntraverse from source GO up parents.", "response": "def _traverse_parent_objs(self, p2cs, goobj_child, goids_seen):\n        \"\"\"Traverse from source GO up parents.\"\"\"\n        # Update public(go2obj p2cs), private(goids_seen)\n        child_id = goobj_child.id\n        # mark child as seen\n        goids_seen.add(child_id)\n        ##A self.go2obj[child_id] = goobj_child\n        # Update goids_seen and go2obj with child alt_ids\n        for goid_altid in goobj_child.alt_ids:\n            goids_seen.add(goid_altid)\n            ##A self.go2obj[goid_altid] = goobj_child\n        # Loop through parents of child object\n        for parent_obj in goobj_child.parents:\n            parent_id = parent_obj.id\n            p2cs[parent_id].add(child_id)\n            # If parent has not been seen, traverse\n            if parent_id not in goids_seen:\n                ##F self._traverse_parent_objs(p2cs, parent_obj, go2obj, goids_seen)\n                self._traverse_parent_objs(p2cs, parent_obj, goids_seen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _traverse_child_objs(self, c2ps, goobj_parent, goids_seen):\n        # Update public(godag.go2obj godag.c2ps), private(_seen_pids)\n        parent_id = goobj_parent.id\n        # mark parent as seen\n        goids_seen.add(parent_id)\n        ##A self.go2obj[parent_id] = goobj_parent\n        # Update goids_seen and go2obj with parent alt_ids\n        for goid_altid in goobj_parent.alt_ids:\n            goids_seen.add(goid_altid)\n            ##A self.go2obj[goid_altid] = goobj_parent\n        # Loop through children\n        for child_obj in goobj_parent.children:\n            child_id = child_obj.id\n            c2ps[child_id].add(parent_id)\n            # If child has not been seen, traverse\n            if child_id not in goids_seen:\n                ##F self._traverse_child_objs(c2ps, child_obj, go2obj, goids_seen)\n                self._traverse_child_objs(c2ps, child_obj, goids_seen)", "response": "Traverse from source GO down children."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_edges(self, dst_srcs_list):\n        from goatools.gosubdag.go_paths import get_paths_goobjs, paths2edges\n        edges_all = set()\n        goid_all = set()\n        go2obj = self.go2obj\n        for dst, srcs in dst_srcs_list:\n            go2obj_srcs = {}\n            for goid in srcs:\n                go2obj_srcs[goid] = go2obj[goid]\n            go_paths, go_all = get_paths_goobjs(go2obj_srcs.values(), go_top=dst, go2obj=go2obj)\n            edges_all |= paths2edges(go_paths)\n            goid_all |= go_all\n        self.edges = [(a.id, b.id) for a, b in edges_all]\n        self.goid_all = goid_all", "response": "Create all GO edges given a list of ( dst srcs )."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_associations(self, fin_gaf, hdr_only, prt, allow_missing_symbol):\n        import timeit\n        tic = timeit.default_timer()\n        nts = self._read_gaf_nts(fin_gaf, hdr_only, allow_missing_symbol)\n        # GAF file has been read\n        if prt:\n            prt.write('HMS:{HMS} {N:7,} annotations READ: {ANNO}\\n'.format(\n                N=len(nts), ANNO=fin_gaf,\n                HMS=str(datetime.timedelta(seconds=(timeit.default_timer()-tic)))))\n        # If there are illegal GAF lines ...\n        if self.datobj:\n            if self.datobj.ignored or self.datobj.illegal_lines:\n                self.datobj.prt_error_summary(fin_gaf)\n        return nts", "response": "Read GAF file. Store annotation data in a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_gaf_nts(self, fin_gaf, hdr_only, allow_missing_symbol):\n        nts = []\n        ver = None\n        hdrobj = GafHdr()\n        datobj = None\n        # pylint: disable=not-callable\n        ntobj_make = None\n        get_gafvals = None\n        lnum = -1\n        line = ''\n        try:\n            with open(fin_gaf) as ifstrm:\n                for lnum, line in enumerate(ifstrm, 1):\n                    # Read data\n                    if get_gafvals:\n                        # print(lnum, line)\n                        gafvals = get_gafvals(line)\n                        if gafvals:\n                            nts.append(ntobj_make(gafvals))\n                        else:\n                            datobj.ignored.append((lnum, line))\n                    # Read header\n                    elif datobj is None:\n                        if line[0] == '!':\n                            if ver is None and line[1:13] == 'gaf-version:':\n                                ver = line[13:].strip()\n                            hdrobj.chkaddhdr(line)\n                        else:\n                            self.hdr = hdrobj.get_hdr()\n                            if hdr_only:\n                                return nts\n                            datobj = GafData(ver, allow_missing_symbol)\n                            get_gafvals = datobj.get_gafvals\n                            ntobj_make = datobj.get_ntobj()._make\n        except Exception as inst:\n            import traceback\n            traceback.print_exc()\n            sys.stderr.write(\"\\n  **FATAL-gaf: {MSG}\\n\\n\".format(MSG=str(inst)))\n            sys.stderr.write(\"**FATAL-gaf: {FIN}[{LNUM}]:\\n{L}\".format(FIN=fin_gaf, L=line, LNUM=lnum))\n            if datobj is not None:\n                datobj.prt_line_detail(sys.stdout, line)\n            sys.exit(1)\n        self.datobj = datobj\n        return nts", "response": "Read GAF file and store annotation data in a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_gafvals(self, line):\n        flds = line.split('\\t')\n\n        flds[3] = self._get_qualifier(flds[3])  # 3  Qualifier\n        flds[5] = self._get_set(flds[5])     # 5  DB_Reference\n        flds[7] = self._get_set(flds[7])     # 7  With_From\n        flds[8] = self.aspect2ns[flds[8]]    # 8 GAF Aspect field converted to BP, MF, or CC\n        flds[9] = self._get_set(flds[9])     # 9  DB_Name\n        flds[10] = self._get_set(flds[10])   # 10 DB_Synonym\n        flds[12] = self._do_taxons(flds[12])  # 12 Taxon\n        flds[13] = GET_DATE_YYYYMMDD(flds[13]) # self.strptime(flds[13], '%Y%m%d').date(),  # 13 Date   20190406\n\n        # Version 2.x has these additional fields not found in v1.0\n        if self.is_long:\n            flds[15] = get_extensions(flds[15])  # Extensions (or Annotation_Extension)\n            flds[16] = self._get_set(flds[16].rstrip())\n        else:\n            flds[14] = self._get_set(flds[14].rstrip())\n        return flds", "response": "Convert fields from string to preferred format for GAF ver 2. 1 and 2. 0."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget qualifiers. Correct for inconsistent capitalization in GAF files", "response": "def _get_qualifier(val):\n        \"\"\"Get qualifiers. Correct for inconsistent capitalization in GAF files\"\"\"\n        quals = set()\n        if val == '':\n            return quals\n        for val in val.split('|'):\n            val = val.lower()\n            quals.add(val if val != 'not' else 'NOT')\n        return quals"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfurthers split a GAF value within a single field.", "response": "def _chk_fld(self, ntd, name, qty_min=0, qty_max=None):\n        \"\"\"Further split a GAF value within a single field.\"\"\"\n        vals = getattr(ntd, name)\n        num_vals = len(vals)\n        if num_vals < qty_min:\n            self.illegal_lines['MIN QTY'].append(\n                (-1, \"FIELD({F}): MIN QUANTITY({Q}) WASN'T MET: {V}\".format(F=name, Q=qty_min, V=vals)))\n        if qty_max is not None:\n            if num_vals > qty_max:\n                self.illegal_lines['MAX QTY'].append(\n                    (-1, \"FIELD({F}): MAX QUANTITY({Q}) EXCEEDED: {V}\\n{NT}\".format(\n                        F=name, Q=qty_max, V=vals, NT=ntd)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _chk_qualifier(self, qualifiers, flds, lnum):\n        # http://geneontology.org/page/go-annotation-conventions#qual\n        for qual in qualifiers:\n            if qual not in AnnoReaderBase.exp_qualifiers:\n                errname = 'UNEXPECTED QUALIFIER({QUAL})'.format(QUAL=qual)\n                self.illegal_lines[errname].append((lnum, \"\\t\".join(flds)))", "response": "Check that qualifiers are expected values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint line header and values in a readable format.", "response": "def prt_line_detail(self, prt, line):\n        \"\"\"Print line header and values in a readable format.\"\"\"\n        values = line.split('\\t')\n        self._prt_line_detail(prt, values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prt_line_detail(self, prt, values, lnum=\"\"):\n        #### data = zip(self.req_str, self.ntgafobj._fields, values)\n        data = zip(self.req_str, self.flds, values)\n        txt = [\"{:2}) {:3} {:20} {}\".format(i, req, hdr, val) for i, (req, hdr, val) in enumerate(data)]\n        prt.write(\"{LNUM}\\n{TXT}\\n\".format(LNUM=lnum, TXT=\"\\n\".join(txt)))", "response": "Print header and field values in a readable format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _chk_qty_eq_1(self, flds):\n        for col in self.req1:\n            if not flds[col]:\n                self.illegal_lines['QTY 1'].append(\n                    (-1, \"**ERROR: UNEXPECTED REQUIRED VAL({V}) FOR COL({R}):{H}: \".format(\n                        V=flds[col], H=self.gafhdr[col], R=col)))\n                self.illegal_lines['QTY 1'].append((-1, \"{H0}({DB}) {H1}({ID})\\n\".format(\n                    H0=self.gafhdr[0], DB=flds[0], H1=self.gafhdr[1], ID=flds[1])))", "response": "Check that these fields have only one value required 1."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of taxon ids from a taxon string", "response": "def _do_taxons(self, taxon_str):\n        \"\"\"Taxon\"\"\"\n        taxons = self._get_list(taxon_str)\n        taxons_str = [v.split(':')[1] for v in taxons] # strip \"taxon:\"\n        taxons_int = [int(s) for s in taxons_str if s]\n        return taxons_int"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prt_error_summary(self, fout_err):\n        # Get summary of error types and their counts\n        errcnts = []\n        if self.ignored:\n            errcnts.append(\"  {N:9,} IGNORED associations\\n\".format(N=len(self.ignored)))\n        if self.illegal_lines:\n            for err_name, errors in self.illegal_lines.items():\n                errcnts.append(\"  {N:9,} {ERROR}\\n\".format(N=len(errors), ERROR=err_name))\n        # Save error details into a log file\n        fout_log = self._wrlog_details_illegal_gaf(fout_err, errcnts)\n        sys.stdout.write(\"  WROTE GAF ERROR LOG: {LOG}:\\n\".format(LOG=fout_log))\n        for err_cnt in errcnts:\n            sys.stdout.write(err_cnt)", "response": "Print a summary about the GAF file that was read."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wrlog_details_illegal_gaf(self, fout_err, err_cnts):\n        # fout_err = \"{}.log\".format(fin_gaf)\n        gaf_base = os.path.basename(fout_err)\n        with open(fout_err, 'w') as prt:\n            prt.write(\"ILLEGAL GAF ERROR SUMMARY:\\n\\n\")\n            for err_cnt in err_cnts:\n                prt.write(err_cnt)\n            prt.write(\"\\n\\nILLEGAL GAF ERROR DETAILS:\\n\\n\")\n            for lnum, line in self.ignored:\n                prt.write(\"**WARNING: GAF LINE IGNORED: {FIN}[{LNUM}]:\\n{L}\\n\".format(\n                    FIN=gaf_base, L=line, LNUM=lnum))\n                self.prt_line_detail(prt, line)\n                prt.write(\"\\n\\n\")\n            for error, lines in self.illegal_lines.items():\n                for lnum, line in lines:\n                    prt.write(\"**WARNING: GAF LINE ILLEGAL({ERR}): {FIN}[{LNUM}]:\\n{L}\\n\".format(\n                        ERR=error, FIN=gaf_base, L=line, LNUM=lnum))\n                    self.prt_line_detail(prt, line)\n                    prt.write(\"\\n\\n\")\n        return fout_err", "response": "Print details regarding illegal GAF lines seen to a log file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_relationship_dicts(self):\n        if not self.relationships:\n            return None\n        for goid, goobj in self.go2obj.items():\n            for reltyp, relset in goobj.relationship.items():\n                relfwd_goids = set(o.id for o in relset)\n                # for relfwd_goid in relfwd_goids:\n                #     assert relfwd_goid in self.go2obj, \"{GO} {REL} NOT FOUND {GO_R}\".format(\n                #         GO=goid, REL=reltyp, GO_R=relfwd_goid)\n                print(\"CountRelativesInit RELLLLS\", goid, goobj.id, reltyp, relfwd_goids)", "response": "Given GO DAG relationships return summaries per GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_goone2ntletter(self, go2dcnt, depth2goobjs):\n        # 1. Group level-01/depth-01 GO terms by namespace\n        ns2dcntgoobj = cx.defaultdict(list)\n        for goobj in depth2goobjs[1]:\n            dcnt = go2dcnt[goobj.id]\n            ns2dcntgoobj[goobj.namespace].append((dcnt, goobj))\n        # 2. Assign letters to level-01/depth-01 GO terms\n        go2nt = {}\n        ntobj = cx.namedtuple(\"NtGoLetters\", \"D1 dcnt goobj\")\n        _go2abc = self.go2letter\n        letters = list(chain(range(ord('A'), ord('Z') + 1), range(ord('a'), ord('z') + 1)))\n        for list_dcnt_goobj in ns2dcntgoobj.values():\n            letter_idx = 0\n            for dcnt, goobj in sorted(list_dcnt_goobj, key=lambda t: t[0], reverse=True):\n                letter = chr(letters[letter_idx]) if _go2abc is None else _go2abc.get(goobj.id, '')\n                go2nt[goobj.id] = ntobj._make([letter, dcnt, goobj])\n                letter_idx += 1\n        return go2nt", "response": "Assign letters to depth - 01 GO terms ordered using descendants cnt."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_depth2goobjs(go2obj, max_depth=2):\n        depth2goobjs = {d:list() for d in range(max_depth+1)}\n        goid_seen = set()\n        for _, goobj in sorted(go2obj.items(), key=lambda t: t[1].depth):\n            # Save depth-00, depth-01, depth-02\n            if goobj.depth > max_depth:\n                break\n            goid = goobj.id\n            if not goobj.is_obsolete and goid not in goid_seen:\n                depth2goobjs[goobj.depth].append(goobj)\n                goid_seen.add(goid)\n        return depth2goobjs", "response": "Init depth2goobjs using list sorted by depth get level - 01 and level - 02 GO terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_goslims(self, dagslim):\n        go2obj_main = self.gosubdag.go2obj\n        go2obj_slim = {go for go, o in dagslim.items() if go in go2obj_main}\n        if self.gosubdag.relationships:\n            return self._get_goslimids_norel(go2obj_slim)\n        return set(dagslim.keys())", "response": "Get GO IDs in GO slims."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_gos_d0d1(self):\n        return set([o.id for d in [0, 1] for o in self.gosubdag.rcntobj.depth2goobjs.get(d)])", "response": "Return set of GO IDs whose depth is 0 and whose depth is 1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_goslimids_norel(self, dagslim):\n        go_slims = set()\n        go2obj = self.gosubdag.go2obj\n        for goid in dagslim:\n            goobj = go2obj[goid]\n            if not goobj.relationship:\n                go_slims.add(goobj.id)\n        return go_slims", "response": "Get all GO slims that do not have a relationship."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_gosubdag(gosubdag=None):\n        if gosubdag is not None:\n            if gosubdag.rcntobj is not None:\n                return gosubdag\n            else:\n                gosubdag.init_auxobjs()\n                return gosubdag\n        else:\n            go2obj = get_godag()\n            return GoSubDag(None, go2obj, rcntobj=True)", "response": "Gets a GoSubDag initialized for use by a Grouper object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning user - specified keyword args in a dictionary and a set.", "response": "def extract_kwargs(args, exp_keys, exp_elems):\n    \"\"\"Return user-specified keyword args in a dictionary and a set (for True/False items).\"\"\"\n    arg_dict = {}    # For arguments that have values\n    arg_set = set()  # For arguments that are True or False (present in set if True)\n    for key, val in args.items():\n        if exp_keys is not None and key in exp_keys and val:\n            arg_dict[key] = val\n        elif exp_elems is not None and key in exp_elems and val:\n            arg_set.add(key)\n    return {'dict':arg_dict, 'set':arg_set}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn user - specified keyword args in a dictionary and a set ( for True or False items.", "response": "def get_kwargs_set(args, exp_elem2dflt):\n    \"\"\"Return user-specified keyword args in a dictionary and a set (for True/False items).\"\"\"\n    arg_set = set()  # For arguments that are True or False (present in set if True)\n    # Add user items if True\n    for key, val in args.items():\n        if exp_elem2dflt is not None and key in exp_elem2dflt and val:\n            arg_set.add(key)\n    # Add defaults if needed\n    for key, dfltval in exp_elem2dflt.items():\n        if dfltval and key not in arg_set:\n            arg_set.add(key)\n    return arg_set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_kwargs(args, exp_keys, exp_elems):\n    arg_dict = {}    # For arguments that have values\n    for key, val in args.items():\n        if exp_keys is not None and key in exp_keys and val:\n            if isinstance(val, str):\n                val = val.strip()\n            arg_dict[key] = val\n        elif exp_elems is not None and key in exp_elems and val:\n            arg_dict[key] = True\n    return arg_dict", "response": "Return user - specified keyword args in a dictionary and a set ( for True / False items."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nkeep annotaion if it passes potentially modified selection.", "response": "def getfnc_qual_ev(self):\n        \"\"\"Keep annotaion if it passes potentially modified selection.\"\"\"\n        fnc_key = (\n            self.nd_not2desc[(self._keep_nd, self._keep_not)],\n            self.incexc2num[(\n                self.include_evcodes is not None,\n                self.exclude_evcodes is not None)],\n        )\n        return self.param2fnc[fnc_key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mapslim(go_term, go_dag, goslim_dag):\n    # check parameters\n    if not isinstance(go_dag, GODag):\n        raise TypeError(\"go_dag must be an instance of GODag\")\n    if not isinstance(goslim_dag, GODag):\n        raise TypeError(\"goslim_dag must be an instance of GODag\")\n    if go_term not in go_dag:\n        raise ValueError(\"go_term must be an accession that is in the go_dag\")\n\n    all_ancestors = set()\n    covered_ancestors = set()\n\n    # get all paths for the term in the go_dag\n    paths = go_dag.paths_to_top(go_term)\n    for path in paths:\n        # the next loop needs to run bottom->up, i.e. from the go_term item to\n        # the root, thus we need to reverse the list prior to iteration\n        path.reverse()\n\n        got_leaf = False\n        for term in path:\n            if term.id in goslim_dag:\n                all_ancestors.add(term.id)\n                if got_leaf:\n                    covered_ancestors.add(term.id)\n                got_leaf = True\n\n    # get the direct ancestors, i.e. those that are not covered by a earlier\n    # ancestor of the GO-Slim in _any_ path (in bottom->top order)\n    direct_ancestors = all_ancestors - covered_ancestors\n    return direct_ancestors, all_ancestors", "response": "Maps a GO term to its GO - Slim terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_kws(self):\n        ret = self.kws['dict'].copy()\n        act_set = self.kws['set']\n        if 'shorten' in act_set and 'goobj2fncname' not in ret:\n            ret['goobj2fncname'] = ShortenText().get_short_plot_name\n        return ret", "response": "Only load keywords if they are specified by the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning hdr line seen inside a GO Term box.", "response": "def str_fmthdr(self, goid, goobj):\n        \"\"\"Return hdr line seen inside a GO Term box.\"\"\"\n        # Shorten: Ex: GO:0007608 -> G0007608\n        go_txt = goid.replace(\"GO:\", \"G\")\n        if 'mark_alt_id' in self.present and goid != goobj.id:\n            go_txt += 'a'\n        return go_txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string to be printed in a GO term box.", "response": "def get_node_text(self, goid, goobj):\n        \"\"\"Return a string to be printed in a GO term box.\"\"\"\n        txt = []\n        # Header line: \"GO:0036464 L04 D06\"\n        txt.append(self.get_hdr(goid, goobj))\n        # GO name line: \"cytoplamic ribonucleoprotein\"\n        if 'no_name' not in self.present:\n            txt.append(self._get_go_name(goobj))\n        # study info line: \"24 genes\"\n        if 'objgoea' in self.kws:\n            study_txt = self.kws['objgoea'].get_study_txt(goid)\n            if study_txt is not None:\n                txt.append(study_txt)\n        # Add user-specified text, if needed\n        if 'go2txt' in self.kws and goid in self.kws['go2txt']:\n            txt.append(self.kws['go2txt'][goid])\n        return \"\\n\".join(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_go_name(self, goobj):\n        if 'goobj2fncname' not in self.kws:\n            return goobj.name.replace(\",\", \"\\n\")\n        # Return GO Term name edited by user-provided function\n        return self.kws['goobj2fncname'](goobj)", "response": "Return GO Term name as is or edited by a user - provided function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns header for a GO Term box.", "response": "def get_hdr(self, goid, goobj):\n        \"\"\"Header for GO Term box. Ex: 'G0001719 L6 D9 d3.'\"\"\"\n        hdr = []\n        ntgo = self.gosubdag.go2nt.get(goid)\n        prt_flds = self._get_prtflds()\n        # Add letter to depth-01 GO Node.\n        if 'D1' in prt_flds and goobj.depth == 1:\n            hdr.append(\"{ABC} \".format(ABC=ntgo.D1))\n        hdr.append(self.str_fmthdr(goid, goobj))\n        if 'level' in prt_flds:\n            hdr.append(\"L{level}\".format(level=goobj.level))\n        if 'depth' in prt_flds:\n            hdr.append(\"D{depth}\".format(depth=goobj.depth))\n        if 'reldepth' in prt_flds:\n            hdr.append(\"R{reldepth}\".format(reldepth=goobj.reldepth))\n        # Print count of parents for this GO term\n        if 'c2ps' in self.kws:\n            self._add_parent_cnt(hdr, goobj, self.kws['c2ps'])\n        # Print count of children for this GO term\n        childcnt_str = self._get_hdr_childcnt(goobj, ntgo)\n        if childcnt_str:\n            hdr.append(childcnt_str)\n        # Print count of all descendants down to the leaf-level for this GO term\n        if 'dcnt' in prt_flds:\n            hdr.append(\"d{N}\".format(N=ntgo.dcnt))\n        if 'tinfo' in prt_flds:\n            hdr.append(\"i{I:4.02f}\".format(I=ntgo.tinfo))\n        if 'REL' in prt_flds:\n            hdr.append(\"{R}\".format(R=ntgo.REL_short))\n        return \" \".join(hdr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget print fields for GO header.", "response": "def _get_prtflds(self):\n        \"\"\"Get print fields for GO header.\"\"\"\n        # User-specified print fields\n        ntflds = self.gosubdag.prt_attr['flds']\n        prt_flds = self.kws.get('prt_flds')\n        if prt_flds:\n            return prt_flds.intersection(ntflds)\n        exclude = set()\n        # Default print fields\n        if self.gosubdag.relationships:\n            exclude.add('level')\n        return set(f for f in ntflds if f not in exclude)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget string representing count of children for this GO term.", "response": "def _get_hdr_childcnt(self, goobj, ntgo):\n        \"\"\"Get string representing count of children for this GO term.\"\"\"\n        if 'childcnt' in self.present:\n            return \"c{N}\".format(N=len(goobj.children))\n        elif self.gosubdag.relationships and not goobj.children and ntgo.dcnt != 0:\n            return \"c0\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_parent_cnt(self, hdr, goobj, c2ps):\n        if goobj.id in c2ps:\n            parents = c2ps[goobj.id]\n            if 'prt_pcnt' in self.present or parents and len(goobj.parents) != len(parents):\n                assert len(goobj.parents) == len(set(goobj.parents))\n                hdr.append(\"p{N}\".format(N=len(set(goobj.parents))))", "response": "Add the parent count to the GO term box for if not all parents are plotted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prt_summary_anno2ev(self, prt=sys.stdout):\n        prt.write('**NOTE: No evidence codes in associations: {F}\\n'.format(F=self.filename))", "response": "Print a summary of all Evidence Codes seen in annotations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_id2gos(self, **kws):\n        return self._get_id2gos(self.associations, **kws) if kws else self.id2gos", "response": "Return associations as a dict : id2gos"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_associations(self, fin_anno):\n        ini = InitAssc(fin_anno, self.godag)\n        # self.hdr = ini.flds\n        self.id2gos = ini.id2gos\n        return ini.nts", "response": "Read an annotation file and store a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncounts the number of terms in the study group", "response": "def count_terms(geneset, assoc, obo_dag):\n    \"\"\"count the number of terms in the study group\n    \"\"\"\n    term_cnt = Counter()\n    for gene in (g for g in geneset if g in assoc):\n        for goid in assoc[gene]:\n            if goid in obo_dag:\n                term_cnt[obo_dag[goid].id] += 1\n\n    return term_cnt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the terms in the study group", "response": "def get_terms(desc, geneset, assoc, obo_dag, log):\n    \"\"\"Get the terms in the study group\n    \"\"\"\n    _chk_gene2go(assoc)\n    term2itemids = defaultdict(set)\n    genes = [g for g in geneset if g in assoc]\n    for gene in genes:\n        for goid in assoc[gene]:\n            if goid in obo_dag:\n                term2itemids[obo_dag[goid].id].add(gene)\n    if log is not None:\n        num_stu = len(genes)\n        num_pop = len(geneset)\n        perc = 100.0*num_stu/num_pop if num_pop != 0 else 0.0\n        log.write(\"{P:3.0f}% {N:>6,} of {M:>6,} {DESC} items found in association\\n\".format(\n            DESC=desc, N=num_stu, M=num_pop, P=perc))\n    return term2itemids"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the ratio go / n is different between the study group and population group and the population group", "response": "def is_ratio_different(min_ratio, study_go, study_n, pop_go, pop_n):\n    \"\"\"\n    check if the ratio go /n is different between the study group and\n    the population\n    \"\"\"\n    if min_ratio is None:\n        return True\n    stu_ratio = float(study_go) / study_n\n    pop_ratio = float(pop_go) / pop_n\n    if stu_ratio == 0.0:\n        stu_ratio = 0.0000001\n    if pop_ratio == 0.0:\n        pop_ratio = 0.0000001\n    if stu_ratio > pop_ratio:\n        return stu_ratio / pop_ratio > min_ratio\n    return pop_ratio / stu_ratio > min_ratio"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that associations are gene2go not go2gene.", "response": "def _chk_gene2go(assoc):\n    \"\"\"Check that associations is gene2go, not go2gene.\"\"\"\n    if not assoc:\n        raise RuntimeError(\"NO ITEMS FOUND IN ASSOCIATIONS {A}\".format(A=assoc))\n    for key in assoc:\n        if isinstance(key, str) and key[:3] == \"GO:\":\n            raise Exception(\"ASSOCIATIONS EXPECTED TO BE gene2go, NOT go2gene: {EX}\".format(\n                EX=assoc.items()[:2]))\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_usrgos(self, goids):\n        usrgos = set()\n        goids_missing = set()\n        _go2obj = self.gosubdag.go2obj\n        for goid in goids:\n            if goid in _go2obj:\n                usrgos.add(goid)\n            else:\n                goids_missing.add(goid)\n        if goids_missing:\n            print(\"MISSING GO IDs: {GOs}\".format(GOs=goids_missing))\n            print(\"{N} of {M} GO IDs ARE MISSING\".format(N=len(goids_missing), M=len(goids)))\n        return usrgos", "response": "Return user GO IDs which have GO Terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_gos_all(self):\n        gos_all = set()\n        # Get:\n        #   * Header GO IDs that are not user GO IDs\n        #   * User GO IDs that are under header GOs\n        for hdrgo, usrgos in self.hdrgo2usrgos.items():\n            gos_all.add(hdrgo)\n            gos_all |= usrgos\n        # User GO IDs that are header GOs in groups containing no other user GO IDs\n        gos_all |= self.hdrgo_is_usrgo\n        assert gos_all == self.usrgos.union(set(self.hdrgo2usrgos.keys()))\n        assert len(self.usrgos.difference(gos_all)) == 0, \\\n            \"GROUPER ERROR: {GOs}\".format(GOs=self.usrgos.difference(gos_all))\n        return gos_all", "response": "Return a flat list of all GO IDs in grouping object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_h2us(self, fnc_most_specific):\n        # Header GO IDs are main. User GO IDs are as specified by the user\n        hdrgo2usrgos = cx.defaultdict(set)\n        # Contains user GO IDs which are also header GO IDs, plus user main GO if needed\n        hdrgo_is_usrgo = set()\n        _go2nt = self.gosubdag.go2nt\n        objhi = GrouperInit.GetGoidHigh(self.gosubdag, self.hdrobj.hdrgos,\n                                        self.most_specific_fncs[fnc_most_specific])\n        for goid_usr in self.usrgos:\n            goid_main = _go2nt[goid_usr].id\n            # Add current GO ID to parents_all in case curr GO ID is a high GO.\n            goid_high = objhi.get_goid_high(goid_main)\n            # Don't add user GO ID if it is also the GO header\n            if goid_main != goid_high:\n                hdrgo2usrgos[goid_high].add(goid_usr)\n            elif goid_high not in hdrgo2usrgos:\n                hdrgo2usrgos[goid_high] = set()\n            if goid_main == goid_high:\n                hdrgo_is_usrgo.add(goid_main)\n                if goid_main != goid_usr:\n                    hdrgo_is_usrgo.add(goid_usr)\n        # Initialize data members\n        self.hdrgo2usrgos = hdrgo2usrgos\n        self.hdrgo_is_usrgo = hdrgo_is_usrgo", "response": "Given a set of user GO IDs return a set of GO ids grouped under the GO high terms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncombine user namedtuple fields GO object fields and format_txt.", "response": "def get_go2nt(self, usr_go2nt):\n        \"\"\"Combine user namedtuple fields, GO object fields, and format_txt.\"\"\"\n        gos_all = self.get_gos_all()\n        # Minimum set of namedtuple fields available for use with Sorter on grouped GO IDs\n        prt_flds_all = get_hdridx_flds() + self.gosubdag.prt_attr['flds']\n        if not usr_go2nt:\n            return self.__init_go2nt_dflt(gos_all, prt_flds_all)\n        usr_nt_flds = next(iter(usr_go2nt.values()))._fields\n        # If user namedtuple already contains all fields available, then return usr_go2nt\n        if len(set(prt_flds_all).difference(usr_nt_flds)) == 0:\n            return self._init_go2nt_aug(usr_go2nt)\n        # Otherwise, combine user fields and default Sorter fields\n        return self.__init_go2nt_w_usr(gos_all, usr_go2nt, prt_flds_all)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncombines GO object fields and format_txt.", "response": "def __init_go2nt_dflt(self, gos_all, prt_flds_all):\n        \"\"\"Combine GO object fields and format_txt.\"\"\"\n        go2nts = [self.gosubdag.go2nt, self._get_go2nthdridx(gos_all)]\n        go2nt = get_dict_w_id2nts(gos_all, go2nts, prt_flds_all)\n        return self._init_go2nt_aug(go2nt)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncombining GO object fields and format_txt.", "response": "def __init_go2nt_w_usr(self, gos_all, usr_go2nt, prt_flds_all):\n        \"\"\"Combine GO object fields and format_txt.\"\"\"\n        assert usr_go2nt, \"go2nt HAS NO ELEMENTS\"\n        from goatools.nt_utils import get_unique_fields\n        go2nts = [usr_go2nt, self.gosubdag.go2nt, self._get_go2nthdridx(gos_all)]\n        usr_nt_flds = next(iter(usr_go2nt.values()))._fields # Get any single value from a dict\n        flds = get_unique_fields([usr_nt_flds, prt_flds_all])\n        go2nt = get_dict_w_id2nts(gos_all, go2nts, flds)\n        return self._init_go2nt_aug(go2nt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naugments go2nt with GO ID key to account for alt GO IDs.", "response": "def _init_go2nt_aug(self, go2nt):\n        \"\"\"Augment go2nt with GO ID key to account for alt GO IDs.\"\"\"\n        go2obj = self.gosubdag.go2obj\n        # Get alt GO IDs\n        go2nt_aug = {}\n        # NOW\n        for goid_usr, nt_usr in go2nt.items():\n            goobj = go2obj[goid_usr]\n            if goobj.alt_ids:\n                alts = set(goobj.alt_ids)\n                alts.add(goobj.id)\n                for goid_alt in alts:\n                    if goid_alt not in go2nt:\n                        go2nt_aug[goid_alt] = nt_usr\n        # WAS\n        # Add alt GO IDs to go2nt\n        for goid, gont in go2nt_aug.items():\n            go2nt[goid] = gont\n        return go2nt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_go2nthdridx(self, gos_all):\n        go2nthdridx = {}\n        # NtHdrIdx Namedtuple fields:\n        #   * format_txt: Used to determine the format when writing Excel cells\n        #   * hdr_idx: Value printed in an Excel cell\n        # shortcuts\n        obj = GrouperInit.NtMaker(self)\n        # Create go2nthdridx\n        for goid in gos_all:\n            go2nthdridx[goid] = obj.get_nt(goid)\n        return go2nthdridx", "response": "Get GO IDs header index for each user GO ID and corresponding parent GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_dflt(self):\n        nts = []\n        ntobj = cx.namedtuple('ntanno', self.flds)\n        for itemid, gos in self.id2gos.items():\n            for goid in gos:\n                nts.append(ntobj(DB_ID=itemid, GO_ID=goid))\n        return nts", "response": "Get a list of namedtuples one for each annotation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _init_w_godag(self):\n        nts = []\n        ntobj = cx.namedtuple('ntanno', self.flds + ['NS'])\n        for itemid, gos in self.id2gos.items():\n            for goid in gos:\n                goobj = self.godag.get(goid, '')\n                nts.append(ntobj(\n                    DB_ID=itemid,\n                    GO_ID=goid,\n                    NS=NAMESPACE2NS[goobj.namespace] if goobj else ''))\n        return nts", "response": "Get a list of namedtuples one for each annotation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a file containing association file and initializes the gene id - > GO terms.", "response": "def _init_id2gos(assoc_fn):  ##, no_top=False):\n        \"\"\"\n        Reads a gene id go term association file. The format of the file\n        is as follows:\n\n        AAR1\tGO:0005575;GO:0003674;GO:0006970;GO:0006970;GO:0040029\n        AAR2\tGO:0005575;GO:0003674;GO:0040029;GO:0009845\n        ACD5\tGO:0005575;GO:0003674;GO:0008219\n        ACL1\tGO:0005575;GO:0003674;GO:0009965;GO:0010073\n        ACL2\tGO:0005575;GO:0003674;GO:0009826\n        ACL3\tGO:0005575;GO:0003674;GO:0009826;GO:0009965\n\n        Also, the following format is accepted (gene ids are repeated):\n\n        AAR1\tGO:0005575\n        AAR1    GO:0003674\n        AAR1    GO:0006970\n        AAR2\tGO:0005575\n        AAR2    GO:0003674\n        AAR2    GO:0040029\n\n        :param assoc_fn: file name of the association\n        :return: dictionary having keys: gene id, values set of GO terms\n        \"\"\"\n        assoc = cx.defaultdict(set)\n        ## top_terms = set(['GO:0008150', 'GO:0003674', 'GO:0005575']) # BP, MF, CC\n        for row in open(assoc_fn, 'r'):\n            atoms = row.split()\n            if len(atoms) == 2:\n                gene_id, go_terms = atoms\n            elif len(atoms) > 2 and row.count('\\t') == 1:\n                gene_id, go_terms = row.split(\"\\t\")\n            else:\n                continue\n            gos = set(go_terms.split(\";\"))\n            ## if no_top:\n            ##     gos = gos.difference(top_terms)\n            assoc[gene_id] |= gos\n        return assoc"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes go2obj in small dag for source gos.", "response": "def _init_go2obj(self, **kws):\n        \"\"\"Initialize go2obj in small dag for source gos.\"\"\"\n        if 'goids' in kws and 'obodag' in kws:\n            self.godag.go_sources = kws['goids']\n            obo = kws['obodag']\n            for goid in self.godag.go_sources:\n                self.godag.go2obj[goid] = obo[goid]\n        elif 'goid2goobj' in kws:\n            goid2goobj = kws['goid2goobj']\n            self.godag.go_sources = goid2goobj.keys()\n            for goid, goobj in goid2goobj.items():\n                self.godag.go2obj[goid] = goobj\n        elif 'goea_results' in kws:\n            goea_results = kws['goea_results']\n            self.godag.go_sources = [rec.GO for rec in goea_results]\n            self.godag.go2obj = {rec.GO:rec.goterm for rec in goea_results}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init(self):\n        for goid in self.godag.go_sources:\n            goobj = self.godag.go2obj[goid]\n            self.godag.go2obj[goid] = goobj\n            # Traverse up parents\n            if self.traverse_parent and goid not in self.seen_cids:\n                self._traverse_parent_objs(goobj)\n            # Traverse down children\n            if self.traverse_child and goid not in self.seen_pids:\n                self._traverse_child_objs(goobj)", "response": "Given GO ids and GOTerm objects create mini GO dag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses from source GO up parents.", "response": "def _traverse_parent_objs(self, goobj_child):\n        \"\"\"Traverse from source GO up parents.\"\"\"\n        child_id = goobj_child.id\n        # mark child as seen\n        self.seen_cids.add(child_id)\n        self.godag.go2obj[child_id] = goobj_child\n        # Loop through parents of child object\n        for parent_obj in goobj_child.parents:\n            parent_id = parent_obj.id\n            self.godag.p_from_cs[parent_id].add(child_id)\n            # If parent has not been seen, traverse\n            if parent_id not in self.seen_cids:\n                self._traverse_parent_objs(parent_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntraverse from source GO down children.", "response": "def _traverse_child_objs(self, goobj_parent):\n        \"\"\"Traverse from source GO down children.\"\"\"\n        parent_id = goobj_parent.id\n        # mark parent as seen\n        self.seen_pids.add(parent_id)\n        self.godag.go2obj[parent_id] = goobj_parent\n        # Loop through children\n        for child_obj in goobj_parent.children:\n            child_id = child_obj.id\n            self.godag.p2cs[parent_id].add(child_id)\n            # If child has not been seen\n            if child_id not in self.seen_pids:\n                self._traverse_child_objs(child_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_hier_rec(self, item_id, depth=1):\n        # Shortens hierarchy report by only printing the hierarchy\n        # for the sub-set of user-specified GO terms which are connected.\n        if self.include_only and item_id not in self.include_only:\n            return\n\n        obj = self.id2obj[item_id]\n        # Optionally space the branches for readability\n        if self.space_branches:\n            if depth == 1 and obj.children:\n                self.prt.write(\"\\n\")\n        # Print marks if provided\n        if self.item_marks:\n            self.prt.write('{MARK} '.format(\n                MARK=self.item_marks.get(item_id, self.mark_dflt)))\n\n        no_repeat = self.concise_prt and item_id in self.items_printed\n        # Print content\n        dashes = self._str_dash(depth, no_repeat, obj)\n        if self.do_prtfmt:\n            self._prtfmt(item_id, dashes)\n        else:\n            self._prtstr(obj, dashes)\n        self.items_printed.add(item_id)\n        self.items_list.append(item_id)\n        # Do not print hierarchy below this turn if it has already been printed\n        if no_repeat:\n            return\n        depth += 1\n        if self.max_indent is not None and depth > self.max_indent:\n            return\n        children = obj.children if self.sortby is None else sorted(obj.children, key=self.sortby)\n        for child in children:\n            self.prt_hier_rec(child.item_id, depth)", "response": "Write a hierarchy for a GO Term record and all GO IDs down to the leaf level."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint object information using a namedtuple and a format pattern.", "response": "def _prtfmt(self, item_id, dashes):\n        \"\"\"Print object information using a namedtuple and a format pattern.\"\"\"\n        ntprt = self.id2nt[item_id]\n        dct = ntprt._asdict()\n        self.prt.write('{DASHES:{N}}'.format(\n            DASHES=self.fmt_dashes.format(DASHES=dashes, ID=self.nm2prtfmt['ID'].format(**dct)),\n            N=self.dash_len))\n        self.prt.write(\"{INFO}\\n\".format(INFO=self.nm2prtfmt['ITEM'].format(**dct)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prtstr(self, obj, dashes):\n        self.prt.write('{DASHES:{N}}'.format(\n            DASHES=self.fmt_dashes.format(DASHES=dashes, ID=obj.item_id),\n            N=self.dash_len))\n        self.prt.write(\"{INFO}\\n\".format(INFO=str(obj)))", "response": "Print object information using a namedtuple and a format pattern."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _str_dash(self, depth, no_repeat, obj):\n        if self.indent:\n            # '-' is default character indicating hierarchy level\n            # '=' is used to indicate a hierarchical path printed in detail previously.\n            single_or_double = not no_repeat or not obj.children\n            letter = '-' if single_or_double else '='\n            return ''.join([letter]*depth)\n        return \"\"", "response": "Return a string containing dashes and GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_item_marks(item_marks):\n        if isinstance(item_marks, dict):\n            return item_marks\n        if item_marks:\n            return {item_id:'>' for item_id in item_marks}", "response": "Initialize the makred item dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_to_obj(self, rec_curr, typedef_curr, line):\n        if rec_curr is not None:\n            self._add_to_ref(rec_curr, line)\n        else:\n            add_to_typedef(typedef_curr, line)", "response": "Add information on line to GOTerm or Typedef."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves obo version and release.", "response": "def _init_obo_version(self, line):\n        \"\"\"Save obo version and release.\"\"\"\n        if line[0:14] == \"format-version\":\n            self.format_version = line[16:-1]\n        if line[0:12] == \"data-version\":\n            self.data_version = line[14:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding new fields to the current reference.", "response": "def _add_to_ref(self, rec_curr, line):\n        \"\"\"Add new fields to the current reference.\"\"\"\n        # Examples of record lines containing ':' include:\n        #   id: GO:0000002\n        #   name: mitochondrial genome maintenance\n        #   namespace: biological_process\n        #   def: \"The maintenance of ...\n        #   is_a: GO:0007005 ! mitochondrion organization\n        if line[:4] == \"id: \":\n            assert not rec_curr.item_id\n            item_id = line[4:]\n            rec_curr.item_id = item_id\n            rec_curr.id = item_id\n        elif line[:8] == \"alt_id: \":\n            rec_curr.alt_ids.add(line[8:])\n        elif line[:6] == \"name: \":\n            assert not rec_curr.name\n            rec_curr.name = line[6:]\n        elif line[:11] == \"namespace: \":\n            assert not rec_curr.namespace\n            rec_curr.namespace = line[11:]\n        elif line[:6] == \"is_a: \":\n            rec_curr._parents.add(line[6:].split()[0])\n        elif line[:13] == \"is_obsolete: \" and line[13:] == \"true\":\n            rec_curr.is_obsolete = True\n        elif self.optobj and ':' in line:\n            self.optobj.update_rec(rec_curr, line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates OboOptionalAttrs or return None.", "response": "def _init_optional_attrs(optional_attrs):\n        \"\"\"Create OboOptionalAttrs or return None.\"\"\"\n        if optional_attrs is None:\n            return None\n        opts = OboOptionalAttrs.get_optional_attrs(optional_attrs)\n        if opts:\n            return OboOptionalAttrs(opts)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_parent(self, term):\n        for parent in self.parents:\n            if parent.item_id == term or parent.has_parent(term):\n                return True\n        return False", "response": "Return True if this GO object has a parent GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_child(self, term):\n        for parent in self.children:\n            if parent.item_id == term or parent.has_child(term):\n                return True\n        return False", "response": "Return True if this GO object has a child GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all parent GO IDs.", "response": "def get_all_parents(self):\n        \"\"\"Return all parent GO IDs.\"\"\"\n        all_parents = set()\n        for parent in self.parents:\n            all_parents.add(parent.item_id)\n            all_parents |= parent.get_all_parents()\n        return all_parents"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all parent GO IDs through both is_a and all relationships.", "response": "def get_all_upper(self):\n        \"\"\"Return all parent GO IDs through both 'is_a' and all relationships.\"\"\"\n        all_upper = set()\n        for upper in self.get_goterms_upper():\n            all_upper.add(upper.item_id)\n            all_upper |= upper.get_all_upper()\n        return all_upper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all children GO IDs.", "response": "def get_all_children(self):\n        \"\"\"Return all children GO IDs.\"\"\"\n        all_children = set()\n        for parent in self.children:\n            all_children.add(parent.item_id)\n            all_children |= parent.get_all_children()\n        return all_children"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_lower(self):\n        all_lower = set()\n        for lower in self.get_goterms_lower():\n            all_lower.add(lower.item_id)\n            all_lower |= lower.get_all_lower()\n        return all_lower", "response": "Return all GO IDs through both reverse is_a and all relationships."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn tuples for all parent GO IDs containing current GO ID and parent GO ID.", "response": "def get_all_parent_edges(self):\n        \"\"\"Return tuples for all parent GO IDs, containing current GO ID and parent GO ID.\"\"\"\n        all_parent_edges = set()\n        for parent in self.parents:\n            all_parent_edges.add((self.item_id, parent.item_id))\n            all_parent_edges |= parent.get_all_parent_edges()\n        return all_parent_edges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_child_edges(self):\n        all_child_edges = set()\n        for parent in self.children:\n            all_child_edges.add((parent.item_id, self.item_id))\n            all_child_edges |= parent.get_all_child_edges()\n        return all_child_edges", "response": "Return all child GO IDs containing current GO ID and child GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_obo_file(self, obo_file, optional_attrs, load_obsolete, prt):\n        reader = OBOReader(obo_file, optional_attrs)\n\n        # Save alt_ids and their corresponding main GO ID. Add to GODag after populating GO Terms\n        alt2rec = {}\n        for rec in reader:\n            # Save record if:\n            #   1) Argument load_obsolete is True OR\n            #   2) Argument load_obsolete is False and the GO term is \"live\" (not obsolete)\n            if load_obsolete or not rec.is_obsolete:\n                self[rec.item_id] = rec\n                for alt in rec.alt_ids:\n                    alt2rec[alt] = rec\n\n        # Save the typedefs and parsed optional_attrs\n        # self.optobj = reader.optobj\n        self.typedefs = reader.typedefs\n\n        self._populate_terms(reader.optobj)\n        self._set_level_depth(reader.optobj)\n\n        # Add alt_ids to go2obj\n        for goid_alt, rec in alt2rec.items():\n            self[goid_alt] = rec\n        desc = self._str_desc(reader)\n        if prt is not None:\n            prt.write(\"{DESC}\\n\".format(DESC=desc))\n        return desc", "response": "Read and store a set of GO Terms from an OBO file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _str_desc(self, reader):\n        data_version = reader.data_version\n        if data_version is not None:\n            data_version = data_version.replace(\"releases/\", \"\")\n        desc = \"{OBO}: fmt({FMT}) rel({REL}) {N:,} GO Terms\".format(\n            OBO=reader.obo_file, FMT=reader.format_version,\n            REL=data_version, N=len(self))\n        if reader.optobj:\n            desc = \"{D}; optional_attrs({A})\".format(D=desc, A=\" \".join(sorted(reader.optobj.optional_attrs)))\n        return desc", "response": "String containing information about the current GO DAG."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _populate_terms(self, optobj):\n        has_relationship = optobj is not None and 'relationship' in optobj.optional_attrs\n        # Make parents and relationships references to the actual GO terms.\n        for rec in self.values():\n            # Given parent GO IDs, set parent GO Term objects\n            rec.parents = set([self[goid] for goid in rec._parents])\n\n            # For each parent GO Term object, add it's child GO Term to the children data member\n            for parent_rec in rec.parents:\n                parent_rec.children.add(rec)\n\n            if has_relationship:\n                self._populate_relationships(rec)", "response": "Convert GO IDs to GO Term record objects. Populate children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert GO IDs in relationships to GO Term record objects. Populate children.", "response": "def _populate_relationships(self, rec_curr):\n        \"\"\"Convert GO IDs in relationships to GO Term record objects. Populate children.\"\"\"\n        for relationship_type, goids in rec_curr.relationship.items():\n            parent_recs = set([self[goid] for goid in goids])\n            rec_curr.relationship[relationship_type] = parent_recs\n            for parent_rec in parent_recs:\n                if relationship_type not in parent_rec.relationship_rev:\n                    parent_rec.relationship_rev[relationship_type] = set([rec_curr])\n                else:\n                    parent_rec.relationship_rev[relationship_type].add(rec_curr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_level_depth(self, optobj):\n        has_relationship = optobj is not None and 'relationship' in optobj.optional_attrs\n\n        def _init_level(rec):\n            if rec.level is None:\n                if rec.parents:\n                    rec.level = min(_init_level(rec) for rec in rec.parents) + 1\n                else:\n                    rec.level = 0\n            return rec.level\n\n        def _init_depth(rec):\n            if rec.depth is None:\n                if rec.parents:\n                    rec.depth = max(_init_depth(rec) for rec in rec.parents) + 1\n                else:\n                    rec.depth = 0\n            return rec.depth\n\n        def _init_reldepth(rec):\n            if not hasattr(rec, 'reldepth'):\n                up_terms = rec.get_goterms_upper()\n                if up_terms:\n                    rec.reldepth = max(_init_reldepth(rec) for rec in up_terms) + 1\n                else:\n                    rec.reldepth = 0\n            return rec.reldepth\n\n        for rec in self.values():\n\n            # Add invert relationships\n            if has_relationship:\n                if rec.depth is None:\n                    _init_reldepth(rec)\n\n                # print(\"BBBBBBBBBBB1\", rec.item_id, rec.relationship)\n                #for (typedef, terms) in rec.relationship.items():\n                #    invert_typedef = self.typedefs[typedef].inverse_of\n                #    # print(\"BBBBBBBBBBB2 {} ({}) ({}) ({})\".format(\n                #    #    rec.item_id, rec.relationship, typedef, invert_typedef))\n                #    if invert_typedef:\n                #        # Add inverted relationship\n                #        for term in terms:\n                #            if not hasattr(term, 'relationship'):\n                #                term.relationship = defaultdict(set)\n                #            term.relationship[invert_typedef].add(rec)\n                # print(\"BBBBBBBBBBB3\", rec.item_id, rec.relationship)\n\n            if rec.level is None:\n                _init_level(rec)\n\n            if rec.depth is None:\n                _init_depth(rec)", "response": "Set level and depth and add inverted relationships."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite info for all GO Terms in obo file sorted numerically.", "response": "def write_dag(self, out=sys.stdout):\n        \"\"\"Write info for all GO Terms in obo file, sorted numerically.\"\"\"\n        for rec in sorted(self.values()):\n            print(rec, file=out)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_term(self, term, verbose=False):\n        if term not in self:\n            sys.stderr.write(\"Term %s not found!\\n\" % term)\n            return\n\n        rec = self[term]\n        if verbose:\n            print(rec)\n            sys.stderr.write(\"all parents: {}\\n\".format(\n                repr(rec.get_all_parents())))\n            sys.stderr.write(\"all children: {}\\n\".format(\n                repr(rec.get_all_children())))\n        return rec", "response": "Given a GO ID return a GO object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef label_wrap(self, label):\n        wrapped_label = r\"%s\\n%s\" % (label,\n                                     self[label].name.replace(\",\", r\"\\n\"))\n        return wrapped_label", "response": "Label text for plot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw AMIGO style network lineage containing one query record.", "response": "def make_graph_pygraphviz(self, recs, nodecolor,\n                              edgecolor, dpi,\n                              draw_parents=True, draw_children=True):\n        \"\"\"Draw AMIGO style network, lineage containing one query record.\"\"\"\n        import pygraphviz as pgv\n\n        grph = pgv.AGraph(name=\"GO tree\")\n\n        edgeset = set()\n        for rec in recs:\n            if draw_parents:\n                edgeset.update(rec.get_all_parent_edges())\n            if draw_children:\n                edgeset.update(rec.get_all_child_edges())\n\n        edgeset = [(self.label_wrap(a), self.label_wrap(b))\n                   for (a, b) in edgeset]\n\n        # add nodes explicitly via add_node\n        # adding nodes implicitly via add_edge misses nodes\n        # without at least one edge\n        for rec in recs:\n            grph.add_node(self.label_wrap(rec.item_id))\n\n        for src, target in edgeset:\n            # default layout in graphviz is top->bottom, so we invert\n            # the direction and plot using dir=\"back\"\n            grph.add_edge(target, src)\n\n        grph.graph_attr.update(dpi=\"%d\" % dpi)\n        grph.node_attr.update(shape=\"box\", style=\"rounded,filled\",\n                              fillcolor=\"beige\", color=nodecolor)\n        grph.edge_attr.update(shape=\"normal\", color=edgecolor,\n                              dir=\"back\", label=\"is_a\")\n        # highlight the query terms\n        for rec in recs:\n            try:\n                node = grph.get_node(self.label_wrap(rec.item_id))\n                node.attr.update(fillcolor=\"plum\")\n            except:\n                continue\n\n        return grph"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a lineage for a set of recs.", "response": "def draw_lineage(self, recs, nodecolor=\"mediumseagreen\",\n                     edgecolor=\"lightslateblue\", dpi=96,\n                     lineage_img=\"GO_lineage.png\", engine=\"pygraphviz\",\n                     gml=False, draw_parents=True, draw_children=True):\n        \"\"\"Draw GO DAG subplot.\"\"\"\n        assert engine in GraphEngines\n        grph = None\n        if engine == \"pygraphviz\":\n            grph = self.make_graph_pygraphviz(recs, nodecolor, edgecolor, dpi,\n                                              draw_parents=draw_parents,\n                                              draw_children=draw_children)\n        else:\n            grph = self.make_graph_pydot(recs, nodecolor, edgecolor, dpi,\n                                         draw_parents=draw_parents, draw_children=draw_children)\n\n        if gml:\n            import networkx as nx  # use networkx to do the conversion\n            gmlbase = lineage_img.rsplit(\".\", 1)[0]\n            obj = nx.from_agraph(grph) if engine == \"pygraphviz\" else nx.from_pydot(grph)\n\n            del obj.graph['node']\n            del obj.graph['edge']\n            gmlfile = gmlbase + \".gml\"\n            nx.write_gml(self.label_wrap, gmlfile)\n            sys.stderr.write(\"GML graph written to {0}\\n\".format(gmlfile))\n\n        sys.stderr.write((\"lineage info for terms %s written to %s\\n\" %\n                          ([rec.item_id for rec in recs], lineage_img)))\n\n        if engine == \"pygraphviz\":\n            grph.draw(lineage_img, prog=\"dot\")\n        else:\n            grph.write_png(lineage_img)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the association of a gene s associated GO IDs to the gene s association.", "response": "def update_association(self, association):\n        \"\"\"Add the GO parents of a gene's associated GO IDs to the gene's association.\"\"\"\n        bad_goids = set()\n        # Loop through all sets of GO IDs for all genes\n        for goids in association.values():\n            parents = set()\n            # Iterate thru each GO ID in the current gene's association\n            for goid in goids:\n                try:\n                    parents.update(self[goid].get_all_parents())\n                except:\n                    bad_goids.add(goid.strip())\n            # Add the GO parents of all GO IDs in the current gene's association\n            goids.update(parents)\n        if bad_goids:\n            sys.stdout.write(\"{N} GO IDs in assc. are not found in the GO-DAG: {GOs}\\n\".format(\n                N=len(bad_goids), GOs=\" \".join(bad_goids)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_to_typedef(typedef_curr, obo_line):\n    if obo_line[:4] == \"id: \":\n        assert not typedef_curr.item_id\n        item_id = obo_line[4:]\n        typedef_curr.item_id = item_id\n    elif obo_line[:6] == \"name: \":\n        assert not typedef_curr.name\n        typedef_curr.name = obo_line[6:]\n    elif obo_line[:11] == \"namespace: \":\n        assert not typedef_curr.namespace\n        typedef_curr.namespace = obo_line[11:]\n    elif obo_line[17:] == \"transitive_over: \":\n        field_value = obo_line[17:].split('!')[0].rstrip()\n        typedef_curr.transitive_over.append(field_value)\n    elif obo_line[12:] == \"inverse_of\":\n        assert not typedef_curr.inverse_of\n        field_value = obo_line[12:].split('!')[0].rstrip()\n        typedef_curr.inverse_of = field_value", "response": "Add new fields to the current typedef."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_ntgpadvals(self, flds, add_ns):\n        is_set = False\n        qualifiers = self._get_qualifier(flds[2])\n        assert flds[3][:3] == 'GO:', 'UNRECOGNIZED GO({GO})'.format(GO=flds[3])\n        db_reference = self._rd_fld_vals(\"DB_Reference\", flds[4], is_set, 1)\n        assert flds[5][:4] == 'ECO:', 'UNRECOGNIZED ECO({ECO})'.format(ECO=flds[3])\n        with_from = self._rd_fld_vals(\"With_From\", flds[6], is_set)\n        taxons = self._get_taxon(flds[7])\n        assert flds[8].isdigit(), 'UNRECOGNIZED DATE({D})'.format(D=flds[8])\n        assert flds[9], '\"Assigned By\" VALUE WAS NOT FOUND'\n        props = self._get_properties(flds[11])\n        self._chk_qty_eq_1(flds, [0, 1, 3, 5, 8, 9])\n        # Additional Formatting\n        self._chk_qualifier(qualifiers)\n        # Create list of values\n        eco = flds[5]\n        goid = flds[3]\n        gpadvals = [\n            flds[0],      #  0  DB\n            flds[1],      #  1  DB_ID\n            qualifiers,   #  3  Qualifier\n            flds[3],      #  4  GO_ID\n            db_reference, #  5  DB_Reference\n            eco,          #  6  ECO\n            ECO2GRP[eco],\n            with_from,    #  7  With_From\n            taxons,       # 12 Taxon\n            GET_DATE_YYYYMMDD(flds[8]),      # 13 Date\n            flds[9],      # 14 Assigned_By\n            get_extensions(flds[10]),        # 12 Extension\n            props]        # 12 Annotation_Properties\n        if add_ns:\n            goobj = self.godag.get(goid, '')\n            gpadvals.append(NAMESPACE2NS[goobj.namespace] if goobj else '')\n        return gpadvals", "response": "Convert fields from string to preferred format for GPAD ver 2. 1 and 2. 0."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _rd_fld_vals(name, val, set_list_ft=True, qty_min=0, qty_max=None):\n        if not val and qty_min == 0:\n            return [] if set_list_ft else set()\n        vals = val.split('|') # Use a pipe to separate entries\n        num_vals = len(vals)\n        assert num_vals >= qty_min, \\\n            \"FLD({F}): MIN QUANTITY({Q}) WASN'T MET: {V}\".format(\n                F=name, Q=qty_min, V=vals)\n        if qty_max is not None:\n            assert num_vals <= qty_max, \\\n                \"FLD({F}): MAX QUANTITY({Q}) EXCEEDED: {V}\".format(\n                    F=name, Q=qty_max, V=vals)\n        return vals if set_list_ft else set(vals)", "response": "Further split a GPAD value within a single field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_taxon(taxon):\n        if not taxon:\n            return None\n        ## assert taxon[:6] == 'taxon:', 'UNRECOGNIZED Taxon({Taxon})'.format(Taxon=taxon)\n        ## taxid = taxon[6:]\n        ## assert taxon[:10] == 'NCBITaxon:', 'UNRECOGNIZED Taxon({Taxon})'.format(Taxon=taxon)\n        ## taxid = taxon[10:]\n        # Get tzxon number: taxon:9606 NCBITaxon:9606\n        sep = taxon.find(':')\n        taxid = taxon[sep + 1:]\n        assert taxid.isdigit(), \"UNEXPECTED TAXON({T})\".format(T=taxid)\n        return int(taxid)", "response": "Return Interacting taxon ID | optional | 0 or 1 | gaf column 13."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning optional Annotation Properties.", "response": "def _get_properties(self, fldstr):\n        \"\"\"Return optional Annotation Properties (0 or greater).\"\"\"\n        prop2val = {}\n        props = self._rd_fld_vals(\"Properties\", fldstr, False)  # Get set\n        go_evidence = None\n        for prop in props:\n            # There can be more properties than 'go_evidence',\n            # but currently we see only 'go_evidence'.\n            # Upon encountering updates, evaluate and update code to support ...\n            if prop[:12] == 'go_evidence=':\n                assert go_evidence is None, \"MORE THAN ONE EVIDENCE CODE FOUND\"\n                go_evidence = prop[12:]\n            else:\n                assert False, \"UNPROGRAMMED PROPERTY({P})\".format(P=prop)\n        ## TBD: Is 'go_evidence' still used? Replaced by ECO? And eco2group\n        ## assert go_evidence is not None, \"go_evidence == None\"\n        ## prop2val['go_evidence'] = go_evidence\n        if go_evidence is not None:\n            prop2val['go_evidence'] = go_evidence\n        return prop2val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread GPAD file and initialize associations.", "response": "def init_associations(self, hdr_only=False, prt=sys.stdout):\n        \"\"\"Read GPAD file. HTTP address okay. GZIPPED/BZIPPED file okay.\"\"\"\n        import timeit\n        import datetime\n        associations = []\n        tic = timeit.default_timer()\n        if self.filename is None:\n            return associations\n        ver = None\n        ntgpadobj_make = None\n        hdrobj = GpadHdr()\n        ifstrm = nopen(self.filename)\n        _add_ns = self.godag is not None\n        _get_ntgpadvals = self._get_ntgpadvals\n        for lnum, line in enumerate(ifstrm, 1):\n            # Read data\n            if ntgpadobj_make:\n                flds = self._split_line(line)\n                try:\n                    # pylint: disable=not-callable\n                    ntgpad = ntgpadobj_make(_get_ntgpadvals(flds, _add_ns))\n                    associations.append(ntgpad)\n                # pylint: disable=broad-except\n                except Exception as inst:\n                    import traceback\n                    traceback.print_exc()\n                    sys.stdout.write(\"\\n  **FATAL: {MSG}\\n\\n\".format(MSG=str(inst)))\n                    sys.stdout.write(\"**FATAL: {FIN}[{LNUM}]:\\n{L}\\n\".format(\n                        FIN=self.filename, L=line, LNUM=lnum))\n                    for idx, val in enumerate(flds):\n                        sys.stdout.write('{I:2} {VAL}\\n'.format(I=idx, VAL=val))\n                    ## if datobj is not None:\n                    ##     datobj.prt_line_detail(sys.stdout, line)\n                    sys.exit(1)\n            # Read header\n            else:\n                if line[0] == '!':\n                    if ver is None and line[1:13] == 'gpa-version:':\n                        ver = line[13:].strip()\n                    hdrobj.chkaddhdr(line)\n                else:\n                    self.hdr = hdrobj.get_hdr()\n                    if hdr_only:\n                        return associations\n                    ntgpadobj_make = self._get_ntgpadnt(ver, _add_ns)._make\n        # GPAD file has been read\n        prt.write('HMS:{HMS} {N:7,} annotations READ: {ANNO}\\n'.format(\n            N=len(associations), ANNO=self.filename,\n            HMS=str(datetime.timedelta(seconds=(timeit.default_timer()-tic)))))\n        return associations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_ntgpadnt(self, ver, add_ns):\n        hdrs = self.gpad_columns[ver]\n        if add_ns:\n            hdrs = hdrs + ['NS']\n        return cx.namedtuple(\"ntgpadobj\", hdrs)", "response": "Create a namedtuple object for each annotation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _split_line(self, line):\n        line = line.rstrip('\\r\\n')\n        flds = re.split('\\t', line)\n        assert len(flds) == self.exp_numcol, \"EXPECTED({E}) COLUMNS, ACTUAL({A}): {L}\".format(\n            E=self.exp_numcol, A=len(flds), L=line)\n        return flds", "response": "Split line into field values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that qualifiers are expected values.", "response": "def _chk_qualifier(self, qualifiers):\n        \"\"\"Check that qualifiers are expected values.\"\"\"\n        # http://geneontology.org/page/go-annotation-conventions#qual\n        for qual in qualifiers:\n            assert qual in self.exp_qualifiers, \"UNEXPECTED QUALIFIER({Q}): {F}\".format(\n                Q=qual, F=self.filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that these fields have only one value required 1.", "response": "def _chk_qty_eq_1(flds, col_lst):\n        \"\"\"Check that these fields have only one value: required 1.\"\"\"\n        for col in col_lst:\n            assert flds[col], \"UNEXPECTED REQUIRED VALUE({V}) AT INDEX({R})\".format(\n                V=flds[col], R=col)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if this line contains desired header info save it.", "response": "def chkaddhdr(self, line):\n        \"\"\"If this line contains desired header info, save it.\"\"\"\n        mtch = self.cmpline.search(line)\n        if mtch:\n            self.gpadhdr.append(mtch.group(1))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new dict of namedtuples by combining dicts of namedtuples or objects.", "response": "def get_dict_w_id2nts(ids, id2nts, flds, dflt_null=\"\"):\n    \"\"\"Return a new dict of namedtuples by combining \"dicts\" of namedtuples or objects.\"\"\"\n    assert len(ids) == len(set(ids)), \"NOT ALL IDs ARE UNIQUE: {IDs}\".format(IDs=ids)\n    assert len(flds) == len(set(flds)), \"DUPLICATE FIELDS: {IDs}\".format(\n        IDs=cx.Counter(flds).most_common())\n    usr_id_nt = []\n    # 1. Instantiate namedtuple object\n    ntobj = cx.namedtuple(\"Nt\", \" \".join(flds))\n    # 2. Fill dict with namedtuple objects for desired ids\n    for item_id in ids:\n        # 2a. Combine various namedtuples into a single namedtuple\n        nts = [id2nt.get(item_id) for id2nt in id2nts]\n        vals = _combine_nt_vals(nts, flds, dflt_null)\n        usr_id_nt.append((item_id, ntobj._make(vals)))\n    return cx.OrderedDict(usr_id_nt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of namedtuples by combining dicts of namedtuples or objects.", "response": "def get_list_w_id2nts(ids, id2nts, flds, dflt_null=\"\"):\n    \"\"\"Return a new list of namedtuples by combining \"dicts\" of namedtuples or objects.\"\"\"\n    combined_nt_list = []\n    # 1. Instantiate namedtuple object\n    ntobj = cx.namedtuple(\"Nt\", \" \".join(flds))\n    # 2. Fill dict with namedtuple objects for desired ids\n    for item_id in ids:\n        # 2a. Combine various namedtuples into a single namedtuple\n        nts = [id2nt.get(item_id) for id2nt in id2nts]\n        vals = _combine_nt_vals(nts, flds, dflt_null)\n        combined_nt_list.append(ntobj._make(vals))\n    return combined_nt_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef combine_nt_lists(lists, flds, dflt_null=\"\"):\n    combined_nt_list = []\n    # Check that all lists are the same length\n    lens = [len(lst) for lst in lists]\n    assert len(set(lens)) == 1, \\\n        \"LIST LENGTHS MUST BE EQUAL: {Ls}\".format(Ls=\" \".join(str(l) for l in lens))\n    # 1. Instantiate namedtuple object\n    ntobj = cx.namedtuple(\"Nt\", \" \".join(flds))\n    # 2. Loop through zipped list\n    for lst0_lstn in zip(*lists):\n        # 2a. Combine various namedtuples into a single namedtuple\n        combined_nt_list.append(ntobj._make(_combine_nt_vals(lst0_lstn, flds, dflt_null)))\n    return combined_nt_list", "response": "Return a new list of namedtuples by zipping lists of namedtuples or objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wr_py_nts(fout_py, nts, docstring=None, varname=\"nts\"):\n    if nts:\n        with open(fout_py, 'w') as prt:\n            prt.write('\"\"\"{DOCSTRING}\"\"\"\\n\\n'.format(DOCSTRING=docstring))\n            prt.write(\"# Created: {DATE}\\n\".format(DATE=str(datetime.date.today())))\n            prt_nts(prt, nts, varname)\n            sys.stdout.write(\" {N:7,} items WROTE: {PY}\\n\".format(N=len(nts), PY=fout_py))", "response": "Write namedtuples into a Python module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints namedtuples into a Python module.", "response": "def prt_nts(prt, nts, varname, spc='    '):\n    \"\"\"Print namedtuples into a Python module.\"\"\"\n    first_nt = nts[0]\n    nt_name = type(first_nt).__name__\n    prt.write(\"import collections as cx\\n\\n\")\n    prt.write(\"NT_FIELDS = [\\n\")\n    for fld in first_nt._fields:\n        prt.write('{SPC}\"{F}\",\\n'.format(SPC=spc, F=fld))\n    prt.write(\"]\\n\\n\")\n    prt.write('{NtName} = cx.namedtuple(\"{NtName}\", \" \".join(NT_FIELDS))\\n\\n'.format(\n        NtName=nt_name))\n    prt.write(\"# {N:,} items\\n\".format(N=len(nts)))\n    prt.write(\"# pylint: disable=line-too-long\\n\")\n    prt.write(\"{VARNAME} = [\\n\".format(VARNAME=varname))\n    for ntup in nts:\n        prt.write(\"{SPC}{NT},\\n\".format(SPC=spc, NT=ntup))\n    prt.write(\"]\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting unique namedtuple fields despite potential duplicates in lists of fields.", "response": "def get_unique_fields(fld_lists):\n    \"\"\"Get unique namedtuple fields, despite potential duplicates in lists of fields.\"\"\"\n    flds = []\n    fld_set = set([f for flst in fld_lists for f in flst])\n    fld_seen = set()\n    # Add unique fields to list of fields in order that they appear\n    for fld_list in fld_lists:\n        for fld in fld_list:\n            # Add fields if the field has not yet been seen\n            if fld not in fld_seen:\n                flds.append(fld)\n                fld_seen.add(fld)\n    assert len(flds) == len(fld_set)\n    return flds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _combine_nt_vals(lst0_lstn, flds, dflt_null):\n    vals = []\n    for fld in flds:\n        fld_seen = False\n        # Set field value using the **first** value seen in list of nt lists(lst0_lstn)\n        for nt_curr in lst0_lstn:\n            if hasattr(nt_curr, fld):\n                vals.append(getattr(nt_curr, fld))\n                fld_seen = True\n                break\n        # Set default value if GO ID or nt value is not present\n        if fld_seen is False:\n            vals.append(dflt_null)\n    return vals", "response": "Given a list of lists of nts return a single namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_goids(self, go_args, fin_goids, prt):\n        goids = set()\n        if fin_goids is not None:\n            goids.update(self.rdtxt_gos(fin_goids, prt))\n        if go_args:\n            goids.update(self.get_goargs(go_args, prt))\n        return goids", "response": "Return source GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_usrgos(self, fin_goids, prt):\n        ret = self.get_goids(None, fin_goids, prt)\n        # If there have been no GO IDs explicitly specified by the user\n        if not ret:\n            # If the GO-DAG is sufficiently small, print all GO IDs\n            if self.max_gos is not None and len(self.go2obj) < self.max_gos:\n                main_gos = set(o.id for go, o in self.go2obj.items() if go != o.id)\n                go_leafs = set(go for go, o in self.go2obj.items() if not o.children)\n                ret = go_leafs.difference(main_gos)\n            else:\n                raise RuntimeError(\"GO IDs NEEDED\")\n        go2obj = self.get_go2obj(ret)\n        return get_go2obj_unique(go2obj)", "response": "Return source GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns GO Terms for each user - specified GO ID. Note missing GO IDs.", "response": "def get_go2obj(self, goids):\n        \"\"\"Return GO Terms for each user-specified GO ID. Note missing GO IDs.\"\"\"\n        goids = goids.intersection(self.go2obj.keys())\n        if len(goids) != len(goids):\n            goids_missing = goids.difference(goids)\n            print(\"  {N} MISSING GO IDs: {GOs}\".format(N=len(goids_missing), GOs=goids_missing))\n        return {go:self.go2obj[go] for go in goids}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rdtxt_gos(go_file, prt):\n        goids_all = set()\n        if not os.path.exists(go_file):\n            raise RuntimeError(\"CAN NOT READ GO FILE: {FILE}\\n\".format(FILE=go_file))\n        re_go = re.compile(r'(GO:\\d{7})+?')\n        re_com = re.compile(r'^\\s*#')  # Lines starting with a '#' are comment lines and ignored\n        with open(go_file) as ifstrm:\n            for line in ifstrm:\n                # Skip lines that are comments\n                if re_com.search(line):\n                    continue\n                # Search for GO IDs on the line\n                goids_found = re_go.findall(line)\n                if goids_found:\n                    goids_all.update(goids_found)\n            if prt:\n                prt.write(\"  {N} GO IDs READ: {TXT}\\n\".format(N=len(goids_all), TXT=go_file))\n        return goids_all", "response": "Read GO IDs from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_goargs(self, go_args, prt):\n        goids = set()\n        go2color = {}\n        # Match on \"GO ID\" or \"GO ID and color\"\n        re_gocolor = re.compile(r'(GO:\\d{7})((?:#[0-9a-fA-F]{6})?)')\n        for go_arg in go_args:\n            mtch = re_gocolor.match(go_arg)\n            if mtch:\n                goid, color = mtch.groups()\n                goids.add(goid)\n                if color:\n                    go2color[goid] = color\n            elif go_arg in self.godagconsts.NS2GO:\n                goids.add(self.godagconsts.NS2GO[go_arg])\n            elif prt:\n                prt.write(\"WARNING: UNRECOGNIZED ARG({})\\n\".format(go_arg))\n        return goids", "response": "Get GO IDs and colors from the GO ID runtime arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef no_duplicates_sections2d(sections2d, prt=None):\n    no_dups = True\n    ctr = cx.Counter()\n    for _, hdrgos in sections2d:\n        for goid in hdrgos:\n            ctr[goid] += 1\n    for goid, cnt in ctr.most_common():\n        if cnt == 1:\n            break\n        no_dups = False\n        if prt is not None:\n            prt.write(\"**SECTIONS WARNING FOUND: {N:3} {GO}\\n\".format(N=cnt, GO=goid))\n    return no_dups", "response": "Check for duplicate header GO IDs in the 2 - D sections variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints summary of codes and groups that can be inputs to get_evcodes.", "response": "def prt_summary_code(self, prt=sys.stdout):\n        \"\"\"Print summary of codes and groups that can be inputs to get_evcodes.\"\"\"\n        prt.write('EVIDENCE GROUP AND CODES:\\n')\n        for grp, c2nt in self.grp2code2nt.items():\n            prt.write('    {GRP:19}: {CODES}\\n'.format(GRP=grp, CODES=' '.join(c2nt.keys())))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prt_details(self, prt=sys.stdout):\n        prt.write('EVIDENCE CODES:\\n')\n        for grp, code2nt in self.grp2code2nt.items():\n            prt.write('    {GROUP}:\\n'.format(GROUP=grp))\n            for code, ntd in code2nt.items():\n                prt.write('        {CODE:>3} {NAME}\\n'.format(CODE=code, NAME=ntd.name))", "response": "Print summary of codes and groups that can be inputs to get_evcodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_min_inc_exc(self, inc_set=None, exc_set=None):\n        if inc_set is None and exc_set is None:\n            return {}\n        inc = self.get_evcodes(inc_set, exc_set)\n        exc = set(self.code2nt.keys()).difference(inc)\n        return {'inc':inc} if len(inc) <= len(exc) else {'exc': exc}", "response": "Get the user - specified Evidence codes. Return smaller set : include and exclude"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all but NOT NO biological data", "response": "def get_evcodes(self, inc_set=None, exc_set=None):\n        \"\"\"Get evidence code for all but NOT 'No biological data'\"\"\"\n        codes = self.get_evcodes_all(inc_set, exc_set)\n        codes.discard('ND')\n        return codes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_evcodes_all(self, inc_set=None, exc_set=None):\n        codes = self._get_grps_n_codes(inc_set) if inc_set else set(self.code2nt)\n        if exc_set:\n            codes.difference_update(self._get_grps_n_codes(exc_set))\n        return codes", "response": "Get set of evidence codes given include set and exclude set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_grps_n_codes(self, usr_set):\n        codes = usr_set.intersection(self.code2nt)\n        for grp in usr_set.intersection(self.grp2codes):\n            codes.update(self.grp2codes[grp])\n        return codes", "response": "Get codes given codes or groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sort_nts(self, nt_list, codekey):\n        # Problem is that some members in the nt_list do NOT have\n        # codekey=EvidenceCode, then it returns None, which breaks py34 and 35\n        # The fix here is that for these members, default to -1 (is this valid?)\n        sortby = lambda nt: self.ev2idx.get(getattr(nt, codekey), -1)\n        return sorted(nt_list, key=sortby)", "response": "Sort list of namedtuples such so evidence codes in same order as code2nt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_grp_name(self, code):\n        nt_code = self.code2nt.get(code.strip(), None)\n        if nt_code is not None:\n            return nt_code.group, nt_code.name\n        return \"\", \"\"", "response": "Return group and name for an evidence code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prt_ev_cnts(self, ctr, prt=sys.stdout):\n        for key, cnt in ctr.most_common():\n            grp, name = self.get_grp_name(key.replace(\"NOT \", \"\"))\n            prt.write(\"{CNT:7,} {EV:>7} {GROUP:<15} {NAME}\\n\".format(\n                CNT=cnt, EV=key, GROUP=grp, NAME=name))", "response": "Prints evidence code counts stored in a collections Counter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn evidence codes in order shown in code2name.", "response": "def get_order(self, codes):\n        \"\"\"Return evidence codes in order shown in code2name.\"\"\"\n        return sorted(codes, key=lambda e: [self.ev2idx.get(e)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint annotation and evidence code summary.", "response": "def prt_summary_anno2ev(self, associations, prt=sys.stdout):\n        \"\"\"Print annotation/evidence code summary.\"\"\"\n        ctr = cx.Counter()\n        for ntanno in associations:\n            evidence_code = ntanno.Evidence_Code\n            if 'NOT' not in ntanno.Qualifier:\n                ctr[evidence_code] += 1\n            elif 'NOT' in ntanno.Qualifier:\n                ctr[\"NOT {EV:3}\".format(EV=ntanno.Evidence_Code)] += 1\n            else:\n                raise Exception(\"UNEXPECTED INFO\")\n        self.prt_ev_cnts(ctr, prt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn ordered dict for group to namedtuple", "response": "def get_grp2code2nt(self):\n        \"\"\"Return ordered dict for group to namedtuple\"\"\"\n        grp2code2nt = cx.OrderedDict([(g, []) for g in self.grps])\n        for code, ntd in self.code2nt.items():\n            grp2code2nt[ntd.group].append((code, ntd))\n        for grp, nts in grp2code2nt.items():\n            grp2code2nt[grp] = cx.OrderedDict(nts)\n        return grp2code2nt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of groups in same order as in code2nt", "response": "def _init_grps(code2nt):\n        \"\"\"Return list of groups in same order as in code2nt\"\"\"\n        seen = set()\n        seen_add = seen.add\n        groups = [nt.group for nt in code2nt.values()]\n        return [g for g in groups if not (g in seen or seen_add(g))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_grp2codes(self):\n        grp2codes = cx.defaultdict(set)\n        for code, ntd in self.code2nt.items():\n            grp2codes[ntd.group].add(code)\n        return dict(grp2codes)", "response": "Get dict of group name to namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot groups of GOs which have been placed in sections.", "response": "def plot_sections(self, fout_dir=\".\", **kws_usr):\n        \"\"\"Plot groups of GOs which have been placed in sections.\"\"\"\n        kws_plt, _ = self._get_kws_plt(None, **kws_usr)\n        PltGroupedGos(self).plot_sections(fout_dir, **kws_plt)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pltdotstr(self, **kws_usr):\n        dotstrs = self.get_pltdotstrs(**kws_usr)\n        assert len(dotstrs) == 1\n        return dotstrs[0]", "response": "Plot one GO header group in Grouper."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots each GO group in the group.", "response": "def plot_groups_unplaced(self, fout_dir=\".\", **kws_usr):\n        \"\"\"Plot each GO group.\"\"\"\n        # kws: go2color max_gos upper_trigger max_upper\n        plotobj = PltGroupedGos(self)\n        return plotobj.plot_groups_unplaced(fout_dir, **kws_usr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a GoSubDagPlot object for the specified GO IDs.", "response": "def get_gosubdagplot(self, goids=None, **kws_usr):\n        \"\"\"Plot GO IDs.\"\"\"\n        if goids is None:\n            goids = self.grprobj.usrgos\n        kws_plt, kws_dag = self._get_kws_plt(goids, **kws_usr)\n        gosubdag = GoSubDag(\n            goids,\n            self.grprobj.gosubdag.get_go2obj(goids),\n            self.grprobj.gosubdag.relationships,\n            rcntobj=self.grprobj.gosubdag.rcntobj,\n            go2nt=self.grprobj.gosubdag.go2nt,\n            **kws_dag)\n        return GoSubDagPlot(gosubdag, **kws_plt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_kws_plt(self, usrgos, **kws_usr):\n        kws_plt = kws_usr.copy()\n        kws_dag = {}\n        hdrgo = kws_plt.get('hdrgo', None)\n        objcolor = GrouperColors(self.grprobj)\n        # GO term colors\n        if 'go2color' not in kws_usr:\n            kws_plt['go2color'] = objcolor.get_go2color_users()\n        elif hdrgo is not None:\n            go2color = kws_plt.get('go2color').copy()\n            go2color[hdrgo] = PltGroupedGosArgs.hdrgo_dflt_color\n            kws_plt['go2color'] = go2color\n        # GO term border colors\n        if 'go2bordercolor' not in kws_usr:\n            kws_plt['go2bordercolor'] = objcolor.get_bordercolor()\n        prune = kws_usr.get('prune', None)\n        if prune is True and hdrgo is not None:\n            kws_dag['dst_srcs_list'] = [(hdrgo, usrgos), (None, set([hdrgo]))]\n            kws_plt['parentcnt'] = True\n        elif prune:\n            kws_dag['dst_srcs_list'] = prune\n            kws_plt['parentcnt'] = True\n        # Group text\n        kws_plt['go2txt'] = self.get_go2txt(self.grprobj,\n                                            kws_plt.get('go2color'), kws_plt.get('go2bordercolor'))\n        return kws_plt, kws_dag", "response": "Add go2color and go2bordercolor relevant to this grouping into plot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict of GO IDs to text.", "response": "def get_go2txt(grprobj_cur, grp_go2color, grp_go2bordercolor):\n        \"\"\"Adds section text in all GO terms if not Misc. Adds Misc in terms of interest.\"\"\"\n        goids_main = set(o.id for o in grprobj_cur.gosubdag.go2obj.values())\n        hdrobj = grprobj_cur.hdrobj\n        grprobj_all = Grouper(\"all\",\n                              grprobj_cur.usrgos.union(goids_main), hdrobj, grprobj_cur.gosubdag)\n        # Adds section text to all GO terms in plot (misses middle GO terms)\n        _secdflt = hdrobj.secdflt\n        _hilight = set(grp_go2color.keys()).union(grp_go2bordercolor)\n        ret_go2txt = {}\n        # Keep sections text only if GO header, GO user, or not Misc.\n        if hdrobj.sections:\n            for goid, txt in grprobj_all.get_go2sectiontxt().items():\n                if txt == 'broad':\n                    continue\n                if txt != _secdflt or goid in _hilight:\n                    ret_go2txt[goid] = txt\n        return ret_go2txt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ungzipper(fh, blocksize=16384):\n    import zlib\n    uzip = zlib.decompressobj(16 + zlib.MAX_WBITS)\n    data = uzip.decompress(fh.read(blocksize)).split(\"\\n\")\n\n    while len(data[0]):\n        # last chunk might not be a full line.\n        save = data.pop()\n        for line in data:\n            yield line\n        data = uzip.decompress(fh.read(blocksize)).split(\"\\n\")\n        # first line is prepended with saved chunk from end of last set.\n        data[0] = save + data[0]", "response": "Ungzip the file and yield the set of entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads Ontologies if necessary.", "response": "def download_go_basic_obo(obo=\"go-basic.obo\", prt=sys.stdout, loading_bar=True):\n    \"\"\"Download Ontologies, if necessary.\"\"\"\n    if not os.path.isfile(obo):\n        http = \"http://purl.obolibrary.org/obo/go\"\n        if \"slim\" in obo:\n            http = \"http://www.geneontology.org/ontology/subsets\"\n            # http = 'http://current.geneontology.org/ontology/subsets'\n        obo_remote = \"{HTTP}/{OBO}\".format(HTTP=http, OBO=os.path.basename(obo))\n        dnld_file(obo_remote, obo, prt, loading_bar)\n    else:\n        if prt is not None:\n            prt.write(\"  EXISTS: {FILE}\\n\".format(FILE=obo))\n    return obo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_ncbi_associations(gene2go=\"gene2go\", prt=sys.stdout, loading_bar=True):\n    # Download: ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz\n    gzip_file = \"{GENE2GO}.gz\".format(GENE2GO=gene2go)\n    if not os.path.isfile(gene2go):\n        file_remote = \"ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/{GZ}\".format(\n            GZ=os.path.basename(gzip_file))\n        dnld_file(file_remote, gene2go, prt, loading_bar)\n    else:\n        if prt is not None:\n            prt.write(\"  EXISTS: {FILE}\\n\".format(FILE=gene2go))\n    return gene2go", "response": "Download associations from NCBI if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gunzip(gzip_file, file_gunzip=None):\n    if file_gunzip is None:\n        file_gunzip = os.path.splitext(gzip_file)[0]\n        gzip_open_to(gzip_file, file_gunzip)\n        return file_gunzip", "response": "Unzip. gz file. Return filename of unzipped file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget GODag object. Initialize if necessary.", "response": "def get_godag(fin_obo=\"go-basic.obo\", prt=sys.stdout, loading_bar=True, optional_attrs=None):\n    \"\"\"Return GODag object. Initialize, if necessary.\"\"\"\n    from goatools.obo_parser import GODag\n    download_go_basic_obo(fin_obo, prt, loading_bar)\n    return GODag(fin_obo, optional_attrs, load_obsolete=False, prt=prt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dnld_gaf(species_txt, prt=sys.stdout, loading_bar=True):\n    return dnld_gafs([species_txt], prt, loading_bar)[0]", "response": "Download GAF file if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dnld_gafs(species_list, prt=sys.stdout, loading_bar=True):\n    # Example GAF files in  http://current.geneontology.org/annotations/:\n    #   http://current.geneontology.org/annotations/mgi.gaf.gz\n    #   http://current.geneontology.org/annotations/fb.gaf.gz\n    #   http://current.geneontology.org/annotations/goa_human.gaf.gz\n    http = \"http://current.geneontology.org/annotations\"\n    # There are two filename patterns for gene associations on geneontology.org\n    fin_gafs = []\n    cwd = os.getcwd()\n    for species_txt in species_list: # e.g., goa_human mgi fb\n        gaf_base = '{ABC}.gaf'.format(ABC=species_txt) # goa_human.gaf\n        gaf_cwd = os.path.join(cwd, gaf_base) # {CWD}/goa_human.gaf\n        wget_cmd = \"{HTTP}/{GAF}.gz\".format(HTTP=http, GAF=gaf_base)\n        dnld_file(wget_cmd, gaf_cwd, prt, loading_bar)\n        fin_gafs.append(gaf_cwd)\n    return fin_gafs", "response": "Download GAF files if necessary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a file from http. Save it in a file named by fout", "response": "def http_get(url, fout=None):\n    \"\"\"Download a file from http. Save it in a file named by fout\"\"\"\n    print('requests.get({URL}, stream=True)'.format(URL=url))\n    rsp = requests.get(url, stream=True)\n    if rsp.status_code == 200 and fout is not None:\n        with open(fout, 'wb') as prt:\n            for chunk in rsp:  # .iter_content(chunk_size=128):\n                prt.write(chunk)\n            print('  WROTE: {F}\\n'.format(F=fout))\n    else:\n        print(rsp.status_code, rsp.reason, url)\n        print(rsp.content)\n    return rsp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads a file from an ftp server", "response": "def ftp_get(fin_src, fout):\n    \"\"\"Download a file from an ftp server\"\"\"\n    assert fin_src[:6] == 'ftp://', fin_src\n    dir_full, fin_ftp = os.path.split(fin_src[6:])\n    pt0 = dir_full.find('/')\n    assert pt0 != -1, pt0\n    ftphost = dir_full[:pt0]\n    chg_dir = dir_full[pt0+1:]\n    print('FTP RETR {HOST} {DIR} {SRC} -> {DST}'.format(\n        HOST=ftphost, DIR=chg_dir, SRC=fin_ftp, DST=fout))\n    ftp = FTP(ftphost)  # connect to host, default port      ftp.ncbi.nlm.nih.gov\n    ftp.login()         # user anonymous, passwd anonymous@\n    ftp.cwd(chg_dir)    # change into \"debian\" directory     gene/DATA\n    cmd = 'RETR {F}'.format(F=fin_ftp)   #                   gene2go.gz\n    ftp.retrbinary(cmd, open(fout, 'wb').write)  #           /usr/home/gene2go.gz\n    ftp.quit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads specified file if necessary.", "response": "def dnld_file(src_ftp, dst_file, prt=sys.stdout, loading_bar=True):\n    \"\"\"Download specified file if necessary.\"\"\"\n    if os.path.isfile(dst_file):\n        return\n    do_gunzip = src_ftp[-3:] == '.gz' and dst_file[-3:] != '.gz'\n    dst_wget = \"{DST}.gz\".format(DST=dst_file) if do_gunzip else dst_file\n    # Write to stderr, not stdout so this message will be seen when running nosetests\n    wget_msg = \"wget({SRC} out={DST})\\n\".format(SRC=src_ftp, DST=dst_wget)\n    #### sys.stderr.write(\"  {WGET}\".format(WGET=wget_msg))\n    #### if loading_bar:\n    ####     loading_bar = wget.bar_adaptive\n    try:\n        #### wget.download(src_ftp, out=dst_wget, bar=loading_bar)\n        rsp = http_get(src_ftp, dst_wget) if src_ftp[:4] == 'http' else ftp_get(src_ftp, dst_wget)\n        if do_gunzip:\n            if prt is not None:\n                prt.write(\"  gunzip {FILE}\\n\".format(FILE=dst_wget))\n            gzip_open_to(dst_wget, dst_file)\n    except IOError as errmsg:\n        import traceback\n        traceback.print_exc()\n        sys.stderr.write(\"**FATAL cmd: {WGET}\".format(WGET=wget_msg))\n        sys.stderr.write(\"**FATAL msg: {ERR}\".format(ERR=str(errmsg)))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunzip a file. gz file.", "response": "def gzip_open_to(fin_gz, fout):\n    \"\"\"Unzip a file.gz file.\"\"\"\n    with gzip.open(fin_gz, 'rb') as zstrm:\n        with  open(fout, 'wb') as ostrm:\n            ostrm.write(zstrm.read())\n    assert os.path.isfile(fout), \"COULD NOT GUNZIP({G}) TO FILE({F})\".format(G=fin_gz, F=fout)\n    os.remove(fin_gz)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_rec(self, rec, line):\n        if 'def' in self.optional_attrs and line[:5] == \"def: \":\n            assert not hasattr(rec, 'defn'), \"ATTR(defn) ALREADY SET({VAL})\".format(VAL=rec.defn)\n            # Use 'defn' because 'def' is a reserved word in python\n            rec.defn = line[5:]\n        elif 'synonym' in self.optional_attrs and line[:9] == \"synonym: \":\n            rec.synonym.append(self._get_synonym(line[9:]))\n        # http://geneontology.org/page/ontology-relations\n        elif 'relationship' in self.optional_attrs and line[:14] == \"relationship: \":\n            # relationships are stored in a dict of sets, mirroring\n            # the structure implied in the GO DAG. Example:\n            #\n            #  relationship = {\n            #     'part_of': set(['GO:0021513', 'GO:0006310']),\n            #     'regulates': set(['GO:0006313']),\n            #     'negatively_regulates': set(['GO:0021910']),\n            #     'positively_regulates': set(['GO:0006313']),\n            # }\n            rel, goid = line[14:].split()[:2]\n            if rel not in rec.relationship:\n                rec.relationship[rel] = set([goid])\n            else:\n                rec.relationship[rel].add(goid)\n        elif 'xref' in self.optional_attrs and line[:6] == \"xref: \":\n            rec.xref.add(self._get_xref(line[6:]))\n        elif 'subset' in self.optional_attrs and line[:8] == \"subset: \":\n            rec.subset.add(line[8:])\n        elif 'comment' in self.optional_attrs and line[:9] == \"comment: \":\n            rec.comment = line[9:]", "response": "Update a record with optional attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize current GOTerm with data members for storing optional attributes.", "response": "def init_datamembers(self, rec):\n        \"\"\"Initialize current GOTerm with data members for storing optional attributes.\"\"\"\n        # pylint: disable=multiple-statements\n        if 'synonym'      in self.optional_attrs: rec.synonym = []\n        if 'xref'         in self.optional_attrs: rec.xref = set()\n        if 'subset'       in self.optional_attrs: rec.subset = set()\n        if 'comment'      in self.optional_attrs: rec.comment = \"\"\n        if 'relationship' in self.optional_attrs:\n            rec.relationship = {}\n            rec.relationship_rev = {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_synonym(self, line):\n        mtch = self.attr2cmp['synonym'].match(line)\n        text, scope, typename, dbxrefs, _ = mtch.groups()\n        typename = typename.strip()\n        dbxrefs = set(dbxrefs.split(', ')) if dbxrefs else set()\n        return self.attr2cmp['synonym nt']._make([text, scope, typename, dbxrefs])", "response": "Given line return optional attribute synonym value in a namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive line return optional attribute xref value in a dict of sets.", "response": "def _get_xref(self, line):\n        \"\"\"Given line, return optional attribute xref value in a dict of sets.\"\"\"\n        # Ex: Wikipedia:Zygotene\n        # Ex: Reactome:REACT_22295 \"Addition of a third mannose to ...\"\n        mtch = self.attr2cmp['xref'].match(line)\n        return mtch.group(1).replace(' ', '')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompiling search patterns for optional attributes if needed.", "response": "def _init_compile_patterns(optional_attrs):\n        \"\"\"Compile search patterns for optional attributes if needed.\"\"\"\n        attr2cmp = {}\n        if optional_attrs is None:\n            return attr2cmp\n        # \"peptidase inhibitor complex\" EXACT [GOC:bf, GOC:pr]\n        # \"blood vessel formation from pre-existing blood vessels\" EXACT systematic_synonym []\n        # \"mitochondrial inheritance\" EXACT []\n        # \"tricarboxylate transport protein\" RELATED [] {comment=\"WIkipedia:Mitochondrial_carrier\"}\n        if 'synonym' in optional_attrs:\n            attr2cmp['synonym'] = re.compile(r'\"(\\S.*\\S)\" ([A-Z]+) (.*)\\[(.*)\\](.*)$')\n            attr2cmp['synonym nt'] = cx.namedtuple(\"synonym\", \"text scope typename dbxrefs\")\n        # Wikipedia:Zygotene\n        # Reactome:REACT_27267 \"DHAP from Ery4P and PEP, Mycobacterium tuberculosis\"\n        if 'xref' in optional_attrs:\n            attr2cmp['xref'] = re.compile(r'^(\\S+:\\s*\\S+)\\b(.*)$')\n        return attr2cmp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_optional_attrs(optional_attrs):\n        attrs_opt = set(['def', 'defn', 'synonym', 'relationship', 'xref', 'subset', 'comment'])\n        # Required attributes are always loaded. All others are optionally loaded.\n        # Allow user to specify either: 'def' or 'defn'\n        #   'def' is an obo field name, but 'defn' is legal Python attribute name\n        getnm = lambda aopt: aopt if aopt != \"defn\" else \"def\"\n        # pylint: disable=redefined-variable-type\n        opts = None\n        if isinstance(optional_attrs, str) and optional_attrs in attrs_opt:\n            opts = set([getnm(optional_attrs)])\n        else:\n            opts = set([getnm(f) for f in optional_attrs if f in attrs_opt])\n        if opts:\n            return opts", "response": "Prepare to store data from user - desired optional fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommand - line script to print a GO term s lower - level hierarchy.", "response": "def cli():\n    \"\"\"Command-line script to print a GO term's lower-level hierarchy.\"\"\"\n    objcli = WrHierCli(sys.argv[1:])\n    fouts_txt = objcli.get_fouts()\n    if fouts_txt:\n        for fout_txt in fouts_txt:\n            objcli.wrtxt_hier(fout_txt)\n    else:\n        objcli.prt_hier(sys.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_fout_go(self):\n        assert self.goids, \"NO VALID GO IDs WERE PROVIDED AS STARTING POINTS FOR HIERARCHY REPORT\"\n        base = next(iter(self.goids)).replace(':', '')\n        upstr = '_up' if 'up' in self.kws else ''\n        return \"hier_{BASE}{UP}.{EXT}\".format(BASE=base, UP=upstr, EXT='txt')", "response": "Get the name of an output file based on the top GO term."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting hierarchy below specfied GO IDs to an ASCII file.", "response": "def wrtxt_hier(self, fout_txt):\n        \"\"\"Write hierarchy below specfied GO IDs to an ASCII file.\"\"\"\n        with open(fout_txt, 'wb') as prt:\n            self.prt_hier(prt)\n            print(\"  WROTE: {TXT}\".format(TXT=fout_txt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_hier(self, prt=sys.stdout):\n        objwr = WrHierGO(self.gosubdag, **self.kws)\n        assert self.goids, \"NO VALID GO IDs WERE PROVIDED\"\n        if 'up' not in objwr.usrset:\n            for goid in self.goids:\n                objwr.prt_hier_down(goid, prt)\n        else:\n            objwr.prt_hier_up(self.goids, prt)", "response": "Write hierarchy below specfied GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadjusting keywords if needed.", "response": "def _adj_item_marks(self):\n        \"\"\"Adjust keywords, if needed.\"\"\"\n        if 'item_marks' in self.kws:\n            # Process GO IDs specified in item_marks\n            goids = self._get_goids(self.kws['item_marks'])\n            # item_marks can take a list of GO IDs on cmdline or in a file.\n            #     --item_marks=GO:0043473,GO:0009987\n            #     --item_marks=item_marks.txt\n            if goids:\n                self.kws['item_marks'] = {go:'>' for go in goids}\n            else:\n                raise Exception(\"NO GO IDs FOUND IN item_marks\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadjust keywords if needed.", "response": "def _adj_include_only(self):\n        \"\"\"Adjust keywords, if needed.\"\"\"\n        if 'include_only' in self.kws:\n            # Process GO IDs specified in include_only\n            goids = self._get_goids(self.kws['include_only'])\n            # include_only can take a list of GO IDs on cmdline or in a file.\n            #     --include_only=GO:0043473,GO:0009987\n            #     --include_only=include_only.txt\n            if goids:\n                self.kws['include_only'] = goids\n            else:\n                raise Exception(\"NO GO IDs FOUND IN include_only\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint only GO IDs from associations and their ancestors.", "response": "def _adj_for_assc(self):\n        \"\"\"Print only GO IDs from associations and their ancestors.\"\"\"\n        if self.gene2gos:\n            gos_assoc = set(get_b2aset(self.gene2gos).keys())\n            if 'item_marks' not in self.kws:\n                self.kws['item_marks'] = {go:'>' for go in gos_assoc}\n            if 'include_only' not in self.kws:\n                gosubdag = GoSubDag(gos_assoc, self.gosubdag.go2obj,\n                                    self.gosubdag.relationships)\n                self.kws['include_only'] = gosubdag.go2obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_goids(gostr):\n        if 'GO:' in gostr:\n            return gostr.split(',')\n        elif os.path.exists(gostr):\n            return GetGOs().get_goids(None, gostr, sys.stdout)", "response": "Return GO IDs from a GO str or a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calc_pvalue(self, study_count, study_n, pop_count, pop_n):\n        fnc_call = \"calc_pvalue({SCNT}, {STOT}, {PCNT} {PTOT})\".format(\n            SCNT=study_count, STOT=study_n, PCNT=pop_count, PTOT=pop_n)\n        raise Exception(\"NOT IMPLEMENTED: {FNC_CALL} using {FNC}.\".format(\n            FNC_CALL=fnc_call, FNC=self.pval_fnc))", "response": "calc_pvalue is a wrapper for calc_pvalue in derived classes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate uncorrected p - values.", "response": "def calc_pvalue(self, study_count, study_n, pop_count, pop_n):\n        \"\"\"Calculate uncorrected p-values.\"\"\"\n        # k, n = study_true, study_tot,\n        # K, N = population_true, population_tot\n        # def pvalue_population(int k, int n, int K, int N): ...\n        return self.pval_fnc(study_count, study_n, pop_count, pop_n).two_tail"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_pvalue(self, study_count, study_n, pop_count, pop_n):\n        # http://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.fisher_exact.html\n        #\n        #         Atlantic  Indian                              YES       NO\n        # whales     8        2    | 10 whales    study_genes    8 scnt   2    | 10 = study_n\n        # sharks     1        5    |  6 sharks    not s_genes    1        5    |  6\n        #         --------  ------                            --------   -----\n        #            9        7      16 = pop_n     pop_genes    9 pcnt   7      16 = pop_n\n        #\n        # We use the preceeding table to find the p-value for whales/sharks:\n        #\n        # >>> import scipy.stats as stats\n        # >>> oddsratio, pvalue = stats.fisher_exact([[8, 2], [1, 5]])\n        #                                              a  b    c  d\n        avar = study_count\n        bvar = study_n - study_count\n        cvar = pop_count - study_count\n        dvar = pop_n - pop_count - bvar\n        assert cvar >= 0, self.fmterr.format(\n            A=avar, B=bvar, C=cvar, D=dvar, scnt=study_count, stot=study_n, pcnt=pop_count, ptot=pop_n)\n        # stats.fisher_exact returns oddsratio, pval_uncorrected\n        _, p_uncorrected = self.pval_fnc([[avar, bvar], [cvar, dvar]])\n        return p_uncorrected", "response": "Calculate uncorrected p - values for the given study count and pop count."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_pval_obj(self):\n        if self.pval_fnc_name in self.options.keys():\n            try:\n                fisher_obj = self.options[self.pval_fnc_name](self.pval_fnc_name, self.log)\n            except ImportError:\n                print(\"fisher module not installed.  Falling back on scipy.stats.fisher_exact\")\n                fisher_obj = self.options['fisher_scipy_stats']('fisher_scipy_stats', self.log)\n\n            return fisher_obj\n\n        raise Exception(\"PVALUE FUNCTION({FNC}) NOT FOUND\".format(FNC=self.pval_fnc_name))", "response": "Returns a Fisher object based on user - input."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the package is running on the supported Python version.", "response": "def check_version(self, name, majorv=2, minorv=7):\n        \"\"\" Make sure the package runs on the supported Python version\n        \"\"\"\n        if sys.version_info.major == majorv and sys.version_info.minor != minorv:\n            sys.stderr.write(\"ERROR: %s is only for >= Python %d.%d but you are running %d.%d\\n\" %\\\n                        (name, majorv, minorv, sys.version_info.major, sys.version_info.minor))\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_init(self, filename=\"__init__.py\"):\n        import ast\n\n        with open(filename) as init_file:\n            module = ast.parse(init_file.read())\n\n        itr = lambda x: (ast.literal_eval(node.value) for node in ast.walk(module) \\\n            if isinstance(node, ast.Assign) and node.targets[0].id == x)\n\n        try:\n            return next(itr(\"__author__\")), \\\n                   next(itr(\"__email__\")), \\\n                   next(itr(\"__license__\")), \\\n                   next(itr(\"__version__\"))\n        except StopIteration:\n            raise ValueError(\"One of author, email, license, or version\"\n                        \" cannot be found in {}\".format(filename))", "response": "Get various info from the package without importing them\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef missing_requirements(self, specifiers):\n        for specifier in specifiers:\n            try:\n                pkg_resources.require(specifier)\n            except pkg_resources.DistributionNotFound:\n                yield specifier", "response": "Find what s missing\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install_requirements(self, requires):\n        # Temporarily install dependencies required by setup.py before trying to import them.\n        sys.path[0:0] = ['setup-requires']\n        pkg_resources.working_set.add_entry('setup-requires')\n\n        to_install = list(self.missing_requirements(requires))\n        if to_install:\n            cmd = [sys.executable, \"-m\", \"pip\", \"install\",\n                \"-t\", \"setup-requires\"] + to_install\n            subprocess.call(cmd)", "response": "Install the specified requirements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint GO IDs grouped under broader GO terms or sections.", "response": "def prt_gos(self, prt=sys.stdout, **kws_usr):\n        \"\"\"Sort user GO ids, grouped under broader GO terms or sections. Print to screen.\"\"\"\n        # deprecated\n        # Keyword arguments (control content): hdrgo_prt section_prt use_sections\n        # desc2nts contains: (sections hdrgo_prt sortobj) or (flat hdrgo_prt sortobj)\n        desc2nts = self.get_desc2nts(**kws_usr)\n        # Keyword arguments (control print format): prt prtfmt\n        self.prt_nts(desc2nts, prt, kws_usr.get('prtfmt'))\n        return desc2nts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint grouped and sorted GO IDs.", "response": "def prt_nts(self, desc2nts, prt=sys.stdout, prtfmt=None):\n        \"\"\"Print grouped and sorted GO IDs.\"\"\"\n        # deprecated\n        # Set print format string\n        if prtfmt is None:\n            prtfmt = \"{{hdr1usr01:2}} {FMT}\\n\".format(FMT=self.grprobj.gosubdag.prt_attr['fmt'])\n        # 1-D: data to print is a flat list of namedtuples\n        if 'flat' in desc2nts:\n            prt_txt(prt, desc2nts['flat'], prtfmt=prtfmt)\n        # 2-D: data to print is a list of [(section, nts), ...\n        else:\n            WrSectionsTxt.prt_sections(prt, desc2nts['sections'], prtfmt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_desc2nts(self, **kws_usr):\n        # desc2nts contains: (sections hdrgo_prt sortobj) or (flat hdrgo_prt sortobj)\n        # keys_nts: hdrgo_prt section_prt top_n use_sections\n        kws_nts = {k:v for k, v in kws_usr.items() if k in self.keys_nts}\n        return self.get_desc2nts_fnc(**kws_nts)", "response": "Return grouped sorted namedtuples in either format flat sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_desc2nts_fnc(self, hdrgo_prt=True, section_prt=None,\n                         top_n=None, use_sections=True):\n        \"\"\"Return grouped, sorted namedtuples in either format: flat, sections.\"\"\"\n        # RETURN: flat list of namedtuples\n        nts_flat = self.get_nts_flat(hdrgo_prt, use_sections)\n        if nts_flat:\n            flds = nts_flat[0]._fields\n            if not use_sections:\n                return {'sortobj':self, 'flat' : nts_flat, 'hdrgo_prt':hdrgo_prt, 'flds':flds,\n                        'num_items':len(nts_flat), 'num_sections':1}\n            else:\n                return {'sortobj':self,\n                        'sections' : [(self.grprobj.hdrobj.secdflt, nts_flat)],\n                        'hdrgo_prt':hdrgo_prt,\n                        'flds':flds,\n                        'num_items':len(nts_flat), 'num_sections':1}\n        # print('FFFF Sorter:get_desc2nts_fnc: nts_flat is None')\n        # RETURN: 2-D list [(section_name0, namedtuples0), (section_name1, namedtuples1), ...\n        #     kws: top_n hdrgo_prt section_sortby\n        # Over-ride hdrgo_prt depending on top_n value\n        assert top_n is not True and top_n is not False, \\\n            \"top_n({T}) MUST BE None OR AN int\".format(T=top_n)\n        assert self.sectobj is not None, \"SECTIONS OBJECT DOES NOT EXIST\"\n        sec_sb = self.sectobj.section_sortby\n        # Override hdrgo_prt, if sorting by sections or returning a subset of GO IDs in section\n        hdrgo_prt_curr = hdrgo_prt is True\n        if sec_sb is True or (sec_sb is not False and sec_sb is not None) or top_n is not None:\n            hdrgo_prt_curr = False\n        # print('GGGG Sorter:get_desc2nts_fnc: hdrgo_prt_curr({}) sec_sb({}) top_n({})'.format(\n        #     hdrgo_prt_curr, sec_sb, top_n))\n        nts_section = self.sectobj.get_sorted_nts_keep_section(hdrgo_prt_curr)\n        # print('HHHH Sorter:get_desc2nts_fnc: nts_section')\n        # Take top_n in each section, if requested\n        if top_n is not None:\n            nts_section = [(s, nts[:top_n]) for s, nts in nts_section]\n            if section_prt is None:\n                nts_flat = self.get_sections_flattened(nts_section)\n                flds = nts_flat[0]._fields if nts_flat else []\n                return {'sortobj':self, 'flat' : nts_flat, 'hdrgo_prt':hdrgo_prt_curr, 'flds':flds,\n                        'num_items':len(nts_flat), 'num_sections':1}\n        # Send flat list of sections nts back, as requested\n        if section_prt is False:\n            nts_flat = self.get_sections_flattened(nts_section)\n            flds = nts_flat[0]._fields if nts_flat else []\n            return {'sortobj':self, 'flat' : nts_flat, 'hdrgo_prt':hdrgo_prt_curr, 'flds':flds,\n                    'num_items':len(nts_flat),\n                    'num_sections':len(nts_section)}\n        # Send 2-D sections nts back\n        # print('IIII Sorter:get_desc2nts_fnc: nts_section')\n        flds = nts_section[0][1][0]._fields if nts_section else []\n        return {'sortobj':self, 'sections' : nts_section, 'hdrgo_prt':hdrgo_prt_curr, 'flds':flds,\n                'num_items':sum(len(nts) for _, nts in nts_section),\n                'num_sections':len(nts_section)}", "response": "Return grouped sorted namedtuples in either format flat sections."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert list of section names to list of namedtuples.", "response": "def get_sections_flattened(section_nts):\n        \"\"\"Convert [(section0, nts0), (section1, nts1), ... to [*nts0, *nts1, ...\"\"\"\n        nt_flds = list(section_nts[0][1][0]._fields)\n        # Flatten section_nts 2-D list\n        if 'section' in nt_flds:\n            return [nt for _, nts in section_nts for nt in nts]\n        # Flatten section_nts 2-D list, and add sections to each namedtuple\n        nt_flds.append('section')\n        nts_flat = []\n        ntobj = cx.namedtuple(\"Nt\", \" \".join(nt_flds))\n        for section_name, nts in section_nts:\n            for nt_go in nts:\n                vals = list(nt_go) + [section_name]\n                nts_flat.append(ntobj._make(vals))\n        return nts_flat"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_nts_flat(self, hdrgo_prt=True, use_sections=True):\n        # Either there are no sections OR we are not using them\n        if self.sectobj is None or not use_sections:\n            return self.sortgos.get_nts_sorted(\n                hdrgo_prt,\n                hdrgos=self.grprobj.get_hdrgos(),\n                hdrgo_sort=True)\n        if not use_sections:\n            return self.sectobj.get_sorted_nts_omit_section(hdrgo_prt, hdrgo_sort=True)\n        return None", "response": "Return a flat list of sorted nts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fields(desc2nts):\n        if 'flat' in desc2nts:\n            nts_flat = desc2nts.get('flat')\n            if nts_flat:\n                return nts_flat[0]._fields\n        if 'sections' in desc2nts:\n            nts_sections = desc2nts.get('sections')\n            if nts_sections:\n                return nts_sections[0][1][0]._fields", "response": "Return grouped sorted namedtuples in either format flat sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_usrgos_w_parents(self, hdrgos, usrgos_all=None):\n        usrgos = set()\n        _go2parents = self.gosubdag.rcntobj.go2parents\n        if usrgos_all is None:\n            usrgos_all = self.usrgos\n        for usrgo in usrgos_all:\n            all_usrgo_parents = _go2parents.get(usrgo)\n            sel_usrgo_parents = all_usrgo_parents.intersection(hdrgos)\n            if sel_usrgo_parents:\n                usrgos.add(usrgo)\n        return usrgos", "response": "Get usrgos w / parents in hdrgos even if hdrgos did not get grouped under hdrgos."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sections_2d(self):\n        sections_hdrgos_act = []\n        hdrgos_act_all = self.get_hdrgos()  # Header GOs actually used to group\n        hdrgos_act_secs = set()\n        if self.hdrobj.sections:\n            for section_name, hdrgos_all_lst in self.hdrobj.sections:\n                # print(\"GGGGGGGGGGGGGGGGG {N:3} {NAME}\".format(N=len(hdrgos_all_lst), NAME=section_name))\n                hdrgos_all_set = set(hdrgos_all_lst)\n                hdrgos_act_set = hdrgos_all_set.intersection(hdrgos_act_all)\n                if hdrgos_act_set:\n                    hdrgos_act_secs |= hdrgos_act_set\n                    # Use original order of header GOs found in sections\n                    hdrgos_act_lst = []\n                    hdrgos_act_ctr = cx.Counter()\n                    for hdrgo_p in hdrgos_all_lst: # Header GO that may or may not be used.\n                        if hdrgo_p in hdrgos_act_set and hdrgos_act_ctr[hdrgo_p] == 0:\n                            hdrgos_act_lst.append(hdrgo_p)\n                        hdrgos_act_ctr[hdrgo_p] += 1\n                    sections_hdrgos_act.append((section_name, hdrgos_act_lst))\n            # print(\">>>>>>>>>>>>>>> hdrgos_act_all {N:3}\".format(N=len(hdrgos_act_all)))\n            # print(\">>>>>>>>>>>>>>> hdrgos_act_secs {N:3}\".format(N=len(hdrgos_act_secs)))\n            hdrgos_act_rem = hdrgos_act_all.difference(hdrgos_act_secs)\n            if hdrgos_act_rem:\n                # print(\"RRRRRRRRRRR {N:3}\".format(N=len(hdrgos_act_rem)))\n                sections_hdrgos_act.append((self.hdrobj.secdflt, hdrgos_act_rem))\n        else:\n            sections_hdrgos_act.append((self.hdrobj.secdflt, hdrgos_act_all))\n        return sections_hdrgos_act", "response": "Get 2 - D list of sections and hdrgos sets actually used in grouping."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets usrgos in a requested section.", "response": "def get_usrgos_g_section(self, section=None):\n        \"\"\"Get usrgos in a requested section.\"\"\"\n        if section is None:\n            section = self.hdrobj.secdflt\n        if section is True:\n            return self.usrgos\n        # Get dict of sections and hdrgos actually used in grouping\n        section2hdrgos = cx.OrderedDict(self.get_sections_2d())\n        hdrgos_lst = section2hdrgos.get(section, None)\n        if hdrgos_lst is not None:\n            hdrgos_set = set(hdrgos_lst)\n            hdrgos_u = hdrgos_set.intersection(self.hdrgo_is_usrgo)\n            hdrgos_h = hdrgos_set.intersection(self.hdrgo2usrgos.keys())\n            usrgos = set([u for h in hdrgos_h for u in self.hdrgo2usrgos.get(h)])\n            usrgos |= hdrgos_u\n            return usrgos\n        return set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_section2items(self, itemkey):\n        sec_items = []\n        section2usrnts = self.get_section2usrnts()\n        for section, usrnts in section2usrnts.items():\n            items = set([e for nt in usrnts for e in getattr(nt, itemkey, set())])\n            sec_items.append((section, items))\n        return cx.OrderedDict(sec_items)", "response": "Collect all items into a single set per section."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hdrgos_g_usrgos(self, usrgos):\n        hdrgos_for_usrgos = set()\n        hdrgos_all = self.get_hdrgos()\n        usrgo2hdrgo = self.get_usrgo2hdrgo()\n        for usrgo in usrgos:\n            if usrgo in hdrgos_all:\n                hdrgos_for_usrgos.add(usrgo)\n                continue\n            hdrgo_cur = usrgo2hdrgo.get(usrgo, None)\n            if hdrgo_cur is not None:\n                hdrgos_for_usrgos.add(hdrgo_cur)\n        return hdrgos_for_usrgos", "response": "Return hdrgos which contain the usrgos."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a flat list of sections and hdrgos actually used in grouping.", "response": "def get_section_hdrgos_nts(self, sortby=None):\n        \"\"\"Get a flat list of sections and hdrgos actually used in grouping.\"\"\"\n        nts_all = []\n        section_hdrgos_actual = self.get_sections_2d()\n        flds_all = ['Section'] + self.gosubdag.prt_attr['flds']\n        ntobj = cx.namedtuple(\"NtGoSec\", \" \".join(flds_all))\n        flds_go = None\n        if sortby is None:\n            sortby = lambda nt: -1*nt.dcnt\n        for section_name, hdrgos_actual in section_hdrgos_actual:\n            nts_sec = []\n            for hdrgo_nt in self.gosubdag.get_go2nt(hdrgos_actual).values():\n                if flds_go is None:\n                    flds_go = hdrgo_nt._fields\n                key2val = {key:val for key, val in zip(flds_go, list(hdrgo_nt))}\n                key2val['Section'] = section_name\n                nts_sec.append(ntobj(**key2val))\n            nts_all.extend(sorted(nts_sec, key=sortby))\n        return nts_all"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget high GO IDs that are actually used to group current set of GO IDs.", "response": "def get_sections_2d_nts(self, sortby=None):\n        \"\"\"Get high GO IDs that are actually used to group current set of GO IDs.\"\"\"\n        sections_2d_nts = []\n        for section_name, hdrgos_actual in self.get_sections_2d():\n            hdrgo_nts = self.gosubdag.get_nts(hdrgos_actual, sortby=sortby)\n            sections_2d_nts.append((section_name, hdrgo_nts))\n        return sections_2d_nts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_usrgos_g_hdrgos(self, hdrgos):\n        usrgos_all = set()\n        if isinstance(hdrgos, str):\n            hdrgos = [hdrgos]\n        for hdrgo in hdrgos:\n            usrgos_cur = self.hdrgo2usrgos.get(hdrgo, None)\n            if usrgos_cur is not None:\n                usrgos_all |= usrgos_cur\n            if hdrgo in self.hdrgo_is_usrgo:\n                usrgos_all.add(hdrgo)\n        return usrgos_all", "response": "Return usrgos under provided hdrgos."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hdrgo2usrgos(self, hdrgos):\n        get_usrgos = self.hdrgo2usrgos.get\n        hdrgos_actual = self.get_hdrgos().intersection(hdrgos)\n        return {h:get_usrgos(h) for h in hdrgos_actual}", "response": "Return a subset of hdrgo2usrgos."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict with all user GO IDs as keys and their respective header GOs as values.", "response": "def get_usrgo2hdrgo(self):\n        \"\"\"Return a dict with all user GO IDs as keys and their respective header GOs as values.\"\"\"\n        usrgo2hdrgo = {}\n        for hdrgo, usrgos in self.hdrgo2usrgos.items():\n            for usrgo in usrgos:\n                assert usrgo not in usrgo2hdrgo\n                usrgo2hdrgo[usrgo] = hdrgo\n        # Add usrgos which are also a hdrgo and the GO group contains no other GO IDs\n        for goid in self.hdrgo_is_usrgo:\n            usrgo2hdrgo[goid] = goid\n        assert len(self.usrgos) <= len(usrgo2hdrgo), \\\n            \"USRGOS({U}) != USRGO2HDRGO({H}): {GOs}\".format(\n                U=len(self.usrgos),\n                H=len(usrgo2hdrgo),\n                GOs=self.usrgos.symmetric_difference(set(usrgo2hdrgo.keys())))\n        return usrgo2hdrgo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict with actual header and user GO IDs as keys and their sections as values.", "response": "def get_go2sectiontxt(self):\n        \"\"\"Return a dict with actual header and user GO IDs as keys and their sections as values.\"\"\"\n        go2txt = {}\n        _get_secs = self.hdrobj.get_sections\n        hdrgo2sectxt = {h:\" \".join(_get_secs(h)) for h in self.get_hdrgos()}\n        usrgo2hdrgo = self.get_usrgo2hdrgo()\n        for goid, ntgo in self.go2nt.items():\n            hdrgo = ntgo.GO if ntgo.is_hdrgo else usrgo2hdrgo[ntgo.GO]\n            go2txt[goid] = hdrgo2sectxt[hdrgo]\n        return go2txt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_usrgo2sections(self):\n        usrgo2sections = cx.defaultdict(set)\n        usrgo2hdrgo = self.get_usrgo2hdrgo()\n        get_sections = self.hdrobj.get_sections\n        for usrgo, hdrgo in usrgo2hdrgo.items():\n            sections = set(get_sections(hdrgo))\n            usrgo2sections[usrgo] |= sections\n        assert len(usrgo2sections) >= len(self.usrgos), \\\n            \"uGOS({U}) != uGO2sections({H}): {GOs}\".format(\n                U=len(self.usrgos),\n                H=len(usrgo2sections),\n                GOs=self.usrgos.symmetric_difference(set(usrgo2sections.keys())))\n        return usrgo2sections", "response": "Return a dict with all user GO IDs as keys and their sections as values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fout_base(self, goid, name=None, pre=\"gogrp\"):\n        goobj = self.gosubdag.go2obj[goid]\n        if name is None:\n            name = self.grpname.replace(\" \", \"_\")\n        sections = \"_\".join(self.hdrobj.get_sections(goid))\n        return \"{PRE}_{BP}_{NAME}_{SEC}_{DSTR}_{D1s}_{GO}\".format(\n            PRE=pre,\n            BP=Consts.NAMESPACE2NS[goobj.namespace],\n            NAME=self._str_replace(name),\n            SEC=self._str_replace(self._str_replace(sections)),\n            GO=goid.replace(\":\", \"\"),\n            DSTR=self._get_depthsr(goobj),\n            D1s=self.gosubdag.go2nt[goobj.id].D1)", "response": "Get a filename for a single header GO ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns DNN or RNN depending on if relationships are loaded.", "response": "def _get_depthsr(self, goobj):\n        \"\"\"Return DNN or RNN depending on if relationships are loaded.\"\"\"\n        if 'reldepth' in self.gosubdag.prt_attr['flds']:\n            return \"R{R:02}\".format(R=goobj.reldepth)\n        return \"D{D:02}\".format(D=goobj.depth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _str_replace(txt):\n        txt = txt.replace(\",\", \"\")\n        txt = txt.replace(\" \", \"_\")\n        txt = txt.replace(\":\", \"\")\n        txt = txt.replace(\".\", \"\")\n        txt = txt.replace(\"/\", \"\")\n        txt = txt.replace(\"\", \"\")\n        return txt", "response": "Makes a small text amenable to being used in a filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prt_summary(self, prt=sys.stdout):\n        # Grouping summary\n        fmtstr = \"Grouped: {U:3,} User GOs, using {h:2,} of {H:,} Grouping GOs, for run: {NAME}\\n\"\n        prt.write(fmtstr.format(\n            NAME=self.grpname,\n            U=len(self.usrgos),\n            h=len(self.hdrobj.hdrgos.intersection(self.hdrgo2usrgos.keys())),\n            H=self.hdrobj.num_hdrgos()))", "response": "Print summary of grouping and sorting run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget print format given fields.", "response": "def get_prtfmt_list(self, flds, add_nl=True):\n        \"\"\"Get print format, given fields.\"\"\"\n        fmts = []\n        for fld in flds:\n            if fld[:2] == 'p_':\n                fmts.append('{{{FLD}:8.2e}}'.format(FLD=fld))\n            elif fld in self.default_fld2fmt:\n                fmts.append(self.default_fld2fmt[fld])\n            else:\n                raise Exception(\"UNKNOWN FORMAT: {FLD}\".format(FLD=fld))\n        if add_nl:\n            fmts.append(\"\\n\")\n        return fmts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    import argparse\n    prs = argparse.ArgumentParser(__doc__,\n                                  formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\n    prs.add_argument('--taxon_id', type=str,\n                     help='NCBI taxon ID, must match exact species/strain used by GO Central, e.g. 4896 for S Pombe')\n    prs.add_argument('--golr_url', default='http://golr.geneontology.org/solr/', type=str,\n                     help='NCBI taxon ID, must match exact species/strain used by GO Central, e.g. 4896 for S Pombe')\n    prs.add_argument('-o', default=None, type=str,\n                     help=\"Specifies the name of the output file\")\n    prs.add_argument('--max_rows', default=100000, type=int,\n                     help=\"maximum rows to be fetched\")\n\n    args = prs.parse_args()\n\n    solr = pysolr.Solr(args.golr_url, timeout=30)\n\n    sys.stderr.write(\"TAX:\"+args.taxon_id+\"\\n\")\n    results = solr.search(q='document_category:\"bioentity\" AND taxon:\"NCBITaxon:'+args.taxon_id+'\"',\n                          fl='bioentity_label,annotation_class_list', rows=args.max_rows)\n    sys.stderr.write(\"NUM GENES:\"+str(len(results))+\"\\n\")\n    if (len(results) ==0):\n        sys.stderr.write(\"NO RESULTS\")\n        exit(1)\n    if (len(results) == args.max_rows):\n        sys.stderr.write(\"max_rows set too low\")\n        exit(1)\n\n    file_out = sys.stdout if args.o is None else open(args.o, 'w')\n    for r in results:\n        gene_symbol = r['bioentity_label']\n        sys.stderr.write(gene_symbol+\"\\n\")\n        if 'annotation_class_list' in r:\n            file_out.write(r['bioentity_label']+\"\\t\" + ';'.join(r['annotation_class_list'])+\"\\n\")\n        else:\n            sys.stderr.write(\"no annotations for \"+gene_symbol+\"\\n\")\n            \n\n    if args.o is not None:\n        file_out.close()\n        sys.stdout.write(\"  WROTE: {}\\n\".format(args.o))", "response": "Fetch simple gene - term assocaitions from Golr using bioentity document type one line per gene."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_short_plot_name(self, goobj):\n        name = goobj.name\n        if self._keep_this(name):\n            return self.replace_greek(name)\n        name = name.replace(\"cellular response to chemical stimulus\",\n                            \"cellular rsp. to chemical stim.\")\n        depth = goobj.depth\n        if depth > 1:\n            name = name.replace(\"regulation of \", \"reg. of \")\n            name = name.replace(\"positive reg\", \"+reg\")\n            name = name.replace(\"negative reg\", \"-reg\")\n            name = name.replace(\"involved in\", \"in\")\n        if depth > 2:\n            name = name.replace(\"antigen processing and presentation\", \"a.p.p\")\n            name = name.replace(\"MHC class I\", \"MHC-I\")\n            if depth == 4:\n                if goobj.id == \"GO:0002460\":\n                    before = \" \".join([\n                        \"adaptive immune response based on somatic recombination of\",\n                        \"immune receptors built from immunoglobulin superfamily domains\"])\n                    name = name.replace(\n                        before,\n                        \"rsp. based on somatic recombination of Ig immune receptors\")\n            if depth > 3:\n                name = name.replace(\"signaling pathway\", \"sig. pw.\")\n                name = name.replace(\"response\", \"rsp.\")\n                name = name.replace(\"immunoglobulin superfamily domains\", \"Ig domains\")\n                name = name.replace(\"immunoglobulin\", \"Ig\")\n            if depth > 4:\n                name = name.replace(\"production\", \"prod.\")\n            if depth == 6 or depth == 5:\n                name = name.replace(\"tumor necrosis factor\", \"TNF\")\n        name = self.replace_greek(name)\n        return name", "response": "Shorten some GO names so plots are smaller."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshortens GO name for tables in paper.", "response": "def shorten_go_name_ptbl1(self, name):\n        \"\"\"Shorten GO name for tables in paper.\"\"\"\n        if self._keep_this(name):\n            return name\n        name = name.replace(\"negative\", \"neg.\")\n        name = name.replace(\"positive\", \"pos.\")\n        name = name.replace(\"response\", \"rsp.\")\n        name = name.replace(\"regulation\", \"reg.\")\n        name = name.replace(\"antigen processing and presentation\", \"app.\")\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshortening GO name for Table 3 in manuscript.", "response": "def shorten_go_name_ptbl3(self, name, dcnt):\n        \"\"\"Shorten GO description for Table 3 in manuscript.\"\"\"\n        if self._keep_this(name):\n            return name\n        name = name.replace(\"positive regulation of immune system process\",\n                            \"+ reg. of immune sys. process\")\n        name = name.replace(\"positive regulation of immune response\",\n                            \"+ reg. of immune response\")\n        name = name.replace(\"positive regulation of cytokine production\",\n                            \"+ reg. of cytokine production\")\n        if dcnt < 40:\n            name = name.replace(\"antigen processing and presentation\", \"a.p.p.\")\n        if dcnt < 10:\n            name = name.replace(\"negative\", \"-\")\n            name = name.replace(\"positive\", \"+\")\n            #name = name.replace(\"tumor necrosis factor production\", \"tumor necrosis factor prod.\")\n            name = name.replace(\"tumor necrosis factor production\", \"TNF production\")\n        if dcnt < 4:\n            name = name.replace(\"regulation\", \"reg.\")\n            name = name.replace(\"exogenous \", \"\")\n            name = name.replace(\" via \", \" w/\")\n            name = name.replace(\"T cell mediated cytotoxicity\", \"cytotoxicity via T cell\")\n        name = name.replace('involved in', 'in')\n        name = name.replace('-positive', '+')\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_greek(self, name):\n        name = name.replace('gamma-delta', 'gammadelta')\n        name = name.replace('interleukin-1 beta', 'interleukin-1beta')\n        greek_present = False\n        for greek_txt, uni in self.greek2uni.items():\n            if greek_txt in name:\n                greek_present = True\n                name = name.replace(greek_txt, \"{B}\".format(B=uni))\n        if greek_present is True:\n            name = unicode(name, 'utf-8') # For writing to xlsx\n        return name", "response": "Replace text representing greek letters with greek letters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing text representing greek letters with greek letters.", "response": "def replace_greek_tex(self, name):\n        \"\"\"Replace text representing greek letters with greek letters.\"\"\"\n        name = name.replace('gamma-delta', 'gammadelta')\n        name = name.replace('interleukin-1 beta', 'interleukin-1beta')\n        # greek_present = False\n        for greek_txt, tex in self.greek2tex.items():\n            if greek_txt in name:\n                # greek_present = True\n                name = name.replace(greek_txt, \"{B}\".format(B=tex))\n        # if greek_present is True:\n        #     name = texcode(name, 'utf-8') # For writing to xlsx\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shorten_go_name_all(self, name):\n        name = self.replace_greek(name)\n        name = name.replace(\"MHC class I\", \"MHC-I\")\n        return name", "response": "Shorten GO name for tables in paper supplemental materials and plots."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _keep_this(self, name):\n        for keep_name in self.keep:\n            if name == keep_name:\n                return True\n        return False", "response": "Return True if there are no modifications to name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading letter aliases from a text file created by GoDepth1LettersWr.", "response": "def read_d1_letter(fin_txt):\n    \"\"\"Reads letter aliases from a text file created by GoDepth1LettersWr.\"\"\"\n    go2letter = {}\n    re_goid = re.compile(r\"(GO:\\d{7})\")\n    with open(fin_txt) as ifstrm:\n        for line in ifstrm:\n            mtch = re_goid.search(line)\n            if mtch and line[:1] != ' ':\n                # Alias is expected to be the first character\n                go2letter[mtch.group(1)] = line[:1]\n    return go2letter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite goids into a table.", "response": "def wr_xlsx(self, fout_xlsx, goids, sortby=None, **kws_usr):\n        \"\"\"Write goids into a table.\"\"\"\n        nts = GoSubDag(goids, self.go2obj).get_nts(goids, sortby)\n        kws_wr = kws_usr.copy()\n        if 'fld2col_widths' not in kws_wr:\n            kws_wr['fld2col_widths'] = self.fld2col_widths\n        wr_xlsx_tbl(fout_xlsx, nts, **kws_wr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting goids into a table.", "response": "def wr_xlsx_sections(self, fout_xlsx, sections, sortby=None, **kws_usr):\n        \"\"\"Write goids into a table.\"\"\"\n        nts = self.get_nts_sections(sections, sortby)\n        kws_wr = kws_usr.copy()\n        if 'fld2col_widths' not in kws_wr:\n            kws_wr['fld2col_widths'] = self.fld2col_widths\n        else:\n            fld2col_widths = self.fld2col_widths.copy()\n            for fld, wid in kws_usr['fld2col_widths'].items():\n                fld2col_widths[fld] = wid\n            kws_wr['fld2col_widths'] = fld2col_widths\n        wr_xlsx_sections_tbl(fout_xlsx, nts, **kws_wr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list of sections containing GO IDs get a list of sections w / GO nts.", "response": "def get_nts_sections(self, sections, sortby=None):\n        \"\"\"Given a list of sections containing GO IDs, get a list of sections w/GO nts.\"\"\"\n        goids = self.get_goids_sections(sections)\n        gosubdag = GoSubDag(goids, self.go2obj)\n        return [(sec, gosubdag.get_nts(gos, sortby)) for sec, gos in sections]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all the GO IDs in a 2 - D sections list.", "response": "def get_goids_sections(sections):\n        \"\"\"Return all the GO IDs in a 2-D sections list.\"\"\"\n        goids_all = set()\n        for _, goids_sec in sections:\n            goids_all |= set(goids_sec)\n        return goids_all"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prt_txt(self, prt=sys.stdout, pre=''):\n        data_nts = self.get_d1nts()\n        for ntdata in data_nts:\n            prt.write(\"{PRE}{L:1} {NS} {d:6,} D{D:02} {GO} {NAME}\\n\".format(\n                PRE=pre,\n                L=ntdata.D1,\n                d=ntdata.dcnt,\n                NS=ntdata.NS,\n                D=ntdata.depth,\n                GO=ntdata.GO,\n                NAME=ntdata.name))\n        return data_nts", "response": "Print letters descendant count GO and name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wr_xlsx(self, fout_xlsx=\"gos_depth01.xlsx\", **kws):\n        data_nts = self.get_d1nts()\n        if 'fld2col_widths' not in kws:\n            kws['fld2col_widths'] = {'D1': 6, 'NS':3, 'depth': 5, 'GO': 12, 'name': 40}\n        if 'hdrs' not in kws:\n            kws['hdrs'] = self.hdrs\n        wr_xlsx_tbl(fout_xlsx, data_nts, **kws)", "response": "Write xlsx table of depth - 01 GO terms and their letter representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite text table of depth - 01 GO terms and their letter representation.", "response": "def wr_txt(self, fout_txt=\"gos_depth01.txt\", title=None):\n        \"\"\"write text table of depth-01 GO terms and their letter representation.\"\"\"\n        with open(fout_txt, 'w') as prt:\n            self.prt_header(prt, title)\n            data_nts = self.prt_txt(prt)\n            sys.stdout.write(\"  {N:>5} items WROTE: {TXT}\\n\".format(\n                N=len(data_nts), TXT=fout_txt))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite text table of depth - 01 GO terms and their letter representation.", "response": "def prt_header(prt, title=None, pre=''):\n        \"\"\"write text table of depth-01 GO terms and their letter representation.\"\"\"\n        if title is not None:\n            prt.write(\"{PRE}{TITLE}\\n\".format(TITLE=title, PRE=pre))\n            prt.write('{PRE}\\n'.format(PRE=pre))\n        prt.write(\"{PRE}    D1 : Letter representing the depth-01 GO term\\n\".format(PRE=pre))\n        prt.write(\"{PRE}    dcnt: Total number of all descendants\\n\".format(PRE=pre))\n        prt.write(\"{PRE}    dep: Depth; The maximum length path to \".format(PRE=pre))\n        prt.write(\"{PRE}leaf-level (childless) GO descendant(s)\\n\".format(PRE=pre))\n        prt.write(\"{PRE}\\n\".format(PRE=pre))\n        prt.write(\"{PRE}D1 NS  dcnt dep GO ID      Description\\n\".format(PRE=pre))\n        prt.write(\"{PRE}- -- ------ --- ---------- ------------------------------\\n\".format(\n            PRE=pre))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wr_tex(self, fout_tex=\"gos_depth01.tex\"):\n        data_nts = self.get_d1nts()\n        joinchr = \" & \"\n        #pylint: disable=anomalous-backslash-in-string\n        eol = \" \\\\\\\\\\n\"\n        with open(fout_tex, 'w') as prt:\n            prt.write(\"\\\\begin{table}[!ht]\\n\")\n            prt.write(\"\\\\begin{tabular}{|p{.5cm} | p{.5cm} | >{\\\\raggedleft}p{.9cm} \")\n            prt.write(\"|p{.7cm} |p{1.8cm} |p{9cm}|}\\n\")\n            prt.write(\"\\multicolumn{6}{c}{} \\\\\\\\\\n\")\n            prt.write(\"\\hline\\n\")\n            prt.write(\"\\\\rowcolor{gray!10}\\n\")\n            prt.write(\"{HDRS}{EOL}\".format(\n                HDRS=joinchr.join(next(iter(data_nts))._fields), EOL=eol))\n            prt.write(\"\\hline\\n\")\n            for idx, line in enumerate(get_lines(data_nts, joinchr=joinchr, eol=eol)):\n                if idx%2 == 1:\n                    prt.write(\"\\\\rowcolor{gray!7}\\n\")\n                line.replace('_', '\\\\_')\n                prt.write(line)\n            prt.write(\"\\hline\\n\")\n            prt.write(\"\\end{tabular}\\n\")\n            caption = (\"The descendant counts of GO terms at depth-01 are highly skewed. The \"\n                       \"root term, \\textit{biological\\_process} has over twenty GO children at \"\n                       \"depth-01 shown in the table sorted by their number of descendants \"\n                       \"(dcnt) with \\textit{cellular process} at the top having 18k+ \"\n                       \"descendants and \\textit{cell killing} near the bottom having only \"\n                       \"about 100 descendants. The first column (D1) contains a letter used as \"\n                       \"an alias for each depth-01 GO term. The second column represents the \"\n                       \"number of descendants from the specified GO term from down to the total  \"\n                       \"of its descendant leaf-level GO terms, which have no child GO terms.\")\n            prt.write(\"\\caption{{{TEXT}}}\\n\\n\".format(TEXT=caption))\n            prt.write(\"\\label{table:supptbl_d1}\\n\")\n            prt.write(\"\\end{table}\\n\")\n            sys.stdout.write(\"  {N:>5} items WROTE: {TXT}\\n\".format(\n                N=len(data_nts), TXT=fout_tex))", "response": "Write a text table of depth - 01 GO terms and their letter representation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_d1nts(self):\n        data = []\n        ntdata = cx.namedtuple(\"NtPrt\", \"D1 NS dcnt depth GO name\")\n        namespace = None\n        for ntlet in sorted(self.goone2ntletter.values(),\n                            key=lambda nt: [nt.goobj.namespace, -1 * nt.dcnt, nt.D1]):\n            goobj = ntlet.goobj\n            goid = goobj.id\n            assert len(goobj.parents) == 1\n            if namespace != goobj.namespace:\n                namespace = goobj.namespace\n                ntns = self.ns2nt[namespace]\n                pobj = ntns.goobj\n                ns2 = self.str2ns[goobj.namespace]\n                data.append(ntdata._make([\" \", ns2, ntns.dcnt, pobj.depth, pobj.id, pobj.name]))\n            data.append(ntdata._make(\n                [ntlet.D1, self.str2ns[namespace], ntlet.dcnt, goobj.depth, goid, goobj.name]))\n        return data", "response": "Get letters for depth - 01 GO terms descendants count and GO information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_ns2nt(rcntobj):\n        go2dcnt = rcntobj.go2dcnt\n        ntobj = cx.namedtuple(\"NtD1\", \"D1 dcnt goobj\")\n        d0s = rcntobj.depth2goobjs[0]\n        ns_nt = [(o.namespace, ntobj(D1=\"\", dcnt=go2dcnt[o.id], goobj=o)) for o in d0s]\n        return cx.OrderedDict(ns_nt)", "response": "Save depth - 00 GO terms ordered using descendants cnt."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wr_xlsx_gos(self, fout_xlsx, **kws_usr):\n        # Keyword arguments: control content\n        desc2nts = self.sortobj.get_desc2nts(**kws_usr)\n        # Keyword arguments: control xlsx format\n        self.wr_xlsx_nts(fout_xlsx, desc2nts, **kws_usr)\n        return desc2nts", "response": "Write an Excel spreadsheet with user GO ids grouped under broader GO terms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wr_xlsx_nts(self, fout_xlsx, desc2nts, **kws_usr):\n        # KWS_XLSX: top_n section_prt section_sortby\n        # Adjust xlsx keyword args\n        kws_xlsx = self._get_xlsx_kws(**kws_usr)\n        # KWS_SHADE: shade_hdrgos hdrgo_prt section_sortby top_n\n        shade_hdrgos = self._get_shade_hdrgos(**kws_usr)\n        self._adjust_prt_flds(kws_xlsx, desc2nts, shade_hdrgos)\n        # 1-D: data to print is a flat list of namedtuples\n        if 'flat' in desc2nts:\n            nts = desc2nts.get('flat')\n            # sys.stdout.write(\"FLAT NTS: {FLDS}\\n\".format(FLDS=\" \".join(next(iter(nts))._fields)))\n            wr_xlsx(fout_xlsx, nts, **kws_xlsx)\n        # 2-D: data to print is a list of [(section, nts), ...\n        else:\n            sections_hdrgos = desc2nts.get('sections')\n            wr_xlsx_sections(fout_xlsx, sections_hdrgos, **kws_xlsx)", "response": "Print grouped and sorted GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wr_txt_gos(self, fout_txt, **kws_usr):\n        # Keyword arguments: control content: hdrgo_prt section_prt top_n use_sections\n        desc2nts = self.sortobj.get_desc2nts(**kws_usr)\n        # Keyword arguments: control txt format\n        self.wr_txt_nts(fout_txt, desc2nts)\n        return desc2nts", "response": "Write an Excel spreadsheet with user GO ids grouped under broader GO terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wr_txt_nts(self, fout_txt, desc2nts, prtfmt=None):\n        with open(fout_txt, 'w') as prt:\n            summary_dct = self._prt_txt_desc2nts(prt, desc2nts, prtfmt)\n            if summary_dct:\n                print(self.sortobj.grprobj.fmtsum.format(\n                    ACTION=\"WROTE:\", FILE=fout_txt, **summary_dct))\n            else:\n                print(\"  WROTE: {TXT}\".format(TXT=fout_txt))", "response": "Write grouped and sorted GO IDs to a text file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prt_txt_desc2nts(self, prt, desc2nts, prtfmt=None):\n        if prtfmt is None:\n            prtfmt = self.get_prtfmt(\"fmta\")\n        if self.ver_list is not None:\n            prt.write(\"# Versions:\\n#    {VER}\\n\".format(VER=\"\\n#    \".join(self.ver_list)))\n        self.prt_txt_desc2nts(prt, desc2nts, prtfmt)", "response": "Print grouped and sorted GO IDs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint grouped and sorted GO IDs.", "response": "def prt_txt_desc2nts(self, prt, desc2nts, prtfmt):\n        \"\"\"Print grouped and sorted GO IDs.\"\"\"\n        # 1-D: data to print is a flat list of namedtuples\n        if 'flat' in desc2nts:\n            nts = desc2nts.get('flat')\n            # sys.stdout.write(\"FLAT NTS: {FLDS}\\n\".format(FLDS=\" \".join(next(iter(nts))._fields)))\n            prt_txt(prt, nts, prtfmt)\n        # 2-D: data to print is a list of [(section, nts), ...\n        else:\n            for section, nts in desc2nts['sections']:\n                prt.write(\"\\nSECTION: {SEC}\\n\".format(SEC=section))\n                prt_txt(prt, nts, prtfmt)\n            grprobj = self.sortobj.grprobj\n            dat = SummarySec2dHdrGos().summarize_sec2hdrnts(desc2nts['sections'])\n            ugos_y = dat['G'].intersection(grprobj.usrgos)\n            ugos_n = dat['U'].intersection(grprobj.usrgos)\n            return {'GO_DESC':'usr', 'SECs':len(dat['S']), 'GOs':len(ugos_y),\n                    'UNGRP':len(ugos_n), 'undesc':'ungrpd'}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_xlsx_kws(self, **kws_usr):\n        kws_xlsx = {'fld2col_widths':self._get_fld2col_widths(**kws_usr), 'items':'GO IDs'}\n        remaining_keys = set(['title', 'hdrs', 'prt_flds', 'fld2fmt',\n                              'ntval2wbfmtdict', 'ntfld_wbfmt'])\n        for usr_key, usr_val in kws_usr.items():\n            if usr_key in remaining_keys:\n                kws_xlsx[usr_key] = usr_val\n        return kws_xlsx", "response": "Return keyword arguments relevant to writing an xlsx."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _adjust_prt_flds(self, kws_xlsx, desc2nts, shade_hdrgos):\n        # Use xlsx prt_flds from the user, if provided\n        if \"prt_flds\" in kws_xlsx:\n            return kws_xlsx[\"prt_flds\"]\n        # If the user did not provide specific fields to print in an xlsx file:\n        dont_print = set(['hdr_idx', 'is_hdrgo', 'is_usrgo'])\n        # Are we printing GO group headers?\n        # Build new list of xlsx print fields, excluding those which add no new information\n        prt_flds_adjusted = []\n        # Get all namedtuple fields\n        nt_flds = self.sortobj.get_fields(desc2nts)\n        # Keep fields intended for print and optionally gray-shade field (format_txt)\n        # print('FFFFFFFFFFFFFFF WrXlsxSortedGos::_adjust_prt_flds:', nt_flds)\n        for nt_fld in nt_flds:\n            if nt_fld not in dont_print:\n                # Only add grey-shade to hdrgo and section name rows if hdrgo_prt=True\n                if nt_fld == \"format_txt\":\n                    if shade_hdrgos is True:\n                        prt_flds_adjusted.append(nt_fld)\n                else:\n                    prt_flds_adjusted.append(nt_fld)\n        kws_xlsx['prt_flds'] = prt_flds_adjusted", "response": "Print user - requested fields or provided fields minus info fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_fld2col_widths(self, **kws):\n        fld2col_widths = self._init_fld2col_widths()\n        if 'fld2col_widths' not in kws:\n            return fld2col_widths\n        for fld, val in kws['fld2col_widths'].items():\n            fld2col_widths[fld] = val\n        return fld2col_widths", "response": "Return xlsx column widths based on default and user - specified field - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_fld2col_widths(self):\n        # GO info namedtuple fields: NS dcnt level depth GO D1 name\n        # GO header namedtuple fields: format_txt hdr_idx\n        fld2col_widths = GoSubDagWr.fld2col_widths.copy()\n        for fld, wid in self.oprtfmt.default_fld2col_widths.items():\n            fld2col_widths[fld] = wid\n        for fld in get_hdridx_flds():\n            fld2col_widths[fld] = 2\n        return fld2col_widths", "response": "Return default column widths for writing an Excel Spreadsheet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn print format for Grouper which includes hdr1usr01 and num_usrgos.", "response": "def get_prtfmt(self, key=\"fmta\"):\n        \"\"\"Return print format for Grouper, which includes hdr1usr01 and num_usrgos.\"\"\"\n        prtfmt = self.sortobj.grprobj.gosubdag.prt_attr[key]\n        prtfmt = prtfmt.replace(\"{NS}\", \"{NS} {num_usrgos:>4} uGOs\")\n        return \"\".join(['{hdr1usr01:2}', prtfmt, '\\n'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if user - sepcified hdrgo_prt is set and False if user - sepcified hdrgo_prt is set to False.", "response": "def _get_shade_hdrgos(**kws):\n        \"\"\"If no hdrgo_prt specified, and these conditions are present -> hdrgo_prt=F.\"\"\"\n        # KWS: shade_hdrgos hdrgo_prt section_sortby top_n\n        if 'shade_hdrgos' in kws:\n            return kws['shade_hdrgos']\n        # Return user-sepcified hdrgo_prt, if provided\n        if 'hdrgo_prt' in kws:\n            return kws['hdrgo_prt']\n        # If no hdrgo_prt provided, set hdrgo_prt to False if:\n        #   * section_sortby == True\n        #   * section_sortby = user_sort\n        #   * top_n == N\n        if 'section_sortby' in kws and kws['section_sortby']:\n            return False\n        if 'top_n' in kws and isinstance(kws['top_n'], int):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_study_items(self):\n        study_items = set()\n        for rec in self.goea_results:\n            study_items |= rec.study_items\n        return study_items", "response": "Get all study items in the GOEA result set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive GOEA namedtuples return nts w / P - value in string format.", "response": "def get_nts_strpval(self, fmt=\"{:8.2e}\"):\n        \"\"\"Given GOEA namedtuples, return nts w/P-value in string format.\"\"\"\n        objntmgr = MgrNts(self.goea_results)\n        dcts = objntmgr.init_dicts()\n        # pylint: disable=line-too-long\n        pval_flds = set(k for k in self._get_fieldnames(next(iter(self.goea_results))) if k[:2] == 'p_')\n        for fld_float in pval_flds:\n            fld_str = \"s_\" + fld_float[2:]\n            objntmgr.add_f2str(dcts, fld_float, fld_str, fmt)\n        return objntmgr.mknts(dcts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndefaulting sorting of GOEA results.", "response": "def dflt_sortby_objgoea(goea_res):\n        \"\"\"Default sorting of GOEA results.\"\"\"\n        return [getattr(goea_res, 'enrichment'),\n                getattr(goea_res, 'namespace'),\n                getattr(goea_res, 'p_uncorrected'),\n                getattr(goea_res, 'depth'),\n                getattr(goea_res, 'GO')]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dflt_sortby_ntgoea(ntgoea):\n        return [ntgoea.enrichment,\n                ntgoea.namespace,\n                ntgoea.p_uncorrected,\n                ntgoea.depth,\n                ntgoea.GO]", "response": "Default sorting of GOEA results stored in namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_goea_nts_prt(self, fldnames=None, **usr_kws):\n        kws = usr_kws.copy()\n        if 'not_fldnames' not in kws:\n            kws['not_fldnames'] = ['goterm', 'parents', 'children', 'id']\n        if 'rpt_fmt' not in kws:\n            kws['rpt_fmt'] = True\n        return self.get_goea_nts_all(fldnames, **kws)", "response": "Return list of namedtuples removing fields which are redundant or verbose."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_goea_nts_all(self, fldnames=None, **kws):\n        # kws: prt_if indent itemid2name(study_items)\n        data_nts = [] # A list of namedtuples containing GOEA results\n        if not self.goea_results:\n            return data_nts\n        keep_if = kws.get('keep_if', None)\n        rpt_fmt = kws.get('rpt_fmt', False)\n        indent = kws.get('indent', False)\n        # I. FIELD (column) NAMES\n        not_fldnames = kws.get('not_fldnames', None)\n        if fldnames is None:\n            fldnames = self._get_fieldnames(self.goea_results[0])\n        # Ia. Explicitly exclude specific fields from named tuple\n        if not_fldnames is not None:\n            fldnames = [f for f in fldnames if f not in not_fldnames]\n        nttyp = cx.namedtuple(\"NtGoeaResults\", \" \".join(fldnames))\n        goid_idx = fldnames.index(\"GO\") if 'GO' in fldnames else None\n        # II. Loop through GOEA results stored in a GOEnrichmentRecord object\n        for goerec in self.goea_results:\n            vals = self._get_field_values(goerec, fldnames, rpt_fmt, kws.get('itemid2name', None))\n            if indent:\n                vals[goid_idx] = \"\".join([goerec.get_indent_dots(), vals[goid_idx]])\n            ntobj = nttyp._make(vals)\n            if keep_if is None or keep_if(goerec):\n                data_nts.append(ntobj)\n        return data_nts", "response": "Get all GOEA data from the GOEnrichmentRecord objects in a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_field_values(item, fldnames, rpt_fmt=None, itemid2name=None):\n        if hasattr(item, \"_fldsdefprt\"): # Is a GOEnrichmentRecord\n            return item.get_field_values(fldnames, rpt_fmt, itemid2name)\n        if hasattr(item, \"_fields\"): # Is a namedtuple\n            return [getattr(item, f) for f in fldnames]", "response": "Return fieldnames and values of either a namedtuple or GOEnrichmentRecord."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fieldnames(item):\n        if hasattr(item, \"_fldsdefprt\"): # Is a GOEnrichmentRecord\n            return item.get_prtflds_all()\n        if hasattr(item, \"_fields\"): # Is a namedtuple\n            return item._fields", "response": "Return fieldnames of either a namedtuple or GOEnrichmentRecord."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bordercolor(self):\n        hdrgos_all = self.grprobj.hdrobj.get_hdrgos()\n        hdrgos_unused = hdrgos_all.difference(self.hdrgos_actual)\n        go2bordercolor = {}\n        # hdrgos that went unused\n        for hdrgo in hdrgos_unused:\n            go2bordercolor[hdrgo] = self.hdrcol_all\n        # hdrgos used in this grouping that are NOT usrgos\n        for hdrgo in self.grprobj.hdrgo2usrgos.keys():\n            go2bordercolor[hdrgo] = self.hdrcol_all\n        # hdrgos used in this grouping that ARE usrgos\n        for hdrgo in self.grprobj.hdrgo_is_usrgo:\n            go2bordercolor[hdrgo] = 'blue'\n        # usrgos which are NOT hdrgos\n        usrgos_rem = self.grprobj.usrgos.difference(self.grprobj.hdrgo_is_usrgo)\n        for usrgo in usrgos_rem:\n            go2bordercolor[usrgo] = '#029386'  # teal\n        # print(\"{N:5} hdrgos actual\".format(N=len(self.hdrgos_actual)))\n        # print(\"{N:5} hdrgos unused\".format(N=len(hdrgos_unused)))\n        # print(\"{N:5} hdrgos only       BLACK\".format(N=len(self.grprobj.hdrgo2usrgos.keys())))\n        # print(\"{N:5} usrgos\".format(N=len(self.grprobj.usrgos)))\n        # print(\"{N:5} usrgos AND hdrgos BLUE\".format(N=len(self.grprobj.hdrgo_is_usrgo)))\n        # print(\"{N:5} usrgos Only\".format(N=len(usrgos_rem)))\n        return go2bordercolor", "response": "Get bordercolor based on hdrgos and usergos."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets go2color for user and header GO IDs.", "response": "def get_go2color_users(self,\n                           usrgo_color='#feffa3', # yellow\n                           hdrusrgo_color='#d4ffea', # green\n                           hdrgo_color='#eee6f6'): # purple\n        \"\"\"Get go2color for GO DAG plots.\"\"\"\n        go2color = {}\n        # Color user GO IDs\n        for goid in self.usrgos:\n            go2color[goid] = usrgo_color\n        # Color header GO IDs. Headers which are also GO IDs get their own color.\n        for goid_hdr in self.hdrgos_actual:\n            go2color[goid_hdr] = hdrusrgo_color if goid_hdr in self.usrgos else hdrgo_color\n        return go2color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning gene product ASCII art.", "response": "def run(self, name, goea_nts, log):\n        \"\"\"Run gene product ASCII art.\"\"\"\n        objaart = AArtGeneProductSetsOne(name, goea_nts, self)\n        if self.hdrobj.sections:\n            return objaart.prt_report_grp1(log)\n        else:\n            return objaart.prt_report_grp0(log)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints summary of all GOEAs in name_marks_list.", "response": "def prt_mrks(self, name_marks_list, prt=sys.stdout):\n        \"\"\"Print summary of all GOEAs.\n           Example:\n             Key for GO sections:\n             A immune\n             B viral/bacteria\n             C neuro\n             D cell death\n             E lipid\n             F adhesion\n             G cell cycle\n             H chromosome\n             I development\n             J extracellular matrix\n             K ion\n             L localization\n             M membrane\n             N metabolic\n             O phosphorylation\n             P signaling\n             Q stimulus\n             R prolif_differ\n             S Misc.\n\n             ABCDEFGHIJKLMNOPQRS\n             XX.X..XXX..X.XX.XXX transient_increase\n             XX.XXX.....X.X.XXXX consistent_increase\n             XXXXXX..XXXXXXXXXXX late_increase\n             ..X.....X.XX.X....X consistent_decrease\n             ..X.XX..X.XX.XXX.XX late_decrease\n        \"\"\"\n        if not name_marks_list:\n            return\n        # prt.write(\"\\nKey for GO sections:\\n\")\n        # self.prt_section_key(prt)\n        prt.write(\"\\n{HDR}\\n\".format(HDR=self.str_hdr()))\n        for name, mark in name_marks_list:\n            if mark is not None:\n                prt.write(\"{MRKS} {NAME}\\n\".format(MRKS=\"\".join(mark), NAME=name))\n        prt.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the section name and its alias.", "response": "def prt_section_key(self, prt=sys.stdout):\n        \"\"\"Print the section name and its alias.\"\"\"\n        for section_name, letter in self.sec2chr.items():\n            prt.write(\"{ABC} {SEC_NAME}\\n\".format(ABC=letter, SEC_NAME=section_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict with the ASCII art character as key and its index as value.", "response": "def get_chr2idx(self):\n        \"\"\"Return a dict with the ASCII art character as key and its index as value.\"\"\"\n        return {chr(ascii_int):idx for idx, ascii_int in enumerate(self.all_chrints)}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_kws(self):\n        # Return user-specified GO formatting, if specfied:\n        if 'fmtgo' not in self.kws:\n            self.kws['fmtgo'] = self.grprdflt.gosubdag.prt_attr['fmt'] + \"\\n\"\n        if 'fmtgo2' not in self.kws:\n            self.kws['fmtgo2'] = self.grprdflt.gosubdag.prt_attr['fmt'] + \"\\n\"\n        if 'fmtgene' not in self.kws:\n            if 'itemid2name' not in self.kws:\n                self.kws['fmtgene'] = \"{AART} {ID}\\n\"\n            else:\n                self.kws['fmtgene'] = \"{AART} {ID} {NAME}\\n\"\n        if 'fmtgene2' not in self.kws:\n            self.kws['fmtgene2'] = self.kws['fmtgene']", "response": "Fill default values for keyword args if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a set of relationships found in all subset GO Terms.", "response": "def _init_relationships(self, relationships_arg):\n        \"\"\"Return a set of relationships found in all subset GO Terms.\"\"\"\n        if relationships_arg:\n            relationships_all = self._get_all_relationships()\n            if relationships_arg is True:\n                return relationships_all\n            else:\n                return relationships_all.intersection(relationships_arg)\n        return set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all GO Dag relationships seen in GO Dag subset.", "response": "def _get_all_relationships(self):\n        \"\"\"Return all relationships seen in GO Dag subset.\"\"\"\n        relationships_all = set()\n        for goterm in self.go2obj.values():\n            if goterm.relationship:\n                relationships_all.update(goterm.relationship)\n            if goterm.relationship_rev:\n                relationships_all.update(goterm.relationship_rev)\n        return relationships_all"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes GO sources and GO2OBJs.", "response": "def _init_gos(self, go_sources_arg, relationships_arg):\n        \"\"\"Initialize GO sources.\"\"\"\n        # No GO sources provided\n        if not go_sources_arg:\n            assert self.go2obj_orig, \"go2obj MUST BE PRESENT IF go_sources IS NOT\"\n            self.go_sources = set(self.go2obj_orig)\n            self.go2obj = self.go2obj_orig\n            sys.stdout.write(\"**NOTE: {N:,} SOURCE GO IDS\\n\".format(N=len(self.go_sources)))\n            return\n        # GO sources provided\n        go_sources = self._init_go_sources(go_sources_arg, self.go2obj_orig)\n        # Create new go2obj_user subset matching GO sources\n        # Fill with source and parent GO IDs and alternate GO IDs\n        go2obj_user = {}\n        objrel = CurNHigher(relationships_arg, self.go2obj_orig)\n        objrel.get_id2obj_cur_n_high(go2obj_user, go_sources)\n        # Add additional GOTerm information, if needed for user task\n        kws_gos = {k:v for k, v in self.kws.items() if k in self.kws_aux_gos}\n        if kws_gos:\n            self._add_goterms_kws(go2obj_user, kws_gos)\n        self.go_sources = go_sources\n        self.go2obj = go2obj_user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_goterms_kws(self, go2obj_user, kws_gos):\n        if 'go2color' in kws_gos:\n            for goid in kws_gos['go2color'].keys():\n                self._add_goterms(go2obj_user, goid)", "response": "Add more GO terms to go2obj_user if requested and relevant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd alt GO IDs to go2obj subset if requested and relevant.", "response": "def _add_goterms(self, go2obj_user, goid):\n        \"\"\"Add alt GO IDs to go2obj subset, if requested and relevant.\"\"\"\n        goterm = self.go2obj_orig[goid]\n        if goid != goterm.id and goterm.id in go2obj_user and goid not in go2obj_user:\n            go2obj_user[goid] = goterm"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_go_sources(self, go_sources_arg, go2obj_arg):\n        gos_user = set(go_sources_arg)\n        if 'children' in self.kws and self.kws['children']:\n            gos_user |= get_leaf_children(gos_user, go2obj_arg)\n        gos_godag = set(go2obj_arg)\n        gos_source = gos_user.intersection(gos_godag)\n        gos_missing = gos_user.difference(gos_godag)\n        if not gos_missing:\n            return gos_source\n        sys.stdout.write(\"{N} GO IDs NOT FOUND IN GO DAG: {GOs}\\n\".format(\n            N=len(gos_missing), GOs=\" \".join([str(e) for e in gos_missing])))\n        return gos_source", "response": "Return GO sources which are present in GODag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning None or user - provided CountRelatives object.", "response": "def get_rcntobj(self):\n        \"\"\"Return None or user-provided CountRelatives object.\"\"\"\n        # rcntobj value in kws can be: None, False, True, CountRelatives object\n        if 'rcntobj' in self.kws:\n            rcntobj = self.kws['rcntobj']\n            if isinstance(rcntobj, CountRelatives):\n                return rcntobj\n            return CountRelatives(\n                self.go2obj,  # Subset go2obj contains only items needed by go_sources\n                self.relationships,\n                dcnt='dcnt' in self.kw_elems,\n                go2letter=self.kws.get('go2letter'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_go2nt_all(self, rcntobj):\n        if 'go2nt' in self.kws:\n            go2nt = self.kws['go2nt']\n            return {go:go2nt[go] for go in self.go2obj}\n        else:\n            return self._get_go2nt_all(rcntobj)", "response": "For each GO id put all printable fields in one namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_prt_flds(self):\n        # Create namedtuple fields or copy namedtuple fields\n        if 'go2nt' not in self.kws:\n            return self.__init_prt_flds()\n        else:\n            return next(iter(self.kws['go2nt'].values()))._asdict()", "response": "Return the print fields in the go2nt namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the print fields in the go2nt namedtuple.", "response": "def __init_prt_flds(self):\n        \"\"\"Return the print fields in the go2nt namedtuple.\"\"\"\n        prt_flds = ['NS', 'level', 'depth']\n        if self.relationships:\n            prt_flds.append('reldepth')\n        prt_flds.extend(['GO', 'alt', 'GO_name'])\n        if 'dcnt' in self.kw_elems:\n            prt_flds.append('dcnt')\n        if 'D1' in self.kw_elems:\n            prt_flds.append('D1')\n        if 'tcnt' in self.kw_elems:\n            prt_flds.append('tcnt')\n            prt_flds.append('tfreq')\n            prt_flds.append('tinfo')\n        if self.relationships:\n            prt_flds.append('childcnt')\n            prt_flds.append('REL')\n            prt_flds.append('REL_short')\n            prt_flds.append('rel')\n        prt_flds.append('id')\n        return prt_flds"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_prt_fmt(self, alt=False):\n        # prt_fmt = [ #                                                        rcnt\n        #     '{GO} # {NS}  L{level:02} D{depth:02} {GO_name}',\n        #     '{GO} # {NS} {dcnt:6,} L{level:02} D{depth:02} {D1:5} {GO_name}']\n        prt_fmt = []\n        if alt:\n            prt_fmt.append('{GO}{alt:1}')\n        else:\n            prt_fmt.append('{GO}')\n        prt_fmt.append('# {NS}')\n        if 'dcnt' in self.prt_flds:\n            prt_fmt.append('{dcnt:5}')\n        if 'childcnt' in self.prt_flds:\n            prt_fmt.append('{childcnt:3}')\n        if 'tcnt' in self.prt_flds:\n            prt_fmt.append(\"{tcnt:7,}\")\n        if 'tfreq' in self.prt_flds:\n            prt_fmt.append(\"{tfreq:8.6f}\")\n        if 'tinfo' in self.prt_flds:\n            prt_fmt.append(\"{tinfo:5.2f}\")\n        prt_fmt.append('L{level:02} D{depth:02}')\n        if self.relationships:\n            prt_fmt.append('R{reldepth:02}')\n        if 'D1' in self.prt_flds:\n            prt_fmt.append('{D1:5}')\n        if 'REL' in self.prt_flds:\n            prt_fmt.append('{REL}')\n            prt_fmt.append('{rel}')\n        prt_fmt.append('{GO_name}')\n        return \" \".join(prt_fmt)", "response": "Return the format for printing a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_go2nt_all(self, rcntobj):\n        ### tic = timeit.default_timer()\n        go2nt = {}\n        ntobj = cx.namedtuple(\"NtGo\", \" \".join(self.prt_flds))\n        ### tic = _rpt_hms(tic, \"GoSubDag: _Init::get_go2nt\")\n        tcntobj = self.kws['tcntobj'] if 'tcntobj' in self.kws else None\n        b_tcnt = tcntobj is not None\n        # b_rcnt = rcntobj is not None and rcntobj\n        objrelstr = RelationshipStr(self.relationships)\n        namespace2ns = objrelstr.consts.NAMESPACE2NS\n        for goid, goobj in self.go2obj.items():\n            ns_go = namespace2ns[goobj.namespace]\n            fld2vals = {\n                'NS' : ns_go,\n                'level' : goobj.level,\n                'depth' : goobj.depth,\n                'GO' : goid,\n                'alt' : '' if goid == goobj.id else 'a',\n                'id' : goobj.id,\n                'GO_name' : goobj.name}\n            if 'dcnt' in self.kw_elems:\n                fld2vals['dcnt'] = rcntobj.go2dcnt.get(goid)\n            if 'D1' in self.kw_elems:\n                fld2vals['D1'] = rcntobj.get_d1str(goobj)\n            if b_tcnt:\n                tcnt = tcntobj.gocnts[goid]\n                num_ns = float(tcntobj.aspect_counts[goobj.namespace])\n                tfreq = float(tcnt)/num_ns if num_ns != 0 else 0\n                fld2vals['tcnt'] = tcnt\n                fld2vals['tfreq'] = tfreq\n                fld2vals['tinfo'] = -1.0 * math.log(tfreq) if tfreq else 0\n            if self.relationships:\n                fld2vals['childcnt'] = len(goobj.children)\n                fld2vals['reldepth'] = goobj.reldepth\n                fld2vals['REL'] = objrelstr.str_relationships(goobj)\n                fld2vals['REL_short'] = objrelstr.str_rel_short(goobj)\n                fld2vals['rel'] = objrelstr.str_relationships_rev(goobj)\n            go2nt[goid] = ntobj(**fld2vals)\n        ### tic = _rpt_hms(tic, \"GoSubDag: _Init::get_go2nt\")\n        return go2nt", "response": "Get all GO2NT fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plt_goids(gosubdag, fout_img, goids, **kws_plt):\n    gosubdag_plt = GoSubDag(goids, gosubdag.go2obj, rcntobj=gosubdag.rcntobj, **kws_plt)\n    godagplot = GoSubDagPlot(gosubdag_plt, **kws_plt)\n    godagplot.plt_dag(fout_img)\n    return godagplot", "response": "Plot GO IDs in a DAG."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_gos(fout_img, goids, go2obj, **kws):\n    gosubdag = GoSubDag(goids, go2obj, rcntobj=True)\n    godagplot = GoSubDagPlot(gosubdag, **kws)\n    godagplot.plt_dag(fout_img)", "response": "Given GO ids and the obo_dag create a plot of paths from GO ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of GOEA results plot result GOs up to top.", "response": "def plot_results(fout_img, goea_results, **kws):\n    \"\"\"Given a list of GOEA results, plot result GOs up to top.\"\"\"\n    if \"{NS}\" not in fout_img:\n        plt_goea_results(fout_img, goea_results, **kws)\n    else:\n        # Plot separately by NS: BP, MF, CC\n        ns2goea_results = cx.defaultdict(list)\n        for rec in goea_results:\n            ns2goea_results[rec.NS].append(rec)\n        for ns_name, ns_res in ns2goea_results.items():\n            fout = fout_img.format(NS=ns_name)\n            plt_goea_results(fout, ns_res, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a single page of GOEA results.", "response": "def plt_goea_results(fout_img, goea_results, **kws):\n    \"\"\"Plot a single page.\"\"\"\n    go_sources = [rec.GO for rec in goea_results]\n    go2obj = {rec.GO:rec.goterm for rec in goea_results}\n    gosubdag = GoSubDag(go_sources, go2obj, rcntobj=True)\n    godagplot = GoSubDagPlot(gosubdag, goea_results=goea_results, **kws)\n    godagplot.plt_dag(fout_img)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the set of all relations.", "response": "def get_relations_cnt(self):\n        \"\"\"Get the set of all relations.\"\"\"\n        return cx.Counter([e.relation for es in self.exts for e in es])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting colors of GO terms based on user - specified colors based on source GO IDs and level - 01 GO IDs.", "response": "def init_goid2color(self):\n        \"\"\"Set colors of GO terms.\"\"\"\n        goid2color = {}\n        # 1. User-specified colors for each GO term\n        if 'go2color' in self.kws:\n            for goid, color in self.kws['go2color'].items():\n                goid2color[goid] = color\n        # 2. colors based on p-value override colors based on source GO\n        if self.objgoea is not None:\n            self.objgoea.set_goid2color_pval(goid2color)\n        key2color = self.kws.get('key2col')\n        if key2color is not None:\n            # 3. Default GO source color\n            if 'go_sources' in key2color:\n                color = key2color['go_sources']\n                go2obj = self.gosubdag.go2obj\n                for goid in self.gosubdag.go_sources:\n                    if goid not in goid2color:\n                        goobj = go2obj[goid]\n                        goid2color[goobj.id] = color\n                        goid2color[goid] = color\n            # 4. Level-01 GO color\n            if 'level_01' in key2color:\n                color = key2color['level_01']\n                for goid, goobj in self.gosubdag.go2obj.items():\n                    if goobj.level == 1:\n                        if goid not in goid2color:\n                            goid2color[goid] = color\n        return goid2color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding equivalent GO IDs to go2color if necessary.", "response": "def _init_equiv(self):\n        \"\"\"Add equivalent GO IDs to go2color, if necessary.\"\"\"\n        gocolored_all = set(self.go2color)\n        go2obj_usr = self.gosubdag.go2obj\n        go2color_add = {}\n        for gocolored_cur, color in self.go2color.items():\n            # Ignore GOs in go2color that are not in the user set\n            if gocolored_cur in go2obj_usr:\n                goobj = go2obj_usr[gocolored_cur]\n                goids_equiv = goobj.alt_ids.union([goobj.id])\n                # mrk_alt = \"*\" if gocolored_cur != goobj.id else \"\"\n                # print(\"COLORED({}) KEY({}){:1} ALL({})\".format(\n                #     gocolored_cur, goobj.id, mrk_alt, goids_equiv))\n                # Loop through GO IDs which are not colored, but are equivalent to colored GO IDs.\n                for goid_add in goids_equiv.difference(gocolored_all):\n                    if goid_add in go2color_add:\n                        print('**TBD: TWO DIFFERENT COLORS FOR EQUIV GO ID') # pylint: disable=superfluous-parens\n                    go2color_add[goid_add] = color\n        # print(\"ADDING {N} GO IDs TO go2color\".format(N=len(go2color_add)))\n        for goid, color in go2color_add.items():\n            self.go2color[goid] = color"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns pval for 1st method. If method_flds is empty returns uncorrected pval.", "response": "def get_pvalue(self):\n        \"\"\"Returns pval for 1st method, if it exists. Else returns uncorrected pval.\"\"\"\n        if self.method_flds:\n            return getattr(self, \"p_{m}\".format(m=self.get_method_name()))\n        return getattr(self, \"p_uncorrected\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_corrected_pval(self, nt_method, pvalue):\n        self.method_flds.append(nt_method)\n        fieldname = \"\".join([\"p_\", nt_method.fieldname])\n        setattr(self, fieldname, pvalue)", "response": "Set the corrected pvalue for the object based on the method name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _chk_fields(field_data, field_formatter):\n        if len(field_data) == len(field_formatter):\n            return\n        len_dat = len(field_data)\n        len_fmt = len(field_formatter)\n        msg = [\n            \"FIELD DATA({d}) != FORMATTER({f})\".format(d=len_dat, f=len_fmt),\n            \"DAT({N}): {D}\".format(N=len_dat, D=field_data),\n            \"FMT({N}): {F}\".format(N=len_fmt, F=field_formatter)]\n        raise Exception(\"\\n\".join(msg))", "response": "Check that expected fields are present."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting goterm and copy GOTerm s name and namespace.", "response": "def set_goterm(self, go2obj):\n        \"\"\"Set goterm and copy GOTerm's name and namespace.\"\"\"\n        if self.GO in go2obj:\n            goterm = go2obj[self.GO]\n            self.goterm = goterm\n            self.name = goterm.name\n            self.depth = goterm.depth\n            self.NS = self.namespace2NS[self.goterm.namespace]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_enrichment(self):\n        if self.study_n:\n            return 'e' if ((1.0 * self.study_count / self.study_n) >\n                           (1.0 * self.pop_count / self.pop_n)) else 'p'\n        return 'p'", "response": "Mark as enriched or purified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinishing updating self ( GOEnrichmentRecord ) field is_ratio_different.", "response": "def update_remaining_fldsdefprt(self, min_ratio=None):\n        \"\"\"Finish updating self (GOEnrichmentRecord) field, is_ratio_different.\"\"\"\n        self.is_ratio_different = is_ratio_different(min_ratio, self.study_count,\n                                                     self.study_n, self.pop_count, self.pop_n)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_prtflds_all(self):\n        flds = []\n        dont_add = set(['_parents', 'method_flds', 'relationship_rev', 'relationship'])\n        # Fields: GO NS enrichment name ratio_in_study ratio_in_pop p_uncorrected\n        #         depth study_count p_sm_bonferroni p_fdr_bh study_items\n        self._flds_append(flds, self.get_prtflds_default(), dont_add)\n        # Fields: GO NS goterm\n        #         ratio_in_pop pop_n pop_count pop_items name\n        #         ratio_in_study study_n study_count study_items\n        #         method_flds enrichment p_uncorrected p_sm_bonferroni p_fdr_bh\n        self._flds_append(flds, vars(self).keys(), dont_add)\n        # Fields: name level is_obsolete namespace id depth parents children _parents alt_ids\n        self._flds_append(flds, vars(self.goterm).keys(), dont_add)\n        return flds", "response": "When converting to a namedtuple get all possible fields in their original order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding fields to the list.", "response": "def _flds_append(flds, addthese, dont_add):\n        \"\"\"Retain order of fields as we add them once to the list.\"\"\"\n        for fld in addthese:\n            if fld not in flds and fld not in dont_add:\n                flds.append(fld)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field_values(self, fldnames, rpt_fmt=True, itemid2name=None):\n        row = []\n        # Loop through each user field desired\n        for fld in fldnames:\n            # 1. Check the GOEnrichmentRecord's attributes\n            val = getattr(self, fld, None)\n            if val is not None:\n                if rpt_fmt:\n                    val = self._get_rpt_fmt(fld, val, itemid2name)\n                row.append(val)\n            else:\n                # 2. Check the GO object for the field\n                val = getattr(self.goterm, fld, None)\n                if rpt_fmt:\n                    val = self._get_rpt_fmt(fld, val, itemid2name)\n                if val is not None:\n                    row.append(val)\n                else:\n                    # 3. Field not found, raise Exception\n                    self._err_fld(fld, fldnames)\n            if rpt_fmt:\n                assert not isinstance(val, list), \\\n                   \"UNEXPECTED LIST: FIELD({F}) VALUE({V}) FMT({P})\".format(\n                       P=rpt_fmt, F=fld, V=val)\n        return row", "response": "Get flat namedtuple fields for one GOEnrichmentRecord."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_rpt_fmt(fld, val, itemid2name=None):\n        if fld.startswith(\"ratio_\"):\n            return \"{N}/{TOT}\".format(N=val[0], TOT=val[1])\n        elif fld in set(['study_items', 'pop_items', 'alt_ids']):\n            if itemid2name is not None:\n                val = [itemid2name.get(v, v) for v in val]\n            return \", \".join([str(v) for v in sorted(val)])\n        return val", "response": "Return values in a format amenable to printing in a table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _err_fld(self, fld, fldnames):\n        msg = ['ERROR. UNRECOGNIZED FIELD({F})'.format(F=fld)]\n        actual_flds = set(self.get_prtflds_default() + self.goterm.__dict__.keys())\n        bad_flds = set(fldnames).difference(set(actual_flds))\n        if bad_flds:\n            msg.append(\"\\nGOEA RESULT FIELDS: {}\".format(\" \".join(self._fldsdefprt)))\n            msg.append(\"GO FIELDS: {}\".format(\" \".join(self.goterm.__dict__.keys())))\n            msg.append(\"\\nFATAL: {N} UNEXPECTED FIELDS({F})\\n\".format(\n                N=len(bad_flds), F=\" \".join(bad_flds)))\n            msg.append(\"  {N} User-provided fields:\".format(N=len(fldnames)))\n            for idx, fld in enumerate(fldnames, 1):\n                mrk = \"ERROR -->\" if fld in bad_flds else \"\"\n                msg.append(\"  {M:>9} {I:>2}) {F}\".format(M=mrk, I=idx, F=fld))\n        raise Exception(\"\\n\".join(msg))", "response": "Print detailed Failure message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun Gene Ontology Enrichment Study on study ids.", "response": "def run_study(self, study, **kws):\n        \"\"\"Run Gene Ontology Enrichment Study (GOEA) on study ids.\"\"\"\n        if not study:\n            return []\n        # Key-word arguments:\n        methods = Methods(kws['methods']) if 'methods' in kws else self.methods\n        alpha = kws['alpha'] if 'alpha' in kws else self.alpha\n        log = kws['log'] if 'log' in kws else self.log\n        # Calculate uncorrected pvalues\n        results = self.get_pval_uncorr(study, log)\n        if not results:\n            return []\n\n        if log is not None:\n            log.write(\"  {MSG}\\n\".format(MSG=\"\\n  \".join(self.get_results_msg(results, study))))\n\n        # Do multipletest corrections on uncorrected pvalues and update results\n        self._run_multitest_corr(results, methods, alpha, study, log)\n\n        for rec in results:\n            # get go term for name and level\n            rec.set_goterm(self.obo_dag)\n\n        # 'keep_if' can be used to keep only significant GO terms. Example:\n        #     >>> keep_if = lambda nt: nt.p_fdr_bh < 0.05 # if results are significant\n        #     >>> goea_results = goeaobj.run_study(geneids_study, keep_if=keep_if)\n        if 'keep_if' in kws:\n            keep_if = kws['keep_if']\n            results = [r for r in results if keep_if(r)]\n\n        # Default sort order:\n        results.sort(key=lambda r: [r.enrichment, r.NS, r.p_uncorrected])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning GOEA on study ids. Return results as a list of namedtuples.", "response": "def run_study_nts(self, study, **kws):\n        \"\"\"Run GOEA on study ids. Return results as a list of namedtuples.\"\"\"\n        goea_results = self.run_study(study, **kws)\n        return MgrNtGOEAs(goea_results).get_goea_nts_all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_results_msg(self, results, study):\n        # To convert msg list to string: \"\\n\".join(msg)\n        msg = []\n        if results:\n            fmt = \"{M:6,} GO terms are associated with {N:6,} of {NT:6,}\"\n            stu_items, num_gos_stu = self.get_item_cnt(results, \"study_items\")\n            pop_items, num_gos_pop = self.get_item_cnt(results, \"pop_items\")\n            stu_txt = fmt.format(N=len(stu_items), M=num_gos_stu, NT=len(set(study)))\n            pop_txt = fmt.format(N=len(pop_items), M=num_gos_pop, NT=self.pop_n)\n            msg.append(\"{POP} population items\".format(POP=pop_txt))\n            msg.append(\"{STU} study items\".format(STU=stu_txt))\n        return msg", "response": "Return summary for GOEA results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pval_uncorr(self, study, log=sys.stdout):\n        results = []\n        study_in_pop = self.pop.intersection(study)\n        # \" 99%    378 of    382 study items found in population\"\n        go2studyitems = get_terms(\"study\", study_in_pop, self.assoc, self.obo_dag, log)\n        pop_n, study_n = self.pop_n, len(study_in_pop)\n        allterms = set(go2studyitems).union(set(self.go2popitems))\n        if log is not None:\n            # Some study genes may not have been found in the population. Report from orig\n            study_n_orig = len(study)\n            perc = 100.0*study_n/study_n_orig if study_n_orig != 0 else 0.0\n            log.write(\"{R:3.0f}% {N:>6,} of {M:>6,} study items found in population({P})\\n\".format(\n                N=study_n, M=study_n_orig, P=pop_n, R=perc))\n            if study_n:\n                log.write(\"Calculating {N:,} uncorrected p-values using {PFNC}\\n\".format(\n                    N=len(allterms), PFNC=self.pval_obj.name))\n        # If no study genes were found in the population, return empty GOEA results\n        if not study_n:\n            return []\n        calc_pvalue = self.pval_obj.calc_pvalue\n\n        for goid in allterms:\n            study_items = go2studyitems.get(goid, set())\n            study_count = len(study_items)\n            pop_items = self.go2popitems.get(goid, set())\n            pop_count = len(pop_items)\n\n            one_record = GOEnrichmentRecord(\n                goid,\n                p_uncorrected=calc_pvalue(study_count, study_n, pop_count, pop_n),\n                study_items=study_items,\n                pop_items=pop_items,\n                ratio_in_study=(study_count, study_n),\n                ratio_in_pop=(pop_count, pop_n))\n\n            results.append(one_record)\n\n        return results", "response": "Calculate the uncorrected p - values for a study items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of study items associated with the given results.", "response": "def get_study_items(results):\n        \"\"\"Return a list of study items associated with the given results.\"\"\"\n        study_items = set()\n        for obj in results:\n            study_items.update(obj.study_items)\n        return study_items"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the data members to store multiple test corrections.", "response": "def _update_pvalcorr(ntmt, corrected_pvals):\n        \"\"\"Add data members to store multiple test corrections.\"\"\"\n        if corrected_pvals is None:\n            return\n        for rec, val in zip(ntmt.results, corrected_pvals):\n            rec.set_corrected_pval(ntmt.nt_method, val)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wr_txt(self, fout_txt, goea_results, prtfmt=None, **kws):\n        if not goea_results:\n            sys.stdout.write(\"      0 GOEA results. NOT WRITING {FOUT}\\n\".format(FOUT=fout_txt))\n            return\n        with open(fout_txt, 'w') as prt:\n            if 'title' in kws:\n                prt.write(\"{TITLE}\\n\".format(TITLE=kws['title']))\n            data_nts = self.prt_txt(prt, goea_results, prtfmt, **kws)\n            log = self.log if self.log is not None else sys.stdout\n            log.write(\"  {N:>5} GOEA results for {CUR:5} study items. WROTE: {F}\\n\".format(\n                N=len(data_nts),\n                CUR=len(MgrNtGOEAs(goea_results).get_study_items()),\n                F=fout_txt))", "response": "Print GOEA results to text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prt_txt(prt, goea_results, prtfmt=None, **kws):\n        objprt = PrtFmt()\n        if prtfmt is None:\n            flds = ['GO', 'NS', 'p_uncorrected',\n                    'ratio_in_study', 'ratio_in_pop', 'depth', 'name', 'study_items']\n            prtfmt = objprt.get_prtfmt_str(flds)\n        prtfmt = objprt.adjust_prtfmt(prtfmt)\n        prt_flds = RPT.get_fmtflds(prtfmt)\n        data_nts = MgrNtGOEAs(goea_results).get_goea_nts_prt(prt_flds, **kws)\n        RPT.prt_txt(prt, data_nts, prtfmt, prt_flds, **kws)\n        return data_nts", "response": "Print GOEA results in text format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a xlsx file.", "response": "def wr_xlsx(self, fout_xlsx, goea_results, **kws):\n        \"\"\"Write a xlsx file.\"\"\"\n        # kws: prt_if indent itemid2name(study_items)\n        objprt = PrtFmt()\n        prt_flds = kws.get('prt_flds', self.get_prtflds_default(goea_results))\n        xlsx_data = MgrNtGOEAs(goea_results).get_goea_nts_prt(prt_flds, **kws)\n        if 'fld2col_widths' not in kws:\n            kws['fld2col_widths'] = {f:objprt.default_fld2col_widths.get(f, 8) for f in prt_flds}\n        RPT.wr_xlsx(fout_xlsx, xlsx_data, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wr_tsv(self, fout_tsv, goea_results, **kws):\n        prt_flds = kws.get('prt_flds', self.get_prtflds_default(goea_results))\n        tsv_data = MgrNtGOEAs(goea_results).get_goea_nts_prt(prt_flds, **kws)\n        RPT.wr_tsv(fout_tsv, tsv_data, **kws)", "response": "Write tab - separated table data to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prt_tsv(self, prt, goea_results, **kws):\n        prt_flds = kws.get('prt_flds', self.get_prtflds_default(goea_results))\n        tsv_data = MgrNtGOEAs(goea_results).get_goea_nts_prt(prt_flds, **kws)\n        RPT.prt_tsv(prt, tsv_data, **kws)", "response": "Write tab - separated table data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget namedtuples of GOEA results split into BP MF CC.", "response": "def get_ns2nts(results, fldnames=None, **kws):\n        \"\"\"Get namedtuples of GOEA results, split into BP, MF, CC.\"\"\"\n        ns2nts = cx.defaultdict(list)\n        nts = MgrNtGOEAs(results).get_goea_nts_all(fldnames, **kws)\n        for ntgoea in nts:\n            ns2nts[ntgoea.NS].append(ntgoea)\n        return ns2nts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all study or population items ( e. g. geneids.", "response": "def get_item_cnt(results, attrname=\"study_items\"):\n        \"\"\"Get all study or population items (e.g., geneids).\"\"\"\n        items = set()\n        go_cnt = 0\n        for rec in results:\n            if hasattr(rec, attrname):\n                items_cur = getattr(rec, attrname)\n                # Only count GO term if there are items in the set.\n                if len(items_cur) != 0:\n                    items |= items_cur\n                    go_cnt += 1\n        return items, go_cnt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_date(min_ratio=None, pval=0.05):\n        import goatools\n\n        # Header contains provenance and parameters\n        date = datetime.date.today()\n        print(\"# Generated by GOATOOLS v{0} ({1})\".format(goatools.__version__, date))\n        print(\"# min_ratio={0} pval={1}\".format(min_ratio, pval))", "response": "Print GOATOOLS version and the date the GOEA was run."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_results(self, results, min_ratio=None, indent=False, pval=0.05, prt=sys.stdout):\n        results_adj = self.get_adj_records(results, min_ratio, pval)\n        self.print_results_adj(results_adj, indent, prt)", "response": "Print GOEA results with some additional statistics calculated."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning GOEA results with some additional statistics calculated.", "response": "def get_adj_records(results, min_ratio=None, pval=0.05):\n        \"\"\"Return GOEA results with some additional statistics calculated.\"\"\"\n        records = []\n        for rec in results:\n            # calculate some additional statistics\n            # (over_under, is_ratio_different)\n            rec.update_remaining_fldsdefprt(min_ratio=min_ratio)\n\n            if pval is not None and rec.p_uncorrected >= pval:\n                continue\n\n            if rec.is_ratio_different:\n                records.append(rec)\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave GOEA results into Python package containing list of namedtuples.", "response": "def wr_py_goea_results(self, fout_py, goea_results, **kws):\n        \"\"\"Save GOEA results into Python package containing list of namedtuples.\"\"\"\n        var_name = kws.get(\"var_name\", \"goea_results\")\n        docstring = kws.get(\"docstring\", \"\")\n        sortby = kws.get(\"sortby\", None)\n        if goea_results:\n            from goatools.nt_utils import wr_py_nts\n            nts_goea = goea_results\n            # If list has GOEnrichmentRecords or verbose namedtuples, exclude some fields.\n            if hasattr(goea_results[0], \"_fldsdefprt\") or hasattr(goea_results[0], 'goterm'):\n                # Exclude some attributes from the namedtuple when saving results\n                # to a Python file because the information is redundant or verbose.\n                nts_goea = MgrNtGOEAs(goea_results).get_goea_nts_prt(**kws)\n            docstring = \"\\n\".join([docstring, \"# {VER}\\n\\n\".format(VER=self.obo_dag.version)])\n            assert hasattr(nts_goea[0], '_fields')\n            if sortby is None:\n                sortby = MgrNtGOEAs.dflt_sortby_objgoea\n            nts_goea = sorted(nts_goea, key=sortby)\n            wr_py_nts(fout_py, nts_goea, docstring, var_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns configured DATABASE dictionary from DATABASE_URL.", "response": "def config(env=DEFAULT_ENV, default=None, engine=None, conn_max_age=0, ssl_require=False):\n    \"\"\"Returns configured DATABASE dictionary from DATABASE_URL.\"\"\"\n\n    config = {}\n\n    s = os.environ.get(env, default)\n\n    if s:\n        config = parse(s, engine, conn_max_age, ssl_require)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(url, engine=None, conn_max_age=0, ssl_require=False):\n\n    if url == 'sqlite://:memory:':\n        # this is a special case, because if we pass this URL into\n        # urlparse, urlparse will choke trying to interpret \"memory\"\n        # as a port number\n        return {\n            'ENGINE': SCHEMES['sqlite'],\n            'NAME': ':memory:'\n        }\n        # note: no other settings are required for sqlite\n\n    # otherwise parse the url as normal\n    config = {}\n\n    url = urlparse.urlparse(url)\n\n    # Split query strings from path.\n    path = url.path[1:]\n    if '?' in path and not url.query:\n        path, query = path.split('?', 2)\n    else:\n        path, query = path, url.query\n    query = urlparse.parse_qs(query)\n\n    # If we are using sqlite and we have no path, then assume we\n    # want an in-memory database (this is the behaviour of sqlalchemy)\n    if url.scheme == 'sqlite' and path == '':\n        path = ':memory:'\n\n    # Handle postgres percent-encoded paths.\n    hostname = url.hostname or ''\n    if '%2f' in hostname.lower():\n        # Switch to url.netloc to avoid lower cased paths\n        hostname = url.netloc\n        if \"@\" in hostname:\n            hostname = hostname.rsplit(\"@\", 1)[1]\n        if \":\" in hostname:\n            hostname = hostname.split(\":\", 1)[0]\n        hostname = hostname.replace('%2f', '/').replace('%2F', '/')\n\n    # Lookup specified engine.\n    engine = SCHEMES[url.scheme] if engine is None else engine\n\n    port = (str(url.port) if url.port and engine in [SCHEMES['oracle'], SCHEMES['mssql']]\n            else url.port)\n\n    # Update with environment configuration.\n    config.update({\n        'NAME': urlparse.unquote(path or ''),\n        'USER': urlparse.unquote(url.username or ''),\n        'PASSWORD': urlparse.unquote(url.password or ''),\n        'HOST': hostname,\n        'PORT': port or '',\n        'CONN_MAX_AGE': conn_max_age,\n    })\n\n    # Pass the query string into OPTIONS.\n    options = {}\n    for key, values in query.items():\n        if url.scheme == 'mysql' and key == 'ssl-ca':\n            options['ssl'] = {'ca': values[-1]}\n            continue\n\n        options[key] = values[-1]\n\n    if ssl_require:\n        options['sslmode'] = 'require'\n\n    # Support for Postgres Schema URLs\n    if 'currentSchema' in options and engine in (\n        'django.contrib.gis.db.backends.postgis',\n        'django.db.backends.postgresql_psycopg2',\n        'django.db.backends.postgresql',\n        'django_redshift_backend',\n    ):\n        options['options'] = '-c search_path={0}'.format(options.pop('currentSchema'))\n\n    if options:\n        config['OPTIONS'] = options\n\n    if engine:\n        config['ENGINE'] = engine\n\n    return config", "response": "Parses a database URL into a dictionary of environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ensure_click(self):\n\n    # We ensure the element is scrolled into the middle of the viewport to ensure that\n    # it is clickable. There are two main ways an element may not be clickable:\n    #   - It is outside of the viewport\n    #   - It is under a banner or toolbar\n    # This script solves both cases\n    script = (\"var viewPortHeight = Math.max(\"\n              \"document.documentElement.clientHeight, window.innerHeight || 0);\"\n              \"var elementTop = arguments[0].getBoundingClientRect().top;\"\n              \"window.scrollBy(0, elementTop-(viewPortHeight/2));\")\n    self.parent.execute_script(script, self)  # parent = the webdriver\n\n    for _ in range(10):\n        try:\n            self.click()\n            return\n        except WebDriverException as e:\n            exception_message = str(e)\n            time.sleep(0.2)\n    raise WebDriverException(\n        \"Couldn't click item after trying 10 times, got error message: \\n{}\".format(\n            exception_message\n        )\n    )", "response": "Ensures a click gets made"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transfer_session_cookies_to_driver(self, domain=None):\n        if not domain and self._last_requests_url:\n            domain = tldextract.extract(self._last_requests_url).registered_domain\n        elif not domain and not self._last_requests_url:\n            raise Exception('Trying to transfer cookies to selenium without specifying a domain '\n                            'and without having visited any page in the current session')\n\n        # Transfer cookies\n        for c in [c for c in self.cookies if domain in c.domain]:\n            self.driver.ensure_add_cookie({'name': c.name, 'value': c.value, 'path': c.path,\n                                           'expiry': c.expires, 'domain': c.domain})", "response": "Copies the Session s cookies into the webdriver"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_user_agent_from_driver(self):\n        selenium_user_agent = self.driver.execute_script(\"return navigator.userAgent;\")\n        self.headers.update({\"user-agent\": selenium_user_agent})", "response": "Updates the user - agent of the current request to the driver s user agent"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring a cookie gets added to the driver.", "response": "def ensure_add_cookie(self, cookie, override_domain=None):\n        \"\"\"Ensures a cookie gets added to the driver\n\n        Selenium needs the driver to be currently at the domain of the cookie\n        before allowing you to add it, so we need to get through this limitation.\n\n        The cookie parameter is a dict which must contain the keys (name, value, domain) and\n        may contain the keys (path, expiry).\n\n        We first check that we aren't currently in the cookie's domain, if we aren't, we GET\n        the cookie's domain and then add the cookies to the driver.\n\n        We can override the cookie's domain using 'override_domain'. The use for this\n        parameter is that sometimes GETting the cookie's domain redirects you to a different\n        sub domain, and therefore adding the cookie fails. So sometimes the user may\n        need to override the cookie's domain to a less strict one, Eg.: 'site.com' instead of\n        'home.site.com', in this way even if the site redirects us to a subdomain, the cookie will\n        stick. If you set the domain to '', the cookie gets added with whatever domain the browser\n        is currently at (at least in chrome it does), so this ensures the cookie gets added.\n\n        It also retries adding the cookie with a more permissive domain if it fails in the first\n        try, and raises an exception if that fails. The standard selenium behaviour in this case\n        was to not do anything, which was very hard to debug.\n        \"\"\"\n        if override_domain:\n            cookie['domain'] = override_domain\n\n        cookie_domain = cookie['domain'] if cookie['domain'][0] != '.' else cookie['domain'][1:]\n        try:\n            browser_domain = tldextract.extract(self.current_url).fqdn\n        except AttributeError:\n            browser_domain = ''\n        if cookie_domain not in browser_domain:\n            # TODO Check if hardcoding 'http' causes trouble\n            # TODO Consider using a new proxy for this next request to not cause an anomalous\n            #      request. This way their server sees our ip address as continuously having the\n            #      same cookies and not have a request mid-session with no cookies\n            self.get('http://' + cookie_domain)\n\n        # Fixes phantomjs bug, all domains must start with a period\n        if self.name == \"phantomjs\": cookie['domain'] = '.' + cookie['domain']\n        self.add_cookie(cookie)\n\n        # If we fail adding the cookie, retry with a more permissive domain\n        if not self.is_cookie_in_driver(cookie):\n            cookie['domain'] = tldextract.extract(cookie['domain']).registered_domain\n            self.add_cookie(cookie)\n            if not self.is_cookie_in_driver(cookie):\n                raise WebDriverException(\n                    \"Couldn't add the following cookie to the webdriver\\n{}\\n\".format(cookie)\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the given cookie is correctly added to the driver.", "response": "def is_cookie_in_driver(self, cookie):\n        \"\"\"We check that the cookie is correctly added to the driver\n\n        We only compare name, value and domain, as the rest can produce false negatives.\n        We are a bit lenient when comparing domains.\n        \"\"\"\n        for driver_cookie in self.get_cookies():\n            if (cookie['name'] == driver_cookie['name'] and\n                cookie['value'] == driver_cookie['value'] and\n                (cookie['domain'] == driver_cookie['domain'] or\n                 '.' + cookie['domain'] == driver_cookie['domain'])):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_element(self, locator, selector, state=\"present\", timeout=None):\n        locators = {'id': By.ID,\n                    'name': By.NAME,\n                    'xpath': By.XPATH,\n                    'link_text': By.LINK_TEXT,\n                    'partial_link_text': By.PARTIAL_LINK_TEXT,\n                    'tag_name': By.TAG_NAME,\n                    'class_name': By.CLASS_NAME,\n                    'css_selector': By.CSS_SELECTOR}\n        locator = locators[locator]\n        if not timeout: timeout = self.default_timeout\n\n        if state == 'visible':\n            element = WebDriverWait(self, timeout).until(\n                EC.visibility_of_element_located((locator, selector))\n            )\n        elif state == 'clickable':\n            element = WebDriverWait(self, timeout).until(\n                EC.element_to_be_clickable((locator, selector))\n            )\n        elif state == 'present':\n            element = WebDriverWait(self, timeout).until(\n                EC.presence_of_element_located((locator, selector))\n            )\n        elif state == 'invisible':\n            WebDriverWait(self, timeout).until(\n                EC.invisibility_of_element_located((locator, selector))\n            )\n            element = None\n        else:\n            raise ValueError(\n                \"The 'state' argument must be 'visible', 'clickable', 'present' \"\n                \"or 'invisible', not '{}'\".format(state)\n            )\n\n        # We add this method to our element to provide a more robust click. Chromedriver\n        # sometimes needs some time before it can click an item, specially if it needs to\n        # scroll into it first. This method ensures clicks don't fail because of this.\n        if element:\n            element.ensure_click = partial(_ensure_click, element)\n        return element", "response": "This method allows us to wait till an element is present or disappears in the browser. It is not possible to wait till an element is present or disappears in the browser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert PDF to Image.", "response": "def convert_from_path(pdf_path, dpi=200, output_folder=None, first_page=None, last_page=None,\n                      fmt='ppm', thread_count=1, userpw=None, use_cropbox=False, strict=False, transparent=False,\n                      output_file=str(uuid.uuid4()), poppler_path=None):\n    \"\"\"\n        Description: Convert PDF to Image will throw whenever one of the condition is reached\n        Parameters:\n            pdf_path -> Path to the PDF that you want to convert\n            dpi -> Image quality in DPI (default 200)\n            output_folder -> Write the resulting images to a folder (instead of directly in memory)\n            first_page -> First page to process\n            last_page -> Last page to process before stopping\n            fmt -> Output image format\n            thread_count -> How many threads we are allowed to spawn for processing\n            userpw -> PDF's password\n            use_cropbox -> Use cropbox instead of mediabox\n            strict -> When a Syntax Error is thrown, it will be raised as an Exception\n            transparent -> Output with a transparent background instead of a white one.\n            output_file -> What is the output filename\n            poppler_path -> Path to look for poppler binaries\n\n    \"\"\"\n\n    page_count = _page_count(pdf_path, userpw, poppler_path=poppler_path)\n\n    # We start by getting the output format, the buffer processing function and if we need pdftocairo\n    parsed_fmt, parse_buffer_func, use_pdfcairo_format = _parse_format(fmt)\n\n    # We use pdftocairo is the format requires it OR we need a transparent output\n    use_pdfcairo = use_pdfcairo_format or (transparent and parsed_fmt in TRANSPARENT_FILE_TYPES)\n\n    if thread_count < 1:\n        thread_count = 1\n\n    if first_page is None:\n        first_page = 1\n\n    if last_page is None or last_page > page_count:\n        last_page = page_count\n\n    if first_page > last_page:\n        return []\n\n    auto_temp_dir = False\n    if output_folder is None and use_pdfcairo:\n        auto_temp_dir = True\n        output_folder = tempfile.mkdtemp()\n\n    # Recalculate page count based on first and last page\n    page_count = last_page - first_page + 1\n\n    if thread_count > page_count:\n        thread_count = page_count\n\n    reminder = page_count % thread_count\n    current_page = first_page\n    processes = []\n    for i in range(thread_count):\n        thread_output_file = output_file + '_' + str(i) if thread_count > 1 else output_file \n        # Get the number of pages the thread will be processing\n        thread_page_count = page_count // thread_count + int(reminder > 0)\n        # Build the command accordingly\n        args = _build_command(['-r', str(dpi), pdf_path], output_folder, current_page, current_page + thread_page_count - 1, parsed_fmt, thread_output_file, userpw, use_cropbox, transparent)\n\n        if use_pdfcairo:\n            args = [_get_command_path('pdftocairo', poppler_path)] + args\n        else:\n            args = [_get_command_path('pdftoppm', poppler_path)] + args\n\n        # Update page values\n        current_page = current_page + thread_page_count\n        reminder -= int(reminder > 0)\n        # Add poppler path to LD_LIBRARY_PATH\n        env = os.environ.copy()\n        if poppler_path is not None:\n            env[\"LD_LIBRARY_PATH\"] = poppler_path + \":\" + env.get(\"LD_LIBRARY_PATH\", \"\")\n        # Spawn the process and save its uuid\n        processes.append((thread_output_file, Popen(args, env=env, stdout=PIPE, stderr=PIPE)))\n\n    images = []\n\n    for uid, proc in processes:\n        data, err = proc.communicate()\n\n        if b'Syntax Error'in err and strict:\n            raise PDFSyntaxError(err.decode(\"utf8\", \"ignore\"))\n\n        if output_folder is not None:\n            images += _load_from_output_folder(output_folder, uid, in_memory=auto_temp_dir)\n        else:\n            images += parse_buffer_func(data)\n\n    if auto_temp_dir:\n        shutil.rmtree(output_folder)\n\n    return images"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_from_bytes(pdf_file, dpi=200, output_folder=None, first_page=None, last_page=None,\n                       fmt='ppm', thread_count=1, userpw=None, use_cropbox=False, strict=False, transparent=False,\n                       output_file=str(uuid.uuid4()), poppler_path=None):\n    \"\"\"\n        Description: Convert PDF to Image will throw whenever one of the condition is reached\n        Parameters:\n            pdf_file -> Bytes representing the PDF file\n            dpi -> Image quality in DPI\n            poppler_path -> Path to look for poppler binaries\n            output_folder -> Write the resulting images to a folder (instead of directly in memory)\n            first_page -> First page to process\n            last_page -> Last page to process before stopping\n            fmt -> Output image format\n            thread_count -> How many threads we are allowed to spawn for processing\n            userpw -> PDF's password\n            use_cropbox -> Use cropbox instead of mediabox\n            strict -> When a Syntax Error is thrown, it will be raised as an Exception\n            transparent -> Output with a transparent background instead of a white one.\n            output_file -> What is the output filename\n            poppler_path -> Path to look for poppler binaries\n    \"\"\"\n\n    fh, temp_filename = tempfile.mkstemp()\n    try:\n        with open(temp_filename, 'wb') as f:\n            f.write(pdf_file)\n            f.flush()\n            return convert_from_path(f.name, dpi=dpi, output_folder=output_folder,\n                                     first_page=first_page, last_page=last_page, fmt=fmt, thread_count=thread_count,\n                                     userpw=userpw, use_cropbox=use_cropbox, strict=strict, transparent=transparent,\n                                     output_file=output_file, poppler_path=poppler_path)\n    finally:\n        os.close(fh)\n        os.remove(temp_filename)", "response": "Convert PDF to Image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing PPM file bytes to Pillow Image", "response": "def parse_buffer_to_ppm(data):\n    \"\"\"\n        Parse PPM file bytes to Pillow Image\n    \"\"\"\n\n    images = []\n\n    index = 0\n\n    while index < len(data):\n        code, size, rgb = tuple(data[index:index + 40].split(b'\\n')[0:3])\n        size_x, size_y = tuple(size.split(b' '))\n        file_size = len(code) + len(size) + len(rgb) + 3 + int(size_x) * int(size_y) * 3\n        images.append(Image.open(BytesIO(data[index:index + file_size])))\n        index += file_size\n\n    return images"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_buffer_to_jpeg(data):\n\n    return [\n        Image.open(BytesIO(image_data + b'\\xff\\xd9'))\n        for image_data in data.split(b'\\xff\\xd9')[:-1] # Last element is obviously empty\n    ]", "response": "Parse JPEG file bytes to Pillow Image\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse PNG file bytes to Pillow Image objects", "response": "def parse_buffer_to_png(data):\n    \"\"\"\n        Parse PNG file bytes to Pillow Image\n    \"\"\"\n\n    images = []\n\n    c1 = 0\n    c2 = 0\n    data_len = len(data)\n    while c1 < data_len:\n        # IEND can appear in a PNG without being the actual end\n        if data[c2:c2 + 4] == b'IEND' and (c2 + 8 == data_len or data[c2+9:c2+12] == b'PNG'):\n            images.append(Image.open(BytesIO(data[c1:c2 + 8])))\n            c1 = c2 + 8\n            c2 = c1\n        c2 += 1\n\n    return images"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring logging. Borrowed from logging.basicConfig Uses the IndentFormatter instead of the regular Formatter Also, opts the caller into Syslog output, unless syslog could not be opened for some reason or another, in which case a warning will be printed to the other log handlers.", "response": "def configure(*args, **kwargs):\n    \"\"\"\n    Configure logging.\n\n    Borrowed from logging.basicConfig\n\n    Uses the IndentFormatter instead of the regular Formatter\n\n    Also, opts the caller into Syslog output, unless syslog could not\n    be opened for some reason or another, in which case a warning will\n    be printed to the other log handlers.\n\n    \"\"\"\n    # Configuration must only happen once: no mechanism for avoiding\n    # duplication of handlers exists.\n    assert len(HANDLERS) == 0\n\n    log_destinations = get_log_destinations()\n\n    if 'stderr' in log_destinations:\n        # Add stderr output.\n        HANDLERS.append(logging.StreamHandler())\n\n    def terrible_log_output(s):\n        import sys\n\n        print(s, file=sys.stderr)\n\n    places = [\n        # Linux\n        '/dev/log',\n\n        # FreeBSD\n        '/var/run/log',\n\n        # Macintosh\n        '/var/run/syslog',\n    ]\n\n    default_syslog_address = places[0]\n    for p in places:\n        if path.exists(p):\n            default_syslog_address = p\n            break\n\n    syslog_address = kwargs.setdefault('syslog_address',\n                                       default_syslog_address)\n\n    valid_facility = False\n    if 'syslog' in log_destinations:\n        facility, valid_facility = get_syslog_facility()\n\n        if not valid_facility:\n            terrible_log_output('invalid syslog facility level specified')\n\n        try:\n            # Add syslog output.\n            HANDLERS.append(handlers.SysLogHandler(syslog_address,\n                                                           facility=facility))\n        except EnvironmentError as e:\n            if e.errno in [errno.EACCES, errno.ECONNREFUSED]:\n                message = ('wal-e: Could not set up syslog, '\n                           'continuing anyway.  '\n                           'Reason: {0}').format(errno.errorcode[e.errno])\n\n                terrible_log_output(message)\n\n    fs = kwargs.get(\"format\", logging.BASIC_FORMAT)\n    dfs = kwargs.get(\"datefmt\", None)\n    fmt = IndentFormatter(fs, dfs)\n\n    for handler in HANDLERS:\n        handler.setFormatter(fmt)\n        logging.root.addHandler(handler)\n\n    # Default to INFO level logging.\n    set_level(kwargs.get('level', logging.INFO))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget syslog facility from ENV var", "response": "def get_syslog_facility():\n    \"\"\"Get syslog facility from ENV var\"\"\"\n    facil = os.getenv('WALE_SYSLOG_FACILITY', 'user')\n\n    valid_facility = True\n    try:\n        facility = handlers.SysLogHandler.facility_names[facil.lower()]\n    except KeyError:\n        valid_facility = False\n        facility = handlers.SysLogHandler.LOG_USER\n\n    return facility, valid_facility"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_level(level):\n    for handler in HANDLERS:\n        handler.setLevel(level)\n\n    logging.root.setLevel(level)", "response": "Adjust the logging level of WAL - E"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format(self, record, *args, **kwargs):\n        return logging.Formatter.format(\n            self, record, *args, **kwargs).replace('\\n', '\\n' + ' ' * 8)", "response": "Format a log record in the log\n            class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fmt_structured(d):\n        timeEntry = datetime.datetime.utcnow().strftime(\n            \"time=%Y-%m-%dT%H:%M:%S.%f-00\")\n        pidEntry = \"pid=\" + str(os.getpid())\n\n        rest = sorted('='.join([str(k), str(v)])\n                      for (k, v) in list(d.items()))\n\n        return ' '.join([timeEntry, pidEntry] + rest)", "response": "Formats dict to a string that can be used in a log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_upload_pipeline(in_fd, out_fd, rate_limit=None,\n                        gpg_key=None, lzop=True):\n    \"\"\" Create a UNIX pipeline to process a file for uploading.\n        (Compress, and optionally encrypt) \"\"\"\n    commands = []\n    if rate_limit is not None:\n        commands.append(PipeViewerRateLimitFilter(rate_limit))\n    if lzop:\n        commands.append(LZOCompressionFilter())\n\n    if gpg_key is not None:\n        commands.append(GPGEncryptionFilter(gpg_key))\n\n    return Pipeline(commands, in_fd, out_fd)", "response": "Create a pipeline to process a file for uploading."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_download_pipeline(in_fd, out_fd, gpg=False, lzop=True):\n    commands = []\n    if gpg:\n        commands.append(GPGDecryptionFilter())\n    if lzop:\n        commands.append(LZODecompressionFilter())\n    return Pipeline(commands, in_fd, out_fd)", "response": "Create a pipeline to process a file after downloading."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fsync_files(filenames):\n    touched_directories = set()\n\n    mode = os.O_RDONLY\n\n    # Windows\n    if hasattr(os, 'O_BINARY'):\n        mode |= os.O_BINARY\n\n    for filename in filenames:\n        fd = os.open(filename, mode)\n        os.fsync(fd)\n        os.close(fd)\n        touched_directories.add(os.path.dirname(filename))\n\n    # Some OSes also require us to fsync the directory where we've\n    # created files or subdirectories.\n    if hasattr(os, 'O_DIRECTORY'):\n        for dirname in touched_directories:\n            fd = os.open(dirname, os.O_RDONLY | os.O_DIRECTORY)\n            os.fsync(fd)\n            os.close(fd)", "response": "Call fsync on a list of file names\n\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts a regular file member using cat for async - like I/O", "response": "def cat_extract(tar, member, targetpath):\n    \"\"\"Extract a regular file member using cat for async-like I/O\n\n    Mostly adapted from tarfile.py.\n\n    \"\"\"\n    assert member.isreg()\n\n    # Fetch the TarInfo object for the given name and build the\n    # destination pathname, replacing forward slashes to platform\n    # specific separators.\n    targetpath = targetpath.rstrip(\"/\")\n    targetpath = targetpath.replace(\"/\", os.sep)\n\n    # Create all upper directories.\n    upperdirs = os.path.dirname(targetpath)\n    if upperdirs and not os.path.exists(upperdirs):\n        try:\n            # Create directories that are not part of the archive with\n            # default permissions.\n            os.makedirs(upperdirs)\n        except EnvironmentError as e:\n            if e.errno == errno.EEXIST:\n                # Ignore an error caused by the race of\n                # the directory being created between the\n                # check for the path and the creation.\n                pass\n            else:\n                raise\n\n    with files.DeleteOnError(targetpath) as dest:\n        with pipeline.get_cat_pipeline(pipeline.PIPE, dest.f) as pl:\n            fp = tar.extractfile(member)\n            copyfileobj.copyfileobj(fp, pl.stdin)\n\n    if sys.version_info < (3, 5):\n        tar.chown(member, targetpath)\n    else:\n        tar.chown(member, targetpath, False)\n\n    tar.chmod(member, targetpath)\n    tar.utime(member, targetpath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsegment a series of file paths into TarPartitions.", "response": "def _segmentation_guts(root, file_paths, max_partition_size):\n    \"\"\"Segment a series of file paths into TarPartition values\n\n    These TarPartitions are disjoint and roughly below the prescribed\n    size.\n    \"\"\"\n    # Canonicalize root to include the trailing slash, since root is\n    # intended to be a directory anyway.\n    if not root.endswith(os.path.sep):\n        root += os.path.sep\n    # Ensure that the root path is a directory before continuing.\n    if not os.path.isdir(root):\n        raise TarBadRootError(root=root)\n\n    bogus_tar = None\n\n    try:\n        # Create a bogus TarFile as a contrivance to be able to run\n        # gettarinfo and produce such instances.  Some of the settings\n        # on the TarFile are important, like whether to de-reference\n        # symlinks.\n        bogus_tar = tarfile.TarFile(os.devnull, 'w', dereference=False)\n\n        # Bookkeeping for segmentation of tar members into partitions.\n        partition_number = 0\n        partition_bytes = 0\n        partition_members = 0\n        partition = TarPartition(partition_number)\n\n        for file_path in file_paths:\n\n            # Ensure tar members exist within a shared root before\n            # continuing.\n            if not file_path.startswith(root):\n                raise TarBadPathError(root=root, offensive_path=file_path)\n\n            # Create an ExtendedTarInfo to represent the tarfile.\n            try:\n                et_info = ExtendedTarInfo(\n                    tarinfo=bogus_tar.gettarinfo(\n                        file_path, arcname=file_path[len(root):]),\n                    submitted_path=file_path)\n\n            except EnvironmentError as e:\n                if (e.errno == errno.ENOENT and\n                    e.filename == file_path):\n                    # log a NOTICE/INFO that the file was unlinked.\n                    # Ostensibly harmless (such unlinks should be replayed\n                    # in the WAL) but good to know.\n                    logger.debug(\n                        msg='tar member additions skipping an unlinked file',\n                        detail='Skipping {0}.'.format(et_info.submitted_path))\n                    continue\n                else:\n                    raise\n\n            # Ensure tar members are within an expected size before\n            # continuing.\n            if et_info.tarinfo.size > max_partition_size:\n                raise TarMemberTooBigError(\n                    et_info.tarinfo.name, max_partition_size,\n                    et_info.tarinfo.size)\n\n            if (partition_bytes + et_info.tarinfo.size >= max_partition_size\n                or partition_members >= PARTITION_MAX_MEMBERS):\n                # Partition is full and cannot accept another member,\n                # so yield the complete one to the caller.\n                yield partition\n\n                # Prepare a fresh partition to accrue additional file\n                # paths into.\n                partition_number += 1\n                partition_bytes = et_info.tarinfo.size\n                partition_members = 1\n                partition = TarPartition(\n                    partition_number, [et_info])\n            else:\n                # Partition is able to accept this member, so just add\n                # it and increment the size counters.\n                partition_bytes += et_info.tarinfo.size\n                partition_members += 1\n                partition.append(et_info)\n\n                # Partition size overflow must not to be possible\n                # here.\n                assert partition_bytes < max_partition_size\n\n    finally:\n        if bogus_tar is not None:\n            bogus_tar.close()\n\n    # Flush out the final partition should it be non-empty.\n    if partition:\n        yield partition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting a tar file to a specified path.", "response": "def tarfile_extract(fileobj, dest_path):\n        \"\"\"Extract a tarfile described by a file object to a specified path.\n\n        Args:\n            fileobj (file): File object wrapping the target tarfile.\n            dest_path (str): Path to extract the contents of the tarfile to.\n        \"\"\"\n        # Though this method doesn't fit cleanly into the TarPartition object,\n        # tarballs are only ever extracted for partitions so the logic jives\n        # for the most part.\n        tar = tarfile.open(mode='r|', fileobj=fileobj,\n                           bufsize=pipebuf.PIPE_BUF_BYTES)\n\n        # canonicalize dest_path so the prefix check below works\n        dest_path = os.path.realpath(dest_path)\n\n        # list of files that need fsyncing\n        extracted_files = []\n\n        # Iterate through each member of the tarfile individually. We must\n        # approach it this way because we are dealing with a pipe and the\n        # getmembers() method will consume it before we extract any data.\n        for member in tar:\n            assert not member.name.startswith('/')\n            relpath = os.path.join(dest_path, member.name)\n\n            # Workaround issue with tar handling of symlink, see:\n            # https://bugs.python.org/issue12800\n            if member.issym():\n                target_path = os.path.join(dest_path, member.name)\n                try:\n                    os.symlink(member.linkname, target_path)\n                except OSError as e:\n                    if e.errno == errno.EEXIST:\n                        os.remove(target_path)\n                        os.symlink(member.linkname, target_path)\n                    else:\n                        raise\n                continue\n\n            if member.isreg() and member.size >= pipebuf.PIPE_BUF_BYTES:\n                cat_extract(tar, member, relpath)\n            else:\n                tar.extract(member, path=dest_path)\n\n            filename = os.path.realpath(relpath)\n            extracted_files.append(filename)\n\n            # avoid accumulating an unbounded list of strings which\n            # could be quite large for a large database\n            if len(extracted_files) > 1000:\n                _fsync_files(extracted_files)\n                del extracted_files[:]\n        tar.close()\n        _fsync_files(extracted_files)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting base backups and basic information about them", "response": "def backup_list(self, query, detail):\n        \"\"\"\n        Lists base backups and basic information about them\n\n        \"\"\"\n        import csv\n        from wal_e.storage.base import BackupInfo\n        bl = self._backup_list(detail)\n\n        # If there is no query, return an exhaustive list, otherwise\n        # find a backup instead.\n        if query is None:\n            bl_iter = bl\n        else:\n            bl_iter = bl.find_all(query)\n\n        # TODO: support switchable formats for difference needs.\n        w_csv = csv.writer(sys.stdout, dialect='excel-tab')\n        w_csv.writerow(BackupInfo._fields)\n\n        for bi in bl_iter:\n            w_csv.writerow([getattr(bi, k) for k in BackupInfo._fields])\n\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef database_backup(self, data_directory, *args, **kwargs):\n        upload_good = False\n        backup_stop_good = False\n        while_offline = False\n        start_backup_info = None\n        if 'while_offline' in kwargs:\n            while_offline = kwargs.pop('while_offline')\n\n        try:\n            if not while_offline:\n                start_backup_info = PgBackupStatements.run_start_backup()\n                version = PgBackupStatements.pg_version()['version']\n            else:\n                if os.path.exists(os.path.join(data_directory,\n                                               'postmaster.pid')):\n                    hint = ('Shut down postgres.  '\n                            'If there is a stale lockfile, '\n                            'then remove it after being very sure postgres '\n                            'is not running.')\n                    raise UserException(\n                        msg='while_offline set, but pg looks to be running',\n                        detail='Found a postmaster.pid lockfile, and aborting',\n                        hint=hint)\n\n                ctrl_data = PgControlDataParser(data_directory)\n                start_backup_info = ctrl_data.last_xlog_file_name_and_offset()\n                version = ctrl_data.pg_version()\n\n            ret_tuple = self._upload_pg_cluster_dir(\n                start_backup_info, data_directory, version=version, *args,\n                **kwargs)\n            spec, uploaded_to, expanded_size_bytes = ret_tuple\n            upload_good = True\n        finally:\n            if not upload_good:\n                logger.warning(\n                    'blocking on sending WAL segments',\n                    detail=('The backup was not completed successfully, '\n                            'but we have to wait anyway.  '\n                            'See README: TODO about pg_cancel_backup'))\n\n            if not while_offline:\n                stop_backup_info = PgBackupStatements.run_stop_backup()\n            else:\n                stop_backup_info = start_backup_info\n            backup_stop_good = True\n\n        # XXX: Ugly, this is more of a 'worker' task because it might\n        # involve retries and error messages, something that is not\n        # treated by the \"operator\" category of modules.  So\n        # basically, if this small upload fails, the whole upload\n        # fails!\n        if upload_good and backup_stop_good:\n            # Try to write a sentinel file to the cluster backup\n            # directory that indicates that the base backup upload has\n            # definitely run its course and also communicates what WAL\n            # segments are needed to get to consistency.\n            sentinel_content = json.dumps(\n                {'wal_segment_backup_stop':\n                    stop_backup_info['file_name'],\n                 'wal_segment_offset_backup_stop':\n                    stop_backup_info['file_offset'],\n                 'expanded_size_bytes': expanded_size_bytes,\n                 'spec': spec})\n\n            # XXX: should use the storage operators.\n            #\n            # XXX: distinguish sentinels by *PREFIX* not suffix,\n            # which makes searching harder. (For the next version\n            # bump).\n\n            uri_put_file(self.creds,\n                             uploaded_to + '_backup_stop_sentinel.json',\n                             BytesIO(sentinel_content.encode(\"utf8\")),\n                             content_type='application/json')\n        else:\n            # NB: Other exceptions should be raised before this that\n            # have more informative results, it is intended that this\n            # exception never will get raised.\n            raise UserCritical('could not complete backup process')", "response": "Uploads a PostgreSQL file cluster to S3 or Windows Azure Blobstore or Windows Azure Blobstore."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload a WAL file to S3 or Windows Azure Blob Service.", "response": "def wal_archive(self, wal_path, concurrency=1):\n        \"\"\"\n        Uploads a WAL file to S3 or Windows Azure Blob Service\n\n        This code is intended to typically be called from Postgres's\n        archive_command feature.\n        \"\"\"\n\n        # Upload the segment expressly indicated.  It's special\n        # relative to other uploads when parallel wal-push is enabled,\n        # in that it's not desirable to tweak its .ready/.done files\n        # in archive_status.\n        xlog_dir = os.path.dirname(wal_path)\n        segment = WalSegment(wal_path, explicit=True)\n        uploader = WalUploader(self.layout, self.creds, self.gpg_key_id)\n        group = WalTransferGroup(uploader)\n        group.start(segment)\n\n        # Upload any additional wal segments up to the specified\n        # concurrency by scanning the Postgres archive_status\n        # directory.\n        started = 1\n        seg_stream = WalSegment.from_ready_archive_status(xlog_dir)\n        while started < concurrency:\n            try:\n                other_segment = next(seg_stream)\n            except StopIteration:\n                break\n\n            if other_segment.path != wal_path:\n                group.start(other_segment)\n                started += 1\n\n        try:\n            # Wait for uploads to finish.\n            group.join()\n        except EnvironmentError as e:\n            if e.errno == errno.ENOENT:\n                print(e)\n                raise UserException(\n                    msg='could not find file for wal-push',\n                    detail=('The operating system reported: {0} {1}'\n                            .format(e.strerror, repr(e.filename))))\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a WAL file from S3 or Windows Azure Blob Service and restores it to the destination location.", "response": "def wal_restore(self, wal_name, wal_destination, prefetch_max):\n        \"\"\"\n        Downloads a WAL file from S3 or Windows Azure Blob Service\n\n        This code is intended to typically be called from Postgres's\n        restore_command feature.\n\n        NB: Postgres doesn't guarantee that wal_name ==\n        basename(wal_path), so both are required.\n\n        \"\"\"\n        url = '{0}://{1}/{2}'.format(\n            self.layout.scheme, self.layout.store_name(),\n            self.layout.wal_path(wal_name))\n\n        if prefetch_max > 0:\n            # Check for prefetch-hit.\n            base = os.path.dirname(os.path.realpath(wal_destination))\n            pd = prefetch.Dirs(base)\n            seg = WalSegment(wal_name)\n\n            started = start_prefetches(seg, pd, prefetch_max)\n            last_size = 0\n\n            while True:\n                if pd.contains(seg):\n                    pd.promote(seg, wal_destination)\n                    logger.info(\n                        msg='promoted prefetched wal segment',\n                        structured={'action': 'wal-fetch',\n                                    'key': url,\n                                    'seg': wal_name,\n                                    'prefix': self.layout.path_prefix})\n\n                    pd.clear_except(started)\n                    return True\n\n                # If there is a 'running' download, wait a bit for it\n                # to make progress or finish.  However, if it doesn't\n                # make progress in some amount of time, assume that\n                # the prefetch process has died and go on with the\n                # in-band downloading code.\n                sz = pd.running_size(seg)\n                if sz <= last_size:\n                    break\n\n                last_size = sz\n                gevent.sleep(0.5)\n\n            pd.clear_except(started)\n\n        logger.info(\n            msg='begin wal restore',\n            structured={'action': 'wal-fetch',\n                        'key': url,\n                        'seg': wal_name,\n                        'prefix': self.layout.path_prefix,\n                        'state': 'begin'})\n\n        ret = do_lzop_get(self.creds, url, wal_destination,\n                          self.gpg_key_id is not None)\n\n        logger.info(\n            msg='complete wal restore',\n            structured={'action': 'wal-fetch',\n                        'key': url,\n                        'seg': wal_name,\n                        'prefix': self.layout.path_prefix,\n                        'state': 'complete'})\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload a file to the PG cluster directory pg_cluster_dir.", "response": "def _upload_pg_cluster_dir(self, start_backup_info, pg_cluster_dir,\n                               version, pool_size, rate_limit=None):\n        \"\"\"\n        Upload to url_prefix from pg_cluster_dir\n\n        This function ignores the directory pg_xlog, which contains WAL\n        files and are not generally part of a base backup.\n\n        Note that this is also lzo compresses the files: thus, the number\n        of pooled processes involves doing a full sequential scan of the\n        uncompressed Postgres heap file that is pipelined into lzo. Once\n        lzo is completely finished (necessary to have access to the file\n        size) the file is sent to S3 or WABS.\n\n        TODO: Investigate an optimization to decouple the compression and\n        upload steps to make sure that the most efficient possible use of\n        pipelining of network and disk resources occurs.  Right now it\n        possible to bounce back and forth between bottlenecking on reading\n        from the database block device and subsequently the S3/WABS sending\n        steps should the processes be at the same stage of the upload\n        pipeline: this can have a very negative impact on being able to\n        make full use of system resources.\n\n        Furthermore, it desirable to overflowing the page cache: having\n        separate tunables for number of simultanious compression jobs\n        (which occupy /tmp space and page cache) and number of uploads\n        (which affect upload throughput) would help.\n\n        \"\"\"\n        spec, parts = tar_partition.partition(pg_cluster_dir)\n\n        # TODO :: Move arbitray path construction to StorageLayout Object\n        backup_prefix = '{0}/basebackups_{1}/base_{file_name}_{file_offset}'\\\n            .format(self.layout.prefix.rstrip('/'), FILE_STRUCTURE_VERSION,\n                        **start_backup_info)\n\n        if rate_limit is None:\n            per_process_limit = None\n        else:\n            per_process_limit = int(rate_limit / pool_size)\n\n        # Reject tiny per-process rate limits.  They should be\n        # rejected more nicely elsewhere.\n        assert per_process_limit is None or per_process_limit > 0\n\n        total_size = 0\n\n        # Make an attempt to upload extended version metadata\n        extended_version_url = backup_prefix + '/extended_version.txt'\n        logger.info(\n            msg='start upload postgres version metadata',\n            detail=('Uploading to {extended_version_url}.'\n                    .format(extended_version_url=extended_version_url)))\n        uri_put_file(self.creds,\n                     extended_version_url, BytesIO(version.encode(\"utf8\")),\n                     content_type='text/plain')\n\n        logger.info(msg='postgres version metadata upload complete')\n\n        uploader = PartitionUploader(self.creds, backup_prefix,\n                                     per_process_limit, self.gpg_key_id)\n\n        pool = TarUploadPool(uploader, pool_size)\n\n        # Enqueue uploads for parallel execution\n        for tpart in parts:\n            total_size += tpart.total_member_size\n\n            # 'put' can raise an exception for a just-failed upload,\n            # aborting the process.\n            pool.put(tpart)\n\n        # Wait for remaining parts to upload.  An exception can be\n        # raised to signal failure of the upload.\n        pool.join()\n\n        return spec, backup_prefix, total_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, segment):\n\n        def lackadaisical_mkdir(place):\n            ok = False\n\n            place = path.realpath(place)\n\n            try:\n                os.makedirs(place, 0o700)\n                ok = True\n            except EnvironmentError as e:\n                if e.errno == errno.EEXIST:\n                    # Has already been created: this is the most\n                    # common situation, and is fine.\n                    ok = True\n                else:\n                    logger.warning(\n                        msg='could not create prefetch directory',\n                        detail=('Prefetch directory creation target: {0}, {1}'\n                                .format(place, e.strerror)))\n\n            return ok\n\n        ok = True\n\n        for d in [self.prefetched_dir, self.running]:\n            ok &= lackadaisical_mkdir(d)\n\n        lackadaisical_mkdir(self.seg_dir(segment))", "response": "A best - effort method to create directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_blobstore(layout):\n    if layout.is_s3:\n        from wal_e.blobstore import s3\n        blobstore = s3\n    elif layout.is_wabs:\n        from wal_e.blobstore import wabs\n        blobstore = wabs\n    elif layout.is_swift:\n        from wal_e.blobstore import swift\n        blobstore = swift\n    elif layout.is_gs:\n        from wal_e.blobstore import gs\n        blobstore = gs\n    elif layout.is_file:\n        from wal_e.blobstore import file\n        blobstore = file\n    return blobstore", "response": "Returns a Blobstore instance for a given storage layout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef acquire(self):\n        try:\n            pidfile = open(self._pidfile, \"a\")\n        except IOError as err:\n            raise SystemExit(err)\n        try:\n            fcntl.flock(pidfile.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)\n        except IOError:\n            raise SystemExit('Already running according to ' + self._pidfile)\n        pidfile.seek(0)\n        pidfile.truncate()\n        pidfile.write(str(os.getpid()) + '\\n')\n        pidfile.flush()\n        self.pidfile = pidfile\n        atexit.register(self.release)", "response": "Acquire the pidfile.\n\n        Create the pidfile, lock it, write the pid into it\n        and register the release with atexit.\n\n\n        :return: None\n        :raise: SystemExit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrelease the pidfile. Close and delete the Pidfile.", "response": "def release(self):\n        \"\"\"Release the pidfile.\n\n        Close and delete the Pidfile.\n\n\n        :return: None\n        \"\"\"\n        try:\n            self.pidfile.close()\n            os.remove(self._pidfile)\n        except OSError as err:\n            if err.errno != 2:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _configure_buffer_sizes():\n    global PIPE_BUF_BYTES\n    global OS_PIPE_SZ\n\n    PIPE_BUF_BYTES = 65536\n    OS_PIPE_SZ = None\n\n    # Teach the 'fcntl' module about 'F_SETPIPE_SZ', which is a Linux-ism,\n    # but a good one that can drastically reduce the number of syscalls\n    # when dealing with high-throughput pipes.\n    if not hasattr(fcntl, 'F_SETPIPE_SZ'):\n        import platform\n\n        if platform.system() == 'Linux':\n            fcntl.F_SETPIPE_SZ = 1031\n\n    # If Linux procfs (or something that looks like it) exposes its\n    # maximum F_SETPIPE_SZ, adjust the default buffer sizes.\n    try:\n        with open('/proc/sys/fs/pipe-max-size', 'r') as f:\n            # Figure out OS pipe size, but in case it is unusually large\n            # or small restrain it to sensible values.\n            OS_PIPE_SZ = min(int(f.read()), 1024 * 1024)\n            PIPE_BUF_BYTES = max(OS_PIPE_SZ, PIPE_BUF_BYTES)\n    except Exception:\n        pass", "response": "Configure the buffer sizes for the current process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting up os pipe buffer size if applicable", "response": "def set_buf_size(fd):\n    \"\"\"Set up os pipe buffer size, if applicable\"\"\"\n    if OS_PIPE_SZ and hasattr(fcntl, 'F_SETPIPE_SZ'):\n        fcntl.fcntl(fd, fcntl.F_SETPIPE_SZ, OS_PIPE_SZ)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup_fd(fd):\n\n    # Make the file nonblocking (but don't lose its previous flags)\n    flags = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK)\n    set_buf_size(fd)", "response": "Common set - up code for initializing a ( pipe ) file descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mark_done(self):\n\n        # Recheck that this is not an segment explicitly passed from Postgres\n        if self.explicit:\n            raise UserCritical(\n                msg='unexpected attempt to modify wal metadata detected',\n                detail=('Segments explicitly passed from postgres should not '\n                        'engage in archiver metadata manipulation: {0}'\n                        .format(self.path)),\n                hint='report a bug')\n\n        # Attempt a rename of archiver metadata, wrapping unexpected\n        # raised exceptions into a UserCritical.\n        try:\n            status_dir = path.join(path.dirname(self.path),\n                                   'archive_status')\n\n            ready_metadata = path.join(status_dir, self.name + '.ready')\n            done_metadata = path.join(status_dir, self.name + '.done')\n\n            os.rename(ready_metadata, done_metadata)\n        except Exception:\n            raise UserCritical(\n                msg='problem moving .ready archive status to .done',\n                detail='Traceback is: {0}'.format(traceback.format_exc()),\n                hint='report a bug')", "response": "Mark the archive status of this segment as done."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for the transfer to exit raising errors as necessary.", "response": "def join(self):\n        \"\"\"Wait for transfer to exit, raising errors as necessary.\"\"\"\n        self.closed = True\n\n        while self.expect > 0:\n            val = self.wait_change.get()\n            self.expect -= 1\n\n            if val is not None:\n                # Wait a while for all running greenlets to exit, and\n                # then attempt to force them to exit so join()\n                # terminates in a reasonable amount of time.\n                gevent.joinall(list(self.greenlets), timeout=30)\n                gevent.killall(list(self.greenlets), block=True, timeout=30)\n                raise val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self, segment):\n\n        if self.closed:\n            raise UserCritical(msg='attempt to transfer wal after closing',\n                               hint='report a bug')\n\n        g = gevent.Greenlet(self.transferer, segment)\n        g.link(self._complete_execution)\n        self.greenlets.add(g)\n\n        # Increment .expect before starting the greenlet, or else a\n        # very unlucky .join could be fooled as to when pool is\n        # complete.\n        self.expect += 1\n\n        g.start()", "response": "Start a new thread for an indicated wal segment."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nforward any raised exceptions across a channel.", "response": "def _complete_execution(self, g):\n        \"\"\"Forward any raised exceptions across a channel.\"\"\"\n\n        # Triggered via completion callback.\n        #\n        # Runs in its own greenlet, so take care to forward the\n        # exception, if any, to fail the entire transfer in event of\n        # trouble.\n        assert g.ready()\n        self.greenlets.remove(g)\n\n        placed = UserCritical(msg='placeholder bogus exception',\n                              hint='report a bug')\n\n        if g.successful():\n            try:\n                segment = g.get()\n\n                if not segment.explicit:\n                    segment.mark_done()\n            except BaseException as e:\n                # Absorb and forward exceptions across the channel.\n                placed = e\n            else:\n                placed = None\n        else:\n            placed = g.exception\n\n        self.wait_change.put(placed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copyfileobj(src, dst, length=None, exception=OSError, bufsize=None):\n    if bufsize is None:\n        bufsize = pipebuf.PIPE_BUF_BYTES\n\n    if length == 0:\n        return\n    if length is None:\n        shutil.copyfileobj(src, dst, bufsize)\n        return\n\n    blocks, remainder = divmod(length, bufsize)\n    for b in range(blocks):\n        buf = src.read(bufsize)\n        if len(buf) < bufsize:\n            raise exception(\"unexpected end of data\")\n        dst.write(buf)\n\n    if remainder != 0:\n        buf = src.read(remainder)\n        if len(buf) < remainder:\n            raise exception(\"unexpected end of data\")\n        dst.write(buf)\n    return", "response": "Copy a file - like object src to dst."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a process in a non - blocking manner.", "response": "def popen_nonblock(*args, **kwargs):\n    \"\"\"\n    Create a process in the same way as popen_sp, but patch the file\n    descriptors so they can be accessed from Python/gevent\n    in a non-blocking manner.\n    \"\"\"\n\n    proc = popen_sp(*args, **kwargs)\n\n    if proc.stdin:\n        proc.stdin = pipebuf.NonBlockBufferedWriter(proc.stdin)\n\n    if proc.stdout:\n        proc.stdout = pipebuf.NonBlockBufferedReader(proc.stdout)\n\n    if proc.stderr:\n        proc.stderr = pipebuf.NonBlockBufferedReader(proc.stderr)\n\n    return proc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns several processes in a pipeline and returns the array of subprocesses created by popen.", "response": "def pipe(*args):\n    \"\"\"\n    Takes as parameters several dicts, each with the same\n    parameters passed to popen.\n\n    Runs the various processes in a pipeline, connecting\n    the stdout of every process except the last with the\n    stdin of the next process.\n\n    Adapted from http://www.enricozini.org/2009/debian/python-pipes/\n\n    \"\"\"\n    if len(args) < 2:\n        raise ValueError(\"pipe needs at least 2 processes\")\n\n    # Set stdout=PIPE in every subprocess except the last\n    for i in args[:-1]:\n        i[\"stdout\"] = subprocess.PIPE\n\n    # Runs all subprocesses connecting stdins and stdouts to create the\n    # pipeline. Closes stdouts to avoid deadlocks.\n    popens = [popen_sp(**args[0])]\n    for i in range(1, len(args)):\n        args[i][\"stdin\"] = popens[i - 1].stdout\n        popens.append(popen_sp(**args[i]))\n        popens[i - 1].stdout.close()\n\n    # Returns the array of subprocesses just created\n    return popens"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipe_wait(popens):\n    # Avoid mutating the passed copy\n    popens = copy.copy(popens)\n    results = [0] * len(popens)\n    while popens:\n        last = popens.pop(-1)\n        results[len(popens)] = last.wait()\n    return results", "response": "This method is used to wait for all processes to terminate and return the array with their return values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to Azure BlockBlobService instance.", "response": "def connect(self, creds):\n        \"\"\"Return an azure BlockBlobService instance.\n        \"\"\"\n        return BlockBlobService(account_name=creds.account_name,\n                           account_key=creds.account_key,\n                           sas_token=creds.access_token,\n                           protocol='https')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget and decompress a URL and store it in a file.", "response": "def do_lzop_get(creds, url, path, decrypt, do_retry):\n    \"\"\"\n    Get and decompress a URL\n\n    This streams the content directly to lzop; the compressed version\n    is never stored on disk.\n\n    \"\"\"\n    assert url.endswith('.lzo'), 'Expect an lzop-compressed file'\n\n    with files.DeleteOnError(path) as decomp_out:\n        key = _uri_to_key(creds, url)\n        with get_download_pipeline(PIPE, decomp_out.f, decrypt) as pl:\n            g = gevent.spawn(write_and_return_error, key, pl.stdin)\n            exc = g.get()\n            if exc is not None:\n                raise exc\n\n        logger.info(\n            msg='completed download and decompression',\n            detail='Downloaded and decompressed \"{url}\" to \"{path}\"'\n            .format(url=url, path=path))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning psql and returns a CSVReader object from the query", "response": "def psql_csv_run(sql_command, error_handler=None):\n    \"\"\"\n    Runs psql and returns a CSVReader object from the query\n\n    This CSVReader includes header names as the first record in all\n    situations.  The output is fully buffered into Python.\n\n    \"\"\"\n    csv_query = ('COPY ({query}) TO STDOUT WITH CSV HEADER;'\n                 .format(query=sql_command))\n\n    new_env = os.environ.copy()\n    new_env.setdefault('PGOPTIONS', '')\n    new_env[\"PGOPTIONS\"] += ' --statement-timeout=0'\n    psql_proc = popen_nonblock([PSQL_BIN, '-d', 'postgres', '--no-password',\n                                '--no-psqlrc', '-c', csv_query],\n                               stdout=PIPE,\n                               env=new_env)\n    stdout = psql_proc.communicate()[0].decode('utf-8')\n\n    if psql_proc.returncode != 0:\n        if error_handler is not None:\n            error_handler(psql_proc)\n        else:\n            assert error_handler is None\n            raise UserException(\n                'could not csv-execute a query successfully via psql',\n                'Query was \"{query}\".'.format(sql_command),\n                'You may have to set some libpq environment '\n                'variables if you are sure the server is running.')\n\n    # Previous code must raise any desired exceptions for non-zero\n    # exit codes\n    assert psql_proc.returncode == 0\n\n    # Fake enough iterator interface to get a CSV Reader object\n    # that works.\n    return csv.reader(iter(stdout.strip().split('\\n')))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset and returns _WAL_NAME to wal or xlog depending on version of postgres we are working with.", "response": "def _wal_name(cls):\n        \"\"\"\n        Sets and returns _WAL_NAME to 'wal' or 'xlog' depending on\n        version of postgres we are working with.\n\n        It is used for handling xlog -> wal rename in postgres v10\n\n        \"\"\"\n        if cls._WAL_NAME is None:\n            version = cls._dict_transform(psql_csv_run(\n                    \"SELECT current_setting('server_version_num')\"))\n            if int(version['current_setting']) >= 100000:\n                cls._WAL_NAME = 'wal'\n            else:\n                cls._WAL_NAME = 'xlog'\n        return cls._WAL_NAME"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a hot backup of the WAL and returns a dictionary of WAL information.", "response": "def run_start_backup(cls):\n        \"\"\"\n        Connects to a server and attempts to start a hot backup\n\n        Yields the WAL information in a dictionary for bookkeeping and\n        recording.\n\n        \"\"\"\n        def handler(popen):\n            assert popen.returncode != 0\n            raise UserException('Could not start hot backup')\n\n        # The difficulty of getting a timezone-stamped, UTC,\n        # ISO-formatted datetime is downright embarrassing.\n        #\n        # See http://bugs.python.org/issue5094\n        label = 'freeze_start_' + (datetime.datetime.utcnow()\n                                   .replace(tzinfo=UTC()).isoformat())\n\n        return cls._dict_transform(psql_csv_run(\n                \"SELECT file_name, \"\n                \"  lpad(file_offset::text, 8, '0') AS file_offset \"\n                \"FROM pg_{0}file_name_offset(\"\n                \"  pg_start_backup('{1}'))\".format(cls._wal_name(), label),\n                error_handler=handler))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_stop_backup(cls):\n        def handler(popen):\n            assert popen.returncode != 0\n            raise UserException('Could not stop hot backup')\n\n        return cls._dict_transform(psql_csv_run(\n                \"SELECT file_name, \"\n                \"  lpad(file_offset::text, 8, '0') AS file_offset \"\n                \"FROM pg_{0}file_name_offset(\"\n                \"  pg_stop_backup())\".format(cls._wal_name()),\n                error_handler=handler))", "response": "Stop a hot backup of the current WAL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_ipv4_like(s):\n    parts = s.split('.')\n\n    if len(parts) != 4:\n        return False\n\n    for part in parts:\n        try:\n            int(part)\n        except ValueError:\n            return False\n\n    return True", "response": "Return True if a string looks like an IPv4 address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_mostly_subdomain_compatible(bucket_name):\n    return (bucket_name.lower() == bucket_name and\n            len(bucket_name) >= 3 and\n            len(bucket_name) <= 63 and\n            '_' not in bucket_name and\n            '..' not in bucket_name and\n            '-.' not in bucket_name and\n            '.-' not in bucket_name and\n            not bucket_name.startswith('-') and\n            not bucket_name.endswith('-') and\n            not bucket_name.startswith('.') and\n            not bucket_name.endswith('.') and\n            not _is_ipv4_like(bucket_name))", "response": "Returns True if the given bucket name is mostly subdomain compatible."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _connect_secureish(*args, **kwargs):\n    if tuple(int(x) for x in boto.__version__.split('.')) >= (2, 6, 0):\n        kwargs['validate_certs'] = True\n\n    kwargs['is_secure'] = True\n\n    auth_region_name = kwargs.pop('auth_region_name', None)\n    conn = connection.S3Connection(*args, **kwargs)\n\n    if auth_region_name:\n        conn.auth_region_name = auth_region_name\n\n    return conn", "response": "Connect to the secureish boto connection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a CallingInfo value from a bucket name.", "response": "def from_store_name(bucket_name, region=None):\n    \"\"\"Construct a CallingInfo value from a bucket name.\n\n    This is useful to encapsulate the ugliness of setting up S3\n    connections, especially with regions and TLS certificates are\n    involved.\n    \"\"\"\n    # Late-bind `region` for the sake of tests that inject the\n    # AWS_REGION environment variable.\n    if region is None:\n        region = os.getenv('AWS_REGION')\n\n    mostly_ok = _is_mostly_subdomain_compatible(bucket_name)\n\n    if not mostly_ok:\n        return CallingInfo(\n            bucket_name=bucket_name,\n            region=region,\n            calling_format=connection.OrdinaryCallingFormat,\n            ordinary_endpoint=must_resolve(region))\n    else:\n        if '.' in bucket_name:\n            # The bucket_name might have been DNS compatible, but once\n            # dots are involved TLS certificate validations will\n            # certainly fail even if that's the case.\n            return CallingInfo(\n                bucket_name=bucket_name,\n                calling_format=connection.OrdinaryCallingFormat,\n                region=region,\n                ordinary_endpoint=must_resolve(region))\n        else:\n            # If the bucket follows naming rules and has no dots in\n            # the name, SubdomainCallingFormat can be used, with TLS,\n            # world-wide.\n            return CallingInfo(\n                bucket_name=bucket_name,\n                calling_format=connection.SubdomainCallingFormat,\n                region=region,\n                ordinary_endpoint=None)\n\n    assert False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self, creds):\n        def _conn_help(*args, **kwargs):\n            return _connect_secureish(\n                *args,\n                provider=creds,\n                calling_format=self.calling_format(),\n                auth_region_name=self.region,\n                **kwargs)\n\n        # If WALE_S3_ENDPOINT is set, do not attempt to guess\n        # the right calling conventions and instead honor the explicit\n        # settings within WALE_S3_ENDPOINT.\n        impl = os.getenv('WALE_S3_ENDPOINT')\n        if impl:\n            return connection.S3Connection(**_s3connection_opts_from_uri(impl))\n\n        # Check if subdomain format compatible: if so, use the\n        # BUCKETNAME.s3.amazonaws.com hostname to communicate with the\n        # bucket.\n        if self.calling_format is connection.SubdomainCallingFormat:\n            return _conn_help(host='s3.amazonaws.com')\n\n        # Check if OrdinaryCallingFormat compatible, but also see if\n        # the endpoint has already been set, in which case only\n        # setting the host= flag is necessary.\n        assert self.calling_format is connection.OrdinaryCallingFormat\n        assert self.ordinary_endpoint is not None\n        return _conn_help(host=self.ordinary_endpoint)", "response": "Connect to the many - item bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving empty dirs under a given path.", "response": "def remove_empty_dirs(path):\n    \"\"\" removes empty dirs under a given path \"\"\"\n    for root, dirs, files in os.walk(path):\n        for d in dirs:\n            dir_path = os.path.join(root, d)\n            if not os.listdir(dir_path):\n                os.rmdir(dir_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a directory if required", "response": "def ensure_dir_exists(path):\n    \"\"\" create a directory if required \"\"\"\n    dir_path = os.path.dirname(path)\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef external_program_check(\n    to_check=frozenset([PSQL_BIN, LZOP_BIN, PV_BIN])):\n    \"\"\"\n    Validates the existence and basic working-ness of other programs\n\n    Implemented because it is easy to get confusing error output when\n    one does not install a dependency because of the fork-worker model\n    that is both necessary for throughput and makes more obscure the\n    cause of failures.  This is intended to be a time and frustration\n    saving measure.  This problem has confused The Author in practice\n    when switching rapidly between machines.\n\n    \"\"\"\n\n    could_not_run = []\n    error_msgs = []\n\n    def psql_err_handler(popen):\n        assert popen.returncode != 0\n        error_msgs.append(textwrap.fill(\n                'Could not get a connection to the database: '\n                'note that superuser access is required'))\n\n        # Bogus error message that is re-caught and re-raised\n        raise EnvironmentError('INTERNAL: Had problems running psql '\n                               'from external_program_check')\n\n    with open(os.devnull, 'wb') as nullf:\n        for program in to_check:\n            try:\n                if program is PSQL_BIN:\n                    psql_csv_run('SELECT 1', error_handler=psql_err_handler)\n                else:\n                    if program is PV_BIN:\n                        extra_args = ['--quiet']\n                    else:\n                        extra_args = []\n\n                    proc = popen_sp([program] + extra_args,\n                                    stdout=nullf, stderr=nullf,\n                                    stdin=subprocess.PIPE)\n\n                    # Close stdin for processes that default to\n                    # reading from the pipe; the programs WAL-E uses\n                    # of this kind will terminate in this case.\n                    proc.stdin.close()\n                    proc.wait()\n            except EnvironmentError:\n                could_not_run.append(program)\n\n    if could_not_run:\n        error_msgs.append(\n            'Could not run the following programs, are they installed? ' +\n            ', '.join(could_not_run))\n\n    if error_msgs:\n        raise UserException(\n            'could not run one or more external programs WAL-E depends upon',\n            '\\n'.join(error_msgs))\n\n    return None", "response": "Checks that the specified programs are available and checks that they are available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_boolean_envvar(val):\n    if not val or val.lower() in {'false', '0'}:\n        return False\n    elif val.lower() in {'true', '1'}:\n        return True\n    else:\n        raise ValueError('Invalid boolean environment variable: %s' % val)", "response": "Parse a boolean environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate HINT language for missing configuration", "response": "def _config_hint_generate(optname, both_env_and_param):\n    \"\"\"Generate HINT language for missing configuration\"\"\"\n    env = optname.replace('-', '_').upper()\n\n    if both_env_and_param:\n        option = '--' + optname.lower()\n        return ('Pass \"{0}\" or set the environment variable \"{1}\".'\n                .format(option, env))\n    else:\n        return 'Set the environment variable {0}.'.format(env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_subcommand(args):\n    if args.subcommand == 'delete':\n        return 'delete ' + args.delete_subcommand\n\n    if args.subcommand in ('wal-prefetch', 'wal-push', 'wal-fetch'):\n        return None\n\n    return args.subcommand", "response": "Render a subcommand for human - centric viewing"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompresses and upload a given local path to a LZO bucket.", "response": "def do_lzop_put(creds, url, local_path, gpg_key):\n    \"\"\"\n    Compress and upload a given local path.\n\n    :type url: string\n    :param url: A (s3|wabs)://bucket/key style URL that is the destination\n\n    :type local_path: string\n    :param local_path: a path to a file to be compressed\n\n    \"\"\"\n    assert url.endswith('.lzo')\n    blobstore = get_blobstore(storage.StorageLayout(url))\n\n    with tempfile.NamedTemporaryFile(\n            mode='r+b', buffering=pipebuf.PIPE_BUF_BYTES) as tf:\n        with pipeline.get_upload_pipeline(\n                open(local_path, 'rb'), tf, gpg_key=gpg_key):\n            pass\n\n        tf.flush()\n\n        clock_start = time.time()\n        tf.seek(0)\n        k = blobstore.uri_put_file(creds, url, tf)\n        clock_finish = time.time()\n\n        kib_per_second = format_kib_per_second(\n            clock_start, clock_finish, k.size)\n\n        return kib_per_second"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget and decompress an S3 or WABS URL and return the content.", "response": "def do_lzop_get(creds, url, path, decrypt, do_retry=True):\n    \"\"\"\n    Get and decompress an S3 or WABS URL\n\n    This streams the content directly to lzop; the compressed version\n    is never stored on disk.\n\n    \"\"\"\n    blobstore = get_blobstore(storage.StorageLayout(url))\n    return blobstore.do_lzop_get(creds, url, path, decrypt, do_retry=do_retry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_all(self, query):\n\n        match = re.match(storage.BASE_BACKUP_REGEXP, query)\n\n        if match is not None:\n            for backup in iter(self):\n                if backup.name == query:\n                    yield backup\n        elif query == 'LATEST':\n            all_backups = list(iter(self))\n\n            if not all_backups:\n                return\n\n            assert len(all_backups) > 0\n\n            all_backups.sort(key=lambda bi: bi.last_modified)\n            yield all_backups[-1]\n        else:\n            raise exception.UserException(\n                msg='invalid backup query submitted',\n                detail='The submitted query operator was \"{0}.\"'\n                .format(query))", "response": "A procedure to assist in finding or detailing specific backups"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _delete_wals_before(self, segment_info):\n        wal_key_depth = self.layout.wal_directory().count('/') + 1\n        for key in self._backup_list(prefix=self.layout.wal_directory()):\n            key_name = self.layout.key_name(key)\n            bucket = self._container_name(key)\n            url = '{scm}://{bucket}/{name}'.format(scm=self.layout.scheme,\n                                                   bucket=bucket,\n                                                   name=key_name)\n            key_parts = key_name.split('/')\n            key_depth = len(key_parts)\n            if key_depth != wal_key_depth:\n                logger.warning(\n                    msg=\"skipping non-qualifying key in 'delete before'\",\n                    detail=(\n                        'The unexpected key is \"{0}\", and it appears to be '\n                        'at an unexpected depth.'.format(url)),\n                    hint=generic_weird_key_hint_message)\n            elif key_depth == wal_key_depth:\n                segment_match = (re.match(storage.SEGMENT_REGEXP + r'\\.lzo',\n                                          key_parts[-1]))\n                label_match = (re.match(storage.SEGMENT_REGEXP +\n                                        r'\\.[A-F0-9]{8,8}.backup.lzo',\n                                        key_parts[-1]))\n                history_match = re.match(r'[A-F0-9]{8,8}\\.history',\n                                         key_parts[-1])\n\n                all_matches = [segment_match, label_match, history_match]\n\n                non_matches = len(list(m for m in all_matches if m is None))\n\n                # These patterns are intended to be mutually\n                # exclusive, so either one should match or none should\n                # match.\n                assert non_matches in (len(all_matches) - 1, len(all_matches))\n                if non_matches == len(all_matches):\n                    logger.warning(\n                        msg=\"skipping non-qualifying key in 'delete before'\",\n                        detail=('The unexpected key is \"{0}\", and it appears '\n                                'not to match the WAL file naming pattern.'\n                                .format(url)),\n                        hint=generic_weird_key_hint_message)\n                elif segment_match is not None:\n                    scanned_sn = self._groupdict_to_segment_number(\n                        segment_match.groupdict())\n                    self._delete_if_before(segment_info, scanned_sn, key,\n                                        'a wal file')\n                elif label_match is not None:\n                    scanned_sn = self._groupdict_to_segment_number(\n                        label_match.groupdict())\n                    self._delete_if_before(segment_info, scanned_sn, key,\n                                        'a backup history file')\n                elif history_match is not None:\n                    # History (timeline) files do not have any actual\n                    # WAL position information, so they are never\n                    # deleted.\n                    pass\n                else:\n                    assert False\n            else:\n                assert False", "response": "Delete all WAL files before segment_info."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_everything(self):\n        for k in self._backup_list(prefix=self.layout.basebackups()):\n            self._maybe_delete_key(k, 'part of a base backup')\n\n        for k in self._backup_list(prefix=self.layout.wal_directory()):\n            self._maybe_delete_key(k, 'part of wal logs')\n\n        if self.deleter:\n            self.deleter.close()", "response": "Delete everything in a storage layout\n ArcGIS - E"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting all base backups and WAL segments before a given segment_info.", "response": "def delete_before(self, segment_info):\n        \"\"\"\n        Delete all base backups and WAL before a given segment\n\n        This is the most commonly-used deletion operator; to delete\n        old backups and WAL.\n\n        \"\"\"\n\n        # This will delete all base backup data before segment_info.\n        self._delete_base_backups_before(segment_info)\n\n        # This will delete all WAL segments before segment_info.\n        self._delete_wals_before(segment_info)\n\n        if self.deleter:\n            self.deleter.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_with_retention(self, num_to_retain):\n        base_backup_sentinel_depth = self.layout.basebackups().count('/') + 1\n\n        # Sweep over base backup files, collecting sentinel files from\n        # completed backups.\n        completed_basebackups = []\n        for key in self._backup_list(prefix=self.layout.basebackups()):\n\n            key_name = self.layout.key_name(key)\n            key_parts = key_name.split('/')\n            key_depth = len(key_parts)\n            url = '{scheme}://{bucket}/{name}'.format(\n                scheme=self.layout.scheme,\n                bucket=self._container_name(key),\n                name=key_name)\n\n            if key_depth == base_backup_sentinel_depth:\n                # This is a key at the depth of a base-backup-sentinel file.\n                # Check to see if it matches the known form.\n                match = re.match(storage.COMPLETE_BASE_BACKUP_REGEXP,\n                                 key_parts[-1])\n\n                # If this isn't a base-backup-sentinel file, just ignore it.\n                if match is None:\n                    continue\n\n                # This key corresponds to a base-backup-sentinel file and\n                # represents a completed backup. Grab its segment number.\n                scanned_sn = \\\n                    self._groupdict_to_segment_number(match.groupdict())\n                completed_basebackups.append(dict(\n                    scanned_sn=scanned_sn,\n                    url=url))\n\n        # Sort the base backups from newest to oldest.\n        basebackups = sorted(\n                        completed_basebackups,\n                        key=lambda backup: backup['scanned_sn'].as_an_integer,\n                        reverse=True)\n        last_retained = None\n        if len(basebackups) <= num_to_retain:\n            detail = None\n            if len(basebackups) == 0:\n                msg = 'Not deleting any data.'\n                detail = 'No existing base backups.'\n            elif len(basebackups) == 1:\n                last_retained = basebackups[-1]\n                msg = 'Retaining existing base backup.'\n            else:\n                last_retained = basebackups[-1]\n                msg = \"Retaining all %d base backups.\" % len(basebackups)\n        else:\n            last_retained = basebackups[num_to_retain - 1]\n            num_deleting = len(basebackups) - num_to_retain\n            msg = \"Deleting %d oldest base backups.\" % num_deleting\n            detail = \"Found %d total base backups.\" % len(basebackups)\n        log_message = dict(msg=msg)\n        if detail is not None:\n            log_message['detail'] = detail\n        if last_retained is not None:\n            log_message['hint'] = \\\n                \"Deleting keys older than %s.\" % last_retained['url']\n        logger.info(**log_message)\n\n        # This will delete all base backup and WAL data before\n        # last_retained['scanned_sn'].\n        if last_retained is not None:\n            self._delete_base_backups_before(last_retained['scanned_sn'])\n            self._delete_wals_before(last_retained['scanned_sn'])\n\n        if self.deleter:\n            self.deleter.close()", "response": "Delete the most recent backups and all of the base - backup - sentinels before the last one."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a connection value from a container countryCode", "response": "def connect(creds):\n    \"\"\"\n    Construct a connection value from a container\n    \"\"\"\n    return swiftclient.Connection(\n        authurl=creds.authurl,\n        user=creds.user,\n        key=creds.password,\n        auth_version=creds.auth_version,\n        tenant_name=creds.tenant_name,\n        os_options={\n            \"region_name\": creds.region,\n            \"endpoint_type\": creds.endpoint_type,\n            \"domain_id\": creds.domain_id,\n            \"domain_name\": creds.domain_name,\n            \"tenant_id\": creds.tenant_id,\n            \"user_id\": creds.user_id,\n            \"user_domain_id\": creds.user_domain_id,\n            \"user_domain_name\": creds.user_domain_name,\n            \"project_id\": creds.project_id,\n            \"project_name\": creds.project_name,\n            \"project_domain_id\": creds.project_domain_id,\n            \"project_domain_name\": creds.project_domain_name,\n        }\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a connection value to Google Storage API", "response": "def connect(creds, max_retries=100):\n    \"\"\"Construct a connection value to Google Storage API\n\n    The credentials are retrieved using get_credentials that checks\n    the environment for the correct values.\n\n    \"\"\"\n    credentials, project = google.auth.default()\n    return RetryClient(max_retries=max_retries, project=project,\n                       credentials=credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart upload and accout for resource consumption.", "response": "def _start(self, tpart):\n        \"\"\"Start upload and accout for resource consumption.\"\"\"\n        g = gevent.Greenlet(self.uploader, tpart)\n        g.link(self._finish)\n\n        # Account for concurrency_burden before starting the greenlet\n        # to avoid racing against .join.\n        self.concurrency_burden += 1\n\n        self.member_burden += len(tpart)\n\n        g.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when the upload is complete.", "response": "def _finish(self, g):\n        \"\"\"Called on completion of an upload greenlet.\n\n        Takes care to forward Exceptions or, if there is no error, the\n        finished TarPartition value across a channel.\n        \"\"\"\n        assert g.ready()\n\n        if g.successful():\n            finished_tpart = g.get()\n            self.wait_change.put(finished_tpart)\n        else:\n            self.wait_change.put(g.exception)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nblocks until an upload finishes. Raise an exception if that tar volume failed with an error.", "response": "def _wait(self):\n        \"\"\"Block until an upload finishes\n\n        Raise an exception if that tar volume failed with an error.\n        \"\"\"\n        val = self.wait_change.get()\n\n        if isinstance(val, Exception):\n            # Don't other uncharging, because execution is going to stop\n            raise val\n        else:\n            # Uncharge for resources.\n            self.member_burden -= len(val)\n            self.concurrency_burden -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a tar volume to a set of greenlets that die unexpectedly.", "response": "def put(self, tpart):\n        \"\"\"Upload a tar volume\n\n        Blocks if there is too much work outstanding already, and\n        raise errors of previously submitted greenlets that die\n        unexpectedly.\n        \"\"\"\n        if self.closed:\n            raise UserCritical(msg='attempt to upload tar after closing',\n                               hint='report a bug')\n\n        while True:\n            too_many = (\n                self.concurrency_burden + 1 > self.max_concurrency\n                or self.member_burden + len(tpart) > self.max_members\n            )\n\n            if too_many:\n                # If there are not enough resources to start an upload\n                # even with zero uploads in progress, then something\n                # has gone wrong: the user should not be given enough\n                # rope to hang themselves in this way.\n                if self.concurrency_burden == 0:\n                    raise UserCritical(\n                        msg=('not enough resources in pool to '\n                             'support an upload'),\n                        hint='report a bug')\n\n                # _wait blocks until an upload finishes and clears its\n                # used resources, after which another attempt to\n                # evaluate scheduling resources for another upload\n                # might be worth evaluating.\n                #\n                # Alternatively, an error was encountered in a\n                # previous upload in which case it'll be raised here\n                # and cause the process to regard the upload as a\n                # failure.\n                self._wait()\n                gc.collect()\n            else:\n                # Enough resources available: commence upload\n                self._start(tpart)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads and decompress a S3 URL and return a file - like object.", "response": "def do_lzop_get(creds, url, path, decrypt, do_retry=True):\n    \"\"\"\n    Get and decompress a S3 URL\n\n    This streams the content directly to lzop; the compressed version\n    is never stored on disk.\n\n    \"\"\"\n    assert url.endswith('.lzo'), 'Expect an lzop-compressed file'\n\n    def log_wal_fetch_failures_on_error(exc_tup, exc_processor_cxt):\n        def standard_detail_message(prefix=''):\n            return (prefix + '  There have been {n} attempts to fetch wal '\n                    'file {url} so far.'.format(n=exc_processor_cxt, url=url))\n        typ, value, tb = exc_tup\n        del exc_tup\n\n        # Screen for certain kinds of known-errors to retry from\n        if issubclass(typ, socket.error):\n            socketmsg = value[1] if isinstance(value, tuple) else value\n\n            logger.info(\n                msg='Retrying fetch because of a socket error',\n                detail=standard_detail_message(\n                    \"The socket error's message is '{0}'.\"\n                    .format(socketmsg)))\n        elif (issubclass(typ, boto.exception.S3ResponseError) and\n              value.error_code == 'RequestTimeTooSkewed'):\n            logger.info(msg='Retrying fetch because of a Request Skew time',\n                        detail=standard_detail_message())\n        else:\n            # For all otherwise untreated exceptions, report them as a\n            # warning and retry anyway -- all exceptions that can be\n            # justified should be treated and have error messages\n            # listed.\n            logger.warning(\n                msg='retrying WAL file fetch from unexpected exception',\n                detail=standard_detail_message(\n                    'The exception type is {etype} and its value is '\n                    '{evalue} and its traceback is {etraceback}'\n                    .format(etype=typ, evalue=value,\n                            etraceback=''.join(traceback.format_tb(tb)))))\n\n        # Help Python GC by resolving possible cycles\n        del tb\n\n    def download():\n        with files.DeleteOnError(path) as decomp_out:\n            key = _uri_to_key(creds, url)\n            with get_download_pipeline(PIPE, decomp_out.f, decrypt) as pl:\n                g = gevent.spawn(write_and_return_error, key, pl.stdin)\n\n                try:\n                    # Raise any exceptions from write_and_return_error\n                    exc = g.get()\n                    if exc is not None:\n                        raise exc\n                except boto.exception.S3ResponseError as e:\n                    if e.status == 404:\n                        # Do not retry if the key not present, this\n                        # can happen under normal situations.\n                        pl.abort()\n                        logger.info(\n                            msg=('could no longer locate object while '\n                                 'performing wal restore'),\n                            detail=('The absolute URI that could not be '\n                                    'located is {url}.'.format(url=url)),\n                            hint=('This can be normal when Postgres is trying '\n                                  'to detect what timelines are available '\n                                  'during restoration.'))\n                        decomp_out.remove_regardless = True\n                        return False\n                    elif e.value.error_code == 'ExpiredToken':\n                        # Do not retry if STS token has expired.  It can never\n                        # succeed in the future anyway.\n                        pl.abort()\n                        logger.info(\n                            msg=('could no longer authenticate while '\n                                 'performing wal restore'),\n                            detail=('The absolute URI that could not be '\n                                    'accessed is {url}.'.format(url=url)),\n                            hint=('This can be normal when using STS '\n                                  'credentials.'))\n                        decomp_out.remove_regardless = True\n                        return False\n                    else:\n                        raise\n\n            logger.info(\n                msg='completed download and decompression',\n                detail='Downloaded and decompressed \"{url}\" to \"{path}\"'\n                .format(url=url, path=path))\n        return True\n\n    if do_retry:\n        download = retry(\n            retry_with_count(log_wal_fetch_failures_on_error))(download)\n\n    return download()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_filenos(preserve):\n    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]\n    if maxfd == resource.RLIM_INFINITY:\n        maxfd = 4096\n    for fileno in range(maxfd):\n        if fileno not in preserve:\n            try:\n                os.close(fileno)\n            except OSError as err:\n                if not err.errno == errno.EBADF:\n                    raise DaemonError(\n                        'Failed to close file descriptor {0}: {1}'\n                        .format(fileno, err))", "response": "Close all open file descriptors that are not in preserve."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the default signal map for this system.", "response": "def default_signal_map():\n    \"\"\" Create the default signal map for this system.\n\n    :return: dict\n    \"\"\"\n    name_map = {\n        'SIGTSTP': None,\n        'SIGTTIN': None,\n        'SIGTTOU': None,\n        'SIGTERM': 'terminate'}\n    signal_map = {}\n    for name, target in list(name_map.items()):\n        if hasattr(signal, name):\n            signal_map[getattr(signal, name)] = target\n    return signal_map"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if our parent is inet", "response": "def parent_is_inet():\n    \"\"\" Check if parent is inet\n\n    Check if our parent seems ot be a superserver, aka inetd/xinetd.\n\n    This is done by checking if sys.__stdin__ is a network socket.\n\n    :return: bool\n    \"\"\"\n    result = False\n    sock = socket.fromfd(\n        sys.__stdin__.fileno(),\n        socket.AF_INET,\n        socket.SOCK_RAW)\n    try:\n        sock.getsockopt(socket.SOL_SOCKET, socket.SO_TYPE)\n        result = True\n    except (OSError, socket.error) as err:\n        if not err.args[0] == errno.ENOTSOCK:\n            result = True\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef redirect_stream(system, target):\n    if target is None:\n        target_fd = os.open(os.devnull, os.O_RDWR)\n    else:\n        target_fd = target.fileno()\n    try:\n        os.dup2(target_fd, system.fileno())\n    except OSError as err:\n        raise DaemonError('Could not redirect {0} to {1}: {2}'\n                          .format(system, target, err))", "response": "Redirect Unix streams to target."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_signal_handler(self, handler):\n        if not handler:\n            result = signal.SIG_IGN\n        elif isinstance(handler, string_types):\n            result = getattr(self, handler)\n        else:\n            result = handler\n        return result", "response": "get the callback function for the given signal handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _files_preserve(self):\n        result = set()\n        files = [] if not self.files_preserve else self.files_preserve\n        files.extend([self.stdin, self.stdout, self.stderr])\n        for item in files:\n            if hasattr(item, 'fileno'):\n                result.add(item.fileno())\n            if isinstance(item, int):\n                result.add(item)\n        return result", "response": "create a set of protected files based on self. files_preserve and\n        self. stdin self. stdout and self. stderr that should not get\n        closed while daemonizing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(\n    model,\n    app=None,\n    manager_name=\"history\",\n    records_class=None,\n    table_name=None,\n    **records_config\n):\n    \"\"\"\n    Create historical model for `model` and attach history manager to `model`.\n\n    Keyword arguments:\n    app -- App to install historical model into (defaults to model.__module__)\n    manager_name -- class attribute name to use for historical manager\n    records_class -- class to use for history relation (defaults to\n        HistoricalRecords)\n    table_name -- Custom name for history table (defaults to\n        'APPNAME_historicalMODELNAME')\n\n    This method should be used as an alternative to attaching an\n    `HistoricalManager` instance directly to `model`.\n    \"\"\"\n    from . import models\n\n    if records_class is None:\n        records_class = models.HistoricalRecords\n\n    records = records_class(**records_config)\n    records.manager_name = manager_name\n    records.table_name = table_name\n    records.module = app and (\"%s.models\" % app) or model.__module__\n    records.cls = model\n    records.add_extra_methods(model)\n    records.finalize(model)", "response": "Register a new historical model with the given app."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_urls(self):\n        urls = super(SimpleHistoryAdmin, self).get_urls()\n        admin_site = self.admin_site\n        opts = self.model._meta\n        info = opts.app_label, opts.model_name\n        history_urls = [\n            url(\n                \"^([^/]+)/history/([^/]+)/$\",\n                admin_site.admin_view(self.history_form_view),\n                name=\"%s_%s_simple_history\" % info,\n            )\n        ]\n        return history_urls + urls", "response": "Returns the additional urls used by the Reversion admin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef history_view(self, request, object_id, extra_context=None):\n        request.current_app = self.admin_site.name\n        model = self.model\n        opts = model._meta\n        app_label = opts.app_label\n        pk_name = opts.pk.attname\n        history = getattr(model, model._meta.simple_history_manager_attribute)\n        object_id = unquote(object_id)\n        action_list = history.filter(**{pk_name: object_id})\n        if not isinstance(history.model.history_user, property):\n            # Only select_related when history_user is a ForeignKey (not a property)\n            action_list = action_list.select_related(\"history_user\")\n        history_list_display = getattr(self, \"history_list_display\", [])\n        # If no history was found, see whether this object even exists.\n        try:\n            obj = self.get_queryset(request).get(**{pk_name: object_id})\n        except model.DoesNotExist:\n            try:\n                obj = action_list.latest(\"history_date\").instance\n            except action_list.model.DoesNotExist:\n                raise http.Http404\n\n        if not self.has_change_permission(request, obj):\n            raise PermissionDenied\n\n        # Set attribute on each action_list entry from admin methods\n        for history_list_entry in history_list_display:\n            value_for_entry = getattr(self, history_list_entry, None)\n            if value_for_entry and callable(value_for_entry):\n                for list_entry in action_list:\n                    setattr(list_entry, history_list_entry, value_for_entry(list_entry))\n\n        content_type = ContentType.objects.get_by_natural_key(*USER_NATURAL_KEY)\n        admin_user_view = \"admin:%s_%s_change\" % (\n            content_type.app_label,\n            content_type.model,\n        )\n        context = {\n            \"title\": _(\"Change history: %s\") % force_text(obj),\n            \"action_list\": action_list,\n            \"module_name\": capfirst(force_text(opts.verbose_name_plural)),\n            \"object\": obj,\n            \"root_path\": getattr(self.admin_site, \"root_path\", None),\n            \"app_label\": app_label,\n            \"opts\": opts,\n            \"admin_user_view\": admin_user_view,\n            \"history_list_display\": history_list_display,\n        }\n        context.update(self.admin_site.each_context(request))\n        context.update(extra_context or {})\n        extra_kwargs = {}\n        return render(request, self.object_history_template, context, **extra_kwargs)", "response": "The history admin view for this object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_model(self, request, obj, form, change):\n        obj._history_user = request.user\n        super(SimpleHistoryAdmin, self).save_model(request, obj, form, change)", "response": "Set special model attribute to user for reference after save"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbulk create a copy of all instances in the model.", "response": "def _bulk_history_create(self, model, batch_size):\n        \"\"\"Save a copy of all instances to the historical model.\n\n        :param model: Model you want to bulk create\n        :param batch_size: number of models to create at once.\n        :return:\n        \"\"\"\n\n        instances = []\n        history = utils.get_history_manager_for_model(model)\n        if self.verbosity >= 1:\n            self.stdout.write(\n                \"Starting bulk creating history models for {} instances {}-{}\".format(\n                    model, 0, batch_size\n                )\n            )\n\n        iterator_kwargs = (\n            {\"chunk_size\": batch_size} if django.VERSION >= (2, 0, 0) else {}\n        )\n        for index, instance in enumerate(\n            model._default_manager.iterator(**iterator_kwargs)\n        ):\n            # Can't Just pass batch_size to bulk_create as this can lead to\n            # Out of Memory Errors as we load too many models into memory after\n            # creating them. So we only keep batch_size worth of models in\n            # historical_instances and clear them after we hit batch_size\n            if index % batch_size == 0:\n\n                history.bulk_history_create(instances, batch_size=batch_size)\n\n                instances = []\n\n                if self.verbosity >= 1:\n                    self.stdout.write(\n                        \"Finished bulk creating history models for {} \"\n                        \"instances {}-{}, starting next {}\".format(\n                            model, index - batch_size, index, batch_size\n                        )\n                    )\n\n            instances.append(instance)\n\n        # create any we didn't get in the last loop\n        if instances:\n            history.bulk_history_create(instances, batch_size=batch_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform_field(field):\n    field.name = field.attname\n    if isinstance(field, models.AutoField):\n        field.__class__ = models.IntegerField\n\n    elif isinstance(field, models.FileField):\n        # Don't copy file, just path.\n        field.__class__ = models.TextField\n\n    # Historical instance shouldn't change create/update timestamps\n    field.auto_now = False\n    field.auto_now_add = False\n\n    if field.primary_key or field.unique:\n        # Unique fields can no longer be guaranteed unique,\n        # but they should still be indexed for faster lookups.\n        field.primary_key = False\n        field._unique = False\n        field.db_index = True\n        field.serialize = True", "response": "Customize field appropriately for use in historical model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_history_model(self, model, inherited):\n        attrs = {\n            \"__module__\": self.module,\n            \"_history_excluded_fields\": self.excluded_fields,\n        }\n\n        app_module = \"%s.models\" % model._meta.app_label\n\n        if inherited:\n            # inherited use models module\n            attrs[\"__module__\"] = model.__module__\n        elif model.__module__ != self.module:\n            # registered under different app\n            attrs[\"__module__\"] = self.module\n        elif app_module != self.module:\n            # Abuse an internal API because the app registry is loading.\n            app = apps.app_configs[model._meta.app_label]\n            models_module = app.name\n            attrs[\"__module__\"] = models_module\n\n        fields = self.copy_fields(model)\n        attrs.update(fields)\n        attrs.update(self.get_extra_fields(model, fields))\n        # type in python2 wants str as a first argument\n        attrs.update(Meta=type(str(\"Meta\"), (), self.get_meta_options(model)))\n        if self.table_name is not None:\n            attrs[\"Meta\"].db_table = self.table_name\n\n        # Set as the default then check for overrides\n        name = self.get_history_model_name(model)\n\n        registered_models[model._meta.db_table] = model\n        return python_2_unicode_compatible(type(str(name), self.bases, attrs))", "response": "Creates a historical model that can be used to associate with the model provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate copies of the model s original fields returning a dictionary mapping field name to copied field object.", "response": "def copy_fields(self, model):\n        \"\"\"\n        Creates copies of the model's original fields, returning\n        a dictionary mapping field name to copied field object.\n        \"\"\"\n        fields = {}\n        for field in self.fields_included(model):\n            field = copy.copy(field)\n            field.remote_field = copy.copy(field.remote_field)\n            if isinstance(field, OrderWrt):\n                # OrderWrt is a proxy field, switch to a plain IntegerField\n                field.__class__ = models.IntegerField\n            if isinstance(field, models.ForeignKey):\n                old_field = field\n                old_swappable = old_field.swappable\n                old_field.swappable = False\n                try:\n                    _name, _path, args, field_args = old_field.deconstruct()\n                finally:\n                    old_field.swappable = old_swappable\n                if getattr(old_field, \"one_to_one\", False) or isinstance(\n                    old_field, models.OneToOneField\n                ):\n                    FieldType = models.ForeignKey\n                else:\n                    FieldType = type(old_field)\n\n                # If field_args['to'] is 'self' then we have a case where the object\n                # has a foreign key to itself. If we pass the historical record's\n                # field to = 'self', the foreign key will point to an historical\n                # record rather than the base record. We can use old_field.model here.\n                if field_args.get(\"to\", None) == \"self\":\n                    field_args[\"to\"] = old_field.model\n\n                # Override certain arguments passed when creating the field\n                # so that they work for the historical field.\n                field_args.update(\n                    db_constraint=False,\n                    related_name=\"+\",\n                    null=True,\n                    blank=True,\n                    primary_key=False,\n                    db_index=True,\n                    serialize=True,\n                    unique=False,\n                    on_delete=models.DO_NOTHING,\n                )\n                field = FieldType(*args, **field_args)\n                field.name = old_field.name\n            else:\n                transform_field(field)\n            fields[field.name] = field\n        return fields"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_extra_fields(self, model, fields):\n\n        def revert_url(self):\n            \"\"\"URL for this change in the default admin site.\"\"\"\n            opts = model._meta\n            app_label, model_name = opts.app_label, opts.model_name\n            return reverse(\n                \"%s:%s_%s_simple_history\" % (admin.site.name, app_label, model_name),\n                args=[getattr(self, opts.pk.attname), self.history_id],\n            )\n\n        def get_instance(self):\n            attrs = {\n                field.attname: getattr(self, field.attname) for field in fields.values()\n            }\n            if self._history_excluded_fields:\n                excluded_attnames = [\n                    model._meta.get_field(field).attname\n                    for field in self._history_excluded_fields\n                ]\n                values = (\n                    model.objects.filter(pk=getattr(self, model._meta.pk.attname))\n                    .values(*excluded_attnames)\n                    .get()\n                )\n                attrs.update(values)\n            return model(**attrs)\n\n        def get_next_record(self):\n            \"\"\"\n            Get the next history record for the instance. `None` if last.\n            \"\"\"\n            history = utils.get_history_manager_for_model(self.instance)\n            return (\n                history.filter(Q(history_date__gt=self.history_date))\n                .order_by(\"history_date\")\n                .first()\n            )\n\n        def get_prev_record(self):\n            \"\"\"\n            Get the previous history record for the instance. `None` if first.\n            \"\"\"\n            history = utils.get_history_manager_for_model(self.instance)\n            return (\n                history.filter(Q(history_date__lt=self.history_date))\n                .order_by(\"history_date\")\n                .last()\n            )\n\n        extra_fields = {\n            \"history_id\": self._get_history_id_field(),\n            \"history_date\": models.DateTimeField(),\n            \"history_change_reason\": self._get_history_change_reason_field(),\n            \"history_type\": models.CharField(\n                max_length=1,\n                choices=((\"+\", _(\"Created\")), (\"~\", _(\"Changed\")), (\"-\", _(\"Deleted\"))),\n            ),\n            \"history_object\": HistoricalObjectDescriptor(\n                model, self.fields_included(model)\n            ),\n            \"instance\": property(get_instance),\n            \"instance_type\": model,\n            \"next_record\": property(get_next_record),\n            \"prev_record\": property(get_prev_record),\n            \"revert_url\": revert_url,\n            \"__str__\": lambda self: \"{} as of {}\".format(\n                self.history_object, self.history_date\n            ),\n        }\n\n        extra_fields.update(self._get_history_related_field(model))\n        extra_fields.update(self._get_history_user_fields())\n\n        return extra_fields", "response": "Returns dict of extra fields added to the historical record model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_meta_options(self, model):\n        meta_fields = {\n            \"ordering\": (\"-history_date\", \"-history_id\"),\n            \"get_latest_by\": \"history_date\",\n        }\n        if self.user_set_verbose_name:\n            name = self.user_set_verbose_name\n        else:\n            name = format_lazy(\"historical {}\", smart_text(model._meta.verbose_name))\n        meta_fields[\"verbose_name\"] = name\n        if self.app:\n            meta_fields[\"app_label\"] = self.app\n        return meta_fields", "response": "Returns a dictionary of fields that will be added to\n            the Meta inner class of the historical record model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_history_user(self, instance):\n        try:\n            return instance._history_user\n        except AttributeError:\n            request = None\n            try:\n                if self.thread.request.user.is_authenticated:\n                    request = self.thread.request\n            except AttributeError:\n                pass\n\n        return self.get_user(instance=instance, request=request)", "response": "Get the modifying user from instance or middleware."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the most recent copy of the instance available in the history.", "response": "def most_recent(self):\n        \"\"\"\n        Returns the most recent copy of the instance available in the history.\n        \"\"\"\n        if not self.instance:\n            raise TypeError(\n                \"Can't use most_recent() without a {} instance.\".format(\n                    self.model._meta.object_name\n                )\n            )\n        tmp = []\n        excluded_fields = getattr(self.model, \"_history_excluded_fields\", [])\n\n        for field in self.instance._meta.fields:\n            if field.name in excluded_fields:\n                continue\n            if isinstance(field, models.ForeignKey):\n                tmp.append(field.name + \"_id\")\n            else:\n                tmp.append(field.name)\n        fields = tuple(tmp)\n        try:\n            values = self.get_queryset().values_list(*fields)[0]\n        except IndexError:\n            raise self.instance.DoesNotExist(\n                \"%s has no historical record.\" % self.instance._meta.object_name\n            )\n        return self.instance.__class__(*values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a snapshot as of a specific date.", "response": "def as_of(self, date):\n        \"\"\"Get a snapshot as of a specific date.\n\n        Returns an instance, or an iterable of the instances, of the\n        original model with all the attributes set according to what\n        was present on the object on the date provided.\n        \"\"\"\n        if not self.instance:\n            return self._as_of_set(date)\n        queryset = self.get_queryset().filter(history_date__lte=date)\n        try:\n            history_obj = queryset[0]\n        except IndexError:\n            raise self.instance.DoesNotExist(\n                \"%s had not yet been created.\" % self.instance._meta.object_name\n            )\n        if history_obj.history_type == \"-\":\n            raise self.instance.DoesNotExist(\n                \"%s had already been deleted.\" % self.instance._meta.object_name\n            )\n        return history_obj.instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbulking create the history for the objects specified by objs", "response": "def bulk_history_create(self, objs, batch_size=None):\n        \"\"\"Bulk create the history for the objects specified by objs\"\"\"\n\n        historical_instances = [\n            self.model(\n                history_date=getattr(instance, \"_history_date\", now()),\n                history_user=getattr(instance, \"_history_user\", None),\n                history_change_reason=getattr(instance, \"changeReason\", \"\"),\n                history_type=\"+\",\n                **{\n                    field.attname: getattr(instance, field.attname)\n                    for field in instance._meta.fields\n                    if field.name not in self.model._history_excluded_fields\n                }\n            )\n            for instance in objs\n        ]\n\n        return self.model.objects.bulk_create(\n            historical_instances, batch_size=batch_size\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_history_manager_for_model(model):\n    try:\n        manager_name = model._meta.simple_history_manager_attribute\n    except AttributeError:\n        raise NotHistoricalModelError(\n            \"Cannot find a historical model for {model}.\".format(model=model)\n        )\n    return getattr(model, manager_name)", "response": "Return the history manager for a given app model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbulk create the objects specified by objs while also bulk creating their history.", "response": "def bulk_create_with_history(objs, model, batch_size=None):\n    \"\"\"\n    Bulk create the objects specified by objs while also bulk creating\n    their history (all in one transaction).\n    :param objs: List of objs (not yet saved to the db) of type model\n    :param model: Model class that should be created\n    :param batch_size: Number of objects that should be created in each batch\n    :return: List of objs with IDs\n    \"\"\"\n\n    history_manager = get_history_manager_for_model(model)\n\n    with transaction.atomic(savepoint=False):\n        objs_with_id = model.objects.bulk_create(objs, batch_size=batch_size)\n        history_manager.bulk_history_create(objs_with_id, batch_size=batch_size)\n\n    return objs_with_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(self, vroot, entry_variables):\n        self.graph_info = GraphInfo(vroot)\n        self.entry_variables = entry_variables\n\n        cnt = 0\n        with nn.parameter_scope(self.name):\n            # Function loop in the forward order\n            for t, func in enumerate(self.graph_info.funcs):\n                if func.name == \"BatchNormalization\":\n                    bn_func = func\n                    # TODO: should deal with both?\n                    if bn_func.info.args[\"batch_stat\"] == False:\n                        o = self._bn_linear_conversion(bn_func, cnt)\n                        cnt += 1\n                        continue\n                # Identity conversion\n                o = self._identity_conversion(func)\n\n        self.end_variable = o\n        return self.end_variable", "response": "This function converts the graph to the new format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the vroot to the end variable.", "response": "def convert(self, vroot, entry_variables):\n        \"\"\"\n        All functions are replaced with the same `new` function.\n\n        Args:\n            vroot (:obj:`Variable`): NNabla Variable\n            entry_variables (:obj:`Variable`): Entry variable from which the conversion starts.\n        \"\"\"\n        self.graph_info = GraphInfo(vroot)\n        self.entry_variables = entry_variables\n\n        with nn.parameter_scope(self.name):\n            # Function loop in the forward order\n            for func in self.graph_info.funcs:\n                o = self._identity_conversion(func)\n            self.end_variable = o\n        return self.end_variable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parameter_scope(name, scope=None):\n    global current_scope\n    names = name.strip('/').split('/')\n    if not names:\n        raise ValueError(\n            'Invalid argument of parameter_scope(\"{}\").'.format(name))\n    prev_scope = current_scope\n    if scope is None:\n        scope = current_scope\n    else:\n        if not isinstance(scope, dict):\n            raise ValueError(\n                'Scope must be a dictionary. {} is given.'.format(type(scope)))\n    for name in names:\n        parent_scope = scope\n        # When name is empty, the given scope is used as a current scope.\n        if name:\n            # Creates a new scope dict if it doesn't exist.\n            # `dict.get` returns default value (OrderedDict())\n            # if scope contains `name`\n            scope = scope.get(name, OrderedDict())\n            assert isinstance(scope, dict)\n            parent_scope[name] = scope\n    current_scope = scope\n    try:\n        yield current_scope\n    finally:\n        current_scope = prev_scope", "response": "This function returns a list of parameters that are defined in the current parameter scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop_parameter(key):\n    '''Remove and get parameter by key.\n\n    Args:\n        key(str): Key of parameter.\n\n    Returns: ~nnabla.Variable\n        Parameter if key found, otherwise None.\n\n    '''\n    names = key.split('/')\n    if len(names) > 1:\n        with parameter_scope(names[0]):\n            return pop_parameter('/'.join(names[1:]))\n    global current_scope\n    param = current_scope.get(key, None)\n    if param is not None:\n        del current_scope[key]\n    return param", "response": "Remove and get a parameter by key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an existing parameter variable with the given name.", "response": "def get_parameter_or_create(name, shape=None, initializer=None, need_grad=True,\n                            as_need_grad=None):\n    \"\"\"\n    Returns an existing parameter variable with the provided name.\n    If a variable with the provided name does not exist,\n    a new variable with the provided name is returned.\n\n    Args:\n\n      name(str): The name under the current scope. If it already exists, the name is queried from the\n          parameter manager.\n      shape (:obj:`tuple` of :obj:`int`): Shape of created parameter. The shape of the specified\n          parameter must match with this shape. The default is None which is only valid if initializer is given as an :obj:`numpy.ndarray`.\n      initializer (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): An initialization function to be applied to the parameter. :obj:`numpy.ndarray` can also be given to initialize parameters from numpy array data.\n      need_grad (bool):\n          Register the parameter with the specified ``need_grad`` flag.\n          The default is True. If the flag is different from the previously\n          specified one, the flag will be overwritten, but the values will be\n          kept.\n      as_need_grad (bool):\n          Get a parameter variable with the specified ``need_grad`` flag.\n          Note that this doesn't overwrite the flag of the registered parameter\n          variable with the provided name. Instead, if the given flag\n          mismatches with the previously registered ``need_grad`` flag, it\n          returns a new variable referring to the same array contents but with\n          ``need_grad=as_need_grad``.\n\n    \"\"\"\n    names = name.split('/')\n    if len(names) > 1:\n        with parameter_scope(names[0]):\n            return get_parameter_or_create('/'.join(names[1:]), shape, initializer, need_grad, as_need_grad)\n    param = get_parameter(names[0])\n    if param is None:\n        class VariableInfo:\n            pass\n        info = VariableInfo()\n        info.initializer = initializer\n\n        if initializer is not None:\n            if isinstance(initializer, numpy.ndarray):  # numpy init\n                param = nn.Variable(initializer.shape, need_grad=need_grad)\n                param.d = initializer\n            # initializer init\n            elif isinstance(initializer, nn.initializer.BaseInitializer) or initializer.__name__ == \"<lambda>\":\n                assert shape is not None\n                param = nn.Variable(shape, need_grad=need_grad)\n                param.d = initializer(shape=param.shape)\n            else:\n                raise ValueError(\n                    \"`initializer` must be either the :obj:`numpy.ndarray` or an instance inherited from `nnabla.initializer.BaseInitializer`.\")\n        else:  # default init\n            assert shape is not None\n            param = nn.Variable(shape, need_grad=need_grad)\n        set_parameter(name, param)\n    else:\n        if param.shape != tuple(shape):\n            raise ValueError(\n                'The size of existing parameter \"{}\" {} is different from the size of new parameter {}.\\n'\n                'To clear all parameters, call nn.clear_parameters().'.format(name, param.shape, tuple(shape)))\n        if need_grad != param.need_grad:\n            param.need_grad = need_grad\n    if as_need_grad is None:\n        return param\n    if param.need_grad != as_need_grad:\n        param = param.get_unlinked_variable(need_grad=as_need_grad)\n    return param"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_parameters(params=None, path='', grad_only=True):\n\n    global current_scope\n    if params is None:\n        params = OrderedDict()\n    for k, v in iteritems(current_scope):\n        if isinstance(v, dict):\n            with parameter_scope(k):\n                params = get_parameters(\n                    params, '/'.join([path, k]) if path else k, grad_only=grad_only)\n        else:\n            assert isinstance(v, nn.Variable)\n            if not grad_only or v.need_grad:\n                params['/'.join([path, k]) if path else k] = v\n    return params", "response": "Get the parameters under the current parameter scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_parameters(path, proto=None, needs_proto=False):\n    _, ext = os.path.splitext(path)\n\n    if ext == '.h5':\n        # TODO temporary work around to suppress FutureWarning message.\n        import warnings\n        warnings.simplefilter('ignore', category=FutureWarning)\n        import h5py\n        with h5py.File(path, 'r') as hd:\n            keys = []\n\n            def _get_keys(name):\n                ds = hd[name]\n                if not isinstance(ds, h5py.Dataset):\n                    # Group\n                    return\n                # To preserve order of parameters\n                keys.append((ds.attrs.get('index', None), name))\n            hd.visit(_get_keys)\n            for _, key in sorted(keys):\n                ds = hd[key]\n\n                var = get_parameter_or_create(\n                    key, ds.shape, need_grad=ds.attrs['need_grad'])\n                var.data.cast(ds.dtype)[...] = ds[...]\n\n                if needs_proto:\n                    if proto is None:\n                        proto = nnabla_pb2.NNablaProtoBuf()\n                    parameter = proto.parameter.add()\n                    parameter.variable_name = key\n                    parameter.shape.dim.extend(ds.shape)\n                    parameter.data.extend(\n                        numpy.array(ds[...]).flatten().tolist())\n                    parameter.need_grad = False\n                    if ds.attrs['need_grad']:\n                        parameter.need_grad = True\n\n    else:\n        if proto is None:\n            proto = nnabla_pb2.NNablaProtoBuf()\n\n        if ext == '.protobuf':\n            with open(path, 'rb') as f:\n                proto.MergeFromString(f.read())\n                set_parameter_from_proto(proto)\n        elif ext == '.nntxt' or ext == '.prototxt':\n            with open(path, 'r') as f:\n                text_format.Merge(f.read(), proto)\n                set_parameter_from_proto(proto)\n\n        elif ext == '.nnp':\n            try:\n                tmpdir = tempfile.mkdtemp()\n                with zipfile.ZipFile(path, 'r') as nnp:\n                    for name in nnp.namelist():\n                        nnp.extract(name, tmpdir)\n                        _, ext = os.path.splitext(name)\n                        if ext in ['.protobuf', '.h5']:\n                            proto = load_parameters(os.path.join(\n                                tmpdir, name), proto, needs_proto)\n            finally:\n                shutil.rmtree(tmpdir)\n                logger.info(\"Parameter load ({}): {}\".format(format, path))\n        else:\n            pass  # TODO: Unknwon extension.\n    return proto", "response": "Load parameters from a file with the specified format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving all parameters into a file with the specified format.", "response": "def save_parameters(path, params=None):\n    \"\"\"Save all parameters into a file with the specified format.\n\n    Currently hdf5 and protobuf formats are supported.\n\n    Args:\n      path : path or file object\n      params (dict, optional): Parameters to be saved. Dictionary is of a parameter name (:obj:`str`) to :obj:`~nnabla.Variable`.\n    \"\"\"\n    _, ext = os.path.splitext(path)\n    params = get_parameters(grad_only=False) if params is None else params\n    if ext == '.h5':\n        # TODO temporary work around to suppress FutureWarning message.\n        import warnings\n        warnings.simplefilter('ignore', category=FutureWarning)\n        import h5py\n        with h5py.File(path, 'w') as hd:\n            for i, (k, v) in enumerate(iteritems(params)):\n                hd[k] = v.d\n                hd[k].attrs['need_grad'] = v.need_grad\n                # To preserve order of parameters\n                hd[k].attrs['index'] = i\n    elif ext == '.protobuf':\n        proto = nnabla_pb2.NNablaProtoBuf()\n        for variable_name, variable in params.items():\n            parameter = proto.parameter.add()\n            parameter.variable_name = variable_name\n            parameter.shape.dim.extend(variable.shape)\n            parameter.data.extend(numpy.array(variable.d).flatten().tolist())\n            parameter.need_grad = variable.need_grad\n\n        with open(path, \"wb\") as f:\n            f.write(proto.SerializeToString())\n    else:\n        logger.critical('Only supported hdf5 or protobuf.')\n        assert False\n    logger.info(\"Parameter save ({}): {}\".format(ext, path))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_extension_module(ext_name):\n    '''\n    Import an extension module by name.\n\n    The extension modules are installed under the `nnabla_ext` package as\n    namespace packages. All extension modules provide a unified set of APIs.\n\n    Args:\n        ext_name(str): Extension name. e.g. 'cpu', 'cuda', 'cudnn' etc.\n\n    Returns: module\n        An Python module of a particular NNabla extension.\n\n    Example:\n\n        .. code-block:: python\n\n            ext = import_extension_module('cudnn')\n            available_devices = ext.get_devices()\n            print(available_devices)\n            ext.device_synchronize(available_devices[0])\n            ext.clear_memory_cache()\n\n    '''\n    import importlib\n    try:\n        return importlib.import_module('.' + ext_name, 'nnabla_ext')\n    except ImportError as e:\n        from nnabla import logger\n        logger.error('Extension `{}` does not exist.'.format(ext_name))\n        raise e", "response": "Imports an extension module by name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist up available extensions.", "response": "def list_extensions():\n    '''\n    List up available extensions.\n\n    Note:\n        It may not work on some platforms/environments since it depends\n        on the directory structure of the namespace packages.\n\n    Returns: list of str\n        Names of available extensions.\n\n    '''\n    import nnabla_ext.cpu\n    from os.path import dirname, join, realpath\n    from os import listdir\n    ext_dir = realpath((join(dirname(nnabla_ext.cpu.__file__), '..')))\n    return listdir(ext_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_extension_context(ext_name, **kw):\n    if ext_name == 'cuda.cudnn':\n        from nnabla import logger\n        logger.warn(\n            'Deprecated extension name \"cuda.cudnn\" passed. Use \"cudnn\" instead.')\n        ext_name = 'cudnn'\n    mod = import_extension_module(ext_name)\n    return mod.context(**kw)", "response": "Get the context of the specified extension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imread(path, grayscale=False, size=None, interpolate=\"bilinear\",\n           channel_first=False, as_uint16=False, num_channels=-1):\n    \"\"\"\n    Read image by PIL module.\n    Notice that PIL only supports uint8 for RGB (not uint16).\n    So this imread function returns only uint8 array for both RGB and gray-scale.\n    (Currently ignore \"I\" mode for gray-scale (32bit integer).)\n\n    Args:\n        path (str or 'file object'): File path or object to read.\n        grayscale (bool):\n        size (tupple of int):\n            (width, height).\n            If None, output img shape depends on the files to read.\n        channel_first (bool):\n            This argument specifies the shape of img is whether (height, width, channel) or (channel, height, width).\n            Default value is False, which means the img shape is (height, width, channel).\n        interpolate (str):\n            must be one of [\"nearest\", \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"].\n        as_uint16 (bool):\n            If you specify this argument, you can use only False for pil backend.\n        num_channels (int):\n            channel size of output array.\n            Default is -1 which preserves raw image shape.\n\n    Returns:\n         numpy.ndarray\n    \"\"\"\n\n    if as_uint16:\n        raise ValueError(\"pillow only supports uint8 for RGB image.\"\n                         \" If you want to load image as uint16,\"\n                         \" install pypng or cv2 and\"\n                         \" nnabla.utils.image_utils automatically change backend to use these module.\")\n\n    _imread_before(grayscale, num_channels)\n\n    pil_img = Image.open(path, mode=\"r\")\n\n    img = pil_image_to_ndarray(pil_img, grayscale, num_channels)\n\n    return _imread_after(img, size, interpolate, channel_first, imresize)", "response": "Read image by PIL module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imsave(path, img, channel_first=False, as_uint16=False, auto_scale=True):\n    img = _imsave_before(img, channel_first, auto_scale)\n\n    if img.dtype == np.uint16 or as_uint16:\n        raise ValueError(\"Pillow only supports uint8 image to save. Cast img to uint8.\"\n                         \"If you want to save image as uint16, install pypng or cv2 \"\n                         \"and nnabla.utils.image_utils automatically change backend to use these module.\")\n\n    if auto_scale and img.dtype != np.uint8:\n        img = (img * 255).astype(np.uint8)\n\n    Image.fromarray(img).save(path)", "response": "Save image by pillow module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a variable graph given a network by name", "response": "def get_network(self, name, batch_size=None, callback=None):\n        '''Create a variable graph given  network by name\n\n        Returns: NnpNetwork\n\n        '''\n        network_proto = nnabla_pb2.Network()\n        network_proto.CopyFrom(self.network_dict[name])\n        return NnpNetwork(network_proto, self._params, batch_size, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset kernel related parameters to the given node and add padding functions.", "response": "def set_kernel_parameter_and_add_padding(node, kp,\n                                         pad_mode, pad_val,\n                                         base_name, func_counter):\n    \"\"\"Set kernel related parameters(strides, pads, kernel_shape) to the given\n    parameter. This function also generates a padding function if we need a\n    seperate pad function for asymmetry padding.\n    \"\"\"\n    dims = []\n    strides = []\n    pads = []\n    kernel = []\n    for attr in node.attribute:\n        if attr.name == \"strides\":\n            if attr.type != AttributeProto.INTS:\n                raise ValueError(\"Only INTS are supported for strides in {}\"\n                                 .format(node.op_type))\n            strides.extend(attr.ints)\n            dims.append(len(strides))\n        elif attr.name == \"pads\":\n            if attr.type != AttributeProto.INTS:\n                raise ValueError(\"Only INTS are supported for pads in {}\"\n                                 .format(node.op_type))\n            pads.extend(attr.ints)\n            dims.append(len(pads))\n        elif attr.name == \"kernel_shape\":\n            if attr.type != AttributeProto.INTS:\n                raise ValueError(\"Only INTS are supported for kernel_shape in {}\"\n                                 .format(node.op_type))\n            kernel.extend(attr.ints)\n            dims.append(len(kernel))\n        elif attr.name == \"count_include_pad\":\n            if attr.type != AttributeProto.INT:\n                raise ValueError(\"Only INT is supported for count_include_pad in {} op_type\"\n                                 .format(node.op_type))\n            kp.including_pad = bool(attr.i)\n        else:\n            raise ValueError(\"Unsupported attribute {} was specified at {}\"\n                             .format(attr.name, node.op_type))\n    # NNabla requires for the dimensions of strides, pads, kernels to match.\n    # We align the dimensions for all three attributes to the shortest one.\n    dim = min(dims)\n    padf = None\n    if strides:\n        kp.stride.dim.extend(strides[:])\n    if pads:\n        padval = []\n        asymmetry = check_padding(pads, dim, padval)\n        if asymmetry:\n            # Add a separate padding function for\n            # asymmetry padding\n            input = node.input[0]\n            padded = input+\"_pad\"\n            pad_width = rearrange_pads(pads)\n            padf = generate_pad(node.name, input, padded,\n                                pad_mode, pad_width, pad_val,\n                                base_name, func_counter)\n        kp.pad.dim.extend(padval)\n    else:\n        # In case we don't have padding set,\n        # we set zero padding just in case NNabla does not set the\n        # default padding values correctly (such as in AveragePooling).\n        # This code should not be needed\n        # if NNabla handles default values correctly.\n        kp.pad.dim.extend([0]*dim)\n    if kernel:\n        kp.kernel.dim.extend(kernel[:])\n    return padf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_function_name(func, node_name, base_name, func_counter):\n    # NNabla requires each function to have a unique name\n    # so we generate one here.\n    func.name, count = generate_function_name(func.type, base_name, node_name,\n                                              func_counter)\n    update_function_counter(func.type, func_counter, count)", "response": "Set a sufficient name for the function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_transpose(node_name, in_name, out_name, axes, base_name, func_counter):\n    trans = nnabla_pb2.Function()\n    trans.type = \"Transpose\"\n    set_function_name(trans, node_name, base_name, func_counter)\n    trans.input.extend([in_name])\n    trans.output.extend([out_name])\n    tp = trans.transpose_param\n    tp.axes.extend(axes)\n    return trans", "response": "Generate a Transpose operator to transpose the specified buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a BroadcastTo operator to brodcast specified buffer", "response": "def generate_broadcast_to(node_name, x, y, out_name, axis, base_name, func_counter):\n    \"\"\"Generate a BroadcastTo operator to brodcast specified buffer\"\"\"\n    bt = nnabla_pb2.Function()\n    bt.type = \"BroadcastTo\"\n    set_function_name(bt, node_name, base_name, func_counter)\n    bt.input.extend([x, y])\n    bt.output.extend([out_name])\n    btp = bt.broadcast_to_param\n    btp.axis = axis\n    return bt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking each padding start end value and set the sufficient pad value.", "response": "def check_padding(pads, dim, padval):\n    \"\"\"Check each padding start/end value\n    and set the sufficient pad value.\n    If we have asymmetry padding, we will return\n    True to indicate the need for a separate padding function\"\"\"\n    asymmetry = False\n    for i in range(dim):\n        s = pads[i]\n        e = pads[i+dim]\n        if s == e:\n            padval.append(s)\n        else:\n            asymmetry = True\n            # We must add a separate pad function for asymmetry padding.\n            # Since the pad function will do all the padding,\n            # we will remove all padding here.\n            del padval[:]\n            padval.extend([0]*dim)\n            break\n    return asymmetry"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rearrange_pads(pads):\n    half = len(pads)//2\n    starts = pads[:half]\n    ends = pads[half:]\n    return [j for i in zip(starts, ends) for j in i]", "response": "Rearrange pads to match NNabla format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_parameter_shape(pb):\n    if len(pb.network) != 1:\n        raise ValueError(\n            \"NNP with more then a single network is currently not supported\")\n    net = pb.network[0]\n    batch_norm_constants = []\n    for f in net.function:\n        if f.type == \"BatchNormalization\":\n            # BatchNormalization in ONNX requires the scale, bias, mean, and variance input to be\n            # one dimensional (https://github.com/onnx/onnx/blob/master/docs/Operators.md#batchnormalization).\n            # However in NNabla these input must have a specific shape that matches the input shape.\n            # For example if the input shape is (1,3,3,3), the above variables must have the shape (1,3,1,1) and not (3).\n            # (1,3,1,1) is actually the same as a one-dimensional tensor of size 3,\n            # but NNabla's check currently does not allow this.\n            # Thus, we convert the shape of the above input so we can pass NNabla's check.\n            # If NNabla lightens the shape check, we should be able to remove this conversion.\n            # copy all input names for scale, bias, mean, variance\n            batch_norm_constants.extend(f.input[1:5])\n\n    # This loop should be fairly slow since we loop through all variables and parameters per constant\n    for c in batch_norm_constants:\n        # Reshape all BatchNormalization constant inputs assuming the size is (1,size,1,1)\n        for v in net.variable:\n            if v.name == c:\n                size = v.shape.dim[0]\n                del v.shape.dim[:]\n                v.shape.dim.extend([1, size, 1, 1])\n                break\n        for p in pb.parameter:\n            if p.variable_name == c:\n                size = p.shape.dim[0]\n                del p.shape.dim[:]\n                p.shape.dim.extend([1, size, 1, 1])\n                break", "response": "Convert the shape of some parameters so they fit NNabla s requirements."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds given tensor as a parameter", "response": "def add_tensor_as_parameter(pb, tensor):\n    \"\"\"Add given tensor as a parameter\"\"\"\n    p = pb.parameter.add()\n    p.variable_name = tensor.name\n    p.shape.dim.extend(tensor.dims)\n    if tensor.data_type == TensorProto.FLOAT:\n        # convert raw bytestream to floating points\n        if tensor.raw_data:\n            p.data.extend(np.fromstring(tensor.raw_data, dtype=np.float32))\n        elif len(tensor.float_data) > 0:\n            p.data.extend(tensor.float_data)\n        else:\n            raise ValueError(\"float data not found for {}\".format(tensor.name))\n    elif tensor.data_type == TensorProto.INT32:\n        # convert raw bytestream to integer\n        if tensor.raw_data:\n            p.data.extend(np.fromstring(tensor.raw_data, dtype=np.int32))\n        elif len(tensor.int32_data) > 0:\n            p.data.extend(tensor.int32_data)\n        else:\n            raise ValueError(\"int32 data not found for {}\".format(tensor.name))\n    elif tensor.data_type == TensorProto.INT64:\n        # convert raw bytestream to integer\n        if tensor.raw_data:\n            p.data.extend(np.fromstring(tensor.raw_data, dtype=np.int64))\n        elif len(tensor.int64_data) > 0:\n            p.data.extend(tensor.int64_data)\n        else:\n            raise ValueError(\"int64 data not found for {}\".format(tensor.name))\n    elif tensor.data_type == TensorProto.BOOL:\n        if tensor.raw_data:\n            p.data.extend(np.fromstring(tensor.raw_data, dtype=np.bool))\n        else:\n            raise ValueError(\"bool data not found for {}\".format(tensor.name))\n\n    else:\n        raise ValueError(\"Unsupported tensor data type for {}: {}\"\n                         .format(tensor.name, tensor.data_type))\n    p.need_grad = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a broadcasting operator to a composite with BroadcastTo", "response": "def BroadcastOperator(self, func_name, func_list, n):\n        \"\"\"Converts a broadcasting operator to a composite with BroadcastTo\"\"\"\n        broadcasting = False\n        broadcast_axis = -1\n        func = self.generate_default_function(func_name, n)\n        for attr in n.attribute:\n            if attr.name == \"axis\":\n                if attr.type != AttributeProto.INT:\n                    raise ValueError(\n                        \"Only INT is supported for axis in {} op_type\".format(n.op_type))\n                broadcast_axis = attr.i\n            elif attr.name == \"broadcast\":\n                if attr.type != AttributeProto.INT:\n                    raise ValueError(\n                        \"Only INT is supported for broadcast in {} op_type\".format(n.op_type))\n                if attr.i == 1:\n                    broadcasting = True\n            else:\n                raise ValueError(\"Unsupported attribute {} was specified at {}\"\n                                 .format(attr.name, n.op_type))\n        if not broadcasting:\n            input0_shape = self.get_func_input_shape(func.input[0])\n            input1_shape = self.get_func_input_shape(func.input[1])\n            output_shape = []\n            for i in range(len(input0_shape)):\n                output_shape.append(max(input0_shape[i], input1_shape[i]))\n            self._shape_output[func.output[0]] = output_shape\n            func_list.append(func)\n            return\n        # Create a BroadcastTo operator to broadcast input B\n        b_idx = 1  # B is the second input\n        broadcasted_postfix = \"_broadcasted\"\n        input = n.input[:]\n        bin = n.input[b_idx]\n        bout = bin+broadcasted_postfix\n        bt = generate_broadcast_to(n.name, n.input[0], bin, bout, broadcast_axis,\n                                   self._graph.name, self._func_counter)\n        self._shape_output[bout] = self.get_func_input_shape(n.input[0])\n        func_list.append(bt)\n        input[b_idx] = bout  # rewire input to broadcasted input\n        # update input with the converted inputs\n        del func.input[:]\n        func.input.extend(input)\n        self._shape_output[func.output[0]] = self._shape_output[bout]\n        func_list.append(func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading image by pypng module.", "response": "def imread(path, grayscale=False, size=None, interpolate=\"bilinear\",\n           channel_first=False, as_uint16=False, num_channels=-1):\n    \"\"\"\n    Read image by pypng module.\n\n    Args:\n        path (str or 'file object'): File path or object to read.\n        grayscale (bool):\n        size (tupple of int):\n            (width, height).\n            If None, output img shape depends on the files to read.\n        channel_first (bool):\n            This argument specifies the shape of img is whether (height, width, channel) or (channel, height, width).\n            Default value is False, which means the img shape is (height, width, channel).\n        interpolate (str):\n            must be one of [\"nearest\", \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"].\n        as_uint16 (bool):\n            If True, this function reads image as uint16.\n        num_channels (int):\n            channel size of output array.\n            Default is -1 which preserves raw image shape.\n\n    Returns:\n         numpy.ndarray\n    \"\"\"\n\n    _imread_before(grayscale, num_channels)\n\n    f = path if hasattr(path, \"read\") else open(path, \"rb\")\n\n    r = png.Reader(file=f)\n    width, height, pixels, metadata = r.asDirect()\n\n    bit_depth = metadata.get(\"bitdepth\")\n\n    if bit_depth not in [8, 16]:\n        raise ValueError(\"The bit-depth of the image you want to read is unsupported ({}bit).\"\n                         \"Currently, pypng backend`s imread supports only [8, 16] bit-depth.\"\n                         \"the path for this image is {}\".format(bit_depth, path))\n\n    img = read_result_to_ndarray(\n        pixels, width, height, metadata, grayscale, as_uint16, num_channels)\n\n    return _imread_after(img, size, interpolate, channel_first, imresize)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imsave(path, img, channel_first=False, as_uint16=False, auto_scale=True):\n\n    img = _imsave_before(img, channel_first, auto_scale)\n\n    if auto_scale:\n        img = upscale_pixel_intensity(img, as_uint16)\n\n    img = check_type_and_cast_if_necessary(img, as_uint16)\n\n    bitdepth = 8 if img.dtype == np.uint8 else 16\n    grayscale = True if len(img.shape) == 2 or (\n        len(img.shape) == 3 and img.shape[-1] == 1) else False\n\n    writer = png.Writer(img.shape[1], img.shape[0],\n                        greyscale=grayscale, bitdepth=bitdepth)\n\n    writer.write(open(path, \"wb\"), img.reshape(img.shape[0], -1))", "response": "Save image to a file in pypng module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert(self, vroot, entry_variables):\n        self.graph_info = GraphInfo(vroot)\n        self.entry_variables = entry_variables\n\n        with nn.parameter_scope(self.name):\n            # Function loop in the forward order\n            for t, func in enumerate(self.graph_info.funcs):\n                if func.name in self.inner_prod_functions:\n                    inner_prod_func = func\n                    o = self._fixed_point_weight_conversion(inner_prod_func)\n                    continue\n                # Identity conversion\n                o = self._identity_conversion(func)\n\n        self.end_variable = o\n\n        if self.call_forward:\n            o.forward(clear_buffer=True)\n        return self.end_variable", "response": "This function converts the given vroot into a new variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_reshape_params(inputs, function_proto, batch_size):\n    '''Resolve shape parameter and returns shape.\n    '''\n    f = function_proto  # alias\n\n    # There are 2 exceptional cases.\n    # A. Negative dimension is batch dimension\n    # A-1. Detect multiple negative dimensions (not allowed).\n    negative_count = 0\n    for d in f.reshape_param.shape.dim:\n        if d < 0:\n            negative_count += 1\n    if negative_count > 1:\n        raise ValueError('Reshape: shape has multiple negative number.')\n\n    # A-2. Fill negative dimensions with batch size.\n    shape = tuple(\n        [d if d >= 0 else batch_size for d in f.reshape_param.shape.dim])\n\n    # B. Console omits batch dimensions (the first dimension) during saving.\n    # B-1. Fill with batch size if shapes don't match.\n    if numpy.prod(shape) != numpy.prod(inputs[0].shape):\n        shape = (batch_size,) + shape\n        if numpy.prod(shape) != numpy.prod(inputs[0].shape):\n            raise ValueError('Shape after filling batch dimension does not match the input shape. prod({}) != prod({})'.format(\n                shape, inputs[0].shape))\n    return shape", "response": "Resolve shape parameter and returns shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves shape parameter and returns shape.", "response": "def resolve_broadcast_params(inputs, function_proto, batch_size):\n    '''Resolve shape parameter and returns shape.\n    '''\n    f = function_proto  # alias\n\n    # A. Detect multiple negative dimensions (not allowed).\n    negative_count = 0\n    for d in f.broadcast_param.shape.dim:\n        if d < 0:\n            negative_count += 1\n    if negative_count > 1:\n        raise ValueError('Reshape: shape has multiple negative number.')\n\n    # B. Fill negative dimensions with batch size.\n    shape = tuple(\n        [d if d >= 0 else batch_size for d in f.broadcast_param.shape.dim])\n    return shape"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(filenames, prepare_data_iterator=True, batch_size=None, exclude_parameter=False, parameter_only=False):\n    '''load\n    Load network information from files.\n\n    Args:\n        filenames (list): List of filenames.\n    Returns:\n        dict: Network information.\n    '''\n    class Info:\n        pass\n    info = Info()\n\n    proto = nnabla_pb2.NNablaProtoBuf()\n    for filename in filenames:\n        _, ext = os.path.splitext(filename)\n\n        # TODO: Here is some known problems.\n        #   - Even when protobuf file includes network structure,\n        #     it will not loaded.\n        #   - Even when prototxt file includes parameter,\n        #     it will not loaded.\n\n        if ext in ['.nntxt', '.prototxt']:\n            if not parameter_only:\n                with open(filename, 'rt') as f:\n                    try:\n                        text_format.Merge(f.read(), proto)\n                    except:\n                        logger.critical('Failed to read {}.'.format(filename))\n                        logger.critical(\n                            '2 byte characters may be used for file name or folder name.')\n                        raise\n            if len(proto.parameter) > 0:\n                if not exclude_parameter:\n                    nn.load_parameters(filename)\n        elif ext in ['.protobuf', '.h5']:\n            if not exclude_parameter:\n                nn.load_parameters(filename)\n            else:\n                logger.info('Skip loading parameter.')\n\n        elif ext == '.nnp':\n            try:\n                tmpdir = tempfile.mkdtemp()\n                with zipfile.ZipFile(filename, 'r') as nnp:\n                    for name in nnp.namelist():\n                        _, ext = os.path.splitext(name)\n                        if name == 'nnp_version.txt':\n                            nnp.extract(name, tmpdir)\n                            with open(os.path.join(tmpdir, name), 'rt') as f:\n                                pass  # TODO currently do nothing with version.\n                        elif ext in ['.nntxt', '.prototxt']:\n                            nnp.extract(name, tmpdir)\n                            if not parameter_only:\n                                with open(os.path.join(tmpdir, name), 'rt') as f:\n                                    text_format.Merge(f.read(), proto)\n                            if len(proto.parameter) > 0:\n                                if not exclude_parameter:\n                                    nn.load_parameters(\n                                        os.path.join(tmpdir, name))\n                        elif ext in ['.protobuf', '.h5']:\n                            nnp.extract(name, tmpdir)\n                            if not exclude_parameter:\n                                nn.load_parameters(os.path.join(tmpdir, name))\n                            else:\n                                logger.info('Skip loading parameter.')\n            finally:\n                shutil.rmtree(tmpdir)\n\n    default_context = None\n    if proto.HasField('global_config'):\n        info.global_config = _global_config(proto)\n        default_context = info.global_config.default_context\n        if 'cuda' in default_context.backend:\n            import nnabla_ext.cudnn\n        elif 'cuda:float' in default_context.backend:\n            try:\n                import nnabla_ext.cudnn\n            except:\n                pass\n    else:\n        import nnabla_ext.cpu\n        default_context = nnabla_ext.cpu.context()\n\n    comm = current_communicator()\n    if comm:\n        default_context.device_id = str(comm.rank)\n    if proto.HasField('training_config'):\n        info.training_config = _training_config(proto)\n\n    info.datasets = _datasets(\n        proto, prepare_data_iterator if prepare_data_iterator is not None else info.training_config.max_epoch > 0)\n\n    info.networks = _networks(proto, default_context, batch_size)\n\n    info.optimizers = _optimizers(\n        proto, default_context, info.networks, info.datasets)\n\n    info.monitors = _monitors(\n        proto, default_context, info.networks, info.datasets)\n\n    info.executors = _executors(proto, info.networks)\n\n    return info", "response": "Load network information from files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef context_scope(ctx):\n    global current_ctx\n    global context_level\n    context_level += 1\n    prev_context = current_ctx\n    current_ctx = ctx\n    try:\n        yield\n    finally:\n        context_level -= 1\n        current_ctx = prev_context", "response": "Context - scope for the internal state machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a scalar value to a Constant buffer.", "response": "def generate_scalar_constant(output_name, tensor_name, scalar):\n    \"\"\"Convert a scalar value to a Constant buffer.\n    This is mainly used for xxScalar operators.\"\"\"\n    t = onnx.helper.make_tensor(tensor_name,\n                                data_type=TensorProto.FLOAT,\n                                dims=[1], vals=[scalar])\n    c = onnx.helper.make_node(\"Constant\",\n                              [],\n                              [output_name],\n                              value=t)\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace all dimensions with negative values to batch size", "response": "def replace_negative_size_with_batch_size(shape, batch_size):\n    \"\"\"Replace all dimensions with negative values to batch size\"\"\"\n    sl = []\n    for d in shape.dim:\n        if d < 0:\n            # Negative size means batch size\n            sl.append(batch_size)\n        else:\n            sl.append(d)\n    out_shape = nnabla_pb2.Shape()\n    out_shape.dim.extend(sl)\n    return out_shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef BinarySigmoid(self, func):\n        '''\n        Currently, caffe2 does not support this function.\n        '''\n        n = onnx.helper.make_node(\n            'HardSigmoid',\n            func.input,\n            func.output,\n            alpha=1.0,\n            beta=0.0\n        )\n        return [n]", "response": "This method returns the node that represents the binary sigmoid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a ONNX function to a node or a group of nodes.", "response": "def set_nodes(self, func):\n        \"\"\"Convert a function to a node or a group of nodes\"\"\"\n        op_type = self.nnabla_function_type_to_onnx_optype.get(func.type)\n        if op_type is None:\n            raise ValueError(\n                \"function {} is currently not supported for ONNX conversion\".format(func.type))\n        if callable(op_type):\n            return op_type(func)\n\n        variables = self._net.variable\n        input_types = self._input_types\n        output_types = self._output_types\n        broadcast_target = self._broadcast_target\n\n        n = onnx.helper.make_node(\n            op_type,\n            func.input,\n            func.output,\n            name=func.name)\n        nl = []\n        if func.type == \"Convolution\":\n            cp = func.convolution_param\n            # Calculate the kernel_shape from input weight data.\n            # Weight data should be the second input for convolution\n            if len(func.input) < 2:\n                raise ValueError(\n                    \"Weight input is missing for convolution {}\"\n                    .format(func.name))\n            weight = func.input[1]\n            weight_var = [v for v in variables if v.name == weight]\n            if len(weight_var) != 1:\n                raise ValueError(\n                    \"No weight input was found, or multiple weight inputs were found\"\n                    \" for convolution {} where there should be only one.\"\n                    .format(func.name))\n            weight_shape = weight_var[0].shape\n            # The base axis for weights is the next axis from the data's base axis\n            weight_base = cp.base_axis + 1\n            k = onnx.helper.make_attribute(\"kernel_shape\",\n                                           weight_shape.dim[weight_base:])\n            d = onnx.helper.make_attribute(\"dilations\", cp.dilation.dim)\n            s = onnx.helper.make_attribute(\"strides\", cp.stride.dim)\n            p = onnx.helper.make_attribute(\"pads\", cp.pad.dim[:] * 2)\n            g = onnx.helper.make_attribute(\"group\", cp.group)\n            n.attribute.extend([k, d, s, p, g])\n            nl.append(n)\n        elif func.type == \"GlobalAveragePooling\":\n            # We wipeout the node name to avoid a bug?\n            # that occurs when we use a GlobalAveragePooling node with a name\n            # \"Conv\" or \"Pool\" contained.\n            # Caffe2 issue is here:\n            # https://github.com/caffe2/caffe2/issues/1971\n            # Because a GlobalAveragePooling operator does not contain a kernel, we get an error at the\n            # following code if we have a specific name.\n            # https://github.com/caffe2/caffe2/blob/master/caffe2/operators/conv_pool_op_base.h#L167\n            # The above caffe2 code should be checking the node's operator name and not the node's name.\n            n.name = \"\"\n            nl.append(n)\n        elif func.type == \"Softmax\":\n            # Softmax on NNabla does softmax ONLY along the specified axis.\n            # ONNX first squashes the input dimensions to 2D based on the specified axis,\n            # and then calculates the Softmax.\n            # Since these two slightly differ, we show a warning here.\n            logger.warning(SOFTMAX_WARNING)\n            attr = onnx.helper.make_attribute(\"axis\", func.softmax_param.axis)\n            n.attribute.extend([attr])\n            nl.append(n)\n        elif func.type == \"Reshape\":\n            # Convert Reshape size to a constant\n            rp = func.reshape_param\n            x = func.input[0]\n            c_out = x + \"_shape\"\n            c = generate_constant(c_out, func.name + \"_shape\",\n                                  TensorProto.INT32, [len(rp.shape.dim)],\n                                  rp.shape.dim)\n            nl.append(c)\n            # Add resize target shape as the second input\n            del n.input[:]\n            n.input.extend([x, c_out])\n            nl.append(n)\n        elif func.type == \"Transpose\":\n            tp = func.transpose_param\n            p = onnx.helper.make_attribute(\"perm\", tp.axes)\n            n.attribute.extend([p])\n            nl.append(n)\n        elif func.type == \"BatchMatmul\":\n            bmp = func.batch_matmul_param\n            if bmp.transpose_a or bmp.transpose_b:\n                raise ValueError(\n                    \"{} with transpose is not supported yet\".format(func.type))\n            nl.append(n)\n        elif func.type == \"LeakyReLU\":\n            lrp = func.leaky_relu_param\n            a = onnx.helper.make_attribute(\"alpha\", lrp.alpha)\n            n.attribute.extend([a])\n            nl.append(n)\n        elif func.type == \"ELU\":\n            ep = func.elu_param\n            a = onnx.helper.make_attribute(\"alpha\", ep.alpha)\n            n.attribute.extend([a])\n            nl.append(n)\n        elif func.type == \"LogicalNot\":\n            # Store the input/output tensor's name and convert it to boolean\n            input_types[n.input[0]] = TensorProto.BOOL\n            output_types[n.output[0]] = TensorProto.BOOL\n            nl.append(n)\n        elif func.type == \"SELU\":\n            sp = func.selu_param\n            a = onnx.helper.make_attribute(\"alpha\", sp.alpha)\n            g = onnx.helper.make_attribute(\"gamma\", sp.scale)\n            n.attribute.extend([a, g])\n            nl.append(n)\n        elif func.type == \"Sum\":\n            sp = func.sum_param\n            set_reduction_attrs(n, sp)\n            nl.append(n)\n        elif func.type == \"Mean\":\n            mp = func.mean_param\n            set_reduction_attrs(n, mp)\n            nl.append(n)\n        elif func.type == \"Max\":\n            mp = func.max_param\n            set_reduction_attrs(n, mp)\n            nl.append(n)\n        elif func.type == \"Min\":\n            mp = func.min_param\n            set_reduction_attrs(n, mp)\n            nl.append(n)\n        elif func.type == \"Prod\":\n            pp = func.prod_param\n            set_reduction_attrs(n, pp)\n            nl.append(n)\n        elif func.type == \"BroadcastTo\":\n            # BroadcastTo conversion only works when the\n            # broadcasted buffer is used as second input for the following:\n            # Add, And, Div, Equal, Greater,\n            # Less, Mul, Or, Pow, Sub, Xor\n            bp = func.broadcast_to_param\n            broadcast_target[func.output[0]] = (func.input[1], bp.axis)\n            # we do not append node here because BroadcastTo should disappear\n        elif func.type == \"MinimumScalar\":\n            msp = func.minimum_scalar_param\n            m = onnx.helper.make_attribute(\"max\", msp.val)\n            n.attribute.extend([m])\n            nl.append(n)\n        elif func.type == \"MaximumScalar\":\n            msp = func.maximum_scalar_param\n            m = onnx.helper.make_attribute(\"min\", msp.val)\n            n.attribute.extend([m])\n            nl.append(n)\n        elif func.type == \"Pad\":\n            pp = func.pad_param\n            mode_conv = {\n                \"constant\": \"constant\",\n                \"replicate\": \"edge\",\n                \"reflect\": \"reflect\"\n            }\n            # separate pad values to match ONNX format\n            # (S0,E0,S1,E1) => (S0,S1,E0,E1)\n            dim = len(pp.pad_width) // 2\n            # If we can get the dimension of the input buffer,\n            # we get it here. If we cannot, we are assuming 4D input\n            in_name = func.input[0]\n            in_var = [v for v in variables if v.name == in_name]\n            in_dim = 4\n            if len(in_var) == 1 and len(in_var[0].shape.dim) > 0:\n                # Found variable with valid shape.\n                # If the shape dimension is zero, it means\n                # that is an intermediate buffer so we can't get\n                # the exact dimension at this point\n                # (thus assuming 4D input).\n                in_dim = len(in_var[0].shape.dim)\n            elif len(in_var) > 1:\n                raise ValueError(\"More than one buffer with\"\n                                 \" the same buffer name found.\")\n            zero_dim_num = in_dim - dim\n            it = iter(pp.pad_width)\n            # We need to fill empty dimensions with zero padding\n            # (at least this is what Caffe2 expects)\n            starts = [0] * zero_dim_num\n            ends = [0] * zero_dim_num\n            for x in it:\n                starts.append(x)\n                ends.append(next(it))\n            starts.extend(ends)\n            pad = onnx.helper.make_attribute(\"pads\", starts)\n            m = onnx.helper.make_attribute(\"mode\", mode_conv[pp.mode])\n            v = onnx.helper.make_attribute(\"value\", pp.constant_value)\n            n.attribute.extend([pad, m, v])\n            nl.append(n)\n        else:\n            # Simply append node to list\n            nl.append(n)\n        return nl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a given graph using the converters in the order of the registeration.", "response": "def convert(self, vroot, entry_variables):\n        \"\"\"Convert a given graph.\n\n        Convert a given graph using the `converters` in the order of the registeration, i.e., sequentially.\n\n        Args:\n            vroot (:obj:`Variable`): NNabla Variable\n            entry_variables (:obj:`Variable`): Entry variable from which the conversion starts.\n        \"\"\"\n\n        for converter in self.converters:\n            vroot = converter.convert(vroot, entry_variables)\n        return vroot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef minmax_auto_scale(img, as_uint16):\n\n    if as_uint16:\n        output_high = 65535\n        output_type = np.uint16\n    else:\n        output_high = 255\n        output_type = np.uint8\n\n    return rescale_pixel_intensity(img, input_low=img.min(), input_high=img.max(),\n                                   output_low=0, output_high=output_high, output_type=output_type)", "response": "Utility function for rescaling all pixel values of input image to fit the range of uint8."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads image from path.", "response": "def imread(path, grayscale=False, size=None, interpolate=\"bilinear\",\n           channel_first=False, as_uint16=False, num_channels=-1, **kwargs):\n    \"\"\"\n    Read image from ``path``.\n    If you specify the ``size``, the output array is resized.\n    Default output shape is (height, width, channel) for RGB image and (height, width) for gray-scale image.\n\n    Args:\n        path (String or File Object): Input image path.\n        grayscale (bool): If True, the img is rescaled to gray-scale. Default is False.\n        size (tuple of int): Output shape. The order is (width, height). If None, the image is not resized. Default is None.\n        interpolate (str): Interpolation method.\n            This argument is depend on the backend.\n            If you want to specify this argument, you should pay much attention to which backend you use now.\n            What you can select is below:\n             - pil backend: [\"nearest\", \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"].\n             - cv2 backend: [\"nearest\", \"bilinear\", \"bicubic\", \"lanczos\"].\n            Default is \"bilinear\" for both backends.\n        channel_first (bool): If True, the shape of the output array is (channel, height, width) for RGB image. Default is False.\n        as_uint16 (bool): If True, this function tries to read img as np.uint16. Default is False.\n        num_channels (int): channel size of output array.\n            Default is -1 which preserves raw image shape.\n    Returns:\n         numpy.ndarray :\n         if as_uint16=True output dtype is np.uint16, else np.uint8 (default).\n    \"\"\"\n\n    return backend_manager.module.imread(path, grayscale=grayscale, size=size, interpolate=interpolate,\n                                         channel_first=channel_first, as_uint16=as_uint16, num_channels=num_channels,\n                                         **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave image to the file specified by path.", "response": "def imsave(path, img, channel_first=False, as_uint16=False, auto_scale=True, **kwargs):\n    \"\"\"\n    Save ``img`` to the file specified by ``path``.\n    As default, the shape of ``img`` has to be (height, width, channel).\n\n    Args:\n        path (str): Output path.\n        img (numpy.ndarray):\n            Input image.\n            All pixel values must be positive and in the range [0, 255] of int for uint8, [0, 65535] of int for uint16 or [0, 1] for float.\n            When you pass float image, you must set `auto_scale` as True (If not, exception will be raised).\n            If img with negative values is passed as input, exception will be raised.\n        channel_first (bool):\n            If True, you can input the image whose shape is (channel, height, width). Default is False.\n        as_uint16 (bool):\n            If True, cast image to uint16 before save. Default is False.\n        auto_scale (bool):\n            Whether the range of pixel values are scaled up or not.\n            The range of upscaled pixel values depends on output dtype, which is [0, 255] as uint8 and [0, 65535] as uint16.\n    \"\"\"\n\n    backend_manager.module.imsave(\n        path, img, channel_first=channel_first, as_uint16=as_uint16, auto_scale=auto_scale, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imresize(img, size, interpolate=\"bilinear\", channel_first=False, **kwargs):\n\n    return backend_manager.module.imresize(img, size, interpolate=interpolate, channel_first=channel_first, **kwargs)", "response": "Resizes the input image to size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_normal_std_he_forward(inmaps, outmaps, kernel=(1, 1)):\n    return np.sqrt(2. / (np.prod(kernel) * inmaps))", "response": "r Calculates the standard deviation proposed by He et al."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_normal_std_he_backward(inmaps, outmaps, kernel=(1, 1)):\n    return np.sqrt(2. / (np.prod(kernel) * outmaps))", "response": "r Calculates the standard deviation of He et al."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_unique_function_name(function_type, functions):\n    '''Get a unique function name.\n\n    Args:\n        function_type(str): Name of Function. Ex) Convolution, Affine\n        functions(OrderedDict of (str, Function)\n\n    Returns: str\n        A unique function name\n    '''\n    function_name = function_name_base = function_type\n    count = 2\n    while function_name in functions:\n        function_name = '{}_{}'.format(function_name_base, count)\n        count += 1\n    return function_name", "response": "Get a unique function name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a unique variable name.", "response": "def _get_unique_variable_name(vname, variables):\n    '''Get a unique variable name.\n\n    Args:\n        vname(str): A candidate name.\n        variable(OrderedDict of str and Variable)\n\n    Returns: str\n        A unique variable name\n    '''\n    count = 2\n    vname_base = vname\n    while vname in variables:\n        vname = '{}_{}'.format(vname_base, count)\n        count += 1\n    return vname"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the name of the variable or registers it if it is not already there.", "response": "def _get_variable_name_or_register(var, variables, names, params, prefix):\n    '''\n    Args:\n        var (~nnabla.Variable)\n        variables (OrderedDict)\n        names (dict): Force name table, Variable -> str\n        params (dict): NdArray -> str\n        prefix(str)\n    '''\n    if var not in variables.values():\n        vname = prefix\n        if var.data in params:\n            vname = params[var.data]\n        elif var in names:\n            vname = names[var]\n        vname = _get_unique_variable_name(vname, variables)\n        variables[vname] = var\n    else:\n        vname = list(variables.keys())[list(variables.values()).index(var)]\n\n    return vname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(filename, contents, include_params=False, variable_batch_size=True):\n    '''Save network definition, inference/training execution\n    configurations etc.\n\n    Args:\n        filename (str): Filename to store information. The file\n            extension is used to determine the saving file format.\n            ``.nnp``: (Recommended) Creating a zip archive with nntxt (network\n            definition etc.) and h5 (parameters).\n            ``.nntxt``: Protobuf in text format.\n            ``.protobuf``: Protobuf in binary format (unsafe in terms of\n             backward compatibility).\n        contents (dict): Information to store.\n        include_params (bool): Includes parameter into single file. This is\n            ignored when the extension of filename is nnp.\n        variable_batch_size (bool):\n            By ``True``, the first dimension of all variables is considered\n            as batch size, and left as a placeholder\n            (more specifically ``-1``). The placeholder dimension will be\n            filled during/after loading.\n\n    Example:\n        The following example creates a two inputs and two\n        outputs MLP, and save the network structure and the initialized\n        parameters.\n\n        .. code-block:: python\n\n            import nnabla as nn\n            import nnabla.functions as F\n            import nnabla.parametric_functions as PF\n            from nnabla.utils.save import save\n\n            batch_size = 16\n            x0 = nn.Variable([batch_size, 100])\n            x1 = nn.Variable([batch_size, 100])\n            h1_0 = PF.affine(x0, 100, name='affine1_0')\n            h1_1 = PF.affine(x1, 100, name='affine1_0')\n            h1 = F.tanh(h1_0 + h1_1)\n            h2 = F.tanh(PF.affine(h1, 50, name='affine2'))\n            y0 = PF.affine(h2, 10, name='affiney_0')\n            y1 = PF.affine(h2, 10, name='affiney_1')\n\n            contents = {\n                'networks': [\n                    {'name': 'net1',\n                     'batch_size': batch_size,\n                     'outputs': {'y0': y0, 'y1': y1},\n                     'names': {'x0': x0, 'x1': x1}}],\n                'executors': [\n                    {'name': 'runtime',\n                     'network': 'net1',\n                     'data': ['x0', 'x1'],\n                     'output': ['y0', 'y1']}]}\n            save('net.nnp', contents)\n\n\n        To get a trainable model, use following code instead.\n\n        .. code-block:: python\n\n            contents = {\n            'global_config': {'default_context': ctx},\n            'training_config':\n                {'max_epoch': args.max_epoch,\n                 'iter_per_epoch': args_added.iter_per_epoch,\n                 'save_best': True},\n            'networks': [\n                {'name': 'training',\n                 'batch_size': args.batch_size,\n                 'outputs': {'loss': loss_t},\n                 'names': {'x': x, 'y': t, 'loss': loss_t}},\n                {'name': 'validation',\n                 'batch_size': args.batch_size,\n                 'outputs': {'loss': loss_v},\n                 'names': {'x': x, 'y': t, 'loss': loss_v}}],\n            'optimizers': [\n                {'name': 'optimizer',\n                 'solver': solver,\n                 'network': 'training',\n                 'dataset': 'mnist_training',\n                 'weight_decay': 0,\n                 'lr_decay': 1,\n                 'lr_decay_interval': 1,\n                 'update_interval': 1}],\n            'datasets': [\n                {'name': 'mnist_training',\n                 'uri': 'MNIST_TRAINING',\n                 'cache_dir': args.cache_dir + '/mnist_training.cache/',\n                 'variables': {'x': x, 'y': t},\n                 'shuffle': True,\n                 'batch_size': args.batch_size,\n                 'no_image_normalization': True},\n                {'name': 'mnist_validation',\n                 'uri': 'MNIST_VALIDATION',\n                 'cache_dir': args.cache_dir + '/mnist_test.cache/',\n                 'variables': {'x': x, 'y': t},\n                 'shuffle': False,\n                 'batch_size': args.batch_size,\n                 'no_image_normalization': True\n                 }],\n            'monitors': [\n                {'name': 'training_loss',\n                 'network': 'validation',\n                 'dataset': 'mnist_training'},\n                {'name': 'validation_loss',\n                 'network': 'validation',\n                 'dataset': 'mnist_validation'}],\n            }\n\n\n    '''\n    _, ext = os.path.splitext(filename)\n    if ext == '.nntxt' or ext == '.prototxt':\n        logger.info(\"Saving {} as prototxt\".format(filename))\n        proto = create_proto(contents, include_params, variable_batch_size)\n        with open(filename, 'w') as file:\n            text_format.PrintMessage(proto, file)\n    elif ext == '.protobuf':\n        logger.info(\"Saving {} as protobuf\".format(filename))\n        proto = create_proto(contents, include_params, variable_batch_size)\n        with open(filename, 'wb') as file:\n            file.write(proto.SerializeToString())\n    elif ext == '.nnp':\n        logger.info(\"Saving {} as nnp\".format(filename))\n        try:\n            tmpdir = tempfile.mkdtemp()\n            save('{}/network.nntxt'.format(tmpdir),\n                 contents, include_params=False, variable_batch_size=variable_batch_size)\n\n            with open('{}/nnp_version.txt'.format(tmpdir), 'w') as file:\n                file.write('{}\\n'.format(nnp_version()))\n\n            save_parameters('{}/parameter.protobuf'.format(tmpdir))\n\n            with zipfile.ZipFile(filename, 'w') as nnp:\n                nnp.write('{}/nnp_version.txt'.format(tmpdir),\n                          'nnp_version.txt')\n                nnp.write('{}/network.nntxt'.format(tmpdir), 'network.nntxt')\n                nnp.write('{}/parameter.protobuf'.format(tmpdir),\n                          'parameter.protobuf')\n        finally:\n            shutil.rmtree(tmpdir)", "response": "Save the information of the current object in a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mean(x, axis=None, keepdims=False):\n    from .function_bases import mean as mean_base\n    if axis is None:\n        axis = range(x.ndim)\n    elif not hasattr(axis, '__iter__'):\n        axis = [axis]\n    return mean_base(x, axis, keepdims)", "response": "Reduction along axes with mean operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef max(x, axis=None, keepdims=False, with_index=False, only_index=False):\n    from .function_bases import max as max_base\n    if axis is None:\n        axis = range(x.ndim)\n    elif not hasattr(axis, '__iter__'):\n        axis = [axis]\n    n_outputs = 2 if with_index and not only_index else 1\n    return max_base(x, axis, keepdims, with_index, only_index, n_outputs)", "response": "Reduce the input N - D array x along the given axis using the max\nTaxonomy operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef min(x, axis=None, keepdims=False, with_index=False, only_index=False):\n    from .function_bases import min as min_base\n    if axis is None:\n        axis = range(x.ndim)\n    elif not hasattr(axis, '__iter__'):\n        axis = [axis]\n    n_outputs = 2 if with_index and not only_index else 1\n    return min_base(x, axis, keepdims, with_index, only_index, n_outputs)", "response": "Reduce the input N - D array x along the given axis using the min\nTaxonomy operation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prod(x, axis=None, keepdims=False):\n    from .function_bases import prod as prod_base\n    if axis is None:\n        axis = range(x.ndim)\n    elif not hasattr(axis, '__iter__'):\n        axis = [axis]\n    return prod_base(x, axis, keepdims)", "response": "Reduction along axes with product operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreduce the elements of a set of items in a sequence.", "response": "def reduce(x, op='sum'):\n    \"\"\"Reduction function with given operation.\n\n    Args:\n        x (Variable): An input.\n        op (str): 'sum' or 'mean'.\n\n    Note:\n        This is deprecated. Use ``mean`` or ``sum`` instead.\n\n    \"\"\"\n    import warnings\n    warnings.warn(\n        \"Deprecated API. Use ``sum`` or ``mean`` instead.\", DeprecationWarning)\n    from .function_bases import reduce_sum, reduce_mean\n    if op == 'sum':\n        return reduce_sum(x)\n    elif op == 'mean':\n        return reduce_mean(x)\n    raise ValueError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split(x, axis=0):\n    from .function_bases import split as split_base\n    return split_base(x, axis, x.shape[axis])", "response": "Splits arrays at the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slice(ctx, x, start=None, stop=None, step=None, n_outputs=-1, outputs=None):\n    import copy\n    start = copy.copy(start)\n    stop = copy.copy(stop)\n    step = copy.copy(step)\n\n    from .function_bases import slice as slice_base\n    if start is None:\n        start = (0,) * len(x.shape)\n    if stop is None:\n        stop = tuple(x.shape)\n    if step is None:\n        step = (1,) * len(x.shape)\n\n    shape = x.shape\n    for i, sss in enumerate(zip(start, stop, step)):\n        s0, s1, s2 = sss\n        # SPECIAL CASE: slice(-1, None, <0) or slice(None, None, <0)\n        SLICE_NONE = 0x7fffffff\n        if s0 == None:\n            start[i] = SLICE_NONE\n        if s1 == None:\n            stop[i] = SLICE_NONE\n        if s2 == None:\n            step[i] = SLICE_NONE\n    return slice_base(x, start, stop, step, n_outputs, outputs)", "response": "r Slice arrays along specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mean_subtraction(x, mean, t, base_axis=1, update_running_mean=True):\n    from .function_bases import mean_subtraction as mean_subtraction_base\n    return mean_subtraction_base(x, mean, t,\n                                 base_axis=base_axis,\n                                 update_running_mean=update_running_mean)", "response": "r Mean Subtraction operation for the base array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clip_by_norm(x, clip_norm, axis=None):\n    from .function_bases import pow_scalar as pow_scalar_base\n    from .function_bases import maximum2 as maximum2_base\n    from .function_bases import maximum_scalar as maximum_scalar_base\n    from .function_bases import sum as sum_base\n    from ._variable import Variable as Variable_base\n    from ._nd_array import NdArray as NdArray_base\n\n    if axis is None:\n        axis = range(x.ndim)\n    elif not hasattr(axis, '__iter__'):\n        axis = [axis]\n    x_norm = pow_scalar_base(sum_base(x**2.0, axis, True), 0.5)\n    if isinstance(clip_norm, (Variable_base, NdArray_base)):\n        y = x * clip_norm / maximum2_base(x_norm, clip_norm)\n    else:\n        if clip_norm <= 0:\n            raise ValueError(\"clip_norm must be positive.\")\n        y = x * clip_norm / maximum_scalar_base(x_norm, clip_norm)\n    return y", "response": "r Clips inputs by its L2 norm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort(x, axis=-1, reverse=False, with_index=False, only_index=False):\n    from .function_bases import sort as sort_base\n    n_outputs = 2 if with_index and not only_index else 1\n    return sort_base(x, axis, reverse, with_index, only_index, n_outputs)", "response": "Sorts the elements of x along a given axis in ascending order\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tile(x, reps):\n    from .function_bases import tile as tile_base\n    reps = [reps] if isinstance(reps, int) else reps\n    return tile_base(x, reps)", "response": "Forward x repeated the number of times given by reps."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(url, output_file=None, open_file=True, allow_overwrite=False):\n    '''Download a file from URL.\n\n    Args:\n        url (str): URL.\n        output_file (str, optional): If given, the downloaded file is written to the given path.\n        open_file (bool): If True, it returns an opened file stream of the downloaded file.\n        allow_overwrite (bool): If True, it overwrites an existing file.\n\n    Returns:\n        Returns file object if open_file is True, otherwise None.\n\n    '''\n    filename = url.split('/')[-1]\n    if output_file is None:\n        cache = os.path.join(get_data_home(), filename)\n    else:\n        cache = output_file\n    if os.path.exists(cache) and not allow_overwrite:\n        logger.info(\"> {} already exists.\".format(cache))\n        logger.info(\"> If you have any issue when using this file, \")\n        logger.info(\"> manually remove the file and try download again.\")\n    else:\n        r = request.urlopen(url)\n        try:\n            if six.PY2:\n                content_length = int(r.info().dict['content-length'])\n            elif six.PY3:\n                content_length = int(r.info()['Content-Length'])\n        except:\n            content_length = 0\n        unit = 1000000\n        content = b''\n        with tqdm(total=content_length, desc=filename, unit='B', unit_scale=True, unit_divisor=1024) as t:\n            while True:\n                data = r.read(unit)\n                l = len(data)\n                t.update(l)\n                if l == 0:\n                    break\n                content += data\n        with open(cache, 'wb') as f:\n            f.write(content)\n    if not open_file:\n        return\n    return open(cache, 'rb')", "response": "Download a file from a URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imread(path, grayscale=False, size=None, interpolate=\"bilinear\",\n           channel_first=False, as_uint16=False, num_channels=-1):\n    \"\"\"\n    Read image by cv2 module.\n\n    Args:\n        path (str or 'file object'): File path or object to read.\n        grayscale (bool):\n        size (tupple of int):\n            (width, height).\n            If None, output img shape depends on the files to read.\n        channel_first (bool):\n            This argument specifies the shape of img is whether (height, width, channel) or (channel, height, width).\n            Default value is False, which means the img shape is (height, width, channel).\n        interpolate (str):\n            must be one of [\"nearest\", \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"].\n        as_uint16 (bool):\n            If True, this function reads image as uint16.\n        num_channels (int):\n            channel size of output array.\n            Default is -1 which preserves raw image shape.\n\n    Returns:\n         numpy.ndarray\n    \"\"\"\n\n    _imread_before(grayscale, num_channels)\n\n    r_mode = cv2.IMREAD_GRAYSCALE if grayscale else cv2.IMREAD_UNCHANGED\n    img = _imread_helper(path, r_mode)\n\n    if as_uint16 and img.dtype != np.uint16:\n        if img.dtype == np.uint8:\n            logger.warning(\"You want to read image as uint16, but the original bit-depth is 8 bit.\"\n                           \"All pixel values are simply increased by 256 times.\")\n            img = img.astype(np.uint16) * 256\n        else:\n            raise ValueError(\n                \"casting {} to uint16 is not safe.\".format(img.dtype))\n\n    img = _cvtColor_helper(img, num_channels)\n\n    img = _imread_after(img, size, interpolate, channel_first, imresize)\n\n    return img", "response": "Read image by cv2 module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imsave(path, img, channel_first=False, as_uint16=False, auto_scale=True):\n\n    img = _imsave_before(img, channel_first, auto_scale)\n\n    if auto_scale:\n        img = upscale_pixel_intensity(img, as_uint16)\n\n    img = check_type_and_cast_if_necessary(img, as_uint16)\n\n    # revert channel order to opencv`s one.\n    if len(img.shape) == 3:\n        if img.shape[-1] == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        elif img.shape[-1] == 4:\n            img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGRA)\n\n    cv2.imwrite(path, img)", "response": "Save image to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info_to_list(info):\n    '''Returns a list of (name, snake_name, [argument types as c++ type])'''\n    items = []\n    for name, item in info.items():\n        items.append((name, item['snake_name'], [\n            type_from_proto[v['type']]['cpp'] for v in item.get('arguments', {}).values()]))\n    return items", "response": "Returns a list of tuples from a dictionary containing information about a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget learning rate with polymomial decay based on current iteration.", "response": "def get_learning_rate(self, iter):\n        '''\n        Get learning rate with polymomial decay based on current iteration.\n\n        Args:\n            iter (int): current iteration (starting with 0).\n\n        Returns:\n            float: Learning rate\n        '''\n        return self.init_lr * ((1.0 - iter * 1.0 / self.max_iter) ** self.power)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_learning_rate(self, iter):\n        '''\n        Get learning rate with cosine decay based on current iteration.\n\n        Args:\n            iter (int): Current iteration (starting with 0).\n\n        Returns:\n            float: Learning rate\n        '''\n        return self.init_lr * ((math.cos(iter * 1.0 / (self.max_iter) * math.pi) + 1.0) * 0.5)", "response": "Get learning rate based on current iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_learning_rate(self, iter):\n        '''\n        Get learning rate with exponential decay based on current iteration.\n\n        Args:\n            iter (int): Current iteration (starting with 0).\n\n        Returns:\n            float: Learning rate\n        '''\n\n        return self.init_lr * (self.gamma ** (iter // self.iter_interval))", "response": "Get learning rate with exponential decay based on current iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_learning_rate(self, iter):\n        '''\n        Get learning rate with exponential decay based on current iteration.\n\n        Args:\n            iter (int): Current iteration (starting with 0).\n\n        Returns:\n            float: Learning rate\n        '''\n        lr = self.init_lr\n        for iter_step in self.iter_steps:\n            if iter >= iter_step:\n                lr *= self.gamma\n        return lr", "response": "Get learning rate based on current iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_learning_rate(self, iter):\n        '''\n        Get learning rate with exponential decay based on current iteration.\n\n        Args:\n            iter (int): Current iteration (starting with 0).\n\n        Returns:\n            float: Learning rate\n        '''\n        lr = self.scheduler.get_learning_rate(iter)\n        if iter < self.warmup_iter:\n            lr *= (iter + 1) * 1.0 / self.warmup_iter\n        return lr", "response": "Get learning rate with exponential decay based on current iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parametric_function_api(scope_name=None, param_desc=None):\n    if scope_name is None:\n        scope_name = name\n\n    def parametric_function_api_inside(func):\n        from nnabla.utils.py23_compatible import getargspec\n        import inspect\n\n        name = func.__name__\n        doc = func.__doc__\n\n        if param_desc:\n            indent = 8\n            try:\n                desc = map(lambda d: ' ' * indent +\n                           '* {} (``need_grad={}``) : {}. (shape: ``{}``)'.format(d[0], d[3], d[1], d[2]), param_desc)\n            except:\n                ValueError(\n                    'param_desc argument of parametric_function_api must be '\n                    'None or a list of tuple with three elements composed of '\n                    '(name(str), description(str), need_grad(bool)).')\n            doc += '''\n    Parameters to be registered\n        The following variables are registered in a parameter scope ``\"{}\"``;\n\n{}\n\n            '''.format(scope_name, '\\n'.join(desc))\n\n        doc += \"\"\"\n    Note:\n\n        If the ``name`` option is passed, the parameters become wrapped inside the parameter scope\n        with the specified name, yielding the same results as the following code.\n        This can be used to simplify the code.\n\n        .. code-block:: python\n\n            with parametric_scope(name):\n                output = {name}(<args>)\n\n        \"\"\".format(name=name)\n\n        spec = getargspec(func)\n        defaults = spec.defaults\n        if defaults is None:\n            defaults = tuple()  # None will be appended later\n        signature = inspect.formatargspec(\n            spec.args + ['name'],\n            spec.varargs, spec.keywords,\n            defaults + (None,))\n        shortsignature = inspect.formatargspec(\n            spec.args, spec.varargs, spec.keywords, None)\n\n        # Check required argument\n        assert 'fix_parameters' in spec.args, \\\n            \"A parametric function must take `fix_parameters` as an argument.\" \\\n            \" `{}{}` doesn't have it.\".format(name, signature)\n\n        code = \"\"\"\ndef {name}{signature}:\n    if name is None:\n        with parameter_scope(scope_name):\n            return func{shortsignature}\n    with parameter_scope(name):\n        with parameter_scope(scope_name):\n            return func{shortsignature}\n        \"\"\".format(**locals())\n        execdict = dict(\n            func=func, parameter_scope=nn.parameter_scope, scope_name=scope_name)\n        exec_(code, execdict)\n        newfunc = execdict[name]\n        newfunc.__doc__ = doc\n        newfunc.__parametric_function_api_base__ = func\n        newfunc.__scope_name__ = scope_name\n        newfunc.__module__ = __name__\n        return newfunc\n    return parametric_function_api_inside", "response": "Decorator for parametric functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a fully connected version of the affine layer.", "response": "def affine(inp, n_outmaps,\n           base_axis=1,\n           w_init=None, b_init=None,\n           fix_parameters=False, rng=None, with_bias=True,\n           apply_w=None, apply_b=None):\n    \"\"\"\n    The affine layer, also known as the fully connected layer. Computes\n\n    .. math::\n        {\\\\mathbf y} = {\\\\mathbf A} {\\\\mathbf x} + {\\\\mathbf b}.\n\n    where :math:`{\\\\mathbf x}, {\\\\mathbf y}` are the inputs and outputs respectively,\n    and :math:`{\\\\mathbf A}, {\\\\mathbf b}` are constants.\n\n    Args:\n        inp (~nnabla.Variable): Input N-D array with shape (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times D_B \\\\times \\ldots \\\\times D_N`). Dimensions before and after base_axis are flattened as if it is a matrix.\n        n_outmaps (:obj:`int` or :obj:`tuple` of :obj:`int`): Number of output neurons per data.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.\n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        apply_w (function): Lambda, function, or callable object applied to the weights.\n        apply_b (function): Lambda, function, or callable object applied to the bias.\n\n    Returns:\n        :class:`~nnabla.Variable`: :math:`(B + 1)`-D array. (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times L`)f\n\n    \"\"\"\n    if not hasattr(n_outmaps, '__iter__'):\n        n_outmaps = [n_outmaps]\n    n_outmaps = list(n_outmaps)\n    n_outmap = int(np.prod(n_outmaps))\n    if w_init is None:\n        inmaps = np.prod(inp.shape[base_axis:])\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inmaps, n_outmap), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n    w = get_parameter_or_create(\n        \"W\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n        w_init, True, not fix_parameters)\n    if apply_w is not None:\n        w = apply_w(w)\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", n_outmaps, b_init, True, not fix_parameters)\n        if apply_b is not None:\n            b = apply_b(b)\n    return F.affine(inp, w, b, base_axis)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inq_affine(inp, n_outmaps, base_axis=1, num_bits=4,\n               inq_iterations=(), selection_algorithm='random',\n               seed=-1, w_init=None, i_init=None, b_init=None,\n               fix_parameters=False, rng=None, with_bias=True):\n    \"\"\"Incremental Network Quantization Affine Layer\n\n    During training, the weights are sequentially quantized to power-of-two\n    values, which allows the training of a multiplierless network.\n\n    Using `inq_iterations`, one can specify after how many forward passes\n    half of the learnable weights are fixed and quantized to powers-of-two.\n    After reaching the last value in `inq_iterations`, all weights are fixed.\n\n    For more details, please refer to the reference.\n\n    Reference:\n    Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization:\n    Towards lossless CNNs with low-precision weights.\n    <https://arxiv.org/abs/1702.03044>\n\n    Args:\n        inp (~nnabla.Variable): Input N-D array with shape (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times D_B \\\\times \\ldots \\\\times D_N`). Dimensions before and after base_axis are flattened as if it was a matrix.\n        n_outmaps (int or :obj:`tuple` of :obj:`int`): Number of output neurons per data.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        quantize_zero_to (float): Input value at zero is quantized to this value.\n        num_bits (int): Number of bits per weight. Value has to be larger than 1 as one bit is already used to code the value \"0\"\n        inq_iterations (tuple of int): Tuple of iteration numbers at which we fix half of the weights.\n        selection_algorithm (str): Chooses algorithm that is used to decide which weights are fixed. (\"largest_abs\" ... fix weights with largest absolute value, \"random\" ... fix weights randomly)\n        seed (int): Random seed for INQ algorithm\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.  \n        i_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for indicators (0 ... learnable, 1 ... fixed). By default, it is initialized with zeros.\n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        fix_parameters (bool): When set to `True`, the weight and bias will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n\n    Returns:\n        :class:`~nnabla.Variable`\n\n    \"\"\"\n    if not hasattr(n_outmaps, '__iter__'):\n        n_outmaps = [n_outmaps]\n    n_outmaps = list(n_outmaps)\n    n_outmap = int(np.prod(n_outmaps))\n    if w_init is None:\n        fan_in = np.prod(inp.shape[base_axis:])\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(fan_in, n_outmap), rng=rng)\n    if i_init is None:\n        fan_in = np.prod(inp.shape[base_axis:])\n        i_init = ConstantInitializer()\n    if b_init is None:\n        b_init = ConstantInitializer()\n    w = get_parameter_or_create(\n        \"W\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n        w_init, True, not fix_parameters)\n    i = get_parameter_or_create(\n        \"I\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n        i_init, False)\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", n_outmaps, b_init, True, not fix_parameters)\n    return F.inq_affine(inp, w, i, b, base_axis, num_bits, inq_iterations, selection_algorithm, seed)", "response": "In - Quantization Affine Layer for Incremental Network Quantization Affine."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cpd3_convolution(inp, outmaps, kernel, r,\n                     pad=None, stride=None, dilation=None,\n                     oik_init=None, b_init=None,\n                     base_axis=1, fix_parameters=False, rng=None, with_bias=True,\n                     max_iter=500, stopping_criterion=1e-5, lambda_reg=0.0):\n    \"\"\"CP convolution is a low rank approximation of a convolution layer. A 3D tensor containing the parameter is built by collapsing the N-D kernels into 1D, then the tensor is decomposed into three matrices. The decomposed layer can be seen as linear combinations of the input feature maps to :math:`{R}` feature maps followed by a depthwise convolution and followed by linear combinations of the feature maps to compute the output feature maps.\n\n    The CP decomposition allows to approximate the kernel tensor by :math:`{R}` rank-1 tensors of the form:\n\n    .. math::\n\n        \\\\sum_{r=1}^{R} \\\\lambda_r {\\\\mathbf{o}^{(r)} \\\\otimes \\\\mathbf{i}^{(r)} \\\\otimes \\\\mathbf{k}^{(r)}},\n\n    where :math:`{\\\\lambda}_r` is the normalization coefficient and :math:`{\\\\otimes}` is the outer product.\n\n\n    If `oik_init` is a numpy array, U and V are computed so that uv_init can be approximates from UV\n    If `oik_init` is None or an initializer, the product of U and V approximate the randomly initialized array\n\n    If `O`, `I` and `K` exist in context, they are used to initialize the layer and oik_init is not used.\n\n    Suppose the kernel tensor of the affine is of :math:`{I \\\\times O}` and\n    the compression rate you want to specify is :math:`{CR}`, then you\n    set :math:`{R}` as\n\n    .. math::\n\n        R = \\\\left\\\\lfloor \\\\frac{(1 - CR)OIK^2}{O + I + K^2} \\\\right\\\\rfloor.\n\n    References:\n        - Lebedev, Vadim, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, and Victor Lempitsky,  \"Speeding-up convolutional neural networks using fine-tuned cp-decomposition.\", arXiv preprint arXiv:1412.6553 (2014).\n\n        - Marcella Astrid, Seung-Ik Lee, \"CP-decomposition with Tensor Power Method for Convolutional Neural Networks Compression\", BigComp 2017.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        r (int): rank of the factorized layer\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        oik_init (numpy array or :obj:`nnabla.initializer.BaseInitializer`): Initializer for weight. Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`. \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. It is initialized with zeros if `with_bias` is `True`.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        max_iter (int): Max iteration of the ALS.\n        stopping_criterion (float): Threshold for stopping the ALS.\n                If the value is negative, the convergence check is ignored;\n                in other words, it may reduce the computation time.\n        lambda_reg (float): regularization parameter for the ALS. Larger\n                lambda_reg means larger regularization.\n\n    Returns:\n        :class:`~nnabla.Variable`: :math:`(B + 1)`-D array. (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times L`)\n\n\n    \"\"\"\n\n    if oik_init is None:\n        oik_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n\n    if type(oik_init) is np.ndarray:\n        # TODO: Assert that size of uv_init is correct\n        # uv is initialize with numpy array\n        oik = oik_init\n    else:\n        # uv is initialize from initializer\n        oik = oik_init((outmaps, inp.shape[base_axis]) + tuple(kernel))\n\n    # flatten kernels\n    oik = oik.reshape((outmaps, inp.shape[base_axis], np.prod(kernel)))\n\n    o = get_parameter('O')\n    i = get_parameter('I')\n    k = get_parameter('K')\n\n    if (o is None) or (i is None) or (k is None):\n        assert r > 0, \"cpd3_convolution: The rank must larger than zero\"\n        from nnabla.utils.factorization import cpd\n        als = cpd.ALS()\n        U, lmbda = als.solve(X=oik, rank=r,\n                             max_iter=max_iter,\n                             stopping_criterion=stopping_criterion,\n                             lambda_reg=lambda_reg,\n                             dtype=oik.dtype,\n                             rng=rng)\n\n        o_ = U[0] * lmbda\n        i_ = U[1]\n        k_ = U[2]\n\n        kernel_one = (1,) * len(kernel)  # 1x1 for 2D convolution\n        inmaps = inp.shape[base_axis]\n\n        # reshape I :  (I,r) -> (r,I,1,1)\n        i = nn.Variable((r, inmaps) + kernel_one, need_grad=True)\n        i.d = np.transpose(i_).reshape((r, inmaps) + kernel_one)\n        nn.parameter.set_parameter(\"I\", i)\n\n        # reshape O :  (O,r) -> (O,r,1,1)\n        o = nn.Variable((outmaps, r) + kernel_one,\n                        need_grad=True)\n        o.d = o_.reshape((outmaps, r) + kernel_one)\n        nn.parameter.set_parameter(\"O\", o)\n\n        # reshape K :  (K*K,r) -> (r,K,K)\n        k = nn.Variable((r,) + kernel, need_grad=True)\n        k.d = np.transpose(k_).reshape((r,) + kernel)\n        nn.parameter.set_parameter(\"K\", k)\n\n    if fix_parameters == o.need_grad:\n        o = o.get_unlinked_variable(need_grad=not fix_parameters)\n    if fix_parameters == i.need_grad:\n        i = i.get_unlinked_variable(need_grad=not fix_parameters)\n    if fix_parameters == k.need_grad:\n        k = k.get_unlinked_variable(need_grad=not fix_parameters)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n\n    y = F.convolution(inp, i, bias=None, base_axis=base_axis, pad=None, stride=None,\n                      dilation=None, group=1)\n    y = F.depthwise_convolution(y, k, bias=None, base_axis=base_axis,\n                                pad=pad, stride=stride, dilation=dilation,\n                                multiplier=1)\n    y = F.convolution(y, o, bias=b, base_axis=base_axis, pad=None, stride=None,\n                      dilation=None, group=1)\n    return y", "response": "This function is used to compute the CP convolution layer for a 3D convolution layer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef binary_connect_convolution(inp, outmaps, kernel,\n                               pad=None, stride=None, dilation=None, group=1,\n                               quantize_zero_to=1.0,\n                               w_init=None, wb_init=None, b_init=None,\n                               base_axis=1, fix_parameters=False, rng=None,\n                               with_bias=True):\n    \"\"\"Binary Connect Convolution, multiplier-less inner-product.\n\n    Binary Connect Convolution is the convolution function,\n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}.\n\n    Therefore :math:`sign(w_i)` is either :math:`1` or :math:`-1` and the inner product\n    simplifies to addition.\n\n    This function should be used together with BatchNormalization.\n\n    References:\n\n        M. Courbariaux, Y. Bengio, and J.-P. David. \"BinaryConnect:\n        Training Deep Neural Networks with binary weights during propagations.\"\n        Advances in Neural Information Processing Systems. 2015.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the binarized weights (`binary_weight`)\n\n        2) The weights and the binary weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the binary weights will not be in sync.\n\n        3) Quantized values are stored as floating point number for `binary_weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        group (int): Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.\n        quantize_zero_to (float): Input value at zero is quantized to this value.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`. \n        wb_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for binary weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.   \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n\n    Returns:\n        :class:`~nnabla.Variable`\n\n    \"\"\"\n    if w_init is None:\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n    if wb_init is None:\n        wb_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n    if b_init is None:\n        b_init = ConstantInitializer()\n    w = get_parameter_or_create(\n        \"W\", (outmaps, inp.shape[base_axis]) + tuple(kernel),\n        w_init, True, not fix_parameters)\n    wb = get_parameter_or_create(\n        \"Wb\", (outmaps, inp.shape[base_axis]) + tuple(kernel),\n        wb_init, False)\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n    return F.binary_connect_convolution(inp, w, wb, b, base_axis, pad, stride, dilation, group, quantize_zero_to)", "response": "Binary Connect Convolution, multiplier-less inner-product.\n\n    Binary Connect Convolution is the convolution function,\n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}.\n\n    Therefore :math:`sign(w_i)` is either :math:`1` or :math:`-1` and the inner product\n    simplifies to addition.\n\n    This function should be used together with BatchNormalization.\n\n    References:\n\n        M. Courbariaux, Y. Bengio, and J.-P. David. \"BinaryConnect:\n        Training Deep Neural Networks with binary weights during propagations.\"\n        Advances in Neural Information Processing Systems. 2015.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the binarized weights (`binary_weight`)\n\n        2) The weights and the binary weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the binary weights will not be in sync.\n\n        3) Quantized values are stored as floating point number for `binary_weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        group (int): Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.\n        quantize_zero_to (float): Input value at zero is quantized to this value.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`. \n        wb_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for binary weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.   \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n\n    Returns:\n        :class:`~nnabla.Variable`"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inq_convolution(inp, outmaps, kernel,\n                    pad=None, stride=None, dilation=None, group=1,\n                    num_bits=4, inq_iterations=(), selection_algorithm='random',\n                    seed=-1, w_init=None, i_init=None, b_init=None,\n                    base_axis=1, fix_parameters=False, rng=None,\n                    with_bias=True):\n    \"\"\"Incremental Network Quantization Convolution Layer\n\n    During training, the weights are sequentially quantized to power-of-two\n    values, which allows the training of a multiplierless network.\n\n    Using `inq_iterations`, one can specify after how many forward passes\n    half of the learnable weights are fixed and quantized to powers-of-two.\n    After reaching the last value in `inq_iterations`, all weights are fixed.\n\n    For more details, please refer to the reference.\n\n    Reference:\n    Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization:\n    Towards lossless CNNs with low-precision weights.\n    <https://arxiv.org/abs/1702.03044>\n\n    Args:\n        inp (~nnabla.Variable): Input N-D array with shape (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times D_B \\\\times \\ldots \\\\times D_N`). Dimensions before and after base_axis are flattened as if it was a matrix.\n        n_outmaps (int or :obj:`tuple` of :obj:`int`): Number of output neurons per data.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        num_bits (int): Number of bits per weight. Value has to be larger than 1 as one bit is already used to code the value \"0\"\n        inq_iterations (tuple of int): Tuple of iteration numbers at which we fix half of the weights.\n        selection_algorithm (str): Chooses algorithm that is used to decide which weights are fixed. (\"largest_abs\" ... fix weights with largest absolute value, \"random\" ... fix weights randomly)\n        seed (int): Random seed for INQ algorithm\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for the weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`. \n        i_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for the indicators (0 ... learnable, 1 ... fixed). By default, it is initialized with zeros.\n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for the bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        fix_parameters (bool): When set to `True`, the weight and bias will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n\n    Returns:\n        :class:`~nnabla.Variable`\n\n    \"\"\"\n    if w_init is None:\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n    if i_init is None:\n        i_init = ConstantInitializer()\n    if b_init is None:\n        b_init = ConstantInitializer()\n    w = get_parameter_or_create(\n        \"W\", (outmaps, inp.shape[base_axis]) + tuple(kernel),\n        w_init, True, not fix_parameters)\n    i = get_parameter_or_create(\n        \"I\", (outmaps, inp.shape[base_axis]) + tuple(kernel),\n        i_init, False)\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n    return F.inq_convolution(inp, w, i, b, base_axis, pad, stride, dilation, group, num_bits, inq_iterations, selection_algorithm, seed)", "response": "In - Quantization Convolution Layer for Incremental Network Quantization Convolution"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new Deconvolution layer that can be used to deconvolve the input image with the given kernels.", "response": "def deconvolution(inp, outmaps, kernel,\n                  pad=None, stride=None, dilation=None, group=1,\n                  w_init=None, b_init=None,\n                  base_axis=1, fix_parameters=False, rng=None, with_bias=True,\n                  apply_w=None, apply_b=None):\n    \"\"\"\n    Deconvolution layer.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of deconvolution kernels (which is equal to the number of output channels). For example, to apply deconvolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply deconvolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        group (int): Number of groups of channels. This makes connections across channels sparser by grouping connections along map direction.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.  \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        apply_w (function): Lambda, function, or callable object applied to the weights.\n        apply_b (function): Lambda, function, or callable object applied to the bias.\n\n    Returns:\n        :class:`~nnabla.Variable`: N-D array. See :obj:`~nnabla.functions.deconvolution` for the output shape.\n\n    \"\"\"\n    if w_init is None:\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(outmaps, inp.shape[base_axis], tuple(kernel)), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n    w = get_parameter_or_create(\n        \"W\", (inp.shape[base_axis], outmaps // group) + tuple(kernel),\n        w_init, True, not fix_parameters)\n    if apply_w is not None:\n        w = apply_w(w)\n    b = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n        if apply_b is not None:\n            b = apply_b(b)\n    return F.deconvolution(inp, w, b, base_axis, pad, stride, dilation, group)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rnn(x, h, w0_init=None, w_init=None, b_init=None, num_layers=1, nonlinearity='tanh', dropout=0.0, bidirectional=False, training=True, rng=None, with_bias=True, fix_parameters=False):\n    input_size = x.shape[2]\n    hidden_size = h.shape[3]\n    num_layers = h.shape[0]\n    num_directions = 2 if bidirectional else 1\n\n    if w0_init is None:\n        w0_init_ih = UniformInitializer(\n            calc_uniform_lim_glorot(input_size, hidden_size), rng)\n        w0_init_ih = w0_init_ih((num_directions, hidden_size, input_size))\n        w0_init_hh = UniformInitializer(\n            calc_uniform_lim_glorot(hidden_size, hidden_size), rng)\n        w0_init_hh = w0_init_hh((num_directions, hidden_size, hidden_size))\n        w0_init = np.concatenate((w0_init_ih, w0_init_hh), axis=2)\n    if w_init is None:\n        w_init_ih = UniformInitializer(calc_uniform_lim_glorot(\n            num_directions*hidden_size, hidden_size), rng)\n        w_init_ih = w_init_ih(\n            (num_layers - 1, num_directions, hidden_size, num_directions*hidden_size))\n        w_init_hh = UniformInitializer(\n            calc_uniform_lim_glorot(hidden_size, hidden_size), rng)\n        w_init_hh = w_init_hh(\n            (num_layers - 1, num_directions, hidden_size, hidden_size))\n        w_init = np.concatenate((w_init_ih, w_init_hh), axis=3)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n    w0 = get_parameter_or_create(\n        \"weight_l0\", w0_init.shape,\n        w0_init, True, not fix_parameters)\n    w = None\n    if num_layers > 1:\n        w = get_parameter_or_create(\n            \"weight\", w_init.shape,\n            w_init, True, not fix_parameters)\n    b = None\n    n_outmaps = (num_layers, num_directions, hidden_size)\n    if with_bias:\n        b = get_parameter_or_create(\n            \"bias\", n_outmaps, b_init, True, not fix_parameters)\n\n    return F.rnn(x, h, weight_l0=w0, weight=w, bias=b, num_layers=num_layers, nonlinearity=nonlinearity, dropout=dropout, bidirectional=bidirectional, training=training)", "response": "N - Step RNN function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbatching normalization layer for the given input.", "response": "def batch_normalization(inp, axes=[1], decay_rate=0.9, eps=1e-5,\n                        batch_stat=True, output_stat=False, fix_parameters=False,\n                        param_init=None):\n    \"\"\"\n    Batch normalization layer.\n\n    .. math::\n\n        \\\\begin{array}{lcl}\n        \\\\mu &=& \\\\frac{1}{M} \\\\sum x_i\\\\\\\\\n        \\\\sigma^2 &=& \\\\frac{1}{M} \\\\sum \\\\left(x_i - \\\\mu\\\\right)^2\\\\\\\\\n        \\\\hat{x}_i &=& \\\\frac{x_i - \\\\mu}{\\\\sqrt{\\\\sigma^2 + \\\\epsilon }}\\\\\\\\\n        y_i &= & \\\\hat{x}_i \\\\gamma + \\\\beta.\n        \\\\end{array}\n\n    where :math:`x_i, y_i` are the inputs.\n    In testing, the mean and variance computed by moving average calculated during training are used.\n\n    Args:\n        inp (~nnabla.Variable): N-D array of input.\n        axes (:obj:`tuple` of :obj:`int`):\n            Mean and variance for each element in ``axes`` are calculated using\n            elements on the rest axes. For example, if an input is 4 dimensions,\n            and ``axes`` is ``[1]``,  batch mean is calculated as\n            ``np.mean(inp.d, axis=(0, 2, 3), keepdims=True)``\n            (using numpy expression as an example).\n        decay_rate (float): Decay rate of running mean and variance.\n        eps (float): Tiny value to avoid zero division by std.\n        batch_stat (bool): Use mini-batch statistics rather than running ones.\n        output_stat (bool): Output batch mean and variance.\n        fix_parameters (bool): When set to `True`, the beta and gamma will not be updated.\n        param_init (dict):\n            Parameter initializers can be set with a dict. A key of the dict must\n            be ``'beta'``, ``'gamma'``, ``'mean'`` or ``'var'``.\n            A value of the dict must be an :obj:`~nnabla.initializer.Initializer`\n            or a :obj:`numpy.ndarray`.\n            E.g. ``{'beta': ConstantIntializer(0), 'gamma': np.ones(gamma_shape) * 2}``.\n\n    Returns:\n        :class:`~nnabla.Variable`: N-D array.\n\n    References:\n\n        - Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. https://arxiv.org/abs/1502.03167\n\n    The shape of parameters has the same number of dimensions with the input\n    data, and the shapes in ``axes`` has the same dimensions with the input, while the rest has ``1``.\n    If an input is 4-dim and ``axes=[1]``, the parameter shape will be\n    ``param_shape  = np.mean(inp.d, axis=(0, 2, 3), keepdims=True).shape``\n    (using numpy expression as an example).\n\n    \"\"\"\n    shape_stat = [1 for _ in inp.shape]\n    for i in range(len(axes)):\n        shape_stat[axes[i]] = inp.shape[axes[i]]\n\n    if param_init is None:\n        param_init = {}\n    beta_init = param_init.get('beta', ConstantInitializer(0))\n    gamma_init = param_init.get('gamma', ConstantInitializer(1))\n    mean_init = param_init.get('mean', ConstantInitializer(0))\n    var_init = param_init.get('var', ConstantInitializer(1))\n    beta = get_parameter_or_create(\n        \"beta\", shape_stat, beta_init, True, not fix_parameters)\n    gamma = get_parameter_or_create(\n        \"gamma\", shape_stat, gamma_init, True, not fix_parameters)\n    mean = get_parameter_or_create(\n        \"mean\", shape_stat, mean_init, False)\n    var = get_parameter_or_create(\n        \"var\", shape_stat, var_init, False)\n    return F.batch_normalization(inp, beta, gamma, mean, var, axes,\n                                 decay_rate, eps, batch_stat, output_stat)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmeans subtraction layer. It subtracts the mean of the elements of the input array, and normalizes it to :math:`0`. Preprocessing arrays with this function has the effect of improving accuracy in various tasks such as image classification. At training time, this function is defined as .. math:: \\\\begin{array}{lcl} \\\\mu &=& \\\\frac{1}{M} \\\\sum x_i \\\\\\\\ y_i &=& x_i - \\\\mu \\\\end{array} At testing time, the mean values used are those that were computed during training by moving average. Note: The backward performs an approximated differentiation that takes into account only the latest mini-batch. Args: inp (~nnabla.Variable): N-D array of input. base_axis (int): Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated as sample dimension. update_running_mean (bool): When set to `True`, the running mean will not be updated. fix_parameters (bool): dummy parameter. This argument dose not affect anything. Returns: ~nnabla.Variable: N-D array.", "response": "def mean_subtraction(inp, base_axis=1, update_running_mean=True, fix_parameters=False):\n    \"\"\"\n    Mean subtraction layer.\n\n    It subtracts the mean of the elements of the input array,\n    and normalizes it to :math:`0`. Preprocessing arrays with this function has the effect of improving accuracy\n    in various tasks such as image classification.\n\n    At training time, this function is defined as\n\n    .. math::\n\n        \\\\begin{array}{lcl}\n        \\\\mu &=& \\\\frac{1}{M} \\\\sum x_i \\\\\\\\\n        y_i &=& x_i - \\\\mu\n        \\\\end{array}\n\n    At testing time, the mean values used are those that were computed during training by moving average.\n\n    Note:\n        The backward performs an approximated differentiation that takes into account only the latest mini-batch.\n\n    Args:\n        inp (~nnabla.Variable): N-D array of input.\n        base_axis (int): Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated as sample dimension.\n        update_running_mean (bool): When set to `True`, the running mean will not be updated.\n        fix_parameters (bool): dummy parameter. This argument dose not affect anything.\n\n    Returns:\n        ~nnabla.Variable: N-D array.\n    \"\"\"\n    assert len(inp.shape) >= base_axis\n    shape = inp.shape[base_axis:]\n    mean = get_parameter_or_create(\n        \"mean\", shape, ConstantInitializer(0), False)\n    t = get_parameter_or_create(\n        \"t\", (1, ), ConstantInitializer(0), False)\n    return F.mean_subtraction(inp, mean, t, base_axis=base_axis, update_running_mean=update_running_mean)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef embed(inp, n_inputs, n_features, initializer=None,\n          fix_parameters=False, apply_w=None):\n    \"\"\" Embed.\n\n    Embed slices a matrix/tensor with indexing array/tensor. Weights are initialized with :obj:`nnabla.initializer.UniformInitializer` within the range of :math:`-\\\\sqrt{3}` and :math:`\\\\sqrt{3}`.\n\n    Args:\n        x(~nnabla.Variable): [Integer] Indices with shape :math:`(I_0, ..., I_N)`\n        n_inputs : number of possible inputs, words or vocabraries\n        n_features : number of embedding features\n        fix_parameters (bool): When set to `True`, the embedding weight matrix\n            will not be updated.\n        apply_w (function): Lambda, function, or callable object applied to the weights.\n\n    Returns:\n        ~nnabla.Variable: Output with shape :math:`(I_0, ..., I_N, W_1, ..., W_M)`\n    \"\"\"\n    if not initializer:\n        initializer = UniformInitializer((-np.sqrt(3.), np.sqrt(3)))\n    w = get_parameter_or_create(\"W\", [n_inputs, n_features],\n                                initializer, True, not fix_parameters)\n    if apply_w is not None:\n        w = apply_w(w)\n    return F.embed(inp, w)", "response": "Embeds a matrix or tensor with indexing array of tensors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fixed_point_quantized_affine(inp, n_outmaps,\n                                 base_axis=1,\n                                 w_init=None, b_init=None,\n                                 fix_parameters=False, rng=None, with_bias=True,\n                                 quantize_w=True, sign_w=True, n_w=8, delta_w=2**-4, ste_fine_grained_w=True,\n                                 quantize_b=True, sign_b=True, n_b=8, delta_b=2**-4, ste_fine_grained_b=True):\n    \"\"\"Fixed-Point Quantized Affine.\n\n    Fixed-Point Quantized Affine is the affine function,\n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_j = \\sum_{i} Q(w_{ji}) x_i,\n\n    where :math:`Q(w_{ji})` is the fixed-point quantization function.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the quantized weights (`quantized weight`)\n\n        2) The weights and the quantized weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the quantized weights will not be in sync.\n\n        3) CPU and GPU implementations now use float value for `quantized weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): Input N-D array with shape (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times D_B \\\\times \\ldots \\\\times D_N`). Dimensions before and after base_axis are flattened as if it is a matrix.\n        n_outmaps (:obj:`int` or :obj:`tuple` of :obj:`int`): Number of output neurons per data.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`. \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        quantize_w (bool): Quantize weights if `True`.\n        sign_w (bool): Use signed quantization if `True`.\n        n_w (int): Bit width used for weight.\n        delta_w (float): Step size for weight.\n        ste_fine_grained_w (bool): STE is fine-grained if `True`.\n        quantize_b (bool): Quantize bias if `True`.\n        n_b (int): Bit width used for bias.\n        delta_w (float): Step size for bias.\n        ste_fine_grained_b (bool): STE is fine-grained if `True`.\n\n    Returns:\n        :class:`~nnabla.Variable`: :math:`(B + 1)`-D array. (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times L`)\n\n    \"\"\"\n\n    if not hasattr(n_outmaps, '__iter__'):\n        n_outmaps = [n_outmaps]\n    n_outmaps = list(n_outmaps)\n    n_outmap = int(np.prod(n_outmaps))\n    if w_init is None:\n        inmaps = np.prod(inp.shape[base_axis:])\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inmaps, n_outmap), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n\n    # Floating Weight\n    w = get_parameter_or_create(\n        \"W\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n        w_init, True, not fix_parameters)\n\n    # Quantized Weight\n    if quantize_w:\n        w_q = get_parameter_or_create(\n            \"W_q\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n            w_init, False)\n        # Link computation graph\n        real_w_q = F.fixed_point_quantize(w, quantize=quantize_w,\n                                          sign=sign_w, n=n_w, delta=delta_w,\n                                          ste_fine_grained=ste_fine_grained_w,\n                                          outputs=[w_q.data])\n        real_w_q.persistent = True\n    else:\n        real_w_q = w\n\n    # Bias\n    # Floating\n    b = None\n    b_q = None\n    real_b_q = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", n_outmaps, b_init, True, not fix_parameters)\n        if quantize_b:\n            b_q = get_parameter_or_create(\n                \"b_q\", n_outmaps, b_init, False)\n            # Link computation graph\n            real_b_q = F.fixed_point_quantize(b, quantize=quantize_b,\n                                              sign=sign_b, n=n_b, delta=delta_b,\n                                              ste_fine_grained=ste_fine_grained_b,\n                                              outputs=[b_q.data])\n            real_b_q.persistent = True\n        else:\n            real_b_q = b\n\n    return F.affine(inp, real_w_q, real_b_q, base_axis)", "response": "Function to create a fixed - point - quantized affine function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfix - Point Quantized Convolution.", "response": "def fixed_point_quantized_convolution(inp, outmaps, kernel,\n                                      pad=None, stride=None, dilation=None, group=1,\n                                      w_init=None, b_init=None,\n                                      base_axis=1, fix_parameters=False, rng=None, with_bias=True,\n                                      quantize_w=True, sign_w=True, n_w=8, delta_w=2**-4, ste_fine_grained_w=True,\n                                      quantize_b=True, sign_b=True, n_b=8, delta_b=2**-4, ste_fine_grained_b=True,):\n    \"\"\"Fixed-Point Quantized Convolution.\n\n    Fixed-Point Quantized Convolution is the convolution function,\n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} Q(w_{n, m, i, j}) x_{m, a + i, b + j},\n\n    where :math:`Q(w_{n, m, i, j})` is the fixed-point quantization function.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the quantized weights (`quantized weight`)\n\n        2) The weights and the quantized weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the quantized weights will not be in sync.\n\n        3) CPU and GPU implementations now use float value for `quantized weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        group (int): Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.  \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        quantize_w (bool): Quantize weights if `True`.\n        quantize_bias (bool): Quantize bias if `True`.\n        sign_w (bool): Use signed quantization if `True`.\n        n_w (int): Bit width used for weight.\n        delta_w (float): Step size for weight.\n        ste_fine_grained_w (bool): STE is fine-grained if `True`.\n        quantize_b (bool): Quantize bias if `True`.\n        n_b (int): Bit width used for bias.\n        delta_w (float): Step size for bias.\n        ste_fine_grained_b (bool): STE is fine-grained if `True`.\n\n    Returns:\n        :class:`~nnabla.Variable`: N-D array.\n\n    \"\"\"\n    if w_init is None:\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n\n    # Floating Weight\n    w = get_parameter_or_create(\n        \"W\", (outmaps, inp.shape[base_axis] // group) + tuple(kernel),\n        w_init, True, not fix_parameters)\n\n    # Quantized Weight\n    if quantize_w:\n        w_q = get_parameter_or_create(\n            \"W_q\", (outmaps, inp.shape[base_axis] // group) + tuple(kernel),\n            w_init, False)\n        # Link computation graph\n        real_w_q = F.fixed_point_quantize(w, quantize=quantize_w,\n                                          sign=sign_w, n=n_w, delta=delta_w,\n                                          ste_fine_grained=ste_fine_grained_w,\n                                          outputs=[w_q.data])\n        real_w_q.persistent = True\n    else:\n        real_w_q = w\n\n    # Bias\n    # Floating\n    b = None\n    b_q = None\n    real_b_q = None\n\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n        if quantize_b:\n            b_q = get_parameter_or_create(\n                \"b_q\", (outmaps,), b_init, False)\n            # Link computation graph\n            real_b_q = F.fixed_point_quantize(b, quantize=quantize_b,\n                                              sign=sign_b, n=n_b, delta=delta_b,\n                                              ste_fine_grained=ste_fine_grained_b,\n                                              outputs=[b_q.data])\n            real_b_q.persistent = True\n        else:\n            real_b_q = b\n\n    return F.convolution(inp, real_w_q, real_b_q, base_axis, pad, stride, dilation, group)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new tree of pruned affine functions.", "response": "def pruned_affine(inp, n_outmaps,\n                  base_axis=1,\n                  w_init=None, b_init=None,\n                  fix_parameters=False, rng=None, with_bias=True,\n                  prune_w=True, rate_w=0.9, prune_b=True, rate_b=0.9):\n    \"\"\"Pruned Affine.\n\n    Pruned Affine is the affine function, \n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_j = \\sum_{i} Q(w_{ji}) x_i, \n\n    where :math:`Q(w_{ji})` is the pruning function, i.e., `F.prune`.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the quantized weights (`quantized weight`)\n\n        2) The weights and the quantized weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the quantized weights will not be in sync.\n\n        3) CPU and GPU implementations now use float value for `quantized weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): Input N-D array with shape (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times D_B \\\\times \\ldots \\\\times D_N`). Dimensions before and after base_axis are flattened as if it is a matrix.\n        n_outmaps (:obj:`int` or :obj:`tuple` of :obj:`int`): Number of output neurons per data.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight.\n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        prune_w (bool): Quantize weights if `True`.\n        rate_w (float): Pruning rate for weights.\n        prune_b (bool): Quantize bias if `True`.\n        rate_b (float): Pruning rate for bias.\n\n\n    Returns:\n        :class:`~nnabla.Variable`: :math:`(B + 1)`-D array. (:math:`M_0 \\\\times \\ldots \\\\times M_{B-1} \\\\times L`)\n\n    \"\"\"\n\n    if not hasattr(n_outmaps, '__iter__'):\n        n_outmaps = [n_outmaps]\n    n_outmaps = list(n_outmaps)\n    n_outmap = int(np.prod(n_outmaps))\n    if w_init is None:\n        inmaps = np.prod(inp.shape[base_axis:])\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inmaps, n_outmap), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n\n    # Floating Weight\n    w = get_parameter_or_create(\n        \"W\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n        w_init, True, not fix_parameters)\n\n    # sparsed Weight\n    if prune_w:\n        w_q = get_parameter_or_create(\n            \"W_q\", [int(np.prod(inp.shape[base_axis:]))] + n_outmaps,\n            w_init, False)\n        # Link computation graph\n        real_w_q = F.prune(w, rate=rate_w, outputs=[w_q.data])\n        real_w_q.persistent = True\n    else:\n        real_w_q = w\n\n    # Bias\n    # Floating\n    real_b_q = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", n_outmaps, b_init, True, not fix_parameters)\n        if prune_b:\n            b_q = get_parameter_or_create(\n                \"b_q\", n_outmaps, b_init, False)\n            # Link computation graph\n            real_b_q = F.prune(b, rate=rate_b, outputs=[b_q.data])\n            real_b_q.persistent = True\n        else:\n            real_b_q = b\n\n    return F.affine(inp, real_w_q, real_b_q, base_axis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pruned_convolution(inp, outmaps, kernel,\n                       pad=None, stride=None, dilation=None, group=1,\n                       w_init=None, b_init=None,\n                       base_axis=1, fix_parameters=False, rng=None, with_bias=True,\n                       prune_w=True, rate_w=0.9, prune_b=True, rate_b=0.9):\n    \"\"\"Pruned Convolution.\n\n    Pruned Convolution is the convolution function, \n    except the definition of the inner product is modified.\n    The input-output relation of this function is as follows:\n\n    .. math::\n\n        y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} Q(w_{n, m, i, j}) x_{m, a + i, b + j}, \n\n    where :math:`Q(w_{ji})` is the pruning function, i.e., `F.prune`.\n\n    .. note::\n\n        1) if you would like to share weights between some layers, please\n        make sure to share the standard, floating value weights (`weight`)\n        and not the quantized weights (`quantized weight`)\n\n        2) The weights and the quantized weights become synced only after :func:`~nnabla._variable.Variable.forward` is called,\n        and not after a call to :func:`~nnabla._variable.Variable.backward`.\n        To access the parameters of the network, remember to call :func:`~nnabla._variable.Variable.forward` once before doing so, otherwise the\n        float weights and the quantized weights will not be in sync.\n\n        3) CPU and GPU implementations now use float value for `quantized weight`,\n        since this function is only for simulation purposes.\n\n    Args:\n        inp (~nnabla.Variable): N-D array.\n        outmaps (int): Number of convolution kernels (which is equal to the number of output channels). For example, to apply convolution on an input with 16 types of filters, specify 16.\n        kernel (:obj:`tuple` of :obj:`int`): Convolution kernel size. For example, to apply convolution on an image with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5).\n        pad (:obj:`tuple` of :obj:`int`): Padding sizes for dimensions.\n        stride (:obj:`tuple` of :obj:`int`): Stride sizes for dimensions.\n        dilation (:obj:`tuple` of :obj:`int`): Dilation sizes for dimensions.\n        group (int): Number of groups of channels. This makes connections across channels more sparse by grouping connections along map direction.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for weight.\n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`): Initializer for bias.\n        base_axis (int): Dimensions up to `base_axis` are treated as the sample dimensions.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n        rng (numpy.random.RandomState): Random generator for Initializer.\n        with_bias (bool): Specify whether to include the bias term.\n        prune_w (bool): Quantize weights if `True`.\n        rate_w (float): Pruning rate for weights.\n        prune_b (bool): Quantize bias if `True`.\n        rate_b (float): Pruning rate for bias.\n\n    Returns:\n        :class:`~nnabla.Variable`: N-D array.\n\n    \"\"\"\n    if w_init is None:\n        w_init = UniformInitializer(\n            calc_uniform_lim_glorot(inp.shape[base_axis], outmaps, tuple(kernel)), rng=rng)\n    if with_bias and b_init is None:\n        b_init = ConstantInitializer()\n\n    # Floating Weight\n    w = get_parameter_or_create(\n        \"W\", (outmaps, inp.shape[base_axis] // group) + tuple(kernel),\n        w_init, True, not fix_parameters)\n\n    # Quantized Weight\n    if prune_w:\n        w_q = get_parameter_or_create(\n            \"W_q\", (outmaps, inp.shape[base_axis] // group) + tuple(kernel),\n            w_init, False)\n        # Link computation graph\n        real_w_q = F.prune(w, rate=rate_w, outputs=[w_q.data])\n        real_w_q.persistent = True\n    else:\n        real_w_q = w\n\n    # Bias\n    # Floating\n    real_b_q = None\n    if with_bias:\n        b = get_parameter_or_create(\n            \"b\", (outmaps,), b_init, True, not fix_parameters)\n        if prune_b:\n            b_q = get_parameter_or_create(\n                \"b_q\", (outmaps,), b_init, False)\n            # Link computation graph\n            real_b_q = F.prune(b, rate=rate_b, outputs=[b_q.data])\n            real_b_q.persistent = True\n        else:\n            real_b_q = b\n\n    return F.convolution(inp, real_w_q, real_b_q, base_axis, pad, stride, dilation, group)", "response": "This function is used to prune the inner product of a convolution function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new LSTM cell.", "response": "def lstm_cell(x, h, c, state_size, w_init=None, b_init=None, fix_parameters=False):\n    \"\"\"Long Short-Term Memory.\n\n    Long Short-Term Memory, or LSTM, is a building block for recurrent neural networks (RNN) layers.\n    LSTM unit consists of a cell and input, output, forget gates whose functions are defined as following:\n\n    .. math::\n        f_t&&=\\\\sigma(W_fx_t+U_fh_{t-1}+b_f) \\\\\\\\\n        i_t&&=\\\\sigma(W_ix_t+U_ih_{t-1}+b_i) \\\\\\\\\n        o_t&&=\\\\sigma(W_ox_t+U_oh_{t-1}+b_o) \\\\\\\\\n        c_t&&=f_t\\\\odot c_{t-1}+i_t\\\\odot\\\\tanh(W_cx_t+U_ch_{t-1}+b_c) \\\\\\\\\n        h_t&&=o_t\\\\odot\\\\tanh(c_t).\n\n    References:\n\n        S. Hochreiter, and J. Schmidhuber. \"Long Short-Term Memory.\"\n        Neural Computation. 1997.\n\n    Args:\n        x (~nnabla.Variable): Input N-D array with shape (batch_size, input_size).\n        h (~nnabla.Variable): Input N-D array with shape (batch_size, state_size).\n        c (~nnabla.Variable): Input N-D array with shape (batch_size, state_size).\n        state_size (int): Internal state size is set to `state_size`.\n        w_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`, optional): Initializer for weight. By default, it is initialized with :obj:`nnabla.initializer.UniformInitializer` within the range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`.  \n        b_init (:obj:`nnabla.initializer.BaseInitializer` or :obj:`numpy.ndarray`, optional): Initializer for bias. By default, it is initialized with zeros if `with_bias` is `True`.\n        fix_parameters (bool): When set to `True`, the weights and biases will not be updated.\n\n    Returns:\n        :class:`~nnabla.Variable`\n\n    \"\"\"\n\n    xh = F.concatenate(*(x, h), axis=1)\n    iofc = affine(xh, (4, state_size), w_init=w_init,\n                  b_init=b_init, fix_parameters=fix_parameters)\n    i_t, o_t, f_t, gate = F.split(iofc, axis=1)\n    c_t = F.sigmoid(f_t) * c + F.sigmoid(i_t) * F.tanh(gate)\n    h_t = F.sigmoid(o_t) * F.tanh(c_t)\n    return h_t, c_t"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spectral_norm(w, dim=0, itr=1, eps=1e-12, test=False, u_init=None, fix_parameters=True):\n\n    assert (0 <= dim and dim < len(w.shape)\n            ), \"`dim` must be `0 <= dim and dim < len(w.shape)`.\"\n    assert 0 < itr, \"`itr` must be greater than 0.\"\n    assert 0 < eps, \"`eps` must be greater than 0.\"\n\n    if dim == len(w.shape) - 1:\n        w_sn = _spectral_norm_outer_most_dim(w, dim=dim, itr=itr, eps=eps, test=test,\n                                             u_init=u_init, fix_parameters=fix_parameters)\n    else:\n        w_sn = _spectral_norm(w, dim=dim, itr=itr, eps=eps, test=test,\n                              u_init=u_init, fix_parameters=fix_parameters)\n    return w_sn", "response": "Spectral Normalization for Generative Adversarial Networks. 2018."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_state(self):\n\n        self.h.data.zero()\n        self.c.data.zero()", "response": "Resets the internal state of the internal state of the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_inputs(inspecs):\n    ret = []\n    for i in inspecs:\n        v = nn.Variable(i.shape, need_grad=i.need_grad)\n        v.d = i.init(v.shape)\n        ret.append(v)\n    return ret", "response": "Create input variables from list of Inspecs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating lap time. Returns: float: Lap time. The duration from the previous call of ``lap()`` or initialization at first call. float: Total time. The duration from initialization.", "response": "def lap(self):\n        \"\"\"Calculate lap time.\n\n        Returns:\n            float: Lap time. The duration from the previous call of ``lap()``\n                 or initialization at first call.\n            float: Total time. The duration from initialization.\n\n        \"\"\"\n        now = time.time()\n        lap_time = now - self.lap_time\n        total_time = now - self.start\n        self.lap_time = now\n        return lap_time, total_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, fb):\n        print('[{}.{}]'.format(fb.module, fb.func.__name__), file=self.file)\n        print('class = {}'.format(fb.func_ins.name), file=self.file)\n        print('inspecs = {}'.format(repr(fb.inspecs)), file=self.file)\n        print('func_args = {}'.format(repr(fb.func_args)), file=self.file)\n        print('func_kwargs = {}'.format(repr(fb.func_kwargs)), file=self.file)\n        print('ext = ({}, {})'.format(\n            repr(fb.ext), repr(fb.ext_kwargs)), file=self.file)\n        if self.setup_stat is not None:\n            self._write_a_stat('setup', self.setup_stat)\n        if self.foward_stat is not None:\n            self._write_a_stat('forward', self.forward_stat)\n        if self.backward_stat is not None:\n            self._write_a_stat('backward', self.backward_stat)", "response": "Write a single function benchmark."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a function instance and execute setup.", "response": "def _setup(self, delete=True):\n        \"\"\"Create a function instance and execute setup.\n\n        Args:\n            delete (bool): Delete buffered variables.\n\n        \"\"\"\n        if delete:\n            self.clear()\n        with nn.context_scope(self.ctx):\n            outputs = self.func(\n                *(self.inputs_f + self.func_args), **self.func_kwargs)\n            if not hasattr(outputs, '__iter__'):\n                self.outputs = [outputs]\n            else:\n                self.outputs = outputs\n        self.func_ins = self.outputs[0].parent\n        self.inputs = self.func_ins.inputs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbenchmark backward execution. Note: If backward execution throws any exception, this benchmark system considers the error is because the function doesn't support backward operation, then set the benchmark ``None``.", "response": "def benchmark_backward(self):\n        \"\"\"Benchmark backward execution.\n\n        Note:\n            If backward execution throws any exception,\n            this benchmark system considers the error is because the function\n            doesn't support backward operation, then set the benchmark\n            ``None``.\n\n        \"\"\"\n        try:\n            self._benchmark_backward()\n        except RuntimeError as e:\n            # Seems like not implemented.\n            print(e)\n            self.mod_ext.synchronize(**self.ext_kwargs)\n            self.backward_stat = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the context of the specified extension.", "response": "def extension_context(extension_name='cpu', **kw):\n    \"\"\"Get the context of the specified extension.\n\n    All extension's module must provide `context(**kw)` function.\n\n    Args:\n        extension_name (str) : Module path relative to `nnabla_ext`.\n        kw (dict) : Additional keyword arguments for context function in a extension module.\n\n    Returns:\n        :class:`nnabla.Context`: The current extension context.\n\n    Note:\n        Deprecated. Use :function:`nnabla.ext_utils.get_extension_context` instead.\n\n    Example:\n\n        .. code-block:: python\n\n            ctx = extension_context('cuda.cudnn', device_id=0)\n            nn.set_default_context(ctx)\n\n    \"\"\"\n    from nnabla import logger\n    logger.warn(\n        'Deprecated API. Use `nnabla.ext_util.get_extension_context(ext_name, **kw)`.')\n    from nnabla.ext_utils import get_extension_context\n    return get_extension_context(extension_name, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revise_buffer_size(info, settings):\n    '''\n    This function is used to revise buffer size, use byte\n    as its unit, instead of data item.\n    This is only used for nnb, not for csrc.\n    When settings contains user customized data type, not pure\n    FLOAT32, it affects the memory consumption.\n    '''\n    size_mapping = {\n        'FLOAT32': 4,\n        'FIXED16': 2,\n        'FIXED8': 1\n    }\n\n    var_dict = settings['variables']\n    buffer_index = 0\n    info._variable_sizes = []\n    info._variable_buffer_index = collections.OrderedDict()\n    info._variable_buffer_size = collections.OrderedDict()\n    info._buffer_ids = {}\n    for n, v in enumerate(info._network.variable):\n        byte_per_item = size_mapping.get(var_dict.get(\n            v.name, 'FLOAT32').split('_')[0], 4)\n        size = nnabla.utils.converter.calc_shape_size(\n            v.shape, info._batch_size) * byte_per_item\n        info._variable_sizes.append(size)\n        if v.type == 'Buffer':\n            info._variable_buffer_index[buffer_index] = [n]\n            for vid in info._variable_buffer_index[buffer_index]:\n                info._buffer_ids[vid] = buffer_index\n\n            info._variable_buffer_size[buffer_index] = size\n            buffer_index += 1", "response": "This function is used to revise buffer size for nnb and csrc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef category_names(self):\n        '''\n        Returns category names of 1000 ImageNet classes.\n        '''\n        if hasattr(self, '_category_names'):\n            return self._category_names\n        with open(os.path.join(os.path.dirname(__file__), 'category_names.txt'), 'r') as fd:\n            self._category_names = fd.read().splitlines()\n        return self._category_names", "response": "Returns category names of 1000 ImageNet classes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the nnp from the database.", "response": "def _load_nnp(self, rel_name, rel_url):\n        '''\n            Args:\n                rel_name: relative path to where donwloaded nnp is saved.\n                rel_url: relative url path to where nnp is downloaded from.\n\n            '''\n        from nnabla.utils.download import download\n        path_nnp = os.path.join(\n                get_model_home(), 'imagenet/{}'.format(rel_name))\n        url = os.path.join(get_model_url_base(),\n                           'imagenet/{}'.format(rel_url))\n        logger.info('Downloading {} from {}'.format(rel_name, url))\n        dir_nnp = os.path.dirname(path_nnp)\n        if not os.path.isdir(dir_nnp):\n            os.makedirs(dir_nnp)\n        download(url, path_nnp, open_file=False, allow_overwrite=False)\n        print('Loading {}.'.format(path_nnp))\n        self.nnp = NnpLoader(path_nnp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self):\n        writer = csv.writer(self.file)\n\n        for f, b in zip(self.gb.result[\"forward\"], self.gb.result[\"backward\"]):\n            f = f._asdict()\n            b = b._asdict()\n            if not self.check_same(f, b):\n                raise AssertionError()\n\n            args_info = \", \".join([\"{}: {}\".format(k, v)\n                                   for k, v in f[\"args_info\"]])\n\n            out = [f[\"parameter_scope\"], f[\"function_name\"], f[\"inputs_shape\"], args_info,\n                   f[\"mean_time\"], b[\"mean_time\"], f[\"n_run\"], b[\"n_run\"]]\n\n            writer.writerow(out)\n\n        writer.writerow([])\n        writer.writerow([\"forward all\", self.gb.result[\"forward_all\"]])\n        writer.writerow(\n            [\"forward_all_n_run\", self.gb.result[\"n_run_forward_all\"]])\n\n        writer.writerow([])\n        writer.writerow([\"backward all\", self.gb.result[\"backward_all\"]])\n        writer.writerow(\n            [\"backward_all_n_run\", self.gb.result[\"n_run_backward_all\"]])\n\n        if set(self.gb.result.keys()) >= {\"training\", \"n_run_training\"}:\n            writer.writerow([])\n            writer.writerow(\n                [\"training(forward + backward + update)\", self.gb.result[\"training\"]])\n            writer.writerow(\n                [\"training_n_run\", self.gb.result[\"n_run_training\"]])", "response": "Write the result of the function to the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tile_images(data, padsize=1, padval=0):\n    assert(data.ndim == 4)\n    data = data.transpose(0, 2, 3, 1)\n\n    # force the number of filters to be square\n    n = int(np.ceil(np.sqrt(data.shape[0])))\n    padding = (\n        (0, n ** 2 - data.shape[0]),\n        (0, padsize),\n        (0, padsize)\n    ) + ((0, 0),) * (data.ndim - 3)\n    data = np.pad(\n        data, padding, mode='constant', constant_values=(padval, padval))\n    data = data.reshape(\n        (n, n)\n        + data.shape[1:]\n    ).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n    data = data.reshape(\n        (n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n    if data.shape[2] == 1:\n        # Return as (H, W)\n        return data.reshape(data.shape[:2])\n    return data", "response": "Convert an array with shape of B C H W into a tiled image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot series data from MonitorSeries output text file.", "response": "def plot_series(filename, plot_kwargs=None):\n    '''Plot series data from MonitorSeries output text file.\n\n    Args:\n        filename (str): Path to *.series.txt file produced by :obj:`~nnabla.MonitorSeries` class.\n        plot_kwags (dict, optional):\n            Keyward arguments passed to :function:`matplotlib.pyplot.plot`.\n\n    Note:\n        matplotlib package is required.\n\n    '''\n    import matplotlib.pyplot as plt\n\n    if plot_kwargs is None:\n        plot_kwargs = {}\n\n    data = np.genfromtxt(filename, dtype='i8,f4', names=['k', 'v'])\n    index = data['k']\n    values = data['v']\n    plt.plot(index, values, **plot_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_time_elapsed(filename, elapsed=False, unit='s', plot_kwargs=None):\n    '''Plot series data from MonitorTimeElapsed output text file.\n\n    Args:\n        filename (str): Path to *.series.txt file produced by :obj:`~nnabla.MonitorSeries` class.\n        elapsed (bool): If ``True``, it plots the total elapsed time.\n        unit (str):\n            Time unit chosen from ``'s'``, ``'m'``, ``'h'``, or ``'d'``.\n        plot_kwags (dict, optional):\n            Keyward arguments passed to :function:`matplotlib.pyplot.plot`.\n\n    Note:\n        matplotlib package is required.\n\n    '''\n    import matplotlib.pyplot as plt\n\n    if plot_kwargs is None:\n        plot_kwargs = {}\n\n    data_column = 3 if elapsed else 1\n    data = np.genfromtxt(filename, dtype='i8,f4',\n                         usecols=(0, data_column), names=['k', 'v'])\n    index = data['k']\n    values = data['v']\n    if unit == 's':\n        pass\n    elif unit == 'm':\n        values /= 60\n    elif unit == 'h':\n        values /= 3600\n    elif unit == 'd':\n        values /= 3600 * 24\n    else:\n        raise ValueError('The argument `unit` must be chosen from {s|m|h|d}.')\n    plt.plot(index, values, **plot_kwargs)", "response": "Plot series data from MonitorTimeElapsed output text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a value to the series.", "response": "def add(self, index, value):\n        \"\"\"Add a value to the series.\n\n        Args:\n            index (int): Index.\n            value (float): Value.\n\n        \"\"\"\n        self.buf.append(value)\n        if (index - self.flush_at) < self.interval:\n            return\n        value = np.mean(self.buf)\n        if self.verbose:\n            logger.info(\"iter={} {{{}}}={}\".format(index, self.name, value))\n        if self.fd is not None:\n            print(\"{} {:g}\".format(index, value), file=self.fd)\n        self.flush_at = index\n        self.buf = []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, index):\n        if (index - self.flush_at) < self.interval:\n            return\n        now = time.time()\n        elapsed = now - self.lap\n        elapsed_total = now - self.start\n        it = index - self.flush_at\n        self.lap = now\n        if self.verbose:\n            logger.info(\"iter={} {{{}}}={}[sec/{}iter] {}[sec]\".format(\n                index, self.name, elapsed, it, elapsed_total))\n        if self.fd is not None:\n            print(\"{} {} {} {}\".format(index, elapsed,\n                                       it, elapsed_total), file=self.fd)\n        self.flush_at = index", "response": "Adds a new entry to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a minibatch of images to the monitor.", "response": "def add(self, index, var):\n        \"\"\"Add a minibatch of images to the monitor.\n\n        Args:\n            index (int): Index.\n            var (:obj:`~nnabla.Variable`, :obj:`~nnabla.NdArray`, or :obj:`~numpy.ndarray`):\n                A minibatch of images with ``(N, ..., C, H, W)`` format.\n                If C == 2, blue channel is appended with ones. If C > 3,\n                the array will be sliced to remove C > 3 sub-array.\n\n        \"\"\"\n        import nnabla as nn\n        from nnabla.utils.image_utils import imsave\n        if index != 0 and (index + 1) % self.interval != 0:\n            return\n        if isinstance(var, nn.Variable):\n            data = var.d.copy()\n        elif isinstance(var, nn.NdArray):\n            data = var.data.copy()\n        else:\n            assert isinstance(var, np.ndarray)\n            data = var.copy()\n        assert data.ndim > 2\n        channels = data.shape[-3]\n        data = data.reshape(-1, *data.shape[-3:])\n        data = data[:min(data.shape[0], self.num_images)]\n        data = self.normalize_method(data)\n        if channels > 3:\n            data = data[:, :3]\n        elif channels == 2:\n            data = np.concatenate(\n                [data, np.ones((data.shape[0], 1) + data.shape[-2:])], axis=1)\n        path_tmpl = os.path.join(self.save_dir, '{:06d}-{}.png')\n        for j in range(min(self.num_images, data.shape[0])):\n            img = data[j].transpose(1, 2, 0)\n            if img.shape[-1] == 1:\n                img = img[..., 0]\n            path = path_tmpl.format(index, '{:03d}'.format(j))\n            imsave(path, img)\n        if self.verbose:\n            logger.info(\"iter={} {{{}}} are written to {}.\".format(\n                index, self.name, path_tmpl.format(index, '*')))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving cache data into file.", "response": "def _save_cache_to_file(self):\n        '''\n        Store cache data into file.\n\n        Data will be stored as hdf5 format, placed at config..\n        Cache file name format is \"cache_START_END.h5\"\n        '''\n        if self._cache_dir is None:\n            raise DataSourceWithFileCacheError(\n                'Use this class with \"with statement\" if you don\\'t specify cache dir.')\n        cache_data = OrderedDict()\n\n        def get_data(args):\n            pos = args[0]\n            q = args[1]\n            retry = 1\n            while True:\n                if retry > 10:\n                    logger.log(\n                        99, '_get_current_data() retry count over give up.')\n                    raise\n                d = self._data_source._get_data(pos)\n                if d is not None:\n                    break\n                logger.log(99, '_get_data() fails. retrying count {}/10.'.format(\n                           retry))\n                retry += 1\n\n            q.put((pos, d))\n\n        q = Queue()\n        with closing(ThreadPool(processes=self._num_of_threads)) as pool:\n            pool.map(get_data, [(pos, q) for pos in self._cache_positions])\n\n        while len(cache_data) < len(self._cache_positions):\n            index, data = q.get()\n            cache_data[index] = data\n        start_position = self.position - len(cache_data) + 1\n        end_position = self.position\n        cache_filename = os.path.join(\n            self._cache_dir, '{}_{:08d}_{:08d}{}'.format(self._cache_file_name_prefix,\n                                                         start_position,\n                                                         end_position,\n                                                         self._cache_file_format))\n\n        data = OrderedDict([(n, []) for n in self._data_source.variables])\n        for pos in sorted(cache_data):\n            cd = cache_data[pos]\n            for i, n in enumerate(self._data_source.variables):\n                if isinstance(cd[i], numpy.ndarray):\n                    d = cd[i]\n                else:\n                    d = numpy.array(cd[i]).astype(numpy.float32)\n                data[n].append(d)\n\n        logger.info('Creating cache file {}'.format(cache_filename))\n        try:\n            if self._cache_file_format == \".h5\":\n                h5 = h5py.File(cache_filename, 'w')\n                for k, v in data.items():\n                    h5.create_dataset(k, data=v)\n                h5.close()\n            else:\n                retry_count = 1\n                is_create_cache_imcomplete = True\n                while is_create_cache_imcomplete:\n                    try:\n                        with open(cache_filename, 'wb') as f:\n                            for v in data.values():\n                                numpy.save(f, v)\n                        is_create_cache_imcomplete = False\n                    except OSError:\n                        retry_count += 1\n                        if retry_count > 10:\n                            raise\n                        logger.info(\n                            'Creating cache retry {}/10'.format(retry_count))\n        except:\n            logger.critical(\n                'An error occurred while creating cache file from dataset.')\n            for k, v in data.items():\n                size = v[0].shape\n                for d in v:\n                    if size != d.shape:\n                        logger.critical('The sizes of data \"{}\" are not the same. ({} != {})'.format(\n                            k, size, d.shape))\n            raise\n\n        self._cache_file_names.append(cache_filename)\n        self._cache_file_order.append(len(self._cache_file_order))\n        self._cache_file_data_orders.append(list(range(len(cache_data))))\n        self._cache_positions = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving the CPD problem with the given target tensor X.", "response": "def solve(self, X, rank, max_iter=500, stopping_criterion=1e-5,\n              lambda_reg=0.0, dtype=np.float32, rng=None):\n        \"\"\"Solve CPD\n\n        Args:\n            X (numpy.ndarray): Target tensor of CPD.\n            rank (int): Rank of the approximate tensor.\n            max_iter (int): Max iteration of the ALS.\n            stopping_criterion (float): Threshold for stopping the ALS.\n                If the value is negative, the convergence check is ignored;\n                in other words, it may reduce the computation time.\n            lambda_reg (float): regularization parameter. Larger lambda_reg\n                means larger regularization.\n            dtype (numpy.dtype): Data type\n\n        Returns:\n            list of numpy.ndarray: Decomposed matrices.\n            numpy.ndarray: Lambda of the CPD.\n\n        \"\"\"\n\n        N = X.ndim  # Tensor dimensions\n        squared_norm_X = np.sum(X ** 2)  # Frobenious norm square\n\n        # Initialize\n        if rng is None:\n            rng = np.random.RandomState(313)\n        A = [None for _ in range(N)]\n        for n in range(1, N):\n            A[n] = np.array(rng.rand(X.shape[n], rank), dtype=dtype)\n\n        # Solve ALS problem\n        criterion = 0\n        for itr in range(max_iter):\n            criterion_prev = criterion\n\n            # Fix one dimension\n            for n in range(N):\n                # Solve sub problem\n                V = self.hadamard_products_of_gramians(A, n)\n                P = self.khatrirao_products(A, n)\n                A_n = np.tensordot(\n                    X,\n                    P,\n                    axes=(\n                        [o for o in range(N) if o != n],\n                        np.arange(N-1)[::-1]))\n                # L2 regularization\n                V = V+np.eye(rank)*lambda_reg\n\n                A_n = A_n.dot(pinv(V))\n\n                # Normalize\n                if itr == 0:\n                    lmbda = np.sqrt((A_n ** 2).sum(axis=0))\n                else:\n                    lmbda = A_n.max(axis=0)\n                    lmbda[lmbda < 1] = 1\n                A[n] = A_n / lmbda\n\n            # Check convergence\n            if stopping_criterion < 0:\n                continue\n            X_approx = self.approximate_tensor(A, lmbda)\n            squared_norm_residual = squared_norm_X + \\\n                np.sum(X_approx**2) - 2 * np.sum(X*X_approx)\n            criterion = 1.0 - (squared_norm_residual / squared_norm_X)\n            criterion_change = abs(criterion_prev - criterion)\n\n            if itr > 0 and criterion_change < stopping_criterion:\n                break\n\n        return A, lmbda"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator over the data sources in a single thread.", "response": "def data_iterator(data_source,\n                  batch_size,\n                  rng=None,\n                  with_memory_cache=True,\n                  with_file_cache=False,\n                  cache_dir=None,\n                  epoch_begin_callbacks=[],\n                  epoch_end_callbacks=[]):\n    '''data_iterator\n    Helper method to use :py:class:`DataSource <nnabla.utils.data_source.DataSource>`.\n\n    You can use :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>` with your own :py:class:`DataSource <nnabla.utils.data_source.DataSource>`\n    for easy implementation of data sources.\n\n    For example,\n\n    .. code-block:: python\n\n        ds = YourOwnImplementationOfDataSource()\n        batch = data_iterator(ds, batch_size)\n\n\n    Args:\n        data_source (:py:class:`DataSource <nnabla.utils.data_source.DataSource>`):\n             Instance of DataSource class which provides data.\n        batch_size (int): Batch size.\n        rng (None or :obj:`numpy.random.RandomState`): Numpy random number\n            generator.\n        with_memory_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithMemoryCache`\n            to wrap ``data_source``. It is a good idea to set this as true unless\n            data_source provides on-memory data.\n            Default value is True.\n        with_file_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithFileCache`\n            to wrap ``data_source``.\n            If ``data_source`` is slow, enabling this option a is good idea.\n            Default value is False.\n        cache_dir (str):\n            Location of file_cache.\n            If this value is None, :py:class:`.data_source.DataSourceWithFileCache`\n            creates file caches implicitly on temporary directory and erases them all\n            when data_iterator is finished.\n            Otherwise, :py:class:`.data_source.DataSourceWithFileCache` keeps created cache.\n            Default is None.\n        epoch_begin_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the beginning of an epoch.\n        epoch_end_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the end of an epoch.\n\n    Returns:\n        :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>`:\n            Instance of DataIterator.\n    '''\n    if with_file_cache:\n        ds = DataSourceWithFileCache(data_source=data_source,\n                                     cache_dir=cache_dir,\n                                     shuffle=data_source.shuffle,\n                                     rng=rng)\n        if with_memory_cache:\n            ds = DataSourceWithMemoryCache(ds,\n                                           shuffle=ds.shuffle,\n                                           rng=rng)\n        return DataIterator(ds,\n                            batch_size,\n                            epoch_begin_callbacks=epoch_begin_callbacks,\n                            epoch_end_callbacks=epoch_end_callbacks)\n    else:\n        if with_memory_cache:\n            data_source = DataSourceWithMemoryCache(data_source,\n                                                    shuffle=data_source.shuffle,\n                                                    rng=rng)\n        return DataIterator(data_source, batch_size,\n                            epoch_begin_callbacks=epoch_begin_callbacks,\n                            epoch_end_callbacks=epoch_end_callbacks)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_iterator_simple(load_func,\n                         num_examples,\n                         batch_size,\n                         shuffle=False,\n                         rng=None,\n                         with_memory_cache=True,\n                         with_file_cache=True,\n                         cache_dir=None,\n                         epoch_begin_callbacks=[],\n                         epoch_end_callbacks=[]):\n    \"\"\"A generator that ``yield`` s minibatch data as a tuple, as defined in ``load_func`` .\n    It can unlimitedly yield minibatches at your request, queried from the provided data.\n\n    Args:\n        load_func (function): Takes a single argument `i`, an index of an\n            example in your dataset to be loaded, and returns a tuple of data.\n            Every call by any index `i` must return a tuple of arrays with\n            the same shape.\n        num_examples (int): Number of examples in your dataset. Random sequence\n            of indexes is generated according to this number.\n        batch_size (int): Size of data unit.\n        shuffle (bool):\n             Indicates whether the dataset is shuffled or not.\n             Default value is False. \n        rng (None or :obj:`numpy.random.RandomState`): Numpy random number\n            generator.\n        with_memory_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithMemoryCache`\n            to wrap ``data_source``. It is a good idea to set this as true unless\n            data_source provides on-memory data.\n            Default value is True.\n        with_file_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithFileCache`\n            to wrap ``data_source``.\n            If ``data_source`` is slow, enabling this option a is good idea.\n            Default value is False.\n        cache_dir (str):\n            Location of file_cache.\n            If this value is None, :py:class:`.data_source.DataSourceWithFileCache`\n            creates file caches implicitly on temporary directory and erases them all\n            when data_iterator is finished.\n            Otherwise, :py:class:`.data_source.DataSourceWithFileCache` keeps created cache.\n            Default is None.\n        epoch_begin_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the beginning of an epoch.\n        epoch_end_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the end of an epoch.\n\n\n    Returns:\n        :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>`:\n            Instance of DataIterator.\n\n\n    Here is an example of `load_func` which returns an image and a label of a\n    classification dataset.\n\n    .. code-block:: python\n\n        import numpy as np\n        from nnabla.utils.image_utils import imread\n        image_paths = load_image_paths()\n        labels = load_labels()\n        def my_load_func(i):\n            '''\n            Returns:\n                image: c x h x w array\n                label: 0-shape array\n            '''\n            img = imread(image_paths[i]).astype('float32')\n            return np.rollaxis(img, 2), np.array(labels[i])\n\n\n    \"\"\"\n    return data_iterator(SimpleDataSource(load_func,\n                                          num_examples,\n                                          shuffle=shuffle,\n                                          rng=rng),\n                         batch_size=batch_size,\n                         with_memory_cache=with_memory_cache,\n                         with_file_cache=with_file_cache,\n                         cache_dir=cache_dir,\n                         epoch_begin_callbacks=epoch_begin_callbacks,\n                         epoch_end_callbacks=epoch_end_callbacks)", "response": "A simple minibatch data generator that yields minibatches from the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_iterator_csv_dataset(uri,\n                              batch_size,\n                              shuffle=False,\n                              rng=None,\n                              normalize=True,\n                              with_memory_cache=True,\n                              with_file_cache=True,\n                              cache_dir=None,\n                              epoch_begin_callbacks=[],\n                              epoch_end_callbacks=[]):\n    '''data_iterator_csv_dataset\n    Get data directly from a dataset provided as a CSV file.\n\n    You can read files located on the local file system, http(s) servers or Amazon AWS S3 storage.\n\n    For example,\n\n    .. code-block:: python\n\n        batch = data_iterator_csv_dataset('CSV_FILE.csv', batch_size, shuffle=True)\n\n    Args:\n        uri (str): Location of dataset CSV file.\n        batch_size (int): Size of data unit.\n        shuffle (bool):\n             Indicates whether the dataset is shuffled or not.\n             Default value is False. \n        rng (None or :obj:`numpy.random.RandomState`): Numpy random number\n            generator.\n        normalize (bool): If True, each sample in the data gets normalized by a factor of 255. \n            Default is True.\n        with_memory_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithMemoryCache`\n            to wrap ``data_source``. It is a good idea to set this as true unless\n            data_source provides on-memory data.\n            Default value is True.\n        with_file_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithFileCache`\n            to wrap ``data_source``.\n            If ``data_source`` is slow, enabling this option a is good idea.\n            Default value is False.\n        cache_dir (str):\n            Location of file_cache.\n            If this value is None, :py:class:`.data_source.DataSourceWithFileCache`\n            creates file caches implicitly on temporary directory and erases them all\n            when data_iterator is finished.\n            Otherwise, :py:class:`.data_source.DataSourceWithFileCache` keeps created cache.\n            Default is None.\n        epoch_begin_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the beginning of an epoch.\n        epoch_end_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the end of an epoch.\n\n\n    Returns:\n        :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>`:\n            Instance of DataIterator\n    '''\n    ds = CsvDataSource(uri,\n                       shuffle=shuffle,\n                       rng=rng,\n                       normalize=normalize)\n\n    return data_iterator(ds,\n                         batch_size=batch_size,\n                         with_memory_cache=with_memory_cache,\n                         with_file_cache=with_file_cache,\n                         cache_dir=cache_dir,\n                         epoch_begin_callbacks=epoch_begin_callbacks,\n                         epoch_end_callbacks=epoch_end_callbacks)", "response": "Returns an iterator over the data in a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data_iterator_cache(uri,\n                        batch_size,\n                        shuffle=False,\n                        rng=None,\n                        normalize=True,\n                        with_memory_cache=True,\n                        epoch_begin_callbacks=[],\n                        epoch_end_callbacks=[]):\n    '''data_iterator_cache\n    Get data from the cache directory.\n\n    Cache files are read from the local file system.\n\n    For example,\n\n    .. code-block:: python\n\n        batch = data_iterator_cache('CACHE_DIR', batch_size, shuffle=True)\n\n    Args:\n        uri (str): Location of directory with cache files.\n        batch_size (int): Size of data unit.\n        shuffle (bool):\n             Indicates whether the dataset is shuffled or not.\n             Default value is False. \n        rng (None or :obj:`numpy.random.RandomState`): Numpy random number\n            generator.\n        normalize (bool): If True, each sample in the data gets normalized by a factor of 255. \n            Default is True.\n        with_memory_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithMemoryCache`\n            to wrap ``data_source``. It is a good idea to set this as true unless\n            data_source provides on-memory data.\n            Default value is True.\n        epoch_begin_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the beginning of an epoch.\n        epoch_end_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the end of an epoch.\n\n\n    Returns:\n        :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>`:\n            Instance of DataIterator\n    '''\n    ds = CacheDataSource(uri,\n                         shuffle=shuffle,\n                         rng=rng,\n                         normalize=normalize)\n\n    return data_iterator(ds,\n                         batch_size=batch_size,\n                         with_memory_cache=with_memory_cache,\n                         epoch_begin_callbacks=epoch_begin_callbacks,\n                         epoch_end_callbacks=epoch_end_callbacks)", "response": "Returns an iterator over the data in the local file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data_iterator_concat_datasets(data_source_list,\n                                  batch_size,\n                                  shuffle=False,\n                                  rng=None,\n                                  with_memory_cache=True,\n                                  with_file_cache=False,\n                                  cache_dir=None,\n                                  epoch_begin_callbacks=[],\n                                  epoch_end_callbacks=[]):\n    '''data_iterator_concat_datasets\n    Get data from multiple datasets.\n\n    For example,\n\n    .. code-block:: python\n\n        batch = data_iterator_concat_datasets([DataSource0, DataSource1, ...], batch_size)\n\n    Args:\n        data_source_list (list of DataSource): list of datasets.\n        batch_size (int): Size of data unit.\n        shuffle (bool):\n             Indicates whether the dataset is shuffled or not.\n             Default value is False. \n        rng (None or :obj:`numpy.random.RandomState`): Numpy random number\n            generator.\n        with_memory_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithMemoryCache`\n            to wrap ``data_source``. It is a good idea to set this as true unless\n            data_source provides on-memory data.\n            Default value is True.\n        with_file_cache (bool):\n            If ``True``, use :py:class:`.data_source.DataSourceWithFileCache`\n            to wrap ``data_source``.\n            If ``data_source`` is slow, enabling this option a is good idea.\n            Default value is False.\n        cache_dir (str):\n            Location of file_cache.\n            If this value is None, :py:class:`.data_source.DataSourceWithFileCache`\n            creates file caches implicitly on temporary directory and erases them all\n            when data_iterator is finished.\n            Otherwise, :py:class:`.data_source.DataSourceWithFileCache` keeps created cache.\n            Default is None.\n        epoch_begin_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the beginning of an epoch.\n        epoch_end_callbacks (list of functions): An item is a function\n            which takes an epoch index as an argument. These are called\n            at the end of an epoch.\n\n\n    Returns:\n        :py:class:`DataIterator <nnabla.utils.data_iterator.DataIterator>`:\n            Instance of DataIterator\n    '''\n    ds = ConcatDataSource(data_source_list,\n                          shuffle=shuffle,\n                          rng=rng)\n    return data_iterator(ds,\n                         batch_size=batch_size,\n                         with_memory_cache=with_memory_cache,\n                         with_file_cache=with_file_cache,\n                         epoch_begin_callbacks=epoch_begin_callbacks,\n                         epoch_end_callbacks=epoch_end_callbacks)", "response": "Returns an iterator over the data from multiple datasets."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slice(self, rng, num_of_slices=None, slice_pos=None,\n              slice_start=None, slice_end=None,\n              cache_dir=None):\n        '''\n        Slices the data iterator so that newly generated data iterator has access to limited portion of the original data.\n\n        Args:\n            rng (numpy.random.RandomState): Random generator for Initializer.\n            num_of_slices(int): Total number of slices to be made. Muts be used together with `slice_pos`. \n            slice_pos(int): Position of the slice to be assigned to the new data iterator. Must be used together with `num_of_slices`.\n            slice_start(int): Starting position of the range to be sliced into new data iterator. Must be used together with `slice_end`.\n            slice_end(int) : End position of the range to be sliced into new data iterator. Must be used together with `slice_start`.\n            cache_dir(str) : Directory to save cache files\n\n        Example:\n\n        .. code-block:: python\n\n            from nnabla.utils.data_iterator import data_iterator_simple\n            import numpy as np\n\n            def load_func1(index):\n                d = np.ones((2, 2)) * index\n                return d\n\n            di = data_iterator_simple(load_func1, 1000, batch_size=3)\n\n            di_s1 = di.slice(None, num_of_slices=10, slice_pos=0)\n            di_s2 = di.slice(None, num_of_slices=10, slice_pos=1)\n\n            di_s3 = di.slice(None, slice_start=100, slice_end=200)\n            di_s4 = di.slice(None, slice_start=300, slice_end=400) \n\n        '''\n\n        if num_of_slices is not None and slice_pos is not None and slice_start is None and slice_end is None:\n            size = self._size // num_of_slices\n            amount = self._size % num_of_slices\n            slice_start = slice_pos * size\n            if slice_pos < amount:\n                slice_start += slice_pos\n            else:\n                slice_start += amount\n            slice_end = slice_start + size\n            if slice_end > self._size:\n                slice_start -= (slice_end - self._size)\n                slice_end = self._size\n\n        elif num_of_slices is None and slice_pos is None and slice_start is not None and slice_end is not None:\n            pass\n        else:\n            logger.critical(\n                'You must specify position(num_of_slice and slice_pos) or range(slice_start and slice_end).')\n            return None\n\n        if cache_dir is None:\n            ds = self._data_source\n            while '_data_source' in dir(ds):\n                if '_cache_dir' in dir(ds):\n                    cache_dir = ds._cache_dir\n                ds = ds._data_source\n\n        if cache_dir is None:\n            return DataIterator(\n                DataSourceWithMemoryCache(\n                    SlicedDataSource(\n                        self._data_source,\n                        self._data_source.shuffle,\n                        slice_start=slice_start,\n                        slice_end=slice_end),\n                    shuffle=self._shuffle,\n                    rng=rng),\n                self._batch_size)\n        else:\n            return DataIterator(\n                DataSourceWithMemoryCache(\n                    DataSourceWithFileCache(\n                        SlicedDataSource(\n                            self._data_source,\n                            self._data_source.shuffle,\n                            slice_start=slice_start,\n                            slice_end=slice_end),\n                        cache_dir=cache_dir,\n                        cache_file_name_prefix='cache_sliced_{:08d}_{:08d}'.format(\n                            slice_start,\n                            slice_end),\n                        shuffle=self._shuffle,\n                        rng=rng),\n                    shuffle=self._shuffle,\n                    rng=rng),\n                self._batch_size)", "response": "Slice the data iterator so that the newly generated data iterator has access to limited portion of the original data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(self, vroot, entry_variables):\n        self.graph_info = GraphInfo(vroot)\n        self.entry_variables = entry_variables\n\n        with nn.parameter_scope(self.name):\n            # Function loop in the forward order\n            for t, func in enumerate(self.graph_info.funcs):\n                # Activation check\n                if func.name in self.activation_functions:\n                    activation_func = func\n                    o = self._fixed_point_activation_conversion(\n                        activation_func)\n                    continue\n                # Identity conversion\n                o = self._identity_conversion(func)\n\n        self.end_variable = o\n        return self.end_variable", "response": "This function converts the vroot variable to the corresponding entry variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef profile(fn=None, condition=None, profile_class=cProfile.Profile, print_freq=0, sort_keys=None, print_restrictions=None):\n    '''Decorating a function that is profiled with a Python profiler\n    such as :class:`cProfile.Profile`.\n\n    **Note**: ``function`` doesn't refer to :obj:`~nnabla.function.Function`.\n    A Python function.\n\n    Args:\n        fn (function):\n            A function that is profiled. If None is specified (default), it\n            returns a new decorator function. It is used when you want to\n            specify optional arguments of this decorator function.\n        condition (function):\n            A function object which takes the same inputs with the decorated\n            function, and returns a boolean value. The decorated function is\n            profiled only when the ``condition`` function returns ``True``.\n            By default, it returns always `True`, hence profiling is performed\n            everytime the decorated function is called.\n        profile_class (class):\n            A profiler class such as :obj:`cProfile.Profile` and\n            :obj:`Profile.Profile`. The default value is\n            :obj:`cProfile.Profile`.\n        print_freq (int):\n            The profiling result is printed at function calls with an interval\n            specified by ``print_freq``. If 0 is specified (default), the\n            profiling result is only printed at the end of the Python process\n            unless ``decorated_func.profiler.print_stats()`` is called\n            manually.\n        sort_keys (iterable):\n            A list or tuple of string, which is passed to\n            :meth:`pstats.Stats.sort_stats` as arguments. The default is\n            ``('cumulative', 'time', 'calls')``.\n        print_restriction (iterable):\n            A list or tuple which is passed to\n            :meth:`pstats.Stats.print_stats` as arguments. The default\n            value is ``(40,)``, which results in only 40 functions inside the\n            decorated function are printed in the profiling result.\n\n    Returns: function\n\n        A decorated function. If ``fn`` is ``None``, a new decorator function\n        with optional arguments specified.\n\n    Example:\n\n        By decorating a function as following, the profling result is printed\n        at the end of the Python process.\n\n        .. code-block:: python\n\n            from nnabla.utils import function_profile\n\n            @function_profile.profile\n            def foo(a, b, c=None, d=None):\n                ...\n\n        If you want to manually print the profiling result so far, use\n        :meth:`FunctionProfile.print_stats`\n        of the :obj:`FunctionProfile` object\n        attached to the decorated function as ``profiler`` attribute.\n\n        .. code-block:: python\n\n            foo.profiler.print_stats()\n\n        If you want to profile the function only when a specific argument is\n        passed to, use the ``condition`` argument as following.\n\n        .. code-block:: python\n\n            def profile_only_if_c_is_not_none(a, b, c=None, d=None):\n                return c is not None\n\n            @function_profile.profile(condition=profile_only_if_c_is_not_none)\n            def foo(a, b, c=None, d=None):\n                ...\n\n\n    '''\n    if fn is None:\n        def new_decorator(fn):\n            return profile(fn, condition=condition, profile_class=profile_class, print_freq=print_freq, sort_keys=sort_keys, print_restrictions=print_restrictions)\n        return new_decorator\n    profiler = FunctionProfile(fn, condition=condition, profile_class=profile_class,\n                               print_freq=print_freq, sort_keys=sort_keys, print_restrictions=print_restrictions)\n\n    def new_fn(*args, **kw):\n        return profiler(*args, **kw)\n\n    new_fn.__name__ = fn.__name__\n    new_fn.__doc__ = fn.__doc__\n    new_fn.__dict__ = fn.__dict__\n    new_fn.__module__ = fn.__module__\n    new_fn.profiler = profiler\n    return new_fn", "response": "Decorator for functions that are profiled with a Python profiler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_stats(self, reset=True):\n        '''Manually print profiling result.\n\n        Args:\n            reset (bool): If False is specified, the profiling statistics so\n                far is maintained. If ``True`` (default),\n                :obj:`~reset_stats`\n                is called to reset the profiling statistics.\n\n        '''\n        if not self.ncalls:\n            return\n\n        stats = self.stats\n        code = self.fn.__code__\n        print('--- Function Profiling ---')\n        print('File \"{}\", line {}, function {}'.format(\n            code.co_filename,\n            code.co_firstlineno,\n            self.fn.__name__))\n        stats.sort_stats(*self.sort_keys)\n        stats.print_stats(*self.print_restrictions)\n        print('--------------------------')\n        if reset:\n            self.reset_stats()", "response": "Manually print profiling result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a root folder path for downloading models.", "response": "def get_model_home():\n    '''\n    Returns a root folder path for downloading models.\n    '''\n    d = os.path.join(get_data_home(), 'nnp_models')\n    if not os.path.isdir(d):\n        os.makedirs(d)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_model_url_base():\n    '''\n    Returns a root folder for models.\n    '''\n    url_base = get_model_url_base_from_env()\n    if url_base is not None:\n        logger.info('NNBLA_MODELS_URL_BASE is set as {}.'.format(url_base))\n    else:\n        url_base = 'https://nnabla.org/pretrained-models/nnp_models/'\n    return url_base", "response": "Returns a root folder for models."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_image_imread(file, shape=None, max_range=1.0):\n    '''\n    Load image from file like object.\n\n    :param file: Image contents\n    :type file: file like object.\n    :param shape: shape of output array\n        e.g. (3, 128, 192) : n_color, height, width.\n    :type shape: tuple of int\n    :param float max_range: the value of return array ranges from 0 to `max_range`.\n\n    :return: numpy array\n\n    '''\n    img255 = imread(\n        file)  # return value is from zero to 255 (even if the image has 16-bitdepth.)\n\n    if len(img255.shape) == 2:  # gray image\n        height, width = img255.shape\n        if shape is None:\n            out_height, out_width, out_n_color = height, width, 1\n        else:\n            out_n_color, out_height, out_width = shape\n        assert(out_n_color == 1)\n        if out_height != height or out_width != width:\n            # imresize returns 0 to 255 image.\n            img255 = imresize(img255, (out_height, out_width))\n        img255 = img255.reshape((out_n_color, out_height, out_width))\n    elif len(img255.shape) == 3:  # RGB image\n        height, width, n_color = img255.shape\n        if shape is None:\n            out_height, out_width, out_n_color = height, width, n_color\n        else:\n            out_n_color, out_height, out_width = shape\n        assert(out_n_color == n_color)\n        if out_height != height or out_width != width or out_n_color != n_color:\n            # imresize returns 0 to 255 image.\n            img255 = imresize(img255, (out_height, out_width, out_n_color))\n        img255 = img255.transpose(2, 0, 1)\n\n    if max_range < 0 or max_range == 255.0:\n        return img255\n    else:\n        return img255 * (max_range / 255.0)", "response": "Load image from file like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a n - viable object from a CSV file.", "response": "def load_csv(file, shape=None, normalize=False):\n    \"\"\"\n    Load CSV file.\n\n    :param file: CSV file.\n    :type file: file like object\n    :param shape : data array is reshape to this shape.\n    :type shape: tuple of int\n\n    :return: numpy array\n    \"\"\"\n    value_list = []\n    if six.PY2:\n        for row in csv.reader(file):\n            value_list.append(list(map(float, row)))\n    elif six.PY34:\n        for row in csv.reader([l.decode('utf-8') for l in file.readlines()]):\n            value_list.append(list(map(float, row)))\n    if shape is None:\n        return numpy.array(value_list)\n    else:\n        return numpy.array(value_list).reshape(shape)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, vleaf, fpath, cleanup=False, format=None):\n        graph = self.create_graphviz_digraph(vleaf, format=format)\n        graph.render(fpath, cleanup=cleanup)", "response": "Save the graph to a given file path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef view(self, vleaf, fpath=None, cleanup=True, format=None):\n        graph = self.create_graphviz_digraph(vleaf, format=format)\n        graph.view(fpath, cleanup=cleanup)", "response": "View the graph of the variable tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a graphviz. Digraph object given the leaf variable of a iteration.", "response": "def create_graphviz_digraph(self, vleaf, format=None):\n        '''\n        Create a :obj:`graphviz.Digraph` object given the leaf variable of a\n        computation graph.\n\n        One of nice things of getting ``Digraph`` directly is that the drawn\n        graph can be displayed inline in a Jupyter notebook as described in\n        `Graphviz documentation <https://graphviz.readthedocs.io/en/stable/manual.html#jupyter-notebooks>`_.\n\n        Args:\n            vleaf (`nnabla.Variable`):\n                End variable. All variables and functions which can be\n                traversed from this variable are shown in the reuslt.\n            format (str):\n                Force overwrite ``format`` (``'pdf', 'png', ...)``) configuration.\n\n        Returns: graphviz.Digraph\n\n        '''\n        from nnabla import get_parameters\n        import copy\n        try:\n            from graphviz import Digraph\n        except:\n            raise ImportError(\"Install graphviz. `pip install graphviz.`\")\n        if format is None:\n            format = self._format\n        graph = Digraph(format=format)\n        graph.attr(\"node\", style=\"filled\")\n\n        params = get_parameters(grad_only=False)\n        var2name = {v.data: k for k, v in params.items()}\n        fun2scope = {}\n        var2postname = copy.copy(var2name)\n\n        def fscope(f):\n            names = [var2name[v.data] for v in f.inputs if v.data in var2name]\n            if names:\n                c = os.path.commonprefix(names)\n                fun2scope[f] = c\n                for n in names:\n                    var2postname[params[n].data] = n[len(c):]\n        vleaf.visit(fscope)\n        func = self.functor(graph, self._verbose,\n                            fun2scope=fun2scope, var2name=var2postname)\n        vleaf.visit(func)\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_parameters(self, grad_only=True):\n        params = OrderedDict()\n\n        for v in self.get_modules():\n            if not isinstance(v, tuple):\n                continue\n            prefix, module = v\n            for k, v in module.__dict__.items():\n                if not isinstance(v, nn.Variable):\n                    continue\n                pname = k\n                name = \"{}/{}\".format(prefix, pname)\n                if grad_only and v.need_grad == False:\n                    continue\n                params[name] = v\n        return params", "response": "Get parameters.\n        Args:\n            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. \n            If you set this option as `False`, All parameters are returned. Default is `True`.\n        Returns:\n            dict: The dictionary of parameter name (`str`) to Variable (:obj:`~nnabla.Variable`)."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget modules. This function is internally used as the helper method for other methods. Args: memo (set, optional): Module set in order to memorize to visit. prefix (str, optional): Prefix to a specific parameter name. Yields: `Module`: The module class.", "response": "def get_modules(self, memo=None, prefix=\"\"):\n        \"\"\"Get modules.\n\n        This function is internally used as the helper method for other methods.\n\n        Args: \n            memo (set, optional): Module set in order to memorize to visit.\n            prefix (str, optional): Prefix to a specific parameter name.\n\n        Yields:\n            `Module`: The module class.\n        \"\"\"\n        if memo is None:\n            memo = set()\n\n        if self not in memo:\n            memo.add(self)\n            yield prefix, self\n            for k, v in self.__dict__.items():\n                if not isinstance(v, Module):\n                    continue\n                name, module = k, v\n                submodule_prefix = \"{}/{}\".format(prefix,\n                                                  name) if prefix != \"\" else name\n                for m in module.get_modules(memo, submodule_prefix):\n                    yield m"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_parameters(self, path, grad_only=False):\n        params = self.get_parameters(grad_only=grad_only)\n        nn.save_parameters(path, params)", "response": "Save all parameters into a file with the specified format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_parameters(self, path):\n        nn.load_parameters(path)\n        for v in self.get_modules():\n            if not isinstance(v, tuple):\n                continue\n            prefix, module = v\n            for k, v in module.__dict__.items():\n                if not isinstance(v, nn.Variable):\n                    continue\n                pname = k\n                name = \"{}/{}\".format(prefix, pname)\n                # Substitute\n                param0 = v\n                param1 = nn.parameter.pop_parameter(name)\n                if param0 is None:\n                    raise ValueError(\n                        \"Model does not have {} parameter.\".format(name))\n                param0.d = param1.d.copy()\n                nn.logger.info(\"`{}` loaded.)\".format(name))", "response": "Load parameters from a file with the specified format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert(self, vroot, entry_variables):\n        self.graph_info = GraphInfo(vroot)\n        self.entry_variables = entry_variables\n\n        with nn.parameter_scope(self.name):\n            # Function loop in the forward order\n            for t, func in enumerate(self.graph_info.funcs):\n                # TODO: error check\n\n                # Batch normalization check, then skip\n                if func.name == \"BatchNormalization\":\n                    i0 = func.inputs[0]\n                    bn_func = func\n                    # Test mode check\n                    if bn_func.info.args[\"batch_stat\"] == False:\n                        # `Target Func -> BN` check from BN\n                        if i0.parent.info.type_name in self.inner_prod_functions:\n                            nn.logger.info(\"{} is skipped.\".format(func.name))\n                            continue\n\n                # `Target Func -> BN` conversion\n                if func.name in self.inner_prod_functions:\n                    inner_prod_func = func\n\n                    o0 = inner_prod_func.outputs[0]\n                    fs = self.graph_info.variable_to_funcs[o0]\n                    # No branch check #TODO: branching check (really needed?)\n                    if fs is not None and len(fs) == 1:\n                        # `Target Func -> BN` check\n                        bn_func = fs[0]\n                        if bn_func.name == \"BatchNormalization\":\n\n                            # Test mode check\n                            if bn_func.info.args[\"batch_stat\"] == False:\n\n                                # Perform `Target Func -> BN` conversion\n                                nn.logger.info(\"BatchNormalization parameters are folded to \"\n                                               \"the preceding convolution.\")\n                                o = self._inner_prod_bn_conversion(\n                                    inner_prod_func, bn_func)\n                                continue\n\n                # Identity conversion\n                o = self._identity_conversion(func)\n\n        self.end_variable = o\n        return self.end_variable", "response": "This function converts the given vroot into a new function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the integer value to be stored from the hex string", "response": "def get_prep_value(self, value):\n\t\t\"\"\" Return the integer value to be stored from the hex string \"\"\"\n\t\tif value is None or value == \"\":\n\t\t\treturn None\n\t\tif isinstance(value, six.string_types):\n\t\t\tvalue = _hex_string_to_unsigned_integer(value)\n\t\tif _using_signed_storage():\n\t\t\tvalue = _unsigned_to_signed_integer(value)\n\t\treturn value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_db_value(self, value, expression, connection, context):\n\t\tif value is None:\n\t\t\treturn value\n\t\tif _using_signed_storage():\n\t\t\tvalue = _signed_to_unsigned_integer(value)\n\t\treturn value", "response": "Convert a db value to an unsigned int representation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a str representation of the hexadecimal", "response": "def to_python(self, value):\n\t\t\"\"\" Return a str representation of the hexadecimal \"\"\"\n\t\tif isinstance(value, six.string_types):\n\t\t\treturn value\n\t\tif value is None:\n\t\t\treturn value\n\t\treturn _unsigned_integer_to_hex_string(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an APNS notification to a single registration_id. This will send the notification as form data. If sending multiple notifications, it is more efficient to use apns_send_bulk_message() Note that if set alert should always be a string. If it is not set, it won\"t be included in the notification. You will need to pass None to this for silent notifications.", "response": "def apns_send_message(registration_id, alert, application_id=None, certfile=None, **kwargs):\n\t\"\"\"\n\tSends an APNS notification to a single registration_id.\n\tThis will send the notification as form data.\n\tIf sending multiple notifications, it is more efficient to use\n\tapns_send_bulk_message()\n\n\tNote that if set alert should always be a string. If it is not set,\n\tit won\"t be included in the notification. You will need to pass None\n\tto this for silent notifications.\n\t\"\"\"\n\n\ttry:\n\t\t_apns_send(\n\t\t\tregistration_id, alert, application_id=application_id,\n\t\t\tcertfile=certfile, **kwargs\n\t\t)\n\texcept apns2_errors.APNsException as apns2_exception:\n\t\tif isinstance(apns2_exception, apns2_errors.Unregistered):\n\t\t\tdevice = models.APNSDevice.objects.get(registration_id=registration_id)\n\t\t\tdevice.active = False\n\t\t\tdevice.save()\n\n\t\traise APNSServerError(status=apns2_exception.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apns_send_bulk_message(\n\tregistration_ids, alert, application_id=None, certfile=None, **kwargs\n):\n\t\"\"\"\n\tSends an APNS notification to one or more registration_ids.\n\tThe registration_ids argument needs to be a list.\n\n\tNote that if set alert should always be a string. If it is not set,\n\tit won\"t be included in the notification. You will need to pass None\n\tto this for silent notifications.\n\t\"\"\"\n\n\tresults = _apns_send(\n\t\tregistration_ids, alert, batch=True, application_id=application_id,\n\t\tcertfile=certfile, **kwargs\n\t)\n\tinactive_tokens = [token for token, result in results.items() if result == \"Unregistered\"]\n\tmodels.APNSDevice.objects.filter(registration_id__in=inactive_tokens).update(active=False)\n\treturn results", "response": "Sends an APNS notification to one or more registration_ids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a FCM or GCM notification to one or more registration_ids as json data.", "response": "def _cm_send_request(\n\tregistration_ids, data, cloud_type=\"GCM\", application_id=None,\n\tuse_fcm_notifications=True, **kwargs\n):\n\t\"\"\"\n\tSends a FCM or GCM notification to one or more registration_ids as json data.\n\tThe registration_ids needs to be a list.\n\t\"\"\"\n\n\tpayload = {\"registration_ids\": registration_ids} if registration_ids else {}\n\n\tdata = data.copy()\n\n\t# If using FCM, optionnally autodiscovers notification related keys\n\t# https://firebase.google.com/docs/cloud-messaging/concept-options#notifications_and_data_messages\n\tif cloud_type == \"FCM\" and use_fcm_notifications:\n\t\tnotification_payload = {}\n\t\tif \"message\" in data:\n\t\t\tnotification_payload[\"body\"] = data.pop(\"message\", None)\n\n\t\tfor key in FCM_NOTIFICATIONS_PAYLOAD_KEYS:\n\t\t\tvalue_from_extra = data.pop(key, None)\n\t\t\tif value_from_extra:\n\t\t\t\tnotification_payload[key] = value_from_extra\n\t\t\tvalue_from_kwargs = kwargs.pop(key, None)\n\t\t\tif value_from_kwargs:\n\t\t\t\tnotification_payload[key] = value_from_kwargs\n\t\tif notification_payload:\n\t\t\tpayload[\"notification\"] = notification_payload\n\n\tif data:\n\t\tpayload[\"data\"] = data\n\n\t# Attach any additional non falsy keyword args (targets, options)\n\t# See ref : https://firebase.google.com/docs/cloud-messaging/http-server-ref#table1\n\tpayload.update({\n\t\tk: v for k, v in kwargs.items() if v and (k in FCM_TARGETS_KEYS or k in FCM_OPTIONS_KEYS)\n\t})\n\n\t# Sort the keys for deterministic output (useful for tests)\n\tjson_payload = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True).encode(\"utf-8\")\n\n\t# Sends requests and handles the response\n\tif cloud_type == \"GCM\":\n\t\tresponse = json.loads(_gcm_send(\n\t\t\tjson_payload, \"application/json\", application_id=application_id\n\t\t))\n\telif cloud_type == \"FCM\":\n\t\tresponse = json.loads(_fcm_send(\n\t\t\tjson_payload, \"application/json\", application_id=application_id\n\t\t))\n\telse:\n\t\traise ImproperlyConfigured(\"cloud_type must be FCM or GCM not %s\" % str(cloud_type))\n\treturn _cm_handle_response(registration_ids, response, cloud_type, application_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _cm_handle_canonical_id(canonical_id, current_id, cloud_type):\n\tdevices = GCMDevice.objects.filter(cloud_message_type=cloud_type)\n\tif devices.filter(registration_id=canonical_id, active=True).exists():\n\t\tdevices.filter(registration_id=current_id).update(active=False)\n\telse:\n\t\tdevices.filter(registration_id=current_id).update(registration_id=canonical_id)", "response": "Handle case when FCM server response contains canonical ID"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_message(registration_ids, data, cloud_type, application_id=None, **kwargs):\n\tif cloud_type in (\"FCM\", \"GCM\"):\n\t\tmax_recipients = get_manager().get_max_recipients(cloud_type, application_id)\n\telse:\n\t\traise ImproperlyConfigured(\"cloud_type must be FCM or GCM not %s\" % str(cloud_type))\n\n\t# Checks for valid recipient\n\tif registration_ids is None and \"/topics/\" not in kwargs.get(\"to\", \"\"):\n\t\treturn\n\n\t# Bundles the registration_ids in an list if only one is sent\n\tif not isinstance(registration_ids, list):\n\t\tregistration_ids = [registration_ids] if registration_ids else None\n\n\t# FCM only allows up to 1000 reg ids per bulk message\n\t# https://firebase.google.com/docs/cloud-messaging/server#http-request\n\tif registration_ids:\n\t\tret = []\n\t\tfor chunk in _chunks(registration_ids, max_recipients):\n\t\t\tret.append(_cm_send_request(\n\t\t\t\tchunk, data, cloud_type=cloud_type, application_id=application_id, **kwargs\n\t\t\t))\n\t\treturn ret[0] if len(ret) == 1 else ret\n\telse:\n\t\treturn _cm_send_request(None, data, cloud_type=cloud_type, **kwargs)", "response": "Sends a FCM or GCM notification to one or more registration_ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_applications(self, apps):\n\t\tfor application_id, application_config in apps.items():\n\t\t\tself._validate_config(application_id, application_config)\n\n\t\t\tapplication_config[\"APPLICATION_ID\"] = application_id", "response": "Validate the application collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the APNS certificate at startup.", "response": "def _validate_apns_certificate(self, certfile):\n\t\t\"\"\"Validate the APNS certificate at startup.\"\"\"\n\n\t\ttry:\n\t\t\twith open(certfile, \"r\") as f:\n\t\t\t\tcontent = f.read()\n\t\t\t\tcheck_apns_certificate(content)\n\t\texcept Exception as e:\n\t\t\traise ImproperlyConfigured(\n\t\t\t\t\"The APNS certificate file at %r is not readable: %s\" % (certfile, e)\n\t\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfirm only allowed settings are present.", "response": "def _validate_allowed_settings(self, application_id, application_config, allowed_settings):\n\t\t\"\"\"Confirm only allowed settings are present.\"\"\"\n\n\t\tfor setting_key in application_config.keys():\n\t\t\tif setting_key not in allowed_settings:\n\t\t\t\traise ImproperlyConfigured(\n\t\t\t\t\t\"Platform {}, app {} does not support the setting: {}.\".format(\n\t\t\t\t\t\tapplication_config[\"PLATFORM\"], application_id, setting_key\n\t\t\t\t\t)\n\t\t\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that all required settings are present in application_config.", "response": "def _validate_required_settings(\n\t\tself, application_id, application_config, required_settings\n\t):\n\t\t\"\"\"All required keys must be present\"\"\"\n\n\t\tfor setting_key in required_settings:\n\t\t\tif setting_key not in application_config.keys():\n\t\t\t\traise ImproperlyConfigured(\n\t\t\t\t\tMISSING_SETTING.format(\n\t\t\t\t\t\tapplication_id=application_id, setting=setting_key\n\t\t\t\t\t)\n\t\t\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the value of a setting for an application.", "response": "def _get_application_settings(self, application_id, platform, settings_key):\n\t\t\"\"\"\n\t\tWalks through PUSH_NOTIFICATIONS_SETTINGS to find the correct setting value\n\t\tor raises ImproperlyConfigured.\n\t\t\"\"\"\n\n\t\tif not application_id:\n\t\t\tconf_cls = \"push_notifications.conf.AppConfig\"\n\t\t\traise ImproperlyConfigured(\n\t\t\t\t\"{} requires the application_id be specified at all times.\".format(conf_cls)\n\t\t\t)\n\n\t\t# verify that the application config exists\n\t\tapp_config = self._settings.get(\"APPLICATIONS\").get(application_id, None)\n\t\tif app_config is None:\n\t\t\traise ImproperlyConfigured(\n\t\t\t\t\"No application configured with application_id: {}.\".format(application_id)\n\t\t\t)\n\n\t\t# fetch a setting for the incorrect type of platform\n\t\tif app_config.get(\"PLATFORM\") != platform:\n\t\t\traise ImproperlyConfigured(\n\t\t\t\tSETTING_MISMATCH.format(\n\t\t\t\t\tapplication_id=application_id,\n\t\t\t\t\tplatform=app_config.get(\"PLATFORM\"),\n\t\t\t\t\tsetting=settings_key\n\t\t\t\t)\n\t\t\t)\n\n\t\t# finally, try to fetch the setting\n\t\tif settings_key not in app_config:\n\t\t\traise ImproperlyConfigured(\n\t\t\t\tMISSING_SETTING.format(\n\t\t\t\t\tapplication_id=application_id, setting=settings_key\n\t\t\t\t)\n\t\t\t)\n\n\t\treturn app_config.get(settings_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_messages(self, request, queryset, bulk=False):\n\t\tret = []\n\t\terrors = []\n\t\tr = \"\"\n\n\t\tfor device in queryset:\n\t\t\ttry:\n\t\t\t\tif bulk:\n\t\t\t\t\tr = queryset.send_message(\"Test bulk notification\")\n\t\t\t\telse:\n\t\t\t\t\tr = device.send_message(\"Test single notification\")\n\t\t\t\tif r:\n\t\t\t\t\tret.append(r)\n\t\t\texcept GCMError as e:\n\t\t\t\terrors.append(str(e))\n\t\t\texcept APNSServerError as e:\n\t\t\t\terrors.append(e.status)\n\t\t\texcept WebPushError as e:\n\t\t\t\terrors.append(e.message)\n\n\t\t\tif bulk:\n\t\t\t\tbreak\n\n\t\t# Because NotRegistered and InvalidRegistration do not throw GCMError\n\t\t# catch them here to display error msg.\n\t\tif not bulk:\n\t\t\tfor r in ret:\n\t\t\t\tif \"error\" in r[\"results\"][0]:\n\t\t\t\t\terrors.append(r[\"results\"][0][\"error\"])\n\t\telse:\n\t\t\ttry:\n\t\t\t\terrors = [r[\"error\"] for r in ret[0][0][\"results\"] if \"error\" in r]\n\t\t\texcept TypeError:\n\t\t\t\tfor entry in ret[0][0]:\n\t\t\t\t\terrors = errors + [r[\"error\"] for r in entry[\"results\"] if \"error\" in r]\n\t\t\texcept IndexError:\n\t\t\t\tpass\n\t\tif errors:\n\t\t\tself.message_user(\n\t\t\t\trequest, _(\"Some messages could not be processed: %r\" % (\", \".join(errors))),\n\t\t\t\tlevel=messages.ERROR\n\t\t\t)\n\t\tif ret:\n\t\t\tif bulk:\n\t\t\t\t# When the queryset exceeds the max_recipients value, the\n\t\t\t\t# send_message method returns a list of dicts, one per chunk\n\t\t\t\ttry:\n\t\t\t\t\tsuccess = ret[0][0][\"success\"]\n\t\t\t\texcept TypeError:\n\t\t\t\t\tsuccess = 0\n\t\t\t\t\tfor entry in ret[0][0]:\n\t\t\t\t\t\tsuccess = success + entry[\"success\"]\n\t\t\t\tif success == 0:\n\t\t\t\t\treturn\n\t\t\telif len(errors) == len(ret):\n\t\t\t\treturn\n\t\t\tif errors:\n\t\t\t\tmsg = _(\"Some messages were sent: %s\" % (ret))\n\t\t\telse:\n\t\t\t\tmsg = _(\"All messages were sent: %s\" % (ret))\n\t\t\tself.message_user(request, msg)", "response": "Send messages to the device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting an Access token for WNS communication.", "response": "def _wns_authenticate(scope=\"notify.windows.com\", application_id=None):\n\t\"\"\"\n\tRequests an Access token for WNS communication.\n\n\t:return: dict: {'access_token': <str>, 'expires_in': <int>, 'token_type': 'bearer'}\n\t\"\"\"\n\tclient_id = get_manager().get_wns_package_security_id(application_id)\n\tclient_secret = get_manager().get_wns_secret_key(application_id)\n\tif not client_id:\n\t\traise ImproperlyConfigured(\n\t\t\t'You need to set PUSH_NOTIFICATIONS_SETTINGS[\"WNS_PACKAGE_SECURITY_ID\"] to use WNS.'\n\t\t)\n\n\tif not client_secret:\n\t\traise ImproperlyConfigured(\n\t\t\t'You need to set PUSH_NOTIFICATIONS_SETTINGS[\"WNS_SECRET_KEY\"] to use WNS.'\n\t\t)\n\n\theaders = {\n\t\t\"Content-Type\": \"application/x-www-form-urlencoded\",\n\t}\n\tparams = {\n\t\t\"grant_type\": \"client_credentials\",\n\t\t\"client_id\": client_id,\n\t\t\"client_secret\": client_secret,\n\t\t\"scope\": scope,\n\t}\n\tdata = urlencode(params).encode(\"utf-8\")\n\n\trequest = Request(SETTINGS[\"WNS_ACCESS_URL\"], data=data, headers=headers)\n\ttry:\n\t\tresponse = urlopen(request)\n\texcept HTTPError as err:\n\t\tif err.code == 400:\n\t\t\t# One of your settings is probably jacked up.\n\t\t\t# https://msdn.microsoft.com/en-us/library/windows/apps/xaml/hh868245\n\t\t\traise WNSAuthenticationError(\"Authentication failed, check your WNS settings.\")\n\t\traise err\n\n\toauth_data = response.read().decode(\"utf-8\")\n\ttry:\n\t\toauth_data = json.loads(oauth_data)\n\texcept Exception:\n\t\t# Upstream WNS issue\n\t\traise WNSAuthenticationError(\"Received invalid JSON data from WNS.\")\n\n\taccess_token = oauth_data.get(\"access_token\")\n\tif not access_token:\n\t\t# Upstream WNS issue\n\t\traise WNSAuthenticationError(\"Access token missing from WNS response.\")\n\n\treturn access_token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _wns_send(uri, data, wns_type=\"wns/toast\", application_id=None):\n\taccess_token = _wns_authenticate(application_id=application_id)\n\n\tcontent_type = \"text/xml\"\n\tif wns_type == \"wns/raw\":\n\t\tcontent_type = \"application/octet-stream\"\n\n\theaders = {\n\t\t# content_type is \"text/xml\" (toast/badge/tile) | \"application/octet-stream\" (raw)\n\t\t\"Content-Type\": content_type,\n\t\t\"Authorization\": \"Bearer %s\" % (access_token),\n\t\t\"X-WNS-Type\": wns_type,  # wns/toast | wns/badge | wns/tile | wns/raw\n\t}\n\n\tif type(data) is str:\n\t\tdata = data.encode(\"utf-8\")\n\n\trequest = Request(uri, data, headers)\n\n\t# A lot of things can happen, let them know which one.\n\ttry:\n\t\tresponse = urlopen(request)\n\texcept HTTPError as err:\n\t\tif err.code == 400:\n\t\t\tmsg = \"One or more headers were specified incorrectly or conflict with another header.\"\n\t\telif err.code == 401:\n\t\t\tmsg = \"The cloud service did not present a valid authentication ticket.\"\n\t\telif err.code == 403:\n\t\t\tmsg = \"The cloud service is not authorized to send a notification to this URI.\"\n\t\telif err.code == 404:\n\t\t\tmsg = \"The channel URI is not valid or is not recognized by WNS.\"\n\t\telif err.code == 405:\n\t\t\tmsg = \"Invalid method. Only POST or DELETE is allowed.\"\n\t\telif err.code == 406:\n\t\t\tmsg = \"The cloud service exceeded its throttle limit\"\n\t\telif err.code == 410:\n\t\t\tmsg = \"The channel expired.\"\n\t\telif err.code == 413:\n\t\t\tmsg = \"The notification payload exceeds the 500 byte limit.\"\n\t\telif err.code == 500:\n\t\t\tmsg = \"An internal failure caused notification delivery to fail.\"\n\t\telif err.code == 503:\n\t\t\tmsg = \"The server is currently unavailable.\"\n\t\telse:\n\t\t\traise err\n\t\traise WNSNotificationResponseError(\"HTTP %i: %s\" % (err.code, msg))\n\n\treturn response.read().decode(\"utf-8\")", "response": "Send a notification to the WNS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the xml tree for a `toast` notification :param data: dict: The notification data to be converted to an xml tree. { \"text\": [\"Title text\", \"Message Text\", \"Another message!\"], \"image\": [\"src1\", \"src2\"], } :return: str", "response": "def _wns_prepare_toast(data, **kwargs):\n\t\"\"\"\n\tCreates the xml tree for a `toast` notification\n\n\t:param data: dict: The notification data to be converted to an xml tree.\n\n\t{\n\t\t\"text\": [\"Title text\", \"Message Text\", \"Another message!\"],\n\t\t\"image\": [\"src1\", \"src2\"],\n\t}\n\n\t:return: str\n\t\"\"\"\n\troot = ET.Element(\"toast\")\n\tvisual = ET.SubElement(root, \"visual\")\n\tbinding = ET.SubElement(visual, \"binding\")\n\tbinding.attrib[\"template\"] = kwargs.pop(\"template\", \"ToastText01\")\n\tif \"text\" in data:\n\t\tfor count, item in enumerate(data[\"text\"], start=1):\n\t\t\telem = ET.SubElement(binding, \"text\")\n\t\t\telem.text = item\n\t\t\telem.attrib[\"id\"] = str(count)\n\tif \"image\" in data:\n\t\tfor count, item in enumerate(data[\"image\"], start=1):\n\t\t\telem = ET.SubElement(binding, \"img\")\n\t\t\telem.attrib[\"src\"] = item\n\t\t\telem.attrib[\"id\"] = str(count)\n\treturn ET.tostring(root)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a notification request to WNS. There are four notification types that WNS can send: toast, tile, badge and raw. Toast, tile, and badge can all be customized to use different templates/icons/sounds/launch params/etc. See docs for more information: https://msdn.microsoft.com/en-us/library/windows/apps/br212853.aspx There are multiple ways to input notification data: 1. The simplest and least custom notification to send is to just pass a string to `message`. This will create a toast notification with one text element. e.g.: \"This is my notification title\" 2. You can also pass a dictionary to `message`: it can only contain one or both keys: [\"text\", \"image\"]. The value of each key must be a list with the text and src respectively. e.g.: { \"text\": [\"text1\", \"text2\"], \"image\": [\"src1\", \"src2\"], } 3. Passing a dictionary to `xml_data` will create one of three types of notifications depending on the dictionary data (toast, tile, badge). See `dict_to_xml_schema` docs for more information on dictionary formatting. 4. Passing a value to `raw_data` will create a `raw` notification and send the input data as is. :param uri: str: The device's unique notification uri. :param message: str|dict: The notification data to be sent. :param xml_data: dict: A dictionary containing data to be converted to an xml tree. :param raw_data: str: Data to be sent via a `raw` notification.", "response": "def wns_send_message(\n\turi, message=None, xml_data=None, raw_data=None, application_id=None, **kwargs\n):\n\t\"\"\"\n\tSends a notification request to WNS.\n\tThere are four notification types that WNS can send: toast, tile, badge and raw.\n\tToast, tile, and badge can all be customized to use different\n\ttemplates/icons/sounds/launch params/etc.\n\tSee docs for more information:\n\thttps://msdn.microsoft.com/en-us/library/windows/apps/br212853.aspx\n\n\tThere are multiple ways to input notification data:\n\n\t1. The simplest and least custom notification to send is to just pass a string\n\tto `message`. This will create a toast notification with one text element. e.g.:\n\t\t\"This is my notification title\"\n\n\t2. You can also pass a dictionary to `message`: it can only contain one or both\n\tkeys: [\"text\", \"image\"]. The value of each key must be a list with the text and\n\tsrc respectively. e.g.:\n\t\t{\n\t\t\t\"text\": [\"text1\", \"text2\"],\n\t\t\t\"image\": [\"src1\", \"src2\"],\n\t\t}\n\n\t3. Passing a dictionary to `xml_data` will create one of three types of\n\tnotifications depending on the dictionary data (toast, tile, badge).\n\tSee `dict_to_xml_schema` docs for more information on dictionary formatting.\n\n\t4. Passing a value to `raw_data` will create a `raw` notification and send the\n\tinput data as is.\n\n\t:param uri: str: The device's unique notification uri.\n\t:param message: str|dict: The notification data to be sent.\n\t:param xml_data: dict: A dictionary containing data to be converted to an xml tree.\n\t:param raw_data: str: Data to be sent via a `raw` notification.\n\t\"\"\"\n\t# Create a simple toast notification\n\tif message:\n\t\twns_type = \"wns/toast\"\n\t\tif isinstance(message, str):\n\t\t\tmessage = {\n\t\t\t\t\"text\": [message, ],\n\t\t\t}\n\t\tprepared_data = _wns_prepare_toast(data=message, **kwargs)\n\t# Create a toast/tile/badge notification from a dictionary\n\telif xml_data:\n\t\txml = dict_to_xml_schema(xml_data)\n\t\twns_type = \"wns/%s\" % xml.tag\n\t\tprepared_data = ET.tostring(xml)\n\t# Create a raw notification\n\telif raw_data:\n\t\twns_type = \"wns/raw\"\n\t\tprepared_data = raw_data\n\telse:\n\t\traise TypeError(\n\t\t\t\"At least one of the following parameters must be set:\"\n\t\t\t\"`message`, `xml_data`, `raw_data`\"\n\t\t)\n\n\treturn _wns_send(\n\t\turi=uri, data=prepared_data, wns_type=wns_type, application_id=application_id\n\t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict_to_xml_schema(data):\n\tfor key, value in data.items():\n\t\troot = _add_element_attrs(ET.Element(key), value.get(\"attrs\", {}))\n\t\tchildren = value.get(\"children\", None)\n\t\tif isinstance(children, dict):\n\t\t\t_add_sub_elements_from_dict(root, children)\n\t\treturn root", "response": "This function converts a dictionary to XML schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds SubElements to the parent element.", "response": "def _add_sub_elements_from_dict(parent, sub_dict):\n\t\"\"\"\n\tAdd SubElements to the parent element.\n\n\t:param parent: ElementTree.Element: The parent element for the newly created SubElement.\n\t:param sub_dict: dict: Used to create a new SubElement. See `dict_to_xml_schema`\n\tmethod docstring for more information. e.g.:\n\t\t{\"example\": {\n\t\t\t\"attrs\": {\n\t\t\t\t\"key1\": \"value1\",\n\t\t\t\t...\n\t\t\t},\n\t\t\t...\n\t\t}}\n\t\"\"\"\n\tfor key, value in sub_dict.items():\n\t\tif isinstance(value, list):\n\t\t\tfor repeated_element in value:\n\t\t\t\tsub_element = ET.SubElement(parent, key)\n\t\t\t\t_add_element_attrs(sub_element, repeated_element.get(\"attrs\", {}))\n\t\t\t\tchildren = repeated_element.get(\"children\", None)\n\t\t\t\tif isinstance(children, dict):\n\t\t\t\t\t_add_sub_elements_from_dict(sub_element, children)\n\t\t\t\telif isinstance(children, str):\n\t\t\t\t\tsub_element.text = children\n\t\telse:\n\t\t\tsub_element = ET.SubElement(parent, key)\n\t\t\t_add_element_attrs(sub_element, value.get(\"attrs\", {}))\n\t\t\tchildren = value.get(\"children\", None)\n\t\t\tif isinstance(children, dict):\n\t\t\t\t_add_sub_elements_from_dict(sub_element, children)\n\t\t\telif isinstance(children, str):\n\t\t\t\tsub_element.text = children"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_element_attrs(elem, attrs):\n\tfor attr, value in attrs.items():\n\t\telem.attrib[attr] = value\n\treturn elem", "response": "Adds attributes to the given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates with Skydive and set the authentication cookie to be used in the future requests .", "response": "def login(self, host_spec=\"\", username=\"\", password=\"\"):\n        \"\"\" Authenticate with infrastructure via the Skydive analyzer\n\n        This method will also set the authentication cookie to be used in\n        the future requests\n        :param host_spec: Host IP and port (e.g. 192.168.10.1:8082)\n        :type host_spec: string\n        :param username: Username to use for login\n        :type username: string\n        :param password: Password to use for login\n        :type password: string\n        :return: True on successful authentication, False otherwise\n        \"\"\"\n\n        warnings.warn(\n            \"shouldn't use this function anymore ! use connect which handles\"\n            \"handles authentication directly.\",\n            DeprecationWarning\n        )\n\n        scheme = \"http\"\n        if not host_spec:\n            u = urlparse(self.endpoint)\n            host_spec = u.netloc\n            if u.scheme == \"wss\":\n                scheme = \"https\"\n            if self.username:\n                username = self.username\n            if self.password:\n                password = self.password\n\n        auth = Authenticate(host_spec, scheme=scheme,\n                            username=username, password=password)\n        try:\n            auth.login()\n            cookie = 'authtok={}'.format(auth.authtok)\n            if self.cookies:\n                self.cookies.append(cookie)\n            else:\n                self.cookies = [cookie, ]\n            return True\n        except Exception:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sdkmanager(self, *args, **kwargs):\n        # Use the android-sdk dir as cwd by default\n        kwargs['cwd'] = kwargs.get('cwd', self.android_sdk_dir)\n        command = self.sdkmanager_path + ' ' + ' '.join(args)\n        return_child = kwargs.pop('return_child', False)\n        if return_child:\n            return self.buildozer.cmd_expect(command, **kwargs)\n        else:\n            kwargs['get_stdout'] = kwargs.get('get_stdout', True)\n            return self.buildozer.cmd(command, **kwargs)", "response": "Call the sdkmanager in our Android SDK with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlocate the java file.", "response": "def _locate_java(self, s):\n        '''If JAVA_HOME is in the environ, return $JAVA_HOME/bin/s. Otherwise,\n        return s.\n        '''\n        if 'JAVA_HOME' in self.buildozer.environ:\n            return join(self.buildozer.environ['JAVA_HOME'], 'bin', s)\n        else:\n            return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _android_get_installed_platform_tools_version(self):\n\n        platform_tools_dir = os.path.join(\n            self.android_sdk_dir,\n            'platform-tools')\n\n        if not os.path.exists(platform_tools_dir):\n            return None\n\n        data_file = os.path.join(platform_tools_dir, 'source.properties')\n        if not os.path.exists(data_file):\n            return None\n\n        with open(data_file, 'r') as fileh:\n            lines = fileh.readlines()\n\n        for line in lines:\n            if line.startswith('Pkg.Revision='):\n                break\n        else:\n            self.buildozer.error('Read {} but found no Pkg.Revision'.format(data_file))\n            # Don't actually exit, in case the build env is\n            # okay. Something else will fault if it's important.\n            return None\n\n        revision = line.split('=')[1].strip()\n\n        return revision", "response": "Crudely parse out the installed platform - tools version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _android_update_sdk(self, *sdkmanager_commands):\n        auto_accept_license = self.buildozer.config.getbooldefault(\n            'app', 'android.accept_sdk_license', False)\n\n        if auto_accept_license:\n            # `SIGPIPE` is not being reported somehow, but `EPIPE` is.\n            # This leads to a stderr \"Broken pipe\" message which is harmless,\n            # but doesn't look good on terminal, hence redirecting to /dev/null\n            yes_command = 'yes 2>/dev/null'\n            command = '{} | {} --licenses'.format(\n                yes_command, self.sdkmanager_path)\n            self.buildozer.cmd(command, cwd=self.android_sdk_dir)\n        self._sdkmanager(*sdkmanager_commands)", "response": "Update the tools and package - tools"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning p4a commands. Args must come after --, or use --alias to make an alias", "response": "def cmd_p4a(self, *args):\n        '''\n        Run p4a commands. Args must come after --, or\n        use --alias to make an alias\n        '''\n        self.check_requirements()\n        self.install_platform()\n        args = args[0]\n        if args and args[0] == '--alias':\n            print('To set up p4a in this shell session, execute:')\n            print('    alias p4a=$(buildozer {} p4a --alias 2>&1 >/dev/null)'\n                  .format(self.targetname))\n            sys.stderr.write('PYTHONPATH={} {}\\n'.format(self.pa_dir, self._p4a_cmd))\n        else:\n            self._p4a(' '.join(args) if args else '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd_adb(self, *args):\n        '''\n        Run adb from the Android SDK.\n        Args must come after --, or use\n        --alias to make an alias\n        '''\n        self.check_requirements()\n        self.install_platform()\n        args = args[0]\n        if args and args[0] == '--alias':\n            print('To set up ADB in this shell session, execute:')\n            print('    alias adb=$(buildozer {} adb --alias 2>&1 >/dev/null)'\n                  .format(self.targetname))\n            sys.stderr.write(self.adb_cmd + '\\n')\n        else:\n            self.buildozer.cmd(' '.join([self.adb_cmd] + args))", "response": "Run ADB from Android SDK."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd_logcat(self, *args):\n        '''Show the log from the device\n        '''\n        self.check_requirements()\n        serial = self.serials[0:]\n        if not serial:\n            return\n        filters = self.buildozer.config.getrawdefault(\n            \"app\", \"android.logcat_filters\", \"\", section_sep=\":\", split_char=\" \")\n        filters = \" \".join(filters)\n        self.buildozer.environ['ANDROID_SERIAL'] = serial[0]\n        self.buildozer.cmd('{adb} logcat {filters}'.format(adb=self.adb_cmd,\n                                                           filters=filters),\n                           cwd=self.buildozer.global_platform_dir,\n                           show_output=True)\n        self.buildozer.environ.pop('ANDROID_SERIAL', None)", "response": "Show the log from the device\n ArcGIS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path_or_git_url(self, repo, owner='kivy', branch='master',\n                        url_format='https://github.com/{owner}/{repo}.git',\n                        platform=None,\n                        squash_hyphen=True):\n        \"\"\"Get source location for a git checkout\n\n        This method will check the `buildozer.spec` for the keys:\n            {repo}_dir\n            {repo}_url\n            {repo}_branch\n\n        and use them to determine the source location for a git checkout.\n\n        If a `platform` is specified, {platform}.{repo} will be used\n        as the base for the buildozer key\n\n        `{repo}_dir` specifies a custom checkout location\n        (relative to `buildozer.root_dir`). If present, `path` will be\n        set to this value and `url`, `branch` will be set to None,\n        None. Otherwise, `{repo}_url` and `{repo}_branch` will be\n        examined.\n\n        If no keys are present, the kwargs will be used to create\n        a sensible default URL and branch.\n\n        :Parameters:\n            `repo`: str (required)\n                name of repository to fetch. Used both for buildozer\n                keys ({platform}.{repo}_dir|_url|_branch) and in building\n                default git URL\n            `branch`: str (default 'master')\n                Specific branch to retrieve if none specified in\n                buildozer.spec.\n            `owner`: str\n                owner of repo.\n            `platform`: str or None\n                platform prefix to use when retrieving `buildozer.spec`\n                keys. If specified, key names will be {platform}.{repo}\n                instead of just {repo}\n            `squash_hyphen`: boolean\n                if True, change '-' to '_' when looking for\n                keys in buildozer.spec. This lets us keep backwards\n                compatibility with old buildozer.spec files\n            `url_format`: format string\n                Used to construct default git URL.\n                can use {repo} {owner} and {branch} if needed.\n\n        :Returns:\n            A Tuple (path, url, branch) where\n                `path`\n                    Path to a custom git checkout. If specified,\n                    both `url` and `branch` will be None\n                `url`\n                    URL of git repository from where code should be\n                    checked-out\n                `branch`\n                    branch name (or tag) that should be used for the\n                    check-out.\n\n        \"\"\"\n        if squash_hyphen:\n            key = repo.replace('-', '_')\n        else:\n            key = repo\n        if platform:\n            key = \"{}.{}\".format(platform, key)\n        config = self.buildozer.config\n        path = config.getdefault('app', '{}_dir'.format(key), None)\n\n        if path is not None:\n            path = join(self.buildozer.root_dir, path)\n            url = None\n            branch = None\n        else:\n            branch = config.getdefault('app', '{}_branch'.format(key), branch)\n            default_url = url_format.format(owner=owner, repo=repo, branch=branch)\n            url = config.getdefault('app', '{}_url'.format(key), default_url)\n            if branch != 'master':\n                url = \"--branch {} {}\".format(branch, url)\n        return path, url, branch", "response": "This method returns the path or git URL of a git checkout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninstall or update a git repository into the platform directory.", "response": "def install_or_update_repo(self, repo, **kwargs):\n        \"\"\"Install or update a git repository into the platform directory.\n\n        This will clone the contents of a git repository to\n        `buildozer.platform_dir`. The location of this repo can be\n        speficied via URL and branch name, or via a custom (local)\n        directory name.\n\n        :Parameters:\n            **kwargs:\n                Any valid arguments for :meth:`path_or_git_url`\n\n        :Returns:\n            fully qualified path to updated git repo\n        \"\"\"\n        cmd = self.buildozer.cmd\n        install_dir = join(self.buildozer.platform_dir, repo)\n        custom_dir, clone_url, clone_branch = self.path_or_git_url(repo, **kwargs)\n        if not self.buildozer.file_exists(install_dir):\n            if custom_dir:\n                cmd('mkdir -p \"{}\"'.format(install_dir))\n                cmd('cp -a \"{}\"/* \"{}\"/'.format(custom_dir, install_dir))\n            else:\n                cmd('git clone {}'.format(clone_url),\n                        cwd=self.buildozer.platform_dir)\n        elif self.platform_update:\n            if custom_dir:\n                cmd('cp -a \"{}\"/* \"{}\"/'.format(custom_dir, install_dir))\n            else:\n                cmd('git clean -dxf', cwd=install_dir)\n                cmd('git pull origin {}'.format(clone_branch), cwd=install_dir)\n        return install_dir"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a ConfigParser and sets the config variable to the env value.", "response": "def set_config_from_envs(config):\n    '''Takes a ConfigParser, and checks every section/token for an\n    environment variable of the form SECTION_TOKEN, with any dots\n    replaced by underscores. If the variable exists, sets the config\n    variable to the env value.\n    '''\n    for section in config.sections():\n        for token in config.options(section):\n            set_config_token_from_env(section, token, config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the config entry to the value of the given section and token from the environment variable.", "response": "def set_config_token_from_env(section, token, config):\n    '''Given a config section and token, checks for an appropriate\n    environment variable. If the variable exists, sets the config entry to\n    its value.\n\n    The environment variable checked is of the form SECTION_TOKEN, all\n    upper case, with any dots replaced by underscores.\n\n    Returns True if the environment variable exists and was used, or\n    False otherwise.\n\n    '''\n    env_var_name = ''.join([section.upper(), '_',\n                            token.upper().replace('.', '_')])\n    env_var = os.environ.get(env_var_name)\n    if env_var is None:\n        return False\n    config.set(section, token, env_var)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the target to use", "response": "def set_target(self, target):\n        '''Set the target to use (one of buildozer.targets, such as \"android\")\n        '''\n        self.targetname = target\n        m = __import__('buildozer.targets.{0}'.format(target),\n                       fromlist=['buildozer'])\n        self.target = m.get_target(self)\n        self.check_build_layout()\n        self.check_configuration_tokens()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build(self):\n        '''Do the build.\n\n        The target can set build_mode to 'release' or 'debug' before calling\n        this method.\n\n        (:meth:`prepare_for_build` must have been call before.)\n        '''\n        assert(self.target is not None)\n        assert(hasattr(self.target, '_build_prepared'))\n\n        if hasattr(self.target, '_build_done'):\n            return\n\n        # increment the build number\n        self.build_id = int(self.state.get('cache.build_id', '0')) + 1\n        self.state['cache.build_id'] = str(self.build_id)\n\n        self.info('Build the application #{}'.format(self.build_id))\n        self.build_application()\n\n        self.info('Package the application')\n        self.target.build_package()\n\n        # flag to prevent multiple build\n        self.target._build_done = True", "response": "Do the build.\n\n        The target can set build_mode to 'release' or 'debug' before calling\n        this method.\n\n        (:meth:`prepare_for_build` must have been call before.)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping env into debug logger in readable format", "response": "def log_env(self, level, env):\n        \"\"\"dump env into debug logger in readable format\"\"\"\n        self.log(level, \"ENVIRONMENT:\")\n        for k, v in env.items():\n            self.log(level, \"    {} = {}\".format(k, pformat(v)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring the spec file is correct.", "response": "def check_configuration_tokens(self):\n        '''Ensure the spec file is 'correct'.\n        '''\n        self.info('Check configuration tokens')\n        self.migrate_configuration_tokens()\n        get = self.config.getdefault\n        errors = []\n        adderror = errors.append\n        if not get('app', 'title', ''):\n            adderror('[app] \"title\" is missing')\n        if not get('app', 'source.dir', ''):\n            adderror('[app] \"source.dir\" is missing')\n\n        package_name = get('app', 'package.name', '')\n        if not package_name:\n            adderror('[app] \"package.name\" is missing')\n        elif package_name[0] in map(str, range(10)):\n            adderror('[app] \"package.name\" may not start with a number.')\n\n        version = get('app', 'version', '')\n        version_regex = get('app', 'version.regex', '')\n        if not version and not version_regex:\n            adderror('[app] One of \"version\" or \"version.regex\" must be set')\n        if version and version_regex:\n            adderror('[app] Conflict between \"version\" and \"version.regex\"'\n                     ', only one can be used.')\n        if version_regex and not get('app', 'version.filename', ''):\n            adderror('[app] \"version.filename\" is missing'\n                     ', required by \"version.regex\"')\n\n        orientation = get('app', 'orientation', 'landscape')\n        if orientation not in ('landscape', 'portrait', 'all', 'sensorLandscape'):\n            adderror('[app] \"orientation\" have an invalid value')\n\n        if errors:\n            self.error('{0} error(s) found in the buildozer.spec'.format(\n                len(errors)))\n            for error in errors:\n                print(error)\n            exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures the build directory layout and files are ready.", "response": "def check_build_layout(self):\n        '''Ensure the build (local and global) directory layout and files are\n        ready.\n        '''\n        self.info('Ensure build layout')\n\n        if not exists(self.specfilename):\n            print('No {0} found in the current directory. Abandon.'.format(\n                self.specfilename))\n            exit(1)\n\n        # create global dir\n        self.mkdir(self.global_buildozer_dir)\n        self.mkdir(self.global_cache_dir)\n\n        # create local .buildozer/ dir\n        self.mkdir(self.buildozer_dir)\n        # create local bin/ dir\n        self.mkdir(self.bin_dir)\n\n        self.mkdir(self.applibs_dir)\n        self.state = JsonStore(join(self.buildozer_dir, 'state.db'))\n\n        target = self.targetname\n        if target:\n            self.mkdir(join(self.global_platform_dir, target, 'platform'))\n            self.mkdir(join(self.buildozer_dir, target, 'platform'))\n            self.mkdir(join(self.buildozer_dir, target, 'app'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_application_requirements(self):\n        '''Ensure the application requirements are all available and ready to be\n        packaged as well.\n        '''\n        requirements = self.config.getlist('app', 'requirements', '')\n        target_available_packages = self.target.get_available_packages()\n        if target_available_packages is True:\n            # target handles all packages!\n            return\n\n        # remove all the requirements that the target can compile\n        onlyname = lambda x: x.split('==')[0]  # noqa: E731\n        requirements = [x for x in requirements if onlyname(x) not in\n                        target_available_packages]\n\n        if requirements and hasattr(sys, 'real_prefix'):\n            e = self.error\n            e('virtualenv is needed to install pure-Python modules, but')\n            e('virtualenv does not support nesting, and you are running')\n            e('buildozer in one. Please run buildozer outside of a')\n            e('virtualenv instead.')\n            exit(1)\n\n        # did we already installed the libs ?\n        if (\n            exists(self.applibs_dir) and\n            self.state.get('cache.applibs', '') == requirements\n        ):\n            self.debug('Application requirements already installed, pass')\n            return\n\n        # recreate applibs\n        self.rmdir(self.applibs_dir)\n        self.mkdir(self.applibs_dir)\n\n        # ok now check the availability of all requirements\n        for requirement in requirements:\n            self._install_application_requirement(requirement)\n\n        # everything goes as expected, save this state!\n        self.state['cache.applibs'] = requirements", "response": "Ensure the application requirements are all available and ready to be packaged as well."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_garden_requirements(self):\n        '''Ensure required garden packages are available to be included.\n        '''\n        garden_requirements = self.config.getlist('app',\n                'garden_requirements', '')\n\n        # have we installed the garden packages?\n        if exists(self.gardenlibs_dir) and \\\n                self.state.get('cache.gardenlibs', '') == garden_requirements:\n            self.debug('Garden requirements already installed, pass')\n            return\n\n        # we're going to reinstall all the garden libs.\n        self.rmdir(self.gardenlibs_dir)\n\n        # but if we don't have requirements, or if the user removed everything,\n        # don't do anything.\n        if not garden_requirements:\n            self.state['cache.gardenlibs'] = garden_requirements\n            return\n\n        self._ensure_virtualenv()\n        self.cmd('pip install Kivy-Garden==0.1.1', env=self.env_venv)\n\n        # recreate gardenlibs\n        self.mkdir(self.gardenlibs_dir)\n\n        for requirement in garden_requirements:\n            self._install_garden_package(requirement)\n\n        # save gardenlibs state\n        self.state['cache.gardenlibs'] = garden_requirements", "response": "Ensure required garden packages are available to be included."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the user is in the root user.", "response": "def check_root(self):\n        '''If effective user id is 0, display a warning and require\n        user input to continue (or to cancel)'''\n\n        if IS_PY3:\n            input_func = input\n        else:\n            input_func = raw_input\n\n        warn_on_root = self.config.getdefault('buildozer', 'warn_on_root', '1')\n        try:\n            euid = os.geteuid() == 0\n        except AttributeError:\n            if sys.platform == 'win32':\n                import ctypes\n            euid = ctypes.windll.shell32.IsUserAnAdmin() != 0\n        if warn_on_root == '1' and euid:\n            print('\\033[91m\\033[1mBuildozer is running as root!\\033[0m')\n            print('\\033[91mThis is \\033[1mnot\\033[0m \\033[91mrecommended, and may lead to problems later.\\033[0m')\n            cont = None\n            while cont not in ('y', 'n'):\n                cont = input_func('Are you sure you want to continue [y/n]? ')\n\n            if cont == 'n':\n                sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a initial buildozer. spec file in the current directory", "response": "def cmd_init(self, *args):\n        '''Create a initial buildozer.spec in the current directory\n        '''\n        if exists('buildozer.spec'):\n            print('ERROR: You already have a buildozer.spec file.')\n            exit(1)\n        copyfile(join(dirname(__file__), 'default.spec'), 'buildozer.spec')\n        print('File buildozer.spec created, ready to customize!')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd_distclean(self, *args):\n        '''Clean the whole Buildozer environment.\n        '''\n        print(\"Warning: Your ndk, sdk and all other cached packages will be\"\n              \" removed. Continue? (y/n)\")\n        if sys.stdin.readline().lower()[0] == 'y':\n            self.info('Clean the global build directory')\n            if not exists(self.global_buildozer_dir):\n                return\n            rmtree(self.global_buildozer_dir)", "response": "Clean the whole Buildozer environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd_serve(self, *args):\n        '''Serve the bin directory via SimpleHTTPServer\n        '''\n        try:\n            from http.server import SimpleHTTPRequestHandler\n            from socketserver import TCPServer\n        except ImportError:\n            from SimpleHTTPServer import SimpleHTTPRequestHandler\n            from SocketServer import TCPServer\n\n        os.chdir(self.bin_dir)\n        handler = SimpleHTTPRequestHandler\n        httpd = TCPServer((\"\", SIMPLE_HTTP_SERVER_PORT), handler)\n        print(\"Serving via HTTP at port {}\".format(SIMPLE_HTTP_SERVER_PORT))\n        print(\"Press Ctrl+c to quit serving.\")\n        httpd.serve_forever()", "response": "Serve the bin directory via SimpleHTTPServer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening the xcode project.", "response": "def cmd_xcode(self, *args):\n        '''Open the xcode project.\n        '''\n        app_name = self.buildozer.namify(self.buildozer.config.get('app',\n            'package.name'))\n        app_name = app_name.lower()\n\n        ios_dir = ios_dir = join(self.buildozer.platform_dir, 'kivy-ios')\n        self.buildozer.cmd('open {}.xcodeproj'.format(\n            app_name), cwd=join(ios_dir, '{}-ios'.format(app_name)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd_list_identities(self, *args):\n        '''List the available identities to use for signing.\n        '''\n        identities = self._get_available_identities()\n        print('Available identities:')\n        for x in identities:\n            print('  - {}'.format(x))", "response": "List the available identities to use for signing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_body_to_bytes(resp):\n    try:\n        if resp['body']['string'] is not None and not isinstance(resp['body']['string'], six.binary_type):\n            resp['body']['string'] = resp['body']['string'].encode('utf-8')\n    except (KeyError, TypeError, UnicodeEncodeError):\n        # The thing we were converting either wasn't a dictionary or didn't\n        # have the keys we were expecting.  Some of the tests just serialize\n        # and deserialize a string.\n\n        # Also, sometimes the thing actually is binary, so if you can't encode\n        # it, just give up.\n        pass\n    return resp", "response": "Convert the request body to bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_string_to_unicode(string):\n    result = string\n\n    try:\n        if string is not None and not isinstance(string, six.text_type):\n            result = string.decode('utf-8')\n    except (TypeError, UnicodeDecodeError, AttributeError):\n        # Sometimes the string actually is binary or StringIO object,\n        # so if you can't decode it, just give up.\n        pass\n\n    return result", "response": "Convert a string to a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_body_to_unicode(resp):\n    if type(resp) is not dict:\n        # Some of the tests just serialize and deserialize a string.\n        return _convert_string_to_unicode(resp)\n    else:\n        body = resp.get('body')\n\n        if body is not None:\n            try:\n                body['string'] = _convert_string_to_unicode(\n                    body['string']\n                )\n            except (KeyError, TypeError, AttributeError):\n                # The thing we were converting either wasn't a dictionary or\n                # didn't have the keys we were expecting.\n                # For example request object has no 'string' key.\n                resp['body'] = _convert_string_to_unicode(body)\n\n    return resp", "response": "Convert the response body to a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap a generator so that we re inside the cassette context for the duration of the generator.", "response": "def _handle_generator(self, fn):\n        \"\"\"Wraps a generator so that we're inside the cassette context for the\n        duration of the generator.\n        \"\"\"\n        with self as cassette:\n            coroutine = fn(cassette)\n            # We don't need to catch StopIteration. The caller (Tornado's\n            # gen.coroutine, for example) will handle that.\n            to_yield = next(coroutine)\n            while True:\n                try:\n                    to_send = yield to_yield\n                except Exception:\n                    to_yield = coroutine.throw(*sys.exc_info())\n                else:\n                    try:\n                        to_yield = coroutine.send(to_send)\n                    except StopIteration:\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append(self, request, response):\n        request = self._before_record_request(request)\n        if not request:\n            return\n        # Deepcopy is here because mutation of `response` will corrupt the\n        # real response.\n        response = copy.deepcopy(response)\n        response = self._before_record_response(response)\n        if response is None:\n            return\n        self.data.append((request, response))\n        self.dirty = True", "response": "Add a request and response pair to this cassette"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _responses(self, request):\n        request = self._before_record_request(request)\n        for index, (stored_request, response) in enumerate(self.data):\n            if requests_match(request, stored_request, self._match_on):\n                yield index, response", "response": "Internal API returns an iterator with all responses matching the request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the response corresponding to a request and mark it as played.", "response": "def play_response(self, request):\n        \"\"\"\n        Get the response corresponding to a request, but only if it\n        hasn't been played back before, and mark it as played\n        \"\"\"\n        for index, response in self._responses(request):\n            if self.play_counts[index] == 0:\n                self.play_counts[index] += 1\n                return response\n        # The cassette doesn't contain the request asked for.\n        raise UnhandledHTTPRequestError(\n            \"The cassette (%r) doesn't contain the request (%r) asked for\"\n            % (self._path, request)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the responses corresponding to a request.", "response": "def responses_of(self, request):\n        \"\"\"\n        Find the responses corresponding to a request.\n        This function isn't actually used by VCR internally, but is\n        provided as an external API.\n        \"\"\"\n        responses = [response for index, response in self._responses(request)]\n\n        if responses:\n            return responses\n        # The cassette doesn't contain the request asked for.\n        raise UnhandledHTTPRequestError(\n            \"The cassette (%r) doesn't contain the request (%r) asked for\"\n            % (self._path, request)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts headers from our serialized dict with lists for keys to a", "response": "def parse_headers(header_list):\n    \"\"\"\n    Convert headers from our serialized dict with lists for keys to a\n    HTTPMessage\n    \"\"\"\n    header_string = b\"\"\n    for key, values in header_list.items():\n        for v in values:\n            header_string += \\\n                key.encode('utf-8') + b\":\" + v.encode('utf-8') + b\"\\r\\n\"\n    return compat.get_httpmessage(header_string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string that is used to fix the port in the log file.", "response": "def _port_postfix(self):\n        \"\"\"\n        Returns empty string for the default port and ':port' otherwise\n        \"\"\"\n        port = self.real_connection.port\n        default_port = {'https': 443, 'http': 80}[self._protocol]\n        return ':{}'.format(port) if port != default_port else ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _uri(self, url):\n        if url and not url.startswith('/'):\n            # Then this must be a proxy request.\n            return url\n        uri = \"{0}://{1}{2}{3}\".format(\n            self._protocol,\n            self.real_connection.host,\n            self._port_postfix(),\n            url,\n        )\n        return uri", "response": "Returns request absolute URI"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn request selector url from absolute URI", "response": "def _url(self, uri):\n        \"\"\"Returns request selector url from absolute URI\"\"\"\n        prefix = \"{}://{}{}\".format(\n            self._protocol,\n            self.real_connection.host,\n            self._port_postfix(),\n        )\n        return uri.replace(prefix, '', 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, method, url, body=None, headers=None, *args, **kwargs):\n        '''Persist the request metadata in self._vcr_request'''\n        self._vcr_request = Request(\n            method=method,\n            uri=self._uri(url),\n            body=body,\n            headers=headers or {}\n        )\n        log.debug('Got {}'.format(self._vcr_request))\n\n        # Note: The request may not actually be finished at this point, so\n        # I'm not sending the actual request until getresponse().  This\n        # allows me to compare the entire length of the response to see if it\n        # exists in the cassette.\n\n        self._sock = VCRFakeSocket()", "response": "Send a request to the VCR server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef putrequest(self, method, url, *args, **kwargs):\n        self._vcr_request = Request(\n            method=method,\n            uri=self._uri(url),\n            body=\"\",\n            headers={}\n        )\n        log.debug('Got {}'.format(self._vcr_request))", "response": "This method is used to make a PUT request to the VCR server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the response from the cassette.", "response": "def getresponse(self, _=False, **kwargs):\n        '''Retrieve the response'''\n        # Check to see if the cassette has a response for this request. If so,\n        # then return it\n        if self.cassette.can_play_response_for(self._vcr_request):\n            log.info(\n                \"Playing response for {} from cassette\".format(\n                    self._vcr_request\n                )\n            )\n            response = self.cassette.play_response(self._vcr_request)\n            return VCRHTTPResponse(response)\n        else:\n            if self.cassette.write_protected and self.cassette.filter_request(\n                self._vcr_request\n            ):\n                raise CannotOverwriteExistingCassetteException(\n                    \"No match for the request (%r) was found. \"\n                    \"Can't overwrite existing cassette (%r) in \"\n                    \"your current record mode (%r).\"\n                    % (self._vcr_request, self.cassette._path,\n                       self.cassette.record_mode)\n                )\n\n            # Otherwise, we should send the request, then get the response\n            # and return it.\n\n            log.info(\n                \"{} not in cassette, sending to real server\".format(\n                    self._vcr_request\n                )\n            )\n            # This is imported here to avoid circular import.\n            # TODO(@IvanMalison): Refactor to allow normal import.\n            from vcr.patch import force_reset\n            with force_reset():\n                self.real_connection.request(\n                    method=self._vcr_request.method,\n                    url=self._url(self._vcr_request.uri),\n                    body=self._vcr_request.body,\n                    headers=self._vcr_request.headers,\n                )\n\n            # get the response\n            response = self.real_connection.getresponse()\n\n            # put the response into the cassette\n            response = {\n                'status': {\n                    'code': response.status,\n                    'message': response.reason\n                },\n                'headers': serialize_headers(response),\n                'body': {'string': response.read()},\n            }\n            self.cassette.append(self._vcr_request, response)\n        return VCRHTTPResponse(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to the server I m assuming.", "response": "def connect(self, *args, **kwargs):\n        \"\"\"\n        httplib2 uses this.  Connects to the server I'm assuming.\n\n        Only pass to the baseclass if we don't have a recorded response\n        and are not write-protected.\n        \"\"\"\n\n        if hasattr(self, '_vcr_request') and \\\n                self.cassette.can_play_response_for(self._vcr_request):\n            # We already have a response we are going to play, don't\n            # actually connect\n            return\n\n        if self.cassette.write_protected:\n            # Cassette is write-protected, don't actually connect\n            return\n\n        from vcr.patch import force_reset\n        with force_reset():\n            return self.real_connection.connect(*args, **kwargs)\n\n        self._sock = VCRFakeSocket()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_headers(request, replacements):\n    new_headers = request.headers.copy()\n    for k, rv in replacements:\n        if k in new_headers:\n            ov = new_headers.pop(k)\n            if callable(rv):\n                rv = rv(key=k, value=ov, request=request)\n            if rv is not None:\n                new_headers[k] = rv\n    request.headers = new_headers\n    return request", "response": "Replace headers in a request according to a list of replacements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_headers(request, headers_to_remove):\n    replacements = [(k, None) for k in headers_to_remove]\n    return replace_headers(request, replacements)", "response": "Wrap replace_headers to remove headers from a request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_query_parameters(request, replacements):\n    query = request.query\n    new_query = []\n    replacements = dict(replacements)\n    for k, ov in query:\n        if k not in replacements:\n            new_query.append((k, ov))\n        else:\n            rv = replacements[k]\n            if callable(rv):\n                rv = rv(key=k, value=ov, request=request)\n            if rv is not None:\n                new_query.append((k, rv))\n    uri_parts = list(urlparse(request.uri))\n    uri_parts[4] = urlencode(new_query)\n    request.uri = urlunparse(uri_parts)\n    return request", "response": "Replace query parameters in a request according to replacements."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps replace_query_parameters to remove query parameters from a request.", "response": "def remove_query_parameters(request, query_parameters_to_remove):\n    \"\"\"\n    Wrap replace_query_parameters() for API backward compatibility.\n    \"\"\"\n    replacements = [(k, None) for k in query_parameters_to_remove]\n    return replace_query_parameters(request, replacements)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_post_data_parameters(request, replacements):\n    replacements = dict(replacements)\n    if request.method == 'POST' and not isinstance(request.body, BytesIO):\n        if request.headers.get('Content-Type') == 'application/json':\n            json_data = json.loads(request.body.decode('utf-8'))\n            for k, rv in replacements.items():\n                if k in json_data:\n                    ov = json_data.pop(k)\n                    if callable(rv):\n                        rv = rv(key=k, value=ov, request=request)\n                    if rv is not None:\n                        json_data[k] = rv\n            request.body = json.dumps(json_data).encode('utf-8')\n        else:\n            if isinstance(request.body, text_type):\n                request.body = request.body.encode('utf-8')\n            splits = [p.partition(b'=') for p in request.body.split(b'&')]\n            new_splits = []\n            for k, sep, ov in splits:\n                if sep is None:\n                    new_splits.append((k, sep, ov))\n                else:\n                    rk = k.decode('utf-8')\n                    if rk not in replacements:\n                        new_splits.append((k, sep, ov))\n                    else:\n                        rv = replacements[rk]\n                        if callable(rv):\n                            rv = rv(key=rk, value=ov.decode('utf-8'),\n                                    request=request)\n                        if rv is not None:\n                            new_splits.append((k, sep, rv.encode('utf-8')))\n            request.body = b'&'.join(k if sep is None else b''.join([k, sep, v])\n                                     for k, sep, v in new_splits)\n    return request", "response": "Replace post data in request. body with the given replacements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping replace_post_data_parameters for API backward compatibility.", "response": "def remove_post_data_parameters(request, post_data_parameters_to_remove):\n    \"\"\"\n    Wrap replace_post_data_parameters() for API backward compatibility.\n    \"\"\"\n    replacements = [(k, None) for k in post_data_parameters_to_remove]\n    return replace_post_data_parameters(request, replacements)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_response(response):\n    def is_compressed(headers):\n        encoding = headers.get('content-encoding', [])\n        return encoding and encoding[0] in ('gzip', 'deflate')\n\n    def decompress_body(body, encoding):\n        \"\"\"Returns decompressed body according to encoding using zlib.\n        to (de-)compress gzip format, use wbits = zlib.MAX_WBITS | 16\n        \"\"\"\n        if encoding == 'gzip':\n            return zlib.decompress(body, zlib.MAX_WBITS | 16)\n        else:  # encoding == 'deflate'\n            return zlib.decompress(body)\n\n    # Deepcopy here in case `headers` contain objects that could\n    # be mutated by a shallow copy and corrupt the real response.\n    response = copy.deepcopy(response)\n    headers = CaseInsensitiveDict(response['headers'])\n    if is_compressed(headers):\n        encoding = headers['content-encoding'][0]\n        headers['content-encoding'].remove(encoding)\n        if not headers['content-encoding']:\n            del headers['content-encoding']\n\n        new_body = decompress_body(response['body']['string'], encoding)\n        response['body']['string'] = new_body\n        headers['content-length'] = [str(len(new_body))]\n        response['headers'] = dict(headers)\n    return response", "response": "Decode a response into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Widget_fontdict():\n    flist = Widget_fontobjects[2:-2].splitlines()\n    fdict = {}\n    for f in flist:\n        k, v = f.split(\" \")\n        fdict[k[1:]] = v\n    return fdict", "response": "Turns the above font definitions into a dictionary. Assumes certain line breaks and spaces."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTextlength(text, fontname=\"helv\", fontsize=11, encoding=0):\n    fontname = fontname.lower()\n    basename = Base14_fontdict.get(fontname, None)\n\n    glyphs = None\n    if basename == \"Symbol\":\n        glyphs = symbol_glyphs\n    if basename == \"ZapfDingbats\":\n        glyphs = zapf_glyphs\n    if glyphs is not None:\n        w = sum([glyphs[ord(c)][1] if ord(c)<256 else glyphs[183][1] for c in text])\n        return w * fontsize\n\n    if fontname in Base14_fontdict.keys():\n        return TOOLS.measure_string(text, Base14_fontdict[fontname], fontsize, encoding)\n\n    if fontname in [\"china-t\", \"china-s\",\n                    \"china-ts\", \"china-ss\",\n                    \"japan\", \"japan-s\",\n                    \"korea\", \"korea-s\"]:\n        return len(text) * fontsize\n\n    raise ValueError(\"Font '%s' is unsupported\" % fontname)", "response": "Calculate the length of a string for a given built - in font."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a PDF string depending on its coding.", "response": "def getPDFstr(s):\n    \"\"\" Return a PDF string depending on its coding.\n\n    Notes:\n        If only ascii then \"(original)\" is returned, else if only 8 bit chars\n        then \"(original)\" with interspersed octal strings \\nnn is returned,\n        else a string \"<FEFF[hexstring]>\" is returned, where [hexstring] is the\n        UTF-16BE encoding of the original.\n    \"\"\"\n    if not bool(s):\n        return \"()\"\n\n    def make_utf16be(s):\n        r = hexlify(bytearray([254, 255]) + bytearray(s, \"UTF-16BE\"))\n        t = r if fitz_py2 else r.decode()\n        return \"<\" + t + \">\"                         # brackets indicate hex\n\n\n# following either returns original string with mixed-in \n# octal numbers \\nnn if outside ASCII range, or:\n# exits with utf-16be BOM version of the string\n    r = \"\"\n    for c in s:\n        oc = ord(c)\n        if oc > 255:                                  # shortcut if beyond code range\n            return make_utf16be(s)\n\n        if oc > 31 and oc < 127:\n            if c in (\"(\", \")\", \"\\\\\"):\n                r += \"\\\\\"\n            r += c\n            continue\n\n        if oc > 127:\n            r += \"\\\\\" + oct(oc)[-3:]\n            continue\n\n        if oc < 8 or oc > 13 or oc == 11 or c == 127:\n            r += \"\\\\267\"   # indicate unsupported char\n            continue\n\n        if oc == 8:\n            r += \"\\\\b\"\n        elif oc == 9:\n            r += \"\\\\t\"\n        elif oc == 10:\n            r += \"\\\\n\"\n        elif oc == 12:\n            r += \"\\\\f\"\n        elif oc == 13:\n            r += \"\\\\r\"\n\n    return \"(\" + r + \")\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string enclosed in [] brackets suitable for the PDF TJ operator.", "response": "def getTJstr(text, glyphs, simple, ordering):\n    \"\"\" Return a PDF string enclosed in [] brackets, suitable for the PDF TJ\n    operator.\n\n    Notes:\n        The input string is converted to either 2 or 4 hex digits per character.\n    Args:\n        simple: no glyphs: 2-chars, use char codes as the glyph\n                glyphs: 2-chars, use glyphs instead of char codes (Symbol,\n                ZapfDingbats)\n        not simple: ordering < 0: 4-chars, use glyphs not char codes\n                    ordering >=0: a CJK font! 4 chars, use char codes as glyphs\n\"\"\"\n    if text.startswith(\"[<\") and text.endswith(\">]\"): # already done\n        return text\n\n    if not bool(text):\n        return \"[<>]\"\n\n    if simple:\n        if glyphs is None:             # simple and not Symbol / ZapfDingbats\n            otxt = \"\".join([hex(ord(c))[2:].rjust(2, \"0\") if ord(c)<256 else \"b7\" for c in text])\n        else:                          # Symbol or ZapfDingbats\n            otxt = \"\".join([hex(glyphs[ord(c)][0])[2:].rjust(2, \"0\") if ord(c)<256 else \"b7\" for c in text])\n        return \"[<\" + otxt + \">]\"\n\n    if ordering < 0:                   # not a CJK font: use the glyphs\n        otxt = \"\".join([hex(glyphs[ord(c)][0])[2:].rjust(4, \"0\") for c in text])\n    else:                              # CJK: use char codes, no glyphs\n        otxt = \"\".join([hex(ord(c))[2:].rjust(4, \"0\") for c in text])\n\n    return \"[<\" + otxt + \">]\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef PaperSize(s):\n    size = s.lower()\n    f = \"p\"\n    if size.endswith(\"-l\"):\n        f = \"l\"\n        size = size[:-2]\n    if size.endswith(\"-p\"):\n        size = size[:-2]\n    rc = paperSizes.get(size, (-1, -1))\n    if f == \"p\":\n        return rc\n    return (rc[1], rc[0])", "response": "Return a tuple of width height for a given paper format string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a font name matches a page s font list.", "response": "def CheckFont(page, fontname):\n    \"\"\"Return an entry in the page's font list if reference name matches.\n    \"\"\"\n    for f in page.getFontList():\n        if f[4] == fontname:\n            return f\n        if f[3].lower() == fontname.lower():\n            return f\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the inverted matrix. Return 0 if successful and replace current one. Else return 1.", "response": "def invert(self, src=None):\n        \"\"\"Calculate the inverted matrix. Return 0 if successful and replace\n        current one. Else return 1 and do nothing.\n        \"\"\"\n        if src is None:\n            dst = TOOLS._invert_matrix(self)\n        else:\n            dst = TOOLS._invert_matrix(src)\n        if dst[0] == 1:\n            return 1\n        self.a, self.b, self.c, self.d, self.e, self.f = dst[1]\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preTranslate(self, tx, ty):\n        self.e += tx * self.a + ty * self.c\n        self.f += tx * self.b + ty * self.d\n        return self", "response": "Calculate pre translation and replace current matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preScale(self, sx, sy):\n        self.a *= sx\n        self.b *= sx\n        self.c *= sy\n        self.d *= sy\n        return self", "response": "Calculate pre scaling and replace current matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preShear(self, h, v):\n        a, b = self.a, self.b\n        self.a += v * self.c\n        self.b += v * self.d\n        self.c += h * a\n        self.d += h * b\n        return self", "response": "Calculate pre shearing and replace current matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preRotate(self, theta):\n        while theta < 0: theta += 360\n        while theta >= 360: theta -= 360\n        epsilon = 1e-5\n        if abs(0 - theta) < epsilon:\n            pass\n\n        elif abs(90.0 - theta) < epsilon:\n            a = self.a\n            b = self.b\n            self.a = self.c\n            self.b = self.d\n            self.c = -a\n            self.d = -b\n\n        elif abs(180.0 - theta) < epsilon:\n            self.a = -self.a\n            self.b = -self.b\n            self.c = -self.c\n            self.d = -self.d\n\n        elif abs(270.0 - theta) < epsilon:\n            a = self.a\n            b = self.b\n            self.a = -self.c\n            self.b = -self.d\n            self.c = a\n            self.d = b\n\n        else:\n            rad = math.radians(theta)\n            s = round(math.sin(rad), 12)\n            c = round(math.cos(rad), 12)\n            a = self.a\n            b = self.b\n            self.a = c * a + s * self.c\n            self.b = c * b + s * self.d\n            self.c =-s * a + c * self.c\n            self.d =-s * b + c * self.d\n\n        return self", "response": "Calculate pre rotation and replace current matrix with new matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmultiplying two matrices and replace current one.", "response": "def concat(self, one, two):\n        \"\"\"Multiply two matrices and replace current one.\"\"\"\n        if not len(one) == len(two) == 6:\n            raise ValueError(\"bad sequ. length\")\n        self.a, self.b, self.c, self.d, self.e, self.f = TOOLS._concat_matrix(one, two)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces point by its transformation with matrix - like m.", "response": "def transform(self, m):\n        \"\"\"Replace point by its transformation with matrix-like m.\"\"\"\n        if len(m) != 6:\n            raise ValueError(\"bad sequ. length\")\n        self.x, self.y = TOOLS._transform_point(self, m)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unit(self):\n        s = self.x * self.x + self.y * self.y\n        if s < 1e-5:\n            return Point(0,0)\n        s = math.sqrt(s)\n        return Point(self.x / s, self.y / s)", "response": "Return unit vector of a point."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns unit vector of a point with positive coordinates.", "response": "def abs_unit(self):\n        \"\"\"Return unit vector of a point with positive coordinates.\"\"\"\n        s = self.x * self.x + self.y * self.y\n        if s < 1e-5:\n            return Point(0,0)\n        s = math.sqrt(s)\n        return Point(abs(self.x) / s, abs(self.y) / s)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distance_to(self, *args):\n        if not len(args) > 0:\n            raise ValueError(\"at least one parameter must be given\")\n\n        x = args[0]\n        if len(args) > 1:\n            unit = args[1]\n        else:\n            unit = \"px\"\n        u = {\"px\": (1.,1.), \"in\": (1.,72.), \"cm\": (2.54, 72.),\n             \"mm\": (25.4, 72.)}\n        f = u[unit][0] / u[unit][1]\n        if type(x) is Point:\n            return abs(self - x) * f\n\n# from here on, x is a rectangle\n# as a safeguard, make a finite copy of it\n        r = Rect(x.top_left, x.top_left)\n        r = r | x.bottom_right\n        if self in r:\n            return 0.0\n        if self.x > r.x1:\n            if self.y >= r.y1:\n                return self.distance_to(r.bottom_right, unit)\n            elif self.y <= r.y0:\n                return self.distance_to(r.top_right, unit)\n            else:\n                return (self.x - r.x1) * f\n        elif r.x0 <= self.x <= r.x1:\n            if self.y >= r.y1:\n                return (self.y - r.y1) * f\n            else:\n                return (r.y0 - self.y) * f\n        else:\n            if self.y >= r.y1:\n                return self.distance_to(r.bottom_left, unit)\n            elif self.y <= r.y0:\n                return self.distance_to(r.top_left, unit)\n            else:\n                return (r.x0 - self.x) * f", "response": "Return the distance to a rectangle or another point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize(self):\n        if self.x1 < self.x0:\n            self.x0, self.x1 = self.x1, self.x0\n        if self.y1 < self.y0:\n            self.y0, self.y1 = self.y1, self.y0\n        return self", "response": "Replace rectangle with its finite version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if rectangle area is empty.", "response": "def isEmpty(self):\n        \"\"\"Check if rectangle area is empty.\"\"\"\n        return self.x0 == self.x1 or self.y0 == self.y1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if rectangle is infinite.", "response": "def isInfinite(self):\n        \"\"\"Check if rectangle is infinite.\"\"\"\n        return self.x0 > self.x1 or self.y0 > self.y1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextends rectangle to include point p.", "response": "def includePoint(self, p):\n        \"\"\"Extend rectangle to include point p.\"\"\"\n        if not len(p) == 2:\n            raise ValueError(\"bad sequ. length\")\n        self.x0, self.y0, self.x1, self.y1 = TOOLS._include_point_in_rect(self, p)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef includeRect(self, r):\n        if not len(r) == 4:\n            raise ValueError(\"bad sequ. length\")\n        self.x0, self.y0, self.x1, self.y1 = TOOLS._union_rect(self, r)\n        return self", "response": "Extend rectangle to include rectangle r."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestricting self to common area with rectangle r.", "response": "def intersect(self, r):\n        \"\"\"Restrict self to common area with rectangle r.\"\"\"\n        if not len(r) == 4:\n            raise ValueError(\"bad sequ. length\")\n        self.x0, self.y0, self.x1, self.y1 = TOOLS._intersect_rect(self, r)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing rectangle with its transformation by matrix m.", "response": "def transform(self, m):\n        \"\"\"Replace rectangle with its transformation by matrix m.\"\"\"\n        if not len(m) == 6:\n            raise ValueError(\"bad sequ. length\")\n        self.x0, self.y0, self.x1, self.y1 = TOOLS._transform_rect(self, m)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef intersects(self, x):\n        r1 = Rect(x)\n        if self.isEmpty or self.isInfinite or r1.isEmpty:\n            return False\n        r = Rect(self)\n        if r.intersect(r1).isEmpty:\n            return False\n        return True", "response": "Check if intersection with rectangle x is not empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isRectangular(self):\n# if any two of the 4 corners are equal return false\n        upper = (self.ur - self.ul).unit\n        if not bool(upper):\n            return False\n        right = (self.lr - self.ur).unit\n        if not bool(right):\n            return False\n        left  = (self.ll - self.ul).unit\n        if not bool(left):\n            return False\n        lower = (self.lr - self.ll).unit\n        if not bool(lower):\n            return False\n        eps = 1e-5\n# we now have 4 sides of length 1. If 3 of them have 90 deg angles,\n# then it is a rectangle -- we check via scalar product == 0\n        return abs(sum(map(lambda x,y: x*y, upper, right))) <= eps and \\\n               abs(sum(map(lambda x,y: x*y, upper, left))) <= eps and \\\n               abs(sum(map(lambda x,y: x*y, left, lower))) <= eps", "response": "Check if the current region is rectangular."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isEmpty(self):\n        if self.isRectangular:\n            return False\n        eps = 1e-5\n        ul = Point()\n        ur = (self.ur - self.ul).abs_unit\n        lr = (self.lr - self.ul).abs_unit\n        ll = (self.ll - self.ul).abs_unit\n        if max(ur.y, lr.y, ll.y) - min(ur.y, lr.y, ll.y) < eps:\n            return True\n        return False", "response": "Check if the current region is empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces quad by its transformation with matrix m.", "response": "def transform(self, m):\n        \"\"\"Replace quad by its transformation with matrix m.\"\"\"\n        if len(m) != 6:\n            raise ValueError(\"bad sequ. length\")\n        self.ul *= m\n        self.ur *= m\n        self.ll *= m\n        self.lr *= m\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the class entries.", "response": "def _validate(self):\n        \"\"\"Validate the class entries.\n        \"\"\"\n        checker = (self._check0, self._check1, self._check2, self._check3,\n                   self._check4, self._check5)\n        if not 0 <= self.field_type <= 5:\n            raise NotImplementedError(\"unsupported widget type\")\n        if type(self.rect) is not Rect:\n            raise ValueError(\"invalid rect\")\n        if self.rect.isInfinite or self.rect.isEmpty:\n            raise ValueError(\"rect must be finite and not empty\")\n        if not self.field_name:\n            raise ValueError(\"field name missing\")\n\n        if self.border_color:\n            if not len(self.border_color) in range(1,5) or \\\n               type(self.border_color) not in (list, tuple):\n               raise ValueError(\"border_color must be 1 - 4 floats\")\n\n        if self.fill_color:\n            if not len(self.fill_color) in range(1,5) or \\\n               type(self.fill_color) not in (list, tuple):\n               raise ValueError(\"fill_color must be 1 - 4 floats\")\n\n        if not self.text_color:\n            self.text_color = (0, 0, 0)\n        if not len(self.text_color) in range(1,5) or \\\n            type(self.text_color) not in (list, tuple):\n            raise ValueError(\"text_color must be 1 - 4 floats\")\n\n        if not self.border_width:\n            self.border_width = 0\n\n        if not self.text_fontsize:\n            self.text_fontsize = 0\n\n        checker[self.field_type]()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure the font name is from our list and correctly spelled.", "response": "def _adjust_font(self):\n        \"\"\"Ensure the font name is from our list and correctly spelled.\n        \"\"\"\n        fnames = [k for k in Widget_fontdict.keys()]\n        fl = list(map(str.lower, fnames))\n        if (not self.text_font) or self.text_font.lower() not in fl:\n            self.text_font = \"helv\"\n        i = fl.index(self.text_font.lower())\n        self.text_font = fnames[i]\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_da(self):\n        if not self._text_da:\n            return\n        font = \"Helv\"\n        fsize = 0\n        col = (0, 0, 0)\n        dat = self._text_da.split()              # split on any whitespace\n        for i, item in enumerate(dat):\n            if item == \"Tf\":\n                font = dat[i - 2][1:]\n                fsize = float(dat[i - 1])\n                dat[i] = dat[i-1] = dat[i-2] = \"\"\n                continue\n            if item == \"g\":            # unicolor text\n                col = [(float(dat[i - 1]))]\n                dat[i] = dat[i-1] = \"\"\n                continue\n            if item == \"rg\":           # RGB colored text\n                col = [float(f) for f in dat[i - 3:i]]\n                dat[i] = dat[i-1] = dat[i-2] = dat[i-3] = \"\"\n                continue\n        self.text_font     = font\n        self.text_fontsize = fsize\n        self.text_color    = col\n        self._text_da = \" \".join([c for c in dat if c != \"\"])\n        return", "response": "Extract font name size and color from default appearance string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n        if hasattr(self, '_outline') and self._outline:\n            self._dropOutline(self._outline)\n            self._outline = None\n        self._reset_page_refs()\n        self.metadata    = None\n        self.stream      = None\n        self.isClosed    = True\n        self.openErrCode = 0\n        self.openErrMsg  = ''\n        self.FontInfos   = []\n        for gmap in self.Graftmaps:\n            self.Graftmaps[gmap] = None\n        self.Graftmaps = {}\n        self.ShownPages = {}\n\n\n        val = _fitz.Document_close(self)\n        self.thisown = False\n\n        return val", "response": "Close the document and clear all related attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadPage(self, number=0):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document_loadPage(self, number)\n\n        if val:\n            val.thisown = True\n            val.parent = weakref.proxy(self)\n            pageCount = self.pageCount\n            n = number\n            while n < 0: n += pageCount\n            val.number = n\n            self._page_refs[id(val)] = val\n            val._annot_refs = weakref.WeakValueDictionary()\n\n\n        return val", "response": "Load a page from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef embeddedFileCount(self):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_embeddedFileCount(self)", "response": "Return number of embedded files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef embeddedFileDel(self, name):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_embeddedFileDel(self, name)", "response": "Delete embedded file by name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef embeddedFileInfo(self, id):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_embeddedFileInfo(self, id)", "response": "Retrieve embedded file information given its entry number or name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef embeddedFileUpd(self, id, buffer=None, filename=None, ufilename=None, desc=None):\n        return _fitz.Document_embeddedFileUpd(self, id, buffer, filename, ufilename, desc)", "response": "Change an embedded file given its entry number or name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef embeddedFileGet(self, id):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_embeddedFileGet(self, id)", "response": "Retrieve embedded file content by name or number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef embeddedFileAdd(self, buffer, name, filename=None, ufilename=None, desc=None):\n\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n\n        return _fitz.Document_embeddedFileAdd(self, buffer, name, filename, ufilename, desc)", "response": "Add a new file to the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convertToPDF(self, from_page=0, to_page=-1, rotate=0):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_convertToPDF(self, from_page, to_page, rotate)", "response": "Convert document to PDF selecting page range and optional rotation. Output bytes object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getMetadata(self, key):\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n\n        return _fitz.Document__getMetadata(self, key)", "response": "Get metadata for a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef layout(self, rect=None, width=0, height=0, fontsize=11):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document_layout(self, rect, width, height, fontsize)\n\n        self._reset_page_refs()\n        self.initData()\n\n        return val", "response": "Re - layout a reflowable document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef makeBookmark(self, pno=0):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_makeBookmark(self, pno)", "response": "Make a page bookmark in a reflowable document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findBookmark(self, bookmark):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_findBookmark(self, bookmark)", "response": "Find page number after layouting a document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an object given its xref.", "response": "def _deleteObject(self, xref):\n        \"\"\"Delete an object given its xref.\"\"\"\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n\n        return _fitz.Document__deleteObject(self, xref)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a document to a file.", "response": "def save(self, filename, garbage=0, clean=0, deflate=0, incremental=0, ascii=0, expand=0, linear=0, pretty=0, decrypt=1):\n        \"\"\"save(self, filename, garbage=0, clean=0, deflate=0, incremental=0, ascii=0, expand=0, linear=0, pretty=0, decrypt=1) -> PyObject *\"\"\"\n\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if type(filename) == str:\n            pass\n        elif type(filename) == unicode:\n            filename = filename.encode('utf8')\n        else:\n            raise TypeError(\"filename must be a string\")\n        if filename == self.name and not incremental:\n            raise ValueError(\"save to original must be incremental\")\n        if self.pageCount < 1:\n            raise ValueError(\"cannot save with zero pages\")\n        if incremental:\n            if self.name != filename or self.stream:\n                raise ValueError(\"incremental needs original file\")\n\n\n        return _fitz.Document_save(self, filename, garbage, clean, deflate, incremental, ascii, expand, linear, pretty, decrypt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a document to a bytes object.", "response": "def write(self, garbage=0, clean=0, deflate=0, ascii=0, expand=0, linear=0, pretty=0, decrypt=1):\n        \"\"\"Write document to a bytes object.\"\"\"\n\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if self.pageCount < 1:\n            raise ValueError(\"cannot write with zero pages\")\n\n\n        return _fitz.Document_write(self, garbage, clean, deflate, ascii, expand, linear, pretty, decrypt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a PDF into the document.", "response": "def insertPDF(self, docsrc, from_page=-1, to_page=-1, start_at=-1, rotate=-1, links=1):\n        \"\"\"Copy page range ['from', 'to'] of source PDF, starting as page number 'start_at'.\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if id(self) == id(docsrc):\n            raise ValueError(\"source must not equal target PDF\")\n        sa = start_at\n        if sa < 0:\n            sa = self.pageCount\n\n        val = _fitz.Document_insertPDF(self, docsrc, from_page, to_page, start_at, rotate, links)\n        self._reset_page_refs()\n        if links:\n            self._do_links(docsrc, from_page = from_page, to_page = to_page,\n                           start_at = sa)\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new page.", "response": "def _newPage(self, pno=-1, width=595, height=842):\n        \"\"\"_newPage(self, pno=-1, width=595, height=842) -> PyObject *\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document__newPage(self, pno, width, height)\n        self._reset_page_refs()\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select(self, pyliste):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document_select(self, pyliste)\n\n        self._reset_page_refs()\n        self.initData()\n\n        return val", "response": "Build sub - pdf with page numbers in list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _getCharWidths(self, xref, bfname, ext, ordering, limit, idx=0):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__getCharWidths(self, xref, bfname, ext, ordering, limit, idx)", "response": "Return list of glyphs and glyph widths of a font."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets page object number.", "response": "def _getPageObjNumber(self, pno):\n        \"\"\"_getPageObjNumber(self, pno) -> PyObject *\"\"\"\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n\n        return _fitz.Document__getPageObjNumber(self, pno)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getPageInfo(self, pno, what):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document__getPageInfo(self, pno, what)\n\n        x = []\n        for v in val:\n            if v not in x:\n                x.append(v)\n        val = x\n\n        return val", "response": "Show fonts or images used on a page."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract a font from the document.", "response": "def extractFont(self, xref=0, info_only=0):\n        \"\"\"extractFont(self, xref=0, info_only=0) -> PyObject *\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_extractFont(self, xref, info_only)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extractImage(self, xref=0):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document_extractImage(self, xref)", "response": "Extract image which xref is pointing to."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a document from the database.", "response": "def _delToC(self):\n        \"\"\"_delToC(self) -> PyObject *\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        val = _fitz.Document__delToC(self)\n        self.initData()\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _addFormFont(self, name, font):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__addFormFont(self, name, font)", "response": "Add a form font."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getOLRootNumber(self):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__getOLRootNumber(self)", "response": "Get the root number of the OL document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _delXmlMetadata(self):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__delXmlMetadata(self)", "response": "Delete xml metadata from the document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn string representation of xref.", "response": "def _getXrefString(self, xref, compressed=1):\n        \"\"\"_getXrefString(self, xref, compressed=1) -> PyObject *\"\"\"\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n\n        return _fitz.Document__getXrefString(self, xref, compressed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the trailer string.", "response": "def _getTrailerString(self, compressed=1):\n        \"\"\"_getTrailerString(self, compressed=1) -> PyObject *\"\"\"\n        if self.isClosed:\n            raise ValueError(\"operation illegal for closed doc\")\n\n        return _fitz.Document__getTrailerString(self, compressed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getXrefStream(self, xref):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__getXrefStream(self, xref)", "response": "Return a stream of the xref."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the object with the given xref.", "response": "def _updateObject(self, xref, text, page=None):\n        \"\"\"_updateObject(self, xref, text, page=None) -> PyObject *\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__updateObject(self, xref, text, page)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the stream of the document.", "response": "def _updateStream(self, xref=0, stream=None, new=0):\n        \"\"\"_updateStream(self, xref=0, stream=None, new=0) -> PyObject *\"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__updateStream(self, xref, stream, new)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setMetadata(self, text):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n\n        return _fitz.Document__setMetadata(self, text)", "response": "Set metadata for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a list of fonts used on a page.", "response": "def getPageFontList(self, pno):\n        \"\"\"Retrieve a list of fonts used on a page.\n        \"\"\"\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if self.isPDF:\n            return self._getPageInfo(pno, 1)\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getPageImageList(self, pno):\n        if self.isClosed or self.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        if self.isPDF:\n            return self._getPageInfo(pno, 2)\n        return []", "response": "Retrieve a list of images used on a page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copyPage(self, pno, to=-1):\n        pl = list(range(len(self)))\n        if pno < 0 or pno > pl[-1]:\n            raise ValueError(\"'from' page number out of range\")\n        if to < -1 or to > pl[-1]:\n            raise ValueError(\"'to' page number out of range\")\n        if to == -1:\n            pl.append(pno)\n        else:\n            pl.insert(to, pno)\n        return self.select(pl)", "response": "Copy a page to before some other page of the document. Specify to = - 1 to copy after last page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving a page to before some other page of the document. Specify to = - 1 to move after last page.", "response": "def movePage(self, pno, to = -1):\n        \"\"\"Move a page to before some other page of the document. Specify 'to = -1' to move after last page.\n        \"\"\"\n        pl = list(range(len(self)))\n        if pno < 0 or pno > pl[-1]:\n            raise ValueError(\"'from' page number out of range\")\n        if to < -1 or to > pl[-1]:\n            raise ValueError(\"'to' page number out of range\")\n        pl.remove(pno)\n        if to == -1:\n            pl.append(pno)\n        else:\n            pl.insert(to-1, pno)\n        return self.select(pl)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deletePage(self, pno = -1):\n        pl = list(range(len(self)))\n        if pno < -1 or pno > pl[-1]:\n            raise ValueError(\"page number out of range\")\n        if pno >= 0:\n            pl.remove(pno)\n        else:\n            pl.remove(pl[-1])\n        return self.select(pl)", "response": "Delete a page from the document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting pages from the document. First page is 0 last page is - 1.", "response": "def deletePageRange(self, from_page = -1, to_page = -1):\n        \"\"\"Delete pages from the document. First page is '0', last page is '-1'.\n        \"\"\"\n        pl = list(range(len(self)))\n        f = from_page\n        t = to_page\n        if f == -1:\n            f = pl[-1]\n        if t == -1:\n            t = pl[-1]\n        if not 0 <= f <= t <= pl[-1]:\n            raise ValueError(\"page number(s) out of range\")\n        for i in range(f, t+1):\n            pl.remove(i)\n        return self.select(pl)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _forget_page(self, page):\n        pid = id(page)\n        if pid in self._page_refs:\n            self._page_refs[pid] = None", "response": "Remove a page from document page dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvalidate all pages in document dictionary.", "response": "def _reset_page_refs(self):\n        \"\"\"Invalidate all pages in document dictionary.\"\"\"\n        if self.isClosed:\n            return\n        for page in self._page_refs.values():\n            if page:\n                page._erase()\n                page = None\n        self._page_refs.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bound(self):\n        CheckParent(self)\n\n        val = _fitz.Page_bound(self)\n        val = Rect(val)\n\n        return val", "response": "Return the bound of the page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, dw, m):\n        CheckParent(self)\n\n        return _fitz.Page_run(self, dw, m)", "response": "Run a page from a cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding Line annot for points p1 and p2.", "response": "def addLineAnnot(self, p1, p2):\n        \"\"\"Add 'Line' annot for points p1 and p2.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addLineAnnot(self, p1, p2)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a sticky note at position point.", "response": "def addTextAnnot(self, point, text):\n        \"\"\"Add a 'sticky note' at position 'point'.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addTextAnnot(self, point, text)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addInkAnnot(self, list):\n        CheckParent(self)\n\n        val = _fitz.Page_addInkAnnot(self, list)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Add a handwriting as a list of point - likes. Each sublist forms an independent stroke. Each sublist forms an independent stroke. Each sublist forms an independent stroke."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a rubber stamp in a rectangle.", "response": "def addStampAnnot(self, rect, stamp=0):\n        \"\"\"Add a 'rubber stamp' in a rectangle.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addStampAnnot(self, rect, stamp)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addFileAnnot(self, point, buffer, filename, ufilename=None, desc=None):\n        CheckParent(self)\n\n        val = _fitz.Page_addFileAnnot(self, point, buffer, filename, ufilename, desc)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Add a FileAttachment annotation at location point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addStrikeoutAnnot(self, rect):\n        CheckParent(self)\n\n        val = _fitz.Page_addStrikeoutAnnot(self, rect)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Add a strikeout annotation to the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nunderlines content in a rectangle or quadrilateral.", "response": "def addUnderlineAnnot(self, rect):\n        \"\"\"Underline content in a rectangle or quadrilateral.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addUnderlineAnnot(self, rect)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addHighlightAnnot(self, rect):\n        CheckParent(self)\n\n        val = _fitz.Page_addHighlightAnnot(self, rect)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Highlight content in a rectangle or quadrilateral."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addRectAnnot(self, rect):\n        CheckParent(self)\n\n        val = _fitz.Page_addRectAnnot(self, rect)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Add a Rectangle annotation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a Circle annotation.", "response": "def addCircleAnnot(self, rect):\n        \"\"\"Add a 'Circle' annotation.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addCircleAnnot(self, rect)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addPolylineAnnot(self, points):\n        CheckParent(self)\n\n        val = _fitz.Page_addPolylineAnnot(self, points)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val", "response": "Add a Polyline annotation for a sequence of points."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a Polygon annotation for a sequence of points.", "response": "def addPolygonAnnot(self, points):\n        \"\"\"Add a 'Polygon' annotation for a sequence of points.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addPolygonAnnot(self, points)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a FreeText annotation in rectangle rect.", "response": "def addFreetextAnnot(self, rect, text, fontsize=12, fontname=None, color=None, rotate=0):\n        \"\"\"Add a 'FreeText' annotation in rectangle 'rect'.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_addFreetextAnnot(self, rect, text, fontsize, fontname, color, rotate)\n\n        if not val: return\n        val.thisown = True\n        val.parent = weakref.proxy(self)\n        self._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addWidget(self, widget):\n        CheckParent(self)\n        doc = self.parent\n        if not doc.isPDF:\n            raise ValueError(\"not a PDF\")\n        widget._validate()\n\n    # Check if PDF already has our fonts.\n    # If none insert all of them in a new object and store the xref.\n    # Else only add any missing fonts.\n    # To determine the situation, /DR object is checked.\n        xref = 0\n        ff = doc.FormFonts               # /DR object: existing fonts\n        if not widget.text_font:         # ensure default\n            widget.text_font = \"Helv\"\n        if not widget.text_font in ff:   # if no existent font ...\n            if not doc.isFormPDF or not ff:   # a fresh /AcroForm PDF!\n                xref = doc._getNewXref()      # insert all our fonts\n                doc._updateObject(xref, Widget_fontobjects)\n            else:                        # add any missing fonts\n                for k in Widget_fontdict.keys():\n                    if not k in ff:      # add our font if missing\n                        doc._addFormFont(k, Widget_fontdict[k])\n            widget._adjust_font()        # ensure correct font spelling\n        widget._dr_xref = xref           # non-zero causes /DR creation\n\n    # now create the /DA string\n        if   len(widget.text_color) == 3:\n            fmt = \"{:g} {:g} {:g} rg /{f:s} {s:g} Tf \" + widget._text_da\n        elif len(widget.text_color) == 1:\n            fmt = \"{:g} g /{f:s} {s:g} Tf \" + widget._text_da\n        elif len(widget.text_color) == 4:\n            fmt = \"{:g} {:g} {:g} {:g} k /{f:s} {s:g} Tf \" + widget._text_da\n        widget._text_da = fmt.format(*widget.text_color, f=widget.text_font,\n                                     s=widget.text_fontsize)\n    # create the widget at last\n        annot = self._addWidget(widget)\n        if annot:\n            annot.thisown = True\n            annot.parent = weakref.proxy(self) # owning page object\n            self._annot_refs[id(annot)] = annot\n        return annot", "response": "Add a form field to the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadLinks(self):\n        CheckParent(self)\n\n        val = _fitz.Page_loadLinks(self)\n\n        if val:\n            val.thisown = True\n            val.parent = weakref.proxy(self) # owning page object\n            self._annot_refs[id(val)] = val\n            if self.parent.isPDF:\n                val.xref = self._getLinkXrefs()[0]\n            else:\n                val.xref = 0\n\n\n        return val", "response": "Load links from page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef firstAnnot(self):\n        CheckParent(self)\n\n        val = _fitz.Page_firstAnnot(self)\n        if val:\n            val.thisown = True\n            val.parent = weakref.proxy(self) # owning page object\n            self._annot_refs[id(val)] = val\n\n        return val", "response": "Points to first annotation on page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deleteLink(self, linkdict):\n        CheckParent(self)\n\n        val = _fitz.Page_deleteLink(self, linkdict)\n        if linkdict[\"xref\"] == 0: return\n        linkid = linkdict[\"id\"]\n        try:\n            linkobj = self._annot_refs[linkid]\n            linkobj._erase()\n        except:\n            pass\n\n\n        return val", "response": "Delete a link from the page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting annot if PDF and return next one", "response": "def deleteAnnot(self, fannot):\n        \"\"\"Delete annot if PDF and return next one\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_deleteAnnot(self, fannot)\n        if val:\n            val.thisown = True\n            val.parent = weakref.proxy(self) # owning page object\n            val.parent._annot_refs[id(val)] = val\n        fannot._erase()\n\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve width height of MediaBox.", "response": "def MediaBoxSize(self):\n        \"\"\"Retrieve width, height of /MediaBox.\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Page_MediaBoxSize(self)\n\n        val = Point(val)\n        if not bool(val):\n            r = self.rect\n            val = Point(r.width, r.height)\n\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CropBoxPosition(self):\n        CheckParent(self)\n\n        val = _fitz.Page_CropBoxPosition(self)\n        val = Point(val)\n\n        return val", "response": "Retrieve position of cropBox. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF. Return 0 for non - PDF."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap for _fitz. Page__showPDFpage.", "response": "def _showPDFpage(self, fz_srcpage, overlay=1, matrix=None, xref=0, clip=None, graftmap=None, _imgname=None):\n        \"\"\"_showPDFpage(self, fz_srcpage, overlay=1, matrix=None, xref=0, clip=None, graftmap=None, _imgname=None) -> PyObject *\"\"\"\n        return _fitz.Page__showPDFpage(self, fz_srcpage, overlay, matrix, xref, clip, graftmap, _imgname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _insertImage(self, filename=None, pixmap=None, stream=None, overlay=1, matrix=None, _imgname=None, _imgpointer=None):\n        return _fitz.Page__insertImage(self, filename, pixmap, stream, overlay, matrix, _imgname, _imgpointer)", "response": "Internal method to insert image into page."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a font into a fontbuffer.", "response": "def _insertFont(self, fontname, bfname, fontfile, fontbuffer, set_simple, idx, wmode, serif, encoding, ordering):\n        \"\"\"_insertFont(self, fontname, bfname, fontfile, fontbuffer, set_simple, idx, wmode, serif, encoding, ordering) -> PyObject *\"\"\"\n        return _fitz.Page__insertFont(self, fontname, bfname, fontfile, fontbuffer, set_simple, idx, wmode, serif, encoding, ordering)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getTransformation(self):\n        CheckParent(self)\n\n        val = _fitz.Page__getTransformation(self)\n        val = Matrix(val)\n\n        return val", "response": "Get the current transformation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _forget_annot(self, annot):\n        aid = id(annot)\n        if aid in self._annot_refs:\n            self._annot_refs[aid] = None", "response": "Remove an annot from reference dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _reset_annot_refs(self):\n        for annot in self._annot_refs.values():\n            if annot:\n                annot._erase()\n        self._annot_refs.clear()", "response": "Invalidate and delete all annots of this page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tintWith(self, red, green, blue):\n\n        if not self.colorspace or self.colorspace.n > 3:\n            print(\"warning: colorspace invalid for function\")\n            return\n\n        return _fitz.Pixmap_tintWith(self, red, green, blue)", "response": "Tint with color space."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the pixel at x y to the integers in sequence color.", "response": "def setPixel(self, x, y, color):\n        \"\"\"Set the pixel at (x,y) to the integers in sequence 'color'.\"\"\"\n        return _fitz.Pixmap_setPixel(self, x, y, color)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef irect(self):\n        val = _fitz.Pixmap_irect(self)\n        val = IRect(val)\n\n        return val", "response": "Return the irect of the current image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uri(self):\n        val = _fitz.Outline_uri(self)\n\n        if val:\n            nval = \"\".join([c for c in val if 32 <= ord(c) <= 127])\n            val = nval\n        else:\n            val = \"\"\n\n\n        return val", "response": "Return the base URI of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rect(self):\n        CheckParent(self)\n\n        val = _fitz.Annot_rect(self)\n        val = Rect(val)\n\n        return val", "response": "Rectangle containing the annot"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the appearance of an annotation.", "response": "def update(self, fontsize=0.0, text_color=None, border_color=None, fill_color=None, rotate=-1):\n        \"\"\"Update the appearance of an annotation.\"\"\"\n\n        if self.type[0] == ANNOT_WIDGET:\n            print(\"Use updateWidget method for form fields.\")\n            return False\n\n        val = _fitz.Annot_update(self, fontsize, text_color, border_color, fill_color, rotate)\n\n        \"\"\"\n        The following code fixes shortcomings of MuPDF's \"pdf_update_annot\"\n        function. Currently these are:\n        1. Opacity (all annots). MuPDF ignores this proprty. This requires\n           to add an ExtGState (extended graphics state) object in the\n           C code as well.\n        2. Dashing (all annots). MuPDF ignores this proprty.\n        3. Colors and font size for FreeText annotations.\n        4. Line end icons also for POLYGON and POLY_LINE annotations.\n           MuPDF only honors them for LINE annotations.\n        5. Always perform a \"clean\" for the annot, because MuPDF does not\n           enclose their syntax in a string pair \"q ... Q\", which may cause\n           Adobe and other readers not to display the annot.\n\n        \"\"\"\n        if not val is True:  # skip if something went wrong\n            return val\n\n        def color_string(cs, code):\n            \"\"\"Return valid PDF color operator for a given color sequence.\n            \"\"\"\n            if cs is None: return \"\"\n            if hasattr(cs, \"__float__\") or len(cs) == 1:\n                app = \" g\\n\" if code == \"f\" else \" G\\n\"\n            elif len(cs) == 3:\n                app = \" rg\\n\" if code == \"f\" else \" RG\\n\"\n            else:\n                app = \" k\\n\" if code == \"f\" else \" K\\n\"\n            if hasattr(cs, \"__len__\"):\n                col = \" \".join(map(str, cs)) + app\n            else:\n                col = \"%g\" % cs + app\n            return bytes(col, \"utf8\") if not fitz_py2 else col\n\n        type   = self.type[0]               # get the annot type\n        dt     = self.border[\"dashes\"]      # get the dashes spec\n        bwidth = self.border[\"width\"]       # get border line width\n        stroke = self.colors[\"stroke\"]      # get the stroke color\n        fill   = self.colors[\"fill\"]        # get the fill color\n        rect   = None                       # used if we change the rect here\n        bfill  = color_string(fill, \"f\")\n        p_ctm  = self.parent._getTransformation() # page transformation matrix\n        imat   = ~p_ctm                     # inverse page transf. matrix\n\n        line_end_le, line_end_ri = 0, 0     # line end codes\n        if self.lineEnds:\n            line_end_le, line_end_ri = self.lineEnds\n\n        ap     = self._getAP()              # get the annot operator source\n        ap_updated = False                  # assume we did nothing\n\n        if type == ANNOT_FREETEXT:\n            CheckColor(fill_color)\n            CheckColor(border_color)\n            CheckColor(text_color)\n\n            ap_tab = ap.splitlines()        # split AP stream into lines\n            idx_BT = ap_tab.index(b\"BT\")    # line no. of text start\n        # to avoid effort, we rely on a fixed format generated by MuPDF for\n        # this annot type: line 0 = fill color, line 5 border color, etc.\n            if fill_color is not None:\n                ap_tab[0] = color_string(fill_color, \"f\")\n                ap_updated = True\n            else:\n                ap_tab[0] = ap_tab[1] = ap_tab[2] = b\"\"\n                ap_updated = True\n\n            if idx_BT == 7:\n                if bwidth > 0:\n                    if border_color is not None:\n                        ap_tab[4] = color_string(border_color, \"s\")\n                        ap_updated = True\n                else: # for zero border width suppress border\n                    ap_tab[3] = b\"0 w\"\n                    ap_tab[4] = ap_tab[5] = ap_tab[6] = b\"\"\n                    ap_updated = True\n\n            if text_color is not None:\n                ap_tab[idx_BT + 1] = color_string(text_color, \"f\")\n                ap_updated = True\n\n            if fontsize > 0.0:\n                x = ap_tab[idx_BT + 2].split()\n                x[1] = b\"%g\" % fontsize\n                ap_tab[idx_BT + 2] = b\" \".join(x)\n                ap_updated = True\n\n            if ap_updated:\n                ap = b\"\\n\".join(ap_tab)         # updated AP stream\n\n        if bfill != \"\":\n            if type == ANNOT_POLYGON:\n                ap = ap[:-1] + bfill + b\"b\" # close, fill, and stroke\n                ap_updated = True\n            elif type == ANNOT_POLYLINE:\n                ap = ap[:-1] + bfill + b\"B\" # fill and stroke\n                ap_updated = True\n\n        # Dashes not handled by MuPDF, so we do it here.\n        if dt:\n            dash = \"[\" + \" \".join(map(str, dt)) + \"] d\\n\"\n            ap = dash.encode(\"utf-8\") + ap\n        # reset dashing - only applies for LINE annots with line ends given\n            ap = ap.replace(b\"\\nS\\n\", b\"\\nS\\n[] d\\n\", 1)\n            ap_updated = True\n\n        # Opacity not handled by MuPDF, so we do it here. The /ExtGState object\n        # \"Alp0\" referenced here has already been added by our C code.\n        if 0 <= self.opacity < 1:\n            ap = b\"/Alp0 gs\\n\" + ap\n            ap_updated = True\n\n        #----------------------------------------------------------------------\n        # the following handles line end symbols for 'Polygon' and 'Polyline\n        #----------------------------------------------------------------------\n        if max(line_end_le, line_end_ri) > 0 and type in (ANNOT_POLYGON, ANNOT_POLYLINE):\n\n            le_funcs = (None, TOOLS._le_square, TOOLS._le_circle,\n                        TOOLS._le_diamond, TOOLS._le_openarrow,\n                        TOOLS._le_closedarrow, TOOLS._le_butt,\n                        TOOLS._le_ropenarrow, TOOLS._le_rclosedarrow,\n                        TOOLS._le_slash)\n            le_funcs_range = range(1, len(le_funcs))\n            d = 4 * max(1, self.border[\"width\"])\n            rect = self.rect + (-d, -d, d, d)\n            ap_updated = True\n            points = self.vertices\n            ap = b\"q\\n\" + ap + b\"\\nQ\\n\"\n            if line_end_le in le_funcs_range:\n                p1 = Point(points[0]) * imat\n                p2 = Point(points[1]) * imat\n                left = le_funcs[line_end_le](self, p1, p2, False)\n                ap += bytes(left, \"utf8\") if not fitz_py2 else left\n            if line_end_ri in le_funcs_range:\n                p1 = Point(points[-2]) * imat\n                p2 = Point(points[-1]) * imat\n                left = le_funcs[line_end_ri](self, p1, p2, True)\n                ap += bytes(left, \"utf8\") if not fitz_py2 else left\n\n        if ap_updated:\n            if rect:                        # rect modified here?\n                self.setRect(rect)\n                self._setAP(ap, rect = 1)\n            else:\n                self._setAP(ap, rect = 0)\n\n        # always perform a clean to wrap stream by \"q\" / \"Q\"\n        self._cleanContents()\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fileUpd(self, buffer=None, filename=None, ufilename=None, desc=None):\n\n        CheckParent(self)\n\n\n        return _fitz.Annot_fileUpd(self, buffer, filename, ufilename, desc)", "response": "Update an annotation attached file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn next annotation in the list.", "response": "def next(self):\n        \"\"\"next(self) -> Annot\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Annot_next(self)\n        if val:\n            val.thisown = True\n            val.parent = self.parent # copy owning page object from previous annot\n            val.parent._annot_refs[id(val)] = val\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget image as a Pixmap.", "response": "def getPixmap(self, matrix=None, colorspace=None, alpha=0):\n        \"\"\"getPixmap(self, matrix=None, colorspace=None, alpha=0) -> Pixmap\"\"\"\n        CheckParent(self)\n\n        return _fitz.Annot_getPixmap(self, matrix, colorspace, alpha)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets border for the link.", "response": "def _setBorder(self, border, doc, xref):\n        \"\"\"_setBorder(self, border, doc, xref) -> PyObject *\"\"\"\n        return _fitz.Link__setBorder(self, border, doc, xref)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting color for the link.", "response": "def _setColors(self, colors, doc, xref):\n        \"\"\"_setColors(self, colors, doc, xref) -> PyObject *\"\"\"\n        return _fitz.Link__setColors(self, colors, doc, xref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uri(self):\n        CheckParent(self)\n\n        val = _fitz.Link_uri(self)\n\n        if not val:\n            val = \"\"\n        else:\n            nval = \"\".join([c for c in val if 32 <= ord(c) <= 127])\n            val = nval\n\n\n        return val", "response": "Return the link s URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate link destination details.", "response": "def dest(self):\n        \"\"\"Create link destination details.\"\"\"\n        if hasattr(self, \"parent\") and self.parent is None:\n            raise ValueError(\"orphaned object: parent is None\")\n        if self.parent.parent.isClosed or self.parent.parent.isEncrypted:\n            raise ValueError(\"operation illegal for closed / encrypted doc\")\n        doc = self.parent.parent\n\n        if self.isExternal or self.uri.startswith(\"#\"):\n            uri = None\n        else:\n            uri = doc.resolveLink(self.uri)\n\n        return linkDest(self, uri)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rect(self):\n        CheckParent(self)\n\n        val = _fitz.Link_rect(self)\n        val = Rect(val)\n\n        return val", "response": "Return the current rectangular area."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn next link in the chain.", "response": "def next(self):\n        \"\"\"next(self) -> Link\"\"\"\n        CheckParent(self)\n\n        val = _fitz.Link_next(self)\n\n        if val:\n            val.thisown = True\n            val.parent = self.parent # copy owning page from prev link\n            val.parent._annot_refs[id(val)] = val\n            if self.xref > 0: # prev link has an xref\n                link_xrefs = self.parent._getLinkXrefs()\n                idx = link_xrefs.index(self.xref)\n                val.xref = link_xrefs[idx + 1]\n            else:\n                val.xref = 0\n\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a display list.", "response": "def run(self, dw, m, area):\n        \"\"\"run(self, dw, m, area) -> PyObject *\"\"\"\n        return _fitz.DisplayList_run(self, dw, m, area)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Rectangle object containing the current display list s size.", "response": "def rect(self):\n        \"\"\"rect(self) -> PyObject *\"\"\"\n        val = _fitz.DisplayList_rect(self)\n        val = Rect(val)\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getPixmap(self, matrix=None, colorspace=None, alpha=0, clip=None):\n        return _fitz.DisplayList_getPixmap(self, matrix, colorspace, alpha, clip)", "response": "Get a Pixmap from the DisplayList."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for a specific entry in the text page.", "response": "def search(self, needle, hit_max=16, quads=0):\n        \"\"\"search(self, needle, hit_max=16, quads=0) -> PyObject *\"\"\"\n        val = _fitz.TextPage_search(self, needle, hit_max, quads)\n\n        if len(val) == 0:\n            return val\n        nval = []\n        for v in val:\n            q = Quad(v)\n            if not quads:\n                nval.append(q.rect)\n            else:\n                nval.append(q)\n        val = nval\n\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extractText(self, format):\n        val = _fitz.TextPage__extractText(self, format)\n\n        if format != 2:\n            return val\n        import base64, json\n\n        class b64encode(json.JSONEncoder):\n            def default(self,s):\n                if not fitz_py2 and type(s) is bytes:\n                    return base64.b64encode(s).decode()\n                if type(s) is bytearray:\n                    if fitz_py2:\n                        return base64.b64encode(s)\n                    else:\n                        return base64.b64encode(s).decode()\n\n        val = json.dumps(val, separators=(\",\", \":\"), cls=b64encode, indent=1)\n\n\n        return val", "response": "_extractText - Helper function for _fitz. TextPage__extractText."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert new content into the page.", "response": "def _insert_contents(self, fzpage, newcont, overlay):\n        \"\"\"_insert_contents(self, fzpage, newcont, overlay) -> PyObject *\"\"\"\n        return _fitz.Tools__insert_contents(self, fzpage, newcont, overlay)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmeasure length of a string for a Base14 font.", "response": "def measure_string(self, text, fontname, fontsize, encoding=0):\n        \"\"\"Measure length of a string for a Base14 font.\"\"\"\n        return _fitz.Tools_measure_string(self, text, fontname, fontsize, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _hor_matrix(self, C, P):\n        S = (P - C).unit                        # unit vector C -> P\n        return Matrix(1, 0, 0, 1, -C.x, -C.y) * Matrix(S.x, -S.y, S.y, S.x, 0, 0)", "response": "Calculate the homogeneous matrix that rotates and translates the vector C - > P such that C is mapped to Point ( 0 ) and P - > Point ( 0 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _le_annot_parms(self, annot, p1, p2):\n        w = annot.border[\"width\"]          # line width\n        sc = annot.colors[\"stroke\"]        # stroke color\n        if not sc: sc = (0,0,0)\n        scol = \" \".join(map(str, sc)) + \" RG\\n\"\n        fc = annot.colors[\"fill\"]          # fill color\n        if not fc: fc = (0,0,0)\n        fcol = \" \".join(map(str, fc)) + \" rg\\n\"\n        nr = annot.rect\n        np1 = p1                   # point coord relative to annot rect\n        np2 = p2                   # point coord relative to annot rect\n        m = self._hor_matrix(np1, np2)        # matrix makes the line horizontal\n        im = ~m                            # inverted matrix\n        L = np1 * m                        # converted start (left) point\n        R = np2 * m                        # converted end (right) point\n        if 0 <= annot.opacity < 1:\n            opacity = \"/Alp0 gs\\n\"\n        else:\n            opacity = \"\"\n        return m, im, L, R, w, scol, fcol, opacity", "response": "Get common parameters for making line end symbols."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _oval_string(self, p1, p2, p3, p4):\n        def bezier(p, q, r):\n            f = \"%f %f %f %f %f %f c\\n\"\n            return f % (p.x, p.y, q.x, q.y, r.x, r.y)\n\n        kappa = 0.55228474983              # magic number\n        ml = p1 + (p4 - p1) * 0.5          # middle points ...\n        mo = p1 + (p2 - p1) * 0.5          # for each ...\n        mr = p2 + (p3 - p2) * 0.5          # polygon ...\n        mu = p4 + (p3 - p4) * 0.5          # side\n        ol1 = ml + (p1 - ml) * kappa       # the 8 bezier\n        ol2 = mo + (p1 - mo) * kappa       # helper points\n        or1 = mo + (p2 - mo) * kappa\n        or2 = mr + (p2 - mr) * kappa\n        ur1 = mr + (p3 - mr) * kappa\n        ur2 = mu + (p3 - mu) * kappa\n        ul1 = mu + (p4 - mu) * kappa\n        ul2 = ml + (p4 - ml) * kappa\n    # now draw, starting from middle point of left side\n        ap = \"%f %f m\\n\" % (ml.x, ml.y)\n        ap += bezier(ol1, ol2, mo)\n        ap += bezier(or1, or2, mr)\n        ap += bezier(ur1, ur2, mu)\n        ap += bezier(ul1, ul2, ml)\n        return ap", "response": "Return a string defining an oval within a 4 - polygon provided as points\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking stream commands for diamond line end symbol. lr denotes left or right point.", "response": "def _le_diamond(self, annot, p1, p2, lr):\n        \"\"\"Make stream commands for diamond line end symbol. \"lr\" denotes left (False) or right point.\n        \"\"\"\n        m, im, L, R, w, scol, fcol, opacity = self._le_annot_parms(annot, p1, p2)\n        shift = 2.5             # 2*shift*width = length of square edge\n        d = shift * max(1, w)\n        M = R - (d/2., 0) if lr else L + (d/2., 0)\n        r = Rect(M, M) + (-d, -d, d, d)         # the square\n    # the square makes line longer by (2*shift - 1)*width\n        p = (r.tl + (r.bl - r.tl) * 0.5) * im\n        ap = \"q\\n%s%f %f m\\n\" % (opacity, p.x, p.y)\n        p = (r.tl + (r.tr - r.tl) * 0.5) * im\n        ap += \"%f %f l\\n\"   % (p.x, p.y)\n        p = (r.tr + (r.br - r.tr) * 0.5) * im\n        ap += \"%f %f l\\n\"   % (p.x, p.y)\n        p = (r.br + (r.bl - r.br) * 0.5) * im\n        ap += \"%f %f l\\n\"   % (p.x, p.y)\n        ap += \"%g w\\n\" % w\n        ap += scol + fcol + \"b\\nQ\\n\"\n        return ap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking stream commands for circle line end symbol. lr denotes left or right point.", "response": "def _le_circle(self, annot, p1, p2, lr):\n        \"\"\"Make stream commands for circle line end symbol. \"lr\" denotes left (False) or right point.\n        \"\"\"\n        m, im, L, R, w, scol, fcol, opacity = self._le_annot_parms(annot, p1, p2)\n        shift = 2.5             # 2*shift*width = length of square edge\n        d = shift * max(1, w)\n        M = R - (d/2., 0) if lr else L + (d/2., 0)\n        r = Rect(M, M) + (-d, -d, d, d)         # the square\n        ap = \"q\\n\" + opacity + self._oval_string(r.tl * im, r.tr * im, r.br * im, r.bl * im)\n        ap += \"%g w\\n\" % w\n        ap += scol + fcol + \"b\\nQ\\n\"\n        return ap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _le_butt(self, annot, p1, p2, lr):\n        m, im, L, R, w, scol, fcol, opacity = self._le_annot_parms(annot, p1, p2)\n        shift = 3\n        d = shift * max(1, w)\n        M = R if lr else L\n        top = (M + (0, -d/2.)) * im\n        bot = (M + (0, d/2.)) * im\n        ap = \"\\nq\\n%s%f %f m\\n\" % (opacity, top.x, top.y)\n        ap += \"%f %f l\\n\" % (bot.x, bot.y)\n        ap += \"%g w\\n\" % w\n        ap += scol + \"s\\nQ\\n\"\n        return ap", "response": "Make stream commands for line end symbol. lr denotes left or right point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _le_slash(self, annot, p1, p2, lr):\n        m, im, L, R, w, scol, fcol, opacity = self._le_annot_parms(annot, p1, p2)\n        rw = 1.1547 * max(1, w) * 1.0         # makes rect diagonal a 30 deg inclination\n        M = R if lr else L\n        r = Rect(M.x - rw, M.y - 2 * w, M.x + rw, M.y + 2 * w)\n        top = r.tl * im\n        bot = r.br * im\n        ap = \"\\nq\\n%s%f %f m\\n\" % (opacity, top.x, top.y)\n        ap += \"%f %f l\\n\" % (bot.x, bot.y)\n        ap += \"%g w\\n\" % w\n        ap += scol + \"s\\nQ\\n\"\n        return ap", "response": "Make stream commands for line end symbol. lr denotes left or right point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _le_ropenarrow(self, annot, p1, p2, lr):\n        m, im, L, R, w, scol, fcol, opacity = self._le_annot_parms(annot, p1, p2)\n        shift = 2.5\n        d = shift * max(1, w)\n        p2 = R - (d/3., 0) if lr else L + (d/3., 0)\n        p1 = p2 + (2*d, -d) if lr else p2 + (-2*d, -d)\n        p3 = p2 + (2*d, d) if lr else p2 + (-2*d, d)\n        p1 *= im\n        p2 *= im\n        p3 *= im\n        ap = \"\\nq\\n%s%f %f m\\n\" % (opacity, p1.x, p1.y)\n        ap += \"%f %f l\\n\" % (p2.x, p2.y)\n        ap += \"%f %f l\\n\" % (p3.x, p3.y)\n        ap += \"%g w\\n\" % w\n        ap += scol + fcol + \"S\\nQ\\n\"\n        return ap", "response": "Make stream commands for right open arrow line end symbol. lr denotes left or right point."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nend point of a reflected sun ray given an angle a.", "response": "def pbis(a):\n    \"\"\"End point of a reflected sun ray, given an angle a.\"\"\"\n    return(math.cos(3*a - math.pi), (math.sin(3*a - math.pi)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a key for a list of colors.", "response": "def sortkey(x):\n    \"\"\"Return '001002003' for (colorname, 1, 2, 3)\"\"\"\n    k = str(x[1]).zfill(3) + str(x[2]).zfill(3) + str(x[3]).zfill(3)\n    return k"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_descr(rect, annot):\n    annot.parent.insertText(rect.br + (10, 0),\n                    \"'%s' annotation\" % annot.type[1], color = red)", "response": "Print a short description to the right of an annot."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a table of a page in a PDF / ( open ) XPS / EPUB document.", "response": "def ParseTab(page, bbox, columns = None):\n    ''' Returns the parsed table of a page in a PDF / (open) XPS / EPUB document.\n    Parameters:\n    page: fitz.Page object\n    bbox: containing rectangle, list of numbers [xmin, ymin, xmax, ymax]\n    columns: optional list of column coordinates. If None, columns are generated\n    Returns the parsed table as a list of lists of strings.\n    The number of rows is determined automatically\n    from parsing the specified rectangle.\n    '''\n    tab_rect = fitz.Rect(bbox).irect\n    xmin, ymin, xmax, ymax = tuple(tab_rect)\n    \n    if tab_rect.isEmpty or tab_rect.isInfinite:\n        print(\"Warning: incorrect rectangle coordinates!\")\n        return []\n    \n    if type(columns) is not list or columns == []:\n        coltab = [tab_rect.x0, tab_rect.x1]\n    else:\n        coltab = sorted(columns)\n    \n    if xmin < min(coltab):\n        coltab.insert(0, xmin)\n    if xmax > coltab[-1]:\n        coltab.append(xmax)\n       \n    words = page.getTextWords()\n\n    if words == []:\n        print(\"Warning: page contains no text\")\n        return []\n    \n    alltxt = []\n    \n    # get words contained in table rectangle and distribute them into columns\n    for w in words:\n        ir = fitz.Rect(w[:4]).irect         # word rectangle\n        if ir in tab_rect:\n            cnr = 0                         # column index\n            for i in range(1, len(coltab)): # loop over column coordinates\n                if ir.x0 < coltab[i]:       # word start left of column border\n                    cnr = i - 1\n                    break\n            alltxt.append([ir.x0, ir.y0, ir.x1, cnr, w[4]])\n        \n    if alltxt == []:\n        print(\"Warning: no text found in rectangle!\")\n        return []\n    \n    alltxt.sort(key = itemgetter(1))        # sort words vertically\n    \n    # create the table / matrix\n    spantab = []                            # the output matrix\n\n    for y, zeile in groupby(alltxt, itemgetter(1)):\n        schema = [\"\"] * (len(coltab) - 1)\n        for c, words in groupby(zeile, itemgetter(3)):\n            entry = \" \".join([w[4] for w in words])\n            schema[c] = entry\n        spantab.append(schema)\n\n    return spantab"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pixlen(text, widthlist, fontsize):\n    pl = 0.0\n    for t in text:\n        pl += widthlist[ord(t)]\n    return pl * fontsize", "response": "Calculate the length of text in pixels given a list of glyph widths and the fontsize."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recoverpix(doc, item):\n    x = item[0]  # xref of PDF image\n    s = item[1]  # xref of its /SMask\n    \n    try:\n        pix1 = fitz.Pixmap(doc, x)     # make pixmap from image\n    except:\n        print(\"xref %i \" % x + doc._getGCTXerrmsg())\n        return None                    # skip if error\n\n    if s == 0:                    # has no /SMask\n        return pix1               # no special handling\n    \n    try:\n        pix2 = fitz.Pixmap(doc, s)    # create pixmap of /SMask entry\n    except:\n        print(\"cannot create mask %i for image xref %i\" % (s,x))\n        return pix1               # return w/ failed transparency\n        \n    # check that we are safe\n    if not (pix1.irect == pix2.irect and \\\n            pix1.alpha == pix2.alpha == 0 and \\\n            pix2.n == 1):\n        print(\"unexpected /SMask situation: pix1\", pix1, \"pix2\", pix2)\n        return pix1\n    pix = fitz.Pixmap(pix1)       # copy of pix1, alpha channel added\n    pix.setAlpha(pix2.samples)    # treat pix2.samples as alpha values\n    pix1 = pix2 = None            # free temp pixmaps\n    return pix", "response": "Return the pixmap for the item which is a list of 2 xref numbers. Second xrefNumber is that of an smask. First xrefNumber is that of an image. Second xrefNumber is that of an image. Second xrefNumber is that of an image. Second xrefNumber is that of an image. Second xrefNumber is that of an image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming PDF update of changed links.", "response": "def on_update_page_links(self, evt):\n        \"\"\" Perform PDF update of changed links.\"\"\"\n        if not self.update_links:                 # skip if unsupported links\n            evt.Skip()\n            return\n        pg = self.doc[getint(self.TextToPage.Value) -1]\n        for i in range(len(self.page_links)):\n            l = self.page_links[i]\n            if l.get(\"update\", False):            # \"update\" must be True\n                if l[\"xref\"] == 0:                # no xref => new link\n                    pg.insertLink(l)\n                elif l[\"kind\"] < 1 or l[\"kind\"] > len(self.linkTypeStrings):\n                    pg.deleteLink(l)              # delete invalid link\n                else:\n                    pg.updateLink(l)              # else link update\n            l[\"update\"] = False                   # reset update indicator\n            self.page_links[i] = l                # update list of page links\n        self.btn_Update.Disable()                 # disable update button\n        self.t_Update.Label = \"\"                  # and its message\n        self.btn_Save.Enable()\n        self.t_Save.Label = \"There are changes. Press to save them to file.\"\n        evt.Skip()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_linkType_changed(self, evt):\n        if self.current_idx < 0:\n            evt.Skip()\n            return\n        n = self.linkType.GetSelection()\n        lt_str = self.linkType.GetString(n)\n        lt = self.link_code[lt_str]\n        self.prep_link_details(lt)\n            \n        lnk = self.page_links[self.current_idx]\n        lnk[\"update\"] = True\n        lnk[\"kind\"] = lt\n        self.enable_update()\n\n        if lt == fitz.LINK_GOTO:\n            if not self.toPage.Value.isdecimal():\n                self.toPage.ChangeValue(\"1\")\n            self.toPage.Enable()\n            if not self.toLeft.Value.isdecimal():\n                self.toLeft.ChangeValue(\"0\")\n            self.toLeft.Enable()\n            if not self.toHeight.Value.isdecimal():\n                self.toHeight.ChangeValue(\"0\")\n            self.toHeight.Enable()\n            lnk[\"page\"] = int(self.toPage.Value) - 1\n            lnk[\"to\"] = fitz.Point(int(self.toLeft.Value),\n                                   int(self.toHeight.Value))\n\n        elif lt == fitz.LINK_GOTOR:\n            if not self.toFile.Value:\n                self.toFile.SetValue(self.text_in_rect())\n                self.toFile.MarkDirty()\n            if not self.toPage.Value.isdecimal():\n                self.toPage.ChangeValue(\"1\")\n            if not self.toLeft.Value.isdecimal():\n                self.toLeft.ChangeValue(\"0\")\n            if not self.toHeight.Value.isdecimal():\n                self.toHeight.ChangeValue(\"0\")\n            self.toLeft.Enable()\n            self.toPage.Enable()\n            self.toFile.Enable()\n            self.toHeight.Enable()\n            lnk[\"file\"] = self.toFile.Value\n            lnk[\"page\"] = int(self.toPage.Value) - 1\n            lnk[\"to\"] = fitz.Point(int(self.toLeft.Value),\n                                   int(self.toHeight.Value))\n            \n        elif lt == fitz.LINK_URI:\n            if not self.toURI.Value:\n                self.toURI.SetValue(self.text_in_rect())\n                self.toURI.MarkDirty()\n            lnk[\"uri\"] = self.toURI.Value\n            self.toURI.Enable()\n            \n        elif lt == fitz.LINK_LAUNCH:\n            if not self.toFile.Value:\n                self.toFile.SetValue(self.text_in_rect())\n                self.toFile.MarkDirty()\n            lnk[\"file\"] = self.toFile.Value\n            self.toFile.Enable()\n            \n        elif lt == fitz.LINK_NAMED:\n            self.toName.SetSelection(0)\n            self.toName.Enable()\n            \n        self.page_links[self.current_idx] = lnk\n            \n        evt.Skip()\n        return", "response": "User changed link kind so prepare available fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Rect_to_wxRect(self, fr):\n        r = (fr * self.zoom).irect   # zoomed IRect\n        return wx.Rect(r.x0, r.y0, r.width, r.height)", "response": "Return a zoomed wx. Rect for given fitz. Rect."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a shrunk fitz. Rect for given wx. Rect.", "response": "def wxRect_to_Rect(self, wr):\n        \"\"\" Return a shrunk fitz.Rect for given wx.Rect.\"\"\"\n        r = fitz.Rect(wr.x, wr.y, wr.x + wr.width, wr.y + wr.height)\n        return r * self.shrink"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if the bitmap contains the given number.", "response": "def is_in_free_area(self, nr, ok = -1):\n        \"\"\" Determine if rect covers a free area inside the bitmap.\"\"\"\n        for i, r in enumerate(self.link_rects):\n            if r.Intersects(nr) and i != ok:\n                return False\n        bmrect = wx.Rect(0,0,dlg.bitmap.Size[0],dlg.bitmap.Size[1])\n        return bmrect.Contains(nr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if cursor is inside one of the link hot spots.", "response": "def get_linkrect_idx(self, pos):\n        \"\"\" Determine if cursor is inside one of the link hot spots.\"\"\"\n        for i, r in enumerate(self.link_rects):\n            if r.Contains(pos):\n                return i\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if cursor is on bottom right corner of a hot spot.", "response": "def get_bottomrect_idx(self, pos):\n        \"\"\" Determine if cursor is on bottom right corner of a hot spot.\"\"\"\n        for i, r in enumerate(self.link_bottom_rects):\n            if r.Contains(pos):\n                return i\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns Bezier control points when pb and pe stand for a full period from ( 0 ) to ( 2 * pi 0 ) respectively.", "response": "def bsinPoints(pb, pe):\n    \"\"\"Return Bezier control points, when pb and pe stand for a full period\n    from (0,0) to (2*pi, 0), respectively, in the user's coordinate system.\n    The returned points can be used to draw up to four Bezier curves for\n    the complete phase of the sine function graph (0 to 360 degrees).\n    \"\"\"\n    v = pe - pb\n    assert v.y == 0, \"begin and end points must have same y coordinate\"\n    f = abs(v) * 0.5 / math.pi              # represents the unit\n    cp1 = 5.34295228e-01\n    cp2 = 1.01474288e+00\n    y_ampl = (0, f)\n    y_cp1 = (0, f * cp1)\n    y_cp2 = (0, f * cp2)\n\n    p0 = pb\n    p4 = pe\n    p1 = pb + v * 0.25 - y_ampl\n    p2 = pb + v * 0.5\n    p3 = pb + v * 0.75 + y_ampl\n    k1 = pb + v * (1./12.)  - y_cp1\n    k2 = pb + v * (2./12.)  - y_cp2\n    k3 = pb + v * (4./12.)  - y_cp2\n    k4 = pb + v * (5./12.)  - y_cp1\n    k5 = pb + v * (7./12.)  + y_cp1\n    k6 = pb + v * (8./12.)  + y_cp2\n    k7 = pb + v * (10./12.) + y_cp2\n    k8 = pb + v * (11./12.) + y_cp1\n    return p0, k1, k2, p1, k3, k4, p2, k5, k6, p3, k7, k8, p4"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrotating a list of points around a pivotal point pb.", "response": "def rot_points(pnts, pb, alfa):\n    \"\"\"Rotate a list of points by an angle alfa (radians) around pivotal point pb.\n    Intended for modifying the control points of trigonometric functions.\n    \"\"\"\n    points = []                   # rotated points\n    calfa = math.cos(alfa)\n    salfa = math.sin(alfa)\n    for p in pnts:\n        s = p - pb\n        r = abs(s)\n        if r > 0: s /= r\n        np = (s.x * calfa - s.y * salfa, s.y * calfa + s.x * salfa)\n        points.append(pb + fitz.Point(np)*r)\n    return points"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the PDF page with the specified page number rect and source image src in rectangle rect.", "response": "def showPDFpage(\n        page,\n        rect,\n        src,\n        pno=0,\n        overlay=True,\n        keep_proportion=True,\n        rotate=0,\n        reuse_xref=0,\n        clip = None,\n    ):\n    \"\"\"Show page number 'pno' of PDF 'src' in rectangle 'rect'.\n\n    Args:\n        rect: (rect-like) where to place the source image\n        src: (document) source PDF\n        pno: (int) source page number\n        overlay: (bool) put in foreground\n        keep_proportion: (bool) do not change width-height-ratio\n        rotate: (int) degrees (multiple of 90)\n        clip: (rect-like) part of source page rectangle\n    Returns:\n        xref of inserted object (for reuse)\n    \"\"\"\n\n    def calc_matrix(sr, tr, keep=True, rotate=0):\n        \"\"\" Calculate transformation matrix from source to target rect.\n\n        Notes:\n            The product of four matrices in this sequence: (1) translate correct\n            source corner to origin, (2) rotate, (3) scale, (4) translate to\n            target's top-left corner.\n        Args:\n            sr: source rect in PDF (!) coordinate system\n            tr: target rect in PDF coordinate system\n            keep: whether to keep source ratio of width to height\n            rotate: rotation angle in degrees\n        Returns:\n            Transformation matrix.\n        \"\"\"\n        # calc center point of source rect\n        smp = Point((sr.x1 + sr.x0) / 2., (sr.y1 + sr.y0) / 2.)\n        # calc center point of target rect\n        tmp = Point((tr.x1 + tr.x0) / 2., (tr.y1 + tr.y0) / 2.)\n\n        rot = Matrix(rotate)  # rotation matrix\n\n        # m moves to (0, 0), then rotates\n        m = Matrix(1, 0, 0, 1, -smp.x, -smp.y) * rot\n\n        sr1 = sr * m  # resulting source rect to calculate scale factors\n\n        fw = tr.width / sr1.width  # scale the width\n        fh = tr.height / sr1.height  # scale the height\n        if keep:\n            fw = fh = min(fw, fh)  # take min if keeping aspect ratio\n\n        m *= Matrix(fw, fh)  # concat scale matrix\n        m *= Matrix(1, 0, 0, 1, tmp.x, tmp.y)  # concat move to target center\n        return m\n\n    CheckParent(page)\n    doc = page.parent\n\n    if not doc.isPDF or not src.isPDF:\n        raise ValueError(\"not a PDF\")\n\n    rect = page.rect & rect  # intersect with page rectangle\n    if rect.isEmpty or rect.isInfinite:\n        raise ValueError(\"rect must be finite and not empty\")\n\n    if reuse_xref > 0:\n        warnings.warn(\"ignoring 'reuse_xref'\", DeprecationWarning)\n\n    while pno < 0:  # support negative page numbers\n        pno += len(src)\n    src_page = src[pno]  # load ource page\n    if len(src_page._getContents()) == 0:\n        raise ValueError(\"nothing to show - source page empty\")\n\n    tar_rect = rect * ~page._getTransformation()  # target rect in PDF coordinates\n\n    src_rect = src_page.rect if not clip else src_page.rect & clip  # source rect\n    if src_rect.isEmpty or src_rect.isInfinite:\n        raise ValueError(\"clip must be finite and not empty\")\n    src_rect = src_rect * ~src_page._getTransformation()  # ... in PDF coord\n\n    matrix = calc_matrix(src_rect, tar_rect, keep=keep_proportion, rotate=rotate)\n\n    # list of existing /Form /XObjects\n    ilst = [i[1] for i in doc._getPageInfo(page.number, 3)]\n\n    # create a name that is not in that list\n    n = \"fzFrm\"\n    i = 0\n    _imgname = n + \"0\"\n    while _imgname in ilst:\n        i += 1\n        _imgname = n + str(i)\n\n    isrc = src._graft_id          # used as key for graftmaps\n    if doc._graft_id == isrc:\n        raise ValueError(\"source document must not equal target\")\n\n    # check if we have already copied objects from this source doc\n    if isrc in doc.Graftmaps:     # yes: use the old graftmap\n        gmap = doc.Graftmaps[isrc]\n    else:                         # no: make a new graftmap\n        gmap = Graftmap(doc)\n        doc.Graftmaps[isrc] = gmap\n\n    # take note of generated xref for automatic reuse\n    pno_id = (isrc, pno)          # id of src[pno]\n    xref = doc.ShownPages.get(pno_id, 0)\n\n    xref = page._showPDFpage(\n                src_page,\n                overlay=overlay,\n                matrix=matrix,\n                xref=xref,\n                clip=src_rect,\n                graftmap=gmap,\n                _imgname=_imgname,\n            )\n    doc.ShownPages[pno_id] = xref\n\n    return xref"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting an image into the current page.", "response": "def insertImage(page, rect, filename=None, pixmap=None, stream=None, rotate=0,\n                keep_proportion = True,\n                overlay=True):\n    \"\"\"Insert an image in a rectangle on the current page.\n\n    Notes:\n        Exactly one of filename, pixmap or stream must be provided.\n    Args:\n        rect: (rect-like) where to place the source image\n        filename: (str) name of an image file\n        pixmap: (obj) a Pixmap object\n        stream: (bytes) an image in memory\n        rotate: (int) degrees (multiple of 90)\n        keep_proportion: (bool) whether to maintain aspect ratio\n        overlay: (bool) put in foreground\n    \"\"\"\n\n    def calc_matrix(fw, fh, tr, rotate=0):\n        \"\"\" Calculate transformation matrix for image insertion.\n\n        Notes:\n            The image will preserve its aspect ratio if and only if arguments\n            fw, fh are both equal to 1.\n        Args:\n            fw, fh: width / height ratio factors of image - floats in (0,1].\n                At least one of them (corresponding to the longer side) is equal to 1.\n            tr: target rect in PDF coordinates\n            rotate: rotation angle in degrees\n        Returns:\n            Transformation matrix.\n        \"\"\"\n        # center point of target rect\n        tmp = Point((tr.x1 + tr.x0) / 2., (tr.y1 + tr.y0) / 2.)\n\n        rot = Matrix(rotate)  # rotation matrix\n\n        # matrix m moves image center to (0, 0), then rotates\n        m = Matrix(1, 0, 0, 1, -0.5, -0.5) * rot\n\n        #sr1 = sr * m  # resulting image rect\n\n        # --------------------------------------------------------------------\n        # calculate the scale matrix\n        # --------------------------------------------------------------------\n        small = min(fw, fh)  # factor of the smaller side\n\n        if rotate not in (0, 180):\n            fw, fh = fh, fw  # width / height exchange their roles\n\n        if fw < 1: # portrait\n            if (float(tr.width) / fw) > (float(tr.height) / fh):\n                w = tr.height * small\n                h = tr.height\n            else:\n                w = tr.width\n                h = tr.width / small\n\n        elif fw != fh:  # landscape\n            if (float(tr.width) / fw) > (float(tr.height) / fh):\n                w = tr.height / small\n                h = tr.height\n            else:\n                w = tr.width\n                h = tr.width * small\n\n        else: # (treated as) equal sided\n            w = tr.width\n            h = tr.height\n\n        m *= Matrix(w, h)  # concat scale matrix\n\n        m *= Matrix(1, 0, 0, 1, tmp.x, tmp.y)  # concat move to target center\n\n        return m\n    # -------------------------------------------------------------------------\n\n    CheckParent(page)\n    doc = page.parent\n    if not doc.isPDF:\n        raise ValueError(\"not a PDF\")\n    if bool(filename) + bool(stream) + bool(pixmap) != 1:\n        raise ValueError(\"need exactly one of filename, pixmap, stream\")\n\n    if filename and not os.path.exists(filename):\n        raise FileNotFoundError(\"No such file: '%s'\" % filename)\n    elif stream and type(stream) not in (bytes, bytearray, io.BytesIO):\n        raise ValueError(\"stream must be bytes-like or BytesIO\")\n    elif pixmap and type(pixmap) is not Pixmap:\n        raise ValueError(\"pixmap must be a Pixmap\")\n\n    while rotate < 0:\n        rotate += 360\n    while rotate > 360:\n        rotate -= 360\n    if rotate not in (0, 90, 180, 270):\n        raise ValueError(\"bad rotate value\")\n\n    r = page.rect & rect\n    if r.isEmpty or r.isInfinite:\n        raise ValueError(\"rect must be finite and not empty\")\n    _imgpointer = None\n\n    if keep_proportion is True:  # for this we need the image dimension\n        if pixmap:  # this is the easy case\n            w = pixmap.width\n            h = pixmap.height\n        elif stream:  # use tool to access the information\n            # we also pass through the generated fz_image address\n            img_size = TOOLS.image_size(stream, keep_image=True)\n            w, h = img_size[:2]\n            stream = None  # make sure this arg is NOT used\n            _imgpointer = img_size[-1]  # pointer to fz_image\n        else:  # worst case, we need to read the file ourselves\n            img = open(filename, \"rb\")\n            stream = img.read()\n            img_size = TOOLS.image_size(stream, keep_image=True)\n            w, h = img_size[:2]\n            _imgpointer = img_size[-1]  # pointer to fz_image\n            stream = None  # make sure this arg is NOT used\n            filename = None  # make sure this arg is NOT used\n            img.close()  # close image file\n\n        maxf = max(w, h).__float__()\n        fw = w / maxf\n        fh = h / maxf\n    else:\n        fw = fh = 1.0\n\n    clip = r * ~page._getTransformation()  # target rect in PDF coordinates\n\n    matrix = calc_matrix(fw, fh, clip, rotate=rotate)\n\n    ilst = [i[7] for i in doc.getPageImageList(page.number)]\n    n = \"fzImg\"\n    i = 0\n    _imgname = n + \"0\"\n    while _imgname in ilst:\n        i += 1\n        _imgname = n + str(i)\n\n    page._insertImage(\n            filename=filename,  # image in file\n            pixmap=pixmap,  # image in pixmap\n            stream=stream,  # image in memory\n            matrix=matrix,  # generated matrix\n            overlay=overlay,\n            _imgname=_imgname,  # generated PDF resource name\n            _imgpointer=_imgpointer,  # address of fz_image\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for a string on a page.", "response": "def searchFor(page, text, hit_max = 16, quads = False):\n    \"\"\" Search for a string on a page.\n\n    Args:\n        text: string to be searched for\n        hit_max: maximum hits\n        quads: return quads instead of rectangles\n    Returns:\n        a list of rectangles or quads, each containing one occurrence.\n    \"\"\"\n    CheckParent(page)\n    dl = page.getDisplayList()         # create DisplayList\n    tp = dl.getTextPage()              # create TextPage\n    # return list of hitting reactangles\n    rlist = tp.search(text, hit_max = hit_max, quads = quads)\n    dl = None\n    tp = None\n    return rlist"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for a string on a page.", "response": "def searchPageFor(doc, pno, text, hit_max=16, quads=False):\n    \"\"\" Search for a string on a page.\n\n    Args:\n        pno: page number\n        text: string to be searched for\n        hit_max: maximum hits\n        quads: return quads instead of rectangles\n    Returns:\n        a list of rectangles or quads, each containing an occurrence.\n    \"\"\"\n\n    return doc[pno].searchFor(text, hit_max = hit_max, quads = quads)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTextBlocks(page, images=False):\n    CheckParent(page)\n    dl = page.getDisplayList()\n    flags = TEXT_PRESERVE_LIGATURES | TEXT_PRESERVE_WHITESPACE\n    if images:\n        flags |= TEXT_PRESERVE_IMAGES\n    tp = dl.getTextPage(flags)\n    l = tp._extractTextBlocks_AsList()\n    del tp\n    del dl\n    return l", "response": "Return the text blocks on a page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the text words as a list with the bbox for each word.", "response": "def getTextWords(page):\n    \"\"\"Return the text words as a list with the bbox for each word.\n    \"\"\"\n    CheckParent(page)\n    dl = page.getDisplayList()\n    tp = dl.getTextPage()\n    l = tp._extractTextWords_AsList()\n    del dl\n    del tp\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract a document page s text.", "response": "def getText(page, output = \"text\"):\n    \"\"\" Extract a document page's text.\n\n    Args:\n        output: (str) text, html, dict, json, rawdict, xhtml or xml.\n\n    Returns:\n        the output of TextPage methods extractText, extractHTML, extractDICT, extractJSON, extractRAWDICT, extractXHTML or etractXML respectively. Default and misspelling choice is \"text\".\n    \"\"\"\n    CheckParent(page)\n    dl = page.getDisplayList()\n    # available output types\n    formats = (\"text\", \"html\", \"json\", \"xml\", \"xhtml\", \"dict\", \"rawdict\")\n    # choose which of them also include images in the TextPage\n    images = (0, 1, 1, 0, 1, 1, 1)      # controls image inclusion in text page\n    try:\n        f = formats.index(output.lower())\n    except:\n        f = 0\n    flags = TEXT_PRESERVE_LIGATURES | TEXT_PRESERVE_WHITESPACE\n    if images[f] :\n        flags |= TEXT_PRESERVE_IMAGES\n    tp = dl.getTextPage(flags)     # TextPage with / without images\n    t = tp._extractText(f)\n    del dl\n    del tp\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getPixmap(page, matrix = None, colorspace = csRGB, clip = None,\n              alpha = True):\n    \"\"\"Create pixmap of page.\n    \n    Args:\n        matrix: Matrix for transformation (default: Identity).\n        colorspace: (str/Colorspace) rgb, rgb, gray - case ignored, default csRGB.\n        clip: (irect-like) restrict rendering to this area.\n        alpha: (bool) include alpha channel\n    \"\"\"\n    CheckParent(page)\n\n    # determine required colorspace\n    cs = colorspace\n    if type(colorspace) is str:\n        if colorspace.upper() == \"GRAY\":\n            cs = csGRAY\n        elif colorspace.upper() == \"CMYK\":\n            cs = csCMYK\n        else:\n            cs = csRGB\n    if cs.n not in (1,3,4):\n        raise ValueError(\"unsupported colorspace\")\n\n    dl = page.getDisplayList()               # create DisplayList\n    if clip:\n        scissor = Rect(clip)\n    else:\n        scissor = None\n    pix = dl.getPixmap(matrix = matrix,\n                       colorspace = cs,\n                       alpha = alpha,\n                       clip = scissor)\n    del dl\n    return pix", "response": "Create a pixmap of the page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a pixmap of a page by page number.", "response": "def getPagePixmap(doc, pno, matrix = None, colorspace = csRGB,\n                  clip = None, alpha = True):\n    \"\"\"Create pixmap of document page by page number.\n\n    Notes:\n        Convenience function calling page.getPixmap.\n    Args:\n        pno: (int) page number\n        matrix: Matrix for transformation (default: Identity).\n        colorspace: (str/Colorspace) rgb, rgb, gray - case ignored, default csRGB.\n        clip: (irect-like) restrict rendering to this area.\n        alpha: (bool) include alpha channel\n    \"\"\"\n    return doc[pno].getPixmap(matrix = matrix, colorspace = colorspace,\n                          clip = clip, alpha = alpha)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a list of all links contained in a PDF page.", "response": "def getLinks(page):\n    \"\"\"Create a list of all links contained in a PDF page.\n    \n    Notes:\n        see PyMuPDF ducmentation for details.\n    \"\"\"\n\n    CheckParent(page)\n    ln = page.firstLink\n    links = []\n    while ln:\n        nl = getLinkDict(ln)\n        if nl[\"kind\"] == LINK_GOTO:\n            if type(nl[\"to\"]) is Point and nl[\"page\"] >= 0:\n                doc = page.parent\n                target_page = doc[nl[\"page\"]]\n                ctm = target_page._getTransformation()\n                point = nl[\"to\"] * ctm\n                nl[\"to\"] = point\n        links.append(nl)\n        ln = ln.next\n    if len(links) > 0:\n        linkxrefs = page._getLinkXrefs()\n        if len(linkxrefs) == len(links):\n            for i in range(len(linkxrefs)):\n                links[i][\"xref\"] = linkxrefs[i]\n    return links"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a table of contents.", "response": "def getToC(doc, simple = True):\n    \"\"\"Create a table of contents.\n\n    Args:\n        simple: a bool to control output. Returns a list, where each entry consists of outline level, title, page number and link destination (if simple = False). For details see PyMuPDF's documentation.\n    \"\"\"\n\n    def recurse(olItem, liste, lvl):\n        '''Recursively follow the outline item chain and record item information in a list.'''\n        while olItem:\n            if olItem.title:\n                title = olItem.title\n            else:\n                title = \" \"\n\n            if not olItem.isExternal:\n                if olItem.uri:\n                    page = olItem.page + 1\n                else:\n                    page = -1\n            else:\n                page = -1\n\n            if not simple:\n                link = getLinkDict(olItem)\n                liste.append([lvl, title, page, link])\n            else:\n                liste.append([lvl, title, page])\n\n            if olItem.down:\n                liste = recurse(olItem.down, liste, lvl+1)\n            olItem = olItem.next\n        return liste\n\n    # check if document is open and not encrypted\n    if doc.isClosed:\n        raise ValueError(\"illegal operation on closed document\")\n\n    olItem = doc.outline\n\n    if not olItem: return []\n    lvl = 1\n    liste = []\n    return recurse(olItem, liste, lvl)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate area of rectangle. parameter is one of px in cm or mm.", "response": "def getRectArea(*args):\n    \"\"\"Calculate area of rectangle.\\nparameter is one of 'px' (default), 'in', 'cm', or 'mm'.\"\"\"\n    rect = args[0]\n    if len(args) > 1:\n        unit = args[1]\n    else:\n        unit = \"px\"    \n    u = {\"px\": (1,1), \"in\": (1.,72.), \"cm\": (2.54, 72.), \"mm\": (25.4, 72.)}\n    f = (u[unit][0] / u[unit][1])**2\n    return f * rect.width * rect.height"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setMetadata(doc, m):\n    if doc.isClosed or doc.isEncrypted:\n        raise ValueError(\"operation on closed or encrypted document\")\n    if type(m) is not dict:\n        raise ValueError(\"arg2 must be a dictionary\")\n    for k in m.keys():\n        if not k in (\"author\", \"producer\", \"creator\", \"title\", \"format\",\n                     \"encryption\", \"creationDate\", \"modDate\", \"subject\",\n                     \"keywords\"):\n            raise ValueError(\"invalid dictionary key: \" + k)\n    d = \"<</Author\"\n    d += getPDFstr(m.get(\"author\", \"none\"))\n    d += \"/CreationDate\"\n    d += getPDFstr(m.get(\"creationDate\", \"none\"))\n    d += \"/Creator\"\n    d += getPDFstr(m.get(\"creator\", \"none\"))\n    d += \"/Keywords\"\n    d += getPDFstr(m.get(\"keywords\", \"none\"))\n    d += \"/ModDate\"\n    d += getPDFstr(m.get(\"modDate\", \"none\"))\n    d += \"/Producer\"\n    d += getPDFstr(m.get(\"producer\", \"none\"))\n    d += \"/Subject\"\n    d += getPDFstr(m.get(\"subject\", \"none\"))\n    d += \"/Title\"\n    d += getPDFstr(m.get(\"title\", \"none\"))\n    d += \">>\"\n    doc._setMetadata(d)\n    doc.initData()\n    return", "response": "Set a PDF s metadata ( / Info dictionary)\\nm : dictionary like doc. metadata"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating new outline tree ( table of contents)\\ntoc : a Python list of lists. Each entry must contain level title page and optionally top margin on the page.", "response": "def setToC(doc, toc):\n    '''Create new outline tree (table of contents)\\ntoc: a Python list of lists. Each entry must contain level, title, page and optionally top margin on the page.'''\n    if doc.isClosed or doc.isEncrypted:\n        raise ValueError(\"operation on closed or encrypted document\")\n    if not doc.isPDF:\n        raise ValueError(\"not a PDF\")\n    toclen = len(toc)\n    # check toc validity ------------------------------------------------------\n    if type(toc) is not list:\n        raise ValueError(\"arg2 must be a list\")\n    if toclen == 0:\n        return len(doc._delToC())\n    pageCount = len(doc)\n    t0 = toc[0]\n    if type(t0) is not list:\n        raise ValueError(\"arg2 must contain lists of 3 or 4 items\")\n    if t0[0] != 1:\n        raise ValueError(\"hierarchy level of item 0 must be 1\")\n    for i in list(range(toclen-1)):\n        t1 = toc[i]\n        t2 = toc[i+1]\n        if not -1 <= t1[2] <= pageCount:\n            raise ValueError(\"row %i:page number out of range\" % i)\n        if (type(t2) is not list) or len(t2) < 3 or len(t2) > 4:\n            raise ValueError(\"arg2 must contain lists of 3 or 4 items\")\n        if (type(t2[0]) is not int) or t2[0] < 1:\n            raise ValueError(\"hierarchy levels must be int > 0\")\n        if t2[0] > t1[0] + 1:\n            raise ValueError(\"row %i: hierarchy step is > 1\" % i)\n    # no formal errors in toc --------------------------------------------------\n\n    old_xrefs = doc._delToC()          # del old outlines, get xref numbers\n    old_xrefs = []                     # force creation of new xrefs\n    # prepare table of xrefs for new bookmarks\n    xref = [0] + old_xrefs\n    xref[0] = doc._getOLRootNumber()        # entry zero is outline root xref#\n    if toclen > len(old_xrefs):             # too few old xrefs?\n        for i in range((toclen - len(old_xrefs))):\n            xref.append(doc._getNewXref())  # acquire new ones\n\n    lvltab = {0:0}                     # to store last entry per hierarchy level\n\n#==============================================================================\n# contains new outline objects as strings - first one is outline root\n#==============================================================================\n    olitems = [{\"count\":0, \"first\":-1, \"last\":-1, \"xref\":xref[0]}]\n#==============================================================================\n# build olitems as a list of PDF-like connnected dictionaries\n#==============================================================================\n    for i in range(toclen):\n        o = toc[i]\n        lvl = o[0] # level\n        title = getPDFstr(o[1]) # titel\n        pno = min(doc.pageCount - 1, max(0, o[2] - 1)) # page number\n        top = 0\n        if len(o) < 4:\n            p = doc.loadPage(pno)\n            top = int(round(p.bound().y1) - 36)  # default top location on page\n            p = None                             # free page resources\n        top1 = top + 0                        # accept provided top parameter\n        dest_dict = {}\n        if len(o) > 3:\n            if type(o[3]) is int or type(o[3]) is float:\n                top1 = int(round(o[3]))\n                dest_dict = o[3]\n            else:\n                dest_dict = o[3] if type(o[3]) is dict else {}\n                try:\n                    top1 = int(round(o[3][\"to\"].y)) # top\n                except: pass\n        else:\n            dest_dict = top\n        if  0 <= top1 <= top + 36:\n            top = top1\n        d = {}\n        d[\"first\"] = -1\n        d[\"count\"] = 0\n        d[\"last\"]  = -1\n        d[\"prev\"]  = -1\n        d[\"next\"]  = -1\n        d[\"dest\"]  = getDestStr(doc._getPageObjNumber(pno), dest_dict)\n        d[\"top\"]   = top\n        d[\"title\"] = title\n        d[\"parent\"] = lvltab[lvl-1]\n        d[\"xref\"] = xref[i+1]\n        lvltab[lvl] = i+1\n        parent = olitems[lvltab[lvl-1]]\n        parent[\"count\"] += 1\n\n        if parent[\"first\"] == -1:\n            parent[\"first\"] = i+1\n            parent[\"last\"] = i+1\n        else:\n            d[\"prev\"] = parent[\"last\"]\n            prev = olitems[parent[\"last\"]]\n            prev[\"next\"]   = i+1\n            parent[\"last\"] = i+1\n        olitems.append(d)\n\n#==============================================================================\n# now create each ol item as a string and insert it in the PDF\n#==============================================================================\n    for i, ol in enumerate(olitems):\n        txt = \"<<\"\n        if ol[\"count\"] > 0:\n            if i > 0:\n                txt += \"/Count -%i\" % ol[\"count\"]\n            else:\n                txt += \"/Count %i\" % ol[\"count\"]\n        try:\n            txt += ol[\"dest\"]\n        except: pass\n        try:\n            if ol[\"first\"] > -1:\n                txt += \"/First %i 0 R\" % xref[ol[\"first\"]]\n        except: pass\n        try:\n            if ol[\"last\"] > -1:\n                txt += \"/Last %i 0 R\" % xref[ol[\"last\"]]\n        except: pass\n        try:\n            if ol[\"next\"] > -1:\n                txt += \"/Next %i 0 R\" % xref[ol[\"next\"]]\n        except: pass\n        try:\n            if ol[\"parent\"] > -1:\n                txt += \"/Parent %i 0 R\" % xref[ol[\"parent\"]]\n        except: pass\n        try:\n            if ol[\"prev\"] > -1:\n                txt += \"/Prev %i 0 R\" % xref[ol[\"prev\"]]\n        except: pass\n        try:\n            txt += \"/Title\" + ol[\"title\"]\n        except: pass\n        if i == 0:           # special: this is the outline root\n            txt += \"/Type/Outlines\"\n        txt += \">>\"\n        doc._updateObject(xref[i], txt)     # insert the PDF object\n\n    doc.initData()\n    return toclen"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert links contained in copied page range into destination PDF. Parameter values **must** equal those of method insertPDF() - which must have been previously executed.", "response": "def do_links(doc1, doc2, from_page = -1, to_page = -1, start_at = -1):\n    '''Insert links contained in copied page range into destination PDF.\n    Parameter values **must** equal those of method insertPDF() - which must have been previously executed.'''\n    #--------------------------------------------------------------------------\n    # define skeletons for /Annots object texts\n    #--------------------------------------------------------------------------\n    annot_goto ='''<</Dest[%i 0 R /XYZ %g %g 0]/Rect[%s]/Subtype/Link>>'''\n\n    annot_gotor = '''<</A<</D[%i /XYZ %g %g 0]/F<</F(%s)/UF(%s)/Type/Filespec\n    >>/S/GoToR>>/Rect[%s]/Subtype/Link>>'''\n\n    annot_gotor_n = \"<</A<</D(%s)/F(%s)/S/GoToR>>/Rect[%s]/Subtype/Link>>\"\n\n    annot_launch = '''<</A<</F<</F(%s)/UF(%s)/Type/Filespec>>/S/Launch\n    >>/Rect[%s]/Subtype/Link>>'''\n\n    annot_uri = '''<</A<</S/URI/URI(%s)/Type/Action>>/Rect[%s]/Subtype/Link>>'''\n\n    #--------------------------------------------------------------------------\n    # internal function to create the actual \"/Annots\" object string\n    #--------------------------------------------------------------------------\n    def cre_annot(lnk, xref_dst, list_src, height):\n        '''Create annotation object string for a passed-in link.'''\n\n        # \"from\" rectangle is always there. Note: y-coords are from bottom!\n\n        r = lnk[\"from\"]\n        rect = \"%g %g %g %g\" % (r.x0, height - r.y0, r.x1, height - r.y1)\n        if lnk[\"kind\"] == LINK_GOTO:\n            txt = annot_goto\n            idx = list_src.index(lnk[\"page\"])\n            annot = txt % (xref_dst[idx], lnk[\"to\"].x,\n                           lnk[\"to\"].y, rect)\n        elif lnk[\"kind\"] == LINK_GOTOR:\n            if lnk[\"page\"] >= 0:\n                txt = annot_gotor\n                pnt = lnk.get(\"to\", Point(0, 0))          # destination point\n                if type(pnt) is not Point:\n                    pnt = Point(0, 0)\n                annot = txt % (lnk[\"page\"], pnt.x, pnt.y,\n                           lnk[\"file\"], lnk[\"file\"], rect)\n            else:\n                txt = annot_gotor_n\n                to = getPDFstr(lnk[\"to\"])\n                to = to[1:-1]\n                f = lnk[\"file\"]\n                annot = txt % (to, f, rect)\n\n        elif lnk[\"kind\"] == LINK_LAUNCH:\n            txt = annot_launch\n            annot = txt % (lnk[\"file\"], lnk[\"file\"], rect)\n        elif lnk[\"kind\"] == LINK_URI:\n            txt = annot_uri\n            annot = txt % (lnk[\"uri\"], rect)\n        else:\n            annot = \"\"\n\n        return annot\n    #--------------------------------------------------------------------------\n\n    # validate & normalize parameters\n    if from_page < 0:\n        fp = 0\n    elif from_page >= doc2.pageCount:\n        from_page = doc2.pageCount - 1\n    else:\n        fp = from_page\n\n    if to_page < 0 or to_page >= doc2.pageCount:\n        tp = doc2.pageCount - 1\n    else:\n        tp = to_page\n\n    if start_at < 0:\n        raise ValueError(\"do_links: 'start_at' arg must be >= 0\")\n    sa = start_at\n\n    incr = 1 if fp <= tp else -1            # page range could be reversed\n    # lists of source / destination page numbers\n    list_src = list(range(fp, tp + incr, incr))\n    list_dst = [sa + i for i in range(len(list_src))]\n    # lists of source / destination page xref numbers\n    xref_src = []\n    xref_dst = []\n    for i in range(len(list_src)):\n        p_src = list_src[i]\n        p_dst = list_dst[i]\n        old_xref = doc2._getPageObjNumber(p_src)[0]\n        new_xref = doc1._getPageObjNumber(p_dst)[0]\n        xref_src.append(old_xref)\n        xref_dst.append(new_xref)\n\n    # create /Annots per copied page in destination PDF\n    for i in range(len(xref_src)):\n        page_src = doc2[list_src[i]]\n        links = page_src.getLinks()\n        if len(links) == 0:\n            page_src = None\n            continue\n        height = page_src.bound().y1\n        p_annots = \"\"\n        page_dst = doc1[list_dst[i]]\n        link_tab = []\n        for l in links:\n            if l[\"kind\"] == LINK_GOTO and (l[\"page\"] not in list_src):\n                continue          # target not in copied pages\n            annot_text = cre_annot(l, xref_dst, list_src, height)\n            if not annot_text:\n                print(\"cannot create /Annot for kind: \" + str(l[\"kind\"]))\n            else:\n                link_tab.append(annot_text)\n        if len(link_tab) > 0:\n            page_dst._addAnnot_FromString(link_tab)\n        page_dst = None\n        page_src = None\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a link on the current page.", "response": "def updateLink(page, lnk):\n    \"\"\" Update a link on the current page. \"\"\"\n    CheckParent(page)\n    annot = getLinkText(page, lnk)\n    if annot == \"\":\n        raise ValueError(\"link kind not supported\")\n\n    page.parent._updateObject(lnk[\"xref\"], annot, page = page) \n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insertLink(page, lnk, mark = True):\n    CheckParent(page)\n    annot = getLinkText(page, lnk)\n    if annot == \"\":\n        raise ValueError(\"link kind not supported\")\n\n    page._addAnnot_FromString([annot])\n    return", "response": "Insert a new link in the current page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insertTextbox(page, rect, buffer,\n                  fontname=\"helv\",\n                  fontfile=None,\n                  set_simple=0,\n                  encoding=0,\n                  fontsize=11,\n                  color=None,\n                  fill=None,\n                  expandtabs=1,\n                  align=0,\n                  rotate=0,\n                  render_mode=0,\n                  border_width=1,\n                  morph=None,\n                  overlay=True):\n    \"\"\" Insert text into a given rectangle.\n\n    Notes:\n        Creates a Shape object, uses its same-named method and commits it.\n    Parameters:\n        rect: (rect-like) area to use for text.\n        buffer: text to be inserted\n        fontname: a Base-14 font, font name or '/name'\n        fontfile: name of a font file\n        fontsize: font size\n        color: RGB color triple\n        expandtabs: handles tabulators with string function\n        align: left, center, right, justified\n        rotate: 0, 90, 180, or 270 degrees\n        morph: morph box with  a matrix and a pivotal point\n        overlay: put text in foreground or background\n    Returns:\n        unused or deficit rectangle area (float)\n    \"\"\"\n    img = page.newShape()\n    rc = img.insertTextbox(rect, buffer,\n                           fontsize=fontsize,\n                           fontname=fontname,\n                           fontfile=fontfile,\n                           set_simple=set_simple,\n                           encoding=encoding,\n                           color=color,\n                           fill=fill,\n                           expandtabs=expandtabs,\n                           render_mode=render_mode,\n                           border_width=border_width,\n                           align=align,\n                           rotate=rotate,\n                           morph=morph)\n    if rc >= 0:\n        img.commit(overlay)\n    return rc", "response": "Insert text into a rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef newPage(doc, pno=-1, width=595, height=842):\n    doc._newPage(pno, width=width, height=height)\n    return doc[pno]", "response": "Create and return a new page object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insertPage(\n        doc,\n        pno,\n        text=None,\n        fontsize=11,\n        width=595,\n        height=842,\n        fontname=\"helv\",\n        fontfile=None,\n        color=None,\n    ):\n    \"\"\" Create a new PDF page and insert some text.\n\n    Notes:\n        Function combining Document.newPage() and Page.insertText().\n        For parameter details see these methods.\n    \"\"\"\n    page = doc.newPage(pno=pno, width=width, height=height)\n    if not bool(text):\n        return 0\n    rc = page.insertText(\n            (50, 72),\n            text,\n            fontsize=fontsize,\n            fontname=fontname,\n            fontfile=fontfile,\n            color=color,\n         )\n    return rc", "response": "Insert a new PDF page and insert some text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a squiggly line from point p1 to point p2.", "response": "def drawSquiggle(page, p1, p2, breadth = 2, color=None, dashes=None,\n               width=1, roundCap=False, overlay=True, morph=None):\n    \"\"\"Draw a squiggly line from point p1 to point p2.\n    \"\"\"\n    img = page.newShape()\n    p = img.drawSquiggle(Point(p1), Point(p2), breadth = breadth)\n    img.finish(color=color, dashes=dashes, width=width, closePath=False,\n               roundCap=roundCap, morph=morph)\n    img.commit(overlay)\n\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef drawPolyline(page, points, color=None, fill=None, dashes=None,\n                 width=1, morph=None, roundCap=False, overlay=True,\n                 closePath=False):\n    \"\"\"Draw multiple connected line segments.\n    \"\"\"\n    img = page.newShape()\n    Q = img.drawPolyline(points)\n    img.finish(color=color, fill=fill, dashes=dashes, width=width,\n               roundCap=roundCap, morph=morph, closePath=closePath)\n    img.commit(overlay)\n\n    return Q", "response": "Draw multiple connected line segments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drawCircle(page, center, radius, color=None, fill=None,\n               morph=None, dashes=None, width=1,\n               roundCap=False, overlay=True):\n    \"\"\"Draw a circle given its center and radius.\n    \"\"\"\n    img = page.newShape()\n    Q = img.drawCircle(Point(center), radius)\n    img.finish(color=color, fill=fill, dashes=dashes, width=width,\n               roundCap=roundCap, morph=morph)\n    img.commit(overlay)\n    return Q", "response": "Draw a circle given its center and radius."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a cubic Bezier curve from p1 to p4 using control points p2 and p3 and p4.", "response": "def drawBezier(page, p1, p2, p3, p4, color=None, fill=None,\n               dashes=None, width=1, morph=None,\n               closePath=False, roundCap=False, overlay=True):\n    \"\"\"Draw a general cubic Bezier curve from p1 to p4 using control points p2 and p3.\n    \"\"\"\n    img = page.newShape()\n    Q = img.drawBezier(Point(p1), Point(p2), Point(p3), Point(p4))\n    img.finish(color=color, fill=fill, dashes=dashes, width=width,\n               roundCap=roundCap, morph=morph, closePath=closePath)\n    img.commit(overlay)\n    \n    return Q"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw a circle sector given a center point and a beta angle.", "response": "def drawSector(page, center, point, beta, color=None, fill=None,\n              dashes=None, fullSector=True, morph=None,\n              width=1, closePath=False, roundCap=False, overlay=True):\n    \"\"\" Draw a circle sector given circle center, one arc end point and the angle of the arc.\n    \n    Parameters:\n        center -- center of circle\n        point -- arc end point\n        beta -- angle of arc (degrees)\n        fullSector -- connect arc ends with center\n    \"\"\"\n    img = page.newShape()\n    Q = img.drawSector(Point(center), Point(point), beta, fullSector=fullSector)\n    img.finish(color=color, fill=fill, dashes=dashes, width=width,\n               roundCap=roundCap, morph=morph, closePath=closePath)\n    img.commit(overlay)\n    \n    return Q"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getColor(name):\n    try:\n        c = getColorInfoList()[getColorList().index(name.upper())]\n        return (c[1] / 255., c[2] / 255., c[3] / 255.)\n    except:\n        return (1, 1, 1)", "response": "Retrieve RGB color in PDF format by name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the hue saturation value triple of a color name.", "response": "def getColorHSV(name):\n    \"\"\"Retrieve the hue, saturation, value triple of a color name.\n\n    Returns:\n        a triple (degree, percent, percent). If not found (-1, -1, -1) is returned.\n    \"\"\"\n    try:\n        x = getColorInfoList()[getColorList().index(name.upper())]\n    except:\n        return (-1, -1, -1)\n    \n    r = x[1] / 255.\n    g = x[2] / 255.\n    b = x[3] / 255.\n    cmax = max(r, g, b)\n    V = round(cmax * 100, 1)\n    cmin = min(r, g, b)\n    delta = cmax - cmin\n    if delta == 0:\n        hue = 0\n    elif cmax == r:\n        hue = 60. * (((g - b)/delta) % 6)\n    elif cmax == g:\n        hue = 60. * (((b - r)/delta) + 2)\n    else:\n        hue = 60. * (((r - g)/delta) + 4)\n        \n    H = int(round(hue))\n    \n    if cmax == 0:\n        sat = 0\n    else:\n        sat = delta / cmax\n    S = int(round(sat  * 100))\n\n    return (H, S, V)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of glyph widths for a single character.", "response": "def getCharWidths(doc, xref, limit = 256, idx = 0):\n    \"\"\"Get list of glyph information of a font.\n    \n    Notes:\n        Must be provided by its XREF number. If we already dealt with the\n        font, it will be recorded in doc.FontInfos. Otherwise we insert an\n        entry there.\n        Finally we return the glyphs for the font. This is a list of\n        (glyph, width) where glyph is an integer controlling the char\n        appearance, and width is a float controlling the char's spacing:\n        width * fontsize is the actual space.\n        For 'simple' fonts, glyph == ord(char) will usually be true.\n        Exceptions are 'Symbol' and 'ZapfDingbats'. We are providing data for these directly here.\n    \"\"\"\n    fontinfo = CheckFontInfo(doc, xref)\n    if fontinfo is None:               # not recorded yet: create it\n        name, ext, stype, _ = doc.extractFont(xref, info_only = True)\n        fontdict = {\"name\": name, \"type\": stype, \"ext\": ext}\n\n        if ext == \"\":\n            raise ValueError(\"xref is not a font\")\n\n        # check for 'simple' fonts\n        if stype in (\"Type1\", \"MMType1\", \"TrueType\"):\n            simple = True\n        else:\n            simple = False\n\n        # check for CJK fonts\n        if name in (\"Fangti\", \"Ming\"):\n            ordering = 0\n        elif name in (\"Heiti\", \"Song\"):\n            ordering = 1\n        elif name in (\"Gothic\", \"Mincho\"):\n            ordering = 2\n        elif name in (\"Dotum\", \"Batang\"):\n            ordering = 3\n        else:\n            ordering = -1\n\n        fontdict[\"simple\"] = simple\n\n        if name == \"ZapfDingbats\":\n            glyphs = zapf_glyphs\n        elif name == \"Symbol\":\n            glyphs = symbol_glyphs\n        else:\n            glyphs = None\n\n        fontdict[\"glyphs\"] = glyphs\n        fontdict[\"ordering\"] = ordering\n        fontinfo = [xref, fontdict]\n        doc.FontInfos.append(fontinfo)\n    else:\n        fontdict = fontinfo[1]\n        glyphs = fontdict[\"glyphs\"]\n        simple = fontdict[\"simple\"]\n        ordering = fontdict[\"ordering\"]\n\n    if glyphs is None:\n        oldlimit = 0\n    else:\n        oldlimit = len(glyphs)\n    \n    mylimit = max(256, limit)\n    \n    if mylimit <= oldlimit:\n        return glyphs\n\n    if ordering < 0:              # not a CJK font\n        glyphs = doc._getCharWidths(xref, fontdict[\"name\"],\n                                    fontdict[\"ext\"],\n                                    fontdict[\"ordering\"],\n                                    mylimit, idx)\n    else:                         # CJK fonts use char codes and width = 1\n        glyphs = None\n\n    fontdict[\"glyphs\"] = glyphs\n    fontinfo[1] = fontdict\n    UpdateFontInfo(doc, fontinfo)\n\n    return glyphs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef horizontal_angle(C, P):\n        S = Point(P - C).unit                   # unit vector 'C' -> 'P'\n        alfa = math.asin(abs(S.y))              # absolute angle from horizontal\n        if S.x < 0:                             # make arcsin result unique\n            if S.y <= 0:                        # bottom-left\n                alfa = -(math.pi - alfa)\n            else:                               # top-left\n                alfa = math.pi - alfa\n        else:\n            if S.y >= 0:                        # top-right\n                pass\n            else:                               # bottom-right\n                alfa = - alfa\n        return alfa", "response": "Return the angle to the horizontal for the connection from C to P."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef drawLine(self, p1, p2):\n        p1 = Point(p1)\n        p2 = Point(p2)\n        if not (self.lastPoint == p1):\n            self.draw_cont += \"%g %g m\\n\" % JM_TUPLE(p1 * self.ipctm)\n            self.lastPoint = p1\n            self.updateRect(p1)\n\n        self.draw_cont += \"%g %g l\\n\" % JM_TUPLE(p2 * self.ipctm)\n        self.updateRect(p2)\n        self.lastPoint = p2\n        return self.lastPoint", "response": "Draw a line between two points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw several connected line segments.", "response": "def drawPolyline(self, points):\n        \"\"\"Draw several connected line segments.\n        \"\"\"\n        for i, p in enumerate(points):\n            if i == 0:\n                if not (self.lastPoint == Point(p)):\n                    self.draw_cont += \"%g %g m\\n\" % JM_TUPLE(Point(p) * self.ipctm)\n                    self.lastPoint = Point(p)\n            else:\n                self.draw_cont += \"%g %g l\\n\" % JM_TUPLE(Point(p) * self.ipctm)\n            self.updateRect(p)\n\n        self.lastPoint = Point(points[-1])\n        return self.lastPoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a standard cubic Bezier curve.", "response": "def drawBezier(self, p1, p2, p3, p4):\n        \"\"\"Draw a standard cubic Bezier curve.\n        \"\"\"\n        p1 = Point(p1)\n        p2 = Point(p2)\n        p3 = Point(p3)\n        p4 = Point(p4)\n        if not (self.lastPoint == p1):\n            self.draw_cont += \"%g %g m\\n\" % JM_TUPLE(p1 * self.ipctm)\n        self.draw_cont += \"%g %g %g %g %g %g c\\n\" % JM_TUPLE(list(p2 * self.ipctm) + \\\n                                                          list(p3 * self.ipctm) + \\\n                                                          list(p4 * self.ipctm))\n        self.updateRect(p1)\n        self.updateRect(p2)\n        self.updateRect(p3)\n        self.updateRect(p4)\n        self.lastPoint = p4\n        return self.lastPoint"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef drawOval(self, tetra):\n        if len(tetra) != 4:\n            raise ValueError(\"invalid arg length\")\n        if hasattr(tetra[0], \"__float__\"):\n            q = Rect(tetra).quad\n        else:\n            q = Quad(tetra)\n\n        mt = q.ul + (q.ur - q.ul) * 0.5\n        mr = q.ur + (q.lr - q.ur) * 0.5\n        mb = q.ll + (q.lr - q.ll) * 0.5\n        ml = q.ul + (q.ll - q.ul) * 0.5\n        if not (self.lastPoint == ml):\n            self.draw_cont += \"%g %g m\\n\" % JM_TUPLE(ml * self.ipctm)\n            self.lastPoint = ml\n        self.drawCurve(ml, q.ll, mb)\n        self.drawCurve(mb, q.lr, mr)\n        self.drawCurve(mr, q.ur, mt)\n        self.drawCurve(mt, q.ul, ml)\n        self.updateRect(q.rect)\n        self.lastPoint = ml\n        return self.lastPoint", "response": "Draw an ellipse inside a tetrapod."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw a circle given its center and radius.", "response": "def drawCircle(self, center, radius):\n        \"\"\"Draw a circle given its center and radius.\n        \"\"\"\n        if not radius > 1e-5:\n            raise ValueError(\"radius must be postive\")\n        center = Point(center)\n        p1 = center - (radius, 0)\n        return self.drawSector(center, p1, 360, fullSector=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws a curve between two control points.", "response": "def drawCurve(self, p1, p2, p3):\n        \"\"\"Draw a curve between points using one control point.\n        \"\"\"\n        kappa = 0.55228474983\n        p1 = Point(p1)\n        p2 = Point(p2)\n        p3 = Point(p3)\n        k1 = p1 + (p2 - p1) * kappa\n        k2 = p3 + (p2 - p3) * kappa\n        return self.drawBezier(p1, k1, k2, p3)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a circle sector.", "response": "def drawSector(self, center, point, beta, fullSector=True):\n        \"\"\"Draw a circle sector.\n        \"\"\"\n        center = Point(center)\n        point = Point(point)\n        l3 = \"%g %g m\\n\"\n        l4 = \"%g %g %g %g %g %g c\\n\"\n        l5 = \"%g %g l\\n\"\n        betar = math.radians(-beta)\n        w360 = math.radians(math.copysign(360, betar)) * (-1)\n        w90  = math.radians(math.copysign(90, betar))\n        w45  = w90 / 2\n        while abs(betar) > 2 * math.pi:\n            betar += w360                       # bring angle below 360 degrees\n        if not (self.lastPoint == point):\n            self.draw_cont += l3 % JM_TUPLE(point * self.ipctm)\n            self.lastPoint = point\n        Q = Point(0, 0)                    # just make sure it exists\n        C = center\n        P = point\n        S = P - C                               # vector 'center' -> 'point'\n        rad = abs(S)                            # circle radius\n\n        if not rad > 1e-5:\n            raise ValueError(\"radius must be positive\")\n\n        alfa = self.horizontal_angle(center, point)\n        while abs(betar) > abs(w90):            # draw 90 degree arcs\n            q1 = C.x + math.cos(alfa + w90) * rad\n            q2 = C.y + math.sin(alfa + w90) * rad\n            Q = Point(q1, q2)              # the arc's end point\n            r1 = C.x + math.cos(alfa + w45) * rad / math.cos(w45)\n            r2 = C.y + math.sin(alfa + w45) * rad / math.cos(w45)\n            R = Point(r1, r2)              # crossing point of tangents\n            kappah = (1 - math.cos(w45)) * 4 / 3 / abs(R - Q)\n            kappa = kappah * abs(P - Q)\n            cp1 = P + (R - P) * kappa           # control point 1\n            cp2 = Q + (R - Q) * kappa           # control point 2\n            self.draw_cont += l4 % JM_TUPLE(list(cp1 * self.ipctm) + \\\n                                         list(cp2 * self.ipctm) + \\\n                                         list(Q * self.ipctm))\n\n            betar -= w90                        # reduce parm angle by 90 deg\n            alfa  += w90                        # advance start angle by 90 deg\n            P = Q                               # advance to arc end point\n        # draw (remaining) arc\n        if abs(betar) > 1e-3:                   # significant degrees left?\n            beta2 = betar / 2\n            q1 = C.x + math.cos(alfa + betar) * rad\n            q2 = C.y + math.sin(alfa + betar) * rad\n            Q = Point(q1, q2)              # the arc's end point\n            r1 = C.x + math.cos(alfa + beta2) * rad / math.cos(beta2)\n            r2 = C.y + math.sin(alfa + beta2) * rad / math.cos(beta2)\n            R = Point(r1, r2)              # crossing point of tangents\n            # kappa height is 4/3 of segment height\n            kappah = (1 - math.cos(beta2)) * 4 / 3 / abs(R - Q) # kappa height\n            kappa = kappah * abs(P - Q) / (1 - math.cos(betar))\n            cp1 = P + (R - P) * kappa           # control point 1\n            cp2 = Q + (R - Q) * kappa           # control point 2\n            self.draw_cont += l4 % JM_TUPLE(list(cp1 * self.ipctm) + \\\n                                         list(cp2 * self.ipctm) + \\\n                                         list(Q * self.ipctm))\n        if fullSector:\n            self.draw_cont += l3 % JM_TUPLE(point * self.ipctm)\n            self.draw_cont += l5 % JM_TUPLE(center * self.ipctm)\n            self.draw_cont += l5 % JM_TUPLE(Q * self.ipctm)\n        self.lastPoint = Q\n        return self.lastPoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws a zig - zagged line from p1 to p2.", "response": "def drawZigzag(self, p1, p2, breadth = 2):\n        \"\"\"Draw a zig-zagged line from p1 to p2.\n        \"\"\"\n        p1 = Point(p1)\n        p2 = Point(p2)\n        S = p2 - p1                             # vector start - end\n        rad = abs(S)                            # distance of points\n        cnt = 4 * int(round(rad / (4 * breadth), 0)) # always take full phases\n        if cnt < 4:\n            raise ValueError(\"points too close\")\n        mb = rad / cnt                          # revised breadth\n        matrix = TOOLS._hor_matrix(p1, p2)      # normalize line to x-axis\n        i_mat  = ~matrix                        # get original position\n        points = []                             # stores edges\n        for i in range (1, cnt):                \n            if i % 4 == 1:                      # point \"above\" connection\n                p = Point(i, -1) * mb\n            elif i % 4 == 3:                    # point \"below\" connection\n                p = Point(i, 1) * mb\n            else:                               # ignore others\n                continue\n            points.append(p * i_mat)\n        self.drawPolyline([p1] + points + [p2])  # add start and end points\n        return p2"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws a squiggly line from p1 to p2.", "response": "def drawSquiggle(self, p1, p2, breadth = 2):\n        \"\"\"Draw a squiggly line from p1 to p2.\n        \"\"\"\n        p1 = Point(p1)\n        p2 = Point(p2)\n        S = p2 - p1                             # vector start - end\n        rad = abs(S)                            # distance of points\n        cnt = 4 * int(round(rad / (4 * breadth), 0)) # always take full phases\n        if cnt < 4:\n            raise ValueError(\"points too close\")\n        mb = rad / cnt                          # revised breadth\n        matrix = TOOLS._hor_matrix(p1, p2)      # normalize line to x-axis\n        i_mat  = ~matrix                        # get original position\n        k = 2.4142135623765633                  # y of drawCurve helper point\n\n        points = []                             # stores edges\n        for i in range (1, cnt):                \n            if i % 4 == 1:                      # point \"above\" connection\n                p = Point(i, -k) * mb\n            elif i % 4 == 3:                    # point \"below\" connection\n                p = Point(i, k) * mb\n            else:                               # else on connection line\n                p = Point(i, 0) * mb\n            points.append(p * i_mat)\n\n        points = [p1] + points + [p2]\n        cnt = len(points)\n        i = 0\n        while i + 2 < cnt:\n            self.drawCurve(points[i], points[i+1], points[i+2])\n            i += 2\n        return p2"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert text into a textbox.", "response": "def insertTextbox(self, rect, buffer,\n                      fontname=\"helv\",\n                      fontfile=None,\n                      fontsize=11,\n                      set_simple=0,\n                      encoding=0,\n                      color=None,\n                      fill=None,\n                      expandtabs=1,\n                      border_width=1,\n                      align=0,\n                      render_mode=0,\n                      rotate=0,\n                      morph=None):\n        \"\"\" Insert text into a given rectangle.\n\n        Args:\n            rect -- the textbox to fill\n            buffer -- text to be inserted\n            fontname -- a Base-14 font, font name or '/name'\n            fontfile -- name of a font file\n            fontsize -- font size\n            color -- RGB stroke color triple\n            fill -- RGB fill color triple\n            render_mode -- text rendering control\n            border_width -- thickness of glyph borders\n            expandtabs -- handles tabulators with string function\n            align -- left, center, right, justified\n            rotate -- 0, 90, 180, or 270 degrees\n            morph -- morph box with  a matrix and a pivotal point\n        Returns:\n            unused or deficit rectangle area (float)\n        \"\"\"\n        rect = Rect(rect)\n        if rect.isEmpty or rect.isInfinite:\n            raise ValueError(\"text box must be finite and not empty\")\n\n        color_str = ColorCode(color, \"c\")\n        fill_str = ColorCode(fill, \"f\")\n        if fill is None and render_mode == 0:    # ensure fill color for 0 Tr\n            fill = color\n            fill_str = ColorCode(color, \"f\")\n\n        if rotate % 90 != 0:\n            raise ValueError(\"rotate must be multiple of 90\")\n\n        rot = rotate\n        while rot < 0: rot += 360\n        rot = rot % 360\n        \n        # is buffer worth of dealing with?\n        if not bool(buffer):\n            return rect.height if rot in (0, 180) else rect.width\n\n        cmp90 = \"0 1 -1 0 0 0 cm\\n\"   # rotates counter-clockwise\n        cmm90 = \"0 -1 1 0 0 0 cm\\n\"   # rotates clockwise\n        cm180 = \"-1 0 0 -1 0 0 cm\\n\"  # rotates by 180 deg.\n        height = self.height\n\n        fname = fontname\n        if fname.startswith(\"/\"):\n            fname = fname[1:]\n\n        xref = self.page.insertFont(fontname=fname,\n                                    fontfile=fontfile,\n                                    encoding=encoding,\n                                    set_simple=set_simple,\n                                   )\n        fontinfo = CheckFontInfo(self.doc, xref)\n\n        fontdict = fontinfo[1]\n        ordering = fontdict[\"ordering\"]\n        simple = fontdict[\"simple\"]\n        glyphs = fontdict[\"glyphs\"]\n        bfname = fontdict[\"name\"]\n\n        # create a list from buffer, split into its lines\n        if type(buffer) in (list, tuple):\n            t0 = \"\\n\".join(buffer)\n        else:\n            t0 = buffer\n            \n        maxcode = max([ord(c) for c in t0])\n        # replace invalid char codes for simple fonts\n        if simple and maxcode > 255:\n            t0 = \"\".join([c if ord(c)<256 else \"?\" for c in t0])\n\n        t0 = t0.splitlines()\n        \n        glyphs = self.doc.getCharWidths(xref, maxcode + 1)\n        if simple and bfname not in (\"Symbol\", \"ZapfDingbats\"):\n            tj_glyphs = None\n        else:\n            tj_glyphs = glyphs\n\n\n        #----------------------------------------------------------------------\n        # calculate pixel length of a string\n        #----------------------------------------------------------------------\n        def pixlen(x):\n            \"\"\"Calculate pixel length of x.\"\"\"\n            if ordering < 0:\n                return sum([glyphs[ord(c)][1] for c in x]) * fontsize\n            else:\n                return len(x) * fontsize\n        #----------------------------------------------------------------------\n\n        if ordering < 0:\n            blen = glyphs[32][1] * fontsize       # pixel size of space character\n        else:\n            blen = fontsize\n\n        text = \"\"                               # output buffer\n        lheight = fontsize * 1.2                # line height\n        if CheckMorph(morph):\n            m1 = Matrix(1, 0, 0, 1, morph[0].x + self.x,\n                             self.height - morph[0].y - self.y)\n            mat = ~m1 * morph[1] * m1\n            cm = \"%g %g %g %g %g %g cm\\n\" % JM_TUPLE(mat)\n        else:\n            cm = \"\"\n        \n        #---------------------------------------------------------------------------\n        # adjust for text orientation / rotation\n        #---------------------------------------------------------------------------\n        progr = 1                               # direction of line progress\n        c_pnt = Point(0, fontsize)         # used for line progress\n        if rot == 0:                            # normal orientation\n            point = rect.tl + c_pnt             # line 1 is 'fontsize' below top\n            pos = point.y + self.y              # y of first line\n            maxwidth = rect.width               # pixels available in one line\n            maxpos = rect.y1 + self.y           # lines must not be below this\n            \n        elif rot == 90:                         # rotate counter clockwise\n            c_pnt = Point(fontsize, 0)     # progress in x-direction\n            point = rect.bl + c_pnt             # line 1 'fontsize' away from left\n            pos = point.x + self.x              # position of first line\n            maxwidth = rect.height              # pixels available in one line\n            maxpos = rect.x1 + self.x           # lines must not be right of this\n            cm += cmp90\n            \n        elif rot == 180:                        # text upside down\n            c_pnt = -Point(0, fontsize)    # progress upwards in y direction\n            point = rect.br + c_pnt             # line 1 'fontsize' above bottom\n            pos = point.y + self.y              # position of first line\n            maxwidth = rect.width               # pixels available in one line\n            progr = -1                          # subtract lheight for next line\n            maxpos = rect.y0 + self.y           # lines must not be above this\n            cm += cm180\n            \n        else:                                   # rotate clockwise (270 or -90)\n            c_pnt = -Point(fontsize, 0)    # progress from right to left\n            point = rect.tr + c_pnt             # line 1 'fontsize' left of right\n            pos = point.x + self.x              # position of first line\n            maxwidth = rect.height              # pixels available in one line\n            progr = -1                          # subtract lheight for next line\n            maxpos = rect.x0 + self.x           # lines must not left of this\n            cm += cmm90\n        \n        #=======================================================================\n        # line loop\n        #=======================================================================\n        just_tab = []                           # 'justify' indicators per line\n        \n        for i, line in enumerate(t0):\n            line_t = line.expandtabs(expandtabs).split(\" \")  # split into words\n            lbuff = \"\"                          # init line buffer\n            rest = maxwidth                     # available line pixels\n            #===================================================================\n            # word loop\n            #===================================================================\n            for word in line_t:\n                pl_w = pixlen(word)             # pixel len of word\n                if rest >= pl_w:                # will it fit on the line?\n                    lbuff += word + \" \"         # yes, and append word\n                    rest -= (pl_w + blen)       # update available line space\n                    continue\n                # word won't fit - output line (if not empty)\n                if len(lbuff) > 0:\n                    lbuff = lbuff.rstrip() + \"\\n\"   # line full, append line break\n                    text += lbuff                   # append to total text\n                    pos += lheight * progr          # increase line position\n                    just_tab.append(True)           # line is justify candidate\n                    lbuff = \"\"                      # re-init line buffer\n                rest = maxwidth                 # re-init avail. space\n                if pl_w <= maxwidth:            # word shorter than 1 line?\n                    lbuff = word + \" \"          # start the line with it\n                    rest = maxwidth - pl_w - blen    # update free space\n                    continue\n                # long word: split across multiple lines - char by char ...\n                if len(just_tab) > 0:\n                    just_tab[-1] = False            # reset justify indicator\n                for c in word:\n                    if pixlen(lbuff) <= maxwidth - pixlen(c):\n                        lbuff += c\n                    else:                       # line full\n                        lbuff += \"\\n\"           # close line\n                        text += lbuff           # append to text\n                        pos += lheight * progr  # increase line position\n                        just_tab.append(False)  # do not justify line\n                        lbuff = c               # start new line with this char\n                lbuff += \" \"                    # finish long word\n                rest = maxwidth - pixlen(lbuff) # long word stored\n                    \n            if lbuff != \"\":                     # unprocessed line content?\n                text += lbuff.rstrip()          # append to text\n                just_tab.append(False)          # do not justify line\n            if i < len(t0) - 1:                 # not the last line?\n                text += \"\\n\"                    # insert line break\n                pos += lheight * progr          # increase line position\n        \n        more = (pos - maxpos) * progr           # difference to rect size limit\n        \n        if more > 1e-5:                         # landed too much outside rect\n            return (-1) * more                  # return deficit, don't output\n    \n        more = abs(more)\n        if more < 1e-5:\n            more = 0                            # don't bother with epsilons\n        nres = \"\\nq BT\\n\" + cm                # initialize output buffer\n        templ = \"1 0 0 1 %g %g Tm /%s %g Tf \"\n        # center, right, justify: output each line with its own specifics\n        spacing = 0\n        text_t = text.splitlines()              # split text in lines again\n        for i, t in enumerate(text_t):\n            pl = maxwidth - pixlen(t)           # length of empty line part\n            pnt = point + c_pnt * (i * 1.2)     # text start of line\n            if align == 1:                      # center: right shift by half width\n                if rot in (0, 180):\n                    pnt = pnt + Point(pl / 2, 0) * progr\n                else:\n                    pnt = pnt - Point(0, pl / 2) * progr\n            elif align == 2:                    # right: right shift by full width\n                if rot in (0, 180):\n                    pnt = pnt + Point(pl, 0) * progr\n                else:\n                    pnt = pnt - Point(0, pl) * progr\n            elif align == 3:                    # justify\n                spaces = t.count(\" \")           # number of spaces in line\n                if spaces > 0 and just_tab[i]:  # if any, and we may justify\n                    spacing = pl / spaces       # make every space this much larger\n                else:\n                    spacing = 0                 # keep normal space length\n            top  = height - pnt.y - self.y\n            left = pnt.x + self.x\n            if rot == 90:\n                left = height - pnt.y - self.y\n                top  = -pnt.x - self.x\n            elif rot == 270:\n                left = -height + pnt.y + self.y\n                top  = pnt.x + self.x\n            elif rot == 180:\n                left = -pnt.x - self.x\n                top  = -height + pnt.y + self.y\n\n            nres += templ % (left, top, fname, fontsize)\n            if render_mode > 0:\n                nres += \"%i Tr \" % render_mode\n            if spacing != 0:\n                nres += \"%g Tw \" % spacing\n            if color is not None:\n                nres += color_str\n            if fill is not None:\n                nres += fill_str\n            if border_width != 1:\n                nres += \"%g w \" % border_width\n            nres += \"%sTJ\\n\" % getTJstr(t, tj_glyphs, simple, ordering)\n\n        nres += \"ET Q\\n\"\n        \n        self.text_cont += nres\n        self.updateRect(rect)\n        return more"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef finish(\n            self,\n            width=1,\n            color=None,\n            fill=None,\n            roundCap=False,\n            dashes=None,\n            even_odd=False,\n            morph=None,\n            closePath=True\n        ):\n        \"\"\"Finish the current drawing segment.\n\n        Notes:\n            Apply stroke and fill colors, dashes, line style and width, or\n            morphing. Also determines whether any open path should be closed\n            by a connecting line to its start point.\n        \"\"\"\n        if self.draw_cont == \"\":            # treat empty contents as no-op\n            return\n\n        color_str = ColorCode(color, \"c\")  # ensure proper color string\n        fill_str = ColorCode(fill, \"f\")  # ensure proper fill string\n\n        if width != 1:\n            self.draw_cont += \"%g w\\n\" % width\n\n        if roundCap:\n            self.draw_cont += \"%i J %i j\\n\" % (roundCap, roundCap)\n\n        if dashes is not None and len(dashes) > 0:\n            self.draw_cont += \"%s d\\n\" % dashes\n\n        if closePath:\n            self.draw_cont += \"h\\n\"\n            self.lastPoint = None\n\n        if color is not None:\n            self.draw_cont += color_str\n\n        if fill is not None:\n            self.draw_cont += fill_str\n            if not even_odd:\n                self.draw_cont += \"B\\n\"\n            else:\n                self.draw_cont += \"B*\\n\"\n        else:\n            self.draw_cont += \"S\\n\"\n\n        if CheckMorph(morph):\n            m1 = Matrix(1, 0, 0, 1, morph[0].x + self.x,\n                             self.height - morph[0].y - self.y)\n            mat = ~m1 * morph[1] * m1\n            self.draw_cont = \"%g %g %g %g %g %g cm\\n\" % JM_TUPLE(mat) + self.draw_cont\n\n        self.totalcont += \"\\nq\\n\" + self.draw_cont + \"Q\\n\"\n        self.draw_cont = \"\"\n        self.lastPoint = None\n        return", "response": "Finish the current drawing segment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the page s contents object with Shape data.", "response": "def commit(self, overlay=True):\n        \"\"\"Update the page's /Contents object with Shape data. The argument controls whether data appear in foreground (default) or background.\n        \"\"\"\n        CheckParent(self.page)              # doc may have died meanwhile\n        self.totalcont += self.text_cont\n\n        if not fitz_py2:                    # need bytes if Python > 2\n            self.totalcont = bytes(self.totalcont, \"utf-8\")\n\n        # make /Contents object with dummy stream\n        xref = TOOLS._insert_contents(self.page, b\" \", overlay)\n        # update it with potential compression\n        self.doc._updateStream(xref, self.totalcont)\n\n        self.lastPoint  = None         # clean up ...\n        self.rect       = None         #\n        self.draw_cont  = \"\"           # for possible ...\n        self.text_cont  = \"\"           # ...\n        self.totalcont  = \"\"           # re-use\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning Hue Saturation Value string for colorname r g b.", "response": "def sortkey(x):\n    \"\"\"Return Hue, Saturation, Value string for (colorname, r, g, b).\"\"\"\n    r = x[1] / 255.\n    g = x[2] / 255.\n    b = x[3] / 255.\n    cmax = max(r, g, b)\n    V = str(int(round(cmax * 100))).zfill(3)\n    cmin = min(r, g, b)\n    delta = cmax - cmin\n    if delta == 0:\n        hue = 0\n    elif cmax == r:\n        hue = 60. * (((g - b)/delta) % 6)\n    elif cmax == g:\n        hue = 60. * (((b - r)/delta) + 2)\n    else:\n        hue = 60. * (((r - g)/delta) + 4)\n        \n    H = str(int(round(hue))).zfill(3)\n    \n    if cmax == 0:\n        sat = 0\n    else:\n        sat = delta / cmax\n    S = str(int(round(sat  * 100))).zfill(3)\n\n    return H + S + V"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a float option.", "response": "def set_float(self, option, value):\n        \"\"\"Set a float option.\n\n            Args:\n                option (str): name of option.\n                value (float): value of the option.\n\n            Raises:\n                TypeError: Value must be a float.\n        \"\"\"\n        if not isinstance(value, float):\n            raise TypeError(\"Value must be a float\")\n        self.options[option] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_integer(self, option, value):\n        try:\n            int_value = int(value)\n        except ValueError as err:\n            print(err.args)\n\n        self.options[option] = value", "response": "Set an integer option."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a boolean option.", "response": "def set_boolean(self, option, value):\n        \"\"\"Set a boolean option.\n\n            Args:\n                option (str): name of option.\n                value (bool): value of the option.\n\n            Raises:\n                TypeError: Value must be a boolean.\n        \"\"\"\n        if not isinstance(value, bool):\n            raise TypeError(\"%s must be a boolean\" % option)\n\n        self.options[option] = str(value).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_string(self, option, value):\n        if not isinstance(value, str):\n            raise TypeError(\"%s must be a string\" % option)\n\n        self.options[option] = value", "response": "Set a string option."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chart_type(self, value):\n        if value not in self._allowed_charts:\n            raise ValueError(\"Not a valid chart type\")\n\n        self.options[\"chart_type\"] = value", "response": "Set the MetricsGraphics chart type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the custom line color map.", "response": "def custom_line_color_map(self, values):\n        \"\"\"Set the custom line color map.\n\n            Args:\n                values (list): list of colors.\n\n            Raises:\n                TypeError: Custom line color map must be a list.\n        \"\"\"\n        if not isinstance(values, list):\n            raise TypeError(\"custom_line_color_map must be a list\")\n\n        self.options[\"custom_line_color_map\"] = values"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the legend labels.", "response": "def legend(self, values):\n        \"\"\"Set the legend labels.\n\n            Args:\n                values (list): list of labels.\n\n            Raises:\n                ValueError: legend must be a list of labels.\n        \"\"\"\n        if not isinstance(values, list):\n            raise TypeError(\"legend must be a list of labels\")\n\n        self.options[\"legend\"] = values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef markers(self, values):\n        if not isinstance(values, list):\n            raise TypeError(\"Markers must be a list of objects\")\n\n        self.options[\"markers\"] = values", "response": "Set the markers.\n\n            Args:\n                values (list): list of marker objects.\n\n            Raises:\n                ValueError: Markers must be a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_confidence_band(self, value):\n        if not isinstance(values, list):\n            raise TypeError(\"show_confidence_band must be a list of strings\")\n\n        self.options[\"show_confidence_band\"] = values", "response": "Set show confidence band of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_filters(df, filters):\n        idx = pd.Series([True]*df.shape[0])\n        for k, v in list(filters.items()):\n            if k not in df.columns:\n                continue\n            idx &= (df[k] == v)\n\n        return df.loc[idx]", "response": "Basic filtering for a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_row(row, bounds, columns):\n        for c in columns:\n            if c not in row:\n                continue\n\n            if \"format\" in columns[c]:\n                row[c] = columns[c][\"format\"] % row[c]\n\n            if c in bounds:\n                b = bounds[c]\n                row[c] = [b[\"min\"],row[b[\"lower\"]], row[b[\"upper\"]], b[\"max\"]]\n\n        return row", "response": "Formats a single row of the dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms dataframe to properly formatted json response", "response": "def to_json(df, columns, confidence={}):\n        \"\"\"Transforms dataframe to properly formatted json response\"\"\"\n        records = []\n\n        display_cols = list(columns.keys())\n        if not display_cols:\n            display_cols = list(df.columns)\n\n        bounds = {}\n        for c in confidence:\n            bounds[c] = {\n                \"min\": df[confidence[c][\"lower\"]].min(),\n                \"max\": df[confidence[c][\"upper\"]].max(),\n                \"lower\": confidence[c][\"lower\"],\n                \"upper\": confidence[c][\"upper\"]\n            }\n\n        labels = {}\n        for c in display_cols:\n            if \"label\" in columns[c]:\n                labels[c] = columns[c][\"label\"]\n            else:\n                labels[c] = c\n\n        for i, row in df.iterrows():\n            row_ = DataTable.format_row(row, bounds, columns)\n            records.append({labels[c]: row_[c] for c in display_cols})\n\n        return {\n            \"data\": records,\n            \"columns\": [{\"data\": labels[c]} for c in display_cols]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self):\n        options = {}\n        for x in [self.axes, self.graphics, self.layout]:\n            for k, v in list(x.get().items()):\n                options[k] = v\n\n        return options", "response": "Return axes graphics and layout options."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats output for json response.", "response": "def to_json(df, x, y):\n        \"\"\"Format output for json response.\"\"\"\n        values = []\n        for i, row in df.iterrows():\n            values.append({\n                \"x\": row[x],\n                \"y\": row[y]\n                })\n\n        if df.empty:\n            return {\"result\": [{\"x\": 0, \"y\": 0}], \"date\": False}\n\n        return {\"result\": values, \"date\": False}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_margin(self, top=40, bottom=30, left=50, right=10, buffer_size=8):\n        self.set_integer(\"top\", top)\n        self.set_integer(\"bottom\", bottom)\n        self.set_integer(\"left\", left)\n        self.set_integer(\"right\", right)\n        self.set_integer(\"buffer\", buffer_size)", "response": "Sets the margin of the chart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_size(self, height=220, width=350,\n                 height_threshold=120,\n                 width_threshold=160):\n        \"\"\"Set the size of the chart.\n\n            Args:\n                height (int): height in pixels.\n                width (int): width in pixels.\n                height_threshold (int): height threshold in pixels\n                width_threshold (int): width threshold in pixesls\n\n        \"\"\"\n        self.set_integer(\"height\", height)\n        self.set_integer(\"width\", width)\n        self.set_integer(\"small_height_threshold\", height_threshold)\n        self.set_integer(\"small_width_threshold\", width_threshold)", "response": "Sets the size of the assessment page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_props(props, prop_template=\"{{k}} = { {{v}} }\", delim=\"\\n\"):\n    vars_ = []\n    props_ = []\n    for k, v in list(props.items()):\n        vars_.append(Template(\"var {{k}} = {{v}};\").render(k=k,v=json.dumps(v)))\n        props_.append(Template(prop_template).render(k=k, v=k))\n    return \"\\n\".join(vars_), delim.join(props_)", "response": "Formats the properties of the object to be written to the template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a function that will send props for each UILayout", "response": "def register_layouts(layouts, app, url=\"/api/props/\", brand=\"Pyxley\"):\n    \"\"\" register UILayout with the flask app\n\n        create a function that will send props for each UILayout\n\n        Args:\n            layouts (dict): dict of UILayout objects by name\n            app (object): flask app\n            url (string): address of props; default is /api/props/\n    \"\"\"\n    def props(name):\n        if name not in layouts:\n            # cast as list for python3\n            name = list(layouts.keys())[0]\n        return jsonify({\"layouts\": layouts[name][\"layout\"]})\n\n    def apps():\n        paths = []\n        for i, k in enumerate(layouts.keys()):\n            if i == 0:\n                paths.append({\n                    \"path\": \"/\",\n                    \"label\": layouts[k].get(\"title\", k)\n                })\n\n            paths.append({\n                \"path\": \"/\"+k,\n                \"label\": layouts[k].get(\"title\", k)\n            })\n\n        return jsonify({\"brand\": brand, \"navlinks\": paths})\n\n    app.add_url_rule(url+\"<string:name>/\", view_func=props)\n    app.add_url_rule(url, view_func=apps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters the api route function with the app.", "response": "def register_route(self, app):\n        \"\"\"Register the api route function with the app.\"\"\"\n        if \"url\" not in self.params[\"options\"]:\n            raise Exception(\"Component does not have a URL property\")\n\n        if not hasattr(self.route_func, \"__call__\"):\n            raise Exception(\"No app route function supplied\")\n\n        app.add_url_rule(self.params[\"options\"][\"url\"],\n            self.params[\"options\"][\"url\"],\n            self.route_func)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the component to a javascript file.", "response": "def render(self, path):\n        \"\"\"Render the component to a javascript file.\"\"\"\n        return ReactComponent(\n            self.layout,\n            self.src_file,\n            self.component_id,\n            props=self.props,\n            static_path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_filter(self, component, filter_group=\"pyxley-filter\"):\n        if getattr(component, \"name\") != \"Filter\":\n            raise Exception(\"Component is not an instance of Filter\")\n        if filter_group not in self.filters:\n            self.filters[filter_group] = []\n        self.filters[filter_group].append(component)", "response": "Add a filter to the layout."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_chart(self, component):\n        if getattr(component, \"name\") != \"Chart\":\n            raise Exception(\"Component is not an instance of Chart\")\n        self.charts.append(component)", "response": "Add a chart to the layout."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_props(self):\n        props = {}\n        if self.filters:\n            props[\"filters\"] = {}\n            for grp in self.filters:\n                props[\"filters\"][grp] = [f.params for f in self.filters[grp]]\n        if self.charts:\n            props[\"charts\"] = [c.params for c in self.charts]\n\n        props[\"type\"] = self.layout\n        return props", "response": "Build the props dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering routes with the app.", "response": "def assign_routes(self, app):\n        \"\"\"Register routes with the app.\"\"\"\n        for grp in self.filters:\n            for f in self.filters[grp]:\n                if f.route_func:\n                    f.register_route(app)\n\n        for c in self.charts:\n            if c.route_func:\n                c.register_route(app)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_json(df, x, y, timeseries=False):\n        values = {k: [] for k in y}\n        for i, row in df.iterrows():\n            for yy in y:\n                values[yy].append({\n                    \"x\": row[x],\n                    \"y\": row[yy]\n                    })\n        return {\"result\":  [values[k] for k in y], \"date\": timeseries}", "response": "Format output for json response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_static_path():\n    fdir = os.path.dirname(__file__)\n    return os.path.abspath(os.path.join(fdir, '../assets/'))", "response": "Returns the path to the javascript bundle\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the path to the index. html", "response": "def default_template_path():\n    \"\"\"\n        Return the path to the index.html\n    \"\"\"\n    fdir = os.path.dirname(__file__)\n    return os.path.abspath(os.path.join(fdir, '../assets/'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a mg line plot", "response": "def create_line_plot(df):\n    \"\"\" create a mg line plot\n\n        Args:\n            df (pandas.DataFrame): data to plot\n    \"\"\"\n    fig = Figure(\"/mg/line_plot/\", \"mg_line_plot\")\n    fig.graphics.transition_on_update(True)\n    fig.graphics.animate_on_load()\n    fig.layout.set_size(width=450, height=200)\n    fig.layout.set_margin(left=40, right=40)\n    return LineChart(df, fig, \"Date\", [\"value\"],\n        init_params={\"Data\": \"Steps\"}, timeseries=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a histogram plot of the", "response": "def create_histogram(df):\n    \"\"\" create a mg line plot\n\n        Args:\n            df (pandas.DataFrame): data to plot\n    \"\"\"\n    fig = Figure(\"/mg/histogram/\", \"mg_histogram\")\n    fig.layout.set_size(width=450, height=200)\n    fig.layout.set_margin(left=40, right=40)\n    fig.graphics.animate_on_load()\n\n    # Make a histogram with 20 bins\n    return Histogram(df, fig, \"value\", 20, init_params={\"Data\": \"Steps\"})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_scatterplot(df):\n    fig = Figure(\"/mg/scatter/\", \"mg_scatter\")\n    fig.layout.set_size(width=450, height=200)\n    fig.layout.set_margin(left=40, right=40)\n    fig.graphics.animate_on_load()\n\n    init_params = {\"Data\": \"Steps\"}\n\n    def get_data():\n        y = request.args.get(\"Data\", \"Steps\")\n        return jsonify(ScatterPlot.to_json(df, \"Steps\", y))\n\n    # Make a histogram with 20 bins\n    return ScatterPlot(df, fig, \"Steps\", \"Distance\",\n        init_params={}, route_func=get_data)", "response": "create a mg line plot"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the x - axis limits for the current log entry.", "response": "def set_xlim(self, xlim):\n        \"\"\" Set x-axis limits.\n\n            Accepts a two-element list to set the x-axis limits.\n\n            Args:\n                xlim (list): lower and upper bounds\n\n            Raises:\n                ValueError: xlim must contain two elements\n                ValueError: Min must be less than max\n        \"\"\"\n        if len(xlim) != 2:\n            raise ValueError(\"xlim must contain two elements\")\n\n        if xlim[1] < xlim[0]:\n            raise ValueError(\"Min must be less than Max\")\n\n        self.options[\"min_x\"] = xlim[0]\n        self.options[\"max_x\"] = xlim[1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the y - axis limits for the current log entry.", "response": "def set_ylim(self, ylim):\n        \"\"\" Set y-axis limits.\n\n            Accepts a two-element list to set the y-axis limits.\n\n            Args:\n                ylim (list): lower and upper bounds\n\n            Raises:\n                ValueError: ylim must contain two elements\n                ValueError: Min must be less than max\n        \"\"\"\n        if len(ylim) != 2:\n            raise ValueError(\"ylim must contain two elements\")\n\n        if ylim[1] < ylim[0]:\n            raise ValueError(\"Min must be less than Max\")\n\n        self.options[\"min_y\"] = ylim[0]\n        self.options[\"max_y\"] = ylim[1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self):\n        return {k:v for k,v in list(self.options.items()) if k in self._allowed_axes}", "response": "Retrieve options set by user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats output for the json response.", "response": "def to_json(df, values):\n        \"\"\"Format output for the json response.\"\"\"\n        records = []\n        if df.empty:\n            return {\"data\": []}\n\n        sum_ = float(np.sum([df[c].iloc[0] for c in values]))\n        for c in values:\n            records.append({\n                \"label\": values[c],\n                \"value\": \"%.2f\"%np.around(df[c].iloc[0] / sum_, decimals=2)\n                })\n        return {\n            \"data\" : records\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform dataframe to json response", "response": "def to_json(df, state_index, color_index, fills):\n        \"\"\"Transforms dataframe to json response\"\"\"\n        records = {}\n        for i, row in df.iterrows():\n\n            records[row[state_index]] = {\n                \"fillKey\": row[color_index]\n            }\n\n        return {\n            \"data\": records,\n            \"fills\": fills\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the device shadow JSON document string from AWS IoT by publishing the provided JSON document string to the corresponding shadow topics.", "response": "def shadowUpdate(self, srcJSONPayload, srcCallback, srcTimeout):\n        \"\"\"\n        **Description**\n\n        Update the device shadow JSON document string from AWS IoT by publishing the provided JSON \n        document to the corresponding shadow topics. Shadow response topics will be subscribed to \n        receive responses from AWS IoT regarding the result of the get operation. Response will be \n        available in the registered callback. If no response is received within the provided timeout, \n        a timeout notification will be passed into the registered callback.\n\n        **Syntax**\n\n        .. code:: python\n\n          # Update the shadow JSON document from AWS IoT, with a timeout set to 5 seconds\n          BotShadow.shadowUpdate(newShadowJSONDocumentString, customCallback, 5)\n\n        **Parameters**\n\n        *srcJSONPayload* - JSON document string used to update shadow JSON document in AWS IoT.\n\n        *srcCallback* - Function to be called when the response for this shadow request comes back. Should \n        be in form :code:`customCallback(payload, responseStatus, token)`, where :code:`payload` is the \n        JSON document returned, :code:`responseStatus` indicates whether the request has been accepted, \n        rejected or is a delta message, :code:`token` is the token used for tracing in this request.\n\n        *srcTimeout* - Timeout to determine whether the request is invalid. When a request gets timeout, \n        a timeout notification will be generated and put into the registered callback to notify users.\n\n        **Returns**\n\n        The token used for tracing in this shadow request.\n\n        \"\"\"\n        # Validate JSON\n        self._basicJSONParserHandler.setString(srcJSONPayload)\n        if self._basicJSONParserHandler.validateJSON():\n            with self._dataStructureLock:\n                # clientToken\n                currentToken = self._tokenHandler.getNextToken()\n                self._tokenPool[currentToken] = Timer(srcTimeout, self._timerHandler, [\"update\", currentToken])\n                self._basicJSONParserHandler.setAttributeValue(\"clientToken\", currentToken)\n                JSONPayloadWithToken = self._basicJSONParserHandler.regenerateString()\n                # Update callback data structure\n                self._shadowSubscribeCallbackTable[\"update\"] = srcCallback\n                # Update number of pending feedback\n                self._shadowSubscribeStatusTable[\"update\"] += 1\n            # Two subscriptions\n            if not self._isPersistentSubscribe or not self._isUpdateSubscribed:\n                self._shadowManagerHandler.basicShadowSubscribe(self._shadowName, \"update\", self.generalCallback)\n                self._isUpdateSubscribed = True\n                self._logger.info(\"Subscribed to update accepted/rejected topics for deviceShadow: \" + self._shadowName)\n            # One publish\n            self._shadowManagerHandler.basicShadowPublish(self._shadowName, \"update\", JSONPayloadWithToken)\n            # Start the timer\n            self._tokenPool[currentToken].start()\n        else:\n            raise ValueError(\"Invalid JSON file.\")\n        return currentToken"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shadowRegisterDeltaCallback(self, srcCallback):\n        with self._dataStructureLock:\n            # Update callback data structure\n            self._shadowSubscribeCallbackTable[\"delta\"] = srcCallback\n        # One subscription\n        self._shadowManagerHandler.basicShadowSubscribe(self._shadowName, \"delta\", self.generalCallback)\n        self._logger.info(\"Subscribed to delta topic for deviceShadow: \" + self._shadowName)", "response": "Register a callback to be called when a delta message is received for this shadow."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shadowUnregisterDeltaCallback(self):\n        with self._dataStructureLock:\n            # Update callback data structure\n            del self._shadowSubscribeCallbackTable[\"delta\"]\n        # One unsubscription\n        self._shadowManagerHandler.basicShadowUnsubscribe(self._shadowName, \"delta\")\n        self._logger.info(\"Unsubscribed to delta topics for deviceShadow: \" + self._shadowName)", "response": "Unregister a callback for delta topics for this device shadow."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configureLastWill(self, topic, payload, QoS, retain=False):\n        self._mqtt_core.configure_last_will(topic, payload, QoS, retain)", "response": "Configure the last will of the specified topic and payload."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring the endpoint for the current AWS IoT instance.", "response": "def configureEndpoint(self, hostName, portNumber):\n        \"\"\"\n        **Description**\n\n        Used to configure the host name and port number the client tries to connect to. Should be called\n        before connect.\n\n        **Syntax**\n\n        .. code:: python\n\n          myAWSIoTMQTTClient.configureEndpoint(\"random.iot.region.amazonaws.com\", 8883)\n\n        **Parameters**\n\n        *hostName* - String that denotes the host name of the user-specific AWS IoT endpoint.\n\n        *portNumber* - Integer that denotes the port number to connect to. Could be :code:`8883` for\n        TLSv1.2 Mutual Authentication or :code:`443` for Websocket SigV4 and TLSv1.2 Mutual Authentication\n        with ALPN extension.\n\n        **Returns**\n\n        None\n\n        \"\"\"\n        endpoint_provider = EndpointProvider()\n        endpoint_provider.set_host(hostName)\n        endpoint_provider.set_port(portNumber)\n        self._mqtt_core.configure_endpoint(endpoint_provider)\n        if portNumber == 443 and not self._mqtt_core.use_wss():\n            self._mqtt_core.configure_alpn_protocols()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the custom IAM credentials for the Websocket SigV4 connection to", "response": "def configureIAMCredentials(self, AWSAccessKeyID, AWSSecretAccessKey, AWSSessionToken=\"\"):\n        \"\"\"\n        **Description**\n\n        Used to configure/update the custom IAM credentials for Websocket SigV4 connection to \n        AWS IoT. Should be called before connect.\n\n        **Syntax**\n\n        .. code:: python\n\n          myAWSIoTMQTTClient.configureIAMCredentials(obtainedAccessKeyID, obtainedSecretAccessKey, obtainedSessionToken)\n\n        .. note::\n\n          Hard-coding credentials into custom script is NOT recommended. Please use AWS Cognito identity service\n          or other credential provider.\n\n        **Parameters**\n\n        *AWSAccessKeyID* - AWS Access Key Id from user-specific IAM credentials.\n\n        *AWSSecretAccessKey* - AWS Secret Access Key from user-specific IAM credentials.\n\n        *AWSSessionToken* - AWS Session Token for temporary authentication from STS.\n\n        **Returns**\n\n        None\n\n        \"\"\"\n        iam_credentials_provider = IAMCredentialsProvider()\n        iam_credentials_provider.set_access_key_id(AWSAccessKeyID)\n        iam_credentials_provider.set_secret_access_key(AWSSecretAccessKey)\n        iam_credentials_provider.set_session_token(AWSSessionToken)\n        self._mqtt_core.configure_iam_credentials(iam_credentials_provider)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the credentials for the root CA", "response": "def configureCredentials(self, CAFilePath, KeyPath=\"\", CertificatePath=\"\"):  # Should be good for MutualAuth certs config and Websocket rootCA config\n        \"\"\"\n        **Description**\n\n        Used to configure the rootCA, private key and certificate files. Should be called before connect.\n\n        **Syntax**\n\n        .. code:: python\n\n          myAWSIoTMQTTClient.configureCredentials(\"PATH/TO/ROOT_CA\", \"PATH/TO/PRIVATE_KEY\", \"PATH/TO/CERTIFICATE\")\n\n        **Parameters**\n\n        *CAFilePath* - Path to read the root CA file. Required for all connection types.\n\n        *KeyPath* - Path to read the private key. Required for X.509 certificate based connection.\n\n        *CertificatePath* - Path to read the certificate. Required for X.509 certificate based connection.\n\n        **Returns**\n\n        None\n\n        \"\"\"\n        cert_credentials_provider = CertificateCredentialsProvider()\n        cert_credentials_provider.set_ca_path(CAFilePath)\n        cert_credentials_provider.set_key_path(KeyPath)\n        cert_credentials_provider.set_cert_path(CertificatePath)\n        self._mqtt_core.configure_cert_credentials(cert_credentials_provider)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configureAutoReconnectBackoffTime(self, baseReconnectQuietTimeSecond, maxReconnectQuietTimeSecond, stableConnectionTimeSecond):\n        self._mqtt_core.configure_reconnect_back_off(baseReconnectQuietTimeSecond, maxReconnectQuietTimeSecond, stableConnectionTimeSecond)", "response": "Configure the auto - reconnect backoff time for the given set of log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configureOfflinePublishQueueing(self, queueSize, dropBehavior=DROP_NEWEST):\n        self._mqtt_core.configure_offline_requests_queue(queueSize, dropBehavior)", "response": "Configure the queue size and drop behavior for the offline publish requests queueing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connectAsync(self, keepAliveIntervalSecond=600, ackCallback=None):\n        self._load_callbacks()\n        return self._mqtt_core.connect_async(keepAliveIntervalSecond, ackCallback)", "response": "Connect to the MQTT server asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npublishing a new message to the specified topic with the specified QoS.", "response": "def publish(self, topic, payload, QoS):\n        \"\"\"\n        **Description**\n\n        Publish a new message to the desired topic with QoS.\n\n        **Syntax**\n\n        .. code:: python\n\n          # Publish a QoS0 message \"myPayload\" to topic \"myTopic\"\n          myAWSIoTMQTTClient.publish(\"myTopic\", \"myPayload\", 0)\n          # Publish a QoS1 message \"myPayloadWithQos1\" to topic \"myTopic/sub\"\n          myAWSIoTMQTTClient.publish(\"myTopic/sub\", \"myPayloadWithQos1\", 1)\n\n        **Parameters**\n\n        *topic* - Topic name to publish to.\n\n        *payload* - Payload to publish.\n\n        *QoS* - Quality of Service. Could be 0 or 1.\n\n        **Returns**\n\n        True if the publish request has been sent to paho. False if the request did not reach paho.\n\n        \"\"\"\n        return self._mqtt_core.publish(topic, payload, QoS, False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npublishes a new message asynchronously to the specified topic with optional PUBACK callback.", "response": "def publishAsync(self, topic, payload, QoS, ackCallback=None):\n        \"\"\"\n        **Description**\n\n        Publish a new message asynchronously to the desired topic with QoS and PUBACK callback. Note that the ack\n        callback configuration for a QoS0 publish request will be ignored as there are no PUBACK reception.\n\n        **Syntax**\n\n        .. code:: python\n\n          # Publish a QoS0 message \"myPayload\" to topic \"myTopic\"\n          myAWSIoTMQTTClient.publishAsync(\"myTopic\", \"myPayload\", 0)\n          # Publish a QoS1 message \"myPayloadWithQos1\" to topic \"myTopic/sub\", with custom PUBACK callback\n          myAWSIoTMQTTClient.publishAsync(\"myTopic/sub\", \"myPayloadWithQos1\", 1, ackCallback=myPubackCallback)\n\n        **Parameters**\n\n        *topic* - Topic name to publish to.\n\n        *payload* - Payload to publish.\n\n        *QoS* - Quality of Service. Could be 0 or 1.\n\n        *ackCallback* - Callback to be invoked when the client receives a PUBACK. Should be in form\n        :code:`customCallback(mid)`, where :code:`mid` is the packet id for the disconnect request.\n\n        **Returns**\n\n        Publish request packet id, for tracking purpose in the corresponding callback.\n\n        \"\"\"\n        return self._mqtt_core.publish_async(topic, payload, QoS, False, ackCallback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubscribe to a topic and register a callback.", "response": "def subscribe(self, topic, QoS, callback):\n        \"\"\"\n        **Description**\n\n        Subscribe to the desired topic and register a callback.\n\n        **Syntax**\n\n        .. code:: python\n\n          # Subscribe to \"myTopic\" with QoS0 and register a callback\n          myAWSIoTMQTTClient.subscribe(\"myTopic\", 0, customCallback)\n          # Subscribe to \"myTopic/#\" with QoS1 and register a callback\n          myAWSIoTMQTTClient.subscribe(\"myTopic/#\", 1, customCallback)\n\n        **Parameters**\n\n        *topic* - Topic name or filter to subscribe to.\n\n        *QoS* - Quality of Service. Could be 0 or 1.\n\n        *callback* - Function to be called when a new message for the subscribed topic\n        comes in. Should be in form :code:`customCallback(client, userdata, message)`, where\n        :code:`message` contains :code:`topic` and :code:`payload`. Note that :code:`client` and :code:`userdata` are\n        here just to be aligned with the underneath Paho callback function signature. These fields are pending to be\n        deprecated and should not be depended on.\n\n        **Returns**\n\n        True if the subscribe attempt succeeded. False if failed.\n\n        \"\"\"\n        return self._mqtt_core.subscribe(topic, QoS, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subscribeAsync(self, topic, QoS, ackCallback=None, messageCallback=None):\n        return self._mqtt_core.subscribe_async(topic, QoS, ackCallback, messageCallback)", "response": "Subscribe to a topic and register a message callback with SUBACK callback."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configureLastWill(self, topic, payload, QoS):\n        # AWSIoTMQTTClient.configureLastWill(srcTopic, srcPayload, srcQos)\n        self._AWSIoTMQTTClient.configureLastWill(topic, payload, QoS)", "response": "Configure the last will topic payload and QoS of the client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configureIAMCredentials(self, AWSAccessKeyID, AWSSecretAccessKey, AWSSTSToken=\"\"):\n        # AWSIoTMQTTClient.configureIAMCredentials\n        self._AWSIoTMQTTClient.configureIAMCredentials(AWSAccessKeyID, AWSSecretAccessKey, AWSSTSToken)", "response": "Configure IAM credentials for the current client."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure the credentials for the root CA file.", "response": "def configureCredentials(self, CAFilePath, KeyPath=\"\", CertificatePath=\"\"):  # Should be good for MutualAuth and Websocket\n        \"\"\"\n        **Description**\n\n        Used to configure the rootCA, private key and certificate files. Should be called before connect. This is a public\n        facing API inherited by application level public clients.\n\n        **Syntax**\n\n        .. code:: python\n\n          myShadowClient.clearLastWill(\"PATH/TO/ROOT_CA\", \"PATH/TO/PRIVATE_KEY\", \"PATH/TO/CERTIFICATE\")\n          myJobsClient.clearLastWill(\"PATH/TO/ROOT_CA\", \"PATH/TO/PRIVATE_KEY\", \"PATH/TO/CERTIFICATE\")\n\n        **Parameters**\n\n        *CAFilePath* - Path to read the root CA file. Required for all connection types.\n\n        *KeyPath* - Path to read the private key. Required for X.509 certificate based connection.\n\n        *CertificatePath* - Path to read the certificate. Required for X.509 certificate based connection.\n\n        **Returns**\n\n        None\n\n        \"\"\"\n        # AWSIoTMQTTClient.configureCredentials\n        self._AWSIoTMQTTClient.configureCredentials(CAFilePath, KeyPath, CertificatePath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the auto - reconnect backoff timing for the given set of time intervals.", "response": "def configureAutoReconnectBackoffTime(self, baseReconnectQuietTimeSecond, maxReconnectQuietTimeSecond, stableConnectionTimeSecond):\n        \"\"\"\n        **Description**\n\n        Used to configure the auto-reconnect backoff timing. Should be called before connect. This is a public\n        facing API inherited by application level public clients.\n\n        **Syntax**\n\n        .. code:: python\n\n          # Configure the auto-reconnect backoff to start with 1 second and use 128 seconds as a maximum back off time.\n          # Connection over 20 seconds is considered stable and will reset the back off time back to its base.\n          myShadowClient.clearLastWill(1, 128, 20)\n          myJobsClient.clearLastWill(1, 128, 20)\n\n        **Parameters**\n\n        *baseReconnectQuietTimeSecond* - The initial back off time to start with, in seconds.\n        Should be less than the stableConnectionTime.\n\n        *maxReconnectQuietTimeSecond* - The maximum back off time, in seconds.\n\n        *stableConnectionTimeSecond* - The number of seconds for a connection to last to be considered as stable.\n        Back off time will be reset to base once the connection is stable.\n\n        **Returns**\n\n        None\n\n        \"\"\"\n        # AWSIoTMQTTClient.configureBackoffTime\n        self._AWSIoTMQTTClient.configureAutoReconnectBackoffTime(baseReconnectQuietTimeSecond, maxReconnectQuietTimeSecond, stableConnectionTimeSecond)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createShadowHandlerWithName(self, shadowName, isPersistentSubscribe):\n        # Create and return a deviceShadow instance\n        return deviceShadow.deviceShadow(shadowName, isPersistentSubscribe, self._shadowManager)", "response": "Create a shadow handler for a named topic."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createJobSubscription(self, callback, jobExecutionType=jobExecutionTopicType.JOB_WILDCARD_TOPIC, jobReplyType=jobExecutionTopicReplyType.JOB_REQUEST_TYPE, jobId=None):\n        topic = self._thingJobManager.getJobTopic(jobExecutionType, jobReplyType, jobId)\n        return self._AWSIoTMQTTClient.subscribe(topic, self._QoS, callback)", "response": "Create a subscription to a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createJobSubscriptionAsync(self, ackCallback, callback, jobExecutionType=jobExecutionTopicType.JOB_WILDCARD_TOPIC, jobReplyType=jobExecutionTopicReplyType.JOB_REQUEST_TYPE, jobId=None):\n        topic = self._thingJobManager.getJobTopic(jobExecutionType, jobReplyType, jobId)\n        return self._AWSIoTMQTTClient.subscribeAsync(topic, self._QoS, ackCallback, callback)", "response": "This method creates a subscription to a specific job related topic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sendJobsQuery(self, jobExecTopicType, jobId=None):\n        topic = self._thingJobManager.getJobTopic(jobExecTopicType, jobExecutionTopicReplyType.JOB_REQUEST_TYPE, jobId)\n        payload = self._thingJobManager.serializeClientTokenPayload()\n        return self._AWSIoTMQTTClient.publish(topic, payload, self._QoS)", "response": "Send a job query to the jobs topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sendJobsStartNext(self, statusDetails=None):\n        topic = self._thingJobManager.getJobTopic(jobExecutionTopicType.JOB_START_NEXT_TOPIC, jobExecutionTopicReplyType.JOB_REQUEST_TYPE)\n        payload = self._thingJobManager.serializeStartNextPendingJobExecutionPayload(statusDetails)\n        return self._AWSIoTMQTTClient.publish(topic, payload, self._QoS)", "response": "Sends an StartNextJobExecution to the Job Manager."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a Describe job request to the describe topic.", "response": "def sendJobsDescribe(self, jobId, executionNumber=0, includeJobDocument=True):\n        \"\"\"\n        **Description**\n\n        Publishes a method to the describe topic for a particular job.\n\n        **Syntax**\n\n        .. code:: python\n\n          #Describe job with id 'jobId1' of any executionNumber, job document will be included in response\n          myAWSIoTMQTTJobsClient.sendJobsDescribe('jobId1')\n\n          #Describe job with id 'jobId2', with execution number of 2, and includeJobDocument in the response\n          myAWSIoTMQTTJobsClient.sendJobsDescribe('jobId2', 2, True)\n\n        **Parameters**\n\n        *jobId* - jobID to describe. This is allowed to be a wildcard such as '$next'\n\n        *executionNumber* - A number that identifies a particular job execution on a particular device. If not specified, the latest job execution is used.\n\n        *includeJobDocument* - When included and set to True, the response contains the JobDocument.\n\n        **Returns**\n\n        True if the publish request has been sent to paho. False if the request did not reach paho.\n\n        \"\"\"\n        topic = self._thingJobManager.getJobTopic(jobExecutionTopicType.JOB_DESCRIBE_TOPIC, jobExecutionTopicReplyType.JOB_REQUEST_TYPE, jobId)\n        payload = self._thingJobManager.serializeDescribeJobExecutionPayload(executionNumber, includeJobDocument)\n        return self._AWSIoTMQTTClient.publish(topic, payload, self._QoS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef error_string(mqtt_errno):\n    if mqtt_errno == MQTT_ERR_SUCCESS:\n        return \"No error.\"\n    elif mqtt_errno == MQTT_ERR_NOMEM:\n        return \"Out of memory.\"\n    elif mqtt_errno == MQTT_ERR_PROTOCOL:\n        return \"A network protocol error occurred when communicating with the broker.\"\n    elif mqtt_errno == MQTT_ERR_INVAL:\n        return \"Invalid function arguments provided.\"\n    elif mqtt_errno == MQTT_ERR_NO_CONN:\n        return \"The client is not currently connected.\"\n    elif mqtt_errno == MQTT_ERR_CONN_REFUSED:\n        return \"The connection was refused.\"\n    elif mqtt_errno == MQTT_ERR_NOT_FOUND:\n        return \"Message not found (internal error).\"\n    elif mqtt_errno == MQTT_ERR_CONN_LOST:\n        return \"The connection was lost.\"\n    elif mqtt_errno == MQTT_ERR_TLS:\n        return \"A TLS error occurred.\"\n    elif mqtt_errno == MQTT_ERR_PAYLOAD_SIZE:\n        return \"Payload too large.\"\n    elif mqtt_errno == MQTT_ERR_NOT_SUPPORTED:\n        return \"This feature is not supported.\"\n    elif mqtt_errno == MQTT_ERR_AUTH:\n        return \"Authorisation failed.\"\n    elif mqtt_errno == MQTT_ERR_ACL_DENIED:\n        return \"Access denied by ACL.\"\n    elif mqtt_errno == MQTT_ERR_UNKNOWN:\n        return \"Unknown error.\"\n    elif mqtt_errno == MQTT_ERR_ERRNO:\n        return \"Error defined by errno.\"\n    else:\n        return \"Unknown error.\"", "response": "Return the error string associated with an MQTT error number."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef topic_matches_sub(sub, topic):\n    result = True\n    multilevel_wildcard = False\n\n    slen = len(sub)\n    tlen = len(topic)\n\n    if slen > 0 and tlen > 0:\n        if (sub[0] == '$' and topic[0] != '$') or (topic[0] == '$' and sub[0] != '$'):\n            return False\n\n    spos = 0\n    tpos = 0\n\n    while spos < slen and tpos < tlen:\n        if sub[spos] == topic[tpos]:\n            if tpos == tlen-1:\n                # Check for e.g. foo matching foo/#\n                if spos == slen-3 and sub[spos+1] == '/' and sub[spos+2] == '#':\n                    result = True\n                    multilevel_wildcard = True\n                    break\n\n            spos += 1\n            tpos += 1\n\n            if tpos == tlen and spos == slen-1 and sub[spos] == '+':\n                spos += 1\n                result = True\n                break\n        else:\n            if sub[spos] == '+':\n                spos += 1\n                while tpos < tlen and topic[tpos] != '/':\n                    tpos += 1\n                if tpos == tlen and spos == slen:\n                    result = True\n                    break\n\n            elif sub[spos] == '#':\n                multilevel_wildcard = True\n                if spos+1 != slen:\n                    result = False\n                    break\n                else:\n                    result = True\n                    break\n\n            else:\n                result = False\n                break\n\n    if not multilevel_wildcard and (tpos < tlen or spos < slen):\n        result = False\n\n    return result", "response": "Check whether a topic matches a subscription."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the base and maximum reconnection time for reconnect logic.", "response": "def setBackoffTiming(self, srcBaseReconnectTimeSecond, srcMaximumReconnectTimeSecond, srcMinimumConnectTimeSecond):\n        \"\"\"\n        Make custom settings for backoff timing for reconnect logic\n        srcBaseReconnectTimeSecond - The base reconnection time in seconds\n        srcMaximumReconnectTimeSecond - The maximum reconnection time in seconds\n        srcMinimumConnectTimeSecond - The minimum time in seconds that a connection must be maintained in order to be considered stable\n        * Raise ValueError if input params are malformed\n        \"\"\"\n        self._backoffCore.configTime(srcBaseReconnectTimeSecond, srcMaximumReconnectTimeSecond, srcMinimumConnectTimeSecond)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configIAMCredentials(self, srcAWSAccessKeyID, srcAWSSecretAccessKey, srcAWSSessionToken):\n        self._AWSAccessKeyIDCustomConfig = srcAWSAccessKeyID\n        self._AWSSecretAccessKeyCustomConfig = srcAWSSecretAccessKey\n        self._AWSSessionTokenCustomConfig = srcAWSSessionToken", "response": "Set custom settings for IAM credentials for websocket connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tls_set(self, ca_certs, certfile=None, keyfile=None, cert_reqs=cert_reqs, tls_version=tls_version, ciphers=None):\n        if HAVE_SSL is False:\n            raise ValueError('This platform has no SSL/TLS.')\n\n        if sys.version < '2.7':\n            raise ValueError('Python 2.7 is the minimum supported version for TLS.')\n\n        if ca_certs is None:\n            raise ValueError('ca_certs must not be None.')\n\n        try:\n            f = open(ca_certs, \"r\")\n        except IOError as err:\n            raise IOError(ca_certs+\": \"+err.strerror)\n        else:\n            f.close()\n        if certfile is not None:\n            try:\n                f = open(certfile, \"r\")\n            except IOError as err:\n                raise IOError(certfile+\": \"+err.strerror)\n            else:\n                f.close()\n        if keyfile is not None:\n            try:\n                f = open(keyfile, \"r\")\n            except IOError as err:\n                raise IOError(keyfile+\": \"+err.strerror)\n            else:\n                f.close()\n\n        self._tls_ca_certs = ca_certs\n        self._tls_certfile = certfile\n        self._tls_keyfile = keyfile\n        self._tls_cert_reqs = cert_reqs\n        self._tls_version = tls_version\n        self._tls_ciphers = ciphers", "response": "Configure SSL and TLS authentication options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(self, host, port=1883, keepalive=60, bind_address=\"\"):\n        self.connect_async(host, port, keepalive, bind_address)\n        return self.reconnect()", "response": "Connect to a remote broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to a remote broker.", "response": "def connect_srv(self, domain=None, keepalive=60, bind_address=\"\"):\n        \"\"\"Connect to a remote broker.\n\n        domain is the DNS domain to search for SRV records; if None,\n        try to determine local domain name.\n        keepalive and bind_address are as for connect()\n        \"\"\"\n\n        if HAVE_DNS is False:\n            raise ValueError('No DNS resolver library found.')\n\n        if domain is None:\n            domain = socket.getfqdn()\n            domain = domain[domain.find('.') + 1:]\n\n        try:\n            rr = '_mqtt._tcp.%s' % domain\n            if self._ssl is not None:\n                # IANA specifies secure-mqtt (not mqtts) for port 8883\n                rr = '_secure-mqtt._tcp.%s' % domain\n            answers = []\n            for answer in dns.resolver.query(rr, dns.rdatatype.SRV):\n                addr = answer.target.to_text()[:-1]\n                answers.append((addr, answer.port, answer.priority, answer.weight))\n        except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer, dns.resolver.NoNameservers):\n            raise ValueError(\"No answer/NXDOMAIN for SRV in %s\" % (domain))\n\n        # FIXME: doesn't account for weight\n        for answer in answers:\n            host, port, prio, weight = answer\n\n            try:\n                return self.connect(host, port, keepalive, bind_address)\n            except:\n                pass\n\n        raise ValueError(\"No SRV hosts responded\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect to a remote broker asynchronously.", "response": "def connect_async(self, host, port=1883, keepalive=60, bind_address=\"\"):\n        \"\"\"Connect to a remote broker asynchronously. This is a non-blocking\n        connect call that can be used with loop_start() to provide very quick\n        start.\n\n        host is the hostname or IP address of the remote broker.\n        port is the network port of the server host to connect to. Defaults to\n        1883. Note that the default port for MQTT over SSL/TLS is 8883 so if you\n        are using tls_set() the port may need providing.\n        keepalive: Maximum period in seconds between communications with the\n        broker. If no other messages are being exchanged, this controls the\n        rate at which the client will send ping messages to the broker.\n        \"\"\"\n        if host is None or len(host) == 0:\n            raise ValueError('Invalid host.')\n        if port <= 0:\n            raise ValueError('Invalid port number.')\n        if keepalive < 0:\n            raise ValueError('Keepalive must be >=0.')\n        if bind_address != \"\" and bind_address is not None:\n            if (sys.version_info[0] == 2 and sys.version_info[1] < 7) or (sys.version_info[0] == 3 and sys.version_info[1] < 2):\n                raise ValueError('bind_address requires Python 2.7 or 3.2.')\n\n        self._host = host\n        self._port = port\n        self._keepalive = keepalive\n        self._bind_address = bind_address\n\n        self._state_mutex.acquire()\n        self._state = mqtt_cs_connect_async\n        self._state_mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reconnect(self):\n        if len(self._host) == 0:\n            raise ValueError('Invalid host.')\n        if self._port <= 0:\n            raise ValueError('Invalid port number.')\n\n        self._in_packet = {\n            \"command\": 0,\n            \"have_remaining\": 0,\n            \"remaining_count\": [],\n            \"remaining_mult\": 1,\n            \"remaining_length\": 0,\n            \"packet\": b\"\",\n            \"to_process\": 0,\n            \"pos\": 0}\n\n        self._out_packet_mutex.acquire()\n        self._out_packet = []\n        self._out_packet_mutex.release()\n\n        self._current_out_packet_mutex.acquire()\n        self._current_out_packet = None\n        self._current_out_packet_mutex.release()\n\n        self._msgtime_mutex.acquire()\n        self._last_msg_in = time.time()\n        self._last_msg_out = time.time()\n        self._msgtime_mutex.release()\n\n        self._ping_t = 0\n        self._state_mutex.acquire()\n        self._state = mqtt_cs_new\n        self._state_mutex.release()\n        if self._ssl:\n            self._ssl.close()\n            self._ssl = None\n            self._sock = None\n        elif self._sock:\n            self._sock.close()\n            self._sock = None\n\n        # Put messages in progress in a valid state.\n        self._messages_reconnect_reset()\n\n        try:\n            if (sys.version_info[0] == 2 and sys.version_info[1] < 7) or (sys.version_info[0] == 3 and sys.version_info[1] < 2):\n                sock = socket.create_connection((self._host, self._port))\n            else:\n                sock = socket.create_connection((self._host, self._port), source_address=(self._bind_address, 0))\n        except socket.error as err:\n            if err.errno != errno.EINPROGRESS and err.errno != errno.EWOULDBLOCK and err.errno != EAGAIN:\n                raise\n\n        verify_hostname = self._tls_insecure is False  # Decide whether we need to verify hostname\n\n        if self._tls_ca_certs is not None:\n            if self._useSecuredWebsocket:\n                # Never assign to ._ssl before wss handshake is finished\n                # Non-None value for ._ssl will allow ops before wss-MQTT connection is established\n                rawSSL = ssl.wrap_socket(sock, ca_certs=self._tls_ca_certs, cert_reqs=ssl.CERT_REQUIRED)  # Add server certificate verification\n                rawSSL.setblocking(0)  # Non-blocking socket\n                self._ssl = SecuredWebSocketCore(rawSSL, self._host, self._port, self._AWSAccessKeyIDCustomConfig, self._AWSSecretAccessKeyCustomConfig, self._AWSSessionTokenCustomConfig)  # Override the _ssl socket\n                # self._ssl.enableDebug()\n            elif self._alpn_protocols is not None:\n                # SSLContext is required to enable ALPN support\n                # Assuming Python 2.7.10+/3.5+ till the end of this elif branch\n                ssl_context = SSLContextBuilder()\\\n                    .with_ca_certs(self._tls_ca_certs)\\\n                    .with_cert_key_pair(self._tls_certfile, self._tls_keyfile)\\\n                    .with_cert_reqs(self._tls_cert_reqs)\\\n                    .with_check_hostname(True)\\\n                    .with_ciphers(self._tls_ciphers)\\\n                    .with_alpn_protocols(self._alpn_protocols)\\\n                    .build()\n                self._ssl = ssl_context.wrap_socket(sock, server_hostname=self._host, do_handshake_on_connect=False)\n                verify_hostname = False  # Since check_hostname in SSLContext is already set to True, no need to verify it again\n                self._ssl.do_handshake()\n            else:\n                self._ssl = ssl.wrap_socket(\n                    sock,\n                    certfile=self._tls_certfile,\n                    keyfile=self._tls_keyfile,\n                    ca_certs=self._tls_ca_certs,\n                    cert_reqs=self._tls_cert_reqs,\n                    ssl_version=self._tls_version,\n                    ciphers=self._tls_ciphers)\n\n            if verify_hostname:\n                if sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] < 5):  # No IP host match before 3.5.x\n                    self._tls_match_hostname()\n                else:\n                    ssl.match_hostname(self._ssl.getpeercert(), self._host)\n\n        self._sock = sock\n\n        if self._ssl and not self._useSecuredWebsocket:\n            self._ssl.setblocking(0)  # For X.509 cert mutual auth.\n        elif not self._ssl:\n            self._sock.setblocking(0)  # For plain socket\n        else:\n            pass  # For MQTT over WebSocket\n\n        return self._send_connect(self._keepalive, self._clean_session)", "response": "Reconnect the client after a disconnect."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses network events. This function must be called regularly to ensure communication with the broker is carried out. It calls select() on the network socket to wait for network events. If incoming data is present it will then be processed. Outgoing commands, from e.g. publish(), are normally sent immediately that their function is called, but this is not always possible. loop() will also attempt to send any remaining outgoing messages, which also includes commands that are part of the flow for messages with QoS>0. timeout: The time in seconds to wait for incoming/outgoing network traffic before timing out and returning. max_packets: Not currently used. Returns MQTT_ERR_SUCCESS on success. Returns >0 on error. A ValueError will be raised if timeout < 0", "response": "def loop(self, timeout=1.0, max_packets=1):\n        \"\"\"Process network events.\n\n        This function must be called regularly to ensure communication with the\n        broker is carried out. It calls select() on the network socket to wait\n        for network events. If incoming data is present it will then be\n        processed. Outgoing commands, from e.g. publish(), are normally sent\n        immediately that their function is called, but this is not always\n        possible. loop() will also attempt to send any remaining outgoing\n        messages, which also includes commands that are part of the flow for\n        messages with QoS>0.\n\n        timeout: The time in seconds to wait for incoming/outgoing network\n          traffic before timing out and returning.\n        max_packets: Not currently used.\n\n        Returns MQTT_ERR_SUCCESS on success.\n        Returns >0 on error.\n\n        A ValueError will be raised if timeout < 0\"\"\"\n        if timeout < 0.0:\n            raise ValueError('Invalid timeout.')\n\n        self._current_out_packet_mutex.acquire()\n        self._out_packet_mutex.acquire()\n        if self._current_out_packet is None and len(self._out_packet) > 0:\n            self._current_out_packet = self._out_packet.pop(0)\n\n        if self._current_out_packet:\n            wlist = [self.socket()]\n        else:\n            wlist = []\n        self._out_packet_mutex.release()\n        self._current_out_packet_mutex.release()\n\n        # sockpairR is used to break out of select() before the timeout, on a\n        # call to publish() etc.\n        rlist = [self.socket(), self._sockpairR]\n        try:\n            socklist = select.select(rlist, wlist, [], timeout)\n        except TypeError as e:\n            # Socket isn't correct type, in likelihood connection is lost\n            return MQTT_ERR_CONN_LOST\n        except ValueError:\n            # Can occur if we just reconnected but rlist/wlist contain a -1 for\n            # some reason.\n            return MQTT_ERR_CONN_LOST\n        except:\n            return MQTT_ERR_UNKNOWN\n\n        if self.socket() in socklist[0]:\n            rc = self.loop_read(max_packets)\n            if rc or (self._ssl is None and self._sock is None):\n                return rc\n\n        if self._sockpairR in socklist[0]:\n            # Stimulate output write even though we didn't ask for it, because\n            # at that point the publish or other command wasn't present.\n            socklist[1].insert(0, self.socket())\n            # Clear sockpairR - only ever a single byte written.\n            try:\n                self._sockpairR.recv(1)\n            except socket.error as err:\n                if err.errno != EAGAIN:\n                    raise\n\n        if self.socket() in socklist[1]:\n            rc = self.loop_write(max_packets)\n            if rc or (self._ssl is None and self._sock is None):\n                return rc\n\n        return self.loop_misc()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a message on a topic.", "response": "def publish(self, topic, payload=None, qos=0, retain=False):\n        \"\"\"Publish a message on a topic.\n\n        This causes a message to be sent to the broker and subsequently from\n        the broker to any clients subscribing to matching topics.\n\n        topic: The topic that the message should be published on.\n        payload: The actual message to send. If not given, or set to None a\n        zero length message will be used. Passing an int or float will result\n        in the payload being converted to a string representing that number. If\n        you wish to send a true int/float, use struct.pack() to create the\n        payload you require.\n        qos: The quality of service level to use.\n        retain: If set to true, the message will be set as the \"last known\n        good\"/retained message for the topic.\n\n        Returns a tuple (result, mid), where result is MQTT_ERR_SUCCESS to\n        indicate success or MQTT_ERR_NO_CONN if the client is not currently\n        connected.  mid is the message ID for the publish request. The mid\n        value can be used to track the publish request by checking against the\n        mid argument in the on_publish() callback if it is defined.\n\n        A ValueError will be raised if topic is None, has zero length or is\n        invalid (contains a wildcard), if qos is not one of 0, 1 or 2, or if\n        the length of the payload is greater than 268435455 bytes.\"\"\"\n        if topic is None or len(topic) == 0:\n            raise ValueError('Invalid topic.')\n        if qos<0 or qos>2:\n            raise ValueError('Invalid QoS level.')\n        if isinstance(payload, str) or isinstance(payload, bytearray):\n            local_payload = payload\n        elif sys.version_info[0] < 3 and isinstance(payload, unicode):\n            local_payload = payload\n        elif isinstance(payload, int) or isinstance(payload, float):\n            local_payload = str(payload)\n        elif payload is None:\n            local_payload = None\n        else:\n            raise TypeError('payload must be a string, bytearray, int, float or None.')\n\n        if local_payload is not None and len(local_payload) > 268435455:\n            raise ValueError('Payload too large.')\n\n        if self._topic_wildcard_len_check(topic) != MQTT_ERR_SUCCESS:\n            raise ValueError('Publish topic cannot contain wildcards.')\n\n        local_mid = self._mid_generate()\n\n        if qos == 0:\n            rc = self._send_publish(local_mid, topic, local_payload, qos, retain, False)\n            return (rc, local_mid)\n        else:\n            message = MQTTMessage()\n            message.timestamp = time.time()\n\n            message.mid = local_mid\n            message.topic = topic\n            if local_payload is None or len(local_payload) == 0:\n                message.payload = None\n            else:\n                message.payload = local_payload\n\n            message.qos = qos\n            message.retain = retain\n            message.dup = False\n\n            self._out_message_mutex.acquire()                \n            self._out_messages.append(message)\n            if self._max_inflight_messages == 0 or self._inflight_messages < self._max_inflight_messages:\n                self._inflight_messages = self._inflight_messages+1\n                if qos == 1:\n                    message.state = mqtt_ms_wait_for_puback\n                elif qos == 2:\n                    message.state = mqtt_ms_wait_for_pubrec\n                self._out_message_mutex.release()\n                    \n                rc = self._send_publish(message.mid, message.topic, message.payload, message.qos, message.retain, message.dup)\n\n                # remove from inflight messages so it will be send after a connection is made\n                if rc is MQTT_ERR_NO_CONN:\n                    with self._out_message_mutex:\n                        self._inflight_messages -= 1\n                        message.state = mqtt_ms_publish\n                        \n                return (rc, local_mid)\n            else:\n                message.state = mqtt_ms_queued;\n                self._out_message_mutex.release()\n                return (MQTT_ERR_SUCCESS, local_mid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef username_pw_set(self, username, password=None):\n        self._username = username.encode('utf-8')\n        self._password = password", "response": "Set a username and optionally a password for broker authentication."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disconnect(self):\n        self._state_mutex.acquire()\n        self._state = mqtt_cs_disconnecting\n        self._state_mutex.release()\n\n        self._backoffCore.stopStableConnectionTimer()\n\n        if self._sock is None and self._ssl is None:\n            return MQTT_ERR_NO_CONN\n\n        return self._send_disconnect()", "response": "Disconnect a connected client from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubscribing the client to one or more topics.", "response": "def subscribe(self, topic, qos=0):\n        \"\"\"Subscribe the client to one or more topics.\n\n        This function may be called in three different ways:\n\n        Simple string and integer\n        -------------------------\n        e.g. subscribe(\"my/topic\", 2)\n\n        topic: A string specifying the subscription topic to subscribe to.\n        qos: The desired quality of service level for the subscription.\n             Defaults to 0.\n\n        String and integer tuple\n        ------------------------\n        e.g. subscribe((\"my/topic\", 1))\n\n        topic: A tuple of (topic, qos). Both topic and qos must be present in\n               the tuple.\n        qos: Not used.\n\n        List of string and integer tuples\n        ------------------------\n        e.g. subscribe([(\"my/topic\", 0), (\"another/topic\", 2)])\n\n        This allows multiple topic subscriptions in a single SUBSCRIPTION\n        command, which is more efficient than using multiple calls to\n        subscribe().\n\n        topic: A list of tuple of format (topic, qos). Both topic and qos must\n               be present in all of the tuples.\n        qos: Not used.\n\n        The function returns a tuple (result, mid), where result is\n        MQTT_ERR_SUCCESS to indicate success or (MQTT_ERR_NO_CONN, None) if the\n        client is not currently connected.  mid is the message ID for the\n        subscribe request. The mid value can be used to track the subscribe\n        request by checking against the mid argument in the on_subscribe()\n        callback if it is defined.\n\n        Raises a ValueError if qos is not 0, 1 or 2, or if topic is None or has\n        zero string length, or if topic is not a string, tuple or list.\n        \"\"\"\n        topic_qos_list = None\n        if isinstance(topic, str):\n            if qos<0 or qos>2:\n                raise ValueError('Invalid QoS level.')\n            if topic is None or len(topic) == 0:\n                raise ValueError('Invalid topic.')\n            topic_qos_list = [(topic.encode('utf-8'), qos)]\n        elif isinstance(topic, tuple):\n            if topic[1]<0 or topic[1]>2:\n                raise ValueError('Invalid QoS level.')\n            if topic[0] is None or len(topic[0]) == 0 or not isinstance(topic[0], str):\n                raise ValueError('Invalid topic.')\n            topic_qos_list = [(topic[0].encode('utf-8'), topic[1])]\n        elif isinstance(topic, list):\n            topic_qos_list = []\n            for t in topic:\n                if t[1]<0 or t[1]>2:\n                    raise ValueError('Invalid QoS level.')\n                if t[0] is None or len(t[0]) == 0 or not isinstance(t[0], str):\n                    raise ValueError('Invalid topic.')\n                topic_qos_list.append((t[0].encode('utf-8'), t[1]))\n\n        if topic_qos_list is None:\n            raise ValueError(\"No topic specified, or incorrect topic type.\")\n\n        if self._sock is None and self._ssl is None:\n            return (MQTT_ERR_NO_CONN, None)\n\n        return self._send_subscribe(False, topic_qos_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unsubscribe(self, topic):\n        topic_list = None\n        if topic is None:\n            raise ValueError('Invalid topic.')\n        if isinstance(topic, str):\n            if len(topic) == 0:\n                raise ValueError('Invalid topic.')\n            topic_list = [topic.encode('utf-8')]\n        elif isinstance(topic, list):\n            topic_list = []\n            for t in topic:\n                if len(t) == 0 or not isinstance(t, str):\n                    raise ValueError('Invalid topic.')\n                topic_list.append(t.encode('utf-8'))\n\n        if topic_list is None:\n            raise ValueError(\"No topic specified, or incorrect topic type.\")\n\n        if self._sock is None and self._ssl is None:\n            return (MQTT_ERR_NO_CONN, None)\n\n        return self._send_unsubscribe(False, topic_list)", "response": "Unsubscribe the client from one or more topics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loop_read(self, max_packets=1):\n        if self._sock is None and self._ssl is None:\n            return MQTT_ERR_NO_CONN\n\n        max_packets = len(self._out_messages) + len(self._in_messages)\n        if max_packets < 1:\n            max_packets = 1\n\n        for i in range(0, max_packets):\n            rc = self._packet_read()\n            if rc > 0:\n                return self._loop_rc_handle(rc)\n            elif rc == MQTT_ERR_AGAIN:\n                return MQTT_ERR_SUCCESS\n        return MQTT_ERR_SUCCESS", "response": "Process read network events."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess read network events.", "response": "def loop_write(self, max_packets=1):\n        \"\"\"Process read network events. Use in place of calling loop() if you\n        wish to handle your client reads as part of your own application.\n\n        Use socket() to obtain the client socket to call select() or equivalent\n        on.\n\n        Use want_write() to determine if there is data waiting to be written.\n\n        Do not use if you are using the threaded interface loop_start().\"\"\"\n\n        if self._sock is None and self._ssl is None:\n            return MQTT_ERR_NO_CONN\n\n        max_packets = len(self._out_packet) + 1\n        if max_packets < 1:\n            max_packets = 1\n\n        for i in range(0, max_packets):\n            rc = self._packet_write()\n            if rc > 0:\n                return self._loop_rc_handle(rc)\n            elif rc == MQTT_ERR_AGAIN:\n                return MQTT_ERR_SUCCESS\n        return MQTT_ERR_SUCCESS"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess miscellaneous network events.", "response": "def loop_misc(self):\n        \"\"\"Process miscellaneous network events. Use in place of calling loop() if you\n        wish to call select() or equivalent on.\n\n        Do not use if you are using the threaded interface loop_start().\"\"\"\n        if self._sock is None and self._ssl is None:\n            return MQTT_ERR_NO_CONN\n\n        now = time.time()\n        self._check_keepalive()\n        if self._last_retry_check+1 < now:\n            # Only check once a second at most\n            self._message_retry_check()\n            self._last_retry_check = now\n\n        if self._ping_t > 0 and now - self._ping_t >= self._keepalive:\n            # client->ping_t != 0 means we are waiting for a pingresp.\n            # This hasn't happened in the keepalive time so we should disconnect.\n            if self._ssl:\n                self._ssl.close()\n                self._ssl = None\n            elif self._sock:\n                self._sock.close()\n                self._sock = None\n\n            self._callback_mutex.acquire()\n            if self._state == mqtt_cs_disconnecting:\n                rc = MQTT_ERR_SUCCESS\n            else:\n                rc = 1\n            if self.on_disconnect:\n                self._in_callback = True\n                self.on_disconnect(self, self._userdata, rc)\n                self._in_callback = False\n            self._callback_mutex.release()\n            return MQTT_ERR_CONN_LOST\n\n        return MQTT_ERR_SUCCESS"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a Will to be sent by the broker in case the client disconnects unexpectedly.", "response": "def will_set(self, topic, payload=None, qos=0, retain=False):\n        \"\"\"Set a Will to be sent by the broker in case the client disconnects unexpectedly.\n\n        This must be called before connect() to have any effect.\n\n        topic: The topic that the will message should be published on.\n        payload: The message to send as a will. If not given, or set to None a\n        zero length message will be used as the will. Passing an int or float\n        will result in the payload being converted to a string representing\n        that number. If you wish to send a true int/float, use struct.pack() to\n        create the payload you require.\n        qos: The quality of service level to use for the will.\n        retain: If set to true, the will message will be set as the \"last known\n        good\"/retained message for the topic.\n\n        Raises a ValueError if qos is not 0, 1 or 2, or if topic is None or has\n        zero string length.\n        \"\"\"\n        if topic is None or len(topic) == 0:\n            raise ValueError('Invalid topic.')\n        if qos<0 or qos>2:\n            raise ValueError('Invalid QoS level.')\n        if isinstance(payload, str):\n            self._will_payload = payload.encode('utf-8')\n        elif isinstance(payload, bytearray):\n            self._will_payload = payload\n        elif isinstance(payload, int) or isinstance(payload, float):\n            self._will_payload = str(payload)\n        elif payload is None:\n            self._will_payload = None\n        else:\n            raise TypeError('payload must be a string, bytearray, int, float or None.')\n\n        self._will = True\n        self._will_topic = topic.encode('utf-8')\n        self._will_qos = qos\n        self._will_retain = retain"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef will_clear(self):\n        self._will = False\n        self._will_topic = \"\"\n        self._will_payload = None\n        self._will_qos = 0\n        self._will_retain = False", "response": "Removes a will that was previously configured with will_set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef socket(self):\n        if self._ssl:\n            if self._useSecuredWebsocket:\n                return self._ssl.getSSLSocket()\n            else:\n                return self._ssl\n        else:\n            return self._sock", "response": "Return the socket or ssl object for this client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loop_forever(self, timeout=1.0, max_packets=1, retry_first_connection=False):\n\n        run = True\n\n        while run:\n            if self._state == mqtt_cs_connect_async:\n                try:\n                    self.reconnect()\n                except socket.error:\n                    if not retry_first_connection:\n                        raise\n                    self._easy_log(MQTT_LOG_DEBUG, \"Connection failed, retrying\")\n                    self._backoffCore.backOff()\n                    # time.sleep(1)\n            else:\n                break\n\n        while run:\n            rc = MQTT_ERR_SUCCESS\n            while rc == MQTT_ERR_SUCCESS:\n                rc = self.loop(timeout, max_packets)\n                # We don't need to worry about locking here, because we've\n                # either called loop_forever() when in single threaded mode, or\n                # in multi threaded mode when loop_stop() has been called and\n                # so no other threads can access _current_out_packet,\n                # _out_packet or _messages.\n                if (self._thread_terminate is True\n                        and self._current_out_packet is None\n                        and len(self._out_packet) == 0\n                        and len(self._out_messages) == 0):\n\n                    rc = 1\n                    run = False\n\n            self._state_mutex.acquire()\n            if self._state == mqtt_cs_disconnecting or run is False or self._thread_terminate is True:\n                run = False\n                self._state_mutex.release()\n            else:\n                self._state_mutex.release()\n                self._backoffCore.backOff()\n                # time.sleep(1)\n\n                self._state_mutex.acquire()\n                if self._state == mqtt_cs_disconnecting or run is False or self._thread_terminate is True:\n                    run = False\n                    self._state_mutex.release()\n                else:\n                    self._state_mutex.release()\n                    try:\n                        self.reconnect()\n                    except socket.error as err:\n                        pass\n\n        return rc", "response": "This function will loop forever until the connection is established or a connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loop_stop(self, force=False):\n        if self._thread is None:\n            return MQTT_ERR_INVAL\n\n        self._thread_terminate = True\n        self._thread.join()\n        self._thread = None", "response": "This is part of the threaded client interface. This is part of the threaded client interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a message callback for a specific topic.", "response": "def message_callback_add(self, sub, callback):\n        \"\"\"Register a message callback for a specific topic.\n        Messages that match 'sub' will be passed to 'callback'. Any\n        non-matching messages will be passed to the default on_message\n        callback.\n        \n        Call multiple times with different 'sub' to define multiple topic\n        specific callbacks.\n        \n        Topic specific callbacks may be removed with\n        message_callback_remove().\"\"\"\n        if callback is None or sub is None:\n            raise ValueError(\"sub and callback must both be defined.\")\n\n        self._callback_mutex.acquire()\n        for i in range(0, len(self.on_message_filtered)):\n            if self.on_message_filtered[i][0] == sub:\n                self.on_message_filtered[i] = (sub, callback)\n                self._callback_mutex.release()\n                return\n\n        self.on_message_filtered.append((sub, callback))\n        self._callback_mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a message callback previously registered with message_callback_add ().", "response": "def message_callback_remove(self, sub):\n        \"\"\"Remove a message callback previously registered with\n        message_callback_add().\"\"\"\n        if sub is None:\n            raise ValueError(\"sub must defined.\")\n\n        self._callback_mutex.acquire()\n        for i in range(0, len(self.on_message_filtered)):\n            if self.on_message_filtered[i][0] == sub:\n                self.on_message_filtered.pop(i)\n                self._callback_mutex.release()\n                return\n        self._callback_mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createproject():\n    os.chdir(build_dir)\n    if windows_build:\n        command = 'cmake -A {} -DPYTHON_EXECUTABLE:FILEPATH=\"{}\" ../..'.format(\"win32\" if bitness==32 else \"x64\", sys.executable)\n        os.system(command)\n        if bitness==64:\n            for line in fileinput.input(\"_rhino3dm.vcxproj\", inplace=1):\n                print(line.replace(\"WIN32;\", \"WIN64;\"))\n            for line in fileinput.input(\"opennurbs_static.vcxproj\", inplace=1):\n                print(line.replace(\"WIN32;\", \"WIN64;\"))\n        #os.system(\"cmake --build . --config Release --target _rhino3dm\")\n    else:\n        rv = os.system(\"cmake -DPYTHON_EXECUTABLE:FILEPATH={} ../..\".format(sys.executable))\n        if int(rv) > 0: sys.exit(1)", "response": "compile for the platform we are running on"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new entry to the internal list of the internal list.", "response": "def add(\n        self,\n        method=None,  # method or ``Response``\n        url=None,\n        body=\"\",\n        adding_headers=None,\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        A basic request:\n\n        >>> responses.add(responses.GET, 'http://example.com')\n\n        You can also directly pass an object which implements the\n        ``BaseResponse`` interface:\n\n        >>> responses.add(Response(...))\n\n        A JSON payload:\n\n        >>> responses.add(\n        >>>     method='GET',\n        >>>     url='http://example.com',\n        >>>     json={'foo': 'bar'},\n        >>> )\n\n        Custom headers:\n\n        >>> responses.add(\n        >>>     method='GET',\n        >>>     url='http://example.com',\n        >>>     headers={'X-Header': 'foo'},\n        >>> )\n\n\n        Strict query string matching:\n\n        >>> responses.add(\n        >>>     method='GET',\n        >>>     url='http://example.com?foo=bar',\n        >>>     match_querystring=True\n        >>> )\n        \"\"\"\n        if isinstance(method, BaseResponse):\n            self._matches.append(method)\n            return\n\n        if adding_headers is not None:\n            kwargs.setdefault(\"headers\", adding_headers)\n\n        self._matches.append(Response(method=method, url=url, body=body, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_passthru(self, prefix):\n        if _has_unicode(prefix):\n            prefix = _clean_unicode(prefix)\n        self.passthru_prefixes += (prefix,)", "response": "Add a URL prefix to passthru any non - matching mock requests to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, method_or_response=None, url=None):\n        if isinstance(method_or_response, BaseResponse):\n            response = method_or_response\n        else:\n            response = BaseResponse(method=method_or_response, url=url)\n\n        while response in self._matches:\n            self._matches.remove(response)", "response": "Removes a response previously added using add or by a BaseResponse object inheriting it s method and url."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace a response previously added using add.", "response": "def replace(self, method_or_response=None, url=None, body=\"\", *args, **kwargs):\n        \"\"\"\n        Replaces a response previously added using ``add()``. The signature\n        is identical to ``add()``. The response is identified using ``method``\n        and ``url``, and the first matching response is replaced.\n\n        >>> responses.add(responses.GET, 'http://example.org', json={'data': 1})\n        >>> responses.replace(responses.GET, 'http://example.org', json={'data': 2})\n        \"\"\"\n        if isinstance(method_or_response, BaseResponse):\n            response = method_or_response\n        else:\n            response = Response(method=method_or_response, url=url, body=body, **kwargs)\n\n        index = self._matches.index(response)\n        self._matches[index] = response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the given XML input and return a dictionary.", "response": "def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n          namespace_separator=':', disable_entities=True, **kwargs):\n    \"\"\"Parse the given XML input and convert it into a dictionary.\n\n    `xml_input` can either be a `string`, a file-like object, or a generator of strings.\n\n    If `xml_attribs` is `True`, element attributes are put in the dictionary\n    among regular child elements, using `@` as a prefix to avoid collisions. If\n    set to `False`, they are just ignored.\n\n    Simple example::\n\n        >>> import xmltodict\n        >>> doc = xmltodict.parse(\\\"\\\"\\\"\n        ... <a prop=\"x\">\n        ...   <b>1</b>\n        ...   <b>2</b>\n        ... </a>\n        ... \\\"\\\"\\\")\n        >>> doc['a']['@prop']\n        u'x'\n        >>> doc['a']['b']\n        [u'1', u'2']\n\n    If `item_depth` is `0`, the function returns a dictionary for the root\n    element (default behavior). Otherwise, it calls `item_callback` every time\n    an item at the specified depth is found and returns `None` in the end\n    (streaming mode).\n\n    The callback function receives two parameters: the `path` from the document\n    root to the item (name-attribs pairs), and the `item` (dict). If the\n    callback's return value is false-ish, parsing will be stopped with the\n    :class:`ParsingInterrupted` exception.\n\n    Streaming example::\n\n        >>> def handle(path, item):\n        ...     print('path:%s item:%s' % (path, item))\n        ...     return True\n        ...\n        >>> xmltodict.parse(\\\"\\\"\\\"\n        ... <a prop=\"x\">\n        ...   <b>1</b>\n        ...   <b>2</b>\n        ... </a>\\\"\\\"\\\", item_depth=2, item_callback=handle)\n        path:[(u'a', {u'prop': u'x'}), (u'b', None)] item:1\n        path:[(u'a', {u'prop': u'x'}), (u'b', None)] item:2\n\n    The optional argument `postprocessor` is a function that takes `path`,\n    `key` and `value` as positional arguments and returns a new `(key, value)`\n    pair where both `key` and `value` may have changed. Usage example::\n\n        >>> def postprocessor(path, key, value):\n        ...     try:\n        ...         return key + ':int', int(value)\n        ...     except (ValueError, TypeError):\n        ...         return key, value\n        >>> xmltodict.parse('<a><b>1</b><b>2</b><b>x</b></a>',\n        ...                 postprocessor=postprocessor)\n        OrderedDict([(u'a', OrderedDict([(u'b:int', [1, 2]), (u'b', u'x')]))])\n\n    You can pass an alternate version of `expat` (such as `defusedexpat`) by\n    using the `expat` parameter. E.g:\n\n        >>> import defusedexpat\n        >>> xmltodict.parse('<a>hello</a>', expat=defusedexpat.pyexpat)\n        OrderedDict([(u'a', u'hello')])\n\n    You can use the force_list argument to force lists to be created even\n    when there is only a single child of a given level of hierarchy. The\n    force_list argument is a tuple of keys. If the key for a given level\n    of hierarchy is in the force_list argument, that level of hierarchy\n    will have a list as a child (even if there is only one sub-element).\n    The index_keys operation takes precendence over this. This is applied\n    after any user-supplied postprocessor has already run.\n\n        For example, given this input:\n        <servers>\n          <server>\n            <name>host1</name>\n            <os>Linux</os>\n            <interfaces>\n              <interface>\n                <name>em0</name>\n                <ip_address>10.0.0.1</ip_address>\n              </interface>\n            </interfaces>\n          </server>\n        </servers>\n\n        If called with force_list=('interface',), it will produce\n        this dictionary:\n        {'servers':\n          {'server':\n            {'name': 'host1',\n             'os': 'Linux'},\n             'interfaces':\n              {'interface':\n                [ {'name': 'em0', 'ip_address': '10.0.0.1' } ] } } }\n\n        `force_list` can also be a callable that receives `path`, `key` and\n        `value`. This is helpful in cases where the logic that decides whether\n        a list should be forced is more complex.\n    \"\"\"\n    handler = _DictSAXHandler(namespace_separator=namespace_separator,\n                              **kwargs)\n    if isinstance(xml_input, _unicode):\n        if not encoding:\n            encoding = 'utf-8'\n        xml_input = xml_input.encode(encoding)\n    if not process_namespaces:\n        namespace_separator = None\n    parser = expat.ParserCreate(\n        encoding,\n        namespace_separator\n    )\n    try:\n        parser.ordered_attributes = True\n    except AttributeError:\n        # Jython's expat does not support ordered_attributes\n        pass\n    parser.StartNamespaceDeclHandler = handler.startNamespaceDecl\n    parser.StartElementHandler = handler.startElement\n    parser.EndElementHandler = handler.endElement\n    parser.CharacterDataHandler = handler.characters\n    parser.buffer_text = True\n    if disable_entities:\n        try:\n            # Attempt to disable DTD in Jython's expat parser (Xerces-J).\n            feature = \"http://apache.org/xml/features/disallow-doctype-decl\"\n            parser._reader.setFeature(feature, True)\n        except AttributeError:\n            # For CPython / expat parser.\n            # Anything not handled ends up here and entities aren't expanded.\n            parser.DefaultHandler = lambda x: None\n            # Expects an integer return; zero means failure -> expat.ExpatError.\n            parser.ExternalEntityRefHandler = lambda *x: 1\n    if hasattr(xml_input, 'read'):\n        parser.ParseFile(xml_input)\n    elif isgenerator(xml_input):\n        for chunk in xml_input:\n            parser.Parse(chunk,False)\n        parser.Parse(b'',True)\n    else:\n        parser.Parse(xml_input, True)\n    return handler.item"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nemitting an XML document for the given `input_dict` (reverse of `parse`). The resulting XML document is returned as a string, but if `output` (a file-like object) is specified, it is written there instead. Dictionary keys prefixed with `attr_prefix` (default=`'@'`) are interpreted as XML node attributes, whereas keys equal to `cdata_key` (default=`'#text'`) are treated as character data. The `pretty` parameter (default=`False`) enables pretty-printing. In this mode, lines are terminated with `'\\n'` and indented with `'\\t'`, but this can be customized with the `newl` and `indent` parameters.", "response": "def unparse(input_dict, output=None, encoding='utf-8', full_document=True,\n            short_empty_elements=False,\n            **kwargs):\n    \"\"\"Emit an XML document for the given `input_dict` (reverse of `parse`).\n\n    The resulting XML document is returned as a string, but if `output` (a\n    file-like object) is specified, it is written there instead.\n\n    Dictionary keys prefixed with `attr_prefix` (default=`'@'`) are interpreted\n    as XML node attributes, whereas keys equal to `cdata_key`\n    (default=`'#text'`) are treated as character data.\n\n    The `pretty` parameter (default=`False`) enables pretty-printing. In this\n    mode, lines are terminated with `'\\n'` and indented with `'\\t'`, but this\n    can be customized with the `newl` and `indent` parameters.\n\n    \"\"\"\n    if full_document and len(input_dict) != 1:\n        raise ValueError('Document must have exactly one root.')\n    must_return = False\n    if output is None:\n        output = StringIO()\n        must_return = True\n    if short_empty_elements:\n        content_handler = XMLGenerator(output, encoding, True)\n    else:\n        content_handler = XMLGenerator(output, encoding)\n    if full_document:\n        content_handler.startDocument()\n    for key, value in input_dict.items():\n        _emit(key, value, content_handler, full_document=full_document,\n              **kwargs)\n    if full_document:\n        content_handler.endDocument()\n    if must_return:\n        value = output.getvalue()\n        try:  # pragma no cover\n            value = value.decode(encoding)\n        except AttributeError:  # pragma no cover\n            pass\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunzip filename to a temporary directory, set to the cwd. The unzipped target is cleaned up after.", "response": "def archive_context(filename):\n    \"\"\"\n    Unzip filename to a temporary directory, set to the cwd.\n\n    The unzipped target is cleaned up after.\n    \"\"\"\n    tmpdir = tempfile.mkdtemp()\n    log.warn('Extracting in %s', tmpdir)\n    old_wd = os.getcwd()\n    try:\n        os.chdir(tmpdir)\n        try:\n            with ContextualZipFile(filename) as archive:\n                archive.extractall()\n        except zipfile.BadZipfile as err:\n            if not err.args:\n                err.args = ('', )\n            err.args = err.args + (\n                MEANINGFUL_INVALID_ZIP_ERR_MSG.format(filename),\n            )\n            raise\n\n        # going in the directory\n        subdir = os.path.join(tmpdir, os.listdir(tmpdir)[0])\n        os.chdir(subdir)\n        log.warn('Now working in %s', subdir)\n        yield\n\n    finally:\n        os.chdir(old_wd)\n        shutil.rmtree(tmpdir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads Setuptools and build the setuptools archive.", "response": "def _do_download(version, download_base, to_dir, download_delay):\n    \"\"\"Download Setuptools.\"\"\"\n    py_desig = 'py{sys.version_info[0]}.{sys.version_info[1]}'.format(sys=sys)\n    tp = 'setuptools-{version}-{py_desig}.egg'\n    egg = os.path.join(to_dir, tp.format(**locals()))\n    if not os.path.exists(egg):\n        archive = download_setuptools(version, download_base,\n            to_dir, download_delay)\n        _build_egg(egg, archive, to_dir)\n    sys.path.insert(0, egg)\n\n    # Remove previously-imported pkg_resources if present (see\n    # https://bitbucket.org/pypa/setuptools/pull-request/7/ for details).\n    if 'pkg_resources' in sys.modules:\n        _unload_pkg_resources()\n\n    import setuptools\n    setuptools.bootstrap_install_from = egg"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a setuptools version of the current version.", "response": "def use_setuptools(\n        version=DEFAULT_VERSION, download_base=DEFAULT_URL,\n        to_dir=DEFAULT_SAVE_DIR, download_delay=15):\n    \"\"\"\n    Ensure that a setuptools version is installed.\n\n    Return None. Raise SystemExit if the requested version\n    or later cannot be installed.\n    \"\"\"\n    to_dir = os.path.abspath(to_dir)\n\n    # prior to importing, capture the module state for\n    # representative modules.\n    rep_modules = 'pkg_resources', 'setuptools'\n    imported = set(sys.modules).intersection(rep_modules)\n\n    try:\n        import pkg_resources\n        pkg_resources.require(\"setuptools>=\" + version)\n        # a suitable version is already installed\n        return\n    except ImportError:\n        # pkg_resources not available; setuptools is not installed; download\n        pass\n    except pkg_resources.DistributionNotFound:\n        # no version of setuptools was found; allow download\n        pass\n    except pkg_resources.VersionConflict as VC_err:\n        if imported:\n            _conflict_bail(VC_err, version)\n\n        # otherwise, unload pkg_resources to allow the downloaded version to\n        #  take precedence.\n        del pkg_resources\n        _unload_pkg_resources()\n\n    return _do_download(version, download_base, to_dir, download_delay)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbail out if there is a conflict with the setuptools.", "response": "def _conflict_bail(VC_err, version):\n    \"\"\"\n    Setuptools was imported prior to invocation, so it is\n    unsafe to unload it. Bail out.\n    \"\"\"\n    conflict_tmpl = textwrap.dedent(\"\"\"\n        The required version of setuptools (>={version}) is not available,\n        and can't be installed while this script is running. Please\n        install a more recent version first, using\n        'easy_install -U setuptools'.\n\n        (Currently using {VC_err.args[0]!r})\n        \"\"\")\n    msg = conflict_tmpl.format(**locals())\n    sys.stderr.write(msg)\n    sys.exit(2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses Python to download the file without connection authentication.", "response": "def download_file_insecure(url, target):\n    \"\"\"Use Python to download the file, without connection authentication.\"\"\"\n    src = urlopen(url)\n    try:\n        # Read all the data in one block.\n        data = src.read()\n    finally:\n        src.close()\n\n    # Write all the data in one block to avoid creating a partial file.\n    with open(target, \"wb\") as dst:\n        dst.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _download_args(options):\n    return dict(\n        version=options.version,\n        download_base=options.download_base,\n        downloader_factory=options.downloader_factory,\n        to_dir=options.to_dir,\n    )", "response": "Return args for download_setuptools function from cmdline args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall or upgrade setuptools and EasyInstall.", "response": "def main():\n    \"\"\"Install or upgrade setuptools and EasyInstall.\"\"\"\n    options = _parse_args()\n    archive = download_setuptools(**_download_args(options))\n    return _install(archive, _build_install_args(options))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef roundClosestValid(val, res, decimals=None):\n        if decimals is None and \".\" in str(res):\n            decimals = len(str(res).split('.')[1])\n\n        return round(round(val / res) * res, decimals)", "response": "round to closest resolution"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestablishes connection to the TWS and IBGW.", "response": "def connect(self, clientId=0, host=\"localhost\", port=4001):\n        \"\"\" Establish connection to TWS/IBGW \"\"\"\n        self.clientId = clientId\n        self.host = host\n        self.port = port\n        self.ibConn = Connection.create(\n            host=self.host,\n            port=int(self.port),\n            clientId=self.clientId\n        )\n\n        # Assign server messages handling function.\n        self.ibConn.registerAll(self.handleServerEvents)\n\n        # connect\n        self.log.info(\"[CONNECTING TO IB]\")\n        self.ibConn.connect()\n\n        # get server time\n        self.getServerTime()\n\n        # subscribe to position and account changes\n        self.subscribeAccount = False\n        self.requestAccountUpdates(subscribe=True)\n\n        self.subscribePositions = False\n        self.requestPositionUpdates(subscribe=True)\n\n        # load working orders\n        self.requestOpenOrders()\n\n        # force refresh of orderId upon connect\n        self.handleNextValidId(self.orderId)\n\n        self._disconnected_by_user = False\n        time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse for when callback receives a contract that isn t found in local database", "response": "def registerContract(self, contract):\n        \"\"\" used for when callback receives a contract\n        that isn't found in local database \"\"\"\n\n        if contract.m_exchange == \"\":\n            return\n\n        \"\"\"\n        if contract not in self.contracts.values():\n            contract_tuple = self.contract_to_tuple(contract)\n            self.createContract(contract_tuple)\n\n        if self.tickerId(contract) not in self.contracts.keys():\n            contract_tuple = self.contract_to_tuple(contract)\n            self.createContract(contract_tuple)\n        \"\"\"\n\n        if self.getConId(contract) == 0:\n            contract_tuple = self.contract_to_tuple(contract)\n            self.createContract(contract_tuple)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch the message to the right handler", "response": "def handleServerEvents(self, msg):\n        \"\"\" dispatch msg to the right handler \"\"\"\n\n        self.log.debug('MSG %s', msg)\n        self.handleConnectionState(msg)\n\n        if msg.typeName == \"error\":\n            self.handleErrorEvents(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_CURRENT_TIME\"]:\n            if self.time < msg.time:\n                self.time = msg.time\n\n        elif (msg.typeName == dataTypes[\"MSG_TYPE_MKT_DEPTH\"] or\n                msg.typeName == dataTypes[\"MSG_TYPE_MKT_DEPTH_L2\"]):\n            self.handleMarketDepth(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_TICK_STRING\"]:\n            self.handleTickString(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_TICK_PRICE\"]:\n            self.handleTickPrice(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_TICK_GENERIC\"]:\n            self.handleTickGeneric(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_TICK_SIZE\"]:\n            self.handleTickSize(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_TICK_OPTION\"]:\n            self.handleTickOptionComputation(msg)\n\n        elif (msg.typeName == dataTypes[\"MSG_TYPE_OPEN_ORDER\"] or\n                msg.typeName == dataTypes[\"MSG_TYPE_OPEN_ORDER_END\"] or\n                msg.typeName == dataTypes[\"MSG_TYPE_ORDER_STATUS\"]):\n            self.handleOrders(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_HISTORICAL_DATA\"]:\n            self.handleHistoricalData(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_ACCOUNT_UPDATES\"]:\n            self.handleAccount(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_PORTFOLIO_UPDATES\"]:\n            self.handlePortfolio(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_POSITION\"]:\n            self.handlePosition(msg)\n\n        elif msg.typeName == dataTypes[\"MSG_TYPE_NEXT_ORDER_ID\"]:\n            self.handleNextValidId(msg.orderId)\n\n        elif msg.typeName == dataTypes[\"MSG_CONNECTION_CLOSED\"]:\n            self.handleConnectionClosed(msg)\n\n        # elif msg.typeName == dataTypes[\"MSG_TYPE_MANAGED_ACCOUNTS\"]:\n        #     self.accountCode = msg.accountsList\n\n        elif msg.typeName == dataTypes[\"MSG_COMMISSION_REPORT\"]:\n            self.commission = msg.commissionReport.m_commission\n\n        elif msg.typeName == dataTypes[\"MSG_CONTRACT_DETAILS\"]:\n            self.handleContractDetails(msg, end=False)\n\n        elif msg.typeName == dataTypes[\"MSG_CONTRACT_DETAILS_END\"]:\n            self.handleContractDetails(msg, end=True)\n\n        elif msg.typeName == dataTypes[\"MSG_TICK_SNAPSHOT_END\"]:\n            self.ibCallback(caller=\"handleTickSnapshotEnd\", msg=msg)\n\n        else:\n            # log handler msg\n            self.log_msg(\"server\", msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling the connection state of the current user.", "response": "def handleConnectionState(self, msg):\n        \"\"\":Return: True if IBPy message `msg` indicates the connection is unavailable for any reason, else False.\"\"\"\n        self.connected = not (msg.typeName == \"error\" and\n                              msg.errorCode in dataTypes[\"DISCONNECT_ERROR_CODES\"])\n\n        if self.connected:\n            self.connection_tracking[\"errors\"] = []\n            self.connection_tracking[\"disconnected\"] = False\n\n            if msg.typeName == dataTypes[\"MSG_CURRENT_TIME\"] and not self.connection_tracking[\"connected\"]:\n                self.log.info(\"[CONNECTION TO IB ESTABLISHED]\")\n                self.connection_tracking[\"connected\"] = True\n                self.ibCallback(caller=\"handleConnectionOpened\", msg=\"<connectionOpened>\")\n        else:\n            self.connection_tracking[\"connected\"] = False\n\n            if not self.connection_tracking[\"disconnected\"]:\n                self.connection_tracking[\"disconnected\"] = True\n                self.log.info(\"[CONNECTION TO IB LOST]\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handleContractDetails(self, msg, end=False):\n\n        if end:\n            # mark as downloaded\n            self._contract_details[msg.reqId]['downloaded'] = True\n\n            # move details from temp to permanent collector\n            self.contract_details[msg.reqId] = self._contract_details[msg.reqId]\n            del self._contract_details[msg.reqId]\n\n            # adjust fields if multi contract\n            if len(self.contract_details[msg.reqId][\"contracts\"]) > 1:\n                self.contract_details[msg.reqId][\"m_contractMonth\"] = \"\"\n                # m_summary should hold closest expiration\n                expirations = self.getExpirations(self.contracts[msg.reqId], expired=0)\n                contract = self.contract_details[msg.reqId][\"contracts\"][-len(expirations)]\n                self.contract_details[msg.reqId][\"m_summary\"] = vars(contract)\n            else:\n                self.contract_details[msg.reqId][\"m_summary\"] = vars(\n                    self.contract_details[msg.reqId][\"contracts\"][0])\n\n            # update local db with correct contractString\n            for tid in self.contract_details:\n                oldString = self.tickerIds[tid]\n                newString = self.contractString(self.contract_details[tid][\"contracts\"][0])\n\n                if len(self.contract_details[msg.reqId][\"contracts\"]) > 1:\n                    self.tickerIds[tid] = newString\n                    if newString != oldString:\n                        if oldString in self._portfolios:\n                            self._portfolios[newString] = self._portfolios[oldString]\n                        if oldString in self._positions:\n                            self._positions[newString] = self._positions[oldString]\n\n            # fire callback\n            self.ibCallback(caller=\"handleContractDetailsEnd\", msg=msg)\n\n            # exit\n            return\n\n        # continue...\n\n        # collect data on all contract details\n        # (including those with multiple expiry/strike/sides)\n        details  = vars(msg.contractDetails)\n        contract = details[\"m_summary\"]\n\n        if msg.reqId in self._contract_details:\n            details['contracts'] = self._contract_details[msg.reqId][\"contracts\"]\n        else:\n            details['contracts'] = []\n\n        details['contracts'].append(contract)\n        details['downloaded'] = False\n        self._contract_details[msg.reqId] = details\n\n        # add details to local symbol list\n        if contract.m_localSymbol not in self.localSymbolExpiry:\n            self.localSymbolExpiry[contract.m_localSymbol] = details[\"m_contractMonth\"]\n\n        # add contract's multiple expiry/strike/sides to class collectors\n        contractString = self.contractString(contract)\n        tickerId = self.tickerId(contractString)\n        self.contracts[tickerId] = contract\n\n        # continue if this is a \"multi\" contract\n        if tickerId == msg.reqId:\n            self._contract_details[msg.reqId][\"m_summary\"] = vars(contract)\n        else:\n            # print(\"+++\", tickerId, contractString)\n            self.contract_details[tickerId] = details.copy()\n            self.contract_details[tickerId][\"m_summary\"] = vars(contract)\n            self.contract_details[tickerId][\"contracts\"] = [contract]\n\n        # fire callback\n        self.ibCallback(caller=\"handleContractDetails\", msg=msg)", "response": "handles contractDetails and contractDetailsEnd"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling account info update", "response": "def handleAccount(self, msg):\n        \"\"\"\n        handle account info update\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/updateaccountvalue.htm\n        \"\"\"\n\n        # parse value\n        try:\n            msg.value = float(msg.value)\n        except Exception:\n            msg.value = msg.value\n            if msg.value in ['true', 'false']:\n                msg.value = (msg.value == 'true')\n\n        try:\n            # log handler msg\n            self.log_msg(\"account\", msg)\n\n            # new account?\n            if msg.accountName not in self._accounts.keys():\n                self._accounts[msg.accountName] = {}\n\n            # set value\n            self._accounts[msg.accountName][msg.key] = msg.value\n\n            # fire callback\n            self.ibCallback(caller=\"handleAccount\", msg=msg)\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling open and status messages", "response": "def handleOrders(self, msg):\n        \"\"\" handle order open & status \"\"\"\n        \"\"\"\n        It is possible that orderStatus() may return duplicate messages.\n        It is essential that you filter the message accordingly.\n        \"\"\"\n\n        # log handler msg\n        self.log_msg(\"order\", msg)\n\n        # get server time\n        self.getServerTime()\n        time.sleep(0.001)\n\n        # we need to handle mutiple events for the same order status\n        duplicateMessage = False\n\n        # open order\n        if msg.typeName == dataTypes[\"MSG_TYPE_OPEN_ORDER\"]:\n            # contract identifier\n            contractString = self.contractString(msg.contract)\n\n            order_account = \"\"\n            if msg.orderId in self.orders and self.orders[msg.orderId][\"status\"] == \"SENT\":\n                order_account = self.orders[msg.orderId][\"account\"]\n                try:\n                    del self.orders[msg.orderId]\n                except Exception:\n                    pass\n\n            if msg.orderId in self.orders:\n                duplicateMessage = True\n            else:\n                self.orders[msg.orderId] = {\n                    \"id\":       msg.orderId,\n                    \"symbol\":   contractString,\n                    \"contract\": msg.contract,\n                    \"order\":    msg.order,\n                    \"status\":   \"OPENED\",\n                    \"reason\":   None,\n                    \"avgFillPrice\": 0.,\n                    \"parentId\": 0,\n                    \"time\": datetime.fromtimestamp(int(self.time)),\n                    \"account\": order_account\n                }\n                self._assgin_order_to_account(self.orders[msg.orderId])\n\n        # order status\n        elif msg.typeName == dataTypes[\"MSG_TYPE_ORDER_STATUS\"]:\n            if msg.orderId in self.orders and self.orders[msg.orderId]['status'] == msg.status.upper():\n                duplicateMessage = True\n            else:\n                # remove cancelled orphan orders\n                # if \"CANCELLED\" in msg.status.upper() and msg.parentId not in self.orders.keys():\n                #     try: del self.orders[msg.orderId]\n                #     except Exception: pass\n                # # otherwise, update order status\n                # else:\n                self.orders[msg.orderId]['status']       = msg.status.upper()\n                self.orders[msg.orderId]['reason']       = msg.whyHeld\n                self.orders[msg.orderId]['avgFillPrice'] = float(msg.avgFillPrice)\n                self.orders[msg.orderId]['parentId']     = int(msg.parentId)\n                self.orders[msg.orderId]['time']         = datetime.fromtimestamp(int(self.time))\n\n            # remove from orders?\n            # if msg.status.upper() == 'CANCELLED':\n            #     del self.orders[msg.orderId]\n\n        # fire callback\n        if duplicateMessage is False:\n            # group orders by symbol\n            self.symbol_orders = self.group_orders(\"symbol\")\n            self.ibCallback(caller=\"handleOrders\", msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the market depth update.", "response": "def handleMarketDepth(self, msg):\n        \"\"\"\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/updatemktdepth.htm\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/updatemktdepthl2.htm\n        \"\"\"\n\n        # make sure symbol exists\n        if msg.tickerId not in self.marketDepthData.keys():\n            self.marketDepthData[msg.tickerId] = self.marketDepthData[0].copy()\n\n        # bid\n        if msg.side == 1:\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"bid\"] = msg.price\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"bidsize\"] = msg.size\n\n        # ask\n        elif msg.side == 0:\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"ask\"] = msg.price\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"asksize\"] = msg.size\n\n        \"\"\"\n        # bid/ask spread / vol diff\n        self.marketDepthData[msg.tickerId].loc[msg.position, \"spread\"] = \\\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"ask\"]-\\\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"bid\"]\n\n        self.marketDepthData[msg.tickerId].loc[msg.position, \"spreadsize\"] = \\\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"asksize\"]-\\\n            self.marketDepthData[msg.tickerId].loc[msg.position, \"bidsize\"]\n        \"\"\"\n\n        self.ibCallback(caller=\"handleMarketDepth\", msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling tick generic message", "response": "def handleTickGeneric(self, msg):\n        \"\"\"\n        holds latest tick bid/ask/last price\n        \"\"\"\n\n        df2use = self.marketData\n        if self.contracts[msg.tickerId].m_secType in (\"OPT\", \"FOP\"):\n            df2use = self.optionsData\n\n        # create tick holder for ticker\n        if msg.tickerId not in df2use.keys():\n            df2use[msg.tickerId] = df2use[0].copy()\n\n        if msg.tickType == dataTypes[\"FIELD_OPTION_IMPLIED_VOL\"]:\n            df2use[msg.tickerId]['iv'] = round(float(msg.value), 2)\n\n        # elif msg.tickType == dataTypes[\"FIELD_OPTION_HISTORICAL_VOL\"]:\n        #     df2use[msg.tickerId]['historical_iv'] = round(float(msg.value), 2)\n\n        # fire callback\n        self.ibCallback(caller=\"handleTickGeneric\", msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhold latest tick bid/ask/last price", "response": "def handleTickPrice(self, msg):\n        \"\"\"\n        holds latest tick bid/ask/last price\n        \"\"\"\n        # self.log.debug(\"[TICK PRICE]: %s - %s\", dataTypes[\"PRICE_TICKS\"][msg.field], msg)\n        # return\n\n        if msg.price < 0:\n            return\n\n        df2use = self.marketData\n        canAutoExecute = msg.canAutoExecute == 1\n        if self.contracts[msg.tickerId].m_secType in (\"OPT\", \"FOP\"):\n            df2use = self.optionsData\n            canAutoExecute = True\n\n        # create tick holder for ticker\n        if msg.tickerId not in df2use.keys():\n            df2use[msg.tickerId] = df2use[0].copy()\n\n        # bid price\n        if canAutoExecute and msg.field == dataTypes[\"FIELD_BID_PRICE\"]:\n            df2use[msg.tickerId]['bid'] = float(msg.price)\n        # ask price\n        elif canAutoExecute and msg.field == dataTypes[\"FIELD_ASK_PRICE\"]:\n            df2use[msg.tickerId]['ask'] = float(msg.price)\n        # last price\n        elif msg.field == dataTypes[\"FIELD_LAST_PRICE\"]:\n            df2use[msg.tickerId]['last'] = float(msg.price)\n\n        # fire callback\n        self.ibCallback(caller=\"handleTickPrice\", msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handleTickSize(self, msg):\n\n        if msg.size < 0:\n            return\n\n        df2use = self.marketData\n        if self.contracts[msg.tickerId].m_secType in (\"OPT\", \"FOP\"):\n            df2use = self.optionsData\n\n        # create tick holder for ticker\n        if msg.tickerId not in df2use.keys():\n            df2use[msg.tickerId] = df2use[0].copy()\n\n        # ---------------------\n        # market data\n        # ---------------------\n        # bid size\n        if msg.field == dataTypes[\"FIELD_BID_SIZE\"]:\n            df2use[msg.tickerId]['bidsize'] = int(msg.size)\n        # ask size\n        elif msg.field == dataTypes[\"FIELD_ASK_SIZE\"]:\n            df2use[msg.tickerId]['asksize'] = int(msg.size)\n        # last size\n        elif msg.field == dataTypes[\"FIELD_LAST_SIZE\"]:\n            df2use[msg.tickerId]['lastsize'] = int(msg.size)\n\n        # ---------------------\n        # options data\n        # ---------------------\n        # open interest\n        elif msg.field == dataTypes[\"FIELD_OPEN_INTEREST\"]:\n            df2use[msg.tickerId]['oi'] = int(msg.size)\n\n        elif msg.field == dataTypes[\"FIELD_OPTION_CALL_OPEN_INTEREST\"] and \\\n                self.contracts[msg.tickerId].m_right == \"CALL\":\n            df2use[msg.tickerId]['oi'] = int(msg.size)\n\n        elif msg.field == dataTypes[\"FIELD_OPTION_PUT_OPEN_INTEREST\"] and \\\n                self.contracts[msg.tickerId].m_right == \"PUT\":\n            df2use[msg.tickerId]['oi'] = int(msg.size)\n\n        # volume\n        elif msg.field == dataTypes[\"FIELD_VOLUME\"]:\n            df2use[msg.tickerId]['volume'] = int(msg.size)\n\n        elif msg.field == dataTypes[\"FIELD_OPTION_CALL_VOLUME\"] and \\\n                self.contracts[msg.tickerId].m_right == \"CALL\":\n            df2use[msg.tickerId]['volume'] = int(msg.size)\n\n        elif msg.field == dataTypes[\"FIELD_OPTION_PUT_VOLUME\"] and \\\n                self.contracts[msg.tickerId].m_right == \"PUT\":\n            df2use[msg.tickerId]['volume'] = int(msg.size)\n\n        # fire callback\n        self.ibCallback(caller=\"handleTickSize\", msg=msg)", "response": "handle tick size message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handleTickString(self, msg):\n\n        df2use = self.marketData\n        if self.contracts[msg.tickerId].m_secType in (\"OPT\", \"FOP\"):\n            df2use = self.optionsData\n\n        # create tick holder for ticker\n        if msg.tickerId not in df2use.keys():\n            df2use[msg.tickerId] = df2use[0].copy()\n\n        # update timestamp\n        if msg.tickType == dataTypes[\"FIELD_LAST_TIMESTAMP\"]:\n            ts = datetime.fromtimestamp(int(msg.value)) \\\n                .strftime(dataTypes[\"DATE_TIME_FORMAT_LONG_MILLISECS\"])\n            df2use[msg.tickerId].index = [ts]\n            # self.log.debug(\"[TICK TS]: %s\", ts)\n\n            # handle trailing stop orders\n            if self.contracts[msg.tickerId].m_secType not in (\"OPT\", \"FOP\"):\n                self.triggerTrailingStops(msg.tickerId)\n                self.handleTrailingStops(msg.tickerId)\n\n            # fire callback\n            self.ibCallback(caller=\"handleTickString\", msg=msg)\n\n        elif (msg.tickType == dataTypes[\"FIELD_RTVOLUME\"]):\n\n            # log handler msg\n            # self.log_msg(\"rtvol\", msg)\n\n            tick = dict(dataTypes[\"RTVOL_TICKS\"])\n            (tick['price'], tick['size'], tick['time'], tick['volume'],\n                tick['wap'], tick['single']) = msg.value.split(';')\n\n            try:\n                tick['last']       = float(tick['price'])\n                tick['lastsize']   = float(tick['size'])\n                tick['volume']     = float(tick['volume'])\n                tick['wap']        = float(tick['wap'])\n                tick['single']     = tick['single'] == 'true'\n                tick['instrument'] = self.tickerSymbol(msg.tickerId)\n\n                # parse time\n                s, ms = divmod(int(tick['time']), 1000)\n                tick['time'] = '{}.{:03d}'.format(\n                    time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(s)), ms)\n\n                # add most recent bid/ask to \"tick\"\n                tick['bid']     = df2use[msg.tickerId]['bid'][0]\n                tick['bidsize'] = int(df2use[msg.tickerId]['bidsize'][0])\n                tick['ask']     = df2use[msg.tickerId]['ask'][0]\n                tick['asksize'] = int(df2use[msg.tickerId]['asksize'][0])\n\n                # self.log.debug(\"%s: %s\\n%s\", tick['time'], self.tickerSymbol(msg.tickerId), tick)\n\n                # fire callback\n                self.ibCallback(caller=\"handleTickString\", msg=msg, tick=tick)\n\n            except Exception:\n                pass\n\n        else:\n            # self.log.info(\"tickString-%s\", msg)\n            # fire callback\n            self.ibCallback(caller=\"handleTickString\", msg=msg)", "response": "Handle a tick string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling tick option computation.", "response": "def handleTickOptionComputation(self, msg):\n        \"\"\"\n        holds latest option data timestamp\n        only option price is kept at the moment\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/tickoptioncomputation.htm\n        \"\"\"\n        def calc_generic_val(data, field):\n            last_val = data['last_' + field].values[-1]\n            bid_val  = data['bid_' + field].values[-1]\n            ask_val  = data['ask_' + field].values[-1]\n            bid_ask_val = last_val\n            if bid_val != 0 and ask_val != 0:\n                bid_ask_val = (bid_val + ask_val) / 2\n            return max([last_val, bid_ask_val])\n\n        def valid_val(val):\n            return float(val) if val < 1000000000 else None\n\n        # create tick holder for ticker\n        if msg.tickerId not in self.optionsData.keys():\n            self.optionsData[msg.tickerId] = self.optionsData[0].copy()\n\n        col_prepend = \"\"\n        if msg.field == \"FIELD_BID_OPTION_COMPUTATION\":\n            col_prepend = \"bid_\"\n        elif msg.field == \"FIELD_ASK_OPTION_COMPUTATION\":\n            col_prepend = \"ask_\"\n        elif msg.field == \"FIELD_LAST_OPTION_COMPUTATION\":\n            col_prepend = \"last_\"\n\n        # save side\n        self.optionsData[msg.tickerId][col_prepend + 'imp_vol']  = valid_val(msg.impliedVol)\n        self.optionsData[msg.tickerId][col_prepend + 'dividend'] = valid_val(msg.pvDividend)\n        self.optionsData[msg.tickerId][col_prepend + 'delta'] = valid_val(msg.delta)\n        self.optionsData[msg.tickerId][col_prepend + 'gamma'] = valid_val(msg.gamma)\n        self.optionsData[msg.tickerId][col_prepend + 'vega'] = valid_val(msg.vega)\n        self.optionsData[msg.tickerId][col_prepend + 'theta'] = valid_val(msg.theta)\n        self.optionsData[msg.tickerId][col_prepend + 'price'] = valid_val(msg.optPrice)\n\n        # save generic/mid\n        data = self.optionsData[msg.tickerId]\n        self.optionsData[msg.tickerId]['imp_vol'] = calc_generic_val(data, 'imp_vol')\n        self.optionsData[msg.tickerId]['dividend'] = calc_generic_val(data, 'dividend')\n        self.optionsData[msg.tickerId]['delta'] = calc_generic_val(data, 'delta')\n        self.optionsData[msg.tickerId]['gamma'] = calc_generic_val(data, 'gamma')\n        self.optionsData[msg.tickerId]['vega'] = calc_generic_val(data, 'vega')\n        self.optionsData[msg.tickerId]['theta'] = calc_generic_val(data, 'theta')\n        self.optionsData[msg.tickerId]['price'] = calc_generic_val(data, 'price')\n        self.optionsData[msg.tickerId]['underlying'] = valid_val(msg.undPrice)\n\n        # fire callback\n        self.ibCallback(caller=\"handleTickOptionComputation\", msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate triggerable trailing stop", "response": "def createTriggerableTrailingStop(self, symbol, quantity=1,\n            triggerPrice=0, trailPercent=100., trailAmount=0.,\n            parentId=0, stopOrderId=None, **kwargs):\n        \"\"\" adds order to triggerable list \"\"\"\n\n        ticksize = self.contractDetails(symbol)[\"m_minTick\"]\n\n        self.triggerableTrailingStops[symbol] = {\n            \"parentId\": parentId,\n            \"stopOrderId\": stopOrderId,\n            \"triggerPrice\": triggerPrice,\n            \"trailAmount\": abs(trailAmount),\n            \"trailPercent\": abs(trailPercent),\n            \"quantity\": quantity,\n            \"ticksize\": ticksize\n        }\n\n        return self.triggerableTrailingStops[symbol]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef registerTrailingStop(self, tickerId, orderId=0, quantity=1,\n            lastPrice=0, trailPercent=100., trailAmount=0., parentId=0, **kwargs):\n        \"\"\" adds trailing stop to monitor list \"\"\"\n\n        ticksize = self.contractDetails(tickerId)[\"m_minTick\"]\n\n        trailingStop = self.trailingStops[tickerId] = {\n            \"orderId\": orderId,\n            \"parentId\": parentId,\n            \"lastPrice\": lastPrice,\n            \"trailAmount\": trailAmount,\n            \"trailPercent\": trailPercent,\n            \"quantity\": quantity,\n            \"ticksize\": ticksize\n        }\n\n        return trailingStop", "response": "registers trailing stop to monitor list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntriggering waiting trailing stops", "response": "def triggerTrailingStops(self, tickerId):\n        \"\"\" trigger waiting trailing stops \"\"\"\n        # print('.')\n        # test\n        symbol = self.tickerSymbol(tickerId)\n        price  = self.marketData[tickerId]['last'][0]\n        # contract = self.contracts[tickerId]\n\n        if symbol in self.triggerableTrailingStops.keys():\n            pendingOrder = self.triggerableTrailingStops[symbol]\n            parentId     = pendingOrder[\"parentId\"]\n            stopOrderId  = pendingOrder[\"stopOrderId\"]\n            triggerPrice = pendingOrder[\"triggerPrice\"]\n            trailAmount  = pendingOrder[\"trailAmount\"]\n            trailPercent = pendingOrder[\"trailPercent\"]\n            quantity     = pendingOrder[\"quantity\"]\n            ticksize     = pendingOrder[\"ticksize\"]\n\n            # print(\">>>>>>>\", pendingOrder)\n            # print(\">>>>>>>\", parentId)\n            # print(\">>>>>>>\", self.orders)\n\n            # abort\n            if parentId not in self.orders.keys():\n                # print(\"DELETING\")\n                del self.triggerableTrailingStops[symbol]\n                return None\n            else:\n                if self.orders[parentId][\"status\"] != \"FILLED\":\n                    return None\n\n            # print(\"\\n\\n\", quantity, triggerPrice, price, \"\\n\\n\")\n\n            # create the order\n            if ((quantity > 0) & (triggerPrice >= price)) | ((quantity < 0) & (triggerPrice <= price)):\n\n                newStop = price\n                if trailAmount > 0:\n                    if quantity > 0:\n                        newStop += trailAmount\n                    else:\n                        newStop -= trailAmount\n                elif trailPercent > 0:\n                    if quantity > 0:\n                        newStop += price * (trailPercent / 100)\n                    else:\n                        newStop -= price * (trailPercent / 100)\n                else:\n                    del self.triggerableTrailingStops[symbol]\n                    return 0\n\n                # print(\"------\", stopOrderId , parentId, newStop , quantity, \"------\")\n\n                # use valid newStop\n                newStop = self.roundClosestValid(newStop, ticksize)\n\n                trailingStopOrderId = self.modifyStopOrder(\n                    orderId  = stopOrderId,\n                    parentId = parentId,\n                    newStop  = newStop,\n                    quantity = quantity\n                )\n\n                if trailingStopOrderId:\n                    # print(\">>> TRAILING STOP\")\n                    del self.triggerableTrailingStops[symbol]\n\n                    # register trailing stop\n                    tickerId = self.tickerId(symbol)\n                    self.registerTrailingStop(\n                        tickerId = tickerId,\n                        parentId = parentId,\n                        orderId = stopOrderId,\n                        lastPrice = price,\n                        trailAmount = trailAmount,\n                        trailPercent = trailPercent,\n                        quantity = quantity,\n                        ticksize = ticksize\n                    )\n\n                    return trailingStopOrderId\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tickerId(self, contract_identifier):\n        # contract passed instead of symbol?\n        symbol = contract_identifier\n        if isinstance(symbol, Contract):\n            symbol = self.contractString(symbol)\n\n        for tickerId in self.tickerIds:\n            if symbol == self.tickerIds[tickerId]:\n                return tickerId\n        else:\n            tickerId = len(self.tickerIds)\n            self.tickerIds[tickerId] = symbol\n            return tickerId", "response": "returns the tickerId for the symbol or sets one if it doesn t exits\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contractString(self, contract, seperator=\"_\"):\n\n        localSymbol = \"\"\n        contractTuple = contract\n\n        if type(contract) != tuple:\n            localSymbol = contract.m_localSymbol\n            contractTuple = self.contract_to_tuple(contract)\n\n        # build identifier\n        try:\n            if contractTuple[1] in (\"OPT\", \"FOP\"):\n                # if contractTuple[5]*100 - int(contractTuple[5]*100):\n                #     strike = contractTuple[5]\n                # else:\n                #     strike = \"{0:.2f}\".format(contractTuple[5])\n                strike = '{:0>5d}'.format(int(contractTuple[5])) + \\\n                    format(contractTuple[5], '.3f').split('.')[1]\n\n                contractString = (contractTuple[0] + str(contractTuple[4]) +\n                                  contractTuple[6][0] + strike, contractTuple[1])\n                                  # contractTuple[6], str(strike).replace(\".\", \"\"))\n\n            elif contractTuple[1] == \"FUT\":\n                exp = ' ' # default\n\n                # round expiry day to expiry month\n                if localSymbol != \"\":\n                    # exp = localSymbol[2:3]+str(contractTuple[4][:4])\n                    exp = localSymbol[2:3] + self.localSymbolExpiry[localSymbol][:4]\n\n                if ' ' in exp:\n                    exp = str(contractTuple[4])[:6]\n                    exp = dataTypes[\"MONTH_CODES\"][int(exp[4:6])] + str(int(exp[:4]))\n\n                contractString = (contractTuple[0] + exp, contractTuple[1])\n\n            elif contractTuple[1] == \"CASH\":\n                contractString = (contractTuple[0] + contractTuple[3], contractTuple[1])\n\n            else:  # STK\n                contractString = (contractTuple[0], contractTuple[1])\n\n            # construct string\n            contractString = seperator.join(\n                str(v) for v in contractString).replace(seperator + \"STK\", \"\")\n\n        except Exception:\n            contractString = contractTuple[0]\n\n        return contractString.replace(\" \", \"_\").upper()", "response": "returns string from contract tuple"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning string from contract tuple", "response": "def contractDetails(self, contract_identifier):\n        \"\"\" returns string from contract tuple \"\"\"\n\n        if isinstance(contract_identifier, Contract):\n            tickerId = self.tickerId(contract_identifier)\n        else:\n            if str(contract_identifier).isdigit():\n                tickerId = contract_identifier\n            else:\n                tickerId = self.tickerId(contract_identifier)\n\n        if tickerId in self.contract_details:\n            return self.contract_details[tickerId]\n        elif tickerId in self._contract_details:\n            return self._contract_details[tickerId]\n\n        # default values\n        return {\n            'm_category': None, 'm_contractMonth': '', 'downloaded': False, 'm_evMultiplier': 0,\n            'm_evRule': None, 'm_industry': None, 'm_liquidHours': '', 'm_longName': '',\n            'm_marketName': '', 'm_minTick': 0.01, 'm_orderTypes': '', 'm_priceMagnifier': 0,\n            'm_subcategory': None, 'm_timeZoneId': '', 'm_tradingHours': '', 'm_underConId': 0,\n            'm_validExchanges': 'SMART', 'contracts': [Contract()], 'm_summary': {\n                'm_conId': 0, 'm_currency': 'USD', 'm_exchange': 'SMART', 'm_expiry': '',\n                'm_includeExpired': False, 'm_localSymbol': '', 'm_multiplier': '',\n                'm_primaryExch': None, 'm_right': None, 'm_secType': '',\n                'm_strike': 0.0, 'm_symbol': '', 'm_tradingClass': '',\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isMultiContract(self, contract):\n        if contract.m_secType == \"FUT\" and contract.m_expiry == \"\":\n            return True\n\n        if contract.m_secType in [\"OPT\", \"FOP\"] and \\\n                (contract.m_expiry == \"\" or contract.m_strike == \"\" or contract.m_right == \"\"):\n            return True\n\n        tickerId = self.tickerId(contract)\n        if tickerId in self.contract_details and \\\n                len(self.contract_details[tickerId][\"contracts\"]) > 1:\n            return True\n\n        return False", "response": "tells if this contract has sub - contracts with expiries and strikes and sides"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse for FX etc.", "response": "def createCashContract(self, symbol, currency=\"USD\", exchange=\"IDEALPRO\"):\n        \"\"\" Used for FX, etc:\n        createCashContract(\"EUR\", currency=\"USD\")\n        \"\"\"\n        contract_tuple = (symbol, \"CASH\", exchange, currency, \"\", 0.0, \"\")\n        contract = self.createContract(contract_tuple)\n        return contract"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createIndexContract(self, symbol, currency=\"USD\", exchange=\"CBOE\"):\n        contract_tuple = (symbol, \"IND\", exchange, currency, \"\", 0.0, \"\")\n        contract = self.createContract(contract_tuple)\n        return contract", "response": "Create a contract for the index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a TARGET order", "response": "def createTargetOrder(self, quantity, parentId=0,\n            target=0., orderType=None, transmit=True, group=None, tif=\"DAY\",\n            rth=False, account=None):\n        \"\"\" Creates TARGET order \"\"\"\n        order = self.createOrder(quantity,\n                    price     = target,\n                    transmit  = transmit,\n                    orderType = dataTypes[\"ORDER_TYPE_LIMIT\"] if orderType == None else orderType,\n                    ocaGroup  = group,\n                    parentId  = parentId,\n                    rth       = rth,\n                    tif       = tif,\n                    account   = account\n                )\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a STOP order.", "response": "def createStopOrder(self, quantity, parentId=0, stop=0., trail=None,\n            transmit=True, group=None, stop_limit=False, rth=False, tif=\"DAY\",\n            account=None):\n\n        \"\"\" Creates STOP order \"\"\"\n        if trail:\n            if trail == \"percent\":\n                order = self.createOrder(quantity,\n                            trailingPercent = stop,\n                            transmit  = transmit,\n                            orderType = dataTypes[\"ORDER_TYPE_TRAIL_STOP\"],\n                            ocaGroup  = group,\n                            parentId  = parentId,\n                            rth       = rth,\n                            tif       = tif,\n                            account   = account\n                        )\n            else:\n                order = self.createOrder(quantity,\n                            trailStopPrice = stop,\n                            stop      = stop,\n                            transmit  = transmit,\n                            orderType = dataTypes[\"ORDER_TYPE_TRAIL_STOP\"],\n                            ocaGroup  = group,\n                            parentId  = parentId,\n                            rth       = rth,\n                            tif       = tif,\n                            account   = account\n                        )\n\n        else:\n            order = self.createOrder(quantity,\n                        stop      = stop,\n                        price     = stop if stop_limit else 0.,\n                        transmit  = transmit,\n                        orderType = dataTypes[\"ORDER_TYPE_STOP_LIMIT\"] if stop_limit else dataTypes[\"ORDER_TYPE_STOP\"],\n                        ocaGroup  = group,\n                        parentId  = parentId,\n                        rth       = rth,\n                        tif       = tif,\n                        account   = account\n                    )\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createTrailingStopOrder(self, contract, quantity,\n            parentId=0, trailPercent=100., group=None, triggerPrice=None,\n            account=None):\n\n        \"\"\" convert hard stop order to trailing stop order \"\"\"\n        if parentId not in self.orders:\n            raise ValueError(\"Order #\" + str(parentId) + \" doesn't exist or wasn't submitted\")\n\n        order = self.createStopOrder(quantity,\n                    stop     = trailPercent,\n                    transmit = True,\n                    trail    = True,\n                    # ocaGroup = group\n                    parentId = parentId,\n                    account  = account\n                )\n\n        self.requestOrderIds()\n        return self.placeOrder(contract, order, self.orderId + 1)", "response": "create trailing stop order"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createBracketOrder(self, contract, quantity,\n            entry=0., target=0., stop=0.,\n            targetType=None, trailingStop=None, group=None, tif=\"DAY\",\n            fillorkill=False, iceberg=False, rth=False, stop_limit=False,\n            transmit=True, account=None, **kwargs):\n\n        \"\"\"\n        creates One Cancels All Bracket Order\n        trailingStop = None (regular stop) / percent / amount\n        \"\"\"\n        if group == None:\n            group = \"bracket_\" + str(int(time.time()))\n\n        # main order\n        enteyOrder = self.createOrder(quantity, price=entry, transmit=False,\n                        tif=tif, fillorkill=fillorkill, iceberg=iceberg,\n                        rth=rth, account=account)\n        entryOrderId = self.placeOrder(contract, enteyOrder)\n\n        # target\n        targetOrderId = 0\n        if target > 0:\n            targetOrder = self.createTargetOrder(-quantity,\n                            parentId  = entryOrderId,\n                            target    = target,\n                            transmit  = False if stop > 0 else True,\n                            orderType = targetType,\n                            group     = group,\n                            rth       = rth,\n                            tif       = tif,\n                            account   = account\n                        )\n\n            time.sleep(0.0001)\n            self.requestOrderIds()\n            targetOrderId = self.placeOrder(contract, targetOrder, self.orderId + 1)\n\n        # stop\n        stopOrderId = 0\n        if stop > 0:\n            stopOrder = self.createStopOrder(-quantity,\n                            parentId   = entryOrderId,\n                            stop       = stop,\n                            trail      = trailingStop,\n                            transmit   = transmit,\n                            group      = group,\n                            rth        = rth,\n                            tif        = tif,\n                            stop_limit = stop_limit,\n                            account    = account\n                        )\n\n            time.sleep(0.0001)\n            self.requestOrderIds()\n            stopOrderId = self.placeOrder(contract, stopOrder, self.orderId + 2)\n\n        # triggered trailing stop?\n        # if (\"triggerPrice\" in kwargs) & (\"trailPercent\" in kwargs):\n            # self.pendingTriggeredTrailingStopOrders.append()\n            # self.signal_ttl    = kwargs[\"signal_ttl\"] if \"signal_ttl\" in kwargs else 0\n\n        return {\n            \"group\": group,\n            \"entryOrderId\": entryOrderId,\n            \"targetOrderId\": targetOrderId,\n            \"stopOrderId\": stopOrderId\n        }", "response": "Creates a bracket order for the given entry target and stop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplacing order on IB TWS", "response": "def placeOrder(self, contract, order, orderId=None, account=None):\n        \"\"\" Place order on IB TWS \"\"\"\n\n        # get latest order id before submitting an order\n        self.requestOrderIds()\n\n        # continue...\n        useOrderId = self.orderId if orderId == None else orderId\n        if account:\n            order.m_account = account\n        self.ibConn.placeOrder(useOrderId, contract, order)\n\n        account_key = order.m_account\n        self.orders[useOrderId] = {\n            \"id\":       useOrderId,\n            \"symbol\":   self.contractString(contract),\n            \"contract\": contract,\n            \"status\":   \"SENT\",\n            \"reason\":   None,\n            \"avgFillPrice\": 0.,\n            \"parentId\": 0,\n            \"time\": datetime.fromtimestamp(int(self.time)),\n            \"account\": None\n        }\n        if hasattr(order, \"m_account\"):\n            self.orders[useOrderId][\"account\"] = order.m_account\n\n        # return order id\n        return useOrderId"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels order on IB TWS", "response": "def cancelOrder(self, orderId):\n        \"\"\" cancel order on IB TWS \"\"\"\n        self.ibConn.cancelOrder(orderId)\n\n        # update order id for next time\n        self.requestOrderIds()\n        return orderId"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requestOpenOrders(self, all_clients=False):\n        if all_clients:\n            self.ibConn.reqAllOpenOrders()\n        self.ibConn.reqOpenOrders()", "response": "Request open orders for this session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef requestMarketDepth(self, contracts=None, num_rows=10):\n\n        if num_rows > 10:\n            num_rows = 10\n\n        if contracts == None:\n            contracts = list(self.contracts.values())\n        elif not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            tickerId = self.tickerId(self.contractString(contract))\n            self.ibConn.reqMktDepth(\n                tickerId, contract, num_rows)", "response": "Request market depth for all contracts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncancel streaming market data for contracts", "response": "def cancelMarketDepth(self, contracts=None):\n        \"\"\"\n        Cancel streaming market data for contract\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/cancelmktdepth.htm\n        \"\"\"\n        if contracts == None:\n            contracts = list(self.contracts.values())\n        elif not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            tickerId = self.tickerId(self.contractString(contract))\n            self.ibConn.cancelMktDepth(tickerId=tickerId)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest market data for a single or multiple contracts", "response": "def requestMarketData(self, contracts=None, snapshot=False):\n        \"\"\"\n        Register to streaming market data updates\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/reqmktdata.htm\n        \"\"\"\n        if contracts == None:\n            contracts = list(self.contracts.values())\n        elif not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            if snapshot:\n                reqType = \"\"\n            else:\n                reqType = dataTypes[\"GENERIC_TICKS_RTVOLUME\"]\n                if contract.m_secType in (\"OPT\", \"FOP\"):\n                    reqType = dataTypes[\"GENERIC_TICKS_NONE\"]\n\n            # get market data for single contract\n            # limit is 250 requests/second\n            if not self.isMultiContract(contract):\n                try:\n                    tickerId = self.tickerId(self.contractString(contract))\n                    self.ibConn.reqMktData(tickerId, contract, reqType, snapshot)\n                    time.sleep(0.0042)  # 250 = 1.05s\n                except KeyboardInterrupt:\n                    sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancelMarketData(self, contracts=None):\n        if contracts == None:\n            contracts = list(self.contracts.values())\n        elif not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            # tickerId = self.tickerId(contract.m_symbol)\n            tickerId = self.tickerId(self.contractString(contract))\n            self.ibConn.cancelMktData(tickerId=tickerId)", "response": "Cancel streaming market data for contracts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requestHistoricalData(self, contracts=None, resolution=\"1 min\",\n            lookback=\"1 D\", data=\"TRADES\", end_datetime=None, rth=False,\n            csv_path=None, format_date=2, utc=False):\n\n        \"\"\"\n        Download to historical data\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/reqhistoricaldata.htm\n        \"\"\"\n\n        self.csv_path = csv_path\n        self.utc_history = utc\n\n        if end_datetime == None:\n            end_datetime = time.strftime(dataTypes[\"DATE_TIME_FORMAT_HISTORY\"])\n\n        if contracts == None:\n            contracts = list(self.contracts.values())\n\n        if not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            show = str(data).upper()\n            if contract.m_secType in ['CASH', 'CFD'] and data == 'TRADES':\n                show = 'MIDPOINT'\n\n            # tickerId = self.tickerId(contract.m_symbol)\n            tickerId = self.tickerId(self.contractString(contract))\n            self.ibConn.reqHistoricalData(\n                tickerId       = tickerId,\n                contract       = contract,\n                endDateTime    = end_datetime,\n                durationStr    = lookback,\n                barSizeSetting = resolution,\n                whatToShow     = show,\n                useRTH         = int(rth),\n                formatDate     = int(format_date)\n            )", "response": "Request historical data for a specific contracts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cancelHistoricalData(self, contracts=None):\n        if contracts == None:\n            contracts = list(self.contracts.values())\n        elif not isinstance(contracts, list):\n            contracts = [contracts]\n\n        for contract in contracts:\n            # tickerId = self.tickerId(contract.m_symbol)\n            tickerId = self.tickerId(self.contractString(contract))\n            self.ibConn.cancelHistoricalData(tickerId=tickerId)", "response": "cancel historical data stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests or cancel real - time position data for all accounts.", "response": "def requestPositionUpdates(self, subscribe=True):\n        \"\"\" Request/cancel request real-time position data for all accounts. \"\"\"\n        if self.subscribePositions != subscribe:\n            self.subscribePositions = subscribe\n            if subscribe == True:\n                self.ibConn.reqPositions()\n            else:\n                self.ibConn.cancelPositions()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters to account updates https://www.interactivebrokers.com/en/software/api/apiguide/java/reqaccountupdates.htm", "response": "def requestAccountUpdates(self, subscribe=True):\n        \"\"\"\n        Register to account updates\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/reqaccountupdates.htm\n        \"\"\"\n        if self.subscribeAccount != subscribe:\n            self.subscribeAccount = subscribe\n            self.ibConn.reqAccountUpdates(subscribe, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requestContractDetails(self, contract):\n        self.ibConn.reqContractDetails(self.tickerId(contract), contract)", "response": "Register to contract details\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/reqcontractdetails.htm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createComboLeg(self, contract, action, ratio=1, exchange=None):\n        leg = ComboLeg()\n\n        loops = 0\n        conId = 0\n        while conId == 0 and loops < 100:\n            conId = self.getConId(contract)\n            loops += 1\n            time.sleep(0.05)\n\n        leg.m_conId = conId\n        leg.m_ratio = abs(ratio)\n        leg.m_action = action\n        leg.m_exchange = contract.m_exchange if exchange is None else exchange\n        leg.m_openClose = 0\n        leg.m_shortSaleSlot = 0\n        leg.m_designatedLocation = \"\"\n\n        return leg", "response": "create combo leg\n        https://www.interactivebrokers.com/en/software/api/apiguide/java/comboleg.htm"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a ComboContract object for the given symbol and legs.", "response": "def createComboContract(self, symbol, legs, currency=\"USD\", exchange=None):\n        \"\"\" Used for ComboLegs. Expecting list of legs \"\"\"\n        exchange = legs[0].m_exchange if exchange is None else exchange\n        contract_tuple = (symbol, \"BAG\", exchange, currency, \"\", 0.0, \"\")\n        contract = self.createContract(contract_tuple, comboLegs=legs)\n        return contract"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getStrikes(self, contract_identifier, smin=None, smax=None):\n        strikes = []\n        contracts = self.contractDetails(contract_identifier)[\"contracts\"]\n\n        if contracts[0].m_secType not in (\"FOP\", \"OPT\"):\n            return []\n\n        # collect expirations\n        for contract in contracts:\n            strikes.append(contract.m_strike)\n\n        # convert to floats\n        strikes = list(map(float, strikes))\n        # strikes = list(set(strikes))\n\n        # get min/max\n        if smin is not None or smax is not None:\n            smin = smin if smin is not None else 0\n            smax = smax if smax is not None else 1000000000\n            srange = list(set(range(smin, smax, 1)))\n            strikes = [n for n in strikes if n in srange]\n\n        strikes.sort()\n        return tuple(strikes)", "response": "get strikes of contract"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getExpirations(self, contract_identifier, expired=0):\n        expirations = []\n        contracts = self.contractDetails(contract_identifier)[\"contracts\"]\n\n        if contracts[0].m_secType not in (\"FUT\", \"FOP\", \"OPT\"):\n            return []\n\n        # collect expirations\n        for contract in contracts:\n            expirations.append(contract.m_expiry)\n\n        # convert to ints\n        expirations = list(map(int, expirations))\n        # expirations = list(set(expirations))\n\n        # remove expired contracts\n        today = int(datetime.now().strftime(\"%Y%m%d\"))\n        closest = min(expirations, key=lambda x: abs(x - today))\n        expirations = expirations[expirations.index(closest) - expired:]\n\n        return tuple(expirations)", "response": "return expiration of contract"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a logger with the given name and optional level.", "response": "def createLogger(name, level=logging.WARNING):\n    \"\"\":Return: a logger with the given `name` and optional `level`.\"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s'))\n    logger.addHandler(handler)\n    logger.propagate = False\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an IBPy Order object to a dict containing any non - default values.", "response": "def order_to_dict(order):\n    \"\"\"Convert an IBPy Order object to a dict containing any non-default values.\"\"\"\n    default = Order()\n    return {field: val for field, val in vars(order).items() if val != getattr(default, field, None)}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an IBPy Contract object to a dict containing any non - default values.", "response": "def contract_to_dict(contract):\n    \"\"\"Convert an IBPy Contract object to a dict containing any non-default values.\"\"\"\n    default = Contract()\n    return {field: val for field, val in vars(contract).items() if val != getattr(default, field, None)}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef local_to_utc(df):\n    try:\n        offset_hour = -(datetime.now() - datetime.utcnow()).seconds\n    except:\n        offset_hour = time.altzone if time.daylight else time.timezone\n\n    offset_hour = offset_hour // 3600\n    offset_hour = offset_hour if offset_hour < 10 else offset_hour // 10\n\n    df = df.copy()\n    df.index = pd_to_datetime(df.index, utc=True) + timedelta(hours=offset_hour)\n\n    return df", "response": "converts local timezone to UTC"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets UTM code given a zone and direction.", "response": "def _get_utm_code(zone, direction):\n    \"\"\" Get UTM code given a zone and direction\n\n    Direction is encoded as NORTH=6, SOUTH=7, while zone is the UTM zone number zero-padded.\n    For instance, the code 32604 is returned for zone number 4, north direction.\n\n    :param zone: UTM zone number\n    :type zone: int\n    :param direction: Direction enum type\n    :type direction: Enum\n    :return: UTM code\n    :rtype: str\n    \"\"\"\n    dir_dict = {_Direction.NORTH: '6', _Direction.SOUTH: '7'}\n    return '{}{}{}'.format('32', dir_dict[direction], str(zone).zfill(2))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting name and code for UTM coordinates.", "response": "def _get_utm_name_value_pair(zone, direction=_Direction.NORTH):\n    \"\"\" Get name and code for UTM coordinates\n\n    :param zone: UTM zone number\n    :type zone: int\n    :param direction: Direction enum type\n    :type direction: Enum, optional (default=NORTH)\n    :return: Name and code of UTM coordinates\n    :rtype: str, str\n    \"\"\"\n    name = 'UTM_{}{}'.format(zone, direction.value)\n    epsg = _get_utm_code(zone, direction)\n    return name, epsg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _crs_parser(cls, value):\n    parsed_value = value\n    if isinstance(parsed_value, int):\n        parsed_value = str(parsed_value)\n    if isinstance(parsed_value, str):\n        parsed_value = parsed_value.strip('epsgEPSG: ')\n    return super(_BaseCRS, cls).__new__(cls, parsed_value)", "response": "Parses user input for CRS\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_wfs_typename(cls, data_source):\n        is_eocloud = SHConfig().is_eocloud_ogc_url()\n        return {\n            cls.SENTINEL2_L1C: 'S2.TILE',\n            cls.SENTINEL2_L2A: 'SEN4CAP_S2L2A.TILE' if is_eocloud else 'DSS2',\n            cls.SENTINEL1_IW: 'S1.TILE' if is_eocloud else 'DSS3',\n            cls.SENTINEL1_EW: 'S1_EW.TILE' if is_eocloud else 'DSS3',\n            cls.SENTINEL1_EW_SH: 'S1_EW_SH.TILE' if is_eocloud else 'DSS3',\n            cls.DEM: 'DSS4',\n            cls.MODIS: 'DSS5',\n            cls.LANDSAT8: 'L8.TILE' if is_eocloud else 'DSS6',\n            # eocloud sources only:\n            cls.LANDSAT5: 'L5.TILE',\n            cls.LANDSAT7: 'L7.TILE',\n            cls.SENTINEL3: 'S3.TILE',\n            cls.SENTINEL5P: 'S5p_L2.TILE',\n            cls.ENVISAT_MERIS: 'ENV.TILE',\n            cls.SENTINEL2_L3B: 'SEN4CAP_S2L3B.TILE',\n            cls.LANDSAT8_L2A: 'SEN4CAP_L8L2A.TILE'\n        }[data_source]", "response": "Returns the string identifier for WFS base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if data source via Sentinel Hub services is available at US West server.", "response": "def is_uswest_source(self):\n        \"\"\"Checks if data source via Sentinel Hub services is available at US West server\n\n        Example: ``DataSource.LANDSAT8.is_uswest_source()`` or ``DataSource.is_uswest_source(DataSource.LANDSAT8)``\n\n        :param self: One of the supported data sources\n        :type self: DataSource\n        :return: ``True`` if data source exists at US West server and ``False`` otherwise\n        :rtype: bool\n        \"\"\"\n        return not SHConfig().is_eocloud_ogc_url() and self.value[0] in [_Source.LANDSAT8, _Source.MODIS, _Source.DEM]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_available_sources(cls):\n        if SHConfig().is_eocloud_ogc_url():\n            return [cls.SENTINEL2_L1C, cls.SENTINEL2_L2A, cls.SENTINEL2_L3B, cls.SENTINEL1_IW, cls.SENTINEL1_EW,\n                    cls.SENTINEL1_EW_SH, cls.SENTINEL3, cls.SENTINEL5P, cls.LANDSAT5, cls.LANDSAT7, cls.LANDSAT8,\n                    cls.LANDSAT8_L2A, cls.ENVISAT_MERIS]\n        return [cls.SENTINEL2_L1C, cls.SENTINEL2_L2A, cls.SENTINEL1_IW, cls.SENTINEL1_EW, cls.SENTINEL1_EW_SH, cls.DEM,\n                cls.MODIS, cls.LANDSAT8]", "response": "Returns a list of data sources available for Sentinel Hub OGC URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts from WGS84 to UTM coordinate system", "response": "def get_utm_from_wgs84(lng, lat):\n        \"\"\" Convert from WGS84 to UTM coordinate system\n\n        :param lng: Longitude\n        :type lng: float\n        :param lat: Latitude\n        :type lat: float\n        :return: UTM coordinates\n        :rtype: tuple\n        \"\"\"\n        _, _, zone, _ = utm.from_latlon(lat, lng)\n        direction = 'N' if lat >= 0 else 'S'\n        return CRS['UTM_{}{}'.format(str(zone), direction)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting whether the class contains a string value", "response": "def has_value(cls, value):\n        \"\"\" Tests whether CustomUrlParam contains a constant defined with a string `value`\n\n        :param value: The string representation of the enum constant\n        :type value: str\n        :return: `True` if there exists a constant with a string value `value`, `False` otherwise\n        :rtype: bool\n        \"\"\"\n        return any(value.lower() == item.value.lower() for item in cls)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef canonical_extension(fmt_ext):\n        if MimeType.has_value(fmt_ext):\n            return fmt_ext\n        try:\n            return {\n                'tif': MimeType.TIFF.value,\n                'jpeg': MimeType.JPG.value,\n                'hdf5': MimeType.HDF.value,\n                'h5': MimeType.HDF.value\n            }[fmt_ext]\n        except KeyError:\n            raise ValueError('Data format .{} is not supported'.format(fmt_ext))", "response": "Returns the canonical extension of the format extension fmt_ext."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether the file format is an image format", "response": "def is_image_format(self):\n        \"\"\" Checks whether file format is an image format\n\n        Example: ``MimeType.PNG.is_image_format()`` or ``MimeType.is_image_format(MimeType.PNG)``\n\n        :param self: File format\n        :type self: MimeType\n        :return: ``True`` if file is in image format, ``False`` otherwise\n        :rtype: bool\n        \"\"\"\n        return self in frozenset([MimeType.TIFF, MimeType.TIFF_d8, MimeType.TIFF_d16, MimeType.TIFF_d32f, MimeType.PNG,\n                                  MimeType.JP2, MimeType.JPG])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether the file format is a TIFF image format", "response": "def is_tiff_format(self):\n        \"\"\" Checks whether file format is a TIFF image format\n\n        Example: ``MimeType.TIFF.is_tiff_format()`` or ``MimeType.is_tiff_format(MimeType.TIFF)``\n\n        :param self: File format\n        :type self: MimeType\n        :return: ``True`` if file is in image format, ``False`` otherwise\n        :rtype: bool\n        \"\"\"\n        return self in frozenset([MimeType.TIFF, MimeType.TIFF_d8, MimeType.TIFF_d16, MimeType.TIFF_d32f])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets file format as string", "response": "def get_string(self):\n        \"\"\" Get file format as string\n\n        :return: String describing the file format\n        :rtype: str\n        \"\"\"\n        if self in [MimeType.TIFF_d8, MimeType.TIFF_d16, MimeType.TIFF_d32f]:\n            return 'image/{}'.format(self.value)\n        if self is MimeType.JP2:\n            return 'image/jpeg2000'\n        if self in [MimeType.RAW, MimeType.REQUESTS_RESPONSE]:\n            return self.value\n        return mimetypes.types_map['.' + self.value]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_expected_max_value(self):\n        try:\n            return {\n                MimeType.TIFF: 65535,\n                MimeType.TIFF_d8: 255,\n                MimeType.TIFF_d16: 65535,\n                MimeType.TIFF_d32f: 1.0,\n                MimeType.PNG: 255,\n                MimeType.JPG: 255,\n                MimeType.JP2: 10000\n            }[self]\n        except IndexError:\n            raise ValueError('Type {} is not supported by this method'.format(self))", "response": "Returns the maximum value of the image format that is expected for the specified image type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter out dates within time_difference preserving only the oldest date.", "response": "def _filter_dates(dates, time_difference):\n        \"\"\"\n        Filters out dates within time_difference, preserving only the oldest date.\n\n        :param dates: a list of datetime objects\n        :param time_difference: a ``datetime.timedelta`` representing the time difference threshold\n        :return: an ordered list of datetimes `d1<=d2<=...<=dn` such that `d[i+1]-di > time_difference`\n        :rtype: list(datetime.datetime)\n        \"\"\"\n\n        LOGGER.debug(\"dates=%s\", dates)\n\n        if len(dates) <= 1:\n            return dates\n\n        sorted_dates = sorted(dates)\n\n        separate_dates = [sorted_dates[0]]\n        for curr_date in sorted_dates[1:]:\n            if curr_date - separate_dates[-1] > time_difference:\n                separate_dates.append(curr_date)\n        return separate_dates"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if Sentinel - 1 product ID matches Sentinel - 1 DataSource configuration.", "response": "def _sentinel1_product_check(product_id, data_source):\n        \"\"\"Checks if Sentinel-1 product ID matches Sentinel-1 DataSource configuration\n\n        :param product_id: Sentinel-1 product ID\n        :type product_id: str\n        :param data_source: One of the supported Sentinel-1 data sources\n        :type data_source: constants.DataSource\n        :return: True if data_source contains product_id and False otherwise\n        :rtype: bool\n        \"\"\"\n        props = product_id.split('_')\n        acquisition, resolution, polarisation = props[1], props[2][3], props[3][2:4]\n        if acquisition in ['IW', 'EW'] and resolution in ['M', 'H'] and polarisation in ['DV', 'DH', 'SV', 'SH']:\n            return acquisition == data_source.value[2].name and polarisation == data_source.value[3].name and \\\n                   resolution == data_source.value[4].name[0]\n        raise ValueError('Unknown Sentinel-1 tile type: {}'.format(product_id))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_request(self, request):\n        size_x, size_y = self.get_image_dimensions(request)\n        return [DownloadRequest(url=self.get_url(request=request, date=date, size_x=size_x, size_y=size_y),\n                                filename=self.get_filename(request, date, size_x, size_y),\n                                data_type=request.image_format, headers=OgcConstants.HEADERS)\n                for date in self.get_dates(request)]", "response": "Get download requests for all Sentinel - 2 acquisitions within request s time interval and acceptable cloud coverage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_url(self, request, *, date=None, size_x=None, size_y=None, geometry=None):\n        url = self.get_base_url(request)\n        authority = self.instance_id if hasattr(self, 'instance_id') else request.theme\n\n        params = self._get_common_url_parameters(request)\n        if request.service_type in (ServiceType.WMS, ServiceType.WCS):\n            params = {**params, **self._get_wms_wcs_url_parameters(request, date)}\n        if request.service_type is ServiceType.WMS:\n            params = {**params, **self._get_wms_url_parameters(request, size_x, size_y)}\n        elif request.service_type is ServiceType.WCS:\n            params = {**params, **self._get_wcs_url_parameters(request, size_x, size_y)}\n        elif request.service_type is ServiceType.FIS:\n            params = {**params, **self._get_fis_parameters(request, geometry)}\n\n        return '{}/{}?{}'.format(url, authority, urlencode(params))", "response": "Returns the url to Sentinel Hub s OGC service for the product specified by the OgcRequest and date."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates base url string.", "response": "def get_base_url(self, request):\n        \"\"\" Creates base url string.\n\n        :param request: OGC-type request with specified bounding box, cloud coverage for specific product.\n        :type request: OgcRequest or GeopediaRequest\n        :return: base string for url to Sentinel Hub's OGC service for this product.\n        :rtype: str\n        \"\"\"\n        url = self.base_url + request.service_type.value\n        # These 2 lines are temporal and will be removed after the use of uswest url wont be required anymore:\n        if hasattr(request, 'data_source') and request.data_source.is_uswest_source():\n            url = 'https://services-uswest2.sentinel-hub.com/ogc/{}'.format(request.service_type.value)\n\n        if hasattr(request, 'data_source') and request.data_source not in DataSource.get_available_sources():\n            raise ValueError(\"{} is not available for service at ogc_base_url={}\".format(request.data_source,\n                                                                                         SHConfig().ogc_base_url))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_common_url_parameters(request):\n        params = {\n            'SERVICE': request.service_type.value\n        }\n\n        if hasattr(request, 'maxcc'):\n            params['MAXCC'] = 100.0 * request.maxcc\n\n        if hasattr(request, 'custom_url_params') and request.custom_url_params is not None:\n            params = {**params,\n                      **{k.value: str(v) for k, v in request.custom_url_params.items()}}\n\n            if CustomUrlParam.EVALSCRIPT.value in params:\n                evalscript = params[CustomUrlParam.EVALSCRIPT.value]\n                params[CustomUrlParam.EVALSCRIPT.value] = b64encode(evalscript.encode()).decode()\n\n            if CustomUrlParam.GEOMETRY.value in params:\n                geometry = params[CustomUrlParam.GEOMETRY.value]\n                crs = request.bbox.crs\n\n                if isinstance(geometry, Geometry):\n                    if geometry.crs is not crs:\n                        raise ValueError('Geometry object in custom_url_params should have the same CRS as given BBox')\n                else:\n                    geometry = Geometry(geometry, crs)\n\n                if geometry.crs is CRS.WGS84:\n                    geometry = geometry.reverse()\n\n                params[CustomUrlParam.GEOMETRY.value] = geometry.wkt\n\n        return params", "response": "Returns parameters common for WMS WCS and FIS request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_wms_wcs_url_parameters(request, date):\n        params = {\n            'BBOX': str(request.bbox.reverse()) if request.bbox.crs is CRS.WGS84 else str(request.bbox),\n            'FORMAT': MimeType.get_string(request.image_format),\n            'CRS': CRS.ogc_string(request.bbox.crs),\n        }\n\n        if date is not None:\n            start_date = date if request.time_difference < datetime.timedelta(\n                seconds=0) else date - request.time_difference\n            end_date = date if request.time_difference < datetime.timedelta(\n                seconds=0) else date + request.time_difference\n            params['TIME'] = '{}/{}'.format(start_date.isoformat(), end_date.isoformat())\n\n        return params", "response": "Returns parameters common dictionary for WMS and WCS requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn parameters dictionary for FIS request.", "response": "def _get_fis_parameters(request, geometry):\n        \"\"\" Returns parameters dictionary for FIS request.\n\n        :param request: OGC-type request with specified bounding box, cloud coverage for specific product.\n        :type request: OgcRequest or GeopediaRequest\n        :param geometry: list of bounding boxes or geometries\n        :type geometry: list of BBox or Geometry\n        :return:  dictionary with parameters\n        :rtype: dict\n        \"\"\"\n        date_interval = parse_time_interval(request.time)\n\n        params = {\n            'CRS': CRS.ogc_string(geometry.crs),\n            'LAYER': request.layer,\n            'RESOLUTION': request.resolution,\n            'TIME': '{}/{}'.format(date_interval[0], date_interval[1])\n        }\n\n        if not isinstance(geometry, (BBox, Geometry)):\n            raise ValueError('Each geometry must be an instance of sentinelhub.{} or sentinelhub.{} but {} '\n                             'found'.format(BBox.__name__, Geometry.__name__, geometry))\n        if geometry.crs is CRS.WGS84:\n            geometry = geometry.reverse()\n        if isinstance(geometry, Geometry):\n            params['GEOMETRY'] = geometry.wkt\n        else:\n            params['BBOX'] = str(geometry)\n\n        if request.bins:\n            params['BINS'] = request.bins\n\n        if request.histogram_type:\n            params['TYPE'] = request.histogram_type.value\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_filename(request, date, size_x, size_y):\n        filename = '_'.join([\n            str(request.service_type.value),\n            request.layer,\n            str(request.bbox.crs),\n            str(request.bbox).replace(',', '_'),\n            '' if date is None else date.strftime(\"%Y-%m-%dT%H-%M-%S\"),\n            '{}X{}'.format(size_x, size_y)\n        ])\n\n        filename = OgcImageService.filename_add_custom_url_params(filename, request)\n\n        return OgcImageService.finalize_filename(filename, request.image_format)", "response": "Get filename location of the file in disk."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filename_add_custom_url_params(filename, request):\n        if hasattr(request, 'custom_url_params') and request.custom_url_params is not None:\n            for param, value in sorted(request.custom_url_params.items(),\n                                       key=lambda parameter_item: parameter_item[0].value):\n                filename = '_'.join([filename, param.value, str(value)])\n\n        return filename", "response": "Adds custom url parameters to the filename string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef finalize_filename(filename, file_format=None):\n        for char in [' ', '/', '\\\\', '|', ';', ':', '\\n', '\\t']:\n            filename = filename.replace(char, '')\n\n        if file_format:\n            suffix = str(file_format.value)\n            if file_format.is_tiff_format() and file_format is not MimeType.TIFF:\n                suffix = str(MimeType.TIFF.value)\n                filename = '_'.join([filename, str(file_format.value).replace(';', '_')])\n\n            filename = '.'.join([filename[:254 - len(suffix)], suffix])\n\n        LOGGER.debug(\"filename=%s\", filename)\n\n        return filename", "response": "Finalizes the filename string according to the file format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all available Sentinel - 2 acquisitions at least time_difference apart", "response": "def get_dates(self, request):\n        \"\"\" Get available Sentinel-2 acquisitions at least time_difference apart\n\n        List of all available Sentinel-2 acquisitions for given bbox with max cloud coverage and the specified\n        time interval. When a single time is specified the request will return that specific date, if it exists.\n        If a time range is specified the result is a list of all scenes between the specified dates conforming to\n        the cloud coverage criteria. Most recent acquisition being first in the list.\n\n        When a time_difference threshold is set to a positive value, the function filters out all datetimes which\n        are within the time difference. The oldest datetime is preserved, all others all deleted.\n\n        :param request: OGC-type request\n        :type request: WmsRequest or WcsRequest\n        :return: List of dates of existing acquisitions for the given request\n        :rtype: list(datetime.datetime) or [None]\n        \"\"\"\n        if DataSource.is_timeless(request.data_source):\n            return [None]\n\n        date_interval = parse_time_interval(request.time)\n\n        LOGGER.debug('date_interval=%s', date_interval)\n\n        if request.wfs_iterator is None:\n            self.wfs_iterator = WebFeatureService(request.bbox, date_interval, data_source=request.data_source,\n                                                  maxcc=request.maxcc, base_url=self.base_url,\n                                                  instance_id=self.instance_id)\n        else:\n            self.wfs_iterator = request.wfs_iterator\n\n        dates = sorted(set(self.wfs_iterator.get_dates()))\n\n        if request.time is OgcConstants.LATEST:\n            dates = dates[-1:]\n        return OgcService._filter_dates(dates, request.time_difference)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies or calculates horizontal and vertical dimensions of requested image.", "response": "def get_image_dimensions(request):\n        \"\"\"\n        Verifies or calculates image dimensions.\n\n        :param request: OGC-type request\n        :type request: WmsRequest or WcsRequest\n        :return: horizontal and vertical dimensions of requested image\n        :rtype: (int or str, int or str)\n        \"\"\"\n        if request.service_type is ServiceType.WCS or (isinstance(request.size_x, int) and\n                                                       isinstance(request.size_y, int)):\n            return request.size_x, request.size_y\n        if not isinstance(request.size_x, int) and not isinstance(request.size_y, int):\n            raise ValueError(\"At least one of parameters 'width' and 'height' must have an integer value\")\n        missing_dimension = get_image_dimension(request.bbox, width=request.size_x, height=request.size_y)\n        if request.size_x is None:\n            return missing_dimension, request.size_y\n        if request.size_y is None:\n            return request.size_x, missing_dimension\n        raise ValueError(\"Parameters 'width' and 'height' must be integers or None\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fetch_features(self):\n        if self.feature_offset is None:\n            return\n\n        main_url = '{}{}/{}?'.format(self.base_url, ServiceType.WFS.value, self.instance_id)\n\n        params = {'SERVICE': ServiceType.WFS.value,\n                  'REQUEST': 'GetFeature',\n                  'TYPENAMES': DataSource.get_wfs_typename(self.data_source),\n                  'BBOX': str(self.bbox.reverse()) if self.bbox.crs is CRS.WGS84 else str(self.bbox),\n                  'OUTPUTFORMAT': MimeType.get_string(MimeType.JSON),\n                  'SRSNAME': CRS.ogc_string(self.bbox.crs),\n                  'TIME': '{}/{}'.format(self.time_interval[0], self.time_interval[1]),\n                  'MAXCC': 100.0 * self.maxcc,\n                  'MAXFEATURES': SHConfig().max_wfs_records_per_query,\n                  'FEATURE_OFFSET': self.feature_offset}\n\n        url = main_url + urlencode(params)\n        LOGGER.debug(\"URL=%s\", url)\n        response = get_json(url)\n\n        is_sentinel1 = self.data_source.is_sentinel1()\n        for tile_info in response[\"features\"]:\n            if not is_sentinel1 or self._sentinel1_product_check(tile_info['properties']['id'], self.data_source):\n                self.tile_list.append(tile_info)\n\n        if len(response[\"features\"]) < SHConfig().max_wfs_records_per_query:\n            self.feature_offset = None\n        else:\n            self.feature_offset += SHConfig().max_wfs_records_per_query", "response": "Fetches data from WFS service and stores it in self. tile_list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dates(self):\n        return [datetime.datetime.strptime('{}T{}'.format(tile_info['properties']['date'],\n                                                          tile_info['properties']['time'].split('.')[0]),\n                                           '%Y-%m-%dT%H:%M:%S') for tile_info in self]", "response": "Returns a list of datetime. datetime objects from tile info data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_tile_url(tile_url):\n        props = tile_url.rsplit('/', 7)\n        return ''.join(props[1:4]), '-'.join(props[4:7]), int(props[7])", "response": "Extracts tile name data and AWS index from tile URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all dates within start_date and end_date in ISO 8601 format", "response": "def get_dates_in_range(start_date, end_date):\n    \"\"\" Get all dates within input start and end date in ISO 8601 format\n\n    :param start_date: start date in ISO 8601 format\n    :type start_date: str\n    :param end_date: end date in ISO 8601 format\n    :type end_date: str\n    :return: list of dates between start_date and end_date in ISO 8601 format\n    :rtype: list of str\n    \"\"\"\n    start_dt = iso_to_datetime(start_date)\n    end_dt = iso_to_datetime(end_date)\n    num_days = int((end_dt - start_dt).days)\n    return [datetime_to_iso(start_dt + datetime.timedelta(i)) for i in range(num_days + 1)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting ISO 8601 time format to datetime", "response": "def iso_to_datetime(date):\n    \"\"\" Convert ISO 8601 time format to datetime format\n\n    This function converts a date in ISO format, e.g. ``2017-09-14`` to a `datetime` instance, e.g.\n    ``datetime.datetime(2017,9,14,0,0)``\n\n    :param date: date in ISO 8601 format\n    :type date: str\n    :return: datetime instance\n    :rtype: datetime\n    \"\"\"\n    chunks = list(map(int, date.split('T')[0].split('-')))\n    return datetime.datetime(chunks[0], chunks[1], chunks[2])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef datetime_to_iso(date, only_date=True):\n    if only_date:\n        return date.isoformat().split('T')[0]\n    return date.isoformat()", "response": "Convert a datetime instance to ISO 8601 time format"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses input time into ISO 8601 string", "response": "def parse_time(time_input):\n    \"\"\" Parse input time/date string into ISO 8601 string\n\n    :param time_input: time/date to parse\n    :type time_input: str or datetime.date or datetime.datetime\n    :return: parsed string in ISO 8601 format\n    :rtype: str\n    \"\"\"\n    if isinstance(time_input, datetime.date):\n        return time_input.isoformat()  # datetime.date only returns date, datetime.datetime also returns time\n\n    if len(time_input) < 8:\n        raise ValueError('Invalid time string {}.\\n'\n                         'Please specify time in formats YYYY-MM-DD or YYYY-MM-DDTHH:MM:SS'.format(time_input))\n    time = dateutil.parser.parse(time_input)\n    if len(time_input) <= 10:\n        return time.date().isoformat()\n    return time.isoformat()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses input into an interval of two times specifying start and end time in ISO 8601 format.", "response": "def parse_time_interval(time):\n    \"\"\" Parse input into an interval of two times, specifying start and end time, in ISO 8601 format, for example:\n\n    ``(2017-01-15:T00:00:00, 2017-01-16:T23:59:59)``\n\n    The input time can have the following formats, which will be parsed as:\n\n    * `YYYY-MM-DD` -> `[YYYY-MM-DD:T00:00:00, YYYY-MM-DD:T23:59:59]`\n    * `YYYY-MM-DDThh:mm:ss` -> `[YYYY-MM-DDThh:mm:ss, YYYY-MM-DDThh:mm:ss]`\n    * list or tuple of two dates in form `YYYY-MM-DD` -> `[YYYY-MM-DDT00:00:00, YYYY-MM-DDT23:59:59]`\n    * list or tuple of two dates in form `YYYY-MM-DDThh:mm:ss` -> `[YYYY-MM-DDThh:mm:ss, YYYY-MM-DDThh:mm:ss]`,\n    * `None` -> `[default_start_date from config.json, current date]`\n\n    All input times can also be specified as `datetime` objects. Instances of `datetime.date` will be treated as\n    `YYYY-MM-DD` and instance of `datetime.datetime` will be treated as `YYYY-MM-DDThh:mm:ss`.\n\n    :param time: An input time\n    :type time: str or datetime.datetime\n    :return: interval of start and end date of the form `YYYY-MM-DDThh:mm:ss`\n    :rtype: (str, str)\n    :raises: ValueError\n    \"\"\"\n    if time is None or time is OgcConstants.LATEST:\n        date_interval = (SHConfig().default_start_date, get_current_date())\n    else:\n        if isinstance(time, (str, datetime.date)):\n            date_interval = (parse_time(time), ) * 2\n        elif isinstance(time, (tuple, list)) and len(time) == 2:\n            date_interval = (parse_time(time[0]), parse_time(time[1]))\n        else:\n            raise ValueError('Time must be a string/datetime object or tuple/list of 2 strings/datetime objects')\n\n    if 'T' not in date_interval[0]:\n        date_interval = (date_interval[0] + 'T00:00:00', date_interval[1])\n    if 'T' not in date_interval[1]:\n        date_interval = (date_interval[0], date_interval[1] + 'T23:59:59')\n\n    if date_interval[1] < date_interval[0]:\n        raise ValueError('Start of time interval is larger than end of time interval')\n\n    return date_interval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading Sentinel - 2 data from Sentinel - 2 on AWS to ESA SAFE format. Download uses multiple threads.", "response": "def aws(product, tile, folder, redownload, info, entire, bands, l2a):\n    \"\"\"Download Sentinel-2 data from Sentinel-2 on AWS to ESA SAFE format. Download uses multiple threads.\n\n    \\b\n    Examples with Sentinel-2 L1C data:\n      sentinelhub.aws --product S2A_MSIL1C_20170414T003551_N0204_R016_T54HVH_20170414T003551\n      sentinelhub.aws --product S2A_MSIL1C_20170414T003551_N0204_R016_T54HVH_20170414T003551 -i\n      sentinelhub.aws --product S2A_MSIL1C_20170414T003551_N0204_R016_T54HVH_20170414T003551 -f /home/ESA_Products\n      sentinelhub.aws --product S2A_MSIL1C_20170414T003551_N0204_R016_T54HVH_20170414T003551 --bands B08,B11\n      sentinelhub.aws --tile T54HVH 2017-04-14\n      sentinelhub.aws --tile T54HVH 2017-04-14 -e\n\n    \\b\n    Examples with Sentinel-2 L2A data:\n      sentinelhub.aws --product S2A_MSIL2A_20180402T151801_N0207_R068_T33XWJ_20180402T202222\n      sentinelhub.aws --tile T33XWJ 2018-04-02 --l2a\n    \"\"\"\n    band_list = None if bands is None else bands.split(',')\n    data_source = DataSource.SENTINEL2_L2A if l2a else DataSource.SENTINEL2_L1C\n    if info:\n        if product is None:\n            click.echo(get_safe_format(tile=tile, entire_product=entire, data_source=data_source))\n        else:\n            click.echo(get_safe_format(product_id=product))\n    else:\n        if product is None:\n            download_safe_format(tile=tile, folder=folder, redownload=redownload, entire_product=entire,\n                                 bands=band_list, data_source=data_source)\n        else:\n            download_safe_format(product_id=product, folder=folder, redownload=redownload, bands=band_list)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _config_options(func):\n    for param in SHConfig().get_params()[-1::-1]:\n        func = click.option('--{}'.format(param), param,\n                            help='Set new values to configuration parameter \"{}\"'.format(param))(func)\n    return func", "response": "A helper function which joins click. option functions of each parameter from config. json\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config(show, reset, **params):\n    sh_config = SHConfig()\n\n    if reset:\n        sh_config.reset()\n\n    for param, value in params.items():\n        if value is not None:\n            try:\n                value = int(value)\n            except ValueError:\n                if value.lower() == 'true':\n                    value = True\n                elif value.lower() == 'false':\n                    value = False\n            if getattr(sh_config, param) != value:\n                setattr(sh_config, param, value)\n\n    old_config = SHConfig()\n    sh_config.save()\n\n    for param in sh_config.get_params():\n        if sh_config[param] != old_config[param]:\n            value = sh_config[param]\n            if isinstance(value, str):\n                value = \"'{}'\".format(value)\n            click.echo(\"The value of parameter '{}' was updated to {}\".format(param, value))\n\n    if show:\n        click.echo(str(sh_config))\n        click.echo('Configuration file location: {}'.format(sh_config.get_config_location()))", "response": "Inspect and configure parameters in your local sentinelhub configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(url, filename, redownload):\n    data_folder, filename = filename.rsplit('/', 1)\n    download_list = [DownloadRequest(url=url, data_folder=data_folder, filename=filename, save_response=True,\n                                     return_data=False)]\n    download_data(download_list, redownload=redownload)", "response": "Download from custom created URL into custom created file path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating sentinelhub package config. json file.", "response": "def update_package_config():\n    \"\"\" Every time sentinelhub package is installed entire config.json is overwritten. However this function\n    will check if sentinelhub is already installed and try to copy those parameters from old config.json that are by\n    default set to an empty value (i.e. instance_id, aws_access_key_id and aws_secret_access_key) into new config.json\n    file.\n    \"\"\"\n    try:\n        import importlib\n        import sys\n        import json\n\n        path = importlib.machinery.PathFinder().find_spec('sentinelhub', sys.path[1:]).submodule_search_locations[0]\n        old_config_filename = os.path.join(path, 'config.json')\n\n        with open(old_config_filename, 'r') as file:\n            old_config = json.load(file)\n\n        from sentinelhub.config import SHConfig\n\n        config = SHConfig()\n        for attr, value in old_config.items():\n            if hasattr(config, attr) and not getattr(config, attr):\n                setattr(config, attr, value)\n\n        config.save()\n\n    except BaseException:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self, params=...):\n        if params is ...:\n            params = self.get_params()\n        if isinstance(params, str):\n            self._reset_param(params)\n        elif isinstance(params, (list, tuple)):\n            for param in params:\n                self._reset_param(param)\n        else:\n            raise ValueError('Parameters must be specified in form of a list of strings or as a single string, instead '\n                             'got {}'.format(params))", "response": "Resets the configuration class to initial values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reset_param(self, param):\n        if param not in self._instance.CONFIG_PARAMS:\n            raise ValueError(\"Cannot reset unknown parameter '{}'\".format(param))\n        setattr(self, param, self._instance.CONFIG_PARAMS[param])", "response": "Resets a single parameter to the value of the specified parameter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config_dict(self):\n        return OrderedDict((prop, getattr(self, prop)) for prop in self._instance.CONFIG_PARAMS)", "response": "Get a dictionary representation of SHConfig class\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bbox_to_dimensions(bbox, resolution):\n    utm_bbox = to_utm_bbox(bbox)\n    east1, north1 = utm_bbox.lower_left\n    east2, north2 = utm_bbox.upper_right\n\n    resx, resy = resolution if isinstance(resolution, tuple) else (resolution, resolution)\n\n    return round(abs(east2 - east1) / resx), round(abs(north2 - north1) / resy)", "response": "Calculates width and height in pixels for a given bounding box and pixel resolution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bbox_to_resolution(bbox, width, height):\n    utm_bbox = to_utm_bbox(bbox)\n    east1, north1 = utm_bbox.lower_left\n    east2, north2 = utm_bbox.upper_right\n    return abs(east2 - east1) / width, abs(north2 - north1) / height", "response": "Calculates pixel resolution in meters for a given bounding box width and height."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_image_dimension(bbox, width=None, height=None):\n    utm_bbox = to_utm_bbox(bbox)\n    east1, north1 = utm_bbox.lower_left\n    east2, north2 = utm_bbox.upper_right\n    if isinstance(width, int):\n        return round(width * abs(north2 - north1) / abs(east2 - east1))\n    return round(height * abs(east2 - east1) / abs(north2 - north1))", "response": "This function will return the image dimension that will best fit the bounding box and width or height."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform bbox into UTM CRS", "response": "def to_utm_bbox(bbox):\n    \"\"\" Transform bbox into UTM CRS\n\n    :param bbox: bounding box\n    :type bbox: geometry.BBox\n    :return: bounding box in UTM CRS\n    :rtype: geometry.BBox\n    \"\"\"\n    if CRS.is_utm(bbox.crs):\n        return bbox\n    lng, lat = bbox.middle\n    utm_crs = get_utm_crs(lng, lat, source_crs=bbox.crs)\n    return bbox.transform(utm_crs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_utm_bbox(img_bbox, transform):\n    east1, north1 = pixel_to_utm(img_bbox[0], img_bbox[1], transform)\n    east2, north2 = pixel_to_utm(img_bbox[2], img_bbox[3], transform)\n    return [east1, north1, east2, north2]", "response": "Get UTM coordinates given a bounding box in pixels and a georeferencing transform"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wgs84_to_utm(lng, lat, utm_crs=None):\n    if utm_crs is None:\n        utm_crs = get_utm_crs(lng, lat)\n    return transform_point((lng, lat), CRS.WGS84, utm_crs)", "response": "Convert WGS84 coordinates to UTM."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts any CRS with ( east north ) coordinates to WGS84 system", "response": "def to_wgs84(east, north, crs):\n    \"\"\" Convert any CRS with (east, north) coordinates to WGS84\n\n    :param east: east coordinate\n    :type east: float\n    :param north: north coordinate\n    :type north: float\n    :param crs: CRS enum constants\n    :type crs: constants.CRS\n    :return: latitude and longitude coordinates in WGS84 system\n    :rtype: float, float\n    \"\"\"\n    return transform_point((east, north), crs, CRS.WGS84)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef utm_to_pixel(east, north, transform, truncate=True):\n    column = (east - transform[0]) / transform[1]\n    row = (north - transform[3]) / transform[5]\n    if truncate:\n        return int(row + ERR), int(column + ERR)\n    return row, column", "response": "Convert UTM coordinate to pixel image coordinates given a transform"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert pixel coordinate to UTM coordinate given a transform", "response": "def pixel_to_utm(row, column, transform):\n    \"\"\" Convert pixel coordinate to UTM coordinate given a transform\n\n    :param row: row pixel coordinate\n    :type row: int or float\n    :param column: column pixel coordinate\n    :type column: int or float\n    :param transform: georeferencing transform of the image, e.g. `(x_upper_left, res_x, 0, y_upper_left, 0, -res_y)`\n    :type transform: tuple or list\n    :return: east, north UTM coordinates\n    :rtype: float, float\n    \"\"\"\n    east = transform[0] + column * transform[1]\n    north = transform[3] + row * transform[5]\n    return east, north"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wgs84_to_pixel(lng, lat, transform, utm_epsg=None, truncate=True):\n    east, north = wgs84_to_utm(lng, lat, utm_epsg)\n    row, column = utm_to_pixel(east, north, transform, truncate=truncate)\n    return row, column", "response": "Convert WGS84 coordinates to pixel image coordinates given transform and UTM CRS."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_utm_crs(lng, lat, source_crs=CRS.WGS84):\n    if source_crs is not CRS.WGS84:\n        lng, lat = transform_point((lng, lat), source_crs, CRS.WGS84)\n    return CRS.get_utm_from_wgs84(lng, lat)", "response": "Get UTM zone from latitude and longitude."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform_point(point, source_crs, target_crs):\n    if source_crs == target_crs:\n        return point\n    old_x, old_y = point\n    new_x, new_y = pyproj.transform(CRS.projection(source_crs), CRS.projection(target_crs), old_x, old_y)\n    return new_x, new_y", "response": "Maps point form src_crs to tgt_crs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_bbox(bbox, target_crs):\n    warnings.warn(\"This function is deprecated, use BBox.transform method instead\", DeprecationWarning, stacklevel=2)\n\n    return bbox.transform(target_crs)", "response": "Maps bbox from current crs to target crs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_safe_format(product_id=None, tile=None, entire_product=False, bands=None, data_source=DataSource.SENTINEL2_L1C):\n    entire_product = entire_product and product_id is None\n    if tile is not None:\n        safe_tile = SafeTile(tile_name=tile[0], time=tile[1], bands=bands, data_source=data_source)\n        if not entire_product:\n            return safe_tile.get_safe_struct()\n        product_id = safe_tile.get_product_id()\n    if product_id is None:\n        raise ValueError('Either product_id or tile must be specified')\n    safe_product = SafeProduct(product_id, tile_list=[tile[0]], bands=bands) if entire_product else \\\n        SafeProduct(product_id, bands=bands)\n    return safe_product.get_safe_struct()", "response": "Returns a structure representing the current state of the base ESA product."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_safe_format(product_id=None, tile=None, folder='.', redownload=False, entire_product=False, bands=None,\n                         data_source=DataSource.SENTINEL2_L1C):\n    \"\"\"\n    Downloads .SAFE format structure in form of nested dictionaries. Either ``product_id`` or ``tile`` must\n    be specified.\n\n    :param product_id: original ESA product identification string. Default is ``None``\n    :type product_id: str\n    :param tile: tuple containing tile name and sensing time/date. Default is ``None``\n    :type tile: (str, str)\n    :param folder: location of the directory where the fetched data will be saved. Default is ``'.'``\n    :type folder: str\n    :param redownload: if ``True``, download again the requested data even though it's already saved to disk. If\n                       ``False``, do not download if data is already available on disk. Default is ``False``\n    :type redownload: bool\n    :param entire_product: in case tile is specified this flag determines if it will be place inside a .SAFE structure\n                           of the product. Default is ``False``\n    :type entire_product: bool\n    :param bands: list of bands to download. If ``None`` all bands will be downloaded. Default is ``None``\n    :type bands: list(str) or None\n    :param data_source: In case of tile request the source of satellite data has to be specified. Default is Sentinel-2\n                        L1C data.\n    :type data_source: constants.DataSource\n    :return: Nested dictionaries representing .SAFE structure.\n    :rtype: dict\n    \"\"\"\n    entire_product = entire_product and product_id is None\n    if tile is not None:\n        safe_request = AwsTileRequest(tile=tile[0], time=tile[1], data_folder=folder, bands=bands,\n                                      safe_format=True, data_source=data_source)\n        if entire_product:\n            safe_tile = safe_request.get_aws_service()\n            product_id = safe_tile.get_product_id()\n    if product_id is not None:\n        safe_request = AwsProductRequest(product_id, tile_list=[tile[0]], data_folder=folder, bands=bands,\n                                         safe_format=True) if entire_product else \\\n            AwsProductRequest(product_id, data_folder=folder, bands=bands, safe_format=True)\n\n    safe_request.save_data(redownload=redownload)", "response": "Download the. SAFE format structure of a single product."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget requested data from the system.", "response": "def get_data(self, *, save_data=False, data_filter=None, redownload=False, max_threads=None,\n                 raise_download_errors=True):\n        \"\"\"\n        Get requested data either by downloading it or by reading it from the disk (if it\n        was previously downloaded and saved).\n\n        :param save_data: flag to turn on/off saving of data to disk. Default is ``False``.\n        :type save_data: bool\n        :param redownload: if ``True``, download again the requested data even though it's already saved to disk.\n                            Default is ``False``, do not download if data is already available on disk.\n        :type redownload: bool\n        :param data_filter: Used to specify which items will be returned by the method and in which order. E.g. with\n            ``data_filter=[0, 2, -1]`` the method will return only 1st, 3rd and last item. Default filter is ``None``.\n        :type data_filter: list(int) or None\n        :param max_threads: number of threads to use when downloading data; default is ``max_threads=None`` which\n            by default uses the number of processors on the system\n        :type max_threads: int\n        :param raise_download_errors: If ``True`` any error in download process should be raised as\n            ``DownloadFailedException``. If ``False`` failed downloads will only raise warnings and the method will\n            return list with ``None`` values in places where the results of failed download requests should be.\n        :type raise_download_errors: bool\n        :return: requested images as numpy arrays, where each array corresponds to a single acquisition and has\n                    shape ``[height, width, channels]``.\n        :rtype: list of numpy arrays\n        \"\"\"\n        self._preprocess_request(save_data, True)\n        data_list = self._execute_data_download(data_filter, redownload, max_threads, raise_download_errors)\n        return self._add_saved_data(data_list, data_filter, raise_download_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves data to disk.", "response": "def save_data(self, *, data_filter=None, redownload=False, max_threads=None, raise_download_errors=False):\n        \"\"\"\n        Saves data to disk. If ``redownload=True`` then the data is redownloaded using ``max_threads`` workers.\n\n        :param data_filter: Used to specify which items will be returned by the method and in which order. E.g. with\n            `data_filter=[0, 2, -1]` the method will return only 1st, 3rd and last item. Default filter is ``None``.\n        :type data_filter: list(int) or None\n        :param redownload: data is redownloaded if ``redownload=True``. Default is ``False``\n        :type redownload: bool\n        :param max_threads: number of threads to use when downloading data; default is ``max_threads=None`` which\n            by default uses the number of processors on the system\n        :type max_threads: int\n        :param raise_download_errors: If ``True`` any error in download process should be raised as\n            ``DownloadFailedException``. If ``False`` failed downloads will only raise warnings.\n        :type raise_download_errors: bool\n        \"\"\"\n        self._preprocess_request(True, False)\n        self._execute_data_download(data_filter, redownload, max_threads, raise_download_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _execute_data_download(self, data_filter, redownload, max_threads, raise_download_errors):\n        is_repeating_filter = False\n        if data_filter is None:\n            filtered_download_list = self.download_list\n        elif isinstance(data_filter, (list, tuple)):\n            try:\n                filtered_download_list = [self.download_list[index] for index in data_filter]\n            except IndexError:\n                raise IndexError('Indices of data_filter are out of range')\n\n            filtered_download_list, mapping_list = self._filter_repeating_items(filtered_download_list)\n            is_repeating_filter = len(filtered_download_list) < len(mapping_list)\n        else:\n            raise ValueError('data_filter parameter must be a list of indices')\n\n        data_list = []\n        for future in download_data(filtered_download_list, redownload=redownload, max_threads=max_threads):\n            try:\n                data_list.append(future.result(timeout=SHConfig().download_timeout_seconds))\n            except ImageDecodingError as err:\n                data_list.append(None)\n                LOGGER.debug('%s while downloading data; will try to load it from disk if it was saved', err)\n            except DownloadFailedException as download_exception:\n                if raise_download_errors:\n                    raise download_exception\n                warnings.warn(str(download_exception))\n                data_list.append(None)\n\n        if is_repeating_filter:\n            data_list = [copy.deepcopy(data_list[index]) for index in mapping_list]\n\n        return data_list", "response": "Executes the download process and returns the list of data obtained from download_list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _filter_repeating_items(download_list):\n        unique_requests_map = {}\n        mapping_list = []\n        unique_download_list = []\n        for download_request in download_list:\n            if download_request not in unique_requests_map:\n                unique_requests_map[download_request] = len(unique_download_list)\n                unique_download_list.append(download_request)\n            mapping_list.append(unique_requests_map[download_request])\n        return unique_download_list, mapping_list", "response": "This method will reduce the list of download requests and return a mapping list which can be used to reconstruct the previous list of download requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _preprocess_request(self, save_data, return_data):\n        if not self.is_valid_request():\n            raise ValueError('Cannot obtain data because request is invalid')\n\n        if save_data and self.data_folder is None:\n            raise ValueError('Request parameter `data_folder` is not specified. '\n                             'In order to save data please set `data_folder` to location on your disk.')\n\n        for download_request in self.download_list:\n            download_request.set_save_response(save_data)\n            download_request.set_return_data(return_data)\n            download_request.set_data_folder(self.data_folder)\n\n        if save_data:\n            for folder in self.folder_list:\n                make_folder(os.path.join(self.data_folder, folder))", "response": "Preprocesses the request for download and creates empty folders."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding already saved data to the requested data list.", "response": "def _add_saved_data(self, data_list, data_filter, raise_download_errors):\n        \"\"\"\n        Adds already saved data that was not redownloaded to the requested data list.\n        \"\"\"\n        filtered_download_list = self.download_list if data_filter is None else \\\n            [self.download_list[index] for index in data_filter]\n        for i, request in enumerate(filtered_download_list):\n            if request.return_data and data_list[i] is None:\n                if os.path.exists(request.get_file_path()):\n                    data_list[i] = read_data(request.get_file_path())\n                elif raise_download_errors:\n                    raise DownloadFailedException('Failed to download data from {}.\\n No previously downloaded data '\n                                                  'exists in file {}.'.format(request.url, request.get_file_path()))\n        return data_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if custom url parameters are valid parameters. Throws ValueError if they are not valid.", "response": "def _check_custom_url_parameters(self):\n        \"\"\"Checks if custom url parameters are valid parameters.\n\n        Throws ValueError if the provided parameter is not a valid parameter.\n        \"\"\"\n        for param in self.custom_url_params:\n            if param not in CustomUrlParam:\n                raise ValueError('Parameter %s is not a valid custom url parameter. Please check and fix.' % param)\n\n        if self.service_type is ServiceType.FIS and CustomUrlParam.GEOMETRY in self.custom_url_params:\n            raise ValueError('{} should not be a custom url parameter of a FIS request'.format(CustomUrlParam.GEOMETRY))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a list of DownloadRequests for all Sentinel - 2 acquisitions within request s time interval and acceptable cloud coverage.", "response": "def create_request(self, reset_wfs_iterator=False):\n        \"\"\"Set download requests\n\n        Create a list of DownloadRequests for all Sentinel-2 acquisitions within request's time interval and\n        acceptable cloud coverage.\n\n        :param reset_wfs_iterator: When re-running the method this flag is used to reset/keep existing ``wfs_iterator``\n            (i.e. instance of ``WebFeatureService`` class). If the iterator is not reset you don't have to repeat a\n            service call but tiles and dates will stay the same.\n        :type reset_wfs_iterator: bool\n        \"\"\"\n        if reset_wfs_iterator:\n            self.wfs_iterator = None\n\n        ogc_service = OgcImageService(instance_id=self.instance_id)\n        self.download_list = ogc_service.get_request(self)\n        self.wfs_iterator = ogc_service.get_wfs_iterator()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_request(self):\n        fis_service = FisService(instance_id=self.instance_id)\n        self.download_list = fis_service.get_request(self)", "response": "Create a list of DownloadRequests for all Sentinel - 2 acquisitions within request s time interval and\n        acceptable cloud coverage."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if custom url parameters are valid.", "response": "def _check_custom_url_parameters(self):\n        \"\"\"Checks if custom url parameters are valid parameters.\n\n        Throws ValueError if the provided parameter is not a valid parameter.\n        \"\"\"\n        for param in self.custom_url_params.keys():\n            if param is not CustomUrlParam.TRANSPARENT:\n                raise ValueError('Parameter {} is currently not supported.'.format(param))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_request(self, reset_gpd_iterator=False):\n        if reset_gpd_iterator:\n            self.gpd_iterator = None\n\n        gpd_service = GeopediaImageService()\n        self.download_list = gpd_service.get_request(self)\n        self.gpd_iterator = gpd_service.get_gpd_iterator()", "response": "Create a download request for all images under the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_layer(layer, return_wms_name=False):\n        if not isinstance(layer, (int, str)):\n            raise ValueError(\"Parameter 'layer' should be an integer or a string, but {} found\".format(type(layer)))\n\n        if return_wms_name:\n            if isinstance(layer, int) or layer.isdigit():\n                return 'ttl{}'.format(layer)\n            return layer\n\n        if isinstance(layer, str):\n            stripped_layer = layer.lstrip('tl')\n            if not stripped_layer.isdigit():\n                raise ValueError(\"Parameter 'layer' has unsupported value {}, expected an integer\".format(layer))\n            layer = stripped_layer\n\n        return int(layer)", "response": "Helper function for parsing Geopedia layer name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake sure that the current session is still valid and provides session info.", "response": "def provide_session(self, start_new=False):\n        \"\"\" Makes sure that session is still valid and provides session info\n\n        :param start_new: If `True` it will always create a new session. Otherwise it will create a new\n            session only if no session exists or the previous session timed out.\n        :type start_new: bool\n        :return: Current session info\n        :rtype: dict\n        \"\"\"\n        if self.is_global:\n            self._session_info = self._global_session_info\n            self._session_start = self._global_session_start\n\n        if self._session_info is None or start_new or \\\n                datetime.datetime.now() > self._session_start + self.SESSION_DURATION:\n            self._start_new_session()\n\n        return self._session_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a new session and calculates when the new session will end.", "response": "def _start_new_session(self):\n        \"\"\" Starts a new session and calculates when the new session will end. If username and password are provided\n        it will also make login.\n        \"\"\"\n        self._session_start = datetime.datetime.now()\n\n        session_id = self._parse_session_id(self._session_info) if self._session_info else ''\n        session_url = '{}data/v1/session/create?locale=en&sid={}'.format(self.base_url, session_id)\n        self._session_info = get_json(session_url)\n\n        if self.username and self.password and self._parse_user_id(self._session_info) == self.UNAUTHENTICATED_USER_ID:\n            self._make_login()\n\n        if self.is_global:\n            GeopediaSession._global_session_info = self._session_info\n            GeopediaSession._global_session_start = self._session_start"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of DownloadRequests for all data that are under the given field in the Geopedia layer.", "response": "def get_request(self, request):\n        \"\"\"Get a list of DownloadRequests for all data that are under the given field in the table of a Geopedia layer.\n\n        :return: list of items which have to be downloaded\n        :rtype: list(DownloadRequest)\n        \"\"\"\n        request.layer = self._parse_layer(request.layer, return_wms_name=True)\n\n        return super().get_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of DownloadRequests for all items that are under the given field in the Geopedia layer.", "response": "def get_request(self, request):\n        \"\"\"Get a list of DownloadRequests for all data that are under the given field in the table of a Geopedia layer.\n\n        :return: list of items which have to be downloaded\n        :rtype: list(DownloadRequest)\n        \"\"\"\n        return [DownloadRequest(url=self._get_url(item),\n                                filename=self._get_filename(request, item),\n                                data_type=request.image_format)\n                for item in self._get_items(request)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_items(self, request):\n        if request.gpd_iterator is None:\n            self.gpd_iterator = GeopediaFeatureIterator(request.layer, bbox=request.bbox, base_url=self.base_url,\n                                                        gpd_session=request.gpd_session)\n        else:\n            self.gpd_iterator = request.gpd_iterator\n\n        field_iter = self.gpd_iterator.get_field_iterator(request.image_field_name)\n        items = []\n\n        for field_items in field_iter:  # an image field can have multiple images\n\n            for item in field_items:\n                if not item['mimeType'].startswith('image/'):\n                    continue\n\n                mime_type = MimeType.from_string(item['mimeType'][6:])\n\n                if mime_type is request.image_format:\n                    items.append(item)\n\n        return items", "response": "Collects data from Geopedia layer and returns list of features\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a filename based on the request and the item.", "response": "def _get_filename(request, item):\n        \"\"\" Creates a filename\n        \"\"\"\n        if request.keep_image_names:\n            filename = OgcImageService.finalize_filename(item['niceName'].replace(' ', '_'))\n        else:\n            filename = OgcImageService.finalize_filename(\n                '_'.join([str(GeopediaService._parse_layer(request.layer)), item['objectPath'].rsplit('/', 1)[-1]]),\n                request.image_format\n            )\n\n        LOGGER.debug(\"filename=%s\", filename)\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch a new page of features from Geopedia", "response": "def _fetch_features(self):\n        \"\"\" Retrieves a new page of features from Geopedia\n        \"\"\"\n        if self.next_page_url is None:\n            return\n\n        response = get_json(self.next_page_url, post_values=self.query, headers=self.gpd_session.session_headers)\n\n        self.features.extend(response['features'])\n        self.next_page_url = response['pagination']['next']\n        self.layer_size = response['pagination']['total']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_folder_list(folder='.'):\n    dir_list = get_content_list(folder)\n    return [f for f in dir_list if not os.path.isfile(os.path.join(folder, f))]", "response": "Get list of sub - folders contained in input folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating parent folder for input filename recursively", "response": "def create_parent_folder(filename):\n    \"\"\" Create parent folder for input filename recursively\n\n    :param filename: input filename\n    :type filename: str\n    :raises: error if folder cannot be created\n    \"\"\"\n    path = os.path.dirname(filename)\n    if path != '':\n        make_folder(path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a folder at input path recursively", "response": "def make_folder(path):\n    \"\"\" Create folder at input path recursively\n\n    Create a folder specified by input path if one\n    does not exist already\n\n    :param path: input path to folder to be created\n    :type path: str\n    :raises: os.error if folder cannot be created\n    \"\"\"\n    if not os.path.exists(path):\n        try:\n            os.makedirs(path)\n        except OSError as exception:\n            if exception.errno != errno.EEXIST:\n                raise ValueError('Specified folder is not writable: %s'\n                                 '\\nPlease check permissions or set a new valid folder.' % path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rename(old_path, new_path, edit_folders=True):\n    if edit_folders:\n        os.renames(old_path, new_path)\n    else:\n        os.rename(old_path, new_path)", "response": "Rename files or folders or folders of a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef size(pathname):\n    if os.path.isfile(pathname):\n        return os.path.getsize(pathname)\n    return sum([size('{}/{}'.format(pathname, name)) for name in get_content_list(pathname)])", "response": "Returns the size of a file or folder in Bytes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets download requests for all Sentinel - 2 acquisitions within a request s time interval and acceptable cloud coverage.", "response": "def get_request(self, request):\n        \"\"\" Get download requests\n\n        Create a list of DownloadRequests for all Sentinel-2 acquisitions within request's time interval and\n        acceptable cloud coverage.\n\n\n        :param request: OGC-type request with specified bounding box, time interval, and cloud coverage for specific\n                        product.\n        :type request: OgcRequest or GeopediaRequest\n        :return: list of DownloadRequests\n        \"\"\"\n\n        return [DownloadRequest(url=self.get_url(request=request, geometry=geometry),\n                                filename=self.get_filename(request, geometry),\n                                data_type=MimeType.JSON, headers=OgcConstants.HEADERS)\n                for geometry in request.geometry_list]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_filename(request, geometry):\n        date_interval = parse_time_interval(request.time)\n        geometry_string = geometry.wkt if isinstance(geometry, Geometry) else str(geometry)\n\n        filename = '_'.join([\n            str(request.service_type.value),\n            request.layer,\n            geometry_string,\n            CRS.ogc_string(geometry.crs),\n            '{}_{}'.format(date_interval[0], date_interval[1]),\n            request.resolution,\n            str(request.bins) if request.bins else '',\n            request.histogram_type.value if request.histogram_type else ''\n        ])\n\n        filename = OgcImageService.filename_add_custom_url_params(filename, request)\n\n        return OgcImageService.finalize_filename(filename, MimeType.JSON)", "response": "Returns the filename for the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the middle point of the bounding box", "response": "def middle(self):\n        \"\"\" Returns the middle point of the bounding box\n\n        :return: middle point\n        :rtype: (float, float)\n        \"\"\"\n        return (self.min_x + self.max_x) / 2, (self.min_y + self.max_y) / 2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new BBox object where x and y coordinates are switched", "response": "def reverse(self):\n        \"\"\" Returns a new BBox object where x and y coordinates are switched\n\n        :return: New BBox object with switched coordinates\n        :rtype: BBox\n        \"\"\"\n        return BBox((self.min_y, self.min_x, self.max_y, self.max_x), crs=self.crs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms the BBox from current CRS to target CRS", "response": "def transform(self, crs):\n        \"\"\" Transforms BBox from current CRS to target CRS\n\n        :param crs: target CRS\n        :type crs: constants.CRS\n        :return: Bounding box in target CRS\n        :rtype: BBox\n        \"\"\"\n        new_crs = CRS(crs)\n        return BBox((transform_point(self.lower_left, self.crs, new_crs),\n                     transform_point(self.upper_right, self.crs, new_crs)), crs=new_crs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new BBox object with the same size and dimensions.", "response": "def buffer(self, buffer):\n        \"\"\" Changes both BBox dimensions (width and height) by a percentage of size of each dimension. If number is\n        negative, the size will decrease. Returns a new instance of BBox object.\n\n        :param buffer: A percentage of BBox size change\n        :type buffer: float\n        :return: A new bounding box of buffered size\n        :rtype: BBox\n        \"\"\"\n        if buffer < -1:\n            raise ValueError('Cannot reduce the bounding box to nothing, buffer must be >= -1.0')\n        ratio = 1 + buffer\n        mid_x, mid_y = self.middle\n        return BBox((mid_x - (mid_x - self.min_x) * ratio, mid_y - (mid_y - self.min_y) * ratio,\n                     mid_x + (self.max_x - mid_x) * ratio, mid_y + (self.max_y - mid_y) * ratio), self.crs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple of coordinates of 5 points describing a polygon.", "response": "def get_polygon(self, reverse=False):\n        \"\"\" Returns a tuple of coordinates of 5 points describing a polygon. Points are listed in clockwise order, first\n        point is the same as the last.\n\n        :param reverse: `True` if x and y coordinates should be switched and `False` otherwise\n        :type reverse: bool\n        :return: `((x_1, y_1), ... , (x_5, y_5))`\n        :rtype: tuple(tuple(float))\n        \"\"\"\n        bbox = self.reverse() if reverse else self\n        polygon = ((bbox.min_x, bbox.min_y),\n                   (bbox.min_x, bbox.max_y),\n                   (bbox.max_x, bbox.max_y),\n                   (bbox.max_x, bbox.min_y),\n                   (bbox.min_x, bbox.min_y))\n        return polygon"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_partition(self, num_x=1, num_y=1):\n        size_x, size_y = (self.max_x - self.min_x) / num_x, (self.max_y - self.min_y) / num_y\n        return [[BBox([self.min_x + i * size_x, self.min_y + j * size_y,\n                       self.min_x + (i + 1) * size_x, self.min_y + (j + 1) * size_y],\n                      crs=self.crs) for j in range(num_y)] for i in range(num_x)]", "response": "Returns a list of parts of the current bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_transform_vector(self, resx, resy):\n        return self.x_min, self._parse_resolution(resx), 0, self.y_max, 0, -self._parse_resolution(resy)", "response": "Given resolution it returns a transformation vector"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the input bbox representation into a flat tuple of size.", "response": "def _to_tuple(bbox):\n        \"\"\" Converts the input bbox representation (see the constructor docstring for a list of valid representations)\n        into a flat tuple\n\n        :param bbox: A bbox in one of 7 forms listed in the class description.\n        :return: A flat tuple of size\n        :raises: TypeError\n        \"\"\"\n        if isinstance(bbox, (list, tuple)):\n            return BBox._tuple_from_list_or_tuple(bbox)\n        if isinstance(bbox, str):\n            return BBox._tuple_from_str(bbox)\n        if isinstance(bbox, dict):\n            return BBox._tuple_from_dict(bbox)\n        if isinstance(bbox, BBox):\n            return BBox._tuple_from_bbox(bbox)\n        if isinstance(bbox, shapely.geometry.base.BaseGeometry):\n            return bbox.bounds\n        raise TypeError('Invalid bbox representation')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a list or tuple representation of a bbox into a flat tuple representation.", "response": "def _tuple_from_list_or_tuple(bbox):\n        \"\"\" Converts a list or tuple representation of a bbox into a flat tuple representation.\n\n        :param bbox: a list or tuple with 4 coordinates that is either flat or nested\n        :return: tuple (min_x,min_y,max_x,max_y)\n        :raises: TypeError\n        \"\"\"\n        if len(bbox) == 4:\n            return tuple(map(float, bbox))\n        if len(bbox) == 2 and all([isinstance(point, (list, tuple)) for point in bbox]):\n            return BBox._tuple_from_list_or_tuple(bbox[0] + bbox[1])\n        raise TypeError('Expected a valid list or tuple representation of a bbox')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _tuple_from_str(bbox):\n        return tuple([float(s) for s in bbox.replace(',', ' ').split() if s])", "response": "Parses a string of numbers separated by any combination of commas and spaces"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new Geometry object where x and y coordinates are switched", "response": "def reverse(self):\n        \"\"\" Returns a new Geometry object where x and y coordinates are switched\n\n        :return: New Geometry object with switched coordinates\n        :rtype: Geometry\n        \"\"\"\n        return Geometry(shapely.ops.transform(lambda x, y: (y, x), self.geometry), crs=self.crs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms the geometry from current CRS to target CRS.", "response": "def transform(self, crs):\n        \"\"\" Transforms Geometry from current CRS to target CRS\n\n        :param crs: target CRS\n        :type crs: constants.CRS\n        :return: Geometry in target CRS\n        :rtype: Geometry\n        \"\"\"\n        new_crs = CRS(crs)\n\n        geometry = self.geometry\n        if new_crs is not self.crs:\n            project = functools.partial(pyproj.transform, self.crs.projection(), new_crs.projection())\n            geometry = shapely.ops.transform(project, geometry)\n\n        return Geometry(geometry, crs=new_crs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses given geometry into shapely polygon or multipolygon", "response": "def _parse_geometry(geometry):\n        \"\"\" Parses given geometry into shapely object\n\n        :param geometry:\n        :return: Shapely polygon or multipolygon\n        :rtype: shapely.geometry.Polygon or shapely.geometry.MultiPolygon\n        :raises TypeError\n        \"\"\"\n        if isinstance(geometry, str):\n            geometry = shapely.wkt.loads(geometry)\n        elif isinstance(geometry, dict):\n            geometry = shapely.geometry.shape(geometry)\n        elif not isinstance(geometry, shapely.geometry.base.BaseGeometry):\n            raise TypeError('Unsupported geometry representation')\n\n        if not isinstance(geometry, (shapely.geometry.Polygon, shapely.geometry.MultiPolygon)):\n            raise ValueError('Supported geometry types are polygon and multipolygon, got {}'.format(type(geometry)))\n\n        return geometry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform BBoxCollection from current CRS to target CRS", "response": "def transform(self, crs):\n        \"\"\" Transforms BBoxCollection from current CRS to target CRS\n\n        :param crs: target CRS\n        :type crs: constants.CRS\n        :return: BBoxCollection in target CRS\n        :rtype: BBoxCollection\n        \"\"\"\n        return BBoxCollection([bbox.transform(crs) for bbox in self.bbox_list])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a multipolygon of bounding box polygons", "response": "def _get_geometry(self):\n        \"\"\" Creates a multipolygon of bounding box polygons\n        \"\"\"\n        return shapely.geometry.MultiPolygon([bbox.geometry for bbox in self.bbox_list])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_data(filename, data_format=None):\n    if not os.path.exists(filename):\n        raise ValueError('Filename {} does not exist'.format(filename))\n\n    if not isinstance(data_format, MimeType):\n        data_format = get_data_format(filename)\n\n    if data_format.is_tiff_format():\n        return read_tiff_image(filename)\n    if data_format is MimeType.JP2:\n        return read_jp2_image(filename)\n    if data_format.is_image_format():\n        return read_image(filename)\n    try:\n        return {\n            MimeType.TXT: read_text,\n            MimeType.CSV: read_csv,\n            MimeType.JSON: read_json,\n            MimeType.XML: read_xml,\n            MimeType.GML: read_xml,\n            MimeType.SAFE: read_xml\n        }[data_format](filename)\n    except KeyError:\n        raise ValueError('Reading data format .{} is not supported'.format(data_format.value))", "response": "Reads image data from file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_jp2_image(filename):\n    # Other option:\n    # return glymur.Jp2k(filename)[:]\n    image = read_image(filename)\n\n    with open(filename, 'rb') as file:\n        bit_depth = get_jp2_bit_depth(file)\n\n    return fix_jp2_image(image, bit_depth)", "response": "Read JPEG2000 file and return it as a string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread data from CSV file into list of objects", "response": "def read_csv(filename, delimiter=CSV_DELIMITER):\n    \"\"\" Read data from CSV file\n\n    :param filename: name of CSV file to be read\n    :type filename: str\n    :param delimiter: type of CSV delimiter. Default is ``;``\n    :type delimiter: str\n    :return: data stored in CSV file as list\n    \"\"\"\n    with open(filename, 'r') as file:\n        return list(csv.reader(file, delimiter=delimiter))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning to write data to file in specified format", "response": "def write_data(filename, data, data_format=None, compress=False, add=False):\n    \"\"\" Write image data to file\n\n    Function to write image data to specified file. If file format is not provided\n    explicitly, it is guessed from the filename extension. If format is TIFF, geo\n    information and compression can be optionally added.\n\n    :param filename: name of file to write data to\n    :type filename: str\n    :param data: image data to write to file\n    :type data: numpy array\n    :param data_format: format of output file. Default is ``None``\n    :type data_format: MimeType\n    :param compress: whether to compress data or not. Default is ``False``\n    :type compress: bool\n    :param add: whether to append to existing text file or not. Default is ``False``\n    :type add: bool\n    :raises: exception if numpy format is not supported or file cannot be written\n    \"\"\"\n    create_parent_folder(filename)\n\n    if not isinstance(data_format, MimeType):\n        data_format = get_data_format(filename)\n\n    if data_format.is_tiff_format():\n        return write_tiff_image(filename, data, compress)\n    if data_format.is_image_format():\n        return write_image(filename, data)\n    if data_format is MimeType.TXT:\n        return write_text(filename, data, add=add)\n\n    try:\n        return {\n            MimeType.CSV: write_csv,\n            MimeType.JSON: write_json,\n            MimeType.XML: write_xml,\n            MimeType.GML: write_xml\n        }[data_format](filename, data)\n    except KeyError:\n        raise ValueError('Writing data format .{} is not supported'.format(data_format.value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_tiff_image(filename, image, compress=False):\n    if compress:\n        return tiff.imsave(filename, image, compress='lzma')  # loseless compression, works very well on masks\n    return tiff.imsave(filename, image)", "response": "Write image data to TIFF file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_image(filename, image):\n    data_format = get_data_format(filename)\n    if data_format is MimeType.JPG:\n        LOGGER.warning('Warning: jpeg is a lossy format therefore saved data will be modified.')\n    return Image.fromarray(image).save(filename)", "response": "Write image data to PNG or JPG file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_text(filename, data, add=False):\n    write_type = 'a' if add else 'w'\n    with open(filename, write_type) as file:\n        print(data, end='', file=file)", "response": "Write image data to text file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_csv(filename, data, delimiter=CSV_DELIMITER):\n    with open(filename, 'w') as file:\n        csv_writer = csv.writer(file, delimiter=delimiter)\n        for line in data:\n            csv_writer.writerow(line)", "response": "Writes image data to CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_json(filename, data):\n    with open(filename, 'w') as file:\n        json.dump(data, file, indent=4, sort_keys=True)", "response": "Write data to JSON file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_jp2_bit_depth(stream):\n    stream.seek(0)\n    while True:\n        read_buffer = stream.read(8)\n        if len(read_buffer) < 8:\n            raise ValueError('Image Header Box not found in Jpeg2000 file')\n\n        _, box_id = struct.unpack('>I4s', read_buffer)\n\n        if box_id == b'ihdr':\n            read_buffer = stream.read(14)\n            params = struct.unpack('>IIHBBBB', read_buffer)\n            return (params[3] & 0x7f) + 1", "response": "Reads bit encoding depth of Jpeg2000 file in binary stream format\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_jp2_image(image, bit_depth):\n    if bit_depth in [8, 16]:\n        return image\n    if bit_depth == 15:\n        try:\n            return image >> 1\n        except TypeError:\n            raise IOError('Failed to read JPEG 2000 image correctly. Most likely reason is that Pillow did not '\n                          'install OpenJPEG library correctly. Try reinstalling Pillow from a wheel')\n\n    raise ValueError('Bit depth {} of jp2 image is currently not supported. '\n                     'Please raise an issue on package Github page'.format(bit_depth))", "response": "This function converts JPEG 2000 images with 15 - bit encoding to 8 - bit encoding and returns corrected image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload all requested data from disk.", "response": "def download_data(request_list, redownload=False, max_threads=None):\n    \"\"\" Download all requested data or read data from disk, if already downloaded and available and redownload is\n    not required.\n\n    :param request_list: list of DownloadRequests\n    :type request_list: list of DownloadRequests\n    :param redownload: if ``True``, download again the data, although it was already downloaded and is available\n                        on the disk. Default is ``False``.\n    :type redownload: bool\n    :param max_threads: number of threads to use when downloading data; default is ``max_threads=None`` which\n            by default uses the number of processors on the system\n    :type max_threads: int\n    :return: list of Futures holding downloaded data, where each element in the list corresponds to an element\n                in the download request list.\n    :rtype: list[concurrent.futures.Future]\n    \"\"\"\n    _check_if_must_download(request_list, redownload)\n\n    LOGGER.debug(\"Using max_threads=%s for %s requests\", max_threads, len(request_list))\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n        return [executor.submit(execute_download_request, request) for request in request_list]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_if_must_download(request_list, redownload):\n    for request in request_list:\n        request.will_download = (request.save_response or request.return_data) \\\n                                and (not request.is_downloaded() or redownload)", "response": "Updates request. will_download attribute of each request in request_list if required."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_download_request(request):\n    if request.save_response and request.data_folder is None:\n        raise ValueError('Data folder is not specified. '\n                         'Please give a data folder name in the initialization of your request.')\n\n    if not request.will_download:\n        return None\n\n    try_num = SHConfig().max_download_attempts\n    response = None\n    while try_num > 0:\n        try:\n            if request.is_aws_s3():\n                response = _do_aws_request(request)\n                response_content = response['Body'].read()\n            else:\n                response = _do_request(request)\n                response.raise_for_status()\n                response_content = response.content\n            LOGGER.debug('Successful download from %s', request.url)\n            break\n        except requests.RequestException as exception:\n            try_num -= 1\n            if try_num > 0 and (_is_temporal_problem(exception) or\n                                (isinstance(exception, requests.HTTPError) and\n                                 exception.response.status_code >= requests.status_codes.codes.INTERNAL_SERVER_ERROR) or\n                                _request_limit_reached(exception)):\n                LOGGER.debug('Download attempt failed: %s\\n%d attempts left, will retry in %ds', exception,\n                             try_num, SHConfig().download_sleep_time)\n                sleep_time = SHConfig().download_sleep_time\n                if _request_limit_reached(exception):\n                    sleep_time = max(sleep_time, 60)\n                time.sleep(sleep_time)\n            else:\n                if request.url.startswith(SHConfig().aws_metadata_url) and \\\n                        isinstance(exception, requests.HTTPError) and \\\n                        exception.response.status_code == requests.status_codes.codes.NOT_FOUND:\n                    raise AwsDownloadFailedException('File in location %s is missing' % request.url)\n                raise DownloadFailedException(_create_download_failed_message(exception, request.url))\n\n    _save_if_needed(request, response_content)\n\n    if request.return_data:\n        return decode_data(response_content, request.data_type, entire_response=response)\n    return None", "response": "Executes download request.\n\n    :param request: DownloadRequest to be executed\n    :type request: DownloadRequest\n    :return: downloaded data or None\n    :rtype: numpy array, other possible data type or None\n    :raises: DownloadFailedException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _do_request(request):\n    if request.request_type is RequestType.GET:\n        return requests.get(request.url, headers=request.headers)\n    if request.request_type is RequestType.POST:\n        return requests.post(request.url, data=json.dumps(request.post_values), headers=request.headers)\n    raise ValueError('Invalid request type {}'.format(request.request_type))", "response": "Executes download request\n    :param request: A request\n    :type request: DownloadRequest\n    :return: Response of the request\n    :rtype: requests.Response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the request from AWS service and returns the response.", "response": "def _do_aws_request(request):\n    \"\"\" Executes download request from AWS service\n    :param request: A request\n    :type request: DownloadRequest\n    :return: Response of the request\n    :rtype: dict\n    :raises: AwsDownloadFailedException, ValueError\n    \"\"\"\n    if SHConfig().aws_access_key_id and SHConfig().aws_secret_access_key:\n        key_args = dict(aws_access_key_id=SHConfig().aws_access_key_id,\n                        aws_secret_access_key=SHConfig().aws_secret_access_key)\n    else:\n        key_args = {}\n    aws_service, _, bucket_name, url_key = request.url.split('/', 3)\n\n    try:\n        s3_client = boto3.Session().client(aws_service.strip(':'), **key_args)\n        request.s3_client = s3_client  # Storing the client prevents warning about unclosed socket\n        DownloadRequest.GLOBAL_AWS_CLIENT = s3_client\n    except KeyError:  # Sometimes creation of client fails and we use the global client if it exists\n        if DownloadRequest.GLOBAL_AWS_CLIENT is None:\n            raise ValueError('Failed to create a client for download from AWS')\n        s3_client = DownloadRequest.GLOBAL_AWS_CLIENT\n\n    try:\n        return s3_client.get_object(Bucket=bucket_name, Key=url_key, RequestPayer='requester')\n    except NoCredentialsError:\n        raise ValueError('The requested data is in Requester Pays AWS bucket. In order to download the data please set '\n                         'your access key either in AWS credentials file or in sentinelhub config.json file using '\n                         'command line:\\n'\n                         '$ sentinelhub.config --aws_access_key_id <your AWS key> --aws_secret_access_key '\n                         '<your AWS secret key>')\n    except s3_client.exceptions.NoSuchKey:\n        raise AwsDownloadFailedException('File in location %s is missing' % request.url)\n    except s3_client.exceptions.NoSuchBucket:\n        raise ValueError('Aws bucket %s does not exist' % bucket_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_temporal_problem(exception):\n    try:\n        return isinstance(exception, (requests.ConnectionError, requests.Timeout))\n    except AttributeError:  # Earlier requests versions might not have requests.Timeout\n        return isinstance(exception, requests.ConnectionError)", "response": "Checks if the exception raised during download is temporal and if download attempt should be repeated\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the exception raised during download is caused because of too many requests.", "response": "def _request_limit_reached(exception):\n    \"\"\" Checks if exception was raised because of too many executed requests. (This is a temporal solution and\n    will be changed in later package versions.)\n\n    :param exception: Exception raised during download\n    :type exception: Exception\n    :return: True if exception is caused because too many requests were executed at once and False otherwise\n    :rtype: bool\n    \"\"\"\n    return isinstance(exception, requests.HTTPError) and \\\n        exception.response.status_code == requests.status_codes.codes.TOO_MANY_REQUESTS"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_download_failed_message(exception, url):\n    message = 'Failed to download from:\\n{}\\nwith {}:\\n{}'.format(url, exception.__class__.__name__, exception)\n\n    if _is_temporal_problem(exception):\n        if isinstance(exception, requests.ConnectionError):\n            message += '\\nPlease check your internet connection and try again.'\n        else:\n            message += '\\nThere might be a problem in connection or the server failed to process ' \\\n                       'your request. Please try again.'\n    elif isinstance(exception, requests.HTTPError):\n        try:\n            server_message = ''\n            for elem in decode_data(exception.response.content, MimeType.XML):\n                if 'ServiceException' in elem.tag or 'Message' in elem.tag:\n                    server_message += elem.text.strip('\\n\\t ')\n        except ElementTree.ParseError:\n            server_message = exception.response.text\n        message += '\\nServer response: \"{}\"'.format(server_message)\n\n    return message", "response": "Creates a message describing why download has failed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _save_if_needed(request, response_content):\n    if request.save_response:\n        file_path = request.get_file_path()\n        create_parent_folder(file_path)\n        with open(file_path, 'wb') as file:\n            file.write(response_content)\n        LOGGER.debug('Saved data from %s to %s', request.url, file_path)", "response": "Save data to disk if requested by the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode_data(response_content, data_type, entire_response=None):\n    LOGGER.debug('data_type=%s', data_type)\n\n    if data_type is MimeType.JSON:\n        if isinstance(entire_response, requests.Response):\n            return entire_response.json()\n        return json.loads(response_content.decode('utf-8'))\n    if MimeType.is_image_format(data_type):\n        return decode_image(response_content, data_type)\n    if data_type is MimeType.XML or data_type is MimeType.GML or data_type is MimeType.SAFE:\n        return ElementTree.fromstring(response_content)\n\n    try:\n        return {\n            MimeType.RAW: response_content,\n            MimeType.TXT: response_content,\n            MimeType.REQUESTS_RESPONSE: entire_response,\n            MimeType.ZIP: BytesIO(response_content)\n        }[data_type]\n    except KeyError:\n        raise ValueError('Unknown response data type {}'.format(data_type))", "response": "Interprets downloaded data and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes the image provided in various formats i. e. png 16 - bit float tiff 32 - bit float tiff jp2 and returns it as numpy array.", "response": "def decode_image(data, image_type):\n    \"\"\" Decodes the image provided in various formats, i.e. png, 16-bit float tiff, 32-bit float tiff, jp2\n        and returns it as an numpy array\n\n    :param data: image in its original format\n    :type data: any of possible image types\n    :param image_type: expected image format\n    :type image_type: constants.MimeType\n    :return: image as numpy array\n    :rtype: numpy array\n    :raises: ImageDecodingError\n    \"\"\"\n    bytes_data = BytesIO(data)\n    if image_type.is_tiff_format():\n        image = tiff.imread(bytes_data)\n    else:\n        image = np.array(Image.open(bytes_data))\n\n        if image_type is MimeType.JP2:\n            try:\n                bit_depth = get_jp2_bit_depth(bytes_data)\n                image = fix_jp2_image(image, bit_depth)\n            except ValueError:\n                pass\n\n    if image is None:\n        raise ImageDecodingError('Unable to decode image')\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading the specified url as JSON data and return the response as a dict.", "response": "def get_json(url, post_values=None, headers=None):\n    \"\"\" Download request as JSON data type\n\n    :param url: url to Sentinel Hub's services or other sources from where the data is downloaded\n    :type url: str\n    :param post_values: form encoded data to send in POST request. Default is ``None``\n    :type post_values: dict\n    :param headers: add HTTP headers to request. Default is ``None``\n    :type headers: dict\n    :return: request response as JSON instance\n    :rtype: JSON instance or None\n    :raises: RunTimeError\n    \"\"\"\n\n    json_headers = {} if headers is None else headers.copy()\n\n    if post_values is None:\n        request_type = RequestType.GET\n    else:\n        request_type = RequestType.POST\n        json_headers = {**json_headers, **{'Content-Type': MimeType.get_string(MimeType.JSON)}}\n\n    request = DownloadRequest(url=url, headers=json_headers, request_type=request_type, post_values=post_values,\n                              save_response=False, return_data=True, data_type=MimeType.JSON)\n\n    return execute_download_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload the XML data from Sentinel Hub s services or other sources from where the data is downloaded", "response": "def get_xml(url):\n    \"\"\" Download request as XML data type\n\n    :param url: url to Sentinel Hub's services or other sources from where the data is downloaded\n    :type url: str\n    :return: request response as XML instance\n    :rtype: XML instance or None\n    :raises: RunTimeError\n    \"\"\"\n    request = DownloadRequest(url=url, request_type=RequestType.GET, save_response=False, return_data=True,\n                              data_type=MimeType.XML)\n\n    return execute_download_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_downloaded(self):\n        if self.file_path is None:\n            return False\n        return os.path.exists(self.file_path)", "response": "Checks if data for this request has already been downloaded and is saved to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets basic information about image tile with given ID.", "response": "def get_tile_info_id(tile_id):\n    \"\"\" Get basic information about image tile\n\n    :param tile_id: original tile identification string provided by ESA (e.g.\n                    'S2A_OPER_MSI_L1C_TL_SGS__20160109T230542_A002870_T10UEV_N02.01')\n    :type tile_id: str\n    :return: dictionary with info provided by Opensearch REST service or ``None`` if such tile does not exist on AWS.\n    :rtype: dict or None\n    :raises: TileMissingException if no tile with tile ID `tile_id` exists\n    \"\"\"\n    result_list = list(search_iter(tile_id=tile_id))\n\n    if not result_list:\n        raise TileMissingException\n\n    if len(result_list) > 1:\n        LOGGER.warning('Obtained %d results for tile_id=%d. Returning the first one', len(result_list), tile_id)\n\n    return result_list[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget basic information about image tile on AWS.", "response": "def get_tile_info(tile, time, aws_index=None, all_tiles=False):\n    \"\"\" Get basic information about image tile\n\n    :param tile: tile name (e.g. ``'T10UEV'``)\n    :type tile: str\n    :param time: A single date or a time interval, times have to be in ISO 8601 string\n    :type time: str or (str, str)\n    :param aws_index: index of tile on AWS\n    :type aws_index: int or None\n    :param all_tiles: If ``True`` it will return list of all tiles otherwise only the first one\n    :type all_tiles: bool\n    :return: dictionary with info provided by Opensearch REST service or None if such tile does not exist on AWS.\n    :rtype: dict or None\n    \"\"\"\n    start_date, end_date = parse_time_interval(time)\n\n    candidates = []\n    for tile_info in search_iter(start_date=start_date, end_date=end_date):\n        path_props = tile_info['properties']['s3Path'].split('/')\n        this_tile = ''.join(path_props[1: 4])\n        this_aws_index = int(path_props[-1])\n        if this_tile == tile.lstrip('T0') and (aws_index is None or aws_index == this_aws_index):\n            candidates.append(tile_info)\n\n    if not candidates:\n        raise TileMissingException\n\n    if len(candidates) > 1:\n        LOGGER.info('Obtained %d results for tile=%s, time=%s. Returning the first one', len(candidates), tile, time)\n    if all_tiles:\n        return candidates\n    return candidates[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget information about all images from the specified area and time range.", "response": "def get_area_info(bbox, date_interval, maxcc=None):\n    \"\"\" Get information about all images from specified area and time range\n\n    :param bbox: bounding box of requested area\n    :type bbox: geometry.BBox\n    :param date_interval: a pair of time strings in ISO8601 format\n    :type date_interval: tuple(str)\n    :param maxcc: filter images by maximum percentage of cloud coverage\n    :type maxcc: float in range [0, 1] or None\n    :return: list of dictionaries containing info provided by Opensearch REST service\n    :rtype: list(dict)\n    \"\"\"\n    result_list = search_iter(bbox=bbox, start_date=date_interval[0], end_date=date_interval[1])\n    if maxcc:\n        return reduce_by_maxcc(result_list, maxcc)\n    return result_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of times of existing images from specified area and time range", "response": "def get_area_dates(bbox, date_interval, maxcc=None):\n    \"\"\" Get list of times of existing images from specified area and time range\n\n    :param bbox: bounding box of requested area\n    :type bbox: geometry.BBox\n    :param date_interval: a pair of time strings in ISO8601 format\n    :type date_interval: tuple(str)\n    :param maxcc: filter images by maximum percentage of cloud coverage\n    :type maxcc: float in range [0, 1] or None\n    :return: list of time strings in ISO8601 format\n    :rtype: list[datetime.datetime]\n    \"\"\"\n\n    area_info = get_area_info(bbox, date_interval, maxcc=maxcc)\n    return sorted({datetime.datetime.strptime(tile_info['properties']['startDate'].strip('Z'),\n                                              '%Y-%m-%dT%H:%M:%S')\n                   for tile_info in area_info})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_iter(tile_id=None, bbox=None, start_date=None, end_date=None, absolute_orbit=None):\n    if bbox and bbox.crs is not CRS.WGS84:\n        bbox = bbox.transform(CRS.WGS84)\n\n    url_params = _prepare_url_params(tile_id, bbox, end_date, start_date, absolute_orbit)\n    url_params['maxRecords'] = SHConfig().max_opensearch_records_per_query\n\n    start_index = 1\n\n    while True:\n        url_params['index'] = start_index\n\n        url = '{}search.json?{}'.format(SHConfig().opensearch_url, urlencode(url_params))\n        LOGGER.debug(\"URL=%s\", url)\n\n        response = get_json(url)\n        for tile_info in response[\"features\"]:\n            yield tile_info\n\n        if len(response[\"features\"]) < SHConfig().max_opensearch_records_per_query:\n            break\n        start_index += SHConfig().max_opensearch_records_per_query", "response": "A generator function that implements OpenSearch search queries and returns results for a specific tile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_url_params(tile_id, bbox, end_date, start_date, absolute_orbit):\n    url_params = {\n        'identifier': tile_id,\n        'startDate': start_date,\n        'completionDate': end_date,\n        'orbitNumber': absolute_orbit,\n        'box': bbox\n    }\n    return {key: str(value) for key, value in url_params.items() if value}", "response": "Constructs a dictionary with URL params as properties when arguments not None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _edit_name(name, code, add_code=None, delete_end=False):\n    info = name.split('_')\n    info[2] = code\n    if add_code is not None:\n        info[3] = add_code\n    if delete_end:\n        info.pop()\n    return '_'.join(info)", "response": "Edit the name of a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate product structure and returns list of files for download", "response": "def get_requests(self):\n        \"\"\"\n        Creates product structure and returns list of files for download\n\n        :return: list of download requests\n        :rtype: list(download.DownloadRequest)\n        \"\"\"\n        safe = self.get_safe_struct()\n\n        self.download_list = []\n        self.structure_recursion(safe, self.parent_folder)\n        self.sort_download_list()\n        return self.download_list, self.folder_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a nested dictionary representing the structure of the current product.", "response": "def get_safe_struct(self):\n        \"\"\"\n        Describes a structure inside tile folder of ESA product .SAFE structure\n\n        :return: nested dictionaries representing .SAFE structure\n        :rtype: dict\n        \"\"\"\n        safe = {}\n        main_folder = self.get_main_folder()\n        safe[main_folder] = {}\n\n        safe[main_folder][AwsConstants.AUX_DATA] = {}\n\n        safe[main_folder][AwsConstants.DATASTRIP] = {}\n        datastrip_list = self.get_datastrip_list()\n        for datastrip_folder, datastrip_url in datastrip_list:\n            safe[main_folder][AwsConstants.DATASTRIP][datastrip_folder] = {}\n            safe[main_folder][AwsConstants.DATASTRIP][datastrip_folder][AwsConstants.QI_DATA] = {}\n            # S-2 L1C reports are on AWS only stored with tiles and without RADIOMETRIC_QUALITY\n            if self.has_reports() and self.data_source is DataSource.SENTINEL2_L2A:\n                for metafile in AwsConstants.QUALITY_REPORTS:\n                    metafile_name = self.add_file_extension(metafile)\n                    safe[main_folder][AwsConstants.DATASTRIP][datastrip_folder][AwsConstants.QI_DATA][\n                        metafile_name] = '{}/qi/{}'.format(datastrip_url, metafile_name)\n\n            safe[main_folder][AwsConstants.DATASTRIP][datastrip_folder][\n                self.get_datastrip_metadata_name(datastrip_folder)] = '{}/{}'.format(\n                    datastrip_url, self.add_file_extension(AwsConstants.METADATA))\n\n        safe[main_folder][AwsConstants.GRANULE] = {}\n\n        for tile_info in self.product_info['tiles']:\n            tile_name, date, aws_index = self.url_to_tile(self.get_tile_url(tile_info))\n            if self.tile_list is None or AwsTile.parse_tile_name(tile_name) in self.tile_list:\n                tile_struct = SafeTile(tile_name, date, aws_index, parent_folder=None, bands=self.bands,\n                                       metafiles=self.metafiles, data_source=self.data_source).get_safe_struct()\n                for tile_name, safe_struct in tile_struct.items():\n                    safe[main_folder][AwsConstants.GRANULE][tile_name] = safe_struct\n\n        safe[main_folder][AwsConstants.HTML] = {}  # AWS doesn't have this data\n        safe[main_folder][AwsConstants.INFO] = {}  # AWS doesn't have this data\n\n        safe[main_folder][self.get_product_metadata_name()] = self.get_url(AwsConstants.METADATA)\n        safe[main_folder]['INSPIRE.xml'] = self.get_url(AwsConstants.INSPIRE)\n        safe[main_folder][self.add_file_extension(AwsConstants.MANIFEST)] = self.get_url(AwsConstants.MANIFEST)\n\n        if self.is_early_compact_l2a():\n            safe[main_folder]['L2A_Manifest.xml'] = self.get_url(AwsConstants.L2A_MANIFEST)\n            safe[main_folder][self.get_report_name()] = self.get_url(AwsConstants.REPORT)\n\n        if self.safe_type == EsaSafeType.OLD_TYPE and self.baseline != '02.02':\n            safe[main_folder][_edit_name(self.product_id, 'BWI') + '.png'] = self.get_url(AwsConstants.PREVIEW,\n                                                                                          MimeType.PNG)\n        return safe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_datastrip_list(self):\n        datastrips = self.product_info['datastrips']\n        return [(self.get_datastrip_name(datastrip['id']), self.base_url + datastrip['path'])\n                for datastrip in datastrips]", "response": "returns list of datastrips folder names and urls from productInfo. json file\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_datastrip_name(self, datastrip):\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            return datastrip\n        return '_'.join(datastrip.split('_')[4:-1])", "response": "returns the name of datastrip"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the datastrip metadata name.", "response": "def get_datastrip_metadata_name(self, datastrip_folder):\n        \"\"\"\n        :param datastrip_folder: name of datastrip folder\n        :type: str\n        :return: name of datastrip metadata file\n        :rtype: str\n        \"\"\"\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = _edit_name(datastrip_folder, 'MTD', delete_end=True)\n        else:\n            name = 'MTD_DS'\n        return '{}.{}'.format(name, MimeType.XML.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_product_metadata_name(self):\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = _edit_name(self.product_id, 'MTD', 'SAFL1C')\n        else:\n            name = 'MTD_{}'.format(self.product_id.split('_')[1])\n        return '{}.{}'.format(name, MimeType.XML.value)", "response": "Get the name of the product metadata file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_report_name(self):\n        return '{}_{}_report.{}'.format(self.product_id, self.get_report_time(), MimeType.XML.value)", "response": "Returns the name of the report file of the L2A products"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the time when the L2A processing started and reports were created.", "response": "def get_report_time(self):\n        \"\"\" Returns time when the L2A processing started and reports was created.\n        :return: String in a form YYYYMMDDTHHMMSS\n        :rtype: str\n        \"\"\"\n        tree = get_xml(self.get_url(AwsConstants.REPORT))\n\n        try:\n            timestamp = tree.find('check/inspection').attrib['execution']\n            return timestamp.split(',')[0].replace(' ', 'T').replace(':', '').replace('-', '')\n        except AttributeError:\n            warnings.warn('Could not obtain the L2A report creation time')\n            return 'unknown'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_safe_struct(self):\n        # pylint: disable=too-many-branches\n        safe = {}\n        main_folder = self.get_main_folder()\n        safe[main_folder] = {}\n\n        safe[main_folder][AwsConstants.AUX_DATA] = {}\n        # Not sure if 2nd condition of the following is correct:\n        if self.data_source is not DataSource.SENTINEL2_L1C or self.baseline != '02.04':\n            ecmwft_file = AwsConstants.ECMWFT if self.data_source is DataSource.SENTINEL2_L1C or \\\n                                                 self.safe_type is EsaSafeType.OLD_TYPE else AwsConstants.AUX_ECMWFT\n            safe[main_folder][AwsConstants.AUX_DATA][self.get_aux_data_name()] = self.get_url(ecmwft_file)\n        # Old products also have DEM and MSI in aux folder\n\n        if self.is_early_compact_l2a():\n            safe[main_folder][AwsConstants.AUX_DATA][self.add_file_extension(AwsConstants.GIPP, remove_path=True)] =\\\n                self.get_url(AwsConstants.GIPP)\n\n        safe[main_folder][AwsConstants.IMG_DATA] = {}\n        if self.data_source is DataSource.SENTINEL2_L1C:\n            for band in self.bands:\n                safe[main_folder][AwsConstants.IMG_DATA][self.get_img_name(band)] = self.get_url(band)\n            if self.safe_type == EsaSafeType.COMPACT_TYPE:\n                safe[main_folder][AwsConstants.IMG_DATA][self.get_img_name(AwsConstants.TCI)] =\\\n                    self.get_url(AwsConstants.TCI)\n        else:\n            for resolution in AwsConstants.RESOLUTIONS:\n                safe[main_folder][AwsConstants.IMG_DATA][resolution] = {}\n            for band_name in self.bands:\n                resolution, band = band_name.split('/')\n                if self._band_exists(band_name):\n                    safe[main_folder][AwsConstants.IMG_DATA][resolution][self.get_img_name(band, resolution)] =\\\n                        self.get_url(band_name)\n\n        safe[main_folder][AwsConstants.QI_DATA] = {}\n        safe[main_folder][AwsConstants.QI_DATA][self.get_qi_name('CLOUDS')] = self.get_gml_url('CLOUDS')\n        for qi_type in AwsConstants.QI_LIST:\n            for band in AwsConstants.S2_L1C_BANDS:\n                safe[main_folder][AwsConstants.QI_DATA][self.get_qi_name(qi_type, band)] = self.get_gml_url(qi_type,\n                                                                                                            band)\n\n        if self.has_reports():\n            for metafile in [AwsConstants.FORMAT_CORRECTNESS, AwsConstants.GENERAL_QUALITY,\n                             AwsConstants.GEOMETRIC_QUALITY, AwsConstants.SENSOR_QUALITY]:\n                metafile_name = self.add_file_extension(metafile, remove_path=True)\n                safe[main_folder][AwsConstants.QI_DATA][metafile_name] = self.get_qi_url(metafile_name)\n\n        if self.data_source is DataSource.SENTINEL2_L2A:\n            for mask in AwsConstants.CLASS_MASKS:\n                for resolution in [AwsConstants.R20m, AwsConstants.R60m]:\n                    if self.baseline <= '02.06':\n                        mask_name = self.get_img_name(mask, resolution)\n                    else:\n                        mask_name = self.get_qi_name('{}PRB'.format(mask), resolution.lstrip('R'), MimeType.JP2)\n                    safe[main_folder][AwsConstants.QI_DATA][mask_name] =\\\n                        self.get_qi_url('{}_{}.jp2'.format(mask, resolution.lstrip('R')))\n\n        if self.is_early_compact_l2a():\n            safe[main_folder][AwsConstants.QI_DATA][self.get_img_name(AwsConstants.PVI)] = self.get_preview_url('L2A')\n\n        preview_type = 'L2A' if self.data_source is DataSource.SENTINEL2_L2A and self.baseline >= '02.07' else 'L1C'\n        safe[main_folder][AwsConstants.QI_DATA][self.get_preview_name()] = self.get_preview_url(preview_type)\n\n        safe[main_folder][self.get_tile_metadata_name()] = self.get_url(AwsConstants.METADATA)\n\n        return safe", "response": "Returns a nested dictionary representing the structure of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tile_id(self):\n        tree = get_xml(self.get_url(AwsConstants.METADATA))\n\n        tile_id_tag = 'TILE_ID_2A' if self.data_source is DataSource.SENTINEL2_L2A and self.baseline <= '02.06' else\\\n            'TILE_ID'\n        tile_id = tree[0].find(tile_id_tag).text\n        if self.safe_type is not EsaSafeType.OLD_TYPE:\n            info = tile_id.split('_')\n            tile_id = '_'.join([info[3], info[-2], info[-3], self.get_sensing_time()])\n        return tile_id", "response": "Creates ESA tile ID from ESA metadata file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the name of the tile metadata file.", "response": "def get_tile_metadata_name(self):\n        \"\"\"\n        :return: name of tile metadata file\n        :rtype: str\n        \"\"\"\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = _edit_name(self.tile_id, 'MTD', delete_end=True)\n        else:\n            name = 'MTD_TL'\n        return '{}.xml'.format(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_img_name(self, band, resolution=None):\n        band = band.split('/')[-1]\n        if self.safe_type is EsaSafeType.OLD_TYPE:\n            name = self.tile_id.rsplit('_', 1)[0] + '_' + band\n        else:\n            name = '_'.join([self.tile_id.split('_')[1], self.get_datatake_time(), band])\n        if self.data_source is DataSource.SENTINEL2_L2A and resolution is not None:\n            name = '{}_{}'.format(name, resolution.lstrip('R'))\n        if self.data_source is DataSource.SENTINEL2_L2A and self.baseline <= '02.06':\n            name = 'L2A_{}'.format(name)\n        return '{}.jp2'.format(name)", "response": "Returns the name of the image file for the specified band and resolution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the name of the quality indicator entry.", "response": "def get_qi_name(self, qi_type, band='B00', data_format=MimeType.GML):\n        \"\"\"\n        :param qi_type: type of quality indicator\n        :type qi_type: str\n        :param band: band name\n        :type band: str\n        :param data_format: format of the file\n        :type data_format: MimeType\n        :return: name of gml file\n        :rtype: str\n        \"\"\"\n        band = band.split('/')[-1]\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = _edit_name(self.tile_id, 'MSK', delete_end=True)\n            source_param = '{}_TL'.format('L1C' if self.data_source is DataSource.SENTINEL2_L1C else 'L2A')\n            name = name.replace(source_param, qi_type)\n            name = '{}_{}_MSIL1C'.format(name, band)\n        else:\n            name = 'MSK_{}_{}'.format(qi_type, band)\n        return '{}.{}'.format(name, data_format.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_preview_name(self):\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = _edit_name(self.tile_id, AwsConstants.PVI, delete_end=True)\n        else:\n            name = '_'.join([self.tile_id.split('_')[1], self.get_datatake_time(), AwsConstants.PVI])\n        return '{}.jp2'.format(name)", "response": "Returns.SAFE name of full resolution L1C preview file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_shape_list(shape_list, crs):\n        if not isinstance(shape_list, list):\n            raise ValueError('Splitter must be initialized with a list of shapes')\n\n        return [AreaSplitter._parse_shape(shape, crs) for shape in shape_list]", "response": "Checks if the given list of shapes is in correct format and parses geometry objects\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bbox_list(self, crs=None, buffer=None, reduce_bbox_sizes=None):\n        bbox_list = self.bbox_list\n        if buffer:\n            bbox_list = [bbox.buffer(buffer) for bbox in bbox_list]\n\n        if reduce_bbox_sizes is None:\n            reduce_bbox_sizes = self.reduce_bbox_sizes\n        if reduce_bbox_sizes:\n            bbox_list = self._reduce_sizes(bbox_list)\n\n        if crs:\n            return [bbox.transform(crs) for bbox in bbox_list]\n        return bbox_list", "response": "Returns a list of bounding boxes that are the result of the split\nCOOKIE command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a bounding box of the entire area of the splitter.", "response": "def get_area_bbox(self, crs=None):\n        \"\"\"Returns a bounding box of the entire area\n\n        :param crs: Coordinate reference system in which the bounding box should be returned. If None the CRS will\n                    be the default CRS of the splitter.\n        :type crs: CRS or None\n        :return: A bounding box of the area defined by the `shape_list`\n        :rtype: BBox\n        \"\"\"\n        bbox_list = [BBox(shape.bounds, crs=self.crs) for shape in self.shape_list]\n        area_minx = min([bbox.lower_left[0] for bbox in bbox_list])\n        area_miny = min([bbox.lower_left[1] for bbox in bbox_list])\n        area_maxx = max([bbox.upper_right[0] for bbox in bbox_list])\n        area_maxy = max([bbox.upper_right[1] for bbox in bbox_list])\n        bbox = BBox([area_minx, area_miny, area_maxx, area_maxy], crs=self.crs)\n        if crs is None:\n            return bbox\n        return bbox.transform(crs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform a bounding box into a shapely. geometry. polygon. Polygon object in the area CRS.", "response": "def _bbox_to_area_polygon(self, bbox):\n        \"\"\"Transforms bounding box into a polygon object in the area CRS.\n\n        :param bbox: A bounding box\n        :type bbox: BBox\n        :return: A polygon\n        :rtype: shapely.geometry.polygon.Polygon\n        \"\"\"\n        projected_bbox = bbox.transform(self.crs)\n        return projected_bbox.geometry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreducing sizes of bounding boxes in a list of sets", "response": "def _reduce_sizes(self, bbox_list):\n        \"\"\"Reduces sizes of bounding boxes\n        \"\"\"\n        return [BBox(self._intersection_area(bbox).bounds, self.crs).transform(bbox.crs) for bbox in bbox_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_split_shape(split_shape):\n        if isinstance(split_shape, int):\n            return split_shape, split_shape\n        if isinstance(split_shape, (tuple, list)):\n            if len(split_shape) == 2 and isinstance(split_shape[0], int) and isinstance(split_shape[1], int):\n                return split_shape[0], split_shape[1]\n            raise ValueError(\"Content of split_shape {} must be 2 integers.\".format(split_shape))\n        raise ValueError(\"Split shape must be an int or a tuple of 2 integers.\")", "response": "Parses the split_shape from class initialization\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the area bounding box is completely inside the OSM grid.", "response": "def _check_area_bbox(self):\n        \"\"\"The method checks if the area bounding box is completely inside the OSM grid. That means that its latitudes\n        must be contained in the interval (-85.0511, 85.0511)\n\n        :raises: ValueError\n        \"\"\"\n        for coord in self.area_bbox:\n            if abs(coord) > self.POP_WEB_MAX:\n                raise ValueError('OsmTileSplitter only works for areas which have latitude in interval '\n                                 '(-85.0511, 85.0511)')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_world_bbox(self):\n        return BBox((-self.POP_WEB_MAX, -self.POP_WEB_MAX, self.POP_WEB_MAX, self.POP_WEB_MAX), crs=CRS.POP_WEB)", "response": "Creates a bounding box of the entire world in EPSG 3857"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_split(self):\n        self.tile_dict = {}\n\n        wfs = WebFeatureService(self.area_bbox, self.time_interval, data_source=self.data_source,\n                                instance_id=self.instance_id)\n        date_list = wfs.get_dates()\n        geometry_list = wfs.get_geometries()\n        for tile_info, (date, geometry) in zip(wfs, zip(date_list, geometry_list)):\n            tile_name = ''.join(tile_info['properties']['path'].split('/')[4:7])\n            if tile_name not in self.tile_dict:\n                self.tile_dict[tile_name] = {'bbox': BBox(tile_info['properties']['mbr'],\n                                                          crs=tile_info['properties']['crs']),\n                                             'times': [],\n                                             'geometries': []}\n            self.tile_dict[tile_name]['times'].append(date)\n            self.tile_dict[tile_name]['geometries'].append(geometry)\n\n        self.tile_dict = {tile_name: tile_props for tile_name, tile_props in self.tile_dict.items() if\n                          self._intersects_area(tile_props['bbox'])}\n\n        self.bbox_list = []\n        self.info_list = []\n\n        for tile_name, tile_info in self.tile_dict.items():\n            tile_bbox = tile_info['bbox']\n            bbox_splitter = BBoxSplitter([tile_bbox.geometry], tile_bbox.crs,\n                                         split_shape=self.tile_split_shape)\n\n            for bbox, info in zip(bbox_splitter.get_bbox_list(), bbox_splitter.get_info_list()):\n                if self._intersects_area(bbox):\n                    info['tile'] = tile_name\n\n                    self.bbox_list.append(bbox)\n                    self.info_list.append(info)", "response": "This method makes the split of the area into two lists of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_split(self):\n        self.bbox_list = []\n        self.info_list = []\n\n        for grid_idx, grid_bbox in enumerate(self.bbox_grid):\n            if self._intersects_area(grid_bbox):\n\n                bbox_splitter = BBoxSplitter([grid_bbox.geometry], grid_bbox.crs,\n                                             split_shape=self.bbox_split_shape)\n\n                for bbox, info in zip(bbox_splitter.get_bbox_list(), bbox_splitter.get_info_list()):\n                    if self._intersects_area(bbox):\n                        info['grid_index'] = grid_idx\n\n                        self.bbox_list.append(bbox)\n                        self.info_list.append(info)", "response": "This method makes the split of the records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_bands(self, band_input):\n        all_bands = AwsConstants.S2_L1C_BANDS if self.data_source is DataSource.SENTINEL2_L1C else \\\n            AwsConstants.S2_L2A_BANDS\n\n        if band_input is None:\n            return all_bands\n        if isinstance(band_input, str):\n            band_list = band_input.split(',')\n        elif isinstance(band_input, list):\n            band_list = band_input.copy()\n        else:\n            raise ValueError('bands parameter must be a list or a string')\n        band_list = [band.strip().split('.')[0] for band in band_list]\n        band_list = [band for band in band_list if band != '']\n        if not set(band_list) <= set(all_bands):\n            raise ValueError('bands {} must be a subset of {}'.format(band_list, all_bands))\n        return band_list", "response": "Parses class input and verifies band names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_metafiles(self, metafile_input):\n        all_metafiles = AwsConstants.S2_L1C_METAFILES if self.data_source is DataSource.SENTINEL2_L1C else \\\n            AwsConstants.S2_L2A_METAFILES\n\n        if metafile_input is None:\n            if self.__class__.__name__ == 'SafeProduct':\n                return all_metafiles\n            if self.__class__.__name__ == 'SafeTile':\n                return [metafile for metafile in all_metafiles if metafile in AwsConstants.TILE_FILES]\n            return []\n        if isinstance(metafile_input, str):\n            metafile_list = metafile_input.split(',')\n        elif isinstance(metafile_input, list):\n            metafile_list = metafile_input.copy()\n        else:\n            raise ValueError('metafiles parameter must be a list or a string')\n        metafile_list = [metafile.strip().split('.')[0] for metafile in metafile_list]\n        metafile_list = [metafile for metafile in metafile_list if metafile != '']\n        if not set(metafile_list) <= set(all_metafiles):\n            raise ValueError('metadata files {} must be a subset of {}'.format(metafile_list, all_metafiles))\n        return metafile_list", "response": "Parses class input and verifies metadata file names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_base_url(self, force_http=False):\n        base_url = SHConfig().aws_metadata_url.rstrip('/') if force_http else 's3:/'\n        aws_bucket = SHConfig().aws_s3_l1c_bucket if self.data_source is DataSource.SENTINEL2_L1C else \\\n            SHConfig().aws_s3_l2a_bucket\n\n        return '{}/{}/'.format(base_url, aws_bucket)", "response": "Creates base URL path for the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the type of ESA product.", "response": "def get_safe_type(self):\n        \"\"\"Determines the type of ESA product.\n\n        In 2016 ESA changed structure and naming of data. Therefore the class must\n        distinguish between old product type and compact (new) product type.\n\n        :return: type of ESA product\n        :rtype: constants.EsaSafeType\n        :raises: ValueError\n        \"\"\"\n        product_type = self.product_id.split('_')[1]\n        if product_type.startswith('MSI'):\n            return EsaSafeType.COMPACT_TYPE\n        if product_type in ['OPER', 'USER']:\n            return EsaSafeType.OLD_TYPE\n        raise ValueError('Unrecognized product type of product id {}'.format(self.product_id))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_baseline(self):\n        if self.safe_type is EsaSafeType.COMPACT_TYPE:\n            baseline = self.product_id.split('_')[3].lstrip('N')\n            if len(baseline) != 4:\n                raise ValueError('Unable to recognize baseline number from the product id {}'.format(self.product_id))\n            return '{}.{}'.format(baseline[:2], baseline[2:])\n        return self._read_baseline_from_info()", "response": "Determines the baseline number of the ESA.SAFE product."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to find and return baseline number from either tileInfo or productInfo file.", "response": "def _read_baseline_from_info(self):\n        \"\"\"Tries to find and return baseline number from either tileInfo or productInfo file.\n\n        :return: Baseline ID\n        :rtype: str\n        :raises: ValueError\n        \"\"\"\n        if hasattr(self, 'tile_info'):\n            return self.tile_info['datastrip']['id'][-5:]\n        if hasattr(self, 'product_info'):\n            return self.product_info['datastrips'][0]['id'][-5:]\n        raise ValueError('No info file has been obtained yet.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_to_tile(url):\n        info = url.strip('/').split('/')\n        name = ''.join(info[-7: -4])\n        date = '-'.join(info[-4: -1])\n        return name, date, int(info[-1])", "response": "Extracts tile name date and AWS index from url on AWS."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort_download_list(self):\n        def aws_sort_function(download_request):\n            data_name = download_request.properties['data_name']\n            if 'product_name' in download_request.properties:\n                product_name = download_request.properties['product_name']\n            else:\n                product_name = self._url_to_props(download_request.url)[0]\n            if data_name in self.bands:\n                return 0, product_name, self.bands.index(data_name)\n            return 1, product_name, self.metafiles.index(data_name)\n        self.download_list.sort(key=aws_sort_function)", "response": "Method for sorting the list of download requests."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef structure_recursion(self, struct, folder):\n        has_subfolder = False\n        for name, substruct in struct.items():\n            subfolder = os.path.join(folder, name)\n            if not isinstance(substruct, dict):\n                product_name, data_name = self._url_to_props(substruct)\n                if '.' in data_name:\n                    data_type = MimeType(data_name.split('.')[-1])\n                    data_name = data_name.rsplit('.', 1)[0]\n                else:\n                    data_type = MimeType.RAW\n                if data_name in self.bands + self.metafiles:\n                    self.download_list.append(DownloadRequest(url=substruct, filename=subfolder, data_type=data_type,\n                                                              data_name=data_name, product_name=product_name))\n            else:\n                has_subfolder = True\n                self.structure_recursion(substruct, subfolder)\n        if not has_subfolder:\n            self.folder_list.append(folder)", "response": "Recursively extracts all the files that need to be downloaded and stores them into the list of download requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _url_to_props(self, url):\n        props = (url[len(self.base_url):] if url.startswith(self.base_url) else\n                 url[len(self.base_http_url):]).split('/')\n        if props[0] == 'products':\n            tile_props = props[:5]\n            props = props[5:]\n            if props[0] == 'datastrip':\n                props[1] = '*'\n        else:\n            tile_props = props[:8]\n            props = props[8:]\n        return '/'.join(tile_props), '/'.join(props)", "response": "Converts url to name of product or tile and name of a file\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\njoin filename and corresponding file extension if it has one.", "response": "def add_file_extension(filename, data_format=None, remove_path=False):\n        \"\"\"Joins filename and corresponding file extension if it has one.\n\n        :param filename: Name of the file without extension\n        :type filename: str\n        :param data_format: format of file, if None it will be set automatically\n        :type data_format: constants.MimeType or None\n        :param remove_path: True if the path in filename string should be removed\n        :type remove_path: bool\n        :return: Name of the file with extension\n        :rtype: str\n        \"\"\"\n        if data_format is None:\n            data_format = AwsConstants.AWS_FILES[filename]\n        if remove_path:\n            filename = filename.split('/')[-1]\n        if filename.startswith('datastrip'):\n            filename = filename.replace('*', '0')\n        if data_format is MimeType.RAW:\n            return filename\n        return '{}.{}'.format(filename.replace('*', ''), data_format.value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_early_compact_l2a(self):\n        return self.data_source is DataSource.SENTINEL2_L2A and self.safe_type is EsaSafeType.COMPACT_TYPE and \\\n            self.baseline <= '02.06'", "response": "Check if product is early version of compact L2A product and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse class input and verifies band names.", "response": "def parse_tile_list(tile_input):\n        \"\"\"\n        Parses class input and verifies band names.\n\n        :param tile_input: class input parameter `tile_list`\n        :type tile_input: str or list(str)\n        :return: parsed list of tiles\n        :rtype: list(str) or None\n        \"\"\"\n        if tile_input is None:\n            return None\n        if isinstance(tile_input, str):\n            tile_list = tile_input.split(',')\n        elif isinstance(tile_input, list):\n            tile_list = tile_input.copy()\n        else:\n            raise ValueError('tile_list parameter must be a list of tile names')\n        tile_list = [AwsTile.parse_tile_name(tile_name) for tile_name in tile_list]\n        return tile_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates product structure and returns list of files for download and list of empty folders that need to be created.", "response": "def get_requests(self):\n        \"\"\"\n        Creates product structure and returns list of files for download.\n\n        :return: List of download requests and list of empty folders that need to be created\n        :rtype: (list(download.DownloadRequest), list(str))\n        \"\"\"\n        self.download_list = [DownloadRequest(url=self.get_url(metafile), filename=self.get_filepath(metafile),\n                                              data_type=AwsConstants.AWS_FILES[metafile], data_name=metafile) for\n                              metafile in self.metafiles if metafile in AwsConstants.PRODUCT_FILES]\n\n        tile_parent_folder = os.path.join(self.parent_folder, self.product_id)\n        for tile_info in self.product_info['tiles']:\n            tile_name, date, aws_index = self.url_to_tile(self.get_tile_url(tile_info))\n            if self.tile_list is None or AwsTile.parse_tile_name(tile_name) in self.tile_list:\n                tile_downloads, tile_folders = AwsTile(tile_name, date, aws_index, parent_folder=tile_parent_folder,\n                                                       bands=self.bands, metafiles=self.metafiles,\n                                                       data_source=self.data_source).get_requests()\n                self.download_list.extend(tile_downloads)\n                self.folder_list.extend(tile_folders)\n        self.sort_download_list()\n        return self.download_list, self.folder_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_data_source(self):\n        product_type = self.product_id.split('_')[1]\n        if product_type.endswith('L1C') or product_type == 'OPER':\n            return DataSource.SENTINEL2_L1C\n        if product_type.endswith('L2A') or product_type == 'USER':\n            return DataSource.SENTINEL2_L2A\n        raise ValueError('Unknown data source of product {}'.format(self.product_id))", "response": "The method determines the data source of the product ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollect sensing date of the product.", "response": "def get_date(self):\n        \"\"\" Collects sensing date of the product.\n\n        :return: Sensing date\n        :rtype: str\n        \"\"\"\n        if self.safe_type == EsaSafeType.OLD_TYPE:\n            name = self.product_id.split('_')[-2]\n            date = [name[1:5], name[5:7], name[7:9]]\n        else:\n            name = self.product_id.split('_')[2]\n            date = [name[:4], name[4:6], name[6:8]]\n        return '-'.join(date_part.lstrip('0') for date_part in date)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_url(self, filename, data_format=None):\n        product_url = self.product_url\n        force_http = filename in [AwsConstants.PRODUCT_INFO, AwsConstants.METADATA]\n        if product_url is None or force_http:\n            product_url = self.get_product_url(force_http=force_http)\n        return '{}/{}'.format(product_url, self.add_file_extension(filename, data_format))", "response": "Creates url of file location on AWS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_product_url(self, force_http=False):\n        base_url = self.base_http_url if force_http else self.base_url\n        return '{}products/{}/{}'.format(base_url, self.date.replace('-', '/'), self.product_id)", "response": "Creates base url of product location on AWS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_filepath(self, filename):\n        return os.path.join(self.parent_folder, self.product_id, self.add_file_extension(filename)).replace(':', '.')", "response": "Creates file path for the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_tile_name(name):\n        tile_name = name.lstrip('T0')\n        if len(tile_name) == 4:\n            tile_name = '0' + tile_name\n        if len(tile_name) != 5:\n            raise ValueError('Invalid tile name {}'.format(name))\n        return tile_name", "response": "Parses and verifies tile name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_requests(self):\n        self.download_list = []\n        for data_name in [band for band in self.bands if self._band_exists(band)] + self.metafiles:\n            if data_name in AwsConstants.TILE_FILES:\n                url = self.get_url(data_name)\n                filename = self.get_filepath(data_name)\n                self.download_list.append(DownloadRequest(url=url, filename=filename,\n                                                          data_type=AwsConstants.AWS_FILES[data_name],\n                                                          data_name=data_name))\n        self.sort_download_list()\n        return self.download_list, self.folder_list", "response": "Creates tile structure and returns list of files for download."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_aws_index(self):\n        if self.aws_index is not None:\n            return self.aws_index\n        tile_info_list = get_tile_info(self.tile_name, self.datetime, all_tiles=True)\n        if not tile_info_list:\n            raise ValueError('Cannot find aws_index for specified tile and time')\n\n        if self.data_source is DataSource.SENTINEL2_L2A:\n            for tile_info in sorted(tile_info_list, key=self._parse_aws_index):\n                try:\n                    self.aws_index = self._parse_aws_index(tile_info)\n                    self.get_tile_info()\n                    return self.aws_index\n                except AwsDownloadFailedException:\n                    pass\n\n        return self._parse_aws_index(tile_info_list[0])", "response": "Returns the index of the tile on AWS."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tile_is_valid(self):\n        return self.tile_info is not None \\\n            and (self.datetime == self.date or self.datetime == self.parse_datetime(self.tile_info['timestamp']))", "response": "Checks if tile has tile info and valid timestamp\n            and returns True if tile is valid and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url(self, filename):\n        tile_url = self.tile_url\n        force_http = filename in [AwsConstants.TILE_INFO, AwsConstants.PRODUCT_INFO, AwsConstants.METADATA]\n        if tile_url is None or force_http:\n            tile_url = self.get_tile_url(force_http=force_http)\n        return '{}/{}'.format(tile_url, self.add_file_extension(filename))", "response": "Returns url of file location on AWS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tile_url(self, force_http=False):\n        base_url = self.base_http_url if force_http else self.base_url\n        url = '{}tiles/{}/{}/{}/'.format(base_url, self.tile_name[0:2].lstrip('0'), self.tile_name[2],\n                                         self.tile_name[3:5])\n        date_params = self.date.split('-')\n        for param in date_params:\n            url += param.lstrip('0') + '/'\n        return url + str(self.aws_index)", "response": "Creates base url of tile location on AWS."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the location of the gml file on AWS", "response": "def get_gml_url(self, qi_type, band='B00'):\n        \"\"\"\n        :param qi_type: type of quality indicator\n        :type qi_type: str\n        :param band: band name\n        :type band: str\n        :return: location of gml file on AWS\n        :rtype: str\n        \"\"\"\n        band = band.split('/')[-1]\n        return self.get_qi_url('MSK_{}_{}.gml'.format(qi_type, band))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn url location of full resolution L1C preview", "response": "def get_preview_url(self, data_type='L1C'):\n        \"\"\"Returns url location of full resolution L1C preview\n        :return:\n        \"\"\"\n        if self.data_source is DataSource.SENTINEL2_L1C or self.safe_type is EsaSafeType.OLD_TYPE:\n            return self.get_url(AwsConstants.PREVIEW_JP2)\n        return self.get_qi_url('{}_PVI.jp2'.format(data_type))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_filepath(self, filename):\n        return os.path.join(self.parent_folder, '{},{},{}'.format(self.tile_name, self.date, self.aws_index),\n                            self.add_file_extension(filename)).replace(':', '.')", "response": "Creates file path for the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tile_id_to_tile(tile_id):\n        if tile_id.split('_')[0] not in ['S2A', 'S2B', 'L1C']:\n            raise ValueError('Transformation from tile ID to tile works currently only for Sentinel-2 L1C products')\n\n        tile_info = get_tile_info_id(tile_id)\n        return AwsService.url_to_tile(tile_info['properties']['s3Path'])", "response": "Transform a tile ID to a tile name sensing date and AWS index."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits data into pieces of 32 bytes.", "response": "def split32(data):\n    \"\"\" Split data into pieces of 32 bytes. \"\"\"\n    all_pieces = []\n\n    for position in range(0, len(data), 32):\n        piece = data[position:position + 32]\n        all_pieces.append(piece)\n\n    return all_pieces"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _canonical_type(name):  # pylint: disable=too-many-return-statements\n\n    if name == 'int':\n        return 'int256'\n\n    if name == 'uint':\n        return 'uint256'\n\n    if name == 'fixed':\n        return 'fixed128x128'\n\n    if name == 'ufixed':\n        return 'ufixed128x128'\n\n    if name.startswith('int['):\n        return 'int256' + name[3:]\n\n    if name.startswith('uint['):\n        return 'uint256' + name[4:]\n\n    if name.startswith('fixed['):\n        return 'fixed128x128' + name[5:]\n\n    if name.startswith('ufixed['):\n        return 'ufixed128x128' + name[6:]\n\n    return name", "response": "Convert a type name to a canonical type name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the unique method id for a given function name and a list of parameter types.", "response": "def method_id(name, encode_types):\n    \"\"\" Return the unique method id.\n\n    The signature is defined as the canonical expression of the basic\n    prototype, i.e. the function name with the parenthesised list of parameter\n    types. Parameter types are split by a single comma - no spaces are used.\n\n    The method id is defined as the first four bytes (left, high-order in\n    big-endian) of the Keccak (SHA-3) hash of the signature of the function.\n    \"\"\"\n    function_types = [\n        _canonical_type(type_)\n        for type_ in encode_types\n    ]\n\n    function_signature = '{function_name}({canonical_types})'.format(\n        function_name=name,\n        canonical_types=','.join(function_types),\n    )\n\n    function_keccak = utils.sha3(function_signature)\n    first_bytes = function_keccak[:4]\n\n    return big_endian_to_int(first_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the event id.", "response": "def event_id(name, encode_types):\n    \"\"\" Return the event id.\n\n    Defined as:\n\n        `keccak(EVENT_NAME+\"(\"+EVENT_ARGS.map(canonical_type_of).join(\",\")+\")\")`\n\n    Where `canonical_type_of` is a function that simply returns the canonical\n    type of a given argument, e.g. for uint indexed foo, it would return\n    uint256). Note the lack of spaces.\n    \"\"\"\n\n    event_types = [\n        _canonical_type(type_)\n        for type_ in encode_types\n    ]\n\n    event_signature = '{event_name}({canonical_types})'.format(\n        event_name=name,\n        canonical_types=','.join(event_types),\n    )\n\n    return big_endian_to_int(utils.sha3(event_signature))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode an unsigned integer.", "response": "def decint(n, signed=False):  # pylint: disable=invalid-name,too-many-branches\n    \"\"\" Decode an unsigned/signed integer. \"\"\"\n\n    if isinstance(n, str):\n        n = utils.to_string(n)\n\n    if n is True:\n        return 1\n\n    if n is False:\n        return 0\n\n    if n is None:\n        return 0\n\n    if is_numeric(n):\n        if signed:\n            if not -TT255 <= n <= TT255 - 1:\n                raise EncodingError('Number out of range: %r' % n)\n        else:\n            if not 0 <= n <= TT256 - 1:\n                raise EncodingError('Number out of range: %r' % n)\n\n        return n\n\n    if is_string(n):\n        if len(n) > 32:\n            raise EncodingError('String too long: %r' % n)\n\n        if len(n) == 40:\n            int_bigendian = decode_hex(n)\n        else:\n            int_bigendian = n  # pylint: disable=redefined-variable-type\n\n        result = big_endian_to_int(int_bigendian)\n        if signed:\n            if result >= TT255:\n                result -= TT256\n\n            if not -TT255 <= result <= TT255 - 1:\n                raise EncodingError('Number out of range: %r' % n)\n        else:\n            if not 0 <= result <= TT256 - 1:\n                raise EncodingError('Number out of range: %r' % n)\n\n        return result\n\n    raise EncodingError('Cannot decode integer: %r' % n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_single(typ, arg):  # pylint: disable=too-many-return-statements,too-many-branches,too-many-statements,too-many-locals\n    base, sub, _ = typ\n\n    if base == 'uint':\n        sub = int(sub)\n\n        if not (0 < sub <= 256 and sub % 8 == 0):\n            raise ValueError(\n                'invalid unsigned integer bit length {}'.format(sub))\n\n        try:\n            i = decint(arg, signed=False)\n        except EncodingError:\n            # arg is larger than 2**256\n            raise ValueOutOfBounds(repr(arg))\n\n        if not 0 <= i < 2 ** sub:\n            raise ValueOutOfBounds(repr(arg))\n\n        value_encoded = int_to_big_endian(i)\n        return zpad(value_encoded, 32)\n\n    if base == 'int':\n        sub = int(sub)\n        bits = sub - 1\n\n        if not (0 < sub <= 256 and sub % 8 == 0):\n            raise ValueError('invalid integer bit length {}'.format(sub))\n\n        try:\n            i = decint(arg, signed=True)\n        except EncodingError:\n            # arg is larger than 2**255\n            raise ValueOutOfBounds(repr(arg))\n\n        if not -2 ** bits <= i < 2 ** bits:\n            raise ValueOutOfBounds(repr(arg))\n\n        value = i % 2 ** 256  # convert negative to \"equivalent\" positive\n        value_encoded = int_to_big_endian(value)\n        return zpad(value_encoded, 32)\n\n    if base == 'bool':\n        if arg is True:\n            value_encoded = int_to_big_endian(1)\n        elif arg is False:\n            value_encoded = int_to_big_endian(0)\n        else:\n            raise ValueError('%r is not bool' % arg)\n\n        return zpad(value_encoded, 32)\n\n    if base == 'ufixed':\n        sub = str(sub)  # pylint: disable=redefined-variable-type\n\n        high_str, low_str = sub.split('x')\n        high = int(high_str)\n        low = int(low_str)\n\n        if not (0 < high + low <= 256 and high % 8 == 0 and low % 8 == 0):\n            raise ValueError('invalid unsigned fixed length {}'.format(sub))\n\n        if not 0 <= arg < 2 ** high:\n            raise ValueOutOfBounds(repr(arg))\n\n        float_point = arg * 2 ** low\n        fixed_point = int(float_point)\n        return zpad(int_to_big_endian(fixed_point), 32)\n\n    if base == 'fixed':\n        sub = str(sub)  # pylint: disable=redefined-variable-type\n\n        high_str, low_str = sub.split('x')\n        high = int(high_str)\n        low = int(low_str)\n        bits = high - 1\n\n        if not (0 < high + low <= 256 and high % 8 == 0 and low % 8 == 0):\n            raise ValueError('invalid unsigned fixed length {}'.format(sub))\n\n        if not -2 ** bits <= arg < 2 ** bits:\n            raise ValueOutOfBounds(repr(arg))\n\n        float_point = arg * 2 ** low\n        fixed_point = int(float_point)\n        value = fixed_point % 2 ** 256\n        return zpad(int_to_big_endian(value), 32)\n\n    # Decimals\n    if base == 'decimal':\n        val_to_encode = int(arg * 10**int(sub))\n        return zpad(encode_int(val_to_encode % 2**256), 32)\n\n    if base == 'string':\n        if isinstance(arg, utils.unicode):\n            arg = arg.encode('utf8')\n        else:\n            try:\n                arg.decode('utf8')\n            except UnicodeDecodeError:\n                raise ValueError('string must be utf8 encoded')\n\n        if len(sub):  # fixed length\n            if not 0 <= len(arg) <= int(sub):\n                raise ValueError('invalid string length {}'.format(sub))\n\n            if not 0 <= int(sub) <= 32:\n                raise ValueError('invalid string length {}'.format(sub))\n\n            return rzpad(arg, 32)\n\n        if not 0 <= len(arg) < TT256:\n            raise Exception('Integer invalid or out of range: %r' % arg)\n\n        length_encoded = zpad(int_to_big_endian(len(arg)), 32)\n        value_encoded = rzpad(arg, utils.ceil32(len(arg)))\n\n        return length_encoded + value_encoded\n\n    if base == 'bytes':\n        if not is_string(arg):\n            if isinstance(arg, str):\n                arg = bytes(arg, 'utf8')\n            else:\n                raise EncodingError('Expecting string: %r' % arg)\n\n        arg = utils.to_string(arg)  # py2: force unicode into str\n\n        if len(sub):  # fixed length\n            if not 0 <= len(arg) <= int(sub):\n                raise ValueError('string must be utf8 encoded')\n\n            if not 0 <= int(sub) <= 32:\n                raise ValueError('string must be utf8 encoded')\n\n            return rzpad(arg, 32)\n\n        if not 0 <= len(arg) < TT256:\n            raise Exception('Integer invalid or out of range: %r' % arg)\n\n        length_encoded = zpad(int_to_big_endian(len(arg)), 32)\n        value_encoded = rzpad(arg, utils.ceil32(len(arg)))\n\n        return length_encoded + value_encoded\n\n    if base == 'hash':\n        if not (int(sub) and int(sub) <= 32):\n            raise EncodingError('too long: %r' % arg)\n\n        if is_numeric(arg):\n            return zpad(encode_int(arg), 32)\n\n        if len(arg) == int(sub):\n            return zpad(arg, 32)\n\n        if len(arg) == int(sub) * 2:\n            return zpad(decode_hex(arg), 32)\n\n        raise EncodingError('Could not parse hash: %r' % arg)\n\n    if base == 'address':\n        assert sub == ''\n\n        if is_numeric(arg):\n            return zpad(encode_int(arg), 32)\n\n        if len(arg) == 20:\n            return zpad(arg, 32)\n\n        if len(arg) == 40:\n            return zpad(decode_hex(arg), 32)\n\n        if len(arg) == 42 and arg[:2] == '0x':\n            return zpad(decode_hex(arg[2:]), 32)\n\n        raise EncodingError('Could not parse address: %r' % arg)\n    raise EncodingError('Unhandled type: %r %r' % (base, sub))", "response": "Encode arg as typ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the encoded function call.", "response": "def encode_function_call(self, function_name, args):\n        \"\"\" Return the encoded function call.\n\n        Args:\n            function_name (str): One of the existing functions described in the\n                contract interface.\n            args (List[object]): The function arguments that wll be encoded and\n                used in the contract execution in the vm.\n\n        Return:\n            bin: The encoded function name and arguments so that it can be used\n                 with the evm to execute a funcion call, the binary string follows\n                 the Ethereum Contract ABI.\n        \"\"\"\n        if function_name not in self.function_data:\n            raise ValueError('Unkown function {}'.format(function_name))\n\n        description = self.function_data[function_name]\n\n        function_selector = zpad(encode_int(description['prefix']), 4)\n        arguments = encode_abi(description['encode_types'], args)\n\n        return function_selector + arguments"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_function_result(self, function_name, data):\n        description = self.function_data[function_name]\n        arguments = decode_abi(description['decode_types'], data)\n        return arguments", "response": "Return the function call result decoded by calling function_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_constructor_arguments(self, args):\n        if self.constructor_data is None:\n            raise ValueError(\n                \"The contract interface didn't have a constructor\")\n\n        return encode_abi(self.constructor_data['encode_types'], args)", "response": "Return the encoded constructor call."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_event(self, log_topics, log_data):\n        # https://github.com/ethereum/wiki/wiki/Ethereum-Contract-ABI#function-selector-and-argument-encoding\n\n        # topics[0]: keccak(EVENT_NAME+\"(\"+EVENT_ARGS.map(canonical_type_of).join(\",\")+\")\")\n        # If the event is declared as anonymous the topics[0] is not generated;\n        if not len(log_topics) or log_topics[0] not in self.event_data:\n            raise ValueError('Unknown log type')\n\n        event_id_ = log_topics[0]\n\n        event = self.event_data[event_id_]\n\n        # data: abi_serialise(EVENT_NON_INDEXED_ARGS)\n        # EVENT_NON_INDEXED_ARGS is the series of EVENT_ARGS that are not\n        # indexed, abi_serialise is the ABI serialisation function used for\n        # returning a series of typed values from a function.\n        unindexed_types = [\n            type_\n            for type_, indexed in zip(event['types'], event['indexed'])\n            if not indexed\n        ]\n        unindexed_args = decode_abi(unindexed_types, log_data)\n\n        # topics[n]: EVENT_INDEXED_ARGS[n - 1]\n        # EVENT_INDEXED_ARGS is the series of EVENT_ARGS that are indexed\n        indexed_count = 1  # skip topics[0]\n\n        result = {}\n        for name, type_, indexed in zip(\n                event['names'], event['types'], event['indexed']):\n            if indexed:\n                topic_bytes = utils.zpad(\n                    utils.encode_int(log_topics[indexed_count]),\n                    32,\n                )\n                indexed_count += 1\n                value = decode_single(process_type(type_), topic_bytes)\n            else:\n                value = unindexed_args.pop(0)\n\n            result[name] = value\n        result['_event_type'] = utils.to_string(event['name'])\n\n        return result", "response": "This function decodes the log and returns a dictionary representation of the event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef listen(self, log, noprint=True):\n        try:\n            result = self.decode_event(log.topics, log.data)\n        except ValueError:\n            return  # api compatibility\n\n        if not noprint:\n            print(result)\n\n        return result", "response": "This function returns a dictionary representation of the Log instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunpack binary data to nibbles sequence", "response": "def unpack_to_nibbles(bindata):\n    \"\"\"unpack packed binary data to nibbles\n\n    :param bindata: binary packed from nibbles\n    :return: nibbles sequence, may have a terminator\n    \"\"\"\n    o = bin_to_nibbles(bindata)\n    flags = o[0]\n    if flags & 2:\n        o.append(NIBBLE_TERMINATOR)\n    if flags & 1 == 1:\n        o = o[1:]\n    else:\n        o = o[2:]\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef starts_with(full, part):\n    if len(full) < len(part):\n        return False\n    return full[:len(part)] == part", "response": "test whether the items in the full list is a leading item of the part"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear(self):\n        self._delete_child_storage(self.root_node)\n        self._delete_node_storage(self.root_node)\n        self.root_node = BLANK_NODE", "response": "clear all tree data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_node_type(self, node):\n        if node == BLANK_NODE:\n            return NODE_TYPE_BLANK\n\n        if len(node) == 2:\n            nibbles = unpack_to_nibbles(node[0])\n            has_terminator = (nibbles and nibbles[-1] == NIBBLE_TERMINATOR)\n            return NODE_TYPE_LEAF if has_terminator\\\n                else NODE_TYPE_EXTENSION\n        if len(node) == 17:\n            return NODE_TYPE_BRANCH", "response": "get node type and content\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting value inside a node", "response": "def _get(self, node, key):\n        \"\"\" get value inside a node\n\n        :param node: node in form of list, or BLANK_NODE\n        :param key: nibble list without terminator\n        :return:\n            BLANK_NODE if does not exist, otherwise value or hash\n        \"\"\"\n        node_type = self._get_node_type(node)\n\n        if node_type == NODE_TYPE_BLANK:\n            return BLANK_NODE\n\n        if node_type == NODE_TYPE_BRANCH:\n            # already reach the expected node\n            if not key:\n                return node[-1]\n            sub_node = self._decode_to_node(node[key[0]])\n            return self._get(sub_node, key[1:])\n\n        # key value node\n        curr_key = without_terminator(unpack_to_nibbles(node[0]))\n        if node_type == NODE_TYPE_LEAF:\n            return node[1] if key == curr_key else BLANK_NODE\n\n        if node_type == NODE_TYPE_EXTENSION:\n            # traverse child nodes\n            if starts_with(key, curr_key):\n                sub_node = self._decode_to_node(node[1])\n                return self._get(sub_node, key[len(curr_key):])\n            else:\n                return BLANK_NODE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting storage :param node: node in form of list, or BLANK_NODE", "response": "def _delete_node_storage(self, node, is_root=False):\n        \"\"\"delete storage\n        :param node: node in form of list, or BLANK_NODE\n        \"\"\"\n        if node == BLANK_NODE:\n            return\n        # assert isinstance(node, list)\n        encoded = rlp_encode(node)\n        if len(encoded) < 32 and not is_root:\n            return\n        \"\"\"\n        ===== FIXME ====\n        in the current trie implementation two nodes can share identical subtrees\n        thus we can not safely delete nodes for now\n        \"\"\"\n        hashkey = utils.sha3(encoded)\n        self.db.dec_refcount(hashkey)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _delete(self, node, key):\n        # sys.stderr.write('del\\n')\n        node_type = self._get_node_type(node)\n        if node_type == NODE_TYPE_BLANK:\n            return BLANK_NODE\n\n        if node_type == NODE_TYPE_BRANCH:\n            return self._delete_branch_node(node, key)\n\n        if is_key_value_type(node_type):\n            return self._delete_kv_node(node, key)", "response": "delete a node in form of list or BLANK_NODE\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, key):\n        if not is_string(key):\n            raise Exception(\"Key must be string\")\n\n        if len(key) > 32:\n            raise Exception(\"Max key length is 32\")\n\n        old_root = copy.deepcopy(self.root_node)\n        self.root_node = self._delete_and_delete_storage(\n            self.root_node,\n            bin_to_nibbles(to_string(key)))\n        self.replace_root_hash(old_root, self.root_node)", "response": "Delete a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_size(self, node):\n        if node == BLANK_NODE:\n            return 0\n\n        node_type = self._get_node_type(node)\n\n        if is_key_value_type(node_type):\n            value_is_node = node_type == NODE_TYPE_EXTENSION\n            if value_is_node:\n                return self._get_size(self._decode_to_node(node[1]))\n            else:\n                return 1\n        elif node_type == NODE_TYPE_BRANCH:\n            sizes = [self._get_size(self._decode_to_node(node[x]))\n                     for x in range(16)]\n            sizes = sizes + [1 if node[-1] else 0]\n            return sum(sizes)", "response": "Get the size of the key value in this and the descendant nodes\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _to_dict(self, node):\n        if node == BLANK_NODE:\n            return {}\n\n        node_type = self._get_node_type(node)\n\n        if is_key_value_type(node_type):\n            nibbles = without_terminator(unpack_to_nibbles(node[0]))\n            key = b'+'.join([to_string(x) for x in nibbles])\n            if node_type == NODE_TYPE_EXTENSION:\n                sub_dict = self._to_dict(self._decode_to_node(node[1]))\n            else:\n                sub_dict = {to_string(NIBBLE_TERMINATOR): node[1]}\n\n            # prepend key of this node to the keys of children\n            res = {}\n            for sub_key, sub_value in sub_dict.items():\n                full_key = (key + b'+' + sub_key).strip(b'+')\n                res[full_key] = sub_value\n            return res\n\n        elif node_type == NODE_TYPE_BRANCH:\n            res = {}\n            for i in range(16):\n                sub_dict = self._to_dict(self._decode_to_node(node[i]))\n\n                for sub_key, sub_value in sub_dict.items():\n                    full_key = (\n                        str_to_bytes(\n                            str(i)) +\n                        b'+' +\n                        sub_key).strip(b'+')\n                    res[full_key] = sub_value\n\n            if node[16]:\n                res[to_string(NIBBLE_TERMINATOR)] = node[-1]\n            return res", "response": "converts a node in form of list to dict items."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the value of a key in the cache.", "response": "def update(self, key, value):\n        \"\"\"\n        :param key: a string\n        :value: a string\n        \"\"\"\n        if not is_string(key):\n            raise Exception(\"Key must be string\")\n\n        # if len(key) > 32:\n        #     raise Exception(\"Max key length is 32\")\n\n        if not is_string(value):\n            raise Exception(\"Value must be string\")\n\n        # if value == '':\n        #     return self.delete(key)\n        old_root = copy.deepcopy(self.root_node)\n        self.root_node = self._update_and_delete_storage(\n            self.root_node,\n            bin_to_nibbles(to_string(key)),\n            to_string(value))\n        self.replace_root_hash(old_root, self.root_node)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing all tree data", "response": "def clear(self):\n        \"\"\" clear all tree data\n        \"\"\"\n        self._delete_child_storage(self.root_node)\n        self._delete_node_storage(self.root_node)\n        self.root_node = BLANK_NODE\n        self._root_hash = BLANK_ROOT"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates item inside a node", "response": "def _update(self, node, key, value):\n        \"\"\" update item inside a node\n\n        :param node: node in form of list, or BLANK_NODE\n        :param key: nibble list without terminator\n            .. note:: key may be []\n        :param value: value string\n        :return: new node\n\n        if this node is changed to a new node, it's parent will take the\n        responsibility to *store* the new node storage, and delete the old\n        node storage\n        \"\"\"\n        node_type = self._get_node_type(node)\n\n        if node_type == NODE_TYPE_BLANK:\n            return [pack_nibbles(with_terminator(key)), value]\n\n        elif node_type == NODE_TYPE_BRANCH:\n            if not key:\n                node[-1] = value\n            else:\n                new_node = self._update_and_delete_storage(\n                    self._decode_to_node(node[key[0]]),\n                    key[1:], value)\n                node[key[0]] = self._encode_node(new_node)\n            return node\n\n        elif is_key_value_type(node_type):\n            return self._update_kv_node(node, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting storage :param node: node in form of list, or BLANK_NODE", "response": "def _delete_node_storage(self, node):\n        \"\"\"delete storage\n        :param node: node in form of list, or BLANK_NODE\n        \"\"\"\n        if node == BLANK_NODE:\n            return\n        # assert isinstance(node, list)\n        encoded = self._encode_node(node, put_in_db=False)\n        if len(encoded) < 32:\n            return\n        \"\"\"\n        ===== FIXME ====\n        in the current trie implementation two nodes can share identical subtrees\n        thus we can not safely delete nodes for now\n        \"\"\"\n        self.deletes.append(encoded)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, key):\n        if not is_string(key):\n            raise Exception(\"Key must be string\")\n\n        if len(key) > 32:\n            raise Exception(\"Max key length is 32\")\n\n        self.root_node = self._delete_and_delete_storage(\n            self.root_node,\n            bin_to_nibbles(to_string(key)))\n        self._update_root_hash()", "response": "Delete a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, key, value):\n        if not is_string(key):\n            raise Exception(\"Key must be string\")\n\n        # if len(key) > 32:\n        #     raise Exception(\"Max key length is 32\")\n\n        if not is_string(value):\n            raise Exception(\"Value must be string\")\n\n        # if value == '':\n        #     return self.delete(key)\n        self.root_node = self._update_and_delete_storage(\n            self.root_node,\n            bin_to_nibbles(to_string(key)),\n            to_string(value))\n        self._update_root_hash()", "response": "Updates the value of a key in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a configuration that can be used to call configure", "response": "def get_configuration():\n    \"\"\"\n    get a configuration (snapshot) that can be used to call configure\n    snapshot = get_configuration()\n    configure(**snapshot)\n    \"\"\"\n    root = getLogger()\n    name_levels = [('', logging.getLevelName(root.level))]\n    name_levels.extend(\n        (name, logging.getLevelName(logger.level))\n        for name, logger\n        in root.manager.loggerDict.items()\n        if hasattr(logger, 'level')\n    )\n\n    config_string = ','.join('%s:%s' % x for x in name_levels)\n\n    return dict(config_string=config_string, log_json=SLogger.manager.log_json)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a logger with the specified name creating it if necessary.", "response": "def getLogger(name=None):\n    \"\"\"\n    Return a logger with the specified name, creating it if necessary.\n\n    If no name is specified, return the root logger.\n    \"\"\"\n\n    if name:\n        logger = SLogger.manager.getLogger(name)\n        return logger\n    else:\n        return rootLogger"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DEBUG(msg, *args, **kwargs):\n    logger = getLogger(\"DEBUG\")\n    if len(logger.handlers) == 0:\n        logger.addHandler(StreamHandler())\n    logger.propagate = False\n    logger.setLevel(logging.DEBUG)\n    logger.DEV(msg, *args, **kwargs)", "response": "temporary logger during development that is always on"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vm_trace(ext, msg, compustate, opcode, pushcache, tracer=log_vm_op):\n\n    op, in_args, out_args, fee = opcodes.opcodes[opcode]\n\n    trace_data = {}\n    trace_data['stack'] = list(map(to_string, list(compustate.prev_stack)))\n    if compustate.prev_prev_op in ('MLOAD', 'MSTORE', 'MSTORE8', 'SHA3', 'CALL',\n                   'CALLCODE', 'CREATE', 'CALLDATACOPY', 'CODECOPY',\n                   'EXTCODECOPY'):\n        if len(compustate.prev_memory) < 4096:\n            trace_data['memory'] = \\\n                ''.join([encode_hex(ascii_chr(x)) for x\n                          in compustate.prev_memory])\n        else:\n            trace_data['sha3memory'] = \\\n                encode_hex(utils.sha3(b''.join([ascii_chr(x) for\n                                      x in compustate.prev_memory])))\n    if compustate.prev_prev_op in ('SSTORE',) or compustate.steps == 0:\n        trace_data['storage'] = ext.log_storage(msg.to)\n    trace_data['gas'] = to_string(compustate.prev_gas)\n    trace_data['gas_cost'] = to_string(compustate.prev_gas - compustate.gas)\n    trace_data['fee'] = fee\n    trace_data['inst'] = opcode\n    trace_data['pc'] = to_string(compustate.prev_pc)\n    if compustate.steps == 0:\n        trace_data['depth'] = msg.depth\n        trace_data['address'] = msg.to\n    trace_data['steps'] = compustate.steps\n    trace_data['depth'] = msg.depth\n    if op[:4] == 'PUSH':\n        print(repr(pushcache))\n        trace_data['pushvalue'] = pushcache[compustate.prev_pc]\n    tracer.trace('vm', op=op, **trace_data)\n    compustate.steps += 1\n    compustate.prev_prev_op = op", "response": "Trace the given opcode in the given stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sign(self, key, network_id=None):\n        if network_id is None:\n            rawhash = utils.sha3(rlp.encode(unsigned_tx_from_tx(self), UnsignedTransaction))\n        else:\n            assert 1 <= network_id < 2**63 - 18\n            rlpdata = rlp.encode(rlp.infer_sedes(self).serialize(self)[\n                                 :-3] + [network_id, b'', b''])\n            rawhash = utils.sha3(rlpdata)\n\n        key = normalize_key(key)\n\n        v, r, s = ecsign(rawhash, key)\n        if network_id is not None:\n            v += 8 + network_id * 2\n\n        ret = self.copy(\n            v=v, r=r, s=s\n        )\n        ret._sender = utils.privtoaddr(key)\n        return ret", "response": "Sign this transaction with a private key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the address of a contract created by this tx", "response": "def creates(self):\n        \"returns the address of a contract created by this tx\"\n        if self.to in (b'', '\\0' * 20):\n            return mk_contract_address(self.sender, self.nonce)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a fixture into a list of tables", "response": "def fixture_to_tables(fixture):\n    \"\"\" convert fixture into *behave* examples\n    :param fixture: a dictionary in the following form::\n\n        {\n            \"test1name\":\n            {\n                \"test1property1\": ...,\n                \"test1property2\": ...,\n                ...\n            },\n            \"test2name\":\n            {\n                \"test2property1\": ...,\n                \"test2property2\": ...,\n                ...\n            }\n        }\n\n    :return: a list, with each item represent a table: `(caption, rows)`,\n    each item in `rows` is `(col1, col2,...)`\n    \"\"\"\n\n    tables = []\n    for (title, content) in fixture.iteritems():\n        rows = []\n\n        # header(keyword) row\n        keys = sorted(content.keys())\n        rows.append(tuple(keys))\n\n        # item(value) row\n        row1 = []\n        for col in rows[0]:\n            row1.append(content[col])\n        rows.append(tuple(row1))\n\n        tables.append((title, tuple(rows)))\n    return tables"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_item(item, py=True):\n    # for non python format, just output itself.\n    # so the result is `something` instead of `\"something\"`\n    if not py:\n        return unicode(item)\n\n    if isinstance(item, (str, unicode)):\n        # long int is prefixed by a #\n        if item.startswith('#'):\n            return unicode(long(item[1:]))\n        return u'\"{0}\"'.format(item)\n\n    return unicode(item)", "response": "format a single item for the n - tuple"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_to_example(table, tabspace=2, indent=2):\n    from io import StringIO\n    output = StringIO()\n\n    caption, rows = table\n\n    # output caption line\n    output.write(u'{0}Examples: {1}\\n'.format(' ' * indent * tabspace,\n                                              caption))\n\n    # calculate max length for each column, for aligning\n    cols = zip(*rows)\n    col_lengths = []\n    for col in cols:\n        max_length = max([len(format_item(row)) for row in col])\n        col_lengths.append(max_length)\n\n    # output each row\n    for r, row in enumerate(rows):\n        output.write(u' ' * (indent + 1) * tabspace)\n        output.write(u'|')\n        for c in range(len(col_lengths)):\n            output.write(u' ')\n            output.write(format_item(row[c], r))\n            output.write(u' ' * (col_lengths[c] - len(format_item(row[c], r))))\n            output.write(u' |')\n        output.write(u'\\n')\n\n    example = output.getvalue()\n    output.close()\n    return example", "response": "format table to behave example"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the proof - of - work of the block is valid.", "response": "def check_pow(block_number, header_hash, mixhash, nonce, difficulty):\n    \"\"\"Check if the proof-of-work of the block is valid.\n\n    :param nonce: if given the proof of work function will be evaluated\n                  with this nonce instead of the one already present in\n                  the header\n    :returns: `True` or `False`\n    \"\"\"\n    log.debug('checking pow', block_number=block_number)\n    if len(mixhash) != 32 or len(header_hash) != 32 or len(nonce) != 8:\n        return False\n\n    # Grab current cache\n    cache = get_cache(block_number)\n    mining_output = hashimoto_light(block_number, cache, header_hash, nonce)\n    if mining_output[b'mix digest'] != mixhash:\n        return False\n    return utils.big_endian_to_int(\n        mining_output[b'result']) <= 2**256 // (difficulty or 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_keystore_json(jsondata):\n    if 'crypto' not in jsondata and 'Crypto' not in jsondata:\n        return False\n    if 'version' not in jsondata:\n        return False\n    if jsondata['version'] != 3:\n        return False\n    crypto = jsondata.get('crypto', jsondata.get('Crypto'))\n    if 'cipher' not in crypto:\n        return False\n    if 'ciphertext' not in crypto:\n        return False\n    if 'kdf' not in crypto:\n        return False\n    if 'mac' not in crypto:\n        return False\n    return True", "response": "Checks if the keystore file jsondata is valid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(self):\n        d = {}\n        for field in ('prevhash', 'uncles_hash', 'extra_data', 'nonce',\n                      'mixhash'):\n            d[field] = '0x' + encode_hex(getattr(self, field))\n        for field in ('state_root', 'tx_list_root', 'receipts_root',\n                      'coinbase'):\n            d[field] = encode_hex(getattr(self, field))\n        for field in ('number', 'difficulty', 'gas_limit', 'gas_used',\n                      'timestamp'):\n            d[field] = utils.to_string(getattr(self, field))\n        d['bloom'] = encode_hex(int256.serialize(self.bloom))\n        assert len(d) == len(BlockHeader.fields)\n        return d", "response": "Serialize the header to a readable dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_int(v):\n    if len(v) > 0 and (v[0] == b'\\x00' or v[0] == 0):\n        raise Exception(\"No leading zero bytes allowed for integers\")\n    return big_endian_to_int(v)", "response": "decodes and integer from serialization"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding an integer into serialization", "response": "def encode_int(v):\n    \"\"\"encodes an integer into serialization\"\"\"\n    if not is_numeric(v) or v < 0 or v >= TT256:\n        raise Exception(\"Integer invalid or out of range: %r\" % v)\n    return int_to_big_endian(v)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_func_call(ignore_first_arg=False, max_call_number=100):\n    from functools import wraps\n\n    def display(x):\n        x = to_string(x)\n        try:\n            x.decode('ascii')\n        except BaseException:\n            return 'NON_PRINTABLE'\n        return x\n\n    local = {'call_number': 0}\n\n    def inner(f):\n\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            local['call_number'] += 1\n            tmp_args = args[1:] if ignore_first_arg and len(args) else args\n            this_call_number = local['call_number']\n            print(('{0}#{1} args: {2}, {3}'.format(\n                f.__name__,\n                this_call_number,\n                ', '.join([display(x) for x in tmp_args]),\n                ', '.join(display(key) + '=' + to_string(value)\n                          for key, value in kwargs.items())\n            )))\n            res = f(*args, **kwargs)\n            print(('{0}#{1} return: {2}'.format(\n                f.__name__,\n                this_call_number,\n                display(res))))\n\n            if local['call_number'] > 100:\n                raise Exception(\"Touch max call number!\")\n            return res\n        return wrapper\n    return inner", "response": "decorator to facilitate debug print function call"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef length_prefix(length, offset):\n    if length < 56:\n        return chr(offset + length)\n    else:\n        length_string = int_to_big_endian(length)\n        return chr(offset + 56 - 1 + len(length_string)) + length_string", "response": "Construct the prefix to lists or strings denoting their length."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a length prefix from an RLP string.", "response": "def consume_length_prefix(rlp, start):\n    \"\"\"Read a length prefix from an RLP string.\n\n    :param rlp: the rlp string to read from\n    :param start: the position at which to start reading\n    :returns: a tuple ``(type, length, end)``, where ``type`` is either ``str``\n              or ``list`` depending on the type of the following payload,\n              ``length`` is the length of the payload in bytes, and ``end`` is\n              the position of the first payload byte in the rlp string\n    \"\"\"\n    b0 = safe_ord(rlp[start])\n    if b0 < 128:  # single byte\n        return (str, 1, start)\n    elif b0 < 128 + 56:  # short string\n        return (str, b0 - 128, start + 1)\n    elif b0 < 192:  # long string\n        ll = b0 - 128 - 56 + 1\n        l = big_endian_to_int(rlp[start + 1:start + 1 + ll])\n        return (str, l, start + 1 + ll)\n    elif b0 < 192 + 56:  # short list\n        return (list, b0 - 192, start + 1)\n    else:  # long list\n        ll = b0 - 192 - 56 + 1\n        l = big_endian_to_int(rlp[start + 1:start + 1 + ll])\n        return (list, l, start + 1 + ll)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_compiler_path():\n    # If the user provides a specific solc binary let's use that\n    given_binary = os.environ.get('SOLC_BINARY')\n    if given_binary:\n        return given_binary\n\n    for path in os.getenv('PATH', '').split(os.pathsep):\n        path = path.strip('\"')\n        executable_path = os.path.join(path, BINARY)\n\n        if os.path.isfile(executable_path) and os.access(\n                executable_path, os.X_OK):\n            return executable_path\n\n    return None", "response": "Returns the path to the solc compiler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solc_arguments(libraries=None, combined='bin,abi',\n                   optimize=True, extra_args=None):\n    \"\"\" Build the arguments to call the solc binary. \"\"\"\n    args = [\n        '--combined-json', combined,\n    ]\n\n    def str_of(address):\n        \"\"\"cast address to string. py2/3 compatability. \"\"\"\n        try:\n            return address.decode('utf8')\n        except AttributeError:\n            return address\n\n\n    if optimize:\n        args.append('--optimize')\n\n    if extra_args:\n        try:\n            args.extend(shlex.split(extra_args))\n        except BaseException:  # if not a parseable string then treat it as a list\n            args.extend(extra_args)\n\n    if libraries is not None and len(libraries):\n        addresses = [\n            '{name}:{address}'.format(\n                name=name, address=str_of(address))\n            for name, address in libraries.items()\n        ]\n        args.extend([\n            '--libraries',\n            ','.join(addresses),\n        ])\n\n    return args", "response": "Build the arguments to call the solc binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solc_parse_output(compiler_output):\n    # At the moment some solc output like --hashes or -- gas will not output\n    # json at all so if used with those arguments the logic here will break.\n    # Perhaps solidity will slowly switch to a json only output and this comment\n    # can eventually go away and we will not need to add more logic here at\n    # all.\n    result = yaml.safe_load(compiler_output)['contracts']\n\n    if 'bin' in tuple(result.values())[0]:\n        for value in result.values():\n            value['bin_hex'] = value['bin']\n\n            # decoding can fail if the compiled contract has unresolved symbols\n            try:\n                value['bin'] = decode_hex(value['bin_hex'])\n            except (TypeError, ValueError):\n                pass\n\n    for json_data in ('abi', 'devdoc', 'userdoc'):\n        # the values in the output can be configured through the\n        # --combined-json flag, check that it's present in the first value and\n        # assume all values are consistent\n        if json_data not in tuple(result.values())[0]:\n            continue\n\n        for value in result.values():\n            value[json_data] = yaml.safe_load(value[json_data])\n\n    return result", "response": "Parses the compiler output and returns a dict of the keys that are available in the order they were generated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compiler_version():\n    version_info = subprocess.check_output(['solc', '--version'])\n    match = re.search(b'^Version: ([0-9a-z.-]+)/', version_info, re.MULTILINE)\n\n    if match:\n        return match.group(1)", "response": "Return the version of the installed solc."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the library and contract names in order of appearence.", "response": "def solidity_names(code):  # pylint: disable=too-many-branches\n    \"\"\" Return the library and contract names in order of appearence. \"\"\"\n    names = []\n    in_string = None\n    backslash = False\n    comment = None\n\n    # \"parse\" the code by hand to handle the corner cases:\n    #  - the contract or library can be inside a comment or string\n    #  - multiline comments\n    #  - the contract and library keywords could not be at the start of the line\n    for pos, char in enumerate(code):\n        if in_string:\n            if not backslash and in_string == char:\n                in_string = None\n                backslash = False\n\n            if char == '\\\\':  # pylint: disable=simplifiable-if-statement\n                backslash = True\n            else:\n                backslash = False\n\n        elif comment == '//':\n            if char in ('\\n', '\\r'):\n                comment = None\n\n        elif comment == '/*':\n            if char == '*' and code[pos + 1] == '/':\n                comment = None\n\n        else:\n            if char == '\"' or char == \"'\":\n                in_string = char\n\n            if char == '/':\n                if code[pos + 1] == '/':\n                    comment = '//'\n                if code[pos + 1] == '*':\n                    comment = '/*'\n\n            if char == 'c' and code[pos: pos + 8] == 'contract':\n                result = re.match(\n                    '^contract[^_$a-zA-Z]+([_$a-zA-Z][_$a-zA-Z0-9]*)', code[pos:])\n\n                if result:\n                    names.append(('contract', result.groups()[0]))\n\n            if char == 'i' and code[pos: pos + 9] == 'interface':\n                result = re.match(\n                    '^interface[^_$a-zA-Z]+([_$a-zA-Z][_$a-zA-Z0-9]*)', code[pos:])\n\n                if result:\n                    names.append(('contract', result.groups()[0]))\n\n            if char == 'l' and code[pos: pos + 7] == 'library':\n                result = re.match(\n                    '^library[^_$a-zA-Z]+([_$a-zA-Z][_$a-zA-Z0-9]*)', code[pos:])\n\n                if result:\n                    names.append(('library', result.groups()[0]))\n\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_file(filepath, libraries=None, combined='bin,abi',\n                 optimize=True, extra_args=None):\n    \"\"\" Return the compile contract code.\n\n    Args:\n        filepath (str): The path to the contract source code.\n        libraries (dict): A dictionary mapping library name to it's address.\n        combined (str): The argument for solc's --combined-json.\n        optimize (bool): Enable/disables compiler optimization.\n\n    Returns:\n        dict: A mapping from the contract name to it's binary.\n    \"\"\"\n\n    workdir, filename = os.path.split(filepath)\n\n    args = solc_arguments(\n        libraries=libraries,\n        combined=combined,\n        optimize=optimize,\n        extra_args=extra_args)\n    args.insert(0, get_compiler_path())\n    args.append(filename)\n\n    output = subprocess.check_output(args, cwd=workdir)\n\n    return solc_parse_output(output)", "response": "Compile a file into a dictionary of the correct format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile(cls, code, path=None, libraries=None,\n                contract_name='', extra_args=None):\n        \"\"\" Return the binary of last contract in code. \"\"\"\n        result = cls._code_or_path(\n            code,\n            path,\n            contract_name,\n            libraries,\n            'bin',\n            extra_args)\n        return result['bin']", "response": "Compile the code and return the binary of the last contract in code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling combined - json with abi bin devdoc userdoc.", "response": "def combined(cls, code, path=None, extra_args=None):\n        \"\"\" Compile combined-json with abi,bin,devdoc,userdoc.\n\n        @param code: literal solidity code as a string.\n        @param path: absolute path to solidity-file. Note: code & path are\n                     mutually exclusive!\n        @param extra_args: Either a space separated string or a list of extra\n                           arguments to be passed to the solidity compiler.\n        \"\"\"\n\n        if code and path:\n            raise ValueError('sourcecode and path are mutually exclusive.')\n\n        if path:\n            contracts = compile_file(path, extra_args=extra_args)\n\n            with open(path) as handler:\n                code = handler.read()\n\n        elif code:\n            contracts = compile_code(code, extra_args=extra_args)\n\n        else:\n            raise ValueError('either code or path needs to be supplied.')\n\n        sorted_contracts = []\n        for name in solidity_names(code):\n            sorted_contracts.append(\n                (\n                    name[1],\n                    solidity_get_contract_data(contracts, path, name[1])\n                )\n            )\n        return sorted_contracts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_rich(cls, code, path=None, extra_args=None):\n\n        return {\n            contract_name: {\n                'code': '0x' + contract.get('bin_hex'),\n                'info': {\n                    'abiDefinition': contract.get('abi'),\n                    'compilerVersion': cls.compiler_version(),\n                    'developerDoc': contract.get('devdoc'),\n                    'language': 'Solidity',\n                    'languageVersion': '0',\n                    'source': code,\n                    'userDoc': contract.get('userdoc')\n                },\n            }\n            for contract_name, contract\n            in cls.combined(code, path=path, extra_args=extra_args)\n        }", "response": "full format as returned by jsonrpc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_uncles(state, block):\n    # Make sure hash matches up\n    if utils.sha3(rlp.encode(block.uncles)) != block.header.uncles_hash:\n        raise VerificationFailed(\"Uncle hash mismatch\")\n    # Enforce maximum number of uncles\n    if len(block.uncles) > state.config['MAX_UNCLES']:\n        raise VerificationFailed(\"Too many uncles\")\n    # Uncle must have lower block number than blockj\n    for uncle in block.uncles:\n        if uncle.number >= block.header.number:\n            raise VerificationFailed(\"Uncle number too high\")\n\n    # Check uncle validity\n    MAX_UNCLE_DEPTH = state.config['MAX_UNCLE_DEPTH']\n    ancestor_chain = [block.header] + \\\n        [a for a in state.prev_headers[:MAX_UNCLE_DEPTH + 1] if a]\n    # Uncles of this block cannot be direct ancestors and cannot also\n    # be uncles included 1-6 blocks ago\n    ineligible = [b.hash for b in ancestor_chain]\n    for blknum, uncles in state.recent_uncles.items():\n        if state.block_number > int(\n                blknum) >= state.block_number - MAX_UNCLE_DEPTH:\n            ineligible.extend([u for u in uncles])\n    eligible_ancestor_hashes = [x.hash for x in ancestor_chain[2:]]\n    for uncle in block.uncles:\n        if uncle.prevhash not in eligible_ancestor_hashes:\n            raise VerificationFailed(\"Uncle does not have a valid ancestor\")\n        parent = [x for x in ancestor_chain if x.hash == uncle.prevhash][0]\n        if uncle.difficulty != calc_difficulty(\n                parent, uncle.timestamp, config=state.config):\n            raise VerificationFailed(\"Difficulty mismatch\")\n        if uncle.number != parent.number + 1:\n            raise VerificationFailed(\"Number mismatch\")\n        if uncle.timestamp < parent.timestamp:\n            raise VerificationFailed(\"Timestamp mismatch\")\n        if uncle.hash in ineligible:\n            raise VerificationFailed(\"Duplicate uncle\")\n        if uncle.gas_used > uncle.gas_limit:\n            raise VerificationFailed(\"Uncle used too much gas\")\n        if not check_pow(state, uncle):\n            raise VerificationFailed('uncle pow mismatch')\n        ineligible.append(uncle.hash)\n    return True", "response": "Validate the uncles of this block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef finalize(state, block):\n\n    if state.is_METROPOLIS():\n        br = state.config['BYZANTIUM_BLOCK_REWARD']\n        nr = state.config['BYZANTIUM_NEPHEW_REWARD']\n    else:\n        br = state.config['BLOCK_REWARD']\n        nr = state.config['NEPHEW_REWARD']\n        \n    delta = int(br + nr * len(block.uncles))\n    state.delta_balance(state.block_coinbase, delta)\n\n    udpf = state.config['UNCLE_DEPTH_PENALTY_FACTOR']\n\n    for uncle in block.uncles:\n        r = int(br * (udpf + uncle.number - state.block_number) // udpf)\n        state.delta_balance(uncle.coinbase, r)\n\n    if state.block_number - \\\n            state.config['MAX_UNCLE_DEPTH'] in state.recent_uncles:\n        del state.recent_uncles[state.block_number -\n                                state.config['MAX_UNCLE_DEPTH']]", "response": "Apply rewards and commit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_new_style_deprecation(cli_ctx, kwargs, object_type):\n        deprecate_info = kwargs.get('deprecate_info', None)\n        if isinstance(deprecate_info, Deprecated):\n            deprecate_info.object_type = object_type\n        elif isinstance(deprecate_info, STRING_TYPES):\n            deprecate_info = Deprecated(cli_ctx, redirect=deprecate_info, object_type=object_type)\n        kwargs['deprecate_info'] = deprecate_info\n        return deprecate_info", "response": "Ensure that the previous string - based deprecate_info kwarg\n            work with the new style."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true if v1 < v2.", "response": "def _version_less_than_or_equal_to(self, v1, v2):\n        \"\"\" Returns true if v1 <= v2. \"\"\"\n        # pylint: disable=no-name-in-module, import-error\n        from distutils.version import LooseVersion\n        return LooseVersion(v1) <= LooseVersion(v2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prompt_choice_list(msg, a_list, default=1, help_string=None):\n    verify_is_a_tty()\n    options = '\\n'.join([' [{}] {}{}'\n                         .format(i + 1,\n                                 x['name'] if isinstance(x, dict) and 'name' in x else x,\n                                 ' - ' + x['desc'] if isinstance(x, dict) and 'desc' in x else '')\n                         for i, x in enumerate(a_list)])\n    allowed_vals = list(range(1, len(a_list) + 1))\n    while True:\n        val = _input('{}\\n{}\\nPlease enter a choice [Default choice({})]: '.format(msg, options, default))\n        if val == '?' and help_string is not None:\n            print(help_string)\n            continue\n        if not val:\n            val = '{}'.format(default)\n        try:\n            ans = int(val)\n            if ans in allowed_vals:\n                # array index is 0-based, user input is 1-based\n                return ans - 1\n            raise ValueError\n        except ValueError:\n            logger.warning('Valid values are %s', allowed_vals)", "response": "Prompts user to select from a list of possible choices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload arguments prefixed with '@' from file as string COOKIE", "response": "def _expand_prefixed_files(args):\n        \"\"\" Load arguments prefixed with '@' from file as string\n\n        :param args: Arguments passed from command line\n        :type args: list\n        \"\"\"\n        for arg, _ in enumerate(args):\n            if args[arg].startswith('@'):\n                try:\n                    logger.debug('Attempting to read file %s', args[arg][1:])\n                    with open(args[arg][1:], 'r') as f:\n                        content = f.read()\n                    args[arg] = content\n                except IOError:\n                    # Leave arg unmodified\n                    logger.debug('File Error: Failed to open %s, assume not a file', args[arg][1:])\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the command table into the parser.", "response": "def load_command_table(self, command_loader):\n        \"\"\" Process the command table and load it into the parser\n\n        :param cmd_tbl: A dictionary containing the commands\n        :type cmd_tbl: dict\n        \"\"\"\n        cmd_tbl = command_loader.command_table\n        grp_tbl = command_loader.command_group_table\n        if not cmd_tbl:\n            raise ValueError('The command table is empty. At least one command is required.')\n        # If we haven't already added a subparser, we\n        # better do it.\n        if not self.subparsers:\n            sp = self.add_subparsers(dest='_command')\n            sp.required = True\n            self.subparsers = {(): sp}\n\n        for command_name, metadata in cmd_tbl.items():\n            subparser = self._get_subparser(command_name.split(), grp_tbl)\n            command_verb = command_name.split()[-1]\n            # To work around http://bugs.python.org/issue9253, we artificially add any new\n            # parsers we add to the \"choices\" section of the subparser.\n            subparser = self._get_subparser(command_name.split(), grp_tbl)\n            deprecate_info = metadata.deprecate_info\n            if not subparser or (deprecate_info and deprecate_info.expired()):\n                continue\n            # inject command_module designer's help formatter -- default is HelpFormatter\n            fc = metadata.formatter_class or argparse.HelpFormatter\n\n            command_parser = subparser.add_parser(command_verb,\n                                                  description=metadata.description,\n                                                  parents=self.parents,\n                                                  conflict_handler='error',\n                                                  help_file=metadata.help,\n                                                  formatter_class=fc,\n                                                  cli_help=self.cli_help)\n            command_parser.cli_ctx = self.cli_ctx\n            command_validator = metadata.validator\n            argument_validators = []\n            argument_groups = {}\n            for arg in metadata.arguments.values():\n\n                # don't add deprecated arguments to the parser\n                deprecate_info = arg.type.settings.get('deprecate_info', None)\n                if deprecate_info and deprecate_info.expired():\n                    continue\n\n                if arg.validator:\n                    argument_validators.append(arg.validator)\n                if arg.arg_group:\n                    try:\n                        group = argument_groups[arg.arg_group]\n                    except KeyError:\n                        # group not found so create\n                        group_name = '{} Arguments'.format(arg.arg_group)\n                        group = command_parser.add_argument_group(arg.arg_group, group_name)\n                        argument_groups[arg.arg_group] = group\n                    param = CLICommandParser._add_argument(group, arg)\n                else:\n                    param = CLICommandParser._add_argument(command_parser, arg)\n                param.completer = arg.completer\n                param.deprecate_info = arg.deprecate_info\n            command_parser.set_defaults(\n                func=metadata,\n                command=command_name,\n                _command_validator=command_validator,\n                _argument_validators=argument_validators,\n                _parser=command_parser)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_subparser(self, path, group_table=None):\n        group_table = group_table or {}\n        for length in range(0, len(path)):\n            parent_path = path[:length]\n            parent_subparser = self.subparsers.get(tuple(parent_path), None)\n            if not parent_subparser:\n                # No subparser exists for the given subpath - create and register\n                # a new subparser.\n                # Since we know that we always have a root subparser (we created)\n                # one when we started loading the command table, and we walk the\n                # path from left to right (i.e. for \"cmd subcmd1 subcmd2\", we start\n                # with ensuring that a subparser for cmd exists, then for subcmd1,\n                # subcmd2 and so on), we know we can always back up one step and\n                # add a subparser if one doesn't exist\n                command_group = group_table.get(' '.join(parent_path))\n                if command_group:\n                    deprecate_info = command_group.group_kwargs.get('deprecate_info', None)\n                    if deprecate_info and deprecate_info.expired():\n                        continue\n                grandparent_path = path[:length - 1]\n                grandparent_subparser = self.subparsers[tuple(grandparent_path)]\n                new_path = path[length - 1]\n                new_parser = grandparent_subparser.add_parser(new_path, cli_help=self.cli_help)\n\n                # Due to http://bugs.python.org/issue9253, we have to give the subparser\n                # a destination and set it to required in order to get a meaningful error\n                parent_subparser = new_parser.add_subparsers(dest='_subcommand')\n                command_group = group_table.get(' '.join(parent_path), None)\n                deprecate_info = None\n                if command_group:\n                    deprecate_info = command_group.group_kwargs.get('deprecate_info', None)\n                parent_subparser.required = True\n                parent_subparser.deprecate_info = deprecate_info\n                self.subparsers[tuple(path[0:length])] = parent_subparser\n        return parent_subparser", "response": "For each part of the path walk down the tree of\n            parsers creating new ones if one doesn t already exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides argparse. ArgumentParser. parse_args to expand the file names before parsing the command line.", "response": "def parse_args(self, args=None, namespace=None):\n        \"\"\" Overrides argparse.ArgumentParser.parse_args\n\n        Enables '@'-prefixed files to be expanded before arguments are processed\n        by ArgumentParser.parse_args as usual\n        \"\"\"\n        self._expand_prefixed_files(args)\n        return super(CLICommandParser, self).parse_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the summary from the docstring of the command.", "response": "def extract_full_summary_from_signature(operation):\n    \"\"\" Extract the summary from the docstring of the command. \"\"\"\n    lines = inspect.getdoc(operation)\n    regex = r'\\s*(:param)\\s+(.+?)\\s*:(.*)'\n    summary = ''\n    if lines:\n        match = re.search(regex, lines)\n        summary = lines[:match.regs[0][0]] if match else lines\n\n    summary = summary.replace('\\n', ' ').replace('\\r', '')\n    return summary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting parameter descriptions from the docstring of the command.", "response": "def option_descriptions(operation):\n    \"\"\" Extract parameter help from docstring of the command. \"\"\"\n    lines = inspect.getdoc(operation)\n\n    if not lines:\n        return {}\n\n    param_breaks = [\"'''\", '\"\"\"', ':param', ':type', ':return', ':rtype']\n    option_descs = {}\n\n    lines = lines.splitlines()\n    index = 0\n    while index < len(lines):\n        l = lines[index]\n        regex = r'\\s*(:param)\\s+(.+?)\\s*:(.*)'\n        match = re.search(regex, l)\n        if not match:\n            index += 1\n            continue\n\n        # 'arg name' portion might have type info, we don't need it\n        arg_name = str.split(match.group(2))[-1]\n        arg_desc = match.group(3).strip()\n        # look for more descriptions on subsequent lines\n        index += 1\n        while index < len(lines):\n            temp = lines[index].strip()\n            if any(temp.startswith(x) for x in param_breaks):\n                break\n            else:\n                if temp:\n                    arg_desc += (' ' + temp)\n                index += 1\n\n        option_descs[arg_name] = arg_desc\n\n    return option_descs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract basic argument data from an operation s signature and docstring.", "response": "def extract_args_from_signature(operation, excluded_params=None):\n    \"\"\" Extracts basic argument data from an operation's signature and docstring\n        excluded_params: List of params to ignore and not extract. By default we ignore ['self', 'kwargs'].\n    \"\"\"\n    args = []\n    try:\n        # only supported in python3 - falling back to argspec if not available\n        sig = inspect.signature(operation)\n        args = sig.parameters\n    except AttributeError:\n        sig = inspect.getargspec(operation)  # pylint: disable=deprecated-method, useless-suppression\n        args = sig.args\n\n    arg_docstring_help = option_descriptions(operation)\n    excluded_params = excluded_params or ['self', 'kwargs']\n\n    for arg_name in [a for a in args if a not in excluded_params]:\n        try:\n            # this works in python3\n            default = args[arg_name].default\n            required = default == inspect.Parameter.empty  # pylint: disable=no-member, useless-suppression\n        except TypeError:\n            arg_defaults = (dict(zip(sig.args[-len(sig.defaults):], sig.defaults))\n                            if sig.defaults\n                            else {})\n            default = arg_defaults.get(arg_name)\n            required = arg_name not in arg_defaults\n\n        action = 'store_' + str(not default).lower() if isinstance(default, bool) else None\n\n        try:\n            default = (default\n                       if default != inspect._empty  # pylint: disable=protected-access\n                       else None)\n        except AttributeError:\n            pass\n\n        options_list = ['--' + arg_name.replace('_', '-')]\n        help_str = arg_docstring_help.get(arg_name)\n\n        yield (arg_name, CLICommandArgument(arg_name,\n                                            options_list=options_list,\n                                            required=required,\n                                            default=default,\n                                            help=help_str,\n                                            action=action))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_runtime_version(self):  # pylint: disable=no-self-use\n        import platform\n\n        version_info = '\\n\\n'\n        version_info += 'Python ({}) {}'.format(platform.system(), sys.version)\n        version_info += '\\n\\n'\n        version_info += 'Python location \\'{}\\''.format(sys.executable)\n        version_info += '\\n'\n        return version_info", "response": "Get the runtime information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint version information to the out file.", "response": "def show_version(self):\n        \"\"\" Print version information to the out file. \"\"\"\n        version_info = self.get_cli_version()\n        version_info += self.get_runtime_version()\n        print(version_info, file=self.out_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises an event. Calls each handler in turn with kwargs", "response": "def raise_event(self, event_name, **kwargs):\n        \"\"\" Raise an event. Calls each handler in turn with kwargs\n\n        :param event_name: The name of the event to raise\n        :type event_name: str\n        :param kwargs: Kwargs to be passed to all event handlers\n        \"\"\"\n        handlers = list(self._event_handlers[event_name])\n        logger.debug('Event: %s %s', event_name, handlers)\n        for func in handlers:\n            func(self, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exception_handler(self, ex):  # pylint: disable=no-self-use\n        if isinstance(ex, CLIError):\n            logger.error(ex)\n        else:\n            logger.exception(ex)\n        return 1", "response": "The default exception handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninvokes a command. :param args: The arguments that represent the command :type args: list, tuple :param initial_invocation_data: Prime the in memory collection of key-value data for this invocation. :type initial_invocation_data: dict :param out_file: The file to send output to. If not used, we use out_file for knack.cli.CLI instance :type out_file: file-like object :return: The exit code of the invocation :rtype: int", "response": "def invoke(self, args, initial_invocation_data=None, out_file=None):\n        \"\"\" Invoke a command.\n\n        :param args: The arguments that represent the command\n        :type args: list, tuple\n        :param initial_invocation_data: Prime the in memory collection of key-value data for this invocation.\n        :type initial_invocation_data: dict\n        :param out_file: The file to send output to. If not used, we use out_file for knack.cli.CLI instance\n        :type out_file: file-like object\n        :return: The exit code of the invocation\n        :rtype: int\n        \"\"\"\n        from .util import CommandResultItem\n\n        if not isinstance(args, (list, tuple)):\n            raise TypeError('args should be a list or tuple.')\n        exit_code = 0\n        try:\n            args = self.completion.get_completion_args() or args\n            out_file = out_file or self.out_file\n\n            self.logging.configure(args)\n            logger.debug('Command arguments: %s', args)\n\n            self.raise_event(EVENT_CLI_PRE_EXECUTE)\n            if CLI._should_show_version(args):\n                self.show_version()\n                self.result = CommandResultItem(None)\n            else:\n                self.invocation = self.invocation_cls(cli_ctx=self,\n                                                      parser_cls=self.parser_cls,\n                                                      commands_loader_cls=self.commands_loader_cls,\n                                                      help_cls=self.help_cls,\n                                                      initial_data=initial_invocation_data)\n                cmd_result = self.invocation.execute(args)\n                self.result = cmd_result\n                exit_code = self.result.exit_code\n                output_type = self.invocation.data['output']\n                if cmd_result and cmd_result.result is not None:\n                    formatter = self.output.get_formatter(output_type)\n                    self.output.out(cmd_result, formatter=formatter, out_file=out_file)\n            self.raise_event(EVENT_CLI_POST_EXECUTE)\n        except KeyboardInterrupt as ex:\n            self.result = CommandResultItem(None, error=ex)\n            exit_code = 1\n        except Exception as ex:  # pylint: disable=broad-except\n            exit_code = self.exception_handler(ex)\n            self.result = CommandResultItem(None, error=ex)\n        finally:\n            pass\n        self.result.exit_code = exit_code\n        return exit_code"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the logger for a module.", "response": "def get_logger(module_name=None):\n    \"\"\" Get the logger for a module. If no module name is given, the current CLI logger is returned.\n\n    Example:\n        get_logger(__name__)\n\n    :param module_name: The module to get the logger for\n    :type module_name: str\n    :return: The logger\n    :rtype: logger\n    \"\"\"\n    if module_name:\n        logger_name = '{}.{}'.format(CLI_LOGGER_NAME, module_name)\n    else:\n        logger_name = CLI_LOGGER_NAME\n    return logging.getLogger(logger_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure(self, args):\n        verbose_level = self._determine_verbose_level(args)\n        log_level_config = self.console_log_configs[verbose_level]\n        root_logger = logging.getLogger()\n        cli_logger = logging.getLogger(CLI_LOGGER_NAME)\n        # Set the levels of the loggers to lowest level.\n        # Handlers can override by choosing a higher level.\n        root_logger.setLevel(logging.DEBUG)\n        cli_logger.setLevel(logging.DEBUG)\n        cli_logger.propagate = False\n        if root_logger.handlers and cli_logger.handlers:\n            # loggers already configured\n            return\n        self._init_console_handlers(root_logger, cli_logger, log_level_config)\n        if self.file_log_enabled:\n            self._init_logfile_handlers(root_logger, cli_logger)\n            get_logger(__name__).debug(\"File logging enabled - writing logs to '%s'.\", self.log_dir)", "response": "Configure the loggers with the appropriate log level etc."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the verbose level by reading the arguments.", "response": "def _determine_verbose_level(self, args):\n        \"\"\" Get verbose level by reading the arguments. \"\"\"\n        verbose_level = 0\n        for arg in args:\n            if arg == CLILogging.VERBOSE_FLAG:\n                verbose_level += 1\n            elif arg == CLILogging.DEBUG_FLAG:\n                verbose_level += 2\n        # Use max verbose level if too much verbosity specified.\n        return min(verbose_level, len(self.console_log_configs) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enum_choice_list(data):\n\n    # transform enum types, otherwise assume list of string choices\n    if not data:\n        return {}\n    try:\n        choices = [x.value for x in data]\n    except AttributeError:\n        choices = data\n\n    def _type(value):\n        return next((x for x in choices if x.lower() == value.lower()), value) if value else value\n    params = {\n        'choices': CaseInsensitiveList(choices),\n        'type': _type\n    }\n    return params", "response": "Creates the argparse choices and type kwargs for a supplied list of strings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters an argument for a specific command level", "response": "def register_cli_argument(self, scope, dest, argtype, **kwargs):\n        \"\"\" Add an argument to the argument registry\n\n        :param scope: The command level to apply the argument registration (e.g. 'mygroup mycommand')\n        :type scope: str\n        :param dest: The parameter/destination that this argument is for\n        :type dest: str\n        :param argtype: The argument type for this command argument\n        :type argtype: knack.arguments.CLIArgumentType\n        :param kwargs: see knack.arguments.CLIArgumentType\n        \"\"\"\n        argument = CLIArgumentType(overrides=argtype, **kwargs)\n        self.arguments[scope][dest] = argument"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cli_argument(self, command, name):\n        parts = command.split()\n        result = CLIArgumentType()\n        for index in range(0, len(parts) + 1):\n            probe = ' '.join(parts[0:index])\n            override = self.arguments.get(probe, {}).get(name, None)\n            if override:\n                result.update(override)\n        return result", "response": "Get the CLI argument for the given command and name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef argument(self, argument_dest, arg_type=None, **kwargs):\n        self._check_stale()\n        if not self._applicable():\n            return\n\n        deprecate_action = self._handle_deprecations(argument_dest, **kwargs)\n        if deprecate_action:\n            kwargs['action'] = deprecate_action\n        self.command_loader.argument_registry.register_cli_argument(self.command_scope,\n                                                                    argument_dest,\n                                                                    arg_type,\n                                                                    **kwargs)", "response": "Register an argument for the given command scope using a knack. arguments. CLIArgumentType"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef positional(self, argument_dest, arg_type=None, **kwargs):\n        self._check_stale()\n        if not self._applicable():\n            return\n\n        if self.command_scope not in self.command_loader.command_table:\n            raise ValueError(\"command authoring error: positional argument '{}' cannot be registered to a group-level \"\n                             \"scope '{}'. It must be registered to a specific command.\".format(\n                                 argument_dest, self.command_scope))\n\n        # Before adding the new positional arg, ensure that there are no existing positional arguments\n        # registered for this command.\n        command_args = self.command_loader.argument_registry.arguments[self.command_scope]\n        positional_args = {k: v for k, v in command_args.items() if v.settings.get('options_list') == []}\n        if positional_args and argument_dest not in positional_args:\n            raise CLIError(\"command authoring error: commands may have, at most, one positional argument. '{}' already \"\n                           \"has positional argument: {}.\".format(self.command_scope, ' '.join(positional_args.keys())))\n\n        deprecate_action = self._handle_deprecations(argument_dest, **kwargs)\n        if deprecate_action:\n            kwargs['action'] = deprecate_action\n\n        kwargs['options_list'] = []\n        self.command_loader.argument_registry.register_cli_argument(self.command_scope,\n                                                                    argument_dest,\n                                                                    arg_type,\n                                                                    **kwargs)", "response": "Registers a new positional argument for the given command scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ignore(self, argument_dest, **kwargs):\n        self._check_stale()\n        if not self._applicable():\n            return\n\n        dest_option = ['--__{}'.format(argument_dest.upper())]\n        self.argument(argument_dest, arg_type=ignore_type, options_list=dest_option, **kwargs)", "response": "Register an argument that will be ignored when the entry point is not present in the log."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister extra parameters for the given command.", "response": "def extra(self, argument_dest, **kwargs):\n        \"\"\"Register extra parameters for the given command. Typically used to augment auto-command built\n        commands to add more parameters than the specific SDK method introspected.\n\n        :param argument_dest: The destination argument to add this argument type to\n        :type argument_dest: str\n        :param kwargs: Possible values: `options_list`, `validator`, `completer`, `nargs`, `action`, `const`, `default`,\n                       `type`, `choices`, `required`, `help`, `metavar`. See /docs/arguments.md.\n        \"\"\"\n        self._check_stale()\n        if not self._applicable():\n            return\n\n        if self.command_scope in self.command_loader.command_group_table:\n            raise ValueError(\"command authoring error: extra argument '{}' cannot be registered to a group-level \"\n                             \"scope '{}'. It must be registered to a specific command.\".format(\n                                 argument_dest, self.command_scope))\n\n        deprecate_action = self._handle_deprecations(argument_dest, **kwargs)\n        if deprecate_action:\n            kwargs['action'] = deprecate_action\n        self.command_loader.extra_argument_registry[self.command_scope][argument_dest] = CLICommandArgument(\n            argument_dest, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_command_table(self, args):  # pylint: disable=unused-argument\n        self.cli_ctx.raise_event(EVENT_CMDLOADER_LOAD_COMMAND_TABLE, cmd_tbl=self.command_table)\n        return OrderedDict(self.command_table)", "response": "Load commands into the command table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_arguments(self, command):\n        from knack.arguments import ArgumentsContext\n\n        self.cli_ctx.raise_event(EVENT_CMDLOADER_LOAD_ARGUMENTS, cmd_tbl=self.command_table, command=command)\n        try:\n            self.command_table[command].load_arguments()\n        except KeyError:\n            return\n\n        # ensure global 'cmd' is ignored\n        with ArgumentsContext(self, '') as c:\n            c.ignore('cmd')\n\n        self._apply_parameter_info(command, self.command_table[command])", "response": "Load the arguments for the specified command"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_command(self, name, operation, **kwargs):\n        if not isinstance(operation, six.string_types):\n            raise ValueError(\"Operation must be a string. Got '{}'\".format(operation))\n\n        name = ' '.join(name.split())\n\n        client_factory = kwargs.get('client_factory', None)\n\n        def _command_handler(command_args):\n            op = CLICommandsLoader._get_op_handler(operation)\n            client = client_factory(command_args) if client_factory else None\n            result = op(client, **command_args) if client else op(**command_args)\n            return result\n\n        def arguments_loader():\n            return list(extract_args_from_signature(CLICommandsLoader._get_op_handler(operation),\n                                                    excluded_params=self.excluded_command_handler_args))\n\n        def description_loader():\n            return extract_full_summary_from_signature(CLICommandsLoader._get_op_handler(operation))\n\n        kwargs['arguments_loader'] = arguments_loader\n        kwargs['description_loader'] = description_loader\n\n        cmd = self.command_cls(self.cli_ctx, name, _command_handler, **kwargs)\n        return cmd", "response": "Creates a new command object that can then be added to the command table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport and load the operation handler", "response": "def _get_op_handler(operation):\n        \"\"\" Import and load the operation handler \"\"\"\n        try:\n            mod_to_import, attr_path = operation.split('#')\n            op = import_module(mod_to_import)\n            for part in attr_path.split('.'):\n                op = getattr(op, part)\n            if isinstance(op, types.FunctionType):\n                return op\n            return six.get_method_function(op)\n        except (ValueError, AttributeError):\n            raise ValueError(\"The operation '{}' is invalid.\".format(operation))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a command into the command table.", "response": "def command(self, name, handler_name, **kwargs):\n        \"\"\" Register a command into the command table\n\n        :param name: The name of the command\n        :type name: str\n        :param handler_name: The name of the handler that will be applied to the operations template\n        :type handler_name: str\n        :param kwargs: Kwargs to apply to the command.\n                       Possible values: `client_factory`, `arguments_loader`, `description_loader`, `description`,\n                       `formatter_class`, `table_transformer`, `deprecate_info`, `validator`, `confirmation`.\n        \"\"\"\n        import copy\n\n        command_name = '{} {}'.format(self.group_name, name) if self.group_name else name\n        command_kwargs = copy.deepcopy(self.group_kwargs)\n        command_kwargs.update(kwargs)\n        # don't inherit deprecation info from command group\n        command_kwargs['deprecate_info'] = kwargs.get('deprecate_info', None)\n\n        self.command_loader._populate_command_group_table_with_subgroups(' '.join(command_name.split()[:-1]))  # pylint: disable=protected-access\n        self.command_loader.command_table[command_name] = self.command_loader.create_command(\n            command_name,\n            self.operations_tmpl.format(handler_name),\n            **command_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an object to a dictionary.", "response": "def todict(obj, post_processor=None):  # pylint: disable=too-many-return-statements\n    \"\"\"\n    Convert an object to a dictionary. Use 'post_processor(original_obj, dictionary)' to update the\n    dictionary in the process\n    \"\"\"\n    if isinstance(obj, dict):\n        result = {k: todict(v, post_processor) for (k, v) in obj.items()}\n        return post_processor(obj, result) if post_processor else result\n    if isinstance(obj, list):\n        return [todict(a, post_processor) for a in obj]\n    if isinstance(obj, Enum):\n        return obj.value\n    if isinstance(obj, (date, time, datetime)):\n        return obj.isoformat()\n    if isinstance(obj, timedelta):\n        return str(obj)\n    if hasattr(obj, '_asdict'):\n        return todict(obj._asdict(), post_processor)\n    if hasattr(obj, '__dict__'):\n        result = {to_camel_case(k): todict(v, post_processor)\n                  for k, v in obj.__dict__.items()\n                  if not callable(v) and not k.startswith('_')}\n        return post_processor(obj, result) if post_processor else result\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, args):\n        import colorama\n\n        self.cli_ctx.raise_event(EVENT_INVOKER_PRE_CMD_TBL_CREATE, args=args)\n        cmd_tbl = self.commands_loader.load_command_table(args)\n        command = self._rudimentary_get_command(args)\n        self.cli_ctx.invocation.data['command_string'] = command\n        self.commands_loader.load_arguments(command)\n\n        self.cli_ctx.raise_event(EVENT_INVOKER_POST_CMD_TBL_CREATE, cmd_tbl=cmd_tbl)\n        self.parser.load_command_table(self.commands_loader)\n        self.cli_ctx.raise_event(EVENT_INVOKER_CMD_TBL_LOADED, parser=self.parser)\n\n        arg_check = [a for a in args if a not in ['--verbose', '--debug']]\n        if not arg_check:\n            self.cli_ctx.completion.enable_autocomplete(self.parser)\n            subparser = self.parser.subparsers[tuple()]\n            self.help.show_welcome(subparser)\n            return CommandResultItem(None, exit_code=0)\n\n        if args[0].lower() == 'help':\n            args[0] = '--help'\n\n        self.cli_ctx.completion.enable_autocomplete(self.parser)\n\n        self.cli_ctx.raise_event(EVENT_INVOKER_PRE_PARSE_ARGS, args=args)\n        parsed_args = self.parser.parse_args(args)\n        self.cli_ctx.raise_event(EVENT_INVOKER_POST_PARSE_ARGS, command=parsed_args.command, args=parsed_args)\n\n        self._validation(parsed_args)\n\n        # save the command name (leaf in the tree)\n        self.data['command'] = parsed_args.command\n        cmd = parsed_args.func\n        if hasattr(parsed_args, 'cmd'):\n            parsed_args.cmd = cmd\n        deprecations = getattr(parsed_args, '_argument_deprecations', [])\n        if cmd.deprecate_info:\n            deprecations.append(cmd.deprecate_info)\n\n        params = self._filter_params(parsed_args)\n\n        # search for implicit deprecation\n        path_comps = cmd.name.split()[:-1]\n        implicit_deprecate_info = None\n        while path_comps and not implicit_deprecate_info:\n            implicit_deprecate_info = resolve_deprecate_info(self.cli_ctx, ' '.join(path_comps))\n            del path_comps[-1]\n\n        if implicit_deprecate_info:\n            deprecate_kwargs = implicit_deprecate_info.__dict__.copy()\n            deprecate_kwargs['object_type'] = 'command'\n            del deprecate_kwargs['_get_tag']\n            del deprecate_kwargs['_get_message']\n            deprecations.append(ImplicitDeprecated(**deprecate_kwargs))\n\n        colorama.init()\n        for d in deprecations:\n            print(d.message, file=sys.stderr)\n        colorama.deinit()\n\n        cmd_result = parsed_args.func(params)\n        cmd_result = todict(cmd_result)\n\n        event_data = {'result': cmd_result}\n        self.cli_ctx.raise_event(EVENT_INVOKER_TRANSFORM_RESULT, event_data=event_data)\n        self.cli_ctx.raise_event(EVENT_INVOKER_FILTER_RESULT, event_data=event_data)\n\n        return CommandResultItem(event_data['result'],\n                                 exit_code=0,\n                                 table_transformer=cmd_tbl[parsed_args.command].table_transformer,\n                                 is_query_active=self.data['query_active'])", "response": "Executes the command invocation\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_completion_args(self, is_completion=False, comp_line=None):  # pylint: disable=no-self-use\n        is_completion = is_completion or os.environ.get(ARGCOMPLETE_ENV_NAME)\n        comp_line = comp_line or os.environ.get('COMP_LINE')\n        # The first item is the exe name so ignore that.\n        return comp_line.split()[1:] if is_completion and comp_line else None", "response": "Get the args that will be used to tab completion if completion is active."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef out(self, obj, formatter=None, out_file=None):  # pylint: disable=no-self-use\n        if not isinstance(obj, CommandResultItem):\n            raise TypeError('Expected {} got {}'.format(CommandResultItem.__name__, type(obj)))\n\n        import platform\n        import colorama\n\n        if platform.system() == 'Windows':\n            out_file = colorama.AnsiToWin32(out_file).stream\n        output = formatter(obj)\n        try:\n            print(output, file=out_file, end='')\n        except IOError as ex:\n            if ex.errno == errno.EPIPE:\n                pass\n            else:\n                raise\n        except UnicodeEncodeError:\n            print(output.encode('ascii', 'ignore').decode('utf-8', 'ignore'),\n                  file=out_file, end='')", "response": "Outputs the command result to a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_status_with_media(self, **params):  # pragma: no cover\n        warnings.warn(\n            'This method is deprecated. You should use Twython.upload_media instead.',\n            TwythonDeprecationWarning,\n            stacklevel=2\n        )\n        return self.post('statuses/update_with_media', params=params)", "response": "Updates the authenticating user s current status and attaches media\n        for upload."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a media file to Twitter servers.", "response": "def upload_media(self, **params):\n        \"\"\"Uploads media file to Twitter servers. The file will be available to be attached\n        to a status for 60 minutes. To attach to a update, pass a list of returned media ids\n        to the :meth:`update_status` method using the ``media_ids`` param.\n\n        Docs:\n        https://developer.twitter.com/en/docs/media/upload-media/api-reference/post-media-upload\n\n        \"\"\"\n        # https://developer.twitter.com/en/docs/media/upload-media/api-reference/get-media-upload-status\n        if params and params.get('command', '') == 'STATUS':\n            return self.get('https://upload.twitter.com/1.1/media/upload.json', params=params)\n\n        return self.post('https://upload.twitter.com/1.1/media/upload.json', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_metadata(self, **params):\n        params = json.dumps(params)\n        return self.post(\"https://upload.twitter.com/1.1/media/metadata/create.json\", params=params)", "response": "Adds metadata to a media element"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading a video to Twitter servers in chunks.", "response": "def upload_video(self, media, media_type, media_category=None, size=None, check_progress=False):\n        \"\"\"Uploads video file to Twitter servers in chunks. The file will be available to be attached\n        to a status for 60 minutes. To attach to a update, pass a list of returned media ids\n        to the :meth:`update_status` method using the ``media_ids`` param.\n\n        Upload happens in 3 stages:\n        - INIT call with size of media to be uploaded(in bytes). If this is more than 15mb, twitter will return error.\n        - APPEND calls each with media chunk. This returns a 204(No Content) if chunk is received.\n        - FINALIZE call to complete media upload. This returns media_id to be used with status update.\n\n        Twitter media upload api expects each chunk to be not more than 5mb. We are sending chunk of 1mb each.\n\n        Docs:\n        https://developer.twitter.com/en/docs/media/upload-media/uploading-media/chunked-media-upload\n\n        \"\"\"\n        upload_url = 'https://upload.twitter.com/1.1/media/upload.json'\n        if not size:\n            media.seek(0, os.SEEK_END)\n            size = media.tell()\n            media.seek(0)\n\n        # Stage 1: INIT call\n        params = {\n            'command': 'INIT',\n            'media_type': media_type,\n            'total_bytes': size,\n            'media_category': media_category\n        }\n        response_init = self.post(upload_url, params=params)\n        media_id = response_init['media_id']\n\n        # Stage 2: APPEND calls with 1mb chunks\n        segment_index = 0\n        while True:\n            data = media.read(1*1024*1024)\n            if not data:\n                break\n            media_chunk = BytesIO()\n            media_chunk.write(data)\n            media_chunk.seek(0)\n\n            params = {\n                'command': 'APPEND',\n                'media_id': media_id,\n                'segment_index': segment_index,\n                'media': media_chunk,\n            }\n            self.post(upload_url, params=params)\n            segment_index += 1\n\n        # Stage 3: FINALIZE call to complete upload\n        params = {\n            'command': 'FINALIZE',\n            'media_id': media_id\n        }\n\n        response = self.post(upload_url, params=params)\n\n        # Only get the status if explicity asked to\n        # Default to False\n        if check_progress:\n\n            # Stage 4: STATUS call if still processing\n            params = {\n                'command': 'STATUS',\n                'media_id': media_id\n            }\n\n            # added code to handle if media_category is NOT set and check_progress=True\n            # the API will return a NoneType object in this case\n            try:\n                processing_state = response.get('processing_info').get('state')\n            except AttributeError:\n                return response\n\n            if processing_state:\n                while (processing_state == 'pending' or processing_state == 'in_progress') :\n                    # get the secs to wait\n                    check_after_secs = response.get('processing_info').get('check_after_secs')\n\n                    if check_after_secs:\n                        sleep(check_after_secs)\n                        response = self.get(upload_url, params=params)\n                        # get new state after waiting\n                        processing_state = response.get('processing_info').get('state')\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate one or more hex values that control the color scheme of the authenticating user s profile page on twitter. com.", "response": "def update_profile_colors(self, **params): # pragma: no cover\n        \"\"\"Sets one or more hex values that control the color scheme of the\n        authenticating user's profile page on twitter.com.\n\n        This method is deprecated, replaced by the ``profile_link_color``\n        parameter to :meth:`update_profile`.\n\n        Docs:\n        https://developer.twitter.com/en/docs/accounts-and-users/manage-account-settings/api-reference/post-account-update_profile\n\n        \"\"\"\n        warnings.warn(\n            'This method is deprecated. You should use the'\n            ' profile_link_color parameter in Twython.update_profile instead.',\n            TwythonDeprecationWarning,\n            stacklevel=2\n        )\n        return self.post('account/update_profile_colors', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse and return the first error message", "response": "def _get_error_message(self, response):\n        \"\"\"Parse and return the first error message\"\"\"\n\n        error_message = 'An error occurred processing your request.'\n        try:\n            content = response.json()\n            # {\"errors\":[{\"code\":34,\"message\":\"Sorry,\n            # that page does not exist\"}]}\n            error_message = content['errors'][0]['message']\n        except TypeError:\n            error_message = content['errors']\n        except ValueError:\n            # bad json data from Twitter for an error\n            pass\n        except (KeyError, IndexError):\n            # missing data so fallback to default message\n            pass\n\n        return error_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request to Twitter s API.", "response": "def request(self, endpoint, method='GET', params=None, version='1.1', json_encoded=False):\n        \"\"\"Return dict of response received from Twitter's API\n\n        :param endpoint: (required) Full url or Twitter API endpoint\n                         (e.g. search/tweets)\n        :type endpoint: string\n        :param method: (optional) Method of accessing data, either\n                       GET, POST or DELETE. (default GET)\n        :type method: string\n        :param params: (optional) Dict of parameters (if any) accepted\n                       the by Twitter API endpoint you are trying to\n                       access (default None)\n        :type params: dict or None\n        :param version: (optional) Twitter API version to access\n                        (default 1.1)\n        :type version: string\n        :param json_encoded: (optional) Flag to indicate if this method should send data encoded as json\n                        (default False)\n        :type json_encoded: bool\n\n        :rtype: dict\n        \"\"\"\n\n        if endpoint.startswith('http://'):\n            raise TwythonError('api.twitter.com is restricted to SSL/TLS traffic.')\n\n        # In case they want to pass a full Twitter URL\n        # i.e. https://api.twitter.com/1.1/search/tweets.json\n        if endpoint.startswith('https://'):\n            url = endpoint\n        else:\n            url = '%s/%s.json' % (self.api_url % version, endpoint)\n\n        content = self._request(url, method=method, params=params,\n                                api_call=url, json_encoded=json_encoded)\n\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a specific header from the last API call", "response": "def get_lastfunction_header(self, header, default_return_value=None):\n        \"\"\"Returns a specific header from the last API call\n        This will return None if the header is not present\n\n        :param header: (required) The name of the header you want to get\n                       the value of\n\n        Most useful for the following header information:\n            x-rate-limit-limit,\n            x-rate-limit-remaining,\n            x-rate-limit-class,\n            x-rate-limit-reset\n\n        \"\"\"\n        if self._last_call is None:\n            raise TwythonError('This function must be called after an API call. \\\n                               It delivers header information.')\n\n        return self._last_call['headers'].get(header, default_return_value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_authentication_tokens(self, callback_url=None, force_login=False,\n                                  screen_name=''):\n        \"\"\"Returns a dict including an authorization URL, ``auth_url``, to\n           direct a user to\n\n        :param callback_url: (optional) Url the user is returned to after\n                             they authorize your app (web clients only)\n        :param force_login: (optional) Forces the user to enter their\n                            credentials to ensure the correct users\n                            account is authorized.\n        :param screen_name: (optional) If forced_login is set OR user is\n                            not currently logged in, Prefills the username\n                            input box of the OAuth login screen with the\n                            given value\n\n        :rtype: dict\n        \"\"\"\n        if self.oauth_version != 1:\n            raise TwythonError('This method can only be called when your \\\n                               OAuth version is 1.0.')\n\n        request_args = {}\n        if callback_url:\n            request_args['oauth_callback'] = callback_url\n        response = self.client.get(self.request_token_url, params=request_args)\n\n        if response.status_code == 401:\n            raise TwythonAuthError(response.content,\n                                   error_code=response.status_code)\n        elif response.status_code != 200:\n            raise TwythonError(response.content,\n                               error_code=response.status_code)\n\n        request_tokens = dict(parse_qsl(response.content.decode('utf-8')))\n        if not request_tokens:\n            raise TwythonError('Unable to decode request tokens.')\n\n        oauth_callback_confirmed = request_tokens.get('oauth_callback_confirmed') \\\n            == 'true'\n\n        auth_url_params = {\n            'oauth_token': request_tokens['oauth_token'],\n        }\n\n        if force_login:\n            auth_url_params.update({\n                'force_login': force_login,\n                'screen_name': screen_name\n            })\n\n        # Use old-style callback argument if server didn't accept new-style\n        if callback_url and not oauth_callback_confirmed:\n            auth_url_params['oauth_callback'] = self.callback_url\n\n        request_tokens['auth_url'] = self.authenticate_url + \\\n            '?' + urlencode(auth_url_params)\n\n        return request_tokens", "response": "Returns a dict containing the authentication URL auth_url to the user to the user with the given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_authorized_tokens(self, oauth_verifier):\n        if self.oauth_version != 1:\n            raise TwythonError('This method can only be called when your \\\n                               OAuth version is 1.0.')\n\n        response = self.client.get(self.access_token_url,\n                                   params={'oauth_verifier': oauth_verifier},\n                                   headers={'Content-Type': 'application/\\\n                                   json'})\n\n        if response.status_code == 401:\n            try:\n                try:\n                    # try to get json\n                    content = response.json()\n                except AttributeError:  # pragma: no cover\n                    # if unicode detected\n                    content = json.loads(response.content)\n            except ValueError:\n                content = {}\n\n            raise TwythonError(content.get('error', 'Invalid / expired To \\\n            ken'), error_code=response.status_code)\n\n        authorized_tokens = dict(parse_qsl(response.content.decode('utf-8')))\n        if not authorized_tokens:\n            raise TwythonError('Unable to decode authorized tokens.')\n\n        return authorized_tokens", "response": "Returns a dict of authorized tokens after they go through the authentication_tokens phase."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an OAuth 2 access token to make OAuth 2 authenticated calls.", "response": "def obtain_access_token(self):\n        \"\"\"Returns an OAuth 2 access token to make OAuth 2 authenticated\n        read-only calls.\n\n        :rtype: string\n        \"\"\"\n        if self.oauth_version != 2:\n            raise TwythonError('This method can only be called when your \\\n                               OAuth version is 2.0.')\n\n        data = {'grant_type': 'client_credentials'}\n        basic_auth = HTTPBasicAuth(self.app_key, self.app_secret)\n        try:\n            response = self.client.post(self.request_token_url,\n                                        data=data, auth=basic_auth)\n            content = response.content.decode('utf-8')\n            try:\n                content = content.json()\n            except AttributeError:\n                content = json.loads(content)\n                access_token = content['access_token']\n        except (KeyError, ValueError, requests.exceptions.RequestException):\n            raise TwythonAuthError('Unable to obtain OAuth 2 access token.')\n        else:\n            return access_token"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef construct_api_url(api_url, **params):\n        querystring = []\n        params, _ = _transparent_params(params or {})\n        params = requests.utils.to_key_val_list(params)\n        for (k, v) in params:\n            querystring.append(\n                '%s=%s' % (Twython.encode(k), quote_plus(Twython.encode(v)))\n            )\n        return '%s?%s' % (api_url, '&'.join(querystring))", "response": "Construct a Twitter API url encoded with parameters\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cursor(self, function, return_pages=False, **params):\n        if not callable(function):\n            raise TypeError('.cursor() takes a Twython function as its first \\\n                            argument. Did you provide the result of a \\\n                            function call?')\n\n        if not hasattr(function, 'iter_mode'):\n            raise TwythonError('Unable to create generator for Twython \\\n                               method \"%s\"' % function.__name__)\n\n        while True:\n            content = function(**params)\n\n            if not content:\n                raise StopIteration\n\n            if hasattr(function, 'iter_key'):\n                results = content.get(function.iter_key)\n            else:\n                results = content\n\n            if return_pages:\n                yield results\n            else:\n                for result in results:\n                    yield result\n\n            if function.iter_mode == 'cursor' and \\\n               content['next_cursor_str'] == '0':\n                raise StopIteration\n\n            try:\n                if function.iter_mode == 'id':\n                    # Set max_id in params to one less than lowest tweet id\n                    if hasattr(function, 'iter_metadata'):\n                        # Get supplied next max_id\n                        metadata = content.get(function.iter_metadata)\n                        if 'next_results' in metadata:\n                            next_results = urlsplit(metadata['next_results'])\n                            params = dict(parse_qsl(next_results.query))\n                        else:\n                            # No more results\n                            raise StopIteration\n                    else:\n                        # Twitter gives tweets in reverse chronological order:\n                        params['max_id'] = str(int(content[-1]['id_str']) - 1)\n                elif function.iter_mode == 'cursor':\n                    params['cursor'] = content['next_cursor_str']\n            except (TypeError, ValueError):  # pragma: no cover\n                raise TwythonError('Unable to generate next page of search \\\n                                   results, `page` is not a number.')\n            except (KeyError, AttributeError):  #pragma no cover\n                raise TwythonError('Unable to generate next page of search \\\n                                   results, content has unexpected structure.')", "response": "Returns a generator for results that match a specified query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning HTML for a tweet.", "response": "def html_for_tweet(tweet, use_display_url=True, use_expanded_url=False, expand_quoted_status=False):\n        \"\"\"Return HTML for a tweet (urls, mentions, hashtags, symbols replaced with links)\n\n        :param tweet: Tweet object from received from Twitter API\n        :param use_display_url: Use display URL to represent link\n        (ex. google.com, github.com). Default: True\n        :param use_expanded_url: Use expanded URL to represent link\n        (e.g. http://google.com). Default False\n\n        If use_expanded_url is True, it overrides use_display_url.\n        If use_display_url and use_expanded_url is False, short url will\n        be used (t.co/xxxxx)\n\n        \"\"\"\n        if 'retweeted_status' in tweet:\n            tweet = tweet['retweeted_status']\n\n        if 'extended_tweet' in tweet:\n            tweet = tweet['extended_tweet']\n\n        orig_tweet_text = tweet.get('full_text') or tweet['text']\n\n        display_text_range = tweet.get('display_text_range') or [0, len(orig_tweet_text)]\n        display_text_start, display_text_end = display_text_range[0], display_text_range[1]\n        display_text = orig_tweet_text[display_text_start:display_text_end]\n        prefix_text = orig_tweet_text[0:display_text_start]\n        suffix_text = orig_tweet_text[display_text_end:len(orig_tweet_text)]\n\n        if 'entities' in tweet:\n            # We'll put all the bits of replacement HTML and their starts/ends\n            # in this list:\n            entities = []\n\n            # Mentions\n            if 'user_mentions' in tweet['entities']:\n                for entity in tweet['entities']['user_mentions']:\n                    temp = {}\n                    temp['start'] = entity['indices'][0]\n                    temp['end'] = entity['indices'][1]\n\n                    mention_html = '<a href=\"https://twitter.com/%(screen_name)s\" class=\"twython-mention\">@%(screen_name)s</a>' % {'screen_name': entity['screen_name']}\n\n                    if display_text_start <= temp['start'] <= display_text_end:\n                        temp['replacement'] = mention_html\n                        temp['start'] -= display_text_start\n                        temp['end'] -= display_text_start\n                        entities.append(temp)\n                    else:\n                        # Make the '@username' at the start, before\n                        # display_text, into a link:\n                        sub_expr = r'(?<!>)' + orig_tweet_text[temp['start']:temp['end']] + '(?!</a>)'\n                        prefix_text = re.sub(sub_expr, mention_html, prefix_text)\n\n            # Hashtags\n            if 'hashtags' in tweet['entities']:\n                for entity in tweet['entities']['hashtags']:\n                    temp = {}\n                    temp['start'] = entity['indices'][0] - display_text_start\n                    temp['end'] = entity['indices'][1] - display_text_start\n\n                    url_html = '<a href=\"https://twitter.com/search?q=%%23%(hashtag)s\" class=\"twython-hashtag\">#%(hashtag)s</a>' % {'hashtag': entity['text']}\n\n                    temp['replacement'] = url_html\n                    entities.append(temp)\n\n            # Symbols\n            if 'symbols' in tweet['entities']:\n                for entity in tweet['entities']['symbols']:\n                    temp = {}\n                    temp['start'] = entity['indices'][0] - display_text_start\n                    temp['end'] = entity['indices'][1] - display_text_start\n\n                    url_html = '<a href=\"https://twitter.com/search?q=%%24%(symbol)s\" class=\"twython-symbol\">$%(symbol)s</a>' % {'symbol': entity['text']}\n\n                    temp['replacement'] = url_html\n                    entities.append(temp)\n\n            # URLs\n            if 'urls' in tweet['entities']:\n                for entity in tweet['entities']['urls']:\n                    temp = {}\n                    temp['start'] = entity['indices'][0] - display_text_start\n                    temp['end'] = entity['indices'][1] - display_text_start\n\n                    if use_display_url and entity.get('display_url') and not use_expanded_url:\n                        shown_url = entity['display_url']\n                    elif use_expanded_url and entity.get('expanded_url'):\n                        shown_url = entity['expanded_url']\n                    else:\n                        shown_url = entity['url']\n\n                    url_html = '<a href=\"%s\" class=\"twython-url\">%s</a>' % (entity['url'], shown_url)\n\n                    if display_text_start <= temp['start'] <= display_text_end:\n                        temp['replacement'] = url_html\n                        entities.append(temp)\n                    else:\n                        suffix_text = suffix_text.replace(orig_tweet_text[temp['start']:temp['end']], url_html)\n\n            if 'media' in tweet['entities'] and len(tweet['entities']['media']) > 0:\n                # We just link to the overall URL for the tweet's media,\n                # rather than to each individual item.\n                # So, we get the URL from the first media item:\n                entity = tweet['entities']['media'][0]\n\n                temp = {}\n                temp['start'] = entity['indices'][0]\n                temp['end'] = entity['indices'][1]\n\n                if use_display_url and entity.get('display_url') and not use_expanded_url:\n                    shown_url = entity['display_url']\n                elif use_expanded_url and entity.get('expanded_url'):\n                    shown_url = entity['expanded_url']\n                else:\n                    shown_url = entity['url']\n\n                url_html = '<a href=\"%s\" class=\"twython-media\">%s</a>' % (entity['url'], shown_url)\n\n                if display_text_start <= temp['start'] <= display_text_end:\n                    temp['replacement'] = url_html\n                    entities.append(temp)\n                else:\n                    suffix_text = suffix_text.replace(orig_tweet_text[temp['start']:temp['end']], url_html)\n\n            # Now do all the replacements, starting from the end, so that the\n            # start/end indices still work:\n            for entity in sorted(entities, key=lambda e: e['start'], reverse=True):\n                display_text = display_text[0:entity['start']] + entity['replacement'] + display_text[entity['end']:]\n\n        quote_text = ''\n        if expand_quoted_status and tweet.get('is_quote_status') and tweet.get('quoted_status'):\n            quoted_status = tweet['quoted_status']\n            quote_text += '<blockquote class=\"twython-quote\">%(quote)s<cite><a href=\"%(quote_tweet_link)s\">' \\\n                    '<span class=\"twython-quote-user-name\">%(quote_user_name)s</span>' \\\n                    '<span class=\"twython-quote-user-screenname\">@%(quote_user_screen_name)s</span></a>' \\\n                    '</cite></blockquote>' % \\\n                    {'quote': Twython.html_for_tweet(quoted_status, use_display_url, use_expanded_url, False),\n                     'quote_tweet_link': 'https://twitter.com/%s/status/%s' %\n                                         (quoted_status['user']['screen_name'], quoted_status['id_str']),\n                     'quote_user_name': quoted_status['user']['name'],\n                     'quote_user_screen_name': quoted_status['user']['screen_name']}\n\n        return '%(prefix)s%(display)s%(suffix)s%(quote)s' % {\n            'prefix': '<span class=\"twython-tweet-prefix\">%s</span>' % prefix_text if prefix_text else '',\n            'display': display_text,\n            'suffix': '<span class=\"twython-tweet-suffix\">%s</span>' % suffix_text if suffix_text else '',\n            'quote': quote_text\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstreaming user with the given params", "response": "def user(self, **params):\n        \"\"\"Stream user\n\n        Accepted params found at:\n        https://dev.twitter.com/docs/api/1.1/get/user\n        \"\"\"\n        url = 'https://userstream.twitter.com/%s/user.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef site(self, **params):\n        url = 'https://sitestream.twitter.com/%s/site.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, params=params)", "response": "Stream site with the given params"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self, **params):\n        url = 'https://stream.twitter.com/%s/statuses/filter.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, 'POST', params=params)", "response": "Stream statuses / filter\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstreams statuses/sample :param \\*\\*params: Parameters to send with your stream request Accepted params found at: https://developer.twitter.com/en/docs/tweets/sample-realtime/api-reference/get-statuses-sample", "response": "def sample(self, **params):\n        \"\"\"Stream statuses/sample\n\n        :param \\*\\*params: Parameters to send with your stream request\n\n        Accepted params found at:\n        https://developer.twitter.com/en/docs/tweets/sample-realtime/api-reference/get-statuses-sample\n        \"\"\"\n        url = 'https://stream.twitter.com/%s/statuses/sample.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstream statuses/firehose :param \\*\\*params: Parameters to send with your stream request Accepted params found at: https://dev.twitter.com/docs/api/1.1/get/statuses/firehose", "response": "def firehose(self, **params):\n        \"\"\"Stream statuses/firehose\n\n        :param \\*\\*params: Parameters to send with your stream request\n\n        Accepted params found at:\n        https://dev.twitter.com/docs/api/1.1/get/statuses/firehose\n        \"\"\"\n        url = 'https://stream.twitter.com/%s/statuses/firehose.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dynamic_filter(self):\n\n        url = 'https://stream.twitter.com/%s/statuses/filter.json' \\\n              % self.streamer.api_version\n        self.streamer._request(url, 'POST', params=self.params)", "response": "Stream statuses with dynamic parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts algorithm implementations by speed.", "response": "def optimize(self):\n        \"\"\"Sort algorithm implementations by speed.\n        \"\"\"\n        # load benchmarks results\n        with open(LIBRARIES_FILE, 'r') as f:\n            libs_data = json.load(f)\n        # optimize\n        for alg, libs_names in libs_data.items():\n            libs = self.get_libs(alg)\n            if not libs:\n                continue\n            # drop slow libs\n            self.libs[alg] = [lib for lib in libs if [lib.module_name, lib.func_name] in libs_names]\n            # sort libs by speed\n            self.libs[alg].sort(key=lambda lib: libs_names.index([lib.module_name, lib.func_name]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clone(self):\n        obj = self.__class__()\n        obj.libs = deepcopy(self.libs)\n        return obj", "response": "Clone library manager prototype"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dynamic(self, seq1, seq2):\n        if numpy:\n            lengths = numpy.zeros((len(seq1) + 1, len(seq2) + 1), dtype=numpy.int)\n        else:\n            lengths = [array('L', [0] * (len(seq2) + 1)) for _ in range(len(seq1) + 1)]\n\n        # row 0 and column 0 are initialized to 0 already\n        for i, char1 in enumerate(seq1):\n            for j, char2 in enumerate(seq2):\n                if char1 == char2:\n                    lengths[i + 1][j + 1] = lengths[i][j] + 1\n                else:\n                    lengths[i + 1][j + 1] = max(lengths[i + 1][j], lengths[i][j + 1])\n\n        # read the substring out from the matrix\n        result = ''\n        i, j = len(seq1), len(seq2)\n        while i != 0 and j != 0:\n            if lengths[i][j] == lengths[i - 1][j]:\n                i -= 1\n            elif lengths[i][j] == lengths[i][j - 1]:\n                j -= 1\n            else:\n                assert seq1[i - 1] == seq2[j - 1]\n                result = seq1[i - 1] + result\n                i -= 1\n                j -= 1\n        return result", "response": "Dynamically generate the sequence from seq1 and seq2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalized_distance(self, *sequences):\n        return float(self.distance(*sequences)) / self.maximum(*sequences)", "response": "Get distance from 0 to 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef external_answer(self, *sequences):\n        # if this feature disabled\n        if not getattr(self, 'external', False):\n            return\n        # all external libs doesn't support test_func\n        if hasattr(self, 'test_func') and self.test_func is not self._ident:\n            return\n        # try to get external libs for algorithm\n        libs = libraries.get_libs(self.__class__.__name__)\n        for lib in libs:\n            # if conditions not satisfied\n            if not lib.check_conditions(self, *sequences):\n                continue\n            # if library is not installed yet\n            if not lib.get_function():\n                continue\n\n            prepared_sequences = lib.prepare(*sequences)\n            # fail side libraries silently and try next libs\n            try:\n                return lib.func(*prepared_sequences)\n            except Exception:\n                pass", "response": "Try to get answer from known external libraries."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ident(*elements):\n        try:\n            # for hashable elements\n            return len(set(elements)) == 1\n        except TypeError:\n            # for unhashable elements\n            for e1, e2 in zip(elements, elements[1:]):\n                if e1 != e2:\n                    return False\n            return True", "response": "Return True if all sequences are equal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_sequences(self, *sequences):\n        # by words\n        if not self.qval:\n            return [s.split() for s in sequences]\n        # by chars\n        if self.qval == 1:\n            return sequences\n        # by n-grams\n        return [find_ngrams(s, self.qval) for s in sequences]", "response": "Prepare sequences.\n\n        qval=None: split text by words\n        qval=1: do not split sequences. For text this is mean comparing by letters.\n        qval>1: split sequences by q-grams"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_counters(self, *sequences):\n        # already Counters\n        if all(isinstance(s, Counter) for s in sequences):\n            return sequences\n        return [Counter(s) for s in self._get_sequences(*sequences)]", "response": "Prepare sequences and convert it to Counters.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all elements count from Counter", "response": "def _count_counters(self, counter):\n        \"\"\"Return all elements count from Counter\n        \"\"\"\n        if getattr(self, 'as_set', False):\n            return len(set(counter))\n        else:\n            return sum(counter.values())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _cicled(self, s1, s2):\n        rows = len(s1) + 1\n        cols = len(s2) + 1\n        prev = None\n        if numpy:\n            cur = numpy.arange(cols)\n        else:\n            cur = range(cols)\n\n        for r in range(1, rows):\n            prev, cur = cur, [r] + [0] * (cols - 1)\n            for c in range(1, cols):\n                deletion = prev[c] + 1\n                insertion = cur[c - 1] + 1\n                dist = self.test_func(s1[r - 1], s2[c - 1])\n                edit = prev[c - 1] + (not dist)\n                cur[c] = min(edit, deletion, insertion)\n        return cur[-1]", "response": "Return the number of cicled entries in the two sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_probs(self, *sequences):\n        sequences = self._get_counters(*sequences)\n        counts = self._sum_counters(*sequences)\n        if self.terminator is not None:\n            counts[self.terminator] = 1\n        total_letters = sum(counts.values())\n\n        prob_pairs = {}\n        cumulative_count = 0\n        counts = sorted(counts.items(), key=lambda x: (x[1], x[0]), reverse=True)\n        for char, current_count in counts:\n            prob_pairs[char] = (\n                Fraction(cumulative_count, total_letters),\n                Fraction(current_count, total_letters),\n            )\n            cumulative_count += current_count\n        assert cumulative_count == total_letters\n        return prob_pairs", "response": "Create a probability pairs of the current set of entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gpp(V,E):\n    model = Model(\"gpp\")\n\n    x = {}\n    y = {}\n    for i in V:\n        x[i] = model.addVar(vtype=\"B\", name=\"x(%s)\"%i)\n    for (i,j) in E:\n        y[i,j] = model.addVar(vtype=\"B\", name=\"y(%s,%s)\"%(i,j))\n\n    model.addCons(quicksum(x[i] for i in V) == len(V)/2, \"Partition\")\n\n    for (i,j) in E:\n        model.addCons(x[i] - x[j] <= y[i,j], \"Edge(%s,%s)\"%(i,j))\n        model.addCons(x[j] - x[i] <= y[i,j], \"Edge(%s,%s)\"%(j,i))\n\n    model.setObjective(quicksum(y[i,j] for (i,j) in E), \"minimize\")\n\n    model.data = x\n    return model", "response": "Returns a model for the graph partitioning problem"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gpp_soco(V,E):\n    model = Model(\"gpp model -- soco\")\n\n    x,s,z = {},{},{}\n    for i in V:\n        x[i] = model.addVar(vtype=\"B\", name=\"x(%s)\"%i)\n    for (i,j) in E:\n        s[i,j] = model.addVar(vtype=\"C\", name=\"s(%s,%s)\"%(i,j))\n        z[i,j] = model.addVar(vtype=\"C\", name=\"z(%s,%s)\"%(i,j))\n\n    model.addCons(quicksum(x[i] for i in V) == len(V)/2, \"Partition\")\n\n    for (i,j) in E:\n        model.addCons((x[i] + x[j] -1)*(x[i] + x[j] -1) <= s[i,j], \"S(%s,%s)\"%(i,j))\n        model.addCons((x[j] - x[i])*(x[j] - x[i]) <= z[i,j], \"Z(%s,%s)\"%(i,j))\n        model.addCons(s[i,j] + z[i,j]  == 1, \"P(%s,%s)\"%(i,j))\n\n    # # triangle inequalities (seem to make model slower)\n    # for i in V:\n    #     for j in V:\n    #         for k in V:\n    #             if (i,j) in E and (j,k) in E and (i,k) in E:\n    #                 print(\"\\t***\",(i,j,k)\n    #                 model.addCons(z[i,j] + z[j,k] + z[i,k] <= 2, \"T1(%s,%s,%s)\"%(i,j,k))\n    #                 model.addCons(z[i,j] + s[j,k] + s[i,k] <= 2, \"T2(%s,%s,%s)\"%(i,j,k))\n    #                 model.addCons(s[i,j] + s[j,k] + z[i,k] <= 2, \"T3(%s,%s,%s)\"%(i,j,k))\n    #                 model.addCons(s[i,j] + z[j,k] + s[i,k] <= 2, \"T4(%s,%s,%s)\"%(i,j,k))\n\n    model.setObjective(quicksum(z[i,j] for (i,j) in E), \"minimize\")\n\n    model.data = x,s,z\n    return model", "response": "This function creates a model for the graph partitioning problem in soco\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare data for a random graph", "response": "def make_data(n,prob):\n    \"\"\"make_data: prepare data for a random graph\n    Parameters:\n        - n: number of vertices\n        - prob: probability of existence of an edge, for each pair of vertices\n    Returns a tuple with a list of vertices and a list edges.\n       \"\"\"\n    V = range(1,n+1)\n    E = [(i,j) for i in V for j in V if i < j and random.random() < prob]\n    return V,E"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmaximize flow from source to sink", "response": "def maxflow(V,M,source,sink):\n    \"\"\"maxflow: maximize flow from source to sink, taking into account arc capacities M\n    Parameters:\n        - V: set of vertices\n        - M[i,j]: dictionary or capacity for arcs (i,j)\n        - source: flow origin\n        - sink: flow target\n    Returns a model, ready to be solved.\n        \"\"\"\n    # create max-flow underlying model, on which to find cuts\n    model = Model(\"maxflow\")\n    \n    f = {} # flow variable\n    for (i,j) in M:\n        f[i,j] = model.addVar(lb=-M[i,j], ub=M[i,j], name=\"flow(%s,%s)\"%(i,j))\n\n    cons = {}\n    for i in V:\n        if i != source and i != sink:\n            cons[i] = model.addCons(\n                quicksum(f[i,j] for j in V if i<j and (i,j) in M) - \\\n                quicksum(f[j,i] for j in V if i>j and (j,i) in M) == 0,\n                \"FlowCons(%s)\"%i)\n\n    model.setObjective(quicksum(f[i,j] for (i,j) in M if i==source), \"maximize\")\n\n    # model.write(\"tmp.lp\")\n    model.data = f,cons\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsolve the traveling salesman problem", "response": "def solve_tsp(V,c):\n    \"\"\"solve_tsp -- solve the traveling salesman problem\n       - start with assignment model\n       - check flow from a source to every other node;\n          - if no flow, a sub-cycle has been found --> add cut\n          - otherwise, the solution is optimal\n    Parameters:\n        - V: set/list of nodes in the graph\n        - c[i,j]: cost for traversing edge (i,j)\n    Returns the optimum objective value and the list of edges used.\n    \"\"\"\n\n    def addcut(X):\n        for sink in V[1:]:\n            mflow = maxflow(V,X,V[0],sink)\n            mflow.optimize()\n            f,cons = mflow.data\n            if mflow.ObjVal < 2-EPS:  # no flow to sink, can add cut\n                break\n        else:\n            return False\n\n        #add a cut/constraint\n        CutA = set([V[0]])\n        for i in cons:\n            if cons[i].Pi <= -1+EPS:\n                CutA.add(i)\n        CutB = set(V) - CutA\n        main.addCons(\n            quicksum(x[i,j] for i in CutA for j in CutB if j>i) + \\\n            quicksum(x[j,i] for i in CutA for j in CutB if j<i) >= 2)\n        print(\"mflow:\",mflow.getObjVal(),\"cut:\",CutA,\"+\",CutB,\">= 2\")\n        print(\"mflow:\",mflow.getObjVal(),\"cut:\",[(i,j) for i in CutA for j in CutB if j>i],\"+\",[(j,i) for i in CutA for j in CutB if j<i],\">= 2\")\n        return True\n\n    def isMIP(x):\n        for var in x:\n            if var.vtype == \"CONTINUOUS\":\n                return False\n        return True\n\n    # main part of the solution process:\n    main = Model(\"tsp\")\n    x = {}\n    for i in V:\n        for j in V:\n            if j > i:\n                x[i,j] = main.addVar(ub=1, vtype=\"C\", name=\"x(%s,%s)\"%(i,j))\n\n    for i in V:\n        main.addCons(quicksum(x[j,i] for j in V if j < i) + \\\n                       quicksum(x[i,j] for j in V if j > i) == 2, \"Degree(%s)\"%i)\n\n    main.setObjective(quicksum(c[i,j]*x[i,j] for i in V for j in V if j > i), \"minimize\")\n\n    while True:\n        main.optimize()\n        z = main.getObjVal()\n        X = {}\n        for (i,j) in x:\n            if main.getVal(x[i,j]) > EPS:\n                X[i,j] = main.getVal(x[i,j])\n\n        if addcut(X) == False:  # i.e., components are connected\n            if isMIP():      # integer variables, components connected: solution found\n                break\n            for (i,j) in x:     # all components connected, switch to integer model\n                main.chgVarType(x[i,j], \"BINARY\")\n\n    # process solution\n    edges = []\n    for (i,j) in x:\n        if main.getVal(x[i,j]) > EPS:\n            edges.append((i,j))\n    return main.getObjVal(),edges"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef and_constraint(v=1, sense=\"minimize\"):\n    assert v in [0,1], \"v must be 0 or 1 instead of %s\" % v.__repr__()\n    model, x, y, z = _init()\n    r = model.addVar(\"r\", \"B\")\n    model.addConsAnd([x,y,z], r)\n    model.addCons(x==v)\n    model.setObjective(r, sense=sense)\n    _optimize(\"AND\", model)", "response": "A simple AND constraint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xors_constraint(v=1):\n    assert v in [0,1], \"v must be 0 or 1 instead of %s\" % v.__repr__()\n    model, x, y, z = _init()\n    r = True\n    model.addConsXor([x,y,z], r)\n    model.addCons(x==v)\n    _optimize(\"Standard XOR (as boolean)\", model)", "response": "XOR ( r as boolean ) standard constraint"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a model for the permutation flow shop problem.", "response": "def permutation_flow_shop(n,m,p):\n    \"\"\"gpp -- model for the graph partitioning problem\n    Parameters:\n        - n: number of jobs\n        - m: number of machines\n        - p[i,j]: processing time of job i on machine j\n    Returns a model, ready to be solved.\n    \"\"\"\n    model = Model(\"permutation flow shop\")\n\n    x,s,f = {},{},{}\n    for j in range(1,n+1):\n        for k in range(1,n+1):\n            x[j,k] = model.addVar(vtype=\"B\", name=\"x(%s,%s)\"%(j,k))\n\n    for i in range(1,m+1):\n        for k in range(1,n+1):\n            s[i,k] = model.addVar(vtype=\"C\", name=\"start(%s,%s)\"%(i,k))\n            f[i,k] = model.addVar(vtype=\"C\", name=\"finish(%s,%s)\"%(i,k))\n\n    for j in range(1,n+1):\n        model.addCons(quicksum(x[j,k] for k in range(1,n+1)) == 1, \"Assign1(%s)\"%(j))\n        model.addCons(quicksum(x[k,j] for k in range(1,n+1)) == 1, \"Assign2(%s)\"%(j))\n\n    for i in range(1,m+1):\n        for k in range(1,n+1):\n            if k != n:\n                model.addCons(f[i,k] <= s[i,k+1], \"FinishStart(%s,%s)\"%(i,k))\n            if i != m:\n                model.addCons(f[i,k] <= s[i+1,k], \"Machine(%s,%s)\"%(i,k))\n\n            model.addCons(s[i,k] + quicksum(p[i,j]*x[j,k] for j in range(1,n+1)) <= f[i,k],\n                            \"StartFinish(%s,%s)\"%(i,k))\n\n    model.setObjective(f[m,n], \"minimize\")\n\n    model.data = x,s,f\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares matrix of n random processing times", "response": "def make_data(n,m):\n    \"\"\"make_data: prepare matrix of m times n random processing times\"\"\"\n    p = {}\n    for i in range(1,m+1):\n        for j in range(1,n+1):\n            p[i,j] = random.randint(1,10)\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating example data set", "response": "def example():\n    \"\"\"creates example data set\"\"\"\n    proc = [[2,3,1],[4,2,3],[1,4,1]]\n    p = {}\n    for i in range(3):\n        for j in range(3):\n            p[i+1,j+1] = proc[j][i]\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses multiple selection model", "response": "def flp_nonlinear_mselect(I,J,d,M,f,c,K):\n    \"\"\"flp_nonlinear_mselect --  use multiple selection model\n    Parameters:\n        - I: set of customers\n        - J: set of facilities\n        - d[i]: demand for customer i\n        - M[j]: capacity of facility j\n        - f[j]: fixed cost for using a facility in point j\n        - c[i,j]: unit cost of servicing demand point i from facility j\n        - K: number of linear pieces for approximation of non-linear cost function\n    Returns a model, ready to be solved.\n    \"\"\"\n    a,b = {},{}\n    for j in J:\n        U = M[j]\n        L = 0\n        width = U/float(K)\n        a[j] = [k*width for k in range(K+1)]\n        b[j] = [f[j]*math.sqrt(value) for value in a[j]]\n\n    model = Model(\"nonlinear flp -- piecewise linear version with multiple selection\")\n    \n    x = {}\n    for j in J:\n        for i in I:\n            x[i,j] = model.addVar(vtype=\"C\", name=\"x(%s,%s)\"%(i,j))  # i's demand satisfied from j\n\n    # total volume transported from plant j, corresponding (linearized) cost, selection variable:\n    X,F,z = {},{},{}\n    for j in J:\n        # add constraints for linking piecewise linear part:\n        X[j],F[j],z[j] = mult_selection(model,a[j],b[j])\n        X[j].ub = M[j]\n        # for i in I:\n        #     model.addCons(\n        #         x[i,j] <= \\\n        #         quicksum(min(d[i],a[j][k+1]) * z[j][k] for k in range(K)),\\\n        #         \"Strong(%s,%s)\"%(i,j))\n\n    # constraints for customer's demand satisfaction\n    for i in I:\n        model.addCons(quicksum(x[i,j] for j in J) == d[i], \"Demand(%s)\"%i)\n\n    for j in J:\n        model.addCons(quicksum(x[i,j] for i in I) == X[j], \"Capacity(%s)\"%j)\n\n    model.setObjective(quicksum(F[j] for j in J) +\\\n                       quicksum(c[i,j]*x[i,j] for j in J for i in I),\\\n                       \"minimize\")\n\n    model.data = x,X,F\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncost based on standard parameters", "response": "def cost(a,b,c,e,f,p_min,p):\n    \"\"\"cost: fuel cost based on \"standard\" parameters\n    (with valve-point loading effect)\n    \"\"\"\n    return a + b*p + c*p*p + abs(e*math.sin(f*(p_min-p)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlower approximation of the cost function", "response": "def lower_brkpts(a,b,c,e,f,p_min,p_max,n):\n    \"\"\"lower_brkpts: lower approximation of the cost function\n    Parameters:\n        - a,...,p_max: cost parameters\n        - n: number of breakpoints' intervals to insert between valve points\n    Returns: list of breakpoints in the form [(x0,y0),...,(xK,yK)]\n    \"\"\"\n    EPS = 1.e-12        # for avoiding round-off errors\n    if f == 0: f = math.pi/(p_max-p_min)\n    brk = []\n    nvalve = int(math.ceil(f*(p_max-p_min)/math.pi))\n    for i in range(nvalve+1):\n        p0 = p_min + i*math.pi/f\n        if p0 >= p_max-EPS:\n            brk.append((p_max,cost(a,b,c,e,f,p_min,p_max)))\n            break\n        for j in range(n):\n            p = p0 + j*math.pi/f/n\n            if p >= p_max:\n                break\n            brk.append((p,cost(a,b,c,e,f,p_min,p)))\n    return brk"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eld_another(U,p_min,p_max,d,brk):\n    model = Model(\"Economic load dispatching\")\n\n    # set objective based on piecewise linear approximation\n    p,F,z = {},{},{}\n    for u in U:\n        abrk = [X for (X,Y) in brk[u]]\n        bbrk = [Y for (X,Y) in brk[u]]\n        p[u],F[u],z[u] = convex_comb_sos(model,abrk,bbrk)\n        p[u].lb = p_min[u]\n        p[u].ub = p_max[u]\n\n    # demand satisfaction\n    model.addCons(quicksum(p[u] for u in U) == d, \"demand\")\n\n    # objective\n    model.setObjective(quicksum(F[u] for u in U), \"minimize\")\n\n    model.data = p\n    return model", "response": "eld - an eld_another function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sequence(arcs):\n    succ = {}\n    for (i,j) in arcs:\n        succ[i] = j\n    curr = 1    # first node being visited\n    sol = [curr]\n    for i in range(len(arcs)-2):\n        curr = succ[curr]\n        sol.append(curr)\n    return sol", "response": "make a list of cities to visit from set of arcs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndiets -- model for the modern diet problem Parameters: - F: set of foods - N: set of nutrients - a[i]: minimum intake of nutrient i - b[i]: maximum intake of nutrient i - c[j]: cost of food j - d[j][i]: amount of nutrient i in food j Returns a model, ready to be solved.", "response": "def diet(F,N,a,b,c,d):\n    \"\"\"diet -- model for the modern diet problem\n    Parameters:\n        - F: set of foods\n        - N: set of nutrients\n        - a[i]: minimum intake of nutrient i\n        - b[i]: maximum intake of nutrient i\n        - c[j]: cost of food j\n        - d[j][i]: amount of nutrient i in food j\n    Returns a model, ready to be solved.\n    \"\"\"\n\n    model = Model(\"modern diet\")\n\n    # Create variables\n    x,y,z = {},{},{}\n    for j in F:\n        x[j] = model.addVar(vtype=\"I\", name=\"x(%s)\"%j)\n        y[j] = model.addVar(vtype=\"B\", name=\"y(%s)\"%j)\n    for i in N:\n        z[i] = model.addVar(lb=a[i], ub=b[i], name=\"z(%s)\"%j)\n    v = model.addVar(vtype=\"C\", name=\"v\")\n\n    # Constraints:\n    for i in N:\n        model.addCons(quicksum(d[j][i]*x[j] for j in F) == z[i], name=\"Nutr(%s)\"%i)\n\n    model.addCons(quicksum(c[j]*x[j] for j in F) == v, name=\"Cost\")\n\n    for j in F:\n        model.addCons(y[j] <= x[j], name=\"Eat(%s)\"%j)\n\n    # Objective:\n    model.setObjective(quicksum(y[j] for j in F), \"maximize\")\n    model.data = x,y,z,v\n\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_inst():\n    F,c,d = multidict({       # cost # composition\n        \"QPounder\" :  [ 1.84, {\"Cal\":510, \"Carbo\":34, \"Protein\":28,\n                               \"VitA\":15, \"VitC\":  6, \"Calc\":30, \"Iron\":20}],\n        \"McLean\"   :  [ 2.19, {\"Cal\":370, \"Carbo\":35, \"Protein\":24, \"VitA\":15,\n                               \"VitC\": 10, \"Calc\":20, \"Iron\":20}],\n        \"Big Mac\"  :  [ 1.84, {\"Cal\":500, \"Carbo\":42, \"Protein\":25,\n                               \"VitA\": 6, \"VitC\":  2, \"Calc\":25, \"Iron\":20}],\n        \"FFilet\"   :  [ 1.44, {\"Cal\":370, \"Carbo\":38, \"Protein\":14,\n                               \"VitA\": 2, \"VitC\":  0, \"Calc\":15, \"Iron\":10}],\n        \"Chicken\"  :  [ 2.29, {\"Cal\":400, \"Carbo\":42, \"Protein\":31,\n                               \"VitA\": 8, \"VitC\": 15, \"Calc\":15, \"Iron\": 8}],\n        \"Fries\"    :  [  .77, {\"Cal\":220, \"Carbo\":26, \"Protein\": 3,\n                               \"VitA\": 0, \"VitC\": 15, \"Calc\": 0, \"Iron\": 2}],\n        \"McMuffin\" :  [ 1.29, {\"Cal\":345, \"Carbo\":27, \"Protein\":15,\n                               \"VitA\": 4, \"VitC\":  0, \"Calc\":20, \"Iron\":15}],\n        \"1% LFMilk\":  [  .60, {\"Cal\":110, \"Carbo\":12, \"Protein\": 9,\n                               \"VitA\":10, \"VitC\":  4, \"Calc\":30, \"Iron\": 0}],\n        \"OrgJuice\" :  [  .72, {\"Cal\": 80, \"Carbo\":20, \"Protein\": 1,\n                               \"VitA\": 2, \"VitC\":120, \"Calc\": 2, \"Iron\": 2}],\n        })\n\n    N,a,b = multidict({       # min,max intake\n        \"Cal\"     : [ 2000,  None ],\n        \"Carbo\"   : [  350,  375 ],\n        \"Protein\" : [   55,  None ],\n        \"VitA\"    : [  100,  None ],\n        \"VitC\"    : [  100,  None ],\n        \"Calc\"    : [  100,  None ],\n        \"Iron\"    : [  100,  None ],\n     })\n\n    return F,N,a,b,c,d", "response": "make_inst - prepare data for the diet model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef staff(I,T,N,J,S,c,b):\n    Ts = range(1,T+1)\n    model = Model(\"staff scheduling\")\n\n    x = {}\n    for t in Ts:\n        for j in J:\n            for i in I:\n                x[i,t,j] = model.addVar(vtype=\"B\", name=\"x(%s,%s,%s)\" % (i,t,j))\n\n\n    model.setObjective(quicksum(c[i,t,j]*x[i,t,j] for i in I for t in Ts for j in J if j != 0),\n                       \"minimize\")\n\n    for t in Ts:\n        for j in J:\n            if j == 0:\n                continue\n            model.addCons(quicksum(x[i,t,j] for i in I) >= b[t,j], \"Cover(%s,%s)\" % (t,j))\n    for i in I:\n        model.addCons(quicksum(x[i,t,j] for t in Ts for j in J if j != 0) == N, \"Work(%s)\"%i)\n        for t in Ts:\n            model.addCons(quicksum(x[i,t,j] for j in J) == 1, \"Assign(%s,%s)\" % (i,t))\n            for j in J:\n                if j != 0:\n                    model.addCons(x[i,t,j] + quicksum(x[i,t,k] for k in J if k != j and k != 0) <= 1,\\\n                                    \"Require(%s,%s,%s)\" % (i,t,j))\n        for t in range(2,T):\n            for j in S:\n                model.addCons(x[i,t-1,j] + x[i,t+1,j] >= x[i,t,j], \"SameShift(%s,%s,%s)\" % (i,t,j))\n\n\n    model.data = x\n    return model", "response": "Return a staff self model ready to be solved."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes the example for the single item lot sizing", "response": "def mk_example():\n    \"\"\"mk_example: book example for the single item lot sizing\"\"\"\n    T = 5\n    _,f,c,d,h = multidict({\n        1 :  [3,1,5,1],\n        2 :  [3,1,7,1],\n        3 :  [3,3,3,1],\n        4 :  [3,3,6,1],\n        5 :  [3,3,4,1],\n        })\n\n    return T,f,c,d,h"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mctransp(I,J,K,c,d,M):\n\n    model = Model(\"multi-commodity transportation\")\n\n    # Create variables\n    x = {}\n    for (i,j,k) in c:\n        x[i,j,k] = model.addVar(vtype=\"C\", name=\"x(%s,%s,%s)\" % (i,j,k), obj=c[i,j,k])\n\n    # tuplelist is a Gurobi data structure to manage lists of equal sized tuples - try itertools as alternative\n    arcs = tuplelist([(i,j,k) for (i,j,k) in x])\n\n    # Demand constraints\n    for i in I:\n        for k in K:\n            model.addCons(sum(x[i,j,k] for (i,j,k) in arcs.select(i,\"*\",k)) == d[i,k], \"Demand(%s,%s)\" % (i,k))\n\n    # Capacity constraints\n    for j in J:\n        model.addCons(sum(x[i,j,k] for (i,j,k) in arcs.select(\"*\",j,\"*\")) <= M[j], \"Capacity(%s)\" % j)\n\n    model.data = x\n    return model", "response": "This function solves the Multi - Commodity Transportation problem for solving the Multi - Commodity Transportation problem."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solveCuttingStock(w,q,B):\n    t = []      # patterns\n    m = len(w)\n\n    # Generate initial patterns with one size for each item width\n    for (i,width) in enumerate(w):\n        pat = [0]*m  # vector of number of orders to be packed into one roll (bin)\n        pat[i] = int(B/width)\n        t.append(pat)\n\n    # if LOG:\n    #     print \"sizes of orders=\",w\n    #     print \"quantities of orders=\",q\n    #     print \"roll size=\",B\n    #     print \"initial patterns\",t\n\n    K = len(t)\n    master = Model(\"master LP\") # master LP problem\n    x = {}\n\n    for k in range(K):\n        x[k] = master.addVar(vtype=\"I\", name=\"x(%s)\"%k)\n\n    orders = {}\n\n    for i in range(m):\n        orders[i] = master.addCons(\n            quicksum(t[k][i]*x[k] for k in range(K) if t[k][i] > 0) >= q[i], \"Order(%s)\"%i)\n\n    master.setObjective(quicksum(x[k] for k in range(K)), \"minimize\")\n\n    # master.Params.OutputFlag = 0 # silent mode\n\n    # iter = 0\n    while True:\n        # print \"current patterns:\"\n        # for ti in t:\n        #     print ti\n        # print\n\n        # iter += 1\n        relax = master.relax()\n        relax.optimize()\n        pi = [relax.getDualsolLinear(c) for c in relax.getConss()] # keep dual variables\n\n        knapsack = Model(\"KP\")     # knapsack sub-problem\n        knapsack.setMaximize       # maximize\n        y = {}\n\n        for i in range(m):\n            y[i] = knapsack.addVar(lb=0, ub=q[i], vtype=\"I\", name=\"y(%s)\"%i)\n\n        knapsack.addCons(quicksum(w[i]*y[i] for i in range(m)) <= B, \"Width\")\n\n        knapsack.setObjective(quicksum(pi[i]*y[i] for i in range(m)), \"maximize\")\n\n        knapsack.hideOutput() # silent mode\n        knapsack.optimize()\n        # if LOG:\n        #     print \"objective of knapsack problem:\", knapsack.ObjVal\n        if knapsack.getObjVal() < 1+EPS: # break if no more columns\n            break\n\n        pat = [int(y[i].X+0.5) for i in y]      # new pattern\n        t.append(pat)\n        # if LOG:\n        #     print \"shadow prices and new pattern:\"\n        #     for (i,d) in enumerate(pi):\n        #         print \"\\t%5s%12s%7s\" % (i,d,pat[i])\n        #     print\n\n        # add new column to the master problem\n        col = Column()\n        for i in range(m):\n            if t[K][i] > 0:\n                col.addTerms(t[K][i], orders[i])\n        x[K] = master.addVar(obj=1, vtype=\"I\", name=\"x(%s)\"%K, column=col)\n\n        # master.write(\"MP\" + str(iter) + \".lp\")\n        K += 1\n\n\n    # Finally, solve the IP\n    # if LOG:\n    #     master.Params.OutputFlag = 1 # verbose mode\n    master.optimize()\n\n    # if LOG:\n    #     print\n    #     print \"final solution (integer master problem):  objective =\", master.ObjVal\n    #     print \"patterns:\"\n    #     for k in x:\n    #         if x[k].X > EPS:\n    #             print \"pattern\",k,\n    #             print \"\\tsizes:\",\n    #             print [w[i] for i in range(m) if t[k][i]>0 for j in range(t[k][i]) ],\n    #             print \"--> %s rolls\" % int(x[k].X+.5)\n\n    rolls = []\n    for k in x:\n        for j in range(int(x[k].X + .5)):\n            rolls.append(sorted([w[i] for i in range(m) if t[k][i]>0 for j in range(t[k][i])]))\n    rolls.sort()\n    return rolls", "response": "This function solves the cutting stock problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mkCuttingStock(s):\n    w,q = [],[]   # list of different widths (sizes) of items, their quantities\n    for item in sorted(s):\n        if w == [] or item != w[-1]:\n            w.append(item)\n            q.append(1)\n        else:\n            q[-1] += 1\n    return w,q", "response": "convert a bin packing instance into cutting stock format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a cutting stock instance into a bin packing format", "response": "def mkBinPacking(w,q):\n    \"\"\"mkBinPacking: convert a cutting stock instance into bin packing format\"\"\"\n    s = []\n    for j in range(len(w)):\n        for i in range(q[j]):\n            s.append(w[j])\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a model for solving the transportation problem", "response": "def transp(I,J,c,d,M):\n    \"\"\"transp -- model for solving the transportation problem\n    Parameters:\n        I - set of customers\n        J - set of facilities\n        c[i,j] - unit transportation cost on arc (i,j)\n        d[i] - demand at node i\n        M[j] - capacity\n    Returns a model, ready to be solved.\n    \"\"\"\n\n    model = Model(\"transportation\")\n\n    # Create variables\n    x = {}\n\n    for i in I:\n        for j in J:\n            x[i,j] = model.addVar(vtype=\"C\", name=\"x(%s,%s)\" % (i, j))\n\n    # Demand constraints\n    for i in I:\n        model.addCons(quicksum(x[i,j] for j in J if (i,j) in x) == d[i], name=\"Demand(%s)\" % i)\n\n    # Capacity constraints\n    for j in J:\n        model.addCons(quicksum(x[i,j] for i in I if (i,j) in x) <= M[j], name=\"Capacity(%s)\" % j)\n\n    # Objective\n    model.setObjective(quicksum(c[i,j]*x[i,j]  for (i,j) in x), \"minimize\")\n\n    model.optimize()\n\n    model.data = x\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_inst1():\n    I,d = multidict({1:80, 2:270, 3:250 , 4:160, 5:180}) # demand\n    J,M = multidict({1:500, 2:500, 3:500})               # capacity\n    c = {(1,1):4,    (1,2):6,    (1,3):9,  # cost\n         (2,1):5,    (2,2):4,    (2,3):7,\n         (3,1):6,    (3,2):3,    (3,3):4,\n         (4,1):8,    (4,2):5,    (4,3):3,\n         (5,1):10,   (5,2):8,    (5,3):4,\n         }\n    return I,J,c,d,M", "response": "creates example data set 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating example data set 2", "response": "def make_inst2():\n    \"\"\"creates example data set 2\"\"\"\n    I,d = multidict({1:45, 2:20, 3:30 , 4:30}) # demand\n    J,M = multidict({1:35, 2:50, 3:40})        # capacity\n    c = {(1,1):8,    (1,2):9,    (1,3):14  ,   # {(customer,factory) : cost<float>}\n         (2,1):6,    (2,2):12,   (2,3):9   ,\n         (3,1):10,   (3,2):13,   (3,3):16  ,\n         (4,1):9,    (4,2):7,    (4,3):5   ,\n         }\n    return I,J,c,d,M"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a value is even or odd per each value in a example list.", "response": "def parity(number):\n    \"\"\"\n    Prints if a value is even/odd/neither per each value in a example list\n\n    This example is made for newcomers and motivated by:\n    - modulus is unsupported for pyscipopt.scip.Variable and int\n    - variables are non-integer by default\n    Based on this: #172#issuecomment-394644046\n\n    Args:\n        number: value which parity is checked\n\n    Returns:\n        sval: 1 if number is odd, 0 if number is even, -1 if neither\n    \"\"\"\n    sval = -1\n    if verbose:\n        print(80*\"*\")\n    try:\n        assert number == int(round(number))\n        m = Model()\n        m.hideOutput()\n\n        # x and n are integer, s is binary\n        # Irrespective to their type, variables are non-negative by default\n        # since 0 is the default lb. To allow for negative values, give None\n        # as lower bound.\n        # (None means -infinity as lower bound and +infinity as upper bound)\n        x = m.addVar(\"x\", vtype=\"I\", lb=None, ub=None) #ub=None is default\n        n = m.addVar(\"n\", vtype=\"I\", lb=None)\n        s = m.addVar(\"s\", vtype=\"B\")\n        # CAVEAT: if number is negative, x's lower bound must be None\n        # if x is set by default as non-negative and number is negative:\n        #     there is no feasible solution (trivial) but the program\n        #     does not highlight which constraints conflict.\n\n        m.addCons(x==number)\n\n        # minimize the difference between the number and twice a natural number\n        m.addCons(s == x-2*n)\n        m.setObjective(s)\n        m.optimize()\n\n        assert m.getStatus() == \"optimal\"\n        boolmod = m.getVal(s) == m.getVal(x)%2\n        if verbose:\n            for v in m.getVars():\n                print(\"%*s: %d\" % (fmtlen, v,m.getVal(v)))\n            print(\"%*d%%2 == %d?\" % (fmtlen, m.getVal(x), m.getVal(s)))\n            print(\"%*s\" % (fmtlen, boolmod))\n\n        xval = m.getVal(x)\n        sval = m.getVal(s)\n        sstr = sdic[sval]\n        print(\"%*d is %s\" % (fmtlen, xval, sstr))\n    except (AssertionError, TypeError):\n        print(\"%*s is neither even nor odd!\" % (fmtlen, number.__repr__()))\n    finally:\n        if verbose:\n            print(80*\"*\")\n            print(\"\")\n    return sval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndiet -- model for the modern diet problem Parameters: F - set of foods N - set of nutrients a[i] - minimum intake of nutrient i b[i] - maximum intake of nutrient i c[j] - cost of food j d[j][i] - amount of nutrient i in food j Returns a model, ready to be solved.", "response": "def diet(F,N,a,b,c,d):\n    \"\"\"diet -- model for the modern diet problem\n    Parameters:\n        F - set of foods\n        N - set of nutrients\n        a[i] - minimum intake of nutrient i\n        b[i] - maximum intake of nutrient i\n        c[j] - cost of food j\n        d[j][i] - amount of nutrient i in food j\n    Returns a model, ready to be solved.\n    \"\"\"\n    model = Model(\"modern diet\")\n\n    # Create variables\n    x,y,z = {},{},{}\n    for j in F:\n        x[j] = model.addVar(vtype=\"I\", name=\"x(%s)\" % j)\n\n    for i in N:\n        z[i] = model.addVar(lb=a[i], ub=b[i], vtype=\"C\", name=\"z(%s)\" % i)\n\n    # Constraints:\n    for i in N:\n        model.addCons(quicksum(d[j][i]*x[j] for j in F) == z[i], name=\"Nutr(%s)\" % i)\n\n    model.setObjective(quicksum(c[j]*x[j]  for j in F), \"minimize\")\n\n    model.data = x,y,z\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a multi - constrained knapsack model for solving the multi - constrained knapsack.", "response": "def mkp(I,J,v,a,b):\n    \"\"\"mkp -- model for solving the multi-constrained knapsack\n    Parameters:\n        - I: set of dimensions\n        - J: set of items\n        - v[j]: value of item j\n        - a[i,j]: weight of item j on dimension i\n        - b[i]: capacity of knapsack on dimension i\n    Returns a model, ready to be solved.\n    \"\"\"\n    model = Model(\"mkp\")\n\n    # Create Variables\n    x = {}\n    for j in J:\n        x[j] = model.addVar(vtype=\"B\", name=\"x(%s)\"%j)\n\n    # Create constraints\n    for i in I:\n        model.addCons(quicksum(a[i,j]*x[j] for j in J) <= b[i], \"Capacity(%s)\"%i)\n\n    # Objective\n    model.setObjective(quicksum(v[j]*x[j] for j in J), \"maximize\")\n    model.data = x\n\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating example data set", "response": "def example():\n    \"\"\"creates example data set\"\"\"\n    J,v = multidict({1:16, 2:19, 3:23, 4:28})\n    a = {(1,1):2,    (1,2):3,    (1,3):4,    (1,4):5,\n         (2,1):3000, (2,2):3500, (2,3):5100, (2,4):7200,\n         }\n    I,b = multidict({1:7, 2:10000})\n    return I,J,v,a,b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eoq(I,F,h,d,w,W,a0,aK,K):\n\n    # construct points for piecewise-linear relation, store in a,b\n    a,b = {},{}\n    delta = float(aK-a0)/K\n    for i in I:\n        for k in range(K):\n            T = a0 + delta*k\n            a[i,k] = T                          # abscissa: cycle time\n            b[i,k] = F[i]/T + h[i]*d[i]*T/2.    # ordinate: (convex) cost for this cycle time\n\n    model = Model(\"multi-item, capacitated EOQ\")\n\n    x,c,w_ = {},{},{}\n    for i in I:\n        x[i] = model.addVar(vtype=\"C\", name=\"x(%s)\"%i)  # cycle time for item i\n        c[i] = model.addVar(vtype=\"C\", name=\"c(%s)\"%i)  # total cost for item i\n        for k in range(K):\n            w_[i,k] = model.addVar(ub=1, vtype=\"C\", name=\"w(%s,%s)\"%(i,k)) #todo ??\n\n    for i in I:\n        model.addCons(quicksum(w_[i,k] for k in range(K)) == 1)\n        model.addCons(quicksum(a[i,k]*w_[i,k] for k in range(K)) == x[i])\n        model.addCons(quicksum(b[i,k]*w_[i,k] for k in range(K)) == c[i])\n\n    model.addCons(quicksum(w[i]*d[i]*x[i] for i in I) <= W)\n\n    model.setObjective(quicksum(c[i] for i in I), \"minimize\")\n\n    model.data = x,w\n    return model", "response": "multi - item capacitated economic ordering quantity model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scheduling_time_index(J,p,r,w):\n    model = Model(\"scheduling: time index\")\n    T = max(r.values()) + sum(p.values())\n    X = {}   # X[j,t]=1 if job j starts processing at time t, 0 otherwise\n    for j in J:\n        for t in range(r[j], T-p[j]+2):\n            X[j,t] = model.addVar(vtype=\"B\", name=\"x(%s,%s)\"%(j,t))\n\n    for j in J:\n        model.addCons(quicksum(X[j,t] for t in range(1,T+1) if (j,t) in X) == 1, \"JobExecution(%s)\"%(j))\n\n    for t in range(1,T+1):\n        ind = [(j,t2) for j in J for t2 in range(t-p[j]+1,t+1) if (j,t2) in X]\n        if ind != []:\n            model.addCons(quicksum(X[j,t2] for (j,t2) in ind) <= 1, \"MachineUB(%s)\"%t)\n\n    model.setObjective(quicksum((w[j] * (t - 1 + p[j])) * X[j,t] for (j,t) in X), \"minimize\")\n\n    model.data = X\n    return model", "response": "This function returns a model for the one machine total weighted tardiness problem with the time index formulation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate data for the one machine scheduling problem.", "response": "def make_data(n):\n    \"\"\"\n    Data generator for the one machine scheduling problem.\n    \"\"\"\n    p,r,d,w = {},{},{},{}\n\n    J = range(1,n+1)\n\n    for j in J:\n        p[j] = random.randint(1,4)\n        w[j] = random.randint(1,3)\n\n    T = sum(p)\n    for j in J:\n        r[j] = random.randint(0,5)\n        d[j] = r[j] + random.randint(0,5)\n\n    return J,p,r,d,w"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vrp(V, c, m, q, Q):\n\n    model = Model(\"vrp\")\n    vrp_conshdlr = VRPconshdlr()\n\n    x = {}\n    for i in V:\n        for j in V:\n            if j > i and i == V[0]:       # depot\n                x[i,j] = model.addVar(ub=2, vtype=\"I\", name=\"x(%s,%s)\"%(i,j))\n            elif j > i:\n                x[i,j] = model.addVar(ub=1, vtype=\"I\", name=\"x(%s,%s)\"%(i,j))\n\n    model.addCons(quicksum(x[V[0],j] for j in V[1:]) == 2*m, \"DegreeDepot\")\n    for i in V[1:]:\n        model.addCons(quicksum(x[j,i] for j in V if j < i) +\n                        quicksum(x[i,j] for j in V if j > i) == 2, \"Degree(%s)\"%i)\n\n    model.setObjective(quicksum(c[i,j]*x[i,j] for i in V for j in V if j>i), \"minimize\")\n    model.data = x\n\n    return model, vrp_conshdlr", "response": "solve the vehicle routing problem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_data(n):\n    V = range(1,n+1)\n    x = dict([(i, random.random()) for i in V])\n    y = dict([(i, random.random()) for i in V])\n    c, q = {}, {}\n    Q = 100\n    for i in V:\n        q[i] = random.randint(10, 20)\n        for j in V:\n            if j > i:\n                c[i, j] = distance(x[i], y[i], x[j], y[j])\n    return V, c, q, Q", "response": "make_data - compute matrix distance based on euclidean distance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding cuts if necessary and return whether model is feasible", "response": "def addCuts(self, checkonly):\n        \"\"\"add cuts if necessary and return whether model is feasible\"\"\"\n        cutsadded = False\n        edges = []\n        x = self.model.data\n        for (i, j) in x:\n            if self.model.getVal(x[i, j]) > .5:\n                if i != V[0] and j != V[0]:\n                    edges.append((i, j))\n        G = networkx.Graph()\n        G.add_edges_from(edges)\n        Components = list(networkx.connected_components(G))\n        for S in Components:\n            S_card = len(S)\n            q_sum = sum(q[i] for i in S)\n            NS = int(math.ceil(float(q_sum) / Q))\n            S_edges = [(i, j) for i in S for j in S if i < j and (i, j) in edges]\n            if S_card >= 3 and (len(S_edges) >= S_card or NS > 1):\n                cutsadded = True\n                if checkonly:\n                    break\n                else:\n                    self.model.addCons(quicksum(x[i, j] for i in S for j in S if j > i) <= S_card - NS)\n                    print(\"adding cut for\", S_edges)\n\n        return cutsadded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate example data set", "response": "def make_data(n,m):\n    \"\"\"creates example data set\"\"\"\n    I = range(1,n+1)\n    J = range(1,m+1)\n    x,y,w = {},{},{}\n    for i in I:\n        x[i] = random.randint(0,100)\n        y[i] = random.randint(0,100)\n        w[i] = random.randint(1,5)\n    return I,J,x,y,w"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef markowitz(I,sigma,r,alpha):\n    model = Model(\"markowitz\")\n\n    x = {}\n    for i in I:\n        x[i] = model.addVar(vtype=\"C\", name=\"x(%s)\"%i)  # quantity of i to buy\n\n    model.addCons(quicksum(r[i]*x[i] for i in I) >= alpha)\n    model.addCons(quicksum(x[i] for i in I) == 1)\n\n    # set nonlinear objective: SCIP only allow for linear objectives hence the following\n    obj = model.addVar(vtype=\"C\", name=\"objective\", lb = None, ub = None)  # auxiliary variable to represent objective\n    model.addCons(quicksum(sigma[i]**2 * x[i] * x[i] for i in I) <= obj)\n    model.setObjective(obj, \"minimize\")\n\n    model.data = x\n    return model", "response": "Simple markowitz model for portfolio optimization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a model for the modified markowitz portfolio optimization.", "response": "def p_portfolio(I,sigma,r,alpha,beta):\n    \"\"\"p_portfolio -- modified markowitz model for portfolio optimization.\n    Parameters:\n        - I: set of items\n        - sigma[i]: standard deviation of item i\n        - r[i]: revenue of item i\n        - alpha: acceptance threshold\n        - beta: desired confidence level\n    Returns a model, ready to be solved.\n    \"\"\"\n\n    model = Model(\"p_portfolio\")\n\n    x = {}\n    for i in I:\n        x[i] = model.addVar(vtype=\"C\", name=\"x(%s)\"%i)  # quantity of i to buy\n    rho = model.addVar(vtype=\"C\", name=\"rho\")\n    rhoaux = model.addVar(vtype=\"C\", name=\"rhoaux\")\n\n    model.addCons(rho == quicksum(r[i]*x[i] for i in I))\n    model.addCons(quicksum(x[i] for i in I) == 1)\n\n    model.addCons(rhoaux == (alpha - rho)*(1/phi_inv(beta))) #todo\n    model.addCons(quicksum(sigma[i]**2 * x[i] * x[i] for i in I) <=  rhoaux * rhoaux)\n\n    model.setObjective(rho, \"maximize\")\n\n    model.data = x\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction for solving the model updating candidate solutions list Will add to cand all the intermediate solutions found and the optimum will be added to cand all the intermediate solutions found and the optimum will be removed from cand", "response": "def optimize(model,cand):\n    \"\"\"optimize: function for solving the model, updating candidate solutions' list\n    Will add to cand all the intermediate solutions found, as well as the optimum\n    Parameters:\n        - model: Gurobi model object\n        - cand: list of pairs of objective functions (for appending more solutions)\n    Returns the solver's exit status\n    \"\"\"\n    model.hideOutput()\n    model.optimize()\n    x,y,C,T = model.data\n    status = model.getStatus()\n    if status == \"optimal\":\n        # collect suboptimal solutions\n        solutions = model.getSols()\n        for sol in solutions:\n            cand.append((model.getSolVal(T, sol), model.getSolVal(C)))\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef base_model(n,c,t):\n    from atsp import mtz_strong\n    model = mtz_strong(n,c)     # model for minimizing cost\n    x,u = model.data\n\n    # some auxiliary information\n    C = model.addVar(vtype=\"C\", name=\"C\")       # for computing solution cost\n    T = model.addVar(vtype=\"C\", name=\"T\")       # for computing solution time\n\n    model.addCons(T == quicksum(t[i,j]*x[i,j] for (i,j) in x), \"Time\")\n    model.addCons(C == quicksum(c[i,j]*x[i,j] for (i,j) in x), \"Cost\")\n\n    model.data = x,u,C,T\n    return model", "response": "This function creates a base model for the atsp and returns the list of candidate solutions that are at the given time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef solve_segment_time(n,c,t,segments):\n\n    model = base_model(n,c,t)   # base model for minimizing cost or time\n    x,u,C,T = model.data\n\n    # store the set of solutions for plotting\n    cand = []\n    # print(\"optimizing time\"\n    model.setObjective(T, \"minimize\")\n    stat1 = optimize(model,cand)\n\n    # print(\"optimizing cost\"\n    model.setObjective(C, \"minimize\")\n    stat2 = optimize(model,cand)\n\n    if stat1 != \"optimal\" or stat2 != \"optimal\":\n        return []\n\n    times = [ti for (ti,ci) in cand]\n    max_time = max(times)\n    min_time = min(times)\n    delta = (max_time-min_time)/segments\n    # print(\"making time range from\",min_time,\"to\",max_time\n\n    # add a time upper bound constraint, moving between min and max values\n    TimeCons = model.addCons(T <= max_time, \"TimeCons\")\n\n    for i in range(segments+1):\n        time_ub = max_time - delta*i\n        model.chgRhs(TimeCons, time_ub)\n        # print(\"optimizing cost subject to time <=\",time_ub\n        optimize(model,cand)\n\n    return cand", "response": "solve a segment for two - objective TSP\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef solve_scalarization(n,c,t):\n\n    model = base_model(n,c,t)   # base model for minimizing cost or time\n    x,u,C,T = model.data\n\n    def explore(C1,T1,C2,T2,front):\n        \"\"\"explore: recursively try to find new non-dominated solutions with a scaled objective\n        Parameters:\n            - C1,T1: cost and time of leftmost point\n            - C1,T1: cost and time of rightmost point\n            - front: current set of non-dominated solutions\n        Returns the updated front\n        \"\"\"\n        alpha = float(C1 - C2)/(T2 - T1)\n        # print(\"%s,%s -- %s,%s  (%s)...\" % (C1,T1,C2,T2,alpha)\n        init = list(front)\n        model.setObjective(quicksum((c[i,j] + alpha*t[i,j])*x[i,j] for (i,j) in x), \"minimize\")\n        optimize(model,front)\n        front = pareto_front(front)\n        # print(\"... added %s points\" % (len(front)-len(init))\n        if front == init:\n            # print(\"no points added, returning\"\n            return front\n\n        CM = model.getVal(C)\n        TM = model.getVal(T)\n        # print(\"will explore %s,%s -- %s,%s and %s,%s -- %s,%s\" % (C1,T1,CM,TM,CM,TM,C2,T2)\n        if TM > T1:\n            front = explore(C1,T1,CM,TM,front)\n        if T2 > TM:\n            front = explore(CM,TM,C2,T2,front)\n        return front\n\n\n    # store the set of solutions for plotting\n    cand = []       # to store the set of solutions for plotting\n    model.setObjective(T, \"minimize\")\n\n    stat = optimize(model,cand)\n    if stat != \"optimal\":\n        return []\n    C1 = model.getVal(C)\n    T1 = model.getVal(T)\n\n    # change the objective function to minimize the travel cost\n    model.setObjective(C, \"minimize\")\n\n    stat = optimize(model,cand)\n    if stat != \"optimal\":\n        return []\n    C2 = model.getVal(C)\n    T2 = model.getVal(T)\n\n    front = pareto_front(cand)\n    return explore(C1,T1,C2,T2,front)", "response": "Solve a scalarization of a candidate set with a given alternative edge weights."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef staff_mo(I,T,N,J,S,c,b):\n\n    Ts = range(1,T+1)\n    model = Model(\"staff scheduling -- multiobjective version\")\n\n    x,y = {},{}\n    for t in Ts:\n        for j in J:\n            for i in I:\n                x[i,t,j] = model.addVar(vtype=\"B\", name=\"x(%s,%s,%s)\" % (i,t,j))\n            y[t,j] = model.addVar(vtype=\"C\", name=\"y(%s,%s)\" % (t,j))\n\n    C = model.addVar(vtype=\"C\", name=\"cost\")\n    U = model.addVar(vtype=\"C\", name=\"uncovered\")\n\n    model.addCons(C >= quicksum(c[i,t,j]*x[i,t,j] for i in I for t in Ts for j in J if j != 0), \"Cost\")\n    model.addCons(U >= quicksum(y[t,j] for t in Ts for j in J if j != 0), \"Uncovered\")\n\n    for t in Ts:\n        for j in J:\n            if j == 0:\n                continue\n            model.addCons(quicksum(x[i,t,j] for i in I) >= b[t,j] - y[t,j], \"Cover(%s,%s)\" % (t,j))\n    for i in I:\n        model.addCons(quicksum(x[i,t,j] for t in Ts for j in J if j != 0) == N, \"Work(%s)\"%i)\n        for t in Ts:\n            model.addCons(quicksum(x[i,t,j] for j in J) == 1, \"Assign(%s,%s)\" % (i,t))\n            for j in J:\n                if j != 0:\n                    model.addCons(x[i,t,j] + quicksum(x[i,t,k] for k in J if k != j and k != 0) <= 1,\\\n                                    \"Require(%s,%s,%s)\" % (i,t,j))\n        for t in range(2,T):\n            for j in S:\n                model.addCons(x[i,t-1,j] + x[i,t+1,j] >= x[i,t,j], \"SameShift(%s,%s,%s)\" % (i,t,j))\n\n\n    model.data = x,y,C,U\n    return model", "response": "Return a staff self model for the given set of members in the given cycle and number of working periods."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning for solving the model updating candidate solutions", "response": "def optimize(model,cand,obj):\n    \"\"\"optimize: function for solving the model, updating candidate solutions' list\n    Parameters:\n        - model: Gurobi model object\n        - cand: list of pairs of objective functions (for appending more solutions)\n        - obj: name of a model's variable to setup as objective\n    Returns the solver's exit status\n    \"\"\"\n    # model.Params.OutputFlag = 0 # silent mode\n    model.setObjective(obj,\"minimize\")\n\n    model.optimize()\n    x,y,C,U = model.data\n    status = model.getStatus()\n    if status == \"optimal\" or status == \"bestsollimit\": # todo GRB.Status.SUBOPTIMAL:\n        sols = model.getSols()\n        for sol in sols:\n            cand.append((model.getVal(var=U,solution=sol),model.getVal(var=C,solution=sol)))\n\n     #   for k in range(model.SolCount):\n     #       model.Params.SolutionNumber = k\n     #       cand.append(model.getVal(U),model.getVal(C))\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solve_segment(I,T,N,J,S,c,b):\n    model = staff_mo(I,T,N,J,S,c,b)     # model for minimizing time\n    x,y,C,U = model.data\n    model.setRealParam(\"limits/time\", 60)\n\n    # store the set of solutions for plotting\n    cand = []\n\n    # first objective: cost\n    stat1 = optimize(model,cand,C)\n    stat2 = optimize(model,cand,U)\n\n    if stat1 != \"optimal\" or stat2 != \"optimal\":\n        return []\n\n    ulist = [int(ui+.5) for (ui,ci) in cand]\n    max_u = max(ulist)\n    min_u = min(ulist)\n\n    # add a time upper bound constraint, moving between min and max values\n    UConstr = model.addCons(U <= max_u, \"UConstr\")\n\n\n    for u_lim in range(max_u-1, min_u, -1):\n        print(\"limiting u to\",u_lim)\n        UConstr.setAttr(\"RHS\",u_lim)\n        optimize(model,cand,C)\n\n    return cand", "response": "This function solves two - objective TSP\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a model for the capacitated facility location problem", "response": "def flp(I,J,d,M,f,c):\n    \"\"\"flp -- model for the capacitated facility location problem\n    Parameters:\n        - I: set of customers\n        - J: set of facilities\n        - d[i]: demand for customer i\n        - M[j]: capacity of facility j\n        - f[j]: fixed cost for using a facility in point j\n        - c[i,j]: unit cost of servicing demand point i from facility j\n    Returns a model, ready to be solved.\n    \"\"\"\n\n    model = Model(\"flp\")\n\n    x,y = {},{}\n    for j in J:\n        y[j] = model.addVar(vtype=\"B\", name=\"y(%s)\"%j)\n        for i in I:\n            x[i,j] = model.addVar(vtype=\"C\", name=\"x(%s,%s)\"%(i,j))\n\n    for i in I:\n        model.addCons(quicksum(x[i,j] for j in J) == d[i], \"Demand(%s)\"%i)\n\n    for j in M:\n        model.addCons(quicksum(x[i,j] for i in I) <= M[j]*y[j], \"Capacity(%s)\"%i)\n\n    for (i,j) in x:\n        model.addCons(x[i,j] <= d[i]*y[j], \"Strong(%s,%s)\"%(i,j))\n\n    model.setObjective(\n        quicksum(f[j]*y[j] for j in J) +\n        quicksum(c[i,j]*x[i,j] for i in I for j in J),\n        \"minimize\")\n    model.data = x,y\n\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_data():\n    I,d = multidict({1:80, 2:270, 3:250, 4:160, 5:180})            # demand\n    J,M,f = multidict({1:[500,1000], 2:[500,1000], 3:[500,1000]}) # capacity, fixed costs\n    c = {(1,1):4,  (1,2):6,  (1,3):9,    # transportation costs\n         (2,1):5,  (2,2):4,  (2,3):7,\n         (3,1):6,  (3,2):3,  (3,3):4,\n         (4,1):8,  (4,2):5,  (4,3):3,\n         (5,1):10, (5,2):8,  (5,3):4,\n         }\n    return I,J,d,M,f,c", "response": "creates example data set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsolve the vehicle routing problem", "response": "def solve_vrp(V,c,m,q,Q):\n    \"\"\"solve_vrp -- solve the vehicle routing problem.\n       - start with assignment model (depot has a special status)\n       - add cuts until all components of the graph are connected\n    Parameters:\n        - V: set/list of nodes in the graph\n        - c[i,j]: cost for traversing edge (i,j)\n        - m: number of vehicles available\n        - q[i]: demand for customer i\n        - Q: vehicle capacity\n    Returns the optimum objective value and the list of edges used.\n    \"\"\"\n\n    def addcut(cut_edges):\n        \"\"\"addcut: add constraint to eliminate infeasible solutions\n        Parameters:\n            - cut_edges: list of edges in the current solution, except connections to depot\n        Returns True if a cut was added, False otherwise\n        \"\"\"\n        G = networkx.Graph()\n        G.add_edges_from(cut_edges)\n        Components = networkx.connected_components(G)\n        cut = False\n        for S in Components:\n            S_card = len(S)\n            q_sum = sum(q[i] for i in S)\n            NS = int(math.ceil(float(q_sum)/Q))\n            S_edges = [(i,j) for i in S for j in S if i<j and (i,j) in cut_edges]\n            if S_card >= 3 and (len(S_edges) >= S_card or NS > 1):\n                add = model.addCons(quicksum(x[i,j] for i in S for j in S if j > i) <= S_card-NS)\n                cut = True\n        return cut\n\n    model = Model(\"vrp\")\n\n    x = {}\n    for i in V:\n        for j in V:\n            if j > i and i == V[0]:       # depot\n                x[i,j] = model.addVar(ub=2, vtype=\"I\", name=\"x(%s,%s)\"%(i,j))\n            elif j > i:\n                x[i,j] = model.addVar(ub=1, vtype=\"I\", name=\"x(%s,%s)\"%(i,j))\n    \n    model.addCons(quicksum(x[V[0],j] for j in V[1:]) == 2*m, \"DegreeDepot\")\n    for i in V[1:]:\n        model.addCons(quicksum(x[j,i] for j in V if j < i) +\n                        quicksum(x[i,j] for j in V if j > i) == 2, \"Degree(%s)\"%i)\n\n    model.setObjective(quicksum(c[i,j]*x[i,j] for i in V for j in V if j>i), \"minimize\")\n\n    model.hideOutput()\n\n    EPS = 1.e-6\n    while True:\n        model.optimize()\n        edges = []\n        for (i,j) in x:\n            if model.getVal(x[i,j]) > EPS:\n                if i != V[0] and j != V[0]:\n                    edges.append((i,j))\n        if addcut(edges) == False:\n            break\n\n    return model.getObjVal(),edges"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kcover(I,J,c,k):\n\n    model = Model(\"k-center\")\n\n    z,y,x = {},{},{}\n    for i in I:\n        z[i] = model.addVar(vtype=\"B\", name=\"z(%s)\"%i, obj=1)\n    for j in J:\n        y[j] = model.addVar(vtype=\"B\", name=\"y(%s)\"%j)\n        for i in I:\n            x[i,j] = model.addVar(vtype=\"B\", name=\"x(%s,%s)\"%(i,j))\n\n    for i in I:\n        model.addCons(quicksum(x[i,j] for j in J) + z[i] == 1, \"Assign(%s)\"%i)\n        for j in J:\n            model.addCons(x[i,j] <= y[j], \"Strong(%s,%s)\"%(i,j))\n\n    model.addCons(sum(y[j] for j in J) == k, \"k_center\")\n    model.data = x,y,z\n\n    return model", "response": "kcover - minimize the number of uncovered customers from facilities I J c k - number of facilities to be used"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsolve k - center search for facilities in the potential facilities and edges linking them to customers", "response": "def solve_kcenter(I,J,c,k,delta):\n    \"\"\"solve_kcenter -- locate k facilities minimizing distance of most distant customer.\n    Parameters:\n        I - set of customers\n        J - set of potential facilities\n        c[i,j] - cost of servicing customer i from facility j\n        k - number of facilities to be used\n        delta - tolerance for terminating bisection\n    Returns:\n        - list of facilities to be used\n        - edges linking them to customers\n    \"\"\"\n\n    model = kcover(I,J,c,k)\n    x,y,z = model.data\n\n    facilities,edges = [],[]\n    LB = 0\n    UB = max(c[i,j] for (i,j) in c)\n    model.setObjlimit(0.1)\n    while UB-LB > delta:\n        theta = (UB+LB) / 2.\n        # print \"\\n\\ncurrent theta:\", theta\n        for j in J:\n            for i in I:\n                if c[i,j]>theta:\n                    model.chgVarUb(x[i,j], 0.0)\n                else:\n                    model.chgVarUb(x[i,j], 1.0)\n\n        # model.Params.OutputFlag = 0 # silent mode\n        model.setObjlimit(.1)\n\n        model.optimize()\n\n        if model.getStatus == \"optimal\":\n            # infeasibility = sum([z[i].X for i in I])\n            # print \"infeasibility=\",infeasibility\n            UB = theta\n            facilities = [j for j in y if model.getVal(y[j]) > .5]\n            edges = [(i,j) for (i,j) in x if model.getVal(x[i,j]) > .5]\n            # print \"updated solution:\"\n            # print \"facilities\",facilities\n            # print \"edges\",edges\n        else:   # infeasibility > 0:\n            LB = theta\n\n    return facilities,edges"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eoq_soco(I,F,h,d,w,W):\n    model = Model(\"EOQ model using SOCO\")\n\n    T,c = {},{}\n    for i in I:\n        T[i] = model.addVar(vtype=\"C\", name=\"T(%s)\"%i)  # cycle time for item i\n        c[i] = model.addVar(vtype=\"C\", name=\"c(%s)\"%i)  # total cost for item i\n\n    for i in I:\n        model.addCons(F[i] <= c[i]*T[i])\n\n    model.addCons(quicksum(w[i]*d[i]*T[i] for i in I) <= W)\n\n    model.setObjective(quicksum(c[i] + h[i]*d[i]*T[i]*0.5 for i in I), \"minimize\")\n\n    model.data = T,c\n    return model", "response": "Returns a multi - item capacitated economic ordering quantity model using SOCO"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tsptw2(n,c,e,l):\n    model = Model(\"tsptw2\")\n    \n    x,u = {},{}\n    for i in range(1,n+1):\n        for j in range(1,n+1):\n            if i != j:\n                x[i,j] = model.addVar(vtype=\"B\", name=\"x(%s,%s)\"%(i,j))\n                u[i,j] = model.addVar(vtype=\"C\", name=\"u(%s,%s)\"%(i,j))\n\n    for i in range(1,n+1):\n        model.addCons(quicksum(x[i,j] for j in range(1,n+1) if j != i) == 1, \"Out(%s)\"%i)\n        model.addCons(quicksum(x[j,i] for j in range(1,n+1) if j != i) == 1, \"In(%s)\"%i)\n\n    for j in range(2,n+1):\n        model.addCons(quicksum(u[i,j] + c[i,j]*x[i,j] for i in range(1,n+1) if i != j) -\n                        quicksum(u[j,k] for k in range(1,n+1) if k != j) <= 0, \"Relate(%s)\"%j)\n\n    for i in range(1,n+1):\n        for j in range(1,n+1):\n            if i != j:\n                model.addCons(e[i]*x[i,j] <= u[i,j], \"LB(%s,%s)\"%(i,j))\n                model.addCons(u[i,j] <= l[i]*x[i,j], \"UB(%s,%s)\"%(i,j))\n\n    model.setObjective(quicksum(c[i,j]*x[i,j] for (i,j) in x), \"minimize\")\n\n    model.data = x,u\n    return model", "response": "This function creates a model for the traveling salesman problem with time windows."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the L2 - norm distance between two points.", "response": "def distL2(x1,y1,x2,y2):\n    \"\"\"Compute the L2-norm (Euclidean) distance between two points.\n\n    The distance is rounded to the closest integer, for compatibility\n    with the TSPLIB convention.\n\n    The two points are located on coordinates (x1,y1) and (x2,y2),\n    sent as parameters\"\"\"\n    xdiff = x2 - x1\n    ydiff = y2 - y1\n    return int(math.sqrt(xdiff*xdiff + ydiff*ydiff) + .5)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distL1(x1,y1,x2,y2):\n    return int(abs(x2-x1) + abs(y2-y1)+.5)", "response": "Compute the L1 - norm distance between two points."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the Linfty distance between two points", "response": "def distLinf(x1,y1,x2,y2):\n    \"\"\"Compute the Linfty distance between two points (see TSPLIB documentation)\"\"\"\n    return int(max(abs(x2-x1),abs(y2-y1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef distATT(x1,y1,x2,y2):\n    xd = x2 - x1\n    yd = y2 - y1\n    rij = math.sqrt((xd*xd + yd*yd) /10.)\n    tij = int(rij + .5)\n    if tij < rij:\n        return tij + 1\n    else:\n        return tij", "response": "Compute the ATT distance between two points"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef distCEIL2D(x1,y1,x2,y2):\n    xdiff = x2 - x1\n    ydiff = y2 - y1\n    return int(math.ceil(math.sqrt(xdiff*xdiff + ydiff*ydiff)))", "response": "returns smallest integer not less than the distance of two points"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_tsplib(filename):\n    \"basic function for reading a symmetric problem in the TSPLIB format\"\n    \"data is stored in an upper triangular matrix\"\n    \"NOTE: some distance types are not handled yet\"\n    if filename[-3:] == \".gz\":\n        f = gzip.open(filename, \"rt\")\n    else:\n        f = open(filename)\n\n    line = f.readline()\n    while line.find(\"DIMENSION\") == -1:\n        line = f.readline()\n    n = int(line.split()[-1])\n\n    while line.find(\"EDGE_WEIGHT_TYPE\") == -1:\n        line = f.readline()\n\n    if line.find(\"EUC_2D\") != -1:\n        dist = distL2\n    elif line.find(\"MAN_2D\") != -1:\n        dist = distL1\n    elif line.find(\"MAX_2D\") != -1:\n        dist = distLinf\n    elif line.find(\"ATT\") != -1:\n        dist = distATT\n    elif line.find(\"CEIL_2D\") != -1:\n        dist = distCEIL2D\n    # elif line.find(\"GEO\") != -1:\n    #     print(\"geographic\"\n    #     dist = distGEO\n    elif line.find(\"EXPLICIT\") != -1:\n        while line.find(\"EDGE_WEIGHT_FORMAT\") == -1:\n            line = f.readline()\n        if line.find(\"LOWER_DIAG_ROW\") != -1:\n            while line.find(\"EDGE_WEIGHT_SECTION\") == -1:\n                line = f.readline()\n            return read_explicit_lowerdiag(f,n)\n        if line.find(\"UPPER_ROW\") != -1:\n            while line.find(\"EDGE_WEIGHT_SECTION\") == -1:\n                line = f.readline()\n            return read_explicit_upper(f,n)\n        if line.find(\"UPPER_DIAG_ROW\") != -1:\n            while line.find(\"EDGE_WEIGHT_SECTION\") == -1:\n                line = f.readline()\n            return read_explicit_upperdiag(f,n)\n        if line.find(\"FULL_MATRIX\") != -1:\n            while line.find(\"EDGE_WEIGHT_SECTION\") == -1:\n                line = f.readline()\n            return read_explicit_matrix(f,n)\n        print(\"error reading line \" + line)\n        raise(Exception)\n    else:\n        print(\"cannot deal with '%s' distances\" % line)\n        raise Exception\n\n    while line.find(\"NODE_COORD_SECTION\") == -1:\n        line = f.readline()\n\n    x,y = {},{}\n    while 1:\n        line = f.readline()\n        if line.find(\"EOF\") != -1 or not line: break\n        (i,xi,yi) = line.split()\n        x[i] = float(xi)\n        y[i] = float(yi)\n\n    V = x.keys()\n    c = {}      # dictionary to hold n times n matrix\n    for i in V:\n        for j in V:\n            c[i,j] = dist(x[i],y[i],x[j],y[j])\n\n    return V,c,x,y", "response": "basic function for reading a symmetric problem in the TSPLIB format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FFD(s,B):\n    remain = [B]        # keep list of empty space per bin\n    sol = [[]]          # a list ot items (i.e., sizes) on each used bin\n    for item in sorted(s,reverse=True):\n        for (j,free) in enumerate(remain):\n            if free >= item:\n                remain[j] -= item\n                sol[j].append(item)\n                break\n        else: #does not fit in any bin\n            sol.append([item])\n            remain.append(B-item)\n    return sol", "response": "First Fit Decreasing Heuristics for the Bin Packing Problem."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bpp(s,B):\n    n = len(s)\n    U = len(FFD(s,B)) # upper bound of the number of bins\n    model = Model(\"bpp\")\n    # setParam(\"MIPFocus\",1)\n    x,y = {},{}\n    for i in range(n):\n        for j in range(U):\n            x[i,j] = model.addVar(vtype=\"B\", name=\"x(%s,%s)\"%(i,j))\n    for j in range(U):\n        y[j] = model.addVar(vtype=\"B\", name=\"y(%s)\"%j)\n\n    # assignment constraints\n    for i in range(n):\n        model.addCons(quicksum(x[i,j] for j in range(U)) == 1, \"Assign(%s)\"%i)\n\n    # bin capacity constraints\n    for j in range(U):\n        model.addCons(quicksum(s[i]*x[i,j] for i in range(n)) <= B*y[j], \"Capac(%s)\"%j)\n\n    # tighten assignment constraints\n    for j in range(U):\n        for i in range(n):\n            model.addCons(x[i,j] <= y[j], \"Strong(%s,%s)\"%(i,j))\n\n    # tie breaking constraints\n    for j in range(U-1):\n        model.addCons(y[j] >= y[j+1],\"TieBrk(%s)\"%j)\n\n    # SOS constraints\n    for i in range(n):\n        model.addConsSOS1([x[i,j] for j in range(U)])\n\n    model.setObjective(quicksum(y[j] for j in range(U)), \"minimize\")\n    model.data = x,y\n\n    return model", "response": "Martello and Toth s model to solve the bin packing problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solveBinPacking(s,B):\n    n = len(s)\n    U = len(FFD(s,B)) # upper bound of the number of bins\n    model = bpp(s,B)\n    x,y = model.data\n\n    model.optimize()\n\n    bins = [[] for i in range(U)]\n    for (i,j) in x:\n        if model.getVal(x[i,j]) > .5:\n            bins[j].append(s[i])\n    for i in range(bins.count([])):\n        bins.remove([])\n    for b in bins:\n        b.sort()\n    bins.sort()\n    return bins", "response": "solveBinPacking - use an IP model to solve the in Packing problem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate random uniform instance for the bin packing problem", "response": "def DiscreteUniform(n=10,LB=1,UB=99,B=100):\n    \"\"\"DiscreteUniform: create random, uniform instance for the bin packing problem.\"\"\"\n    B = 100\n    s = [0]*n\n    for i in range(n):\n        s[i] = random.randint(LB,UB)\n    return s,B"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solve_tsp(V,c):\n\n    def addcut(cut_edges):\n        G = networkx.Graph()\n        G.add_edges_from(cut_edges)\n        Components = list(networkx.connected_components(G))\n        if len(Components) == 1:\n            return False\n        model.freeTransform()\n        for S in Components:\n            model.addCons(quicksum(x[i,j] for i in S for j in S if j>i) <= len(S)-1)\n            print(\"cut: len(%s) <= %s\" % (S,len(S)-1))\n        return True\n\n\n    def addcut2(cut_edges):\n        G = networkx.Graph()\n        G.add_edges_from(cut_edges)\n        Components = list(networkx.connected_components(G))\n\n        if len(Components) == 1:\n            return False\n        model.freeTransform()\n        for S in Components:\n            T = set(V) - set(S)\n            print(\"S:\",S)\n            print(\"T:\",T)\n            model.addCons(quicksum(x[i,j] for i in S for j in T if j>i) +\n                          quicksum(x[i,j] for i in T for j in S if j>i) >= 2)\n            print(\"cut: %s >= 2\" % \"+\".join([(\"x[%s,%s]\" % (i,j)) for i in S for j in T if j>i]))\n        return True\n\n    # main part of the solution process:\n    model = Model(\"tsp\")\n\n    model.hideOutput() # silent/verbose mode\n    x = {}\n    for i in V:\n        for j in V:\n            if j > i:\n                x[i,j] = model.addVar(ub=1, name=\"x(%s,%s)\"%(i,j))\n\n    for i in V:\n        model.addCons(quicksum(x[j,i] for j in V if j < i) + \\\n                        quicksum(x[i,j] for j in V if j > i) == 2, \"Degree(%s)\"%i)\n\n    model.setObjective(quicksum(c[i,j]*x[i,j] for i in V for j in V if j > i), \"minimize\")\n\n    EPS = 1.e-6\n    isMIP = False\n    while True:\n        model.optimize()\n        edges = []\n        for (i,j) in x:\n            if model.getVal(x[i,j]) > EPS:\n                edges.append( (i,j) )\n\n        if addcut(edges) == False:\n            if isMIP:     # integer variables, components connected: solution found\n                break\n            model.freeTransform()\n            for (i,j) in x:     # all components connected, switch to integer model\n                model.chgVarType(x[i,j], \"B\")\n                isMIP = True\n\n    return model.getObjVal(),edges", "response": "solve the traveling salesman problem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ssa(n,h,K,f,T):\n\n    model = Model(\"safety stock allocation\")\n\n    # calculate endpoints for linear segments\n    a,b = {},{}\n    for i in range(1,n+1):\n        a[i] = [k for k in range(K)]\n        b[i] = [f(i,k) for k in range(K)]\n\n    # x: net replenishment time for stage i\n    # y: corresponding cost\n    # s: piecewise linear segment of variable x\n    x,y,s = {},{},{}\n    L = {} # service time of stage i\n    for i in range(1,n+1):\n        x[i],y[i],s[i] = convex_comb_sos(model,a[i],b[i])\n        if i == 1:\n            L[i] = model.addVar(ub=0, vtype=\"C\", name=\"L[%s]\"%i)\n        else:\n            L[i] = model.addVar(vtype=\"C\", name=\"L[%s]\"%i)\n    L[n+1] = model.addVar(ub=0, vtype=\"C\", name=\"L[%s]\"%(n+1))\n\n    for i in range(1,n+1):\n        # net replenishment time for each stage i\n        model.addCons(x[i] + L[i] == T[i] + L[i+1])\n\n    model.setObjective(quicksum(h[i]*y[i] for i in range(1,n+1)), \"minimize\")\n\n    model.data = x,s,L\n    return model", "response": "multi - stage safety stock allocation model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate example data set", "response": "def make_data():\n    \"\"\"creates example data set\"\"\"\n    n = 30      # number of stages\n    z = 1.65    # for 95% service level\n    sigma = 100 # demand's standard deviation\n    h = {}      # inventory cost\n    T = {}      # production lead time\n    h[n] = 1\n    for i in range(n-1,0,-1):\n        h[i] = h[i+1] + random.randint(30,50)\n    K = 0 # number of segments (=sum of processing times)\n    for i in range(1,n+1):\n        T[i] = random.randint(3,5)      # production lead time at stage i\n        K += T[i]\n    return z,sigma,h,T,K,n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mils(T,P,f,g,c,d,h,M):\n    def mils_callback(model,where):\n        # remember to set     model.params.DualReductions = 0     before using!\n        if where != GRB.Callback.MIPSOL and where != GRB.Callback.MIPNODE:\n            return\n        for p in P:\n            for ell in Ts:\n                lhs = 0\n                S,L = [],[]\n                for t in range(1,ell+1):\n                    yt = model.cbGetSolution(y[t,p])\n                    xt = model.cbGetSolution(x[t,p])\n                    if D[t,ell,p]*yt < xt:\n                        S.append(t)\n                        lhs += D[t,ell,p]*yt\n                    else:\n                        L.append(t)\n                        lhs += xt\n                if lhs < D[1,ell,p]:\n                    # add cutting plane constraint\n                    model.cbLazy(quicksum(x[t,p] for t in L) +\\\n                                 quicksum(D[t,ell,p] * y[t,p] for t in S)\n                                 >= D[1,ell,p])\n        return\n\n    model = Model(\"standard multi-item lotsizing\")\n\n    y,x,I = {},{},{}\n    Ts = range(1,T+1)\n    for p in P:\n        for t in Ts:\n            y[t,p] = model.addVar(vtype=\"B\", name=\"y(%s,%s)\"%(t,p))\n            x[t,p] = model.addVar(vtype=\"C\", name=\"x(%s,%s)\"%(t,p))\n            I[t,p] = model.addVar(vtype=\"C\", name=\"I(%s,%s)\"%(t,p))\n        I[0,p] = 0\n\n    for t in Ts:\n        # time capacity constraints\n        model.addCons(quicksum(g[t,p]*y[t,p] + x[t,p] for p in P) <= M[t], \"TimeUB(%s)\"%(t))\n\n        for p in P:\n            # flow conservation constraints\n            model.addCons(I[t-1,p] + x[t,p] == I[t,p] + d[t,p], \"FlowCons(%s,%s)\"%(t,p))\n\n            # capacity connection constraints\n            model.addCons(x[t,p] <= (M[t]-g[t,p])*y[t,p], \"ConstrUB(%s,%s)\"%(t,p))\n\n            # tighten constraints\n            model.addCons(x[t,p] <= d[t,p]*y[t,p] + I[t,p], \"Tighten(%s,%s)\"%(t,p))\n\n    model.setObjective(\\\n        quicksum(f[t,p]*y[t,p] + c[t,p]*x[t,p] + h[t,p]*I[t,p] for t in Ts for p in P),\\\n        \"minimize\")\n\n    # compute D[i,j,p] = sum_{t=i}^j d[t,p]\n    D = {}\n    for p in P:\n        for t in Ts:\n            s = 0\n            for j in range(t,T+1):\n                s += d[j,p]\n                D[t,j,p] = s\n\n    model.data = y,x,I\n    return model,mils_callback", "response": "This function returns a model ready to be solved for the multi - item lot - sizing problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mils_fl(T,P,f,g,c,d,h,M):\n    Ts = range(1,T+1)\n\n    model = Model(\"multi-item lotsizing -- facility location formulation\")\n\n    y,X = {},{}\n    for p in P:\n        for t in Ts:\n            y[t,p] = model.addVar(vtype=\"B\", name=\"y(%s,%s)\"%(t,p))\n            for s in range(1,t+1):\n                X[s,t,p] = model.addVar(name=\"X(%s,%s,%s)\"%(s,t,p))\n\n\n    for t in Ts:\n        # capacity constraints\n        model.addCons(quicksum(X[t,s,p] for s in range(t,T+1) for p in P) + \\\n                        quicksum(g[t,p]*y[t,p] for p in P) <= M[t],\n                        \"Capacity(%s)\"%(t))\n\n        for p in P:\n            # demand satisfaction constraints\n            model.addCons(quicksum(X[s,t,p] for s in range(1,t+1)) == d[t,p], \"Demand(%s,%s)\"%(t,p))\n\n            # connection constraints\n            for s in range(1,t+1):\n                model.addCons(X[s,t,p] <= d[t,p] * y[s,p], \"Connect(%s,%s,%s)\"%(s,t,p))\n\n    C = {} # variable costs plus holding costs\n    for p in P:\n        for s in Ts:\n            sumC = 0\n            for t in range(s,T+1):\n                C[s,t,p] = (c[s,p] + sumC)\n                sumC += h[t,p]\n\n    model.setObjective(quicksum(f[t,p]*y[t,p] for t in Ts for p in P) + \\\n                       quicksum(C[s,t,p]*X[s,t,p] for t in Ts for p in P for s in range(1,t+1)),\n                       \"minimize\")\n\n\n    model.data = y,X\n    model.write(\"tmp.lp\")\n    return model", "response": "This function returns a model that solves the multi - item lot - sizing problem for the multi - item lot - sizing problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trigeiro(T,N,factor):\n    P = range(1,N+1)\n    f,g,c,d,h,M = {},{},{},{},{},{}\n\n    sumT = 0\n    for t in range(1,T+1):\n        for p in P:\n            # capacity used per unit production: 1, except for\n            # except for specific instances with random value in [0.5, 1.5]\n            # (not tackled in our model)\n\n            # setup times\n            g[t,p] = 10 * random.randint(1,5)   # 10, 50: trigeiro's values\n\n            # set-up costs\n            f[t,p] = 100 * random.randint(1,10) # checked from Wolsey's instances\n            c[t,p] = 0                          # variable costs\n\n            # demands\n            d[t,p] = 100+random.randint(-25,25) # checked from Wolsey's instances\n            if t <= 4:\n                if random.random() < .25:       # trigeiro's parameter\n                    d[t,p] = 0\n            sumT += g[t,p] + d[t,p]             # sumT is the total capacity usage in the lot-for-lot solution\n            h[t,p] = random.randint(1,5)        # holding costs; checked from Wolsey's instances\n\n    for t in range(1,T+1):\n        M[t] = int(float(sumT)/float(T)/factor)\n\n    return P,f,g,c,d,h,M", "response": "This function generates a multi - item lot - sizing problem for a multi - item lot - sizing problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate example data set 1", "response": "def make_1r():\n    \"\"\"creates example data set 1\"\"\"\n    J, p = multidict({       # jobs, processing times\n        1 : 1,\n        2 : 3,\n        3 : 2,\n        4 : 2,\n        })\n    P = [(1,2), (1,3), (2,4)]\n    R = [1]\n    T = 6\n    c = {}\n    for j in J:\n        for t in range(1,T-p[j]+2):\n            c[j,t] = 1*(t-1+p[j])\n    a = {\n        (1,1,0):2,\n        (2,1,0):2, (2,1,1):1, (2,1,2):1,\n        (3,1,0):1, (3,1,1):1,\n        (4,1,0):1, (4,1,1):2,\n        }\n    RUB = {(1,1):2, (1,2):2, (1,3):1, (1,4):2, (1,5):2, (1,6):2}\n    return (J,P,R,T,p,c,a,RUB)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_data():\n    a = { (1,1):.25, (1,2):.15, (1,3):.2,\n          (2,1):.3,  (2,2):.3,  (2,3):.1,\n          (3,1):.15, (3,2):.65, (3,3):.05,\n          (4,1):.1,  (4,2):.05,  (4,3):.8\n          }\n    epsilon = 0.01\n    I,p = multidict({1:5, 2:6, 3:8, 4:20})\n    K,LB = multidict({1:.2, 2:.3, 3:.2})\n    return I,K,a,p,epsilon,LB", "response": "creates example data set"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ssp(V,E):\n    model = Model(\"ssp\")\n\n    x = {}\n    for i in V:\n        x[i] = model.addVar(vtype=\"B\", name=\"x(%s)\"%i)\n\n    for (i,j) in E:\n        model.addCons(x[i] + x[j] <= 1, \"Edge(%s,%s)\"%(i,j))\n\n    model.setObjective(quicksum(x[i] for i in V), \"maximize\")\n\n    model.data = x\n    return model", "response": "Returns a model for the stable set problem"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding piecewise linear relation with multiple selection formulation", "response": "def mult_selection(model,a,b):\n    \"\"\"mult_selection -- add piecewise relation with multiple selection formulation\n    Parameters:\n        - model: a model where to include the piecewise linear relation\n        - a[k]: x-coordinate of the k-th point in the piecewise linear relation\n        - b[k]: y-coordinate of the k-th point in the piecewise linear relation\n    Returns the model with the piecewise linear relation on added variables X, Y, and z.\n    \"\"\"\n\n    K = len(a)-1\n    w,z = {},{}\n    for k in range(K):\n        w[k] = model.addVar(lb=-model.infinity()) # do not name variables for avoiding clash\n        z[k] = model.addVar(vtype=\"B\")\n    X = model.addVar(lb=a[0], ub=a[K], vtype=\"C\")\n    Y = model.addVar(lb=-model.infinity())\n\n    for k in range(K):\n        model.addCons(w[k] >= a[k]*z[k])\n        model.addCons(w[k] <= a[k+1]*z[k])\n\n    model.addCons(quicksum(z[k] for k in range(K)) == 1)\n    model.addCons(X == quicksum(w[k] for k in range(K)))\n\n    c = [float(b[k+1]-b[k])/(a[k+1]-a[k]) for k in range(K)]\n    d = [b[k]-c[k]*a[k] for k in range(K)]\n    model.addCons(Y == quicksum(d[k]*z[k] + c[k]*w[k] for k in range(K)))\n\n    return X,Y,z"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convex_comb_dis(model,a,b):\n    K = len(a)-1\n    wL,wR,z = {},{},{}\n    for k in range(K):\n        wL[k] = model.addVar(lb=0, ub=1, vtype=\"C\")\n        wR[k] = model.addVar(lb=0, ub=1, vtype=\"C\")\n        z[k] = model.addVar(vtype=\"B\")\n    X = model.addVar(lb=a[0], ub=a[K], vtype=\"C\")\n    Y = model.addVar(lb=-model.infinity(), vtype=\"C\")\n\n    model.addCons(X == quicksum(a[k]*wL[k] + a[k+1]*wR[k] for k in range(K)))\n    model.addCons(Y == quicksum(b[k]*wL[k] + b[k+1]*wR[k] for k in range(K)))\n    for k in range(K):\n        model.addCons(wL[k] + wR[k] == z[k])\n\n    model.addCons(quicksum(z[k] for k in range(K)) == 1)\n\n    return X,Y,z", "response": "This function adds a piecewise linear relation with convex combination formulation to the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convex_comb_agg_log(model,a,b):\n    K = len(a)-1\n    G = int(math.ceil((math.log(K)/math.log(2))))     # number of required bits\n    w,g = {},{}\n    for k in range(K+1):\n        w[k] = model.addVar(lb=0, ub=1, vtype=\"C\")\n    for j in range(G):\n        g[j] = model.addVar(vtype=\"B\")\n    X = model.addVar(lb=a[0], ub=a[K], vtype=\"C\")\n    Y = model.addVar(lb=-model.infinity(), vtype=\"C\")\n\n    model.addCons(X == quicksum(a[k]*w[k]  for k in range(K+1)))\n    model.addCons(Y == quicksum(b[k]*w[k]  for k in range(K+1)))\n    model.addCons(quicksum(w[k] for k in range(K+1)) == 1)\n\n    # binary variables setup\n    for j in range(G):\n        zeros,ones = [0],[]\n        # print(j,\"\\tinit zeros:\",zeros,\"ones:\",ones\n        for k in range(1,K+1):\n            # print(j,k,\"\\t>zeros:\",zeros,\"ones:\",ones\n            if (1 & gray(k)>>j) == 1 and (1 & gray(k-1)>>j) == 1:\n                ones.append(k)\n            if (1 & gray(k)>>j) == 0 and (1 & gray(k-1)>>j) == 0:\n                zeros.append(k)\n            # print(j,k,\"\\tzeros>:\",zeros,\"ones:\",ones\n\n        # print(j,\"\\tzeros:\",zeros,\"ones:\",ones\n        model.addCons(quicksum(w[k] for k in ones) <= g[j])\n        model.addCons(quicksum(w[k] for k in zeros) <= 1-g[j])\n\n    return X,Y,w", "response": "This function adds a piecewise linear relation with a logarithmic number of binary variables a and b."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mils_standard(T,K,P,f,g,c,d,h,a,M,UB,phi):\n    model = Model(\"multi-stage lotsizing -- standard formulation\")\n\n    y,x,I = {},{},{}\n    Ts = range(1,T+1)\n    for p in P:\n        for t in Ts:\n            y[t,p] = model.addVar(vtype=\"B\", name=\"y(%s,%s)\"%(t,p))\n            x[t,p] = model.addVar(vtype=\"C\",name=\"x(%s,%s)\"%(t,p))\n            I[t,p] = model.addVar(vtype=\"C\",name=\"I(%s,%s)\"%(t,p))\n        I[0,p] = model.addVar(name=\"I(%s,%s)\"%(0,p))\n\n    for t in Ts:\n        for p in P:\n            # flow conservation constraints\n            model.addCons(I[t-1,p] + x[t,p] == \\\n                            quicksum(phi[p,q]*x[t,q] for (p2,q) in phi if p2 == p) \\\n                            + I[t,p] + d[t,p],\n                            \"FlowCons(%s,%s)\"%(t,p))\n\n            # capacity connection constraints\n            model.addCons(x[t,p] <= UB[t,p]*y[t,p], \"ConstrUB(%s,%s)\"%(t,p))\n\n        # time capacity constraints\n        for k in K:\n            model.addCons(quicksum(a[t,k,p]*x[t,p] + g[t,p]*y[t,p] for p in P) <= M[t,k],\n                            \"TimeUB(%s,%s)\"%(t,k))\n\n    # initial inventory quantities\n    for p in P:\n        model.addCons(I[0,p] == 0, \"InventInit(%s)\"%(p))\n\n    model.setObjective(\\\n        quicksum(f[t,p]*y[t,p] + c[t,p]*x[t,p] + h[t,p]*I[t,p] for t in Ts for p in P), \\\n        \"minimize\")\n\n    model.data = y,x,I\n    return model", "response": "This function returns the multi - item multi - stage lot - sizing problem for the multi - item multi - stage lot - sizing problem."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mils_echelon(T,K,P,f,g,c,d,h,a,M,UB,phi):\n    rho = calc_rho(phi) # rho[(i,j)]: units of i required to produce a unit of j (j ancestor of i)\n\n    model = Model(\"multi-stage lotsizing -- echelon formulation\")\n\n    y,x,E,H = {},{},{},{}\n    Ts = range(1,T+1)\n    for p in P:\n        for t in Ts:\n            y[t,p] = model.addVar(vtype=\"B\", name=\"y(%s,%s)\"%(t,p))\n            x[t,p] = model.addVar(vtype=\"C\", name=\"x(%s,%s)\"%(t,p))\n            H[t,p] = h[t,p] - sum([h[t,q]*phi[q,p] for (q,p2) in phi if p2 == p])\n            E[t,p] = model.addVar(vtype=\"C\", name=\"E(%s,%s)\"%(t,p))        # echelon inventory\n        E[0,p] = model.addVar(vtype=\"C\", name=\"E(%s,%s)\"%(0,p))    # echelon inventory\n\n    for t in Ts:\n        for p in P:\n            # flow conservation constraints\n            dsum = d[t,p] + sum([rho[p,q]*d[t,q] for (p2,q) in rho if p2 == p])\n            model.addCons(E[t-1,p] + x[t,p] == E[t,p] + dsum, \"FlowCons(%s,%s)\"%(t,p))\n\n            # capacity connection constraints\n            model.addCons(x[t,p] <= UB[t,p]*y[t,p], \"ConstrUB(%s,%s)\"%(t,p))\n\n        # time capacity constraints\n        for k in K:\n            model.addCons(quicksum(a[t,k,p]*x[t,p] + g[t,p]*y[t,p] for p in P) <= M[t,k],\n                            \"TimeUB(%s,%s)\"%(t,k))\n\n\n    # calculate echelon quantities\n    for p in P:\n        model.addCons(E[0,p] == 0, \"EchelonInit(%s)\"%(p))\n        for t in Ts:\n            model.addCons(E[t,p] >= quicksum(phi[p,q]*E[t,q] for (p2,q) in phi if p2 == p),\n                            \"EchelonLB(%s,%s)\"%(t,p))\n\n    model.setObjective(\\\n        quicksum(f[t,p]*y[t,p] + c[t,p]*x[t,p] + H[t,p]*E[t,p] for t in Ts for p in P), \\\n        \"minimize\")\n\n    model.data = y,x,E\n    return model", "response": "This function generates the multi - item multi - stage lot - sizing problem for the multi - item multi - stage lot - sizing problem."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake data for a single base language tree", "response": "def make_data():\n    \"\"\"\n    1..T: set of periods\n    K: set of resources\n    P: set of items\n    f[t,p]: set-up costs\n    g[t,p]: set-up times\n    c[t,p]: variable costs\n    d[t,p]: demand values\n    h[t,p]: holding costs\n    a[t,k,p]: amount of resource k for producing product p in period. t\n    M[t,k]: resource upper bounds\n    UB[t,p]: upper bound of production time of product p in period t\n    phi[(i,j)] : units of i required to produce a unit of j (j parent of i)\n    \"\"\"\n    T = 5\n    K = [1]\n    P = [1,2,3,4,5]\n    _,f,g,c,d,h,UB = multidict({\n        (1,1): [10, 1, 2, 0, 0.5, 24],\n        (1,2): [10, 1, 2, 0, 0.5, 24],\n        (1,3): [10, 1, 2, 0, 0.5, 24],\n        (1,4): [10, 1, 2, 0, 0.5, 24],\n        (1,5): [10, 1, 2, 0, 0.5, 24],\n        (2,1): [10, 1, 2, 0, 0.5, 24],\n        (2,2): [10, 1, 2, 0, 0.5, 24],\n        (2,3): [10, 1, 2, 0, 0.5, 24],\n        (2,4): [10, 1, 2, 0, 0.5, 24],\n        (2,5): [10, 1, 2, 0, 0.5, 24],\n        (3,1): [10, 1, 2, 0, 0.5, 24],\n        (3,2): [10, 1, 2, 0, 0.5, 24],\n        (3,3): [10, 1, 2, 0, 0.5, 24],\n        (3,4): [10, 1, 2, 0, 0.5, 24],\n        (3,5): [10, 1, 2, 0, 0.5, 24],\n        (4,1): [10, 1, 2, 0, 0.5, 24],\n        (4,2): [10, 1, 2, 0, 0.5, 24],\n        (4,3): [10, 1, 2, 0, 0.5, 24],\n        (4,4): [10, 1, 2, 0, 0.5, 24],\n        (4,5): [10, 1, 2, 0, 0.5, 24],\n        (5,1): [10, 1, 2, 0, 0.5, 24],\n        (5,2): [10, 1, 2, 0, 0.5, 24],\n        (5,3): [10, 1, 2, 0, 0.5, 24],\n        (5,4): [10, 1, 2, 0, 0.5, 24],\n        (5,5): [10, 1, 2, 5, 0.5, 24],\n        })\n    a = {\n        (1,1,1): 1,\n        (1,1,2): 1,\n        (1,1,3): 1,\n        (1,1,4): 1,\n        (1,1,5): 1,\n        (2,1,1): 1,\n        (2,1,2): 1,\n        (2,1,3): 1,\n        (2,1,4): 1,\n        (2,1,5): 1,\n        (3,1,1): 1,\n        (3,1,2): 1,\n        (3,1,3): 1,\n        (3,1,4): 1,\n        (3,1,5): 1,\n        (4,1,1): 1,\n        (4,1,2): 1,\n        (4,1,3): 1,\n        (4,1,4): 1,\n        (4,1,5): 1,\n        (5,1,1): 1,\n        (5,1,2): 1,\n        (5,1,3): 1,\n        (5,1,4): 1,\n        (5,1,5): 1,\n        }\n    M = {\n        (1,1): 15,\n        (2,1): 15,\n        (3,1): 15,\n        (4,1): 15,\n        (5,1): 15,\n        }\n\n    phi = {     # phi[(i,j)] : units of i required to produce a unit of j (j parent of i)\n        (1,3):2,\n        (2,3):3,\n        (2,4):3/2.,\n        (3,5):1/2.,\n        (4,5):3\n        }\n\n\n    return T,K,P,f,g,c,d,h,a,M,UB,phi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsolve the graph coloring problem with bisection and fixed - k model", "response": "def solve_gcp(V,E):\n    \"\"\"solve_gcp -- solve the graph coloring problem with bisection and fixed-k model\n    Parameters:\n        - V: set/list of nodes in the graph\n        - E: set/list of edges in the graph\n    Returns tuple with number of colors used, and dictionary mapping colors to vertices\n    \"\"\"\n    LB = 0\n    UB = len(V)\n    color = {}\n    while UB-LB > 1:\n        K = int((UB+LB) / 2)\n        gcp = gcp_fixed_k(V,E,K)\n        # gcp.Params.OutputFlag = 0 # silent mode\n        #gcp.Params.Cutoff = .1\n        gcp.setObjlimit(0.1)\n        gcp.optimize()\n        status = gcp.getStatus()\n        if status == \"optimal\":\n            x,z = gcp.data\n            for i in V:\n                for k in range(K):\n                    if gcp.getVal(x[i,k]) > 0.5:\n                        color[i] = k\n                        break\n                # else:\n                #     raise \"undefined color for\", i\n            UB = K\n        else:\n            LB = K\n\n    return UB,color"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_plugin_module(mod):\n    for k, v in load_plugins_from_module(mod).items():\n        if k:\n            if isinstance(k, (list, tuple)):\n                k = k[0]\n            global_registry[k] = v", "response": "Find plugins in given module"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds plugins in given directory", "response": "def register_plugin_dir(path):\n    \"\"\"Find plugins in given directory\"\"\"\n    import glob\n    for f in glob.glob(path + '/*.py'):\n        for k, v in load_plugins_from_module(f).items():\n            if k:\n                global_registry[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary describing this parameter.", "response": "def describe(self):\n        \"\"\"Information about this parameter\"\"\"\n        desc = {\n            'name': self.name,\n            'description': self.description,\n            # the Parameter might not have a type at all\n            'type': self.type or 'unknown',\n        }\n        for attr in ['min', 'max', 'allowed', 'default']:\n            v = getattr(self, attr)\n            if v is not None:\n                desc[attr] = v\n        return desc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand the default values of the class.", "response": "def expand_defaults(self, client=False, getenv=True, getshell=True):\n        \"\"\"Compile env, client_env, shell and client_shell commands\n        \"\"\"\n        if not isinstance(self._default, six.string_types):\n            self.expanded_default = self._default\n        else:\n            self.expanded_default = coerce(self.type, expand_defaults(\n                self._default, client, getenv, getshell))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, value):\n        if self.type is not None:\n            value = coerce(self.type, value)\n\n        if self.min is not None and value < self.min:\n            raise ValueError('%s=%s is less than %s' % (self.name, value,\n                                                        self.min))\n        if self.max is not None and value > self.max:\n            raise ValueError('%s=%s is greater than %s' % (\n                self.name, value, self.max))\n        if self.allowed is not None and value not in self.allowed:\n            raise ValueError('%s=%s is not one of the allowed values: %s' % (\n                self.name, value, ','.join(map(str, self.allowed))))\n\n        return value", "response": "Validates that the value meets the parameter requirements?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load(self, reload=False):\n        if self.autoreload or reload:\n            # First, we load from YAML, failing if syntax errors are found\n            options = self.storage_options or {}\n            if hasattr(self.path, 'path') or hasattr(self.path, 'read'):\n                file_open = self.path\n                self.path = make_path_posix(\n                    getattr(self.path, 'path',\n                            getattr(self.path, 'name', 'file')))\n            else:\n                file_open = open_files(self.path, mode='rb', **options)\n                assert len(file_open) == 1\n                file_open = file_open[0]\n            self._dir = get_dir(self.path)\n\n            with file_open as f:\n                text = f.read().decode()\n            if \"!template \" in text:\n                logger.warning(\"Use of '!template' deprecated - fixing\")\n                text = text.replace('!template ', '')\n            self.parse(text)", "response": "Load text of fcatalog file and pass to parse\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, text):\n        self.text = text\n        data = yaml_load(self.text)\n\n        if data is None:\n            raise exceptions.CatalogException('No YAML data in file')\n\n        # Second, we validate the schema and semantics\n        context = dict(root=self._dir)\n        result = CatalogParser(data, context=context, getenv=self.getenv,\n                               getshell=self.getshell)\n        if result.errors:\n            raise exceptions.ValidationError(\n                \"Catalog '{}' has validation errors:\\n\\n{}\"\n                \"\".format(self.path, \"\\n\".join(result.errors)), result.errors)\n\n        cfg = result.data\n\n        self._entries = {}\n        for entry in cfg['data_sources']:\n            entry._catalog = self\n            self._entries[entry.name] = entry\n\n        self.metadata = cfg.get('metadata', {})\n        self.name = self.name or cfg.get('name') or self.name_from_path\n        self.description = self.description or cfg.get('description')", "response": "Parse the text and create entries from the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets name of the class from path", "response": "def name_from_path(self):\n        \"\"\"If catalog is named 'catalog' take name from parent directory\"\"\"\n        name = os.path.splitext(os.path.basename(self.path))[0]\n        if name == 'catalog':\n            name = os.path.basename(os.path.dirname(self.path))\n        return name.replace('.', '_')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting one source s info.", "response": "def get(self):\n        \"\"\"\n        Access one source's info.\n\n        This is for direct access to an entry by name for random access, which\n        is useful to the client when the whole catalog has not first been\n        listed and pulled locally (e.g., in the case of pagination).\n        \"\"\"\n        head = self.request.headers\n        name = self.get_argument('name')\n        if self.auth.allow_connect(head):\n            if 'source_id' in head:\n                cat = self._cache.get(head['source_id'])\n            else:\n                cat = self._catalog\n            try:\n                source = cat[name]\n            except KeyError:\n                msg = 'No such entry'\n                raise tornado.web.HTTPError(status_code=404, log_message=msg,\n                                            reason=msg)\n            if self.auth.allow_access(head, source, self._catalog):\n                info = source.describe()\n                info['name'] = name\n                source_info = dict(source=info)\n                self.write(msgpack.packb(source_info, use_bin_type=True))\n                return\n\n        msg = 'Access forbidden'\n        raise tornado.web.HTTPError(status_code=403, log_message=msg,\n                                    reason=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to run on each cat input", "response": "def preprocess(cls, cat):\n        \"\"\"Function to run on each cat input\"\"\"\n        if isinstance(cat, str):\n            cat = intake.open_catalog(cat)\n        return cat"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_nested(self, cats):\n        down = '\u2502'\n        right = '\u2514\u2500\u2500'\n\n        def get_children(parent):\n            return [e() for e in parent._entries.values() if e._container == 'catalog']\n\n        if len(cats) == 0:\n            return\n\n        cat = cats[0]\n        old = list(self.options.items())\n        name = next(k for k, v in old if v == cat)\n        index = next(i for i, (k, v) in enumerate(old) if v == cat)\n        if right in name:\n            prefix = f'{name.split(right)[0]}{down} {right}'\n        else:\n            prefix = right\n\n        children = get_children(cat)\n        for i, child in enumerate(children):\n            old.insert(index+i+1, (f'{prefix} {child.name}', child))\n        self.widget.options = dict(old)", "response": "Populate widget with nested catalogs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collapse_nested(self, cats, max_nestedness=10):\n        children = []\n        removed = set()\n        nestedness = max_nestedness\n\n        old = list(self.widget.options.values())\n        nested = [cat for cat in old if getattr(cat, 'cat') is not None]\n        parents = {cat.cat for cat in nested}\n        parents_to_remove = cats\n        while len(parents_to_remove) > 0 and nestedness > 0:\n            for cat in nested:\n                if cat.cat in parents_to_remove:\n                    children.append(cat)\n            removed = removed.union(parents_to_remove)\n            nested = [cat for cat in nested if cat not in children]\n            parents_to_remove = {c for c in children if c in parents - removed}\n            nestedness -= 1\n        self.remove(children)", "response": "Collapse any items that are nested under cats."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the selected catalog - allow the passing of arbitrary args so that buttons work. Also remove any nested catalogs.", "response": "def remove_selected(self, *args):\n        \"\"\"Remove the selected catalog - allow the passing of arbitrary\n        args so that buttons work. Also remove any nested catalogs.\"\"\"\n        self.collapse_nested(self.selected)\n        self.remove(self.selected)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears and create a directory to store a persisted dataset into", "response": "def getdir(self, source):\n        \"\"\"Clear/create a directory to store a persisted dataset into\"\"\"\n        subdir = posixpath.join(self.pdir, source._tok)\n        try:\n            self.fs.rm(subdir, True)\n        except Exception as e:\n            logger.debug(\"Directory clear failed: %s\" % e)\n        self.fs.mkdirs(subdir)\n        return subdir"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the persisted source to the store under the given key", "response": "def add(self, key, source):\n        \"\"\"Add the persisted source to the store under the given key\n\n        key : str\n            The unique token of the un-persisted, original source\n        source : DataSource instance\n            The thing to add to the persisted catalogue, referring to persisted\n            data\n        \"\"\"\n        from intake.catalog.local import LocalCatalogEntry\n        try:\n            with self.fs.open(self.path, 'rb') as f:\n                data = yaml.safe_load(f)\n        except IOError:\n            data = {'sources': {}}\n        ds = source._yaml()['sources'][source.name]\n        data['sources'][key] = ds\n        with self.fs.open(self.path, 'wb') as fo:\n            fo.write(yaml.dump(data, default_flow_style=False).encode())\n        self._entries[key] = LocalCatalogEntry(\n            name=ds['metadata']['original_name'],\n            direct_access=True,\n            cache=[],\n            parameters=[],\n            catalog_dir=None,\n            **data['sources'][key])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tok(self, source):\n        if isinstance(source, str):\n            return source\n\n        if isinstance(source, CatalogEntry):\n            return source._metadata.get('original_tok', source._tok)\n\n        if isinstance(source, DataSource):\n            return source.metadata.get('original_tok', source._tok)\n        raise IndexError", "response": "Get string token from object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, source, delfiles=True):\n        source = self.get_tok(source)\n        with self.fs.open(self.path, 'rb') as f:\n            data = yaml.safe_load(f.read().decode())\n        data['sources'].pop(source, None)\n        with self.fs.open(self.path, 'wb') as fo:\n            fo.write(yaml.dump(data, default_flow_style=False).encode())\n        if delfiles:\n            path = posixpath.join(self.pdir, source)\n            try:\n                self.fs.rm(path, True)\n            except Exception as e:\n                logger.debug(\"Failed to delete persisted data dir %s\" % path)\n        self._entries.pop(source, None)", "response": "Remove a dataset from the persist store"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a unique key in the store recreate original source", "response": "def backtrack(self, source):\n        \"\"\"Given a unique key in the store, recreate original source\"\"\"\n        key = self.get_tok(source)\n        s = self[key]()\n        meta = s.metadata['original_source']\n        cls = meta['cls']\n        args = meta['args']\n        kwargs = meta['kwargs']\n        cls = import_name(cls)\n        sout = cls(*args, **kwargs)\n        sout.metadata = s.metadata['original_metadata']\n        sout.name = s.metadata['original_name']\n        return sout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh(self, key):\n        s0 = self[key]\n        s = self.backtrack(key)\n        s.persist(**s0.metadata['persist_kwargs'])", "response": "Recreate and re - persist the source for the given unique ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the source has expired in the store False otherwise", "response": "def needs_refresh(self, source):\n        \"\"\"Has the (persisted) source expired in the store\n\n        Will return True if the source is not in the store at all, if it's\n        TTL is set to None, or if more seconds have passed than the TTL.\n        \"\"\"\n        now = time.time()\n        if source._tok in self:\n            s0 = self[source._tok]\n            if self[source._tok].metadata.get('ttl', None):\n                then = s0.metadata['timestamp']\n                if s0.metadata['ttl'] < then - now:\n                    return True\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting sources from a list of cats", "response": "def cats(self, cats):\n        \"\"\"Set sources from a list of cats\"\"\"\n        sources = []\n        for cat in coerce_to_list(cats):\n            sources.extend([entry for entry in cat._entries.values() if entry._container != 'catalog'])\n        self.items = sources"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the intake catalog CLI.", "response": "def main(argv=None):\n    ''' Execute the \"intake\" command line program.\n\n    '''\n    from intake.cli.bootstrap import main as _main\n\n    return _main('Intake Catalog CLI', subcommands.all, argv or sys.argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_metadata(self):\n        if self._schema is None:\n            self._schema = self._get_schema()\n            self.datashape = self._schema.datashape\n            self.dtype = self._schema.dtype\n            self.shape = self._schema.shape\n            self.npartitions = self._schema.npartitions\n            self.metadata.update(self._schema.extra_metadata)", "response": "load metadata only if needed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a YAML representation of this data - source with optional plugins section.", "response": "def yaml(self, with_plugin=False):\n        \"\"\"Return YAML representation of this data-source\n\n        The output may be roughly appropriate for inclusion in a YAML\n        catalog. This is a best-effort implementation\n\n        Parameters\n        ----------\n        with_plugin: bool\n            If True, create a \"plugins\" section, for cases where this source\n            is created with a plugin not expected to be in the global Intake\n            registry.\n        \"\"\"\n        from yaml import dump\n        data = self._yaml(with_plugin=with_plugin)\n        return dump(data, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens resource and populate the source attributes.", "response": "def discover(self):\n        \"\"\"Open resource and populate the source attributes.\"\"\"\n        self._load_metadata()\n\n        return dict(datashape=self.datashape,\n                    dtype=self.dtype,\n                    shape=self.shape,\n                    npartitions=self.npartitions,\n                    metadata=self.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning iterator over the data fragments of the source", "response": "def read_chunked(self):\n        \"\"\"Return iterator over container fragments of data source\"\"\"\n        self._load_metadata()\n        for i in range(self.npartitions):\n            yield self._get_partition(i)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_partition(self, i):\n        self._load_metadata()\n        if i < 0 or i >= self.npartitions:\n            raise IndexError('%d is out of range' % i)\n\n        return self._get_partition(i)", "response": "Return a part of the data corresponding to i - th partition."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a high - level plotting API for the current object.", "response": "def plot(self):\n        \"\"\"\n        Returns a hvPlot object to provide a high-level plotting API.\n\n        To display in a notebook, be sure to run ``intake.output_notebook()``\n        first.\n        \"\"\"\n        try:\n            from hvplot import hvPlot\n        except ImportError:\n            raise ImportError(\"The intake plotting API requires hvplot.\"\n                              \"hvplot may be installed with:\\n\\n\"\n                              \"`conda install -c pyviz hvplot` or \"\n                              \"`pip install hvplot`.\")\n        metadata = self.metadata.get('plot', {})\n        fields = self.metadata.get('fields', {})\n        for attrs in fields.values():\n            if 'range' in attrs:\n                attrs['range'] = tuple(attrs['range'])\n        metadata['fields'] = fields\n        plots = self.metadata.get('plots', {})\n        return hvPlot(self, custom_plots=plots, **metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving data from this source to local persistent storage", "response": "def persist(self, ttl=None, **kwargs):\n        \"\"\"Save data from this source to local persistent storage\"\"\"\n        from ..container import container_map\n        from ..container.persist import PersistStore\n        import time\n        if 'original_tok' in self.metadata:\n            raise ValueError('Cannot persist a source taken from the persist '\n                             'store')\n        method = container_map[self.container]._persist\n        store = PersistStore()\n        out = method(self, path=store.getdir(self), **kwargs)\n        out.description = self.description\n        metadata = {'timestamp': time.time(),\n                    'original_metadata': self.metadata,\n                    'original_source': self.__getstate__(),\n                    'original_name': self.name,\n                    'original_tok': self._tok,\n                    'persist_kwargs': kwargs,\n                    'ttl': ttl,\n                    'cat': {} if self.cat is None else self.cat.__getstate__()}\n        out.metadata = metadata\n        out.name = self.name\n        store.add(self._tok, out)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(self, path, **kwargs):\n        from ..container import container_map\n        import time\n        method = container_map[self.container]._persist\n        # may need to create path - access file-system method\n        out = method(self, path=path, **kwargs)\n        out.description = self.description\n        metadata = {'timestamp': time.time(),\n                    'original_metadata': self.metadata,\n                    'original_source': self.__getstate__(),\n                    'original_name': self.name,\n                    'original_tok': self._tok,\n                    'persist_kwargs': kwargs}\n        out.metadata = metadata\n        out.name = self.name\n        return out.yaml()", "response": "Save this data for sharing with other people"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_user_catalog():\n    cat_dir = user_data_dir()\n    if not os.path.isdir(cat_dir):\n        return Catalog()\n    else:\n        return YAMLFilesCatalog(cat_dir)", "response": "Return a catalog for the platform - specific user Intake directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_global_catalog():\n    cat_dir = global_data_dir()\n    if not os.path.isdir(cat_dir):\n        return Catalog()\n    else:\n        return YAMLFilesCatalog(cat_dir)", "response": "Return a catalog for the environment - specific Intake directory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasking conda to see if there is a prefix in PATH", "response": "def conda_prefix():\n    \"\"\"Fallback: ask conda in PATH for its prefix\"\"\"\n    try:\n        out = subprocess.check_output(['conda', 'info', '--json'])\n        return json.loads(out.decode())[\"default_prefix\"]\n    except (subprocess.CalledProcessError, json.JSONDecodeError, OSError):\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef global_data_dir():\n    prefix = False\n    if VIRTUALENV_VAR in os.environ:\n        prefix = os.environ[VIRTUALENV_VAR]\n    elif CONDA_VAR in os.environ:\n        prefix = sys.prefix\n    elif which('conda'):\n        # conda exists but is not activated\n        prefix = conda_prefix()\n\n    if prefix:\n        # conda and virtualenv use Linux-style directory pattern\n        return make_path_posix(os.path.join(prefix, 'share', 'intake'))\n    else:\n        return appdirs.site_data_dir(appname='intake', appauthor='intake')", "response": "Return the global Intake catalog dir for the current environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_combo_catalog():\n    user_dir = user_data_dir()\n    global_dir = global_data_dir()\n    desc = 'Generated from data packages found on your intake search path'\n    cat_dirs = []\n    if os.path.isdir(user_dir):\n        cat_dirs.append(user_dir + '/*.yaml')\n        cat_dirs.append(user_dir + '/*.yml')\n    if os.path.isdir(global_dir):\n        cat_dirs.append(global_dir + '/*.yaml')\n        cat_dirs.append(global_dir + '/*.yml')\n    for path_dir in conf.get('catalog_path', []):\n        if path_dir != '':\n            if not path_dir.endswith(('yaml', 'yml')):\n                cat_dirs.append(path_dir + '/*.yaml')\n                cat_dirs.append(path_dir + '/*.yml')\n            else:\n                cat_dirs.append(path_dir)\n\n    return YAMLFilesCatalog(cat_dirs, name='builtin', description=desc)", "response": "Load a union of the user and global catalogs for convenience"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new instance of the class from a dict - like object.", "response": "def from_dict(cls, entries, **kwargs):\n        \"\"\"\n        Create Catalog from the given set of entries\n\n        Parameters\n        ----------\n        entries : dict-like\n            A mapping of name:entry which supports dict-like functionality,\n            e.g., is derived from ``collections.abc.Mapping``.\n        kwargs : passed on the constructor\n            Things like metadata, name; see ``__init__``.\n\n        Returns\n        -------\n        Catalog instance\n        \"\"\"\n        from dask.base import tokenize\n        cat = cls(**kwargs)\n        cat._entries = entries\n        cat._tok = tokenize(kwargs, entries)\n        return cat"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reload(self):\n        if time.time() - self.updated > self.ttl:\n            self.force_reload()", "response": "Reload catalog if sufficient time has passed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter(self, func):\n        return Catalog.from_dict({key: entry for key, entry in self.items()\n                                  if func(entry)})", "response": "Create a new Catalog instance with only the entries that satisfy a condition"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk(self, sofar=None, prefix=None, depth=2):\n        out = sofar if sofar is not None else {}\n        prefix = [] if prefix is None else prefix\n        for name, item in self._entries.items():\n            if item._container == 'catalog' and depth > 1:\n                # recurse with default open parameters\n                try:\n                    item().walk(out, prefix + [name], depth-1)\n                except Exception as e:\n                    print(e)\n                    pass  # ignore inability to descend\n            n = '.'.join(prefix + [name])\n            out[n] = item\n        return out", "response": "Walks the catalog and sub - catalogs and returns a dict of all entries in this catalog and sub - catalogs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproducing YAML version of this catalog.", "response": "def serialize(self):\n        \"\"\"\n        Produce YAML version of this catalog.\n\n        Note that this is not the same as ``.yaml()``, which produces a YAML\n        block referring to this catalog.\n        \"\"\"\n        import yaml\n        output = {\"metadata\": self.metadata, \"sources\": {},\n                  \"name\": self.name}\n        for key, entry in self.items():\n            output[\"sources\"][key] = entry._captured_init_kwargs\n        return yaml.dump(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves this catalog to a file as YAML", "response": "def save(self, url, storage_options=None):\n        \"\"\"\n        Output this catalog to a file as YAML\n\n        Parameters\n        ----------\n        url : str\n            Location to save to, perhaps remote\n        storage_options : dict\n            Extra arguments for the file-system\n        \"\"\"\n        from dask.bytes import open_files\n        with open_files([url], **(storage_options or {}), mode='wt')[0] as f:\n            f.write(self.serialize())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing caches to force a reload.", "response": "def reset(self):\n        \"Clear caches to force a reload.\"\n        self._page_cache.clear()\n        self._direct_lookup_cache.clear()\n        self._page_offset = 0\n        self.complete = self._catalog.page_size is None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over items that are already cached. Perform no requests.", "response": "def cached_items(self):\n        \"\"\"\n        Iterate over items that are already cached. Perform no requests.\n        \"\"\"\n        for item in six.iteritems(self._page_cache):\n            yield item\n        for item in six.iteritems(self._direct_lookup_cache):\n            yield item"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the http_args with the headers and source_id merged in params.", "response": "def _get_http_args(self, params):\n        \"\"\"\n        Return a copy of the http_args\n\n        Adds auth headers and 'source_id', merges in params.\n        \"\"\"\n        # Add the auth headers to any other headers\n        headers = self.http_args.get('headers', {})\n        if self.auth is not None:\n            auth_headers = self.auth.get_headers()\n            headers.update(auth_headers)\n\n        # build new http args with these headers\n        http_args = self.http_args.copy()\n        if self._source_id is not None:\n            headers['source_id'] = self._source_id\n        http_args['headers'] = headers\n\n        # Merge in any params specified by the caller.\n        merged_params = http_args.get('params', {})\n        merged_params.update(params)\n        http_args['params'] = merged_params\n        return http_args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load(self):\n        # This will not immediately fetch any sources (entries). It will lazily\n        # fetch sources from the server in paginated blocks when this Catalog\n        # is iterated over. It will fetch specific sources when they are\n        # accessed in this Catalog via __getitem__.\n\n        if self.page_size is None:\n            # Fetch all source info.\n            params = {}\n        else:\n            # Just fetch the metadata now; fetch source info later in pages.\n            params = {'page_offset': 0, 'page_size': 0}\n        http_args = self._get_http_args(params)\n        response = requests.get(self.info_url, **http_args)\n        try:\n            response.raise_for_status()\n        except requests.HTTPError as err:\n            six.raise_from(RemoteCatalogError(\n                \"Failed to fetch metadata.\"), err)\n        info = msgpack.unpackb(response.content, **unpack_kwargs)\n        self.metadata = info['metadata']\n        # The intake server now always provides a length, but the server may be\n        # running an older version of intake.\n        self._len = info.get('length')\n        self._entries.reset()\n        # If we are paginating (page_size is not None) and the server we are\n        # working with is new enough to support pagination, info['sources']\n        # should be empty. If either of those things is not true,\n        # info['sources'] will contain all the entries and we should cache them\n        # now.\n        if info['sources']:\n            # Signal that we are not paginating, even if we were asked to.\n            self._page_size = None\n            self._entries._page_cache.update(\n                {source['name']: RemoteCatalogEntry(\n                    url=self.url,\n                    getenv=self.getenv,\n                    getshell=self.getshell,\n                    auth=self.auth,\n                    http_args=self.http_args, **source)\n                 for source in info['sources']})", "response": "Fetch metadata from remote."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nice_join(seq, sep=\", \", conjunction=\"or\"):\n    ''' Join together sequences of strings into English-friendly phrases using\n    a conjunction when appropriate.\n\n    Args:\n        seq (seq[str]) : a sequence of strings to nicely join\n\n        sep (str, optional) : a sequence delimiter to use (default: \", \")\n\n        conjunction (str or None, optional) : a conjunction to use for the last\n            two items, or None to reproduce basic join behavior (default: \"or\")\n\n    Returns:\n        a joined string\n\n    Examples:\n        >>> nice_join([\"a\", \"b\", \"c\"])\n        'a, b or c'\n\n    '''\n    seq = [str(x) for x in seq]\n\n    if len(seq) <= 1 or conjunction is None:\n        return sep.join(seq)\n    else:\n        return \"%s %s %s\" % (sep.join(seq[:-1]), conjunction, seq[-1])", "response": "Join together sequences of strings into English - friendly phrases using\n    a conjunction when appropriate."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates open_* functions from the current state of registry.", "response": "def make_open_functions():\n    \"\"\"From the current state of ``registry``, create open_* functions\"\"\"\n    # Create shortcut open methods\n    if hasattr(str, 'isidentifier'):\n        def isidentifier(x):\n            return x.isidentifier()\n    else:\n        IDENTIFIER_REGEX = re.compile(r'[a-zA-Z_][a-zA-Z0-9_]*$')\n        isidentifier = IDENTIFIER_REGEX.match\n    for plugin_name, plugin in registry.items():\n        func_name = 'open_' + plugin_name\n        if not isidentifier(func_name):\n            # primitive name normalization\n            func_name = re.sub('[-=~^&|@+]', '_', func_name)\n        if isidentifier(func_name):\n            globals()[func_name] = plugin\n        else:\n            warnings.warn('Invalid Intake plugin name \"%s\" found.' %\n                          plugin_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the notebook extension and output it as a string.", "response": "def output_notebook(inline=True, logo=False):\n    \"\"\"\n    Load the notebook extension\n\n    Parameters\n    ----------\n    inline : boolean (optional)\n        Whether to inline JS code or load it from a CDN\n    logo : boolean (optional)\n        Whether to show the logo(s)\n    \"\"\"\n    try:\n        import hvplot\n    except ImportError:\n        raise ImportError(\"The intake plotting API requires hvplot.\"\n                          \"hvplot may be installed with:\\n\\n\"\n                          \"`conda install -c pyviz hvplot` or \"\n                          \"`pip install hvplot`.\")\n    import holoviews as hv\n    return hv.extension('bokeh', inline=inline, logo=logo)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_catalog(uri=None, **kwargs):\n    driver = kwargs.pop('driver', None)\n    if driver is None:\n        if uri:\n            if ((isinstance(uri, str) and \"*\" in uri)\n                    or ((isinstance(uri, (list, tuple))) and len(uri) > 1)):\n                # glob string or list of files/globs\n                driver = 'yaml_files_cat'\n            elif isinstance(uri, (list, tuple)) and len(uri) == 1:\n                uri = uri[0]\n                if \"*\" in uri[0]:\n                    # single glob string in a list\n                    driver = 'yaml_files_cat'\n                else:\n                    # single filename in a list\n                    driver = 'yaml_file_cat'\n            elif isinstance(uri, str):\n                # single URL\n                if uri.startswith('intake:'):\n                    # server\n                    driver = 'intake_remote'\n                else:\n                    if uri.endswith(('.yml', '.yaml')):\n                        driver = 'yaml_file_cat'\n                    else:\n                        uri = uri.rstrip('/') + '/*.y*ml'\n                        driver = 'yaml_files_cat'\n        else:\n            # empty cat\n            driver = 'catalog'\n    if driver not in registry:\n        raise ValueError('Unknown catalog driver (%s), supply one of: %s'\n                         % (driver, list(sorted(registry))))\n    return registry[driver](uri, **kwargs)", "response": "Create a base catalog object which can be used to open a specific file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _persist(source, path, **kwargs):\n        try:\n            from intake_parquet import ParquetSource\n        except ImportError:\n            raise ImportError(\"Please install intake-parquet to use persistence\"\n                              \" on dataframe container sources.\")\n        try:\n            df = source.to_dask()\n        except NotImplementedError:\n            import dask.dataframe as dd\n            df = dd.from_pandas(source.read(), 1)\n        df.to_parquet(path, **kwargs)\n        source = ParquetSource(path, meta={})\n        return source", "response": "Save dataframe to local persistent store"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving current configuration to file as YAML", "response": "def save_conf(fn=None):\n    \"\"\"Save current configuration to file as YAML\n\n    If not given, uses current config directory, ``confdir``, which can be\n    set by INTAKE_CONF_DIR.\n    \"\"\"\n    if fn is None:\n        fn = cfile()\n    try:\n        os.makedirs(os.path.dirname(fn))\n    except (OSError, IOError):\n        pass\n    with open(fn, 'w') as f:\n        yaml.dump(conf, f)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a single config file from YAML file.", "response": "def load_conf(fn=None):\n    \"\"\"Update global config from YAML file\n\n    If fn is None, looks in global config directory, which is either defined\n    by the INTAKE_CONF_DIR env-var or is ~/.intake/ .\n    \"\"\"\n    if fn is None:\n        fn = cfile()\n    if os.path.isfile(fn):\n        with open(fn) as f:\n            try:\n                conf.update(yaml_load(f))\n            except Exception as e:\n                logger.warning('Failure to load config file \"{fn}\": {e}'\n                               ''.format(fn=fn, e=e))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef intake_path_dirs(path):\n    if isinstance(path, (list, tuple)):\n        return path\n    import re\n    pattern = re.compile(\";\" if os.name == 'nt' else r\"(?<!:):(?![:/])\")\n    return pattern.split(path)", "response": "Return a list of directories from the intake path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_env():\n    # environment variables take precedence over conf file\n    for key, envvar in [['cache_dir', 'INTAKE_CACHE_DIR'],\n                        ['catalog_path', 'INTAKE_PATH'],\n                        ['persist_path', 'INTAKE_PERSIST_PATH']]:\n        if envvar in os.environ:\n            conf[key] = make_path_posix(os.environ[envvar])\n    conf['catalog_path'] = intake_path_dirs(conf['catalog_path'])\n    for key, envvar in [['cache_disabled', 'INTAKE_DISABLE_CACHING'],\n                        ['cache_download_progress', 'INTAKE_CACHE_PROGRESS']]:\n        if envvar in os.environ:\n            conf[key] = os.environ[envvar].lower() in ['true', 't', 'y', 'yes']\n    if 'INTAKE_LOG_LEVEL' in os.environ:\n        conf['logging'] = os.environ['INTAKE_LOG_LEVEL']", "response": "Analyse enviroment variables and update conf accordingly"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contents(self):\n        if not self._source:\n            return ' ' * 100  # HACK - make sure that area is big\n        contents = self.source.describe()\n        return pretty_describe(contents)", "response": "String representation of the source s description"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreverse the string method format for a list of strings.", "response": "def reverse_formats(format_string, resolved_strings):\n    \"\"\"\n    Reverse the string method format for a list of strings.\n\n    Given format_string and resolved_strings, for each resolved string\n    find arguments that would give\n    ``format_string.format(**arguments) == resolved_string``.\n\n    Each item in the output corresponds to a new column with the key setting\n    the name and the values representing a mapping from list of resolved_strings\n    to the related value.\n\n    Parameters\n    ----------\n    format_strings : str\n        Format template string as used with str.format method\n    resolved_strings : list\n        List of strings with same pattern as format_string but with fields\n        filled out.\n\n    Returns\n    -------\n    args : dict\n        Dict of the form ``{field: [value_0, ..., value_n], ...}`` where values are in\n        the same order as resolved_strings, so:\n        ``format_sting.format(**{f: v[0] for f, v in args.items()}) == resolved_strings[0]``\n\n    Examples\n    --------\n\n    >>> paths = ['data_2014_01_03.csv', 'data_2014_02_03.csv', 'data_2015_12_03.csv']\n    >>> reverse_formats('data_{year}_{month}_{day}.csv', paths)\n    {'year':  ['2014', '2014', '2015'],\n     'month': ['01', '02', '12'],\n     'day':   ['03', '03', '03']}\n    >>> reverse_formats('data_{year:d}_{month:d}_{day:d}.csv', paths)\n    {'year': [2014, 2014, 2015], 'month': [1, 2, 12], 'day': [3, 3, 3]}\n    >>> reverse_formats('data_{date:%Y_%m_%d}.csv', paths)\n    {'date': [datetime.datetime(2014, 1, 3, 0, 0),\n              datetime.datetime(2014, 2, 3, 0, 0),\n              datetime.datetime(2015, 12, 3, 0, 0)]}\n    >>> reverse_formats('{state:2}{zip:5}', ['PA19104', 'PA19143', 'MA02534'])\n    {'state': ['PA', 'PA', 'MA'], 'zip': ['19104', '19143', '02534']}\n\n    See also\n    --------\n    str.format : method that this reverses\n    reverse_format : method for reversing just one string using a pattern\n    \"\"\"\n    from string import Formatter\n\n    fmt = Formatter()\n\n    # get the fields from the format_string\n    field_names = [i[1] for i in fmt.parse(format_string) if i[1]]\n\n    # itialize the args dict with an empty dict for each field\n    args = {field_name: [] for field_name in field_names}\n    for resolved_string in resolved_strings:\n        for field, value in reverse_format(format_string, resolved_string).items():\n            args[field].append(value)\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreversing the string method format.", "response": "def reverse_format(format_string, resolved_string):\n    \"\"\"\n    Reverse the string method format.\n\n    Given format_string and resolved_string, find arguments that would\n    give ``format_string.format(**arguments) == resolved_string``\n\n    Parameters\n    ----------\n    format_string : str\n        Format template string as used with str.format method\n    resolved_string : str\n        String with same pattern as format_string but with fields\n        filled out.\n\n    Returns\n    -------\n    args : dict\n        Dict of the form {field_name: value} such that\n        ``format_string.(**args) == resolved_string``\n\n    Examples\n    --------\n\n    >>> reverse_format('data_{year}_{month}_{day}.csv', 'data_2014_01_03.csv')\n    {'year': '2014', 'month': '01', 'day': '03'}\n    >>> reverse_format('data_{year:d}_{month:d}_{day:d}.csv', 'data_2014_01_03.csv')\n    {'year': 2014, 'month': 1, 'day': 3}\n    >>> reverse_format('data_{date:%Y_%m_%d}.csv', 'data_2016_10_01.csv')\n    {'date': datetime.datetime(2016, 10, 1, 0, 0)}\n    >>> reverse_format('{state:2}{zip:5}', 'PA19104')\n    {'state': 'PA', 'zip': '19104'}\n\n    See also\n    --------\n    str.format : method that this reverses\n    reverse_formats : method for reversing a list of strings using one pattern\n    \"\"\"\n    from string import Formatter\n    from datetime import datetime\n\n    fmt = Formatter()\n    args = {}\n\n    # ensure that format_string is in posix format\n    format_string = make_path_posix(format_string)\n\n    # split the string into bits\n    literal_texts, field_names, format_specs, conversions = zip(*fmt.parse(format_string))\n    if not any(field_names):\n        return {}\n\n    for i, conversion in enumerate(conversions):\n        if conversion:\n            raise ValueError(('Conversion not allowed. Found on {}.'\n                              .format(field_names[i])))\n\n    # ensure that resolved string is in posix format\n    resolved_string = make_path_posix(resolved_string)\n\n    # get a list of the parts that matter\n    bits = _get_parts_of_format_string(resolved_string, literal_texts, format_specs)\n\n    for i, (field_name, format_spec) in enumerate(zip(field_names, format_specs)):\n        if field_name:\n            try:\n                if format_spec.startswith('%'):\n                    args[field_name] = datetime.strptime(bits[i], format_spec)\n                elif format_spec[-1] in list('bcdoxX'):\n                    args[field_name] = int(bits[i])\n                elif format_spec[-1] in list('eEfFgGn'):\n                    args[field_name] = float(bits[i])\n                elif format_spec[-1] == '%':\n                    args[field_name] = float(bits[i][:-1])/100\n                else:\n                    args[field_name] = fmt.format_field(bits[i], format_spec)\n            except:\n                args[field_name] = bits[i]\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path_to_glob(path):\n    from string import Formatter\n\n    fmt = Formatter()\n\n    if not isinstance(path, str):\n        return path\n\n    # Get just the real bits of the urlpath\n    literal_texts = [i[0] for i in fmt.parse(path)]\n\n    # Only use a star for first empty string in literal_texts\n    index_of_empty = [i for i, lt in enumerate(literal_texts) if lt == '' and i != 0]\n    glob = '*'.join([literal_texts[i] for i in range(len(literal_texts)) if i not in index_of_empty])\n\n    return glob", "response": "Converts pattern style paths to glob style paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a path to a pattern that can be used to build a cache object.", "response": "def path_to_pattern(path, metadata=None):\n    \"\"\"\n    Remove source information from path when using chaching\n\n    Returns None if path is not str\n\n    Parameters\n    ----------\n    path : str\n        Path to data optionally containing format_strings\n    metadata : dict, optional\n        Extra arguments to the class, contains any cache information\n\n    Returns\n    -------\n    pattern : str\n        Pattern style path stripped of everything to the left of cache regex.\n    \"\"\"\n    if not isinstance(path, str):\n        return\n\n    pattern = path\n    if metadata:\n        cache = metadata.get('cache')\n        if cache:\n            regex = next(c.get('regex') for c in cache if c.get('argkey') == 'urlpath')\n            pattern = pattern.split(regex)[-1]\n    return pattern"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_partition(url, headers, source_id, container, partition):\n    accepted_formats = list(serializer.format_registry.keys())\n    accepted_compression = list(serializer.compression_registry.keys())\n    payload = dict(action='read',\n                   source_id=source_id,\n                   accepted_formats=accepted_formats,\n                   accepted_compression=accepted_compression)\n\n    if partition is not None:\n        payload['partition'] = partition\n\n    try:\n        resp = requests.post(urljoin(url, '/v1/source'),\n                             data=msgpack.packb(payload, use_bin_type=True),\n                             **headers)\n        if resp.status_code != 200:\n            raise Exception('Error reading data')\n\n        msg = msgpack.unpackb(resp.content, **unpack_kwargs)\n        format = msg['format']\n        compression = msg['compression']\n        compressor = serializer.compression_registry[compression]\n        encoder = serializer.format_registry[format]\n        chunk = encoder.decode(compressor.decompress(msg['data']),\n                               container)\n        return chunk\n    finally:\n        if resp is not None:\n            resp.close()", "response": "Serializable function for fetching a data source partition"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flatten(iterable):\n    # likely not used\n    iterable = iter(iterable)\n    while True:\n        try:\n            item = next(iterable)\n        except StopIteration:\n            break\n\n        if isinstance(item, six.string_types):\n            yield item\n            continue\n\n        try:\n            data = iter(item)\n            iterable = itertools.chain(data, iterable)\n        except:\n            yield item", "response": "Flatten an arbitrarily deep list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clamp(value, lower=0, upper=sys.maxsize):\n    return max(lower, min(upper, value))", "response": "Clamp float between given range"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexpand variables in context into a set of parameters with jinja2.", "response": "def expand_templates(pars, context, return_left=False, client=False,\n                     getenv=True, getshell=True):\n    \"\"\"\n    Render variables in context into the set of parameters with jinja2.\n\n    For variables that are not strings, nothing happens.\n\n    Parameters\n    ----------\n    pars: dict\n        values are strings containing some jinja2 controls\n    context: dict\n        values to use while rendering\n    return_left: bool\n        whether to return the set of variables in context that were not used\n        in rendering parameters\n\n    Returns\n    -------\n    dict with the same keys as ``pars``, but updated values; optionally also\n    return set of unused parameter names.\n    \"\"\"\n    all_vars = set(context)\n    out = _expand(pars, context, all_vars, client, getenv, getshell)\n    if return_left:\n        return out, all_vars\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_defaults(default, client=False, getenv=True, getshell=True):\n    r = re.match(r'env\\((.*)\\)', default)\n    if r and not client and getenv:\n        default = os.environ.get(r.groups()[0], '')\n    r = re.match(r'client_env\\((.*)\\)', default)\n    if r and client and getenv:\n        default = os.environ.get(r.groups()[0], '')\n    r = re.match(r'shell\\((.*)\\)', default)\n    if r and not client and getshell:\n        try:\n            cmd = shlex.split(r.groups()[0])\n            default = subprocess.check_output(\n                cmd).rstrip().decode('utf8')\n        except (subprocess.CalledProcessError, OSError):\n            default = ''\n    r = re.match(r'client_shell\\((.*)\\)', default)\n    if r and client and getshell:\n        try:\n            cmd = shlex.split(r.groups()[0])\n            default = subprocess.check_output(\n                cmd).rstrip().decode('utf8')\n        except (subprocess.CalledProcessError, OSError):\n            default = ''\n    return default", "response": "Expand the default string for the cat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_pars(params, user_inputs, spec_pars, client=False, getenv=True,\n               getshell=True):\n    \"\"\"Produce open arguments by merging various inputs\n\n    This function is called in the context of a catalog entry, when finalising\n    the arguments for instantiating the corresponding data source.\n\n    The three sets of inputs to be considered are:\n    - the arguments section of the original spec (params)\n    - UserParameters associated with the entry (spec_pars)\n    - explicit arguments provided at instantiation time, like entry(arg=value)\n      (user_inputs)\n\n    Both spec_pars and user_inputs can be considered as template variables and\n    used in expanding string values in params.\n\n    The default value of a spec_par, if given, may have embedded env and shell\n    functions, which will be evaluated before use, if the default is used and\n    the corresponding getenv/getsgell are set. Similarly, string value params\n    will also have access to these functions within jinja template groups,\n    as well as full jinja processing.\n\n    Where a key exists in both the spec_pars and the user_inputs, the\n    user_input wins. Where user_inputs contains keys not seen elsewhere, they\n    are regarded as extra kwargs to pass to the data source.\n\n    Where spec pars have the same name as keys in params, their type, max/min\n    and allowed fields are used to validate the final values of the\n    corresponding arguments.\n\n    Parameters\n    ----------\n    params : dict\n        From the entry's original spec\n    user_inputs : dict\n        Provided by the user/calling function\n    spec_pars : list of UserParameters\n        Default and validation instances\n    client : bool\n        Whether this is all running on a client to a remote server - sets\n        which of the env/shell functions are in operation.\n    getenv : bool\n        Whether to allow pulling environment variables. If False, the\n        template blocks will pass through unevaluated\n    getshell : bool\n        Whether or not to allow executing of shell commands. If False, the\n        template blocks will pass through unevaluated\n\n    Returns\n    -------\n    Final parameter dict\n    \"\"\"\n    context = params.copy()\n    for par in spec_pars:\n        val = user_inputs.get(par.name, par.default)\n        if val is not None:\n            if isinstance(val, six.string_types):\n                val = expand_defaults(val, getenv=getenv, getshell=getshell,\n                                      client=client)\n            context[par.name] = par.validate(val)\n    context.update({k: v for k, v in user_inputs.items() if k not in context})\n    out, left = expand_templates(params, context, True, client, getenv,\n                                 getshell)\n    context = {k: v for k, v in context.items() if k in left}\n    for par in spec_pars:\n        if par.name in context:\n            # coerces to type\n            context[par.name] = par.validate(context[par.name])\n            left.remove(par.name)\n\n    params.update(out)\n    user_inputs = expand_templates(user_inputs, context, False, client, getenv,\n                                   getshell)\n    params.update({k: v for k, v in user_inputs.items() if k in left})\n    params.pop('CATALOG_DIR')\n    for k, v in params.copy().items():\n        # final validation/coersion\n        for sp in [p for p in spec_pars if p.name == k]:\n            params[k] = sp.validate(params[k])\n\n    return params", "response": "This function takes a dictionary of parameters and a list of UserParameters associated with the entry and returns a dict of the final set of parameters that can be used to instantiate the final set of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coerce(dtype, value):\n    if dtype is None:\n        return value\n    if type(value).__name__ == dtype:\n        return value\n    op = COERCION_RULES[dtype]\n    return op() if value is None else op(value)", "response": "Coerce a value to a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_remote(url, entry, container, user_parameters, description, http_args,\n                page_size=None, auth=None, getenv=None, getshell=None):\n    \"\"\"Create either local direct data source or remote streamed source\"\"\"\n    from intake.container import container_map\n    if url.startswith('intake://'):\n        url = url[len('intake://'):]\n    payload = dict(action='open',\n                   name=entry,\n                   parameters=user_parameters,\n                   available_plugins=list(plugin_registry.keys()))\n    req = requests.post(urljoin(url, '/v1/source'),\n                        data=msgpack.packb(payload, use_bin_type=True),\n                        **http_args)\n    if req.ok:\n        response = msgpack.unpackb(req.content, **unpack_kwargs)\n\n        if 'plugin' in response:\n            pl = response['plugin']\n            pl = [pl] if isinstance(pl, str) else pl\n            # Direct access\n            for p in pl:\n                if p in plugin_registry:\n                    source = plugin_registry[p](**response['args'])\n                    proxy = False\n                    break\n            else:\n                proxy = True\n        else:\n            proxy = True\n        if proxy:\n            response.pop('container')\n            response.update({'name': entry, 'parameters': user_parameters})\n            if container == 'catalog':\n                response.update({'auth': auth,\n                                 'getenv': getenv,\n                                 'getshell': getshell,\n                                 'page_size': page_size\n                                 # TODO ttl?\n                                 # TODO storage_options?\n                                 })\n            source = container_map[container](url, http_args, **response)\n        source.description = description\n        return source\n\n    else:\n        raise Exception('Server error: %d, %s' % (req.status_code, req.reason))", "response": "Create either local direct or remote streamed source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _persist(source, path, encoder=None):\n        import posixpath\n        from dask.bytes import open_files\n        import dask\n        import pickle\n        import json\n        from intake.source.textfiles import TextFilesSource\n        encoder = {None: str, 'str': str, 'json': json.dumps,\n                   'pickle': pickle.dumps}[encoder]\n        try:\n            b = source.to_dask()\n        except NotImplementedError:\n            import dask.bag as db\n            b = db.from_sequence(source.read(), npartitions=1)\n        files = open_files(posixpath.join(path, 'part.*'), mode='wt',\n                           num=b.npartitions)\n        dwrite = dask.delayed(write_file)\n        out = [dwrite(part, f, encoder)\n               for part, f in zip(b.to_delayed(), files)]\n        dask.compute(out)\n        s = TextFilesSource(posixpath.join(path, 'part.*'))\n        return s", "response": "Save list to files using encoding\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay the entry as a rich object in an IPython session.", "response": "def _ipython_display_(self):\n        \"\"\"Display the entry as a rich object in an IPython session.\"\"\"\n        contents = self.describe()\n        display({  # noqa: F821\n            'application/json': contents,\n            'text/plain': pretty_describe(contents)\n        }, metadata={\n            'application/json': {'root': contents[\"name\"]}\n        }, raw=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans for Intake plugin packages and return a dict of plugins.", "response": "def autodiscover(path=None, plugin_prefix='intake_'):\n    \"\"\"Scan for Intake plugin packages and return a dict of plugins.\n\n    This function searches path (or sys.path) for packages with names that\n    start with plugin_prefix.  Those modules will be imported and scanned for\n    subclasses of intake.source.base.Plugin.  Any subclasses found will be\n    instantiated and returned in a dictionary, with the plugin's name attribute\n    as the key.\n    \"\"\"\n\n    plugins = {}\n\n    for importer, name, ispkg in pkgutil.iter_modules(path=path):\n        if name.startswith(plugin_prefix):\n            t = time.time()\n            new_plugins = load_plugins_from_module(name)\n\n            for plugin_name, plugin in new_plugins.items():\n                if plugin_name in plugins:\n                    orig_path = inspect.getfile(plugins[plugin_name])\n                    new_path = inspect.getfile(plugin)\n                    warnings.warn('Plugin name collision for \"%s\" from'\n                                  '\\n    %s'\n                                  '\\nand'\n                                  '\\n    %s'\n                                  '\\nKeeping plugin from first location.'\n                                  % (plugin_name, orig_path, new_path))\n                else:\n                    plugins[plugin_name] = plugin\n            logger.debug(\"Import %s took: %7.2f s\" % (name, time.time() - t))\n\n    return plugins"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports a module and returns a dictionary of Intake plugins.", "response": "def load_plugins_from_module(module_name):\n    \"\"\"Imports a module and returns dictionary of discovered Intake plugins.\n\n    Plugin classes are instantiated and added to the dictionary, keyed by the\n    name attribute of the plugin object.\n    \"\"\"\n    plugins = {}\n\n    try:\n        if module_name.endswith('.py'):\n            import imp\n            mod = imp.load_source('module.name', module_name)\n        else:\n            mod = importlib.import_module(module_name)\n    except Exception as e:\n        logger.debug(\"Import module <{}> failed: {}\".format(module_name, e))\n        return {}\n    for _, cls in inspect.getmembers(mod, inspect.isclass):\n        # Don't try to register plugins imported into this module elsewhere\n        if issubclass(cls, (Catalog, DataSource)):\n            plugins[cls.name] = cls\n\n    return plugins"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_pattern_columns(self, path_column):\n        try:\n            # CategoricalDtype allows specifying known categories when\n            # creating objects. It was added in pandas 0.21.0.\n            from pandas.api.types import CategoricalDtype\n            _HAS_CDT = True\n        except ImportError:\n            _HAS_CDT = False\n\n        col = self._dataframe[path_column]\n        paths = col.cat.categories\n\n        column_by_field = {field:\n            col.cat.codes.map(dict(enumerate(values))).astype(\n                \"category\" if not _HAS_CDT else CategoricalDtype(set(values))\n            ) for field, values in reverse_formats(self.pattern, paths).items()\n        }\n        self._dataframe = self._dataframe.assign(**column_by_field)", "response": "Set the columns of the pattern to the values for each field in pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets include_path_column in csv_kwargs and returns path column name", "response": "def _path_column(self):\n        \"\"\"Set ``include_path_column`` in csv_kwargs and returns path column name\n        \"\"\"\n        path_column = self._csv_kwargs.get('include_path_column')\n\n        if path_column is None:\n            # if path column name is not set by user, set to a unique string to\n            # avoid conflicts\n            path_column = unique_string()\n            self._csv_kwargs['include_path_column'] = path_column\n        elif isinstance(path_column, bool):\n            path_column = 'path'\n            self._csv_kwargs['include_path_column'] = path_column\n        return path_column"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _open_dataset(self, urlpath):\n        import dask.dataframe\n\n        if self.pattern is None:\n            self._dataframe = dask.dataframe.read_csv(\n                urlpath, storage_options=self._storage_options,\n                **self._csv_kwargs)\n            return\n\n        if not (DASK_VERSION >= '0.19.0'):\n            raise ValueError(\"Your version of dask is '{}'. \"\n                \"The ability to include filenames in read_csv output \"\n                \"(``include_path_column``) was added in 0.19.0, so \"\n                \"pattern urlpaths are not supported.\".format(DASK_VERSION))\n\n        drop_path_column = 'include_path_column' not in self._csv_kwargs\n        path_column = self._path_column()\n\n        self._dataframe = dask.dataframe.read_csv(\n            urlpath, storage_options=self._storage_options, **self._csv_kwargs)\n\n        # add the new columns to the dataframe\n        self._set_pattern_columns(path_column)\n\n        if drop_path_column:\n            self._dataframe = self._dataframe.drop([path_column], axis=1)", "response": "Open dataset using dask and use pattern fields to set new columns"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo search and close panel", "response": "def do_search(self, arg=None):\n        \"\"\"Do search and close panel\"\"\"\n        new_cats = []\n        for cat in self.cats:\n            new_cat = cat.search(self.inputs.text,\n                                 depth=self.inputs.depth)\n            if len(list(new_cat)) > 0:\n                new_cats.append(new_cat)\n        if len(new_cats) > 0:\n            self.done_callback(new_cats)\n            self.visible = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave an array to local persistent store.", "response": "def _persist(source, path, component=None, storage_options=None,\n                 **kwargs):\n        \"\"\"Save array to local persistent store\n\n        Makes a parquet dataset out of the data using zarr.\n        This then becomes a data entry in the persisted datasets catalog.\n        Only works locally for the moment.\n\n        Parameters\n        ----------\n        source: a DataSource instance to save\n        name: str or None\n            Key to refer to this persisted dataset by. If not given, will\n            attempt to get from the source's name\n        kwargs: passed on to zarr array creation, see\n        \"\"\"\n        from dask.array import to_zarr, from_array\n        from ..source.zarr import ZarrArraySource\n        try:\n            arr = source.to_dask()\n        except NotImplementedError:\n            arr = from_array(source.read(), chunks=-1).rechunk('auto')\n        to_zarr(arr, path, component=None,\n                storage_options=storage_options, **kwargs)\n\n        source = ZarrArraySource(path, storage_options, component)\n        return source"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef source(self, source):\n        BaseView.source.fset(self, source)\n        if self.select:\n            self.select.options = self.options", "response": "When the source gets updated update the options in the selector"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_case_insensitive(self, dictionary, key, default=None):\n        lower_key = key.lower()\n        for k, v in dictionary.items():\n            if lower_key == k.lower():\n                return v\n        else:\n            return default", "response": "Case - insensitive search of a dictionary for key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url(self):\n        return os.path.join(self.path, self.main.value[0])", "response": "Path to local catalog file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that inputted path is valid - set validator accordingly", "response": "def validate(self, arg=None):\n        \"\"\"Check that inputted path is valid - set validator accordingly\"\"\"\n        if os.path.isdir(self.path):\n            self.validator.object = None\n        else:\n            self.validator.object = ICONS['error']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds cat and close panel", "response": "def add_cat(self, arg=None):\n        \"\"\"Add cat and close panel\"\"\"\n        try:\n            self.done_callback(self.cat)\n            self.visible = False\n        except Exception as e:\n            self.validator.object = ICONS['error']\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tab_change(self, event):\n        self.remove_error()\n        if event.new == 1:\n            self.widget.disabled = False", "response": "When tab changes remove error and enable widget if on url tab"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef callback(self, cats):\n        enable = bool(cats)\n        if not enable:\n            # close search if it is visible\n            self.search.visible = False\n        enable_widget(self.search_widget, enable)\n        enable_widget(self.remove_widget, enable)\n\n        if self.done_callback:\n            self.done_callback(cats)", "response": "When a catalog is selected enable widgets that depend on that condition\n            and do done_callback"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_click_search_widget(self, event):\n        self.search.cats = self.cats\n        self.search.visible = event.new\n        if self.search.visible:\n            self.search.watchers.append(\n                self.select.widget.link(self.search, value='cats'))", "response": "When the search control is toggled set visibility and hand down cats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking for duplicate keys while loading YAML https://gist. github. com / pypt / 95d747fe5180851196eb", "response": "def no_duplicates_constructor(loader, node, deep=False):\n    \"\"\"Check for duplicate keys while loading YAML\n\n    https://gist.github.com/pypt/94d747fe5180851196eb\n    \"\"\"\n\n    mapping = {}\n    for key_node, value_node in node.value:\n        key = loader.construct_object(key_node, deep=deep)\n        value = loader.construct_object(value_node, deep=deep)\n        if key in mapping:\n            from intake.catalog.exceptions import DuplicateKeyError\n\n            raise DuplicateKeyError(\"while constructing a mapping\",\n                                    node.start_mark,\n                                    \"found duplicate key (%s)\" % key,\n                                    key_node.start_mark)\n        mapping[key] = value\n\n    return loader.construct_mapping(node, deep)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef classname(ob):\n    import inspect\n    if inspect.isclass(ob):\n        return '.'.join([ob.__module__, ob.__name__])\n    else:\n        return '.'.join([ob.__class__.__module__, ob.__class__.__name__])", "response": "Get the object s class s name as package. module. Class"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaintains dict ordering - but make string version prettier", "response": "def pretty_describe(object, nestedness=0, indent=2):\n    \"\"\"Maintain dict ordering - but make string version prettier\"\"\"\n    if not isinstance(object, dict):\n        return str(object)\n    sep = f'\\n{\" \" * nestedness * indent}'\n    out = sep.join((f'{k}: {pretty_describe(v, nestedness + 1)}' for k, v in object.items()))\n    if nestedness > 0 and out:\n        return f'{sep}{out}'\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, *args, **kwargs):\n        return self.cat.select.add(*args, **kwargs)", "response": "Add to list of cats"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coerce_to_list(items, preprocess=None):\n    if not isinstance(items, list):\n        items = [items]\n    if preprocess:\n        items = list(map(preprocess, items))\n    return items", "response": "Given an instance or list coerce to list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _repr_mimebundle_(self, *args, **kwargs):\n        try:\n            if self.logo:\n                p = pn.Row(\n                    self.logo_panel,\n                    self.panel,\n                    margin=0)\n                return p._repr_mimebundle_(*args, **kwargs)\n            else:\n                return self.panel._repr_mimebundle_(*args, **kwargs)\n        except:\n            raise RuntimeError(\"Panel does not seem to be set up properly\")", "response": "Display in a notebook or a server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unwatch(self):\n        if self.watchers is not None:\n            unwatched = []\n            for watcher in self.watchers:\n                watcher.inst.param.unwatch(watcher)\n                unwatched.append(watcher)\n            self.watchers = [w for w in self.watchers if w not in unwatched]", "response": "Remove any lingering watchers and remove from list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset options from list or instance of named item Over - writes old options", "response": "def options(self, new):\n        \"\"\"Set options from list, or instance of named item\n\n        Over-writes old options\n        \"\"\"\n        options = self._create_options(new)\n        if self.widget.value:\n            self.widget.set_param(options=options, value=list(options.values())[:1])\n        else:\n            self.widget.options = options\n            self.widget.value = list(options.values())[:1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, items):\n        options = self._create_options(items)\n        for k, v in options.items():\n            if k in self.labels and v not in self.items:\n                options.pop(k)\n                count = 0\n                while f'{k}_{count}' in self.labels:\n                    count += 1\n                options[f'{k}_{count}'] = v\n        self.widget.options.update(options)\n        self.widget.param.trigger('options')\n        self.widget.value = list(options.values())[:1]", "response": "Add items to options"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove items from options", "response": "def remove(self, items):\n        \"\"\"Remove items from options\"\"\"\n        items = coerce_to_list(items)\n        new_options = {k: v for k, v in self.options.items() if v not in items}\n        self.widget.options = new_options\n        self.widget.param.trigger('options')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting selected from list or instance of object or name.", "response": "def selected(self, new):\n        \"\"\"Set selected from list or instance of object or name.\n\n        Over-writes existing selection\n        \"\"\"\n        def preprocess(item):\n            if isinstance(item, str):\n                return self.options[item]\n            return item\n        items = coerce_to_list(new, preprocess)\n        self.widget.value = items"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef source(self, source):\n        if isinstance(source, list):\n            # if source is a list, get first item or None\n            source = source[0] if len(source) > 0 else None\n        self._source = source", "response": "When the source gets updated update the select widget"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_click_plot_widget(self, event):\n        self.plot.source = self.sources\n        self.plot.visible = event.new\n        if self.plot.visible:\n            self.plot.watchers.append(\n                self.select.widget.link(self.plot, value='source'))", "response": "When the plot control is toggled set visibility and hand down source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sanitize_path(path):\n\n    storage_option = infer_storage_options(path)\n\n    protocol = storage_option['protocol']\n    if protocol in ('http', 'https'):\n        # Most FSs remove the protocol but not HTTPFS. We need to strip\n        # it to match properly.\n        path = os.path.normpath(path.replace(\"{}://\".format(protocol), ''))\n    elif protocol == 'file':\n        # Remove trailing slashes from file paths.\n        path = os.path.normpath(path)\n        # Remove colons\n        path = path.replace(':', '')\n    # Otherwise we just make sure that path is posix\n    return make_path_posix(path)", "response": "Utility for cleaning up paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _download(file_in, file_out, blocksize, output=False):\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore')\n\n        if output:\n            try:\n                from tqdm.autonotebook import tqdm\n            except ImportError:\n                logger.warn(\"Cache progress bar requires tqdm to be installed:\"\n                            \" conda/pip install tqdm\")\n                output = False\n        if output:\n            try:\n                file_size = file_in.fs.size(file_in.path)\n                pbar_disabled = False\n            except ValueError as err:\n                logger.debug(\"File system error requesting size: {}\".format(err))\n                file_size = 0\n                pbar_disabled = True\n            for i in range(100):\n                if i not in display:\n                    display.add(i)\n                    out = i\n                    break\n            pbar = tqdm(total=file_size // 2 ** 20, leave=False,\n                        disable=pbar_disabled,\n                        position=out, desc=os.path.basename(file_out.path),\n                        mininterval=0.1,\n                        bar_format=r'{n}/|/{l_bar}')\n\n        logger.debug(\"Caching {}\".format(file_in.path))\n        with file_in as f1:\n            with file_out as f2:\n                data = True\n                while data:\n                    data = f1.read(blocksize)\n                    f2.write(data)\n                    if output:\n                        pbar.update(len(data) // 2**20)\n        if output:\n            try:\n                pbar.update(pbar.total - pbar.n)  # force to full\n                pbar.close()\n            except Exception as e:\n                logger.debug('tqdm exception: %s' % e)\n            finally:\n                display.remove(out)", "response": "Download the next 100 items from input file and write them to output file in blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a list of Cache objects from the cache_specs provided in the catalog yaml file.", "response": "def make_caches(driver, specs, catdir=None, cache_dir=None, storage_options={}):\n    \"\"\"\n    Creates Cache objects from the cache_specs provided in the catalog yaml file\n\n    Parameters\n    ----------\n\n    driver: str\n        Name of the plugin that can load catalog entry\n    specs: list\n        Specification for caching the data source.\n    \"\"\"\n    if specs is None:\n        return []\n    return [registry.get(spec['type'], FileCache)(\n        driver, spec, catdir=catdir, cache_dir=cache_dir,\n        storage_options=storage_options)\n        for spec in specs]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self, urlpath, output=None, **kwargs):\n        if conf.get('cache_disabled', False):\n            return [urlpath]\n        self.output = output if output is not None else conf.get(\n            'cache_download_progress', True)\n\n        cache_paths = self._from_metadata(urlpath)\n        if cache_paths is None:\n            files_in, files_out = self._make_files(urlpath)\n            self._load(files_in, files_out, urlpath)\n        cache_paths = self._from_metadata(urlpath)\n        return cache_paths", "response": "Downloads data from a given url generates a hashed filename logs metadata and caches it locally."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _from_metadata(self, urlpath):\n        md = self.get_metadata(urlpath)\n        if md is not None:\n            return [e['cache_path'] for e in md]", "response": "Return set of local URLs if files already exist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a set of files and return a list of names of the files that were downloaded.", "response": "def _load(self, files_in, files_out, urlpath, meta=True):\n        \"\"\"Download a set of files\"\"\"\n        import dask\n        out = []\n        outnames = []\n        for file_in, file_out in zip(files_in, files_out):\n            cache_path = file_out.path\n            outnames.append(cache_path)\n\n            # If `_munge_path` did not find a match we want to avoid\n            # writing to the urlpath.\n            if cache_path == urlpath:\n                continue\n\n            if not os.path.isfile(cache_path):\n                logger.debug(\"Caching file: {}\".format(file_in.path))\n                logger.debug(\"Original path: {}\".format(urlpath))\n                logger.debug(\"Cached at: {}\".format(cache_path))\n                if meta:\n                    self._log_metadata(urlpath, file_in.path, cache_path)\n                ddown = dask.delayed(_download)\n                out.append(ddown(file_in, file_out, self.blocksize,\n                                 self.output))\n        dask.compute(*out)\n        return outnames"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear_cache(self, urlpath):\n        cache_entries = self._metadata.pop(urlpath, [])  # ignore if missing\n        for cache_entry in cache_entries:\n            try:\n                os.remove(cache_entry['cache_path'])\n            except (OSError, IOError):\n                pass\n        try:\n            fn = os.path.dirname(cache_entry['cache_path'])\n            os.rmdir(fn)\n        except (OSError, IOError):\n            logger.debug(\"Failed to remove cache directory: %s\" % fn)", "response": "Clears the cache and metadata for a given urlpath."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_all(self):\n        for urlpath in self._metadata.keys():\n            self.clear_cache(urlpath)\n\n        # Safely clean up anything else.\n        if not os.path.isdir(self._cache_dir):\n            return\n        for subdir in os.listdir(self._cache_dir):\n            try:\n                fn = posixpath.join(self._cache_dir, subdir)\n                if os.path.isdir(fn):\n                    shutil.rmtree(fn)\n                if os.path.isfile(fn):\n                    os.remove(fn)\n            except (OSError, IOError) as e:\n                logger.warning(str(e))", "response": "Clears all cache and metadata."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _from_metadata(self, urlpath):\n        md = self.get_metadata(urlpath)\n        if md is not None:\n            return [self._path(urlpath)]", "response": "Return set of local URLs if files already exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a Qt Designer. ui file and returns an instance of the user interface", "response": "def setup_ui(uifile, base_instance=None):\n    \"\"\"Load a Qt Designer .ui file and returns an instance of the user interface\n\n    Args:\n        uifile (str): Absolute path to .ui file\n        base_instance (QWidget): The widget into which UI widgets are loaded\n\n    Returns:\n        QWidget: the base instance\n\n    \"\"\"\n    ui = QtCompat.loadUi(uifile)  # Qt.py mapped function\n    if not base_instance:\n        return ui\n    else:\n        for member in dir(ui):\n            if not member.startswith('__') and \\\n               member is not 'staticMetaObject':\n                setattr(base_instance, member, getattr(ui, member))\n        return ui"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_json(dictionary, filename):\n    with open(filename, 'w') as data_file:\n        json.dump(dictionary, data_file, indent=4, sort_keys=True)\n    print('--> Wrote ' + os.path.basename(filename))", "response": "Write dictionary to JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_qtgui_to_modules():\n\n    pyside_filepath = PREFIX + '/PySide.json'\n    pyqt4_filepath = PREFIX + '/PyQt4.json'\n    pyside = read_json(pyside_filepath)\n    pyqt4 = read_json(pyqt4_filepath)\n\n    # When Qt4 was moved to Qt5, they split QtGui into QtGui, QtWidgets, and\n    # QtPrintSupport.\n    pyside['QtWidgets'] = pyside['QtGui']\n    pyqt4['QtWidgets'] = pyqt4['QtGui']\n    pyside['QtPrintSupport'] = pyside['QtGui']\n    pyqt4['QtPrintSupport'] = pyqt4['QtGui']\n\n    write_json(pyside, pyside_filepath)\n    print('--> Copied QtGui to QtWidgets and QtPrintSupport for {0}'.format(\n        os.path.basename(pyside_filepath)))\n    write_json(pyqt4, pyqt4_filepath)\n    print('--> Copied QtGui to QtWidgets and QtPrintSupport for {0}'.format(\n        os.path.basename(pyqt4_filepath)))", "response": "Copies the QtGui list of PySide and PyQt4 into QtWidgets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsort the keys and members of the common members of the current page", "response": "def sort_common_members():\n    \"\"\"Sorts the keys and members\"\"\"\n\n    filename = PREFIX + '/common_members.json'\n    sorted_json_data = {}\n    json_data = read_json(filename)\n\n    all_keys = []\n    for key, value in json_data.items():\n        all_keys.append(key)\n    sorted_keys = sorted(all_keys)\n\n    for key in sorted_keys:\n        if len(json_data[key]) > 0:\n            # Only add modules which have common members\n            sorted_json_data[key] = sorted(json_data[key])\n\n    print('--> Sorted/cleaned ' + os.path.basename(filename))\n\n    write_json(sorted_json_data, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate JSON with commonly shared members", "response": "def generate_common_members():\n    \"\"\"Generate JSON with commonly shared members\"\"\"\n\n    pyside = read_json(PREFIX + '/PySide.json')\n    pyside2 = read_json(PREFIX + '/PySide2.json')\n    pyqt4 = read_json(PREFIX + '/PyQt4.json')\n    pyqt5 = read_json(PREFIX + '/PyQt5.json')\n\n    dicts = [pyside, pyside2, pyqt4, pyqt5]\n    common_members = compare(dicts)\n    write_json(common_members, PREFIX + '/common_members.json')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a file and return a list of dicts. Each dict is a list of dicts where each dict is a list of tuples where the first element is the name of the main doctest and the second is the value of the main doctest.", "response": "def parse(fname):\n    \"\"\"Return blocks of code as list of dicts\n\n    Arguments:\n        fname (str): Relative name of caveats file\n\n    \"\"\"\n\n    blocks = list()\n    with io.open(fname, \"r\", encoding=\"utf-8\") as f:\n        in_block = False\n        current_block = None\n        current_header = \"\"\n\n        for line in f:\n\n            # Doctests are within a quadruple hashtag header.\n            if line.startswith(\"#### \"):\n                current_header = line.rstrip()\n\n            # The actuat test is within a fenced block.\n            if line.startswith(\"```\"):\n                in_block = False\n\n            if in_block:\n                current_block.append(line)\n\n            if line.startswith(\"```python\"):\n                in_block = True\n                current_block = list()\n                current_block.append(current_header)\n                blocks.append(current_block)\n\n    tests = list()\n    for block in blocks:\n        header = (\n            block[0].strip(\"# \")  # Remove Markdown\n                    .rstrip()     # Remove newline\n                    .lower()      # PEP08\n        )\n\n        # Remove unsupported characters\n        header = re.sub(r\"\\W\", \"_\", header)\n\n        # Adding \"untested\" anywhere in the first line of\n        # the doctest excludes it from the test.\n        if \"untested\" in block[1].lower():\n            continue\n\n        data = re.sub(\" \", \"\", block[1])  # Remove spaces\n        data = (\n            data.strip(\"#\")\n                .rstrip()     # Remove newline\n                .split(\",\")\n        )\n\n        binding, doctest_version = (data + [None])[:2]\n\n        # Run tests on both Python 2 and 3, unless explicitly stated\n        if doctest_version is not None:\n            if doctest_version not in (\"Python2\", \"Python3\"):\n                raise SyntaxError(\n                    \"Invalid Python version:\\n%s\\n\"\n                    \"Python version must follow binding, e.g.\\n\"\n                    \"# PyQt5, Python3\" % doctest_version)\n\n            active_version = \"Python%i\" % sys.version_info[0]\n            if doctest_version != active_version:\n                continue\n\n        tests.append({\n            \"header\": header,\n            \"binding\": binding,\n            \"body\": block[2:]\n        })\n\n    return tests"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nproduces Python module from a list of blocks of tests.", "response": "def format_(blocks):\n    \"\"\"Produce Python module from blocks of tests\n\n    Arguments:\n        blocks (list): Blocks of tests from func:`parse()`\n\n    \"\"\"\n\n    tests = list()\n    function_count = 0  # For each test to have a unique name\n\n    for block in blocks:\n\n        # Validate docstring format of body\n        if not any(line[:3] == \">>>\" for line in block[\"body\"]):\n            # A doctest requires at least one `>>>` directive.\n            block[\"body\"].insert(0, \">>> assert False, \"\n                                 \"'Body must be in docstring format'\\n\")\n\n        # Validate binding on first line\n        if not block[\"binding\"] in (\"PySide\", \"PySide2\", \"PyQt5\", \"PyQt4\"):\n            block[\"body\"].insert(0, \">>> assert False, \"\n                                 \"'Invalid binding'\\n\")\n\n        if sys.version_info > (3, 4) and block[\"binding\"] in (\"PySide\"):\n            # Skip caveat test if it requires PySide on Python > 3.4\n            continue\n        else:\n            function_count += 1\n            block[\"header\"] = block[\"header\"]\n            block[\"count\"] = str(function_count)\n            block[\"body\"] = \"    \".join(block[\"body\"])\n            tests.append(\"\"\"\\\n\ndef test_{count}_{header}():\n    '''Test {header}\n\n    >>> import os, sys\n    >>> PYTHON = sys.version_info[0]\n    >>> long = int if PYTHON == 3 else long\n    >>> _ = os.environ.pop(\"QT_VERBOSE\", None)  # Disable debug output\n    >>> os.environ[\"QT_PREFERRED_BINDING\"] = \"{binding}\"\n    {body}\n    '''\n\n    \"\"\".format(**block))\n\n    return tests"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _qInstallMessageHandler(handler):\n    def messageOutputHandler(*args):\n        # In Qt4 bindings, message handlers are passed 2 arguments\n        # In Qt5 bindings, message handlers are passed 3 arguments\n        # The first argument is a QtMsgType\n        # The last argument is the message to be printed\n        # The Middle argument (if passed) is a QMessageLogContext\n        if len(args) == 3:\n            msgType, logContext, msg = args\n        elif len(args) == 2:\n            msgType, msg = args\n            logContext = None\n        else:\n            raise TypeError(\n                \"handler expected 2 or 3 arguments, got {0}\".format(len(args)))\n\n        if isinstance(msg, bytes):\n            # In python 3, some bindings pass a bytestring, which cannot be\n            # used elsewhere. Decoding a python 2 or 3 bytestring object will\n            # consistently return a unicode object.\n            msg = msg.decode()\n\n        handler(msgType, logContext, msg)\n\n    passObject = messageOutputHandler if handler else handler\n    if Qt.IsPySide or Qt.IsPyQt4:\n        return Qt._QtCore.qInstallMsgHandler(passObject)\n    elif Qt.IsPySide2 or Qt.IsPyQt5:\n        return Qt._QtCore.qInstallMessageHandler(passObject)", "response": "Install a message handler that works in all bindings\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _wrapinstance(ptr, base=None):\n\n    assert isinstance(ptr, long), \"Argument 'ptr' must be of type <long>\"\n    assert (base is None) or issubclass(base, Qt.QtCore.QObject), (\n        \"Argument 'base' must be of type <QObject>\")\n\n    if Qt.IsPyQt4 or Qt.IsPyQt5:\n        func = getattr(Qt, \"_sip\").wrapinstance\n    elif Qt.IsPySide2:\n        func = getattr(Qt, \"_shiboken2\").wrapInstance\n    elif Qt.IsPySide:\n        func = getattr(Qt, \"_shiboken\").wrapInstance\n    else:\n        raise AttributeError(\"'module' has no attribute 'wrapInstance'\")\n\n    if base is None:\n        q_object = func(long(ptr), Qt.QtCore.QObject)\n        meta_object = q_object.metaObject()\n        class_name = meta_object.className()\n        super_class_name = meta_object.superClass().className()\n\n        if hasattr(Qt.QtWidgets, class_name):\n            base = getattr(Qt.QtWidgets, class_name)\n\n        elif hasattr(Qt.QtWidgets, super_class_name):\n            base = getattr(Qt.QtWidgets, super_class_name)\n\n        else:\n            base = Qt.QtCore.QObject\n\n    return func(long(ptr), base)", "response": "Wrap the given pointer to the most suitable class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loadUi(uifile, baseinstance=None):\n    if hasattr(Qt, \"_uic\"):\n        return Qt._uic.loadUi(uifile, baseinstance)\n\n    elif hasattr(Qt, \"_QtUiTools\"):\n        # Implement `PyQt5.uic.loadUi` for PySide(2)\n\n        class _UiLoader(Qt._QtUiTools.QUiLoader):\n            \"\"\"Create the user interface in a base instance.\n\n            Unlike `Qt._QtUiTools.QUiLoader` itself this class does not\n            create a new instance of the top-level widget, but creates the user\n            interface in an existing instance of the top-level class if needed.\n\n            This mimics the behaviour of `PyQt5.uic.loadUi`.\n\n            \"\"\"\n\n            def __init__(self, baseinstance):\n                super(_UiLoader, self).__init__(baseinstance)\n                self.baseinstance = baseinstance\n                self.custom_widgets = {}\n\n            def _loadCustomWidgets(self, etree):\n                \"\"\"\n                Workaround to pyside-77 bug.\n\n                From QUiLoader doc we should use registerCustomWidget method.\n                But this causes a segfault on some platforms.\n\n                Instead we fetch from customwidgets DOM node the python class\n                objects. Then we can directly use them in createWidget method.\n                \"\"\"\n\n                def headerToModule(header):\n                    \"\"\"\n                    Translate a header file to python module path\n                    foo/bar.h => foo.bar\n                    \"\"\"\n                    # Remove header extension\n                    module = os.path.splitext(header)[0]\n\n                    # Replace os separator by python module separator\n                    return module.replace(\"/\", \".\").replace(\"\\\\\", \".\")\n\n                custom_widgets = etree.find(\"customwidgets\")\n\n                if custom_widgets is None:\n                    return\n\n                for custom_widget in custom_widgets:\n                    class_name = custom_widget.find(\"class\").text\n                    header = custom_widget.find(\"header\").text\n                    module = importlib.import_module(headerToModule(header))\n                    self.custom_widgets[class_name] = getattr(module,\n                                                              class_name)\n\n            def load(self, uifile, *args, **kwargs):\n                from xml.etree.ElementTree import ElementTree\n\n                # For whatever reason, if this doesn't happen then\n                # reading an invalid or non-existing .ui file throws\n                # a RuntimeError.\n                etree = ElementTree()\n                etree.parse(uifile)\n                self._loadCustomWidgets(etree)\n\n                widget = Qt._QtUiTools.QUiLoader.load(\n                    self, uifile, *args, **kwargs)\n\n                # Workaround for PySide 1.0.9, see issue #208\n                widget.parentWidget()\n\n                return widget\n\n            def createWidget(self, class_name, parent=None, name=\"\"):\n                \"\"\"Called for each widget defined in ui file\n\n                Overridden here to populate `baseinstance` instead.\n\n                \"\"\"\n\n                if parent is None and self.baseinstance:\n                    # Supposed to create the top-level widget,\n                    # return the base instance instead\n                    return self.baseinstance\n\n                # For some reason, Line is not in the list of available\n                # widgets, but works fine, so we have to special case it here.\n                if class_name in self.availableWidgets() + [\"Line\"]:\n                    # Create a new widget for child widgets\n                    widget = Qt._QtUiTools.QUiLoader.createWidget(self,\n                                                                  class_name,\n                                                                  parent,\n                                                                  name)\n                elif class_name in self.custom_widgets:\n                    widget = self.custom_widgets[class_name](parent)\n                else:\n                    raise Exception(\"Custom widget '%s' not supported\"\n                                    % class_name)\n\n                if self.baseinstance:\n                    # Set an attribute for the new child widget on the base\n                    # instance, just like PyQt5.uic.loadUi does.\n                    setattr(self.baseinstance, name, widget)\n\n                return widget\n\n        widget = _UiLoader(baseinstance).load(uifile)\n        Qt.QtCore.QMetaObject.connectSlotsByName(widget)\n\n        return widget\n\n    else:\n        raise NotImplementedError(\"No implementation available for loadUi\")", "response": "Dynamically load a user interface from a given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports a sub - module of a module.", "response": "def _import_sub_module(module, name):\n    \"\"\"import_sub_module will mimic the function of importlib.import_module\"\"\"\n    module = __import__(module.__name__ + \".\" + name)\n    for level in name.split(\".\"):\n        module = getattr(module, level)\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup(module, extras):\n\n    Qt.__binding__ = module.__name__\n\n    for name in list(_common_members) + extras:\n        try:\n            submodule = _import_sub_module(\n                module, name)\n        except ImportError:\n            try:\n                # For extra modules like sip and shiboken that may not be\n                # children of the binding.\n                submodule = __import__(name)\n            except ImportError:\n                continue\n\n        setattr(Qt, \"_\" + name, submodule)\n\n        if name not in extras:\n            # Store reference to original binding,\n            # but don't store speciality modules\n            # such as uic or QtUiTools\n            setattr(Qt, name, _new_module(name))", "response": "Install common submodules and store references to original binding and other modules."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reassign_misplaced_members(binding):\n\n    for src, dst in _misplaced_members[binding].items():\n        dst_value = None\n\n        src_parts = src.split(\".\")\n        src_module = src_parts[0]\n        src_member = None\n        if len(src_parts) > 1:\n            src_member = src_parts[1:]\n\n        if isinstance(dst, (list, tuple)):\n            dst, dst_value = dst\n\n        dst_parts = dst.split(\".\")\n        dst_module = dst_parts[0]\n        dst_member = None\n        if len(dst_parts) > 1:\n            dst_member = dst_parts[1]\n\n        # Get the member we want to store in the namesapce.\n        if not dst_value:\n            try:\n                _part = getattr(Qt, \"_\" + src_module)\n                while src_member:\n                    member = src_member.pop(0)\n                    _part = getattr(_part, member)\n                dst_value = _part\n            except AttributeError:\n                # If the member we want to store in the namespace does not\n                # exist, there is no need to continue. This can happen if a\n                # request was made to rename a member that didn't exist, for\n                # example if QtWidgets isn't available on the target platform.\n                _log(\"Misplaced member has no source: {0}\".format(src))\n                continue\n\n        try:\n            src_object = getattr(Qt, dst_module)\n        except AttributeError:\n            if dst_module not in _common_members:\n                # Only create the Qt parent module if its listed in\n                # _common_members. Without this check, if you remove QtCore\n                # from _common_members, the default _misplaced_members will add\n                # Qt.QtCore so it can add Signal, Slot, etc.\n                msg = 'Not creating missing member module \"{m}\" for \"{c}\"'\n                _log(msg.format(m=dst_module, c=dst_member))\n                continue\n            # If the dst is valid but the Qt parent module does not exist\n            # then go ahead and create a new module to contain the member.\n            setattr(Qt, dst_module, _new_module(dst_module))\n            src_object = getattr(Qt, dst_module)\n            # Enable direct import of the new module\n            sys.modules[__name__ + \".\" + dst_module] = src_object\n\n        if not dst_value:\n            dst_value = getattr(Qt, \"_\" + src_module)\n            if src_member:\n                dst_value = getattr(dst_value, src_member)\n\n        setattr(\n            src_object,\n            dst_member or dst_module,\n            dst_value\n        )", "response": "Reassigns the misplaced members from the binding to the Qt. py version."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the QtCompat object for the top level binding in _compatibility_members.", "response": "def _build_compatibility_members(binding, decorators=None):\n    \"\"\"Apply `binding` to QtCompat\n\n    Arguments:\n        binding (str): Top level binding in _compatibility_members.\n        decorators (dict, optional): Provides the ability to decorate the\n            original Qt methods when needed by a binding. This can be used\n            to change the returned value to a standard value. The key should\n            be the classname, the value is a dict where the keys are the\n            target method names, and the values are the decorator functions.\n\n    \"\"\"\n\n    decorators = decorators or dict()\n\n    # Allow optional site-level customization of the compatibility members.\n    # This method does not need to be implemented in QtSiteConfig.\n    try:\n        import QtSiteConfig\n    except ImportError:\n        pass\n    else:\n        if hasattr(QtSiteConfig, 'update_compatibility_decorators'):\n            QtSiteConfig.update_compatibility_decorators(binding, decorators)\n\n    _QtCompat = type(\"QtCompat\", (object,), {})\n\n    for classname, bindings in _compatibility_members[binding].items():\n        attrs = {}\n        for target, binding in bindings.items():\n            namespaces = binding.split('.')\n            try:\n                src_object = getattr(Qt, \"_\" + namespaces[0])\n            except AttributeError as e:\n                _log(\"QtCompat: AttributeError: %s\" % e)\n                # Skip reassignment of non-existing members.\n                # This can happen if a request was made to\n                # rename a member that didn't exist, for example\n                # if QtWidgets isn't available on the target platform.\n                continue\n\n            # Walk down any remaining namespace getting the object assuming\n            # that if the first namespace exists the rest will exist.\n            for namespace in namespaces[1:]:\n                src_object = getattr(src_object, namespace)\n\n            # decorate the Qt method if a decorator was provided.\n            if target in decorators.get(classname, []):\n                # staticmethod must be called on the decorated method to\n                # prevent a TypeError being raised when the decorated method\n                # is called.\n                src_object = staticmethod(\n                    decorators[classname][target](src_object))\n\n            attrs[target] = src_object\n\n        # Create the QtCompat class and install it into the namespace\n        compat_class = type(classname, (_QtCompat,), attrs)\n        setattr(Qt.QtCompat, classname, compat_class)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitialising PySide2 These functions serve to test the existence of a binding along with set it up in such a way that it aligns with the final step; adding members from the original binding to Qt.py", "response": "def _pyside2():\n    \"\"\"Initialise PySide2\n\n    These functions serve to test the existence of a binding\n    along with set it up in such a way that it aligns with\n    the final step; adding members from the original binding\n    to Qt.py\n\n    \"\"\"\n\n    import PySide2 as module\n    extras = [\"QtUiTools\"]\n    try:\n        try:\n            # Before merge of PySide and shiboken\n            import shiboken2\n        except ImportError:\n            # After merge of PySide and shiboken, May 2017\n            from PySide2 import shiboken2\n        extras.append(\"shiboken2\")\n    except ImportError:\n        pass\n\n    _setup(module, extras)\n    Qt.__binding_version__ = module.__version__\n\n    if hasattr(Qt, \"_shiboken2\"):\n        Qt.QtCompat.wrapInstance = _wrapinstance\n        Qt.QtCompat.getCppPointer = _getcpppointer\n        Qt.QtCompat.delete = shiboken2.delete\n\n    if hasattr(Qt, \"_QtUiTools\"):\n        Qt.QtCompat.loadUi = _loadUi\n\n    if hasattr(Qt, \"_QtCore\"):\n        Qt.__qt_version__ = Qt._QtCore.qVersion()\n\n    if hasattr(Qt, \"_QtWidgets\"):\n        Qt.QtCompat.setSectionResizeMode = \\\n            Qt._QtWidgets.QHeaderView.setSectionResizeMode\n\n    _reassign_misplaced_members(\"PySide2\")\n    _build_compatibility_members(\"PySide2\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitialises PyQt4 with the necessary modules and modules.", "response": "def _pyqt4():\n    \"\"\"Initialise PyQt4\"\"\"\n\n    import sip\n\n    # Validation of envivornment variable. Prevents an error if\n    # the variable is invalid since it's just a hint.\n    try:\n        hint = int(QT_SIP_API_HINT)\n    except TypeError:\n        hint = None  # Variable was None, i.e. not set.\n    except ValueError:\n        raise ImportError(\"QT_SIP_API_HINT=%s must be a 1 or 2\")\n\n    for api in (\"QString\",\n                \"QVariant\",\n                \"QDate\",\n                \"QDateTime\",\n                \"QTextStream\",\n                \"QTime\",\n                \"QUrl\"):\n        try:\n            sip.setapi(api, hint or 2)\n        except AttributeError:\n            raise ImportError(\"PyQt4 < 4.6 isn't supported by Qt.py\")\n        except ValueError:\n            actual = sip.getapi(api)\n            if not hint:\n                raise ImportError(\"API version already set to %d\" % actual)\n            else:\n                # Having provided a hint indicates a soft constraint, one\n                # that doesn't throw an exception.\n                sys.stderr.write(\n                    \"Warning: API '%s' has already been set to %d.\\n\"\n                    % (api, actual)\n                )\n\n    import PyQt4 as module\n    extras = [\"uic\"]\n    try:\n        import sip\n        extras.append(sip.__name__)\n    except ImportError:\n        sip = None\n\n    _setup(module, extras)\n    if hasattr(Qt, \"_sip\"):\n        Qt.QtCompat.wrapInstance = _wrapinstance\n        Qt.QtCompat.getCppPointer = _getcpppointer\n        Qt.QtCompat.delete = sip.delete\n\n    if hasattr(Qt, \"_uic\"):\n        Qt.QtCompat.loadUi = _loadUi\n\n    if hasattr(Qt, \"_QtGui\"):\n        setattr(Qt, \"QtWidgets\", _new_module(\"QtWidgets\"))\n        setattr(Qt, \"_QtWidgets\", Qt._QtGui)\n        if hasattr(Qt._QtGui, \"QX11Info\"):\n            setattr(Qt, \"QtX11Extras\", _new_module(\"QtX11Extras\"))\n            Qt.QtX11Extras.QX11Info = Qt._QtGui.QX11Info\n\n        Qt.QtCompat.setSectionResizeMode = \\\n            Qt._QtGui.QHeaderView.setResizeMode\n\n    if hasattr(Qt, \"_QtCore\"):\n        Qt.__binding_version__ = Qt._QtCore.PYQT_VERSION_STR\n        Qt.__qt_version__ = Qt._QtCore.QT_VERSION_STR\n\n    _reassign_misplaced_members(\"PyQt4\")\n\n    # QFileDialog QtCompat decorator\n    def _standardizeQFileDialog(some_function):\n        \"\"\"Decorator that makes PyQt4 return conform to other bindings\"\"\"\n        def wrapper(*args, **kwargs):\n            ret = (some_function(*args, **kwargs))\n\n            # PyQt4 only returns the selected filename, force it to a\n            # standard return of the selected filename, and a empty string\n            # for the selected filter\n            return ret, ''\n\n        wrapper.__doc__ = some_function.__doc__\n        wrapper.__name__ = some_function.__name__\n\n        return wrapper\n\n    decorators = {\n        \"QFileDialog\": {\n            \"getOpenFileName\": _standardizeQFileDialog,\n            \"getOpenFileNames\": _standardizeQFileDialog,\n            \"getSaveFileName\": _standardizeQFileDialog,\n        }\n    }\n    _build_compatibility_members('PyQt4', decorators)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert compiled. ui file from PySide2 to Qt. py", "response": "def _convert(lines):\n    \"\"\"Convert compiled .ui file from PySide2 to Qt.py\n\n    Arguments:\n        lines (list): Each line of of .ui file\n\n    Usage:\n        >> with open(\"myui.py\") as f:\n        ..   lines = _convert(f.readlines())\n\n    \"\"\"\n\n    def parse(line):\n        line = line.replace(\"from PySide2 import\", \"from Qt import QtCompat,\")\n        line = line.replace(\"QtWidgets.QApplication.translate\",\n                            \"QtCompat.translate\")\n        if \"QtCore.SIGNAL\" in line:\n            raise NotImplementedError(\"QtCore.SIGNAL is missing from PyQt5 \"\n                                      \"and so Qt.py does not support it: you \"\n                                      \"should avoid defining signals inside \"\n                                      \"your ui files.\")\n        return line\n\n    parsed = list()\n    for line in lines:\n        line = parse(line)\n        parsed.append(line)\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_ui_type(uifile):\n    import pysideuic\n    import xml.etree.ElementTree as ElementTree\n    from cStringIO import StringIO\n\n    parsed = ElementTree.parse(uifile)\n    widget_class = parsed.find('widget').get('class')\n    form_class = parsed.find('class').text\n\n    with open(uifile, 'r') as f:\n        o = StringIO()\n        frame = {}\n\n        pysideuic.compileUi(f, o, indent=0)\n        pyc = compile(o.getvalue(), '<string>', 'exec')\n        exec(pyc) in frame\n\n        # Fetch the base_class and form class based on their type in\n        # the xml from designer\n        form_class = frame['Ui_%s' % form_class]\n        base_class = eval('QtWidgets.%s' % widget_class)\n    return form_class, base_class", "response": "Load a Qt Designer. ui file and return a tuple of the generated form class and Qt base class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pyside_load_ui(uifile, base_instance=None):\n    form_class, base_class = load_ui_type(uifile)\n    if not base_instance:\n        typeName = form_class.__name__\n        finalType = type(typeName,\n                         (form_class, base_class),\n                         {})\n        base_instance = finalType()\n    else:\n        if not isinstance(base_instance, base_class):\n            raise RuntimeError(\n                'The base_instance passed to loadUi does not inherit from'\n                ' needed base type (%s)' % type(base_class))\n        typeName = type(base_instance).__name__\n        base_instance.__class__ = type(typeName,\n                                       (form_class, type(base_instance)),\n                                       {})\n    base_instance.setupUi(base_instance)\n    return base_instance", "response": "Provide PyQt4. uic. loadUi functionality to PySide."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_ui_wrapper(uifile, base_instance=None):\n    if 'PySide' in __binding__:\n        return pyside_load_ui(uifile, base_instance)\n    elif 'PyQt' in __binding__:\n        uic = __import__(__binding__ + \".uic\").uic\n        return uic.loadUi(uifile, base_instance)", "response": "Load a Qt Designer. ui file and returns an instance of the user interface\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning true if the request should be retried based on the passed - in exception.", "response": "def ShouldRetry(self, exception):\n        \"\"\"Returns true if should retry based on the passed-in exception.\n\n        :param (errors.HTTPFailure instance) exception:\n\n        :rtype:\n            boolean\n\n        \"\"\"\n        self.session_token_retry_count += 1\n        # clear previous location-based routing directive\n        self.request.clear_route_to_location()\n\n        if not self.endpoint_discovery_enable:\n            # if endpoint discovery is disabled, the request cannot be retried anywhere else\n            return False\n        else:\n            if self.can_use_multiple_write_locations:\n                if _OperationType.IsReadOnlyOperation(self.request.operation_type):\n                    endpoints = self.global_endpoint_manager.get_ordered_read_endpoints()\n                else:\n                    endpoints = self.global_endpoint_manager.get_ordered_write_endpoints()\n\n                if self.session_token_retry_count > len(endpoints):\n                    # When use multiple write locations is true and the request has been tried \n                    # on all locations, then don't retry the request\n                    return False\n                else:\n                    # set location-based routing directive based on request retry context\n                    self.request.route_to_location_with_preferred_location_flag(self.session_token_retry_count - 1, self.session_token_retry_count > self._max_retry_attempt_count)\n                    self.request.should_clear_session_token_on_session_read_failure = self.session_token_retry_count == len(endpoints) # clear on last attempt\n                    \n                    # Resolve the endpoint for the request and pin the resolution to the resolved endpoint\n                    # This enables marking the endpoint unavailability on endpoint failover/unreachability\n                    self.location_endpoint = self.global_endpoint_manager.resolve_service_endpoint(self.request)\n                    self.request.route_to_location(self.location_endpoint)\n                    return True\n            else:\n                if self.session_token_retry_count > self._max_retry_attempt_count:\n                    # When cannot use multiple write locations, then don't retry the request if \n                    # we have already tried this request on the write location\n                    return False\n                else:\n                    # set location-based routing directive based on request retry context\n                    self.request.route_to_location_with_preferred_location_flag(self.session_token_retry_count - 1, False)\n                    self.request.should_clear_session_token_on_session_read_failure = True \n\n                    # Resolve the endpoint for the request and pin the resolution to the resolved endpoint\n                    # This enables marking the endpoint unavailability on endpoint failover/unreachability\n                    self.location_endpoint = self.global_endpoint_manager.resolve_service_endpoint(self.request)\n                    self.request.route_to_location(self.location_endpoint)\n                    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ExplicitlyExcludeFromIndex(client, database_id):\n    try:\n        DeleteContainerIfExists(client, database_id, COLLECTION_ID)\n        database_link = GetDatabaseLink(database_id)\n        # collections = Query_Entities(client, 'collection', parent_link = database_link)\n        # print(collections)\n\n        # Create a collection with default index policy (i.e. automatic = true)\n        created_Container = client.CreateContainer(database_link, {\"id\" : COLLECTION_ID})\n        print(created_Container)\n\n        print(\"\\n\" + \"-\" * 25 + \"\\n1. Collection created with index policy\")\n        print_dictionary_items(created_Container[\"indexingPolicy\"])\n\n        # Create a document and query on it immediately.\n        # Will work as automatic indexing is still True\n        collection_link = GetContainerLink(database_id, COLLECTION_ID)\n        doc = client.CreateItem(collection_link, { \"id\" : \"doc1\", \"orderId\" : \"order1\" })\n        print(\"\\n\" + \"-\" * 25 + \"Document doc1 created with order1\" +  \"-\" * 25)\n        print(doc)\n\n        query = {\n                \"query\": \"SELECT * FROM r WHERE r.orderId=@orderNo\",\n                \"parameters\": [ { \"name\":\"@orderNo\", \"value\": \"order1\" } ]\n            }\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        # Now, create a document but this time explictly exclude it from the collection using IndexingDirective\n        # Then query for that document\n        # Shoud NOT find it, because we excluded it from the index\n        # BUT, the document is there and doing a ReadDocument by Id will prove it\n        doc2 = client.CreateItem(collection_link, { \"id\" : \"doc2\", \"orderId\" : \"order2\" }, {'indexingDirective' : documents.IndexingDirective.Exclude})\n        print(\"\\n\" + \"-\" * 25 + \"Document doc2 created with order2\" +  \"-\" * 25)\n        print(doc2)\n\n        query = {\n                \"query\": \"SELECT * FROM r WHERE r.orderId=@orderNo\",\n                \"parameters\": [ { \"name\":\"@orderNo\", \"value\": \"order2\" } ]\n                }\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        docRead = client.ReadItem(GetDocumentLink(database_id, COLLECTION_ID, \"doc2\"))\n        print(\"Document read by ID: \\n\", docRead[\"id\"])\n\n        # Cleanup\n        client.DeleteContainer(collection_link)\n        print(\"\\n\")\n    \n    except errors.HTTPFailure as e:\n        if e.status_code == 409:\n            print(\"Entity already exists\")\n        elif e.status_code == 404:\n            print(\"Entity doesn't exist\")\n        else:\n            raise", "response": "Explicitly exclude a specific document from the index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ExcludePathsFromIndex(client, database_id):\n    try:\n        DeleteContainerIfExists(client, database_id, COLLECTION_ID)\n        database_link = GetDatabaseLink(database_id)\n        # collections = Query_Entities(client, 'collection', parent_link = database_link)\n        # print(collections)\n\n        doc_with_nested_structures = {\n            \"id\" : \"doc1\",\n            \"foo\" : \"bar\",\n            \"metaData\" : \"meta\",\n            \"subDoc\" : { \"searchable\" : \"searchable\", \"nonSearchable\" : \"value\" },\n            \"excludedNode\" : { \"subExcluded\" : \"something\",  \"subExcludedNode\" : { \"someProperty\" : \"value\" } }\n            }\n        collection_to_create = { \"id\" : COLLECTION_ID ,\n                                \"indexingPolicy\" : \n                                { \n                                    \"includedPaths\" : [ {'path' : \"/*\"} ], # Special mandatory path of \"/*\" required to denote include entire tree\n                                    \"excludedPaths\" : [ {'path' : \"/metaData/*\"}, # exclude metaData node, and anything under it\n                                                        {'path' : \"/subDoc/nonSearchable/*\"}, # exclude ONLY a part of subDoc    \n                                                        {'path' : \"/\\\"excludedNode\\\"/*\"} # exclude excludedNode node, and anything under it\n                                                      ]\n                                    } \n                                }\n        print(collection_to_create)\n        print(doc_with_nested_structures)\n        # Create a collection with the defined properties\n        # The effect of the above IndexingPolicy is that only id, foo, and the subDoc/searchable are indexed\n        created_Container = client.CreateContainer(database_link, collection_to_create)\n        print(created_Container)\n        print(\"\\n\" + \"-\" * 25 + \"\\n4. Collection created with index policy\")\n        print_dictionary_items(created_Container[\"indexingPolicy\"])\n\n        # The effect of the above IndexingPolicy is that only id, foo, and the subDoc/searchable are indexed\n        collection_link = GetContainerLink(database_id, COLLECTION_ID)\n        doc = client.CreateItem(collection_link, doc_with_nested_structures)\n        print(\"\\n\" + \"-\" * 25 + \"Document doc1 created with nested structures\" +  \"-\" * 25)\n        print(doc)\n\n        # Querying for a document on either metaData or /subDoc/subSubDoc/someProperty > fail because these paths were excluded and they raise a BadRequest(400) Exception\n        query = {\"query\": \"SELECT * FROM r WHERE r.metaData=@desiredValue\", \"parameters\" : [{ \"name\":\"@desiredValue\", \"value\": \"meta\" }]}\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        query = {\"query\": \"SELECT * FROM r WHERE r.subDoc.nonSearchable=@desiredValue\", \"parameters\" : [{ \"name\":\"@desiredValue\", \"value\": \"value\" }]}\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        query = {\"query\": \"SELECT * FROM r WHERE r.excludedNode.subExcludedNode.someProperty=@desiredValue\", \"parameters\" : [{ \"name\":\"@desiredValue\", \"value\": \"value\" }]}\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        # Querying for a document using foo, or even subDoc/searchable > succeed because they were not excluded\n        query = {\"query\": \"SELECT * FROM r WHERE r.foo=@desiredValue\", \"parameters\" : [{ \"name\":\"@desiredValue\", \"value\": \"bar\" }]}\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        query = {\"query\": \"SELECT * FROM r WHERE r.subDoc.searchable=@desiredValue\", \"parameters\" : [{ \"name\":\"@desiredValue\", \"value\": \"searchable\" }]}\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        # Cleanup\n        client.DeleteContainer(collection_link)\n        print(\"\\n\")\n\n    except errors.HTTPFailure as e:\n        if e.status_code == 409:\n            print(\"Entity already exists\")\n        elif e.status_code == 404:\n            print(\"Entity doesn't exist\")\n        else:\n            raise", "response": "This method will index every attribute in every document in every document in every document in every document in every document in every document in every document in every document in every document in every document in every document in every document in every document in every document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RangeScanOnHashIndex(client, database_id):\n    try:\n        DeleteContainerIfExists(client, database_id, COLLECTION_ID)\n        database_link = GetDatabaseLink(database_id)\n        # collections = Query_Entities(client, 'collection', parent_link = database_link)\n        # print(collections)\n\n        # Force a range scan operation on a hash indexed path\n        collection_to_create = { \"id\" : COLLECTION_ID ,\n                                \"indexingPolicy\" : \n                                { \n                                    \"includedPaths\" : [ {'path' : \"/\"} ],\n                                    \"excludedPaths\" : [ {'path' : \"/length/*\"} ] # exclude length\n                                    } \n                                }\n        created_Container = client.CreateContainer(database_link, collection_to_create)\n        print(created_Container)\n        print(\"\\n\" + \"-\" * 25 + \"\\n5. Collection created with index policy\")\n        print_dictionary_items(created_Container[\"indexingPolicy\"])\n\n        collection_link = GetContainerLink(database_id, COLLECTION_ID)\n        doc1 = client.CreateItem(collection_link, { \"id\" : \"dyn1\", \"length\" : 10, \"width\" : 5, \"height\" : 15 })\n        doc2 = client.CreateItem(collection_link, { \"id\" : \"dyn2\", \"length\" : 7, \"width\" : 15 })\n        doc3 = client.CreateItem(collection_link, { \"id\" : \"dyn3\", \"length\" : 2 })\n        print(\"Three docs created with ids : \", doc1[\"id\"], doc2[\"id\"], doc3[\"id\"])\n\n        # Query for length > 5 - fail, this is a range based query on a Hash index only document\n        query = { \"query\": \"SELECT * FROM r WHERE r.length > 5\" }\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n\n        # Now add IndexingDirective and repeat query\n        # expect 200 OK because now we are explicitly allowing scans in a query\n        # using the enableScanInQuery directive\n        QueryDocumentsWithCustomQuery(client, collection_link, query)\n        results = list(client.QueryItems(collection_link, query, {\"enableScanInQuery\" : True}))\n        print(\"Printing documents queried by range by providing enableScanInQuery = True\")\n        for doc in results: print(doc[\"id\"])\n\n        # Cleanup\n        client.DeleteContainer(collection_link)\n        print(\"\\n\")\n    except errors.HTTPFailure as e:\n        if e.status_code == 409:\n            print(\"Entity already exists\")\n        elif e.status_code == 404:\n            print(\"Entity doesn't exist\")\n        else:\n            raise", "response": "For a range index on a hash index create a new range index and return the list of documents that can be used to compare against the hash index on the path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow how range queries can be performed on strings.", "response": "def UseRangeIndexesOnStrings(client, database_id):\n    \"\"\"Showing how range queries can be performed even on strings.\n\n    \"\"\"\n    try:\n        DeleteContainerIfExists(client, database_id, COLLECTION_ID)\n        database_link = GetDatabaseLink(database_id)\n        # collections = Query_Entities(client, 'collection', parent_link = database_link)\n        # print(collections)\n\n        # Use range indexes on strings\n        \n        # This is how you can specify a range index on strings (and numbers) for all properties.\n        # This is the recommended indexing policy for collections. i.e. precision -1\n        #indexingPolicy = { \n        #    'indexingPolicy': {\n        #        'includedPaths': [\n        #            {\n        #                'indexes': [\n        #                    {\n        #                        'kind': documents.IndexKind.Range,\n        #                        'dataType': documents.DataType.String,\n        #                        'precision': -1\n        #                    }\n        #                ]\n        #            }\n        #        ]\n        #    }\n        #}\n\n        # For demo purposes, we are going to use the default (range on numbers, hash on strings) for the whole document (/* )\n        # and just include a range index on strings for the \"region\".\n        collection_definition = {\n            'id': COLLECTION_ID,\n            'indexingPolicy': {\n                'includedPaths': [\n                    {\n                        'path': '/region/?',\n                        'indexes': [\n                            {\n                                'kind': documents.IndexKind.Range,\n                                'dataType': documents.DataType.String,\n                                'precision': -1\n                            }\n                        ]\n                    },\n                    {\n                        'path': '/*'\n                    }\n                ]\n            }\n        }\n\n        created_Container = client.CreateContainer(database_link, collection_definition)\n        print(created_Container)\n        print(\"\\n\" + \"-\" * 25 + \"\\n6. Collection created with index policy\")\n        print_dictionary_items(created_Container[\"indexingPolicy\"])\n\n        collection_link = GetContainerLink(database_id, COLLECTION_ID)\n        client.CreateItem(collection_link, { \"id\" : \"doc1\", \"region\" : \"USA\" })\n        client.CreateItem(collection_link, { \"id\" : \"doc2\", \"region\" : \"UK\" })\n        client.CreateItem(collection_link, { \"id\" : \"doc3\", \"region\" : \"Armenia\" })\n        client.CreateItem(collection_link, { \"id\" : \"doc4\", \"region\" : \"Egypt\" })\n\n        # Now ordering against region is allowed. You can run the following query\n        query = { \"query\" : \"SELECT * FROM r ORDER BY r.region\" }\n        message = \"Documents ordered by region\"\n        QueryDocumentsWithCustomQuery(client, collection_link, query, message)\n\n        # You can also perform filters against string comparison like >= 'UK'. Note that you can perform a prefix query, \n        # the equivalent of LIKE 'U%' (is >= 'U' AND < 'U')\n        query = { \"query\" : \"SELECT * FROM r WHERE r.region >= 'U'\" }\n        message = \"Documents with region begining with U\"\n        QueryDocumentsWithCustomQuery(client, collection_link, query, message)\n\n        # Cleanup\n        client.DeleteContainer(collection_link)\n        print(\"\\n\")\n    except errors.HTTPFailure as e:\n        if e.status_code == 409:\n            print(\"Entity already exists\")\n        elif e.status_code == 404:\n            print(\"Entity doesn't exist\")\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ResolveForCreate(self, document):\n        if document is None:\n            raise ValueError(\"document is None.\")\n\n        partition_key = self.partition_key_extractor(document)\n        containing_range = self._GetContainingRange(partition_key)\n        \n        if containing_range is None:\n            raise ValueError(\"A containing range for \" + str(partition_key) + \" doesn't exist in the partition map.\")\n        \n        return self.partition_map.get(containing_range)", "response": "Resolves the collection for creating the document based on the partition key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the collection for reading based on the partition key.", "response": "def ResolveForRead(self, partition_key):\n        \"\"\"Resolves the collection for reading/querying the documents based on the partition key.\n\n        :param dict document:\n            The document to be read/queried.\n\n        :return:\n            Collection Self link(s) or Name based link(s) which should handle the Read operation.\n        :rtype:\n            list\n        \"\"\"\n        intersecting_ranges = self._GetIntersectingRanges(partition_key)\n\n        collection_links = list()\n        for keyrange in intersecting_ranges:\n            collection_links.append(self.partition_map.get(keyrange))\n\n        return collection_links"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetContainingRange(self, partition_key):\n        for keyrange in self.partition_map.keys():\n            if keyrange.Contains(partition_key):\n                return keyrange\n\n        return None", "response": "Gets the containing range based on the partition key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the set of intersecting ranges based on the partition key.", "response": "def _GetIntersectingRanges(self, partition_key):\n        \"\"\"Gets the intersecting ranges based on the partition key.\n        \"\"\"\n        partitionkey_ranges = set()\n        intersecting_ranges = set()\n\n        if partition_key is None:\n            return list(self.partition_map.keys())\n\n        if isinstance(partition_key, prange.Range):\n            partitionkey_ranges.add(partition_key)\n        elif isinstance(partition_key, list):\n            for key in partition_key:\n                if key is None:\n                    return list(self.partition_map.keys())\n                elif isinstance(key, prange.Range):\n                    partitionkey_ranges.add(key)\n                else:\n                    partitionkey_ranges.add(prange.Range(key, key))\n        else:\n            partitionkey_ranges.add(prange.Range(partition_key, partition_key))\n\n        for partitionKeyRange in partitionkey_ranges:\n            for keyrange in self.partition_map.keys():\n                if keyrange.Intersect(partitionKeyRange):\n                    intersecting_ranges.add(keyrange)\n\n        return intersecting_ranges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef PartitioningQueryIterable(cls, client, query, options, database_link, partition_key):\n        # This will call the base constructor(__init__ method above)\n        \n        self = cls(client, query, options, None, None)\n        self._database_link = database_link\n        self._partition_key = partition_key\n\n        return self", "response": "This is the base class method that instantiates a QueryIterable for the client side partitioning queries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_execution_context(self):\n        if hasattr(self, '_database_link'):\n            # client side partitioning query\n            return base_execution_context._MultiCollectionQueryExecutionContext(self._client, self._options, self._database_link, self._query, self._partition_key)\n        else:\n            # \n            return execution_dispatcher._ProxyQueryExecutionContext(self._client, self._collection_link, self._query, self._options, self._fetch_function)", "response": "instantiates the internal query execution context based."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_next_block(self):\n                \n        if self._ex_context is None:\n            # initiates execution context for the first time\n            self._ex_context = self._create_execution_context()\n        \n        return self._ex_context.fetch_next_block()", "response": "Returns a block of results with respecting retry policy."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ShouldRetry(self, exception):\n        if self.current_retry_attempt_count < self._max_retry_attempt_count:\n            self.current_retry_attempt_count += 1\n            self.retry_after_in_milliseconds = 0\n                \n            if self._fixed_retry_interval_in_milliseconds:\n                self.retry_after_in_milliseconds = self._fixed_retry_interval_in_milliseconds\n            elif http_constants.HttpHeaders.RetryAfterInMilliseconds in exception.headers:\n                self.retry_after_in_milliseconds = int(exception.headers[http_constants.HttpHeaders.RetryAfterInMilliseconds])\n                \n            if self.cummulative_wait_time_in_milliseconds < self._max_wait_time_in_milliseconds:\n                self.cummulative_wait_time_in_milliseconds += self.retry_after_in_milliseconds\n                return True\n            \n        return False", "response": "Returns true if the current retry count is less than or equal to the max retry count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the database account for the current user.", "response": "def _GetDatabaseAccount(self):\n        \"\"\"Gets the database account first by using the default endpoint, and if that doesn't returns\n           use the endpoints for the preferred locations in the order they are specified to get \n           the database account.\n        \"\"\"\n        try:\n            database_account = self._GetDatabaseAccountStub(self.DefaultEndpoint)\n            return database_account\n        # If for any reason(non-globaldb related), we are not able to get the database account from the above call to GetDatabaseAccount,\n        # we would try to get this information from any of the preferred locations that the user might have specified(by creating a locational endpoint)\n        # and keeping eating the exception until we get the database account and return None at the end, if we are not able to get that info from any endpoints\n        except errors.HTTPFailure:\n            for location_name in self.PreferredLocations:\n                locational_endpoint = _GlobalEndpointManager.GetLocationalEndpoint(self.DefaultEndpoint, location_name)\n                try:\n                    database_account = self._GetDatabaseAccountStub(locational_endpoint)\n                    return database_account\n                except errors.HTTPFailure:\n                    pass\n\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing the passed hash value of this object with the hash value of the passed object.", "response": "def CompareTo(self, other_hash_value):\n        \"\"\"Compares the passed hash value with the hash value of this object\n        \"\"\"\n        if len(self.hash_value) != len(other_hash_value):\n            raise ValueError(\"Length of hashes doesn't match.\")\n\n        # The hash byte array that is returned from ComputeHash method has the MSB at the end of the array\n        # so comparing the bytes from the end for compare operations.\n        for i in xrange(0, len(self.hash_value)):\n            if(self.hash_value[len(self.hash_value) - i - 1] < other_hash_value[len(self.hash_value) - i - 1]):\n                return -1\n            elif self.hash_value[len(self.hash_value) - i - 1] > other_hash_value[len(self.hash_value) - i - 1]:\n                return 1\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ComputeHash(self, key):\n        if key is None:\n            raise ValueError(\"key is None.\")\n\n        hash_value = self._ComputeHash(key)\n        return bytearray(pack('I', hash_value))", "response": "Computes the hash of the value passed using MurmurHash3 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ComputeHash( key, seed = 0x0 ):\n        def fmix( h ):\n            h ^= h >> 16\n            h  = ( h * 0x85ebca6b ) & 0xFFFFFFFF\n            h ^= h >> 13\n            h  = ( h * 0xc2b2ae35 ) & 0xFFFFFFFF\n            h ^= h >> 16\n            return h\n\n        length = len( key )\n        nblocks = int( length / 4 )\n\n        h1 = seed\n\n        c1 = 0xcc9e2d51\n        c2 = 0x1b873593\n\n        # body\n        for block_start in xrange( 0, nblocks * 4, 4 ):\n            k1 = key[ block_start + 3 ] << 24 | \\\n                 key[ block_start + 2 ] << 16 | \\\n                 key[ block_start + 1 ] <<  8 | \\\n                 key[ block_start + 0 ]\n             \n            k1 = c1 * k1 & 0xFFFFFFFF\n            k1 = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # inlined ROTL32\n            k1 = ( c2 * k1 ) & 0xFFFFFFFF\n        \n            h1 ^= k1\n            h1  = ( h1 << 13 | h1 >> 19 ) & 0xFFFFFFFF # inlined _ROTL32 \n            h1  = ( h1 * 5 + 0xe6546b64 ) & 0xFFFFFFFF\n\n        # tail\n        tail_index = nblocks * 4\n        k1 = 0\n        tail_size = length & 3\n\n        if tail_size >= 3:\n            k1 ^= key[ tail_index + 2 ] << 16\n        if tail_size >= 2:\n            k1 ^= key[ tail_index + 1 ] << 8\n        if tail_size >= 1:\n            k1 ^= key[ tail_index + 0 ]\n    \n        if tail_size != 0:\n            k1  = ( k1 * c1 ) & 0xFFFFFFFF\n            k1  = ( k1 << 15 | k1 >> 17 ) & 0xFFFFFFFF # _ROTL32\n            k1  = ( k1 * c2 ) & 0xFFFFFFFF\n            h1 ^= k1\n\n        return fmix( h1 ^ length )", "response": "Computes the hash of the value passed using MurmurHash3 algorithm with the seed value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a session token and creates the vector session token.", "response": "def create(cls, session_token):\n        \"\"\" Parses session token and creates the vector session token\n\n        :param str session_token:\n\n        :return:\n            A Vector session Token \n        :rtype: VectorSessionToken\n        \"\"\"\n\n        version = None\n        global_lsn = None\n        local_lsn_by_region = {}\n\n        if not session_token:\n            return None\n\n        segments = session_token.split(cls.segment_separator)\n        \n        if len(segments) < 2:\n            return None\n\n        try:\n            version = int(segments[0])\n        except ValueError as _:\n            return None\n\n        try:\n            global_lsn = int(segments[1])\n        except ValueError as _:\n            return None\n\n        for i in range(2, len(segments)):\n            region_segment = segments[i]\n            region_id_with_lsn = region_segment.split(cls.region_progress_separator)\n\n            if len(region_id_with_lsn) != 2:\n                return None\n\n            try:\n                region_id = int(region_id_with_lsn[0])\n                local_lsn = int(region_id_with_lsn[1])\n            except ValueError as _:\n                return None\n            local_lsn_by_region[region_id] = local_lsn\n\n        return VectorSessionToken(version, global_lsn, local_lsn_by_region, session_token)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if the retry should be performed based on the passed - in exception.", "response": "def ShouldRetry(self, exception):\n        \"\"\"Returns true if should retry based on the passed-in exception.\n\n        :param (errors.HTTPFailure instance) exception: \n\n        :rtype:\n            boolean\n\n        \"\"\"\n        if not self.connection_policy.EnableEndpointDiscovery:\n            return False\n\n        if self.failover_retry_count >= self.Max_retry_attempt_count:\n            return False\n\n        self.failover_retry_count += 1\n\n        if self.location_endpoint:\n            if _OperationType.IsReadOnlyOperation(self.request.operation_type):\n                #Mark current read endpoint as unavailable\n                self.global_endpoint_manager.mark_endpoint_unavailable_for_read(self.location_endpoint)\n            else:\n                self.global_endpoint_manager.mark_endpoint_unavailable_for_write(self.location_endpoint)\n\n        # set the refresh_needed flag to ensure that endpoint list is\n        # refreshed with new writable and readable locations\n        self.global_endpoint_manager.refresh_needed = True\n        \n        # clear previous location-based routing directive\n        self.request.clear_route_to_location()\n\n        # set location-based routing directive based on retry count\n        # simulating single master writes by ensuring usePreferredLocations\n        # is set to false\n        self.request.route_to_location_with_preferred_location_flag(self.failover_retry_count, False)\n        \n        # Resolve the endpoint for the request and pin the resolution to the resolved endpoint\n        # This enables marking the endpoint unavailability on endpoint failover/unreachability\n        self.location_endpoint = self.global_endpoint_manager.resolve_service_endpoint(self.request)\n        self.request.route_to_location(self.location_endpoint)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the rewritten query if any", "response": "def get_rewritten_query(self):\n        \"\"\"Returns rewritten query or None (if any)\n        \"\"\"\n        rewrittenQuery = self._extract(_PartitionedQueryExecutionInfo.RewrittenQueryPath)\n        if rewrittenQuery is not None:\n            # Hardcode formattable filter to true for now \n            rewrittenQuery = rewrittenQuery.replace('{documentdb-formattableorderbyquery-filter}', 'true')\n        return rewrittenQuery"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetCollectionNode(self, partition_key):\n        if partition_key is None:\n            raise ValueError(\"partition_key is None or empty.\")\n\n        partition_number = self._FindPartition(self._GetBytes(partition_key))\n        return self.partitions[partition_number].GetNode()", "response": "Gets the SelfLink or ID based link of the collection node that maps to the partition key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ConstructPartitions(self, collection_links, partitions_per_node):\n        collections_node_count = len(collection_links)\n        partitions = [partition._Partition() for _ in xrange(0, partitions_per_node * collections_node_count)]\n\n        index = 0\n        for collection_node in collection_links:\n            hash_value = self.hash_generator.ComputeHash(self._GetBytes(collection_node))\n            for _ in xrange(0, partitions_per_node):\n                partitions[index] = partition._Partition(hash_value, collection_node)\n                index += 1\n                hash_value = self.hash_generator.ComputeHash(hash_value)\n\n        partitions.sort()\n        return partitions", "response": "Constructs the partitions in the consistent ring by assigning them to collection nodes\n        and then sorting them based on the hash value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the partition from the byte array representation of the key.", "response": "def _FindPartition(self, key):\n        \"\"\"Finds the partition from the byte array representation of the partition key.\n        \"\"\"\n        hash_value = self.hash_generator.ComputeHash(key)\n        return self._LowerBoundSearch(self.partitions, hash_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetSerializedPartitionList(self):\n        partition_list = list()\n        \n        for part in self.partitions:\n            partition_list.append((part.node, unpack(\"<L\", part.hash_value)[0]))\n\n        return partition_list", "response": "Gets the serialized version of the ConsistentRing. \n        Added this helper for the test code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetBytes(partition_key):\n        if isinstance(partition_key, six.string_types):\n            return bytearray(partition_key, encoding='utf-8')\n        else:\n            raise ValueError(\"Unsupported \" + str(type(partition_key)) + \" for partitionKey.\")", "response": "Gets the bytes representing the value of the partition key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches the partition array using the hash value.", "response": "def _LowerBoundSearch(partitions, hash_value):\n        \"\"\"Searches the partition in the partition array using hashValue.\n        \"\"\"\n        for i in xrange(0, len(partitions) - 1):\n            if partitions[i].CompareTo(hash_value) <= 0 and partitions[i+1].CompareTo(hash_value) > 0:\n                return i\n\n        return len(partitions) - 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        if self._cur_item is not None:\n            res = self._cur_item\n            self._cur_item = None\n            return res\n        \n        return next(self._ex_context)", "response": "Returns the next result item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef peek(self):\n        if self._cur_item is None:\n            self._cur_item = next(self._ex_context)\n\n        return self._cur_item", "response": "Returns the next item in the result set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTypeOrd(orderby_item):\n        if 'item' not in orderby_item:\n            return 0\n        val = orderby_item['item']\n        if val is None: return 1\n        if isinstance(val, bool): return 2\n        if isinstance(val, numbers.Number): return 4\n        if isinstance(val, six.string_types): return 5\n\n        raise TypeError('unknown type' + str(val))", "response": "Returns the ordinal of the value of the item in the item_pair in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares the two orderby item pairs.", "response": "def compare(orderby_item1, orderby_item2):\n        \"\"\"compares the two orderby item pairs.\n        :param dict orderby_item1:\n        :param dict orderby_item2:\n\n        :return:\n            Integer comparison result.\n            The comparator acts such that \n            - if the types are different we get:\n                Undefined value < Null < booleans < Numbers < Strings\n            - if both arguments are of the same type:\n                it simply compares the values.\n\n        :rtype: int\n\n        \"\"\"\n        \n        type1_ord = _OrderByHelper.getTypeOrd(orderby_item1)\n        type2_ord = _OrderByHelper.getTypeOrd(orderby_item2)\n\n        type_ord_diff = type1_ord - type2_ord\n\n        if type_ord_diff:\n            return type_ord_diff\n        \n        # the same type, \n        if type1_ord == 0:\n            return 0\n\n        return _compare_helper(orderby_item1['item'],  orderby_item2['item'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compare(self, doc_producer1, doc_producer2):\n        \n        res1 = self._peek_order_by_items(doc_producer1.peek())\n        res2 = self._peek_order_by_items(doc_producer2.peek())\n        \n        self._validate_orderby_items(res1, res2)\n\n        for i in xrange(len(res1)):\n            res = _OrderByHelper.compare(res1[i], res2[i])\n            if (res != 0):\n                if self._sort_order[i] == 'Ascending':\n                    return res\n                elif self._sort_order[i] == 'Descending':\n                    return -res\n\n        return _PartitionKeyRangeDocumentProduerComparator.compare(self, doc_producer1, doc_producer2)", "response": "Compares the given two instances of DocumentProducers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of results with respecting retry policy.", "response": "def fetch_next_block(self):\n        \"\"\"Returns a block of results with respecting retry policy.\n        \n        This method only exists for backward compatibility reasons. (Because QueryIterable\n        has exposed fetch_next_block api).\n        \n        :return:\n            List of results.\n        :rtype: list\n        \"\"\"\n        if not self._has_more_pages():\n            return []\n        \n        if len(self._buffer):\n            # if there is anything in the buffer returns that\n            res = list(self._buffer)\n            self._buffer.clear()\n            return res\n        else:\n            # fetches the next block\n            return self._fetch_next_block()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next(self):\n        if self._has_finished:\n            raise StopIteration\n\n        if not len(self._buffer):\n                    \n            results = self.fetch_next_block()\n            self._buffer.extend(results)\n            \n        if not len(self._buffer):\n            raise StopIteration\n            \n        return self._buffer.popleft()", "response": "Returns the next query result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fetch_items_helper_no_retries(self, fetch_function): \n        fetched_items = []\n        # Continues pages till finds a non empty page or all results are exhausted\n        while self._continuation or not self._has_started:\n            if not self._has_started:\n                self._has_started = True\n            self._options['continuation'] = self._continuation\n            (fetched_items, response_headers) = fetch_function(self._options)\n            fetched_items\n            continuation_key = http_constants.HttpHeaders.Continuation \n            # Use Etag as continuation token for change feed queries.\n            if self._is_change_feed:\n                continuation_key = http_constants.HttpHeaders.ETag\n            # In change feed queries, the continuation token is always populated. The hasNext() test is whether\n            # there is any items in the response or not.\n            if not self._is_change_feed or len(fetched_items) > 0:\n                self._continuation = response_headers.get(continuation_key)\n            else:\n                self._continuation = None\n            if fetched_items:\n                break\n        return fetched_items", "response": "Fetches more items and doesn t retry on failure\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch the next block of query results.", "response": "def _fetch_next_block(self):    \n        \"\"\"Fetches the next block of query results.\n        \n        This iterates fetches the next block of results from the current collection link.\n        Once the current collection results were exhausted. It moves to the next collection link.\n\n        :return:\n            List of fetched items.\n        :rtype: list\n        \"\"\"\n        # Fetch next block of results by executing the query against the current document collection\n        fetched_items = self._fetch_items_helper_with_retries(self._fetch_function)\n\n        # If there are multiple document collections to query for(in case of partitioning), keep looping through each one of them,\n        # creating separate feed queries for each collection and fetching the items\n        while not fetched_items:\n            if self._collection_links and self._current_collection_index < self._collection_links_length:\n                path = base.GetPathFromLink(self._collection_links[self._current_collection_index], 'docs')\n                collection_id = base.GetResourceIdOrFullNameFromLink(self._collection_links[self._current_collection_index])\n                \n                self._continuation = None\n                self._has_started = False\n\n                def fetch_fn(options):\n                    return self._client.QueryFeed(path,\n                                            collection_id,\n                                            self._query,\n                                            options)\n\n                self._fetch_function = fetch_fn\n\n                fetched_items = self._fetch_items_helper_with_retries(self._fetch_function)\n                self._current_collection_index += 1\n            else:\n                break\n\n        return fetched_items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a partition key range and a collection returns the list of overlapping partition key ranges.", "response": "def get_overlapping_ranges(self, collection_link, partition_key_ranges):\n        '''\n        Given a partition key range and a collection, \n        returns the list of overlapping partition key ranges\n        \n        :param str collection_link:\n            The name of the collection.\n        :param list partition_key_range: \n            List of partition key range.\n        \n        :return:\n            List of overlapping partition key ranges.\n        :rtype: list\n        '''\n        cl = self._documentClient\n        \n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        \n        collection_routing_map = self._collection_routing_map_by_item.get(collection_id)\n        if collection_routing_map is None:\n            collection_pk_ranges = list(cl._ReadPartitionKeyRanges(collection_link))\n            # for large collections, a split may complete between the read partition key ranges query page responses, \n            # causing the partitionKeyRanges to have both the children ranges and their parents. Therefore, we need \n            # to discard the parent ranges to have a valid routing map.\n            collection_pk_ranges = _PartitionKeyRangeCache._discard_parent_ranges(collection_pk_ranges)\n            collection_routing_map = _CollectionRoutingMap.CompleteRoutingMap([(r, True) for r in collection_pk_ranges], collection_id)\n            self._collection_routing_map_by_item[collection_id] = collection_routing_map\n        return collection_routing_map.get_overlapping_ranges(partition_key_ranges)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates and returns r - partition_key_range", "response": "def _subtract_range(self, r, partition_key_range):\n        \"\"\"\n        Evaluates and returns r - partition_key_range\n        :param dict partition_key_range:\n            Partition key range.\n        :param routing_range._Range r: query range.\n        :return:\n            The subtract r - partition_key_range.\n        :rtype: routing_range._Range\n        \"\"\"\n        \n        left = max(partition_key_range[routing_range._PartitionKeyRange.MaxExclusive], r.min)\n\n        if left == r.min:\n            leftInclusive = r.isMinInclusive\n        else:\n            leftInclusive = False\n\n        queryRange = routing_range._Range(left, r.max, leftInclusive,\n                r.isMaxInclusive)\n        return queryRange"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_overlapping_ranges(self, collection_link, sorted_ranges):\n        '''\n        Given the sorted ranges and a collection,\n        Returns the list of overlapping partition key ranges\n        \n        :param str collection_link:\n            The collection link.\n        :param (list of routing_range._Range) sorted_ranges: The sorted list of non-overlapping ranges.\n        :return:\n            List of partition key ranges.\n        :rtype: list of dict\n        :raises ValueError: If two ranges in sorted_ranges overlap or if the list is not sorted\n        '''\n        \n        # validate if the list is non-overlapping and sorted\n        if not self._is_sorted_and_non_overlapping(sorted_ranges):\n            raise ValueError(\"the list of ranges is not a non-overlapping sorted ranges\")\n        \n        target_partition_key_ranges = []\n        \n        it = iter(sorted_ranges)\n        try:\n            currentProvidedRange = next(it)\n            while True:\n                if (currentProvidedRange.isEmpty()):\n                    # skip and go to the next item\\\n                    currentProvidedRange = next(it)\n                    continue\n                \n                if len(target_partition_key_ranges):\n                    queryRange = self._subtract_range(currentProvidedRange, target_partition_key_ranges[-1])\n                else:\n                    queryRange = currentProvidedRange\n    \n                overlappingRanges = _PartitionKeyRangeCache.get_overlapping_ranges(self, collection_link, queryRange)\n                assert len(overlappingRanges), (\"code bug: returned overlapping ranges for queryRange {} is empty\".format(queryRange))\n                target_partition_key_ranges.extend(overlappingRanges)\n\n                lastKnownTargetRange = routing_range._Range.PartitionKeyRangeToRange(target_partition_key_ranges[-1])\n                \n                # the overlapping ranges must contain the requested range\n                assert currentProvidedRange.max <= lastKnownTargetRange.max, \"code bug: returned overlapping ranges {} does not contain the requested range {}\".format(overlappingRanges, queryRange)\n                \n                # the current range is contained in target_partition_key_ranges just move forward\n                currentProvidedRange = next(it)\n                \n                while currentProvidedRange.max <= lastKnownTargetRange.max:\n                    # the current range is covered too. just move forward\n                    currentProvidedRange = next(it)\n        except StopIteration:\n            # when the iteration is exhausted we get here. There is nothing else to be done\n            pass\n        \n        return target_partition_key_ranges", "response": "Given the sorted ranges and a collection returns the list of overlapping partition key ranges."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving the collection for creating the document based on the partition key.", "response": "def ResolveForCreate(self, document):\n        \"\"\"Resolves the collection for creating the document based on the partition key.\n        \n        :param dict document:\n            The document to be created.\n\n        :return:\n            Collection Self link or Name based link which should handle the Create operation.\n        :rtype:\n            str\n        \"\"\"\n        if document is None:\n            raise ValueError(\"document is None.\")\n\n        partition_key = self.partition_key_extractor(document)\n        return self.consistent_hash_ring.GetCollectionNode(partition_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresolving the collection for reading based on the partition key.", "response": "def ResolveForRead(self, partition_key):\n        \"\"\"Resolves the collection for reading/querying the documents based on the partition key.\n\n        :param dict document:\n            The document to be read/queried.\n\n        :return:\n            Collection Self link(s) or Name based link(s) which should handle the Read operation.\n        :rtype:\n            list\n        \"\"\"\n        if partition_key is None:\n            return self.collection_links\n        else:\n            return [self.consistent_hash_ring.GetCollectionNode(partition_key)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next query result.", "response": "def next(self):\n        \"\"\"Returns the next query result.\n        \n        :return:\n            The next query result.\n        :rtype: dict\n        :raises StopIteration: If no more result is left.\n            \n        \"\"\"\n        try:\n            return next(self._execution_context)\n        except HTTPFailure as e:        \n            if self._is_partitioned_execution_info(e):\n                query_execution_info = self._get_partitioned_execution_info(e)\n                self._execution_context = self._create_pipelined_execution_context(query_execution_info)\n            else:\n                raise e\n        \n        return next(self._execution_context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a block of results.", "response": "def fetch_next_block(self):\n        \"\"\"Returns a block of results. \n        \n        This method only exists for backward compatibility reasons. (Because QueryIterable\n        has exposed fetch_next_block api).\n        \n        This method internally invokes next() as many times required to collect the \n        requested fetch size.\n        \n        :return:\n            List of results.\n        :rtype: list\n        \"\"\"\n        \n        results = []\n        for _ in xrange(self._page_size):\n            try:\n                results.append(next(self))\n            except StopIteration:\n                # no more results\n                break\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ShouldRetry(self, exception):\n        if (self.current_retry_attempt_count < self._max_retry_attempt_count) and self.needsRetry(exception.status_code):\n            self.current_retry_attempt_count += 1\n            return True\n        return False", "response": "Returns true if the current retry count is less than the max retry count."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next(self):\n        if self._orderByPQ.size() > 0:\n            \n            targetRangeExContext = self._orderByPQ.pop()\n            res = next(targetRangeExContext)\n            \n            try:\n                \"\"\"TODO: we can also use more_itertools.peekable to be more python friendly\"\"\"\n                targetRangeExContext.peek()\n                self._orderByPQ.push(targetRangeExContext)\n\n            except StopIteration:\n                pass\n                \n            return res\n        raise StopIteration", "response": "returns the next result in the sequence"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Contains(self, other):\n        if other is None:\n            raise ValueError(\"other is None.\")\n\n        if isinstance(other, Range):\n            if other.low >= self.low and other.high <= self.high:\n                return True\n            return False\n        else:\n            return self.Contains(Range(other, other))", "response": "Checks if the passed parameter is in the range of this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the passed parameter intersects the range of this object.", "response": "def Intersect(self, other):\n        \"\"\"Checks if the passed parameter intersects the range of this object.\n        \"\"\"\n        if isinstance(other, Range):\n            max_low = self.low if (self.low >= other.low) else other.low\n            min_high = self.high if (self.high <= other.high) else other.high\n\n            if max_low <= min_high:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister the partition resolver associated with the database link.", "response": "def RegisterPartitionResolver(self, database_link, partition_resolver):\n        \"\"\"Registers the partition resolver associated with the database link\n\n        :param str database_link:\n            Database Self Link or ID based link.\n        :param object partition_resolver:\n            An instance of PartitionResolver.\n        \n        \"\"\"\n        if not database_link:\n            raise ValueError(\"database_link is None or empty.\")\n\n        if partition_resolver is None:\n            raise ValueError(\"partition_resolver is None.\")\n\n        self.partition_resolvers = {base.TrimBeginningAndEndingSlashes(database_link): partition_resolver}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetPartitionResolver(self, database_link):\n        if not database_link:\n            raise ValueError(\"database_link is None or empty.\")\n\n        return self.partition_resolvers.get(base.TrimBeginningAndEndingSlashes(database_link))", "response": "Retrieves the partition resolver associated with the database link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CreateDatabase(self, database, options=None):\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(database)\n        path = '/dbs'\n        return self.Create(database, path, 'dbs', None, None, options)", "response": "Creates a Azure Cosmos database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a database. :param str database_link: The link to the database. :param dict options: The request options for the request. :return: The Database that was read. :rtype: dict", "response": "def ReadDatabase(self, database_link, options=None):\n        \"\"\"Reads a database.\n\n        :param str database_link:\n            The link to the database.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The Database that was read.\n        :rtype: dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(database_link)\n        database_id = base.GetResourceIdOrFullNameFromLink(database_link)\n        return self.Read(path, 'dbs', database_id, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef QueryDatabases(self, query, options=None):\n        if options is None:\n            options = {}\n\n        def fetch_fn(options):\n            return self.__QueryFeed('/dbs',\n                                    'dbs',\n                                    '',\n                                    lambda r: r['Databases'],\n                                    lambda _, b: b,\n                                    query,\n                                    options), self.last_response_headers\n        return query_iterable.QueryIterable(self, query, options, fetch_fn)", "response": "Queries databases.\n\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n\n        :return: Query Iterable of Databases.\n        :rtype:\n            query_iterable.QueryIterable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ReadContainers(self, database_link, options=None):\n        if options is None:\n            options = {}\n\n        return self.QueryContainers(database_link, None, options)", "response": "Reads all collections in a database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a collection in a database.", "response": "def CreateContainer(self, database_link, collection, options=None):\n        \"\"\"Creates a collection in a database.\n\n        :param str database_link:\n            The link to the database.\n        :param dict collection:\n            The Azure Cosmos collection to create.\n        :param dict options:\n            The request options for the request.\n\n        :return: The Collection that was created.\n        :rtype: dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(collection)\n        path = base.GetPathFromLink(database_link, 'colls')\n        database_id = base.GetResourceIdOrFullNameFromLink(database_link)\n        return self.Create(collection,\n                           path,\n                           'colls',\n                           database_id,\n                           None,\n                           options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ReplaceContainer(self, collection_link, collection, options=None):\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(collection)\n        path = base.GetPathFromLink(collection_link)\n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        return self.Replace(collection,\n                            path,\n                            'colls',\n                            collection_id,\n                            None,\n                            options)", "response": "Replaces a collection and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReadContainer(self, collection_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(collection_link)\n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        return self.Read(path,\n                         'colls',\n                         collection_id,\n                         None,\n                         options)", "response": "Reads a collection.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read Collection.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a user. :param str database_link: The link to the database. :param dict user: The Azure Cosmos user to create. :param dict options: The request options for the request. :return: The created User. :rtype: dict", "response": "def CreateUser(self, database_link, user, options=None):\n        \"\"\"Creates a user.\n\n        :param str database_link:\n            The link to the database.\n        :param dict user:\n            The Azure Cosmos user to create.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The created User.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        database_id, path = self._GetDatabaseIdWithPathForUser(database_link, user)\n        return self.Create(user,\n                           path,\n                           'users',\n                           database_id,\n                           None,\n                           options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a user. :param str user_link: The link to the user entity. :param dict options: The request options for the request. :return: The read User. :rtype: dict", "response": "def ReadUser(self, user_link, options=None):\n        \"\"\"Reads a user.\n\n        :param str user_link:\n            The link to the user entity.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read User.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(user_link)\n        user_id = base.GetResourceIdOrFullNameFromLink(user_link)\n        return self.Read(path, 'users', user_id, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading all users in a database.", "response": "def ReadUsers(self, database_link, options=None):\n        \"\"\"Reads all users in a database.\n\n        :params str database_link:\n            The link to the database.\n        :params dict options:\n            The request options for the request.\n        :return:\n            Query iterable of Users.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        return self.QueryUsers(database_link, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying users in a database.", "response": "def QueryUsers(self, database_link, query, options=None):\n        \"\"\"Queries users in a database.\n\n        :param str database_link:\n            The link to the database.\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of Users.\n        :rtype:   \n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(database_link, 'users')\n        database_id = base.GetResourceIdOrFullNameFromLink(database_link)\n        def fetch_fn(options):\n            return self.__QueryFeed(path,\n                                    'users',\n                                    database_id,\n                                    lambda r: r['Users'],\n                                    lambda _, b: b,\n                                    query,\n                                    options), self.last_response_headers\n        return query_iterable.QueryIterable(self, query, options, fetch_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DeleteDatabase(self, database_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(database_link)\n        database_id = base.GetResourceIdOrFullNameFromLink(database_link)\n        return self.DeleteResource(path,\n                                   'dbs',\n                                   database_id,\n                                   None,\n                                   options)", "response": "Deletes a database.\n\n        :param str database_link:\n            The link to the database.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Database.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a permission for a user.", "response": "def CreatePermission(self, user_link, permission, options=None):\n        \"\"\"Creates a permission for a user.\n\n        :param str user_link:\n            The link to the user entity.\n        :param dict permission:\n            The Azure Cosmos user permission to create.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The created Permission.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path, user_id = self._GetUserIdWithPathForPermission(permission, user_link)\n        return self.Create(permission,\n                           path,\n                           'permissions',\n                           user_id,\n                           None,\n                           options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef UpsertPermission(self, user_link, permission, options=None):\n        if options is None:\n            options = {}\n\n        path, user_id = self._GetUserIdWithPathForPermission(permission, user_link)\n        return self.Upsert(permission,\n                            path,\n                            'permissions',\n                            user_id,\n                            None,\n                            options)", "response": "Upserts a permission for a user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ReadPermission(self, permission_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(permission_link)\n        permission_id = base.GetResourceIdOrFullNameFromLink(permission_link)\n        return self.Read(path,\n                         'permissions',\n                          permission_id,\n                          None,\n                          options)", "response": "Reads a permission.\n\n        :param str permission_link:\n            The link to the permission.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read permission.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReadPermissions(self, user_link, options=None):\n        if options is None:\n            options = {}\n\n        return self.QueryPermissions(user_link, None, options)", "response": "Reads all permissions for a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries permissions for a user.", "response": "def QueryPermissions(self, user_link, query, options=None):\n        \"\"\"Queries permissions for a user.\n\n        :param str user_link:\n            The link to the user entity.\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of Permissions.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(user_link, 'permissions')\n        user_id = base.GetResourceIdOrFullNameFromLink(user_link)\n        def fetch_fn(options):\n            return self.__QueryFeed(path,\n                                    'permissions',\n                                    user_id,\n                                    lambda r: r['Permissions'],\n                                    lambda _, b: b,\n                                    query,\n                                    options), self.last_response_headers\n        return query_iterable.QueryIterable(self, query, options, fetch_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces a user and returns it.", "response": "def ReplaceUser(self, user_link, user, options=None):\n        \"\"\"Replaces a user and return it.\n\n        :param str user_link:\n            The link to the user entity.\n        :param dict user:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The new User.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(user)\n        path = base.GetPathFromLink(user_link)\n        user_id = base.GetResourceIdOrFullNameFromLink(user_link)\n        return self.Replace(user,\n                            path,\n                            'users',\n                            user_id,\n                            None,\n                            options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DeleteUser(self, user_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(user_link)\n        user_id = base.GetResourceIdOrFullNameFromLink(user_link)\n        return self.DeleteResource(path,\n                                   'users',\n                                   user_id,\n                                   None,\n                                   options)", "response": "Deletes a user.\n\n        :param str user_link:\n            The link to the user entity.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted user.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace a permission and returns it.", "response": "def ReplacePermission(self, permission_link, permission, options=None):\n        \"\"\"Replaces a permission and return it.\n\n        :param str permission_link:\n            The link to the permission.\n        :param dict permission:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The new Permission.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(permission)\n        path = base.GetPathFromLink(permission_link)\n        permission_id = base.GetResourceIdOrFullNameFromLink(permission_link)\n        return self.Replace(permission,\n                            path,\n                            'permissions',\n                            permission_id,\n                            None,\n                            options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DeletePermission(self, permission_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(permission_link)\n        permission_id = base.GetResourceIdOrFullNameFromLink(permission_link)\n        return self.DeleteResource(path,\n                                   'permissions',\n                                   permission_id,\n                                   None,\n                                   options)", "response": "Deletes a permission.\n\n        :param str permission_link:\n            The link to the permission.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Permission.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ReadItems(self, collection_link, feed_options=None):\n        if feed_options is None:\n            feed_options = {}\n\n        return self.QueryItems(collection_link, None, feed_options)", "response": "Reads all documents in a collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the items in a collection.", "response": "def QueryItems(self, database_or_Container_link, query, options=None, partition_key=None):\n        \"\"\"Queries documents in a collection.\n\n        :param str database_or_Container_link:\n            The link to the database when using partitioning, otherwise link to the document collection.\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n        :param str partition_key:\n            Partition key for the query(default value None)\n\n        :return:\n            Query Iterable of Documents.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        database_or_Container_link = base.TrimBeginningAndEndingSlashes(database_or_Container_link)\n\n        if options is None:\n            options = {}\n\n        if(base.IsDatabaseLink(database_or_Container_link)):\n            # Python doesn't have a good way of specifying an overloaded constructor, and this is how it's generally overloaded constructors are specified(by calling a @classmethod) and returning the 'self' instance\n            return query_iterable.QueryIterable.PartitioningQueryIterable(self, query, options, database_or_Container_link, partition_key)\n        else:    \n            path = base.GetPathFromLink(database_or_Container_link, 'docs')\n            collection_id = base.GetResourceIdOrFullNameFromLink(database_or_Container_link)\n            def fetch_fn(options):\n                return self.__QueryFeed(path,\n                                        'docs',\n                                        collection_id,\n                                        lambda r: r['Documents'],\n                                        lambda _, b: b,\n                                        query,\n                                        options), self.last_response_headers\n            return query_iterable.QueryIterable(self, query, options, fetch_fn, database_or_Container_link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef QueryItemsChangeFeed(self, collection_link, options=None):\n\n        partition_key_range_id = None\n        if options is not None and 'partitionKeyRangeId' in options:\n            partition_key_range_id = options['partitionKeyRangeId']\n\n        return self._QueryChangeFeed(collection_link, \"Documents\" , options, partition_key_range_id)", "response": "Queries the items change feed in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _QueryChangeFeed(self, collection_link, resource_type, options=None, partition_key_range_id=None):\n        if options is None:\n            options = {}\n        options['changeFeed'] = True\n\n        resource_key_map = {'Documents' : 'docs'}\n\n        # For now, change feed only supports Documents and Partition Key Range resouce type\n        if resource_type not in resource_key_map:\n            raise NotImplementedError(resource_type + \" change feed query is not supported.\")\n\n        resource_key = resource_key_map[resource_type]\n        path = base.GetPathFromLink(collection_link, resource_key)\n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        def fetch_fn(options):\n            return self.__QueryFeed(path,\n                                    resource_key,\n                                    collection_id,\n                                    lambda r: r[resource_type],\n                                    lambda _, b: b,\n                                    None,\n                                    options,\n                                    partition_key_range_id), self.last_response_headers\n        return query_iterable.QueryIterable(self, None, options, fetch_fn, collection_link)", "response": "Queries the change feed of a resource in a collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadPartitionKeyRanges(self, collection_link, feed_options=None):\n        if feed_options is None:\n            feed_options = {}\n\n        return self._QueryPartitionKeyRanges(collection_link, None, feed_options)", "response": "Reads Partition Key Ranges."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CreateItem(self, database_or_Container_link, document, options=None):\n        # Python's default arguments are evaluated once when the function is defined, not each time the function is called (like it is in say, Ruby). \n        # This means that if you use a mutable default argument and mutate it, you will and have mutated that object for all future calls to the function as well.\n        # So, using a non-mutable deafult in this case(None) and assigning an empty dict(mutable) inside the method\n        # For more details on this gotcha, please refer http://docs.python-guide.org/en/latest/writing/gotchas/\n        if options is None:\n            options = {}\n        \n        # We check the link to be document collection link since it can be database link in case of client side partitioning\n        if(base.IsItemContainerLink(database_or_Container_link)):\n            options = self._AddPartitionKey(database_or_Container_link, document, options)\n\n        collection_id, document, path = self._GetContainerIdWithPathForItem(database_or_Container_link, document, options)\n        return self.Create(document,\n                           path,\n                           'docs',\n                           collection_id,\n                           None,\n                           options)", "response": "Creates a new Azure Cosmos item in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a document. :param str document_link: The link to the document. :param dict options: The request options for the request. :return: The read Document. :rtype: dict", "response": "def ReadItem(self, document_link, options=None):\n        \"\"\"Reads a document.\n\n        :param str document_link:\n            The link to the document.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read Document.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(document_link)\n        document_id = base.GetResourceIdOrFullNameFromLink(document_link)\n        return self.Read(path,\n                         'docs',\n                         document_id,\n                         None,\n                         options)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread all triggers in a document collection.", "response": "def ReadTriggers(self, collection_link, options=None):\n        \"\"\"Reads all triggers in a collection.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of Triggers.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        return self.QueryTriggers(collection_link, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CreateTrigger(self, collection_link, trigger, options=None):\n        if options is None:\n            options = {}\n\n        collection_id, path, trigger = self._GetContainerIdWithPathForTrigger(collection_link, trigger)\n        return self.Create(trigger,\n                           path,\n                           'triggers',\n                           collection_id,\n                           None,\n                           options)", "response": "Creates a new trigger in a document collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a trigger. :param str trigger_link: The link to the trigger. :param dict options: The request options for the request. :return: The read Trigger. :rtype: dict", "response": "def ReadTrigger(self, trigger_link, options=None):\n        \"\"\"Reads a trigger.\n\n        :param str trigger_link:\n            The link to the trigger.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read Trigger.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(trigger_link)\n        trigger_id = base.GetResourceIdOrFullNameFromLink(trigger_link)\n        return self.Read(path, 'triggers', trigger_id, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading all user defined functions in a collection.", "response": "def ReadUserDefinedFunctions(self, collection_link, options=None):\n        \"\"\"Reads all user defined functions in a collection.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of UDFs.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        return self.QueryUserDefinedFunctions(collection_link, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef QueryUserDefinedFunctions(self, collection_link, query, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(collection_link, 'udfs')\n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        def fetch_fn(options):\n            return self.__QueryFeed(path,\n                                    'udfs',\n                                    collection_id,\n                                    lambda r: r['UserDefinedFunctions'],\n                                    lambda _, b: b,\n                                    query,\n                                    options), self.last_response_headers\n        return query_iterable.QueryIterable(self, query, options, fetch_fn)", "response": "Queries user defined functions in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CreateUserDefinedFunction(self, collection_link, udf, options=None):\n        if options is None:\n            options = {}\n\n        collection_id, path, udf = self._GetContainerIdWithPathForUDF(collection_link, udf)\n        return self.Create(udf,\n                           path,\n                           'udfs',\n                           collection_id,\n                           None,\n                           options)", "response": "Creates a user defined function in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef UpsertUserDefinedFunction(self, collection_link, udf, options=None):\n        if options is None:\n            options = {}\n\n        collection_id, path, udf = self._GetContainerIdWithPathForUDF(collection_link, udf)\n        return self.Upsert(udf,\n                           path,\n                           'udfs',\n                           collection_id,\n                           None,\n                           options)", "response": "Upserts a user defined function in a collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ReadUserDefinedFunction(self, udf_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(udf_link)\n        udf_id = base.GetResourceIdOrFullNameFromLink(udf_link)\n        return self.Read(path, 'udfs', udf_id, None, options)", "response": "Reads a user defined function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ReadStoredProcedures(self, collection_link, options=None):\n        if options is None:\n            options = {}\n\n        return self.QueryStoredProcedures(collection_link, None, options)", "response": "Reads all store procedures in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a stored procedure in a collection.", "response": "def CreateStoredProcedure(self, collection_link, sproc, options=None):\n        \"\"\"Creates a stored procedure in a collection.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param str sproc:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The created Stored Procedure.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        collection_id, path, sproc = self._GetContainerIdWithPathForSproc(collection_link, sproc)\n        return self.Create(sproc,\n                           path,\n                           'sprocs',\n                           collection_id,\n                           None,\n                           options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef UpsertStoredProcedure(self, collection_link, sproc, options=None):\n        if options is None:\n            options = {}\n\n        collection_id, path, sproc = self._GetContainerIdWithPathForSproc(collection_link, sproc)\n        return self.Upsert(sproc,\n                           path,\n                           'sprocs',\n                           collection_id,\n                           None,\n                           options)", "response": "Upserts a stored procedure in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a stored procedure.", "response": "def ReadStoredProcedure(self, sproc_link, options=None):\n        \"\"\"Reads a stored procedure.\n\n        :param str sproc_link:\n            The link to the stored procedure.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read Stored Procedure.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(sproc_link)\n        sproc_id = base.GetResourceIdOrFullNameFromLink(sproc_link)\n        return self.Read(path, 'sprocs', sproc_id, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading conflicts. :param str collection_link: The link to the document collection. :param dict feed_options: :return: Query Iterable of Conflicts. :rtype: query_iterable.QueryIterable", "response": "def ReadConflicts(self, collection_link, feed_options=None):\n        \"\"\"Reads conflicts.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param dict feed_options:\n\n        :return:\n            Query Iterable of Conflicts.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if feed_options is None:\n            feed_options = {}\n\n        return self.QueryConflicts(collection_link, None, feed_options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a conflict. :param str conflict_link: The link to the conflict. :param dict options: :return: The read Conflict. :rtype: dict", "response": "def ReadConflict(self, conflict_link, options=None):\n        \"\"\"Reads a conflict.\n\n        :param str conflict_link:\n            The link to the conflict.\n        :param dict options:\n\n        :return:\n            The read Conflict.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(conflict_link)\n        conflict_id = base.GetResourceIdOrFullNameFromLink(conflict_link)\n        return self.Read(path,\n                         'conflicts',\n                         conflict_id,\n                         None,\n                         options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DeleteContainer(self, collection_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(collection_link)\n        collection_id = base.GetResourceIdOrFullNameFromLink(collection_link)\n        return self.DeleteResource(path,\n                                   'colls',\n                                   collection_id,\n                                   None,\n                                   options)", "response": "Deletes a collection.\n\n        :param str collection_link:\n            The link to the document collection.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Collection.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace a document and returns it.", "response": "def ReplaceItem(self, document_link, new_document, options=None):\n        \"\"\"Replaces a document and returns it.\n\n        :param str document_link:\n            The link to the document.\n        :param dict new_document:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The new Document.\n        :rtype:\n            dict\n\n        \"\"\"\n        CosmosClient.__ValidateResource(new_document)\n        path = base.GetPathFromLink(document_link)\n        document_id = base.GetResourceIdOrFullNameFromLink(document_link)\n        \n        # Python's default arguments are evaluated once when the function is defined, not each time the function is called (like it is in say, Ruby). \n        # This means that if you use a mutable default argument and mutate it, you will and have mutated that object for all future calls to the function as well.\n        # So, using a non-mutable deafult in this case(None) and assigning an empty dict(mutable) inside the function so that it remains local\n        # For more details on this gotcha, please refer http://docs.python-guide.org/en/latest/writing/gotchas/\n        if options is None:\n            options = {}\n\n        # Extract the document collection link and add the partition key to options\n        collection_link = base.GetItemContainerLink(document_link)\n        options = self._AddPartitionKey(collection_link, new_document, options)\n        \n        return self.Replace(new_document,\n                            path,\n                            'docs',\n                            document_id,\n                            None,\n                            options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a document. :param str document_link: The link to the document. :param dict options: The request options for the request. :return: The deleted Document. :rtype: dict", "response": "def DeleteItem(self, document_link, options=None):\n        \"\"\"Deletes a document.\n\n        :param str document_link:\n            The link to the document.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Document.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(document_link)\n        document_id = base.GetResourceIdOrFullNameFromLink(document_link)\n        return self.DeleteResource(path,\n                                   'docs',\n                                   document_id,\n                                   None,\n                                   options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef CreateAttachment(self, document_link, attachment, options=None):\n        if options is None:\n            options = {}\n\n        document_id, path = self._GetItemIdWithPathForAttachment(attachment, document_link)\n        return self.Create(attachment,\n                           path,\n                           'attachments',\n                           document_id,\n                           None,\n                           options)", "response": "Creates an attachment in a document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef UpsertAttachment(self, document_link, attachment, options=None):\n        if options is None:\n            options = {}\n\n        document_id, path = self._GetItemIdWithPathForAttachment(attachment, document_link)\n        return self.Upsert(attachment,\n                           path,\n                           'attachments',\n                           document_id,\n                           None,\n                           options)", "response": "Upserts an attachment in a document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CreateAttachmentAndUploadMedia(self,\n                                       document_link,\n                                       readable_stream,\n                                       options=None):\n        \"\"\"Creates an attachment and upload media.\n\n        :param str document_link:\n            The link to the document.\n        :param (file-like stream object) readable_stream: \n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The created Attachment.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        document_id, initial_headers, path = self._GetItemIdWithPathForAttachmentMedia(document_link, options)\n        return self.Create(readable_stream,\n                           path,\n                           'attachments',\n                           document_id,\n                           initial_headers,\n                           options)", "response": "Creates an attachment and upload media."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef UpsertAttachmentAndUploadMedia(self,\n                                       document_link,\n                                       readable_stream,\n                                       options=None):\n        \"\"\"Upserts an attachment and upload media.\n\n        :param str document_link:\n            The link to the document.\n        :param (file-like stream object) readable_stream:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The upserted Attachment.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        document_id, initial_headers, path = self._GetItemIdWithPathForAttachmentMedia(document_link, options)\n        return self.Upsert(readable_stream,\n                           path,\n                           'attachments',\n                           document_id,\n                           initial_headers,\n                           options)", "response": "Upserts an attachment and uploads media."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ReadAttachment(self, attachment_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(attachment_link)\n        attachment_id = base.GetResourceIdOrFullNameFromLink(attachment_link)\n        return self.Read(path,\n                         'attachments',\n                         attachment_id,\n                         None,\n                         options)", "response": "Reads an attachment.\n\n        :param str attachment_link:\n            The link to the attachment.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The read Attachment.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread all attachments in a document.", "response": "def ReadAttachments(self, document_link, options=None):\n        \"\"\"Reads all attachments in a document.\n\n        :param str document_link:\n            The link to the document.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of Attachments.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        return self.QueryAttachments(document_link, None, options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the attachments in a document.", "response": "def QueryAttachments(self, document_link, query, options=None):\n        \"\"\"Queries attachments in a document.\n\n        :param str document_link:\n            The link to the document.\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            Query Iterable of Attachments.\n        :rtype:\n            query_iterable.QueryIterable\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(document_link, 'attachments')\n        document_id = base.GetResourceIdOrFullNameFromLink(document_link)\n\n        def fetch_fn(options):\n            return self.__QueryFeed(path,\n                                    'attachments',\n                                    document_id,\n                                    lambda r: r['Attachments'],\n                                    lambda _, b: b,\n                                    query,\n                                    options), self.last_response_headers\n        return query_iterable.QueryIterable(self, query, options, fetch_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a media. When self.connection_policy.MediaReadMode == documents.MediaReadMode.Streamed, returns a file-like stream object; otherwise, returns a str. :param str media_link: The link to the media. :return: The read Media. :rtype: str or file-like stream object", "response": "def ReadMedia(self, media_link):\n        \"\"\"Reads a media.\n\n        When self.connection_policy.MediaReadMode ==\n        documents.MediaReadMode.Streamed, returns a file-like stream object;\n        otherwise, returns a str.\n\n        :param str media_link:\n            The link to the media.\n\n        :return:\n            The read Media.\n        :rtype:\n            str or file-like stream object\n\n        \"\"\"\n        default_headers = self.default_headers\n\n        path = base.GetPathFromLink(media_link)\n        media_id = base.GetResourceIdOrFullNameFromLink(media_link)\n        attachment_id = base.GetAttachmentIdFromMediaId(media_id)\n        headers = base.GetHeaders(self,\n                                  default_headers,\n                                  'get',\n                                  path,\n                                  attachment_id,\n                                  'media',\n                                  {})\n\n        # ReadMedia will always use WriteEndpoint since it's not replicated in readable Geo regions\n        request = request_object._RequestObject('media', documents._OperationType.Read)\n        result, self.last_response_headers = self.__Get(path,\n                                                        request,\n                                                        headers)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef UpdateMedia(self, media_link, readable_stream, options=None):\n        if options is None:\n            options = {}\n\n        initial_headers = dict(self.default_headers)\n\n        # Add required headers slug and content-type in case the body is a stream\n        if options.get('slug'):\n            initial_headers[http_constants.HttpHeaders.Slug] = options['slug']\n\n        if options.get('contentType'):\n            initial_headers[http_constants.HttpHeaders.ContentType] = (\n                options['contentType'])\n        else:\n            initial_headers[http_constants.HttpHeaders.ContentType] = (\n                runtime_constants.MediaTypes.OctetStream)\n\n        path = base.GetPathFromLink(media_link)\n        media_id = base.GetResourceIdOrFullNameFromLink(media_link)\n        attachment_id = base.GetAttachmentIdFromMediaId(media_id)\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'put',\n                                  path,\n                                  attachment_id,\n                                  'media',\n                                  options)\n\n        # UpdateMedia will use WriteEndpoint since it uses PUT operation\n        request = request_object._RequestObject('media', documents._OperationType.Update)\n        result, self.last_response_headers = self.__Put(path,\n                                                        request,\n                                                        readable_stream,\n                                                        headers)\n        \n        self._UpdateSessionIfRequired(headers, result, self.last_response_headers)\n        return result", "response": "Updates a media and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace an attachment and returns it.", "response": "def ReplaceAttachment(self, attachment_link, attachment, options=None):\n        \"\"\"Replaces an attachment and returns it.\n\n        :param str attachment_link:\n            The link to the attachment.\n        :param dict attachment:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The replaced Attachment\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(attachment)\n        path = base.GetPathFromLink(attachment_link)\n        attachment_id = base.GetResourceIdOrFullNameFromLink(attachment_link)\n        return self.Replace(attachment,\n                            path,\n                            'attachments',\n                            attachment_id,\n                            None,\n                            options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DeleteAttachment(self, attachment_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(attachment_link)\n        attachment_id = base.GetResourceIdOrFullNameFromLink(attachment_link)\n        return self.DeleteResource(path,\n                                   'attachments',\n                                   attachment_id,\n                                   None,\n                                   options)", "response": "Deletes an attachment.\n\n        :param str attachment_link:\n            The link to the attachment.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Attachment.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ReplaceTrigger(self, trigger_link, trigger, options=None):\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(trigger)\n        trigger = trigger.copy()\n        if trigger.get('serverScript'):\n            trigger['body'] = str(trigger['serverScript'])\n        elif trigger.get('body'):\n            trigger['body'] = str(trigger['body'])\n\n        path = base.GetPathFromLink(trigger_link)\n        trigger_id = base.GetResourceIdOrFullNameFromLink(trigger_link)\n        return self.Replace(trigger,\n                            path,\n                            'triggers',\n                            trigger_id,\n                            None,\n                            options)", "response": "Replaces a trigger and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a specific trigger.", "response": "def DeleteTrigger(self, trigger_link, options=None):\n        \"\"\"Deletes a trigger.\n\n        :param str trigger_link:\n            The link to the trigger.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Trigger.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(trigger_link)\n        trigger_id = base.GetResourceIdOrFullNameFromLink(trigger_link)\n        return self.DeleteResource(path,\n                                   'triggers',\n                                   trigger_id,\n                                   None,\n                                   options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces a user defined function and returns it.", "response": "def ReplaceUserDefinedFunction(self, udf_link, udf, options=None):\n        \"\"\"Replaces a user defined function and returns it.\n\n        :param str udf_link:\n            The link to the user defined function.\n        :param dict udf:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The new UDF.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(udf)\n        udf = udf.copy()\n        if udf.get('serverScript'):\n            udf['body'] = str(udf['serverScript'])\n        elif udf.get('body'):\n            udf['body'] = str(udf['body'])\n\n        path = base.GetPathFromLink(udf_link)\n        udf_id = base.GetResourceIdOrFullNameFromLink(udf_link)\n        return self.Replace(udf,\n                            path,\n                            'udfs',\n                            udf_id,\n                            None,\n                            options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a user defined function.", "response": "def DeleteUserDefinedFunction(self, udf_link, options=None):\n        \"\"\"Deletes a user defined function.\n\n        :param str udf_link:\n            The link to the user defined function.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted UDF.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(udf_link)\n        udf_id = base.GetResourceIdOrFullNameFromLink(udf_link)\n        return self.DeleteResource(path,\n                                   'udfs',\n                                   udf_id,\n                                   None,\n                                   options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ExecuteStoredProcedure(self, sproc_link, params, options=None):\n        if options is None:\n            options = {}\n\n        initial_headers = dict(self.default_headers)\n        initial_headers.update({\n            http_constants.HttpHeaders.Accept: (\n                runtime_constants.MediaTypes.Json)\n        })\n\n        if params and not type(params) is list:\n            params = [params]\n\n        path = base.GetPathFromLink(sproc_link)\n        sproc_id = base.GetResourceIdOrFullNameFromLink(sproc_link)\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'post',\n                                  path,\n                                  sproc_id,\n                                  'sprocs',\n                                  options)\n\n        # ExecuteStoredProcedure will use WriteEndpoint since it uses POST operation\n        request = request_object._RequestObject('sprocs', documents._OperationType.ExecuteJavaScript)\n        result, self.last_response_headers = self.__Post(path,\n                                                         request,\n                                                         params,\n                                                         headers)\n        return result", "response": "Executes a stored procedure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReplaceStoredProcedure(self, sproc_link, sproc, options=None):\n        if options is None:\n            options = {}\n\n        CosmosClient.__ValidateResource(sproc)\n        sproc = sproc.copy()\n        if sproc.get('serverScript'):\n            sproc['body'] = str(sproc['serverScript'])\n        elif sproc.get('body'):\n            sproc['body'] = str(sproc['body'])\n\n        path = base.GetPathFromLink(sproc_link)\n        sproc_id = base.GetResourceIdOrFullNameFromLink(sproc_link)\n        return self.Replace(sproc,\n                            path,\n                            'sprocs',\n                            sproc_id,\n                            None,\n                            options)", "response": "Replaces a stored procedure and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a stored procedure.", "response": "def DeleteStoredProcedure(self, sproc_link, options=None):\n        \"\"\"Deletes a stored procedure.\n\n        :param str sproc_link:\n            The link to the stored procedure.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Stored Procedure.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(sproc_link)\n        sproc_id = base.GetResourceIdOrFullNameFromLink(sproc_link)\n        return self.DeleteResource(path,\n                                   'sprocs',\n                                   sproc_id,\n                                   None,\n                                   options)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DeleteConflict(self, conflict_link, options=None):\n        if options is None:\n            options = {}\n\n        path = base.GetPathFromLink(conflict_link)\n        conflict_id = base.GetResourceIdOrFullNameFromLink(conflict_link)\n        return self.DeleteResource(path,\n                                   'conflicts',\n                                   conflict_id,\n                                   None,\n                                   options)", "response": "Deletes a conflict.\n\n        :param str conflict_link:\n            The link to the conflict.\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Conflict.\n        :rtype:\n            dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ReplaceOffer(self, offer_link, offer):\n        CosmosClient.__ValidateResource(offer)\n        path = base.GetPathFromLink(offer_link)\n        offer_id = base.GetResourceIdOrFullNameFromLink(offer_link)\n        return self.Replace(offer, path, 'offers', offer_id, None, None)", "response": "Replaces an offer and returns it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread an offer. :param str offer_link: The link to the offer. :return: The read Offer. :rtype: dict", "response": "def ReadOffer(self, offer_link):\n        \"\"\"Reads an offer.\n\n        :param str offer_link:\n            The link to the offer.\n\n        :return:\n            The read Offer.\n        :rtype:\n            dict\n\n        \"\"\"\n        path = base.GetPathFromLink(offer_link)\n        offer_id = base.GetResourceIdOrFullNameFromLink(offer_link)\n        return self.Read(path, 'offers', offer_id, None, {})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetDatabaseAccount(self, url_connection=None):\n        if url_connection is None:\n            url_connection = self.url_connection\n\n        initial_headers = dict(self.default_headers)\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'get',\n                                  '',  # path\n                                  '',  # id\n                                  '',  # type\n                                  {})\n\n        request = request_object._RequestObject('databaseaccount', documents._OperationType.Read, url_connection)\n        result, self.last_response_headers = self.__Get('',\n                                                        request,\n                                                        headers)\n        database_account = documents.DatabaseAccount()\n        database_account.DatabasesLink = '/dbs/'\n        database_account.MediaLink = '/media/'\n        if (http_constants.HttpHeaders.MaxMediaStorageUsageInMB in\n            self.last_response_headers):\n            database_account.MaxMediaStorageUsageInMB = (\n                self.last_response_headers[\n                    http_constants.HttpHeaders.MaxMediaStorageUsageInMB])\n        if (http_constants.HttpHeaders.CurrentMediaStorageUsageInMB in\n            self.last_response_headers):\n            database_account.CurrentMediaStorageUsageInMB = (\n                self.last_response_headers[\n                    http_constants.HttpHeaders.CurrentMediaStorageUsageInMB])\n        database_account.ConsistencyPolicy = result.get(constants._Constants.UserConsistencyPolicy)\n\n        # WritableLocations and ReadableLocations fields will be available only for geo-replicated database accounts\n        if constants._Constants.WritableLocations in result:\n            database_account._WritableLocations = result[constants._Constants.WritableLocations]\n        if constants._Constants.ReadableLocations in result:\n            database_account._ReadableLocations = result[constants._Constants.ReadableLocations]\n        if constants._Constants.EnableMultipleWritableLocations in result:\n            database_account._EnableMultipleWritableLocations = result[constants._Constants.EnableMultipleWritableLocations]\n\n        self._useMultipleWriteLocations = self.connection_policy.UseMultipleWriteLocations and database_account._EnableMultipleWritableLocations\n        return database_account", "response": "Gets the database account info."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Azure Cosmos resource and returns it.", "response": "def Create(self, body, path, type, id, initial_headers, options=None):\n        \"\"\"Creates a Azure Cosmos resource and returns it.\n\n        :param dict body:\n        :param str path:\n        :param str type:\n        :param str id:\n        :param dict initial_headers:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The created Azure Cosmos resource.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        initial_headers = initial_headers or self.default_headers\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'post',\n                                  path,\n                                  id,\n                                  type,\n                                  options)\n        # Create will use WriteEndpoint since it uses POST operation\n\n        request = request_object._RequestObject(type, documents._OperationType.Create)\n        result, self.last_response_headers = self.__Post(path,\n                                                         request,\n                                                         body,\n                                                         headers)\n\n        # update session for write request\n        self._UpdateSessionIfRequired(headers, result, self.last_response_headers)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Upsert(self, body, path, type, id, initial_headers, options=None):\n        if options is None:\n            options = {}\n\n        initial_headers = initial_headers or self.default_headers\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'post',\n                                  path,\n                                  id,\n                                  type,\n                                  options)\n\n        headers[http_constants.HttpHeaders.IsUpsert] = True\n\n        # Upsert will use WriteEndpoint since it uses POST operation\n        request = request_object._RequestObject(type, documents._OperationType.Upsert)\n        result, self.last_response_headers = self.__Post(path,\n                                                         request,\n                                                         body,\n                                                         headers)\n        # update session for write request\n        self._UpdateSessionIfRequired(headers, result, self.last_response_headers)\n        return result", "response": "Upserts a Azure Cosmos resource and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Replace(self, resource, path, type, id, initial_headers, options=None):\n        if options is None:\n            options = {}\n\n        initial_headers = initial_headers or self.default_headers\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'put',\n                                  path,\n                                  id,\n                                  type,\n                                  options)\n        # Replace will use WriteEndpoint since it uses PUT operation\n        request = request_object._RequestObject(type, documents._OperationType.Replace)\n        result, self.last_response_headers = self.__Put(path,\n                                                        request,\n                                                        resource,\n                                                        headers)\n        \n        # update session for request mutates data on server side\n        self._UpdateSessionIfRequired(headers, result, self.last_response_headers)\n        return result", "response": "Replaces a Azure Cosmos resource and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a Azure Cosmos resource and returns it.", "response": "def Read(self, path, type, id, initial_headers, options=None):\n        \"\"\"Reads a Azure Cosmos resource and returns it.\n\n        :param str path:\n        :param str type:\n        :param str id:\n        :param dict initial_headers:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The upserted Azure Cosmos resource.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        initial_headers = initial_headers or self.default_headers\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'get',\n                                  path,\n                                  id,\n                                  type,\n                                  options)\n        # Read will use ReadEndpoint since it uses GET operation\n        request = request_object._RequestObject(type, documents._OperationType.Read)\n        result, self.last_response_headers = self.__Get(path,\n                                                        request,\n                                                        headers)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a Azure Cosmos resource and returns it.", "response": "def DeleteResource(self, path, type, id, initial_headers, options=None):\n        \"\"\"Deletes a Azure Cosmos resource and returns it.\n\n        :param str path:\n        :param str type:\n        :param str id:\n        :param dict initial_headers:\n        :param dict options:\n            The request options for the request.\n\n        :return:\n            The deleted Azure Cosmos resource.\n        :rtype:\n            dict\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        initial_headers = initial_headers or self.default_headers\n        headers = base.GetHeaders(self,\n                                  initial_headers,\n                                  'delete',\n                                  path,\n                                  id,\n                                  type,\n                                  options)\n        # Delete will use WriteEndpoint since it uses DELETE operation\n        request = request_object._RequestObject(type, documents._OperationType.Delete)\n        result, self.last_response_headers = self.__Delete(path,\n                                                           request,\n                                                           headers)\n\n        # update session for request mutates data on server side\n        self._UpdateSessionIfRequired(headers, result, self.last_response_headers)\n\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __Post(self, path, request, body, headers):\n        return synchronized_request.SynchronizedRequest(self,\n                                                        request,\n                                                        self._global_endpoint_manager,\n                                                        self.connection_policy,\n                                                        self._requests_session,\n                                                        'POST',\n                                                        path,\n                                                        body,\n                                                        query_params=None,\n                                                        headers=headers)", "response": "Azure Cosmos POST http request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __Delete(self, path, request, headers):\n        return synchronized_request.SynchronizedRequest(self,\n                                                        request,\n                                                        self._global_endpoint_manager,\n                                                        self.connection_policy,\n                                                        self._requests_session,\n                                                        'DELETE',\n                                                        path,\n                                                        request_data=None,\n                                                        query_params=None,\n                                                        headers=headers)", "response": "Azure Cosmos DELETE http request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef QueryFeed(self, path, collection_id, query, options, partition_key_range_id = None):\n        return self.__QueryFeed(path,\n                                'docs',\n                                collection_id,\n                                lambda r: r['Documents'],\n                                lambda _, b: b,\n                                query,\n                                options,\n                                partition_key_range_id), self.last_response_headers", "response": "Query Feed for Document Collection resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying for more than one Azure Cosmos resource.", "response": "def __QueryFeed(self,\n                    path,\n                    type,\n                    id,\n                    result_fn,\n                    create_fn,\n                    query,\n                    options=None,\n                    partition_key_range_id=None):\n        \"\"\"Query for more than one Azure Cosmos resources.\n\n        :param str path:\n        :param str type:\n        :param str id:\n        :param function result_fn:\n        :param function create_fn:\n        :param (str or dict) query:\n        :param dict options:\n            The request options for the request.\n        :param str partition_key_range_id:\n            Specifies partition key range id.\n\n        :rtype:\n            list\n        \n        :raises SystemError: If the query compatibility mode is undefined.\n\n        \"\"\"\n        if options is None:\n            options = {}\n\n        if query:\n            __GetBodiesFromQueryResult = result_fn\n        else:\n            def __GetBodiesFromQueryResult(result):\n                if result is not None:\n                    return [create_fn(self, body) for body in result_fn(result)]\n                else:\n                    # If there is no change feed, the result data is empty and result is None.\n                    # This case should be interpreted as an empty array.\n                    return []\n\n\n        initial_headers = self.default_headers.copy()\n        # Copy to make sure that default_headers won't be changed.\n        if query is None:\n            # Query operations will use ReadEndpoint even though it uses GET(for feed requests)\n            request = request_object._RequestObject(type, documents._OperationType.ReadFeed)\n            headers = base.GetHeaders(self,\n                                      initial_headers,\n                                      'get',\n                                      path,\n                                      id,\n                                      type,\n                                      options,\n                                      partition_key_range_id)\n            result, self.last_response_headers = self.__Get(path,\n                                                            request,\n                                                            headers)\n            return __GetBodiesFromQueryResult(result)\n        else:\n            query = self.__CheckAndUnifyQueryFormat(query)\n\n            initial_headers[http_constants.HttpHeaders.IsQuery] = 'true'\n            if (self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.Default or\n                    self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.Query):\n                initial_headers[http_constants.HttpHeaders.ContentType] = runtime_constants.MediaTypes.QueryJson\n            elif self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.SqlQuery:\n                initial_headers[http_constants.HttpHeaders.ContentType] = runtime_constants.MediaTypes.SQL\n            else:\n                raise SystemError('Unexpected query compatibility mode.')\n\n            # Query operations will use ReadEndpoint even though it uses POST(for regular query operations)\n            request = request_object._RequestObject(type, documents._OperationType.SqlQuery)\n            headers = base.GetHeaders(self,\n                                      initial_headers,\n                                      'post',\n                                      path,\n                                      id,\n                                      type,\n                                      options,\n                                      partition_key_range_id)\n            result, self.last_response_headers = self.__Post(path,\n                                                             request,\n                                                             query,\n                                                             headers)\n            return __GetBodiesFromQueryResult(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __CheckAndUnifyQueryFormat(self, query_body):\n        if (self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.Default or\n               self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.Query):\n            if not isinstance(query_body, dict) and not isinstance(query_body, six.string_types):\n                raise TypeError('query body must be a dict or string.')\n            if isinstance(query_body, dict) and not query_body.get('query'):\n                raise ValueError('query body must have valid query text with key \"query\".')\n            if isinstance(query_body, six.string_types):\n                return {'query': query_body}\n        elif (self._query_compatibility_mode == CosmosClient._QueryCompatibilityMode.SqlQuery and\n              not isinstance(query_body, six.string_types)):\n            raise TypeError('query body must be a string.')\n        else:\n            raise SystemError('Unexpected query compatibility mode.')\n\n        return query_body", "response": "Checks and unifies the format of the query body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the session if necessary.", "response": "def _UpdateSessionIfRequired(self, request_headers, response_result, response_headers):    \n        \"\"\"\n        Updates session if necessary.\n\n        :param dict response_result:\n        :param dict response_headers:\n        :param dict response_headers\n\n        :return:\n            None, but updates the client session if necessary.\n\n        \"\"\"\n\n        '''if this request was made with consistency level as session, then update\n        the session'''\n\n        if response_result is None or response_headers is None:\n            return\n\n        is_session_consistency = False\n        if http_constants.HttpHeaders.ConsistencyLevel in request_headers:\n            if documents.ConsistencyLevel.Session == request_headers[http_constants.HttpHeaders.ConsistencyLevel]:\n                is_session_consistency = True\n              \n        if is_session_consistency:\n            # update session\n            self.session.update_session(response_result, response_headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetHeaders(cosmos_client,\n               default_headers,\n               verb,\n               path,\n               resource_id,\n               resource_type,\n               options,\n               partition_key_range_id = None):\n    \"\"\"Gets HTTP request headers.\n\n    :param cosmos_client.CosmosClient cosmos_client:\n    :param dict default_headers:\n    :param str verb:\n    :param str path:\n    :param str resource_id:\n    :param str resource_type:\n    :param dict options:\n    :param str partition_key_range_id:\n\n    :return:\n        The HTTP request headers.\n    :rtype: dict\n    \"\"\"\n    headers = dict(default_headers)\n    options = options or {}\n\n    if cosmos_client._useMultipleWriteLocations:\n        headers[http_constants.HttpHeaders.AllowTentativeWrites] = \"true\"\n\n    pre_trigger_include = options.get('preTriggerInclude')\n    if pre_trigger_include:\n        headers[http_constants.HttpHeaders.PreTriggerInclude] = (\n            pre_trigger_include\n            if isinstance(pre_trigger_include, str)\n            else (',').join(pre_trigger_include))\n\n    post_trigger_include = options.get('postTriggerInclude')\n    if post_trigger_include:\n        headers[http_constants.HttpHeaders.PostTriggerInclude] = (\n            post_trigger_include\n            if isinstance(post_trigger_include, str)\n            else (',').join(post_trigger_include))\n\n    if options.get('maxItemCount'):\n        headers[http_constants.HttpHeaders.PageSize] = options['maxItemCount']\n\n    access_condition = options.get('accessCondition')\n    if access_condition:\n        if access_condition['type'] == 'IfMatch':\n            headers[http_constants.HttpHeaders.IfMatch] = access_condition['condition']\n        else:\n            headers[http_constants.HttpHeaders.IfNoneMatch] = access_condition['condition']\n\n    if options.get('indexingDirective'):\n        headers[http_constants.HttpHeaders.IndexingDirective] = (\n            options['indexingDirective'])\n\n    consistency_level = None\n    \n    ''' get default client consistency level'''\n    default_client_consistency_level = headers.get(http_constants.HttpHeaders.ConsistencyLevel)\n\n    ''' set consistency level. check if set via options, this will \n    override the default '''\n    if options.get('consistencyLevel'):\n        consistency_level = options['consistencyLevel']\n        headers[http_constants.HttpHeaders.ConsistencyLevel] = consistency_level\n    elif default_client_consistency_level is not None:\n        consistency_level = default_client_consistency_level\n        headers[http_constants.HttpHeaders.ConsistencyLevel] = consistency_level\n\n    # figure out if consistency level for this request is session\n    is_session_consistency = (consistency_level == documents.ConsistencyLevel.Session)\n\n    # set session token if required\n    if is_session_consistency is True and not IsMasterResource(resource_type):\n        # if there is a token set via option, then use it to override default\n        if options.get('sessionToken'):\n            headers[http_constants.HttpHeaders.SessionToken] = options['sessionToken']\n        else:\n            # check if the client's default consistency is session (and request consistency level is same), \n            # then update from session container\n            if default_client_consistency_level == documents.ConsistencyLevel.Session:\n                # populate session token from the client's session container\n                headers[http_constants.HttpHeaders.SessionToken] = (\n                    cosmos_client.session.get_session_token(path))\n           \n    if options.get('enableScanInQuery'):\n        headers[http_constants.HttpHeaders.EnableScanInQuery] = (\n            options['enableScanInQuery'])\n\n    if options.get('resourceTokenExpirySeconds'):\n        headers[http_constants.HttpHeaders.ResourceTokenExpiry] = (\n            options['resourceTokenExpirySeconds'])\n\n    if options.get('offerType'):\n        headers[http_constants.HttpHeaders.OfferType] = options['offerType']\n\n    if options.get('offerThroughput'):\n        headers[http_constants.HttpHeaders.OfferThroughput] = options['offerThroughput']\n\n    if 'partitionKey' in options:\n        # if partitionKey value is Undefined, serialize it as {} to be consistent with other SDKs\n        if options.get('partitionKey') is documents.Undefined:\n            headers[http_constants.HttpHeaders.PartitionKey] = [{}]\n        # else serialize using json dumps method which apart from regular values will serialize None into null\n        else:\n            headers[http_constants.HttpHeaders.PartitionKey] = json.dumps([options['partitionKey']])\n\n    if options.get('enableCrossPartitionQuery'):\n        headers[http_constants.HttpHeaders.EnableCrossPartitionQuery] = options['enableCrossPartitionQuery']\n\n    if options.get('populateQueryMetrics'):\n        headers[http_constants.HttpHeaders.PopulateQueryMetrics] = options['populateQueryMetrics']\n\n    if cosmos_client.master_key:\n        headers[http_constants.HttpHeaders.XDate] = (\n            datetime.datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT'))\n\n    if cosmos_client.master_key or cosmos_client.resource_tokens:\n        authorization = auth.GetAuthorizationHeader(cosmos_client,\n                                        verb,\n                                        path,\n                                        resource_id,\n                                        IsNameBased(resource_id),\n                                        resource_type,\n                                        headers)\n        # urllib.quote throws when the input parameter is None\n        if authorization:\n            # -_.!~*'() are valid characters in url, and shouldn't be quoted.\n            authorization = urllib_quote(authorization, '-_.!~*\\'()')\n        headers[http_constants.HttpHeaders.Authorization] = authorization\n\n    if verb == 'post' or verb == 'put':\n        if not headers.get(http_constants.HttpHeaders.ContentType):\n            headers[http_constants.HttpHeaders.ContentType] = runtime_constants.MediaTypes.Json\n\n    if not headers.get(http_constants.HttpHeaders.Accept):\n        headers[http_constants.HttpHeaders.Accept] = runtime_constants.MediaTypes.Json\n\n    if partition_key_range_id is not None:\n        headers[http_constants.HttpHeaders.PartitionKeyRangeID] = partition_key_range_id\n\n    if options.get('enableScriptLogging'):\n        headers[http_constants.HttpHeaders.EnableScriptLogging] = options['enableScriptLogging']\n\n    if options.get('offerEnableRUPerMinuteThroughput'):\n        headers[http_constants.HttpHeaders.OfferIsRUPerMinuteThroughputEnabled] = options['offerEnableRUPerMinuteThroughput']\n\n    if options.get('disableRUPerMinuteUsage'):\n        headers[http_constants.HttpHeaders.DisableRUPerMinuteUsage] = options['disableRUPerMinuteUsage']\n\n    if options.get('changeFeed') is True:\n        # On REST level, change feed is using IfNoneMatch/ETag instead of continuation.\n        if_none_match_value = None\n        if options.get('continuation'):\n            if_none_match_value = options['continuation']\n        elif options.get('isStartFromBeginning') and options['isStartFromBeginning'] == False:\n            if_none_match_value = '*'\n        if if_none_match_value:\n            headers[http_constants.HttpHeaders.IfNoneMatch] = if_none_match_value\n        headers[http_constants.HttpHeaders.AIM] = http_constants.HttpHeaders.IncrementalFeedHeaderValue\n    else:\n        if options.get('continuation'):\n            headers[http_constants.HttpHeaders.Continuation] = (options['continuation'])\n\n    if options.get('populatePartitionKeyRangeStatistics'):\n            headers[http_constants.HttpHeaders.PopulatePartitionKeyRangeStatistics] = options['populatePartitionKeyRangeStatistics']\n\n    if options.get('populateQuotaInfo'):\n            headers[http_constants.HttpHeaders.PopulateQuotaInfo] = options['populateQuotaInfo']\n\n    return headers", "response": "Gets HTTP request headers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the resource id or full name from a resource link.", "response": "def GetResourceIdOrFullNameFromLink(resource_link):\n    \"\"\"Gets resource id or full name from resource link.\n\n    :param str resource_link:\n\n    :return:\n        The resource id or full name from the resource link.\n    :rtype: str\n    \"\"\"\n    # For named based, the resource link is the full name\n    if IsNameBased(resource_link):\n        return TrimBeginningAndEndingSlashes(resource_link)\n    \n    # Padding the resource link with leading and trailing slashes if not already\n    if resource_link[-1] != '/':\n        resource_link = resource_link + '/'\n\n    if resource_link[0] != '/':\n        resource_link = '/' + resource_link\n\n    # The path will be in the form of \n    # /[resourceType]/[resourceId]/ .... /[resourceType]/[resourceId]/ or\n    # /[resourceType]/[resourceId]/ .... /[resourceType]/\n    # The result of split will be in the form of\n    # [\"\", [resourceType], [resourceId] ... ,[resourceType], [resourceId], \"\"]\n    # In the first case, to extract the resourceId it will the element\n    # before last ( at length -2 ) and the the type will before it\n    # ( at length -3 )\n    # In the second case, to extract the resource type it will the element\n    # before last ( at length -2 )\n    path_parts = resource_link.split(\"/\")\n    if len(path_parts) % 2 == 0:\n        # request in form\n        # /[resourceType]/[resourceId]/ .... /[resourceType]/[resourceId]/.\n        return str(path_parts[-2])\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetAttachmentIdFromMediaId(media_id):\n    altchars = '+-'\n    if not six.PY2:\n        altchars = altchars.encode('utf-8')\n    # altchars for '+' and '/'. We keep '+' but replace '/' with '-'\n    buffer = base64.b64decode(str(media_id), altchars)\n    resoure_id_length = 20\n    attachment_id = ''\n    if len(buffer) > resoure_id_length:\n        # We are cutting off the storage index.\n        attachment_id = base64.b64encode(buffer[0:resoure_id_length], altchars)\n        if not six.PY2:\n            attachment_id = attachment_id.decode('utf-8')\n    else:\n        attachment_id = media_id\n\n    return attachment_id", "response": "Gets the attachment id from the media id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetPathFromLink(resource_link, resource_type=''):\n    resource_link = TrimBeginningAndEndingSlashes(resource_link)\n        \n    if IsNameBased(resource_link):\n        # Replace special characters in string using the %xx escape. For example, space(' ') would be replaced by %20\n        # This function is intended for quoting the path section of the URL and excludes '/' to be quoted as that's the default safe char\n        resource_link = urllib_quote(resource_link)\n        \n    # Padding leading and trailing slashes to the path returned both for name based and resource id based links\n    if resource_type:\n        return '/' + resource_link + '/' + resource_type + '/'\n    else:\n        return '/' + resource_link + '/'", "response": "Gets the path from a resource link with optional resource type appended."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef IsNameBased(link):\n    if not link:\n        return False\n\n    # trimming the leading \"/\"\n    if link.startswith('/') and len(link) > 1:\n        link = link[1:]\n\n    # Splitting the link(separated by \"/\") into parts \n    parts = link.split('/')\n\n    # First part should be \"dbs\" \n    if len(parts) == 0 or not parts[0] or not parts[0].lower() == 'dbs':\n        return False\n\n    # The second part is the database id(ResourceID or Name) and cannot be empty\n    if len(parts) < 2 or not parts[1]:\n    \treturn False\n\n    # Either ResourceID or database name\n    databaseID = parts[1]\n    \t\n    # Length of databaseID(in case of ResourceID) is always 8\n    if len(databaseID) != 8:\n        return True\n\n    return not IsValidBase64String(str(databaseID))", "response": "Returns True if the link is name - based ; otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the link is a database Self Link or a database ID based link.", "response": "def IsDatabaseLink(link):\n    \"\"\"Finds whether the link is a database Self Link or a database ID based link\n\n    :param str link:\n        Link to analyze\n\n    :return:\n        True or False.\n    :rtype: boolean\n    \"\"\"\n    if not link:\n        return False\n\n    # trimming the leading and trailing \"/\" from the input string\n    link = TrimBeginningAndEndingSlashes(link)\n\n    # Splitting the link(separated by \"/\") into parts \n    parts = link.split('/')\n\n    if len(parts) != 2:\n    \treturn False\n\n    # First part should be \"dbs\" \n    if not parts[0] or not parts[0].lower() == 'dbs':\n        return False\n\n    # The second part is the database id(ResourceID or Name) and cannot be empty\n    if not parts[1]:\n    \treturn False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive the self link and alt_content_path from the reponse header and result extract the collection name and collection id Ever response header has alt-content-path that is the owner's path in ascii. For document create / update requests, this can be used to get the collection name, but for collection create response, we can't use it. So we also rely on :param str self_link: Self link of the resource, as obtained from response result. :param str alt_content_path: Owner path of the resource, as obtained from response header. :param str resource_id: 'id' as returned from the response result. This is only used if it is deduced that the request was to create a collection. :return: tuple of (collection rid, collection name) :rtype: tuple", "response": "def GetItemContainerInfo(self_link, alt_content_path, id_from_response):\n    \"\"\" Given the self link and alt_content_path from the reponse header and result\n        extract the collection name and collection id\n\n        Ever response header has alt-content-path that is the \n        owner's path in ascii. For document create / update requests, this can be used\n        to get the collection name, but for collection create response, we can't use it.\n        So we also rely on  \n\n    :param str self_link:\n        Self link of the resource, as obtained from response result.\n    :param str alt_content_path:\n        Owner path of the resource, as obtained from response header.\n    :param str resource_id:\n        'id' as returned from the response result. This is only used if it is deduced that the\n         request was to create a collection.\n\n    :return:\n        tuple of (collection rid, collection name)\n    :rtype: tuple\n    \"\"\" \n\n    self_link = TrimBeginningAndEndingSlashes(self_link) + '/'\n\n    index = IndexOfNth(self_link, '/', 4)\n\n    if index != -1:\n        collection_id = self_link[0:index]\n\n        if 'colls' in self_link:\n            # this is a collection request\n            index_second_slash = IndexOfNth(alt_content_path, '/', 2)\n            if index_second_slash == -1:\n                collection_name = alt_content_path + '/colls/' + urllib_quote(id_from_response)\n                return collection_id, collection_name\n            else:\n                collection_name = alt_content_path\n                return collection_id, collection_name\n        else:\n            raise ValueError('Response Not from Server Partition, self_link: {0}, alt_content_path: {1}, id: {2}'\n                .format(self_link, alt_content_path, id_from_response))\n    else:\n        raise ValueError('Unable to parse document collection link from ' + self_link)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the document collection link.", "response": "def GetItemContainerLink(link):\n    \"\"\"Gets the document collection link\n\n    :param str link:\n        Resource link\n\n    :return:\n        Document collection link.\n    :rtype: str\n\n    \"\"\"\n    link = TrimBeginningAndEndingSlashes(link) + '/'\n\n    index = IndexOfNth(link, '/', 4)\n    \n    if index != -1:\n        return link[0:index]\n    else:\n        raise ValueError('Unable to parse document collection link from ' + link)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the index of the nth occurrence of a given character in a string.", "response": "def IndexOfNth(s, value, n):\n    \"\"\"Gets the index of Nth occurance of a given character in a string\n\n    :param str s:\n        Input string\n    :param char value:\n        Input char to be searched.\n    :param int n:\n        Nth occurrence of char to be searched.\n\n    :return:\n        Index of the Nth occurrence in the string.\n    :rtype: int\n\n    \"\"\"\n    remaining = n\n    for i in xrange(0, len(s)):\n        if s[i] == value:\n            remaining -= 1\n            if remaining == 0:\n                return i\n    return -1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef IsValidBase64String(string_to_validate):\n    # '-' is not supported char for decoding in Python(same as C# and Java) which has similar logic while parsing ResourceID generated by backend\n    try:\n        buffer = base64.standard_b64decode(string_to_validate.replace('-', '/'))\n        if len(buffer) != 4:\n            return False\n    except Exception as e:\n        if six.PY2:\n            e = e.message\n        if type(e) == binascii.Error:\n            return False\n        else:\n            raise e\n    return True", "response": "Verifies if a string is a valid Base64 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrimming beginning and ending slashes in a path.", "response": "def TrimBeginningAndEndingSlashes(path):\n    \"\"\"Trims beginning and ending slashes\n\n    :param str path:\n\n    :return:\n        Path with beginning and ending slashes trimmed.\n    :rtype: str\n    \"\"\"\n    if path.startswith('/'):\n        # Returns substring starting from index 1 to end of the string\n        path = path[1:]\n\n    if path.endswith('/'):\n        # Returns substring starting from beginning to last but one char in the string\n        path = path[:-1]\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets request body from data.", "response": "def _RequestBodyFromData(data):\n    \"\"\"Gets request body from data.\n\n    When `data` is dict and list into unicode string; otherwise return `data`\n    without making any change.\n\n    :param (str, unicode, file-like stream object, dict, list or None) data:\n\n    :rtype:\n        str, unicode, file-like stream object, or None\n\n    \"\"\"\n    if isinstance(data, six.string_types) or _IsReadableStream(data):\n        return data\n    elif isinstance(data, (dict, list, tuple)):\n        \n        json_dumped = json.dumps(data, separators=(',',':'))\n\n        if six.PY2:\n            return json_dumped.decode('utf-8')\n        else:\n            return json_dumped\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Request(global_endpoint_manager, request, connection_policy, requests_session, path, request_options, request_body):\n    is_media = request_options['path'].find('media') > -1\n    is_media_stream = is_media and connection_policy.MediaReadMode == documents.MediaReadMode.Streamed\n\n    connection_timeout = (connection_policy.MediaRequestTimeout\n                          if is_media\n                          else connection_policy.RequestTimeout)\n\n    # Every request tries to perform a refresh\n    global_endpoint_manager.refresh_endpoint_list(None)\n\n    if (request.endpoint_override):\n        base_url = request.endpoint_override\n    else:\n        base_url = global_endpoint_manager.resolve_service_endpoint(request)\n\n    if path:\n        resource_url = base_url + path\n    else:\n        resource_url = base_url\n\n    parse_result = urlparse(resource_url)\n\n    # The requests library now expects header values to be strings only starting 2.11, \n    # and will raise an error on validation if they are not, so casting all header values to strings.\n    request_options['headers'] = { header: str(value) for header, value in request_options['headers'].items() } \n\n    # We are disabling the SSL verification for local emulator(localhost/127.0.0.1) or if the user\n    # has explicitly specified to disable SSL verification.\n    is_ssl_enabled = (parse_result.hostname != 'localhost' and parse_result.hostname != '127.0.0.1' and not connection_policy.DisableSSLVerification)\n    \n    if connection_policy.SSLConfiguration:\n        ca_certs = connection_policy.SSLConfiguration.SSLCaCerts\n        cert_files = (connection_policy.SSLConfiguration.SSLCertFile, connection_policy.SSLConfiguration.SSLKeyFile)\n\n        response = requests_session.request(request_options['method'], \n                                resource_url, \n                                data = request_body, \n                                headers = request_options['headers'],\n                                timeout = connection_timeout / 1000.0,\n                                stream = is_media_stream,\n                                verify = ca_certs,\n                                cert = cert_files)\n    else:\n        response = requests_session.request(request_options['method'], \n                                    resource_url, \n                                    data = request_body, \n                                    headers = request_options['headers'],\n                                    timeout = connection_timeout / 1000.0,\n                                    stream = is_media_stream,\n                                    # If SSL is disabled, verify = false\n                                    verify = is_ssl_enabled)\n\n    headers = dict(response.headers)\n\n    # In case of media stream response, return the response to the user and the user\n    # will need to handle reading the response.\n    if is_media_stream:\n        return (response.raw, headers)\n\n    data = response.content\n    if not six.PY2:\n        # python 3 compatible: convert data from byte to unicode string\n        data = data.decode('utf-8')\n\n    if response.status_code >= 400:\n        raise errors.HTTPFailure(response.status_code, data, headers)\n\n    result = None\n    if is_media:\n        result = data\n    else:\n        if len(data) > 0:\n            try:\n                result = json.loads(data)\n            except:\n                raise errors.JSONParseFailure(data)\n\n    return (result, headers)", "response": "Makes one http request using the requests module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming one synchronized http request according to the parameters.", "response": "def SynchronizedRequest(client,\n                        request,\n                        global_endpoint_manager,\n                        connection_policy,\n                        requests_session,\n                        method,\n                        path,\n                        request_data,\n                        query_params,\n                        headers):\n    \"\"\"Performs one synchronized http request according to the parameters.\n\n    :param object client:\n        Document client instance\n    :param dict request:\n    :param _GlobalEndpointManager global_endpoint_manager: \n    :param  documents.ConnectionPolicy connection_policy:\n    :param requests.Session requests_session:\n        Session object in requests module\n    :param str method:\n    :param str path:\n    :param (str, unicode, file-like stream object, dict, list or None) request_data:\n    :param dict query_params:\n    :param dict headers:\n\n    :return:\n        tuple of (result, headers)\n    :rtype:\n        tuple of (dict dict)\n\n    \"\"\"\n    request_body = None\n    if request_data:\n        request_body = _RequestBodyFromData(request_data)\n        if not request_body:\n           raise errors.UnexpectedDataType(\n               'parameter data must be a JSON object, string or' +\n               ' readable stream.')\n\n    request_options = {}\n    request_options['path'] = path\n    request_options['method'] = method\n    if query_params:\n        request_options['path'] += '?' + urlencode(query_params)\n\n    request_options['headers'] = headers\n    if request_body and (type(request_body) is str or\n                         type(request_body) is six.text_type):\n        request_options['headers'][http_constants.HttpHeaders.ContentLength] = (\n            len(request_body))\n    elif request_body is None:\n        request_options['headers'][http_constants.HttpHeaders.ContentLength] = 0\n\n    # Pass _Request function with it's parameters to retry_utility's Execute method that wraps the call with retries\n    return retry_utility._Execute(client, global_endpoint_manager, _Request, request, connection_policy, requests_session, path, request_options, request_body)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the range containing the given partition key value.", "response": "def get_range_by_effective_partition_key(self, effective_partition_key_value):\n        \"\"\"Gets the range containing the given partition key\n\n        :param str effective_partition_key_value:\n            The partition key value.\n        :return:\n            The partition key range.\n        :rtype: dict\n        \"\"\"\n        if _CollectionRoutingMap.MinimumInclusiveEffectivePartitionKey == effective_partition_key_value:\n            return self._orderedPartitionKeyRanges[0]\n        \n        if _CollectionRoutingMap.MaximumExclusiveEffectivePartitionKey == effective_partition_key_value:\n            return None\n        \n        sortedLow = [(r.min, not r.isMinInclusive) for r in self._orderedRanges]\n\n        index = bisect.bisect_right(sortedLow, (effective_partition_key_value, True))\n        if (index > 0):\n            index = index -1\n        return self._orderedPartitionKeyRanges[index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_range_by_partition_key_range_id(self, partition_key_range_id):\n        t = self._rangeById.get(partition_key_range_id)\n\n        if t is None:\n            return None\n        return t[0]", "response": "Gets the partition key range given the partition key range id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_overlapping_ranges(self, provided_partition_key_ranges):\n\n        if isinstance(provided_partition_key_ranges, routing_range._Range):\n            return self.get_overlapping_ranges([provided_partition_key_ranges])\n\n        minToPartitionRange = {}\n\n        sortedLow = [(r.min, not r.isMinInclusive) for r in self._orderedRanges]\n        sortedHigh = [(r.max, r.isMaxInclusive) for r in self._orderedRanges]\n\n        for providedRange in provided_partition_key_ranges:\n            minIndex = bisect.bisect_right(sortedLow, (providedRange.min, not providedRange.isMinInclusive))\n            if minIndex > 0: minIndex = minIndex - 1\n                \n            maxIndex = bisect.bisect_left(sortedHigh, (providedRange.max, providedRange.isMaxInclusive))\n            if maxIndex >= len(sortedHigh):\n                maxIndex = maxIndex - 1\n            \n            for i in xrange(minIndex, maxIndex + 1):\n                if routing_range._Range.overlaps(self._orderedRanges[i], providedRange):\n                    minToPartitionRange[self._orderedPartitionKeyRanges[i][_PartitionKeyRange.MinInclusive]] = self._orderedPartitionKeyRanges[i]\n\n\n        overlapping_partition_key_ranges = list(minToPartitionRange.values())\n\n        def getKey(r):\n            return r[_PartitionKeyRange.MinInclusive]\n        overlapping_partition_key_ranges.sort(key = getKey)\n        return overlapping_partition_key_ranges", "response": "Returns the partition key ranges overlapping the provided ranges."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the authorization header.", "response": "def GetAuthorizationHeader(cosmos_client,\n                           verb,\n                           path,\n                           resource_id_or_fullname,\n                           is_name_based,\n                           resource_type,\n                           headers):\n    \"\"\"Gets the authorization header.\n\n    :param cosmos_client.CosmosClient cosmos_client:\n    :param str verb:\n    :param str path:\n    :param str resource_id_or_fullname:\n    :param str resource_type:\n    :param dict headers:\n\n    :return:\n        The authorization headers.\n    :rtype: dict\n    \"\"\"\n    # In the AuthorizationToken generation logic, lower casing of ResourceID is required as rest of the fields are lower cased\n    # Lower casing should not be done for named based \"ID\", which should be used as is\n    if resource_id_or_fullname is not None and not is_name_based:\n        resource_id_or_fullname = resource_id_or_fullname.lower()\n\n    if cosmos_client.master_key:\n        return __GetAuthorizationTokenUsingMasterKey(verb,\n                                                    resource_id_or_fullname,\n                                                    resource_type,\n                                                    headers,\n                                                    cosmos_client.master_key)\n    elif cosmos_client.resource_tokens:\n        return __GetAuthorizationTokenUsingResourceTokens(\n            cosmos_client.resource_tokens, path, resource_id_or_fullname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __GetAuthorizationTokenUsingMasterKey(verb,\n                                         resource_id_or_fullname,\n                                         resource_type,\n                                         headers,\n                                         master_key):\n    \"\"\"Gets the authorization token using `master_key.\n\n    :param str verb:\n    :param str resource_id_or_fullname:\n    :param str resource_type:\n    :param dict headers:\n    :param str master_key:\n\n    :return:\n        The authorization token.\n    :rtype: dict\n\n    \"\"\"\n\n\n    # decodes the master key which is encoded in base64    \n    key = base64.b64decode(master_key)\n    \n    # Skipping lower casing of resource_id_or_fullname since it may now contain \"ID\" of the resource as part of the fullname\n    text = '{verb}\\n{resource_type}\\n{resource_id_or_fullname}\\n{x_date}\\n{http_date}\\n'.format(\n        verb=(verb.lower() or ''),\n        resource_type=(resource_type.lower() or ''),\n        resource_id_or_fullname=(resource_id_or_fullname or ''),\n        x_date=headers.get(http_constants.HttpHeaders.XDate, '').lower(),\n        http_date=headers.get(http_constants.HttpHeaders.HttpDate, '').lower())\n   \n    if six.PY2:\n        body = text.decode('utf-8')\n        digest = hmac.new(key, body, sha256).digest()\n        signature = digest.encode('base64')\n    else:\n        # python 3 support\n        body = text.encode('utf-8')\n        digest = hmac.new(key, body, sha256).digest()\n        signature = base64.encodebytes(digest).decode('utf-8')\n\n    master_token = 'master'\n    token_version = '1.0'\n    return  'type={type}&ver={ver}&sig={sig}'.format(type=master_token,\n                                                    ver=token_version,\n                                                    sig=signature[:-1])", "response": "Gets the authorization token using master_key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __GetAuthorizationTokenUsingResourceTokens(resource_tokens,\n                                              path,\n                                              resource_id_or_fullname):\n    \"\"\"Get the authorization token using `resource_tokens`.\n\n    :param dict resource_tokens:\n    :param str path:\n    :param str resource_id_or_fullname:\n\n    :return:\n        The authorization token.\n    :rtype: dict\n\n    \"\"\"\n    if resource_tokens and len(resource_tokens) > 0:\n        # For database account access(through GetDatabaseAccount API), path and resource_id_or_fullname are '', \n        # so in this case we return the first token to be used for creating the auth header as the service will accept any token in this case\n        if not path and not resource_id_or_fullname:\n            return next(six.itervalues(resource_tokens))\n\n        if resource_tokens.get(resource_id_or_fullname):\n            return resource_tokens[resource_id_or_fullname]\n        else:\n            path_parts = []\n            if path:\n                path_parts = path.split('/')\n            resource_types = ['dbs', 'colls', 'docs', 'sprocs', 'udfs', 'triggers',\n                              'users', 'permissions', 'attachments', 'media',\n                              'conflicts', 'offers']\n            # Get the last resource id or resource name from the path and get it's token from resource_tokens\n            for one_part in reversed(path_parts):\n                if not one_part in resource_types and one_part in resource_tokens:\n                    return resource_tokens[one_part]\n    return None", "response": "Get the authorization token using resource_tokens."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_Container(client, id):\n\n        print(\"\\n2.1 Create Collection - Basic\")\n        \n        try:\n            client.CreateContainer(database_link, {\"id\": id})\n            print('Collection with id \\'{0}\\' created'.format(id))\n\n        except errors.HTTPFailure as e:\n            if e.status_code == 409:\n               print('A collection with id \\'{0}\\' already exists'.format(id))\n            else: \n                raise errors.HTTPFailure(e.status_code)               \n\n        print(\"\\n2.2 Create Collection - With custom index policy\")\n        \n        try:\n            coll = {\n                \"id\": \"collection_custom_index_policy\",\n                \"indexingPolicy\": {\n                    \"indexingMode\": \"lazy\",\n                    \"automatic\": False\n                }\n            }\n\n            collection = client.CreateContainer(database_link, coll)\n            print('Collection with id \\'{0}\\' created'.format(collection['id']))\n            print('IndexPolicy Mode - \\'{0}\\''.format(collection['indexingPolicy']['indexingMode']))\n            print('IndexPolicy Automatic - \\'{0}\\''.format(collection['indexingPolicy']['automatic']))\n            \n        except errors.CosmosError as e:\n            if e.status_code == 409:\n               print('A collection with id \\'{0}\\' already exists'.format(collection['id']))\n            else: \n                raise errors.HTTPFailure(e.status_code) \n\n        print(\"\\n2.3 Create Collection - With custom offer throughput\")\n\n        try:\n            coll = {\"id\": \"collection_custom_throughput\"}\n            collection_options = { 'offerThroughput': 400 }\n            collection = client.CreateContainer(database_link, coll, collection_options )\n            print('Collection with id \\'{0}\\' created'.format(collection['id']))\n            \n        except errors.HTTPFailure as e:\n            if e.status_code == 409:\n               print('A collection with id \\'{0}\\' already exists'.format(collection['id']))\n            else: \n                raise errors.HTTPFailure(e.status_code)\n\n        print(\"\\n2.4 Create Collection - With Unique keys\")\n\n        try:\n            coll = {\"id\": \"collection_unique_keys\", 'uniqueKeyPolicy': {'uniqueKeys': [{'paths': ['/field1/field2', '/field3']}]}}\n            collection_options = { 'offerThroughput': 400 }\n            collection = client.CreateContainer(database_link, coll, collection_options )\n            unique_key_paths = collection['uniqueKeyPolicy']['uniqueKeys'][0]['paths']\n            print('Collection with id \\'{0}\\' created'.format(collection['id']))\n            print('Unique Key Paths - \\'{0}\\', \\'{1}\\''.format(unique_key_paths[0], unique_key_paths[1]))\n            \n        except errors.HTTPFailure as e:\n            if e.status_code == 409:\n               print('A collection with id \\'{0}\\' already exists'.format(collection['id']))\n            else: \n                raise errors.HTTPFailure(e.status_code)\n\n        print(\"\\n2.5 Create Collection - With Partition key\")\n        \n        try:\n            coll = {\n                \"id\": \"collection_partition_key\",\n                \"partitionKey\": {\n                    \"paths\": [\n                      \"/field1\"\n                    ],\n                    \"kind\": \"Hash\"\n                }\n            }\n\n            collection = client.CreateContainer(database_link, coll)\n            print('Collection with id \\'{0}\\' created'.format(collection['id']))\n            \n        except errors.CosmosError as e:\n            if e.status_code == 409:\n               print('A collection with id \\'{0}\\' already exists'.format(collection['id']))\n            else: \n                raise errors.HTTPFailure(e.status_code)", "response": "Execute the most basic Create of collection. This will create a collection with 400 RUs throughput and default indexing policy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_session_token(self, resource_path):\n\n        with self.session_lock:\n            is_name_based = base.IsNameBased(resource_path)\n            collection_rid = ''\n            session_token = ''\n\n            try:\n                if is_name_based:\n                    # get the collection name\n                    collection_name = base.GetItemContainerLink(resource_path)\n                    collection_rid = self.collection_name_to_rid[collection_name]\n                else:\n                    collection_rid = base.GetItemContainerLink(resource_path)\n\n                if collection_rid in self.rid_to_session_token:\n                    token_dict = self.rid_to_session_token[collection_rid]\n                    session_token_list = []\n                    for key in token_dict.keys():\n                        session_token_list.append(\"{0}:{1}\".format(key, token_dict[key].convert_to_string()))\n                    session_token = ','.join(session_token_list)\n                    return session_token\n                else:\n                    # return empty token if not found \n                    return ''\n            except: \n                return ''", "response": "Get the session token for the resource_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the session token for the item in the item container.", "response": "def set_session_token(self, response_result, response_headers):\n        \"\"\" \n        Session token must only be updated from response of requests that successfully mutate resource on the \n        server side (write, replace, delete etc) \n        \n        :param dict response_result:\n        :param dict response_headers:\n\n        :return:\n            - None\n        \"\"\"\n\n        ''' there are two pieces of information that we need to update session token- \n        self link which has the rid representation of the resource, and\n        x-ms-alt-content-path which is the string representation of the resource'''\n\n        with self.session_lock:\n            collection_rid = ''\n            collection_name = ''\n\n            try:\n                self_link = response_result['_self']\n\n                ''' extract alternate content path from the response_headers \n                (only document level resource updates will have this), \n                and if not present, then we can assume that we don't have to update\n                session token for this request'''\n                alt_content_path = ''\n                alt_content_path_key = http_constants.HttpHeaders.AlternateContentPath\n                response_result_id_key = u'id'\n                response_result_id = None\n                if alt_content_path_key in response_headers:\n                    alt_content_path = response_headers[http_constants.HttpHeaders.AlternateContentPath]\n                    response_result_id = response_result[response_result_id_key]\n                else:\n                    return\n                collection_rid, collection_name = base.GetItemContainerInfo(self_link, alt_content_path, response_result_id)\n         \n            except ValueError:\n                return\n            except:\n                exc_type, exc_value, exc_traceback = sys.exc_info()\n                traceback.print_exception(exc_type, exc_value, exc_traceback,\n                                  limit=2, file=sys.stdout)\n                return\n\n            if collection_name in self.collection_name_to_rid:\n                ''' check if the rid for the collection name has changed\n                this means that potentially, the collection was deleted\n                and recreated\n                '''\n                existing_rid = self.collection_name_to_rid[collection_name]\n                if (collection_rid != existing_rid):\n                    ''' flush the session tokens for the old rid, and \n                    update the new rid into the collection name to rid map.\n                    '''\n                    self.rid_to_session_token[existing_rid] = {}\n                    self.collection_name_to_rid[collection_name] = collection_rid\n\n            # parse session token\n            parsed_tokens = self.parse_session_token(response_headers)\n\n            # update session token in collection rid to session token map\n            if collection_rid in self.rid_to_session_token:\n                ''' we need to update the session tokens for 'this' collection\n                '''\n                for id in parsed_tokens:\n                    old_session_token = self.rid_to_session_token[collection_rid][id] if id in self.rid_to_session_token[collection_rid] else None\n                    if not old_session_token:\n                        self.rid_to_session_token[collection_rid][id] = parsed_tokens[id]\n                    else:\n                        self.rid_to_session_token[collection_rid][id] = parsed_tokens[id].merge(old_session_token)\n                    self.collection_name_to_rid[collection_name] = collection_rid\n            else:\n                self.rid_to_session_token[collection_rid] = parsed_tokens\n                self.collection_name_to_rid[collection_name] = collection_rid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting session token from response headers and parses them into a dictionary of partition id to session lsn for given collection", "response": "def parse_session_token(response_headers):\n        \"\"\" Extracts session token from response headers and parses\n\n        :param dict response_headers:\n\n        :return:\n            A dictionary of partition id to session lsn\n            for given collection \n        :rtype: dict    \n        \"\"\"\n\n        # extract session token from response header\n        session_token = ''\n        if http_constants.HttpHeaders.SessionToken in response_headers:\n                session_token = response_headers[http_constants.HttpHeaders.SessionToken]\n\n        id_to_sessionlsn = {}\n        if session_token is not '':\n            ''' extract id, lsn from the token. For p-collection,\n            the token will be a concatenation of pairs for each collection'''\n            token_pairs = session_token.split(',')\n            for token_pair in token_pairs:\n                tokens = token_pair.split(':')\n                if (len(tokens) == 2):\n                    id = tokens[0]\n                    sessionToken = VectorSessionToken.create(tokens[1])\n                    if sessionToken is None:\n                        raise HTTPFailure(http_constants.StatusCodes.INTERNAL_SERVER_ERROR, \"Could not parse the received session token: %s\" % tokens[1])\n                    id_to_sessionlsn[id] = sessionToken\n        return id_to_sessionlsn"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates color stops array for use with match expression in mapbox template", "response": "def generate_vector_color_map(self):\n        \"\"\"Generate color stops array for use with match expression in mapbox template\"\"\"\n        vector_stops = []\n\n        # if join data specified as filename or URL, parse JSON to list of Python dicts\n        if type(self.data) == str:\n            self.data = geojson_to_dict_list(self.data)\n\n        # loop through features in self.data to create join-data map\n        for row in self.data:\n            \n            # map color to JSON feature using color_property\n            color = color_map(row[self.color_property], self.color_stops, self.color_default)\n\n            # link to vector feature using data_join_property (from JSON object)\n            vector_stops.append([row[self.data_join_property], color])\n\n        return vector_stops"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_vector_numeric_map(self, numeric_property):\n        vector_stops = []\n        \n        function_type = getattr(self, '{}_function_type'.format(numeric_property))\n        lookup_property = getattr(self, '{}_property'.format(numeric_property))\n        numeric_stops = getattr(self, '{}_stops'.format(numeric_property))\n        default = getattr(self, '{}_default'.format(numeric_property))\n\n        if function_type == 'match':\n            match_width = numeric_stops\n\n        # if join data specified as filename or URL, parse JSON to list of Python dicts\n        if type(self.data) == str:\n            self.data = geojson_to_dict_list(self.data)\n\n        for row in self.data:\n\n            # map value to JSON feature using the numeric property\n            value = numeric_map(row[lookup_property], numeric_stops, default)\n            \n            # link to vector feature using data_join_property (from JSON object)\n            vector_stops.append([row[self.data_join_property], value])\n\n        return vector_stops", "response": "Generate array of stops for use with match expression in mapbox template"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if features are defined as vector source based on MapViz arguments.", "response": "def check_vector_template(self):\n        \"\"\"Determines if features are defined as vector source based on MapViz arguments.\"\"\"\n\n        if self.vector_url is not None and self.vector_layer_name is not None:\n            self.template = 'vector_' + self.template\n            self.vector_source = True\n        else:\n            self.vector_source = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_iframe(self, html_data):\n\n        srcdoc = html_data.replace('\"', \"'\")\n        return ('<iframe id=\"{div_id}\", srcdoc=\"{srcdoc}\" style=\"width: {width}; '\n                'height: {height};\"></iframe>'.format(\n                    div_id=self.div_id,\n                    srcdoc=srcdoc,\n                    width=self.width,\n                    height=self.height))", "response": "Build the HTML representation for the mapviz."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_html(self, filename=None):\n        \n        if isinstance(self.style, str):\n            style = \"'{}'\".format(self.style)\n        else:\n            style = self.style\n        \n        options = dict(\n            gl_js_version=GL_JS_VERSION,\n            accessToken=self.access_token,\n            div_id=self.div_id,\n            style=style,\n            center=list(self.center),\n            zoom=self.zoom,\n            geojson_data=json.dumps(self.data, ensure_ascii=False),\n            belowLayer=self.below_layer,\n            opacity=self.opacity,\n            minzoom=self.min_zoom,\n            maxzoom=self.max_zoom,\n            pitch=self.pitch, \n            bearing=self.bearing,\n            boxZoomOn=json.dumps(self.box_zoom_on),\n            doubleClickZoomOn=json.dumps(self.double_click_zoom_on),\n            scrollZoomOn=json.dumps(self.scroll_zoom_on),\n            touchZoomOn=json.dumps(self.touch_zoom_on),\n            popupOpensOnHover=self.popup_open_action=='hover',\n            includeSnapshotLinks=self.add_snapshot_links,\n            preserveDrawingBuffer=json.dumps(self.add_snapshot_links),\n            showScale=self.scale,\n            scaleUnits=self.scale_unit_system,\n            scaleBorderColor=self.scale_border_color,\n            scalePosition=self.scale_position,\n            scaleFillColor=self.scale_background_color,\n            scaleTextColor=self.scale_text_color,\n        )\n\n        if self.legend:\n\n            if all([self.legend, self.legend_gradient, self.legend_function == 'radius']):\n                raise LegendError(' '.join(['Gradient legend format not compatible with a variable radius legend.',\n                                            'Please either change `legend_gradient` to False or `legend_function` to \"color\".']))\n\n            options.update(\n                showLegend=self.legend,\n                legendLayout=self.legend_layout,\n                legendFunction=self.legend_function,\n                legendStyle=self.legend_style, # reserve for custom CSS\n                legendGradient=json.dumps(self.legend_gradient),\n                legendFill=self.legend_fill,\n                legendHeaderFill=self.legend_header_fill,\n                legendTextColor=self.legend_text_color,\n                legendNumericPrecision=json.dumps(self.legend_text_numeric_precision),\n                legendTitleHaloColor=self.legend_title_halo_color,\n                legendKeyShape=self.legend_key_shape,\n                legendKeyBordersOn=json.dumps(self.legend_key_borders_on)\n            )\n\n        if self.vector_source:\n            options.update(\n                vectorUrl=self.vector_url,\n                vectorLayer=self.vector_layer_name,\n                vectorJoinDataProperty=self.vector_join_property,\n                joinData=json.dumps(False),\n                dataJoinProperty=self.data_join_property,\n                enableDataJoin=not self.disable_data_join\n            )\n            data = geojson_to_dict_list(self.data)\n            if bool(data):\n                options.update(joinData=json.dumps(data, ensure_ascii=False))\n\n        if self.label_property is None:\n            options.update(labelProperty=None)\n        else:\n            options.update(labelProperty='{' + self.label_property + '}')\n        \n        options.update(\n            labelColor=self.label_color,\n            labelSize=self.label_size,\n            labelHaloColor=self.label_halo_color,\n            labelHaloWidth=self.label_halo_width\n        )\n\n        self.add_unique_template_variables(options)\n\n        if filename:\n            html = templates.format(self.template, **options)\n            with codecs.open(filename, \"w\", \"utf-8-sig\") as f:\n                f.write(html)\n            return None\n        else:\n            return templates.format(self.template, **options)", "response": "Create a circle visual from a geojson data source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate map template variables specific to circle visual", "response": "def add_unique_template_variables(self, options):\n        \"\"\"Update map template variables specific to circle visual\"\"\"\n        options.update(dict(\n            geojson_data=json.dumps(self.data, ensure_ascii=False),\n            colorProperty=self.color_property,\n            colorType=self.color_function_type,\n            colorStops=self.color_stops,\n            strokeWidth=self.stroke_width,\n            strokeColor=self.stroke_color,\n            radius=self.radius,\n            defaultColor=self.color_default,\n            highlightColor=self.highlight_color\n        ))\n\n        if self.vector_source:\n            options.update(vectorColorStops=self.generate_vector_color_map())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate map template variables specific to graduated circle visual", "response": "def add_unique_template_variables(self, options):\n        \"\"\"Update map template variables specific to graduated circle visual\"\"\"\n        options.update(dict(\n            colorProperty=self.color_property,\n            colorStops=self.color_stops,\n            colorType=self.color_function_type,\n            radiusType=self.radius_function_type,\n            defaultColor=self.color_default,\n            defaultRadius=self.radius_default,\n            radiusProperty=self.radius_property,\n            radiusStops=self.radius_stops,\n            strokeWidth=self.stroke_width,\n            strokeColor=self.stroke_color,\n            highlightColor=self.highlight_color\n        ))\n        if self.vector_source:\n            options.update(dict(\n                vectorColorStops=self.generate_vector_color_map(),\n                vectorRadiusStops=self.generate_vector_numeric_map('radius')))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate map template variables specific to heatmap visual", "response": "def add_unique_template_variables(self, options):\n        \"\"\"Update map template variables specific to heatmap visual\"\"\"\n        options.update(dict(\n            colorStops=self.color_stops,\n            radiusStops=self.radius_stops,\n            weightProperty=self.weight_property,\n            weightStops=self.weight_stops,\n            intensityStops=self.intensity_stops,\n        ))\n        if self.vector_source:\n            options.update(dict(\n                vectorWeightStops=self.generate_vector_numeric_map('weight')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_unique_template_variables(self, options):\n        options.update(dict(\n            colorStops=self.color_stops,\n            colorDefault=self.color_default,\n            radiusStops=self.radius_stops,\n            clusterRadius=self.clusterRadius,\n            clusterMaxZoom=self.clusterMaxZoom,\n            strokeWidth=self.stroke_width,\n            strokeColor=self.stroke_color,\n            radiusDefault=self.radius_default,\n            highlightColor=self.highlight_color\n        ))", "response": "Update map template variables specific to a clustered circle visual"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_unique_template_variables(self, options):\n\n        # set line stroke dash interval based on line_stroke property\n        if self.line_stroke in [\"dashed\", \"--\"]:\n            self.line_dash_array = [6, 4]\n        elif self.line_stroke in [\"dotted\", \":\"]:\n            self.line_dash_array = [0.5, 4]\n        elif self.line_stroke in [\"dash dot\", \"-.\"]:\n            self.line_dash_array = [6, 4, 0.5, 4]\n        elif self.line_stroke in [\"solid\", \"-\"]:\n            self.line_dash_array = [1, 0]\n        else:\n            # default to solid line\n            self.line_dash_array = [1, 0]\n\n        # check if choropleth map should include 3-D extrusion\n        self.extrude = all([bool(self.height_property), bool(self.height_stops)])\n\n        # common variables for vector and geojson-based choropleths\n        options.update(dict(\n            colorStops=self.color_stops,\n            colorProperty=self.color_property,\n            colorType=self.color_function_type,\n            defaultColor=self.color_default,\n            lineColor=self.line_color,\n            lineDashArray=self.line_dash_array,\n            lineStroke=self.line_stroke,\n            lineWidth=self.line_width,\n            extrudeChoropleth=self.extrude,\n            highlightColor=self.highlight_color\n        ))\n        if self.extrude:\n            options.update(dict(\n                heightType=self.height_function_type,\n                heightProperty=self.height_property,\n                heightStops=self.height_stops,\n                defaultHeight=self.height_default,\n            ))\n\n        # vector-based choropleth map variables\n        if self.vector_source:\n            options.update(vectorColorStops=self.generate_vector_color_map())\n            \n            if self.extrude:\n                options.update(vectorHeightStops=self.generate_vector_numeric_map('height'))\n\n        # geojson-based choropleth map variables\n        else:\n            options.update(geojson_data=json.dumps(self.data, ensure_ascii=False))", "response": "Update map template variables specific to heatmap visual"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_unique_template_variables(self, options):\n        options.update(dict(\n            image=self.image,\n            coordinates=self.coordinates))", "response": "Update map template variables specific to image visual"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_unique_template_variables(self, options):\n        options.update(dict(\n            tiles_url=self.tiles_url,\n            tiles_size=self.tiles_size,\n            tiles_minzoom=self.tiles_minzoom,\n            tiles_maxzoom=self.tiles_maxzoom,\n            tiles_bounds=self.tiles_bounds if self.tiles_bounds else 'undefined'))", "response": "Update map template variables specific to a raster visual"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_unique_template_variables(self, options):\n\n        # set line stroke dash interval based on line_stroke property\n        if self.line_stroke in [\"dashed\", \"--\"]:\n            self.line_dash_array = [6, 4]\n        elif self.line_stroke in [\"dotted\", \":\"]:\n            self.line_dash_array = [0.5, 4]\n        elif self.line_stroke in [\"dash dot\", \"-.\"]:\n            self.line_dash_array = [6, 4, 0.5, 4]\n        elif self.line_stroke in [\"solid\", \"-\"]:\n            self.line_dash_array = [1, 0]\n        else:\n            # default to solid line\n            self.line_dash_array = [1, 0]\n\n        # common variables for vector and geojson-based linestring maps\n        options.update(dict(\n            colorStops=self.color_stops,\n            colorProperty=self.color_property,\n            colorType=self.color_function_type,\n            defaultColor=self.color_default,\n            lineColor=self.color_default,\n            lineDashArray=self.line_dash_array,\n            lineStroke=self.line_stroke,\n            widthStops=self.line_width_stops,\n            widthProperty=self.line_width_property,\n            widthType=self.line_width_function_type,\n            defaultWidth=self.line_width_default,\n            highlightColor=self.highlight_color\n        ))\n\n        # vector-based linestring map variables\n        if self.vector_source:\n            options.update(dict(\n                vectorColorStops=[[0, self.color_default]],\n                vectorWidthStops=[[0, self.line_width_default]],\n            ))\n\n            if self.color_property:\n                options.update(vectorColorStops=self.generate_vector_color_map())\n        \n            if self.line_width_property:\n                options.update(vectorWidthStops=self.generate_vector_numeric_map('line_width'))\n\n        # geojson-based linestring map variables\n        else:\n            options.update(geojson_data=json.dumps(self.data, ensure_ascii=False))", "response": "Update the map template variables specific to linestring visual"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a pandas dataframe row to a geojson format object.", "response": "def row_to_geojson(row, lon, lat, precision, date_format='epoch'):\n    \"\"\"Convert a pandas dataframe row to a geojson format object.  Converts all datetimes to epoch seconds.\n    \"\"\"\n\n    # Let pandas handle json serialization\n    row_json = json.loads(row.to_json(date_format=date_format, date_unit='s'))\n    return geojson.Feature(geometry=geojson.Point((round(row_json[lon], precision), round(row_json[lat], precision))),\n                           properties={key: row_json[key] for key in row_json.keys() if key not in [lon, lat]})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef df_to_geojson(df, properties=None, lat='lat', lon='lon', precision=6, date_format='epoch', filename=None):\n\n    if not properties:\n        # if no properties are selected, use all properties in dataframe\n        properties = [c for c in df.columns if c not in [lon, lat]]\n\n    for prop in properties:\n        # Check if list of properties exists in dataframe columns\n        if prop not in list(df.columns):\n            raise ValueError(\n                'properties must be a valid list of column names from dataframe')\n        if prop in [lon, lat]:\n            raise ValueError(\n                'properties cannot be the geometry longitude or latitude column')\n\n    # convert dates/datetimes to preferred string format if specified\n    df = convert_date_columns(df, date_format)\n\n    if filename:\n        with open(filename, 'w') as f:\n            # Overwrite file if it already exists\n            pass\n\n        with open(filename, 'a+') as f:\n\n            # Write out file to line\n            f.write('{\"type\": \"FeatureCollection\", \"features\": [\\n')\n            # Iterate over enumerated iterrows as index from iterrows alone could be non-sequential\n            for i, (index, row) in enumerate(df[[lon, lat] + properties].iterrows()):\n                if i == 0:\n                    f.write(geojson.dumps(row_to_geojson(row, lon, lat, precision, date_format)) + '\\n')\n                else:\n                    f.write(',' + geojson.dumps(row_to_geojson(row, lon, lat, precision, date_format)) + '\\n')\n            f.write(']}')\n\n            return {\n                \"type\": \"file\",\n                \"filename\": filename,\n                \"feature_count\": df.shape[0]\n            }\n    else:\n        features = []\n        df[[lon, lat] + properties].apply(lambda x: features.append(\n            row_to_geojson(x, lon, lat, precision, date_format)), axis=1)\n        return geojson.FeatureCollection(features)", "response": "Serialize a Pandas dataframe to a geojson format Python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef geojson_to_dict_list(data):\n    \n    # return data formatted as list or dict\n    if type(data) in (list, dict):\n        return data\n\n    # read from data defined as local file address\n    try:\n        with open(data, 'r') as f:\n            features = json.load(f)['features']\n\n    # if data is defined as a URL, load JSON object from address\n    except IOError:\n        features = requests.get(data).json()['features']\n\n    except:\n        raise SourceDataError('MapViz data must be valid GeoJSON or JSON.  Please check your <data> parameter.')\n\n    return [feature['properties'] for feature in features]", "response": "Parse GeoJSON - formatted information in data to list of Python dicts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing a GeoPandas dataframe to a geojson format Python dictionary", "response": "def gdf_to_geojson(gdf, date_format='epoch', properties=None, filename=None):\n    \"\"\"Serialize a GeoPandas dataframe to a geojson format Python dictionary / file\n    \"\"\"\n\n    # convert dates/datetimes to preferred string format if specified\n    gdf = convert_date_columns(gdf, date_format)\n\n    gdf_out = gdf[['geometry'] + properties or []]\n\n    geojson_str = gdf_out.to_json()\n\n    if filename:\n        with codecs.open(filename, \"w\", \"utf-8-sig\") as f:\n            f.write(geojson_str)\n        return None\n    else:\n        return json.loads(geojson_str)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_date_columns(df, date_format='epoch'):\n\n    if date_format not in ['epoch', 'iso']:\n        if '%' in date_format:\n            try:\n                datetime.datetime.now().strftime(date_format)\n            except:\n                raise DateConversionError('Error serializing dates in DataFrame using format {}.'.format(date_format))\n            finally:\n                for column, data_type in df.dtypes.to_dict().items():\n                    if 'date' in str(data_type):\n                        df[column] = df[column].dt.strftime(date_format)\n        else:\n            raise DateConversionError('Error serializing dates in DataFrame using format {}.'.format(date_format))\n\n    return df", "response": "Convert dates and datetimes to preferred string format if specified."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscale a min and max value to equal interval domain with numStops discrete values", "response": "def scale_between(minval, maxval, numStops):\n    \"\"\" Scale a min and max value to equal interval domain with\n        numStops discrete values\n    \"\"\"\n\n    scale = []\n\n    if numStops < 2:\n        return [minval, maxval]\n    elif maxval < minval:\n        raise ValueError()\n    else:\n        domain = maxval - minval\n        interval = float(domain) / float(numStops)\n        for i in range(numStops):\n            scale.append(round(minval + interval * i, 2))\n        return scale"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a data breaks into a radius ramp", "response": "def create_radius_stops(breaks, min_radius, max_radius):\n    \"\"\"Convert a data breaks into a radius ramp\n    \"\"\"\n    num_breaks = len(breaks)\n    radius_breaks = scale_between(min_radius, max_radius, num_breaks)\n    stops = []\n\n    for i, b in enumerate(breaks):\n        stops.append([b, radius_breaks[i]])\n    return stops"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_weight_stops(breaks):\n    num_breaks = len(breaks)\n    weight_breaks = scale_between(0, 1, num_breaks)\n    stops = []\n\n    for i, b in enumerate(breaks):\n        stops.append([b, weight_breaks[i]])\n    return stops", "response": "Convert data breaks into heatmap - weight ramp\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts data breaks into a general numeric ramp.", "response": "def create_numeric_stops(breaks, min_value, max_value):\n    \"\"\"Convert data breaks into a general numeric ramp (height, radius, weight, etc.)\n    \"\"\"\n    weight_breaks = scale_between(min_value, max_value, len(breaks))\n    return [list(x) for x in zip(breaks, weight_breaks)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a list of breaks into color stops using colors from colorBrewer or a custom list of color values in RGB RGBA HSL CSS text or HEX format.", "response": "def create_color_stops(breaks, colors='RdYlGn', color_ramps=color_ramps):\n    \"\"\"Convert a list of breaks into color stops using colors from colorBrewer\n    or a custom list of color values in RGB, RGBA, HSL, CSS text, or HEX format.\n    See www.colorbrewer2.org for a list of color options to pass\n    \"\"\"\n\n    num_breaks = len(breaks)\n    stops = []\n\n    if isinstance(colors, list):\n        # Check if colors contain a list of color values\n        if len(colors) == 0 or len(colors) != num_breaks:\n            raise ValueError(\n                'custom color list must be of same length as breaks list')\n\n        for color in colors:\n            # Check if color is valid string\n            try:\n                Colour(color)\n            except:\n                raise ValueError(\n                    'The color code {color} is in the wrong format'.format(color=color))\n\n        for i, b in enumerate(breaks):\n            stops.append([b, colors[i]])\n\n    else:\n        if colors not in color_ramps.keys():\n            raise ValueError('color does not exist in colorBrewer!')\n        else:\n\n            try:\n                ramp = color_ramps[colors][num_breaks]\n            except KeyError:\n                raise ValueError(\"Color ramp {} does not have a {} breaks\".format(\n                    colors, num_breaks))\n\n            for i, b in enumerate(breaks):\n                stops.append([b, ramp[i]])\n\n    return stops"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rgb_tuple_from_str(color_string):\n    try:\n        # English color names (limited)\n        rgb_string = common_html_colors[color_string]\n        return tuple([float(x) for x in re.findall(r'\\d{1,3}', rgb_string)]) \n    \n    except KeyError:\n        try:\n            # HEX color code\n            hex_string = color_string.lstrip('#')\n            return tuple(int(hex_string[i:i+2], 16) for i in (0, 2 ,4))\n        \n        except ValueError:\n            # RGB or RGBA formatted strings\n            return tuple([int(x) if float(x) > 1 else float(x) \n                          for x in re.findall(r\"[-+]?\\d*\\.*\\d+\", color_string)])", "response": "Convert color in format rgb ( RRG G BBB or limited English color name eg red or rgb ( RG G BBB or alpha."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef color_map(lookup, color_stops, default_color='rgb(122,122,122)'):\n    # if no color_stops, use default color\n    if len(color_stops) == 0:\n        return default_color\n    \n    # dictionary to lookup color from match-type color_stops\n    match_map = dict((x, y) for (x, y) in color_stops)\n\n    # if lookup matches stop exactly, return corresponding color (first priority)\n    # (includes non-numeric color_stop \"keys\" for finding color by match)\n    if lookup in match_map.keys():\n        return match_map.get(lookup)\n\n    # if lookup value numeric, map color by interpolating from color scale\n    if isinstance(lookup, (int, float, complex)):\n\n        # try ordering stops \n        try:\n            stops, colors = zip(*sorted(color_stops))\n        \n        # if not all stops are numeric, attempt looking up as if categorical stops\n        except TypeError:\n            return match_map.get(lookup, default_color)\n\n        # for interpolation, all stops must be numeric\n        if not all(isinstance(x, (int, float, complex)) for x in stops):\n            return default_color\n\n        # check if lookup value in stops bounds\n        if float(lookup) <= stops[0]:\n            return colors[0]\n        \n        elif float(lookup) >= stops[-1]:\n            return colors[-1]\n        \n        # check if lookup value matches any stop value\n        elif float(lookup) in stops:\n            return colors[stops.index(lookup)]\n        \n        # interpolation required\n        else:\n\n            rgb_tuples = [Color(rgb_tuple_from_str(x)) for x in colors]\n\n            # identify bounding color stop values\n            lower = max([stops[0]] + [x for x in stops if x < lookup])\n            upper = min([stops[-1]] + [x for x in stops if x > lookup])\n            \n            # colors from bounding stops\n            lower_color = rgb_tuples[stops.index(lower)]\n            upper_color = rgb_tuples[stops.index(upper)]\n            \n            # generate color scale for mapping lookup value to interpolated color\n            scale = Scale(Color(lower_color), Color(upper_color))\n\n            # compute linear \"relative distance\" from lower bound color to upper bound color\n            distance = (lookup - lower) / (upper - lower)\n\n            # return string representing rgb color value\n            return scale(distance).to_string().replace(', ', ',')\n\n    # default color value catch-all\n    return default_color", "response": "Return an rgb color value interpolated from given color_stops ; return default color if no color_stops are provided"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef numeric_map(lookup, numeric_stops, default=0.0):\n    # if no numeric_stops, use default\n    if len(numeric_stops) == 0:\n        return default\n    \n    # dictionary to lookup value from match-type numeric_stops\n    match_map = dict((x, y) for (x, y) in numeric_stops)\n\n    # if lookup matches stop exactly, return corresponding stop (first priority)\n    # (includes non-numeric numeric_stop \"keys\" for finding value by match)\n    if lookup in match_map.keys():\n        return match_map.get(lookup)\n\n    # if lookup value numeric, map value by interpolating from scale\n    if isinstance(lookup, (int, float, complex)):\n\n        # try ordering stops \n        try:\n            stops, values = zip(*sorted(numeric_stops))\n        \n        # if not all stops are numeric, attempt looking up as if categorical stops\n        except TypeError:\n            return match_map.get(lookup, default)\n\n        # for interpolation, all stops must be numeric\n        if not all(isinstance(x, (int, float, complex)) for x in stops):\n            return default\n\n        # check if lookup value in stops bounds\n        if float(lookup) <= stops[0]:\n            return values[0]\n        \n        elif float(lookup) >= stops[-1]:\n            return values[-1]\n        \n        # check if lookup value matches any stop value\n        elif float(lookup) in stops:\n            return values[stops.index(lookup)]\n        \n        # interpolation required\n        else:\n\n            # identify bounding stop values\n            lower = max([stops[0]] + [x for x in stops if x < lookup])\n            upper = min([stops[-1]] + [x for x in stops if x > lookup])\n            \n            # values from bounding stops\n            lower_value = values[stops.index(lower)]\n            upper_value = values[stops.index(upper)]\n            \n            # compute linear \"relative distance\" from lower bound to upper bound\n            distance = (lookup - lower) / (upper - lower)\n\n            # return interpolated value\n            return lower_value + distance * (upper_value - lower_value)\n\n    # default value catch-all\n    return default", "response": "Returns a number value interpolated from given numeric_stops\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding ndarray to base64 string image data", "response": "def img_encode(arr, **kwargs):\n    \"\"\"Encode ndarray to base64 string image data\n    \n    Parameters\n    ----------\n    arr: ndarray (rows, cols, depth)\n    kwargs: passed directly to matplotlib.image.imsave\n    \"\"\"\n    sio = BytesIO()\n    imsave(sio, arr, **kwargs)\n    sio.seek(0)\n    img_format = kwargs['format'] if kwargs.get('format') else 'png'\n    img_str = base64.b64encode(sio.getvalue()).decode()\n\n    return 'data:image/{};base64,{}'.format(img_format, img_str)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading YAML from docstring.", "response": "def load_yaml_from_docstring(docstring):\n    \"\"\"Loads YAML from docstring.\"\"\"\n    split_lines = trim_docstring(docstring).split(\"\\n\")\n\n    # Cut YAML from rest of docstring\n    for index, line in enumerate(split_lines):\n        line = line.strip()\n        if line.startswith(\"---\"):\n            cut_from = index\n            break\n    else:\n        return {}\n\n    yaml_string = \"\\n\".join(split_lines[cut_from:])\n    yaml_string = dedent(yaml_string)\n    return yaml.safe_load(yaml_string) or {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_operations_from_docstring(docstring):\n    doc_data = load_yaml_from_docstring(docstring)\n    return {\n        key: val\n        for key, val in iteritems(doc_data)\n        if key in PATH_KEYS or key.startswith(\"x-\")\n    }", "response": "Return a dictionary of OpenAPI operations parsed from a\n    a docstring."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning schema instance for given schema.", "response": "def resolve_schema_instance(schema):\n    \"\"\"Return schema instance for given schema (instance or class)\n\n    :param type|Schema|str schema: instance, class or class name of marshmallow.Schema\n    :return: schema instance of given schema (instance or class)\n    \"\"\"\n    if isinstance(schema, type) and issubclass(schema, marshmallow.Schema):\n        return schema()\n    if isinstance(schema, marshmallow.Schema):\n        return schema\n    try:\n        return marshmallow.class_registry.get_class(schema)()\n    except marshmallow.exceptions.RegistryError:\n        raise ValueError(\n            \"{!r} is not a marshmallow.Schema subclass or instance and has not\"\n            \" been registered in the Marshmallow class registry.\".format(schema)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_fields(schema, exclude_dump_only=False):\n    if hasattr(schema, \"fields\"):\n        fields = schema.fields\n    elif hasattr(schema, \"_declared_fields\"):\n        fields = copy.deepcopy(schema._declared_fields)\n    else:\n        raise ValueError(\n            \"{!r} doesn't have either `fields` or `_declared_fields`.\".format(schema)\n        )\n    Meta = getattr(schema, \"Meta\", None)\n    warn_if_fields_defined_in_meta(fields, Meta)\n    return filter_excluded_fields(fields, Meta, exclude_dump_only)", "response": "Return the fields from a marshmallow schema."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwarn user that fields defined in Meta. fields or Meta. additional will be ignored.", "response": "def warn_if_fields_defined_in_meta(fields, Meta):\n    \"\"\"Warns user that fields defined in Meta.fields or Meta.additional will\n    be ignored\n\n    :param dict fields: A dictionary of fields name field object pairs\n    :param Meta: the schema's Meta class\n    \"\"\"\n    if getattr(Meta, \"fields\", None) or getattr(Meta, \"additional\", None):\n        declared_fields = set(fields.keys())\n        if (\n            set(getattr(Meta, \"fields\", set())) > declared_fields\n            or set(getattr(Meta, \"additional\", set())) > declared_fields\n        ):\n            warnings.warn(\n                \"Only explicitly-declared fields will be included in the Schema Object. \"\n                \"Fields defined in Meta.fields or Meta.additional are ignored.\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_excluded_fields(fields, Meta, exclude_dump_only):\n    exclude = list(getattr(Meta, \"exclude\", []))\n    if exclude_dump_only:\n        exclude.extend(getattr(Meta, \"dump_only\", []))\n\n    filtered_fields = OrderedDict(\n        (key, value) for key, value in fields.items() if key not in exclude\n    )\n\n    return filtered_fields", "response": "Filter fields that should be ignored in the OpenAPI spec\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to generate a unique name based on the provided name and names already in the spec.", "response": "def get_unique_schema_name(components, name, counter=0):\n    \"\"\"Function to generate a unique name based on the provided name and names\n    already in the spec.  Will append a number to the name to make it unique if\n    the name is already in the spec.\n\n    :param Components components: instance of the components of the spec\n    :param string name: the name to use as a basis for the unique name\n    :param int counter: the counter of the number of recursions\n    :return: the unique name\n    \"\"\"\n    if name not in components._schemas:\n        return name\n    if not counter:  # first time through recursion\n        warnings.warn(\n            \"Multiple schemas resolved to the name {}. The name has been modified. \"\n            \"Either manually add each of the schemas with a different name or \"\n            \"provide a custom schema_name_resolver.\".format(name),\n            UserWarning,\n        )\n    else:  # subsequent recursions\n        name = name[: -len(str(counter))]\n    counter += 1\n    return get_unique_schema_name(components, name + str(counter), counter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a reference to the current resource.", "response": "def build_reference(component_type, openapi_major_version, component_name):\n    \"\"\"Return path to reference\n\n    :param str component_type: Component type (schema, parameter, response, security_scheme)\n    :param int openapi_major_version: OpenAPI major version (2 or 3)\n    :param str component_name: Name of component to reference\n    \"\"\"\n    return {\n        \"$ref\": \"#/{}{}/{}\".format(\n            \"components/\" if openapi_major_version >= 3 else \"\",\n            COMPONENT_SUBSECTIONS[openapi_major_version][component_type],\n            component_name,\n        )\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the output of an APISpec object against the current OpenAPI specification.", "response": "def validate_spec(spec):\n    \"\"\"Validate the output of an :class:`APISpec` object against the\n    OpenAPI specification.\n\n    Note: Requires installing apispec with the ``[validation]`` extras.\n    ::\n\n        pip install 'apispec[validation]'\n\n    :raise: apispec.exceptions.OpenAPIError if validation fails.\n    \"\"\"\n    try:\n        import prance\n    except ImportError as error:  # re-raise with a more verbose message\n        exc_class = type(error)\n        raise exc_class(\n            \"validate_spec requires prance to be installed. \"\n            \"You can install all validation requirements using:\\n\"\n            \"    pip install 'apispec[validation]'\"\n        )\n    parser_kwargs = {}\n    if spec.openapi_version.version[0] == 3:\n        parser_kwargs[\"backend\"] = \"openapi-spec-validator\"\n    try:\n        prance.BaseParser(spec_string=json.dumps(spec.to_dict()), **parser_kwargs)\n    except prance.ValidationError as err:\n        raise exceptions.OpenAPIError(*err.args)\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deepupdate(original, update):\n    for key, value in original.items():\n        if key not in update:\n            update[key] = value\n        elif isinstance(value, dict):\n            deepupdate(value, update[key])\n    return update", "response": "Recursively update a dict.\n    Subdict s won t be overwritten but also updated.\n    Subdict s won t be overwritten but also updated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _observed_name(field, name):\n        if MARSHMALLOW_VERSION_INFO[0] < 3:\n            # use getattr in case we're running against older versions of marshmallow.\n            dump_to = getattr(field, \"dump_to\", None)\n            load_from = getattr(field, \"load_from\", None)\n            return dump_to or load_from or name\n        return field.data_key or name", "response": "Adjust field name to reflect dump_to and load_from attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_to_openapi_type(self, *args):\n        if len(args) == 1 and args[0] in self.field_mapping:\n            openapi_type_field = self.field_mapping[args[0]]\n        elif len(args) == 2:\n            openapi_type_field = args\n        else:\n            raise TypeError(\"Pass core marshmallow field type or (type, fmt) pair.\")\n\n        def inner(field_type):\n            self.field_mapping[field_type] = openapi_type_field\n            return field_type\n\n        return inner", "response": "Decorator to set the mapping for custom fields."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef field2type_and_format(self, field):\n        # If this type isn't directly in the field mapping then check the\n        # hierarchy until we find something that does.\n        for field_class in type(field).__mro__:\n            if field_class in self.field_mapping:\n                type_, fmt = self.field_mapping[field_class]\n                break\n        else:\n            warnings.warn(\n                \"Field of type {} does not inherit from marshmallow.Field.\".format(\n                    type(field)\n                ),\n                UserWarning,\n            )\n            type_, fmt = \"string\", None\n\n        ret = {\"type\": type_}\n\n        if fmt:\n            ret[\"format\"] = fmt\n\n        return ret", "response": "Returns the dictionary of OpenAPI type and format based on the field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef field2default(self, field):\n        ret = {}\n        if \"doc_default\" in field.metadata:\n            ret[\"default\"] = field.metadata[\"doc_default\"]\n        else:\n            default = field.missing\n            if default is not marshmallow.missing and not callable(default):\n                ret[\"default\"] = default\n\n        return ret", "response": "Return the dictionary containing the field s default value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef field2choices(self, field, **kwargs):\n        attributes = {}\n\n        comparable = [\n            validator.comparable\n            for validator in field.validators\n            if hasattr(validator, \"comparable\")\n        ]\n        if comparable:\n            attributes[\"enum\"] = comparable\n        else:\n            choices = [\n                OrderedSet(validator.choices)\n                for validator in field.validators\n                if hasattr(validator, \"choices\")\n            ]\n            if choices:\n                attributes[\"enum\"] = list(functools.reduce(operator.and_, choices))\n\n        return attributes", "response": "Return the dictionary of OpenAPI field attributes for valid choices definition"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the dictionary of OpenAPI field attributes for a dump_only field.", "response": "def field2read_only(self, field, **kwargs):\n        \"\"\"Return the dictionary of OpenAPI field attributes for a dump_only field.\n\n        :param Field field: A marshmallow field.\n        :rtype: dict\n        \"\"\"\n        attributes = {}\n        if field.dump_only:\n            attributes[\"readOnly\"] = True\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef field2write_only(self, field, **kwargs):\n        attributes = {}\n        if field.load_only and self.openapi_version.major >= 3:\n            attributes[\"writeOnly\"] = True\n        return attributes", "response": "Return the dictionary of OpenAPI field attributes for a load_only field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dictionary of OpenAPI field attributes for a nullable field.", "response": "def field2nullable(self, field, **kwargs):\n        \"\"\"Return the dictionary of OpenAPI field attributes for a nullable field.\n\n        :param Field field: A marshmallow field.\n        :rtype: dict\n        \"\"\"\n        attributes = {}\n        if field.allow_none:\n            attributes[\n                \"x-nullable\" if self.openapi_version.major < 3 else \"nullable\"\n            ] = True\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef field2range(self, field, **kwargs):\n        validators = [\n            validator\n            for validator in field.validators\n            if (\n                hasattr(validator, \"min\")\n                and hasattr(validator, \"max\")\n                and not hasattr(validator, \"equal\")\n            )\n        ]\n\n        attributes = {}\n        for validator in validators:\n            if validator.min is not None:\n                if hasattr(attributes, \"minimum\"):\n                    attributes[\"minimum\"] = max(attributes[\"minimum\"], validator.min)\n                else:\n                    attributes[\"minimum\"] = validator.min\n            if validator.max is not None:\n                if hasattr(attributes, \"maximum\"):\n                    attributes[\"maximum\"] = min(attributes[\"maximum\"], validator.max)\n                else:\n                    attributes[\"maximum\"] = validator.max\n        return attributes", "response": "Return the dictionary of OpenAPI field attributes for a set of OpenAPI field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the dictionary of OpenAPI field attributes for a set of unambiguous length fields.", "response": "def field2length(self, field, **kwargs):\n        \"\"\"Return the dictionary of OpenAPI field attributes for a set of\n        :class:`Length <marshmallow.validators.Length>` validators.\n\n        :param Field field: A marshmallow field.\n        :rtype: dict\n        \"\"\"\n        attributes = {}\n\n        validators = [\n            validator\n            for validator in field.validators\n            if (\n                hasattr(validator, \"min\")\n                and hasattr(validator, \"max\")\n                and hasattr(validator, \"equal\")\n            )\n        ]\n\n        is_array = isinstance(\n            field, (marshmallow.fields.Nested, marshmallow.fields.List)\n        )\n        min_attr = \"minItems\" if is_array else \"minLength\"\n        max_attr = \"maxItems\" if is_array else \"maxLength\"\n\n        for validator in validators:\n            if validator.min is not None:\n                if hasattr(attributes, min_attr):\n                    attributes[min_attr] = max(attributes[min_attr], validator.min)\n                else:\n                    attributes[min_attr] = validator.min\n            if validator.max is not None:\n                if hasattr(attributes, max_attr):\n                    attributes[max_attr] = min(attributes[max_attr], validator.max)\n                else:\n                    attributes[max_attr] = validator.max\n\n        for validator in validators:\n            if validator.equal is not None:\n                attributes[min_attr] = validator.equal\n                attributes[max_attr] = validator.equal\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef field2pattern(self, field, **kwargs):\n        regex_validators = (\n            v\n            for v in field.validators\n            if isinstance(getattr(v, \"regex\", None), RegexType)\n        )\n        v = next(regex_validators, None)\n        attributes = {} if v is None else {\"pattern\": v.regex.pattern}\n\n        if next(regex_validators, None) is not None:\n            warnings.warn(\n                \"More than one regex validator defined on {} field. Only the \"\n                \"first one will be used in the output spec.\".format(type(field)),\n                UserWarning,\n            )\n\n        return attributes", "response": "Return the dictionary of OpenAPI field attributes for a set of OpenAPI field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of properties extracted from the metadata of a marshmallow field.", "response": "def metadata2properties(self, field):\n        \"\"\"Return a dictionary of properties extracted from field Metadata\n\n        Will include field metadata that are valid properties of `OpenAPI schema\n        objects\n        <https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schemaObject>`_\n        (e.g. \u201cdescription\u201d, \u201cenum\u201d, \u201cexample\u201d).\n\n        In addition, `specification extensions\n        <https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#specification-extensions>`_\n        are supported.  Prefix `x_` to the desired extension when passing the\n        keyword argument to the field constructor. apispec will convert `x_` to\n        `x-` to comply with OpenAPI.\n\n        :param Field field: A marshmallow field.\n        :rtype: dict\n        \"\"\"\n        # Dasherize metadata that starts with x_\n        metadata = {\n            key.replace(\"_\", \"-\") if key.startswith(\"x_\") else key: value\n            for key, value in iteritems(field.metadata)\n        }\n\n        # Avoid validation error with \"Additional properties not allowed\"\n        ret = {\n            key: value\n            for key, value in metadata.items()\n            if key in _VALID_PROPERTIES or key.startswith(_VALID_PREFIX)\n        }\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef field2property(self, field):\n        ret = {}\n\n        for attr_func in (\n            self.field2type_and_format,\n            self.field2default,\n            self.field2choices,\n            self.field2read_only,\n            self.field2write_only,\n            self.field2nullable,\n            self.field2range,\n            self.field2length,\n            self.field2pattern,\n            self.metadata2properties,\n        ):\n            ret.update(attr_func(field))\n\n        if isinstance(field, marshmallow.fields.Nested):\n            del ret[\"type\"]\n            schema_dict = self.resolve_nested_schema(field.schema)\n            if ret and \"$ref\" in schema_dict:\n                ret.update({\"allOf\": [schema_dict]})\n            else:\n                ret.update(schema_dict)\n        elif isinstance(field, marshmallow.fields.List):\n            ret[\"items\"] = self.field2property(field.container)\n        elif isinstance(field, marshmallow.fields.Dict):\n            if MARSHMALLOW_VERSION_INFO[0] >= 3:\n                if field.value_container:\n                    ret[\"additionalProperties\"] = self.field2property(\n                        field.value_container\n                    )\n\n        return ret", "response": "Returns the JSON Schema property definition given a marshmallow. fields. Field object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves a nested schema.", "response": "def resolve_nested_schema(self, schema):\n        \"\"\"Return the Open API representation of a marshmallow Schema.\n\n        Adds the schema to the spec if it isn't already present.\n\n        Typically will return a dictionary with the reference to the schema's\n        path in the spec unless the `schema_name_resolver` returns `None`, in\n        which case the returned dictoinary will contain a JSON Schema Object\n        representation of the schema.\n\n        :param schema: schema to add to the spec\n        \"\"\"\n        schema_instance = resolve_schema_instance(schema)\n        schema_key = make_schema_key(schema_instance)\n        if schema_key not in self.refs:\n            schema_cls = self.resolve_schema_class(schema)\n            name = self.schema_name_resolver(schema_cls)\n            if not name:\n                try:\n                    json_schema = self.schema2jsonschema(schema)\n                except RuntimeError:\n                    raise APISpecError(\n                        \"Name resolver returned None for schema {schema} which is \"\n                        \"part of a chain of circular referencing schemas. Please\"\n                        \" ensure that the schema_name_resolver passed to\"\n                        \" MarshmallowPlugin returns a string for all circular\"\n                        \" referencing schemas.\".format(schema=schema)\n                    )\n                if getattr(schema, \"many\", False):\n                    return {\"type\": \"array\", \"items\": json_schema}\n                return json_schema\n            name = get_unique_schema_name(self.spec.components, name)\n            self.spec.components.schema(name, schema=schema)\n        return self.get_ref_dict(schema_instance)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef schema2parameters(\n        self, schema, default_in=\"body\", name=\"body\", required=False, description=None\n    ):\n        \"\"\"Return an array of OpenAPI parameters given a given marshmallow\n        :class:`Schema <marshmallow.Schema>`. If `default_in` is \"body\", then return an array\n        of a single parameter; else return an array of a parameter for each included field in\n        the :class:`Schema <marshmallow.Schema>`.\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#parameterObject\n        \"\"\"\n        openapi_default_in = __location_map__.get(default_in, default_in)\n        if self.openapi_version.major < 3 and openapi_default_in == \"body\":\n            prop = self.resolve_schema_dict(schema)\n\n            param = {\n                \"in\": openapi_default_in,\n                \"required\": required,\n                \"name\": name,\n                \"schema\": prop,\n            }\n\n            if description:\n                param[\"description\"] = description\n\n            return [param]\n\n        assert not getattr(\n            schema, \"many\", False\n        ), \"Schemas with many=True are only supported for 'json' location (aka 'in: body')\"\n\n        fields = get_fields(schema, exclude_dump_only=True)\n\n        return self.fields2parameters(fields, default_in=default_in)", "response": "Return an array of OpenAPI parameters given a given marshmallow. Schema object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an array of OpenAPI parameters given a mapping between field names and marshmallow. Field objects.", "response": "def fields2parameters(self, fields, default_in=\"body\"):\n        \"\"\"Return an array of OpenAPI parameters given a mapping between field names and\n        :class:`Field <marshmallow.Field>` objects. If `default_in` is \"body\", then return an array\n        of a single parameter; else return an array of a parameter for each included field in\n        the :class:`Schema <marshmallow.Schema>`.\n\n        In OpenAPI3, only \"query\", \"header\", \"path\" or \"cookie\" are allowed for the location\n        of parameters. In OpenAPI 3, \"requestBody\" is used when fields are in the body.\n\n        This function always returns a list, with a parameter\n        for each included field in the :class:`Schema <marshmallow.Schema>`.\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#parameterObject\n        \"\"\"\n        parameters = []\n        body_param = None\n        for field_name, field_obj in iteritems(fields):\n            if field_obj.dump_only:\n                continue\n            param = self.field2parameter(\n                field_obj,\n                name=self._observed_name(field_obj, field_name),\n                default_in=default_in,\n            )\n            if (\n                self.openapi_version.major < 3\n                and param[\"in\"] == \"body\"\n                and body_param is not None\n            ):\n                body_param[\"schema\"][\"properties\"].update(param[\"schema\"][\"properties\"])\n                required_fields = param[\"schema\"].get(\"required\", [])\n                if required_fields:\n                    body_param[\"schema\"].setdefault(\"required\", []).extend(\n                        required_fields\n                    )\n            else:\n                if self.openapi_version.major < 3 and param[\"in\"] == \"body\":\n                    body_param = param\n                parameters.append(param)\n        return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef field2parameter(self, field, name=\"body\", default_in=\"body\"):\n        location = field.metadata.get(\"location\", None)\n        prop = self.field2property(field)\n        return self.property2parameter(\n            prop,\n            name=name,\n            required=field.required,\n            multiple=isinstance(field, marshmallow.fields.List),\n            location=location,\n            default_in=default_in,\n        )", "response": "Return an OpenAPI parameter as a dict given a marshmallow. Field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef property2parameter(\n        self,\n        prop,\n        name=\"body\",\n        required=False,\n        multiple=False,\n        location=None,\n        default_in=\"body\",\n    ):\n        \"\"\"Return the Parameter Object definition for a JSON Schema property.\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#parameterObject\n\n        :param dict prop: JSON Schema property\n        :param str name: Field name\n        :param bool required: Parameter is required\n        :param bool multiple: Parameter is repeated\n        :param str location: Location to look for ``name``\n        :param str default_in: Default location to look for ``name``\n        :raise: TranslationError if arg object cannot be translated to a Parameter Object schema.\n        :rtype: dict, a Parameter Object\n        \"\"\"\n        openapi_default_in = __location_map__.get(default_in, default_in)\n        openapi_location = __location_map__.get(location, openapi_default_in)\n        ret = {\"in\": openapi_location, \"name\": name}\n\n        if openapi_location == \"body\":\n            ret[\"required\"] = False\n            ret[\"name\"] = \"body\"\n            ret[\"schema\"] = {\n                \"type\": \"object\",\n                \"properties\": {name: prop} if name else {},\n            }\n            if name and required:\n                ret[\"schema\"][\"required\"] = [name]\n        else:\n            ret[\"required\"] = required\n            if self.openapi_version.major < 3:\n                if multiple:\n                    ret[\"collectionFormat\"] = \"multi\"\n                ret.update(prop)\n            else:\n                if multiple:\n                    ret[\"explode\"] = True\n                    ret[\"style\"] = \"form\"\n                if prop.get(\"description\", None):\n                    ret[\"description\"] = prop.pop(\"description\")\n                ret[\"schema\"] = prop\n        return ret", "response": "Return the Parameter Object definition for a JSON Schema property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the JSON Schema Object for a given marshmallow. Schema instance.", "response": "def schema2jsonschema(self, schema):\n        \"\"\"Return the JSON Schema Object for a given marshmallow\n        :class:`Schema <marshmallow.Schema>` instance. Schema may optionally\n        provide the ``title`` and ``description`` class Meta options.\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schemaObject\n\n        Example: ::\n\n            class UserSchema(Schema):\n                _id = fields.Int()\n                email = fields.Email(description='email address of the user')\n                name = fields.Str()\n\n                class Meta:\n                    title = 'User'\n                    description = 'A registered user'\n\n            oaic = OpenAPIConverter(openapi_version='3.0.2', schema_name_resolver=resolver, spec=spec)\n            pprint(oaic.schema2jsonschema(UserSchema))\n            # {'description': 'A registered user',\n            #  'properties': {'_id': {'format': 'int32', 'type': 'integer'},\n            #                 'email': {'description': 'email address of the user',\n            #                           'format': 'email',\n            #                           'type': 'string'},\n            #                 'name': {'type': 'string'}},\n            #  'title': 'User',\n            #  'type': 'object'}\n\n        :param Schema schema: A marshmallow Schema instance\n        :rtype: dict, a JSON Schema Object\n        \"\"\"\n        fields = get_fields(schema)\n        Meta = getattr(schema, \"Meta\", None)\n        partial = getattr(schema, \"partial\", None)\n        ordered = getattr(schema, \"ordered\", False)\n\n        jsonschema = self.fields2jsonschema(fields, partial=partial, ordered=ordered)\n\n        if hasattr(Meta, \"title\"):\n            jsonschema[\"title\"] = Meta.title\n        if hasattr(Meta, \"description\"):\n            jsonschema[\"description\"] = Meta.description\n\n        return jsonschema"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the JSON Schema Object given a mapping between field names and marshmallow. Field objects.", "response": "def fields2jsonschema(self, fields, ordered=False, partial=None):\n        \"\"\"Return the JSON Schema Object given a mapping between field names and\n        :class:`Field <marshmallow.Field>` objects.\n\n        :param dict fields: A dictionary of field name field object pairs\n        :param bool ordered: Whether to preserve the order in which fields were declared\n        :param bool|tuple partial: Whether to override a field's required flag.\n            If `True` no fields will be set as required. If an iterable fields\n            in the iterable will not be marked as required.\n        :rtype: dict, a JSON Schema Object\n        \"\"\"\n        jsonschema = {\"type\": \"object\", \"properties\": OrderedDict() if ordered else {}}\n\n        for field_name, field_obj in iteritems(fields):\n            observed_field_name = self._observed_name(field_obj, field_name)\n            property = self.field2property(field_obj)\n            jsonschema[\"properties\"][observed_field_name] = property\n\n            if field_obj.required:\n                if not partial or (\n                    is_collection(partial) and field_name not in partial\n                ):\n                    jsonschema.setdefault(\"required\", []).append(observed_field_name)\n\n        if \"required\" in jsonschema:\n            jsonschema[\"required\"].sort()\n\n        return jsonschema"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ref_dict(self, schema):\n        schema_key = make_schema_key(schema)\n        ref_schema = build_reference(\n            \"schema\", self.openapi_version.major, self.refs[schema_key]\n        )\n        if getattr(schema, \"many\", False):\n            return {\"type\": \"array\", \"items\": ref_schema}\n        return ref_schema", "response": "Method to create a dictionary containing a JSON reference to the\n            schema in the spec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_operations(operations, openapi_major_version):\n    invalid = {\n        key\n        for key in set(iterkeys(operations)) - set(VALID_METHODS[openapi_major_version])\n        if not key.startswith(\"x-\")\n    }\n    if invalid:\n        raise APISpecError(\n            \"One or more HTTP methods are invalid: {}\".format(\", \".join(invalid))\n        )\n\n    def get_ref(obj_type, obj, openapi_major_version):\n        \"\"\"Return object or rererence\n\n        If obj is a dict, it is assumed to be a complete description and it is returned as is.\n        Otherwise, it is assumed to be a reference name as string and the corresponding $ref\n        string is returned.\n\n        :param str obj_type: \"parameter\" or \"response\"\n        :param dict|str obj: parameter or response in dict form or as ref_id string\n        :param int openapi_major_version: The major version of the OpenAPI standard\n        \"\"\"\n        if isinstance(obj, dict):\n            return obj\n        return build_reference(obj_type, openapi_major_version, obj)\n\n    for operation in (operations or {}).values():\n        if \"parameters\" in operation:\n            parameters = operation[\"parameters\"]\n            for parameter in parameters:\n                if (\n                    isinstance(parameter, dict)\n                    and \"in\" in parameter\n                    and parameter[\"in\"] == \"path\"\n                ):\n                    parameter[\"required\"] = True\n            operation[\"parameters\"] = [\n                get_ref(\"parameter\", p, openapi_major_version) for p in parameters\n            ]\n        if \"responses\" in operation:\n            responses = OrderedDict()\n            for code, response in iteritems(operation[\"responses\"]):\n                try:\n                    code = int(code)  # handles IntEnums like http.HTTPStatus\n                except (TypeError, ValueError):\n                    if openapi_major_version < 3:\n                        warnings.warn(\"Non-integer code not allowed in OpenAPI < 3\")\n\n                responses[str(code)] = get_ref(\n                    \"response\", response, openapi_major_version\n                )\n            operation[\"responses\"] = responses", "response": "Clean the given operations dictionary to ensure that all parameters with in equal to path are also required by the OpenAPI specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new schema to the spec.", "response": "def schema(self, name, component=None, **kwargs):\n        \"\"\"Add a new schema to the spec.\n\n        :param str name: identifier by which schema may be referenced.\n        :param dict component: schema definition.\n\n        .. note::\n\n            If you are using `apispec.ext.marshmallow`, you can pass fields' metadata as\n            additional keyword arguments.\n\n            For example, to add ``enum`` and ``description`` to your field: ::\n\n                status = fields.String(\n                    required=True,\n                    enum=['open', 'closed'],\n                    description='Status (open or closed)',\n                )\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schemaObject\n        \"\"\"\n        if name in self._schemas:\n            raise DuplicateComponentNameError(\n                'Another schema with name \"{}\" is already registered.'.format(name)\n            )\n        component = component or {}\n        ret = component.copy()\n        # Execute all helpers from plugins\n        for plugin in self._plugins:\n            try:\n                ret.update(plugin.schema_helper(name, component, **kwargs) or {})\n            except PluginMethodNotImplementedError:\n                continue\n        self._schemas[name] = ret\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a parameter which can be referenced by a specific component.", "response": "def parameter(self, component_id, location, component=None, **kwargs):\n        \"\"\" Add a parameter which can be referenced.\n\n        :param str param_id: identifier by which parameter may be referenced.\n        :param str location: location of the parameter.\n        :param dict component: parameter fields.\n        :param dict kwargs: plugin-specific arguments\n        \"\"\"\n        if component_id in self._parameters:\n            raise DuplicateComponentNameError(\n                'Another parameter with name \"{}\" is already registered.'.format(\n                    component_id\n                )\n            )\n        component = component or {}\n        ret = component.copy()\n        ret.setdefault(\"name\", component_id)\n        ret[\"in\"] = location\n        # Execute all helpers from plugins\n        for plugin in self._plugins:\n            try:\n                ret.update(plugin.parameter_helper(component, **kwargs) or {})\n            except PluginMethodNotImplementedError:\n                continue\n        self._parameters[component_id] = ret\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a response which can be referenced.", "response": "def response(self, component_id, component=None, **kwargs):\n        \"\"\"Add a response which can be referenced.\n\n        :param str component_id: ref_id to use as reference\n        :param dict component: response fields\n        :param dict kwargs: plugin-specific arguments\n        \"\"\"\n        if component_id in self._responses:\n            raise DuplicateComponentNameError(\n                'Another response with name \"{}\" is already registered.'.format(\n                    component_id\n                )\n            )\n        component = component or {}\n        ret = component.copy()\n        # Execute all helpers from plugins\n        for plugin in self._plugins:\n            try:\n                ret.update(plugin.response_helper(component, **kwargs) or {})\n            except PluginMethodNotImplementedError:\n                continue\n        self._responses[component_id] = ret\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a security scheme which can be referenced.", "response": "def security_scheme(self, component_id, component):\n        \"\"\"Add a security scheme which can be referenced.\n\n        :param str component_id: component_id to use as reference\n        :param dict kwargs: security scheme fields\n        \"\"\"\n        if component_id in self._security_schemes:\n            raise DuplicateComponentNameError(\n                'Another security scheme with name \"{}\" is already registered.'.format(\n                    component_id\n                )\n            )\n        self._security_schemes[component_id] = component\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new path object to the spec.", "response": "def path(\n        self, path=None, operations=None, summary=None, description=None, **kwargs\n    ):\n        \"\"\"Add a new path object to the spec.\n\n        https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#path-item-object\n\n        :param str|None path: URL path component\n        :param dict|None operations: describes the http methods and options for `path`\n        :param str summary: short summary relevant to all operations in this path\n        :param str description: long description relevant to all operations in this path\n        :param dict kwargs: parameters used by any path helpers see :meth:`register_path_helper`\n        \"\"\"\n        operations = operations or OrderedDict()\n\n        # Execute path helpers\n        for plugin in self.plugins:\n            try:\n                ret = plugin.path_helper(path=path, operations=operations, **kwargs)\n            except PluginMethodNotImplementedError:\n                continue\n            if ret is not None:\n                path = ret\n        if not path:\n            raise APISpecError(\"Path template is not specified.\")\n\n        # Execute operation helpers\n        for plugin in self.plugins:\n            try:\n                plugin.operation_helper(path=path, operations=operations, **kwargs)\n            except PluginMethodNotImplementedError:\n                continue\n\n        clean_operations(operations, self.openapi_version.major)\n\n        self._paths.setdefault(path, operations).update(operations)\n        if summary is not None:\n            self._paths[path][\"summary\"] = summary\n        if description is not None:\n            self._paths[path][\"description\"] = description\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolver(schema):\n    name = schema.__name__\n    if name.endswith(\"Schema\"):\n        return name[:-6] or name\n    return name", "response": "Default implementation of a schema name resolver function"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_schema_in_request_body(self, request_body):\n        content = request_body[\"content\"]\n        for content_type in content:\n            schema = content[content_type][\"schema\"]\n            content[content_type][\"schema\"] = self.openapi.resolve_schema_dict(schema)", "response": "Function to resolve a schema in a requestBody object - modifies then\n        response dict to convert Marshmallow Schema object or class into dict\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to resolve a schema in a parameter or response dictionary", "response": "def resolve_schema(self, data):\n        \"\"\"Function to resolve a schema in a parameter or response - modifies the\n        corresponding dict to convert Marshmallow Schema object or class into dict\n\n        :param APISpec spec: `APISpec` containing refs.\n        :param dict|str data: either a parameter or response dictionary that may\n            contain a schema, or a reference provided as string\n        \"\"\"\n        if not isinstance(data, dict):\n            return\n\n        # OAS 2 component or OAS 3 header\n        if \"schema\" in data:\n            data[\"schema\"] = self.openapi.resolve_schema_dict(data[\"schema\"])\n        # OAS 3 component except header\n        if self.openapi_version.major >= 3:\n            if \"content\" in data:\n                for content_type in data[\"content\"]:\n                    schema = data[\"content\"][content_type][\"schema\"]\n                    data[\"content\"][content_type][\n                        \"schema\"\n                    ] = self.openapi.resolve_schema_dict(schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schema_helper(self, name, _, schema=None, **kwargs):\n        if schema is None:\n            return None\n\n        schema_instance = resolve_schema_instance(schema)\n\n        schema_key = make_schema_key(schema_instance)\n        self.warn_if_schema_already_in_spec(schema_key)\n        self.openapi.refs[schema_key] = name\n\n        json_schema = self.openapi.schema2jsonschema(schema_instance)\n\n        return json_schema", "response": "Definition helper that allows using a marshmallow. Schema to provide OpenAPI\n        metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response_helper(self, response, **kwargs):\n        self.resolve_schema(response)\n        if \"headers\" in response:\n            for header in response[\"headers\"].values():\n                self.resolve_schema(header)\n        return response", "response": "Response component helper that allows using a marshmallow. Schema class or instance of marshmallow. Schema instance in response definition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the size in bytes from a string such as 5 mb t p", "response": "def size_in_bytes(insize):\n    \"\"\"\n    Returns the size in bytes from strings such as '5 mb' into 5242880.\n\n    >>> size_in_bytes('1m')\n    1048576\n    >>> size_in_bytes('1.5m')\n    1572864\n    >>> size_in_bytes('2g')\n    2147483648\n    >>> size_in_bytes(None)\n    Traceback (most recent call last):\n        raise ValueError('no string specified')\n    ValueError: no string specified\n    >>> size_in_bytes('')\n    Traceback (most recent call last):\n        raise ValueError('no string specified')\n    ValueError: no string specified\n    \"\"\"\n    if insize is None or insize.strip() == '':\n        raise ValueError('no string specified')\n\n    units = {\n        'k': 1024,\n        'm': 1024 ** 2,\n        'g': 1024 ** 3,\n        't': 1024 ** 4,\n        'p': 1024 ** 5,\n    }\n    match = re.search('^\\s*([0-9\\.]+)\\s*([kmgtp])?', insize, re.I)\n\n    if match is None:\n        raise ValueError('match not found')\n\n    size, unit = match.groups()\n\n    if size:\n        size = float(size)\n\n    if unit:\n        size = size * units[unit.lower().strip()]\n\n    return int(size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the music download filepath from scdl. cfg", "response": "def get_config():\n    \"\"\"\n    Reads the music download filepath from scdl.cfg\n    \"\"\"\n    global token\n    config = configparser.ConfigParser()\n    config.read(os.path.join(os.path.expanduser('~'), '.config/scdl/scdl.cfg'))\n    try:\n        token = config['scdl']['auth_token']\n        path = config['scdl']['path']\n    except:\n        logger.error('Are you sure scdl.cfg is in $HOME/.config/scdl/ ?')\n        logger.error('Are both \"auth_token\" and \"path\" defined there?')\n        sys.exit()\n    if os.path.exists(path):\n        os.chdir(path)\n    else:\n        logger.error('Invalid path in scdl.cfg...')\n        sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item(track_url, client_id=CLIENT_ID):\n    try:\n        item_url = url['resolve'].format(track_url)\n\n        r = requests.get(item_url, params={'client_id': client_id})\n        logger.debug(r.url)\n        if r.status_code == 403:\n            return get_item(track_url, ALT_CLIENT_ID)\n\n        item = r.json()\n        no_tracks = item['kind'] == 'playlist' and not item['tracks']\n        if no_tracks and client_id != ALT_CLIENT_ID:\n            return get_item(track_url, ALT_CLIENT_ID)\n    except Exception:\n        if client_id == ALT_CLIENT_ID:\n            logger.error('Failed to get item...')\n            return\n        logger.error('Error resolving url, retrying...')\n        time.sleep(5)\n        try:\n            return get_item(track_url, ALT_CLIENT_ID)\n        except Exception as e:\n            logger.error('Could not resolve url {0}'.format(track_url))\n            logger.exception(e)\n            sys.exit(0)\n    return item", "response": "Fetches metadata for a track or playlist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect if a URL is a track or a playlist and parses the track ( s ) to the track downloader", "response": "def parse_url(track_url):\n    \"\"\"\n    Detects if a URL is a track or a playlist, and parses the track(s)\n    to the track downloader\n    \"\"\"\n    global arguments\n    item = get_item(track_url)\n    logger.debug(item)\n    if not item:\n        return\n    elif item['kind'] == 'track':\n        logger.info('Found a track')\n        download_track(item)\n    elif item['kind'] == 'playlist':\n        logger.info('Found a playlist')\n        download_playlist(item)\n    elif item['kind'] == 'user':\n        logger.info('Found a user profile')\n        if arguments['-f']:\n            download(item, 'favorites', 'likes')\n        elif arguments['-C']:\n            download(item, 'commented', 'commented tracks')\n        elif arguments['-t']:\n            download(item, 'tracks', 'uploaded tracks')\n        elif arguments['-a']:\n            download(item, 'all', 'tracks and reposts')\n        elif arguments['-p']:\n            download(item, 'playlists', 'playlists')\n        elif arguments['-m']:\n            download(item, 'playlists-liked', 'my and liked playlists')\n        else:\n            logger.error('Please provide a download type...')\n    else:\n        logger.error('Unknown item type {0}'.format(item['kind']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef who_am_i():\n    me = url['me'].format(token)\n    r = requests.get(me, params={'client_id': CLIENT_ID})\n    r.raise_for_status()\n    current_user = r.json()\n    logger.debug(me)\n\n    logger.info('Hello {0}!'.format(current_user['username']))\n    return current_user", "response": "Display username from current token and check for validity\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove any files that were not just downloaded from the local track file system.", "response": "def remove_files():\n    \"\"\"\n    Removes any pre-existing tracks that were not just downloaded\n    \"\"\"\n    logger.info(\"Removing local track files that were not downloaded...\")\n    files = [f for f in os.listdir('.') if os.path.isfile(f)]\n    for f in files:\n        if f not in fileToKeep:\n            os.remove(f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_track_info(track_id):\n    logger.info('Retrieving more info on the track')\n    info_url = url[\"trackinfo\"].format(track_id)\n    r = requests.get(info_url, params={'client_id': CLIENT_ID}, stream=True)\n    item = r.json()\n    logger.debug(item)\n    return item", "response": "Fetches track info from Soundcloud given a track_id\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(user, dl_type, name):\n    username = user['username']\n    user_id = user['id']\n    logger.info(\n        'Retrieving all {0} of user {1}...'.format(name, username)\n    )\n    dl_url = url[dl_type].format(user_id)\n    logger.debug(dl_url)\n    resources = client.get_collection(dl_url, token)\n    del resources[:offset - 1]\n    logger.debug(resources)\n    total = len(resources)\n    logger.info('Retrieved {0} {1}'.format(total, name))\n    for counter, item in enumerate(resources, offset):\n        try:\n            logger.debug(item)\n            logger.info('{0} n\u00b0{1} of {2}'.format(\n                name.capitalize(), counter, total)\n            )\n            if dl_type == 'all':\n                item_name = item['type'].split('-')[0]  # remove the '-repost'\n                uri = item[item_name]['uri']\n                parse_url(uri)\n            elif dl_type == 'playlists':\n                download_playlist(item)\n            elif dl_type == 'playlists-liked':\n                parse_url(item['playlist']['uri'])\n            elif dl_type == 'commented':\n                item = get_track_info(item['track_id'])\n                download_track(item)\n            else:\n                download_track(item)\n        except Exception as e:\n            logger.exception(e)\n    logger.info('Downloaded all {0} {1} of user {2}!'.format(\n        total, name, username)\n    )", "response": "Download all user items of dl_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a playlist into a new folder.", "response": "def download_playlist(playlist):\n    \"\"\"\n    Downloads a playlist\n    \"\"\"\n    global arguments\n    invalid_chars = '\\/:*?|<>\"'\n    playlist_name = playlist['title'].encode('utf-8', 'ignore')\n    playlist_name = playlist_name.decode('utf8')\n    playlist_name = ''.join(c for c in playlist_name if c not in invalid_chars)\n\n    if not arguments['--no-playlist-folder']:\n        if not os.path.exists(playlist_name):\n            os.makedirs(playlist_name)\n        os.chdir(playlist_name)\n\n    try:\n        with codecs.open(playlist_name + '.m3u', 'w+', 'utf8') as playlist_file:\n            playlist_file.write('#EXTM3U' + os.linesep)\n            del playlist['tracks'][:offset - 1]\n            for counter, track_raw in enumerate(playlist['tracks'], offset):\n                logger.debug(track_raw)\n                logger.info('Track n\u00b0{0}'.format(counter))\n                download_track(track_raw, playlist['title'], playlist_file)\n    finally:\n        os.chdir('..')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_track(track, playlist_name=None, playlist_file=None):\n    global arguments\n\n    title = track['title']\n    title = title.encode('utf-8', 'ignore').decode('utf8')\n    logger.info('Downloading {0}'.format(title))\n\n    # Not streamable\n    if not track['streamable']:\n        logger.error('{0} is not streamable...'.format(title))\n        return\n\n    r = None\n    # Downloadable track\n    if track['downloadable'] and not arguments['--onlymp3']:\n        logger.info('Downloading the original file.')\n        original_url = track['download_url']\n        r = requests.get(\n            original_url, params={'client_id': CLIENT_ID}, stream=True\n        )\n        if r.status_code == 401:\n            logger.info('The original file has no download left.')\n            filename = get_filename(track)\n        else:\n            d = r.headers.get('content-disposition')\n            filename = re.findall(\"filename=(.+)\", d)[0][1:-1]\n            filename = get_filename(track, filename)\n\n    else:\n        filename = get_filename(track)\n    logger.debug(\"filename : {0}\".format(filename))\n\n    # Skip if file ID or filename already exists\n    if already_downloaded(track, title, filename):\n        return\n\n    # Add the track to the generated m3u playlist file\n    if playlist_file:\n        duration = math.floor(track['duration'] / 1000)\n        playlist_file.write(\n            '#EXTINF:{0},{1}{3}{2}{3}'.format(\n                duration, title, filename, os.linesep\n            )\n        )\n\n    if arguments['--remove']:\n        fileToKeep.append(filename)\n\n    # Streamable track download\n    if r is None or r.status_code == 401:\n        url = track['stream_url']\n        r = requests.get(url, params={'client_id': CLIENT_ID}, stream=True)\n        logger.debug(r.url)\n        if r.status_code == 401 or r.status_code == 429:\n            r = requests.get(\n                url, params={'client_id': ALT_CLIENT_ID}, stream=True\n            )\n            logger.debug(r.url)\n            r.raise_for_status()\n    temp = tempfile.NamedTemporaryFile(delete=False)\n\n    total_length = int(r.headers.get('content-length'))\n\n    min_size = arguments.get('--min-size')\n    max_size = arguments.get('--max-size')\n\n    if min_size is not None and total_length < min_size:\n        logging.info('{0} not large enough, skipping'.format(title))\n        return\n\n    if max_size is not None and total_length > max_size:\n        logging.info('{0} too large, skipping'.format(title))\n        return\n\n    received=0\n    with temp as f:\n        for chunk in progress.bar(\n            r.iter_content(chunk_size=1024),\n            expected_size=(total_length/1024) + 1,\n            hide=True if arguments[\"--hide-progress\"] else False\n        ):\n            if chunk:\n                received+=len(chunk)\n                f.write(chunk)\n                f.flush()\n\n    if received != total_length:\n        logger.error('connection closed prematurely, download incomplete')\n        sys.exit()\n\n    shutil.move(temp.name, os.path.join(os.getcwd(), filename))\n    if arguments['--flac'] and can_convert(filename):\n        logger.info('Converting to .flac...')\n        newfilename = filename[:-4] + \".flac\"\n        new = shlex.quote(newfilename)\n        old = shlex.quote(filename)\n        logger.debug(\"ffmpeg -i {0} {1} -loglevel fatal\".format(old, new))\n        os.system(\"ffmpeg -i {0} {1} -loglevel fatal\".format(old, new))\n        os.remove(filename)\n        filename = newfilename\n\n    if filename.endswith('.mp3') or filename.endswith('.flac'):\n        try:\n            set_metadata(track, filename, playlist_name)\n        except Exception as e:\n            logger.error('Error trying to set the tags...')\n            logger.debug(e)\n    else:\n        logger.error(\"This type of audio doesn't support tagging...\")\n\n    # Try to change the real creation date\n    created_at = track['created_at']\n    timestamp = datetime.strptime(created_at, '%Y/%m/%d %H:%M:%S %z')\n    filetime = int(time.mktime(timestamp.timetuple()))\n    try_utime(filename, filetime)\n\n    logger.info('{0} Downloaded.\\n'.format(filename))\n    record_download_archive(track)", "response": "Downloads a track and adds it to the generated m3u playlist file if it does not already exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef already_downloaded(track, title, filename):\n    global arguments\n    already_downloaded = False\n\n    if os.path.isfile(filename):\n        already_downloaded = True\n    if arguments['--flac'] and can_convert(filename) \\\n                           and os.path.isfile(filename[:-4] + \".flac\"):\n        already_downloaded = True\n    if arguments['--download-archive'] and in_download_archive(track):\n        already_downloaded = True\n\n    if arguments['--flac'] and can_convert(filename) and os.path.isfile(filename):\n        already_downloaded = False\n\n    if already_downloaded:\n        if arguments['-c'] or arguments['--remove']:\n            logger.info('Track \"{0}\" already downloaded.'.format(title))\n            return True\n        else:\n            logger.error('Track \"{0}\" already exists!'.format(title))\n            logger.error('Exiting... (run again with -c to continue)')\n            sys.exit(0)\n    return False", "response": "Returns True if the file has already been downloaded False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if a track_id exists in the download archive otherwise False", "response": "def in_download_archive(track):\n    \"\"\"\n    Returns True if a track_id exists in the download archive\n    \"\"\"\n    global arguments\n    if not arguments['--download-archive']:\n        return\n\n    archive_filename = arguments.get('--download-archive')\n    try:\n        with open(archive_filename, 'a+', encoding='utf-8') as file:\n            logger.debug('Contents of {0}:'.format(archive_filename))\n            file.seek(0)\n            track_id = '{0}'.format(track['id'])\n            for line in file:\n                logger.debug('\"'+line.strip()+'\"')\n                if line.strip() == track_id:\n                    return True\n    except IOError as ioe:\n        logger.error('Error trying to read download archive...')\n        logger.debug(ioe)\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef record_download_archive(track):\n    global arguments\n    if not arguments['--download-archive']:\n        return\n\n    archive_filename = arguments.get('--download-archive')\n    try:\n        with open(archive_filename, 'a', encoding='utf-8') as file:\n            file.write('{0}'.format(track['id'])+'\\n')\n    except IOError as ioe:\n        logger.error('Error trying to write to download archive...')\n        logger.debug(ioe)", "response": "Write the track_id in the download archive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the mp3 file metadata using the Mutagen module.", "response": "def set_metadata(track, filename, album=None):\n    \"\"\"\n    Sets the mp3 file metadata using the Python module Mutagen\n    \"\"\"\n    logger.info('Setting tags...')\n    global arguments\n    artwork_url = track['artwork_url']\n    user = track['user']\n    if not artwork_url:\n        artwork_url = user['avatar_url']\n    artwork_url = artwork_url.replace('large', 't500x500')\n    response = requests.get(artwork_url, stream=True)\n    with tempfile.NamedTemporaryFile() as out_file:\n        shutil.copyfileobj(response.raw, out_file)\n        out_file.seek(0)\n\n        track_created = track['created_at']\n        track_date = datetime.strptime(track_created, \"%Y/%m/%d %H:%M:%S %z\")\n        debug_extract_dates = '{0} {1}'.format(track_created, track_date)\n        logger.debug('Extracting date: {0}'.format(debug_extract_dates))\n        track['date'] = track_date.strftime(\"%Y-%m-%d %H::%M::%S\")\n\n        track['artist'] = user['username']\n        if arguments['--extract-artist']:\n            for dash in [' - ', ' \u2212 ', ' \u2013 ', ' \u2014 ', ' \u2015 ']:\n                if dash in track['title']:\n                    artist_title = track['title'].split(dash)\n                    track['artist'] = artist_title[0].strip()\n                    track['title'] = artist_title[1].strip()\n                    break\n\n        audio = mutagen.File(filename, easy=True)\n        audio['title'] = track['title']\n        audio['artist'] = track['artist']\n        if album: audio['album'] = album\n        if track['genre']: audio['genre'] = track['genre']\n        if track['permalink_url']: audio['website'] = track['permalink_url']\n        if track['date']: audio['date'] = track['date']\n        audio.save()\n\n        a = mutagen.File(filename)\n        if track['description']:\n            if a.__class__ == mutagen.flac.FLAC:\n                a['description'] = track['description']\n            elif a.__class__ == mutagen.mp3.MP3:\n                a['COMM'] = mutagen.id3.COMM(\n                    encoding=3, lang=u'ENG', text=track['description']\n                )\n        if artwork_url:\n            if a.__class__ == mutagen.flac.FLAC:\n                p = mutagen.flac.Picture()\n                p.data = out_file.read()\n                p.width = 500\n                p.height = 500\n                p.type = mutagen.id3.PictureType.COVER_FRONT\n                a.add_picture(p)\n            elif a.__class__ == mutagen.mp3.MP3:\n                a['APIC'] = mutagen.id3.APIC(\n                    encoding=3, mime='image/jpeg', type=3,\n                    desc='Cover', data=out_file.read()\n                )\n        a.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_utf8(s):\n    if six.PY2:\n        if isinstance(s, str):\n            return s\n        elif isinstance(s, unicode):\n            return s.encode('utf-8')\n        elif isinstance(s, (list, tuple, set)):\n            return [to_utf8(v) for v in s]\n        else:\n            return s\n    else:\n        return s", "response": "Convert a string to utf8."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake sure the first parameter of the decorated method to be a unicode object.", "response": "def unicode_compact(func):\n    \"\"\"\n    Make sure the first parameter of the decorated method to be a unicode\n    object.\n    \"\"\"\n\n    @wraps(func)\n    def wrapped(self, text, *a, **kw):\n        if not isinstance(text, six.text_type):\n            text = text.decode('utf-8')\n        return func(self, text, *a, **kw)\n\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a reply to the sender using Web API.", "response": "def reply_webapi(self, text, attachments=None, as_user=True, in_thread=None):\n        \"\"\"\n            Send a reply to the sender using Web API\n\n            (This function supports formatted message\n            when using a bot integration)\n\n            If the message was send in a thread, answer in a thread per default.\n        \"\"\"\n        if in_thread is None:\n            in_thread = 'thread_ts' in self.body\n\n        if in_thread:\n            self.send_webapi(text, attachments=attachments, as_user=as_user, thread_ts=self.thread_ts)\n        else:\n            text = self.gen_reply(text)\n            self.send_webapi(text, attachments=attachments, as_user=as_user)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_webapi(self, text, attachments=None, as_user=True, thread_ts=None):\n        self._client.send_message(\n            self._body['channel'],\n            text,\n            attachments=attachments,\n            as_user=as_user,\n            thread_ts=thread_ts)", "response": "Send a message using Web API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a reply to the sender using RTM API.", "response": "def reply(self, text, in_thread=None):\n        \"\"\"\n            Send a reply to the sender using RTM API\n\n            (This function doesn't supports formatted message\n            when using a bot integration)\n\n            If the message was send in a thread, answer in a thread per default.\n        \"\"\"\n        if in_thread is None:\n            in_thread = 'thread_ts' in self.body\n\n        if in_thread:\n            self.send(text, thread_ts=self.thread_ts)\n        else:\n            text = self.gen_reply(text)\n            self.send(text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef direct_reply(self, text):\n        channel_id = self._client.open_dm_channel(self._get_user_id())\n        self._client.rtm_send_message(channel_id, text)", "response": "Send a direct reply via RTM API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, text, thread_ts=None):\n        self._client.rtm_send_message(self._body['channel'], text, thread_ts=thread_ts)", "response": "Send a reply using RTM API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef react(self, emojiname):\n        self._client.react_to_message(\n            emojiname=emojiname,\n            channel=self._body['channel'],\n            timestamp=self._body['ts'])", "response": "React to a message using the web api"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default_reply(*args, **kwargs):\n    invoked = bool(not args or kwargs)\n    matchstr = kwargs.pop('matchstr', r'^.*$')\n    flags = kwargs.pop('flags', 0)\n\n    if not invoked:\n        func = args[0]\n\n    def wrapper(func):\n        PluginsManager.commands['default_reply'][\n            re.compile(matchstr, flags)] = func\n        logger.info('registered default_reply plugin \"%s\" to \"%s\"', func.__name__,\n                    matchstr)\n        return func\n\n    return wrapper if invoked else wrapper(func)", "response": "Decorator to register a default reply plugin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend data directly to the websocket.", "response": "def send_to_websocket(self, data):\n        \"\"\"Send (data) directly to the websocket.\"\"\"\n        data = json.dumps(data)\n        self.websocket.send(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data from the websocket and returns it if available otherwise an empty string. Newlines indicate multiple messages", "response": "def websocket_safe_read(self):\n        \"\"\"Returns data if available, otherwise ''. Newlines indicate multiple messages \"\"\"\n        data = ''\n        while True:\n            try:\n                data += '{0}\\n'.format(self.websocket.recv())\n            except WebSocketException as e:\n                if isinstance(e, WebSocketConnectionClosedException):\n                    logger.warning('lost websocket connection, try to reconnect now')\n                else:\n                    logger.warning('websocket exception: %s', e)\n                self.reconnect()\n            except Exception as e:\n                if isinstance(e, SSLError) and e.errno == 2:\n                    pass\n                else:\n                    logger.warning('Exception in websocket_safe_read: %s', e)\n                return data.rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets Price for one bit coin on given date", "response": "def get_previous_price(self, currency, date_obj):\n        \"\"\"\n        Get Price for one bit coin on given date\n        \"\"\"\n        start = date_obj.strftime('%Y-%m-%d')\n        end = date_obj.strftime('%Y-%m-%d')\n        url = (\n            'https://api.coindesk.com/v1/bpi/historical/close.json'\n            '?start={}&end={}&currency={}'.format(\n                   start, end, currency\n               )\n        )\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            price = data.get('bpi', {}).get(start, None)\n            if self._force_decimal:\n                return Decimal(price)\n            return price\n        raise RatesNotAvailableError(\"BitCoin Rates Source Not Ready For Given date\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_previous_price_list(self, currency, start_date, end_date):\n        start = start_date.strftime('%Y-%m-%d')\n        end = end_date.strftime('%Y-%m-%d')\n        url = (\n            'https://api.coindesk.com/v1/bpi/historical/close.json'\n            '?start={}&end={}&currency={}'.format(\n                   start, end, currency\n               )\n        )\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = self._decode_rates(response)\n            price_dict = data.get('bpi', {})\n            return price_dict\n        return {}", "response": "Get the previous price list between two dates\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_to_btc(self, amount, currency):\n        if isinstance(amount, Decimal):\n            use_decimal = True\n        else:\n            use_decimal = self._force_decimal\n\n        url = 'https://api.coindesk.com/v1/bpi/currentprice/{}.json'.format(currency)\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            price = data.get('bpi').get(currency, {}).get('rate_float', None)\n            if price:\n                if use_decimal:\n                    price = Decimal(price)\n                try:\n                    converted_btc = amount/price\n                    return converted_btc\n                except TypeError:\n                    raise DecimalFloatMismatchError(\"convert_to_btc requires amount parameter is of type Decimal when force_decimal=True\")\n        raise RatesNotAvailableError(\"BitCoin Rates Source Not Ready For Given date\")", "response": "Convert X amount to Bit Coins"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts X bit coins to valid currency amount", "response": "def convert_btc_to_cur(self, coins, currency):\n        \"\"\"\n        Convert X bit coins to valid currency amount\n        \"\"\"\n        if isinstance(coins, Decimal):\n            use_decimal = True\n        else:\n            use_decimal = self._force_decimal\n\n        url = 'https://api.coindesk.com/v1/bpi/currentprice/{}.json'.format(currency)\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            price = data.get('bpi').get(currency, {}).get('rate_float', None)\n            if price:\n                if use_decimal:\n                    price = Decimal(price)\n                try:\n                    converted_amount = coins * price\n                    return converted_amount\n                except TypeError:\n                    raise DecimalFloatMismatchError(\"convert_btc_to_cur requires coins parameter is of type Decimal when force_decimal=True\")\n        raise RatesNotAvailableError(\"BitCoin Rates Source Not Ready For Given date\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert X amount to BTC based on given date rate", "response": "def convert_to_btc_on(self, amount, currency, date_obj):\n        \"\"\"\n        Convert X amount to BTC based on given date rate\n        \"\"\"\n        if isinstance(amount, Decimal):\n            use_decimal = True\n        else:\n            use_decimal = self._force_decimal\n\n        start = date_obj.strftime('%Y-%m-%d')\n        end = date_obj.strftime('%Y-%m-%d')\n        url = (\n            'https://api.coindesk.com/v1/bpi/historical/close.json'\n            '?start={}&end={}&currency={}'.format(\n                   start, end, currency\n               )\n        )\n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            price = data.get('bpi', {}).get(start, None)\n            if price:\n                if use_decimal:\n                    price = Decimal(price)\n                try:\n                    converted_btc = amount/price\n                    return converted_btc\n                except TypeError:\n                    raise DecimalFloatMismatchError(\"convert_to_btc_on requires amount parameter is of type Decimal when force_decimal=True\")\n        raise RatesNotAvailableError(\"BitCoin Rates Source Not Ready For Given Date\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rate_limit(f):\n    def new_f(*args, **kwargs):\n        errors = 0\n        while True:\n            resp = f(*args, **kwargs)\n            if resp.status_code == 200:\n                errors = 0\n                return resp\n            elif resp.status_code == 401:\n                # Hack to retain the original exception, but augment it with\n                # additional context for the user to interpret it. In a Python\n                # 3 only future we can raise a new exception of the same type\n                # with a new message from the old error.\n                try:\n                    resp.raise_for_status()\n                except requests.HTTPError as e:\n                    message = \"\\nThis is a protected or locked account, or\" +\\\n                              \" the credentials provided are no longer valid.\"\n                    e.args = (e.args[0] + message,) + e.args[1:]\n                    log.warning(\"401 Authentication required for %s\", resp.url)\n                    raise\n            elif resp.status_code == 429:\n                reset = int(resp.headers['x-rate-limit-reset'])\n                now = time.time()\n                seconds = reset - now + 10\n                if seconds < 1:\n                    seconds = 10\n                log.warning(\"rate limit exceeded: sleeping %s secs\", seconds)\n                time.sleep(seconds)\n            elif resp.status_code >= 500:\n                errors += 1\n                if errors > 30:\n                    log.warning(\"too many errors from Twitter, giving up\")\n                    resp.raise_for_status()\n                seconds = 60 * errors\n                log.warning(\"%s from Twitter API, sleeping %s\",\n                             resp.status_code, seconds)\n                time.sleep(seconds)\n            else:\n                resp.raise_for_status()\n    return new_f", "response": "A decorator to handle rate limiting from the Twitter API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef catch_conn_reset(f):\n    try:\n        import OpenSSL\n        ConnectionError = OpenSSL.SSL.SysCallError\n    except:\n        ConnectionError = None\n\n    def new_f(self, *args, **kwargs):\n        # Only handle if pyOpenSSL is installed.\n        if ConnectionError:\n            try:\n                return f(self, *args, **kwargs)\n            except ConnectionError as e:\n                log.warning(\"caught connection reset error: %s\", e)\n                self.connect()\n                return f(self, *args, **kwargs)\n        else:\n            return f(self, *args, **kwargs)\n    return new_f", "response": "A decorator to handle connection reset errors even ones from pyOpenSSL."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef catch_timeout(f):\n    def new_f(self, *args, **kwargs):\n        try:\n            return f(self, *args, **kwargs)\n        except (requests.exceptions.ReadTimeout,\n                requests.packages.urllib3.exceptions.ReadTimeoutError) as e:\n            log.warning(\"caught read timeout: %s\", e)\n            self.connect()\n            return f(self, *args, **kwargs)\n    return new_f", "response": "A decorator to handle read timeouts from Twitter.\n ArcGIS."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsleep for a specified duration optionally stopping early for event.", "response": "def interruptible_sleep(t, event=None):\n    \"\"\"\n    Sleeps for a specified duration, optionally stopping early for event.\n\n    Returns True if interrupted\n    \"\"\"\n    log.info(\"sleeping %s\", t)\n\n    if event is None:\n        time.sleep(t)\n        return False\n    else:\n        return not event.wait(t)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing media file URL s form tweet data", "response": "def parse_extended_entities(extended_entities_dict):\n    \"\"\"Parse media file URL:s form tweet data\n\n    :extended_entities_dict:\n    :returns: list of media file urls\n\n    \"\"\"\n    urls = []\n\n    if \"media\" in extended_entities_dict.keys():\n        for item in extended_entities_dict[\"media\"]:\n\n            # add static image\n            urls.append(item[\"media_url_https\"])\n\n            # add best quality video file\n            if \"video_info\" in item.keys():\n                max_bitrate = -1  # handle twitters occasional bitrate=0\n                video_url = None\n                for video in item[\"video_info\"][\"variants\"]:\n                    if \"bitrate\" in video.keys() and \"content_type\" in video.keys():\n                        if video[\"content_type\"] == \"video/mp4\":\n                            if int(video[\"bitrate\"]) > max_bitrate:\n                                max_bitrate = int(video[\"bitrate\"])\n                                video_url = video[\"url\"]\n\n                if not video_url:\n                    print(\"Error: No bitrate / content_type\")\n                    print(item[\"video_info\"])\n                else:\n                    urls.append(video_url)\n\n    return urls"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse binary file url s from a single tweet.", "response": "def parse_binlinks_from_tweet(tweetdict):\n    \"\"\"Parse binary file url:s from a single tweet.\n\n    :tweetdict: json data dict for tweet\n    :returns: list of urls for media files\n\n    \"\"\"\n\n    urls = []\n\n    if \"user\" in tweetdict.keys():\n        urls.append(tweetdict[\"user\"][\"profile_image_url_https\"])\n        urls.append(tweetdict[\"user\"][\"profile_background_image_url_https\"])\n\n    if \"extended_entities\" in tweetdict.keys():\n        urls.extend(parse_extended_entities(tweetdict[\"extended_entities\"]))\n    return urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over json files in path.", "response": "def tweets_files(string, path):\n    \"\"\"Iterates over json files in path.\"\"\"\n    for filename in os.listdir(path):\n        if re.match(string, filename) and \".jsonl\" in filename:\n            f = gzip.open if \".gz\" in filename else open\n            yield path + filename, f\n\n            Ellipsis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract and write found attributes.", "response": "def extract(json_object, args, csv_writer):\n    \"\"\"Extract and write found attributes.\"\"\"\n    found = [[]]\n    for attribute in args.attributes:\n        item = attribute.getElement(json_object)\n        if len(item) == 0:\n            for row in found:\n                row.append(\"NA\")\n        else:\n            found1 = []\n            for value in item:\n                if value is None:\n                    value = \"NA\"\n                new = copy.deepcopy(found)\n                for row in new:\n                    row.append(value)\n                found1.extend(new)\n            found = found1\n\n    for row in found:\n\n        csv_writer.writerow(row)\n    return len(found)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(from_user, from_id, to_user, to_id, type):\n    \"adds a relation to the graph\"\n\n    if options.users and to_user:\n        G.add_node(from_user, screen_name=from_user)\n        G.add_node(to_user, screen_name=to_user)\n       \n        if G.has_edge(from_user, to_user):\n            weight = G[from_user][to_user]['weight'] + 1\n        else:\n            weight = 1\n        G.add_edge(from_user, to_user, type=type, weight=weight)\n\n    elif not options.users and to_id:\n        G.add_node(from_id, screen_name=from_user, type=type)\n        if to_user:\n            G.add_node(to_id, screen_name=to_user)\n        else:\n            G.add_node(to_id)\n        G.add_edge(from_id, to_id, type=type)", "response": "adds a relation to the graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator of tuples that yields the user_id and friend_id of a protected user.", "response": "def friendships(user_id, level=2):\n    \"\"\"\n    Pass in a user_id and you will be returned a generator of friendship \n    tuples (user_id, friend_id). By default it will return the friend\n    of a friend network (level=2), but you can expand this by settings the \n    level parameter to either another number. But beware, it could run for a \n    while!\n    \"\"\"\n\n    logging.info(\"getting friends for user %s\", user_id)\n    level -= 1\n    try:\n        for friend_id in t.friend_ids(user_id):\n            yield (user_id, friend_id)\n            if level > 0:\n                yield from friendships(friend_id, level)\n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 401:\n            logging.error(\"can't get friends for protected user %s\", user_id)\n        else:\n            raise(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, q, max_id=None, since_id=None, lang=None,\n               result_type='recent', geocode=None, max_pages=None):\n        \"\"\"\n        Pass in a query with optional max_id, min_id, lang or geocode\n        and get back an iterator for decoded tweets. Defaults to recent (i.e.\n        not mixed, the API default, or popular) tweets.\n        \"\"\"\n        url = \"https://api.twitter.com/1.1/search/tweets.json\"\n        params = {\n            \"count\": 100,\n            \"q\": q,\n            \"include_ext_alt_text\": 'true'\n        }\n        if lang is not None:\n            params['lang'] = lang\n        if result_type in ['mixed', 'recent', 'popular']:\n            params['result_type'] = result_type\n        else:\n            params['result_type'] = 'recent'\n        if geocode is not None:\n            params['geocode'] = geocode\n\n        retrieved_pages = 0\n        reached_end = False\n\n        while True:\n            if since_id:\n                # Make the since_id inclusive, so we can avoid retrieving\n                # an empty page of results in some cases\n                params['since_id'] = str(int(since_id) - 1)\n            if max_id:\n                params['max_id'] = max_id\n\n            resp = self.get(url, params=params)\n            retrieved_pages += 1\n\n            statuses = resp.json()[\"statuses\"]\n\n            if len(statuses) == 0:\n                log.info(\"no new tweets matching %s\", params)\n                break\n\n            for status in statuses:\n                # We've certainly reached the end of new results\n                if since_id is not None and status['id_str'] == str(since_id):\n                    reached_end = True\n                    break\n\n                yield status\n\n            if reached_end:\n                log.info(\"no new tweets matching %s\", params)\n                break\n\n            if max_pages is not None and retrieved_pages == max_pages:\n                log.info(\"reached max page limit for %s\", params)\n                break\n\n            max_id = str(int(status[\"id_str\"]) - 1)", "response": "Search for tweets in the twitter API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timeline(self, user_id=None, screen_name=None, max_id=None,\n                 since_id=None, max_pages=None):\n        \"\"\"\n        Returns a collection of the most recent tweets posted\n        by the user indicated by the user_id or screen_name parameter.\n        Provide a user_id or screen_name.\n        \"\"\"\n\n        if user_id and screen_name:\n            raise ValueError('only user_id or screen_name may be passed')\n\n        # Strip if screen_name is prefixed with '@'\n        if screen_name:\n            screen_name = screen_name.lstrip('@')\n        id = screen_name or str(user_id)\n        id_type = \"screen_name\" if screen_name else \"user_id\"\n        log.info(\"starting user timeline for user %s\", id)\n\n        if screen_name or user_id:\n            url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n        else:\n            url = \"https://api.twitter.com/1.1/statuses/home_timeline.json\"\n\n        params = {\"count\": 200, id_type: id, \"include_ext_alt_text\": \"true\"}\n\n        retrieved_pages = 0\n        reached_end = False\n\n        while True:\n            if since_id:\n                # Make the since_id inclusive, so we can avoid retrieving\n                # an empty page of results in some cases\n                params['since_id'] = str(int(since_id) - 1)\n            if max_id:\n                params['max_id'] = max_id\n\n            try:\n                resp = self.get(url, params=params, allow_404=True)\n                retrieved_pages += 1\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 404:\n                    log.warn(\"no timeline available for %s\", id)\n                    break\n                elif e.response.status_code == 401:\n                    log.warn(\"protected account %s\", id)\n                    break\n                raise e\n\n            statuses = resp.json()\n\n            if len(statuses) == 0:\n                log.info(\"no new tweets matching %s\", params)\n                break\n\n            for status in statuses:\n                # We've certainly reached the end of new results\n                if since_id is not None and status['id_str'] == str(since_id):\n                    reached_end = True\n                    break\n                # If you request an invalid user_id, you may still get\n                # results so need to check.\n                if not user_id or id == status.get(\"user\",\n                                                   {}).get(\"id_str\"):\n                    yield status\n\n            if reached_end:\n                log.info(\"no new tweets matching %s\", params)\n                break\n\n            if max_pages is not None and retrieved_pages == max_pages:\n                log.info(\"reached max page limit for %s\", params)\n                break\n\n            max_id = str(int(status[\"id_str\"]) - 1)", "response": "Returns a collection of most recent tweets posted by the user indicated by the user_id or screen_name parameter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef user_lookup(self, ids, id_type=\"user_id\"):\n\n        if id_type not in ['user_id', 'screen_name']:\n            raise RuntimeError(\"id_type must be user_id or screen_name\")\n\n        if not isinstance(ids, types.GeneratorType):\n            ids = iter(ids)\n\n        # TODO: this is similar to hydrate, maybe they could share code?\n\n        lookup_ids = []\n\n        def do_lookup():\n            ids_str = \",\".join(lookup_ids)\n            log.info(\"looking up users %s\", ids_str)\n            url = 'https://api.twitter.com/1.1/users/lookup.json'\n            params = {id_type: ids_str}\n            try:\n                resp = self.get(url, params=params, allow_404=True)\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 404:\n                    log.warning(\"no users matching %s\", ids_str)\n                raise e\n            return resp.json()\n\n        for id in ids:\n            lookup_ids.append(id.strip())\n            if len(lookup_ids) == 100:\n                for u in do_lookup():\n                    yield u\n                lookup_ids = []\n\n        if len(lookup_ids) > 0:\n            for u in do_lookup():\n                yield u", "response": "A generator that returns users for supplied user ids screen_names or user_id or screen_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef follower_ids(self, user):\n        user = str(user)\n        user = user.lstrip('@')\n        url = 'https://api.twitter.com/1.1/followers/ids.json'\n\n        if re.match(r'^\\d+$', user):\n            params = {'user_id': user, 'cursor': -1}\n        else:\n            params = {'screen_name': user, 'cursor': -1}\n\n        while params['cursor'] != 0:\n            try:\n                resp = self.get(url, params=params, allow_404=True)\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 404:\n                    log.info(\"no users matching %s\", screen_name)\n                raise e\n            user_ids = resp.json()\n            for user_id in user_ids['ids']:\n                yield str_type(user_id)\n            params['cursor'] = user_ids['next_cursor']", "response": "Returns a generator that yields Twitter user id lists for the specified user s followers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator for tweets that match a given filter track.", "response": "def filter(self, track=None, follow=None, locations=None, event=None,\n               record_keepalive=False):\n        \"\"\"\n        Returns an iterator for tweets that match a given filter track from\n        the livestream of tweets happening right now.\n\n        If a threading.Event is provided for event and the event is set,\n        the filter will be interrupted.\n        \"\"\"\n        if locations is not None:\n            if type(locations) == list:\n                locations = ','.join(locations)\n            locations = locations.replace('\\\\', '')\n\n        url = 'https://stream.twitter.com/1.1/statuses/filter.json'\n        params = {\n            \"stall_warning\": True,\n            \"include_ext_alt_text\": True\n        }\n        if track:\n            params[\"track\"] = track\n        if follow:\n            params[\"follow\"] = follow\n        if locations:\n            params[\"locations\"] = locations\n        headers = {'accept-encoding': 'deflate, gzip'}\n        errors = 0\n        while True:\n            try:\n                log.info(\"connecting to filter stream for %s\", params)\n                resp = self.post(url, params, headers=headers, stream=True)\n                errors = 0\n                for line in resp.iter_lines(chunk_size=1024):\n                    if event and event.is_set():\n                        log.info(\"stopping filter\")\n                        # Explicitly close response\n                        resp.close()\n                        return\n                    if not line:\n                        log.info(\"keep-alive\")\n                        if record_keepalive:\n                            yield \"keep-alive\"\n                        continue\n                    try:\n                        yield json.loads(line.decode())\n                    except Exception as e:\n                        log.error(\"json parse error: %s - %s\", e, line)\n            except requests.exceptions.HTTPError as e:\n                errors += 1\n                log.error(\"caught http error %s on %s try\", e, errors)\n                if self.http_errors and errors == self.http_errors:\n                    log.warning(\"too many errors\")\n                    raise e\n                if e.response.status_code == 420:\n                    if interruptible_sleep(errors * 60, event):\n                        log.info(\"stopping filter\")\n                        return\n                else:\n                    if interruptible_sleep(errors * 5, event):\n                        log.info(\"stopping filter\")\n                        return\n            except Exception as e:\n                errors += 1\n                log.error(\"caught exception %s on %s try\", e, errors)\n                if self.http_errors and errors == self.http_errors:\n                    log.warning(\"too many exceptions\")\n                    raise e\n                log.error(e)\n                if interruptible_sleep(errors, event):\n                    log.info(\"stopping filter\")\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a small random sample of all public statuses.", "response": "def sample(self, event=None, record_keepalive=False):\n        \"\"\"\n        Returns a small random sample of all public statuses. The Tweets\n        returned by the default access level are the same, so if two different\n        clients connect to this endpoint, they will see the same Tweets.\n\n        If a threading.Event is provided for event and the event is set,\n        the sample will be interrupted.\n        \"\"\"\n        url = 'https://stream.twitter.com/1.1/statuses/sample.json'\n        params = {\"stall_warning\": True}\n        headers = {'accept-encoding': 'deflate, gzip'}\n        errors = 0\n        while True:\n            try:\n                log.info(\"connecting to sample stream\")\n                resp = self.post(url, params, headers=headers, stream=True)\n                errors = 0\n                for line in resp.iter_lines(chunk_size=512):\n                    if event and event.is_set():\n                        log.info(\"stopping sample\")\n                        # Explicitly close response\n                        resp.close()\n                        return\n                    if line == \"\":\n                        log.info(\"keep-alive\")\n                        if record_keepalive:\n                            yield \"keep-alive\"\n                        continue\n                    try:\n                        yield json.loads(line.decode())\n                    except Exception as e:\n                        log.error(\"json parse error: %s - %s\", e, line)\n            except requests.exceptions.HTTPError as e:\n                errors += 1\n                log.error(\"caught http error %s on %s try\", e, errors)\n                if self.http_errors and errors == self.http_errors:\n                    log.warning(\"too many errors\")\n                    raise e\n                if e.response.status_code == 420:\n                    if interruptible_sleep(errors * 60, event):\n                        log.info(\"stopping filter\")\n                        return\n                else:\n                    if interruptible_sleep(errors * 5, event):\n                        log.info(\"stopping filter\")\n                        return\n\n            except Exception as e:\n                errors += 1\n                log.error(\"caught exception %s on %s try\", e, errors)\n                if self.http_errors and errors == self.http_errors:\n                    log.warning(\"too many errors\")\n                    raise e\n                if interruptible_sleep(errors, event):\n                    log.info(\"stopping filter\")\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npasses in an iterator of tweets' JSON and get back an iterator of the IDs of each tweet.", "response": "def dehydrate(self, iterator):\n        \"\"\"\n        Pass in an iterator of tweets' JSON and get back an iterator of the\n        IDs of each tweet.\n        \"\"\"\n        for line in iterator:\n            try:\n                yield json.loads(line)['id_str']\n            except Exception as e:\n                log.error(\"uhoh: %s\\n\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npassing in an iterator of tweet ids and get back an iterator for each corresponding tweet.", "response": "def hydrate(self, iterator):\n        \"\"\"\n        Pass in an iterator of tweet ids and get back an iterator for the\n        decoded JSON for each corresponding tweet.\n        \"\"\"\n        ids = []\n        url = \"https://api.twitter.com/1.1/statuses/lookup.json\"\n\n        # lookup 100 tweets at a time\n        for tweet_id in iterator:\n            tweet_id = str(tweet_id)\n            tweet_id = tweet_id.strip()  # remove new line if present\n            ids.append(tweet_id)\n            if len(ids) == 100:\n                log.info(\"hydrating %s ids\", len(ids))\n                resp = self.post(url, data={\n                    \"id\": ','.join(ids),\n                    \"include_ext_alt_text\": 'true'\n                })\n                tweets = resp.json()\n                tweets.sort(key=lambda t: t['id_str'])\n                for tweet in tweets:\n                    yield tweet\n                ids = []\n\n        # hydrate any remaining ones\n        if len(ids) > 0:\n            log.info(\"hydrating %s\", ids)\n            resp = self.post(url, data={\n                \"id\": ','.join(ids),\n                \"include_ext_alt_text\": 'true'\n            })\n            for tweet in resp.json():\n                yield tweet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retweets(self, tweet_id):\n        log.info(\"retrieving retweets of %s\", tweet_id)\n        url = \"https://api.twitter.com/1.1/statuses/retweets/\"\"{}.json\".format(\n                tweet_id)\n\n        resp = self.get(url, params={\"count\": 100})\n        for tweet in resp.json():\n            yield tweet", "response": "Returns a generator that yields the most recent 100 retweets for the provided tweet_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of regions for which Twitter tracks trends.", "response": "def trends_available(self):\n        \"\"\"\n        Returns a list of regions for which Twitter tracks trends.\n        \"\"\"\n        url = 'https://api.twitter.com/1.1/trends/available.json'\n        try:\n            resp = self.get(url)\n        except requests.exceptions.HTTPError as e:\n            raise e\n        return resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trends_place(self, woeid, exclude=None):\n        url = 'https://api.twitter.com/1.1/trends/place.json'\n        params = {'id': woeid}\n        if exclude:\n            params['exclude'] = exclude\n        try:\n            resp = self.get(url, params=params, allow_404=True)\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 404:\n                log.info(\"no region matching WOEID %s\", woeid)\n            raise e\n        return resp.json()", "response": "Returns recent Twitter trends for the specified WOEID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the closest regions for the supplied lat lon.", "response": "def trends_closest(self, lat, lon):\n        \"\"\"\n        Returns the closest regions for the supplied lat/lon.\n        \"\"\"\n        url = 'https://api.twitter.com/1.1/trends/closest.json'\n        params = {'lat': lat, 'long': lon}\n        try:\n            resp = self.get(url, params=params)\n        except requests.exceptions.HTTPError as e:\n            raise e\n        return resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator of tweets that are replies for a given tweet.", "response": "def replies(self, tweet, recursive=False, prune=()):\n        \"\"\"\n        replies returns a generator of tweets that are replies for a given\n        tweet. It includes the original tweet. If you would like to fetch the\n        replies to the replies use recursive=True which will do a depth-first\n        recursive walk of the replies. It also walk up the reply chain if you\n        supply a tweet that is itself a reply to another tweet. You can\n        optionally supply a tuple of tweet ids to ignore during this traversal\n        using the prune parameter.\n        \"\"\"\n\n        yield tweet\n\n        # get replies to the tweet\n        screen_name = tweet['user']['screen_name']\n        tweet_id = tweet['id_str']\n        log.info(\"looking for replies to: %s\", tweet_id)\n        for reply in self.search(\"to:%s\" % screen_name, since_id=tweet_id):\n\n            if reply['in_reply_to_status_id_str'] != tweet_id:\n                continue\n\n            if reply['id_str'] in prune:\n                log.info(\"ignoring pruned tweet id %s\", reply['id_str'])\n                continue\n\n            log.info(\"found reply: %s\", reply[\"id_str\"])\n\n            if recursive:\n                if reply['id_str'] not in prune:\n                    prune = prune + (tweet_id,)\n                    for r in self.replies(reply, recursive, prune):\n                        yield r\n            else:\n                yield reply\n\n        # if this tweet is itself a reply to another tweet get it and\n        # get other potential replies to it\n\n        reply_to_id = tweet.get('in_reply_to_status_id_str')\n        log.info(\"prune=%s\", prune)\n        if recursive and reply_to_id and reply_to_id not in prune:\n            t = self.tweet(reply_to_id)\n            if t:\n                log.info(\"found reply-to: %s\", t['id_str'])\n                prune = prune + (tweet['id_str'],)\n                for r in self.replies(t, recursive=True, prune=prune):\n                    yield r\n\n        # if this tweet is a quote go get that too whatever tweets it\n        # may be in reply to\n\n        quote_id = tweet.get('quotes_status_id_str')\n        if recursive and quote_id and quote_id not in prune:\n            t = self.tweet(quote_id)\n            if t:\n                log.info(\"found quote: %s\", t['id_str'])\n                prune = prune + (tweet['id_str'],)\n                for r in self.replies(t, recursive=True, prune=prune):\n                    yield r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the members of a list.", "response": "def list_members(self, list_id=None, slug=None, owner_screen_name=None, owner_id=None):\n        \"\"\"\n        Returns the members of a list.\n\n        List id or (slug and (owner_screen_name or owner_id)) are required\n        \"\"\"\n        assert list_id or (slug and (owner_screen_name or owner_id))\n        url = 'https://api.twitter.com/1.1/lists/members.json'\n        params = {'cursor': -1}\n        if list_id:\n            params['list_id'] = list_id\n        else:\n            params['slug'] = slug\n            if owner_screen_name:\n                params['owner_screen_name'] = owner_screen_name\n            else:\n                params['owner_id'] = owner_id\n\n        while params['cursor'] != 0:\n            try:\n                resp = self.get(url, params=params, allow_404=True)\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 404:\n                    log.error(\"no matching list\")\n                raise e\n\n            users = resp.json()\n            for user in users['users']:\n                yield user\n            params['cursor'] = users['next_cursor']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to the Twitter API.", "response": "def connect(self):\n        \"\"\"\n        Sets up the HTTP session to talk to Twitter. If one is active it is\n        closed and another one is opened.\n        \"\"\"\n        if not (self.consumer_key and self.consumer_secret and self.access_token\n                and self.access_token_secret):\n            raise RuntimeError(\"MissingKeys\")\n\n        if self.client:\n            log.info(\"closing existing http session\")\n            self.client.close()\n        if self.last_response:\n            log.info(\"closing last response\")\n            self.last_response.close()\n        log.info(\"creating http session\")\n\n        self.client = OAuth1Session(\n            client_key=self.consumer_key,\n            client_secret=self.consumer_secret,\n            resource_owner_key=self.access_token,\n            resource_owner_secret=self.access_token_secret\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_keys(self):\n        env = os.environ.get\n        if not self.consumer_key:\n            self.consumer_key = env('CONSUMER_KEY')\n        if not self.consumer_secret:\n            self.consumer_secret = env('CONSUMER_SECRET')\n        if not self.access_token:\n            self.access_token = env('ACCESS_TOKEN')\n        if not self.access_token_secret:\n            self.access_token_secret = env('ACCESS_TOKEN_SECRET')\n\n        if self.config and not (self.consumer_key and\n                                self.consumer_secret and\n                                self.access_token and\n                                self.access_token_secret):\n            self.load_config()", "response": "Get the Twitter API keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the keys provided are authentic credentials.", "response": "def validate_keys(self):\n        \"\"\"\n        Validate the keys provided are authentic credentials.\n        \"\"\"\n        url = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n\n        keys_present = self.consumer_key and self.consumer_secret and \\\n                       self.access_token and self.access_token_secret\n\n        if keys_present:\n            try:\n                # Need to explicitly reconnect to confirm the current creds\n                # are used in the session object.\n                self.connect()\n                self.get(url)\n            except requests.HTTPError as e:\n                if e.response.status_code == 401:\n                    raise RuntimeError('Invalid credentials provided.')\n                else:\n                    raise e\n        else:\n            raise RuntimeError('Incomplete credentials provided.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the command line argument parser.", "response": "def get_argparser():\n    \"\"\"\n    Get the command line argument parser.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\"twarc\")\n    parser.add_argument('command', choices=commands)\n    parser.add_argument('query', nargs='?', default=None)\n    parser.add_argument(\"--log\", dest=\"log\",\n                        default=\"twarc.log\", help=\"log file\")\n    parser.add_argument(\"--consumer_key\",\n                        default=None, help=\"Twitter API consumer key\")\n    parser.add_argument(\"--consumer_secret\",\n                        default=None, help=\"Twitter API consumer secret\")\n    parser.add_argument(\"--access_token\",\n                        default=None, help=\"Twitter API access key\")\n    parser.add_argument(\"--access_token_secret\",\n                        default=None, help=\"Twitter API access token secret\")\n    parser.add_argument('--config',\n                        help=\"Config file containing Twitter keys and secrets\")\n    parser.add_argument('--profile',\n                        help=\"Name of a profile in your configuration file\")\n    parser.add_argument('--warnings', action='store_true',\n                        help=\"Include warning messages in output\")\n    parser.add_argument(\"--connection_errors\", type=int, default=\"0\",\n                        help=\"Number of connection errors before giving up\")\n    parser.add_argument(\"--http_errors\", type=int, default=\"0\",\n                        help=\"Number of http errors before giving up\")\n    parser.add_argument(\"--max_id\", dest=\"max_id\",\n                        help=\"maximum tweet id to search for\")\n    parser.add_argument(\"--since_id\", dest=\"since_id\",\n                        help=\"smallest id to search for\")\n    parser.add_argument(\"--result_type\", dest=\"result_type\",\n                        choices=[\"mixed\", \"recent\", \"popular\"],\n                        default=\"recent\", help=\"search result type\")\n    parser.add_argument(\"--lang\", dest=\"lang\",\n                        help=\"limit to ISO 639-1 language code\"),\n    parser.add_argument(\"--geocode\", dest=\"geocode\",\n                        help=\"limit by latitude,longitude,radius\")\n    parser.add_argument(\"--locations\", dest=\"locations\",\n                        help=\"limit filter stream to location(s)\")\n    parser.add_argument(\"--follow\", dest=\"follow\",\n                        help=\"limit filter to tweets from given user id(s)\")\n    parser.add_argument(\"--recursive\", dest=\"recursive\", action=\"store_true\",\n                        help=\"also fetch replies to replies\")\n    parser.add_argument(\"--tweet_mode\", action=\"store\", default=\"extended\",\n                        dest=\"tweet_mode\", choices=[\"compat\", \"extended\"],\n                        help=\"set tweet mode\")\n    parser.add_argument(\"--protected\", dest=\"protected\", action=\"store_true\",\n                        help=\"include protected tweets\")\n    parser.add_argument(\"--output\", action=\"store\", default=None,\n                        dest=\"output\", help=\"write output to file path\")\n    parser.add_argument(\"--format\", action=\"store\", default=\"json\",\n                        dest=\"format\", choices=[\"json\", \"csv\", \"csv-excel\"],\n                        help=\"set output format\")\n    parser.add_argument(\"--split\", action=\"store\", type=int, default=0,\n                        help=\"used with --output to split into numbered files\")\n    parser.add_argument(\"--skip_key_validation\", action=\"store_true\",\n                        help=\"skip checking keys are valid on startup\")\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the dynaconf configuration for the given application.", "response": "def init_app(self, app, **kwargs):\n        \"\"\"kwargs holds initial dynaconf configuration\"\"\"\n        self.kwargs.update(kwargs)\n        self.settings = self.dynaconf_instance or LazySettings(**self.kwargs)\n        app.config = self.make_config(app)\n        app.dynaconf = self.settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, key, default=None):\n        return self._settings.get(key, Config.get(self, key, default))", "response": "Gets config from dynaconf variables\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef object_merge(old, new, unique=False):\n    if isinstance(old, list) and isinstance(new, list):\n        if old == new:\n            return\n        for item in old[::-1]:\n            if unique and item in new:\n                continue\n            new.insert(0, item)\n    if isinstance(old, dict) and isinstance(new, dict):\n        for key, value in old.items():\n            if key not in new:\n                new[key] = value\n            else:\n                object_merge(value, new[key])", "response": "Recursively merge two data structures."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deduplicate(list_object):\n    new = []\n    for item in list_object:\n        if item not in new:\n            new.append(item)\n    return new", "response": "Rebuild list_object removing duplicated and keeping order"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trimmed_split(s, seps=(\";\", \",\")):\n    for sep in seps:\n        if sep not in s:\n            continue\n        data = [item.strip() for item in s.strip().split(sep)]\n        return data\n    return [s]", "response": "Given a string s split is by one of one of the seps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure data is a list or wrap it in a list", "response": "def ensure_a_list(data):\n    \"\"\"Ensure data is a list or wrap it in a list\"\"\"\n    if not data:\n        return []\n    if isinstance(data, (list, tuple, set)):\n        return list(data)\n    if isinstance(data, str):\n        data = trimmed_split(data)  # settings.toml,other.yaml\n        return data\n    return [data]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading and loads in to obj a single key or all keys from source file.", "response": "def load(obj, env=None, silent=True, key=None, filename=None):\n    \"\"\"\n    Reads and loads in to \"obj\" a single key or all keys from source file.\n\n    :param obj: the settings instance\n    :param env: settings current env default='development'\n    :param silent: if errors should raise\n    :param key: if defined load a single key, else load all in env\n    :param filename: Optional custom filename to load\n    :return: None\n    \"\"\"\n    if yaml is None:  # pragma: no cover\n        BaseLoader.warn_not_installed(obj, \"yaml\")\n        return\n\n    # Resolve the loaders\n    # https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation\n    # Possible values are `safe_load, full_load, unsafe_load, load`\n    yaml_reader = getattr(yaml, obj.get(\"YAML_LOADER_FOR_DYNACONF\"), yaml.load)\n    if yaml_reader.__name__ == \"unsafe_load\":  # pragma: no cover\n        warn(\n            \"yaml.unsafe_load is deprecated.\"\n            \" Please read https://msg.pyyaml.org/load for full details.\"\n            \" Try to use full_load or safe_load.\"\n        )\n\n    loader = BaseLoader(\n        obj=obj,\n        env=env,\n        identifier=\"yaml\",\n        extensions=YAML_EXTENSIONS,\n        file_reader=yaml_reader,\n        string_reader=yaml_reader,\n    )\n    loader.load(filename=filename, key=key, silent=silent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data to a new settings file.", "response": "def write(settings_path, settings_data, merge=True):\n    \"\"\"Write data to a settings file.\n\n    :param settings_path: the filepath\n    :param settings_data: a dictionary with data\n    :param merge: boolean if existing file should be merged with new data\n    \"\"\"\n    settings_path = Path(settings_path)\n    if settings_path.exists() and merge:  # pragma: no cover\n        with io.open(\n            str(settings_path), encoding=default_settings.ENCODING_FOR_DYNACONF\n        ) as open_file:\n            object_merge(yaml.full_load(open_file), settings_data)\n\n    with io.open(\n        str(settings_path),\n        \"w\",\n        encoding=default_settings.ENCODING_FOR_DYNACONF,\n    ) as open_file:\n        yaml.dump(settings_data, open_file)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(obj, env=None, silent=True, key=None):\n    redis = StrictRedis(**obj.get(\"REDIS_FOR_DYNACONF\"))\n    holder = obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\")\n    try:\n        if key:\n            value = redis.hget(holder.upper(), key)\n            if value:\n                obj.logger.debug(\n                    \"redis_loader: loading by key: %s:%s (%s:%s)\",\n                    key,\n                    value,\n                    IDENTIFIER,\n                    holder,\n                )\n            if value:\n                parsed_value = parse_conf_data(value, tomlfy=True)\n                if parsed_value:\n                    obj.set(key, parsed_value)\n        else:\n            data = {\n                key: parse_conf_data(value, tomlfy=True)\n                for key, value in redis.hgetall(holder.upper()).items()\n            }\n            if data:\n                obj.logger.debug(\n                    \"redis_loader: loading: %s (%s:%s)\",\n                    data,\n                    IDENTIFIER,\n                    holder,\n                )\n                obj.update(data, loader_identifier=IDENTIFIER)\n    except Exception as e:\n        if silent:\n            if hasattr(obj, \"logger\"):\n                obj.logger.error(str(e))\n            return False\n        raise", "response": "Reads and loads in to settings a single key or all keys from redis"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(obj, data=None, **kwargs):\n    if obj.REDIS_ENABLED_FOR_DYNACONF is False:\n        raise RuntimeError(\n            \"Redis is not configured \\n\"\n            \"export REDIS_ENABLED_FOR_DYNACONF=true\\n\"\n            \"and configure the REDIS_FOR_DYNACONF_* variables\"\n        )\n    client = StrictRedis(**obj.REDIS_FOR_DYNACONF)\n    holder = obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\")\n    data = data or {}\n    data.update(kwargs)\n    if not data:\n        raise AttributeError(\"Data must be provided\")\n    redis_data = {\n        key.upper(): unparse_conf_data(value) for key, value in data.items()\n    }\n    client.hmset(holder.upper(), redis_data)\n    load(obj)", "response": "Write a value in to loader source\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(obj, key=None):\n    client = StrictRedis(**obj.REDIS_FOR_DYNACONF)\n    holder = obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\")\n    if key:\n        client.hdel(holder.upper(), key.upper())\n        obj.unset(key)\n    else:\n        keys = client.hkeys(holder.upper())\n        client.delete(holder.upper())\n        obj.unset_all(keys)", "response": "Delete a single key or all env variables if key is none."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to import a python module and loads it into the object", "response": "def load(obj, settings_module, identifier=\"py\", silent=False, key=None):\n    \"\"\"Tries to import a python module\"\"\"\n    mod, loaded_from = get_module(obj, settings_module, silent)\n\n    if mod and loaded_from:\n        obj.logger.debug(\"py_loader: {}\".format(mod))\n    else:\n        obj.logger.debug(\n            \"py_loader: %s (Ignoring, Not Found)\", settings_module\n        )\n        return\n\n    for setting in dir(mod):\n        if setting.isupper():\n            if key is None or key == setting:\n                setting_value = getattr(mod, setting)\n                obj.logger.debug(\n                    \"py_loader: loading %s: %s (%s)\",\n                    setting,\n                    \"*****\" if \"secret\" in settings_module else setting_value,\n                    identifier,\n                )\n                obj.set(setting, setting_value, loader_identifier=identifier)\n\n    obj._loaded_files.append(mod.__file__)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_from_filename(obj, filename, silent=False):  # pragma: no cover\n    if filename in [item.filename for item in inspect.stack()]:\n        raise ImportError(\n            \"Looks like you are loading dynaconf \"\n            \"from inside the {} file and then it is trying \"\n            \"to load itself entering in a circular reference \"\n            \"problem. To solve it you have to \"\n            \"invoke your program from another root folder \"\n            \"or rename your program file.\".format(filename)\n        )\n\n    _find_file = getattr(obj, \"find_file\", find_file)\n    if not filename.endswith(\".py\"):\n        filename = \"{0}.py\".format(filename)\n\n    if filename in default_settings.SETTINGS_FILE_FOR_DYNACONF:\n        silent = True\n    mod = types.ModuleType(filename.rstrip(\".py\"))\n    mod.__file__ = filename\n    mod._is_error = False\n    try:\n        with io.open(\n            _find_file(filename),\n            encoding=default_settings.ENCODING_FOR_DYNACONF,\n        ) as config_file:\n            exec(compile(config_file.read(), filename, \"exec\"), mod.__dict__)\n    except IOError as e:\n        e.strerror = (\"py_loader: error loading file (%s %s)\\n\") % (\n            e.strerror,\n            filename,\n        )\n        if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n            return\n        raw_logger().debug(e.strerror)\n        mod._is_error = True\n    return mod", "response": "Imports a module from a file path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(settings_path, settings_data, merge=True):\n    settings_path = Path(settings_path)\n    if settings_path.exists() and merge:  # pragma: no cover\n        existing = DynaconfDict()\n        load(existing, str(settings_path))\n        object_merge(existing, settings_data)\n    with io.open(\n        str(settings_path),\n        \"w\",\n        encoding=default_settings.ENCODING_FOR_DYNACONF,\n    ) as f:\n        f.writelines(\n            [\n                \"{} = {}\\n\".format(k.upper(), repr(v))\n                for k, v in settings_data.items()\n            ]\n        )", "response": "Write data to a new settings file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the list of environments to read", "response": "def _get_env_list(obj, env):\n    \"\"\"Creates the list of environments to read\n\n    :param obj: the settings instance\n    :param env: settings env default='DYNACONF'\n    :return: a list of working environments\n    \"\"\"\n    # add the [default] env\n    env_list = [obj.get(\"DEFAULT_ENV_FOR_DYNACONF\")]\n    # compatibility with older versions that still uses [dynaconf] as\n    # [default] env\n    global_env = obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\") or \"DYNACONF\"\n    if global_env not in env_list:\n        env_list.append(global_env)\n    # add the current env\n    if obj.current_env and obj.current_env not in env_list:\n        env_list.append(obj.current_env)\n    # add a manually set env\n    if env and env not in env_list:\n        env_list.append(env)\n    # add the [global] env\n    env_list.append(\"GLOBAL\")\n    return [env.lower() for env in env_list]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(obj, env=None, silent=None, key=None):\n\n    client = get_client(obj)\n    env_list = _get_env_list(obj, env)\n    for env in env_list:\n        path = \"/\".join([obj.VAULT_PATH_FOR_DYNACONF, env]).replace(\"//\", \"/\")\n        data = client.read(path)\n        if data:\n            # There seems to be a data dict within a data dict,\n            # extract the inner data\n            data = data.get(\"data\", {}).get(\"data\", {})\n        try:\n            if data and key:\n                value = parse_conf_data(data.get(key), tomlfy=True)\n                if value:\n                    obj.logger.debug(\n                        \"vault_loader: loading by key: %s:%s (%s:%s)\",\n                        key,\n                        \"****\",\n                        IDENTIFIER,\n                        path,\n                    )\n                    obj.set(key, value)\n            elif data:\n                obj.logger.debug(\n                    \"vault_loader: loading: %s (%s:%s)\",\n                    list(data.keys()),\n                    IDENTIFIER,\n                    path,\n                )\n                obj.update(data, loader_identifier=IDENTIFIER, tomlfy=True)\n        except Exception as e:\n            if silent:\n                if hasattr(obj, \"logger\"):\n                    obj.logger.error(str(e))\n                return False\n            raise", "response": "Reads and loads in to the vault base object a single key or all keys from vault base object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(obj, data=None, **kwargs):\n    if obj.VAULT_ENABLED_FOR_DYNACONF is False:\n        raise RuntimeError(\n            \"Vault is not configured \\n\"\n            \"export VAULT_ENABLED_FOR_DYNACONF=true\\n\"\n            \"and configure the VAULT_FOR_DYNACONF_* variables\"\n        )\n    data = data or {}\n    data.update(kwargs)\n    if not data:\n        raise AttributeError(\"Data must be provided\")\n    client = get_client(obj)\n    path = \"/\".join(\n        [obj.VAULT_PATH_FOR_DYNACONF, obj.current_env.lower()]\n    ).replace(\"//\", \"/\")\n    client.write(path, data=data)\n    load(obj)", "response": "Write a value in to loader source"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_settings(instance=None):\n\n    global settings\n\n    settings = None\n\n    if instance:\n        settings = import_settings(instance)\n\n    elif \"INSTANCE_FOR_DYNACONF\" in os.environ:\n        settings = import_settings(os.environ[\"INSTANCE_FOR_DYNACONF\"])\n\n    elif \"FLASK_APP\" in os.environ:  # pragma: no cover\n        with suppress(ImportError, click.UsageError):\n            from flask.cli import ScriptInfo\n\n            flask_app = ScriptInfo().load_app()\n            settings = flask_app.config\n            click.echo(\n                click.style(\n                    \"Flask app detected\", fg=\"white\", bg=\"bright_black\"\n                )\n            )\n\n    elif \"DJANGO_SETTINGS_MODULE\" in os.environ:  # pragma: no cover\n        sys.path.insert(0, os.path.abspath(os.getcwd()))\n        try:\n            # Django extension v2\n            from django.conf import settings\n\n            settings.DYNACONF.configure()\n        except (ImportError, AttributeError):\n            # Backwards compatible with old django extension (pre 2.0.0)\n            import dynaconf.contrib.django_dynaconf  # noqa\n            from django.conf import settings as django_settings\n\n            django_settings.configure()\n            settings = django_settings\n\n        if settings is not None:\n            click.echo(\n                click.style(\n                    \"Django app detected\", fg=\"white\", bg=\"bright_black\"\n                )\n            )\n\n    if settings is None:\n        settings = LazySettings()", "response": "Pick correct settings instance and set it to a global variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_settings(dotted_path):\n    if \".\" in dotted_path:\n        module, name = dotted_path.rsplit(\".\", 1)\n    else:\n        raise click.UsageError(\n            \"invalid path to settings instance: {}\".format(dotted_path)\n        )\n    try:\n        module = importlib.import_module(module)\n    except ImportError as e:\n        raise click.UsageError(e)\n    try:\n        return getattr(module, name)\n    except AttributeError as e:\n        raise click.UsageError(e)", "response": "Import settings instance from python dotted path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting values like foo = bar = zaz in {'foo = zaz in {'foo = zaz }", "response": "def split_vars(_vars):\n    \"\"\"Splits values like foo=bar=zaz in {'foo': 'bar=zaz'}\"\"\"\n    return (\n        {\n            k.upper().strip(): parse_conf_data(v.strip(), tomlfy=True)\n            for k, _, v in [item.partition(\"=\") for item in _vars]\n        }\n        if _vars\n        else {}\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a file in the root directory.", "response": "def read_file_in_root_directory(*names, **kwargs):\n    \"\"\"Read a file on root dir.\"\"\"\n    return read_file(\n        os.path.join(os.path.dirname(__file__), *names),\n        encoding=kwargs.get(\"encoding\", \"utf-8\"),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow dynaconf awesome banner", "response": "def show_banner(ctx, param, value):\n    \"\"\"Shows dynaconf awesome banner\"\"\"\n    if not value or ctx.resilient_parsing:\n        return\n    set_settings()\n    click.echo(settings.dynaconf_banner)\n    click.echo(\"Learn more at: http://github.com/rochacbruno/dynaconf\")\n    ctx.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(fileformat, path, env, _vars, _secrets, wg, y, django):\n    click.echo(\"Cofiguring your Dynaconf environment\")\n\n    env = env or settings.current_env.lower()\n\n    loader = importlib.import_module(\n        \"dynaconf.loaders.{}_loader\".format(fileformat)\n    )\n    # Turn foo=bar=zaz in {'foo': 'bar=zaz'}\n    env_data = split_vars(_vars)\n    _secrets = split_vars(_secrets)\n\n    # create placeholder data for every env\n    settings_data = {k: {\"value\": \"value for {}\".format(k)} for k in ENVS}\n    secrets_data = {k: {\"secret\": \"secret for {}\".format(k)} for k in ENVS}\n    if env_data:\n        settings_data[env] = env_data\n        settings_data[\"default\"] = {k: \"default\" for k in env_data}\n    if _secrets:\n        secrets_data[env] = _secrets\n        secrets_data[\"default\"] = {k: \"default\" for k in _secrets}\n\n    path = Path(path)\n\n    if str(path).endswith(\n        constants.ALL_EXTENSIONS + (\"py\",)\n    ):  # pragma: no cover  # noqa\n        settings_path = path\n        secrets_path = path.parent / \".secrets.{}\".format(fileformat)\n        dotenv_path = path.parent / \".env\"\n        gitignore_path = path.parent / \".gitignore\"\n    else:\n        if fileformat == \"env\":\n            if str(path) in (\".env\", \"./.env\"):  # pragma: no cover\n                settings_path = path\n            elif str(path).endswith(\"/.env\"):  # pragma: no cover\n                settings_path = path\n            elif str(path).endswith(\".env\"):  # pragma: no cover\n                settings_path = path.parent / \".env\"\n            else:\n                settings_path = path / \".env\"\n            Path.touch(settings_path)\n            secrets_path = None\n        else:\n            settings_path = path / \"settings.{}\".format(fileformat)\n            secrets_path = path / \".secrets.{}\".format(fileformat)\n        dotenv_path = path / \".env\"\n        gitignore_path = path / \".gitignore\"\n\n    if fileformat in [\"py\", \"env\"]:\n        # for Python and .env files writes a single env\n        settings_data = settings_data[env]\n        secrets_data = secrets_data[env]\n\n    if not y and settings_path and settings_path.exists():  # pragma: no cover\n        click.confirm(\n            \"{} exists do you want to overwrite it?\".format(settings_path),\n            abort=True,\n        )\n\n    if not y and secrets_path and secrets_path.exists():  # pragma: no cover\n        click.confirm(\n            \"{} exists do you want to overwrite it?\".format(secrets_path),\n            abort=True,\n        )\n\n    if settings_path and settings_data:\n        loader.write(settings_path, settings_data, merge=True)\n    if secrets_path and secrets_data:\n        loader.write(secrets_path, secrets_data, merge=True)\n\n    # write .env file\n    # if env not in ['default', 'development']:  # pragma: no cover\n    if not dotenv_path.exists():  # pragma: no cover\n        Path.touch(dotenv_path)\n        dotenv_cli.set_key(str(dotenv_path), \"ENV_FOR_DYNACONF\", env.upper())\n    else:  # pragma: no cover\n        click.echo(\n            \".env already exists please set ENV_FOR_DYNACONF={}\".format(\n                env.upper()\n            )\n        )\n\n    if wg:\n        # write .gitignore\n        ignore_line = \".secrets.*\"\n        comment = \"\\n# Ignore dynaconf secret files\\n\"\n        if not gitignore_path.exists():\n            with io.open(str(gitignore_path), \"w\", encoding=ENC) as f:\n                f.writelines([comment, ignore_line, \"\\n\"])\n        else:\n            existing = (\n                ignore_line\n                in io.open(str(gitignore_path), encoding=ENC).read()\n            )\n            if not existing:  # pragma: no cover\n                with io.open(str(gitignore_path), \"a+\", encoding=ENC) as f:\n                    f.writelines([comment, ignore_line, \"\\n\"])\n\n    if django:  # pragma: no cover\n        dj_module, loaded_from = get_module({}, django)\n        dj_filename = dj_module.__file__\n        if Path(dj_filename).exists():\n            click.confirm(\n                \"{} is found do you want to add dynaconf?\".format(dj_filename),\n                abort=True,\n            )\n            with open(dj_filename, \"a\") as dj_file:\n                dj_file.write(constants.DJANGO_PATCH)\n        else:\n            click.echo(\"Django settings file not written.\")", "response": "Initializes a dynaconf project\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all user defined config values.", "response": "def _list(env, key, more, loader, _all=False, output=None):\n    \"\"\"Lists all user defined config values\n    and if `--all` is passed it also shows dynaconf internal variables.\n    \"\"\"\n    if env:\n        env = env.strip()\n    if key:\n        key = key.strip()\n    if loader:\n        loader = loader.strip()\n\n    if env:\n        settings.setenv(env)\n\n    cur_env = settings.current_env.lower()\n\n    click.echo(\n        click.style(\n            \"Working in %s environment \" % cur_env,\n            bold=True,\n            bg=\"blue\",\n            fg=\"bright_black\",\n        )\n    )\n\n    if not loader:\n        data = settings.as_dict(env=env, internal=_all)\n    else:\n        identifier = \"{}_{}\".format(loader, cur_env)\n        data = settings._loaded_by_loaders.get(identifier, {})\n        data = data or settings._loaded_by_loaders.get(loader, {})\n\n    # remove to avoid displaying twice\n    data.pop(\"SETTINGS_MODULE\", None)\n\n    def color(_k):\n        if _k in dir(default_settings):\n            return \"blue\"\n        return \"green\"\n\n    if not key:\n        datalines = \"\\n\".join(\n            \"%s: %s\"\n            % (click.style(k, bg=color(k), fg=\"white\"), pprint.pformat(v))\n            for k, v in data.items()\n        )\n        (click.echo_via_pager if more else click.echo)(datalines)\n        if output:\n            with open(output, \"w\") as output_file:\n                json.dump({cur_env: data}, output_file)\n    else:\n        key = key.upper()\n        value = data.get(key)\n        if not value:\n            click.echo(click.style(\"Key not found\", bg=\"red\", fg=\"white\"))\n            return\n        click.echo(\n            \"%s: %s\"\n            % (\n                click.style(key.upper(), bg=color(key), fg=\"white\"),\n                pprint.pformat(value),\n            )\n        )\n        if output:\n            with open(output, \"w\") as output_file:\n                json.dump({cur_env: {key.upper(): value}}, output_file)\n\n    if env:\n        settings.setenv()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites data to specific source", "response": "def write(to, _vars, _secrets, path, env, y):\n    \"\"\"Writes data to specific source\"\"\"\n    _vars = split_vars(_vars)\n    _secrets = split_vars(_secrets)\n    loader = importlib.import_module(\"dynaconf.loaders.{}_loader\".format(to))\n\n    if to in EXTS:\n\n        # Lets write to a file\n        path = Path(path)\n\n        if str(path).endswith(constants.ALL_EXTENSIONS + (\"py\",)):\n            settings_path = path\n            secrets_path = path.parent / \".secrets.{}\".format(to)\n        else:\n            if to == \"env\":\n                if str(path) in (\".env\", \"./.env\"):  # pragma: no cover\n                    settings_path = path\n                elif str(path).endswith(\"/.env\"):\n                    settings_path = path\n                elif str(path).endswith(\".env\"):\n                    settings_path = path.parent / \".env\"\n                else:\n                    settings_path = path / \".env\"\n                Path.touch(settings_path)\n                secrets_path = None\n                _vars.update(_secrets)\n            else:\n                settings_path = path / \"settings.{}\".format(to)\n                secrets_path = path / \".secrets.{}\".format(to)\n\n        if (\n            _vars and not y and settings_path and settings_path.exists()\n        ):  # pragma: no cover  # noqa\n            click.confirm(\n                \"{} exists do you want to overwrite it?\".format(settings_path),\n                abort=True,\n            )\n\n        if (\n            _secrets and not y and secrets_path and secrets_path.exists()\n        ):  # pragma: no cover  # noqa\n            click.confirm(\n                \"{} exists do you want to overwrite it?\".format(secrets_path),\n                abort=True,\n            )\n\n        if to not in [\"py\", \"env\"]:\n            if _vars:\n                _vars = {env: _vars}\n            if _secrets:\n                _secrets = {env: _secrets}\n\n        if _vars and settings_path:\n            loader.write(settings_path, _vars, merge=True)\n            click.echo(\"Data successful written to {}\".format(settings_path))\n\n        if _secrets and secrets_path:\n            loader.write(secrets_path, _secrets, merge=True)\n            click.echo(\"Data successful written to {}\".format(secrets_path))\n\n    else:  # pragma: no cover\n        # lets write to external source\n        with settings.using_env(env):\n            # make sure we're in the correct environment\n            loader.write(settings, _vars, **_secrets)\n        click.echo(\"Data successful written to {}\".format(to))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate Dynaconf settings based on rules defined in dynaconf_validators. toml file.", "response": "def validate(path):  # pragma: no cover\n    \"\"\"Validates Dynaconf settings based on rules defined in\n    dynaconf_validators.toml\"\"\"\n    # reads the 'dynaconf_validators.toml' from path\n    # for each section register the validator for specific env\n    # call validate\n\n    path = Path(path)\n\n    if not str(path).endswith(\".toml\"):\n        path = path / \"dynaconf_validators.toml\"\n\n    if not path.exists():  # pragma: no cover  # noqa\n        click.echo(\n            click.style(\"{} not found\".format(path), fg=\"white\", bg=\"red\")\n        )\n        sys.exit(1)\n\n    validation_data = toml.load(open(str(path)))\n\n    success = True\n    for env, name_data in validation_data.items():\n        for name, data in name_data.items():\n            if not isinstance(data, dict):  # pragma: no cover\n                click.echo(\n                    click.style(\n                        \"Invalid rule for parameter '{}'\".format(name),\n                        fg=\"white\",\n                        bg=\"yellow\",\n                    )\n                )\n            else:\n                data.setdefault(\"env\", env)\n                click.echo(\n                    click.style(\n                        \"Validating '{}' with '{}'\".format(name, data),\n                        fg=\"white\",\n                        bg=\"blue\",\n                    )\n                )\n                try:\n                    Validator(name, **data).validate(settings)\n                except ValidationError as e:\n                    click.echo(\n                        click.style(\n                            \"Error: {}\".format(e), fg=\"white\", bg=\"red\"\n                        )\n                    )\n                    success = False\n\n    if success:\n        click.echo(click.style(\"Validation success!\", fg=\"white\", bg=\"green\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to a server", "response": "def connect(server, port, username, password):\n    \"\"\"This function might be something coming from your ORM\"\"\"\n    print(\"-\" * 79)\n    print(\"Connecting to: {}\".format(server))\n    print(\"At port: {}\".format(port))\n    print(\"Using username: {}\".format(username))\n    print(\"Using password: {}\".format(password))\n    print(\"-\" * 79)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(obj, env=None, silent=True, key=None):\n    global_env = obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\")\n    if global_env is False or global_env.upper() != \"DYNACONF\":\n        load_from_env(IDENTIFIER + \"_global\", key, \"DYNACONF\", obj, silent)\n\n    # Load the global env if exists and overwrite everything\n    load_from_env(IDENTIFIER + \"_global\", key, global_env, obj, silent)", "response": "Loads the environment variables from the object obj."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites data to. env file", "response": "def write(settings_path, settings_data, **kwargs):\n    \"\"\"Write data to .env file\"\"\"\n    for key, value in settings_data.items():\n        dotenv_cli.set_key(str(settings_path), key.upper(), str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(obj, env=None, silent=True, key=None, filename=None):\n    if ConfigObj is None:  # pragma: no cover\n        BaseLoader.warn_not_installed(obj, \"ini\")\n        return\n\n    loader = BaseLoader(\n        obj=obj,\n        env=env,\n        identifier=\"ini\",\n        extensions=INI_EXTENSIONS,\n        file_reader=lambda fileobj: ConfigObj(fileobj).dict(),\n        string_reader=lambda strobj: ConfigObj(strobj.split(\"\\n\")).dict(),\n    )\n    loader.load(filename=filename, key=key, silent=silent)", "response": "Reads and loads in to obj a single key or all keys from source file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites data to a new settings file.", "response": "def write(settings_path, settings_data, merge=True):\n    \"\"\"Write data to a settings file.\n\n    :param settings_path: the filepath\n    :param settings_data: a dictionary with data\n    :param merge: boolean if existing file should be merged with new data\n    \"\"\"\n    settings_path = Path(settings_path)\n    if settings_path.exists() and merge:  # pragma: no cover\n        with io.open(\n            str(settings_path), encoding=default_settings.ENCODING_FOR_DYNACONF\n        ) as open_file:\n            object_merge(ConfigObj(open_file).dict(), settings_data)\n    new = ConfigObj()\n    new.update(settings_data)\n    new.write(open(str(settings_path), \"bw\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(obj, env=None, silent=True, key=None, filename=None):\n    if toml is None:  # pragma: no cover\n        BaseLoader.warn_not_installed(obj, \"toml\")\n        return\n\n    loader = BaseLoader(\n        obj=obj,\n        env=env,\n        identifier=\"toml\",\n        extensions=TOML_EXTENSIONS,\n        file_reader=toml.load,\n        string_reader=toml.loads,\n    )\n    loader.load(filename=filename, key=key, silent=silent)", "response": "Reads and loads in to obj a single key or all keys from source file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_with_toml(data):\n    try:\n        return toml.loads(\"key={}\".format(data), DynaBox).key\n    except toml.TomlDecodeError:\n        return data", "response": "Uses TOML syntax to parse data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the configuration data.", "response": "def _parse_conf_data(data, tomlfy=False):\n    \"\"\"\n    @int @bool @float @json (for lists and dicts)\n    strings does not need converters\n\n    export DYNACONF_DEFAULT_THEME='material'\n    export DYNACONF_DEBUG='@bool True'\n    export DYNACONF_DEBUG_TOOLBAR_ENABLED='@bool False'\n    export DYNACONF_PAGINATION_PER_PAGE='@int 20'\n    export DYNACONF_MONGODB_SETTINGS='@json {\"DB\": \"quokka_db\"}'\n    export DYNACONF_ALLOWED_EXTENSIONS='@json [\"jpg\", \"png\"]'\n    \"\"\"\n    cast_toggler = os.environ.get(\"AUTO_CAST_FOR_DYNACONF\", \"true\").lower()\n    castenabled = cast_toggler not in false_values\n\n    if (\n        castenabled\n        and data\n        and isinstance(data, str)\n        and data.startswith(tuple(converters.keys()))\n    ):\n        parts = data.partition(\" \")\n        converter_key = parts[0]\n        value = parts[-1]\n        return converters.get(converter_key)(value)\n\n    return parse_with_toml(data) if tomlfy else data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread and loads in to self. obj a single key or all keys from source", "response": "def load(self, filename=None, key=None, silent=True):\n        \"\"\"\n        Reads and loads in to `self.obj` a single key or all keys from source\n\n        :param filename: Optional filename to load\n        :param key: if provided load a single key\n        :param silent: if load erros should be silenced\n        \"\"\"\n        filename = filename or self.obj.get(self.identifier.upper())\n        if not filename:\n            return\n\n        if not isinstance(filename, (list, tuple)):\n            split_files = ensure_a_list(filename)\n            if all([f.endswith(self.extensions) for f in split_files]):  # noqa\n                files = split_files  # it is a ['file.ext', ...]\n            else:  # it is a single config as string\n                files = [filename]\n        else:  # it is already a list/tuple\n            files = filename\n\n        self.obj._loaded_files.extend(files)\n\n        # add the [default] env\n        env_list = [self.obj.get(\"DEFAULT_ENV_FOR_DYNACONF\")]\n\n        # compatibility with older versions that still uses [dynaconf] as\n        # [default] env\n        global_env = self.obj.get(\"ENVVAR_PREFIX_FOR_DYNACONF\") or \"DYNACONF\"\n        if global_env not in env_list:\n            env_list.append(global_env)\n\n        # add the current [env]\n        if self.env not in env_list:\n            env_list.append(self.env)\n\n        # add the [global] env\n        env_list.append(\"GLOBAL\")\n\n        # load all envs\n        self._read(files, env_list, silent, key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitialing setup run once.", "response": "def _setup(self):\n        \"\"\"Initial setup, run once.\"\"\"\n        default_settings.reload()\n        environment_variable = self._kwargs.get(\n            \"ENVVAR_FOR_DYNACONF\", default_settings.ENVVAR_FOR_DYNACONF\n        )\n        settings_module = os.environ.get(environment_variable)\n        self._wrapped = Settings(\n            settings_module=settings_module, **self._kwargs\n        )\n        self.logger.debug(\"Lazy Settings _setup ...\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configure(self, settings_module=None, **kwargs):\n        default_settings.reload()\n        environment_var = self._kwargs.get(\n            \"ENVVAR_FOR_DYNACONF\", default_settings.ENVVAR_FOR_DYNACONF\n        )\n        settings_module = settings_module or os.environ.get(environment_var)\n        compat_kwargs(kwargs)\n        kwargs.update(self._kwargs)\n        self._wrapped = Settings(settings_module=settings_module, **kwargs)\n        self.logger.debug(\"Lazy Settings configured ...\")", "response": "Allows user to reconfigure settings object passing a new settings module or separated kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary with set key and values.", "response": "def as_dict(self, env=None, internal=False):\n        \"\"\"Returns a dictionary with set key and values.\n\n        :param env: Str env name, default self.current_env `DEVELOPMENT`\n        :param internal: bool - should include dynaconf internal vars?\n        \"\"\"\n        ctx_mgr = suppress() if env is None else self.using_env(env)\n        with ctx_mgr:\n            data = self.store.copy()\n            # if not internal remove internal settings\n            if not internal:\n                for name in dir(default_settings):\n                    data.pop(name, None)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _dotted_get(self, dotted_key, default=None, **kwargs):\n        split_key = dotted_key.split(\".\")\n        name, keys = split_key[0], split_key[1:]\n        result = self.get(name, default=default, **kwargs)\n        self._memoized = result\n\n        # If we've reached the end, then return result and clear the\n        # memoized data.\n        if not keys or result is default:\n            self._memoized = None\n            return result\n\n        # If we've still got key elements to traverse, let's do that.\n        return self._dotted_get(\".\".join(keys), default=default, **kwargs)", "response": "Perform dotted key lookups and keep track of where we are."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(\n        self, key, default=None, cast=None, fresh=False, dotted_lookup=True\n    ):\n        \"\"\"\n        Get a value from settings store, this is the prefered way to access::\n\n            >>> from dynaconf import settings\n            >>> settings.get('KEY')\n\n        :param key: The name of the setting value, will always be upper case\n        :param default: In case of not found it will be returned\n        :param cast: Should cast in to @int, @float, @bool or @json ?\n        :param fresh: Should reload from loaders store before access?\n        :param dotted_lookup: Should perform dotted-path lookup?\n        :return: The value if found, default or None\n        \"\"\"\n        key = key.upper()\n\n        if \".\" in key and dotted_lookup:\n            return self._dotted_get(\n                dotted_key=key, default=default, cast=cast, fresh=fresh\n            )\n\n        if key in self._deleted:\n            return default\n\n        if (\n            fresh\n            or self._fresh\n            or key in getattr(self, \"FRESH_VARS_FOR_DYNACONF\", ())\n        ) and key not in dir(default_settings):\n            self.unset(key)\n            self.execute_loaders(key=key)\n\n        store = self._memoized or self.store\n        data = store.get(key, default)\n        if cast:\n            data = converters.get(cast)(data)\n        return data", "response": "Get a value from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a key exists in the cache.", "response": "def exists(self, key, fresh=False):\n        \"\"\"Check if key exists\n\n        :param key: the name of setting variable\n        :param fresh: if key should be taken from source direclty\n        :return: Boolean\n        \"\"\"\n        key = key.upper()\n        if key in self._deleted:\n            return False\n        return self.get(key, fresh=fresh, default=missing) is not missing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fresh(self, key, default=None, cast=None):\n        return self.get(key, default=default, cast=cast, fresh=True)", "response": "This is a shortcut to get the value of the key from the loader store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting value from environment variable using os. environ. get 69.", "response": "def get_environ(self, key, default=None, cast=None):\n        \"\"\"Get value from environment variable using os.environ.get\n\n        :param key: The name of the setting value, will always be upper case\n        :param default: In case of not found it will be returned\n        :param cast: Should cast in to @int, @float, @bool or @json ?\n         or cast must be true to use cast inference\n        :return: The value if found, default or None\n        \"\"\"\n        key = key.upper()\n        data = self.environ.get(key, default)\n        if data:\n            if cast in converters:\n                data = converters.get(cast)(data)\n            if cast is True:\n                data = parse_conf_data(data, tomlfy=True)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef using_env(self, env, clean=True, silent=True, filename=None):\n        try:\n            self.setenv(env, clean=clean, silent=silent, filename=filename)\n            self.logger.debug(\"In env: %s\", env)\n            yield\n        finally:\n            if env.lower() != self.ENV_FOR_DYNACONF.lower():\n                del self.loaded_envs[-1]\n            self.logger.debug(\"Out env: %s\", env)\n            self.setenv(self.current_env, clean=clean, filename=filename)", "response": "Context manager for contextual use of a different env"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setenv(self, env=None, clean=True, silent=True, filename=None):\n        env = env or self.ENV_FOR_DYNACONF\n\n        if not isinstance(env, str):\n            raise AttributeError(\"env should be a string\")\n        if \"_\" in env:\n            raise AttributeError(\"env should not contains _\")\n\n        self.logger.debug(\"env switching to: %s\", env)\n\n        env = env.upper()\n\n        if env != self.ENV_FOR_DYNACONF:\n            self.loaded_envs.append(env)\n        else:\n            self.loaded_envs = []\n\n        if clean:\n            self.clean(env=env)\n        self.execute_loaders(env=env, silent=silent, filename=filename)", "response": "Used to interactively change the env for the current context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self, *args, **kwargs):\n        for key in list(self.store.keys()):\n            self.unset(key)", "response": "Clean all loaded values to reload when switching envs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a value for the key in the object.", "response": "def set(\n        self,\n        key,\n        value,\n        loader_identifier=None,\n        tomlfy=False,\n        dotted_lookup=True,\n        is_secret=False,\n    ):\n        \"\"\"Set a value storing references for the loader\n\n        :param key: The key to store\n        :param value: The value to store\n        :param loader_identifier: Optional loader name e.g: toml, yaml etc.\n        :param tomlfy: Bool define if value is parsed by toml (defaults False)\n        :param is_secret: Bool define if secret values is hidden on logs.\n        \"\"\"\n\n        if \".\" in key and dotted_lookup is True:\n            return self._dotted_set(\n                key, value, loader_identifier=loader_identifier, tomlfy=tomlfy\n            )\n\n        value = parse_conf_data(value, tomlfy=tomlfy)\n        key = key.strip().upper()\n        existing = getattr(self, key, None)\n        if existing is not None and existing != value:\n            value = self._merge_before_set(key, existing, value, is_secret)\n\n        if isinstance(value, dict):\n            value = DynaBox(value, box_it_up=True)\n\n        setattr(self, key, value)\n        self.store[key] = value\n        self._deleted.discard(key)\n\n        # set loader identifiers so cleaners know which keys to clean\n        if loader_identifier and loader_identifier in self.loaded_by_loaders:\n            self.loaded_by_loaders[loader_identifier][key] = value\n        elif loader_identifier:\n            self.loaded_by_loaders[loader_identifier] = {key: value}\n        elif loader_identifier is None:\n            # if .set is called without loader identifier it becomes\n            # a default value and goes away only when explicitly unset\n            self._defaults[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the values in the current store with the given data.", "response": "def update(\n        self,\n        data=None,\n        loader_identifier=None,\n        tomlfy=False,\n        is_secret=False,\n        **kwargs\n    ):\n        \"\"\"\n        Update values in the current settings object without saving in stores::\n\n            >>> from dynaconf import settings\n            >>> print settings.NAME\n            'Bruno'\n            >>> settings.update({'NAME': 'John'}, other_value=1)\n            >>> print settings.NAME\n            'John'\n            >>> print settings.OTHER_VALUE\n            1\n\n        :param data: Data to be updated\n        :param loader_identifier: Only to be used by custom loaders\n        :param tomlfy: Bool define if value is parsed by toml (defaults False)\n        :param kwargs: extra values to update\n        :return: None\n        \"\"\"\n        data = data or {}\n        data.update(kwargs)\n        for key, value in data.items():\n            self.set(\n                key,\n                value,\n                loader_identifier=loader_identifier,\n                tomlfy=tomlfy,\n                is_secret=is_secret,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge the new value being set with the existing value before set.", "response": "def _merge_before_set(self, key, existing, value, is_secret):\n        \"\"\"Merge the new value being set with the existing value before set\"\"\"\n\n        def _log_before_merging(_value):\n            self.logger.debug(\n                \"Merging existing %s: %s with new: %s\", key, existing, _value\n            )\n\n        def _log_after_merge(_value):\n            self.logger.debug(\"%s merged to %s\", key, _value)\n\n        global_merge = getattr(self, \"MERGE_ENABLED_FOR_DYNACONF\", False)\n\n        if isinstance(value, dict):\n            local_merge = value.pop(\n                \"dynaconf_merge\", value.pop(\"dynaconf_merge_unique\", None)\n            )\n            if global_merge or local_merge:\n                safe_value = {k: \"***\" for k in value} if is_secret else value\n                _log_before_merging(safe_value)\n                object_merge(existing, value)\n                safe_value = (\n                    {\n                        k: (\"***\" if k in safe_value else v)\n                        for k, v in value.items()\n                    }\n                    if is_secret\n                    else value\n                )\n                _log_after_merge(safe_value)\n\n        if isinstance(value, (list, tuple)):\n            local_merge = (\n                \"dynaconf_merge\" in value or \"dynaconf_merge_unique\" in value\n            )\n            if global_merge or local_merge:\n                value = list(value)\n                unique = False\n\n                if local_merge:\n                    try:\n                        value.remove(\"dynaconf_merge\")\n                    except ValueError:  # EAFP\n                        value.remove(\"dynaconf_merge_unique\")\n                        unique = True\n\n                original = set(value)\n                _log_before_merging(\n                    [\"***\" for item in value] if is_secret else value\n                )\n                object_merge(existing, value, unique=unique)\n                safe_value = (\n                    [\"***\" if item in original else item for item in value]\n                    if is_secret\n                    else value\n                )\n                _log_after_merge(safe_value)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncleans end Execute all loaders", "response": "def reload(self, env=None, silent=None):  # pragma: no cover\n        \"\"\"Clean end Execute all loaders\"\"\"\n        self.clean()\n        self.execute_loaders(env, silent)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_loaders(self, env=None, silent=None, key=None, filename=None):\n        if key is None:\n            default_loader(self, self._defaults)\n        env = (env or self.current_env).upper()\n        silent = silent or self.SILENT_ERRORS_FOR_DYNACONF\n        settings_loader(\n            self, env=env, silent=silent, key=key, filename=filename\n        )\n        self.load_extra_yaml(env, silent, key)  # DEPRECATED\n        enable_external_loaders(self)\n        for loader in self.loaders:\n            self.logger.debug(\"Dynaconf executing: %s\", loader.__name__)\n            loader.load(self, env, silent=silent, key=key)\n        self.load_includes(env, silent=silent, key=key)\n        self.logger.debug(\"Loaded Files: %s\", deduplicate(self._loaded_files))", "response": "Execute all internal and registered loaders."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_includes(self, env, silent, key):\n        includes = self.get(\"DYNACONF_INCLUDE\", [])\n        includes.extend(ensure_a_list(self.get(\"INCLUDES_FOR_DYNACONF\")))\n        if includes:\n            self.logger.debug(\"Processing includes %s\", includes)\n            self.load_file(path=includes, env=env, silent=silent, key=key)", "response": "Load all includes for this class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a single file from a file list.", "response": "def load_file(self, path=None, env=None, silent=True, key=None):\n        \"\"\"Programmatically load files from ``path``.\n\n        :param path: A single filename or a file list\n        :param env: Which env to load from file (default current_env)\n        :param silent: Should raise errors?\n        :param key: Load a single key?\n        \"\"\"\n        env = (env or self.current_env).upper()\n        files = ensure_a_list(path)\n        if files:\n            self.logger.debug(\"Got %s files to process\", files)\n            already_loaded = set()\n            for _filename in files:\n                self.logger.debug(\"Processing file %s\", _filename)\n                filepath = os.path.join(self._root_path, _filename)\n                self.logger.debug(\"File path is %s\", filepath)\n                # Handle possible *.globs sorted alphanumeric\n                for path in sorted(glob.glob(filepath)):\n                    self.logger.debug(\"Loading %s\", path)\n                    if path in already_loaded:  # pragma: no cover\n                        self.logger.debug(\"Skipping %s, already loaded\", path)\n                        continue\n                    settings_loader(\n                        obj=self,\n                        env=env,\n                        silent=silent,\n                        key=key,\n                        filename=path,\n                    )\n                    already_loaded.add(path)\n            if not already_loaded:\n                self.logger.warning(\n                    \"Not able to locate the files %s to load\", files\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _root_path(self):\n        if self.ROOT_PATH_FOR_DYNACONF is not None:\n            return self.ROOT_PATH_FOR_DYNACONF\n        elif self._loaded_files:  # called once\n            root_path = os.path.dirname(self._loaded_files[0])\n            self.set(\"ROOT_PATH_FOR_DYNACONF\", root_path)\n            return root_path", "response": "Returns the path of the root directory of the current loaded file or."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading extra YAML file.", "response": "def load_extra_yaml(self, env, silent, key):\n        \"\"\"This is deprecated, kept for compat\n\n        .. deprecated:: 1.0.0\n            Use multiple settings or INCLUDES_FOR_DYNACONF files instead.\n        \"\"\"\n        if self.get(\"YAML\") is not None:\n            self.logger.warning(\n                \"The use of YAML var is deprecated, please define multiple \"\n                \"filepaths instead: \"\n                \"e.g: SETTINGS_FILE_FOR_DYNACONF = \"\n                \"'settings.py,settings.yaml,settings.toml' or \"\n                \"INCLUDES_FOR_DYNACONF=['path.toml', 'folder/*']\"\n            )\n            yaml_loader.load(\n                self,\n                env=env,\n                filename=self.find_file(self.get(\"YAML\")),\n                silent=silent,\n                key=key,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_for(self, *args):\n        if args and args[0].startswith(os.path.sep):\n            return os.path.join(*args)\n        return os.path.join(self._root_path or os.getcwd(), *args)", "response": "Return the path to the file containing the _root_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting or creates validator wrapper", "response": "def validators(self):\n        \"\"\"Gets or creates validator wrapper\"\"\"\n        if not hasattr(self, \"_validators\"):\n            self._validators = ValidatorList(self)\n        return self._validators"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflagging the value of the key in the specified environment", "response": "def flag(self, key, env=None):\n        \"\"\"Feature flagging system\n        write flags to redis\n        $ dynaconf write redis -s DASHBOARD=1 -e premiumuser\n        meaning: Any premium user has DASHBOARD feature enabled\n\n        In your program do::\n\n            # premium user has access to dashboard?\n            >>> if settings.flag('dashboard', 'premiumuser'):\n            ...     activate_dashboard()\n\n        The value is ensured to be loaded fresh from redis server\n\n        It also works with file settings but the recommended is redis\n        as the data can be loaded once it is updated.\n\n        :param key: The flag name\n        :param env: The env to look for\n        \"\"\"\n        env = env or self.ENVVAR_PREFIX_FOR_DYNACONF or \"DYNACONF\"\n        with self.using_env(env):\n            value = self.get_fresh(key)\n            return value is True or value in true_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives the obj populate it using self. store items.", "response": "def populate_obj(self, obj, keys=None):\n        \"\"\"Given the `obj` populate it using self.store items.\"\"\"\n        keys = keys or self.keys()\n        for key in keys:\n            key = key.upper()\n            value = self.get(key, empty)\n            if value is not empty:\n                setattr(obj, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_loader(obj, defaults=None):\n    defaults = defaults or {}\n    default_settings_values = {\n        key: value\n        for key, value in default_settings.__dict__.items()  # noqa\n        if key.isupper()\n    }\n\n    all_keys = deduplicate(\n        list(defaults.keys()) + list(default_settings_values.keys())\n    )\n\n    for key in all_keys:\n        if not obj.exists(key):\n            value = defaults.get(key, default_settings_values.get(key))\n            obj.logger.debug(\"loading: %s:%s\", key, value)\n            obj.set(key, value)\n\n    # start dotenv to get default env vars from there\n    # check overrides in env vars\n    default_settings.start_dotenv(obj)\n\n    # Deal with cases where a custom ENV_SWITCHER_IS_PROVIDED\n    # Example: Flask and Django Extensions\n    env_switcher = defaults.get(\n        \"ENV_SWITCHER_FOR_DYNACONF\", \"ENV_FOR_DYNACONF\"\n    )\n\n    for key in all_keys:\n        if key not in default_settings_values.keys():\n            continue\n\n        env_value = obj.get_environ(\n            env_switcher if key == \"ENV_FOR_DYNACONF\" else key,\n            default=\"_not_found\",\n        )\n\n        if env_value != \"_not_found\":\n            obj.logger.debug(\"overriding from envvar: %s:%s\", key, env_value)\n            obj.set(key, env_value, tomlfy=True)", "response": "Loads default settings and checks if there are overridings in env vars"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef settings_loader(\n    obj, settings_module=None, env=None, silent=True, key=None, filename=None\n):\n    \"\"\"Loads from defined settings module\n\n    :param obj: A dynaconf instance\n    :param settings_module: A path or a list of paths e.g settings.toml\n    :param env: Env to look for data defaults: development\n    :param silent: Boolean to raise loading errors\n    :param key: Load a single key if provided\n    :param filename: optional filename to override the settings_module\n    \"\"\"\n    if filename is None:\n        settings_module = settings_module or obj.settings_module\n        if not settings_module:  # pragma: no cover\n            return\n        files = ensure_a_list(settings_module)\n    else:\n        files = ensure_a_list(filename)\n\n    files.extend(ensure_a_list(obj.get(\"SECRETS_FOR_DYNACONF\", None)))\n\n    found_files = []\n    modules_names = []\n    for item in files:\n        if item.endswith(ct.ALL_EXTENSIONS + (\".py\",)):\n            p_root = obj._root_path or (\n                os.path.dirname(found_files[0]) if found_files else None\n            )\n            found = obj.find_file(item, project_root=p_root)\n            if found:\n                found_files.append(found)\n        else:\n            # a bare python module name w/o extension\n            modules_names.append(item)\n\n    enabled_core_loaders = obj.get(\"CORE_LOADERS_FOR_DYNACONF\")\n\n    for mod_file in modules_names + found_files:\n        # can be set to multiple files settings.py,settings.yaml,...\n\n        # Cascade all loaders\n        loaders = [\n            {\"ext\": ct.YAML_EXTENSIONS, \"name\": \"YAML\", \"loader\": yaml_loader},\n            {\"ext\": ct.TOML_EXTENSIONS, \"name\": \"TOML\", \"loader\": toml_loader},\n            {\"ext\": ct.INI_EXTENSIONS, \"name\": \"INI\", \"loader\": ini_loader},\n            {\"ext\": ct.JSON_EXTENSIONS, \"name\": \"JSON\", \"loader\": json_loader},\n        ]\n\n        for loader in loaders:\n            if loader[\"name\"] not in enabled_core_loaders:\n                continue\n\n            if mod_file.endswith(loader[\"ext\"]):\n                loader[\"loader\"].load(\n                    obj, filename=mod_file, env=env, silent=silent, key=key\n                )\n                continue\n\n        if mod_file.endswith(ct.ALL_EXTENSIONS):\n            continue\n\n        if \"PY\" not in enabled_core_loaders:\n            # pyloader is disabled\n            continue\n\n        # must be Python file or module\n        # load from default defined module settings.py or .secrets.py if exists\n        py_loader.load(obj, mod_file, key=key)\n\n        # load from the current env e.g: development_settings.py\n        env = env or obj.current_env\n        if mod_file.endswith(\".py\"):\n            if \".secrets.py\" == mod_file:\n                tmpl = \".{0}_{1}{2}\"\n                mod_file = \"secrets.py\"\n            else:\n                tmpl = \"{0}_{1}{2}\"\n\n            dirname = os.path.dirname(mod_file)\n            filename, extension = os.path.splitext(os.path.basename(mod_file))\n            new_filename = tmpl.format(env.lower(), filename, extension)\n            env_mod_file = os.path.join(dirname, new_filename)\n            global_filename = tmpl.format(\"global\", filename, extension)\n            global_mod_file = os.path.join(dirname, global_filename)\n        else:\n            env_mod_file = \"{0}_{1}\".format(env.lower(), mod_file)\n            global_mod_file = \"{0}_{1}\".format(\"global\", mod_file)\n\n        py_loader.load(\n            obj,\n            env_mod_file,\n            identifier=\"py_{0}\".format(env.upper()),\n            silent=True,\n            key=key,\n        )\n\n        # load from global_settings.py\n        py_loader.load(\n            obj, global_mod_file, identifier=\"py_global\", silent=True, key=key\n        )", "response": "Loads from the specified settings module or a list of paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables external service loaders likeVAULT_ and REDIS_", "response": "def enable_external_loaders(obj):\n    \"\"\"Enable external service loaders like `VAULT_` and `REDIS_`\n    looks forenv variables like `REDIS_ENABLED_FOR_DYNACONF`\n    \"\"\"\n    for name, loader in ct.EXTERNAL_LOADERS.items():\n        enabled = getattr(\n            obj, \"{}_ENABLED_FOR_DYNACONF\".format(name.upper()), False\n        )\n        if (\n            enabled\n            and enabled not in false_values\n            and loader not in obj.LOADERS_FOR_DYNACONF\n        ):  # noqa\n            obj.logger.debug(\"loaders: Enabling %s\", loader)\n            obj.LOADERS_FOR_DYNACONF.insert(0, loader)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_aafigure(self, text, options):\n\n    fname = get_basename(text, options)\n    fname = '%s.%s' % (get_basename(text, options), options['format'])\n    if True: #TODO: hasattr(self.builder, 'imgpath'):\n        # HTML\n        #TODO relfn = posixpath.join(self.builder.imgpath, fname)\n        relfn = '_build/html/_images/' + fname\n        #TODO: outfn = path.join(self.builder.outdir, '_images', fname)\n        outfn = '/home/luca/repos/aafigure/documentation/_build/html/_images/' + fname\n    else:\n        # LaTeX\n        relfn = fname\n        outfn = path.join(self.builder.outdir, fname)\n    metadata_fname = '%s.aafig' % outfn\n\n    try:\n        if path.isfile(outfn):\n            extra = None\n            if options['format'].lower() == 'svg':\n                f = None\n                try:\n                    try:\n                        f = file(metadata_fname, 'r')\n                        extra = f.read()\n                    except:\n                        raise AafigError()\n                finally:\n                    if f is not None:\n                        f.close()\n            return relfn, outfn, id, extra\n    except AafigError:\n        pass\n\n    ensuredir(path.dirname(outfn))\n\n    try:\n        (visitor, output) = aafigure.render(text, outfn, options)\n\toutput.close()\n    except aafigure.UnsupportedFormatError, e:\n        raise AafigError(str(e))\n\n    extra = None\n    if options['format'].lower() == 'svg':\n        extra = visitor.get_size_attrs()\n        f = file(metadata_fname, 'w')\n        f.write(extra)\n        f.close()\n\n    return relfn, outfn, id, extra", "response": "Render an ASCII art figure into the requested format output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(obj, env=None, silent=True, key=None, filename=None):\n    # Load data from your custom data source (file, database, memory etc)\n    # use `obj.set(key, value)` or `obj.update(dict)` to load data\n    # use `obj.logger.debug` to log your loader activities\n    # use `obj.find_file('filename.ext')` to find the file in search tree\n    # Return nothing\n\n    # This loader reads the .sff file // Stupid File Format\n    keys = []\n    values = []\n    found_file = obj.find_file(\"settings.sff\")\n    if not found_file:\n        obj.logger.debug(\"Cannot find settings.sff\")\n        return\n\n    with open(found_file) as settings_file:\n        for line in settings_file.readlines():\n            if line.startswith(\"#\"):\n                continue\n            if line.startswith(\"KEYS:\"):\n                keys = line.strip(\"KEYS:\").strip(\"\\n\").split(\";\")\n            if line.startswith(\"VALUES:\"):\n                values = line.strip(\"VALUES:\").strip(\"\\n\").split(\";\")\n\n    # // PLEASE DON'T USE THIS SFF file format :)\n\n    data = dict(zip(keys, values))\n\n    if key:\n        value = data.get(key.lower())  # sff format have lower case keys\n        obj.logger.debug(\"Sff loader: %s:%s\", key, value)\n        obj.set(key, value)\n    else:\n        obj.logger.debug(\"Sff loader: loading: {0}\".format(data))\n        obj.update(data)\n\n    obj._loaded_files.append(found_file)", "response": "Reads and loads in to obj a single key or all keys from source\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _walk_to_root(path, break_at=None):\n    if not os.path.exists(path):  # pragma: no cover\n        raise IOError(\"Starting path not found\")\n\n    if os.path.isfile(path):  # pragma: no cover\n        path = os.path.dirname(path)\n\n    last_dir = None\n    current_dir = os.path.abspath(path)\n    paths = []\n    while last_dir != current_dir:\n        paths.append(current_dir)\n        paths.append(os.path.join(current_dir, \"config\"))\n        if break_at and current_dir == os.path.abspath(break_at):  # noqa\n            logger.debug(\"Reached the %s directory, breaking.\", break_at)\n            break\n        parent_dir = os.path.abspath(os.path.join(current_dir, os.path.pardir))\n        last_dir, current_dir = current_dir, parent_dir\n    return paths", "response": "Walks the given path up to the root directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching in increasingly higher folders for the given file. Returns an empty string if not found.", "response": "def find_file(filename=\".env\", project_root=None, skip_files=None, **kwargs):\n    \"\"\"Search in increasingly higher folders for the given file\n    Returns path to the file if found, or an empty string otherwise.\n\n    This function will build a `search_tree` based on:\n\n    - Project_root if specified\n    - Invoked script location and its parents until root\n    - Current working directory\n\n    For each path in the `search_tree` it will also look for an\n    aditional `./config` folder.\n    \"\"\"\n    search_tree = []\n    work_dir = os.getcwd()\n    skip_files = skip_files or []\n\n    if project_root is None:\n        logger.debug(\"No root_path for %s\", filename)\n    else:\n        logger.debug(\"Got root_path %s for %s\", project_root, filename)\n        search_tree.extend(_walk_to_root(project_root, break_at=work_dir))\n\n    script_dir = os.path.dirname(os.path.abspath(inspect.stack()[-1].filename))\n\n    # Path to invoked script and recursively to root with its ./config dirs\n    search_tree.extend(_walk_to_root(script_dir))\n\n    # Path to where Python interpreter was invoked and recursively to root\n    search_tree.extend(_walk_to_root(work_dir))\n\n    # Don't look the same place twice\n    search_tree = deduplicate(search_tree)\n\n    global SEARCHTREE\n    SEARCHTREE != search_tree and logger.debug(\"Search Tree: %s\", search_tree)\n    SEARCHTREE = search_tree\n\n    logger.debug(\"Searching for %s\", filename)\n\n    for dirname in search_tree:\n        check_path = os.path.join(dirname, filename)\n        if check_path in skip_files:\n            continue\n        if os.path.exists(check_path):\n            logger.debug(\"Found: %s\", os.path.abspath(check_path))\n            return check_path  # First found will return\n\n    # return empty string if not found so it can still be joined in os.path\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread and loads in to obj a single key or all keys from source file.", "response": "def load(obj, env=None, silent=True, key=None, filename=None):\n    \"\"\"\n    Reads and loads in to \"obj\" a single key or all keys from source file.\n\n    :param obj: the settings instance\n    :param env: settings current env default='development'\n    :param silent: if errors should raise\n    :param key: if defined load a single key, else load all in env\n    :param filename: Optional custom filename to load\n    :return: None\n    \"\"\"\n    if (\n        obj.get(\"COMMENTJSON_ENABLED_FOR_DYNACONF\") and commentjson\n    ):  # pragma: no cover  # noqa\n        file_reader = commentjson.load\n        string_reader = commentjson.loads\n    else:\n        file_reader = json.load\n        string_reader = json.loads\n\n    loader = BaseLoader(\n        obj=obj,\n        env=env,\n        identifier=\"json\",\n        extensions=JSON_EXTENSIONS,\n        file_reader=file_reader,\n        string_reader=string_reader,\n    )\n    loader.load(filename=filename, key=key, silent=silent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender an ASCII art figure into the requested format output file.", "response": "def render_aafigure(app, text, options):\n    \"\"\"\n    Render an ASCII art figure into the requested format output file.\n    \"\"\"\n\n    if aafigure is None:\n        raise AafigError('aafigure module not installed')\n\n    fname = get_basename(text, options)\n    fname = '%s.%s' % (get_basename(text, options), options['format'])\n    if app.builder.format == 'html':\n        # HTML\n        imgpath = relative_uri(app.builder.env.docname, '_images')\n        relfn = posixpath.join(imgpath, fname)\n        outfn = path.join(app.builder.outdir, '_images', fname)\n    else:\n        # Non-HTML\n        if app.builder.format != 'latex':\n            app.builder.warn('aafig: the builder format %s is not officially '\n                    'supported, aafigure images could not work. Please report '\n                    'problems and working builder to avoid this warning in '\n                    'the future' % app.builder.format)\n        relfn = fname\n        outfn = path.join(app.builder.outdir, fname)\n    metadata_fname = '%s.aafig' % outfn\n\n    try:\n        if path.isfile(outfn):\n            extra = None\n            if options['format'].lower() == 'svg':\n                f = None\n                try:\n                    try:\n                        f = open(metadata_fname, 'r')\n                        extra = f.read()\n                    except:\n                        raise AafigError()\n                finally:\n                    if f is not None:\n                        f.close()\n            return relfn, outfn, id, extra\n    except AafigError:\n        pass\n\n    ensuredir(path.dirname(outfn))\n\n    try:\n        (visitor, output) = aafigure.render(text, outfn, options)\n        output.close()\n    except aafigure.UnsupportedFormatError as e:\n        raise AafigError(str(e))\n\n    extra = None\n    if options['format'].lower() == 'svg':\n        extra = visitor.get_size_attrs()\n        f = open(metadata_fname, 'w')\n        f.write(extra)\n        f.close()\n\n    return relfn, outfn, id, extra"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nraises ValidationError if invalid", "response": "def validate(self, settings):\n        \"\"\"Raise ValidationError if invalid\"\"\"\n\n        if self.envs is None:\n            self.envs = [settings.current_env]\n\n        if self.when is not None:\n            try:\n                # inherit env if not defined\n                if self.when.envs is None:\n                    self.when.envs = self.envs\n\n                self.when.validate(settings)\n            except ValidationError:\n                # if when is invalid, return canceling validation flow\n                return\n\n        # If only using current_env, skip using_env decoration (reload)\n        if (\n            len(self.envs) == 1\n            and self.envs[0].upper() == settings.current_env.upper()\n        ):\n            self._validate_items(settings, settings.current_env)\n            return\n\n        for env in self.envs:\n            with settings.using_env(env):\n                self._validate_items(settings, env)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride the parent to omit explicity defined meta fields from the list of declared fields", "response": "def get_field_names(self, declared_fields, info):\n        \"\"\"\n        We override the parent to omit explicity defined meta fields (such\n        as SerializerMethodFields) from the list of declared fields\n        \"\"\"\n        meta_fields = getattr(self.Meta, 'meta_fields', [])\n\n        declared = OrderedDict()\n        for field_name in set(declared_fields.keys()):\n            field = declared_fields[field_name]\n            if field_name not in meta_fields:\n                declared[field_name] = field\n        fields = super(ModelSerializer, self).get_field_names(declared, info)\n        return list(fields) + list(getattr(self.Meta, 'meta_fields', list()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_representation(self, instance):\n        ret = OrderedDict()\n        readable_fields = [\n            field for field in self.fields.values()\n            if not field.write_only\n        ]\n\n        for field in readable_fields:\n            try:\n                field_representation = self._get_field_representation(field, instance)\n                ret[field.field_name] = field_representation\n            except SkipField:\n                continue\n\n        return ret", "response": "Returns a dict of primitive datatypes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_invalid_fields(self, queryset, fields, view, request):\n        valid_fields = [\n            item[0] for item in self.get_valid_fields(queryset, view,\n                                                      {'request': request})\n        ]\n        bad_terms = [\n            term for term in fields\n            if format_value(term.replace(\".\", \"__\").lstrip('-'), \"underscore\") not in valid_fields\n        ]\n        if bad_terms:\n            raise ValidationError('invalid sort parameter{}: {}'.format(\n                ('s' if len(bad_terms) > 1 else ''), ','.join(bad_terms)))\n        # this looks like it duplicates code above, but we want the ValidationError to report\n        # the actual parameter supplied while we want the fields passed to the super() to\n        # be correctly rewritten.\n        # The leading `-` has to be stripped to prevent format_value from turning it into `_`.\n        underscore_fields = []\n        for item in fields:\n            item_rewritten = item.replace(\".\", \"__\")\n            if item_rewritten.startswith('-'):\n                underscore_fields.append(\n                    '-' + format_value(item_rewritten.lstrip('-'), \"underscore\"))\n            else:\n                underscore_fields.append(format_value(item_rewritten, \"underscore\"))\n\n        return super(OrderingFilter, self).remove_invalid_fields(\n            queryset, underscore_fields, view, request)", "response": "This method is used to remove invalid fields from the queryset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that the query params in the request match the valid keywords in the resource.", "response": "def validate_query_params(self, request):\n        \"\"\"\n        Validate that query params are in the list of valid query keywords in\n        :py:attr:`query_regex`\n\n        :raises ValidationError: if not.\n        \"\"\"\n        # TODO: For jsonapi error object conformance, must set jsonapi errors \"parameter\" for\n        # the ValidationError. This requires extending DRF/DJA Exceptions.\n        for qp in request.query_params.keys():\n            if not self.query_regex.match(qp):\n                raise ValidationError('invalid query parameter: {}'.format(qp))\n            if len(request.query_params.getlist(qp)) > 1:\n                raise ValidationError(\n                    'repeated query parameter not allowed: {}'.format(qp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the attributes from the JSON API resource.", "response": "def extract_attributes(cls, fields, resource):\n        \"\"\"\n        Builds the `attributes` object of the JSON API resource object.\n        \"\"\"\n        data = OrderedDict()\n        for field_name, field in six.iteritems(fields):\n            # ID is always provided in the root of JSON API so remove it from attributes\n            if field_name == 'id':\n                continue\n            # don't output a key for write only fields\n            if fields[field_name].write_only:\n                continue\n            # Skip fields with relations\n            if isinstance(\n                    field, (relations.RelatedField, relations.ManyRelatedField, BaseSerializer)\n            ):\n                continue\n\n            # Skip read_only attribute fields when `resource` is an empty\n            # serializer. Prevents the \"Raw Data\" form of the browsable API\n            # from rendering `\"foo\": null` for read only fields\n            try:\n                resource[field_name]\n            except KeyError:\n                if fields[field_name].read_only:\n                    continue\n\n            data.update({\n                field_name: resource.get(field_name)\n            })\n\n        return utils._format_object(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_relationships(cls, fields, resource, resource_instance):\n        # Avoid circular deps\n        from rest_framework_json_api.relations import ResourceRelatedField\n\n        data = OrderedDict()\n\n        # Don't try to extract relationships from a non-existent resource\n        if resource_instance is None:\n            return\n\n        for field_name, field in six.iteritems(fields):\n            # Skip URL field\n            if field_name == api_settings.URL_FIELD_NAME:\n                continue\n\n            # don't output a key for write only fields\n            if fields[field_name].write_only:\n                continue\n\n            # Skip fields without relations\n            if not isinstance(\n                field, (relations.RelatedField, relations.ManyRelatedField, BaseSerializer)\n            ):\n                continue\n\n            source = field.source\n            relation_type = utils.get_related_resource_type(field)\n\n            if isinstance(field, relations.HyperlinkedIdentityField):\n                resolved, relation_instance = utils.get_relation_instance(\n                    resource_instance, source, field.parent\n                )\n                if not resolved:\n                    continue\n                # special case for HyperlinkedIdentityField\n                relation_data = list()\n\n                # Don't try to query an empty relation\n                relation_queryset = relation_instance \\\n                    if relation_instance is not None else list()\n\n                for related_object in relation_queryset:\n                    relation_data.append(\n                        OrderedDict([\n                            ('type', relation_type),\n                            ('id', encoding.force_text(related_object.pk))\n                        ])\n                    )\n\n                data.update({field_name: {\n                    'links': {\n                        \"related\": resource.get(field_name)},\n                    'data': relation_data,\n                    'meta': {\n                        'count': len(relation_data)\n                    }\n                }})\n                continue\n\n            relation_data = {}\n            if isinstance(field, HyperlinkedMixin):\n                field_links = field.get_links(resource_instance, field.related_link_lookup_field)\n                relation_data.update({'links': field_links} if field_links else dict())\n                data.update({field_name: relation_data})\n\n            if isinstance(field, (ResourceRelatedField, )):\n                if not isinstance(field, SkipDataMixin):\n                    relation_data.update({'data': resource.get(field_name)})\n\n                data.update({field_name: relation_data})\n                continue\n\n            if isinstance(\n                    field, (relations.PrimaryKeyRelatedField, relations.HyperlinkedRelatedField)\n            ):\n                resolved, relation = utils.get_relation_instance(\n                    resource_instance, '%s_id' % source, field.parent\n                )\n                if not resolved:\n                    continue\n                relation_id = relation if resource.get(field_name) else None\n                relation_data = {\n                    'data': (\n                        OrderedDict([\n                            ('type', relation_type), ('id', encoding.force_text(relation_id))\n                        ])\n                        if relation_id is not None else None)\n                }\n\n                if (\n                    isinstance(field, relations.HyperlinkedRelatedField) and\n                    resource.get(field_name)\n                ):\n                    relation_data.update(\n                        {\n                            'links': {\n                                'related': resource.get(field_name)\n                            }\n                        }\n                    )\n                data.update({field_name: relation_data})\n                continue\n\n            if isinstance(field, relations.ManyRelatedField):\n                resolved, relation_instance = utils.get_relation_instance(\n                    resource_instance, source, field.parent\n                )\n                if not resolved:\n                    continue\n\n                relation_data = {}\n\n                if isinstance(resource.get(field_name), Iterable):\n                    relation_data.update(\n                        {\n                            'meta': {'count': len(resource.get(field_name))}\n                        }\n                    )\n\n                if isinstance(field.child_relation, ResourceRelatedField):\n                    # special case for ResourceRelatedField\n                    relation_data.update(\n                        {'data': resource.get(field_name)}\n                    )\n\n                if isinstance(field.child_relation, HyperlinkedMixin):\n                    field_links = field.child_relation.get_links(\n                        resource_instance,\n                        field.child_relation.related_link_lookup_field\n                    )\n                    relation_data.update(\n                        {'links': field_links}\n                        if field_links else dict()\n                    )\n\n                    data.update({field_name: relation_data})\n                    continue\n\n                relation_data = list()\n                for nested_resource_instance in relation_instance:\n                    nested_resource_instance_type = (\n                        relation_type or\n                        utils.get_resource_type_from_instance(nested_resource_instance)\n                    )\n\n                    relation_data.append(OrderedDict([\n                        ('type', nested_resource_instance_type),\n                        ('id', encoding.force_text(nested_resource_instance.pk))\n                    ]))\n                data.update({\n                    field_name: {\n                        'data': relation_data,\n                        'meta': {\n                            'count': len(relation_data)\n                        }\n                    }\n                })\n                continue\n\n            if isinstance(field, ListSerializer):\n                resolved, relation_instance = utils.get_relation_instance(\n                    resource_instance, source, field.parent\n                )\n                if not resolved:\n                    continue\n\n                relation_data = list()\n\n                serializer_data = resource.get(field_name)\n                resource_instance_queryset = list(relation_instance)\n                if isinstance(serializer_data, list):\n                    for position in range(len(serializer_data)):\n                        nested_resource_instance = resource_instance_queryset[position]\n                        nested_resource_instance_type = (\n                            relation_type or\n                            utils.get_resource_type_from_instance(nested_resource_instance)\n                        )\n\n                        relation_data.append(OrderedDict([\n                            ('type', nested_resource_instance_type),\n                            ('id', encoding.force_text(nested_resource_instance.pk))\n                        ]))\n\n                    data.update({field_name: {'data': relation_data}})\n                    continue\n\n            if isinstance(field, Serializer):\n                relation_instance_id = getattr(resource_instance, source + \"_id\", None)\n                if not relation_instance_id:\n                    resolved, relation_instance = utils.get_relation_instance(\n                        resource_instance, source, field.parent\n                    )\n                    if not resolved:\n                        continue\n\n                    if relation_instance is not None:\n                        relation_instance_id = relation_instance.pk\n\n                data.update({\n                    field_name: {\n                        'data': (\n                            OrderedDict([\n                                ('type', relation_type),\n                                ('id', encoding.force_text(relation_instance_id))\n                            ]) if resource.get(field_name) else None)\n                    }\n                })\n                continue\n\n        return utils._format_object(data)", "response": "Extract the top level relationships from a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine what instance represents given relation and extracts it.", "response": "def extract_relation_instance(cls, field_name, field, resource_instance, serializer):\n        \"\"\"\n        Determines what instance represents given relation and extracts it.\n\n        Relation instance is determined by given field_name or source configured on\n        field. As fallback is a serializer method called with name of field's source.\n        \"\"\"\n        relation_instance = None\n\n        try:\n            relation_instance = getattr(resource_instance, field_name)\n        except AttributeError:\n            try:\n                # For ManyRelatedFields if `related_name` is not set\n                # we need to access `foo_set` from `source`\n                relation_instance = getattr(resource_instance, field.child_relation.source)\n            except AttributeError:\n                if hasattr(serializer, field.source):\n                    serializer_method = getattr(serializer, field.source)\n                    relation_instance = serializer_method(resource_instance)\n                else:\n                    # case when source is a simple remap on resource_instance\n                    try:\n                        relation_instance = getattr(resource_instance, field.source)\n                    except AttributeError:\n                        pass\n\n        return relation_instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the included data for the resource.", "response": "def extract_included(cls, fields, resource, resource_instance, included_resources,\n                         included_cache):\n        \"\"\"\n        Adds related data to the top level included key when the request includes\n        ?include=example,example_field2\n        \"\"\"\n        # this function may be called with an empty record (example: Browsable Interface)\n        if not resource_instance:\n            return\n\n        current_serializer = fields.serializer\n        context = current_serializer.context\n        included_serializers = utils.get_included_serializers(current_serializer)\n        included_resources = copy.copy(included_resources)\n        included_resources = [inflection.underscore(value) for value in included_resources]\n\n        for field_name, field in six.iteritems(fields):\n            # Skip URL field\n            if field_name == api_settings.URL_FIELD_NAME:\n                continue\n\n            # Skip fields without relations or serialized data\n            if not isinstance(\n                    field, (relations.RelatedField, relations.ManyRelatedField, BaseSerializer)\n            ):\n                continue\n\n            try:\n                included_resources.remove(field_name)\n            except ValueError:\n                # Skip fields not in requested included resources\n                # If no child field, directly continue with the next field\n                if field_name not in [node.split('.')[0] for node in included_resources]:\n                    continue\n\n            relation_instance = cls.extract_relation_instance(\n                field_name, field, resource_instance, current_serializer\n            )\n            if isinstance(relation_instance, Manager):\n                relation_instance = relation_instance.all()\n\n            serializer_data = resource.get(field_name)\n\n            if isinstance(field, relations.ManyRelatedField):\n                serializer_class = included_serializers[field_name]\n                field = serializer_class(relation_instance, many=True, context=context)\n                serializer_data = field.data\n\n            if isinstance(field, relations.RelatedField):\n                if relation_instance is None or not serializer_data:\n                    continue\n\n                many = field._kwargs.get('child_relation', None) is not None\n\n                if isinstance(field, ResourceRelatedField) and not many:\n                    already_included = serializer_data['type'] in included_cache and \\\n                        serializer_data['id'] in included_cache[serializer_data['type']]\n\n                    if already_included:\n                        continue\n\n                serializer_class = included_serializers[field_name]\n                field = serializer_class(relation_instance, many=many, context=context)\n                serializer_data = field.data\n\n            new_included_resources = [key.replace('%s.' % field_name, '', 1)\n                                      for key in included_resources\n                                      if field_name == key.split('.')[0]]\n\n            if isinstance(field, ListSerializer):\n                serializer = field.child\n                relation_type = utils.get_resource_type_from_serializer(serializer)\n                relation_queryset = list(relation_instance)\n\n                if serializer_data:\n                    for position in range(len(serializer_data)):\n                        serializer_resource = serializer_data[position]\n                        nested_resource_instance = relation_queryset[position]\n                        resource_type = (\n                            relation_type or\n                            utils.get_resource_type_from_instance(nested_resource_instance)\n                        )\n                        serializer_fields = utils.get_serializer_fields(\n                            serializer.__class__(\n                                nested_resource_instance, context=serializer.context\n                            )\n                        )\n                        new_item = cls.build_json_resource_obj(\n                            serializer_fields,\n                            serializer_resource,\n                            nested_resource_instance,\n                            resource_type,\n                            getattr(serializer, '_poly_force_type_resolution', False)\n                        )\n                        included_cache[new_item['type']][new_item['id']] = \\\n                            utils._format_object(new_item)\n                        cls.extract_included(\n                            serializer_fields,\n                            serializer_resource,\n                            nested_resource_instance,\n                            new_included_resources,\n                            included_cache,\n                        )\n\n            if isinstance(field, Serializer):\n                relation_type = utils.get_resource_type_from_serializer(field)\n\n                # Get the serializer fields\n                serializer_fields = utils.get_serializer_fields(field)\n                if serializer_data:\n                    new_item = cls.build_json_resource_obj(\n                        serializer_fields,\n                        serializer_data,\n                        relation_instance,\n                        relation_type,\n                        getattr(field, '_poly_force_type_resolution', False)\n                    )\n                    included_cache[new_item['type']][new_item['id']] = utils._format_object(\n                        new_item\n                    )\n                    cls.extract_included(\n                        serializer_fields,\n                        serializer_data,\n                        relation_instance,\n                        new_included_resources,\n                        included_cache,\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_meta(cls, serializer, resource):\n        if hasattr(serializer, 'child'):\n            meta = getattr(serializer.child, 'Meta', None)\n        else:\n            meta = getattr(serializer, 'Meta', None)\n        meta_fields = getattr(meta, 'meta_fields', [])\n        data = OrderedDict()\n        for field_name in meta_fields:\n            data.update({\n                field_name: resource.get(field_name)\n            })\n        return data", "response": "Extracts the data from the meta object and adds it to the meta object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the root meta data from a resource.", "response": "def extract_root_meta(cls, serializer, resource):\n        \"\"\"\n        Calls a `get_root_meta` function on a serializer, if it exists.\n        \"\"\"\n        many = False\n        if hasattr(serializer, 'child'):\n            many = True\n            serializer = serializer.child\n\n        data = {}\n        if getattr(serializer, 'get_root_meta', None):\n            json_api_meta = serializer.get_root_meta(resource, many)\n            assert isinstance(json_api_meta, dict), 'get_root_meta must return a dict'\n            data.update(json_api_meta)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the resource object from the fields and resource and returns it as a dictionary.", "response": "def build_json_resource_obj(cls, fields, resource, resource_instance, resource_name,\n                                force_type_resolution=False):\n        \"\"\"\n        Builds the resource object (type, id, attributes) and extracts relationships.\n        \"\"\"\n        # Determine type from the instance if the underlying model is polymorphic\n        if force_type_resolution:\n            resource_name = utils.get_resource_type_from_instance(resource_instance)\n        resource_data = [\n            ('type', resource_name),\n            ('id', encoding.force_text(resource_instance.pk) if resource_instance else None),\n            ('attributes', cls.extract_attributes(fields, resource)),\n        ]\n        relationships = cls.extract_relationships(fields, resource, resource_instance)\n        if relationships:\n            resource_data.append(('relationships', relationships))\n        # Add 'self' link if field is present and valid\n        if api_settings.URL_FIELD_NAME in resource and \\\n                isinstance(fields[api_settings.URL_FIELD_NAME], relations.RelatedField):\n            resource_data.append(('links', {'self': resource[api_settings.URL_FIELD_NAME]}))\n        return OrderedDict(resource_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_queryset(self):\n        qs = super(PrefetchForIncludesHelperMixin, self).get_queryset()\n        if not hasattr(self, 'prefetch_for_includes'):\n            return qs\n\n        includes = self.request.GET.get('include', '').split(',')\n        for inc in includes + ['__all__']:\n            prefetches = self.prefetch_for_includes.get(inc)\n            if prefetches:\n                qs = qs.prefetch_related(*prefetches)\n\n        return qs", "response": "This viewset provides a helper attribute to prefetch related models based on the include parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a name view name and kwargs return the URL that hyperlinks to the object.", "response": "def get_url(self, name, view_name, kwargs, request):\n        \"\"\"\n        Given a name, view name and kwargs, return the URL that hyperlinks to the object.\n\n        May raise a `NoReverseMatch` if the `view_name` and `lookup_field`\n        attributes are not configured to correctly match the URL conf.\n        \"\"\"\n\n        # Return None if the view name is not supplied\n        if not view_name:\n            return None\n\n        # Return the hyperlink, or error if incorrectly configured.\n        try:\n            url = self.reverse(view_name, kwargs=kwargs, request=request)\n        except NoReverseMatch:\n            msg = (\n                'Could not resolve URL for hyperlinked relationship using '\n                'view name \"%s\". You may have failed to include the related '\n                'model in your API, or incorrectly configured the '\n                '`lookup_field` attribute on this field.'\n            )\n            raise ImproperlyConfigured(msg % view_name)\n\n        if url is None:\n            return None\n\n        return Hyperlink(url, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noverrides get_queryset to filter by multiple ID", "response": "def get_queryset(self):\n        \"\"\"\n        Override :meth:``get_queryset``\n        \"\"\"\n        queryset = super(MultipleIDMixin, self).get_queryset()\n        if hasattr(self.request, 'query_params'):\n            ids = dict(self.request.query_params).get('ids[]')\n        else:\n            ids = dict(self.request.QUERY_PARAMS).get('ids[]')\n        if ids:\n            queryset = queryset.filter(id__in=ids)\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives an instance of a serializer return a dictionary of metadata about its fields.", "response": "def get_serializer_info(self, serializer):\n        \"\"\"\n        Given an instance of a serializer, return a dictionary of metadata\n        about its fields.\n        \"\"\"\n        if hasattr(serializer, 'child'):\n            # If this is a `ListSerializer` then we want to examine the\n            # underlying child serializer instance instead.\n            serializer = serializer.child\n\n        # Remove the URL field if present\n        serializer.fields.pop(api_settings.URL_FIELD_NAME, None)\n\n        return OrderedDict([\n            (field_name, self.get_field_info(field))\n            for field_name, field in serializer.fields.items()\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_field_info(self, field):\n        field_info = OrderedDict()\n        serializer = field.parent\n\n        if isinstance(field, serializers.ManyRelatedField):\n            field_info['type'] = self.type_lookup[field.child_relation]\n        else:\n            field_info['type'] = self.type_lookup[field]\n\n        try:\n            serializer_model = getattr(serializer.Meta, 'model')\n            field_info['relationship_type'] = self.relation_type_lookup[\n                getattr(serializer_model, field.field_name)\n            ]\n        except KeyError:\n            pass\n        except AttributeError:\n            pass\n        else:\n            field_info['relationship_resource'] = get_related_resource_type(field)\n\n        field_info['required'] = getattr(field, 'required', False)\n\n        attrs = [\n            'read_only', 'write_only', 'label', 'help_text',\n            'min_length', 'max_length',\n            'min_value', 'max_value', 'initial'\n        ]\n\n        for attr in attrs:\n            value = getattr(field, attr, None)\n            if value is not None and value != '':\n                field_info[attr] = force_text(value, strings_only=True)\n\n        if getattr(field, 'child', None):\n            field_info['child'] = self.get_field_info(field.child)\n        elif getattr(field, 'fields', None):\n            field_info['children'] = self.get_serializer_info(field)\n\n        if (\n            not field_info.get('read_only') and\n            not field_info.get('relationship_resource') and\n            hasattr(field, 'choices')\n        ):\n            field_info['choices'] = [\n                {\n                    'value': choice_value,\n                    'display_name': force_text(choice_name, strings_only=True)\n                }\n                for choice_value, choice_name in field.choices.items()\n            ]\n\n        if hasattr(serializer, 'included_serializers') and 'relationship_resource' in field_info:\n            field_info['allows_include'] = field.field_name in serializer.included_serializers\n\n        return field_info", "response": "Returns a dictionary of metadata about a given serializer field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, pk=None):\n        obj = self.get_object()\n        return Response(IdentitySerializer(obj).data)", "response": "Get the object from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_resource_name(context, expand_polymorphic_types=False):\n    from rest_framework_json_api.serializers import PolymorphicModelSerializer\n    view = context.get('view')\n\n    # Sanity check to make sure we have a view.\n    if not view:\n        return None\n\n    # Check to see if there is a status code and return early\n    # with the resource_name value of `errors`.\n    try:\n        code = str(view.response.status_code)\n    except (AttributeError, ValueError):\n        pass\n    else:\n        if code.startswith('4') or code.startswith('5'):\n            return 'errors'\n\n    try:\n        resource_name = getattr(view, 'resource_name')\n    except AttributeError:\n        try:\n            serializer = view.get_serializer_class()\n            if expand_polymorphic_types and issubclass(serializer, PolymorphicModelSerializer):\n                return serializer.get_polymorphic_types()\n            else:\n                return get_resource_type_from_serializer(serializer)\n        except AttributeError:\n            try:\n                resource_name = get_resource_type_from_model(view.model)\n            except AttributeError:\n                resource_name = view.__class__.__name__\n\n            if not isinstance(resource_name, six.string_types):\n                # The resource name is not a string - return as is\n                return resource_name\n\n            # the name was calculated automatically from the view > pluralize and format\n            resource_name = format_resource_type(resource_name)\n\n    return resource_name", "response": "Return the name of a resource in the current context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a dict and returns it with formatted keys as set in format_type or JSON_API_FORMAT_FIELD_NAMES", "response": "def format_field_names(obj, format_type=None):\n    \"\"\"\n    Takes a dict and returns it with formatted keys as set in `format_type`\n    or `JSON_API_FORMAT_FIELD_NAMES`\n\n    :format_type: Either 'dasherize', 'camelize', 'capitalize' or 'underscore'\n    \"\"\"\n    if format_type is None:\n        format_type = json_api_settings.FORMAT_FIELD_NAMES\n\n    if isinstance(obj, dict):\n        formatted = OrderedDict()\n        for key, value in obj.items():\n            key = format_value(key, format_type)\n            formatted[key] = value\n        return formatted\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_object(obj, format_type=None):\n\n    if json_api_settings.FORMAT_KEYS is not None:\n        return format_keys(obj, format_type)\n\n    return format_field_names(obj, format_type)", "response": "Format an object according to the settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict with camelized keys only if the JSON API_FORMAT_KEYS setting is set.", "response": "def format_keys(obj, format_type=None):\n    \"\"\"\n    .. warning::\n\n        `format_keys` function and `JSON_API_FORMAT_KEYS` setting are deprecated and will be\n        removed in the future.\n        Use `format_field_names` and `JSON_API_FORMAT_FIELD_NAMES` instead. Be aware that\n        `format_field_names` only formats keys and preserves value.\n\n    Takes either a dict or list and returns it with camelized keys only if\n    JSON_API_FORMAT_KEYS is set.\n\n    :format_type: Either 'dasherize', 'camelize', 'capitalize' or 'underscore'\n    \"\"\"\n    warnings.warn(\n        \"`format_keys` function and `JSON_API_FORMAT_KEYS` setting are deprecated and will be \"\n        \"removed in the future. \"\n        \"Use `format_field_names` and `JSON_API_FORMAT_FIELD_NAMES` instead. Be aware that \"\n        \"`format_field_names` only formats keys and preserves value.\",\n        DeprecationWarning\n    )\n\n    if format_type is None:\n        format_type = json_api_settings.FORMAT_KEYS\n\n    if format_type in ('dasherize', 'camelize', 'underscore', 'capitalize'):\n\n        if isinstance(obj, dict):\n            formatted = OrderedDict()\n            for key, value in obj.items():\n                if format_type == 'dasherize':\n                    # inflection can't dasherize camelCase\n                    key = inflection.underscore(key)\n                    formatted[inflection.dasherize(key)] \\\n                        = format_keys(value, format_type)\n                elif format_type == 'camelize':\n                    formatted[inflection.camelize(key, False)] \\\n                        = format_keys(value, format_type)\n                elif format_type == 'capitalize':\n                    formatted[inflection.camelize(key)] \\\n                        = format_keys(value, format_type)\n                elif format_type == 'underscore':\n                    formatted[inflection.underscore(key)] \\\n                        = format_keys(value, format_type)\n            return formatted\n        if isinstance(obj, list):\n            return [format_keys(item, format_type) for item in obj]\n        else:\n            return obj\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_relation_name(value, format_type=None):\n    warnings.warn(\n        \"The 'format_relation_name' function has been renamed 'format_resource_type' and the \"\n        \"settings are now 'JSON_API_FORMAT_TYPES' and 'JSON_API_PLURALIZE_TYPES' instead of \"\n        \"'JSON_API_FORMAT_RELATION_KEYS' and 'JSON_API_PLURALIZE_RELATION_TYPE'\",\n        DeprecationWarning\n    )\n    if format_type is None:\n        format_type = json_api_settings.FORMAT_RELATION_KEYS\n    pluralize = json_api_settings.PLURALIZE_RELATION_TYPE\n    return format_resource_type(value, format_type, pluralize)", "response": "Format the name of a resource in the given format_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a list of included resources.", "response": "def get_included_resources(request, serializer=None):\n    \"\"\" Build a list of included resources. \"\"\"\n    include_resources_param = request.query_params.get('include') if request else None\n    if include_resources_param:\n        return include_resources_param.split(',')\n    else:\n        return get_default_included_resources_from_serializer(serializer)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self, stream, media_type=None, parser_context=None):\n        result = super(JSONParser, self).parse(\n            stream, media_type=media_type, parser_context=parser_context\n        )\n\n        if not isinstance(result, dict) or 'data' not in result:\n            raise ParseError('Received document does not contain primary data')\n\n        data = result.get('data')\n        view = parser_context['view']\n\n        from rest_framework_json_api.views import RelationshipView\n        if isinstance(view, RelationshipView):\n            # We skip parsing the object as JSONAPI Resource Identifier Object and not a regular\n            # Resource Object\n            if isinstance(data, list):\n                for resource_identifier_object in data:\n                    if not (\n                        resource_identifier_object.get('id') and\n                        resource_identifier_object.get('type')\n                    ):\n                        raise ParseError(\n                            'Received data contains one or more malformed JSONAPI '\n                            'Resource Identifier Object(s)'\n                        )\n            elif not (data.get('id') and data.get('type')):\n                raise ParseError('Received data is not a valid JSONAPI Resource Identifier Object')\n\n            return data\n\n        request = parser_context.get('request')\n\n        # Check for inconsistencies\n        if request.method in ('PUT', 'POST', 'PATCH'):\n            resource_name = utils.get_resource_name(\n                parser_context, expand_polymorphic_types=True)\n            if isinstance(resource_name, six.string_types):\n                if data.get('type') != resource_name:\n                    raise exceptions.Conflict(\n                        \"The resource object's type ({data_type}) is not the type that \"\n                        \"constitute the collection represented by the endpoint \"\n                        \"({resource_type}).\".format(\n                            data_type=data.get('type'),\n                            resource_type=resource_name))\n            else:\n                if data.get('type') not in resource_name:\n                    raise exceptions.Conflict(\n                        \"The resource object's type ({data_type}) is not the type that \"\n                        \"constitute the collection represented by the endpoint \"\n                        \"(one of [{resource_types}]).\".format(\n                            data_type=data.get('type'),\n                            resource_types=\", \".join(resource_name)))\n        if not data.get('id') and request.method in ('PATCH', 'PUT'):\n            raise ParseError(\"The resource identifier object must contain an 'id' member\")\n\n        # Construct the return data\n        serializer_class = getattr(view, 'serializer_class', None)\n        parsed_data = {'id': data.get('id')} if 'id' in data else {}\n        # `type` field needs to be allowed in none polymorphic serializers\n        if serializer_class is not None:\n            if issubclass(serializer_class, serializers.PolymorphicModelSerializer):\n                parsed_data['type'] = data.get('type')\n        parsed_data.update(self.parse_attributes(data))\n        parsed_data.update(self.parse_relationships(data))\n        parsed_data.update(self.parse_metadata(result))\n        return parsed_data", "response": "Parses the incoming bytestream as JSON and returns the resulting data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_filter(self, keys, filterset_class):\n        for k in keys:\n            if ((not filterset_class) or (k not in filterset_class.base_filters)):\n                raise ValidationError(\"invalid filter[{}]\".format(k))", "response": "Validate that all the filter keys are valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_filterset(self, request, queryset, view):\n        # TODO: .base_filters vs. .filters attr (not always present)\n        filterset_class = self.get_filterset_class(view, queryset)\n        kwargs = self.get_filterset_kwargs(request, queryset, view)\n        self._validate_filter(kwargs.pop('filter_keys'), filterset_class)\n        if filterset_class is None:\n            return None\n        return filterset_class(**kwargs)", "response": "Get the filterset for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns filter [ field = value ] into list of key = value pairs which is what DjangoFilterBackend expects", "response": "def get_filterset_kwargs(self, request, queryset, view):\n        \"\"\"\n        Turns filter[<field>]=<value> into <field>=<value> which is what\n        DjangoFilterBackend expects\n\n        :raises ValidationError: for bad filter syntax\n        \"\"\"\n        filter_keys = []\n        # rewrite filter[field] query params to make DjangoFilterBackend work.\n        data = request.query_params.copy()\n        for qp, val in request.query_params.items():\n            m = self.filter_regex.match(qp)\n            if m and (not m.groupdict()['assoc'] or\n                      m.groupdict()['ldelim'] != '[' or m.groupdict()['rdelim'] != ']'):\n                raise ValidationError(\"invalid query parameter: {}\".format(qp))\n            if m and qp != self.search_param:\n                if not val:\n                    raise ValidationError(\"missing {} test value\".format(qp))\n                # convert jsonapi relationship path to Django ORM's __ notation\n                key = m.groupdict()['assoc'].replace('.', '__')\n                # undo JSON_API_FORMAT_FIELD_NAMES conversion:\n                key = format_value(key, 'underscore')\n                data[key] = val\n                filter_keys.append(key)\n                del data[qp]\n        return {\n            'data': data,\n            'queryset': queryset,\n            'request': request,\n            'filter_keys': filter_keys,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef many_init(cls, *args, **kwargs):\n        list_kwargs = {'child_relation': cls(*args, **kwargs)}\n        for key in kwargs:\n            if key in MANY_RELATION_KWARGS:\n                list_kwargs[key] = kwargs[key]\n        return ManyRelatedFieldWithNoData(**list_kwargs)", "response": "This method handles creating a parent ManyRelatedField when the many = True keyword argument is passed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef conflict(self, key, **kwargs):\n        try:\n            msg = self.error_messages[key]\n        except KeyError:\n            class_name = self.__class__.__name__\n            msg = MISSING_ERROR_MESSAGE.format(class_name=class_name, key=key)\n            raise AssertionError(msg)\n        message_string = msg.format(**kwargs)\n        raise Conflict(message_string)", "response": "A helper method that raises an AssertionError if there is a conflict with the key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck to see if this resource has a different resource_name when included and return that name or None", "response": "def get_resource_type_from_included_serializer(self):\n        \"\"\"\n        Check to see it this resource has a different resource_name when\n        included and return that name, or None\n        \"\"\"\n        field_name = self.field_name or self.parent.field_name\n        parent = self.get_parent_serializer()\n\n        if parent is not None:\n            # accept both singular and plural versions of field_name\n            field_names = [\n                inflection.singularize(field_name),\n                inflection.pluralize(field_name)\n            ]\n            includes = get_included_serializers(parent)\n            for field in field_names:\n                if field in includes.keys():\n                    return get_resource_type_from_serializer(includes[field])\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signature_base_string(http_method, base_str_uri,\n                          normalized_encoded_request_parameters):\n    \"\"\"**Construct the signature base string.**\n    Per `section 3.4.1.1`_ of the spec.\n\n    For example, the HTTP request::\n\n        POST /request?b5=%3D%253D&a3=a&c%40=&a2=r%20b HTTP/1.1\n        Host: example.com\n        Content-Type: application/x-www-form-urlencoded\n        Authorization: OAuth realm=\"Example\",\n            oauth_consumer_key=\"9djdj82h48djs9d2\",\n            oauth_token=\"kkk9d7dh3k39sjv7\",\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=\"137131201\",\n            oauth_nonce=\"7d8f3e4a\",\n            oauth_signature=\"bYT5CMsGcbgUdFHObYMEfcx6bsw%3D\"\n\n        c2&a3=2+q\n\n    is represented by the following signature base string (line breaks\n    are for display purposes only)::\n\n        POST&http%3A%2F%2Fexample.com%2Frequest&a2%3Dr%2520b%26a3%3D2%2520q\n        %26a3%3Da%26b5%3D%253D%25253D%26c%2540%3D%26c2%3D%26oauth_consumer_\n        key%3D9djdj82h48djs9d2%26oauth_nonce%3D7d8f3e4a%26oauth_signature_m\n        ethod%3DHMAC-SHA1%26oauth_timestamp%3D137131201%26oauth_token%3Dkkk\n        9d7dh3k39sjv7\n\n    .. _`section 3.4.1.1`: https://tools.ietf.org/html/rfc5849#section-3.4.1.1\n    \"\"\"\n\n    # The signature base string is constructed by concatenating together,\n    # in order, the following HTTP request elements:\n\n    # 1.  The HTTP request method in uppercase.  For example: \"HEAD\",\n    #     \"GET\", \"POST\", etc.  If the request uses a custom HTTP method, it\n    #     MUST be encoded (`Section 3.6`_).\n    #\n    # .. _`Section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6\n    base_string = utils.escape(http_method.upper())\n\n    # 2.  An \"&\" character (ASCII code 38).\n    base_string += '&'\n\n    # 3.  The base string URI from `Section 3.4.1.2`_, after being encoded\n    #     (`Section 3.6`_).\n    #\n    # .. _`Section 3.4.1.2`: https://tools.ietf.org/html/rfc5849#section-3.4.1.2\n    # .. _`Section 3.4.6`: https://tools.ietf.org/html/rfc5849#section-3.4.6\n    base_string += utils.escape(base_str_uri)\n\n    # 4.  An \"&\" character (ASCII code 38).\n    base_string += '&'\n\n    # 5.  The request parameters as normalized in `Section 3.4.1.3.2`_, after\n    #     being encoded (`Section 3.6`).\n    #\n    # .. _`Section 3.4.1.3.2`: https://tools.ietf.org/html/rfc5849#section-3.4.1.3.2\n    # .. _`Section 3.4.6`: https://tools.ietf.org/html/rfc5849#section-3.4.6\n    base_string += utils.escape(normalized_encoded_request_parameters)\n\n    return base_string", "response": "Construct the signature base string for the request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef base_string_uri(uri, host=None):\n    if not isinstance(uri, unicode_type):\n        raise ValueError('uri must be a unicode object.')\n\n    # FIXME: urlparse does not support unicode\n    scheme, netloc, path, params, query, fragment = urlparse.urlparse(uri)\n\n    # The scheme, authority, and path of the request resource URI `RFC3986`\n    # are included by constructing an \"http\" or \"https\" URI representing\n    # the request resource (without the query or fragment) as follows:\n    #\n    # .. _`RFC3986`: https://tools.ietf.org/html/rfc3986\n\n    if not scheme or not netloc:\n        raise ValueError('uri must include a scheme and netloc')\n\n    # Per `RFC 2616 section 5.1.2`_:\n    #\n    # Note that the absolute path cannot be empty; if none is present in\n    # the original URI, it MUST be given as \"/\" (the server root).\n    #\n    # .. _`RFC 2616 section 5.1.2`: https://tools.ietf.org/html/rfc2616#section-5.1.2\n    if not path:\n        path = '/'\n\n    # 1.  The scheme and host MUST be in lowercase.\n    scheme = scheme.lower()\n    netloc = netloc.lower()\n\n    # 2.  The host and port values MUST match the content of the HTTP\n    #     request \"Host\" header field.\n    if host is not None:\n        netloc = host.lower()\n\n    # 3.  The port MUST be included if it is not the default port for the\n    #     scheme, and MUST be excluded if it is the default.  Specifically,\n    #     the port MUST be excluded when making an HTTP request `RFC2616`_\n    #     to port 80 or when making an HTTPS request `RFC2818`_ to port 443.\n    #     All other non-default port numbers MUST be included.\n    #\n    # .. _`RFC2616`: https://tools.ietf.org/html/rfc2616\n    # .. _`RFC2818`: https://tools.ietf.org/html/rfc2818\n    default_ports = (\n        ('http', '80'),\n        ('https', '443'),\n    )\n    if ':' in netloc:\n        host, port = netloc.split(':', 1)\n        if (scheme, port) in default_ports:\n            netloc = host\n\n    v = urlparse.urlunparse((scheme, netloc, path, params, '', ''))\n\n    # RFC 5849 does not specify which characters are encoded in the\n    # \"base string URI\", nor how they are encoded - which is very bad, since\n    # the signatures won't match if there are any differences. Fortunately,\n    # most URIs only use characters that are clearly not encoded (e.g. digits\n    # and A-Z, a-z), so have avoided any differences between implementations.\n    #\n    # The example from its section 3.4.1.2 illustrates that spaces in\n    # the path are percent encoded. But it provides no guidance as to what other\n    # characters (if any) must be encoded (nor how); nor if characters in the\n    # other components are to be encoded or not.\n    #\n    # This implementation **assumes** that **only** the space is percent-encoded\n    # and it is done to the entire value (not just to spaces in the path).\n    #\n    # This code may need to be changed if it is discovered that other characters\n    # are expected to be encoded.\n    #\n    # Note: the \"base string URI\" returned by this function will be encoded\n    # again before being concatenated into the \"signature base string\". So any\n    # spaces in the URI will actually appear in the \"signature base string\"\n    # as \"%2520\" (the \"%20\" further encoded according to section 3.6).\n\n    return v.replace(' ', '%20')", "response": "Return a base string URI for the given URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect all parameters from the base sting.", "response": "def collect_parameters(uri_query='', body=[], headers=None,\n                       exclude_oauth_signature=True, with_realm=False):\n    \"\"\"**Parameter Sources**\n\n    Parameters starting with `oauth_` will be unescaped.\n\n    Body parameters must be supplied as a dict, a list of 2-tuples, or a\n    formencoded query string.\n\n    Headers must be supplied as a dict.\n\n    Per `section 3.4.1.3.1`_ of the spec.\n\n    For example, the HTTP request::\n\n        POST /request?b5=%3D%253D&a3=a&c%40=&a2=r%20b HTTP/1.1\n        Host: example.com\n        Content-Type: application/x-www-form-urlencoded\n        Authorization: OAuth realm=\"Example\",\n            oauth_consumer_key=\"9djdj82h48djs9d2\",\n            oauth_token=\"kkk9d7dh3k39sjv7\",\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=\"137131201\",\n            oauth_nonce=\"7d8f3e4a\",\n            oauth_signature=\"djosJKDKJSD8743243%2Fjdk33klY%3D\"\n\n        c2&a3=2+q\n\n    contains the following (fully decoded) parameters used in the\n    signature base sting::\n\n        +------------------------+------------------+\n        |          Name          |       Value      |\n        +------------------------+------------------+\n        |           b5           |       =%3D       |\n        |           a3           |         a        |\n        |           c@           |                  |\n        |           a2           |        r b       |\n        |   oauth_consumer_key   | 9djdj82h48djs9d2 |\n        |       oauth_token      | kkk9d7dh3k39sjv7 |\n        | oauth_signature_method |     HMAC-SHA1    |\n        |     oauth_timestamp    |     137131201    |\n        |       oauth_nonce      |     7d8f3e4a     |\n        |           c2           |                  |\n        |           a3           |        2 q       |\n        +------------------------+------------------+\n\n    Note that the value of \"b5\" is \"=%3D\" and not \"==\".  Both \"c@\" and\n    \"c2\" have empty values.  While the encoding rules specified in this\n    specification for the purpose of constructing the signature base\n    string exclude the use of a \"+\" character (ASCII code 43) to\n    represent an encoded space character (ASCII code 32), this practice\n    is widely used in \"application/x-www-form-urlencoded\" encoded values,\n    and MUST be properly decoded, as demonstrated by one of the \"a3\"\n    parameter instances (the \"a3\" parameter is used twice in this\n    request).\n\n    .. _`section 3.4.1.3.1`: https://tools.ietf.org/html/rfc5849#section-3.4.1.3.1\n    \"\"\"\n    headers = headers or {}\n    params = []\n\n    # The parameters from the following sources are collected into a single\n    # list of name/value pairs:\n\n    # *  The query component of the HTTP request URI as defined by\n    #    `RFC3986, Section 3.4`_.  The query component is parsed into a list\n    #    of name/value pairs by treating it as an\n    #    \"application/x-www-form-urlencoded\" string, separating the names\n    #    and values and decoding them as defined by\n    #    `W3C.REC-html40-19980424`_, Section 17.13.4.\n    #\n    # .. _`RFC3986, Section 3.4`: https://tools.ietf.org/html/rfc3986#section-3.4\n    # .. _`W3C.REC-html40-19980424`: https://tools.ietf.org/html/rfc5849#ref-W3C.REC-html40-19980424\n    if uri_query:\n        params.extend(urldecode(uri_query))\n\n    # *  The OAuth HTTP \"Authorization\" header field (`Section 3.5.1`_) if\n    #    present.  The header's content is parsed into a list of name/value\n    #    pairs excluding the \"realm\" parameter if present.  The parameter\n    #    values are decoded as defined by `Section 3.5.1`_.\n    #\n    # .. _`Section 3.5.1`: https://tools.ietf.org/html/rfc5849#section-3.5.1\n    if headers:\n        headers_lower = dict((k.lower(), v) for k, v in headers.items())\n        authorization_header = headers_lower.get('authorization')\n        if authorization_header is not None:\n            params.extend([i for i in utils.parse_authorization_header(\n                authorization_header) if with_realm or i[0] != 'realm'])\n\n    # *  The HTTP request entity-body, but only if all of the following\n    #    conditions are met:\n    #     *  The entity-body is single-part.\n    #\n    #     *  The entity-body follows the encoding requirements of the\n    #        \"application/x-www-form-urlencoded\" content-type as defined by\n    #        `W3C.REC-html40-19980424`_.\n\n    #     *  The HTTP request entity-header includes the \"Content-Type\"\n    #        header field set to \"application/x-www-form-urlencoded\".\n    #\n    # .._`W3C.REC-html40-19980424`: https://tools.ietf.org/html/rfc5849#ref-W3C.REC-html40-19980424\n\n    # TODO: enforce header param inclusion conditions\n    bodyparams = extract_params(body) or []\n    params.extend(bodyparams)\n\n    # ensure all oauth params are unescaped\n    unescaped_params = []\n    for k, v in params:\n        if k.startswith('oauth_'):\n            v = utils.unescape(v)\n        unescaped_params.append((k, v))\n\n    # The \"oauth_signature\" parameter MUST be excluded from the signature\n    # base string if present.\n    if exclude_oauth_signature:\n        unescaped_params = list(filter(lambda i: i[0] != 'oauth_signature',\n                                       unescaped_params))\n\n    return unescaped_params"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_parameters(params):\n\n    # The parameters collected in `Section 3.4.1.3`_ are normalized into a\n    # single string as follows:\n    #\n    # .. _`Section 3.4.1.3`: https://tools.ietf.org/html/rfc5849#section-3.4.1.3\n\n    # 1.  First, the name and value of each parameter are encoded\n    #     (`Section 3.6`_).\n    #\n    # .. _`Section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6\n    key_values = [(utils.escape(k), utils.escape(v)) for k, v in params]\n\n    # 2.  The parameters are sorted by name, using ascending byte value\n    #     ordering.  If two or more parameters share the same name, they\n    #     are sorted by their value.\n    key_values.sort()\n\n    # 3.  The name of each parameter is concatenated to its corresponding\n    #     value using an \"=\" character (ASCII code 61) as a separator, even\n    #     if the value is empty.\n    parameter_parts = ['{0}={1}'.format(k, v) for k, v in key_values]\n\n    # 4.  The sorted name/value pairs are concatenated together into a\n    #     single string by using an \"&\" character (ASCII code 38) as\n    #     separator.\n    return '&'.join(parameter_parts)", "response": "This function normalizes the parameters of the current page."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsigns a base string using the RSA - SHA1 algorithm.", "response": "def sign_rsa_sha1(base_string, rsa_private_key):\n    \"\"\"**RSA-SHA1**\n\n    Per `section 3.4.3`_ of the spec.\n\n    The \"RSA-SHA1\" signature method uses the RSASSA-PKCS1-v1_5 signature\n    algorithm as defined in `RFC3447, Section 8.2`_ (also known as\n    PKCS#1), using SHA-1 as the hash function for EMSA-PKCS1-v1_5.  To\n    use this method, the client MUST have established client credentials\n    with the server that included its RSA public key (in a manner that is\n    beyond the scope of this specification).\n\n    .. _`section 3.4.3`: https://tools.ietf.org/html/rfc5849#section-3.4.3\n    .. _`RFC3447, Section 8.2`: https://tools.ietf.org/html/rfc3447#section-8.2\n\n    \"\"\"\n    if isinstance(base_string, unicode_type):\n        base_string = base_string.encode('utf-8')\n    # TODO: finish RSA documentation\n    alg = _jwt_rs1_signing_algorithm()\n    key = _prepare_key_plus(alg, rsa_private_key)\n    s=alg.sign(base_string, key)\n    return binascii.b2a_base64(s)[:-1].decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsigns a request using plaintext.", "response": "def sign_plaintext(client_secret, resource_owner_secret):\n    \"\"\"Sign a request using plaintext.\n\n    Per `section 3.4.4`_ of the spec.\n\n    The \"PLAINTEXT\" method does not employ a signature algorithm.  It\n    MUST be used with a transport-layer mechanism such as TLS or SSL (or\n    sent over a secure channel with equivalent protections).  It does not\n    utilize the signature base string or the \"oauth_timestamp\" and\n    \"oauth_nonce\" parameters.\n\n    .. _`section 3.4.4`: https://tools.ietf.org/html/rfc5849#section-3.4.4\n\n    \"\"\"\n\n    # The \"oauth_signature\" protocol parameter is set to the concatenated\n    # value of:\n\n    # 1.  The client shared-secret, after being encoded (`Section 3.6`_).\n    #\n    # .. _`Section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6\n    signature = utils.escape(client_secret or '')\n\n    # 2.  An \"&\" character (ASCII code 38), which MUST be included even\n    #     when either secret is empty.\n    signature += '&'\n\n    # 3.  The token shared-secret, after being encoded (`Section 3.6`_).\n    #\n    # .. _`Section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6\n    signature += utils.escape(resource_owner_secret or '')\n\n    return signature"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies a HMAC - SHA1 signature.", "response": "def verify_hmac_sha1(request, client_secret=None,\n                     resource_owner_secret=None):\n    \"\"\"Verify a HMAC-SHA1 signature.\n\n    Per `section 3.4`_ of the spec.\n\n    .. _`section 3.4`: https://tools.ietf.org/html/rfc5849#section-3.4\n\n    To satisfy `RFC2616 section 5.2`_ item 1, the request argument's uri\n    attribute MUST be an absolute URI whose netloc part identifies the\n    origin server or gateway on which the resource resides. Any Host\n    item of the request argument's headers dict attribute will be\n    ignored.\n\n    .. _`RFC2616 section 5.2`: https://tools.ietf.org/html/rfc2616#section-5.2\n\n    \"\"\"\n    norm_params = normalize_parameters(request.params)\n    bs_uri = base_string_uri(request.uri)\n    sig_base_str = signature_base_string(request.http_method, bs_uri,\n                                         norm_params)\n    signature = sign_hmac_sha1(sig_base_str, client_secret,\n                               resource_owner_secret)\n    match = safe_string_equals(signature, request.signature)\n    if not match:\n        log.debug('Verify HMAC-SHA1 failed: signature base string: %s',\n                  sig_base_str)\n    return match"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying a RSA - SHA1 signature.", "response": "def verify_rsa_sha1(request, rsa_public_key):\n    \"\"\"Verify a RSASSA-PKCS #1 v1.5 base64 encoded signature.\n\n    Per `section 3.4.3`_ of the spec.\n\n    Note this method requires the jwt and cryptography libraries.\n\n    .. _`section 3.4.3`: https://tools.ietf.org/html/rfc5849#section-3.4.3\n\n    To satisfy `RFC2616 section 5.2`_ item 1, the request argument's uri\n    attribute MUST be an absolute URI whose netloc part identifies the\n    origin server or gateway on which the resource resides. Any Host\n    item of the request argument's headers dict attribute will be\n    ignored.\n\n    .. _`RFC2616 section 5.2`: https://tools.ietf.org/html/rfc2616#section-5.2\n    \"\"\"\n    norm_params = normalize_parameters(request.params)\n    bs_uri = base_string_uri(request.uri)\n    sig_base_str = signature_base_string(request.http_method, bs_uri,\n                                         norm_params).encode('utf-8')\n    sig = binascii.a2b_base64(request.signature.encode('utf-8'))\n\n    alg = _jwt_rs1_signing_algorithm()\n    key = _prepare_key_plus(alg, rsa_public_key)\n\n    verify_ok = alg.verify(sig_base_str, key, sig)\n    if not verify_ok:\n        log.debug('Verify RSA-SHA1 failed: signature base string: %s',\n                  sig_base_str)\n    return verify_ok"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify a PLAINTEXT signature.", "response": "def verify_plaintext(request, client_secret=None, resource_owner_secret=None):\n    \"\"\"Verify a PLAINTEXT signature.\n\n    Per `section 3.4`_ of the spec.\n\n    .. _`section 3.4`: https://tools.ietf.org/html/rfc5849#section-3.4\n    \"\"\"\n    signature = sign_plaintext(client_secret, resource_owner_secret)\n    match = safe_string_equals(signature, request.signature)\n    if not match:\n        log.debug('Verify PLAINTEXT failed')\n    return match"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_verifier(self, request, credentials):\n        verifier = {\n            'oauth_token': request.resource_owner_key,\n            'oauth_verifier': self.token_generator(),\n        }\n        verifier.update(credentials)\n        self.request_validator.save_verifier(\n            request.resource_owner_key, verifier, request)\n        return verifier", "response": "Create and save a new request token."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_authorization_response(self, uri, http_method='GET', body=None,\n                                      headers=None, realms=None, credentials=None):\n        \"\"\"Create an authorization response, with a new request token if valid.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :param credentials: A list of credentials to include in the verifier.\n        :returns: A tuple of 3 elements.\n                  1. A dict of headers to set on the response.\n                  2. The response body as a string.\n                  3. The response status code as an integer.\n\n        If the callback URI tied to the current token is \"oob\", a response with\n        a 200 status code will be returned. In this case, it may be desirable to\n        modify the response to better display the verifier to the client.\n\n        An example of an authorization request::\n\n            >>> from your_validator import your_validator\n            >>> from oauthlib.oauth1 import AuthorizationEndpoint\n            >>> endpoint = AuthorizationEndpoint(your_validator)\n            >>> h, b, s = endpoint.create_authorization_response(\n            ...     'https://your.provider/authorize?oauth_token=...',\n            ...     credentials={\n            ...         'extra': 'argument',\n            ...     })\n            >>> h\n            {'Location': 'https://the.client/callback?oauth_verifier=...&extra=argument'}\n            >>> b\n            None\n            >>> s\n            302\n\n        An example of a request with an \"oob\" callback::\n\n            >>> from your_validator import your_validator\n            >>> from oauthlib.oauth1 import AuthorizationEndpoint\n            >>> endpoint = AuthorizationEndpoint(your_validator)\n            >>> h, b, s = endpoint.create_authorization_response(\n            ...     'https://your.provider/authorize?foo=bar',\n            ...     credentials={\n            ...         'extra': 'argument',\n            ...     })\n            >>> h\n            {'Content-Type': 'application/x-www-form-urlencoded'}\n            >>> b\n            'oauth_verifier=...&extra=argument'\n            >>> s\n            200\n        \"\"\"\n        request = self._create_request(uri, http_method=http_method, body=body,\n                                       headers=headers)\n\n        if not request.resource_owner_key:\n            raise errors.InvalidRequestError(\n                'Missing mandatory parameter oauth_token.')\n        if not self.request_validator.verify_request_token(\n                request.resource_owner_key, request):\n            raise errors.InvalidClientError()\n\n        request.realms = realms\n        if (request.realms and not self.request_validator.verify_realms(\n                request.resource_owner_key, request.realms, request)):\n            raise errors.InvalidRequestError(\n                description=('User granted access to realms outside of '\n                             'what the client may request.'))\n\n        verifier = self.create_verifier(request, credentials or {})\n        redirect_uri = self.request_validator.get_redirect_uri(\n            request.resource_owner_key, request)\n        if redirect_uri == 'oob':\n            response_headers = {\n                'Content-Type': 'application/x-www-form-urlencoded'}\n            response_body = urlencode(verifier)\n            return response_headers, response_body, 200\n        else:\n            populated_redirect = add_params_to_uri(\n                redirect_uri, verifier.items())\n            return {'Location': populated_redirect}, None, 302", "response": "Create an authorization response for the current token if valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_realms_and_credentials(self, uri, http_method='GET', body=None,\n                                   headers=None):\n        \"\"\"Fetch realms and credentials for the presented request token.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :returns: A tuple of 2 elements.\n                  1. A list of request realms.\n                  2. A dict of credentials which may be useful in creating the\n                  authorization form.\n        \"\"\"\n        request = self._create_request(uri, http_method=http_method, body=body,\n                                       headers=headers)\n\n        if not self.request_validator.verify_request_token(\n                request.resource_owner_key, request):\n            raise errors.InvalidClientError()\n\n        realms = self.request_validator.get_realms(\n            request.resource_owner_key, request)\n        return realms, {'resource_owner_key': request.resource_owner_key}", "response": "Fetch the realms and credentials for the presented request token."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate introspect valid or invalid response for the current state of the token.", "response": "def create_introspect_response(self, uri, http_method='POST', body=None,\n                                   headers=None):\n        \"\"\"Create introspect valid or invalid response\n\n        If the authorization server is unable to determine the state\n        of the token without additional information, it SHOULD return\n        an introspection response indicating the token is not active\n        as described in Section 2.2.\n        \"\"\"\n        resp_headers = {\n            'Content-Type': 'application/json',\n            'Cache-Control': 'no-store',\n            'Pragma': 'no-cache',\n        }\n        request = Request(uri, http_method, body, headers)\n        try:\n            self.validate_introspect_request(request)\n            log.debug('Token introspect valid for %r.', request)\n        except OAuth2Error as e:\n            log.debug('Client error during validation of %r. %r.', request, e)\n            resp_headers.update(e.headers)\n            return resp_headers, e.json, e.status_code\n\n        claims = self.request_validator.introspect_token(\n            request.token,\n            request.token_type_hint,\n            request\n        )\n        if claims is None:\n            return resp_headers, json.dumps(dict(active=False)), 200\n        if \"active\" in claims:\n            claims.pop(\"active\")\n        return resp_headers, json.dumps(dict(active=True, **claims)), 200"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures the request is valid for the protected resource introspection endpoint.", "response": "def validate_introspect_request(self, request):\n        \"\"\"Ensure the request is valid.\n\n        The protected resource calls the introspection endpoint using\n        an HTTP POST request with parameters sent as\n        \"application/x-www-form-urlencoded\".\n\n        token REQUIRED.  The string value of the token.\n\n        token_type_hint OPTIONAL.\n        A hint about the type of the token submitted for\n        introspection.  The protected resource MAY pass this parameter to\n        help the authorization server optimize the token lookup.  If the\n        server is unable to locate the token using the given hint, it MUST\n        extend its search across all of its supported token types.  An\n        authorization server MAY ignore this parameter, particularly if it\n        is able to detect the token type automatically.\n            *  access_token: An Access Token as defined in [`RFC6749`],\n                `section 1.4`_\n\n            *  refresh_token: A Refresh Token as defined in [`RFC6749`],\n                `section 1.5`_\n\n        The introspection endpoint MAY accept other OPTIONAL\n        parameters to provide further context to the query.  For\n        instance, an authorization server may desire to know the IP\n        address of the client accessing the protected resource to\n        determine if the correct client is likely to be presenting the\n        token.  The definition of this or any other parameters are\n        outside the scope of this specification, to be defined by\n        service documentation or extensions to this specification.\n\n        .. _`section 1.4`: http://tools.ietf.org/html/rfc6749#section-1.4\n        .. _`section 1.5`: http://tools.ietf.org/html/rfc6749#section-1.5\n        .. _`RFC6749`: http://tools.ietf.org/html/rfc6749\n        \"\"\"\n        self._raise_on_missing_token(request)\n        self._raise_on_invalid_client(request)\n        self._raise_on_unsupported_token(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and add a JWT assertion to the request body.", "response": "def prepare_request_body(self,\n                             private_key=None,\n                             subject=None,\n                             issuer=None,\n                             audience=None,\n                             expires_at=None,\n                             issued_at=None,\n                             extra_claims=None,\n                             body='',\n                             scope=None,\n                             include_client_id=False,\n                             **kwargs):\n        \"\"\"Create and add a JWT assertion to the request body.\n\n        :param private_key: Private key used for signing and encrypting.\n                            Must be given as a string.\n\n        :param subject: (sub) The principal that is the subject of the JWT,\n                        i.e.  which user is the token requested on behalf of.\n                        For example, ``foo@example.com.\n\n        :param issuer: (iss) The JWT MUST contain an \"iss\" (issuer) claim that\n                       contains a unique identifier for the entity that issued\n                       the JWT. For example, ``your-client@provider.com``.\n\n        :param audience: (aud) A value identifying the authorization server as an\n                         intended audience, e.g.\n                         ``https://provider.com/oauth2/token``.\n\n        :param expires_at: A unix expiration timestamp for the JWT. Defaults\n                           to an hour from now, i.e. ``time.time() + 3600``.\n\n        :param issued_at: A unix timestamp of when the JWT was created.\n                          Defaults to now, i.e. ``time.time()``.\n\n        :param extra_claims: A dict of additional claims to include in the JWT.\n\n        :param body: Existing request body (URL encoded string) to embed parameters\n                     into. This may contain extra paramters. Default ''.\n\n        :param scope: The scope of the access request.\n\n        :param include_client_id: `True` to send the `client_id` in the\n                                  body of the upstream request. This is required\n                                  if the client is not authenticating with the\n                                  authorization server as described in\n                                  `Section 3.2.1`_. False otherwise (default).\n        :type include_client_id: Boolean\n\n        :param not_before: A unix timestamp after which the JWT may be used.\n                           Not included unless provided. *\n\n        :param jwt_id: A unique JWT token identifier. Not included unless\n                       provided. *\n\n        :param kwargs: Extra credentials to include in the token request.\n\n        Parameters marked with a `*` above are not explicit arguments in the\n        function signature, but are specially documented arguments for items\n        appearing in the generic `**kwargs` keyworded input.\n\n        The \"scope\" parameter may be used, as defined in the Assertion\n        Framework for OAuth 2.0 Client Authentication and Authorization Grants\n        [I-D.ietf-oauth-assertions] specification, to indicate the requested\n        scope.\n\n        Authentication of the client is optional, as described in\n        `Section 3.2.1`_ of OAuth 2.0 [RFC6749] and consequently, the\n        \"client_id\" is only needed when a form of client authentication that\n        relies on the parameter is used.\n\n        The following non-normative example demonstrates an Access Token\n        Request with a JWT as an authorization grant (with extra line breaks\n        for display purposes only):\n\n        .. code-block: http\n\n            POST /token.oauth2 HTTP/1.1\n            Host: as.example.com\n            Content-Type: application/x-www-form-urlencoded\n\n            grant_type=urn%3Aietf%3Aparams%3Aoauth%3Agrant-type%3Ajwt-bearer\n            &assertion=eyJhbGciOiJFUzI1NiJ9.\n            eyJpc3Mi[...omitted for brevity...].\n            J9l-ZhwP[...omitted for brevity...]\n\n        .. _`Section 3.2.1`: https://tools.ietf.org/html/rfc6749#section-3.2.1\n        \"\"\"\n        import jwt\n\n        key = private_key or self.private_key\n        if not key:\n            raise ValueError('An encryption key must be supplied to make JWT'\n                             ' token requests.')\n        claim = {\n            'iss': issuer or self.issuer,\n            'aud': audience or self.audience,\n            'sub': subject or self.subject,\n            'exp': int(expires_at or time.time() + 3600),\n            'iat': int(issued_at or time.time()),\n        }\n\n        for attr in ('iss', 'aud', 'sub'):\n            if claim[attr] is None:\n                raise ValueError(\n                        'Claim must include %s but none was given.' % attr)\n\n        if 'not_before' in kwargs:\n            claim['nbf'] = kwargs.pop('not_before')\n\n        if 'jwt_id' in kwargs:\n            claim['jti'] = kwargs.pop('jwt_id')\n\n        claim.update(extra_claims or {})\n\n        assertion = jwt.encode(claim, key, 'RS256')\n        assertion = to_unicode(assertion)\n\n        kwargs['client_id'] = self.client_id\n        kwargs['include_client_id'] = include_client_id\n        return prepare_token_request(self.grant_type,\n                                     body=body,\n                                     assertion=assertion,\n                                     scope=scope,\n                                     **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting grant type and route to the designated handler.", "response": "def create_token_response(self, uri, http_method='GET', body=None,\n                              headers=None, credentials=None, grant_type_for_scope=None,\n                              claims=None):\n        \"\"\"Extract grant_type and route to the designated handler.\"\"\"\n        request = Request(\n            uri, http_method=http_method, body=body, headers=headers)\n\n        # 'scope' is an allowed Token Request param in both the \"Resource Owner Password Credentials Grant\"\n        # and \"Client Credentials Grant\" flows\n        # https://tools.ietf.org/html/rfc6749#section-4.3.2\n        # https://tools.ietf.org/html/rfc6749#section-4.4.2\n        request.scopes = utils.scope_to_list(request.scope)\n\n        request.extra_credentials = credentials\n        if grant_type_for_scope:\n            request.grant_type = grant_type_for_scope\n\n        # OpenID Connect claims, if provided.  The server using oauthlib might choose\n        # to implement the claims parameter of the Authorization Request.  In this case\n        # it should retrieve those claims and pass them via the claims argument here,\n        # as a dict.\n        if claims:\n            request.claims = claims\n\n        grant_type_handler = self.grant_types.get(request.grant_type,\n                                                  self.default_grant_type_handler)\n        log.debug('Dispatching grant_type %s request to %r.',\n                  request.grant_type, grant_type_handler)\n        return grant_type_handler.create_token_response(\n            request, self.default_token_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef code_challenge_method_s256(verifier, challenge):\n    return base64.urlsafe_b64encode(\n        hashlib.sha256(verifier.encode()).digest()\n    ).decode().rstrip('=') == challenge", "response": "Return the code_challenge_method for the given code_verifier and challenge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_authorization_code(self, request):\n        grant = {'code': common.generate_token()}\n        if hasattr(request, 'state') and request.state:\n            grant['state'] = request.state\n        log.debug('Created authorization code grant %r for request %r.',\n                  grant, request)\n        return grant", "response": "Generates an authorization code grant represented as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a response for the authorization flow of the client.", "response": "def create_authorization_response(self, request, token_handler):\n        \"\"\"\n        The client constructs the request URI by adding the following\n        parameters to the query component of the authorization endpoint URI\n        using the \"application/x-www-form-urlencoded\" format, per `Appendix B`_:\n\n        response_type\n                REQUIRED.  Value MUST be set to \"code\" for standard OAuth2\n                authorization flow.  For OpenID Connect it must be one of\n                \"code token\", \"code id_token\", or \"code token id_token\" - we\n                essentially test that \"code\" appears in the response_type.\n        client_id\n                REQUIRED.  The client identifier as described in `Section 2.2`_.\n        redirect_uri\n                OPTIONAL.  As described in `Section 3.1.2`_.\n        scope\n                OPTIONAL.  The scope of the access request as described by\n                `Section 3.3`_.\n        state\n                RECOMMENDED.  An opaque value used by the client to maintain\n                state between the request and callback.  The authorization\n                server includes this value when redirecting the user-agent back\n                to the client.  The parameter SHOULD be used for preventing\n                cross-site request forgery as described in `Section 10.12`_.\n\n        The client directs the resource owner to the constructed URI using an\n        HTTP redirection response, or by other means available to it via the\n        user-agent.\n\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        :param token_handler: A token handler instance, for example of type\n                              oauthlib.oauth2.BearerToken.\n        :returns: headers, body, status\n        :raises: FatalClientError on invalid redirect URI or client id.\n\n        A few examples::\n\n            >>> from your_validator import your_validator\n            >>> request = Request('https://example.com/authorize?client_id=valid'\n            ...                   '&redirect_uri=http%3A%2F%2Fclient.com%2F')\n            >>> from oauthlib.common import Request\n            >>> from oauthlib.oauth2 import AuthorizationCodeGrant, BearerToken\n            >>> token = BearerToken(your_validator)\n            >>> grant = AuthorizationCodeGrant(your_validator)\n            >>> request.scopes = ['authorized', 'in', 'some', 'form']\n            >>> grant.create_authorization_response(request, token)\n            (u'http://client.com/?error=invalid_request&error_description=Missing+response_type+parameter.', None, None, 400)\n            >>> request = Request('https://example.com/authorize?client_id=valid'\n            ...                   '&redirect_uri=http%3A%2F%2Fclient.com%2F'\n            ...                   '&response_type=code')\n            >>> request.scopes = ['authorized', 'in', 'some', 'form']\n            >>> grant.create_authorization_response(request, token)\n            (u'http://client.com/?code=u3F05aEObJuP2k7DordviIgW5wl52N', None, None, 200)\n            >>> # If the client id or redirect uri fails validation\n            >>> grant.create_authorization_response(request, token)\n            Traceback (most recent call last):\n                File \"<stdin>\", line 1, in <module>\n                File \"oauthlib/oauth2/rfc6749/grant_types.py\", line 515, in create_authorization_response\n                    >>> grant.create_authorization_response(request, token)\n                File \"oauthlib/oauth2/rfc6749/grant_types.py\", line 591, in validate_authorization_request\n            oauthlib.oauth2.rfc6749.errors.InvalidClientIdError\n\n        .. _`Appendix B`: https://tools.ietf.org/html/rfc6749#appendix-B\n        .. _`Section 2.2`: https://tools.ietf.org/html/rfc6749#section-2.2\n        .. _`Section 3.1.2`: https://tools.ietf.org/html/rfc6749#section-3.1.2\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        .. _`Section 10.12`: https://tools.ietf.org/html/rfc6749#section-10.12\n        \"\"\"\n        try:\n            self.validate_authorization_request(request)\n            log.debug('Pre resource owner authorization validation ok for %r.',\n                      request)\n\n        # If the request fails due to a missing, invalid, or mismatching\n        # redirection URI, or if the client identifier is missing or invalid,\n        # the authorization server SHOULD inform the resource owner of the\n        # error and MUST NOT automatically redirect the user-agent to the\n        # invalid redirection URI.\n        except errors.FatalClientError as e:\n            log.debug('Fatal client error during validation of %r. %r.',\n                      request, e)\n            raise\n\n        # If the resource owner denies the access request or if the request\n        # fails for reasons other than a missing or invalid redirection URI,\n        # the authorization server informs the client by adding the following\n        # parameters to the query component of the redirection URI using the\n        # \"application/x-www-form-urlencoded\" format, per Appendix B:\n        # https://tools.ietf.org/html/rfc6749#appendix-B\n        except errors.OAuth2Error as e:\n            log.debug('Client error during validation of %r. %r.', request, e)\n            request.redirect_uri = request.redirect_uri or self.error_uri\n            redirect_uri = common.add_params_to_uri(\n                request.redirect_uri, e.twotuples,\n                fragment=request.response_mode == \"fragment\")\n            return {'Location': redirect_uri}, None, 302\n\n        grant = self.create_authorization_code(request)\n        for modifier in self._code_modifiers:\n            grant = modifier(grant, token_handler, request)\n        log.debug('Saving grant %r for %r.', grant, request)\n        self.request_validator.save_authorization_code(\n            request.client_id, grant, request)\n        return self.prepare_authorization_response(\n            request, grant, {}, None, 302)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_token_response(self, request, token_handler):\n        headers = self._get_default_headers()\n        try:\n            self.validate_token_request(request)\n            log.debug('Token request validation ok for %r.', request)\n        except errors.OAuth2Error as e:\n            log.debug('Client error during validation of %r. %r.', request, e)\n            headers.update(e.headers)\n            return headers, e.json, e.status_code\n\n        token = token_handler.create_token(request, refresh_token=self.refresh_token)\n\n        for modifier in self._token_modifiers:\n            token = modifier(token, token_handler, request)\n\n        self.request_validator.save_token(token, request)\n        self.request_validator.invalidate_authorization_code(\n            request.client_id, request.code, request)\n        return headers, json.dumps(token), 200", "response": "Validate the authorization code and create a token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the request for fatal errors and return a dict of the client - identifier and the client - id that the client has requested access.", "response": "def validate_authorization_request(self, request):\n        \"\"\"Check the authorization request for normal and fatal errors.\n\n        A normal error could be a missing response_type parameter or the client\n        attempting to access scope it is not allowed to ask authorization for.\n        Normal errors can safely be included in the redirection URI and\n        sent back to the client.\n\n        Fatal errors occur when the client_id or redirect_uri is invalid or\n        missing. These must be caught by the provider and handled, how this\n        is done is outside of the scope of OAuthLib but showing an error\n        page describing the issue is a good idea.\n\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        \"\"\"\n\n        # First check for fatal errors\n\n        # If the request fails due to a missing, invalid, or mismatching\n        # redirection URI, or if the client identifier is missing or invalid,\n        # the authorization server SHOULD inform the resource owner of the\n        # error and MUST NOT automatically redirect the user-agent to the\n        # invalid redirection URI.\n\n        # First check duplicate parameters\n        for param in ('client_id', 'response_type', 'redirect_uri', 'scope', 'state'):\n            try:\n                duplicate_params = request.duplicate_params\n            except ValueError:\n                raise errors.InvalidRequestFatalError(description='Unable to parse query string', request=request)\n            if param in duplicate_params:\n                raise errors.InvalidRequestFatalError(description='Duplicate %s parameter.' % param, request=request)\n\n        # REQUIRED. The client identifier as described in Section 2.2.\n        # https://tools.ietf.org/html/rfc6749#section-2.2\n        if not request.client_id:\n            raise errors.MissingClientIdError(request=request)\n\n        if not self.request_validator.validate_client_id(request.client_id, request):\n            raise errors.InvalidClientIdError(request=request)\n\n        # OPTIONAL. As described in Section 3.1.2.\n        # https://tools.ietf.org/html/rfc6749#section-3.1.2\n        log.debug('Validating redirection uri %s for client %s.',\n                  request.redirect_uri, request.client_id)\n\n        # OPTIONAL. As described in Section 3.1.2.\n        # https://tools.ietf.org/html/rfc6749#section-3.1.2\n        self._handle_redirects(request)\n\n        # Then check for normal errors.\n\n        # If the resource owner denies the access request or if the request\n        # fails for reasons other than a missing or invalid redirection URI,\n        # the authorization server informs the client by adding the following\n        # parameters to the query component of the redirection URI using the\n        # \"application/x-www-form-urlencoded\" format, per Appendix B.\n        # https://tools.ietf.org/html/rfc6749#appendix-B\n\n        # Note that the correct parameters to be added are automatically\n        # populated through the use of specific exceptions.\n\n        request_info = {}\n        for validator in self.custom_validators.pre_auth:\n            request_info.update(validator(request))\n\n        # REQUIRED.\n        if request.response_type is None:\n            raise errors.MissingResponseTypeError(request=request)\n        # Value MUST be set to \"code\" or one of the OpenID authorization code including\n        # response_types \"code token\", \"code id_token\", \"code token id_token\"\n        elif not 'code' in request.response_type and request.response_type != 'none':\n            raise errors.UnsupportedResponseTypeError(request=request)\n\n        if not self.request_validator.validate_response_type(request.client_id,\n                                                             request.response_type,\n                                                             request.client, request):\n\n            log.debug('Client %s is not authorized to use response_type %s.',\n                      request.client_id, request.response_type)\n            raise errors.UnauthorizedClientError(request=request)\n\n        # OPTIONAL. Validate PKCE request or reply with \"error\"/\"invalid_request\"\n        # https://tools.ietf.org/html/rfc6749#section-4.4.1\n        if self.request_validator.is_pkce_required(request.client_id, request) is True:\n            if request.code_challenge is None:\n                raise errors.MissingCodeChallengeError(request=request)\n\n        if request.code_challenge is not None:\n            # OPTIONAL, defaults to \"plain\" if not present in the request.\n            if request.code_challenge_method is None:\n                request.code_challenge_method = \"plain\"\n\n            if request.code_challenge_method not in self._code_challenge_methods:\n                raise errors.UnsupportedCodeChallengeMethodError(request=request)\n\n        # OPTIONAL. The scope of the access request as described by Section 3.3\n        # https://tools.ietf.org/html/rfc6749#section-3.3\n        self.validate_scopes(request)\n\n        request_info.update({\n            'client_id': request.client_id,\n            'redirect_uri': request.redirect_uri,\n            'response_type': request.response_type,\n            'state': request.state,\n            'request': request\n        })\n\n        for validator in self.custom_validators.post_auth:\n            request_info.update(validator(request))\n\n        return request.scopes, request_info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the token endpoint is used in the grant type and the grant type is valid.", "response": "def validate_metadata_token(self, claims, endpoint):\n        \"\"\"\n        If the token endpoint is used in the grant type, the value of this\n        parameter MUST be the same as the value of the \"grant_type\"\n        parameter passed to the token endpoint defined in the grant type\n        definition.\n        \"\"\"\n        self._grant_types.extend(endpoint._grant_types.keys())\n        claims.setdefault(\"token_endpoint_auth_methods_supported\", [\"client_secret_post\", \"client_secret_basic\"])\n\n        self.validate_metadata(claims, \"token_endpoint_auth_methods_supported\", is_list=True)\n        self.validate_metadata(claims, \"token_endpoint_auth_signing_alg_values_supported\", is_list=True)\n        self.validate_metadata(claims, \"token_endpoint\", is_required=True, is_url=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_metadata_server(self):\n        claims = copy.deepcopy(self.initial_claims)\n        self.validate_metadata(claims, \"issuer\", is_required=True, is_issuer=True)\n        self.validate_metadata(claims, \"jwks_uri\", is_url=True)\n        self.validate_metadata(claims, \"scopes_supported\", is_list=True)\n        self.validate_metadata(claims, \"service_documentation\", is_url=True)\n        self.validate_metadata(claims, \"ui_locales_supported\", is_list=True)\n        self.validate_metadata(claims, \"op_policy_uri\", is_url=True)\n        self.validate_metadata(claims, \"op_tos_uri\", is_url=True)\n\n        self._grant_types = []\n        for endpoint in self.endpoints:\n            if isinstance(endpoint, TokenEndpoint):\n                self.validate_metadata_token(claims, endpoint)\n            if isinstance(endpoint, AuthorizationEndpoint):\n                self.validate_metadata_authorization(claims, endpoint)\n            if isinstance(endpoint, RevocationEndpoint):\n                self.validate_metadata_revocation(claims, endpoint)\n            if isinstance(endpoint, IntrospectEndpoint):\n                self.validate_metadata_introspection(claims, endpoint)\n\n        # \"grant_types_supported\" is a combination of all OAuth2 grant types\n        # allowed in the current provider implementation.\n        claims.setdefault(\"grant_types_supported\", self._grant_types)\n        self.validate_metadata(claims, \"grant_types_supported\", is_list=True)\n        return claims", "response": "Validates that the authorization server configuration is well - formed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the request for a token request.", "response": "def validate_token_request(self, request):\n        \"\"\"\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        \"\"\"\n        # REQUIRED. Value MUST be set to \"refresh_token\".\n        if request.grant_type != 'refresh_token':\n            raise errors.UnsupportedGrantTypeError(request=request)\n\n        for validator in self.custom_validators.pre_token:\n            validator(request)\n\n        if request.refresh_token is None:\n            raise errors.InvalidRequestError(\n                description='Missing refresh token parameter.',\n                request=request)\n\n        # Because refresh tokens are typically long-lasting credentials used to\n        # request additional access tokens, the refresh token is bound to the\n        # client to which it was issued.  If the client type is confidential or\n        # the client was issued client credentials (or assigned other\n        # authentication requirements), the client MUST authenticate with the\n        # authorization server as described in Section 3.2.1.\n        # https://tools.ietf.org/html/rfc6749#section-3.2.1\n        if self.request_validator.client_authentication_required(request):\n            log.debug('Authenticating client, %r.', request)\n            if not self.request_validator.authenticate_client(request):\n                log.debug('Invalid client (%r), denying access.', request)\n                raise errors.InvalidClientError(request=request)\n        elif not self.request_validator.authenticate_client_id(request.client_id, request):\n            log.debug('Client authentication failed, %r.', request)\n            raise errors.InvalidClientError(request=request)\n\n        # Ensure client is authorized use of this grant type\n        self.validate_grant_type(request)\n\n        # REQUIRED. The refresh token issued to the client.\n        log.debug('Validating refresh token %s for client %r.',\n                  request.refresh_token, request.client)\n        if not self.request_validator.validate_refresh_token(\n                request.refresh_token, request.client, request):\n            log.debug('Invalid refresh token, %s, for client %r.',\n                      request.refresh_token, request.client)\n            raise errors.InvalidGrantError(request=request)\n\n        original_scopes = utils.scope_to_list(\n            self.request_validator.get_original_scopes(\n                request.refresh_token, request))\n\n        if request.scope:\n            request.scopes = utils.scope_to_list(request.scope)\n            if (not all((s in original_scopes for s in request.scopes))\n                and not self.request_validator.is_within_original_scope(\n                    request.scopes, request.refresh_token, request)):\n                log.debug('Refresh token %s lack requested scopes, %r.',\n                          request.refresh_token, request.scopes)\n                raise errors.InvalidScopeError(request=request)\n        else:\n            request.scopes = original_scopes\n\n        for validator in self.custom_validators.post_token:\n            validator(request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_request_body(self, code=None, redirect_uri=None, body='',\n                             include_client_id=True, **kwargs):\n        \"\"\"Prepare the access token request body.\n\n        The client makes a request to the token endpoint by adding the\n        following parameters using the \"application/x-www-form-urlencoded\"\n        format in the HTTP request entity-body:\n\n        :param code:    REQUIRED. The authorization code received from the\n                        authorization server.\n\n        :param redirect_uri:    REQUIRED, if the \"redirect_uri\" parameter was included in the\n                                authorization request as described in `Section 4.1.1`_, and their\n                                values MUST be identical.\n\n        :param body: Existing request body (URL encoded string) to embed parameters\n                     into. This may contain extra paramters. Default ''.\n\n        :param include_client_id: `True` (default) to send the `client_id` in the\n                                  body of the upstream request. This is required\n                                  if the client is not authenticating with the\n                                  authorization server as described in `Section 3.2.1`_.\n        :type include_client_id: Boolean\n\n        :param kwargs: Extra parameters to include in the token request.\n\n        In addition OAuthLib will add the ``grant_type`` parameter set to\n        ``authorization_code``.\n\n        If the client type is confidential or the client was issued client\n        credentials (or assigned other authentication requirements), the\n        client MUST authenticate with the authorization server as described\n        in `Section 3.2.1`_::\n\n            >>> from oauthlib.oauth2 import WebApplicationClient\n            >>> client = WebApplicationClient('your_id')\n            >>> client.prepare_request_body(code='sh35ksdf09sf')\n            'grant_type=authorization_code&code=sh35ksdf09sf'\n            >>> client.prepare_request_body(code='sh35ksdf09sf', foo='bar')\n            'grant_type=authorization_code&code=sh35ksdf09sf&foo=bar'\n\n        `Section 3.2.1` also states:\n            In the \"authorization_code\" \"grant_type\" request to the token\n            endpoint, an unauthenticated client MUST send its \"client_id\" to\n            prevent itself from inadvertently accepting a code intended for a\n            client with a different \"client_id\".  This protects the client from\n            substitution of the authentication code.  (It provides no additional\n            security for the protected resource.)\n\n        .. _`Section 4.1.1`: https://tools.ietf.org/html/rfc6749#section-4.1.1\n        .. _`Section 3.2.1`: https://tools.ietf.org/html/rfc6749#section-3.2.1\n        \"\"\"\n        code = code or self.code\n        if 'client_id' in kwargs:\n            warnings.warn(\"`client_id` has been deprecated in favor of \"\n                          \"`include_client_id`, a boolean value which will \"\n                          \"include the already configured `self.client_id`.\",\n                          DeprecationWarning)\n            if kwargs['client_id'] != self.client_id:\n                raise ValueError(\"`client_id` was supplied as an argument, but \"\n                                 \"it does not match `self.client_id`\")\n\n        kwargs['client_id'] = self.client_id\n        kwargs['include_client_id'] = include_client_id\n        return prepare_token_request(self.grant_type, code=code, body=body,\n                                     redirect_uri=redirect_uri, **kwargs)", "response": "Prepares the request body for the access token request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the URI query for code and state.", "response": "def parse_request_uri_response(self, uri, state=None):\n        \"\"\"Parse the URI query for code and state.\n\n        If the resource owner grants the access request, the authorization\n        server issues an authorization code and delivers it to the client by\n        adding the following parameters to the query component of the\n        redirection URI using the \"application/x-www-form-urlencoded\" format:\n\n        :param uri: The callback URI that resulted from the user being redirected\n                    back from the provider to you, the client.\n        :param state: The state provided in the authorization request.\n\n        **code**\n            The authorization code generated by the authorization server.\n            The authorization code MUST expire shortly after it is issued\n            to mitigate the risk of leaks. A maximum authorization code\n            lifetime of 10 minutes is RECOMMENDED. The client MUST NOT\n            use the authorization code more than once. If an authorization\n            code is used more than once, the authorization server MUST deny\n            the request and SHOULD revoke (when possible) all tokens\n            previously issued based on that authorization code.\n            The authorization code is bound to the client identifier and\n            redirection URI.\n\n        **state**\n                If the \"state\" parameter was present in the authorization request.\n\n        This method is mainly intended to enforce strict state checking with\n        the added benefit of easily extracting parameters from the URI::\n\n            >>> from oauthlib.oauth2 import WebApplicationClient\n            >>> client = WebApplicationClient('your_id')\n            >>> uri = 'https://example.com/callback?code=sdfkjh345&state=sfetw45'\n            >>> client.parse_request_uri_response(uri, state='sfetw45')\n            {'state': 'sfetw45', 'code': 'sdfkjh345'}\n            >>> client.parse_request_uri_response(uri, state='other')\n            Traceback (most recent call last):\n                File \"<stdin>\", line 1, in <module>\n                File \"oauthlib/oauth2/rfc6749/__init__.py\", line 357, in parse_request_uri_response\n                    back from the provider to you, the client.\n                File \"oauthlib/oauth2/rfc6749/parameters.py\", line 153, in parse_authorization_code_response\n                    raise MismatchingStateError()\n            oauthlib.oauth2.rfc6749.errors.MismatchingStateError\n        \"\"\"\n        response = parse_authorization_code_response(uri, state=state)\n        self.populate_code_attributes(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_token(self, uri, http_method='GET', body=None, headers=None,\n                  token_placement=None, **kwargs):\n        \"\"\"Add token to the request uri, body or authorization header.\n\n        The access token type provides the client with the information\n        required to successfully utilize the access token to make a protected\n        resource request (along with type-specific attributes).  The client\n        MUST NOT use an access token if it does not understand the token\n        type.\n\n        For example, the \"bearer\" token type defined in\n        [`I-D.ietf-oauth-v2-bearer`_] is utilized by simply including the access\n        token string in the request:\n\n        .. code-block:: http\n\n            GET /resource/1 HTTP/1.1\n            Host: example.com\n            Authorization: Bearer mF_9.B5f-4.1JqM\n\n        while the \"mac\" token type defined in [`I-D.ietf-oauth-v2-http-mac`_] is\n        utilized by issuing a MAC key together with the access token which is\n        used to sign certain components of the HTTP requests:\n\n        .. code-block:: http\n\n            GET /resource/1 HTTP/1.1\n            Host: example.com\n            Authorization: MAC id=\"h480djs93hd8\",\n                                nonce=\"274312:dj83hs9s\",\n                                mac=\"kDZvddkndxvhGRXZhvuDjEWhGeE=\"\n\n        .. _`I-D.ietf-oauth-v2-bearer`: https://tools.ietf.org/html/rfc6749#section-12.2\n        .. _`I-D.ietf-oauth-v2-http-mac`: https://tools.ietf.org/html/rfc6749#section-12.2\n        \"\"\"\n        if not is_secure_transport(uri):\n            raise InsecureTransportError()\n\n        token_placement = token_placement or self.default_token_placement\n\n        case_insensitive_token_types = dict(\n            (k.lower(), v) for k, v in self.token_types.items())\n        if not self.token_type.lower() in case_insensitive_token_types:\n            raise ValueError(\"Unsupported token type: %s\" % self.token_type)\n\n        if not (self.access_token or self.token.get('access_token')):\n            raise ValueError(\"Missing access token.\")\n\n        if self._expires_at and self._expires_at < time.time():\n            raise TokenExpiredError()\n\n        return case_insensitive_token_types[self.token_type.lower()](uri, http_method, body,\n                                                                     headers, token_placement, **kwargs)", "response": "Add a token to the request uri body or authorization header."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the authorization request.", "response": "def prepare_authorization_request(self, authorization_url, state=None,\n                                      redirect_url=None, scope=None, **kwargs):\n        \"\"\"Prepare the authorization request.\n\n        This is the first step in many OAuth flows in which the user is\n        redirected to a certain authorization URL. This method adds\n        required parameters to the authorization URL.\n\n        :param authorization_url: Provider authorization endpoint URL.\n\n        :param state: CSRF protection string. Will be automatically created if\n        not provided. The generated state is available via the ``state``\n        attribute. Clients should verify that the state is unchanged and\n        present in the authorization response. This verification is done\n        automatically if using the ``authorization_response`` parameter\n        with ``prepare_token_request``.\n\n        :param redirect_url: Redirect URL to which the user will be returned\n        after authorization. Must be provided unless previously setup with\n        the provider. If provided then it must also be provided in the\n        token request.\n\n        :param scope:\n\n        :param kwargs: Additional parameters to included in the request.\n\n        :returns: The prepared request tuple with (url, headers, body).\n        \"\"\"\n        if not is_secure_transport(authorization_url):\n            raise InsecureTransportError()\n\n        self.state = state or self.state_generator()\n        self.redirect_url = redirect_url or self.redirect_url\n        self.scope = scope or self.scope\n        auth_url = self.prepare_request_uri(\n            authorization_url, redirect_uri=self.redirect_url,\n            scope=self.scope, state=self.state, **kwargs)\n        return auth_url, FORM_ENC_HEADERS, ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_token_request(self, token_url, authorization_response=None,\n                              redirect_url=None, state=None, body='', **kwargs):\n        \"\"\"Prepare a token creation request.\n\n        Note that these requests usually require client authentication, either\n        by including client_id or a set of provider specific authentication\n        credentials.\n\n        :param token_url: Provider token creation endpoint URL.\n\n        :param authorization_response: The full redirection URL string, i.e.\n        the location to which the user was redirected after successfull\n        authorization. Used to mine credentials needed to obtain a token\n        in this step, such as authorization code.\n\n        :param redirect_url: The redirect_url supplied with the authorization\n        request (if there was one).\n\n        :param state:\n\n        :param body: Existing request body (URL encoded string) to embed parameters\n                     into. This may contain extra paramters. Default ''.\n\n        :param kwargs: Additional parameters to included in the request.\n\n        :returns: The prepared request tuple with (url, headers, body).\n        \"\"\"\n        if not is_secure_transport(token_url):\n            raise InsecureTransportError()\n\n        state = state or self.state\n        if authorization_response:\n            self.parse_request_uri_response(\n                authorization_response, state=state)\n        self.redirect_url = redirect_url or self.redirect_url\n        body = self.prepare_request_body(body=body,\n                                         redirect_uri=self.redirect_url, **kwargs)\n\n        return token_url, FORM_ENC_HEADERS, body", "response": "Prepare a token creation request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing an access token refresh request.", "response": "def prepare_refresh_token_request(self, token_url, refresh_token=None,\n                                      body='', scope=None, **kwargs):\n        \"\"\"Prepare an access token refresh request.\n\n        Expired access tokens can be replaced by new access tokens without\n        going through the OAuth dance if the client obtained a refresh token.\n        This refresh token and authentication credentials can be used to\n        obtain a new access token, and possibly a new refresh token.\n\n        :param token_url: Provider token refresh endpoint URL.\n\n        :param refresh_token: Refresh token string.\n\n        :param body: Existing request body (URL encoded string) to embed parameters\n                     into. This may contain extra paramters. Default ''.\n\n        :param scope: List of scopes to request. Must be equal to\n        or a subset of the scopes granted when obtaining the refresh\n        token.\n\n        :param kwargs: Additional parameters to included in the request.\n\n        :returns: The prepared request tuple with (url, headers, body).\n        \"\"\"\n        if not is_secure_transport(token_url):\n            raise InsecureTransportError()\n\n        self.scope = scope or self.scope\n        body = self.prepare_refresh_body(body=body,\n                                         refresh_token=refresh_token, scope=self.scope, **kwargs)\n        return token_url, FORM_ENC_HEADERS, body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing a token revocation request.", "response": "def prepare_token_revocation_request(self, revocation_url, token,\n                                         token_type_hint=\"access_token\", body='', callback=None, **kwargs):\n        \"\"\"Prepare a token revocation request.\n\n        :param revocation_url: Provider token revocation endpoint URL.\n\n        :param token: The access or refresh token to be revoked (string).\n\n        :param token_type_hint: ``\"access_token\"`` (default) or\n        ``\"refresh_token\"``. This is optional and if you wish to not pass it you\n        must provide ``token_type_hint=None``.\n\n        :param body:\n\n        :param callback: A jsonp callback such as ``package.callback`` to be invoked\n        upon receiving the response. Not that it should not include a () suffix.\n\n        :param kwargs: Additional parameters to included in the request.\n\n        :returns: The prepared request tuple with (url, headers, body).\n\n        Note that JSONP request may use GET requests as the parameters will\n        be added to the request URL query as opposed to the request body.\n\n        An example of a revocation request\n\n        .. code-block: http\n\n            POST /revoke HTTP/1.1\n            Host: server.example.com\n            Content-Type: application/x-www-form-urlencoded\n            Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\n\n            token=45ghiukldjahdnhzdauz&token_type_hint=refresh_token\n\n        An example of a jsonp revocation request\n\n        .. code-block: http\n\n            GET /revoke?token=agabcdefddddafdd&callback=package.myCallback HTTP/1.1\n            Host: server.example.com\n            Content-Type: application/x-www-form-urlencoded\n            Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\n\n        and an error response\n\n        .. code-block: http\n\n        package.myCallback({\"error\":\"unsupported_token_type\"});\n\n        Note that these requests usually require client credentials, client_id in\n        the case for public clients and provider specific authentication\n        credentials for confidential clients.\n        \"\"\"\n        if not is_secure_transport(revocation_url):\n            raise InsecureTransportError()\n\n        return prepare_token_revocation_request(revocation_url, token,\n                                                token_type_hint=token_type_hint, body=body, callback=callback,\n                                                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_request_body_response(self, body, scope=None, **kwargs):\n        self.token = parse_token_response(body, scope=scope)\n        self.populate_token_attributes(self.token)\n        return self.token", "response": "Parse the response body from the OAuth2 server and return a dictionary of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares an access token request using a refresh token.", "response": "def prepare_refresh_body(self, body='', refresh_token=None, scope=None, **kwargs):\n        \"\"\"Prepare an access token request, using a refresh token.\n\n        If the authorization server issued a refresh token to the client, the\n        client makes a refresh request to the token endpoint by adding the\n        following parameters using the \"application/x-www-form-urlencoded\"\n        format in the HTTP request entity-body:\n\n        grant_type\n                REQUIRED.  Value MUST be set to \"refresh_token\".\n        refresh_token\n                REQUIRED.  The refresh token issued to the client.\n        scope\n                OPTIONAL.  The scope of the access request as described by\n                Section 3.3.  The requested scope MUST NOT include any scope\n                not originally granted by the resource owner, and if omitted is\n                treated as equal to the scope originally granted by the\n                resource owner.\n        \"\"\"\n        refresh_token = refresh_token or self.refresh_token\n        return prepare_token_request(self.refresh_token_key, body=body, scope=scope,\n                                     refresh_token=refresh_token, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a bearer token to the request uri headers and body.", "response": "def _add_bearer_token(self, uri, http_method='GET', body=None,\n                          headers=None, token_placement=None):\n        \"\"\"Add a bearer token to the request uri, body or authorization header.\"\"\"\n        if token_placement == AUTH_HEADER:\n            headers = tokens.prepare_bearer_headers(self.access_token, headers)\n\n        elif token_placement == URI_QUERY:\n            uri = tokens.prepare_bearer_uri(self.access_token, uri)\n\n        elif token_placement == BODY:\n            body = tokens.prepare_bearer_body(self.access_token, body)\n\n        else:\n            raise ValueError(\"Invalid token placement.\")\n        return uri, headers, body"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_mac_token(self, uri, http_method='GET', body=None,\n                       headers=None, token_placement=AUTH_HEADER, ext=None, **kwargs):\n        \"\"\"Add a MAC token to the request authorization header.\n\n        Warning: MAC token support is experimental as the spec is not yet stable.\n        \"\"\"\n        if token_placement != AUTH_HEADER:\n            raise ValueError(\"Invalid token placement.\")\n\n        headers = tokens.prepare_mac_header(self.access_token, uri,\n                                            self.mac_key, http_method, headers=headers, body=body, ext=ext,\n                                            hash_algorithm=self.mac_algorithm, **kwargs)\n        return uri, headers, body", "response": "Add a MAC token to the request authorization header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating the attributes of the object from a token exchange response.", "response": "def populate_token_attributes(self, response):\n        \"\"\"Add attributes from a token exchange response to self.\"\"\"\n\n        if 'access_token' in response:\n            self.access_token = response.get('access_token')\n\n        if 'refresh_token' in response:\n            self.refresh_token = response.get('refresh_token')\n\n        if 'token_type' in response:\n            self.token_type = response.get('token_type')\n\n        if 'expires_in' in response:\n            self.expires_in = response.get('expires_in')\n            self._expires_at = time.time() + int(self.expires_in)\n\n        if 'expires_at' in response:\n            self._expires_at = int(response.get('expires_at'))\n\n        if 'mac_key' in response:\n            self.mac_key = response.get('mac_key')\n\n        if 'mac_algorithm' in response:\n            self.mac_algorithm = response.get('mac_algorithm')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_signature_type_and_params(self, request):\n        # Per RFC5849, only the Authorization header may contain the 'realm'\n        # optional parameter.\n        header_params = signature.collect_parameters(headers=request.headers,\n                                                     exclude_oauth_signature=False, with_realm=True)\n        body_params = signature.collect_parameters(body=request.body,\n                                                   exclude_oauth_signature=False)\n        query_params = signature.collect_parameters(uri_query=request.uri_query,\n                                                    exclude_oauth_signature=False)\n\n        params = []\n        params.extend(header_params)\n        params.extend(body_params)\n        params.extend(query_params)\n        signature_types_with_oauth_params = list(filter(lambda s: s[2], (\n            (SIGNATURE_TYPE_AUTH_HEADER, params,\n                utils.filter_oauth_params(header_params)),\n            (SIGNATURE_TYPE_BODY, params,\n                utils.filter_oauth_params(body_params)),\n            (SIGNATURE_TYPE_QUERY, params,\n                utils.filter_oauth_params(query_params))\n        )))\n\n        if len(signature_types_with_oauth_params) > 1:\n            found_types = [s[0] for s in signature_types_with_oauth_params]\n            raise errors.InvalidRequestError(\n                description=('oauth_ params must come from only 1 signature'\n                             'type but were found in %s',\n                             ', '.join(found_types)))\n\n        try:\n            signature_type, params, oauth_params = signature_types_with_oauth_params[\n                0]\n        except IndexError:\n            raise errors.InvalidRequestError(\n                description='Missing mandatory OAuth parameters.')\n\n        return signature_type, params, oauth_params", "response": "Extracts parameters from query headers and body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_token_response(self, request, token_handler):\n        headers = self._get_default_headers()\n        try:\n            if self.request_validator.client_authentication_required(request):\n                log.debug('Authenticating client, %r.', request)\n                if not self.request_validator.authenticate_client(request):\n                    log.debug('Client authentication failed, %r.', request)\n                    raise errors.InvalidClientError(request=request)\n            elif not self.request_validator.authenticate_client_id(request.client_id, request):\n                log.debug('Client authentication failed, %r.', request)\n                raise errors.InvalidClientError(request=request)\n            log.debug('Validating access token request, %r.', request)\n            self.validate_token_request(request)\n        except errors.OAuth2Error as e:\n            log.debug('Client error in token request, %s.', e)\n            headers.update(e.headers)\n            return headers, e.json, e.status_code\n\n        token = token_handler.create_token(request, self.refresh_token)\n\n        for modifier in self._token_modifiers:\n            token = modifier(token)\n\n        self.request_validator.save_token(token, request)\n\n        log.debug('Issuing token %r to client id %r (%r) and username %s.',\n                  token, request.client_id, request.client, request.username)\n        return headers, json.dumps(token), 200", "response": "Create a token response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the request to the token endpoint.", "response": "def validate_token_request(self, request):\n        \"\"\"\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n\n        The client makes a request to the token endpoint by adding the\n        following parameters using the \"application/x-www-form-urlencoded\"\n        format per Appendix B with a character encoding of UTF-8 in the HTTP\n        request entity-body:\n\n        grant_type\n                REQUIRED.  Value MUST be set to \"password\".\n\n        username\n                REQUIRED.  The resource owner username.\n\n        password\n                REQUIRED.  The resource owner password.\n\n        scope\n                OPTIONAL.  The scope of the access request as described by\n                `Section 3.3`_.\n\n        If the client type is confidential or the client was issued client\n        credentials (or assigned other authentication requirements), the\n        client MUST authenticate with the authorization server as described\n        in `Section 3.2.1`_.\n\n        The authorization server MUST:\n\n        o  require client authentication for confidential clients or for any\n            client that was issued client credentials (or with other\n            authentication requirements),\n\n        o  authenticate the client if client authentication is included, and\n\n        o  validate the resource owner password credentials using its\n            existing password validation algorithm.\n\n        Since this access token request utilizes the resource owner's\n        password, the authorization server MUST protect the endpoint against\n        brute force attacks (e.g., using rate-limitation or generating\n        alerts).\n\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        .. _`Section 3.2.1`: https://tools.ietf.org/html/rfc6749#section-3.2.1\n        \"\"\"\n        for validator in self.custom_validators.pre_token:\n            validator(request)\n\n        for param in ('grant_type', 'username', 'password'):\n            if not getattr(request, param, None):\n                raise errors.InvalidRequestError(\n                    'Request is missing %s parameter.' % param, request=request)\n\n        for param in ('grant_type', 'username', 'password', 'scope'):\n            if param in request.duplicate_params:\n                raise errors.InvalidRequestError(description='Duplicate %s parameter.' % param, request=request)\n\n        # This error should rarely (if ever) occur if requests are routed to\n        # grant type handlers based on the grant_type parameter.\n        if not request.grant_type == 'password':\n            raise errors.UnsupportedGrantTypeError(request=request)\n\n        log.debug('Validating username %s.', request.username)\n        if not self.request_validator.validate_user(request.username,\n                                                    request.password, request.client, request):\n            raise errors.InvalidGrantError(\n                'Invalid credentials given.', request=request)\n        else:\n            if not hasattr(request.client, 'client_id'):\n                raise NotImplementedError(\n                    'Validate user must set the '\n                    'request.client.client_id attribute '\n                    'in authenticate_client.')\n        log.debug('Authorizing access to user %r.', request.user)\n\n        # Ensure client is authorized use of this grant type\n        self.validate_grant_type(request)\n\n        if request.client:\n            request.client_id = request.client_id or request.client.client_id\n        self.validate_scopes(request)\n\n        for validator in self.custom_validators.post_token:\n            validator(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_client_key(self, client_key):\n        lower, upper = self.client_key_length\n        return (set(client_key) <= self.safe_characters and\n                lower <= len(client_key) <= upper)", "response": "Check that the client key only contains safe characters\n        and is no longer than lower and no longer than upper."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the request token contains only safe characters and is no longer than lower and no longer than upper.", "response": "def check_request_token(self, request_token):\n        \"\"\"Checks that the request token contains only safe characters\n        and is no shorter than lower and no longer than upper.\n        \"\"\"\n        lower, upper = self.request_token_length\n        return (set(request_token) <= self.safe_characters and\n                lower <= len(request_token) <= upper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_access_token(self, request_token):\n        lower, upper = self.access_token_length\n        return (set(request_token) <= self.safe_characters and\n                lower <= len(request_token) <= upper)", "response": "Checks that the token contains only safe characters\n        and is no longer than lower and no longer than upper."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the nonce contains only safe characters and is no longer than lower and no longer than upper.", "response": "def check_nonce(self, nonce):\n        \"\"\"Checks that the nonce only contains only safe characters\n        and is no shorter than lower and no longer than upper.\n        \"\"\"\n        lower, upper = self.nonce_length\n        return (set(nonce) <= self.safe_characters and\n                lower <= len(nonce) <= upper)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_verifier(self, verifier):\n        lower, upper = self.verifier_length\n        return (set(verifier) <= self.safe_characters and\n                lower <= len(verifier) <= upper)", "response": "Checks that the verifier contains only safe characters\n        and is no longer than lower and no longer than upper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _subclass_must_implement(self, fn):\n        m = \"Missing function implementation in {}: {}\".format(type(self), fn)\n        return NotImplementedError(m)", "response": "Returns a NotImplementedError for a function that should be implemented."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_timestamp_and_nonce(self, client_key, timestamp, nonce,\n                                     request, request_token=None, access_token=None):\n        \"\"\"Validates that the nonce has not been used before.\n\n        :param client_key: The client/consumer key.\n        :param timestamp: The ``oauth_timestamp`` parameter.\n        :param nonce: The ``oauth_nonce`` parameter.\n        :param request_token: Request token string, if any.\n        :param access_token: Access token string, if any.\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        :returns: True or False\n\n        Per `Section 3.3`_ of the spec.\n\n        \"A nonce is a random string, uniquely generated by the client to allow\n        the server to verify that a request has never been made before and\n        helps prevent replay attacks when requests are made over a non-secure\n        channel.  The nonce value MUST be unique across all requests with the\n        same timestamp, client credentials, and token combinations.\"\n\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc5849#section-3.3\n\n        One of the first validation checks that will be made is for the validity\n        of the nonce and timestamp, which are associated with a client key and\n        possibly a token. If invalid then immediately fail the request\n        by returning False. If the nonce/timestamp pair has been used before and\n        you may just have detected a replay attack. Therefore it is an essential\n        part of OAuth security that you not allow nonce/timestamp reuse.\n        Note that this validation check is done before checking the validity of\n        the client and token.::\n\n           nonces_and_timestamps_database = [\n              (u'foo', 1234567890, u'rannoMstrInghere', u'bar')\n           ]\n\n           def validate_timestamp_and_nonce(self, client_key, timestamp, nonce,\n              request_token=None, access_token=None):\n\n              return ((client_key, timestamp, nonce, request_token or access_token)\n                       not in self.nonces_and_timestamps_database)\n\n        This method is used by\n\n        * AccessTokenEndpoint\n        * RequestTokenEndpoint\n        * ResourceEndpoint\n        * SignatureOnlyEndpoint\n        \"\"\"\n        raise self._subclass_must_implement(\"validate_timestamp_and_nonce\")", "response": "Validates that the nonce value is unique across all requests with the same client key and request token."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare the grant request URI.", "response": "def prepare_grant_uri(uri, client_id, response_type, redirect_uri=None,\n                      scope=None, state=None, **kwargs):\n    \"\"\"Prepare the authorization grant request URI.\n\n    The client constructs the request URI by adding the following\n    parameters to the query component of the authorization endpoint URI\n    using the ``application/x-www-form-urlencoded`` format as defined by\n    [`W3C.REC-html401-19991224`_]:\n\n    :param uri:\n    :param client_id: The client identifier as described in `Section 2.2`_.\n    :param response_type: To indicate which OAuth 2 grant/flow is required,\n                          \"code\" and \"token\".\n    :param redirect_uri: The client provided URI to redirect back to after\n                         authorization as described in `Section 3.1.2`_.\n    :param scope: The scope of the access request as described by\n                  `Section 3.3`_.\n    :param state: An opaque value used by the client to maintain\n                  state between the request and callback.  The authorization\n                  server includes this value when redirecting the user-agent\n                  back to the client.  The parameter SHOULD be used for\n                  preventing cross-site request forgery as described in\n                  `Section 10.12`_.\n    :param kwargs: Extra arguments to embed in the grant/authorization URL.\n\n    An example of an authorization code grant authorization URL:\n\n    .. code-block:: http\n\n        GET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz\n            &redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\n        Host: server.example.com\n\n    .. _`W3C.REC-html401-19991224`: https://tools.ietf.org/html/rfc6749#ref-W3C.REC-html401-19991224\n    .. _`Section 2.2`: https://tools.ietf.org/html/rfc6749#section-2.2\n    .. _`Section 3.1.2`: https://tools.ietf.org/html/rfc6749#section-3.1.2\n    .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n    .. _`section 10.12`: https://tools.ietf.org/html/rfc6749#section-10.12\n    \"\"\"\n    if not is_secure_transport(uri):\n        raise InsecureTransportError()\n\n    params = [(('response_type', response_type)),\n              (('client_id', client_id))]\n\n    if redirect_uri:\n        params.append(('redirect_uri', redirect_uri))\n    if scope:\n        params.append(('scope', list_to_scope(scope)))\n    if state:\n        params.append(('state', state))\n\n    for k in kwargs:\n        if kwargs[k]:\n            params.append((unicode_type(k), kwargs[k]))\n\n    return add_params_to_uri(uri, params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing the access token request.", "response": "def prepare_token_request(grant_type, body='', include_client_id=True, **kwargs):\n    \"\"\"Prepare the access token request.\n\n    The client makes a request to the token endpoint by adding the\n    following parameters using the ``application/x-www-form-urlencoded``\n    format in the HTTP request entity-body:\n\n    :param grant_type: To indicate grant type being used, i.e. \"password\",\n                       \"authorization_code\" or \"client_credentials\".\n\n    :param body: Existing request body (URL encoded string) to embed parameters\n                 into. This may contain extra parameters. Default ''.\n\n    :param include_client_id: `True` (default) to send the `client_id` in the\n                              body of the upstream request. This is required\n                              if the client is not authenticating with the\n                              authorization server as described in\n                              `Section 3.2.1`_.\n    :type include_client_id: Boolean\n\n    :param client_id: Unicode client identifier. Will only appear if\n                      `include_client_id` is True. *\n\n    :param client_secret: Unicode client secret. Will only appear if set to a\n                          value that is not `None`. Invoking this function with\n                          an empty string will send an empty `client_secret`\n                          value to the server. *\n\n    :param code: If using authorization_code grant, pass the previously\n                 obtained authorization code as the ``code`` argument. *\n\n    :param redirect_uri: If the \"redirect_uri\" parameter was included in the\n                         authorization request as described in\n                         `Section 4.1.1`_, and their values MUST be identical. *\n\n    :param kwargs: Extra arguments to embed in the request body.\n\n    Parameters marked with a `*` above are not explicit arguments in the\n    function signature, but are specially documented arguments for items\n    appearing in the generic `**kwargs` keyworded input.\n\n    An example of an authorization code token request body:\n\n    .. code-block:: http\n\n        grant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA\n        &redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb\n\n    .. _`Section 4.1.1`: https://tools.ietf.org/html/rfc6749#section-4.1.1\n    \"\"\"\n    params = [('grant_type', grant_type)]\n\n    if 'scope' in kwargs:\n        kwargs['scope'] = list_to_scope(kwargs['scope'])\n\n    # pull the `client_id` out of the kwargs.\n    client_id = kwargs.pop('client_id', None)\n    if include_client_id:\n        if client_id is not None:\n            params.append((unicode_type('client_id'), client_id))\n\n    # the kwargs iteration below only supports including boolean truth (truthy)\n    # values, but some servers may require an empty string for `client_secret`\n    client_secret = kwargs.pop('client_secret', None)\n    if client_secret is not None:\n        params.append((unicode_type('client_secret'), client_secret))\n\n    # this handles: `code`, `redirect_uri`, and other undocumented params\n    for k in kwargs:\n        if kwargs[k]:\n            params.append((unicode_type(k), kwargs[k]))\n\n    return add_params_to_qs(body, params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_token_revocation_request(url, token, token_type_hint=\"access_token\",\n        callback=None, body='', **kwargs):\n    \"\"\"Prepare a token revocation request.\n\n    The client constructs the request by including the following parameters\n    using the \"application/x-www-form-urlencoded\" format in the HTTP request\n    entity-body:\n\n    :param token: REQUIRED.  The token that the client wants to get revoked.\n\n    :param token_type_hint: OPTIONAL.  A hint about the type of the token\n                            submitted for revocation. Clients MAY pass this\n                            parameter in order to help the authorization server\n                            to optimize the token lookup.  If the server is\n                            unable to locate the token using the given hint, it\n                            MUST extend its search across all of its supported\n                            token types.  An authorization server MAY ignore\n                            this parameter, particularly if it is able to detect\n                            the token type automatically.\n\n    This specification defines two values for `token_type_hint`:\n\n        * access_token: An access token as defined in [RFC6749],\n             `Section 1.4`_\n\n        * refresh_token: A refresh token as defined in [RFC6749],\n             `Section 1.5`_\n\n        Specific implementations, profiles, and extensions of this\n        specification MAY define other values for this parameter using the\n        registry defined in `Section 4.1.2`_.\n\n    .. _`Section 1.4`: https://tools.ietf.org/html/rfc6749#section-1.4\n    .. _`Section 1.5`: https://tools.ietf.org/html/rfc6749#section-1.5\n    .. _`Section 4.1.2`: https://tools.ietf.org/html/rfc7009#section-4.1.2\n\n    \"\"\"\n    if not is_secure_transport(url):\n        raise InsecureTransportError()\n\n    params = [('token', token)]\n\n    if token_type_hint:\n        params.append(('token_type_hint', token_type_hint))\n\n    for k in kwargs:\n        if kwargs[k]:\n            params.append((unicode_type(k), kwargs[k]))\n\n    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n\n    if callback:\n        params.append(('callback', callback))\n        return add_params_to_uri(url, params), headers, body\n    else:\n        return url, headers, add_params_to_qs(body, params)", "response": "Prepare a token revocation request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the authorization grant response URI into a dict.", "response": "def parse_authorization_code_response(uri, state=None):\n    \"\"\"Parse authorization grant response URI into a dict.\n\n    If the resource owner grants the access request, the authorization\n    server issues an authorization code and delivers it to the client by\n    adding the following parameters to the query component of the\n    redirection URI using the ``application/x-www-form-urlencoded`` format:\n\n    **code**\n            REQUIRED.  The authorization code generated by the\n            authorization server.  The authorization code MUST expire\n            shortly after it is issued to mitigate the risk of leaks.  A\n            maximum authorization code lifetime of 10 minutes is\n            RECOMMENDED.  The client MUST NOT use the authorization code\n            more than once.  If an authorization code is used more than\n            once, the authorization server MUST deny the request and SHOULD\n            revoke (when possible) all tokens previously issued based on\n            that authorization code.  The authorization code is bound to\n            the client identifier and redirection URI.\n\n    **state**\n            REQUIRED if the \"state\" parameter was present in the client\n            authorization request.  The exact value received from the\n            client.\n\n    :param uri: The full redirect URL back to the client.\n    :param state: The state parameter from the authorization request.\n\n    For example, the authorization server redirects the user-agent by\n    sending the following HTTP response:\n\n    .. code-block:: http\n\n        HTTP/1.1 302 Found\n        Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA\n                &state=xyz\n\n    \"\"\"\n    if not is_secure_transport(uri):\n        raise InsecureTransportError()\n\n    query = urlparse.urlparse(uri).query\n    params = dict(urlparse.parse_qsl(query))\n\n    if not 'code' in params:\n        raise MissingCodeError(\"Missing code parameter in response.\")\n\n    if state and params.get('state', None) != state:\n        raise MismatchingStateError()\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_implicit_response(uri, state=None, scope=None):\n    if not is_secure_transport(uri):\n        raise InsecureTransportError()\n\n    fragment = urlparse.urlparse(uri).fragment\n    params = dict(urlparse.parse_qsl(fragment, keep_blank_values=True))\n\n    for key in ('expires_in',):\n        if key in params:  # cast things to int\n            params[key] = int(params[key])\n\n    if 'scope' in params:\n        params['scope'] = scope_to_list(params['scope'])\n\n    if 'expires_in' in params:\n        params['expires_at'] = time.time() + int(params['expires_in'])\n\n    if state and params.get('state', None) != state:\n        raise ValueError(\"Mismatching or missing state in params.\")\n\n    params = OAuth2Token(params, old_scope=scope)\n    validate_token_parameters(params)\n    return params", "response": "Parse the implicit token response URI into a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the response body into a dict.", "response": "def parse_token_response(body, scope=None):\n    \"\"\"Parse the JSON token response body into a dict.\n\n    The authorization server issues an access token and optional refresh\n    token, and constructs the response by adding the following parameters\n    to the entity body of the HTTP response with a 200 (OK) status code:\n\n    access_token\n            REQUIRED.  The access token issued by the authorization server.\n    token_type\n            REQUIRED.  The type of the token issued as described in\n            `Section 7.1`_.  Value is case insensitive.\n    expires_in\n            RECOMMENDED.  The lifetime in seconds of the access token.  For\n            example, the value \"3600\" denotes that the access token will\n            expire in one hour from the time the response was generated.\n            If omitted, the authorization server SHOULD provide the\n            expiration time via other means or document the default value.\n    refresh_token\n            OPTIONAL.  The refresh token which can be used to obtain new\n            access tokens using the same authorization grant as described\n            in `Section 6`_.\n    scope\n            OPTIONAL, if identical to the scope requested by the client,\n            otherwise REQUIRED.  The scope of the access token as described\n            by `Section 3.3`_.\n\n    The parameters are included in the entity body of the HTTP response\n    using the \"application/json\" media type as defined by [`RFC4627`_].  The\n    parameters are serialized into a JSON structure by adding each\n    parameter at the highest structure level.  Parameter names and string\n    values are included as JSON strings.  Numerical values are included\n    as JSON numbers.  The order of parameters does not matter and can\n    vary.\n\n    :param body: The full json encoded response body.\n    :param scope: The scope requested during authorization.\n\n    For example:\n\n    .. code-block:: http\n\n        HTTP/1.1 200 OK\n        Content-Type: application/json\n        Cache-Control: no-store\n        Pragma: no-cache\n\n        {\n            \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n            \"token_type\":\"example\",\n            \"expires_in\":3600,\n            \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n            \"example_parameter\":\"example_value\"\n        }\n\n    .. _`Section 7.1`: https://tools.ietf.org/html/rfc6749#section-7.1\n    .. _`Section 6`: https://tools.ietf.org/html/rfc6749#section-6\n    .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n    .. _`RFC4627`: https://tools.ietf.org/html/rfc4627\n    \"\"\"\n    try:\n        params = json.loads(body)\n    except ValueError:\n\n        # Fall back to URL-encoded string, to support old implementations,\n        # including (at time of writing) Facebook. See:\n        #   https://github.com/oauthlib/oauthlib/issues/267\n\n        params = dict(urlparse.parse_qsl(body))\n        for key in ('expires_in',):\n            if key in params:  # cast things to int\n                params[key] = int(params[key])\n\n    if 'scope' in params:\n        params['scope'] = scope_to_list(params['scope'])\n\n    if 'expires_in' in params:\n        params['expires_at'] = time.time() + int(params['expires_in'])\n\n    params = OAuth2Token(params, old_scope=scope)\n    validate_token_parameters(params)\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring token precence token type expiration and scope in params.", "response": "def validate_token_parameters(params):\n    \"\"\"Ensures token precence, token type, expiration and scope in params.\"\"\"\n    if 'error' in params:\n        raise_from_error(params.get('error'), params)\n\n    if not 'access_token' in params:\n        raise MissingTokenError(description=\"Missing access token parameter.\")\n\n    if not 'token_type' in params:\n        if os.environ.get('OAUTHLIB_STRICT_TOKEN_TYPE'):\n            raise MissingTokenTypeError()\n\n    # If the issued access token scope is different from the one requested by\n    # the client, the authorization server MUST include the \"scope\" response\n    # parameter to inform the client of the actual scope granted.\n    # https://tools.ietf.org/html/rfc6749#section-3.3\n    if params.scope_changed:\n        message = 'Scope has changed from \"{old}\" to \"{new}\".'.format(\n            old=params.old_scope, new=params.scope,\n        )\n        scope_changed.send(message=message, old=params.old_scopes, new=params.scopes)\n        if not os.environ.get('OAUTHLIB_RELAX_TOKEN_SCOPE', None):\n            w = Warning(message)\n            w.token = params\n            w.old_scope = params.old_scopes\n            w.new_scope = params.scopes\n            raise w"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing the request body for the current request.", "response": "def prepare_request_body(self, username, password, body='', scope=None,\n                             include_client_id=False, **kwargs):\n        \"\"\"Add the resource owner password and username to the request body.\n\n        The client makes a request to the token endpoint by adding the\n        following parameters using the \"application/x-www-form-urlencoded\"\n        format per `Appendix B`_ in the HTTP request entity-body:\n\n        :param username:    The resource owner username.\n        :param password:    The resource owner password.\n        :param body: Existing request body (URL encoded string) to embed parameters\n                     into. This may contain extra paramters. Default ''.\n        :param scope:   The scope of the access request as described by\n                        `Section 3.3`_.\n        :param include_client_id: `True` to send the `client_id` in the\n                                  body of the upstream request. This is required\n                                  if the client is not authenticating with the\n                                  authorization server as described in\n                                  `Section 3.2.1`_. False otherwise (default).\n        :type include_client_id: Boolean\n        :param kwargs:  Extra credentials to include in the token request.\n\n        If the client type is confidential or the client was issued client\n        credentials (or assigned other authentication requirements), the\n        client MUST authenticate with the authorization server as described\n        in `Section 3.2.1`_.\n\n        The prepared body will include all provided credentials as well as\n        the ``grant_type`` parameter set to ``password``::\n\n            >>> from oauthlib.oauth2 import LegacyApplicationClient\n            >>> client = LegacyApplicationClient('your_id')\n            >>> client.prepare_request_body(username='foo', password='bar', scope=['hello', 'world'])\n            'grant_type=password&username=foo&scope=hello+world&password=bar'\n\n        .. _`Appendix B`: https://tools.ietf.org/html/rfc6749#appendix-B\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        .. _`Section 3.2.1`: https://tools.ietf.org/html/rfc6749#section-3.2.1\n        \"\"\"\n        kwargs['client_id'] = self.client_id\n        kwargs['include_client_id'] = include_client_id\n        return prepare_token_request(self.grant_type, body=body, username=username,\n                                     password=password, scope=scope, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_request_uri(self, uri, redirect_uri=None, scope=None,\n                            state=None, **kwargs):\n        \"\"\"Prepare the implicit grant request URI.\n\n        The client constructs the request URI by adding the following\n        parameters to the query component of the authorization endpoint URI\n        using the \"application/x-www-form-urlencoded\" format, per `Appendix B`_:\n\n        :param redirect_uri:  OPTIONAL. The redirect URI must be an absolute URI\n                              and it should have been registerd with the OAuth\n                              provider prior to use. As described in `Section 3.1.2`_.\n\n        :param scope:  OPTIONAL. The scope of the access request as described by\n                       Section 3.3`_. These may be any string but are commonly\n                       URIs or various categories such as ``videos`` or ``documents``.\n\n        :param state:   RECOMMENDED.  An opaque value used by the client to maintain\n                        state between the request and callback.  The authorization\n                        server includes this value when redirecting the user-agent back\n                        to the client.  The parameter SHOULD be used for preventing\n                        cross-site request forgery as described in `Section 10.12`_.\n\n        :param kwargs:  Extra arguments to include in the request URI.\n\n        In addition to supplied parameters, OAuthLib will append the ``client_id``\n        that was provided in the constructor as well as the mandatory ``response_type``\n        argument, set to ``token``::\n\n            >>> from oauthlib.oauth2 import MobileApplicationClient\n            >>> client = MobileApplicationClient('your_id')\n            >>> client.prepare_request_uri('https://example.com')\n            'https://example.com?client_id=your_id&response_type=token'\n            >>> client.prepare_request_uri('https://example.com', redirect_uri='https://a.b/callback')\n            'https://example.com?client_id=your_id&response_type=token&redirect_uri=https%3A%2F%2Fa.b%2Fcallback'\n            >>> client.prepare_request_uri('https://example.com', scope=['profile', 'pictures'])\n            'https://example.com?client_id=your_id&response_type=token&scope=profile+pictures'\n            >>> client.prepare_request_uri('https://example.com', foo='bar')\n            'https://example.com?client_id=your_id&response_type=token&foo=bar'\n\n        .. _`Appendix B`: https://tools.ietf.org/html/rfc6749#appendix-B\n        .. _`Section 2.2`: https://tools.ietf.org/html/rfc6749#section-2.2\n        .. _`Section 3.1.2`: https://tools.ietf.org/html/rfc6749#section-3.1.2\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        .. _`Section 10.12`: https://tools.ietf.org/html/rfc6749#section-10.12\n        \"\"\"\n        return prepare_grant_uri(uri, self.client_id, self.response_type,\n                                 redirect_uri=redirect_uri, state=state, scope=scope, **kwargs)", "response": "Prepares the request URI for the implicit grant request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the response URI fragment of the request URI.", "response": "def parse_request_uri_response(self, uri, state=None, scope=None):\n        \"\"\"Parse the response URI fragment.\n\n        If the resource owner grants the access request, the authorization\n        server issues an access token and delivers it to the client by adding\n        the following parameters to the fragment component of the redirection\n        URI using the \"application/x-www-form-urlencoded\" format:\n\n        :param uri: The callback URI that resulted from the user being redirected\n                    back from the provider to you, the client.\n        :param state: The state provided in the authorization request.\n        :param scope: The scopes provided in the authorization request.\n        :return: Dictionary of token parameters.\n        :raises: OAuth2Error if response is invalid.\n\n        A successful response should always contain\n\n        **access_token**\n                The access token issued by the authorization server. Often\n                a random string.\n\n        **token_type**\n            The type of the token issued as described in `Section 7.1`_.\n            Commonly ``Bearer``.\n\n        **state**\n            If you provided the state parameter in the authorization phase, then\n            the provider is required to include that exact state value in the\n            response.\n\n        While it is not mandated it is recommended that the provider include\n\n        **expires_in**\n            The lifetime in seconds of the access token.  For\n            example, the value \"3600\" denotes that the access token will\n            expire in one hour from the time the response was generated.\n            If omitted, the authorization server SHOULD provide the\n            expiration time via other means or document the default value.\n\n        **scope**\n            Providers may supply this in all responses but are required to only\n            if it has changed since the authorization request.\n\n        A few example responses can be seen below::\n\n            >>> response_uri = 'https://example.com/callback#access_token=sdlfkj452&state=ss345asyht&token_type=Bearer&scope=hello+world'\n            >>> from oauthlib.oauth2 import MobileApplicationClient\n            >>> client = MobileApplicationClient('your_id')\n            >>> client.parse_request_uri_response(response_uri)\n            {\n                'access_token': 'sdlfkj452',\n                'token_type': 'Bearer',\n                'state': 'ss345asyht',\n                'scope': [u'hello', u'world']\n            }\n            >>> client.parse_request_uri_response(response_uri, state='other')\n            Traceback (most recent call last):\n                File \"<stdin>\", line 1, in <module>\n                File \"oauthlib/oauth2/rfc6749/__init__.py\", line 598, in parse_request_uri_response\n                    **scope**\n                File \"oauthlib/oauth2/rfc6749/parameters.py\", line 197, in parse_implicit_response\n                    raise ValueError(\"Mismatching or missing state in params.\")\n            ValueError: Mismatching or missing state in params.\n            >>> def alert_scope_changed(message, old, new):\n            ...     print(message, old, new)\n            ...\n            >>> oauthlib.signals.scope_changed.connect(alert_scope_changed)\n            >>> client.parse_request_body_response(response_body, scope=['other'])\n            ('Scope has changed from \"other\" to \"hello world\".', ['other'], ['hello', 'world'])\n\n        .. _`Section 7.1`: https://tools.ietf.org/html/rfc6749#section-7.1\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        \"\"\"\n        self.token = parse_implicit_response(uri, state=state, scope=scope)\n        self.populate_token_attributes(self.token)\n        return self.token"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract response_type and route to the designated handler.", "response": "def create_authorization_response(self, uri, http_method='GET', body=None,\n                                      headers=None, scopes=None, credentials=None):\n        \"\"\"Extract response_type and route to the designated handler.\"\"\"\n        request = Request(\n            uri, http_method=http_method, body=body, headers=headers)\n        request.scopes = scopes\n        # TODO: decide whether this should be a required argument\n        request.user = None     # TODO: explain this in docs\n        for k, v in (credentials or {}).items():\n            setattr(request, k, v)\n        response_type_handler = self.response_types.get(\n            request.response_type, self.default_response_type_handler)\n        log.debug('Dispatching response_type %s request to %r.',\n                  request.response_type, response_type_handler)\n        return response_type_handler.create_authorization_response(\n            request, self.default_token_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts response_type and route to the designated handler.", "response": "def validate_authorization_request(self, uri, http_method='GET', body=None,\n                                       headers=None):\n        \"\"\"Extract response_type and route to the designated handler.\"\"\"\n        request = Request(\n            uri, http_method=http_method, body=body, headers=headers)\n\n        request.scopes = utils.scope_to_list(request.scope)\n\n        response_type_handler = self.response_types.get(\n            request.response_type, self.default_response_type_handler)\n        return response_type_handler.validate_authorization_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that the authorization process represented by this authorization code began with this 'redirect_uri'. If the client specifies a redirect_uri when obtaining code then that redirect URI must be bound to the code and verified equal in this method, according to RFC 6749 section 4.1.3. Do not compare against the client's allowed redirect URIs, but against the URI used when the code was saved. :param client_id: Unicode client identifier. :param code: Unicode authorization_code. :param redirect_uri: Unicode absolute URI. :param client: Client object set by you, see ``.authenticate_client``. :param request: OAuthlib request. :type request: oauthlib.common.Request :rtype: True or False Method is used by: - Authorization Code Grant (during token request)", "response": "def confirm_redirect_uri(self, client_id, code, redirect_uri, client, request,\n                             *args, **kwargs):\n        \"\"\"Ensure that the authorization process represented by this authorization\n        code began with this 'redirect_uri'.\n\n        If the client specifies a redirect_uri when obtaining code then that\n        redirect URI must be bound to the code and verified equal in this\n        method, according to RFC 6749 section 4.1.3.  Do not compare against\n        the client's allowed redirect URIs, but against the URI used when the\n        code was saved.\n\n        :param client_id: Unicode client identifier.\n        :param code: Unicode authorization_code.\n        :param redirect_uri: Unicode absolute URI.\n        :param client: Client object set by you, see ``.authenticate_client``.\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        :rtype: True or False\n\n        Method is used by:\n            - Authorization Code Grant (during token request)\n        \"\"\"\n        raise NotImplementedError('Subclasses must implement this method.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_token(self, token, request, *args, **kwargs):\n        return self.save_bearer_token(token, request, *args, **kwargs)", "response": "Saves the token with a token type specific method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that all parameters in a list of 2 - element tuples are encoded to bytestrings using UTF - 8", "response": "def encode_params_utf8(params):\n    \"\"\"Ensures that all parameters in a list of 2-element tuples are encoded to\n    bytestrings using UTF-8\n    \"\"\"\n    encoded = []\n    for k, v in params:\n        encoded.append((\n            k.encode('utf-8') if isinstance(k, unicode_type) else k,\n            v.encode('utf-8') if isinstance(v, unicode_type) else v))\n    return encoded"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that all parameters in a list of 2 - element tuples are decoded to unicode using UTF - 8.", "response": "def decode_params_utf8(params):\n    \"\"\"Ensures that all parameters in a list of 2-element tuples are decoded to\n    unicode using UTF-8.\n    \"\"\"\n    decoded = []\n    for k, v in params:\n        decoded.append((\n            k.decode('utf-8') if isinstance(k, bytes) else k,\n            v.decode('utf-8') if isinstance(v, bytes) else v))\n    return decoded"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef urldecode(query):\n    # Check if query contains invalid characters\n    if query and not set(query) <= urlencoded:\n        error = (\"Error trying to decode a non urlencoded string. \"\n                 \"Found invalid characters: %s \"\n                 \"in the string: '%s'. \"\n                 \"Please ensure the request/response body is \"\n                 \"x-www-form-urlencoded.\")\n        raise ValueError(error % (set(query) - urlencoded, query))\n\n    # Check for correctly hex encoded values using a regular expression\n    # All encoded values begin with % followed by two hex characters\n    # correct = %00, %A0, %0A, %FF\n    # invalid = %G0, %5H, %PO\n    if INVALID_HEX_PATTERN.search(query):\n        raise ValueError('Invalid hex encoding in query string.')\n\n    # We encode to utf-8 prior to parsing because parse_qsl behaves\n    # differently on unicode input in python 2 and 3.\n    # Python 2.7\n    # >>> urlparse.parse_qsl(u'%E5%95%A6%E5%95%A6')\n    # u'\\xe5\\x95\\xa6\\xe5\\x95\\xa6'\n    # Python 2.7, non unicode input gives the same\n    # >>> urlparse.parse_qsl('%E5%95%A6%E5%95%A6')\n    # '\\xe5\\x95\\xa6\\xe5\\x95\\xa6'\n    # but now we can decode it to unicode\n    # >>> urlparse.parse_qsl('%E5%95%A6%E5%95%A6').decode('utf-8')\n    # u'\\u5566\\u5566'\n    # Python 3.3 however\n    # >>> urllib.parse.parse_qsl(u'%E5%95%A6%E5%95%A6')\n    # u'\\u5566\\u5566'\n    query = query.encode(\n        'utf-8') if not PY3 and isinstance(query, unicode_type) else query\n    # We want to allow queries such as \"c2\" whereas urlparse.parse_qsl\n    # with the strict_parsing flag will not.\n    params = urlparse.parse_qsl(query, keep_blank_values=True)\n\n    # unicode all the things\n    return decode_params_utf8(params)", "response": "Decode a query string in x - www - form - urlencoded format into a sequence of two - element tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting parameters and return them as a list of 2 - tuples.", "response": "def extract_params(raw):\n    \"\"\"Extract parameters and return them as a list of 2-tuples.\n\n    Will successfully extract parameters from urlencoded query strings,\n    dicts, or lists of 2-tuples. Empty strings/dicts/lists will return an\n    empty list of parameters. Any other input will result in a return\n    value of None.\n    \"\"\"\n    if isinstance(raw, (bytes, unicode_type)):\n        try:\n            params = urldecode(raw)\n        except ValueError:\n            params = None\n    elif hasattr(raw, '__iter__'):\n        try:\n            dict(raw)\n        except ValueError:\n            params = None\n        except TypeError:\n            params = None\n        else:\n            params = list(raw.items() if isinstance(raw, dict) else raw)\n            params = decode_params_utf8(params)\n    else:\n        params = None\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_token(length=30, chars=UNICODE_ASCII_CHARACTER_SET):\n    rand = SystemRandom()\n    return ''.join(rand.choice(chars) for x in range(length))", "response": "Generates a non - guessable OAuth token."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextends a query with a list of two - tuples.", "response": "def add_params_to_qs(query, params):\n    \"\"\"Extend a query with a list of two-tuples.\"\"\"\n    if isinstance(params, dict):\n        params = params.items()\n    queryparams = urlparse.parse_qsl(query, keep_blank_values=True)\n    queryparams.extend(params)\n    return urlencode(queryparams)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_params_to_uri(uri, params, fragment=False):\n    sch, net, path, par, query, fra = urlparse.urlparse(uri)\n    if fragment:\n        fra = add_params_to_qs(fra, params)\n    else:\n        query = add_params_to_qs(query, params)\n    return urlparse.urlunparse((sch, net, path, par, query, fra))", "response": "Add a list of two - tuples to the uri query components."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a number of different types of objects to unicode.", "response": "def to_unicode(data, encoding='UTF-8'):\n    \"\"\"Convert a number of different types of objects to unicode.\"\"\"\n    if isinstance(data, unicode_type):\n        return data\n\n    if isinstance(data, bytes):\n        return unicode_type(data, encoding=encoding)\n\n    if hasattr(data, '__iter__'):\n        try:\n            dict(data)\n        except TypeError:\n            pass\n        except ValueError:\n            # Assume it's a one dimensional data structure\n            return (to_unicode(i, encoding) for i in data)\n        else:\n            # We support 2.6 which lacks dict comprehensions\n            if hasattr(data, 'items'):\n                data = data.items()\n            return dict(((to_unicode(k, encoding), to_unicode(v, encoding)) for k, v in data))\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the HTTP headers for the given OAuth parameters.", "response": "def prepare_headers(oauth_params, headers=None, realm=None):\n    \"\"\"**Prepare the Authorization header.**\n    Per `section 3.5.1`_ of the spec.\n\n    Protocol parameters can be transmitted using the HTTP \"Authorization\"\n    header field as defined by `RFC2617`_ with the auth-scheme name set to\n    \"OAuth\" (case insensitive).\n\n    For example::\n\n        Authorization: OAuth realm=\"Example\",\n            oauth_consumer_key=\"0685bd9184jfhq22\",\n            oauth_token=\"ad180jjd733klru7\",\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_signature=\"wOJIO9A2W5mFwDgiDvZbTSMK%2FPY%3D\",\n            oauth_timestamp=\"137131200\",\n            oauth_nonce=\"4572616e48616d6d65724c61686176\",\n            oauth_version=\"1.0\"\n\n\n    .. _`section 3.5.1`: https://tools.ietf.org/html/rfc5849#section-3.5.1\n    .. _`RFC2617`: https://tools.ietf.org/html/rfc2617\n    \"\"\"\n    headers = headers or {}\n\n    # Protocol parameters SHALL be included in the \"Authorization\" header\n    # field as follows:\n    authorization_header_parameters_parts = []\n    for oauth_parameter_name, value in oauth_params:\n        # 1.  Parameter names and values are encoded per Parameter Encoding\n        #     (`Section 3.6`_)\n        #\n        # .. _`Section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6\n        escaped_name = utils.escape(oauth_parameter_name)\n        escaped_value = utils.escape(value)\n\n        # 2.  Each parameter's name is immediately followed by an \"=\" character\n        #     (ASCII code 61), a \"\"\" character (ASCII code 34), the parameter\n        #     value (MAY be empty), and another \"\"\" character (ASCII code 34).\n        part = '{0}=\"{1}\"'.format(escaped_name, escaped_value)\n\n        authorization_header_parameters_parts.append(part)\n\n    # 3.  Parameters are separated by a \",\" character (ASCII code 44) and\n    #     OPTIONAL linear whitespace per `RFC2617`_.\n    #\n    # .. _`RFC2617`: https://tools.ietf.org/html/rfc2617\n    authorization_header_parameters = ', '.join(\n        authorization_header_parameters_parts)\n\n    # 4.  The OPTIONAL \"realm\" parameter MAY be added and interpreted per\n    #     `RFC2617 section 1.2`_.\n    #\n    # .. _`RFC2617 section 1.2`: https://tools.ietf.org/html/rfc2617#section-1.2\n    if realm:\n        # NOTE: realm should *not* be escaped\n        authorization_header_parameters = ('realm=\"%s\", ' % realm +\n                                           authorization_header_parameters)\n\n    # the auth-scheme name set to \"OAuth\" (case insensitive).\n    authorization_header = 'OAuth %s' % authorization_header_parameters\n\n    # contribute the Authorization header to the given headers\n    full_headers = {}\n    full_headers.update(headers)\n    full_headers['Authorization'] = authorization_header\n    return full_headers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend OAuth params to an existing set of parameters.", "response": "def _append_params(oauth_params, params):\n    \"\"\"Append OAuth params to an existing set of parameters.\n\n    Both params and oauth_params is must be lists of 2-tuples.\n\n    Per `section 3.5.2`_ and `3.5.3`_ of the spec.\n\n    .. _`section 3.5.2`: https://tools.ietf.org/html/rfc5849#section-3.5.2\n    .. _`3.5.3`: https://tools.ietf.org/html/rfc5849#section-3.5.3\n\n    \"\"\"\n    merged = list(params)\n    merged.extend(oauth_params)\n    # The request URI / entity-body MAY include other request-specific\n    # parameters, in which case, the protocol parameters SHOULD be appended\n    # following the request-specific parameters, properly separated by an \"&\"\n    # character (ASCII code 38)\n    merged.sort(key=lambda i: i[0].startswith('oauth_'))\n    return merged"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the Request URI Query.", "response": "def prepare_request_uri_query(oauth_params, uri):\n    \"\"\"Prepare the Request URI Query.\n\n    Per `section 3.5.3`_ of the spec.\n\n    .. _`section 3.5.3`: https://tools.ietf.org/html/rfc5849#section-3.5.3\n\n    \"\"\"\n    # append OAuth params to the existing set of query components\n    sch, net, path, par, query, fra = urlparse(uri)\n    query = urlencode(\n        _append_params(oauth_params, extract_params(query) or []))\n    return urlunparse((sch, net, path, par, query, fra))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_request_token(self, request, credentials):\n        token = {\n            'oauth_token': self.token_generator(),\n            'oauth_token_secret': self.token_generator(),\n            'oauth_callback_confirmed': 'true'\n        }\n        token.update(credentials)\n        self.request_validator.save_request_token(token, request)\n        return urlencode(token.items())", "response": "Create and save a new request token."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a response to a request token if valid.", "response": "def create_request_token_response(self, uri, http_method='GET', body=None,\n                                      headers=None, credentials=None):\n        \"\"\"Create a request token response, with a new request token if valid.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :param credentials: A list of extra credentials to include in the token.\n        :returns: A tuple of 3 elements.\n                  1. A dict of headers to set on the response.\n                  2. The response body as a string.\n                  3. The response status code as an integer.\n\n        An example of a valid request::\n\n            >>> from your_validator import your_validator\n            >>> from oauthlib.oauth1 import RequestTokenEndpoint\n            >>> endpoint = RequestTokenEndpoint(your_validator)\n            >>> h, b, s = endpoint.create_request_token_response(\n            ...     'https://your.provider/request_token?foo=bar',\n            ...     headers={\n            ...         'Authorization': 'OAuth realm=movies user, oauth_....'\n            ...     },\n            ...     credentials={\n            ...         'my_specific': 'argument',\n            ...     })\n            >>> h\n            {'Content-Type': 'application/x-www-form-urlencoded'}\n            >>> b\n            'oauth_token=lsdkfol23w54jlksdef&oauth_token_secret=qwe089234lkjsdf&oauth_callback_confirmed=true&my_specific=argument'\n            >>> s\n            200\n\n        An response to invalid request would have a different body and status::\n\n            >>> b\n            'error=invalid_request&description=missing+callback+uri'\n            >>> s\n            400\n\n        The same goes for an an unauthorized request:\n\n            >>> b\n            ''\n            >>> s\n            401\n        \"\"\"\n        resp_headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n        try:\n            request = self._create_request(uri, http_method, body, headers)\n            valid, processed_request = self.validate_request_token_request(\n                request)\n            if valid:\n                token = self.create_request_token(request, credentials or {})\n                return resp_headers, token, 200\n            else:\n                return {}, None, 401\n        except errors.OAuth1Error as e:\n            return resp_headers, e.urlencoded, e.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_request_token_request(self, request):\n        self._check_transport_security(request)\n        self._check_mandatory_parameters(request)\n\n        if request.realm:\n            request.realms = request.realm.split(' ')\n        else:\n            request.realms = self.request_validator.get_default_realms(\n                request.client_key, request)\n        if not self.request_validator.check_realms(request.realms):\n            raise errors.InvalidRequestError(\n                description='Invalid realm %s. Allowed are %r.' % (\n                    request.realms, self.request_validator.realms))\n\n        if not request.redirect_uri:\n            raise errors.InvalidRequestError(\n                description='Missing callback URI.')\n\n        if not self.request_validator.validate_timestamp_and_nonce(\n                request.client_key, request.timestamp, request.nonce, request,\n                request_token=request.resource_owner_key):\n            return False, request\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid client credentials.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy client is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable client enumeration\n        valid_client = self.request_validator.validate_client_key(\n            request.client_key, request)\n        if not valid_client:\n            request.client_key = self.request_validator.dummy_client\n\n        # Note that `realm`_ is only used in authorization headers and how\n        # it should be interepreted is not included in the OAuth spec.\n        # However they could be seen as a scope or realm to which the\n        # client has access and as such every client should be checked\n        # to ensure it is authorized access to that scope or realm.\n        # .. _`realm`: https://tools.ietf.org/html/rfc2617#section-1.2\n        #\n        # Note that early exit would enable client realm access enumeration.\n        #\n        # The require_realm indicates this is the first step in the OAuth\n        # workflow where a client requests access to a specific realm.\n        # This first step (obtaining request token) need not require a realm\n        # and can then be identified by checking the require_resource_owner\n        # flag and abscence of realm.\n        #\n        # Clients obtaining an access token will not supply a realm and it will\n        # not be checked. Instead the previously requested realm should be\n        # transferred from the request token to the access token.\n        #\n        # Access to protected resources will always validate the realm but note\n        # that the realm is now tied to the access token and not provided by\n        # the client.\n        valid_realm = self.request_validator.validate_requested_realms(\n            request.client_key, request.realms, request)\n\n        # Callback is normally never required, except for requests for\n        # a Temporary Credential as described in `Section 2.1`_\n        # .._`Section 2.1`: https://tools.ietf.org/html/rfc5849#section-2.1\n        valid_redirect = self.request_validator.validate_redirect_uri(\n            request.client_key, request.redirect_uri, request)\n        if not request.redirect_uri:\n            raise NotImplementedError('Redirect URI must either be provided '\n                                      'or set to a default during validation.')\n\n        valid_signature = self._check_signature(request)\n\n        # log the results to the validator_log\n        # this lets us handle internal reporting and analysis\n        request.validator_log['client'] = valid_client\n        request.validator_log['realm'] = valid_realm\n        request.validator_log['callback'] = valid_redirect\n        request.validator_log['signature'] = valid_signature\n\n        # We delay checking validity until the very end, using dummy values for\n        # calculations and fetching secrets/keys to ensure the flow of every\n        # request remains almost identical regardless of whether valid values\n        # have been supplied. This ensures near constant time execution and\n        # prevents malicious users from guessing sensitive information\n        v = all((valid_client, valid_realm, valid_redirect, valid_signature))\n        if not v:\n            log.info(\"[Failure] request verification failed.\")\n            log.info(\"Valid client: %s.\", valid_client)\n            log.info(\"Valid realm: %s.\", valid_realm)\n            log.info(\"Valid callback: %s.\", valid_redirect)\n            log.info(\"Valid signature: %s.\", valid_signature)\n        return v, request", "response": "Validate a request token request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate a signed OAuth request.", "response": "def validate_request(self, uri, http_method='GET',\n                         body=None, headers=None):\n        \"\"\"Validate a signed OAuth request.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :returns: A tuple of 2 elements.\n                  1. True if valid, False otherwise.\n                  2. An oauthlib.common.Request object.\n        \"\"\"\n        try:\n            request = self._create_request(uri, http_method, body, headers)\n        except errors.OAuth1Error as err:\n            log.info(\n                'Exception caught while validating request, %s.' % err)\n            return False, None\n\n        try:\n            self._check_transport_security(request)\n            self._check_mandatory_parameters(request)\n        except errors.OAuth1Error as err:\n            log.info(\n                'Exception caught while validating request, %s.' % err)\n            return False, request\n\n        if not self.request_validator.validate_timestamp_and_nonce(\n                request.client_key, request.timestamp, request.nonce, request):\n            log.debug('[Failure] verification failed: timestamp/nonce')\n            return False, request\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid client credentials.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy client is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable client enumeration\n        valid_client = self.request_validator.validate_client_key(\n            request.client_key, request)\n        if not valid_client:\n            request.client_key = self.request_validator.dummy_client\n\n        valid_signature = self._check_signature(request)\n\n        # log the results to the validator_log\n        # this lets us handle internal reporting and analysis\n        request.validator_log['client'] = valid_client\n        request.validator_log['signature'] = valid_signature\n\n        # We delay checking validity until the very end, using dummy values for\n        # calculations and fetching secrets/keys to ensure the flow of every\n        # request remains almost identical regardless of whether valid values\n        # have been supplied. This ensures near constant time execution and\n        # prevents malicious users from guessing sensitive information\n        v = all((valid_client, valid_signature))\n        if not v:\n            log.info(\"[Failure] request verification failed.\")\n            log.info(\"Valid client: %s\", valid_client)\n            log.info(\"Valid signature: %s\", valid_signature)\n        return v, request"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_token(self, request, refresh_token=False):\n\n        if callable(self.expires_in):\n            expires_in = self.expires_in(request)\n        else:\n            expires_in = self.expires_in\n\n        request.expires_in = expires_in\n\n        return self.request_validator.get_jwt_bearer_token(None, None, request)", "response": "Create a JWT Token using requestvalidator method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_oauth_signature(self, request):\n        if self.signature_method == SIGNATURE_PLAINTEXT:\n            # fast-path\n            return signature.sign_plaintext(self.client_secret,\n                                            self.resource_owner_secret)\n\n        uri, headers, body = self._render(request)\n\n        collected_params = signature.collect_parameters(\n            uri_query=urlparse.urlparse(uri).query,\n            body=body,\n            headers=headers)\n        log.debug(\"Collected params: {0}\".format(collected_params))\n\n        normalized_params = signature.normalize_parameters(collected_params)\n        normalized_uri = signature.base_string_uri(uri, headers.get('Host', None))\n        log.debug(\"Normalized params: {0}\".format(normalized_params))\n        log.debug(\"Normalized URI: {0}\".format(normalized_uri))\n\n        base_string = signature.signature_base_string(request.http_method,\n                                                      normalized_uri, normalized_params)\n\n        log.debug(\"Signing: signature base string: {0}\".format(base_string))\n\n        if self.signature_method not in self.SIGNATURE_METHODS:\n            raise ValueError('Invalid signature method.')\n\n        sig = self.SIGNATURE_METHODS[self.signature_method](base_string, self)\n\n        log.debug(\"Signature: {0}\".format(sig))\n        return sig", "response": "Get an OAuth signature to be used in signing a request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the OAuth parameters to be used in generating a signature.", "response": "def get_oauth_params(self, request):\n        \"\"\"Get the basic OAuth parameters to be used in generating a signature.\n        \"\"\"\n        nonce = (generate_nonce()\n                 if self.nonce is None else self.nonce)\n        timestamp = (generate_timestamp()\n                     if self.timestamp is None else self.timestamp)\n        params = [\n            ('oauth_nonce', nonce),\n            ('oauth_timestamp', timestamp),\n            ('oauth_version', '1.0'),\n            ('oauth_signature_method', self.signature_method),\n            ('oauth_consumer_key', self.client_key),\n        ]\n        if self.resource_owner_key:\n            params.append(('oauth_token', self.resource_owner_key))\n        if self.callback_uri:\n            params.append(('oauth_callback', self.callback_uri))\n        if self.verifier:\n            params.append(('oauth_verifier', self.verifier))\n\n        # providing body hash for requests other than x-www-form-urlencoded\n        # as described in https://tools.ietf.org/html/draft-eaton-oauth-bodyhash-00#section-4.1.1\n        # 4.1.1. When to include the body hash\n        #    *  [...] MUST NOT include an oauth_body_hash parameter on requests with form-encoded request bodies\n        #    *  [...] SHOULD include the oauth_body_hash parameter on all other requests.\n        # Note that SHA-1 is vulnerable. The spec acknowledges that in https://tools.ietf.org/html/draft-eaton-oauth-bodyhash-00#section-6.2\n        # At this time, no further effort has been made to replace SHA-1 for the OAuth Request Body Hash extension.\n        content_type = request.headers.get('Content-Type', None)\n        content_type_eligible = content_type and content_type.find('application/x-www-form-urlencoded') < 0\n        if request.body is not None and content_type_eligible:\n            params.append(('oauth_body_hash', base64.b64encode(hashlib.sha1(request.body.encode('utf-8')).digest()).decode('utf-8')))\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a signed request according to signature type.", "response": "def _render(self, request, formencode=False, realm=None):\n        \"\"\"Render a signed request according to signature type\n\n        Returns a 3-tuple containing the request URI, headers, and body.\n\n        If the formencode argument is True and the body contains parameters, it\n        is escaped and returned as a valid formencoded string.\n        \"\"\"\n        # TODO what if there are body params on a header-type auth?\n        # TODO what if there are query params on a body-type auth?\n\n        uri, headers, body = request.uri, request.headers, request.body\n\n        # TODO: right now these prepare_* methods are very narrow in scope--they\n        # only affect their little thing. In some cases (for example, with\n        # header auth) it might be advantageous to allow these methods to touch\n        # other parts of the request, like the headers\u2014so the prepare_headers\n        # method could also set the Content-Type header to x-www-form-urlencoded\n        # like the spec requires. This would be a fundamental change though, and\n        # I'm not sure how I feel about it.\n        if self.signature_type == SIGNATURE_TYPE_AUTH_HEADER:\n            headers = parameters.prepare_headers(\n                request.oauth_params, request.headers, realm=realm)\n        elif self.signature_type == SIGNATURE_TYPE_BODY and request.decoded_body is not None:\n            body = parameters.prepare_form_encoded_body(\n                request.oauth_params, request.decoded_body)\n            if formencode:\n                body = urlencode(body)\n            headers['Content-Type'] = 'application/x-www-form-urlencoded'\n        elif self.signature_type == SIGNATURE_TYPE_QUERY:\n            uri = parameters.prepare_request_uri_query(\n                request.oauth_params, request.uri)\n        else:\n            raise ValueError('Unknown signature type specified.')\n\n        return uri, headers, body"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign(self, uri, http_method='GET', body=None, headers=None, realm=None):\n        # normalize request data\n        request = Request(uri, http_method, body, headers,\n                          encoding=self.encoding)\n\n        # sanity check\n        content_type = request.headers.get('Content-Type', None)\n        multipart = content_type and content_type.startswith('multipart/')\n        should_have_params = content_type == CONTENT_TYPE_FORM_URLENCODED\n        has_params = request.decoded_body is not None\n        # 3.4.1.3.1.  Parameter Sources\n        # [Parameters are collected from the HTTP request entity-body, but only\n        # if [...]:\n        #    *  The entity-body is single-part.\n        if multipart and has_params:\n            raise ValueError(\n                \"Headers indicate a multipart body but body contains parameters.\")\n        #    *  The entity-body follows the encoding requirements of the\n        #       \"application/x-www-form-urlencoded\" content-type as defined by\n        #       [W3C.REC-html40-19980424].\n        elif should_have_params and not has_params:\n            raise ValueError(\n                \"Headers indicate a formencoded body but body was not decodable.\")\n        #    *  The HTTP request entity-header includes the \"Content-Type\"\n        #       header field set to \"application/x-www-form-urlencoded\".\n        elif not should_have_params and has_params:\n            raise ValueError(\n                \"Body contains parameters but Content-Type header was {0} \"\n                \"instead of {1}\".format(content_type or \"not set\",\n                                        CONTENT_TYPE_FORM_URLENCODED))\n\n        # 3.5.2.  Form-Encoded Body\n        # Protocol parameters can be transmitted in the HTTP request entity-\n        # body, but only if the following REQUIRED conditions are met:\n        # o  The entity-body is single-part.\n        # o  The entity-body follows the encoding requirements of the\n        #    \"application/x-www-form-urlencoded\" content-type as defined by\n        #    [W3C.REC-html40-19980424].\n        # o  The HTTP request entity-header includes the \"Content-Type\" header\n        #    field set to \"application/x-www-form-urlencoded\".\n        elif self.signature_type == SIGNATURE_TYPE_BODY and not (\n                should_have_params and has_params and not multipart):\n            raise ValueError(\n                'Body signatures may only be used with form-urlencoded content')\n\n        # We amend https://tools.ietf.org/html/rfc5849#section-3.4.1.3.1\n        # with the clause that parameters from body should only be included\n        # in non GET or HEAD requests. Extracting the request body parameters\n        # and including them in the signature base string would give semantic\n        # meaning to the body, which it should not have according to the\n        # HTTP 1.1 spec.\n        elif http_method.upper() in ('GET', 'HEAD') and has_params:\n            raise ValueError('GET/HEAD requests should not include body.')\n\n        # generate the basic OAuth parameters\n        request.oauth_params = self.get_oauth_params(request)\n\n        # generate the signature\n        request.oauth_params.append(\n            ('oauth_signature', self.get_oauth_signature(request)))\n\n        # render the signed request and return it\n        uri, headers, body = self._render(request, formencode=True,\n                                          realm=(realm or self.realm))\n\n        if self.decoding:\n            log.debug('Encoding URI, headers and body to %s.', self.decoding)\n            uri = uri.encode(self.decoding)\n            body = body.encode(self.decoding) if body else body\n            new_headers = {}\n            for k, v in headers.items():\n                new_headers[k.encode(self.decoding)] = v.encode(self.decoding)\n            headers = new_headers\n        return uri, headers, body", "response": "Sign a request with the specified parts."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise on failed client authentication.", "response": "def _raise_on_invalid_client(self, request):\n        \"\"\"Raise on failed client authentication.\"\"\"\n        if self.request_validator.client_authentication_required(request):\n            if not self.request_validator.authenticate_client(request):\n                log.debug('Client authentication failed, %r.', request)\n                raise InvalidClientError(request=request)\n        elif not self.request_validator.authenticate_client_id(request.client_id, request):\n            log.debug('Client authentication failed, %r.', request)\n            raise InvalidClientError(request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _raise_on_unsupported_token(self, request):\n        if (request.token_type_hint and\n            request.token_type_hint in self.valid_token_types and\n            request.token_type_hint not in self.supported_token_types):\n            raise UnsupportedTokenTypeError(request=request)", "response": "Raise on unsupported tokens."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a revocation response for the specified request.", "response": "def create_revocation_response(self, uri, http_method='POST', body=None,\n                                   headers=None):\n        \"\"\"Revoke supplied access or refresh token.\n\n\n        The authorization server responds with HTTP status code 200 if the\n        token has been revoked sucessfully or if the client submitted an\n        invalid token.\n\n        Note: invalid tokens do not cause an error response since the client\n        cannot handle such an error in a reasonable way.  Moreover, the purpose\n        of the revocation request, invalidating the particular token, is\n        already achieved.\n\n        The content of the response body is ignored by the client as all\n        necessary information is conveyed in the response code.\n\n        An invalid token type hint value is ignored by the authorization server\n        and does not influence the revocation response.\n        \"\"\"\n        resp_headers = {\n            'Content-Type': 'application/json',\n            'Cache-Control': 'no-store',\n            'Pragma': 'no-cache',\n        }\n        request = Request(\n            uri, http_method=http_method, body=body, headers=headers)\n        try:\n            self.validate_revocation_request(request)\n            log.debug('Token revocation valid for %r.', request)\n        except OAuth2Error as e:\n            log.debug('Client error during validation of %r. %r.', request, e)\n            response_body = e.json\n            if self.enable_jsonp and request.callback:\n                response_body = '%s(%s);' % (request.callback, response_body)\n            resp_headers.update(e.headers)\n            return resp_headers, response_body, e.status_code\n\n        self.request_validator.revoke_token(request.token,\n                                            request.token_type_hint, request)\n\n        response_body = ''\n        if self.enable_jsonp and request.callback:\n            response_body = request.callback + '();'\n        return {}, response_body, 200"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures the request is valid for revocation.", "response": "def validate_revocation_request(self, request):\n        \"\"\"Ensure the request is valid.\n\n        The client constructs the request by including the following parameters\n        using the \"application/x-www-form-urlencoded\" format in the HTTP\n        request entity-body:\n\n        token (REQUIRED).  The token that the client wants to get revoked.\n\n        token_type_hint (OPTIONAL).  A hint about the type of the token\n        submitted for revocation.  Clients MAY pass this parameter in order to\n        help the authorization server to optimize the token lookup.  If the\n        server is unable to locate the token using the given hint, it MUST\n        extend its search accross all of its supported token types.  An\n        authorization server MAY ignore this parameter, particularly if it is\n        able to detect the token type automatically.  This specification\n        defines two such values:\n\n                *  access_token: An Access Token as defined in [RFC6749],\n                    `section 1.4`_\n\n                *  refresh_token: A Refresh Token as defined in [RFC6749],\n                    `section 1.5`_\n\n                Specific implementations, profiles, and extensions of this\n                specification MAY define other values for this parameter using\n                the registry defined in `Section 4.1.2`_.\n\n        The client also includes its authentication credentials as described in\n        `Section 2.3`_. of [`RFC6749`_].\n\n        .. _`section 1.4`: https://tools.ietf.org/html/rfc6749#section-1.4\n        .. _`section 1.5`: https://tools.ietf.org/html/rfc6749#section-1.5\n        .. _`section 2.3`: https://tools.ietf.org/html/rfc6749#section-2.3\n        .. _`Section 4.1.2`: https://tools.ietf.org/html/draft-ietf-oauth-revocation-11#section-4.1.2\n        .. _`RFC6749`: https://tools.ietf.org/html/rfc6749\n        \"\"\"\n        self._raise_on_missing_token(request)\n        self._raise_on_invalid_client(request)\n        self._raise_on_unsupported_token(request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_token(self, token, token_handler, request):\n        # Only add a hybrid access token on auth step if asked for\n        if not request.response_type in [\"token\", \"code token\", \"id_token token\", \"code id_token token\"]:\n            return token\n\n        token.update(token_handler.create_token(request, refresh_token=False))\n        return token", "response": "Add a token to the token list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the grant type of the user is allowed to access the object.", "response": "def validate_grant_type(self, request):\n        \"\"\"\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        \"\"\"\n        client_id = getattr(request, 'client_id', None)\n        if not self.request_validator.validate_grant_type(client_id,\n                                                          request.grant_type, request.client, request):\n            log.debug('Unauthorized from %r (%r) access to grant type %s.',\n                      request.client_id, request.client, request.grant_type)\n            raise errors.UnauthorizedClientError(request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_scopes(self, request):\n        if not request.scopes:\n            request.scopes = utils.scope_to_list(request.scope) or utils.scope_to_list(\n                self.request_validator.get_default_scopes(request.client_id, request))\n        log.debug('Validating access to scopes %r for client %r (%r).',\n                  request.scopes, request.client_id, request.client)\n        if not self.request_validator.validate_scopes(request.client_id,\n                                                      request.scopes, request.client, request):\n            raise errors.InvalidScopeError(request=request)", "response": "Validate the scopes for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_authorization_response(self, request, token, headers, body, status):\n        request.response_mode = request.response_mode or self.default_response_mode\n\n        if request.response_mode not in ('query', 'fragment'):\n            log.debug('Overriding invalid response mode %s with %s',\n                      request.response_mode, self.default_response_mode)\n            request.response_mode = self.default_response_mode\n\n        token_items = token.items()\n\n        if request.response_type == 'none':\n            state = token.get('state', None)\n            if state:\n                token_items = [('state', state)]\n            else:\n                token_items = []\n\n        if request.response_mode == 'query':\n            headers['Location'] = add_params_to_uri(\n                request.redirect_uri, token_items, fragment=False)\n            return headers, body, status\n\n        if request.response_mode == 'fragment':\n            headers['Location'] = add_params_to_uri(\n                request.redirect_uri, token_items, fragment=True)\n            return headers, body, status\n\n        raise NotImplementedError(\n            'Subclasses must set a valid default_response_mode')", "response": "Prepare the authorization response for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_mac_header(token, uri, key, http_method,\n                       nonce=None,\n                       headers=None,\n                       body=None,\n                       ext='',\n                       hash_algorithm='hmac-sha-1',\n                       issue_time=None,\n                       draft=0):\n    \"\"\"Add an `MAC Access Authentication`_ signature to headers.\n\n    Unlike OAuth 1, this HMAC signature does not require inclusion of the\n    request payload/body, neither does it use a combination of client_secret\n    and token_secret but rather a mac_key provided together with the access\n    token.\n\n    Currently two algorithms are supported, \"hmac-sha-1\" and \"hmac-sha-256\",\n    `extension algorithms`_ are not supported.\n\n    Example MAC Authorization header, linebreaks added for clarity\n\n    Authorization: MAC id=\"h480djs93hd8\",\n                       nonce=\"1336363200:dj83hs9s\",\n                       mac=\"bhCQXTVyfj5cmA9uKkPFx1zeOXM=\"\n\n    .. _`MAC Access Authentication`: https://tools.ietf.org/html/draft-ietf-oauth-v2-http-mac-01\n    .. _`extension algorithms`: https://tools.ietf.org/html/draft-ietf-oauth-v2-http-mac-01#section-7.1\n\n    :param token:\n    :param uri: Request URI.\n    :param key: MAC given provided by token endpoint.\n    :param http_method: HTTP Request method.\n    :param nonce:\n    :param headers: Request headers as a dictionary.\n    :param body:\n    :param ext:\n    :param hash_algorithm: HMAC algorithm provided by token endpoint.\n    :param issue_time: Time when the MAC credentials were issued (datetime).\n    :param draft: MAC authentication specification version.\n    :return: headers dictionary with the authorization field added.\n    \"\"\"\n    http_method = http_method.upper()\n    host, port = utils.host_from_uri(uri)\n\n    if hash_algorithm.lower() == 'hmac-sha-1':\n        h = hashlib.sha1\n    elif hash_algorithm.lower() == 'hmac-sha-256':\n        h = hashlib.sha256\n    else:\n        raise ValueError('unknown hash algorithm')\n\n    if draft == 0:\n        nonce = nonce or '{0}:{1}'.format(utils.generate_age(issue_time),\n                                          common.generate_nonce())\n    else:\n        ts = common.generate_timestamp()\n        nonce = common.generate_nonce()\n\n    sch, net, path, par, query, fra = urlparse(uri)\n\n    if query:\n        request_uri = path + '?' + query\n    else:\n        request_uri = path\n\n    # Hash the body/payload\n    if body is not None and draft == 0:\n        body = body.encode('utf-8')\n        bodyhash = b2a_base64(h(body).digest())[:-1].decode('utf-8')\n    else:\n        bodyhash = ''\n\n    # Create the normalized base string\n    base = []\n    if draft == 0:\n        base.append(nonce)\n    else:\n        base.append(ts)\n        base.append(nonce)\n    base.append(http_method.upper())\n    base.append(request_uri)\n    base.append(host)\n    base.append(port)\n    if draft == 0:\n        base.append(bodyhash)\n    base.append(ext or '')\n    base_string = '\\n'.join(base) + '\\n'\n\n    # hmac struggles with unicode strings - http://bugs.python.org/issue5285\n    if isinstance(key, unicode_type):\n        key = key.encode('utf-8')\n    sign = hmac.new(key, base_string.encode('utf-8'), h)\n    sign = b2a_base64(sign.digest())[:-1].decode('utf-8')\n\n    header = []\n    header.append('MAC id=\"%s\"' % token)\n    if draft != 0:\n        header.append('ts=\"%s\"' % ts)\n    header.append('nonce=\"%s\"' % nonce)\n    if bodyhash:\n        header.append('bodyhash=\"%s\"' % bodyhash)\n    if ext:\n        header.append('ext=\"%s\"' % ext)\n    header.append('mac=\"%s\"' % sign)\n\n    headers = headers or {}\n    headers['Authorization'] = ', '.join(header)\n    return headers", "response": "Prepares the MAC Authorization header for the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signed_token_generator(private_pem, **kwargs):\n    def signed_token_generator(request):\n        request.claims = kwargs\n        return common.generate_signed_token(private_pem, request)\n\n    return signed_token_generator", "response": "Returns a function that generates a signed token for the given private_pem."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_token_from_header(request):\n    token = None\n\n    if 'Authorization' in request.headers:\n        split_header = request.headers.get('Authorization').split()\n        if len(split_header) == 2 and split_header[0] == 'Bearer':\n            token = split_header[1]\n    else:\n        token = request.access_token\n\n    return token", "response": "Helper function to extract a token from the Authorization header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a BearerToken by default without refresh token.", "response": "def create_token(self, request, refresh_token=False, **kwargs):\n        \"\"\"\n        Create a BearerToken, by default without refresh token.\n\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        :param refresh_token:\n        \"\"\"\n        if \"save_token\" in kwargs:\n            warnings.warn(\"`save_token` has been deprecated, it was not called internally.\"\n                          \"If you do, call `request_validator.save_token()` instead.\",\n                          DeprecationWarning)\n\n        if callable(self.expires_in):\n            expires_in = self.expires_in(request)\n        else:\n            expires_in = self.expires_in\n\n        request.expires_in = expires_in\n\n        token = {\n            'access_token': self.token_generator(request),\n            'expires_in': expires_in,\n            'token_type': 'Bearer',\n        }\n\n        # If provided, include - this is optional in some cases https://tools.ietf.org/html/rfc6749#section-3.3 but\n        # there is currently no mechanism to coordinate issuing a token for only a subset of the requested scopes so\n        # all tokens issued are for the entire set of requested scopes.\n        if request.scopes is not None:\n            token['scope'] = ' '.join(request.scopes)\n\n        if refresh_token:\n            if (request.refresh_token and\n                    not self.request_validator.rotate_refresh_token(request)):\n                token['refresh_token'] = request.refresh_token\n            else:\n                token['refresh_token'] = self.refresh_token_generator(request)\n\n        token.update(request.extra_credentials or {})\n        return OAuth2Token(token)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a list of scopes to a space separated string.", "response": "def list_to_scope(scope):\n    \"\"\"Convert a list of scopes to a space separated string.\"\"\"\n    if isinstance(scope, unicode_type) or scope is None:\n        return scope\n    elif isinstance(scope, (set, tuple, list)):\n        return \" \".join([unicode_type(s) for s in scope])\n    else:\n        raise ValueError(\"Invalid scope (%s), must be string, tuple, set, or list.\" % scope)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a space separated string to a list of scopes.", "response": "def scope_to_list(scope):\n    \"\"\"Convert a space separated string to a list of scopes.\"\"\"\n    if isinstance(scope, (tuple, list, set)):\n        return [unicode_type(s) for s in scope]\n    elif scope is None:\n        return None\n    else:\n        return scope.strip().split(\" \")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef host_from_uri(uri):\n    default_ports = {\n        'HTTP': '80',\n        'HTTPS': '443',\n    }\n\n    sch, netloc, path, par, query, fra = urlparse(uri)\n    if ':' in netloc:\n        netloc, port = netloc.split(':', 1)\n    else:\n        port = default_ports.get(sch.upper())\n\n    return netloc, port", "response": "Extract hostname and port from URI."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef escape(u):\n    if not isinstance(u, unicode_type):\n        raise ValueError('Only unicode objects are escapable.')\n    return quote(u.encode('utf-8'), safe=b'~')", "response": "Escape a string in an OAuth - compatible fashion."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_age(issue_time):\n    td = datetime.datetime.now() - issue_time\n    age = (td.microseconds + (td.seconds + td.days * 24 * 3600)\n           * 10 ** 6) / 10 ** 6\n    return unicode_type(age)", "response": "Generate a age parameter for MAC authentication draft 00."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_protected_resource_request(self, uri, http_method='GET',\n                                            body=None, headers=None, realms=None):\n        \"\"\"Create a request token response, with a new request token if valid.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :param realms: A list of realms the resource is protected under.\n                       This will be supplied to the ``validate_realms``\n                       method of the request validator.\n        :returns: A tuple of 2 elements.\n                  1. True if valid, False otherwise.\n                  2. An oauthlib.common.Request object.\n        \"\"\"\n        try:\n            request = self._create_request(uri, http_method, body, headers)\n        except errors.OAuth1Error:\n            return False, None\n\n        try:\n            self._check_transport_security(request)\n            self._check_mandatory_parameters(request)\n        except errors.OAuth1Error:\n            return False, request\n\n        if not request.resource_owner_key:\n            return False, request\n\n        if not self.request_validator.check_access_token(\n                request.resource_owner_key):\n            return False, request\n\n        if not self.request_validator.validate_timestamp_and_nonce(\n                request.client_key, request.timestamp, request.nonce, request,\n                access_token=request.resource_owner_key):\n            return False, request\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid client credentials.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy client is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable client enumeration\n        valid_client = self.request_validator.validate_client_key(\n            request.client_key, request)\n        if not valid_client:\n            request.client_key = self.request_validator.dummy_client\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid or expired token.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy token is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable resource owner enumeration\n        valid_resource_owner = self.request_validator.validate_access_token(\n            request.client_key, request.resource_owner_key, request)\n        if not valid_resource_owner:\n            request.resource_owner_key = self.request_validator.dummy_access_token\n\n        # Note that `realm`_ is only used in authorization headers and how\n        # it should be interepreted is not included in the OAuth spec.\n        # However they could be seen as a scope or realm to which the\n        # client has access and as such every client should be checked\n        # to ensure it is authorized access to that scope or realm.\n        # .. _`realm`: https://tools.ietf.org/html/rfc2617#section-1.2\n        #\n        # Note that early exit would enable client realm access enumeration.\n        #\n        # The require_realm indicates this is the first step in the OAuth\n        # workflow where a client requests access to a specific realm.\n        # This first step (obtaining request token) need not require a realm\n        # and can then be identified by checking the require_resource_owner\n        # flag and abscence of realm.\n        #\n        # Clients obtaining an access token will not supply a realm and it will\n        # not be checked. Instead the previously requested realm should be\n        # transferred from the request token to the access token.\n        #\n        # Access to protected resources will always validate the realm but note\n        # that the realm is now tied to the access token and not provided by\n        # the client.\n        valid_realm = self.request_validator.validate_realms(request.client_key,\n                                                             request.resource_owner_key, request, uri=request.uri,\n                                                             realms=realms)\n\n        valid_signature = self._check_signature(request)\n\n        # log the results to the validator_log\n        # this lets us handle internal reporting and analysis\n        request.validator_log['client'] = valid_client\n        request.validator_log['resource_owner'] = valid_resource_owner\n        request.validator_log['realm'] = valid_realm\n        request.validator_log['signature'] = valid_signature\n\n        # We delay checking validity until the very end, using dummy values for\n        # calculations and fetching secrets/keys to ensure the flow of every\n        # request remains almost identical regardless of whether valid values\n        # have been supplied. This ensures near constant time execution and\n        # prevents malicious users from guessing sensitive information\n        v = all((valid_client, valid_resource_owner, valid_realm,\n                 valid_signature))\n        if not v:\n            log.info(\"[Failure] request verification failed.\")\n            log.info(\"Valid client: %s\", valid_client)\n            log.info(\"Valid token: %s\", valid_resource_owner)\n            log.info(\"Valid realm: %s\", valid_realm)\n            log.info(\"Valid signature: %s\", valid_signature)\n        return v, request", "response": "Validate a protected resource request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a token response for the given request and token_handler.", "response": "def create_token_response(self, request, token_handler):\n        \"\"\"Return token or error embedded in the URI fragment.\n\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n        :param token_handler: A token handler instance, for example of type\n                              oauthlib.oauth2.BearerToken.\n\n        If the resource owner grants the access request, the authorization\n        server issues an access token and delivers it to the client by adding\n        the following parameters to the fragment component of the redirection\n        URI using the \"application/x-www-form-urlencoded\" format, per\n        `Appendix B`_:\n\n        access_token\n                REQUIRED.  The access token issued by the authorization server.\n\n        token_type\n                REQUIRED.  The type of the token issued as described in\n                `Section 7.1`_.  Value is case insensitive.\n\n        expires_in\n                RECOMMENDED.  The lifetime in seconds of the access token.  For\n                example, the value \"3600\" denotes that the access token will\n                expire in one hour from the time the response was generated.\n                If omitted, the authorization server SHOULD provide the\n                expiration time via other means or document the default value.\n\n        scope\n                OPTIONAL, if identical to the scope requested by the client;\n                otherwise, REQUIRED.  The scope of the access token as\n                described by `Section 3.3`_.\n\n        state\n                REQUIRED if the \"state\" parameter was present in the client\n                authorization request.  The exact value received from the\n                client.\n\n        The authorization server MUST NOT issue a refresh token.\n\n        .. _`Appendix B`: https://tools.ietf.org/html/rfc6749#appendix-B\n        .. _`Section 3.3`: https://tools.ietf.org/html/rfc6749#section-3.3\n        .. _`Section 7.1`: https://tools.ietf.org/html/rfc6749#section-7.1\n        \"\"\"\n        try:\n            self.validate_token_request(request)\n\n        # If the request fails due to a missing, invalid, or mismatching\n        # redirection URI, or if the client identifier is missing or invalid,\n        # the authorization server SHOULD inform the resource owner of the\n        # error and MUST NOT automatically redirect the user-agent to the\n        # invalid redirection URI.\n        except errors.FatalClientError as e:\n            log.debug('Fatal client error during validation of %r. %r.',\n                      request, e)\n            raise\n\n        # If the resource owner denies the access request or if the request\n        # fails for reasons other than a missing or invalid redirection URI,\n        # the authorization server informs the client by adding the following\n        # parameters to the fragment component of the redirection URI using the\n        # \"application/x-www-form-urlencoded\" format, per Appendix B:\n        # https://tools.ietf.org/html/rfc6749#appendix-B\n        except errors.OAuth2Error as e:\n            log.debug('Client error during validation of %r. %r.', request, e)\n            return {'Location': common.add_params_to_uri(request.redirect_uri, e.twotuples,\n                                                         fragment=True)}, None, 302\n\n        # In OIDC implicit flow it is possible to have a request_type that does not include the access_token!\n        # \"id_token token\" - return the access token and the id token\n        # \"id_token\" - don't return the access token\n        if \"token\" in request.response_type.split():\n            token = token_handler.create_token(request, refresh_token=False)\n        else:\n            token = {}\n\n        if request.state is not None:\n            token['state'] = request.state\n\n        for modifier in self._token_modifiers:\n            token = modifier(token, token_handler, request)\n\n        # In OIDC implicit flow it is possible to have a request_type that does\n        # not include the access_token! In this case there is no need to save a token.\n        if \"token\" in request.response_type.split():\n            self.request_validator.save_token(token, request)\n\n        return self.prepare_authorization_response(\n            request, token, {}, None, 302)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the request for normal and fatal errors.", "response": "def validate_token_request(self, request):\n        \"\"\"Check the token request for normal and fatal errors.\n\n        :param request: OAuthlib request.\n        :type request: oauthlib.common.Request\n\n        This method is very similar to validate_authorization_request in\n        the AuthorizationCodeGrant but differ in a few subtle areas.\n\n        A normal error could be a missing response_type parameter or the client\n        attempting to access scope it is not allowed to ask authorization for.\n        Normal errors can safely be included in the redirection URI and\n        sent back to the client.\n\n        Fatal errors occur when the client_id or redirect_uri is invalid or\n        missing. These must be caught by the provider and handled, how this\n        is done is outside of the scope of OAuthLib but showing an error\n        page describing the issue is a good idea.\n        \"\"\"\n\n        # First check for fatal errors\n\n        # If the request fails due to a missing, invalid, or mismatching\n        # redirection URI, or if the client identifier is missing or invalid,\n        # the authorization server SHOULD inform the resource owner of the\n        # error and MUST NOT automatically redirect the user-agent to the\n        # invalid redirection URI.\n\n        # First check duplicate parameters\n        for param in ('client_id', 'response_type', 'redirect_uri', 'scope', 'state'):\n            try:\n                duplicate_params = request.duplicate_params\n            except ValueError:\n                raise errors.InvalidRequestFatalError(description='Unable to parse query string', request=request)\n            if param in duplicate_params:\n                raise errors.InvalidRequestFatalError(description='Duplicate %s parameter.' % param, request=request)\n\n        # REQUIRED. The client identifier as described in Section 2.2.\n        # https://tools.ietf.org/html/rfc6749#section-2.2\n        if not request.client_id:\n            raise errors.MissingClientIdError(request=request)\n\n        if not self.request_validator.validate_client_id(request.client_id, request):\n            raise errors.InvalidClientIdError(request=request)\n\n        # OPTIONAL. As described in Section 3.1.2.\n        # https://tools.ietf.org/html/rfc6749#section-3.1.2\n        self._handle_redirects(request)\n\n        # Then check for normal errors.\n\n        request_info = self._run_custom_validators(request,\n                                                   self.custom_validators.all_pre)\n\n        # If the resource owner denies the access request or if the request\n        # fails for reasons other than a missing or invalid redirection URI,\n        # the authorization server informs the client by adding the following\n        # parameters to the fragment component of the redirection URI using the\n        # \"application/x-www-form-urlencoded\" format, per Appendix B.\n        # https://tools.ietf.org/html/rfc6749#appendix-B\n\n        # Note that the correct parameters to be added are automatically\n        # populated through the use of specific exceptions\n\n        # REQUIRED.\n        if request.response_type is None:\n            raise errors.MissingResponseTypeError(request=request)\n        # Value MUST be one of our registered types: \"token\" by default or if using OIDC \"id_token\" or \"id_token token\"\n        elif not set(request.response_type.split()).issubset(self.response_types):\n            raise errors.UnsupportedResponseTypeError(request=request)\n\n        log.debug('Validating use of response_type token for client %r (%r).',\n                  request.client_id, request.client)\n        if not self.request_validator.validate_response_type(request.client_id,\n                                                             request.response_type,\n                                                             request.client, request):\n\n            log.debug('Client %s is not authorized to use response_type %s.',\n                      request.client_id, request.response_type)\n            raise errors.UnauthorizedClientError(request=request)\n\n        # OPTIONAL. The scope of the access request as described by Section 3.3\n        # https://tools.ietf.org/html/rfc6749#section-3.3\n        self.validate_scopes(request)\n\n        request_info.update({\n            'client_id': request.client_id,\n            'redirect_uri': request.redirect_uri,\n            'response_type': request.response_type,\n            'state': request.state,\n            'request': request,\n        })\n\n        request_info = self._run_custom_validators(\n            request,\n            self.custom_validators.all_post,\n            request_info\n        )\n\n        return request.scopes, request_info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_authorization_request(self, request):\n        # If request.prompt is 'none' then no login/authorization form should\n        # be presented to the user. Instead, a silent login/authorization\n        # should be performed.\n        if request.prompt == 'none':\n            raise OIDCNoPrompt()\n        else:\n            return self.proxy_target.validate_authorization_request(request)", "response": "Validates the OpenID Connect authorization request parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef openid_authorization_validator(self, request):\n\n        # Treat it as normal OAuth 2 auth code request if openid is not present\n        if not request.scopes or 'openid' not in request.scopes:\n            return {}\n\n        prompt = request.prompt if request.prompt else []\n        if hasattr(prompt, 'split'):\n            prompt = prompt.strip().split()\n        prompt = set(prompt)\n\n        if 'none' in prompt:\n\n            if len(prompt) > 1:\n                msg = \"Prompt none is mutually exclusive with other values.\"\n                raise InvalidRequestError(request=request, description=msg)\n\n            if not self.request_validator.validate_silent_login(request):\n                raise LoginRequired(request=request)\n\n            if not self.request_validator.validate_silent_authorization(request):\n                raise ConsentRequired(request=request)\n\n        self._inflate_claims(request)\n\n        if not self.request_validator.validate_user_match(\n                request.id_token_hint, request.scopes, request.claims, request):\n            msg = \"Session user does not match client supplied user.\"\n            raise LoginRequired(request=request, description=msg)\n\n        request_info = {\n            'display': request.display,\n            'nonce': request.nonce,\n            'prompt': prompt,\n            'ui_locales': request.ui_locales.split() if request.ui_locales else [],\n            'id_token_hint': request.id_token_hint,\n            'login_hint': request.login_hint,\n            'claims': request.claims\n        }\n\n        return request_info", "response": "Perform OpenID Connect specific authorization request validation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef openid_authorization_validator(self, request):\n        request_info = super(HybridGrant, self).openid_authorization_validator(request)\n        if not request_info:  # returns immediately if OAuth2.0\n            return request_info\n\n        # REQUIRED if the Response Type of the request is `code\n        # id_token` or `code id_token token` and OPTIONAL when the\n        # Response Type of the request is `code token`. It is a string\n        # value used to associate a Client session with an ID Token,\n        # and to mitigate replay attacks. The value is passed through\n        # unmodified from the Authentication Request to the ID\n        # Token. Sufficient entropy MUST be present in the `nonce`\n        # values used to prevent attackers from guessing values. For\n        # implementation notes, see Section 15.5.2.\n        if request.response_type in [\"code id_token\", \"code id_token token\"]:\n            if not request.nonce:\n                raise InvalidRequestError(\n                    request=request,\n                    description='Request is missing mandatory nonce parameter.'\n                )\n        return request_info", "response": "Additional validation when following the Authorization Code flow."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_oauth_params(params):\n    is_oauth = lambda kv: kv[0].startswith(\"oauth_\")\n    if isinstance(params, dict):\n        return list(filter(is_oauth, list(params.items())))\n    else:\n        return list(filter(is_oauth, params))", "response": "Removes all non oauth parameters from a dict or a list of params."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an OAuth authorization header into a list of 2 - tuples", "response": "def parse_authorization_header(authorization_header):\n    \"\"\"Parse an OAuth authorization header into a list of 2-tuples\"\"\"\n    auth_scheme = 'OAuth '.lower()\n    if authorization_header[:len(auth_scheme)].lower().startswith(auth_scheme):\n        items = parse_http_list(authorization_header[len(auth_scheme):])\n        try:\n            return list(parse_keqv_list(items).items())\n        except (IndexError, ValueError):\n            pass\n    raise ValueError('Malformed authorization header')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_access_token(self, request, credentials):\n        request.realms = self.request_validator.get_realms(\n            request.resource_owner_key, request)\n        token = {\n            'oauth_token': self.token_generator(),\n            'oauth_token_secret': self.token_generator(),\n            # Backport the authorized scopes indication used in OAuth2\n            'oauth_authorized_realms': ' '.join(request.realms)\n        }\n        token.update(credentials)\n        self.request_validator.save_access_token(token, request)\n        return urlencode(token.items())", "response": "Create and save a new access token."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an access token response.", "response": "def create_access_token_response(self, uri, http_method='GET', body=None,\n                                     headers=None, credentials=None):\n        \"\"\"Create an access token response, with a new request token if valid.\n\n        :param uri: The full URI of the token request.\n        :param http_method: A valid HTTP verb, i.e. GET, POST, PUT, HEAD, etc.\n        :param body: The request body as a string.\n        :param headers: The request headers as a dict.\n        :param credentials: A list of extra credentials to include in the token.\n        :returns: A tuple of 3 elements.\n                  1. A dict of headers to set on the response.\n                  2. The response body as a string.\n                  3. The response status code as an integer.\n\n        An example of a valid request::\n\n            >>> from your_validator import your_validator\n            >>> from oauthlib.oauth1 import AccessTokenEndpoint\n            >>> endpoint = AccessTokenEndpoint(your_validator)\n            >>> h, b, s = endpoint.create_access_token_response(\n            ...     'https://your.provider/access_token?foo=bar',\n            ...     headers={\n            ...         'Authorization': 'OAuth oauth_token=234lsdkf....'\n            ...     },\n            ...     credentials={\n            ...         'my_specific': 'argument',\n            ...     })\n            >>> h\n            {'Content-Type': 'application/x-www-form-urlencoded'}\n            >>> b\n            'oauth_token=lsdkfol23w54jlksdef&oauth_token_secret=qwe089234lkjsdf&oauth_authorized_realms=movies+pics&my_specific=argument'\n            >>> s\n            200\n\n        An response to invalid request would have a different body and status::\n\n            >>> b\n            'error=invalid_request&description=missing+resource+owner+key'\n            >>> s\n            400\n\n        The same goes for an an unauthorized request:\n\n            >>> b\n            ''\n            >>> s\n            401\n        \"\"\"\n        resp_headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n        try:\n            request = self._create_request(uri, http_method, body, headers)\n            valid, processed_request = self.validate_access_token_request(\n                request)\n            if valid:\n                token = self.create_access_token(request, credentials or {})\n                self.request_validator.invalidate_request_token(\n                    request.client_key,\n                    request.resource_owner_key,\n                    request)\n                return resp_headers, token, 200\n            else:\n                return {}, None, 401\n        except errors.OAuth1Error as e:\n            return resp_headers, e.urlencoded, e.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_access_token_request(self, request):\n        self._check_transport_security(request)\n        self._check_mandatory_parameters(request)\n\n        if not request.resource_owner_key:\n            raise errors.InvalidRequestError(\n                description='Missing resource owner.')\n\n        if not self.request_validator.check_request_token(\n                request.resource_owner_key):\n            raise errors.InvalidRequestError(\n                description='Invalid resource owner key format.')\n\n        if not request.verifier:\n            raise errors.InvalidRequestError(\n                description='Missing verifier.')\n\n        if not self.request_validator.check_verifier(request.verifier):\n            raise errors.InvalidRequestError(\n                description='Invalid verifier format.')\n\n        if not self.request_validator.validate_timestamp_and_nonce(\n                request.client_key, request.timestamp, request.nonce, request,\n                request_token=request.resource_owner_key):\n            return False, request\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid client credentials.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy client is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable client enumeration\n        valid_client = self.request_validator.validate_client_key(\n            request.client_key, request)\n        if not valid_client:\n            request.client_key = self.request_validator.dummy_client\n\n        # The server SHOULD return a 401 (Unauthorized) status code when\n        # receiving a request with invalid or expired token.\n        # Note: This is postponed in order to avoid timing attacks, instead\n        # a dummy token is assigned and used to maintain near constant\n        # time request verification.\n        #\n        # Note that early exit would enable resource owner enumeration\n        valid_resource_owner = self.request_validator.validate_request_token(\n            request.client_key, request.resource_owner_key, request)\n        if not valid_resource_owner:\n            request.resource_owner_key = self.request_validator.dummy_request_token\n\n        # The server MUST verify (Section 3.2) the validity of the request,\n        # ensure that the resource owner has authorized the provisioning of\n        # token credentials to the client, and ensure that the temporary\n        # credentials have not expired or been used before.  The server MUST\n        # also verify the verification code received from the client.\n        # .. _`Section 3.2`: https://tools.ietf.org/html/rfc5849#section-3.2\n        #\n        # Note that early exit would enable resource owner authorization\n        # verifier enumertion.\n        valid_verifier = self.request_validator.validate_verifier(\n            request.client_key,\n            request.resource_owner_key,\n            request.verifier,\n            request)\n\n        valid_signature = self._check_signature(request, is_token_request=True)\n\n        # log the results to the validator_log\n        # this lets us handle internal reporting and analysis\n        request.validator_log['client'] = valid_client\n        request.validator_log['resource_owner'] = valid_resource_owner\n        request.validator_log['verifier'] = valid_verifier\n        request.validator_log['signature'] = valid_signature\n\n        # We delay checking validity until the very end, using dummy values for\n        # calculations and fetching secrets/keys to ensure the flow of every\n        # request remains almost identical regardless of whether valid values\n        # have been supplied. This ensures near constant time execution and\n        # prevents malicious users from guessing sensitive information\n        v = all((valid_client, valid_resource_owner, valid_verifier,\n                 valid_signature))\n        if not v:\n            log.info(\"[Failure] request verification failed.\")\n            log.info(\"Valid client:, %s\", valid_client)\n            log.info(\"Valid token:, %s\", valid_resource_owner)\n            log.info(\"Valid verifier:, %s\", valid_verifier)\n            log.info(\"Valid signature:, %s\", valid_signature)\n        return v, request", "response": "Validate an access token request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_request(self, uri, http_method='GET', body=None, headers=None,\n                       scopes=None):\n        \"\"\"Validate client, code etc, return body + headers\"\"\"\n        request = Request(uri, http_method, body, headers)\n        request.token_type = self.find_token_type(request)\n        request.scopes = scopes\n        token_type_handler = self.tokens.get(request.token_type,\n                                             self.default_token_type_handler)\n        log.debug('Dispatching token_type %s request to %r.',\n                  request.token_type, token_type_handler)\n        return token_type_handler.validate_request(request), request", "response": "Validate the request and return the response body + headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_token_type(self, request):\n        estimates = sorted(((t.estimate_type(request), n)\n                            for n, t in self.tokens.items()), reverse=True)\n        return estimates[0][1] if len(estimates) else None", "response": "Find the most likely token type for the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef val_accuracy(show_swap):\n    kv = kernel_ver()\n    pid = os.getpid()\n    swap_accuracy = -1\n    if kv[:2] == (2,4):\n        if proc.open('meminfo').read().find(\"Inact_\") == -1:\n            return 1, swap_accuracy\n        return 0, swap_accuracy\n    elif kv[:2] == (2,6):\n        if os.path.exists(proc.path(pid, 'smaps')):\n            swap_accuracy = 1\n            if proc.open(pid, 'smaps').read().find(\"Pss:\")!=-1:\n                return 2, swap_accuracy\n            else:\n                return 1, swap_accuracy\n        if (2,6,1) <= kv <= (2,6,9):\n            return -1, swap_accuracy\n        return 0, swap_accuracy\n    elif kv[0] > 2 and os.path.exists(proc.path(pid, 'smaps')):\n        swap_accuracy = 1\n        if show_swap and proc.open(pid, 'smaps').read().find(\"SwapPss:\")!=-1:\n            swap_accuracy = 2\n        return 2, swap_accuracy\n    else:\n        return 1, swap_accuracy", "response": "Return the current value of the Accuracy field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_file(file_path):\n        log.debug('read data from {0}'.format(file_path))\n        if os.path.exists(file_path):\n            with open(file_path) as f:\n                json_data = json.load(f)\n\n            tf_state = Tfstate(json_data)\n            tf_state.tfstate_file = file_path\n            return tf_state\n\n        log.debug('{0} is not exist'.format(file_path))\n\n        return Tfstate()", "response": "Read the tfstate file and load its contents as JSON and put the result into the object\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, dir_or_plan=None, input=False, skip_plan=False, no_color=IsFlagged,\n              **kwargs):\n        \"\"\"\n        refer to https://terraform.io/docs/commands/apply.html\n        no-color is flagged by default\n        :param no_color: disable color of stdout\n        :param input: disable prompt for a missing variable\n        :param dir_or_plan: folder relative to working folder\n        :param skip_plan: force apply without plan (default: false)\n        :param kwargs: same as kwags in method 'cmd'\n        :returns return_code, stdout, stderr\n        \"\"\"\n        default = kwargs\n        default['input'] = input\n        default['no_color'] = no_color\n        default['auto-approve'] = (skip_plan == True)\n        option_dict = self._generate_default_options(default)\n        args = self._generate_default_args(dir_or_plan)\n        return self.cmd('apply', *args, **option_dict)", "response": "Wrapper for the command apply"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndestroys the current resource store", "response": "def destroy(self, dir_or_plan=None, force=IsFlagged, **kwargs):\n        \"\"\"\n        refer to https://www.terraform.io/docs/commands/destroy.html\n        force/no-color option is flagged by default\n        :return: ret_code, stdout, stderr\n        \"\"\"\n        default = kwargs\n        default['force'] = force\n        options = self._generate_default_options(default)\n        args = self._generate_default_args(dir_or_plan)\n        return self.cmd('destroy', *args, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plan(self, dir_or_plan=None, detailed_exitcode=IsFlagged, **kwargs):\n        options = kwargs\n        options['detailed_exitcode'] = detailed_exitcode\n        options = self._generate_default_options(options)\n        args = self._generate_default_args(dir_or_plan)\n        return self.cmd('plan', *args, **options)", "response": "Execute the plan command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrefers to https://www.terraform.io/docs/commands/init.html By default, this assumes you want to use backend config, and tries to init fresh. The flags -reconfigure and -backend=true are default. :param dir_or_plan: relative path to the folder want to init :param backend_config: a dictionary of backend config options. eg. t = Terraform() t.init(backend_config={'access_key': 'myaccesskey', 'secret_key': 'mysecretkey', 'bucket': 'mybucketname'}) :param reconfigure: whether or not to force reconfiguration of backend :param backend: whether or not to use backend settings for init :param kwargs: options :return: ret_code, stdout, stderr", "response": "def init(self, dir_or_plan=None, backend_config=None,\n             reconfigure=IsFlagged, backend=True, **kwargs):\n        \"\"\"\n        refer to https://www.terraform.io/docs/commands/init.html\n\n        By default, this assumes you want to use backend config, and tries to\n        init fresh. The flags -reconfigure and -backend=true are default.\n\n        :param dir_or_plan: relative path to the folder want to init\n        :param backend_config: a dictionary of backend config options. eg.\n                t = Terraform()\n                t.init(backend_config={'access_key': 'myaccesskey', \n                'secret_key': 'mysecretkey', 'bucket': 'mybucketname'})\n        :param reconfigure: whether or not to force reconfiguration of backend\n        :param backend: whether or not to use backend settings for init\n        :param kwargs: options\n        :return: ret_code, stdout, stderr\n        \"\"\"\n        options = kwargs\n        options['backend_config'] = backend_config\n        options['reconfigure'] = reconfigure\n        options['backend'] = backend\n        options = self._generate_default_options(options)\n        args = self._generate_default_args(dir_or_plan)\n        return self.cmd('init', *args, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a terraform command", "response": "def cmd(self, cmd, *args, **kwargs):\n        \"\"\"\n        run a terraform command, if success, will try to read state file\n        :param cmd: command and sub-command of terraform, seperated with space\n                    refer to https://www.terraform.io/docs/commands/index.html\n        :param args: arguments of a command\n        :param kwargs:  any option flag with key value without prefixed dash character\n                if there's a dash in the option name, use under line instead of dash,\n                    ex. -no-color --> no_color\n                if it's a simple flag with no value, value should be IsFlagged\n                    ex. cmd('taint', allow\uff3fmissing=IsFlagged)\n                if it's a boolean value flag, assign True or false\n                if it's a flag could be used multiple times, assign list to it's value\n                if it's a \"var\" variable flag, assign dictionary to it\n                if a value is None, will skip this option\n                if the option 'capture_output' is passed (with any value other than\n                    True), terraform output will be printed to stdout/stderr and\n                    \"None\" will be returned as out and err.\n                if the option 'raise_on_error' is passed (with any value that evaluates to True),\n                    and the terraform command returns a nonzerop return code, then\n                    a TerraformCommandError exception will be raised. The exception object will\n                    have the following properties:\n                      returncode: The command's return code\n                      out: The captured stdout, or None if not captured\n                      err: The captured stderr, or None if not captured\n        :return: ret_code, out, err\n        \"\"\"\n        capture_output = kwargs.pop('capture_output', True)\n        raise_on_error = kwargs.pop('raise_on_error', False)\n        if capture_output is True:\n            stderr = subprocess.PIPE\n            stdout = subprocess.PIPE\n        else:\n            stderr = sys.stderr\n            stdout = sys.stdout\n\n        cmds = self.generate_cmd_string(cmd, *args, **kwargs)\n        log.debug('command: {c}'.format(c=' '.join(cmds)))\n\n        working_folder = self.working_dir if self.working_dir else None\n\n        environ_vars = {}\n        if self.is_env_vars_included:\n            environ_vars = os.environ.copy()\n\n        p = subprocess.Popen(cmds, stdout=stdout, stderr=stderr,\n                             cwd=working_folder, env=environ_vars)\n\n        synchronous = kwargs.pop('synchronous', True)\n        if not synchronous:\n            return p, None, None\n\n        out, err = p.communicate()\n        ret_code = p.returncode\n        log.debug('output: {o}'.format(o=out))\n\n        if ret_code == 0:\n            self.read_state_file()\n        else:\n            log.warn('error: {e}'.format(e=err))\n\n        self.temp_var_files.clean_up()\n        if capture_output is True:\n            out = out.decode('utf-8')\n            err = err.decode('utf-8')\n        else:\n            out = None\n            err = None\n\n        if ret_code != 0 and raise_on_error:\n            raise TerraformCommandError(\n                ret_code, ' '.join(cmds), out=out, err=err)\n\n        return ret_code, out, err"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output(self, *args, **kwargs):\n        full_value = kwargs.pop('full_value', False)\n        name_provided = (len(args) > 0)\n        kwargs['json'] = IsFlagged\n        if not kwargs.get('capture_output', True) is True:\n          raise ValueError('capture_output is required for this method')\n\n        ret, out, err = self.output_cmd(*args, **kwargs)\n\n        if ret != 0:\n            return None\n\n        out = out.lstrip()\n\n        value = json.loads(out)\n\n        if name_provided and not full_value:\n            value = value['value']\n\n        return value", "response": "This method will call the output_cmd method of the resource manager command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread tfstate file in dict type", "response": "def read_state_file(self, file_path=None):\n        \"\"\"\n        read .tfstate file\n        :param file_path: relative path to working dir\n        :return: states file in dict type\n        \"\"\"\n\n        working_dir = self.working_dir or ''\n\n        file_path = file_path or self.state or ''\n\n        if not file_path:\n            backend_path = os.path.join(file_path, '.terraform',\n                                        'terraform.tfstate')\n\n            if os.path.exists(os.path.join(working_dir, backend_path)):\n                file_path = backend_path\n            else:\n                file_path = os.path.join(file_path, 'terraform.tfstate')\n\n        file_path = os.path.join(working_dir, file_path)\n\n        self.tfstate = Tfstate.load_file(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the SAML Response for validity.", "response": "def is_valid(self, request_data, request_id=None, raise_exceptions=False):\n        \"\"\"\n        Validates the response object.\n\n        :param request_data: Request Data\n        :type request_data: dict\n\n        :param request_id: Optional argument. The ID of the AuthNRequest sent by this SP to the IdP\n        :type request_id: string\n\n        :param raise_exceptions: Whether to return false on failure or raise an exception\n        :type raise_exceptions: Boolean\n\n        :returns: True if the SAML Response is valid, False if not\n        :rtype: bool\n        \"\"\"\n        self.__error = None\n        try:\n            # Checks SAML version\n            if self.document.get('Version', None) != '2.0':\n                raise OneLogin_Saml2_ValidationError(\n                    'Unsupported SAML version',\n                    OneLogin_Saml2_ValidationError.UNSUPPORTED_SAML_VERSION\n                )\n\n            # Checks that ID exists\n            if self.document.get('ID', None) is None:\n                raise OneLogin_Saml2_ValidationError(\n                    'Missing ID attribute on SAML Response',\n                    OneLogin_Saml2_ValidationError.MISSING_ID\n                )\n\n            # Checks that the response has the SUCCESS status\n            self.check_status()\n\n            # Checks that the response only has one assertion\n            if not self.validate_num_assertions():\n                raise OneLogin_Saml2_ValidationError(\n                    'SAML Response must contain 1 assertion',\n                    OneLogin_Saml2_ValidationError.WRONG_NUMBER_OF_ASSERTIONS\n                )\n\n            idp_data = self.__settings.get_idp_data()\n            idp_entity_id = idp_data.get('entityId', '')\n            sp_data = self.__settings.get_sp_data()\n            sp_entity_id = sp_data.get('entityId', '')\n\n            signed_elements = self.process_signed_elements()\n\n            has_signed_response = '{%s}Response' % OneLogin_Saml2_Constants.NS_SAMLP in signed_elements\n            has_signed_assertion = '{%s}Assertion' % OneLogin_Saml2_Constants.NS_SAML in signed_elements\n\n            if self.__settings.is_strict():\n                no_valid_xml_msg = 'Invalid SAML Response. Not match the saml-schema-protocol-2.0.xsd'\n                res = OneLogin_Saml2_Utils.validate_xml(\n                    tostring(self.document),\n                    'saml-schema-protocol-2.0.xsd',\n                    self.__settings.is_debug_active()\n                )\n                if not isinstance(res, Document):\n                    raise OneLogin_Saml2_ValidationError(\n                        no_valid_xml_msg,\n                        OneLogin_Saml2_ValidationError.INVALID_XML_FORMAT\n                    )\n\n                # If encrypted, check also the decrypted document\n                if self.encrypted:\n                    res = OneLogin_Saml2_Utils.validate_xml(\n                        tostring(self.decrypted_document),\n                        'saml-schema-protocol-2.0.xsd',\n                        self.__settings.is_debug_active()\n                    )\n                    if not isinstance(res, Document):\n                        raise OneLogin_Saml2_ValidationError(\n                            no_valid_xml_msg,\n                            OneLogin_Saml2_ValidationError.INVALID_XML_FORMAT\n                        )\n\n                security = self.__settings.get_security_data()\n                current_url = OneLogin_Saml2_Utils.get_self_url_no_query(request_data)\n\n                in_response_to = self.document.get('InResponseTo', None)\n                if request_id is None and in_response_to is not None and security.get('rejectUnsolicitedResponsesWithInResponseTo', False):\n                    raise OneLogin_Saml2_ValidationError(\n                        'The Response has an InResponseTo attribute: %s while no InResponseTo was expected' % in_response_to,\n                        OneLogin_Saml2_ValidationError.WRONG_INRESPONSETO\n                    )\n\n                # Check if the InResponseTo of the Response matchs the ID of the AuthNRequest (requestId) if provided\n                if request_id is not None and in_response_to != request_id:\n                    raise OneLogin_Saml2_ValidationError(\n                        'The InResponseTo of the Response: %s, does not match the ID of the AuthNRequest sent by the SP: %s' % (in_response_to, request_id),\n                        OneLogin_Saml2_ValidationError.WRONG_INRESPONSETO\n                    )\n\n                if not self.encrypted and security.get('wantAssertionsEncrypted', False):\n                    raise OneLogin_Saml2_ValidationError(\n                        'The assertion of the Response is not encrypted and the SP require it',\n                        OneLogin_Saml2_ValidationError.NO_ENCRYPTED_ASSERTION\n                    )\n\n                if security.get('wantNameIdEncrypted', False):\n                    encrypted_nameid_nodes = self.__query_assertion('/saml:Subject/saml:EncryptedID/xenc:EncryptedData')\n                    if len(encrypted_nameid_nodes) != 1:\n                        raise OneLogin_Saml2_ValidationError(\n                            'The NameID of the Response is not encrypted and the SP require it',\n                            OneLogin_Saml2_ValidationError.NO_ENCRYPTED_NAMEID\n                        )\n\n                # Checks that a Conditions element exists\n                if not self.check_one_condition():\n                    raise OneLogin_Saml2_ValidationError(\n                        'The Assertion must include a Conditions element',\n                        OneLogin_Saml2_ValidationError.MISSING_CONDITIONS\n                    )\n\n                # Validates Assertion timestamps\n                self.validate_timestamps(raise_exceptions=True)\n\n                # Checks that an AuthnStatement element exists and is unique\n                if not self.check_one_authnstatement():\n                    raise OneLogin_Saml2_ValidationError(\n                        'The Assertion must include an AuthnStatement element',\n                        OneLogin_Saml2_ValidationError.WRONG_NUMBER_OF_AUTHSTATEMENTS\n                    )\n\n                # Checks that the response has all of the AuthnContexts that we provided in the request.\n                # Only check if failOnAuthnContextMismatch is true and requestedAuthnContext is set to a list.\n                requested_authn_contexts = security.get('requestedAuthnContext', True)\n\n                if security.get('failOnAuthnContextMismatch', False) and requested_authn_contexts and requested_authn_contexts is not True:\n                    authn_contexts = self.get_authn_contexts()\n                    unmatched_contexts = set(requested_authn_contexts).difference(authn_contexts)\n                    if unmatched_contexts:\n                        raise OneLogin_Saml2_ValidationError(\n                            'The AuthnContext \"%s\" didn\\'t include requested context \"%s\"' % (', '.join(authn_contexts), ', '.join(unmatched_contexts)),\n                            OneLogin_Saml2_ValidationError.AUTHN_CONTEXT_MISMATCH\n                        )\n\n                # Checks that there is at least one AttributeStatement if required\n                attribute_statement_nodes = self.__query_assertion('/saml:AttributeStatement')\n                if security.get('wantAttributeStatement', True) and not attribute_statement_nodes:\n                    raise OneLogin_Saml2_ValidationError(\n                        'There is no AttributeStatement on the Response',\n                        OneLogin_Saml2_ValidationError.NO_ATTRIBUTESTATEMENT\n                    )\n\n                encrypted_attributes_nodes = self.__query_assertion('/saml:AttributeStatement/saml:EncryptedAttribute')\n                if encrypted_attributes_nodes:\n                    raise OneLogin_Saml2_ValidationError(\n                        'There is an EncryptedAttribute in the Response and this SP not support them',\n                        OneLogin_Saml2_ValidationError.ENCRYPTED_ATTRIBUTES\n                    )\n\n                # Checks destination\n                destination = self.document.get('Destination', None)\n                if destination:\n                    if not destination.startswith(current_url):\n                        # TODO: Review if following lines are required, since we can control the\n                        # request_data\n                        #  current_url_routed = OneLogin_Saml2_Utils.get_self_routed_url_no_query(request_data)\n                        #  if not destination.startswith(current_url_routed):\n                        raise OneLogin_Saml2_ValidationError(\n                            'The response was received at %s instead of %s' % (current_url, destination),\n                            OneLogin_Saml2_ValidationError.WRONG_DESTINATION\n                        )\n                elif destination == '':\n                    raise OneLogin_Saml2_ValidationError(\n                        'The response has an empty Destination value',\n                        OneLogin_Saml2_ValidationError.EMPTY_DESTINATION\n                    )\n\n                # Checks audience\n                valid_audiences = self.get_audiences()\n                if valid_audiences and sp_entity_id not in valid_audiences:\n                    raise OneLogin_Saml2_ValidationError(\n                        '%s is not a valid audience for this Response' % sp_entity_id,\n                        OneLogin_Saml2_ValidationError.WRONG_AUDIENCE\n                    )\n\n                # Checks the issuers\n                issuers = self.get_issuers()\n                for issuer in issuers:\n                    if issuer is None or issuer != idp_entity_id:\n                        raise OneLogin_Saml2_ValidationError(\n                            'Invalid issuer in the Assertion/Response (expected %(idpEntityId)s, got %(issuer)s)' %\n                            {\n                                'idpEntityId': idp_entity_id,\n                                'issuer': issuer\n                            },\n                            OneLogin_Saml2_ValidationError.WRONG_ISSUER\n                        )\n\n                # Checks the session Expiration\n                session_expiration = self.get_session_not_on_or_after()\n                if session_expiration and session_expiration <= OneLogin_Saml2_Utils.now():\n                    raise OneLogin_Saml2_ValidationError(\n                        'The attributes have expired, based on the SessionNotOnOrAfter of the AttributeStatement of this Response',\n                        OneLogin_Saml2_ValidationError.SESSION_EXPIRED\n                    )\n\n                # Checks the SubjectConfirmation, at least one SubjectConfirmation must be valid\n                any_subject_confirmation = False\n                subject_confirmation_nodes = self.__query_assertion('/saml:Subject/saml:SubjectConfirmation')\n\n                for scn in subject_confirmation_nodes:\n                    method = scn.get('Method', None)\n                    if method and method != OneLogin_Saml2_Constants.CM_BEARER:\n                        continue\n                    sc_data = scn.find('saml:SubjectConfirmationData', namespaces=OneLogin_Saml2_Constants.NSMAP)\n                    if sc_data is None:\n                        continue\n                    else:\n                        irt = sc_data.get('InResponseTo', None)\n                        if (in_response_to is None and irt is not None and\n                           security.get('rejectUnsolicitedResponsesWithInResponseTo', False)) or \\\n                           in_response_to and irt and irt != in_response_to:\n                            continue\n                        recipient = sc_data.get('Recipient', None)\n                        if recipient and current_url not in recipient:\n                            continue\n                        nooa = sc_data.get('NotOnOrAfter', None)\n                        if nooa:\n                            parsed_nooa = OneLogin_Saml2_Utils.parse_SAML_to_time(nooa)\n                            if parsed_nooa <= OneLogin_Saml2_Utils.now():\n                                continue\n                        nb = sc_data.get('NotBefore', None)\n                        if nb:\n                            parsed_nb = OneLogin_Saml2_Utils.parse_SAML_to_time(nb)\n                            if parsed_nb > OneLogin_Saml2_Utils.now():\n                                continue\n\n                        if nooa:\n                            self.valid_scd_not_on_or_after = OneLogin_Saml2_Utils.parse_SAML_to_time(nooa)\n\n                        any_subject_confirmation = True\n                        break\n\n                if not any_subject_confirmation:\n                    raise OneLogin_Saml2_ValidationError(\n                        'A valid SubjectConfirmation was not found on this Response',\n                        OneLogin_Saml2_ValidationError.WRONG_SUBJECTCONFIRMATION\n                    )\n\n                if security.get('wantAssertionsSigned', False) and not has_signed_assertion:\n                    raise OneLogin_Saml2_ValidationError(\n                        'The Assertion of the Response is not signed and the SP require it',\n                        OneLogin_Saml2_ValidationError.NO_SIGNED_ASSERTION\n                    )\n\n                if security.get('wantMessagesSigned', False) and not has_signed_response:\n                    raise OneLogin_Saml2_ValidationError(\n                        'The Message of the Response is not signed and the SP require it',\n                        OneLogin_Saml2_ValidationError.NO_SIGNED_MESSAGE\n                    )\n\n            if not signed_elements or (not has_signed_response and not has_signed_assertion):\n                raise OneLogin_Saml2_ValidationError(\n                    'No Signature found. SAML Response rejected',\n                    OneLogin_Saml2_ValidationError.NO_SIGNATURE_FOUND\n                )\n            else:\n                cert = idp_data.get('x509cert', None)\n                fingerprint = idp_data.get('certFingerprint', None)\n                fingerprintalg = idp_data.get('certFingerprintAlgorithm', None)\n\n                multicerts = None\n                if 'x509certMulti' in idp_data and 'signing' in idp_data['x509certMulti'] and idp_data['x509certMulti']['signing']:\n                    multicerts = idp_data['x509certMulti']['signing']\n\n                # If find a Signature on the Response, validates it checking the original response\n                if has_signed_response and not OneLogin_Saml2_Utils.validate_sign(self.document, cert, fingerprint, fingerprintalg, xpath=OneLogin_Saml2_Utils.RESPONSE_SIGNATURE_XPATH, multicerts=multicerts, raise_exceptions=False):\n                    raise OneLogin_Saml2_ValidationError(\n                        'Signature validation failed. SAML Response rejected',\n                        OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                    )\n\n                document_check_assertion = self.decrypted_document if self.encrypted else self.document\n                if has_signed_assertion and not OneLogin_Saml2_Utils.validate_sign(document_check_assertion, cert, fingerprint, fingerprintalg, xpath=OneLogin_Saml2_Utils.ASSERTION_SIGNATURE_XPATH, multicerts=multicerts, raise_exceptions=False):\n                    raise OneLogin_Saml2_ValidationError(\n                        'Signature validation failed. SAML Response rejected',\n                        OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                    )\n\n            return True\n        except Exception as err:\n            self.__error = err.__str__()\n            debug = self.__settings.is_debug_active()\n            if debug:\n                print(err.__str__())\n            if raise_exceptions:\n                raise err\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_audiences(self):\n        audience_nodes = self.__query_assertion('/saml:Conditions/saml:AudienceRestriction/saml:Audience')\n        return [OneLogin_Saml2_Utils.element_text(node) for node in audience_nodes if OneLogin_Saml2_Utils.element_text(node) is not None]", "response": "Gets the valid audiences for the SAML Response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the authentication contexts", "response": "def get_authn_contexts(self):\n        \"\"\"\n        Gets the authentication contexts\n         :returns: The authentication classes for the SAML Response\n        :rtype: list\n        \"\"\"\n        authn_context_nodes = self.__query_assertion('/saml:AuthnStatement/saml:AuthnContext/saml:AuthnContextClassRef')\n        return [OneLogin_Saml2_Utils.element_text(node) for node in authn_context_nodes]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_issuers(self):\n        issuers = []\n\n        message_issuer_nodes = OneLogin_Saml2_Utils.query(self.document, '/samlp:Response/saml:Issuer')\n        if len(message_issuer_nodes) > 0:\n            if len(message_issuer_nodes) == 1:\n                issuers.append(OneLogin_Saml2_Utils.element_text(message_issuer_nodes[0]))\n            else:\n                raise OneLogin_Saml2_ValidationError(\n                    'Issuer of the Response is multiple.',\n                    OneLogin_Saml2_ValidationError.ISSUER_MULTIPLE_IN_RESPONSE\n                )\n\n        assertion_issuer_nodes = self.__query_assertion('/saml:Issuer')\n        if len(assertion_issuer_nodes) == 1:\n            issuers.append(OneLogin_Saml2_Utils.element_text(assertion_issuer_nodes[0]))\n        else:\n            raise OneLogin_Saml2_ValidationError(\n                'Issuer of the Assertion not found or multiple.',\n                OneLogin_Saml2_ValidationError.ISSUER_NOT_FOUND_IN_ASSERTION\n            )\n\n        return list(set(issuers))", "response": "Gets the issuers from the message and assertion."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the NameID Data from the IdP response.", "response": "def get_nameid_data(self):\n        \"\"\"\n        Gets the NameID Data provided by the SAML Response from the IdP\n\n        :returns: Name ID Data (Value, Format, NameQualifier, SPNameQualifier)\n        :rtype: dict\n        \"\"\"\n        nameid = None\n        nameid_data = {}\n\n        encrypted_id_data_nodes = self.__query_assertion('/saml:Subject/saml:EncryptedID/xenc:EncryptedData')\n        if encrypted_id_data_nodes:\n            encrypted_data = encrypted_id_data_nodes[0]\n            key = self.__settings.get_sp_key()\n            nameid = OneLogin_Saml2_Utils.decrypt_element(encrypted_data, key)\n        else:\n            nameid_nodes = self.__query_assertion('/saml:Subject/saml:NameID')\n            if nameid_nodes:\n                nameid = nameid_nodes[0]\n\n        is_strict = self.__settings.is_strict()\n        want_nameid = self.__settings.get_security_data().get('wantNameId', True)\n        if nameid is None:\n            if is_strict and want_nameid:\n                raise OneLogin_Saml2_ValidationError(\n                    'NameID not found in the assertion of the Response',\n                    OneLogin_Saml2_ValidationError.NO_NAMEID\n                )\n        else:\n            if is_strict and want_nameid and not OneLogin_Saml2_Utils.element_text(nameid):\n                raise OneLogin_Saml2_ValidationError(\n                    'An empty NameID value found',\n                    OneLogin_Saml2_ValidationError.EMPTY_NAMEID\n                )\n\n            nameid_data = {'Value': OneLogin_Saml2_Utils.element_text(nameid)}\n            for attr in ['Format', 'SPNameQualifier', 'NameQualifier']:\n                value = nameid.get(attr, None)\n                if value:\n                    if is_strict and attr == 'SPNameQualifier':\n                        sp_data = self.__settings.get_sp_data()\n                        sp_entity_id = sp_data.get('entityId', '')\n                        if sp_entity_id != value:\n                            raise OneLogin_Saml2_ValidationError(\n                                'The SPNameQualifier value mistmatch the SP entityID value.',\n                                OneLogin_Saml2_ValidationError.SP_NAME_QUALIFIER_NAME_MISMATCH\n                            )\n\n                    nameid_data[attr] = value\n        return nameid_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the document has the expected signed nodes.", "response": "def validate_signed_elements(self, signed_elements):\n        \"\"\"\n        Verifies that the document has the expected signed nodes.\n\n        :param signed_elements: The signed elements to be checked\n        :type signed_elements: list\n\n        :param raise_exceptions: Whether to return false on failure or raise an exception\n        :type raise_exceptions: Boolean\n        \"\"\"\n        if len(signed_elements) > 2:\n            return False\n\n        response_tag = '{%s}Response' % OneLogin_Saml2_Constants.NS_SAMLP\n        assertion_tag = '{%s}Assertion' % OneLogin_Saml2_Constants.NS_SAML\n\n        if (response_tag in signed_elements and signed_elements.count(response_tag) > 1) or \\\n           (assertion_tag in signed_elements and signed_elements.count(assertion_tag) > 1) or \\\n           (response_tag not in signed_elements and assertion_tag not in signed_elements):\n            return False\n\n        # Check that the signed elements found here, are the ones that will be verified\n        # by OneLogin_Saml2_Utils.validate_sign\n        if response_tag in signed_elements:\n            expected_signature_nodes = OneLogin_Saml2_Utils.query(self.document, OneLogin_Saml2_Utils.RESPONSE_SIGNATURE_XPATH)\n            if len(expected_signature_nodes) != 1:\n                raise OneLogin_Saml2_ValidationError(\n                    'Unexpected number of Response signatures found. SAML Response rejected.',\n                    OneLogin_Saml2_ValidationError.WRONG_NUMBER_OF_SIGNATURES_IN_RESPONSE\n                )\n\n        if assertion_tag in signed_elements:\n            expected_signature_nodes = self.__query(OneLogin_Saml2_Utils.ASSERTION_SIGNATURE_XPATH)\n            if len(expected_signature_nodes) != 1:\n                raise OneLogin_Saml2_ValidationError(\n                    'Unexpected number of Assertion signatures found. SAML Response rejected.',\n                    OneLogin_Saml2_ValidationError.WRONG_NUMBER_OF_SIGNATURES_IN_ASSERTION\n                )\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the response for the nodes that match the query", "response": "def __query(self, query, tagid=None):\n        \"\"\"\n        Extracts nodes that match the query from the Response\n\n        :param query: Xpath Expresion\n        :type query: String\n\n        :param tagid: Tag ID\n        :type query: String\n\n        :returns: The queried nodes\n        :rtype: list\n        \"\"\"\n        if self.encrypted:\n            document = self.decrypted_document\n        else:\n            document = self.document\n        return OneLogin_Saml2_Utils.query(document, query, None, tagid)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_issuer(self):\n        issuer = None\n        issuer_nodes = self.__query('/samlp:LogoutResponse/saml:Issuer')\n        if len(issuer_nodes) == 1:\n            issuer = OneLogin_Saml2_Utils.element_text(issuer_nodes[0])\n        return issuer", "response": "Gets the Issuer of the Logout Response Message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the SAML Logout Response is valid.", "response": "def is_valid(self, request_data, request_id=None, raise_exceptions=False):\n        \"\"\"\n        Determines if the SAML LogoutResponse is valid\n        :param request_id: The ID of the LogoutRequest sent by this SP to the IdP\n        :type request_id: string\n        :param raise_exceptions: Whether to return false on failure or raise an exception\n        :type raise_exceptions: Boolean\n        :return: Returns if the SAML LogoutResponse is or not valid\n        :rtype: boolean\n        \"\"\"\n        self.__error = None\n        lowercase_urlencoding = False\n        try:\n            idp_data = self.__settings.get_idp_data()\n            idp_entity_id = idp_data['entityId']\n            get_data = request_data['get_data']\n\n            if 'lowercase_urlencoding' in request_data.keys():\n                lowercase_urlencoding = request_data['lowercase_urlencoding']\n\n            if self.__settings.is_strict():\n                res = OneLogin_Saml2_Utils.validate_xml(self.document, 'saml-schema-protocol-2.0.xsd', self.__settings.is_debug_active())\n                if not isinstance(res, Document):\n                    raise OneLogin_Saml2_ValidationError(\n                        'Invalid SAML Logout Response. Not match the saml-schema-protocol-2.0.xsd',\n                        OneLogin_Saml2_ValidationError.INVALID_XML_FORMAT\n                    )\n\n                security = self.__settings.get_security_data()\n\n                # Check if the InResponseTo of the Logout Response matches the ID of the Logout Request (requestId) if provided\n                if request_id is not None and self.document.documentElement.hasAttribute('InResponseTo'):\n                    in_response_to = self.document.documentElement.getAttribute('InResponseTo')\n                    if request_id != in_response_to:\n                        raise OneLogin_Saml2_ValidationError(\n                            'The InResponseTo of the Logout Response: %s, does not match the ID of the Logout request sent by the SP: %s' % (in_response_to, request_id),\n                            OneLogin_Saml2_ValidationError.WRONG_INRESPONSETO\n                        )\n\n                # Check issuer\n                issuer = self.get_issuer()\n                if issuer is not None and issuer != idp_entity_id:\n                    raise OneLogin_Saml2_ValidationError(\n                        'Invalid issuer in the Logout Response (expected %(idpEntityId)s, got %(issuer)s)' %\n                        {\n                            'idpEntityId': idp_entity_id,\n                            'issuer': issuer\n                        },\n                        OneLogin_Saml2_ValidationError.WRONG_ISSUER\n                    )\n\n                current_url = OneLogin_Saml2_Utils.get_self_url_no_query(request_data)\n\n                # Check destination\n                if self.document.documentElement.hasAttribute('Destination'):\n                    destination = self.document.documentElement.getAttribute('Destination')\n                    if destination != '':\n                        if current_url not in destination:\n                            raise OneLogin_Saml2_ValidationError(\n                                'The LogoutResponse was received at %s instead of %s' % (current_url, destination),\n                                OneLogin_Saml2_ValidationError.WRONG_DESTINATION\n                            )\n\n                if security['wantMessagesSigned']:\n                    if 'Signature' not in get_data:\n                        raise OneLogin_Saml2_ValidationError(\n                            'The Message of the Logout Response is not signed and the SP require it',\n                            OneLogin_Saml2_ValidationError.NO_SIGNED_MESSAGE\n                        )\n\n            if 'Signature' in get_data:\n                if 'SigAlg' not in get_data:\n                    sign_alg = OneLogin_Saml2_Constants.RSA_SHA1\n                else:\n                    sign_alg = get_data['SigAlg']\n\n                signed_query = 'SAMLResponse=%s' % OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'SAMLResponse', lowercase_urlencoding=lowercase_urlencoding)\n                if 'RelayState' in get_data:\n                    signed_query = '%s&RelayState=%s' % (signed_query, OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'RelayState', lowercase_urlencoding=lowercase_urlencoding))\n                signed_query = '%s&SigAlg=%s' % (signed_query, OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'SigAlg', OneLogin_Saml2_Constants.RSA_SHA1, lowercase_urlencoding=lowercase_urlencoding))\n\n                exists_x509cert = 'x509cert' in idp_data and idp_data['x509cert']\n                exists_multix509sign = 'x509certMulti' in idp_data and \\\n                    'signing' in idp_data['x509certMulti'] and \\\n                    idp_data['x509certMulti']['signing']\n\n                if not (exists_x509cert or exists_multix509sign):\n                    raise OneLogin_Saml2_Error(\n                        'In order to validate the sign on the Logout Response, the x509cert of the IdP is required',\n                        OneLogin_Saml2_Error.CERT_NOT_FOUND\n                    )\n                if exists_multix509sign:\n                    for cert in idp_data['x509certMulti']['signing']:\n                        if OneLogin_Saml2_Utils.validate_binary_sign(signed_query, b64decode(get_data['Signature']), cert, sign_alg):\n                            return True\n                    raise OneLogin_Saml2_ValidationError(\n                        'Signature validation failed. Logout Response rejected',\n                        OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                    )\n                else:\n                    cert = idp_data['x509cert']\n\n                    if not OneLogin_Saml2_Utils.validate_binary_sign(signed_query, b64decode(get_data['Signature']), cert, sign_alg):\n                        raise OneLogin_Saml2_ValidationError(\n                            'Signature validation failed. Logout Response rejected',\n                            OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                        )\n\n            return True\n        # pylint: disable=R0801\n        except Exception as err:\n            self.__error = err.__str__()\n            debug = self.__settings.is_debug_active()\n            if debug:\n                print(err.__str__())\n            if raise_exceptions:\n                raise err\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __query(self, query):\n        # Switch to lxml for querying\n        xml = self.document.toxml()\n        return OneLogin_Saml2_Utils.query(fromstring(xml, forbid_dtd=True), query)", "response": "Query the node list for the given query"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the Logout Response maybe deflated base64 encoded", "response": "def get_response(self, deflate=True):\n        \"\"\"\n        Returns the Logout Response defated, base64encoded\n        :param deflate: It makes the deflate process optional\n        :type: bool\n        :return: Logout Response maybe deflated and base64 encoded\n        :rtype: string\n        \"\"\"\n        if deflate:\n            response = OneLogin_Saml2_Utils.deflate_and_base64_encode(self.__logout_response)\n        else:\n            response = b64encode(self.__logout_response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_metadata(url, validate_cert=True):\n        valid = False\n        if validate_cert:\n            response = urllib2.urlopen(url)\n        else:\n            ctx = ssl.create_default_context()\n            ctx.check_hostname = False\n            ctx.verify_mode = ssl.CERT_NONE\n            response = urllib2.urlopen(url, context=ctx)\n        xml = response.read()\n\n        if xml:\n            try:\n                dom = fromstring(xml, forbid_dtd=True)\n                idp_descriptor_nodes = OneLogin_Saml2_Utils.query(dom, '//md:IDPSSODescriptor')\n                if idp_descriptor_nodes:\n                    valid = True\n            except Exception:\n                pass\n\n        if not valid:\n            raise Exception('Not valid IdP XML found from URL: %s' % (url))\n\n        return xml", "response": "Gets the metadata XML from the provided URL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(\n            idp_metadata,\n            required_sso_binding=OneLogin_Saml2_Constants.BINDING_HTTP_REDIRECT,\n            required_slo_binding=OneLogin_Saml2_Constants.BINDING_HTTP_REDIRECT,\n            entity_id=None):\n        \"\"\"\n        Parse the Identity Provider metadata and return a dict with extracted data.\n\n        If there are multiple <IDPSSODescriptor> tags, parse only the first.\n\n        Parse only those SSO endpoints with the same binding as given by\n        the `required_sso_binding` parameter.\n\n        Parse only those SLO endpoints with the same binding as given by\n        the `required_slo_binding` parameter.\n\n        If the metadata specifies multiple SSO endpoints with the required\n        binding, extract only the first (the same holds true for SLO\n        endpoints).\n\n        :param idp_metadata: XML of the Identity Provider Metadata.\n        :type idp_metadata: string\n\n        :param required_sso_binding: Parse only POST or REDIRECT SSO endpoints.\n        :type required_sso_binding: one of OneLogin_Saml2_Constants.BINDING_HTTP_REDIRECT\n            or OneLogin_Saml2_Constants.BINDING_HTTP_POST\n\n        :param required_slo_binding: Parse only POST or REDIRECT SLO endpoints.\n        :type required_slo_binding: one of OneLogin_Saml2_Constants.BINDING_HTTP_REDIRECT\n            or OneLogin_Saml2_Constants.BINDING_HTTP_POST\n\n        :param entity_id: Specify the entity_id of the EntityDescriptor that you want to parse a XML\n                          that contains multiple EntityDescriptor.\n        :type entity_id: string\n\n        :returns: settings dict with extracted data\n        :rtype: dict\n        \"\"\"\n        data = {}\n\n        dom = fromstring(idp_metadata, forbid_dtd=True)\n\n        entity_desc_path = '//md:EntityDescriptor'\n        if entity_id:\n            entity_desc_path += \"[@entityID='%s']\" % entity_id\n\n        entity_descriptor_nodes = OneLogin_Saml2_Utils.query(dom, entity_desc_path)\n\n        idp_entity_id = want_authn_requests_signed = idp_name_id_format = idp_sso_url = idp_slo_url = certs = None\n\n        if len(entity_descriptor_nodes) > 0:\n            entity_descriptor_node = entity_descriptor_nodes[0]\n            idp_descriptor_nodes = OneLogin_Saml2_Utils.query(entity_descriptor_node, './md:IDPSSODescriptor')\n            if len(idp_descriptor_nodes) > 0:\n                idp_descriptor_node = idp_descriptor_nodes[0]\n\n                idp_entity_id = entity_descriptor_node.get('entityID', None)\n\n                want_authn_requests_signed = entity_descriptor_node.get('WantAuthnRequestsSigned', None)\n\n                name_id_format_nodes = OneLogin_Saml2_Utils.query(idp_descriptor_node, './md:NameIDFormat')\n                if len(name_id_format_nodes) > 0:\n                    idp_name_id_format = OneLogin_Saml2_Utils.element_text(name_id_format_nodes[0])\n\n                sso_nodes = OneLogin_Saml2_Utils.query(\n                    idp_descriptor_node,\n                    \"./md:SingleSignOnService[@Binding='%s']\" % required_sso_binding\n                )\n\n                if len(sso_nodes) > 0:\n                    idp_sso_url = sso_nodes[0].get('Location', None)\n\n                slo_nodes = OneLogin_Saml2_Utils.query(\n                    idp_descriptor_node,\n                    \"./md:SingleLogoutService[@Binding='%s']\" % required_slo_binding\n                )\n                if len(slo_nodes) > 0:\n                    idp_slo_url = slo_nodes[0].get('Location', None)\n\n                signing_nodes = OneLogin_Saml2_Utils.query(idp_descriptor_node, \"./md:KeyDescriptor[not(contains(@use, 'encryption'))]/ds:KeyInfo/ds:X509Data/ds:X509Certificate\")\n                encryption_nodes = OneLogin_Saml2_Utils.query(idp_descriptor_node, \"./md:KeyDescriptor[not(contains(@use, 'signing'))]/ds:KeyInfo/ds:X509Data/ds:X509Certificate\")\n\n                if len(signing_nodes) > 0 or len(encryption_nodes) > 0:\n                    certs = {}\n                    if len(signing_nodes) > 0:\n                        certs['signing'] = []\n                        for cert_node in signing_nodes:\n                            certs['signing'].append(''.join(OneLogin_Saml2_Utils.element_text(cert_node).split()))\n                    if len(encryption_nodes) > 0:\n                        certs['encryption'] = []\n                        for cert_node in encryption_nodes:\n                            certs['encryption'].append(''.join(OneLogin_Saml2_Utils.element_text(cert_node).split()))\n\n                data['idp'] = {}\n\n                if idp_entity_id is not None:\n                    data['idp']['entityId'] = idp_entity_id\n\n                if idp_sso_url is not None:\n                    data['idp']['singleSignOnService'] = {}\n                    data['idp']['singleSignOnService']['url'] = idp_sso_url\n                    data['idp']['singleSignOnService']['binding'] = required_sso_binding\n\n                if idp_slo_url is not None:\n                    data['idp']['singleLogoutService'] = {}\n                    data['idp']['singleLogoutService']['url'] = idp_slo_url\n                    data['idp']['singleLogoutService']['binding'] = required_slo_binding\n\n                if certs is not None:\n                    if (len(certs) == 1 and\n                        (('signing' in certs and len(certs['signing']) == 1) or\n                         ('encryption' in certs and len(certs['encryption']) == 1))) or \\\n                        (('signing' in certs and len(certs['signing']) == 1) and\n                         ('encryption' in certs and len(certs['encryption']) == 1 and\n                         certs['signing'][0] == certs['encryption'][0])):\n                        if 'signing' in certs:\n                            data['idp']['x509cert'] = certs['signing'][0]\n                        else:\n                            data['idp']['x509cert'] = certs['encryption'][0]\n                    else:\n                        data['idp']['x509certMulti'] = certs\n\n                if want_authn_requests_signed is not None:\n                    data['security'] = {}\n                    data['security']['authnRequestsSigned'] = want_authn_requests_signed\n\n                if idp_name_id_format:\n                    data['sp'] = {}\n                    data['sp']['NameIDFormat'] = idp_name_id_format\n        return data", "response": "Parses the Identity Provider Metadata and returns a dictionary with extracted data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_xmlsec_errors(filename, line, func, error_object, error_subject, reason, msg):\n\n    info = []\n    if error_object != \"unknown\":\n        info.append(\"obj=\" + error_object)\n    if error_subject != \"unknown\":\n        info.append(\"subject=\" + error_subject)\n    if msg.strip():\n        info.append(\"msg=\" + msg)\n    if reason != 1:\n        info.append(\"errno=%d\" % reason)\n    if info:\n        print(\"%s:%d(%s)\" % (filename, line, func), \" \".join(info))", "response": "Auxiliary method that prints xmlsec debug messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_base64_and_inflate(value):\n        decoded = base64.b64decode(value)\n        # We try to inflate\n        try:\n            result = zlib.decompress(decoded, -15)\n        except Exception:\n            result = decoded\n\n        return result.decode('utf-8')", "response": "base64 decodes and then inflates according to RFC1951\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a xml against a schema", "response": "def validate_xml(xml, schema, debug=False):\n        \"\"\"\n        Validates a xml against a schema\n        :param xml: The xml that will be validated\n        :type: string|DomDocument\n        :param schema: The schema\n        :type: string\n        :param debug: If debug is active, the parse-errors will be showed\n        :type: bool\n        :returns: Error code or the DomDocument of the xml\n        :rtype: string\n        \"\"\"\n        assert isinstance(xml, basestring) or isinstance(xml, Document) or isinstance(xml, etree._Element)\n        assert isinstance(schema, basestring)\n\n        if isinstance(xml, Document):\n            xml = xml.toxml()\n        elif isinstance(xml, etree._Element):\n            xml = tostring(xml, encoding='unicode')\n\n        # Switch to lxml for schema validation\n        try:\n            dom = fromstring(xml.encode('utf-8'), forbid_dtd=True)\n        except Exception:\n            return 'unloaded_xml'\n\n        schema_file = join(dirname(__file__), 'schemas', schema)\n        f_schema = open(schema_file, 'r')\n        schema_doc = etree.parse(f_schema)\n        f_schema.close()\n        xmlschema = etree.XMLSchema(schema_doc)\n\n        if not xmlschema.validate(dom):\n            if debug:\n                stderr.write('Errors validating the metadata')\n                stderr.write(':\\n\\n')\n                for error in xmlschema.error_log:\n                    stderr.write('%s\\n' % error.message)\n\n            return 'invalid_xml'\n\n        return parseString(tostring(dom, encoding='unicode').encode('utf-8'), forbid_dtd=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a redirection to the provided url.", "response": "def redirect(url, parameters={}, request_data={}):\n        \"\"\"\n        Executes a redirection to the provided url (or return the target url).\n\n        :param url: The target url\n        :type: string\n\n        :param parameters: Extra parameters to be passed as part of the url\n        :type: dict\n\n        :param request_data: The request as a dict\n        :type: dict\n\n        :returns: Url\n        :rtype: string\n        \"\"\"\n        assert isinstance(url, basestring)\n        assert isinstance(parameters, dict)\n\n        if url.startswith('/'):\n            url = '%s%s' % (OneLogin_Saml2_Utils.get_self_url_host(request_data), url)\n\n        # Verify that the URL is to a http or https site.\n        if re.search('^https?://', url) is None:\n            raise OneLogin_Saml2_Error(\n                'Redirect to invalid URL: ' + url,\n                OneLogin_Saml2_Error.REDIRECT_INVALID_URL\n            )\n\n        # Add encoded parameters\n        if url.find('?') < 0:\n            param_prefix = '?'\n        else:\n            param_prefix = '&'\n\n        for name, value in parameters.items():\n\n            if value is None:\n                param = quote_plus(name)\n            elif isinstance(value, list):\n                param = ''\n                for val in value:\n                    param += quote_plus(name) + '[]=' + quote_plus(val) + '&'\n                if len(param) > 0:\n                    param = param[0:-1]\n            else:\n                param = quote_plus(name) + '=' + quote_plus(value)\n\n            if param:\n                url += param_prefix + param\n                param_prefix = '&'\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current host.", "response": "def get_self_host(request_data):\n        \"\"\"\n        Returns the current host.\n\n        :param request_data: The request as a dict\n        :type: dict\n\n        :return: The current host\n        :rtype: string\n        \"\"\"\n        if 'http_host' in request_data:\n            current_host = request_data['http_host']\n        elif 'server_name' in request_data:\n            current_host = request_data['server_name']\n        else:\n            raise Exception('No hostname defined')\n\n        if ':' in current_host:\n            current_host_data = current_host.split(':')\n            possible_port = current_host_data[-1]\n            try:\n                possible_port = float(possible_port)\n                current_host = current_host_data[0]\n            except ValueError:\n                current_host = ':'.join(current_host_data)\n\n        return current_host"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninterpreting a ISO8601 duration value relative to a given unix timestamp.", "response": "def parse_duration(duration, timestamp=None):\n        \"\"\"\n        Interprets a ISO8601 duration value relative to a given timestamp.\n\n        :param duration: The duration, as a string.\n        :type: string\n\n        :param timestamp: The unix timestamp we should apply the duration to.\n                          Optional, default to the current time.\n        :type: string\n\n        :return: The new timestamp, after the duration is applied.\n        :rtype: int\n        \"\"\"\n        assert isinstance(duration, basestring)\n        assert timestamp is None or isinstance(timestamp, int)\n\n        timedelta = duration_parser(duration)\n        if timestamp is None:\n            data = datetime.utcnow() + timedelta\n        else:\n            data = datetime.utcfromtimestamp(timestamp) + timedelta\n        return calendar.timegm(data.utctimetuple())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a nameID. :param value: fingerprint :type: string :param sp_nq: SP Name Qualifier :type: string :param sp_format: SP Format :type: string :param cert: IdP Public Cert to encrypt the nameID :type: string :param debug: Activate the xmlsec debug :type: bool :param nq: IDP Name Qualifier :type: string :returns: DOMElement | XMLSec nameID :rtype: string", "response": "def generate_name_id(value, sp_nq, sp_format=None, cert=None, debug=False, nq=None):\n        \"\"\"\n        Generates a nameID.\n\n        :param value: fingerprint\n        :type: string\n\n        :param sp_nq: SP Name Qualifier\n        :type: string\n\n        :param sp_format: SP Format\n        :type: string\n\n        :param cert: IdP Public Cert to encrypt the nameID\n        :type: string\n\n        :param debug: Activate the xmlsec debug\n        :type: bool\n\n        :param nq: IDP Name Qualifier\n        :type: string\n\n        :returns: DOMElement | XMLSec nameID\n        :rtype: string\n        \"\"\"\n        doc = Document()\n        name_id_container = doc.createElementNS(OneLogin_Saml2_Constants.NS_SAML, 'container')\n        name_id_container.setAttribute(\"xmlns:saml\", OneLogin_Saml2_Constants.NS_SAML)\n\n        name_id = doc.createElement('saml:NameID')\n        if sp_nq is not None:\n            name_id.setAttribute('SPNameQualifier', sp_nq)\n        if nq is not None:\n            name_id.setAttribute('NameQualifier', nq)\n        if sp_format is not None:\n            name_id.setAttribute('Format', sp_format)\n        name_id.appendChild(doc.createTextNode(value))\n        name_id_container.appendChild(name_id)\n\n        if cert is not None:\n            xml = name_id_container.toxml()\n            elem = fromstring(xml, forbid_dtd=True)\n\n            error_callback_method = None\n            if debug:\n                error_callback_method = print_xmlsec_errors\n            xmlsec.set_error_callback(error_callback_method)\n\n            # Load the public cert\n            mngr = xmlsec.KeysMngr()\n            file_cert = OneLogin_Saml2_Utils.write_temp_file(cert)\n            key_data = xmlsec.Key.load(file_cert.name, xmlsec.KeyDataFormatCertPem, None)\n            key_data.name = basename(file_cert.name)\n            mngr.addKey(key_data)\n            file_cert.close()\n\n            # Prepare for encryption\n            enc_data = EncData(xmlsec.TransformAes128Cbc, type=xmlsec.TypeEncElement)\n            enc_data.ensureCipherValue()\n            key_info = enc_data.ensureKeyInfo()\n            # enc_key = key_info.addEncryptedKey(xmlsec.TransformRsaPkcs1)\n            enc_key = key_info.addEncryptedKey(xmlsec.TransformRsaOaep)\n            enc_key.ensureCipherValue()\n\n            # Encrypt!\n            enc_ctx = xmlsec.EncCtx(mngr)\n            enc_ctx.encKey = xmlsec.Key.generate(xmlsec.KeyDataAes, 128, xmlsec.KeyDataTypeSession)\n\n            edata = enc_ctx.encryptXml(enc_data, elem[0])\n\n            newdoc = parseString(tostring(edata, encoding='unicode').encode('utf-8'), forbid_dtd=True)\n\n            if newdoc.hasChildNodes():\n                child = newdoc.firstChild\n                child.removeAttribute('xmlns')\n                child.removeAttribute('xmlns:saml')\n                child.setAttribute('xmlns:xenc', OneLogin_Saml2_Constants.NS_XENC)\n                child.setAttribute('xmlns:dsig', OneLogin_Saml2_Constants.NS_DS)\n\n            nodes = newdoc.getElementsByTagName(\"*\")\n            for node in nodes:\n                if node.tagName == 'ns0:KeyInfo':\n                    node.tagName = 'dsig:KeyInfo'\n                    node.removeAttribute('xmlns:ns0')\n                    node.setAttribute('xmlns:dsig', OneLogin_Saml2_Constants.NS_DS)\n                else:\n                    node.tagName = 'xenc:' + node.tagName\n\n            encrypted_id = newdoc.createElement('saml:EncryptedID')\n            encrypted_data = newdoc.replaceChild(encrypted_id, newdoc.firstChild)\n            encrypted_id.appendChild(encrypted_data)\n            return newdoc.saveXML(encrypted_id)\n        else:\n            return doc.saveXML(name_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_status(dom):\n        status = {}\n\n        status_entry = OneLogin_Saml2_Utils.query(dom, '/samlp:Response/samlp:Status')\n        if len(status_entry) != 1:\n            raise OneLogin_Saml2_ValidationError(\n                'Missing Status on response',\n                OneLogin_Saml2_ValidationError.MISSING_STATUS\n            )\n\n        code_entry = OneLogin_Saml2_Utils.query(dom, '/samlp:Response/samlp:Status/samlp:StatusCode', status_entry[0])\n        if len(code_entry) != 1:\n            raise OneLogin_Saml2_ValidationError(\n                'Missing Status Code on response',\n                OneLogin_Saml2_ValidationError.MISSING_STATUS_CODE\n            )\n        code = code_entry[0].values()[0]\n        status['code'] = code\n\n        status['msg'] = ''\n        message_entry = OneLogin_Saml2_Utils.query(dom, '/samlp:Response/samlp:Status/samlp:StatusMessage', status_entry[0])\n        if len(message_entry) == 0:\n            subcode_entry = OneLogin_Saml2_Utils.query(dom, '/samlp:Response/samlp:Status/samlp:StatusCode/samlp:StatusCode', status_entry[0])\n            if len(subcode_entry) == 1:\n                status['msg'] = subcode_entry[0].values()[0]\n        elif len(message_entry) == 1:\n            status['msg'] = OneLogin_Saml2_Utils.element_text(message_entry[0])\n\n        return status", "response": "Gets the Status from a Response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt_element(encrypted_data, key, debug=False, inplace=False):\n        if isinstance(encrypted_data, Element):\n            encrypted_data = fromstring(str(encrypted_data.toxml()), forbid_dtd=True)\n        elif isinstance(encrypted_data, basestring):\n            encrypted_data = fromstring(str(encrypted_data), forbid_dtd=True)\n        elif not inplace and isinstance(encrypted_data, etree._Element):\n            encrypted_data = deepcopy(encrypted_data)\n\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        mngr = xmlsec.KeysMngr()\n\n        key = xmlsec.Key.loadMemory(key, xmlsec.KeyDataFormatPem, None)\n        mngr.addKey(key)\n        enc_ctx = xmlsec.EncCtx(mngr)\n\n        return enc_ctx.decrypt(encrypted_data)", "response": "Decrypts an encrypted element."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites some content into a temporary file and returns it.", "response": "def write_temp_file(content):\n        \"\"\"\n        Writes some content into a temporary file and returns it.\n\n        :param content: The file content\n        :type: string\n\n        :returns: The temporary file\n        :rtype: file-like object\n        \"\"\"\n        f_temp = NamedTemporaryFile(delete=True)\n        f_temp.file.write(content)\n        f_temp.file.flush()\n        return f_temp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a signature key and senders certificate to an element.", "response": "def add_sign(xml, key, cert, debug=False, sign_algorithm=OneLogin_Saml2_Constants.RSA_SHA1, digest_algorithm=OneLogin_Saml2_Constants.SHA1):\n        \"\"\"\n        Adds signature key and senders certificate to an element (Message or\n        Assertion).\n\n        :param xml: The element we should sign\n        :type: string | Document\n\n        :param key: The private key\n        :type: string\n\n        :param cert: The public\n        :type: string\n\n        :param debug: Activate the xmlsec debug\n        :type: bool\n\n        :param sign_algorithm: Signature algorithm method\n        :type sign_algorithm: string\n\n        :param digest_algorithm: Digest algorithm method\n        :type digest_algorithm: string\n\n        :returns: Signed XML\n        :rtype: string\n        \"\"\"\n        if xml is None or xml == '':\n            raise Exception('Empty string supplied as input')\n        elif isinstance(xml, etree._Element):\n            elem = xml\n        elif isinstance(xml, Document):\n            xml = xml.toxml()\n            elem = fromstring(xml.encode('utf-8'), forbid_dtd=True)\n        elif isinstance(xml, Element):\n            xml.setAttributeNS(\n                unicode(OneLogin_Saml2_Constants.NS_SAMLP),\n                'xmlns:samlp',\n                unicode(OneLogin_Saml2_Constants.NS_SAMLP)\n            )\n            xml.setAttributeNS(\n                unicode(OneLogin_Saml2_Constants.NS_SAML),\n                'xmlns:saml',\n                unicode(OneLogin_Saml2_Constants.NS_SAML)\n            )\n            xml = xml.toxml()\n            elem = fromstring(xml.encode('utf-8'), forbid_dtd=True)\n        elif isinstance(xml, basestring):\n            elem = fromstring(xml.encode('utf-8'), forbid_dtd=True)\n        else:\n            raise Exception('Error parsing xml string')\n\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        sign_algorithm_transform_map = {\n            OneLogin_Saml2_Constants.DSA_SHA1: xmlsec.TransformDsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA1: xmlsec.TransformRsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA256: xmlsec.TransformRsaSha256,\n            OneLogin_Saml2_Constants.RSA_SHA384: xmlsec.TransformRsaSha384,\n            OneLogin_Saml2_Constants.RSA_SHA512: xmlsec.TransformRsaSha512\n        }\n        sign_algorithm_transform = sign_algorithm_transform_map.get(sign_algorithm, xmlsec.TransformRsaSha1)\n\n        signature = Signature(xmlsec.TransformExclC14N, sign_algorithm_transform, nsPrefix='ds')\n\n        issuer = OneLogin_Saml2_Utils.query(elem, '//saml:Issuer')\n        if len(issuer) > 0:\n            issuer = issuer[0]\n            issuer.addnext(signature)\n            elem_to_sign = issuer.getparent()\n        else:\n            entity_descriptor = OneLogin_Saml2_Utils.query(elem, '//md:EntityDescriptor')\n            if len(entity_descriptor) > 0:\n                elem.insert(0, signature)\n            else:\n                elem[0].insert(0, signature)\n            elem_to_sign = elem\n\n        elem_id = elem_to_sign.get('ID', None)\n        if elem_id is not None:\n            if elem_id:\n                elem_id = '#' + elem_id\n        else:\n            generated_id = generated_id = OneLogin_Saml2_Utils.generate_unique_id()\n            elem_id = '#' + generated_id\n            elem_to_sign.attrib['ID'] = generated_id\n\n        xmlsec.addIDs(elem_to_sign, [\"ID\"])\n\n        digest_algorithm_transform_map = {\n            OneLogin_Saml2_Constants.SHA1: xmlsec.TransformSha1,\n            OneLogin_Saml2_Constants.SHA256: xmlsec.TransformSha256,\n            OneLogin_Saml2_Constants.SHA384: xmlsec.TransformSha384,\n            OneLogin_Saml2_Constants.SHA512: xmlsec.TransformSha512\n        }\n        digest_algorithm_transform = digest_algorithm_transform_map.get(digest_algorithm, xmlsec.TransformSha1)\n\n        ref = signature.addReference(digest_algorithm_transform)\n        if elem_id:\n            ref.attrib['URI'] = elem_id\n\n        ref.addTransform(xmlsec.TransformEnveloped)\n        ref.addTransform(xmlsec.TransformExclC14N)\n\n        key_info = signature.ensureKeyInfo()\n        key_info.addX509Data()\n\n        dsig_ctx = xmlsec.DSigCtx()\n        sign_key = xmlsec.Key.loadMemory(key, xmlsec.KeyDataFormatPem, None)\n\n        file_cert = OneLogin_Saml2_Utils.write_temp_file(cert)\n        sign_key.loadCert(file_cert.name, xmlsec.KeyDataFormatCertPem)\n        file_cert.close()\n\n        dsig_ctx.signKey = sign_key\n        dsig_ctx.sign(signature)\n\n        return tostring(elem, encoding='unicode').encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_sign(xml, cert=None, fingerprint=None, fingerprintalg='sha1', validatecert=False, debug=False, xpath=None, multicerts=None):\n        if xml is None or xml == '':\n            raise Exception('Empty string supplied as input')\n        elif isinstance(xml, etree._Element):\n            elem = xml\n        elif isinstance(xml, Document):\n            xml = xml.toxml()\n            elem = fromstring(str(xml), forbid_dtd=True)\n        elif isinstance(xml, Element):\n            xml.setAttributeNS(\n                unicode(OneLogin_Saml2_Constants.NS_SAMLP),\n                'xmlns:samlp',\n                unicode(OneLogin_Saml2_Constants.NS_SAMLP)\n            )\n            xml.setAttributeNS(\n                unicode(OneLogin_Saml2_Constants.NS_SAML),\n                'xmlns:saml',\n                unicode(OneLogin_Saml2_Constants.NS_SAML)\n            )\n            xml = xml.toxml()\n            elem = fromstring(str(xml), forbid_dtd=True)\n        elif isinstance(xml, basestring):\n            elem = fromstring(str(xml), forbid_dtd=True)\n        else:\n            raise Exception('Error parsing xml string')\n\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        xmlsec.addIDs(elem, [\"ID\"])\n\n        if xpath:\n            signature_nodes = OneLogin_Saml2_Utils.query(elem, xpath)\n        else:\n            signature_nodes = OneLogin_Saml2_Utils.query(elem, OneLogin_Saml2_Utils.RESPONSE_SIGNATURE_XPATH)\n\n            if len(signature_nodes) == 0:\n                signature_nodes = OneLogin_Saml2_Utils.query(elem, OneLogin_Saml2_Utils.ASSERTION_SIGNATURE_XPATH)\n\n        if len(signature_nodes) == 1:\n            signature_node = signature_nodes[0]\n\n            if not multicerts:\n                return OneLogin_Saml2_Utils.validate_node_sign(signature_node, elem, cert, fingerprint, fingerprintalg, validatecert, debug, raise_exceptions=True)\n            else:\n                # If multiple certs are provided, I may ignore cert and\n                # fingerprint provided by the method and just check the\n                # certs multicerts\n                fingerprint = fingerprintalg = None\n                for cert in multicerts:\n                    if OneLogin_Saml2_Utils.validate_node_sign(signature_node, elem, cert, fingerprint, fingerprintalg, validatecert, False, raise_exceptions=False):\n                        return True\n                raise OneLogin_Saml2_ValidationError('Signature validation failed. SAML Response rejected.')\n        else:\n            raise OneLogin_Saml2_ValidationError('Expected exactly one signature node; got {}.'.format(len(signature_nodes)), OneLogin_Saml2_ValidationError.WRONG_NUMBER_OF_SIGNATURES)", "response": "Validates a signature of a SAML 2. 0 XML element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_metadata_sign(xml, cert=None, fingerprint=None, fingerprintalg='sha1', validatecert=False, debug=False):\n        if xml is None or xml == '':\n            raise Exception('Empty string supplied as input')\n        elif isinstance(xml, etree._Element):\n            elem = xml\n        elif isinstance(xml, Document):\n            xml = xml.toxml()\n            elem = fromstring(str(xml), forbid_dtd=True)\n        elif isinstance(xml, Element):\n            xml.setAttributeNS(\n                unicode(OneLogin_Saml2_Constants.NS_MD),\n                'xmlns:md',\n                unicode(OneLogin_Saml2_Constants.NS_MD)\n            )\n            xml = xml.toxml()\n            elem = fromstring(str(xml), forbid_dtd=True)\n        elif isinstance(xml, basestring):\n            elem = fromstring(str(xml), forbid_dtd=True)\n        else:\n            raise Exception('Error parsing xml string')\n\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        xmlsec.addIDs(elem, [\"ID\"])\n\n        signature_nodes = OneLogin_Saml2_Utils.query(elem, '/md:EntitiesDescriptor/ds:Signature')\n\n        if len(signature_nodes) == 0:\n            signature_nodes += OneLogin_Saml2_Utils.query(elem, '/md:EntityDescriptor/ds:Signature')\n\n            if len(signature_nodes) == 0:\n                signature_nodes += OneLogin_Saml2_Utils.query(elem, '/md:EntityDescriptor/md:SPSSODescriptor/ds:Signature')\n                signature_nodes += OneLogin_Saml2_Utils.query(elem, '/md:EntityDescriptor/md:IDPSSODescriptor/ds:Signature')\n\n        if len(signature_nodes) > 0:\n            for signature_node in signature_nodes:\n                OneLogin_Saml2_Utils.validate_node_sign(signature_node, elem, cert, fingerprint, fingerprintalg, validatecert, debug, raise_exceptions=True)\n            return True\n        else:\n            raise Exception('Could not validate metadata signature: No signature nodes found.')", "response": "Validates a metadata signature of a EntityDescriptor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_node_sign(signature_node, elem, cert=None, fingerprint=None, fingerprintalg='sha1', validatecert=False, debug=False):\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        xmlsec.addIDs(elem, [\"ID\"])\n\n        if (cert is None or cert == '') and fingerprint:\n            x509_certificate_nodes = OneLogin_Saml2_Utils.query(signature_node, '//ds:Signature/ds:KeyInfo/ds:X509Data/ds:X509Certificate')\n            if len(x509_certificate_nodes) > 0:\n                x509_certificate_node = x509_certificate_nodes[0]\n                x509_cert_value = OneLogin_Saml2_Utils.element_text(x509_certificate_node)\n                x509_cert_value_formatted = OneLogin_Saml2_Utils.format_cert(x509_cert_value)\n                x509_fingerprint_value = OneLogin_Saml2_Utils.calculate_x509_fingerprint(x509_cert_value_formatted, fingerprintalg)\n\n                if fingerprint == x509_fingerprint_value:\n                    cert = x509_cert_value_formatted\n\n        # Check if Reference URI is empty\n        # reference_elem = OneLogin_Saml2_Utils.query(signature_node, '//ds:Reference')\n        # if len(reference_elem) > 0:\n        #    if reference_elem[0].get('URI') == '':\n        #        reference_elem[0].set('URI', '#%s' % signature_node.getparent().get('ID'))\n\n        if cert is None or cert == '':\n            raise OneLogin_Saml2_Error(\n                'Could not validate node signature: No certificate provided.',\n                OneLogin_Saml2_Error.CERT_NOT_FOUND\n            )\n\n        file_cert = OneLogin_Saml2_Utils.write_temp_file(cert)\n\n        if validatecert:\n            mngr = xmlsec.KeysMngr()\n            mngr.loadCert(file_cert.name, xmlsec.KeyDataFormatCertPem, xmlsec.KeyDataTypeTrusted)\n            dsig_ctx = xmlsec.DSigCtx(mngr)\n        else:\n            dsig_ctx = xmlsec.DSigCtx()\n            dsig_ctx.signKey = xmlsec.Key.load(file_cert.name, xmlsec.KeyDataFormatCertPem, None)\n\n        file_cert.close()\n\n        dsig_ctx.setEnabledKeyData([xmlsec.KeyDataX509])\n\n        try:\n            dsig_ctx.verify(signature_node)\n        except Exception as err:\n            raise OneLogin_Saml2_ValidationError(\n                'Signature validation failed. SAML Response rejected. %s',\n                OneLogin_Saml2_ValidationError.INVALID_SIGNATURE,\n                err.__str__()\n            )\n\n        return True", "response": "Validates a signature node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the binary signature of the element we should use.", "response": "def validate_binary_sign(signed_query, signature, cert=None, algorithm=OneLogin_Saml2_Constants.RSA_SHA1, debug=False):\n        \"\"\"\n        Validates signed binary data (Used to validate GET Signature).\n\n        :param signed_query: The element we should validate\n        :type: string\n\n\n        :param signature: The signature that will be validate\n        :type: string\n\n        :param cert: The public cert\n        :type: string\n\n        :param algorithm: Signature algorithm\n        :type: string\n\n        :param debug: Activate the xmlsec debug\n        :type: bool\n\n        :param raise_exceptions: Whether to return false on failure or raise an exception\n        :type raise_exceptions: Boolean\n        \"\"\"\n        error_callback_method = None\n        if debug:\n            error_callback_method = print_xmlsec_errors\n        xmlsec.set_error_callback(error_callback_method)\n\n        dsig_ctx = xmlsec.DSigCtx()\n\n        file_cert = OneLogin_Saml2_Utils.write_temp_file(cert)\n        dsig_ctx.signKey = xmlsec.Key.load(file_cert.name, xmlsec.KeyDataFormatCertPem, None)\n        file_cert.close()\n\n        # Sign the metadata with our private key.\n        sign_algorithm_transform_map = {\n            OneLogin_Saml2_Constants.DSA_SHA1: xmlsec.TransformDsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA1: xmlsec.TransformRsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA256: xmlsec.TransformRsaSha256,\n            OneLogin_Saml2_Constants.RSA_SHA384: xmlsec.TransformRsaSha384,\n            OneLogin_Saml2_Constants.RSA_SHA512: xmlsec.TransformRsaSha512\n        }\n        sign_algorithm_transform = sign_algorithm_transform_map.get(algorithm, xmlsec.TransformRsaSha1)\n\n        dsig_ctx.verifyBinary(signed_query, sign_algorithm_transform, signature)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_encoded_parameter(get_data, name, default=None, lowercase_urlencoding=False):\n\n        if name not in get_data:\n            return OneLogin_Saml2_Utils.case_sensitive_urlencode(default, lowercase_urlencoding)\n        if 'query_string' in get_data:\n            return OneLogin_Saml2_Utils.extract_raw_query_parameter(get_data['query_string'], name)\n        return OneLogin_Saml2_Utils.case_sensitive_urlencode(get_data[name], lowercase_urlencoding)", "response": "Return a URL encoded get parameter value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __load_settings_from_file(self):\n        filename = self.get_base_path() + 'settings.json'\n\n        if not exists(filename):\n            raise OneLogin_Saml2_Error(\n                'Settings file not found: %s',\n                OneLogin_Saml2_Error.SETTINGS_FILE_NOT_FOUND,\n                filename\n            )\n\n        # In the php toolkit instead of being a json file it is a php file and\n        # it is directly included\n        json_data = open(filename, 'r')\n        settings = json.load(json_data)\n        json_data.close()\n\n        advanced_filename = self.get_base_path() + 'advanced_settings.json'\n        if exists(advanced_filename):\n            json_data = open(advanced_filename, 'r')\n            settings.update(json.load(json_data))  # Merge settings\n            json_data.close()\n\n        return self.__load_settings_from_dict(settings)", "response": "Loads the settings from the json file and returns True if the settings info is valid False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __add_default_values(self):\n        self.__sp.setdefault('assertionConsumerService', {})\n        self.__sp['assertionConsumerService'].setdefault('binding', OneLogin_Saml2_Constants.BINDING_HTTP_POST)\n\n        self.__sp.setdefault('attributeConsumingService', {})\n\n        self.__sp.setdefault('singleLogoutService', {})\n        self.__sp['singleLogoutService'].setdefault('binding', OneLogin_Saml2_Constants.BINDING_HTTP_REDIRECT)\n\n        # Related to nameID\n        self.__sp.setdefault('NameIDFormat', OneLogin_Saml2_Constants.NAMEID_UNSPECIFIED)\n        self.__security.setdefault('nameIdEncrypted', False)\n\n        # Metadata format\n        self.__security.setdefault('metadataValidUntil', None)  # None means use default\n        self.__security.setdefault('metadataCacheDuration', None)  # None means use default\n\n        # Sign provided\n        self.__security.setdefault('authnRequestsSigned', False)\n        self.__security.setdefault('logoutRequestSigned', False)\n        self.__security.setdefault('logoutResponseSigned', False)\n        self.__security.setdefault('signMetadata', False)\n\n        # Sign expected\n        self.__security.setdefault('wantMessagesSigned', False)\n        self.__security.setdefault('wantAssertionsSigned', False)\n\n        # NameID element expected\n        self.__security.setdefault('wantNameId', True)\n\n        # SAML responses with a InResponseTo attribute not rejected when requestId not passed\n        self.__security.setdefault('rejectUnsolicitedResponsesWithInResponseTo', False)\n\n        # Encrypt expected\n        self.__security.setdefault('wantAssertionsEncrypted', False)\n        self.__security.setdefault('wantNameIdEncrypted', False)\n\n        # Signature Algorithm\n        self.__security.setdefault('signatureAlgorithm', OneLogin_Saml2_Constants.RSA_SHA1)\n\n        # Digest Algorithm\n        self.__security.setdefault('digestAlgorithm', OneLogin_Saml2_Constants.SHA1)\n\n        # AttributeStatement required by default\n        self.__security.setdefault('wantAttributeStatement', True)\n\n        self.__idp.setdefault('x509cert', '')\n        self.__idp.setdefault('certFingerprint', '')\n        self.__idp.setdefault('certFingerprintAlgorithm', 'sha1')\n\n        self.__sp.setdefault('x509cert', '')\n        self.__sp.setdefault('privateKey', '')\n\n        self.__security.setdefault('requestedAuthnContext', True)\n        self.__security.setdefault('failOnAuthnContextMismatch', False)", "response": "Add default values to the settings info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the SP settings info.", "response": "def check_sp_settings(self, settings):\n        \"\"\"\n        Checks the SP settings info.\n\n        :param settings: Dict with settings data\n        :type settings: dict\n\n        :returns: Errors found on the SP settings data\n        :rtype: list\n        \"\"\"\n        assert isinstance(settings, dict)\n\n        errors = []\n        if not isinstance(settings, dict) or not settings:\n            errors.append('invalid_syntax')\n        else:\n            if not settings.get('sp'):\n                errors.append('sp_not_found')\n            else:\n                # check_sp_certs uses self.__sp so I add it\n                old_sp = self.__sp\n                self.__sp = settings['sp']\n\n                sp = settings['sp']\n                security = settings.get('security', {})\n\n                if not sp.get('entityId'):\n                    errors.append('sp_entityId_not_found')\n\n                if not sp.get('assertionConsumerService', {}).get('url'):\n                    errors.append('sp_acs_not_found')\n                elif not validate_url(sp['assertionConsumerService']['url']):\n                    errors.append('sp_acs_url_invalid')\n\n                if sp.get('attributeConsumingService'):\n                    attributeConsumingService = sp['attributeConsumingService']\n                    if 'serviceName' not in attributeConsumingService:\n                        errors.append('sp_attributeConsumingService_serviceName_not_found')\n                    elif not isinstance(attributeConsumingService['serviceName'], basestring):\n                        errors.append('sp_attributeConsumingService_serviceName_type_invalid')\n\n                    if 'requestedAttributes' not in attributeConsumingService:\n                        errors.append('sp_attributeConsumingService_requestedAttributes_not_found')\n                    elif not isinstance(attributeConsumingService['requestedAttributes'], list):\n                        errors.append('sp_attributeConsumingService_serviceName_type_invalid')\n                    else:\n                        for req_attrib in attributeConsumingService['requestedAttributes']:\n                            if 'name' not in req_attrib:\n                                errors.append('sp_attributeConsumingService_requestedAttributes_name_not_found')\n                            if 'name' in req_attrib and not req_attrib['name'].strip():\n                                errors.append('sp_attributeConsumingService_requestedAttributes_name_invalid')\n                            if 'attributeValue' in req_attrib and type(req_attrib['attributeValue']) != list:\n                                errors.append('sp_attributeConsumingService_requestedAttributes_attributeValue_type_invalid')\n                            if 'isRequired' in req_attrib and type(req_attrib['isRequired']) != bool:\n                                errors.append('sp_attributeConsumingService_requestedAttributes_isRequired_type_invalid')\n\n                    if \"serviceDescription\" in attributeConsumingService and not isinstance(attributeConsumingService['serviceDescription'], basestring):\n                        errors.append('sp_attributeConsumingService_serviceDescription_type_invalid')\n\n                slo_url = sp.get('singleLogoutService', {}).get('url')\n                if slo_url and not validate_url(slo_url):\n                    errors.append('sp_sls_url_invalid')\n\n                if 'signMetadata' in security and isinstance(security['signMetadata'], dict):\n                    if 'keyFileName' not in security['signMetadata'] or \\\n                            'certFileName' not in security['signMetadata']:\n                        errors.append('sp_signMetadata_invalid')\n\n                authn_sign = bool(security.get('authnRequestsSigned'))\n                logout_req_sign = bool(security.get('logoutRequestSigned'))\n                logout_res_sign = bool(security.get('logoutResponseSigned'))\n                want_assert_enc = bool(security.get('wantAssertionsEncrypted'))\n                want_nameid_enc = bool(security.get('wantNameIdEncrypted'))\n\n                if not self.check_sp_certs():\n                    if authn_sign or logout_req_sign or logout_res_sign or \\\n                       want_assert_enc or want_nameid_enc:\n                        errors.append('sp_cert_not_found_and_required')\n\n            if 'contactPerson' in settings:\n                types = settings['contactPerson'].keys()\n                valid_types = ['technical', 'support', 'administrative', 'billing', 'other']\n                for c_type in types:\n                    if c_type not in valid_types:\n                        errors.append('contact_type_invalid')\n                        break\n\n                for c_type in settings['contactPerson']:\n                    contact = settings['contactPerson'][c_type]\n                    if ('givenName' not in contact or len(contact['givenName']) == 0) or \\\n                            ('emailAddress' not in contact or len(contact['emailAddress']) == 0):\n                        errors.append('contact_not_enought_data')\n                        break\n\n            if 'organization' in settings:\n                for org in settings['organization']:\n                    organization = settings['organization'][org]\n                    if ('name' not in organization or len(organization['name']) == 0) or \\\n                        ('displayname' not in organization or len(organization['displayname']) == 0) or \\\n                            ('url' not in organization or len(organization['url']) == 0):\n                        errors.append('organization_not_enought_data')\n                        break\n            # Restores the value that had the self.__sp\n            if 'old_sp' in locals():\n                self.__sp = old_sp\n\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_metadata(self, xml):\n\n        assert isinstance(xml, basestring)\n\n        if len(xml) == 0:\n            raise Exception('Empty string supplied as input')\n\n        errors = []\n        res = OneLogin_Saml2_Utils.validate_xml(xml, 'saml-schema-metadata-2.0.xsd', self.__debug)\n        if not isinstance(res, Document):\n            errors.append(res)\n        else:\n            dom = res\n            element = dom.documentElement\n            if element.tagName not in 'md:EntityDescriptor':\n                errors.append('noEntityDescriptor_xml')\n            else:\n                if len(element.getElementsByTagName('md:SPSSODescriptor')) != 1:\n                    errors.append('onlySPSSODescriptor_allowed_xml')\n                else:\n                    valid_until = cache_duration = expire_time = None\n\n                    if element.hasAttribute('validUntil'):\n                        valid_until = OneLogin_Saml2_Utils.parse_SAML_to_time(element.getAttribute('validUntil'))\n                    if element.hasAttribute('cacheDuration'):\n                        cache_duration = element.getAttribute('cacheDuration')\n\n                    expire_time = OneLogin_Saml2_Utils.get_expire_time(cache_duration, valid_until)\n                    if expire_time is not None and int(time()) > int(expire_time):\n                        errors.append('expired_xml')\n\n        # TODO: Validate Sign\n\n        return errors", "response": "Validates an XML SP Metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the requested SAML attribute.", "response": "def get_attribute(self, name):\n        \"\"\"\n        Returns the requested SAML attribute.\n\n        :param name: Name of the attribute\n        :type name: string\n\n        :returns: Attribute value if exists or []\n        :rtype: string\n        \"\"\"\n        assert isinstance(name, basestring)\n        value = None\n        if self.__attributes and name in self.__attributes.keys():\n            value = self.__attributes[name]\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitiate the SSO process. :param return_to: Optional argument. The target URL the user should be redirected to after login. :type return_to: string :param force_authn: Optional argument. When true the AuthNRequest will set the ForceAuthn='true'. :type force_authn: bool :param is_passive: Optional argument. When true the AuthNRequest will set the Ispassive='true'. :type is_passive: bool :param set_nameid_policy: Optional argument. When true the AuthNRequest will set a nameIdPolicy element. :type set_nameid_policy: bool :param name_id_value_req: Optional argument. Indicates to the IdP the subject that should be authenticated :type name_id_value_req: string :returns: Redirection URL :rtype: string", "response": "def login(self, return_to=None, force_authn=False, is_passive=False, set_nameid_policy=True, name_id_value_req=None):\n        \"\"\"\n        Initiates the SSO process.\n\n        :param return_to: Optional argument. The target URL the user should be redirected to after login.\n        :type return_to: string\n\n        :param force_authn: Optional argument. When true the AuthNRequest will set the ForceAuthn='true'.\n        :type force_authn: bool\n\n        :param is_passive: Optional argument. When true the AuthNRequest will set the Ispassive='true'.\n        :type is_passive: bool\n\n        :param set_nameid_policy: Optional argument. When true the AuthNRequest will set a nameIdPolicy element.\n        :type set_nameid_policy: bool\n\n        :param name_id_value_req: Optional argument. Indicates to the IdP the subject that should be authenticated\n        :type name_id_value_req: string\n\n        :returns: Redirection URL\n        :rtype: string\n        \"\"\"\n        authn_request = OneLogin_Saml2_Authn_Request(self.__settings, force_authn, is_passive, set_nameid_policy, name_id_value_req)\n        self.__last_request = authn_request.get_xml()\n        self.__last_request_id = authn_request.get_id()\n        saml_request = authn_request.get_request()\n\n        parameters = {'SAMLRequest': saml_request}\n        if return_to is not None:\n            parameters['RelayState'] = return_to\n        else:\n            parameters['RelayState'] = OneLogin_Saml2_Utils.get_self_url_no_query(self.__request_data)\n\n        security = self.__settings.get_security_data()\n        if security.get('authnRequestsSigned', False):\n            parameters['SigAlg'] = security['signatureAlgorithm']\n            parameters['Signature'] = self.build_request_signature(saml_request, parameters['RelayState'], security['signatureAlgorithm'])\n        return self.redirect_to(self.get_sso_url(), parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logout(self, return_to=None, name_id=None, session_index=None, nq=None, name_id_format=None):\n        slo_url = self.get_slo_url()\n        if slo_url is None:\n            raise OneLogin_Saml2_Error(\n                'The IdP does not support Single Log Out',\n                OneLogin_Saml2_Error.SAML_SINGLE_LOGOUT_NOT_SUPPORTED\n            )\n\n        if name_id is None and self.__nameid is not None:\n            name_id = self.__nameid\n        if name_id_format is None and self.__nameid_format is not None:\n            name_id_format = self.__nameid_format\n\n        logout_request = OneLogin_Saml2_Logout_Request(\n            self.__settings,\n            name_id=name_id,\n            session_index=session_index,\n            nq=nq,\n            name_id_format=name_id_format\n        )\n        self.__last_request = logout_request.get_xml()\n        self.__last_request_id = logout_request.id\n        saml_request = logout_request.get_request()\n\n        parameters = {'SAMLRequest': logout_request.get_request()}\n        if return_to is not None:\n            parameters['RelayState'] = return_to\n        else:\n            parameters['RelayState'] = OneLogin_Saml2_Utils.get_self_url_no_query(self.__request_data)\n\n        security = self.__settings.get_security_data()\n        if security.get('logoutRequestSigned', False):\n            parameters['SigAlg'] = security['signatureAlgorithm']\n            parameters['Signature'] = self.build_request_signature(saml_request, parameters['RelayState'], security['signatureAlgorithm'])\n        return self.redirect_to(slo_url, parameters)", "response": "Initiates the SLO process.\n\n        :param return_to: Optional argument. The target URL the user should be redirected to after logout.\n        :type return_to: string\n\n        :param name_id: The NameID that will be set in the LogoutRequest.\n        :type name_id: string\n\n        :param session_index: SessionIndex that identifies the session of the user.\n        :type session_index: string\n\n        :param nq: IDP Name Qualifier\n        :type: string\n\n        :param name_id_format: The NameID Format that will be set in the LogoutRequest.\n        :type: string\n\n        :returns: Redirection url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_slo_url(self):\n        url = None\n        idp_data = self.__settings.get_idp_data()\n        if 'singleLogoutService' in idp_data.keys() and 'url' in idp_data['singleLogoutService']:\n            url = idp_data['singleLogoutService']['url']\n        return url", "response": "Gets the SLO URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the Signature of the SAML Request.", "response": "def build_request_signature(self, saml_request, relay_state, sign_algorithm=OneLogin_Saml2_Constants.RSA_SHA1):\n        \"\"\"\n        Builds the Signature of the SAML Request.\n\n        :param saml_request: The SAML Request\n        :type saml_request: string\n\n        :param relay_state: The target URL the user should be redirected to\n        :type relay_state: string\n\n        :param sign_algorithm: Signature algorithm method\n        :type sign_algorithm: string\n        \"\"\"\n        return self.__build_signature(saml_request, relay_state, 'SAMLRequest', sign_algorithm)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the Signature of the SAML Response.", "response": "def build_response_signature(self, saml_response, relay_state, sign_algorithm=OneLogin_Saml2_Constants.RSA_SHA1):\n        \"\"\"\n        Builds the Signature of the SAML Response.\n        :param saml_request: The SAML Response\n        :type saml_request: string\n\n        :param relay_state: The target URL the user should be redirected to\n        :type relay_state: string\n\n        :param sign_algorithm: Signature algorithm method\n        :type sign_algorithm: string\n        \"\"\"\n        return self.__build_signature(saml_response, relay_state, 'SAMLResponse', sign_algorithm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the Signature for the SAML request and response.", "response": "def __build_signature(self, saml_data, relay_state, saml_type, sign_algorithm=OneLogin_Saml2_Constants.RSA_SHA1):\n        \"\"\"\n        Builds the Signature\n        :param saml_data: The SAML Data\n        :type saml_data: string\n\n        :param relay_state: The target URL the user should be redirected to\n        :type relay_state: string\n\n        :param saml_type: The target URL the user should be redirected to\n        :type saml_type: string  SAMLRequest | SAMLResponse\n\n        :param sign_algorithm: Signature algorithm method\n        :type sign_algorithm: string\n        \"\"\"\n        assert saml_type in ['SAMLRequest', 'SAMLResponse']\n\n        # Load the key into the xmlsec context\n        key = self.__settings.get_sp_key()\n\n        if not key:\n            raise OneLogin_Saml2_Error(\n                \"Trying to sign the %s but can't load the SP private key\" % saml_type,\n                OneLogin_Saml2_Error.PRIVATE_KEY_NOT_FOUND\n            )\n\n        dsig_ctx = xmlsec.DSigCtx()\n        dsig_ctx.signKey = xmlsec.Key.loadMemory(key, xmlsec.KeyDataFormatPem, None)\n\n        msg = '%s=%s' % (saml_type, quote_plus(saml_data))\n        if relay_state is not None:\n            msg += '&RelayState=%s' % quote_plus(relay_state)\n        msg += '&SigAlg=%s' % quote_plus(sign_algorithm)\n\n        # Sign the metadata with our private key.\n        sign_algorithm_transform_map = {\n            OneLogin_Saml2_Constants.DSA_SHA1: xmlsec.TransformDsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA1: xmlsec.TransformRsaSha1,\n            OneLogin_Saml2_Constants.RSA_SHA256: xmlsec.TransformRsaSha256,\n            OneLogin_Saml2_Constants.RSA_SHA384: xmlsec.TransformRsaSha384,\n            OneLogin_Saml2_Constants.RSA_SHA512: xmlsec.TransformRsaSha512\n        }\n        sign_algorithm_transform = sign_algorithm_transform_map.get(sign_algorithm, xmlsec.TransformRsaSha1)\n\n        signature = dsig_ctx.signBinary(str(msg), sign_algorithm_transform)\n        return b64encode(signature)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_last_response_xml(self, pretty_print_if_possible=False):\n        response = None\n        if self.__last_response is not None:\n            if isinstance(self.__last_response, basestring):\n                response = self.__last_response\n            else:\n                response = tostring(self.__last_response, pretty_print=pretty_print_if_possible)\n        return response", "response": "Retrieves the raw XML of the last SAML response generated or processed by the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the metadata of the SP", "response": "def builder(sp, authnsign=False, wsign=False, valid_until=None, cache_duration=None, contacts=None, organization=None):\n        \"\"\"\n        Builds the metadata of the SP\n\n        :param sp: The SP data\n        :type sp: string\n\n        :param authnsign: authnRequestsSigned attribute\n        :type authnsign: string\n\n        :param wsign: wantAssertionsSigned attribute\n        :type wsign: string\n\n        :param valid_until: Metadata's expiry date\n        :type valid_until: string|DateTime|Timestamp\n\n        :param cache_duration: Duration of the cache in seconds\n        :type cache_duration: int|string\n\n        :param contacts: Contacts info\n        :type contacts: dict\n\n        :param organization: Organization info\n        :type organization: dict\n        \"\"\"\n        if valid_until is None:\n            valid_until = int(time()) + OneLogin_Saml2_Metadata.TIME_VALID\n        if not isinstance(valid_until, basestring):\n            if isinstance(valid_until, datetime):\n                valid_until_time = valid_until.timetuple()\n            else:\n                valid_until_time = gmtime(valid_until)\n            valid_until_str = strftime(r'%Y-%m-%dT%H:%M:%SZ', valid_until_time)\n        else:\n            valid_until_str = valid_until\n\n        if cache_duration is None:\n            cache_duration = OneLogin_Saml2_Metadata.TIME_CACHED\n        if not isinstance(cache_duration, basestring):\n            cache_duration_str = 'PT%sS' % cache_duration  # 'P'eriod of 'T'ime x 'S'econds\n        else:\n            cache_duration_str = cache_duration\n\n        if contacts is None:\n            contacts = {}\n        if organization is None:\n            organization = {}\n\n        str_attribute_consuming_service = ''\n        if 'attributeConsumingService' in sp and len(sp['attributeConsumingService']):\n            attr_cs_desc_str = ''\n            if \"serviceDescription\" in sp['attributeConsumingService']:\n                attr_cs_desc_str = \"\"\"            <md:ServiceDescription xml:lang=\"en\">%s</md:ServiceDescription>\n\"\"\" % sp['attributeConsumingService']['serviceDescription']\n\n            requested_attribute_data = []\n            for req_attribs in sp['attributeConsumingService']['requestedAttributes']:\n                req_attr_nameformat_str = req_attr_friendlyname_str = req_attr_isrequired_str = ''\n                req_attr_aux_str = ' />'\n\n                if 'nameFormat' in req_attribs.keys() and req_attribs['nameFormat']:\n                    req_attr_nameformat_str = \" NameFormat=\\\"%s\\\"\" % req_attribs['nameFormat']\n                if 'friendlyName' in req_attribs.keys() and req_attribs['friendlyName']:\n                    req_attr_friendlyname_str = \" FriendlyName=\\\"%s\\\"\" % req_attribs['friendlyName']\n                if 'isRequired' in req_attribs.keys() and req_attribs['isRequired']:\n                    req_attr_isrequired_str = \" isRequired=\\\"%s\\\"\" % 'true' if req_attribs['isRequired'] else 'false'\n\n                if 'attributeValue' in req_attribs.keys() and req_attribs['attributeValue']:\n                    if isinstance(req_attribs['attributeValue'], basestring):\n                        req_attribs['attributeValue'] = [req_attribs['attributeValue']]\n\n                    req_attr_aux_str = \">\"\n                    for attrValue in req_attribs['attributeValue']:\n                        req_attr_aux_str += \"\"\"\n                <saml:AttributeValue xmlns:saml=\"urn:oasis:names:tc:SAML:2.0:assertion\">%(attributeValue)s</saml:AttributeValue>\"\"\" % \\\n                            {\n                                'attributeValue': attrValue\n                            }\n                    req_attr_aux_str += \"\"\"\n            </md:RequestedAttribute>\"\"\"\n\n                requested_attribute = \"\"\"            <md:RequestedAttribute Name=\"%(req_attr_name)s\"%(req_attr_nameformat_str)s%(req_attr_friendlyname_str)s%(req_attr_isrequired_str)s%(req_attr_aux_str)s\"\"\" % \\\n                    {\n                        'req_attr_name': req_attribs['name'],\n                        'req_attr_nameformat_str': req_attr_nameformat_str,\n                        'req_attr_friendlyname_str': req_attr_friendlyname_str,\n                        'req_attr_isrequired_str': req_attr_isrequired_str,\n                        'req_attr_aux_str': req_attr_aux_str\n                    }\n\n                requested_attribute_data.append(requested_attribute)\n\n            str_attribute_consuming_service = \"\"\"        <md:AttributeConsumingService index=\"1\">\n            <md:ServiceName xml:lang=\"en\">%(service_name)s</md:ServiceName>\n%(attr_cs_desc)s%(requested_attribute_str)s\n        </md:AttributeConsumingService>\n\"\"\" % \\\n                {\n                    'service_name': sp['attributeConsumingService']['serviceName'],\n                    'attr_cs_desc': attr_cs_desc_str,\n                    'requested_attribute_str': '\\n'.join(requested_attribute_data)\n                }\n\n        sls = ''\n        if 'singleLogoutService' in sp and 'url' in sp['singleLogoutService']:\n            sls = \"\"\"        <md:SingleLogoutService Binding=\"%(binding)s\"\n                                Location=\"%(location)s\" />\\n\"\"\" % \\\n                {\n                    'binding': sp['singleLogoutService']['binding'],\n                    'location': sp['singleLogoutService']['url'],\n                }\n\n        str_authnsign = 'true' if authnsign else 'false'\n        str_wsign = 'true' if wsign else 'false'\n\n        str_organization = ''\n        if len(organization) > 0:\n            organization_names = []\n            organization_displaynames = []\n            organization_urls = []\n            for (lang, info) in organization.items():\n                organization_names.append(\"\"\"        <md:OrganizationName xml:lang=\"%s\">%s</md:OrganizationName>\"\"\" % (lang, info['name']))\n                organization_displaynames.append(\"\"\"        <md:OrganizationDisplayName xml:lang=\"%s\">%s</md:OrganizationDisplayName>\"\"\" % (lang, info['displayname']))\n                organization_urls.append(\"\"\"        <md:OrganizationURL xml:lang=\"%s\">%s</md:OrganizationURL>\"\"\" % (lang, info['url']))\n            org_data = '\\n'.join(organization_names) + '\\n' + '\\n'.join(organization_displaynames) + '\\n' + '\\n'.join(organization_urls)\n            str_organization = \"\"\"    <md:Organization>\n%(org)s\n    </md:Organization>\\n\"\"\" % {'org': org_data}\n\n        str_contacts = ''\n        if len(contacts) > 0:\n            contacts_info = []\n            for (ctype, info) in contacts.items():\n                contact = \"\"\"    <md:ContactPerson contactType=\"%(type)s\">\n        <md:GivenName>%(name)s</md:GivenName>\n        <md:EmailAddress>%(email)s</md:EmailAddress>\n    </md:ContactPerson>\"\"\" % \\\n                    {\n                        'type': ctype,\n                        'name': info['givenName'],\n                        'email': info['emailAddress'],\n                    }\n                contacts_info.append(contact)\n            str_contacts = '\\n'.join(contacts_info) + '\\n'\n\n        metadata = u\"\"\"<?xml version=\"1.0\"?>\n<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\"\n                     %(valid)s\n                     %(cache)s\n                     entityID=\"%(entity_id)s\">\n    <md:SPSSODescriptor AuthnRequestsSigned=\"%(authnsign)s\" WantAssertionsSigned=\"%(wsign)s\" protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\">\n%(sls)s        <md:NameIDFormat>%(name_id_format)s</md:NameIDFormat>\n        <md:AssertionConsumerService Binding=\"%(binding)s\"\n                                     Location=\"%(location)s\"\n                                     index=\"1\" />\n%(attribute_consuming_service)s    </md:SPSSODescriptor>\n%(organization)s%(contacts)s</md:EntityDescriptor>\"\"\" % \\\n            {\n                'valid': ('validUntil=\"%s\"' % valid_until_str) if valid_until_str else '',\n                'cache': ('cacheDuration=\"%s\"' % cache_duration_str) if cache_duration_str else '',\n                'entity_id': sp['entityId'],\n                'authnsign': str_authnsign,\n                'wsign': str_wsign,\n                'name_id_format': sp['NameIDFormat'],\n                'binding': sp['assertionConsumerService']['binding'],\n                'location': sp['assertionConsumerService']['url'],\n                'sls': sls,\n                'organization': str_organization,\n                'contacts': str_contacts,\n                'attribute_consuming_service': str_attribute_consuming_service\n            }\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the x509 key descriptors to the metadata XML.", "response": "def add_x509_key_descriptors(metadata, cert=None, add_encryption=True):\n        \"\"\"\n        Adds the x509 descriptors (sign/encryption) to the metadata\n        The same cert will be used for sign/encrypt\n\n        :param metadata: SAML Metadata XML\n        :type metadata: string\n\n        :param cert: x509 cert\n        :type cert: string\n\n        :param add_encryption: Determines if the KeyDescriptor[use=\"encryption\"] should be added.\n        :type add_encryption: boolean\n\n        :returns: Metadata with KeyDescriptors\n        :rtype: string\n        \"\"\"\n        if cert is None or cert == '':\n            return metadata\n        try:\n            xml = parseString(metadata.encode('utf-8'), forbid_dtd=True)\n        except Exception as e:\n            raise Exception('Error parsing metadata. ' + e.message)\n\n        formated_cert = OneLogin_Saml2_Utils.format_cert(cert, False)\n        x509_certificate = xml.createElementNS(OneLogin_Saml2_Constants.NS_DS, 'ds:X509Certificate')\n        content = xml.createTextNode(formated_cert)\n        x509_certificate.appendChild(content)\n\n        key_data = xml.createElementNS(OneLogin_Saml2_Constants.NS_DS, 'ds:X509Data')\n        key_data.appendChild(x509_certificate)\n\n        key_info = xml.createElementNS(OneLogin_Saml2_Constants.NS_DS, 'ds:KeyInfo')\n        key_info.appendChild(key_data)\n\n        key_descriptor = xml.createElementNS(OneLogin_Saml2_Constants.NS_DS, 'md:KeyDescriptor')\n\n        entity_descriptor = xml.getElementsByTagName('md:EntityDescriptor')[0]\n\n        sp_sso_descriptor = entity_descriptor.getElementsByTagName('md:SPSSODescriptor')[0]\n        sp_sso_descriptor.insertBefore(key_descriptor.cloneNode(True), sp_sso_descriptor.firstChild)\n        if add_encryption:\n            sp_sso_descriptor.insertBefore(key_descriptor.cloneNode(True), sp_sso_descriptor.firstChild)\n\n        signing = xml.getElementsByTagName('md:KeyDescriptor')[0]\n        signing.setAttribute('use', 'signing')\n        signing.appendChild(key_info)\n        signing.setAttribute('xmlns:ds', OneLogin_Saml2_Constants.NS_DS)\n\n        if add_encryption:\n            encryption = xml.getElementsByTagName('md:KeyDescriptor')[1]\n            encryption.setAttribute('use', 'encryption')\n            encryption.appendChild(key_info.cloneNode(True))\n            encryption.setAttribute('xmlns:ds', OneLogin_Saml2_Constants.NS_DS)\n\n        return xml.toxml()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the Logout Request maybe deflated base64 encoded", "response": "def get_request(self, deflate=True):\n        \"\"\"\n        Returns the Logout Request deflated, base64encoded\n        :param deflate: It makes the deflate process optional\n        :type: bool\n        :return: Logout Request maybe deflated and base64 encoded\n        :rtype: str object\n        \"\"\"\n        if deflate:\n            request = OneLogin_Saml2_Utils.deflate_and_base64_encode(self.__logout_request)\n        else:\n            request = b64encode(self.__logout_request)\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the ID of the Logout Request", "response": "def get_id(request):\n        \"\"\"\n        Returns the ID of the Logout Request\n        :param request: Logout Request Message\n        :type request: string|DOMDocument\n        :return: string ID\n        :rtype: str object\n        \"\"\"\n        if isinstance(request, etree._Element):\n            elem = request\n        else:\n            if isinstance(request, Document):\n                request = request.toxml()\n            elem = fromstring(request, forbid_dtd=True)\n        return elem.get('ID', None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_nameid_data(request, key=None):\n        if isinstance(request, etree._Element):\n            elem = request\n        else:\n            if isinstance(request, Document):\n                request = request.toxml()\n            elem = fromstring(request, forbid_dtd=True)\n\n        name_id = None\n        encrypted_entries = OneLogin_Saml2_Utils.query(elem, '/samlp:LogoutRequest/saml:EncryptedID')\n\n        if len(encrypted_entries) == 1:\n            if key is None:\n                raise OneLogin_Saml2_Error(\n                    'Private Key is required in order to decrypt the NameID, check settings',\n                    OneLogin_Saml2_Error.PRIVATE_KEY_NOT_FOUND\n                )\n\n            encrypted_data_nodes = OneLogin_Saml2_Utils.query(elem, '/samlp:LogoutRequest/saml:EncryptedID/xenc:EncryptedData')\n            if len(encrypted_data_nodes) == 1:\n                encrypted_data = encrypted_data_nodes[0]\n                name_id = OneLogin_Saml2_Utils.decrypt_element(encrypted_data, key)\n        else:\n            entries = OneLogin_Saml2_Utils.query(elem, '/samlp:LogoutRequest/saml:NameID')\n            if len(entries) == 1:\n                name_id = entries[0]\n\n        if name_id is None:\n            raise OneLogin_Saml2_ValidationError(\n                'NameID not found in the Logout Request',\n                OneLogin_Saml2_ValidationError.NO_NAMEID\n            )\n\n        name_id_data = {\n            'Value': OneLogin_Saml2_Utils.element_text(name_id)\n        }\n        for attr in ['Format', 'SPNameQualifier', 'NameQualifier']:\n            if attr in name_id.attrib.keys():\n                name_id_data[attr] = name_id.attrib[attr]\n\n        return name_id_data", "response": "Gets the NameID Data of the Logout Request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_issuer(request):\n        if isinstance(request, etree._Element):\n            elem = request\n        else:\n            if isinstance(request, Document):\n                request = request.toxml()\n            elem = fromstring(request, forbid_dtd=True)\n\n        issuer = None\n        issuer_nodes = OneLogin_Saml2_Utils.query(elem, '/samlp:LogoutRequest/saml:Issuer')\n        if len(issuer_nodes) == 1:\n            issuer = OneLogin_Saml2_Utils.element_text(issuer_nodes[0])\n        return issuer", "response": "Gets the Issuer of the Logout Request Message\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the SessionIndexes from the Logout Request.", "response": "def get_session_indexes(request):\n        \"\"\"\n        Gets the SessionIndexes from the Logout Request\n        :param request: Logout Request Message\n        :type request: string|DOMDocument\n        :return: The SessionIndex value\n        :rtype: list\n        \"\"\"\n        if isinstance(request, etree._Element):\n            elem = request\n        else:\n            if isinstance(request, Document):\n                request = request.toxml()\n            elem = fromstring(request, forbid_dtd=True)\n\n        session_indexes = []\n        session_index_nodes = OneLogin_Saml2_Utils.query(elem, '/samlp:LogoutRequest/samlp:SessionIndex')\n        for session_index_node in session_index_nodes:\n            session_indexes.append(OneLogin_Saml2_Utils.element_text(session_index_node))\n        return session_indexes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid(self, request_data, raise_exceptions=False):\n        self.__error = None\n        lowercase_urlencoding = False\n        try:\n            dom = fromstring(self.__logout_request, forbid_dtd=True)\n\n            idp_data = self.__settings.get_idp_data()\n            idp_entity_id = idp_data['entityId']\n\n            if 'get_data' in request_data.keys():\n                get_data = request_data['get_data']\n            else:\n                get_data = {}\n\n            if 'lowercase_urlencoding' in request_data.keys():\n                lowercase_urlencoding = request_data['lowercase_urlencoding']\n\n            if self.__settings.is_strict():\n                res = OneLogin_Saml2_Utils.validate_xml(dom, 'saml-schema-protocol-2.0.xsd', self.__settings.is_debug_active())\n                if not isinstance(res, Document):\n                    raise OneLogin_Saml2_ValidationError(\n                        'Invalid SAML Logout Request. Not match the saml-schema-protocol-2.0.xsd',\n                        OneLogin_Saml2_ValidationError.INVALID_XML_FORMAT\n                    )\n\n                security = self.__settings.get_security_data()\n\n                current_url = OneLogin_Saml2_Utils.get_self_url_no_query(request_data)\n\n                # Check NotOnOrAfter\n                if dom.get('NotOnOrAfter', None):\n                    na = OneLogin_Saml2_Utils.parse_SAML_to_time(dom.get('NotOnOrAfter'))\n                    if na <= OneLogin_Saml2_Utils.now():\n                        raise OneLogin_Saml2_ValidationError(\n                            'Could not validate timestamp: expired. Check system clock.',\n                            OneLogin_Saml2_ValidationError.RESPONSE_EXPIRED\n                        )\n\n                # Check destination\n                if dom.get('Destination', None):\n                    destination = dom.get('Destination')\n                    if destination != '':\n                        if current_url not in destination:\n                            raise Exception(\n                                'The LogoutRequest was received at '\n                                '%(currentURL)s instead of %(destination)s' %\n                                {\n                                    'currentURL': current_url,\n                                    'destination': destination,\n                                },\n                                OneLogin_Saml2_ValidationError.WRONG_DESTINATION\n                            )\n\n                # Check issuer\n                issuer = OneLogin_Saml2_Logout_Request.get_issuer(dom)\n                if issuer is not None and issuer != idp_entity_id:\n                    raise OneLogin_Saml2_ValidationError(\n                        'Invalid issuer in the Logout Request (expected %(idpEntityId)s, got %(issuer)s)' %\n                        {\n                            'idpEntityId': idp_entity_id,\n                            'issuer': issuer\n                        },\n                        OneLogin_Saml2_ValidationError.WRONG_ISSUER\n                    )\n\n                if security['wantMessagesSigned']:\n                    if 'Signature' not in get_data:\n                        raise OneLogin_Saml2_ValidationError(\n                            'The Message of the Logout Request is not signed and the SP require it',\n                            OneLogin_Saml2_ValidationError.NO_SIGNED_MESSAGE\n                        )\n\n            if 'Signature' in get_data:\n                if 'SigAlg' not in get_data:\n                    sign_alg = OneLogin_Saml2_Constants.RSA_SHA1\n                else:\n                    sign_alg = get_data['SigAlg']\n\n                signed_query = 'SAMLRequest=%s' % OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'SAMLRequest', lowercase_urlencoding=lowercase_urlencoding)\n                if 'RelayState' in get_data:\n                    signed_query = '%s&RelayState=%s' % (signed_query, OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'RelayState', lowercase_urlencoding=lowercase_urlencoding))\n                signed_query = '%s&SigAlg=%s' % (signed_query, OneLogin_Saml2_Utils.get_encoded_parameter(get_data, 'SigAlg', OneLogin_Saml2_Constants.RSA_SHA1, lowercase_urlencoding=lowercase_urlencoding))\n\n                exists_x509cert = 'x509cert' in idp_data and idp_data['x509cert']\n                exists_multix509sign = 'x509certMulti' in idp_data and \\\n                    'signing' in idp_data['x509certMulti'] and \\\n                    idp_data['x509certMulti']['signing']\n\n                if not (exists_x509cert or exists_multix509sign):\n                    raise OneLogin_Saml2_Error(\n                        'In order to validate the sign on the Logout Request, the x509cert of the IdP is required',\n                        OneLogin_Saml2_Error.CERT_NOT_FOUND\n                    )\n                if exists_multix509sign:\n                    for cert in idp_data['x509certMulti']['signing']:\n                        if OneLogin_Saml2_Utils.validate_binary_sign(signed_query, b64decode(get_data['Signature']), cert, sign_alg):\n                            return True\n                    raise OneLogin_Saml2_ValidationError(\n                        'Signature validation failed. Logout Request rejected',\n                        OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                    )\n                else:\n                    cert = idp_data['x509cert']\n\n                    if not OneLogin_Saml2_Utils.validate_binary_sign(signed_query, b64decode(get_data['Signature']), cert, sign_alg):\n                        raise OneLogin_Saml2_ValidationError(\n                            'Signature validation failed. Logout Request rejected',\n                            OneLogin_Saml2_ValidationError.INVALID_SIGNATURE\n                        )\n            return True\n        except Exception as err:\n            # pylint: disable=R0801sign_alg\n            self.__error = err.__str__()\n            debug = self.__settings.is_debug_active()\n            if debug:\n                print(err.__str__())\n            if raise_exceptions:\n                raise err\n            return False", "response": "Checks if the Logout Request received is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_model(ts, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n\n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.EWMA.fitModel(_py2java(sc, Vectors.dense(ts)))\n    return EWMAModel(jmodel=jmodel, sc=sc)", "response": "Fits an EWMA model to a time series."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding PySpark to the library path based on the value of SPARK_HOME.", "response": "def add_pyspark_path():\n    \"\"\"Add PySpark to the library path based on the value of SPARK_HOME. \"\"\"\n\n    try:\n        spark_home = os.environ['SPARK_HOME']\n\n        sys.path.append(os.path.join(spark_home, 'python'))\n        py4j_src_zip = glob(os.path.join(spark_home, 'python',\n                                         'lib', 'py4j-*-src.zip'))\n        if len(py4j_src_zip) == 0:\n            raise ValueError('py4j source archive not found in %s'\n                             % os.path.join(spark_home, 'python', 'lib'))\n        else:\n            py4j_src_zip = sorted(py4j_src_zip)[::-1]\n            sys.path.append(py4j_src_zip[0])\n    except KeyError:\n        logging.error(\"\"\"SPARK_HOME was not set. please set it. e.g.\n          SPARK_HOME='/home/...' ./bin/pyspark [program]\"\"\")\n        exit(-1)\n    except ValueError as e:\n        logging.error(str(e))\n        exit(-1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a datetime object to nanoseconds since the epoch.", "response": "def datetime_to_nanos(dt):\n    \"\"\"\n    Accepts a string, Pandas Timestamp, or long, and returns nanos since the epoch.\n    \"\"\"\n    if isinstance(dt, pd.Timestamp):\n        return dt.value\n    elif isinstance(dt, str):\n        return pd.Timestamp(dt).value\n    elif isinstance(dt, long):\n        return dt\n    elif isinstance(dt, datetime):\n\treturn long(dt.strftime(\"%s%f\")) * 1000\n\n    raise ValueError"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autofit(ts, maxp=5, maxd=2, maxq=5, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n    \n    jmodel = sc._jvm.com.cloudera.sparkts.models.ARIMA.autoFit(_py2java(sc, Vectors.dense(ts)), maxp, maxd, maxq)\n    return ARIMAModel(jmodel=jmodel, sc=sc)", "response": "This function automatically fit an ARIMA model based on the given time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_model(p, d, q, ts, includeIntercept=True, method=\"css-cgd\", userInitParams=None, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.ARIMA.fitModel(p, d, q, _py2java(sc, Vectors.dense(ts)), includeIntercept, method, _py2java_double_array(sc, userInitParams))\n    return ARIMAModel(jmodel=jmodel, sc=sc)", "response": "Given a time series fit an ARIMA model of order p d q."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_likelihood_css(self, y):\n        likelihood = self._jmodel.logLikelihoodCSS(_py2java(self._ctx, y))\n        return _java2py(self._ctx, likelihood)", "response": "Returns the log likelihood of a DenseVector\n ArcGIS time series y."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_likelihood_css_arma(self, diffedy):\n        # need to copy diffedy to a double[] for Java\n        likelihood =  self._jmodel.logLikelihoodCSSARMA(_py2java_double_array(self._ctx, diffedy))\n        return _java2py(self._ctx, likelihood)", "response": "Returns the log likelihood of the ARMA with conditional sum of squares."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the gradient log likelihood function using CSS Derivation", "response": "def gradient_log_likelihood_css_arma(self, diffedy):\n        \"\"\"\n        Calculates the gradient for the log likelihood function using CSS\n        Derivation:\n            L(y | \\theta) = -\\frac{n}{2}log(2\\pi\\sigma^2) - \\frac{1}{2\\pi}\\sum_{i=1}^n \\epsilon_t^2 \\\\\n            \\sigma^2 = \\frac{\\sum_{i = 1}^n \\epsilon_t^2}{n} \\\\\n            \\frac{\\partial L}{\\partial \\theta} = -\\frac{1}{\\sigma^2}\n            \\sum_{i = 1}^n \\epsilon_t \\frac{\\partial \\epsilon_t}{\\partial \\theta} \\\\\n            \\frac{\\partial \\epsilon_t}{\\partial \\theta} = -\\frac{\\partial \\hat{y}}{\\partial \\theta} \\\\\n            \\frac{\\partial\\hat{y}}{\\partial c} = 1 +\n            \\phi_{t-q}^{t-1}*\\frac{\\partial \\epsilon_{t-q}^{t-1}}{\\partial c} \\\\\n            \\frac{\\partial\\hat{y}}{\\partial \\theta_{ar_i}} =  y_{t - i} +\n            \\phi_{t-q}^{t-1}*\\frac{\\partial \\epsilon_{t-q}^{t-1}}{\\partial \\theta_{ar_i}} \\\\\n            \\frac{\\partial\\hat{y}}{\\partial \\theta_{ma_i}} =  \\epsilon_{t - i} +\n            \\phi_{t-q}^{t-1}*\\frac{\\partial \\epsilon_{t-q}^{t-1}}{\\partial \\theta_{ma_i}} \\\\\n        \n        Parameters\n        ----------\n        diffedY:\n            array of differenced values\n        \n        returns the gradient log likelihood as an array of double\n        \"\"\"\n        # need to copy diffedy to a double[] for Java\n        result =  self._jmodel.gradientlogLikelihoodCSSARMA(_py2java_double_array(self._ctx, diffedy))\n        return _java2py(self._ctx, result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a series of size n assuming an ARIMA process.", "response": "def sample(self, n):\n        \"\"\"\n        Sample a series of size n assuming an ARIMA(p, d, q) process.\n        \n        Parameters\n        ----------\n        n:\n            size of sample\n            \n        Returns a series reflecting ARIMA(p, d, q) process as a DenseVector\n        \"\"\"\n        rg = self._ctx._jvm.org.apache.commons.math3.random.JDKRandomGenerator()\n        return _java2py(self._ctx, self._jmodel.sample(n, rg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a series consisting of fitted 1 - step ahead forecasts for the given time series.", "response": "def forecast(self, ts, nfuture):\n        \"\"\"\n        Provided fitted values for timeseries ts as 1-step ahead forecasts, based on current\n        model parameters, and then provide `nFuture` periods of forecast. We assume AR terms\n        prior to the start of the series are equal to the model's intercept term (or 0.0, if fit\n        without and intercept term).Meanwhile, MA terms prior to the start are assumed to be 0.0. If\n        there is differencing, the first d terms come from the original series.\n       \n        Parameters\n        ----------\n        ts:\n            Timeseries to use as gold-standard. Each value (i) in the returning series\n            is a 1-step ahead forecast of ts(i). We use the difference between ts(i) -\n            estimate(i) to calculate the error at time i, which is used for the moving\n            average terms. Numpy array.\n        nFuture:\n            Periods in the future to forecast (beyond length of ts)\n            \n        Returns a series consisting of fitted 1-step ahead forecasts for historicals and then\n        `nFuture` periods of forecasts. Note that in the future values error terms become\n        zero and prior predictions are used for any AR terms.\n        \n        \"\"\"\n        jts = _py2java(self._ctx, Vectors.dense(ts))\n        jfore = self._jmodel.forecast(jts, nfuture)\n        return _java2py(self._ctx, jfore)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates an approximation to the Akaike Information Criterion for the given time series.", "response": "def approx_aic(self, ts):\n        \"\"\"\n        Calculates an approximation to the Akaike Information Criterion (AIC). This is an approximation\n        as we use the conditional likelihood, rather than the exact likelihood. Please see\n        [[https://en.wikipedia.org/wiki/Akaike_information_criterion]] for more information on this\n        measure.\n        \n        Parameters\n        ----------\n        ts:\n            the timeseries to evaluate under current model\n            \n        Returns an approximation to the AIC under the current model as a double\n        \"\"\"\n        return self._jmodel.approxAIC(_py2java(self._ctx, Vectors.dense(ts)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting an ARIMA model to a set of time series regressors and returns a RegressionARIMAModel.", "response": "def fit_model(ts, regressors, method=\"cochrane-orcutt\", optimizationArgs=None, sc=None):\n    \"\"\"\n    Parameters\n    ----------\n    ts:\n        time series to which to fit an ARIMA model as a Numpy array\n    regressors:\n        regression matrix as a Numpy array\n    method:\n        Regression method. Currently, only \"cochrane-orcutt\" is supported.\n    optimizationArgs:\n        \n    sc:\n        The SparkContext, required.\n    \n    returns an RegressionARIMAModel\n    \"\"\"\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    \n    jmodel = jvm.com.cloudera.sparkts.models.RegressionARIMA.fitModel(_nparray2breezevector(sc, ts), _nparray2breezematrix(sc, regressors), method, _py2scala_seq(sc, optimizationArgs))\n    return RegressionARIMAModel(jmodel=jmodel, sc=sc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfits a cochrane - orcutt model to a time series.", "response": "def fit_cochrane_orcutt(ts, regressors, maxIter=10, sc=None):\n    \"\"\"\n    Fit linear regression model with AR(1) errors , for references on Cochrane Orcutt model:\n    See [[https://onlinecourses.science.psu.edu/stat501/node/357]]\n    See : Applied Linear Statistical Models - Fifth Edition - Michael H. Kutner , page 492\n    The method assumes the time series to have the following model\n    \n    Y_t = B.X_t + e_t\n    e_t = rho*e_t-1+w_t\n    e_t has autoregressive structure , where w_t is iid ~ N(0,&sigma 2)\n    \n    Outline of the method :\n    1) OLS Regression for Y (timeseries) over regressors (X)\n    2) Apply auto correlation test (Durbin-Watson test) over residuals , to test whether e_t still\n       have auto-regressive structure\n    3) if test fails stop , else update update coefficients (B's) accordingly and go back to step 1)\n    \n    Parameters\n    ----------\n    ts:\n        Vector of size N for time series data to create the model for as a Numpy array\n    regressors:\n        Matrix N X K for the timed values for K regressors over N time points as a Numpy array\n    maxIter:\n        maximum number of iterations in iterative cochrane-orchutt estimation\n    \n    Returns instance of class [[RegressionARIMAModel]]\n    \"\"\"\n    \n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    \n    fnord = _nparray2breezematrix(sc, regressors)\n    print(fnord)\n    \n    jmodel = jvm.com.cloudera.sparkts.models.RegressionARIMA.fitCochraneOrcutt(_nparray2breezevector(sc, ts), _nparray2breezematrix(sc, regressors), maxIter)\n    return RegressionARIMAModel(jmodel=jmodel, sc=sc)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit an AR model to the given time series.", "response": "def fit_model(ts, maxLag=1, noIntercept=False, sc=None):\n    \"\"\"\n    Fits an AR(1) model to the given time series\n    \n    Parameters\n    ----------\n    ts:\n        the time series to which we want to fit an autoregression model as a Numpy array\n        \n    Returns an ARModel\n    \"\"\"\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.Autoregression.fitModel(_py2java(sc, Vectors.dense(ts)), maxLag, noIntercept)\n    return ARModel(jmodel=jmodel, sc=sc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a timeseries returns the original series of underlying errors.", "response": "def remove_time_dependent_effects(self, ts):\n        \"\"\"\n        Given a timeseries, apply inverse operations to obtain the original series of underlying errors.\n        Parameters\n        ----------\n        ts:\n            Time series of observations with this model's characteristics as a Numpy array\n        \n        returns the time series with removed time-dependent effects as a Numpy array\n        \"\"\"\n        destts = Vectors.dense(np.array([0] * len(ts)))\n        result =  self._jmodel.removeTimeDependentEffects(_py2java(self._ctx, Vectors.dense(ts)), _py2java(self._ctx, destts))\n        return _java2py(self._ctx, result.toArray())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a timeseries apply a model to it.", "response": "def add_time_dependent_effects(self, ts):\n        \"\"\"\n        Given a timeseries, apply a model to it.\n        \n        Parameters\n        ----------\n        ts:\n            Time series of i.i.d. observations as a Numpy array\n        \n        returns the time series with added time-dependent effects as a Numpy array.\n        \"\"\"\n        destts = Vectors.dense([0] * len(ts))\n        result =  self._jmodel.addTimeDependentEffects(_py2java(self._ctx, Vectors.dense(ts)), _py2java(self._ctx, destts))\n        return _java2py(self._ctx, result.toArray())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit_model(ts, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.ARGARCH.fitModel(_py2java(sc, Vectors.dense(ts)))\n    return ARGARCHModel(jmodel=jmodel, sc=sc)", "response": "Fits an AR + GARCH model to the given time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef irregular(timestamps, sc):\n    dtmodule = sc._jvm.com.cloudera.sparkts.__getattr__('DateTimeIndex$').__getattr__('MODULE$')\n    arr = sc._gateway.new_array(sc._jvm.long, len(timestamps))\n    for i in xrange(len(timestamps)):\n        arr[i] = datetime_to_nanos(timestamps[i])\n    return DateTimeIndex(dtmodule.irregular(arr))", "response": "Instantiates an irregular DateTimeIndex."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _zdt_to_nanos(self, zdt):\n        instant = zdt.toInstant()\n        return instant.getNano() + instant.getEpochSecond() * 1000000000", "response": "Extracts nanoseconds from a ZonedDateTime"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef datetime_at_loc(self, loc):\n        return pd.Timestamp(self._zdt_to_nanos(self._jdt_index.dateTimeAtLoc(loc)))", "response": "Returns the timestamp at the given integer location as a Pandas Timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new DateTimeIndex containing a subslice of the timestamps in this index and the given start and end locations.", "response": "def islice(self, start, end):\n        \"\"\"\n        Returns a new DateTimeIndex, containing a subslice of the timestamps in this index,\n        as specified by the given integer start and end locations.\n\n        Parameters\n        ----------\n        start : int\n            The location of the start of the range, inclusive.\n        end : int\n            The location of the end of the range, exclusive.\n        \"\"\"\n        jdt_index = self._jdt_index.islice(start, end)\n        return DateTimeIndex(jdt_index=jdt_index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_model(y, x, yMaxLag, xMaxLag, includesOriginalX=True, noIntercept=False, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.AutoregressionX.fitModel(_nparray2breezevector(sc, y.toArray()), _nparray2breezematrix(sc, x.toArray()), yMaxLag, xMaxLag, includesOriginalX, noIntercept)\n    return ARXModel(jmodel=jmodel, sc=sc)", "response": "Fit an autoregressive model with additional exogenous variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_model(ts, sc=None):\n    assert sc != None, \"Missing SparkContext\"\n    \n    jvm = sc._jvm\n    jmodel = jvm.com.cloudera.sparkts.models.GARCH.fitModel(_py2java(sc, Vectors.dense(ts)))\n    return GARCHModel(jmodel=jmodel, sc=sc)", "response": "Fits a GARCH model to the given time series."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the gradient of the log likelihood with respect to the given time series.", "response": "def gradient(self, ts):\n        \"\"\"\n        Find the gradient of the log likelihood with respect to the given time series.\n        \n        Based on http://www.unc.edu/~jbhill/Bollerslev_GARCH_1986.pdf\n        \n        Returns an 3-element array containing the gradient for the alpha, beta, and omega parameters.\n        \"\"\"\n        gradient = self._jmodel.gradient(_py2java(self._ctx, Vectors.dense(ts)))\n        return _java2py(self._ctx, gradient)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_likelihood(self, ts):\n        likelihood = self._jmodel.logLikelihood(_py2java(self._ctx, Vectors.dense(ts)))\n        return _java2py(self._ctx, likelihood)", "response": "Returns the log likelihood of the parameters on the given time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef time_series_rdd_from_pandas_series_rdd(series_rdd):\n    first = series_rdd.first()\n    dt_index = irregular(first[1].index, series_rdd.ctx)\n    return TimeSeriesRDD(dt_index, series_rdd.mapValues(lambda x: x.values))", "response": "Instantiates a TimeSeriesRDD from an RDD of Pandas Series objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a TimeSeriesRDD from a DataFrame of observations.", "response": "def time_series_rdd_from_observations(dt_index, df, ts_col, key_col, val_col):\n    \"\"\"\n    Instantiates a TimeSeriesRDD from a DataFrame of observations.\n\n    An observation is a row containing a timestamp, a string key, and float value.\n\n    Parameters\n    ----------\n    dt_index : DateTimeIndex\n        The index of the RDD to create. Observations not contained in this index will be ignored.\n    df : DataFrame\n    ts_col : string\n        The name of the column in the DataFrame containing the timestamps.\n    key_col : string\n        The name of the column in the DataFrame containing the keys.\n    val_col : string\n        The name of the column in the DataFrame containing the values.\n    \"\"\"\n    jvm = df._sc._jvm\n    jtsrdd = jvm.com.cloudera.sparkts.api.java.JavaTimeSeriesRDDFactory.timeSeriesRDDFromObservations( \\\n      dt_index._jdt_index, df._jdf, ts_col, key_col, val_col)\n    return TimeSeriesRDD(None, None, jtsrdd, df._sc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an RDD of n time series differences with the given order.", "response": "def differences(self, n):\n        \"\"\"\n        Returns a TimeSeriesRDD where each time series is differenced with the given order.\n        \n        The new RDD will be missing the first n date-times.\n        \n        Parameters\n        ----------\n        n : int\n            The order of differencing to perform.\n        \"\"\"\n        return TimeSeriesRDD(None, None, self._jtsrdd.differences(n), self.ctx)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new TimeSeriesRDD with missing values imputed using the given method.", "response": "def fill(self, method):\n        \"\"\"\n        Returns a TimeSeriesRDD with missing values imputed using the given method.\n        \n        Parameters\n        ----------\n        method : string\n            \"nearest\" fills in NaNs with the closest non-NaN value, using the closest previous value\n            in the case of a tie.  \"linear\" does a linear interpolation from the closest filled-in\n            values.  \"next\" uses the closest value that is in the future of the missing value.\n            \"previous\" uses the closest value from the past of the missing value.  \"spline\"\n            interpolates using a cubic spline.\n        \"\"\"\n        return TimeSeriesRDD(None, None, self._jtsrdd.fill(method), self.ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new TimeseriesRDD with a transformation applied to all the series in this RDD.", "response": "def map_series(self, fn, dt_index = None):\n        \"\"\"\n        Returns a TimeSeriesRDD, with a transformation applied to all the series in this RDD.\n\n        Either the series produced by the given function should conform to this TimeSeriesRDD's\n        index, or a new DateTimeIndex should be given that they conform to.\n        \n        Parameters\n        ----------\n        fn : function\n            A function that maps arrays of floats to arrays of floats.\n        dt_index : DateTimeIndex\n            A DateTimeIndex for the produced TimeseriesRDD.\n        \"\"\"\n        if dt_index == None:\n          dt_index = self.index()\n        return TimeSeriesRDD(dt_index, self.map(fn))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an RDD of instants each a horizontal slice of this TimeSeriesRDD at a time.", "response": "def to_instants(self):\n        \"\"\"\n        Returns an RDD of instants, each a horizontal slice of this TimeSeriesRDD at a time.\n\n        This essentially transposes the TimeSeriesRDD, producing an RDD of tuples of datetime and\n        a numpy array containing all the observations that occurred at that time.\n        \"\"\"\n        jrdd = self._jtsrdd.toInstants(-1).map( \\\n            self.ctx._jvm.com.cloudera.sparkts.InstantToBytes())\n        return RDD(jrdd, self.ctx, _InstantDeserializer())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_instants_dataframe(self, sql_ctx):\n        ssql_ctx = sql_ctx._ssql_ctx\n        jdf = self._jtsrdd.toInstantsDataFrame(ssql_ctx, -1)\n        return DataFrame(jdf, sql_ctx)", "response": "Returns a DataFrame of instants each a horizontal slice of this TimeSeriesRDD at a time."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a DataFrame of observations each containing a timestamp a key and a value.", "response": "def to_observations_dataframe(self, sql_ctx, ts_col='timestamp', key_col='key', val_col='value'):\n        \"\"\"\n        Returns a DataFrame of observations, each containing a timestamp, a key, and a value.\n\n        Parameters\n        ----------\n        sql_ctx : SQLContext\n        ts_col : string\n            The name for the timestamp column.\n        key_col : string\n            The name for the key column.\n        val_col : string\n            The name for the value column.\n        \"\"\"\n        ssql_ctx = sql_ctx._ssql_ctx\n        jdf = self._jtsrdd.toObservationsDataFrame(ssql_ctx, ts_col, key_col, val_col)\n        return DataFrame(jdf, sql_ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_pandas_series_rdd(self):\n        pd_index = self.index().to_pandas_index()\n        return self.map(lambda x: (x[0], pd.Series(x[1], pd_index)))", "response": "Returns an RDD of Pandas Series objects indexed with Pandas DatetimeIndexes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_pandas_dataframe(self):\n        pd_index = self.index().to_pandas_index()\n        return pd.DataFrame.from_items(self.collect()).set_index(pd_index)", "response": "Converts the RDD to a Pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new TimeSeriesRDD rebased on top of a new index.", "response": "def with_index(self, new_index):\n        \"\"\"\n        Returns a TimeSeriesRDD rebased on top of a new index.  Any timestamps that exist in the new\n        index but not in the existing index will be filled in with NaNs.\n        \n        Parameters\n        ----------\n        new_index : DateTimeIndex\n        \"\"\"\n        return TimeSeriesRDD(None, None, self._jtsrdd.withIndex(new_index._jdt_index), self.ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_toast(self, title=\"Notification\", msg=\"Here comes the message\",\n                    icon_path=None, duration=5, threaded=False):\n        \"\"\"Notification settings.\n\n        :title: notification title\n        :msg: notification message\n        :icon_path: path to the .ico file to custom notification\n        :duration: delay in seconds before notification self-destruction\n        \"\"\"\n        if not threaded:\n            self._show_toast(title, msg, icon_path, duration)\n        else:\n            if self.notification_active():\n                # We have an active notification, let is finish so we don't spam them\n                return False\n\n            self._thread = threading.Thread(target=self._show_toast, args=(title, msg, icon_path, duration))\n            self._thread.start()\n        return True", "response": "Show the toast for the current instance of the class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the row s header from a list.", "response": "def _SetHeader(self, values):\n    \"\"\"Set the row's header from a list.\"\"\"\n    if self._values and len(values) != len(self._values):\n      raise ValueError('Header values not equal to existing data width.')\n    if not self._values:\n      for _ in range(len(values)):\n        self._values.append(None)\n    self._keys = list(values)\n    self._BuildIndex()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the values of the internal dictionary.", "response": "def _SetValues(self, values):\n    \"\"\"Set values from supplied dictionary or list.\n\n    Args:\n      values: A Row, dict indexed by column name, or list.\n\n    Raises:\n      TypeError: Argument is not a list or dict, or list is not equal row\n      length or dictionary keys don't match.\n    \"\"\"\n\n    def _ToStr(value):\n      \"\"\"Convert individul list entries to string.\"\"\"\n      if isinstance(value, (list, tuple)):\n        result = []\n        for val in value:\n          result.append(str(val))\n        return result\n      else:\n        return str(value)\n\n    # Row with identical header can be copied directly.\n    if isinstance(values, Row):\n      if self._keys != values.header:\n        raise TypeError('Attempt to append row with mismatched header.')\n      self._values = copy.deepcopy(values.values)\n\n    elif isinstance(values, dict):\n      for key in self._keys:\n        if key not in values:\n          raise TypeError('Dictionary key mismatch with row.')\n      for key in self._keys:\n        self[key] = _ToStr(values[key])\n\n    elif isinstance(values, list) or isinstance(values, tuple):\n      if len(values) != len(self._values):\n        raise TypeError('Supplied list length != row length')\n      for (index, value) in enumerate(values):\n        self._values[index] = _ToStr(value)\n\n    else:\n      raise TypeError('Supplied argument must be Row, dict or list, not %s',\n                      type(values))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a new TextTable from the rows of which the function returns a bool.", "response": "def Filter(self, function=None):\n    \"\"\"Construct Textable from the rows of which the function returns true.\n\n\n    Args:\n      function: A function applied to each row which returns a bool. If\n                function is None, all rows with empty column values are\n                removed.\n    Returns:\n      A new TextTable()\n\n    Raises:\n      TableError: When an invalid row entry is Append()'d\n    \"\"\"\n    flat = lambda x: x if isinstance(x, str) else ''.join([flat(y) for y in x])\n    if function is None:\n      function = lambda row: bool(flat(row.values))\n\n    new_table = self.__class__()\n    # pylint: disable=protected-access\n    new_table._table = [self.header]\n    for row in self:\n      if function(row) is True:\n        new_table.Append(row)\n    return new_table"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string containing the entire table with column headers and separators.", "response": "def _GetTable(self):\n    \"\"\"Returns table, with column headers and separators.\n\n    Returns:\n      The whole table including headers as a string. Each row is\n      joined by a newline and each entry by self.separator.\n    \"\"\"\n    result = []\n    # Avoid the global lookup cost on each iteration.\n    lstr = str\n    for row in self._table:\n      result.append(\n          '%s\\n' %\n          self.separator.join(lstr(v) for v in row))\n\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets table, with column headers and separators.", "response": "def _SetTable(self, table):\n    \"\"\"Sets table, with column headers and separators.\"\"\"\n    if not isinstance(table, TextTable):\n      raise TypeError('Not an instance of TextTable.')\n    self.Reset()\n    self._table = copy.deepcopy(table._table)   # pylint: disable=W0212\n    # Point parent table of each row back ourselves.\n    for row in self:\n      row.table = self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _TextJustify(self, text, col_size):\n    result = []\n    if '\\n' in text:\n      for paragraph in text.split('\\n'):\n        result.extend(self._TextJustify(paragraph, col_size))\n      return result\n\n    wrapper = textwrap.TextWrapper(width=col_size-2, break_long_words=False,\n                                   expand_tabs=False)\n    try:\n      text_list = wrapper.wrap(text)\n    except ValueError:\n      raise TableError('Field too small (minimum width: 3)')\n\n    if not text_list:\n      return [' '*col_size]\n\n    for current_line in text_list:\n      stripped_len = len(terminal.StripAnsiText(current_line))\n      ansi_color_adds = len(current_line) - stripped_len\n      # +2 for white space on either side.\n      if stripped_len + 2 > col_size:\n        raise TableError('String contains words that do not fit in column.')\n\n      result.append(' %-*s' % (col_size - 1 + ansi_color_adds, current_line))\n\n    return result", "response": "Formats text within column with white space padding."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string that can be displayed in a table.", "response": "def FormattedTable(self, width=80, force_display=False, ml_delimiter=True,\n                     color=True, display_header=True, columns=None):\n    \"\"\"Returns whole table, with whitespace padding and row delimiters.\n\n    Args:\n      width: An int, the max width we want the table to fit in.\n      force_display: A bool, if set to True will display table when the table\n          can't be made to fit to the width.\n      ml_delimiter: A bool, if set to False will not display the multi-line\n          delimiter.\n      color: A bool. If true, display any colours in row.colour.\n      display_header: A bool. If true, display header.\n      columns: A list of str, show only columns with these names.\n\n    Returns:\n      A string.  The tabled output.\n\n    Raises:\n      TableError: Width too narrow to display table.\n    \"\"\"\n\n    def _FilteredCols():\n      \"\"\"Returns list of column names to display.\"\"\"\n      if not columns:\n        return self._Header().values\n      return [col for col in self._Header().values if col in columns]\n\n    # Largest is the biggest data entry in a column.\n    largest = {}\n    # Smallest is the same as above but with linewrap i.e. largest unbroken\n    # word in the data stream.\n    smallest = {}\n    # largest == smallest for a column with a single word of data.\n    # Initialise largest and smallest for all columns.\n    for key in _FilteredCols():\n      largest[key] = 0\n      smallest[key] = 0\n\n    # Find the largest and smallest values.\n    # Include Title line in equation.\n    # pylint: disable=E1103\n    for row in self._table:\n      for key, value in row.items():\n        if key not in _FilteredCols():\n          continue\n        # Convert lists into a string.\n        if isinstance(value, list):\n          value = ', '.join(value)\n        value = terminal.StripAnsiText(value)\n        largest[key] = max(len(value), largest[key])\n        smallest[key] = max(self._SmallestColSize(value), smallest[key])\n    # pylint: enable=E1103\n\n    min_total_width = 0\n    multi_word = []\n    # Bump up the size of each column to include minimum pad.\n    # Find all columns that can be wrapped (multi-line).\n    # And the minimum width needed to display all columns (even if wrapped).\n    for key in _FilteredCols():\n      # Each column is bracketed by a space on both sides.\n      # So increase size required accordingly.\n      largest[key] += 2\n      smallest[key] += 2\n      min_total_width += smallest[key]\n      # If column contains data that 'could' be split over multiple lines.\n      if largest[key] != smallest[key]:\n        multi_word.append(key)\n\n    # Check if we have enough space to display the table.\n    if min_total_width > width and not force_display:\n      raise TableError('Width too narrow to display table.')\n\n    # We have some columns that may need wrapping over several lines.\n    if multi_word:\n      # Find how much space is left over for the wrapped columns to use.\n      # Also find how much space we would need if they were not wrapped.\n      # These are 'spare_width' and 'desired_width' respectively.\n      desired_width = 0\n      spare_width = width - min_total_width\n      for key in multi_word:\n        spare_width += smallest[key]\n        desired_width += largest[key]\n\n      # Scale up the space we give each wrapped column.\n      # Proportional to its size relative to 'desired_width' for all columns.\n      # Rinse and repeat if we changed the wrap list in this iteration.\n      # Once done we will have a list of columns that definitely need wrapping.\n      done = False\n      while not done:\n        done = True\n        for key in multi_word:\n          # If we scale past the desired width for this particular column,\n          # then give it its desired width and remove it from the wrapped list.\n          if (largest[key] <=\n              round((largest[key] / float(desired_width)) * spare_width)):\n            smallest[key] = largest[key]\n            multi_word.remove(key)\n            spare_width -= smallest[key]\n            desired_width -= largest[key]\n            done = False\n          # If we scale below the minimum width for this particular column,\n          # then leave it at its minimum and remove it from the wrapped list.\n          elif (smallest[key] >=\n                round((largest[key] / float(desired_width)) * spare_width)):\n            multi_word.remove(key)\n            spare_width -= smallest[key]\n            desired_width -= largest[key]\n            done = False\n\n      # Repeat the scaling algorithm with the final wrap list.\n      # This time we assign the extra column space by increasing 'smallest'.\n      for key in multi_word:\n        smallest[key] = int(round((largest[key] / float(desired_width))\n                                  * spare_width))\n\n    total_width = 0\n    row_count = 0\n    result_dict = {}\n    # Format the header lines and add to result_dict.\n    # Find what the total width will be and use this for the ruled lines.\n    # Find how many rows are needed for the most wrapped line (row_count).\n    for key in _FilteredCols():\n      result_dict[key] = self._TextJustify(key, smallest[key])\n      if len(result_dict[key]) > row_count:\n        row_count = len(result_dict[key])\n      total_width += smallest[key]\n\n    # Store header in header_list, working down the wrapped rows.\n    header_list = []\n    for row_idx in range(row_count):\n      for key in _FilteredCols():\n        try:\n          header_list.append(result_dict[key][row_idx])\n        except IndexError:\n          # If no value than use whitespace of equal size.\n          header_list.append(' '*smallest[key])\n      header_list.append('\\n')\n\n    # Format and store the body lines\n    result_dict = {}\n    body_list = []\n    # We separate multi line rows with a single line delimiter.\n    prev_muli_line = False\n    # Unless it is the first line in which there is already the header line.\n    first_line = True\n    for row in self:\n      row_count = 0\n      for key, value in row.items():\n        if key not in _FilteredCols():\n          continue\n        # Convert field contents to a string.\n        if isinstance(value, list):\n          value = ', '.join(value)\n        # Store results in result_dict and take note of wrapped line count.\n        result_dict[key] = self._TextJustify(value, smallest[key])\n        if len(result_dict[key]) > row_count:\n          row_count = len(result_dict[key])\n\n      if row_count > 1:\n        prev_muli_line = True\n      # If current or prior line was multi-line then include delimiter.\n      if not first_line and prev_muli_line and ml_delimiter:\n        body_list.append('-'*total_width + '\\n')\n        if row_count == 1:\n          # Our current line was not wrapped, so clear flag.\n          prev_muli_line = False\n\n      row_list = []\n      for row_idx in range(row_count):\n        for key in _FilteredCols():\n          try:\n            row_list.append(result_dict[key][row_idx])\n          except IndexError:\n            # If no value than use whitespace of equal size.\n            row_list.append(' '*smallest[key])\n        row_list.append('\\n')\n\n      if color and row.color is not None:\n        body_list.append(\n            terminal.AnsiText(''.join(row_list)[:-1],\n                              command_list=row.color))\n        body_list.append('\\n')\n      else:\n        body_list.append(''.join(row_list))\n\n      first_line = False\n\n    header = ''.join(header_list) + '='*total_width\n    if color and self._Header().color is not None:\n      header = terminal.AnsiText(header, command_list=self._Header().color)\n    # Add double line delimiter between header and main body.\n    if display_header:\n      return '%s\\n%s' % (header, ''.join(body_list))\n    return '%s' % ''.join(body_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns whole table as rows of name value pairs.", "response": "def LabelValueTable(self, label_list=None):\n    \"\"\"Returns whole table as rows of name/value pairs.\n\n    One (or more) column entries are used for the row prefix label.\n    The remaining columns are each displayed as a row entry with the\n    prefix labels appended.\n\n    Use the first column as the label if label_list is None.\n\n    Args:\n      label_list: A list of prefix labels to use.\n\n    Returns:\n      Label/Value formatted table.\n\n    Raises:\n      TableError: If specified label is not a column header of the table.\n    \"\"\"\n    label_list = label_list or self._Header()[0]\n    # Ensure all labels are valid.\n    for label in label_list:\n      if label not in self._Header():\n        raise TableError('Invalid label prefix: %s.' % label)\n\n    sorted_list = []\n    for header in self._Header():\n      if header in label_list:\n        sorted_list.append(header)\n\n    label_str = '# LABEL %s\\n' % '.'.join(sorted_list)\n\n    body = []\n    for row in self:\n    # Some of the row values are pulled into the label, stored in label_prefix.\n      label_prefix = []\n      value_list = []\n      for key, value in row.items():\n        if key in sorted_list:\n          # Set prefix.\n          label_prefix.append(value)\n        else:\n          value_list.append('%s %s' % (key, value))\n\n      body.append(''.join(\n          ['%s.%s\\n' % ('.'.join(label_prefix), v) for v in value_list]))\n\n    return '%s%s' % (label_str, ''.join(body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the index number of the specified column name.", "response": "def index(self, name=None):  # pylint: disable=C6409\n    \"\"\"Returns index number of supplied column name.\n\n    Args:\n      name: string of column name.\n\n    Raises:\n      TableError: If name not found.\n\n    Returns:\n      Index of the specified header entry.\n    \"\"\"\n    try:\n      return self.header.index(name)\n    except ValueError:\n      raise TableError('Unknown index name %s.' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ParseCmdItem(self, cmd_input, template_file=None):\n    # Build FSM machine from the template.\n    fsm = textfsm.TextFSM(template_file)\n    if not self._keys:\n      self._keys = set(fsm.GetValuesByAttrib('Key'))\n\n    # Pass raw data through FSM.\n    table = texttable.TextTable()\n    table.header = fsm.header\n\n    # Fill TextTable from record entries.\n    for record in fsm.ParseText(cmd_input):\n      table.Append(record)\n    return table", "response": "Parses a command line and returns a Texttable containing the command output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute against each field of each row read from index table.", "response": "def _PreParse(self, key, value):\n    \"\"\"Executed against each field of each row read from index table.\"\"\"\n    if key == 'Command':\n      return re.sub(r'(\\[\\[.+?\\]\\])', self._Completion, value)\n    else:\n      return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace double square brackets with variable length completion.", "response": "def _Completion(self, match):\n    # pylint: disable=C6114\n    r\"\"\"Replaces double square brackets with variable length completion.\n\n    Completion cannot be mixed with regexp matching or '\\' characters\n    i.e. '[[(\\n)]] would become (\\(n)?)?.'\n\n    Args:\n      match: A regex Match() object.\n\n    Returns:\n      String of the format '(a(b(c(d)?)?)?)?'.\n    \"\"\"\n    # Strip the outer '[[' & ']]' and replace with ()? regexp pattern.\n    word = str(match.group())[2:-2]\n    return '(' + ('(').join(word) + ')?' * len(word)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(argv=None):\n\n  if argv is None:\n    argv = sys.argv\n\n  try:\n    opts, args = getopt.getopt(argv[1:], 'h', ['help'])\n  except getopt.error as msg:\n    raise Usage(msg)\n\n  for opt, _ in opts:\n    if opt in ('-h', '--help'):\n      print(__doc__)\n      print(help_msg)\n      return 0\n\n  if not args or len(args) > 4:\n    raise Usage('Invalid arguments.')\n\n  # If we have an argument, parse content of file and display as a template.\n  # Template displayed will match input template, minus any comment lines.\n  with open(args[0], 'r') as template:\n    fsm = TextFSM(template)\n    print('FSM Template:\\n%s\\n' % fsm)\n\n    if len(args) > 1:\n      # Second argument is file with example cli input.\n      # Prints parsed tabular result.\n      with open(args[1], 'r') as f:\n        cli_input = f.read()\n\n      table = fsm.ParseText(cli_input)\n      print('FSM Table:')\n      result = str(fsm.header) + '\\n'\n      for line in table:\n        result += str(line) + '\\n'\n      print(result, end='')\n\n  if len(args) > 2:\n    # Compare tabular result with data in third file argument.\n    # Exit value indicates if processed data matched expected result.\n    with open(args[2], 'r') as f:\n      ref_table = f.read()\n\n    if ref_table != result:\n      print('Data mis-match!')\n      return 1\n    else:\n      print('Data match!')", "response": "Validate text parsed with FSM or validate an FSM via command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of valid option names.", "response": "def ValidOptions(cls):\n    \"\"\"Returns a list of valid option names.\"\"\"\n    valid_options = []\n    for obj_name in dir(cls):\n      obj = getattr(cls, obj_name)\n      if inspect.isclass(obj) and issubclass(obj, cls.OptionBase):\n        valid_options.append(obj_name)\n    return valid_options"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ClearAllVar(self):\n    self.value = None\n    # Call OnClearAllVar on options.\n    _ = [option.OnClearAllVar() for option in self.options]", "response": "Clear this Value and all options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Header(self):\n    # Call OnGetValue on options.\n    _ = [option.OnGetValue() for option in self.options]\n    return self.name", "response": "Fetch the header name of this Value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Parse(self, value):\n\n    value_line = value.split(' ')\n    if len(value_line) < 3:\n      raise TextFSMTemplateError('Expect at least 3 tokens on line.')\n\n    if not value_line[2].startswith('('):\n      # Options are present\n      options = value_line[1]\n      for option in options.split(','):\n        self._AddOption(option)\n      # Call option OnCreateOptions callbacks\n      _ = [option.OnCreateOptions() for option in self.options]\n\n      self.name = value_line[2]\n      self.regex = ' '.join(value_line[3:])\n    else:\n      # There were no valid options, so there are no options.\n      # Treat this argument as the name.\n      self.name = value_line[1]\n      self.regex = ' '.join(value_line[2:])\n\n    if len(self.name) > self.max_name_len:\n      raise TextFSMTemplateError(\n          \"Invalid Value name '%s' or name too long.\" % self.name)\n\n    if (not re.match(r'^\\(.*\\)$', self.regex) or\n        self.regex.count('(') != self.regex.count(')')):\n      raise TextFSMTemplateError(\n          \"Value '%s' must be contained within a '()' pair.\" % self.regex)\n\n    self.template = re.sub(r'^\\(', '(?P<%s>' % self.name, self.regex)\n\n    # Compile and store the regex object only on List-type values for use in nested matching\n    if any(map(lambda x: isinstance(x, TextFSMOptions.List), self.options)):\n        try:\n            self.compiled_regex = re.compile(self.regex)\n        except re.error as e:\n            raise TextFSMTemplateError(str(e))", "response": "Parses a Value declaration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an option to this Value.", "response": "def _AddOption(self, name):\n    \"\"\"Add an option to this Value.\n\n    Args:\n      name: (str), the name of the Option to add.\n\n    Raises:\n      TextFSMTemplateError: If option is already present or\n        the option does not exist.\n    \"\"\"\n\n    # Check for duplicate option declaration\n    if name in [option.name for option in self.options]:\n      raise TextFSMTemplateError('Duplicate option \"%s\"' % name)\n\n    # Create the option object\n    try:\n      option = self._options_cls.GetOption(name)(self)\n    except AttributeError:\n      raise TextFSMTemplateError('Unknown option \"%s\"' % name)\n\n    self.options.append(option)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npreserve FSM but resets starting state and current record.", "response": "def Reset(self):\n    \"\"\"Preserves FSM but resets starting state and current record.\"\"\"\n\n    # Current state is Start state.\n    self._cur_state = self.states['Start']\n    self._cur_state_name = 'Start'\n\n    # Clear table of results and current record.\n    self._result = []\n    self._ClearAllRecord()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GetHeader(self):\n    header = []\n    for value in self.values:\n      try:\n        header.append(value.Header())\n      except SkipValue:\n        continue\n    return header", "response": "Returns a list of all the header elements in the list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetValue(self, name):\n    for value in self.values:\n      if value.name == name:\n        return value", "response": "Returns the TextFSMValue object natching the requested name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _AppendRecord(self):\n\n    # If no Values then don't output.\n    if not self.values:\n      return\n\n    cur_record = []\n    for value in self.values:\n      try:\n        value.OnSaveRecord()\n      except SkipRecord:\n        self._ClearRecord()\n        return\n      except SkipValue:\n        continue\n\n      # Build current record into a list.\n      cur_record.append(value.value)\n\n    # If no Values in template or whole record is empty then don't output.\n    if len(cur_record) == (cur_record.count(None) + cur_record.count([])):\n      return\n\n    # Replace any 'None' entries with null string ''.\n    while None in cur_record:\n      cur_record[cur_record.index(None)] = ''\n\n    self._result.append(cur_record)\n    self._ClearRecord()", "response": "Adds current record to result if well formed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Parse(self, template):\n\n    if not template:\n      raise TextFSMTemplateError('Null template.')\n\n    # Parse header with Variables.\n    self._ParseFSMVariables(template)\n\n    # Parse States.\n    while self._ParseFSMState(template):\n      pass\n\n    # Validate destination states.\n    self._ValidateFSM()", "response": "Parses template file for FSM structure.\n\n    Args:\n      template: Valid template file.\n\n    Raises:\n      TextFSMTemplateError: If template file syntax is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ParseFSMVariables(self, template):\n\n    self.values = []\n\n    for line in template:\n      self._line_num += 1\n      line = line.rstrip()\n\n      # Blank line signifies end of Value definitions.\n      if not line:\n        return\n\n      # Skip commented lines.\n      if self.comment_regex.match(line):\n        continue\n\n      if line.startswith('Value '):\n        try:\n          value = TextFSMValue(\n              fsm=self, max_name_len=self.MAX_NAME_LEN,\n              options_class=self._options_cls)\n          value.Parse(line)\n        except TextFSMTemplateError as error:\n          raise TextFSMTemplateError('%s Line %s.' % (error, self._line_num))\n\n        if value.name in self.header:\n          raise TextFSMTemplateError(\n              \"Duplicate declarations for Value '%s'. Line: %s.\"\n              % (value.name, self._line_num))\n\n        try:\n          self._ValidateOptions(value)\n        except TextFSMTemplateError as error:\n          raise TextFSMTemplateError('%s Line %s.' % (error, self._line_num))\n\n        self.values.append(value)\n        self.value_map[value.name] = value.template\n      # The line has text but without the 'Value ' prefix.\n      elif not self.values:\n        raise TextFSMTemplateError('No Value definitions found.')\n      else:\n        raise TextFSMTemplateError(\n            'Expected blank line after last Value entry. Line: %s.'\n            % (self._line_num))", "response": "Parses the Variables from the beginning of a template file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ParseFSMState(self, template):\n\n    if not template:\n      return\n\n    state_name = ''\n    # Strip off extra white space lines (including comments).\n    for line in template:\n      self._line_num += 1\n      line = line.rstrip()\n\n      # First line is state definition\n      if line and not self.comment_regex.match(line):\n         # Ensure statename has valid syntax and is not a reserved word.\n        if (not self.state_name_re.match(line) or\n            len(line) > self.MAX_NAME_LEN or\n            line in TextFSMRule.LINE_OP or\n            line in TextFSMRule.RECORD_OP):\n          raise TextFSMTemplateError(\"Invalid state name: '%s'. Line: %s\"\n                                     % (line, self._line_num))\n\n        state_name = line\n        if state_name in self.states:\n          raise TextFSMTemplateError(\"Duplicate state name: '%s'. Line: %s\"\n                                     % (line, self._line_num))\n        self.states[state_name] = []\n        self.state_list.append(state_name)\n        break\n\n    # Parse each rule in the state.\n    for line in template:\n      self._line_num += 1\n      line = line.rstrip()\n\n      # Finish rules processing on blank line.\n      if not line:\n        break\n\n      if self.comment_regex.match(line):\n        continue\n\n      # A rule within a state, starts with whitespace\n      if not (line.startswith('  ^') or line.startswith('\\t^')):\n        raise TextFSMTemplateError(\n            \"Missing white space or carat ('^') before rule. Line: %s\" %\n            self._line_num)\n\n      self.states[state_name].append(\n          TextFSMRule(line, self._line_num, self.value_map))\n\n    return state_name", "response": "Parses the state and associated Rules from a template file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the FSM for validity.", "response": "def _ValidateFSM(self):\n    \"\"\"Checks state names and destinations for validity.\n\n    Each destination state must exist, be a valid name and\n    not be a reserved name.\n    There must be a 'Start' state and if 'EOF' or 'End' states are specified,\n    they must be empty.\n\n    Returns:\n      True if FSM is valid.\n\n    Raises:\n      TextFSMTemplateError: If any state definitions are invalid.\n    \"\"\"\n\n    # Must have 'Start' state.\n    if 'Start' not in self.states:\n      raise TextFSMTemplateError(\"Missing state 'Start'.\")\n\n    # 'End/EOF' state (if specified) must be empty.\n    if self.states.get('End'):\n      raise TextFSMTemplateError(\"Non-Empty 'End' state.\")\n\n    if self.states.get('EOF'):\n      raise TextFSMTemplateError(\"Non-Empty 'EOF' state.\")\n\n    # Remove 'End' state.\n    if 'End' in self.states:\n      del self.states['End']\n      self.state_list.remove('End')\n\n    # Ensure jump states are all valid.\n    for state in self.states:\n      for rule in self.states[state]:\n        if rule.line_op == 'Error':\n          continue\n\n        if not rule.new_state or rule.new_state in ('End', 'EOF'):\n          continue\n\n        if rule.new_state not in self.states:\n          raise TextFSMTemplateError(\n              \"State '%s' not found, referenced in state '%s'\" %\n              (rule.new_state, state))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ParseText(self, text, eof=True):\n\n    lines = []\n    if text:\n      lines = text.splitlines()\n\n    for line in lines:\n      self._CheckLine(line)\n      if self._cur_state_name in ('End', 'EOF'):\n        break\n\n    if self._cur_state_name != 'End' and 'EOF' not in self.states and eof:\n      # Implicit EOF performs Next.Record operation.\n      # Suppressed if Null EOF state is instantiated.\n      self._AppendRecord()\n\n    return self._result", "response": "Parses the given text and returns a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling ParseText and turns the result into list of dicts.", "response": "def ParseTextToDicts(self, *args, **kwargs):\n    \"\"\"Calls ParseText and turns the result into list of dicts.\n\n    List items are dicts of rows, dict key is column header and value is column\n    value.\n\n    Args:\n      text: (str), Text to parse with embedded newlines.\n      eof: (boolean), Set to False if we are parsing only part of the file.\n            Suppresses triggering EOF state.\n\n    Raises:\n      TextFSMError: An error occurred within the FSM.\n\n    Returns:\n      List of dicts.\n    \"\"\"\n\n    result_lists = self.ParseText(*args, **kwargs)\n    result_dicts = []\n\n    for row in result_lists:\n      result_dicts.append(dict(zip(self.header, row)))\n\n    return result_dicts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning variable into current record from a matched rule.", "response": "def _AssignVar(self, matched, value):\n    \"\"\"Assigns variable into current record from a matched rule.\n\n    If a record entry is a list then append, otherwise values are replaced.\n\n    Args:\n      matched: (regexp.match) Named group for each matched value.\n      value: (str) The matched value.\n    \"\"\"\n    _value = self._GetValue(value)\n    if _value is not None:\n        _value.AssignVar(matched.group(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the list of values that have a particular attribute.", "response": "def GetValuesByAttrib(self, attribute):\n    \"\"\"Returns the list of values that have a particular attribute.\"\"\"\n\n    if attribute not in self._options_cls.ValidOptions():\n      raise ValueError(\"'%s': Not a valid attribute.\" % attribute)\n\n    result = []\n    for value in self.values:\n      if attribute in value.OptionNames():\n        result.append(value.name)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a list of SGR values and formats them as an ANSI escape sequence.", "response": "def _AnsiCmd(command_list):\n  \"\"\"Takes a list of SGR values and formats them as an ANSI escape sequence.\n\n  Args:\n    command_list: List of strings, each string represents an SGR value.\n        e.g. 'fg_blue', 'bg_yellow'\n\n  Returns:\n    The ANSI escape sequence.\n\n  Raises:\n    ValueError: if a member of command_list does not map to a valid SGR value.\n  \"\"\"\n  if not isinstance(command_list, list):\n    raise ValueError('Invalid list: %s' % command_list)\n  # Checks that entries are valid SGR names.\n  # No checking is done for sequences that are correct but 'nonsensical'.\n  for sgr in command_list:\n    if sgr.lower() not in SGR:\n      raise ValueError('Invalid or unsupported SGR name: %s' % sgr)\n  # Convert to numerical strings.\n  command_str = [str(SGR[x.lower()]) for x in command_list]\n  # Wrap values in Ansi escape sequence (CSI prefix & SGR suffix).\n  return '\\033[%sm' % (';'.join(command_str))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AnsiText(text, command_list=None, reset=True):\n  command_list = command_list or ['reset']\n  if reset:\n    return '%s%s%s' % (_AnsiCmd(command_list), text, _AnsiCmd(['reset']))\n  else:\n    return '%s%s' % (_AnsiCmd(command_list), text)", "response": "Wrap text in ANSI escape codes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef EncloseAnsiText(text):\n  return sgr_re.sub(lambda x: ANSI_START + x.group(1) + ANSI_END, text)", "response": "Enclose ANSI escape sequences with ANSI_START and ANSI_END."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns terminal length and width as a tuple.", "response": "def TerminalSize():\n  \"\"\"Returns terminal length and width as a tuple.\"\"\"\n  try:\n    with open(os.ctermid(), 'r') as tty_instance:\n      length_width = struct.unpack(\n          'hh', fcntl.ioctl(tty_instance.fileno(), termios.TIOCGWINSZ, '1234'))\n  except (IOError, OSError):\n    try:\n      length_width = (int(os.environ['LINES']),\n                      int(os.environ['COLUMNS']))\n    except (ValueError, KeyError):\n      length_width = (24, 80)\n  return length_width"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbreaking a string into lines of width width.", "response": "def LineWrap(text, omit_sgr=False):\n  \"\"\"Break line to fit screen width, factoring in ANSI/SGR escape sequences.\n\n  Args:\n    text: String to line wrap.\n    omit_sgr: Bool, to omit counting ANSI/SGR sequences in the length.\n\n  Returns:\n    Text with additional line wraps inserted for lines grater than the width.\n  \"\"\"\n\n  def _SplitWithSgr(text_line):\n    \"\"\"Tokenise the line so that the sgr sequences can be omitted.\"\"\"\n    token_list = sgr_re.split(text_line)\n    text_line_list = []\n    line_length = 0\n    for (index, token) in enumerate(token_list):\n      # Skip null tokens.\n      if token is '':\n        continue\n\n      if sgr_re.match(token):\n        # Add sgr escape sequences without splitting or counting length.\n        text_line_list.append(token)\n        text_line = ''.join(token_list[index +1:])\n      else:\n        if line_length + len(token) <= width:\n          # Token fits in line and we count it towards overall length.\n          text_line_list.append(token)\n          line_length += len(token)\n          text_line = ''.join(token_list[index +1:])\n        else:\n          # Line splits part way through this token.\n          # So split the token, form a new line and carry the remainder.\n          text_line_list.append(token[:width - line_length])\n          text_line = token[width - line_length:]\n          text_line += ''.join(token_list[index +1:])\n          break\n\n    return (''.join(text_line_list), text_line)\n\n  # We don't use textwrap library here as it insists on removing\n  # trailing/leading whitespace (pre 2.6).\n  (_, width) = TerminalSize()\n  text = str(text)\n  text_multiline = []\n  for text_line in text.splitlines():\n    # Is this a line that needs splitting?\n    while ((omit_sgr and (len(StripAnsiText(text_line)) > width)) or\n           (len(text_line) > width)):\n      # If there are no sgr escape characters then do a straight split.\n      if not omit_sgr:\n        text_multiline.append(text_line[:width])\n        text_line = text_line[width:]\n      else:\n        (multiline_line, text_line) = _SplitWithSgr(text_line)\n        text_multiline.append(multiline_line)\n    if text_line:\n      text_multiline.append(text_line)\n  return '\\n'.join(text_multiline)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(argv=None):\n\n  if argv is None:\n    argv = sys.argv\n\n  try:\n    opts, args = getopt.getopt(argv[1:], 'dhs', ['nodelay', 'help', 'size'])\n  except getopt.error as msg:\n    raise Usage(msg)\n\n  # Print usage and return, regardless of presence of other args.\n  for opt, _ in opts:\n    if opt in ('-h', '--help'):\n      print(__doc__)\n      print(help_msg)\n      return 0\n\n  isdelay = False\n  for opt, _ in opts:\n    # Prints the size of the terminal and returns.\n    # Mutually exclusive to the paging of text and overrides that behaviour.\n    if opt in ('-s', '--size'):\n      print('Length: %d, Width: %d' % TerminalSize())\n      return 0\n    elif opt in ('-d', '--delay'):\n      isdelay = True\n    else:\n      raise Usage('Invalid arguments.')\n\n  # Page text supplied in either specified file or stdin.\n\n  if len(args) == 1:\n    with open(args[0]) as f:\n      fd = f.read()\n  else:\n    fd = sys.stdin.read()\n  Pager(fd, delay=isdelay).Page()", "response": "Routine to page text or determine window size via command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the pager to the top of the text.", "response": "def Reset(self):\n    \"\"\"Reset the pager to the top of the text.\"\"\"\n    self._displayed = 0\n    self._currentpagelines = 0\n    self._lastscroll = 1\n    self._lines_to_show = self._cli_lines"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SetLines(self, lines):\n\n    (self._cli_lines, self._cli_cols) = TerminalSize()\n\n    if lines:\n      self._cli_lines = int(lines)", "response": "Sets the number of lines in the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Page(self, text=None, show_percent=None):\n    if text is not None:\n      self._text += text\n\n    if show_percent is None:\n      show_percent = text is None\n    self._show_percent = show_percent\n\n    text = LineWrap(self._text).splitlines()\n    while True:\n      # Get a list of new lines to display.\n      self._newlines = text[self._displayed:self._displayed+self._lines_to_show]\n      for line in self._newlines:\n        sys.stdout.write(line + '\\n')\n        if self._delay and self._lastscroll > 0:\n          time.sleep(0.005)\n      self._displayed += len(self._newlines)\n      self._currentpagelines += len(self._newlines)\n      if self._currentpagelines >= self._lines_to_show:\n        self._currentpagelines = 0\n        wish = self._AskUser()\n        if wish == 'q':         # Quit pager.\n          return False\n        elif wish == 'g':       # Display till the end.\n          self._Scroll(len(text) - self._displayed + 1)\n        elif wish == '\\r':      #  Enter, down a line.\n          self._Scroll(1)\n        elif wish == '\\033[B':  # Down arrow, down a line.\n          self._Scroll(1)\n        elif wish == '\\033[A':  # Up arrow, up a line.\n          self._Scroll(-1)\n        elif wish == 'b':       # Up a page.\n          self._Scroll(0 - self._cli_lines)\n        else:                   # Next page.\n          self._Scroll()\n      if self._displayed >= len(text):\n        break\n\n    return True", "response": "Page through the text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscroll the buffer correctly.", "response": "def _Scroll(self, lines=None):\n    \"\"\"Set attributes to scroll the buffer correctly.\n\n    Args:\n      lines: An int, number of lines to scroll. If None, scrolls\n        by the terminal length.\n    \"\"\"\n    if lines is None:\n      lines = self._cli_lines\n\n    if lines < 0:\n      self._displayed -= self._cli_lines\n      self._displayed += lines\n      if self._displayed < 0:\n        self._displayed = 0\n      self._lines_to_show = self._cli_lines\n    else:\n      self._lines_to_show = lines\n\n    self._lastscroll = lines"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _AskUser(self):\n    if self._show_percent:\n      progress = int(self._displayed*100 / (len(self._text.splitlines())))\n      progress_text = ' (%d%%)' % progress\n    else:\n      progress_text = ''\n    question = AnsiText(\n        'Enter: next line, Space: next page, '\n        'b: prev page, q: quit.%s' %\n        progress_text, ['green'])\n    sys.stdout.write(question)\n    sys.stdout.flush()\n    ch = self._GetCh()\n    sys.stdout.write('\\r%s\\r' % (' '*len(question)))\n    sys.stdout.flush()\n    return ch", "response": "Prompt the user for the next action."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a single character from the user.", "response": "def _GetCh(self):\n    \"\"\"Read a single character from the user.\n\n    Returns:\n      A string, the character read.\n    \"\"\"\n    fd = self._tty.fileno()\n    old = termios.tcgetattr(fd)\n    try:\n      tty.setraw(fd)\n      ch = self._tty.read(1)\n      # Also support arrow key shortcuts (escape + 2 chars)\n      if ord(ch) == 27:\n        ch += self._tty.read(2)\n    finally:\n      termios.tcsetattr(fd, termios.TCSADRAIN, old)\n    return ch"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_deflection(position, observer, ephemeris, t,\n                   include_earth_deflection, count=3):\n    \"\"\"Update `position` for how solar system masses will deflect its light.\n\n    Given the ICRS `position` [x,y,z] of an object (au) that is being\n    viewed from the `observer` also expressed as [x,y,z], and given an\n    ephemeris that can be used to determine solar system body positions,\n    and given the time `t` and Boolean `apply_earth` indicating whether\n    to worry about the effect of Earth's mass, and a `count` of how many\n    major solar system bodies to worry about, this function updates\n    `position` in-place to show how the masses in the solar system will\n    deflect its image.\n\n    \"\"\"\n    # Compute light-time to observed object.\n\n    tlt = length_of(position) / C_AUDAY\n\n    # Cycle through gravitating bodies.\n\n    jd_tdb = t.tdb\n    ts = t.ts\n    for name in deflectors[:count]:\n        try:\n            deflector = ephemeris[name]\n        except KeyError:\n            deflector = ephemeris[name + ' barycenter']\n\n        # Get position of gravitating body wrt ss barycenter at time 't_tdb'.\n\n        bposition = deflector.at(ts.tdb(jd=jd_tdb)).position.au  # TODO\n\n        # Get position of gravitating body wrt observer at time 'jd_tdb'.\n\n        gpv = bposition - observer\n\n        # Compute light-time from point on incoming light ray that is closest\n        # to gravitating body.\n\n        dlt = light_time_difference(position, gpv)\n\n        # Get position of gravitating body wrt ss barycenter at time when\n        # incoming photons were closest to it.\n\n        tclose = jd_tdb\n\n        # if dlt > 0.0:\n        #     tclose = jd - dlt\n\n        tclose = where(dlt > 0.0, jd_tdb - dlt, tclose)\n        tclose = where(tlt < dlt, jd_tdb - tlt, tclose)\n\n        # if tlt < dlt:\n        #     tclose = jd - tlt\n\n        bposition = deflector.at(ts.tdb(jd=tclose)).position.au  # TODO\n        rmass = rmasses[name]\n        _add_deflection(position, observer, bposition, rmass)\n\n    # If observer is not at geocenter, add in deflection due to Earth.\n\n    if include_earth_deflection.any():\n        deflector = ephemeris['earth']\n        bposition = deflector.at(ts.tdb(jd=tclose)).position.au  # TODO\n        rmass = rmasses['earth']\n        # TODO: Make the following code less messy, maybe by having\n        # _add_deflection() return a new vector instead of modifying the\n        # old one in-place.\n        deflected_position = position.copy()\n        _add_deflection(deflected_position, observer, bposition, rmass)\n        if include_earth_deflection.shape:\n            position[:,include_earth_deflection] = (\n                deflected_position[:,include_earth_deflection])\n        else:\n            position[:] = deflected_position[:]", "response": "Add a deflection to the solar system body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef light_time_difference(position, observer_position):\n    # From 'pos1', form unit vector 'u1' in direction of star or light\n    # source.\n\n    dis = length_of(position)\n    u1 = position / dis\n\n    # Light-time returned is the projection of vector 'pos_obs' onto the\n    # unit vector 'u1' (formed from 'pos1'), divided by the speed of light.\n\n    diflt = einsum('a...,a...', u1, observer_position) / C_AUDAY\n    return diflt", "response": "Returns the difference in light - time for a star and an observer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a deflection to the ICRS position vector.", "response": "def _add_deflection(position, observer, deflector, rmass):\n    \"\"\"Correct a position vector for how one particular mass deflects light.\n\n    Given the ICRS `position` [x,y,z] of an object (AU) together with\n    the positions of an `observer` and a `deflector` of reciprocal mass\n    `rmass`, this function updates `position` in-place to show how much\n    the presence of the deflector will deflect the image of the object.\n\n    \"\"\"\n    # Construct vector 'pq' from gravitating body to observed object and\n    # construct vector 'pe' from gravitating body to observer.\n\n    pq = observer + position - deflector\n    pe = observer - deflector\n\n    # Compute vector magnitudes and unit vectors.\n\n    pmag = length_of(position)\n    qmag = length_of(pq)\n    emag = length_of(pe)\n\n    phat = position / where(pmag, pmag, 1.0)  # where() avoids divide-by-zero\n    qhat = pq / where(qmag, qmag, 1.0)\n    ehat = pe / where(emag, emag, 1.0)\n\n    # Compute dot products of vectors.\n\n    pdotq = dots(phat, qhat)\n    qdote = dots(qhat, ehat)\n    edotp = dots(ehat, phat)\n\n    # If gravitating body is observed object, or is on a straight line\n    # toward or away from observed object to within 1 arcsec, deflection\n    # is set to zero set 'pos2' equal to 'pos1'.\n\n    make_no_correction = abs(edotp) > 0.99999999999\n\n    # Compute scalar factors.\n\n    fac1 = 2.0 * GS / (C * C * emag * AU_M * rmass)\n    fac2 = 1.0 + qdote\n\n    # Correct position vector.\n\n    position += where(make_no_correction, 0.0,\n                      fac1 * (pdotq * ehat - edotp * qhat) / fac2 * pmag)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncorrect a relative position vector for aberration of light.", "response": "def add_aberration(position, velocity, light_time):\n    \"\"\"Correct a relative position vector for aberration of light.\n\n    Given the relative `position` [x,y,z] of an object (AU) from a\n    particular observer, the `velocity` [dx,dy,dz] at which the observer\n    is traveling (AU/day), and the light propagation delay `light_time`\n    to the object (days), this function updates `position` in-place to\n    give the object's apparent position due to the aberration of light.\n\n    \"\"\"\n    p1mag = light_time * C_AUDAY\n    vemag = length_of(velocity)\n    beta = vemag / C_AUDAY\n    dot = dots(position, velocity)\n\n    cosd = dot / (p1mag * vemag)\n    gammai = sqrt(1.0 - beta * beta)\n    p = beta * cosd\n    q = (1.0 + p / (1.0 + gammai)) * light_time\n    r = 1.0 + p\n\n    position *= gammai\n    position += q * velocity\n    position /= r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _center(code, segment_dict):\n    while code in segment_dict:\n        segment = segment_dict[code]\n        yield segment\n        code = segment.center", "response": "Given a segment dictionary and a code yield all segments from target to center."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all target names that are valid with this kernel.", "response": "def names(self):\n        \"\"\"Return all target names that are valid with this kernel.\n\n        >>> pprint(planets.names())\n        {0: ['SOLAR_SYSTEM_BARYCENTER', 'SSB', 'SOLAR SYSTEM BARYCENTER'],\n         1: ['MERCURY_BARYCENTER', 'MERCURY BARYCENTER'],\n         2: ['VENUS_BARYCENTER', 'VENUS BARYCENTER'],\n         3: ['EARTH_BARYCENTER',\n             'EMB',\n         ...\n\n        The result is a dictionary with target code keys and name lists\n        as values.  The last name in each list is the one that Skyfield\n        uses when printing information about a body.\n\n        \"\"\"\n        d = defaultdict(list)\n        for code, name in target_name_pairs:\n            if code in self.codes:\n                d[code].append(name)\n        return dict(d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntranslating a target name into its integer code.", "response": "def decode(self, name):\n        \"\"\"Translate a target name into its integer code.\n\n        >>> planets.decode('Venus')\n        299\n\n        Raises ``ValueError`` if you supply an unknown name, or\n        ``KeyError`` if the target is missing from this kernel.  You can\n        supply an integer code if you already have one and just want to\n        check whether it is present in this kernel.\n\n        \"\"\"\n        if isinstance(name, int):\n            code = name\n        else:\n            name = name.upper()\n            code = _targets.get(name)\n            if code is None:\n                raise ValueError('unknown SPICE target {0!r}'.format(name))\n        if code not in self.codes:\n            targets = ', '.join(_format_code_and_name(c) for c in self.codes)\n            raise KeyError('kernel {0!r} is missing {1!r} -'\n                           ' the targets it supports are: {2}'\n                           .format(self.filename, name, targets))\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _search(mapping, filename):\n    result = mapping.get(filename)\n    if result is not None:\n        return result\n    name, ext = os.path.splitext(filename)\n    result = mapping.get(ext)\n    if result is not None:\n        for pattern, result2 in result:\n            if fnmatch(filename, pattern):\n                return result2\n    return None", "response": "Search a Loader data structure for a filename."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a file on your local drive using its extension to guess its type.", "response": "def load_file(path):\n    \"\"\"Open a file on your local drive, using its extension to guess its type.\n\n    This routine only works on ``.bsp`` ephemeris files right now, but\n    will gain support for additional file types in the future. ::\n\n        from skyfield.api import load_file\n        planets = load_file('~/Downloads/de421.bsp')\n\n    \"\"\"\n    path = os.path.expanduser(path)\n    base, ext = os.path.splitext(path)\n    if ext == '.bsp':\n        return SpiceKernel(path)\n    raise ValueError('unrecognized file extension: {}'.format(path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_deltat_data(fileobj):\n    array = np.loadtxt(fileobj)\n    year, month, day = array[-1,:3].astype(int)\n    expiration_date = date(year + 1, month, day)\n    year, month, day, delta_t = array.T\n    data = np.array((julian_date(year, month, day), delta_t))\n    return expiration_date, data", "response": "Parse the United States Naval Observatory deltat. data file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the United States Naval Observatory Delta T file and return a 2xN array of raw Julian dates and matching Delta T values.", "response": "def parse_deltat_preds(fileobj):\n    \"\"\"Parse the United States Naval Observatory ``deltat.preds`` file.\n\n    The old format supplies a floating point year, the value of Delta T,\n    and one or two other fields::\n\n    2015.75      67.97               0.210         0.02\n\n    The new format adds a modified Julian day as the first field:\n\n    58484.000  2019.00   69.34      -0.152       0.117\n\n    This function returns a 2xN array of raw Julian dates and matching\n    Delta T values.\n\n    \"\"\"\n    lines = iter(fileobj)\n    header = next(lines)\n\n    if header.startswith(b'YEAR'):\n        # Format in use until 2019 February\n        next(lines)             # discard blank line\n        year_float, delta_t = np.loadtxt(lines, usecols=[0, 1]).T\n    else:\n        # Format in use since 2019 February\n        year_float, delta_t = np.loadtxt(lines, usecols=[1, 2]).T\n\n    year = year_float.astype(int)\n    month = 1 + (year_float * 12.0).astype(int) % 12\n    expiration_date = date(year[0] + 2, month[0], 1)\n    data = np.array((julian_date(year, month, 1), delta_t))\n    return expiration_date, data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the IERS file for the current year and date of the IERS file.", "response": "def parse_leap_seconds(fileobj):\n    \"\"\"Parse the IERS file ``Leap_Second.dat``.\n\n    The leap dates array can be searched with::\n\n        index = np.searchsorted(leap_dates, jd, 'right')\n\n    The resulting index allows (TAI - UTC) to be fetched with::\n\n        offset = leap_offsets[index]\n\n    \"\"\"\n    lines = iter(fileobj)\n    for line in lines:\n        if line.startswith(b'#  File expires on'):\n            break\n    else:\n        raise ValueError('Leap_Second.dat is missing its expiration date')\n    line = line.decode('ascii')\n\n    with _lock:  # won't help if anyone user threads are doing parsing, alas\n        original_locale = locale.setlocale(locale.LC_ALL)\n        locale.setlocale(locale.LC_ALL, 'C')\n        try:\n            dt = datetime.strptime(line, '#  File expires on %d %B %Y\\n')\n        finally:\n            locale.setlocale(locale.LC_ALL, original_locale)\n\n    # The file went out of date at the beginning of July 2016, and kept\n    # downloading every time a user ran a Skyfield program.  So we now\n    # build in a grace period:\n    grace_period = timedelta(days=30)\n    expiration_date = dt.date() + grace_period\n    mjd, day, month, year, offsets = np.loadtxt(lines).T\n    leap_dates = np.ndarray(len(mjd) + 2)\n    leap_dates[0] = '-inf'\n    leap_dates[1:-1] = mjd + 2400000.5\n    leap_dates[-1] = 'inf'\n    leap_offsets = np.ndarray(len(mjd) + 2)\n    leap_offsets[0] = leap_offsets[1] = offsets[0]\n    leap_offsets[2:] = offsets\n    return expiration_date, (leap_dates, leap_offsets)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a TLE file and return a generator of tuples. Each tuple is returned as a tuple containing the names and sat.", "response": "def parse_tle(fileobj):\n    \"\"\"Parse a file of TLE satellite element sets.\n\n    Builds an Earth satellite from each pair of adjacent lines in the\n    file that start with \"1 \" and \"2 \" and have 69 or more characters\n    each.  If the preceding line is exactly 24 characters long, then it\n    is parsed as the satellite's name.  For each satellite found, yields\n    a tuple `(names, sat)` giving the name(s) on the preceding line (or\n    `None` if no name was found) and the satellite object itself.\n\n    An exception is raised if the attempt to parse a pair of candidate\n    lines as TLE elements fails.\n\n    \"\"\"\n    b0 = b1 = b''\n    for b2 in fileobj:\n        if (b1.startswith(b'1 ') and len(b1) >= 69 and\n            b2.startswith(b'2 ') and len(b2) >= 69):\n\n            b0 = b0.rstrip(b'\\n\\r')\n            if len(b0) == 24:   # Celestrak\n                name = b0.decode('ascii').rstrip()\n                names = [name]\n            elif b0.startswith(b'0 '): # Spacetrack 3-line format\n                name = b0[2:].decode('ascii').rstrip()\n                names = [name]\n            else:\n                name = None\n                names = ()\n\n            line1 = b1.decode('ascii')\n            line2 = b2.decode('ascii')\n            sat = EarthSatellite(line1, line2, name)\n\n            if name and ' (' in name:\n                # Given a name like `ISS (ZARYA)` or `HTV-6 (KOUNOTORI\n                # 6)`, also support lookup by the name inside or outside\n                # the parentheses.\n                short_name, secondary_name = name.split(' (')\n                secondary_name = secondary_name.rstrip(')')\n                names.append(short_name)\n                names.append(secondary_name)\n\n            yield names, sat\n\n        b0 = b1\n        b1 = b2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(url, path, verbose=None, blocksize=128*1024):\n    tempname = path + '.download'\n    try:\n        connection = urlopen(url)\n    except Exception as e:\n        raise IOError('cannot get {0} because {1}'.format(url, e))\n    if verbose is None:\n        verbose = sys.stderr.isatty()\n\n    bar = None\n    if verbose:\n        if _running_IDLE:\n            print('Downloading {0} ...'.format(os.path.basename(path)),\n                  file=sys.stderr)\n        else:\n            bar = ProgressBar(path)\n            content_length = int(connection.headers.get('content-length', -1))\n\n    # Python open() provides no way to achieve O_CREAT without also\n    # truncating the file, which would ruin the work of another process\n    # that is trying to download the same file at the same time.  So:\n\n    flags = getattr(os, 'O_BINARY', 0) | os.O_CREAT | os.O_RDWR\n    fd = os.open(tempname, flags, 0o666)\n    with os.fdopen(fd, 'wb') as w:\n        try:\n            if lockf is not None:\n                fd = w.fileno()\n                lockf(fd, LOCK_EX)           # only one download at a time\n                if os.path.exists(path): # did someone else finish first?\n                    if os.path.exists(tempname):\n                        os.unlink(tempname)\n                    return\n            w.seek(0)\n            length = 0\n            while True:\n                data = connection.read(blocksize)\n                if not data:\n                    break\n                w.write(data)\n                length += len(data)\n                if bar is not None:\n                    bar.report(length, content_length)\n            w.flush()\n            if lockf is not None:\n                # On Unix, rename while still protected by the lock.\n                try:\n                    os.rename(tempname, path)\n                except Exception as e:\n                    raise IOError('error renaming {0} to {1} - {2}'.format(\n                        tempname, path, e))\n        except Exception as e:\n            raise IOError('error getting {0} - {1}'.format(url, e))\n        finally:\n            if lockf is not None:\n                lockf(fd, LOCK_UN)\n    if lockf is None:\n        # On Windows, rename here because the file needs to be closed first.\n        try:\n            _replace(tempname, path)\n        except Exception as e:\n            raise IOError('error renaming {0} to {1} - {2}'.format(\n                tempname, path, e))", "response": "Download a file from a URL and save it to a file named by path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading and parse a satellite TLE file and return a dictionary of satellite names and numbers.", "response": "def tle(self, url, reload=False, filename=None):\n        \"\"\"Load and parse a satellite TLE file.\n\n        Given a URL or a local path, this loads a file of three-line records in\n        the common Celestrak file format, or two-line records like those from\n        space-track.org. For a three-line element set, each first line gives\n        the name of a satellite and the following two lines are the TLE orbital\n        elements. A two-line element set comprises only these last two lines.\n\n        See the :meth:`~skyfield.iokit.Loader.open()` documentation for\n        the meaning of the ``reload`` and ``filename`` parameters.\n\n        Returns a dictionary whose keys are satellite names and numbers,\n        and whose values are :class:`~skyfield.sgp4lib.EarthSatellite`\n        objects.  If you want to build a list in which each satellite\n        appears only once, simply run ``sats = set(d.values())`` on the\n        returned dictionary.\n\n        \"\"\"\n        d = {}\n        with self.open(url, reload=reload, filename=filename) as f:\n            for names, sat in parse_tle(f):\n                d[sat.model.satnum] = sat\n                for name in names:\n                    d[name] = sat\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, url, mode='rb', reload=False, filename=None):\n        if '://' not in url:\n            path_that_might_be_relative = url\n            path = os.path.join(self.directory, path_that_might_be_relative)\n            return open(path, mode)\n        if filename is None:\n            filename = urlparse(url).path.split('/')[-1]\n        path = self.path_to(filename)\n        if reload and os.path.exists(path):\n            os.remove(path)\n        if not os.path.exists(path):\n            download(url, path, self.verbose)\n        return open(path, mode)", "response": "Open a file in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen or download three time scale files returning a Timescale object.", "response": "def timescale(self, delta_t=None):\n        \"\"\"Open or download three time scale files, returning a `Timescale`.\n\n        This method is how most Skyfield users build a `Timescale`\n        object, which is necessary for building specific `Time` objects\n        that name specific moments.\n\n        This will open or download the three files that Skyfield needs\n        to measure time.  UT1 is tabulated by the United States Naval\n        Observatory files ``deltat.data`` and ``deltat.preds``, while\n        UTC is defined by ``Leap_Second.dat`` from the International\n        Earth Rotation Service.\n\n        \"\"\"\n        if delta_t is not None:\n            delta_t_recent = np.array(((-1e99, 1e99), (delta_t, delta_t)))\n        else:\n            data = self('deltat.data')\n            preds = self('deltat.preds')\n            data_end_time = data[0, -1]\n            i = np.searchsorted(preds[0], data_end_time, side='right')\n            delta_t_recent = np.concatenate([data, preds[:,i:]], axis=1)\n        leap_dates, leap_offsets = self('Leap_Second.dat')\n        return Timescale(delta_t_recent, leap_dates, leap_offsets)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_summary(url, spk=True):\n    ''' simple function to retrieve the header of a BSP file and return SPK object'''\n    # connect to file at URL\n    bspurl = urllib2.urlopen(url)\n    # retrieve the \"tip\" of a file at URL\n    bsptip = bspurl.read(10**5) # first 100kB\n    # save data in fake file object (in-memory)\n    bspstr = StringIO(bsptip)\n    # load into DAF object\n    daf = DAF(bspstr)\n    # return either SPK or DAF object\n    if spk:\n      # make a SPK object\n      spk = SPK(daf)\n      # return representation \n      return spk\n    else:\n      # return representation \n      return daf", "response": "simple function to retrieve the header of a BSP file and return SPK object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncorrects the astrometric position and velocity for light - travel time.", "response": "def _correct_for_light_travel_time(observer, target):\n    \"\"\"Return a light-time corrected astrometric position and velocity.\n\n    Given an `observer` that is a `Barycentric` position somewhere in\n    the solar system, compute where in the sky they will see the body\n    `target`, by computing the light-time between them and figuring out\n    where `target` was back when the light was leaving it that is now\n    reaching the eyes or instruments of the `observer`.\n\n    \"\"\"\n    t = observer.t\n    ts = t.ts\n    cposition = observer.position.au\n    cvelocity = observer.velocity.au_per_d\n    tposition, tvelocity, gcrs_position, message = target._at(t)\n    distance = length_of(tposition - cposition)\n    light_time0 = 0.0\n    t_tdb = t.tdb\n    for i in range(10):\n        light_time = distance / C_AUDAY\n        delta = light_time - light_time0\n        if -1e-12 < min(delta) and max(delta) < 1e-12:\n            break\n        t2 = ts.tdb(jd=t_tdb - light_time)\n        tposition, tvelocity, gcrs_position, message = target._at(t2)\n        distance = length_of(tposition - cposition)\n        light_time0 = light_time\n    else:\n        raise ValueError('light-travel time failed to converge')\n    return tposition - cposition, tvelocity - cvelocity, t, light_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef at(self, t):\n        if not isinstance(t, Time):\n            raise ValueError('please provide the at() method with a Time'\n                             ' instance as its argument, instead of the'\n                             ' value {0!r}'.format(t))\n        observer_data = ObserverData()\n        observer_data.ephemeris = self.ephemeris\n        p, v, observer_data.gcrs_position, message = self._at(t)\n        center = self.center\n        if center == 0:\n            observer_data.bcrs_position = p\n            observer_data.bcrs_velocity = v\n        self._snag_observer_data(observer_data, t)\n        position = build_position(p, v, t, center, self.target, observer_data)\n        position.message = message\n        return position", "response": "Compute the position relative to the center of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef julian_day(year, month=1, day=1):\n    janfeb = month < 3\n    return (day\n            + 1461 * (year + 4800 - janfeb) // 4\n            + 367 * (month - 2 + janfeb * 12) // 12\n            - 3 * ((year + 4900 - janfeb) // 100) // 4\n            - 32075)", "response": "Given a proleptic Gregorian calendar date return a Julian day int."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef julian_date(year, month=1, day=1, hour=0, minute=0, second=0.0):\n    return julian_day(year, month, day) - 0.5 + (\n        second + minute * 60.0 + hour * 3600.0) / DAY_S", "response": "Given a proleptic Gregorian calendar date return a Julian date float."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calendar_date(jd_integer):\n\n    k = jd_integer + 68569\n    n = 4 * k // 146097\n\n    k = k - (146097 * n + 3) // 4\n    m = 4000 * (k + 1) // 1461001\n    k = k - 1461 * m // 4 + 31\n    month = 80 * k // 2447\n    day = k - 2447 * month // 80\n    k = month // 11\n\n    month = month + 2 - 12 * k\n    year = 100 * (n - 49) + m + k\n\n    return year, month, day", "response": "Convert Julian Day jd_integer into a Gregorian date."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a (year, month, day, hour, minute, second.fraction) tuple. The `offset` is added to the time before it is split into its components. This is useful if the user is going to round the result before displaying it. If the result is going to be displayed as seconds, for example, set `offset` to half a second and then throw away the fraction; if the result is going to be displayed as minutes, set `offset` to thirty seconds and then throw away the seconds; and so forth.", "response": "def calendar_tuple(jd_float, offset=0.0):\n    \"\"\"Return a (year, month, day, hour, minute, second.fraction) tuple.\n\n    The `offset` is added to the time before it is split into its\n    components.  This is useful if the user is going to round the\n    result before displaying it.  If the result is going to be\n    displayed as seconds, for example, set `offset` to half a second\n    and then throw away the fraction; if the result is going to be\n    displayed as minutes, set `offset` to thirty seconds and then\n    throw away the seconds; and so forth.\n\n    \"\"\"\n    jd_float = _to_array(jd_float)\n    whole, fraction = divmod(jd_float + 0.5, 1.0)\n    whole = whole.astype(int)\n    year, month, day = calendar_date(whole)\n    hour, hfrac = divmod(fraction * 24.0, 1.0)\n    minute, second = divmod(hfrac * 3600.0, 60.0)\n    return year, month, day, hour.astype(int), minute.astype(int), second"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tdb_minus_tt(jd_tdb):\n    t = (jd_tdb - T0) / 36525.0\n\n    # USNO Circular 179, eq. 2.6.\n    return (0.001657 * sin ( 628.3076 * t + 6.2401)\n          + 0.000022 * sin ( 575.3385 * t + 4.2970)\n          + 0.000014 * sin (1256.6152 * t + 6.1969)\n          + 0.000005 * sin ( 606.9777 * t + 4.0212)\n          + 0.000005 * sin (  52.9691 * t + 0.4444)\n          + 0.000002 * sin (  21.3299 * t + 5.5431)\n          + 0.000010 * t * sin ( 628.3076 * t + 4.2490))", "response": "Computes how far TDB is in advance of TT given TDB."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn interpolated Delta T values for the times in tt.", "response": "def interpolate_delta_t(delta_t_table, tt):\n    \"\"\"Return interpolated Delta T values for the times in `tt`.\n\n    The 2xN table should provide TT values as element 0 and\n    corresponding Delta T values for element 1.  For times outside the\n    range of the table, a long-term formula is used instead.\n\n    \"\"\"\n    tt_array, delta_t_array = delta_t_table\n    delta_t = _to_array(interp(tt, tt_array, delta_t_array, nan, nan))\n    missing = isnan(delta_t)\n\n    if missing.any():\n        # Test if we are dealing with an array and proceed appropriately\n        if missing.shape:\n            tt = tt[missing]\n            delta_t[missing] = delta_t_formula_morrison_and_stephenson_2004(tt)\n        else:\n            delta_t = delta_t_formula_morrison_and_stephenson_2004(tt)\n    return delta_t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_delta_t_table(delta_t_recent):\n    ancient = load_bundled_npy('morrison_stephenson_deltat.npy')\n    historic = load_bundled_npy('historic_deltat.npy')\n\n    # Prefer USNO over Morrison and Stephenson where they overlap.\n    historic_start_time = historic[0,0]\n    i = searchsorted(ancient[0], historic_start_time)\n    bundled = concatenate([ancient[:,:i], historic], axis=1)\n\n    # Let recent data replace everything else.\n    recent_start_time = delta_t_recent[0,0]\n    i = searchsorted(bundled[0], recent_start_time)\n    row = ((0,),(0,))\n    table = concatenate([row, bundled[:,:i], delta_t_recent, row], axis=1)\n\n    # Create initial and final point to provide continuity with formula.\n    century = 36524.0\n    start = table[0,1] - century\n    table[:,0] = start, delta_t_formula_morrison_and_stephenson_2004(start)\n    end = table[0,-2] + century\n    table[:,-1] = end, delta_t_formula_morrison_and_stephenson_2004(end)\n    return table", "response": "Builds a table for interpolating Delta T values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a Time object from a UTC calendar date.", "response": "def utc(self, year, month=1, day=1, hour=0, minute=0, second=0.0):\n        \"\"\"Build a `Time` from a UTC calendar date.\n\n        You can either specify the date as separate components, or\n        provide a time zone aware Python datetime.  The following two\n        calls are equivalent (the ``utc`` time zone object can be\n        imported from the ``skyfield.api`` module, or from ``pytz`` if\n        you have it)::\n\n            ts.utc(2014, 1, 18, 1, 35, 37.5)\n            ts.utc(datetime(2014, 1, 18, 1, 35, 37, 500000, tzinfo=utc))\n\n        Note that only by passing the components separately can you\n        specify a leap second, because a Python datetime will not allow\n        the value 60 in its seconds field.\n\n        \"\"\"\n        if isinstance(year, datetime):\n            dt = year\n            tai = _utc_datetime_to_tai(self.leap_dates, self.leap_offsets, dt)\n        elif isinstance(year, date):\n            d = year\n            tai = _utc_date_to_tai(self.leap_dates, self.leap_offsets, d)\n        elif hasattr(year, '__len__') and isinstance(year[0], datetime):\n            # TODO: clean this up and better document the possibilities.\n            list_of_datetimes = year\n            tai = array([\n                _utc_datetime_to_tai(self.leap_dates, self.leap_offsets, dt)\n                for dt in list_of_datetimes])\n        else:\n            tai = _utc_to_tai(self.leap_dates, self.leap_offsets,\n                              _to_array(year), _to_array(month),\n                              _to_array(day), _to_array(hour),\n                              _to_array(minute), _to_array(second))\n        t = Time(self, tai + tt_minus_tai)\n        t.tai = tai\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tai(self, year=None, month=1, day=1, hour=0, minute=0, second=0.0,\n            jd=None):\n        \"\"\"Build a `Time` from a TAI calendar date.\n\n        Supply the International Atomic Time (TAI) as a proleptic\n        Gregorian calendar date:\n\n        >>> t = ts.tai(2014, 1, 18, 1, 35, 37.5)\n        >>> t.tai\n        2456675.56640625\n        >>> t.tai_calendar()\n        (2014, 1, 18, 1, 35, 37.5)\n\n        \"\"\"\n        if jd is not None:\n            tai = jd\n        else:\n            tai = julian_date(\n                _to_array(year), _to_array(month), _to_array(day),\n                _to_array(hour), _to_array(minute), _to_array(second),\n            )\n        return self.tai_jd(tai)", "response": "Build a Time object from a TAI calendar date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a Time object from a TAI Julian date.", "response": "def tai_jd(self, jd):\n        \"\"\"Build a `Time` from a TAI Julian date.\n\n        Supply the International Atomic Time (TAI) as a Julian date:\n\n        >>> t = ts.tai_jd(2456675.56640625)\n        >>> t.tai\n        2456675.56640625\n        >>> t.tai_calendar()\n        (2014, 1, 18, 1, 35, 37.5)\n\n        \"\"\"\n        tai = _to_array(jd)\n        t = Time(self, tai + tt_minus_tai)\n        t.tai = tai\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tt(self, year=None, month=1, day=1, hour=0, minute=0, second=0.0,\n           jd=None):\n        \"\"\"Build a `Time` from a TT calendar date.\n\n        Supply the Terrestrial Time (TT) as a proleptic Gregorian\n        calendar date:\n\n        >>> t = ts.tt(2014, 1, 18, 1, 35, 37.5)\n        >>> t.tt\n        2456675.56640625\n        >>> t.tt_calendar()\n        (2014, 1, 18, 1, 35, 37.5)\n\n        \"\"\"\n        if jd is not None:\n            tt = jd\n        else:\n            tt = julian_date(\n                _to_array(year), _to_array(month), _to_array(day),\n                _to_array(hour), _to_array(minute), _to_array(second),\n            )\n        tt = _to_array(tt)\n        return Time(self, tt)", "response": "Build a Time object from a Terrestrial Time calendar date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tdb(self, year=None, month=1, day=1, hour=0, minute=0, second=0.0,\n            jd=None):\n        \"\"\"Build a `Time` from a TDB calendar date.\n\n        Supply the Barycentric Dynamical Time (TDB) as a proleptic\n        Gregorian calendar date:\n\n        >>> t = ts.tdb(2014, 1, 18, 1, 35, 37.5)\n        >>> t.tdb\n        2456675.56640625\n\n        \"\"\"\n        if jd is not None:\n            tdb = jd\n        else:\n            tdb = julian_date(\n                _to_array(year), _to_array(month), _to_array(day),\n                _to_array(hour), _to_array(minute), _to_array(second),\n            )\n        tdb = _to_array(tdb)\n        tt = tdb - tdb_minus_tt(tdb) / DAY_S\n        t = Time(self, tt)\n        t.tdb = tdb\n        return t", "response": "Build a Time object from a TDB calendar date."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a Time from a TDB Julian date.", "response": "def tdb_jd(self, jd):\n        \"\"\"Build a `Time` from a TDB Julian date.\n\n        Supply the Barycentric Dynamical Time (TDB) as a Julian date:\n\n        >>> t = ts.tdb_jd(2456675.56640625)\n        >>> t.tdb\n        2456675.56640625\n\n        \"\"\"\n        tdb = _to_array(jd)\n        tt = tdb - tdb_minus_tt(tdb) / DAY_S\n        t = Time(self, tt)\n        t.tdb = tdb\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ut1(self, year=None, month=1, day=1, hour=0, minute=0, second=0.0,\n            jd=None):\n        \"\"\"Build a `Time` from a UT1 calendar date.\n\n        Supply the Universal Time (UT1) as a proleptic Gregorian\n        calendar date:\n\n        >>> t = ts.ut1(2014, 1, 18, 1, 35, 37.5)\n        >>> t.ut1\n        2456675.56640625\n\n        \"\"\"\n        if jd is not None:\n            ut1 = jd\n        else:\n            ut1 = julian_date(\n                _to_array(year), _to_array(month), _to_array(day),\n                _to_array(hour), _to_array(minute), _to_array(second),\n            )\n        return self.ut1_jd(ut1)", "response": "Build a Time object from a Universal Time calendar date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ut1_jd(self, jd):\n        ut1 = _to_array(jd)\n\n        # Estimate TT = UT1, to get a rough Delta T estimate.\n        tt_approx = ut1\n        delta_t_approx = interpolate_delta_t(self.delta_t_table, tt_approx)\n\n        # Use the rough Delta T to make a much better estimate of TT,\n        # then generate an even better Delta T.\n        tt_approx = ut1 + delta_t_approx / DAY_S\n        delta_t_approx = interpolate_delta_t(self.delta_t_table, tt_approx)\n\n        # We can now estimate TT with an error of < 1e-9 seconds within\n        # 10 centuries of either side of the present; for details, see:\n        # https://github.com/skyfielders/astronomy-notebooks\n        # and look for the notebook \"error-in-timescale-ut1.ipynb\".\n        tt = ut1 + delta_t_approx / DAY_S\n        t = Time(self, tt)\n        t.ut1 = ut1\n        return t", "response": "Build a Time from an Universal Time and a Julian date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting this time to a Python datetime and leap second in a timezone.", "response": "def astimezone_and_leap_second(self, tz):\n        \"\"\"Convert to a Python ``datetime`` and leap second in a timezone.\n\n        Convert this time to a Python ``datetime`` and a leap second::\n\n            dt, leap_second = t.astimezone_and_leap_second(tz)\n\n        The argument ``tz`` should be a timezone from the third-party\n        ``pytz`` package, which must be installed separately.  The date\n        and time returned will be for that time zone.\n\n        The leap second value is provided because a Python ``datetime``\n        can only number seconds ``0`` through ``59``, but leap seconds\n        have a designation of at least ``60``.  The leap second return\n        value will normally be ``0``, but will instead be ``1`` if the\n        date and time are a UTC leap second.  Add the leap second value\n        to the ``second`` field of the ``datetime`` to learn the real\n        name of the second.\n\n        If this time is an array, then an array of ``datetime`` objects\n        and an array of leap second integers is returned, instead of a\n        single value each.\n\n        \"\"\"\n        dt, leap_second = self.utc_datetime_and_leap_second()\n        normalize = getattr(tz, 'normalize', None)\n        if self.shape and normalize is not None:\n            dt = array([normalize(d.astimezone(tz)) for d in dt])\n        elif self.shape:\n            dt = array([d.astimezone(tz) for d in dt])\n        elif normalize is not None:\n            dt = normalize(dt.astimezone(tz))\n        else:\n            dt = dt.astimezone(tz)\n        return dt, leap_second"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef utc_datetime_and_leap_second(self):\n        year, month, day, hour, minute, second = self._utc_tuple(\n            _half_millisecond)\n        second, fraction = divmod(second, 1.0)\n        second = second.astype(int)\n        leap_second = second // 60\n        second -= leap_second\n        milli = (fraction * 1000).astype(int) * 1000\n        if self.shape:\n            utcs = [utc] * self.shape[0]\n            argsets = zip(year, month, day, hour, minute, second, milli, utcs)\n            dt = array([datetime(*args) for args in argsets])\n        else:\n            dt = datetime(year, month, day, hour, minute, second, milli, utc)\n        return dt, leap_second", "response": "Convert this time to a Python datetime in UTC plus a leap second value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting to an ISO 8601 string like 2011 - 01 - 18T01 - 35 - 38Z in UTC.", "response": "def utc_iso(self, delimiter='T', places=0):\n        \"\"\"Convert to an ISO 8601 string like ``2014-01-18T01:35:38Z`` in UTC.\n\n        If this time is an array of dates, then a sequence of strings is\n        returned instead of a single string.\n\n        \"\"\"\n        # \"places\" used to be the 1st argument, so continue to allow an\n        # integer in that spot.  TODO: deprecate this in Skyfield 2.0\n        # and remove it in 3.0.\n        if isinstance(delimiter, int):\n            places = delimiter\n            delimiter = 'T'\n\n        if places:\n            power_of_ten = 10 ** places\n            offset = _half_second / power_of_ten\n            year, month, day, hour, minute, second = self._utc_tuple(offset)\n            second, fraction = divmod(second, 1.0)\n            fraction *= power_of_ten\n            format = '%04d-%02d-%02d{0}%02d:%02d:%02d.%0{1}dZ'.format(\n                delimiter, places)\n            args = (year, month, day, hour, minute, second, fraction)\n        else:\n            format = '%04d-%02d-%02d{0}%02d:%02d:%02dZ'.format(delimiter)\n            args = self._utc_tuple(_half_second)\n\n        if self.shape:\n            return [format % tup for tup in zip(*args)]\n        else:\n            return format % args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting to an A. D. 2014 - Jan - 18 01. 2014 - Jan - 18 01. 35. 5000 UT string.", "response": "def utc_jpl(self):\n        \"\"\"Convert to an ``A.D. 2014-Jan-18 01:35:37.5000 UT`` string.\n\n        Returns a string for this date and time in UTC, in the format\n        used by the JPL HORIZONS system.  If this time is an array of\n        dates, then a sequence of strings is returned instead of a\n        single string.\n\n        \"\"\"\n        offset = _half_second / 1e4\n        year, month, day, hour, minute, second = self._utc_tuple(offset)\n        second, fraction = divmod(second, 1.0)\n        fraction *= 1e4\n        bc = year < 1\n        year = abs(year - bc)\n        era = where(bc, 'B.C.', 'A.D.')\n        format = '%s %04d-%s-%02d %02d:%02d:%02d.%04d UT'\n        args = (era, year, _months[month], day, hour, minute, second, fraction)\n\n        if self.shape:\n            return [format % tup for tup in zip(*args)]\n        else:\n            return format % args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef utc_strftime(self, format):\n        tup = self._utc_tuple(_half_second)\n        year, month, day, hour, minute, second = tup\n        second = second.astype(int)\n        zero = zeros_like(year)\n        tup = (year, month, day, hour, minute, second, zero, zero, zero)\n        if self.shape:\n            return [strftime(format, item) for item in zip(*tup)]\n        else:\n            return strftime(format, tup)", "response": "Format the UTC time using a Python date formatting string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _utc_year(self):\n        d = self._utc_float() - 1721059.5\n        #d += offset\n        C = 365 * 100 + 24\n        d -= 365\n        d += d // C - d // (4 * C)\n        d += 365\n        # Y = d / C * 100\n        # print(Y)\n        K = 365 * 3 + 366\n        d -= (d + K*7//8) // K\n        # d -= d // 1461.0\n        return d / 365.0", "response": "Return a fractional UTC year for convenience when plotting."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the UTC time as a tuple.", "response": "def _utc_tuple(self, offset=0.0):\n        \"\"\"Return UTC as (year, month, day, hour, minute, second.fraction).\n\n        The `offset` is added to the UTC time before it is split into\n        its components.  This is useful if the user is going to round\n        the result before displaying it.  If the result is going to be\n        displayed as seconds, for example, set `offset` to half a second\n        and then throw away the fraction; if the result is going to be\n        displayed as minutes, set `offset` to thirty seconds and then\n        throw away the seconds; and so forth.\n\n        \"\"\"\n        tai = self.tai + offset\n        leap_dates = self.ts.leap_dates\n        leap_offsets = self.ts.leap_offsets\n        leap_reverse_dates = leap_dates + leap_offsets / DAY_S\n        i = searchsorted(leap_reverse_dates, tai, 'right')\n        j = tai - leap_offsets[i] / DAY_S\n        whole, fraction = divmod(j + 0.5, 1.0)\n        whole = whole.astype(int)\n        year, month, day = calendar_date(whole)\n        hour, hfrac = divmod(fraction * 24.0, 1.0)\n        minute, second = divmod(hfrac * 3600.0, 60.0)\n        is_leap_second = j < leap_dates[i-1]\n        second += is_leap_second\n        return year, month, day, hour.astype(int), minute.astype(int), second"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns UTC as a floating point Julian date.", "response": "def _utc_float(self):\n        \"\"\"Return UTC as a floating point Julian date.\"\"\"\n        tai = self.tai\n        leap_dates = self.ts.leap_dates\n        leap_offsets = self.ts.leap_offsets\n        leap_reverse_dates = leap_dates + leap_offsets / DAY_S\n        i = searchsorted(leap_reverse_dates, tai, 'right')\n        return tai - leap_offsets[i] / DAY_S"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a named star catalog.", "response": "def NamedStar(name):\n    \"\"\"DEPRECATED: See stars.rst for how to load a star catalog.\"\"\"\n    try:\n        hid = named_star_dict[name]\n        return hipparcos.get(str(hid))\n    except KeyError:\n        raise ValueError(\"No star named {0} known to skyfield.\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the position and velocity of a terrestrial observer.", "response": "def terra(latitude, longitude, elevation, gast):\n    \"\"\"Compute the position and velocity of a terrestrial observer.\n\n    `latitude` - Latitude in radians.\n    `longitude` - Longitude in radians.\n    `elevation` - Elevation above sea level in au.\n    `gast` - Hours of Greenwich Apparent Sidereal Time (can be an array).\n\n    The return value is a tuple of two 3-vectors `(pos, vel)` in the\n    dynamical reference system (the true equator and equinox of date)\n    whose components are measured in au with respect to the center of\n    the Earth.\n\n    \"\"\"\n    zero = zeros_like(gast)\n    sinphi = sin(latitude)\n    cosphi = cos(latitude)\n    c = 1.0 / sqrt(cosphi * cosphi +\n                   sinphi * sinphi * one_minus_flattening_squared)\n    s = one_minus_flattening_squared * c\n    ach = earth_radius_au * c + elevation\n    ash = earth_radius_au * s + elevation\n\n    # Compute local sidereal time factors at the observer's longitude.\n\n    stlocl = 15.0 * DEG2RAD * gast + longitude\n    sinst = sin(stlocl)\n    cosst = cos(stlocl)\n\n    # Compute position vector components in kilometers.\n\n    ac = ach * cosphi\n    acsst = ac * sinst\n    accst = ac * cosst\n    pos = array((accst, acsst, zero + ash * sinphi))\n\n    # Compute velocity vector components in kilometers/sec.\n\n    vel = ANGVEL * DAY_S * array((-acsst, accst, zero))\n\n    return pos, vel"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a geocentric x y z at time t to latitude and longitude and elevation.", "response": "def reverse_terra(xyz_au, gast, iterations=3):\n    \"\"\"Convert a geocentric (x,y,z) at time `t` to latitude and longitude.\n\n    Returns a tuple of latitude, longitude, and elevation whose units\n    are radians and meters.  Based on Dr. T.S. Kelso's quite helpful\n    article \"Orbital Coordinate Systems, Part III\":\n    https://www.celestrak.com/columns/v02n03/\n\n    \"\"\"\n    x, y, z = xyz_au\n    R = sqrt(x*x + y*y)\n\n    lon = (arctan2(y, x) - 15 * DEG2RAD * gast - pi) % tau - pi\n    lat = arctan2(z, R)\n\n    a = ERAD / AU_M\n    f = 1.0 / IERS_2010_INVERSE_EARTH_FLATTENING\n    e2 = 2.0*f - f*f\n    i = 0\n    while i < iterations:\n        i += 1\n        C = 1.0 / sqrt(1.0 - e2 * (sin(lat) ** 2.0))\n        lat = arctan2(z + a * C * e2 * sin(lat), R)\n    elevation_m = ((R / cos(lat)) - a * C) * AU_M\n    return lat, lon, elevation_m"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the angle of an object above or below the Earth s limb.", "response": "def compute_limb_angle(position_au, observer_au):\n    \"\"\"Determine the angle of an object above or below the Earth's limb.\n\n    Given an object's GCRS `position_au` [x,y,z] vector and the position\n    of an `observer_au` as a vector in the same coordinate system,\n    return a tuple that provides `(limb_ang, nadir_ang)`:\n\n    limb_angle\n        Angle of observed object above (+) or below (-) limb in degrees.\n    nadir_angle\n        Nadir angle of observed object as a fraction of apparent radius\n        of limb: <1.0 means below the limb, =1.0 means on the limb, and\n        >1.0 means above the limb.\n\n    \"\"\"\n    # Compute the distance to the object and the distance to the observer.\n\n    disobj = sqrt(dots(position_au, position_au))\n    disobs = sqrt(dots(observer_au, observer_au))\n\n    # Compute apparent angular radius of Earth's limb.\n\n    aprad = arcsin(minimum(earth_radius_au / disobs, 1.0))\n\n    # Compute zenith distance of Earth's limb.\n\n    zdlim = pi - aprad\n\n    # Compute zenith distance of observed object.\n\n    coszd = dots(position_au, observer_au) / (disobj * disobs)\n    coszd = clip(coszd, -1.0, 1.0)\n    zdobj = arccos(coszd)\n\n    # Angle of object wrt limb is difference in zenith distances.\n\n    limb_angle = (zdlim - zdobj) * RAD2DEG\n\n    # Nadir angle of object as a fraction of angular radius of limb.\n\n    nadir_angle = (pi - zdobj) / aprad\n\n    return limb_angle, nadir_angle"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the Greenwich sidereal time at the given Time.", "response": "def sidereal_time(t):\n    \"\"\"Compute Greenwich sidereal time at the given ``Time``.\"\"\"\n\n    # Compute the Earth Rotation Angle.  Time argument is UT1.\n\n    theta = earth_rotation_angle(t.ut1)\n\n    # The equinox method.  See Circular 179, Section 2.6.2.\n    # Precession-in-RA terms in mean sidereal time taken from third\n    # reference, eq. (42), with coefficients in arcseconds.\n\n    t = (t.tdb - T0) / 36525.0\n    st =        ( 0.014506 +\n        (((( -    0.0000000368   * t\n             -    0.000029956  ) * t\n             -    0.00000044   ) * t\n             +    1.3915817    ) * t\n             + 4612.156534     ) * t)\n\n    # Form the Greenwich sidereal time.\n\n    return (st / 54000.0 + theta * 24.0) % 24.0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving an observed altitude return how much the image is refracted.", "response": "def refraction(alt_degrees, temperature_C, pressure_mbar):\n    \"\"\"Given an observed altitude, return how much the image is refracted.\n\n    Zero refraction is returned both for objects very near the zenith,\n    as well as for objects more than one degree below the horizon.\n\n    \"\"\"\n    r = 0.016667 / tan((alt_degrees + 7.31 / (alt_degrees + 4.4)) * DEG2RAD)\n    d = r * (0.28 * pressure_mbar / (temperature_C + 273.0))\n    return where((-1.0 <= alt_degrees) & (alt_degrees <= 89.9), d, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refract(alt_degrees, temperature_C, pressure_mbar):\n    alt = alt_degrees\n    while True:\n        alt1 = alt\n        alt = alt_degrees + refraction(alt, temperature_C, pressure_mbar)\n        converged = abs(alt - alt1) <= 3.0e-5\n        if converged.all():\n            break\n    return alt", "response": "Given an unrefracted alt determine where it will appear in the sky."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the rotation matrices for precessing to an array of epochs.", "response": "def compute_precession(jd_tdb):\n    \"\"\"Return the rotation matrices for precessing to an array of epochs.\n\n    `jd_tdb` - array of TDB Julian dates\n\n    The array returned has the shape `(3, 3, n)` where `n` is the number\n    of dates that have been provided as input.\n\n    \"\"\"\n    eps0 = 84381.406\n\n    # 't' is time in TDB centuries.\n\n    t = (jd_tdb - T0) / 36525.0\n\n    # Numerical coefficients of psi_a, omega_a, and chi_a, along with\n    # epsilon_0, the obliquity at J2000.0, are 4-angle formulation from\n    # Capitaine et al. (2003), eqs. (4), (37), & (39).\n\n    psia   = ((((-    0.0000000951  * t\n                 +    0.000132851 ) * t\n                 -    0.00114045  ) * t\n                 -    1.0790069   ) * t\n                 + 5038.481507    ) * t\n\n    omegaa = ((((+    0.0000003337  * t\n                 -    0.000000467 ) * t\n                 -    0.00772503  ) * t\n                 +    0.0512623   ) * t\n                 -    0.025754    ) * t + eps0\n\n    chia   = ((((-    0.0000000560  * t\n                 +    0.000170663 ) * t\n                 -    0.00121197  ) * t\n                 -    2.3814292   ) * t\n                 +   10.556403    ) * t\n\n    eps0 = eps0 * ASEC2RAD\n    psia = psia * ASEC2RAD\n    omegaa = omegaa * ASEC2RAD\n    chia = chia * ASEC2RAD\n\n    sa = sin(eps0)\n    ca = cos(eps0)\n    sb = sin(-psia)\n    cb = cos(-psia)\n    sc = sin(-omegaa)\n    cc = cos(-omegaa)\n    sd = sin(chia)\n    cd = cos(chia)\n\n    # Compute elements of precession rotation matrix equivalent to\n    # R3(chi_a) R1(-omega_a) R3(-psi_a) R1(epsilon_0).\n\n    rot3 = array(((cd * cb - sb * sd * cc,\n                   cd * sb * ca + sd * cc * cb * ca - sa * sd * sc,\n                   cd * sb * sa + sd * cc * cb * sa + ca * sd * sc),\n                  (-sd * cb - sb * cd * cc,\n                   -sd * sb * ca + cd * cc * cb * ca - sa * cd * sc,\n                   -sd * sb * sa + cd * cc * cb * sa + ca * cd * sc),\n                  (sb * sc,\n                   -sc * cb * ca - sa * cc,\n                   -sc * cb * sa + cc * ca)))\n\n    return rot3"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the nutation rotations for Time t.", "response": "def compute_nutation(t):\n    \"\"\"Generate the nutation rotations for Time `t`.\n\n    If the Julian date is scalar, a simple ``(3, 3)`` matrix is\n    returned; if the date is an array of length ``n``, then an array of\n    matrices is returned with dimensions ``(3, 3, n)``.\n\n    \"\"\"\n    oblm, oblt, eqeq, psi, eps = t._earth_tilt\n\n    cobm = cos(oblm * DEG2RAD)\n    sobm = sin(oblm * DEG2RAD)\n    cobt = cos(oblt * DEG2RAD)\n    sobt = sin(oblt * DEG2RAD)\n    cpsi = cos(psi * ASEC2RAD)\n    spsi = sin(psi * ASEC2RAD)\n\n    return array(((cpsi,\n                  -spsi * cobm,\n                  -spsi * sobm),\n                  (spsi * cobt,\n                   cpsi * cobm * cobt + sobm * sobt,\n                   cpsi * sobm * cobt - cobm * sobt),\n                  (spsi * sobt,\n                   cpsi * cobm * sobt - sobm * cobt,\n                   cpsi * sobm * sobt + cobm * cobt)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef earth_tilt(t):\n    dp, de = t._nutation_angles\n    c_terms = equation_of_the_equinoxes_complimentary_terms(t.tt) / ASEC2RAD\n\n    d_psi = dp * 1e-7 + t.psi_correction\n    d_eps = de * 1e-7 + t.eps_correction\n\n    mean_ob = mean_obliquity(t.tdb)\n    true_ob = mean_ob + d_eps\n\n    mean_ob /= 3600.0\n    true_ob /= 3600.0\n\n    eq_eq = d_psi * cos(mean_ob * DEG2RAD) + c_terms\n    eq_eq /= 15.0\n\n    return mean_ob, true_ob, eq_eq, d_psi, d_eps", "response": "Return a tuple of information about the earth s axis and position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the mean obliquity of the ecliptic in arcseconds.", "response": "def mean_obliquity(jd_tdb):\n    \"\"\"Return the mean obliquity of the ecliptic in arcseconds.\n\n    `jd_tt` - TDB time as a Julian date float, or NumPy array of floats\n\n    \"\"\"\n    # Compute time in Julian centuries from epoch J2000.0.\n\n    t = (jd_tdb - T0) / 36525.0\n\n    # Compute the mean obliquity in arcseconds.  Use expression from the\n    # reference's eq. (39) with obliquity at J2000.0 taken from eq. (37)\n    # or Table 8.\n\n    epsilon = (((( -  0.0000000434   * t\n                   -  0.000000576  ) * t\n                   +  0.00200340   ) * t\n                   -  0.0001831    ) * t\n                   - 46.836769     ) * t + 84381.406\n\n    return epsilon"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the complementary terms of the equation of the equinoxes.", "response": "def equation_of_the_equinoxes_complimentary_terms(jd_tt):\n    \"\"\"Compute the complementary terms of the equation of the equinoxes.\n\n    `jd_tt` - Terrestrial Time: Julian date float, or NumPy array of floats\n\n    \"\"\"\n    # Interval between fundamental epoch J2000.0 and current date.\n\n    t = (jd_tt - T0) / 36525.0\n\n    # Build array for intermediate results.\n\n    shape = getattr(jd_tt, 'shape', ())\n    fa = zeros((14,) if shape == () else (14, shape[0]))\n\n    # Mean Anomaly of the Moon.\n\n    fa[0] = ((485868.249036 +\n              (715923.2178 +\n              (    31.8792 +\n              (     0.051635 +\n              (    -0.00024470)\n              * t) * t) * t) * t) * ASEC2RAD\n              + (1325.0*t % 1.0) * tau)\n\n    # Mean Anomaly of the Sun.\n\n    fa[1] = ((1287104.793048 +\n              (1292581.0481 +\n              (     -0.5532 +\n              (     +0.000136 +\n              (     -0.00001149)\n              * t) * t) * t) * t) * ASEC2RAD\n              + (99.0*t % 1.0) * tau)\n\n    # Mean Longitude of the Moon minus Mean Longitude of the Ascending\n    # Node of the Moon.\n\n    fa[2] = (( 335779.526232 +\n              ( 295262.8478 +\n              (    -12.7512 +\n              (     -0.001037 +\n              (      0.00000417)\n              * t) * t) * t) * t) * ASEC2RAD\n              + (1342.0*t % 1.0) * tau)\n\n    # Mean Elongation of the Moon from the Sun.\n\n    fa[3] = ((1072260.703692 +\n              (1105601.2090 +\n              (     -6.3706 +\n              (      0.006593 +\n              (     -0.00003169)\n              * t) * t) * t) * t) * ASEC2RAD\n              + (1236.0*t % 1.0) * tau)\n\n    # Mean Longitude of the Ascending Node of the Moon.\n\n    fa[4] = (( 450160.398036 +\n              (-482890.5431 +\n              (      7.4722 +\n              (      0.007702 +\n              (     -0.00005939)\n              * t) * t) * t) * t) * ASEC2RAD\n              + (-5.0*t % 1.0) * tau)\n\n    fa[ 5] = (4.402608842 + 2608.7903141574 * t)\n    fa[ 6] = (3.176146697 + 1021.3285546211 * t)\n    fa[ 7] = (1.753470314 +  628.3075849991 * t)\n    fa[ 8] = (6.203480913 +  334.0612426700 * t)\n    fa[ 9] = (0.599546497 +   52.9690962641 * t)\n    fa[10] = (0.874016757 +   21.3299104960 * t)\n    fa[11] = (5.481293872 +    7.4781598567 * t)\n    fa[12] = (5.311886287 +    3.8133035638 * t)\n    fa[13] = (0.024381750 +    0.00000538691 * t) * t\n\n    fa %= tau\n\n    # Evaluate the complementary terms.\n\n    a = ke0_t.dot(fa)\n    s0 = se0_t_0.dot(sin(a)) + se0_t_1.dot(cos(a))\n\n    a = ke1.dot(fa)\n    s1 = se1_0 * sin(a) + se1_1 * cos(a)\n\n    c_terms = s0 + s1 * t\n    c_terms *= ASEC2RAD\n    return c_terms"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the Earth nutation based on the IAU 2000A nutation model.", "response": "def iau2000a(jd_tt):\n    \"\"\"Compute Earth nutation based on the IAU 2000A nutation model.\n\n    `jd_tt` - Terrestrial Time: Julian date float, or NumPy array of floats\n\n    Returns a tuple ``(delta_psi, delta_epsilon)`` measured in tenths of\n    a micro-arcsecond.  Each value is either a float, or a NumPy array\n    with the same dimensions as the input argument.\n\n    \"\"\"\n    # Interval between fundamental epoch J2000.0 and given date.\n\n    t = (jd_tt - T0) / 36525.0\n\n    # Compute fundamental arguments from Simon et al. (1994), in radians.\n\n    a = fundamental_arguments(t)\n\n    # ** Luni-solar nutation **\n    # Summation of luni-solar nutation series (in reverse order).\n\n    arg = nals_t.dot(a)\n    fmod(arg, tau, out=arg)\n\n    sarg = sin(arg)\n    carg = cos(arg)\n\n    stsc = array((sarg, t * sarg, carg)).T\n    ctcs = array((carg, t * carg, sarg)).T\n\n    dpsi = tensordot(stsc, lunisolar_longitude_coefficients)\n    deps = tensordot(ctcs, lunisolar_obliquity_coefficients)\n\n    # Compute and add in planetary components.\n\n    if getattr(t, 'shape', ()) == ():\n        a = t * anomaly_coefficient + anomaly_constant\n    else:\n        a = (outer(anomaly_coefficient, t).T + anomaly_constant).T\n    a[-1] *= t\n\n    fmod(a, tau, out=a)\n    arg = napl_t.dot(a)\n    fmod(arg, tau, out=arg)\n    sc = array((sin(arg), cos(arg))).T\n\n    dpsi += tensordot(sc, nutation_coefficients_longitude)\n    deps += tensordot(sc, nutation_coefficients_obliquity)\n\n    return dpsi, deps"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the Earth nutation based on the faster IAU 2000B nutation model.", "response": "def iau2000b(jd_tt):\n    \"\"\"Compute Earth nutation based on the faster IAU 2000B nutation model.\n\n    `jd_tt` - Terrestrial Time: Julian date float, or NumPy array of floats\n\n    Returns a tuple ``(delta_psi, delta_epsilon)`` measured in tenths of\n    a micro-arcsecond.  Each is either a float, or a NumPy array with\n    the same dimensions as the input argument.  The result will not take\n    as long to compute as the full IAU 2000A series, but should still\n    agree with ``iau2000a()`` to within a milliarcsecond between the\n    years 1995 and 2020.\n\n    \"\"\"\n    dpplan = -0.000135 * 1e7\n    deplan =  0.000388 * 1e7\n\n    t = (jd_tt - T0) / 36525.0\n\n    # TODO: can these be replaced with fa0 and f1?\n\n    el  = fmod (485868.249036 +\n          t * 1717915923.2178, ASEC360) * ASEC2RAD;\n\n    elp = fmod (1287104.79305 +\n             t * 129596581.0481, ASEC360) * ASEC2RAD;\n\n    f   = fmod (335779.526232 +\n             t * 1739527262.8478, ASEC360) * ASEC2RAD;\n\n    d   = fmod (1072260.70369 +\n             t * 1602961601.2090, ASEC360) * ASEC2RAD;\n\n    om  = fmod (450160.398036 -\n             t * 6962890.5431, ASEC360) * ASEC2RAD;\n\n    a = array((el, elp, f, d, om))\n\n    arg = nals_t[:77].dot(a)\n    fmod(arg, tau, out=arg)\n\n    sarg = sin(arg)\n    carg = cos(arg)\n\n    stsc = array((sarg, t * sarg, carg)).T\n    ctcs = array((carg, t * carg, sarg)).T\n\n    dp = tensordot(stsc, lunisolar_longitude_coefficients[:77,])\n    de = tensordot(ctcs, lunisolar_obliquity_coefficients[:77,])\n\n    dpsi = dpplan + dp\n    deps = deplan + de\n\n    return dpsi, deps"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fundamental_arguments(t):\n\n    \"\"\"Compute the fundamental arguments (mean elements) of Sun and Moon.\n\n    `t` - TDB time in Julian centuries since J2000.0, as float or NumPy array\n\n    Outputs fundamental arguments, in radians:\n          a[0] = l (mean anomaly of the Moon)\n          a[1] = l' (mean anomaly of the Sun)\n          a[2] = F (mean argument of the latitude of the Moon)\n          a[3] = D (mean elongation of the Moon from the Sun)\n          a[4] = Omega (mean longitude of the Moon's ascending node);\n                 from Simon section 3.4(b.3),\n                 precession = 5028.8200 arcsec/cy)\n\n    \"\"\"\n    a = fa4 * t\n    a += fa3\n    a *= t\n    a += fa2\n    a *= t\n    a += fa1\n    a *= t\n    a += fa0\n    fmod(a, ASEC360, out=a)\n    a *= ASEC2RAD\n    if getattr(t, 'shape', ()):\n        return a\n    return a[:,0]", "response": "Compute the fundamental arguments of the Sun and Moon."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndeprecate ; see ~skyfield. data. hipparcos. load_dataframe() instead.", "response": "def parse(line):\n    \"DEPRECATED; see :func:`~skyfield.data.hipparcos.load_dataframe() instead.\"\n    # See ftp://cdsarc.u-strasbg.fr/cats/I/239/ReadMe\n    star = Star(\n        ra=Angle(degrees=float(line[51:63])),\n        dec=Angle(degrees=float(line[64:76])),\n        ra_mas_per_year=float(line[87:95]),\n        dec_mas_per_year=float(line[96:104]),\n        parallax_mas=float(line[79:86]),\n        names=[('HIP', int(line[8:14]))],\n        )\n    star._position_au += star._velocity_au_per_d * days\n    distance, dec, ra = to_polar(star._position_au)\n    star.ra = Angle(radians=ra, preference='hours')\n    star.dec = Angle(radians=dec)\n    return star"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(match_function):\n    \"DEPRECATED; see :func:`~skyfield.data.hipparcos.load_dataframe() instead.\"\n    from skyfield import api\n\n    with api.load.open(url) as f:\n        for line in gzip.GzipFile(fileobj=f):\n            if match_function(line):\n                yield parse(line)", "response": "DEPRECATED ; see ~skyfield. data. hipparcos. load_dataframe() instead."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive an open file for hip_main. dat. gz return a parsed dataframe.", "response": "def load_dataframe(fobj, compression='gzip'):\n    \"\"\"Given an open file for `hip_main.dat.gz`, return a parsed dataframe.\n\n    If your copy of ``hip_main.dat`` has already been unzipped, pass the\n    optional argument ``compression=None``.\n\n    \"\"\"\n    try:\n        from pandas import read_fwf\n    except ImportError:\n        raise ImportError(PANDAS_MESSAGE)\n\n    names, colspecs = zip(\n        ('hip', (2, 14)),\n        ('magnitude', (41, 46)),\n        ('ra_degrees', (51, 63)),\n        ('dec_degrees', (64, 76)),\n        ('parallax_mas', (79, 86)),  # TODO: have Star load this\n        ('ra_mas_per_year', (87, 95)),\n        ('dec_mas_per_year', (96, 104)),\n    )\n\n    df = read_fwf(fobj, colspecs, names=names, compression=compression)\n    df = df.assign(\n        ra_hours = df['ra_degrees'] / 15.0,\n        epoch_year = 1991.25,\n    )\n    return df.set_index('hip')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(which):\n    \"DEPRECATED; see :func:`~skyfield.data.hipparcos.load_dataframe() instead.\"\n    if isinstance(which, str):\n        pattern = ('H|      %6s' % which).encode('ascii')\n        for star in load(lambda line: line.startswith(pattern)):\n            return star\n    else:\n        patterns = set(id.encode('ascii').rjust(6) for id in which)\n        return list(load(lambda line: line[8:14] in patterns))", "response": "DEPRECATED ; see ~skyfield. data. hipparcos. load_dataframe() instead."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _altaz_rotation(self, t):\n        R_lon = rot_z(- self.longitude.radians - t.gast * tau / 24.0)\n        return einsum('ij...,jk...,kl...->il...', self.R_lat, R_lon, t.M)", "response": "Compute the rotation from the ICRF into the alt - az system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _at(self, t):\n        pos, vel = terra(self.latitude.radians, self.longitude.radians,\n                         self.elevation.au, t.gast)\n        pos = einsum('ij...,j...->i...', t.MT, pos)\n        vel = einsum('ij...,j...->i...', t.MT, vel)\n        if self.x:\n            R = rot_y(self.x * ASEC2RAD)\n            pos = einsum('ij...,j...->i...', R, pos)\n        if self.y:\n            R = rot_x(self.y * ASEC2RAD)\n            pos = einsum('ij...,j...->i...', R, pos)\n        # TODO: also rotate velocity\n\n        return pos, vel, pos, None", "response": "Compute the GCRS position and velocity of this Topos object at time t."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproduce the osculating orbital elements for a position.", "response": "def osculating_elements_of(position, reference_frame=None):\n    \"\"\"Produce the osculating orbital elements for a position.\n\n    The ``position`` should be an :class:`~skyfield.positionlib.ICRF`\n    instance like that returned by the ``at()`` method of any Solar\n    System body, specifying a position, a velocity, and a time.  An\n    instance of :class:`~skyfield.elementslib.OsculatingElements` is\n    returned.\n\n    \"\"\"\n    mu = GM_dict.get(position.center, 0) + GM_dict.get(position.target, 0)\n    \n    if reference_frame is not None:\n        position_vec = Distance(reference_frame.dot(position.position.au))\n        velocity_vec = Velocity(reference_frame.dot(position.velocity.au_per_d))\n    else:\n        position_vec = position.position\n        velocity_vec = position.velocity\n        \n    return OsculatingElements(position_vec,\n                              velocity_vec,\n                              position.t,\n                              mu)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef theta_GMST1982(jd_ut1):\n    t = (jd_ut1 - T0) / 36525.0\n    g = 67310.54841 + (8640184.812866 + (0.093104 + (-6.2e-6) * t) * t) * t\n    dg = 8640184.812866 + (0.093104 * 2.0 + (-6.2e-6 * 3.0) * t) * t\n    theta = (jd_ut1 % 1.0 + g * _second % 1.0) * tau\n    theta_dot = (1.0 + dg * _second / 36525.0) * tau\n    return theta, theta_dot", "response": "Return the angle of Greenwich Mean Standard Time 1982 given the JD."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts TEME position and velocity into standard ITRS coordinates.", "response": "def TEME_to_ITRF(jd_ut1, rTEME, vTEME, xp=0.0, yp=0.0):\n    \"\"\"Convert TEME position and velocity into standard ITRS coordinates.\n\n    This converts a position and velocity vector in the idiosyncratic\n    True Equator Mean Equinox (TEME) frame of reference used by the SGP4\n    theory into vectors into the more standard ITRS frame of reference.\n    The velocity should be provided in units per day, not per second.\n\n    From AIAA 2006-6753 Appendix C.\n\n    \"\"\"\n    theta, theta_dot = theta_GMST1982(jd_ut1)\n    zero = theta_dot * 0.0\n    angular_velocity = array([zero, zero, -theta_dot])\n    R = rot_z(-theta)\n\n    if len(rTEME.shape) == 1:\n        rPEF = (R).dot(rTEME)\n        vPEF = (R).dot(vTEME) + cross(angular_velocity, rPEF)\n    else:\n        rPEF = einsum('ij...,j...->i...', R, rTEME)\n        vPEF = einsum('ij...,j...->i...', R, vTEME) + cross(\n            angular_velocity, rPEF, 0, 0).T\n\n    if xp == 0.0 and yp == 0.0:\n        rITRF = rPEF\n        vITRF = vPEF\n    else:\n        W = (rot_x(yp)).dot(rot_y(xp))\n        rITRF = (W).dot(rPEF)\n        vITRF = (W).dot(vPEF)\n    return rITRF, vITRF"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the raw true equator mean equinox vectors from SGP4.", "response": "def _position_and_velocity_TEME_km(self, t):\n        \"\"\"Return the raw true equator mean equinox (TEME) vectors from SGP4.\n\n        Returns a tuple of NumPy arrays ``([x y z], [xdot ydot zdot])``\n        expressed in kilometers and kilometers per second.  Note that we\n        assume the TLE epoch to be a UTC date, per AIAA 2006-6753.\n\n        \"\"\"\n        sat = self.model\n        minutes_past_epoch = (t._utc_float() - sat.jdsatepoch) * 1440.0\n        if getattr(minutes_past_epoch, 'shape', None):\n            position = []\n            velocity = []\n            error = []\n            for m in minutes_past_epoch:\n                p, v = sgp4(sat, m)\n                position.append(p)\n                velocity.append(v)\n                error.append(sat.error_message)\n            return array(position).T, array(velocity).T, error\n        else:\n            position, velocity = sgp4(sat, minutes_past_epoch)\n            return array(position), array(velocity), sat.error_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ITRF_position_velocity_error(self, t):\n        rTEME, vTEME, error = self._position_and_velocity_TEME_km(t)\n        rTEME /= AU_KM\n        vTEME /= AU_KM\n        vTEME *= DAY_S\n        rITRF, vITRF = TEME_to_ITRF(t.ut1, rTEME, vTEME)\n        return rITRF, vITRF, error", "response": "Return the position velocity and error at time t."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _at(self, t):\n        rITRF, vITRF, error = self.ITRF_position_velocity_error(t)\n        rGCRS, vGCRS = ITRF_to_GCRS2(t, rITRF, vITRF)\n        return rGCRS, vGCRS, rGCRS, error", "response": "Compute this satellite s GCRS position and velocity at time t."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntables of smoothed Delta T values from Morrison and Stephenson 2004.", "response": "def morrison_and_stephenson_2004_table():\n    \"\"\"Table of smoothed Delta T values from Morrison and Stephenson, 2004.\"\"\"\n    import pandas as pd\n    f = load.open('http://eclipse.gsfc.nasa.gov/SEcat5/deltat.html')\n    tables = pd.read_html(f.read())\n    df = tables[0]\n    return pd.DataFrame({'year': df[0], 'delta_t': df[1]})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive 2 vectors in v and u return the angle separating them.", "response": "def angle_between(u_vec, v_vec):\n    \"\"\"Given 2 vectors in `v` and `u`, return the angle separating them.\n\n    This works whether `v` and `u` each have the shape ``(3,)``, or\n    whether they are each whole arrays of corresponding x, y, and z\n    coordinates and have shape ``(3, N)``. The returned angle will be\n    between 0 and 180 degrees.\n\n    This formula is from Section 12 of:\n    https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf\n\n    \"\"\"\n    u = length_of(u_vec)\n    v = length_of(v_vec)\n    num = v*u_vec - u*v_vec\n    denom = v*u_vec + u*v_vec\n    return 2*arctan2(length_of(num), length_of(denom))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting xyz into spherical coordinates r theta phi.", "response": "def to_polar(xyz):\n    \"\"\"Convert ``[x y z]`` into spherical coordinates ``(r, theta, phi)``.\n\n    ``r`` - vector length\n    ``theta`` - angle above (+) or below (-) the xy-plane\n    ``phi`` - angle around the z-axis\n\n    The meaning and order of the three return values is designed to\n    match both ISO 31-11 and the traditional order used by physicists.\n    Mathematicians usually define ``theta`` and ``phi`` the other way\n    around, and may need to use caution when using the return values.\n    See: https://en.wikipedia.org/wiki/Spherical_coordinate_system\n\n    \"\"\"\n    r = length_of(xyz)\n    x, y, z = xyz\n    theta = arcsin(z / r)\n    phi = arctan2(y, x) % tau\n    return r, theta, phi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting polar coordinates r theta phi to Cartesian coordinates x y z.", "response": "def from_polar(r, theta, phi):\n    \"\"\"Convert ``(r, theta, phi)`` to Cartesian coordinates ``[x y z]``.\n\n    ``r`` - vector length\n    ``theta`` - angle above (+) or below (-) the xy-plane\n    ``phi`` - angle around the z-axis\n\n    The meaning and order of the three polar parameters is designed to\n    match both ISO 31-11 and the traditional order used by physicists.\n    Mathematicians usually define ``theta`` and ``phi`` the other way\n    around, and may need to use caution when calling this function.\n    See: https://en.wikipedia.org/wiki/Spherical_coordinate_system\n\n    \"\"\"\n    rxy = r * cos(theta)\n    return array((rxy * cos(phi), rxy * sin(phi), r * sin(theta)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the position and velocity vectors for the ICRF star.", "response": "def _compute_vectors(self):\n        \"\"\"Compute the star's position as an ICRF position and velocity.\"\"\"\n\n        # Use 1 gigaparsec for stars whose parallax is zero.\n\n        parallax = self.parallax_mas\n        if parallax <= 0.0:\n            parallax = 1.0e-6\n\n        # Convert right ascension, declination, and parallax to position\n        # vector in equatorial system with units of au.\n\n        dist = 1.0 / sin(parallax * 1.0e-3 * ASEC2RAD)\n        r = self.ra.radians\n        d = self.dec.radians\n        cra = cos(r)\n        sra = sin(r)\n        cdc = cos(d)\n        sdc = sin(d)\n\n        self._position_au = array((\n            dist * cdc * cra,\n            dist * cdc * sra,\n            dist * sdc,\n            ))\n\n        # Compute Doppler factor, which accounts for change in light\n        # travel time to star.\n\n        k = 1.0 / (1.0 - self.radial_km_per_s / C * 1000.0)\n\n        # Convert proper motion and radial velocity to orthogonal\n        # components of motion with units of au/day.\n\n        pmr = self.ra_mas_per_year / (parallax * 365.25) * k\n        pmd = self.dec_mas_per_year / (parallax * 365.25) * k\n        rvl = self.radial_km_per_s * DAY_S / self.au_km * k\n\n        # Transform motion vector to equatorial system.\n\n        self._velocity_au_per_d = array((\n            - pmr * sra - pmd * sdc * cra + rvl * cdc * cra,\n              pmr * cra - pmd * sdc * sra + rvl * cdc * sra,\n              pmd * cdc + rvl * sdc,\n              ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _to_array(value):\n    if isinstance(value, (tuple, list)):\n        return array(value)\n    elif isinstance(value, (float, int)):\n        return np.float64(value)\n    else:\n        return value", "response": "As a convenience turn Python lists and tuples into NumPy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecompose a floating point value into units minutes and seconds.", "response": "def _sexagesimalize_to_float(value):\n    \"\"\"Decompose `value` into units, minutes, and seconds.\n\n    Note that this routine is not appropriate for displaying a value,\n    because rounding to the smallest digit of display is necessary\n    before showing a value to the user.  Use `_sexagesimalize_to_int()`\n    for data being displayed to the user.\n\n    This routine simply decomposes the floating point `value` into a\n    sign (+1.0 or -1.0), units, minutes, and seconds, returning the\n    result in a four-element tuple.\n\n    >>> _sexagesimalize_to_float(12.05125)\n    (1.0, 12.0, 3.0, 4.5)\n    >>> _sexagesimalize_to_float(-12.05125)\n    (-1.0, 12.0, 3.0, 4.5)\n\n    \"\"\"\n    sign = np.sign(value)\n    n = abs(value)\n    minutes, seconds = divmod(n * 3600.0, 60.0)\n    units, minutes = divmod(minutes, 60.0)\n    return sign, units, minutes, seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecomposes value into units minutes seconds and second fractions.", "response": "def _sexagesimalize_to_int(value, places=0):\n    \"\"\"Decompose `value` into units, minutes, seconds, and second fractions.\n\n    This routine prepares a value for sexagesimal display, with its\n    seconds fraction expressed as an integer with `places` digits.  The\n    result is a tuple of five integers:\n\n    ``(sign [either +1 or -1], units, minutes, seconds, second_fractions)``\n\n    The integers are properly rounded per astronomical convention so\n    that, for example, given ``places=3`` the result tuple ``(1, 11, 22,\n    33, 444)`` means that the input was closer to 11u 22' 33.444\" than\n    to either 33.443\" or 33.445\" in its value.\n\n    \"\"\"\n    sign = int(np.sign(value))\n    value = abs(value)\n    power = 10 ** places\n    n = int(7200 * power * value + 1) // 2\n    n, fraction = divmod(n, power)\n    n, seconds = divmod(n, 60)\n    n, minutes = divmod(n, 60)\n    return sign, n, minutes, seconds, fraction"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _hstr(hours, places=2):\n    if isnan(hours):\n        return 'nan'\n    sgn, h, m, s, etc = _sexagesimalize_to_int(hours, places)\n    sign = '-' if sgn < 0.0 else ''\n    return '%s%02dh %02dm %02d.%0*ds' % (sign, h, m, s, places, etc)", "response": "Convert floating point hours into sexagesimal string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning value after interpreting a tuple.", "response": "def _unsexagesimalize(value):\n    \"\"\"Return `value` after interpreting a (units, minutes, seconds) tuple.\n\n    When `value` is not a tuple, it is simply returned.\n\n    >>> _unsexagesimalize(3.25)\n    3.25\n\n    An input tuple is interpreted as units, minutes, and seconds.  Note\n    that only the sign of `units` is significant!  So all of the\n    following tuples convert into exactly the same value:\n\n    >>> '%f' % _unsexagesimalize((-1, 2, 3))\n    '-1.034167'\n    >>> '%f' % _unsexagesimalize((-1, -2, 3))\n    '-1.034167'\n    >>> '%f' % _unsexagesimalize((-1, -2, -3))\n    '-1.034167'\n\n    \"\"\"\n    if isinstance(value, tuple):\n        for i, component in enumerate(value):\n            if i:\n                value = value + copysign(component, value) * 60.0 ** -i\n            else:\n                value = component\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninterpreting an angle in radians from one of two arguments.", "response": "def _interpret_angle(name, angle_object, angle_float, unit='degrees'):\n    \"\"\"Return an angle in radians from one of two arguments.\n\n    It is common for Skyfield routines to accept both an argument like\n    `alt` that takes an Angle object as well as an `alt_degrees` that\n    can be given a bare float or a sexagesimal tuple.  A pair of such\n    arguments can be passed to this routine for interpretation.\n\n    \"\"\"\n    if angle_object is not None:\n        if isinstance(angle_object, Angle):\n            return angle_object.radians\n    elif angle_float is not None:\n        return _unsexagesimalize(angle_float) * _from_degrees\n    raise ValueError('you must either provide the {0}= parameter with'\n                     ' an Angle argument or supply the {0}_{1}= parameter'\n                     ' with a numeric argument'.format(name, unit))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninterprets a string float or tuple as a latitude or longitude angle.", "response": "def _interpret_ltude(value, name, psuffix, nsuffix):\n    \"\"\"Interpret a string, float, or tuple as a latitude or longitude angle.\n\n    `value` - The string to interpret.\n    `name` - 'latitude' or 'longitude', for use in exception messages.\n    `positive` - The string that indicates a positive angle ('N' or 'E').\n    `negative` - The string that indicates a negative angle ('S' or 'W').\n\n    \"\"\"\n    if not isinstance(value, str):\n        return Angle(degrees=_unsexagesimalize(value))\n\n    value = value.strip().upper()\n\n    if value.endswith(psuffix):\n        sign = +1.0\n    elif value.endswith(nsuffix):\n        sign = -1.0\n    else:\n        raise ValueError('your {0} string {1!r} does not end with either {2!r}'\n                         ' or {3!r}'.format(name, value, psuffix, nsuffix))\n\n    try:\n        value = float(value[:-1])\n    except ValueError:\n        raise ValueError('your {0} string {1!r} cannot be parsed as a floating'\n                         ' point number'.format(name, value))\n\n    return Angle(degrees=sign * value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to(self, unit):\n        from astropy.units import au\n        return (self.au * au).to(unit)", "response": "Convert this distance to the given AstroPy unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to(self, unit):\n        from astropy.units import au, d\n        return (self.au_per_d * au / d).to(unit)", "response": "Convert this velocity to the given AstroPy unit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hms(self, warn=True):\n        if warn and self.preference != 'hours':\n            raise WrongUnitError('hms')\n        sign, units, minutes, seconds = _sexagesimalize_to_float(self._hours)\n        return sign * units, sign * minutes, sign * seconds", "response": "Convert to a tuple of hours minutes and seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signed_hms(self, warn=True):\n        if warn and self.preference != 'hours':\n            raise WrongUnitError('signed_hms')\n        return _sexagesimalize_to_float(self._hours)", "response": "Convert to a tuple of signed hours minutes seconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts to a string like 12h 07m 30. 00s.", "response": "def hstr(self, places=2, warn=True):\n        \"\"\"Convert to a string like ``12h 07m 30.00s``.\"\"\"\n        if warn and self.preference != 'hours':\n            raise WrongUnitError('hstr')\n        if self.radians.size == 0:\n            return '<Angle []>'\n        hours = self._hours\n        shape = getattr(hours, 'shape', ())\n        if shape and shape != (1,):\n            return \"{0} values from {1} to {2}\".format(\n                len(hours),\n                _hstr(min(hours), places),\n                _hstr(max(hours), places),\n                )\n        return _hstr(hours, places)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert to a tuple ( degrees minutes seconds.", "response": "def dms(self, warn=True):\n        \"\"\"Convert to a tuple (degrees, minutes, seconds).\n\n        All three quantities will have the same sign as the angle itself.\n\n        \"\"\"\n        if warn and self.preference != 'degrees':\n            raise WrongUnitError('dms')\n        sign, units, minutes, seconds = _sexagesimalize_to_float(self._degrees)\n        return sign * units, sign * minutes, sign * seconds"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef signed_dms(self, warn=True):\n        if warn and self.preference != 'degrees':\n            raise WrongUnitError('signed_dms')\n        return _sexagesimalize_to_float(self._degrees)", "response": "Convert to a tuple of degrees hours minutes seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting to a string like 181deg 52. 0. 0", "response": "def dstr(self, places=1, warn=True):\n        \"\"\"Convert to a string like ``181deg 52\\' 30.0\"``.\"\"\"\n        if warn and self.preference != 'degrees':\n            raise WrongUnitError('dstr')\n        if self.radians.size == 0:\n            return '<Angle []>'\n        degrees = self._degrees\n        signed = self.signed\n        shape = getattr(degrees, 'shape', ())\n        if shape and shape != (1,):\n            return \"{0} values from {1} to {2}\".format(\n                len(degrees),\n                _dstr(min(degrees), places, signed),\n                _dstr(max(degrees), places, signed),\n                )\n        return _dstr(degrees, places, signed)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert this angle to the given AstroPy unit.", "response": "def to(self, unit):\n        \"\"\"Convert this angle to the given AstroPy unit.\"\"\"\n        from astropy.units import rad\n        return (self.radians * rad).to(unit)\n\n        # Or should this do:\n        from astropy.coordinates import Angle\n        from astropy.units import rad\n        return Angle(self.radians, rad).to(unit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the alt and az positions relative to the observer s horizon.", "response": "def _to_altaz(position_au, observer_data, temperature_C, pressure_mbar):\n    \"\"\"Compute (alt, az, distance) relative to the observer's horizon.\n\n    \"\"\"\n    elevation_m = observer_data.elevation_m\n    R = observer_data.altaz_rotation\n\n    if (elevation_m is None) or (R is None):\n        raise ValueError('to compute an altazimuth position, you must'\n                         ' observe from a specific Earth location that'\n                         ' you specify using a Topos instance')\n\n    # TODO: wobble\n\n    position_au = einsum('ij...,j...->i...', R, position_au)\n    r_au, alt, az = to_polar(position_au)\n\n    if temperature_C is None:\n        alt = Angle(radians=alt)\n    else:\n        if temperature_C == 'standard':\n            temperature_C = 10.0\n        if pressure_mbar == 'standard':\n            pressure_mbar = 1010.0 * exp(-elevation_m / 9.1e3)\n        alt = refract(alt * RAD2DEG, temperature_C, pressure_mbar)\n        alt = Angle(degrees=alt)\n\n    return alt, Angle(radians=az), Distance(r_au)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef radec(self, epoch=None):\n        position_au = self.position.au\n        if epoch is not None:\n            if isinstance(epoch, Time):\n                pass\n            elif isinstance(epoch, float):\n                epoch = Time(None, tt=epoch)\n            elif epoch == 'date':\n                epoch = self.t\n            else:\n                raise ValueError('the epoch= must be a Time object,'\n                                 ' a floating point Terrestrial Time (TT),'\n                                 ' or the string \"date\" for epoch-of-date')\n            position_au = einsum('ij...,j...->i...', epoch.M, position_au)\n        r_au, dec, ra = to_polar(position_au)\n        return (Angle(radians=ra, preference='hours'),\n                Angle(radians=dec, signed=True),\n                Distance(r_au))", "response": "r Compute the right ascension and declination of the dynamical object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef separation_from(self, another_icrf):\n        p1 = self.position.au\n        p2 = another_icrf.position.au\n        u1 = p1 / length_of(p1)\n        u2 = p2 / length_of(p2)\n        if u2.ndim > 1:\n            if u1.ndim == 1:\n                u1 = u1[:,None]\n        elif u1.ndim > 1:\n            u2 = u2[:,None]\n        c = dots(u1, u2)\n        return Angle(radians=arccos(clip(c, -1.0, 1.0)))", "response": "Return the angle between this position and another."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute cartesian CIRS coordinates at a given epoch.", "response": "def cirs_xyz(self, epoch):\n        \"\"\"Compute cartesian CIRS coordinates at a given epoch (x, y, z).\n\n        Calculate coordinates in the Celestial Intermediate Reference System\n        (CIRS), a dynamical coordinate system referenced to the Celestial\n        Intermediate Origin (CIO). As this is a dynamical system it must be\n        calculated at a specific epoch.\n        \"\"\"\n        if isinstance(epoch, Time):\n            pass\n        elif isinstance(epoch, float):\n            epoch = Time(None, tt=epoch)\n        elif epoch == 'date':\n            epoch = self.t\n        else:\n            raise ValueError('the epoch= must be a Time object,'\n                             ' a floating point Terrestrial Time (TT),'\n                             ' or the string \"date\" for epoch-of-date')\n\n        vector = einsum('ij...,j...->i...', epoch.C, self.position.au)\n        return Distance(vector)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget spherical CIRS coordinates at a given epoch.", "response": "def cirs_radec(self, epoch):\n        \"\"\"Get spherical CIRS coordinates at a given epoch (ra, dec, distance).\n\n        Calculate coordinates in the Celestial Intermediate Reference System\n        (CIRS), a dynamical coordinate system referenced to the Celestial\n        Intermediate Origin (CIO). As this is a dynamical system it must be\n        calculated at a specific epoch.\n        \"\"\"\n        r_au, dec, ra = to_polar(self.cirs_xyz(epoch).au)\n\n        return (Angle(radians=ra, preference='hours'),\n                Angle(radians=dec, signed=True),\n                Distance(r_au))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ecliptic_xyz(self, epoch=None):\n        if epoch is None:\n            vector = _ECLIPJ2000.dot(self.position.au)\n            return Distance(vector)\n\n        position_au = self.position.au\n\n        if isinstance(epoch, Time):\n            pass\n        elif isinstance(epoch, float):\n            epoch = Time(None, tt=epoch)\n        elif epoch == 'date':\n            epoch = self.t\n        else:\n            raise ValueError('the epoch= must be a Time object,'\n                             ' a floating point Terrestrial Time (TT),'\n                             ' or the string \"date\" for epoch-of-date')\n\n        oblm, oblt, eqeq, psi, eps = epoch._earth_tilt\n        e = oblt * DEG2RAD\n        rotation = einsum('ij...,jk...->ik...', rot_x(-e), epoch.M)\n        position_au = einsum('ij...,j...->i...', rotation, position_au)\n        return Distance(position_au)", "response": "Compute the J2000 ecliptic position vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing J2000 ecliptic velocity vector", "response": "def ecliptic_velocity(self):\n        \"\"\"Compute J2000 ecliptic velocity vector (x_dot, y_dot, z_dot)\"\"\"\n        vector = _ECLIPJ2000.dot(self.velocity.au_per_d)\n        return Velocity(vector)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ecliptic_latlon(self, epoch=None):\n        vector = self.ecliptic_xyz(epoch)\n        d, lat, lon = to_polar(vector.au)\n        return (Angle(radians=lat, signed=True),\n                Angle(radians=lon),\n                Distance(au=d))", "response": "Compute J2000 ecliptic coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the galactic coordinates ( x y z", "response": "def galactic_xyz(self):\n        \"\"\"Compute galactic coordinates (x, y, z)\"\"\"\n        vector = _GALACTIC.dot(self.position.au)\n        return Distance(vector)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the galactic coordinates ( lat lon distance", "response": "def galactic_latlon(self):\n        \"\"\"Compute galactic coordinates (lat, lon, distance)\"\"\"\n        vector = _GALACTIC.dot(self.position.au)\n        d, lat, lon = to_polar(vector)\n        return (Angle(radians=lat, signed=True),\n                Angle(radians=lon),\n                Distance(au=d))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert this distance to an AstroPy SkyCoord object.", "response": "def to_skycoord(self, unit=None):\n        \"\"\"Convert this distance to an AstroPy ``SkyCoord`` object.\"\"\"\n        from astropy.coordinates import SkyCoord\n        from astropy.units import au\n        x, y, z = self.position.au\n        return SkyCoord(representation='cartesian', x=x, y=y, z=z, unit=au)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_altaz(self, alt=None, az=None, alt_degrees=None, az_degrees=None,\n                   distance=Distance(au=0.1)):\n        \"\"\"Generate an Apparent position from an altitude and azimuth.\n\n        The altitude and azimuth can each be provided as an `Angle`\n        object, or else as a number of degrees provided as either a\n        float or a tuple of degrees, arcminutes, and arcseconds::\n\n            alt=Angle(...), az=Angle(...)\n            alt_degrees=23.2289, az_degrees=142.1161\n            alt_degrees=(23, 13, 44.1), az_degrees=(142, 6, 58.1)\n\n        The distance should be a :class:`~skyfield.units.Distance`\n        object, if provided; otherwise a default of 0.1 au is used.\n\n        \"\"\"\n        # TODO: should this method live on another class?\n        R = self.observer_data.altaz_rotation if self.observer_data else None\n        if R is None:\n            raise ValueError('only a position generated by a topos() call'\n                             ' knows the orientation of the horizon'\n                             ' and can understand altitude and azimuth')\n        alt = _interpret_angle('alt', alt, alt_degrees)\n        az = _interpret_angle('az', az, az_degrees)\n        r = distance.au\n        p = from_polar(r, alt, az)\n        p = einsum('ji...,j...->i...', R, p)\n        return Apparent(p)", "response": "Generate an Apparent position from an altitude and azimuth."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the altitude and azimuth of the object in degrees.", "response": "def altaz(self, temperature_C=None, pressure_mbar='standard'):\n        \"\"\"Compute (alt, az, distance) relative to the observer's horizon\n\n        The altitude returned is an `Angle` in degrees above the\n        horizon, while the azimuth is the compass direction in degrees\n        with north being 0 degrees and east being 90 degrees.\n\n        \"\"\"\n        return _to_altaz(self.position.au, self.observer_data,\n                         temperature_C, pressure_mbar)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the astrometric position of a body from this location.", "response": "def observe(self, body):\n        \"\"\"Compute the `Astrometric` position of a body from this location.\n\n        To compute the body's astrometric position, it is first asked\n        for its position at the time `t` of this position itself.  The\n        distance to the body is then divided by the speed of light to\n        find how long it takes its light to arrive.  Finally, the light\n        travel time is subtracted from `t` and the body is asked for a\n        series of increasingly exact positions to learn where it was\n        when it emitted the light that is now reaching this position.\n\n        >>> earth.at(t).observe(mars)\n        <Astrometric position and velocity at date t>\n\n        \"\"\"\n        p, v, t, light_time = body._observe_from_bcrs(self)\n        astrometric = Astrometric(p, v, t, observer_data=self.observer_data)\n        astrometric.light_time = light_time\n        return astrometric"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes an Apparent position for this body.", "response": "def apparent(self):\n        \"\"\"Compute an :class:`Apparent` position for this body.\n\n        This applies two effects to the position that arise from\n        relativity and shift slightly where the other body will appear\n        in the sky: the deflection that the image will experience if its\n        light passes close to large masses in the Solar System, and the\n        aberration of light caused by the observer's own velocity.\n\n        >>> earth.at(t).observe(mars).apparent()\n        <Apparent position and velocity at date t>\n\n        These transforms convert the position from the BCRS reference\n        frame of the Solar System barycenter and to the reference frame\n        of the observer.  In the specific case of an Earth observer, the\n        output reference frame is the GCRS.\n\n        \"\"\"\n        t = self.t\n        position_au = self.position.au.copy()\n        observer_data = self.observer_data\n        gcrs_position = observer_data.gcrs_position\n\n        if gcrs_position is None:\n            include_earth_deflection = array((False,))\n        else:\n            limb_angle, nadir_angle = compute_limb_angle(\n                position_au, gcrs_position)\n            include_earth_deflection = nadir_angle >= 0.8\n\n        add_deflection(position_au, observer_data.bcrs_position,\n                       observer_data.ephemeris, t, include_earth_deflection)\n\n        add_aberration(position_au, observer_data.bcrs_velocity,\n                       self.light_time)\n\n        return Apparent(position_au, t=t, observer_data=observer_data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subpoint(self):\n        if self.center != 399:  # TODO: should an __init__() check this?\n            raise ValueError(\"you can only ask for the geographic subpoint\"\n                             \" of a position measured from Earth's center\")\n        t = self.t\n        xyz_au = einsum('ij...,j...->i...', t.M, self.position.au)\n        lat, lon, elevation_m = reverse_terra(xyz_au, t.gast)\n\n        # TODO. Move VectorFunction and Topos into this file, since the\n        # three kinds of class work together: Topos is-a VF; VF.at() can\n        # return a Geocentric position; and Geocentric.subpoint() should\n        # return a Topos. I'm deferring the refactoring for now, to get\n        # this new feature to users more quickly.\n        from .toposlib import Topos\n        return Topos(latitude=Angle(radians=lat),\n                     longitude=Angle(radians=lon),\n                     elevation_m=elevation_m)", "response": "Return the latitude and longitude of the subpoint of this position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots stars in a catalog plot.", "response": "def _plot_stars(catalog, observer, project, ax, mag1, mag2, margin=1.25):\n    \"\"\"Experiment in progress, hence the underscore; expect changes.\"\"\"\n\n    art = []\n\n    # from astropy import wcs\n    # w = wcs.WCS(naxis=2)\n    # w.wcs.crpix = [-234.75, 8.3393]\n    # w.wcs.cdelt = np.array([-0.066667, 0.066667])\n    # w.wcs.crval = [0, -90]\n    # w.wcs.ctype = [\"RA---AIR\", \"DEC--AIR\"]\n    # w.wcs.set_pv([(2, 1, 45.0)])\n\n    # import matplotlib.pyplot as plt\n\n    # plt.subplot(projection=wcs)\n    # #plt.imshow(hdu.data, vmin=-2.e-5, vmax=2.e-4, origin='lower')\n    # plt.grid(color='white', ls='solid')\n    # plt.xlabel('Galactic Longitude')\n    # plt.ylabel('Galactic Latitude')\n\n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_xlim()\n    lim = max(abs(xmin), abs(xmax), abs(ymin), abs(ymax)) * margin\n    lims = (-lim, lim)\n    ax.set_xlim(lims)\n    ax.set_ylim(lims)\n    ax.set_aspect('equal')\n\n    o = observer[0]\n\n    # Dim stars: points of with varying gray levels.\n\n    c = catalog\n    c = c[c['magnitude'] > mag1]\n    c = c[c['magnitude'] <= mag2]\n    #print('Second star group:', len(c))\n    c = c.sort_values('magnitude', ascending=False)\n    s = Star(ra_hours=c.ra_hours, dec_degrees=c.dec_degrees)\n    spos = o.observe(s)\n    x, y = project(spos)\n    m = (mag2 - c['magnitude']) / (mag2 - mag1)\n    # Note that \"gray_r\" is white for 0.0 and black for 1.0\n    art.append(ax.scatter(\n        x, y, s=1.0,\n        c=1 - 0.8 * m, cmap='gray_r', vmin=0.0, vmax=1.0,\n    ))\n\n    # Bright stars: black circles of varying radius, surrounded by a\n    # white gap in case stars are touching.  Draw the brightest stars\n    # first to stop them from completely occluding smaller companions.\n\n    def mag_to_radius(m):\n        return (mag1 - m) * scale + 1.0\n\n    c = catalog\n    c = c[c['magnitude'] <= mag1]\n    c = c.sort_values('magnitude', ascending=True)\n    #print('First star group:', len(c))\n    s = Star(ra_hours=c.ra_hours, dec_degrees=c.dec_degrees)\n    spos = o.observe(s)\n    x, y = project(spos)\n    scale = 1.5\n    radius = mag_to_radius(c['magnitude'])\n\n    x2 = np.repeat(x, 2)\n    y2 = np.repeat(y, 2)\n    radius2 = (radius[:,None] + (3.0,0.0)).flatten()\n    c2 = ('w', 'k')\n    c2 = ('k', 'w')\n\n    art.append(ax.scatter(x2, y2, s=radius2 ** 2.0, c=c2))\n\n    return art, mag_to_radius"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the phase angle of a body viewed from Earth.", "response": "def phase_angle(ephemeris, body, t):\n    \"\"\"Compute the phase angle of a body viewed from Earth.\n\n    The ``body`` should be an integer or string that can be looked up in\n    the given ``ephemeris``, which will also be asked to provide\n    positions for the Earth and Sun.  The return value will be an\n    :class:`~skyfield.units.Angle` object.\n\n    \"\"\"\n    earth = ephemeris['earth']\n    sun = ephemeris['sun']\n    body = ephemeris[body]\n    pe = earth.at(t).observe(body)\n    pe.position.au *= -1     # rotate 180 degrees to point back at Earth\n    t2 = t.ts.tt_jd(t.tt - pe.light_time)\n    ps = body.at(t2).observe(sun)\n    return pe.separation_from(ps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fraction_illuminated(ephemeris, body, t):\n    a = phase_angle(ephemeris, body, t).radians\n    return 0.5 * (1.0 + cos(a))", "response": "Compute the illuminated fraction of a body viewed from Earth."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the times when a function changes value.", "response": "def find_discrete(start_time, end_time, f, epsilon=EPSILON, num=12):\n    \"\"\"Find the times when a function changes value.\n\n    Searches between ``start_time`` and ``end_time``, which should both\n    be :class:`~skyfield.timelib.Time` objects, for the occasions where\n    the function ``f`` changes from one value to another.  Use this to\n    search for events like sunrise or moon phases.\n\n    A tuple of two arrays is returned. The first array gives the times\n    at which the input function changes, and the second array specifies\n    the new value of the function at each corresponding time.\n\n    This is an expensive operation as it needs to repeatedly call the\n    function to narrow down the times that it changes.  It continues\n    searching until it knows each time to at least an accuracy of\n    ``epsilon`` Julian days.  At each step, it creates an array of\n    ``num`` new points between the lower and upper bound that it has\n    established for each transition.  These two values can be changed to\n    tune the behavior of the search.\n\n    \"\"\"\n    ts = start_time.ts\n    jd0 = start_time.tt\n    jd1 = end_time.tt\n    if jd0 >= jd1:\n        raise ValueError('your start_time {0} is later than your end_time {1}'\n                         .format(start_time, end_time))\n\n    periods = (jd1 - jd0) / f.rough_period\n    if periods < 1.0:\n        periods = 1.0\n\n    jd = linspace(jd0, jd1, periods * num // 1.0)\n\n    end_mask = linspace(0.0, 1.0, num)\n    start_mask = end_mask[::-1]\n    o = multiply.outer\n\n    while True:\n        t = ts.tt_jd(jd)\n        y = f(t)\n\n        indices = flatnonzero(diff(y))\n        if not len(indices):\n            return indices, y[0:0]\n\n        starts = jd.take(indices)\n        ends = jd.take(indices + 1)\n\n        # Since we start with equal intervals, they all should fall\n        # below epsilon at around the same time; so for efficiency we\n        # only test the first pair.\n        if ends[0] - starts[0] <= epsilon:\n            break\n\n        jd = o(starts, start_mask).flatten() + o(ends, end_mask).flatten()\n\n    return ts.tt_jd(ends), y.take(indices + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a function that returns the quarter of the year.", "response": "def seasons(ephemeris):\n    \"\"\"Build a function of time that returns the quarter of the year.\n\n    The function that this returns will expect a single argument that is\n    a :class:`~skyfield.timelib.Time` and will return 0 through 3 for\n    the seasons Spring, Summer, Autumn, and Winter.\n\n    \"\"\"\n    earth = ephemeris['earth']\n    sun = ephemeris['sun']\n\n    def season_at(t):\n        \"\"\"Return season 0 (Spring) through 3 (Winter) at time `t`.\"\"\"\n        t._nutation_angles = iau2000b(t.tt)\n        e = earth.at(t)\n        _, slon, _ = e.observe(sun).apparent().ecliptic_latlon('date')\n        return (slon.radians // (tau / 4) % 4).astype(int)\n\n    season_at.rough_period = 90.0\n    return season_at"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a function that returns whether the sun is up.", "response": "def sunrise_sunset(ephemeris, topos):\n\n    \"\"\"Build a function of time that returns whether the sun is up.\n\n    The function that this returns will expect a single argument that is\n    a :class:`~skyfield.timelib.Time` and will return ``True`` if the\n    sun is up, else ``False``.\n\n    \"\"\"\n    sun = ephemeris['sun']\n    topos_at = (ephemeris['earth'] + topos).at\n\n    def is_sun_up_at(t):\n        \"\"\"Return `True` if the sun has risen by time `t`.\"\"\"\n        t._nutation_angles = iau2000b(t.tt)\n        return topos_at(t).observe(sun).apparent().altaz()[0].degrees > -0.8333\n\n    is_sun_up_at.rough_period = 0.5  # twice a day\n    return is_sun_up_at"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a function that returns the moon phase 0 through 3.", "response": "def moon_phases(ephemeris):\n    \"\"\"Build a function of time that returns the moon phase 0 through 3.\n\n    The function that this returns will expect a single argument that is\n    a :class:`~skyfield.timelib.Time` and will return the phase of the\n    moon as an integer.  See the accompanying array ``MOON_PHASES`` if\n    you want to give string names to each phase.\n\n    \"\"\"\n    earth = ephemeris['earth']\n    moon = ephemeris['moon']\n    sun = ephemeris['sun']\n\n    def moon_phase_at(t):\n        \"\"\"Return the phase of the moon 0 through 3 at time `t`.\"\"\"\n        t._nutation_angles = iau2000b(t.tt)\n        e = earth.at(t)\n        _, mlon, _ = e.observe(moon).apparent().ecliptic_latlon('date')\n        _, slon, _ = e.observe(sun).apparent().ecliptic_latlon('date')\n        return ((mlon.radians - slon.radians) // (tau / 4) % 4).astype(int)\n\n    moon_phase_at.rough_period = 7.0  # one lunar phase per week\n    return moon_phase_at"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getECLCoordinatesAtTime(self, date):\n         # localize the orbital parameters\n        a = self.semimajor_axis\n        e = self.eccentricity\n        I = self.inclination\n        Om = self.longitude_ascending\n        #n = 0.230605479\n        n = 0.230652907\n\n        w = self.argument_perihelion\n\n        M = self.mean_anomaly\n        d = date.tdb - self.epoch.tdb\n\n        Om = Om / 360.0 * constants.tau\n        w = w / 360.0 * constants.tau\n        I = I / 360.0 * constants.tau\n        M = M / 360.0 * constants.tau\n        n = n / 360.0 * constants.tau\n\n        M += d * n\n\n        # calculate the mean anomaly in rads\n        E = convergeEccentricAnomaly(M, e, 30)\n\n        # calculate the initial primes\n        x_prime = a * (cos(E) - e)\n        y_prime = a * (1 - e ** 2.0) ** (0.5) * sin(E)\n\n        \"\"\"\n        http://ssd.jpl.nasa.gov/txt/aprx_pos_planets.pdf\n        x_ecl = cos(w)cos(Om)-sin(w)sin(Om)cos(I) * x_prime +\n            (-sin(w)cos(Om) - cos(w)sin(Om)cos(I)) * y_prime\n        y_ecl = cos(w)sin(Om)-sin(w)cos(Om)cos(I) * x_prime +\n            (-sin(w)cos(Om) - cos(w)sin(Om)cos(I)) * y_prime\n        z_ecl = (sin(w)sin(I)) * x_prime +\n            (cos(w)sin(I)) * y_prime\n        \"\"\"\n\n        # calculate the ecliptic coordinates\n        x_ecl = ((cos(w) * cos(Om) - sin(w) * sin(Om) * cos(I)) * x_prime +\n                (-1 * sin(w) * cos(Om) - cos(w) * sin(Om) * cos(I)) * y_prime)\n        y_ecl = ((cos(w) * sin(Om) + sin(w) * cos(Om) * cos(I)) * x_prime +\n                (-1 * sin(w) * sin(Om) + cos(w) * cos(Om) * cos(I)) * y_prime)\n        z_ecl = ((sin(w) * sin(I)) * x_prime + (cos(w) * sin(I)) * y_prime)\n\n        return ICRCoordinates(x_ecl, y_ecl, z_ecl)", "response": "Calculates the ecliptic coordinates at the specified time."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the stereographic projection of the current object.", "response": "def _derive_stereographic():\n    \"\"\"Compute the formulae to cut-and-paste into the routine below.\"\"\"\n    from sympy import symbols, atan2, acos, rot_axis1, rot_axis3, Matrix\n    x_c, y_c, z_c, x, y, z = symbols('x_c y_c z_c x y z')\n\n    # The angles we'll need to rotate through.\n    around_z = atan2(x_c, y_c)\n    around_x = acos(-z_c)\n\n    # Apply rotations to produce an \"o\" = output vector.\n    v = Matrix([x, y, z])\n    xo, yo, zo = rot_axis1(around_x) * rot_axis3(-around_z) * v\n\n    # Which we then use the stereographic projection to produce the\n    # final \"p\" = plotting coordinates.\n    xp = xo / (1 - zo)\n    yp = yo / (1 - zo)\n\n    return xp, yp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the stereographic projection of the current species.", "response": "def build_stereographic_projection(center):\n    \"\"\"Compute *x* and *y* coordinates at which to plot the positions.\"\"\"\n\n    # TODO: Computing the center should really be done using\n    # optimization, as in:\n    # https://math.stackexchange.com/questions/409217/\n    p = center.position.au\n    u = p / length_of(p)\n    c = u.mean(axis=1)\n    c = c / length_of(c)\n    x_c, y_c, z_c = c\n\n    def project(position):\n        p = position.position.au\n        u = p / length_of(p)\n        x, y, z = u\n#        x_out = (x*y_c/sqrt(x_c**2 + y_c**2) - x_c*y/sqrt(x_c**2 + y_c**2))/(x*x_c*sqrt(-z_c**2 + 1)/sqrt(x_c**2 + y_c**2) + y*y_c*sqrt(-z_c**2 + 1)/sqrt(x_c**2 + y_c**2) + z*z_c + 1)\n#        y_out = (-x*x_c*z_c/sqrt(x_c**2 + y_c**2) - y*y_c*z_c/sqrt(x_c**2 + y_c**2) + z*sqrt(-z_c**2 + 1))/(x*x_c*sqrt(-z_c**2 + 1)/sqrt(x_c**2 + y_c**2) + y*y_c*sqrt(-z_c**2 + 1)/sqrt(x_c**2 + y_c**2) + z*z_c + 1)\n#        return x_out, y_out\n\n        t0 = 1/sqrt(x_c**2 + y_c**2)\n        t1 = x*x_c\n        t2 = sqrt(-z_c**2 + 1)\n        t3 = t0*t2\n        t4 = y*y_c\n        t5 = 1/(t1*t3 + t3*t4 + z*z_c + 1)\n        t6 = t0*z_c\n\n        return t0*t5*(x*y_c - x_c*y), -t5*(t1*t6 - t2*z + t4*t6)\n\n    return project"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the PCA components explained variance ratios.", "response": "def plot_pca_component_variance(clf, title='PCA Component Explained Variances',\n                                target_explained_variance=0.75, ax=None,\n                                figsize=None, title_fontsize=\"large\",\n                                text_fontsize=\"medium\"):\n    \"\"\"Plots PCA components' explained variance ratios. (new in v0.2.2)\n\n    Args:\n        clf: PCA instance that has the ``explained_variance_ratio_`` attribute.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"PCA Component Explained Variances\"\n\n        target_explained_variance (float, optional): Looks for the minimum\n            number of principal components that satisfies this value and\n            emphasizes it on the plot. Defaults to 0.75\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> pca = PCA(random_state=1)\n        >>> pca.fit(X)\n        >>> skplt.decomposition.plot_pca_component_variance(pca)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_pca_component_variance.png\n           :align: center\n           :alt: PCA Component variances\n    \"\"\"\n    if not hasattr(clf, 'explained_variance_ratio_'):\n        raise TypeError('\"clf\" does not have explained_variance_ratio_ '\n                        'attribute. Has the PCA been fitted?')\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    cumulative_sum_ratios = np.cumsum(clf.explained_variance_ratio_)\n\n    # Magic code for figuring out closest value to target_explained_variance\n    idx = np.searchsorted(cumulative_sum_ratios, target_explained_variance)\n\n    ax.plot(range(len(clf.explained_variance_ratio_) + 1),\n            np.concatenate(([0], np.cumsum(clf.explained_variance_ratio_))),\n            '*-')\n    ax.grid(True)\n    ax.set_xlabel('First n principal components', fontsize=text_fontsize)\n    ax.set_ylabel('Explained variance ratio of first n components',\n                  fontsize=text_fontsize)\n    ax.set_ylim([-0.02, 1.02])\n    if idx < len(cumulative_sum_ratios):\n        ax.plot(idx+1, cumulative_sum_ratios[idx], 'ro',\n                label='{0:0.3f} Explained variance ratio for '\n                'first {1} components'.format(cumulative_sum_ratios[idx],\n                                              idx+1),\n                markersize=4, markeredgewidth=4)\n        ax.axhline(cumulative_sum_ratios[idx],\n                   linestyle=':', lw=3, color='black')\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the 2 - dimensional projection of a given PCA instance.", "response": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection',\n                           biplot=False, feature_labels=None,\n                           ax=None, figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Plots the 2-dimensional projection of PCA on a given dataset.\n\n    Args:\n        clf: Fitted PCA instance that can ``transform`` given data set into 2\n            dimensions.\n\n        X (array-like, shape (n_samples, n_features)):\n            Feature set to project, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y (array-like, shape (n_samples) or (n_samples, n_features)):\n            Target relative to X for labeling.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"PCA 2-D Projection\"\n\n        biplot (bool, optional): If True, the function will generate and plot\n        \tbiplots. If false, the biplots are not generated.\n\n        feature_labels (array-like, shape (n_classes), optional): List of labels\n        \tthat represent each feature of X. Its index position must also be\n        \trelative to the features. If ``None`` is given, then labels will be\n        \tautomatically generated for each feature.\n        \te.g. \"variable1\", \"variable2\", \"variable3\" ...\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> pca = PCA(random_state=1)\n        >>> pca.fit(X)\n        >>> skplt.decomposition.plot_pca_2d_projection(pca, X, y)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_pca_2d_projection.png\n           :align: center\n           :alt: PCA 2D Projection\n    \"\"\"\n    transformed_X = clf.transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    classes = np.unique(np.array(y))\n\n    colors = plt.cm.get_cmap(cmap)(np.linspace(0, 1, len(classes)))\n\n    for label, color in zip(classes, colors):\n        ax.scatter(transformed_X[y == label, 0], transformed_X[y == label, 1],\n                   alpha=0.8, lw=2, label=label, color=color)\n\n    if biplot:\n        xs = transformed_X[:, 0]\n        ys = transformed_X[:, 1]\n        vectors = np.transpose(clf.components_[:2, :])\n        vectors_scaled = vectors * [xs.max(), ys.max()]\n        for i in range(vectors.shape[0]):\n            ax.annotate(\"\", xy=(vectors_scaled[i, 0], vectors_scaled[i, 1]),\n                        xycoords='data', xytext=(0, 0), textcoords='data',\n                        arrowprops={'arrowstyle': '-|>', 'ec': 'r'})\n\n            ax.text(vectors_scaled[i, 0] * 1.05, vectors_scaled[i, 1] * 1.05,\n                    feature_labels[i] if feature_labels else \"Variable\" + str(i),\n                    color='b', fontsize=text_fontsize)\n\n    ax.legend(loc='best', shadow=False, scatterpoints=1,\n              fontsize=text_fontsize)\n    ax.set_xlabel('First Principal Component', fontsize=text_fontsize)\n    ax.set_ylabel('Second Principal Component', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef classifier_factory(clf):\n    required_methods = ['fit', 'score', 'predict']\n\n    for method in required_methods:\n        if not hasattr(clf, method):\n            raise TypeError('\"{}\" is not in clf. Did you pass a '\n                            'classifier instance?'.format(method))\n\n    optional_methods = ['predict_proba']\n\n    for method in optional_methods:\n        if not hasattr(clf, method):\n            warnings.warn('{} not in clf. Some plots may '\n                          'not be possible to generate.'.format(method))\n\n    additional_methods = {\n        'plot_learning_curve': plot_learning_curve,\n        'plot_confusion_matrix': plot_confusion_matrix_with_cv,\n        'plot_roc_curve': plot_roc_curve_with_cv,\n        'plot_ks_statistic': plot_ks_statistic_with_cv,\n        'plot_precision_recall_curve': plot_precision_recall_curve_with_cv,\n        'plot_feature_importances': plot_feature_importances\n    }\n\n    for key, fn in six.iteritems(additional_methods):\n        if hasattr(clf, key):\n            warnings.warn('\"{}\" method already in clf. '\n                          'Overriding anyway. This may '\n                          'result in unintended behavior.'.format(key))\n        setattr(clf, key, types.MethodType(fn, clf))\n    return clf", "response": "Returns a new classifier instance with embedded scikit - plot instance methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a confusion matrix that can be used to fit and predict a given classifier and dataset.", "response": "def plot_confusion_matrix_with_cv(clf, X, y, labels=None, true_labels=None,\n                                  pred_labels=None, title=None,\n                                  normalize=False, hide_zeros=False,\n                                  x_tick_rotation=0, do_cv=True, cv=None,\n                                  shuffle=True, random_state=None, ax=None,\n                                  figsize=None, cmap='Blues',\n                                  title_fontsize=\"large\",\n                                  text_fontsize=\"medium\"):\n    \"\"\"Generates the confusion matrix for a given classifier and dataset.\n\n    Args:\n        clf: Classifier instance that implements ``fit`` and ``predict``\n            methods.\n\n        X (array-like, shape (n_samples, n_features)):\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        y (array-like, shape (n_samples) or (n_samples, n_features)):\n            Target relative to X for classification.\n\n        labels (array-like, shape (n_classes), optional): List of labels to\n            index the matrix. This may be used to reorder or select a subset of\n            labels. If none is given, those that appear at least once in ``y``\n            are used in sorted order.\n            (new in v0.2.5)\n\n        true_labels (array-like, optional): The true labels to display.\n            If none is given, then all of the labels are used.\n\n        pred_labels (array-like, optional): The predicted labels to display.\n            If none is given, then all of the labels are used.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Confusion Matrix\" if normalize` is True. Else, defaults to\n            \"Normalized Confusion Matrix.\n\n        normalize (bool, optional): If True, normalizes the confusion matrix\n            before plotting. Defaults to False.\n\n        hide_zeros (bool, optional): If True, does not plot cells containing a\n            value of zero. Defaults to False.\n\n        x_tick_rotation (int, optional): Rotates x-axis tick labels by the\n            specified angle. This is useful in cases where there are numerous\n            categories and the labels overlap each other.\n\n        do_cv (bool, optional): If True, the classifier is cross-validated on\n            the dataset using the cross-validation strategy in `cv` to generate\n            the confusion matrix. If False, the confusion matrix is generated\n            without training or cross-validating the classifier. This assumes\n            that the classifier has already been called with its `fit` method\n            beforehand.\n\n        cv (int, cross-validation generator, iterable, optional): Determines\n            the cross-validation strategy to be used for splitting.\n\n            Possible inputs for cv are:\n              - None, to use the default 3-fold cross-validation,\n              - integer, to specify the number of folds.\n              - An object to be used as a cross-validation generator.\n              - An iterable yielding train/test splits.\n\n            For integer/None inputs, if ``y`` is binary or multiclass,\n            :class:`StratifiedKFold` used. If the estimator is not a classifier\n            or if ``y`` is neither binary nor multiclass, :class:`KFold` is\n            used.\n\n        shuffle (bool, optional): Used when do_cv is set to True. Determines\n            whether to shuffle the training data before splitting using\n            cross-validation. Default set to True.\n\n        random_state (int :class:`RandomState`): Pseudo-random number generator\n            state used for random sampling.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the learning curve. If None, the plot is drawn on a new set of\n            axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> rf = classifier_factory(RandomForestClassifier())\n        >>> rf.plot_confusion_matrix(X, y, normalize=True)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_confusion_matrix.png\n           :align: center\n           :alt: Confusion matrix\n    \"\"\"\n    y = np.array(y)\n\n    if not do_cv:\n        y_pred = clf.predict(X)\n        y_true = y\n\n    else:\n        if cv is None:\n            cv = StratifiedKFold(shuffle=shuffle, random_state=random_state)\n        elif isinstance(cv, int):\n            cv = StratifiedKFold(n_splits=cv, shuffle=shuffle,\n                                 random_state=random_state)\n        else:\n            pass\n\n        clf_clone = clone(clf)\n\n        preds_list = []\n        trues_list = []\n        for train_index, test_index in cv.split(X, y):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            clf_clone.fit(X_train, y_train)\n            preds = clf_clone.predict(X_test)\n            preds_list.append(preds)\n            trues_list.append(y_test)\n        y_pred = np.concatenate(preds_list)\n        y_true = np.concatenate(trues_list)\n\n    ax = plotters.plot_confusion_matrix(y_true=y_true, y_pred=y_pred,\n                                        labels=labels, true_labels=true_labels,\n                                        pred_labels=pred_labels,\n                                        title=title, normalize=normalize,\n                                        hide_zeros=hide_zeros,\n                                        x_tick_rotation=x_tick_rotation, ax=ax,\n                                        figsize=figsize, cmap=cmap,\n                                        title_fontsize=title_fontsize,\n                                        text_fontsize=text_fontsize)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_ks_statistic_with_cv(clf, X, y, title='KS Statistic Plot',\n                              do_cv=True, cv=None, shuffle=True,\n                              random_state=None, ax=None, figsize=None,\n                              title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Generates the KS Statistic plot for a given classifier and dataset.\n\n    Args:\n        clf: Classifier instance that implements \"fit\" and \"predict_proba\"\n            methods.\n\n        X (array-like, shape (n_samples, n_features)):\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        y (array-like, shape (n_samples) or (n_samples, n_features)):\n            Target relative to X for classification.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"KS Statistic Plot\".\n\n        do_cv (bool, optional): If True, the classifier is cross-validated on\n            the dataset using the cross-validation strategy in `cv` to generate\n            the confusion matrix. If False, the confusion matrix is generated\n            without training or cross-validating the classifier. This assumes\n            that the classifier has already been called with its `fit` method\n            beforehand.\n\n        cv (int, cross-validation generator, iterable, optional): Determines\n            the cross-validation strategy to be used for splitting.\n\n            Possible inputs for cv are:\n              - None, to use the default 3-fold cross-validation,\n              - integer, to specify the number of folds.\n              - An object to be used as a cross-validation generator.\n              - An iterable yielding train/test splits.\n\n            For integer/None inputs, if ``y`` is binary or multiclass,\n            :class:`StratifiedKFold` used. If the estimator is not a classifier\n            or if ``y`` is neither binary nor multiclass, :class:`KFold` is\n            used.\n\n        shuffle (bool, optional): Used when do_cv is set to True. Determines\n            whether to shuffle the training data before splitting using\n            cross-validation. Default set to True.\n\n        random_state (int :class:`RandomState`): Pseudo-random number generator\n            state used for random sampling.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the learning curve. If None, the plot is drawn on a new set of\n            axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n            >>> lr = classifier_factory(LogisticRegression())\n            >>> lr.plot_ks_statistic(X, y, random_state=1)\n            <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n            >>> plt.show()\n\n        .. image:: _static/examples/plot_ks_statistic.png\n           :align: center\n           :alt: KS Statistic\n    \"\"\"\n    y = np.array(y)\n\n    if not hasattr(clf, 'predict_proba'):\n        raise TypeError('\"predict_proba\" method not in classifier. '\n                        'Cannot calculate ROC Curve.')\n\n    if not do_cv:\n        probas = clf.predict_proba(X)\n        y_true = y\n\n    else:\n        if cv is None:\n            cv = StratifiedKFold(shuffle=shuffle, random_state=random_state)\n        elif isinstance(cv, int):\n            cv = StratifiedKFold(n_splits=cv, shuffle=shuffle,\n                                 random_state=random_state)\n        else:\n            pass\n\n        clf_clone = clone(clf)\n\n        preds_list = []\n        trues_list = []\n        for train_index, test_index in cv.split(X, y):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            clf_clone.fit(X_train, y_train)\n            preds = clf_clone.predict_proba(X_test)\n            preds_list.append(preds)\n            trues_list.append(y_test)\n        probas = np.concatenate(preds_list, axis=0)\n        y_true = np.concatenate(trues_list)\n\n    ax = plotters.plot_ks_statistic(y_true, probas, title=title,\n                                    ax=ax, figsize=figsize,\n                                    title_fontsize=title_fontsize,\n                                    text_fontsize=text_fontsize)\n\n    return ax", "response": "Generates the KS Statistic plot for a given classifier and dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_confusion_matrix(y_true, y_pred, labels=None, true_labels=None,\n                          pred_labels=None, title=None, normalize=False,\n                          hide_zeros=False, x_tick_rotation=0, ax=None,\n                          figsize=None, cmap='Blues', title_fontsize=\"large\",\n                          text_fontsize=\"medium\"):\n    \"\"\"Generates confusion matrix plot from predictions and true labels\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_pred (array-like, shape (n_samples)):\n            Estimated targets as returned by a classifier.\n\n        labels (array-like, shape (n_classes), optional): List of labels to\n            index the matrix. This may be used to reorder or select a subset\n            of labels. If none is given, those that appear at least once in\n            ``y_true`` or ``y_pred`` are used in sorted order. (new in v0.2.5)\n\n        true_labels (array-like, optional): The true labels to display.\n            If none is given, then all of the labels are used.\n\n        pred_labels (array-like, optional): The predicted labels to display.\n            If none is given, then all of the labels are used.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Confusion Matrix\" if `normalize` is True. Else, defaults to\n            \"Normalized Confusion Matrix.\n\n        normalize (bool, optional): If True, normalizes the confusion matrix\n            before plotting. Defaults to False.\n\n        hide_zeros (bool, optional): If True, does not plot cells containing a\n            value of zero. Defaults to False.\n\n        x_tick_rotation (int, optional): Rotates x-axis tick labels by the\n            specified angle. This is useful in cases where there are numerous\n            categories and the labels overlap each other.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> rf = RandomForestClassifier()\n        >>> rf = rf.fit(X_train, y_train)\n        >>> y_pred = rf.predict(X_test)\n        >>> skplt.plot_confusion_matrix(y_test, y_pred, normalize=True)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_confusion_matrix.png\n           :align: center\n           :alt: Confusion matrix\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    if labels is None:\n        classes = unique_labels(y_true, y_pred)\n    else:\n        classes = np.asarray(labels)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n\n    if true_labels is None:\n        true_classes = classes\n    else:\n        validate_labels(classes, true_labels, \"true_labels\")\n\n        true_label_indexes = np.in1d(classes, true_labels)\n\n        true_classes = classes[true_label_indexes]\n        cm = cm[true_label_indexes]\n\n    if pred_labels is None:\n        pred_classes = classes\n    else:\n        validate_labels(classes, pred_labels, \"pred_labels\")\n\n        pred_label_indexes = np.in1d(classes, pred_labels)\n\n        pred_classes = classes[pred_label_indexes]\n        cm = cm[:, pred_label_indexes]\n\n    if title:\n        ax.set_title(title, fontsize=title_fontsize)\n    elif normalize:\n        ax.set_title('Normalized Confusion Matrix', fontsize=title_fontsize)\n    else:\n        ax.set_title('Confusion Matrix', fontsize=title_fontsize)\n\n    image = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap(cmap))\n    plt.colorbar(mappable=image)\n    x_tick_marks = np.arange(len(pred_classes))\n    y_tick_marks = np.arange(len(true_classes))\n    ax.set_xticks(x_tick_marks)\n    ax.set_xticklabels(pred_classes, fontsize=text_fontsize,\n                       rotation=x_tick_rotation)\n    ax.set_yticks(y_tick_marks)\n    ax.set_yticklabels(true_classes, fontsize=text_fontsize)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if not (hide_zeros and cm[i, j] == 0):\n            ax.text(j, i, cm[i, j],\n                    horizontalalignment=\"center\",\n                    verticalalignment=\"center\",\n                    fontsize=text_fontsize,\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    ax.set_ylabel('True label', fontsize=text_fontsize)\n    ax.set_xlabel('Predicted label', fontsize=text_fontsize)\n    ax.grid('off')\n\n    return ax", "response": "Generates a confusion matrix plot from predicted and true target values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_roc_curve(y_true, y_probas, title='ROC Curves',\n                   curves=('micro', 'macro', 'each_class'),\n                   ax=None, figsize=None, cmap='nipy_spectral',\n                   title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Generates the ROC curves from labels and predicted scores/probabilities\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"ROC Curves\".\n\n        curves (array-like): A listing of which curves should be plotted on the\n            resulting plot. Defaults to `(\"micro\", \"macro\", \"each_class\")`\n            i.e. \"micro\" for micro-averaged curve, \"macro\" for macro-averaged\n            curve\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> nb = GaussianNB()\n        >>> nb = nb.fit(X_train, y_train)\n        >>> y_probas = nb.predict_proba(X_test)\n        >>> skplt.plot_roc_curve(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_roc_curve.png\n           :align: center\n           :alt: ROC Curves\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    if 'micro' not in curves and 'macro' not in curves and \\\n            'each_class' not in curves:\n        raise ValueError('Invalid argument for curves as it '\n                         'only takes \"micro\", \"macro\", or \"each_class\"')\n\n    classes = np.unique(y_true)\n    probas = y_probas\n\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(len(classes)):\n        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n                                      pos_label=classes[i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Compute micro-average ROC curve and ROC area\n    micro_key = 'micro'\n    i = 0\n    while micro_key in fpr:\n        i += 1\n        micro_key += str(i)\n\n    y_true = label_binarize(y_true, classes=classes)\n    if len(classes) == 2:\n        y_true = np.hstack((1 - y_true, y_true))\n\n    fpr[micro_key], tpr[micro_key], _ = roc_curve(y_true.ravel(),\n                                                  probas.ravel())\n    roc_auc[micro_key] = auc(fpr[micro_key], tpr[micro_key])\n\n    # Compute macro-average ROC curve and ROC area\n\n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[x] for x in range(len(classes))]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(len(classes)):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr /= len(classes)\n\n    macro_key = 'macro'\n    i = 0\n    while macro_key in fpr:\n        i += 1\n        macro_key += str(i)\n    fpr[macro_key] = all_fpr\n    tpr[macro_key] = mean_tpr\n    roc_auc[macro_key] = auc(fpr[macro_key], tpr[macro_key])\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if 'each_class' in curves:\n        for i in range(len(classes)):\n            color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n            ax.plot(fpr[i], tpr[i], lw=2, color=color,\n                    label='ROC curve of class {0} (area = {1:0.2f})'\n                    ''.format(classes[i], roc_auc[i]))\n\n    if 'micro' in curves:\n        ax.plot(fpr[micro_key], tpr[micro_key],\n                label='micro-average ROC curve '\n                      '(area = {0:0.2f})'.format(roc_auc[micro_key]),\n                color='deeppink', linestyle=':', linewidth=4)\n\n    if 'macro' in curves:\n        ax.plot(fpr[macro_key], tpr[macro_key],\n                label='macro-average ROC curve '\n                      '(area = {0:0.2f})'.format(roc_auc[macro_key]),\n                color='navy', linestyle=':', linewidth=4)\n\n    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate', fontsize=text_fontsize)\n    ax.set_ylabel('True Positive Rate', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='lower right', fontsize=text_fontsize)\n    return ax", "response": "Generates the ROC curves from labels and predicted scores."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the KS Statistic plot from labels and scores.", "response": "def plot_ks_statistic(y_true, y_probas, title='KS Statistic Plot',\n                      ax=None, figsize=None, title_fontsize=\"large\",\n                      text_fontsize=\"medium\"):\n    \"\"\"Generates the KS Statistic plot from labels and scores/probabilities\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"KS Statistic Plot\".\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the learning curve. If None, the plot is drawn on a new set of\n            axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> lr = LogisticRegression()\n        >>> lr = lr.fit(X_train, y_train)\n        >>> y_probas = lr.predict_proba(X_test)\n        >>> skplt.plot_ks_statistic(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_ks_statistic.png\n           :align: center\n           :alt: KS Statistic\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    classes = np.unique(y_true)\n    if len(classes) != 2:\n        raise ValueError('Cannot calculate KS statistic for data with '\n                         '{} category/ies'.format(len(classes)))\n    probas = y_probas\n\n    # Compute KS Statistic curves\n    thresholds, pct1, pct2, ks_statistic, \\\n        max_distance_at, classes = binary_ks_curve(y_true,\n                                                   probas[:, 1].ravel())\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    ax.plot(thresholds, pct1, lw=3, label='Class {}'.format(classes[0]))\n    ax.plot(thresholds, pct2, lw=3, label='Class {}'.format(classes[1]))\n    idx = np.where(thresholds == max_distance_at)[0][0]\n    ax.axvline(max_distance_at, *sorted([pct1[idx], pct2[idx]]),\n               label='KS Statistic: {:.3f} at {:.3f}'.format(ks_statistic,\n                                                             max_distance_at),\n               linestyle=':', lw=3, color='black')\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.0])\n\n    ax.set_xlabel('Threshold', fontsize=text_fontsize)\n    ax.set_ylabel('Percentage below threshold', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='lower right', fontsize=text_fontsize)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_precision_recall_curve(y_true, y_probas,\n                                title='Precision-Recall Curve',\n                                curves=('micro', 'each_class'), ax=None,\n                                figsize=None, cmap='nipy_spectral',\n                                title_fontsize=\"large\",\n                                text_fontsize=\"medium\"):\n    \"\"\"Generates the Precision Recall Curve from labels and probabilities\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        curves (array-like): A listing of which curves should be plotted on the\n            resulting plot. Defaults to `(\"micro\", \"each_class\")`\n            i.e. \"micro\" for micro-averaged curve\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> nb = GaussianNB()\n        >>> nb = nb.fit(X_train, y_train)\n        >>> y_probas = nb.predict_proba(X_test)\n        >>> skplt.plot_precision_recall_curve(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_precision_recall_curve.png\n           :align: center\n           :alt: Precision Recall Curve\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    classes = np.unique(y_true)\n    probas = y_probas\n\n    if 'micro' not in curves and 'each_class' not in curves:\n        raise ValueError('Invalid argument for curves as it '\n                         'only takes \"micro\" or \"each_class\"')\n\n    # Compute Precision-Recall curve and area for each class\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(len(classes)):\n        precision[i], recall[i], _ = precision_recall_curve(\n            y_true, probas[:, i], pos_label=classes[i])\n\n    y_true = label_binarize(y_true, classes=classes)\n    if len(classes) == 2:\n        y_true = np.hstack((1 - y_true, y_true))\n\n    for i in range(len(classes)):\n        average_precision[i] = average_precision_score(y_true[:, i],\n                                                       probas[:, i])\n\n    # Compute micro-average ROC curve and ROC area\n    micro_key = 'micro'\n    i = 0\n    while micro_key in precision:\n        i += 1\n        micro_key += str(i)\n\n    precision[micro_key], recall[micro_key], _ = precision_recall_curve(\n        y_true.ravel(), probas.ravel())\n    average_precision[micro_key] = average_precision_score(y_true, probas,\n                                                           average='micro')\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if 'each_class' in curves:\n        for i in range(len(classes)):\n            color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n            ax.plot(recall[i], precision[i], lw=2,\n                    label='Precision-recall curve of class {0} '\n                          '(area = {1:0.3f})'.format(classes[i],\n                                                     average_precision[i]),\n                    color=color)\n\n    if 'micro' in curves:\n        ax.plot(recall[micro_key], precision[micro_key],\n                label='micro-average Precision-recall curve '\n                      '(area = {0:0.3f})'.format(average_precision[micro_key]),\n                color='navy', linestyle=':', linewidth=4)\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n    return ax", "response": "Generates the Precision Recall curve plot from labels and probabilities."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a plot of a classifier s feature importances.", "response": "def plot_feature_importances(clf, title='Feature Importance',\n                             feature_names=None, max_num_features=20,\n                             order='descending', x_tick_rotation=0, ax=None,\n                             figsize=None, title_fontsize=\"large\",\n                             text_fontsize=\"medium\"):\n    \"\"\"Generates a plot of a classifier's feature importances.\n\n    Args:\n        clf: Classifier instance that implements ``fit`` and ``predict_proba``\n            methods. The classifier must also have a ``feature_importances_``\n            attribute.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Feature importances\".\n\n        feature_names (None, :obj:`list` of string, optional): Determines the\n            feature names used to plot the feature importances. If None,\n            feature names will be numbered.\n\n        max_num_features (int): Determines the maximum number of features to\n            plot. Defaults to 20.\n\n        order ('ascending', 'descending', or None, optional): Determines the\n            order in which the feature importances are plotted. Defaults to\n            'descending'.\n\n        x_tick_rotation (int, optional): Rotates x-axis tick labels by the\n            specified angle. This is useful in cases where there are numerous\n            categories and the labels overlap each other.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> rf = RandomForestClassifier()\n        >>> rf.fit(X, y)\n        >>> skplt.plot_feature_importances(\n        ...     rf, feature_names=['petal length', 'petal width',\n        ...                        'sepal length', 'sepal width'])\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_feature_importances.png\n           :align: center\n           :alt: Feature Importances\n    \"\"\"\n    if not hasattr(clf, 'feature_importances_'):\n        raise TypeError('\"feature_importances_\" attribute not in classifier. '\n                        'Cannot plot feature importances.')\n\n    importances = clf.feature_importances_\n\n    if hasattr(clf, 'estimators_')\\\n            and isinstance(clf.estimators_, list)\\\n            and hasattr(clf.estimators_[0], 'feature_importances_'):\n        std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n                     axis=0)\n\n    else:\n        std = None\n\n    if order == 'descending':\n        indices = np.argsort(importances)[::-1]\n\n    elif order == 'ascending':\n        indices = np.argsort(importances)\n\n    elif order is None:\n        indices = np.array(range(len(importances)))\n\n    else:\n        raise ValueError('Invalid argument {} for \"order\"'.format(order))\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    if feature_names is None:\n        feature_names = indices\n    else:\n        feature_names = np.array(feature_names)[indices]\n\n    max_num_features = min(max_num_features, len(importances))\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if std is not None:\n        ax.bar(range(max_num_features),\n               importances[indices][:max_num_features], color='r',\n               yerr=std[indices][:max_num_features], align='center')\n    else:\n        ax.bar(range(max_num_features),\n               importances[indices][:max_num_features],\n               color='r', align='center')\n\n    ax.set_xticks(range(max_num_features))\n    ax.set_xticklabels(feature_names[:max_num_features],\n                       rotation=x_tick_rotation)\n    ax.set_xlim([-1, max_num_features])\n    ax.tick_params(labelsize=text_fontsize)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_silhouette(clf, X, title='Silhouette Analysis', metric='euclidean',\n                    copy=True, ax=None, figsize=None, cmap='nipy_spectral',\n                    title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Plots silhouette analysis of clusters using fit_predict.\n\n    Args:\n        clf: Clusterer instance that implements ``fit`` and ``fit_predict``\n            methods.\n\n        X (array-like, shape (n_samples, n_features)):\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Silhouette Analysis\"\n\n        metric (string or callable, optional): The metric to use when\n            calculating distance between instances in a feature array.\n            If metric is a string, it must be one of the options allowed by\n            sklearn.metrics.pairwise.pairwise_distances. If X is\n            the distance array itself, use \"precomputed\" as the metric.\n\n        copy (boolean, optional): Determines whether ``fit`` is used on\n            **clf** or on a copy of **clf**.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> kmeans = KMeans(n_clusters=4, random_state=1)\n        >>> skplt.plot_silhouette(kmeans, X)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_silhouette.png\n           :align: center\n           :alt: Silhouette Plot\n    \"\"\"\n    if copy:\n        clf = clone(clf)\n\n    cluster_labels = clf.fit_predict(X)\n\n    n_clusters = len(set(cluster_labels))\n\n    silhouette_avg = silhouette_score(X, cluster_labels, metric=metric)\n\n    sample_silhouette_values = silhouette_samples(X, cluster_labels,\n                                                  metric=metric)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlim([-0.1, 1])\n\n    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10 + 10])\n\n    ax.set_xlabel('Silhouette coefficient values', fontsize=text_fontsize)\n    ax.set_ylabel('Cluster label', fontsize=text_fontsize)\n\n    y_lower = 10\n\n    for i in range(n_clusters):\n        ith_cluster_silhouette_values = sample_silhouette_values[\n            cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = plt.cm.get_cmap(cmap)(float(i) / n_clusters)\n\n        ax.fill_betweenx(np.arange(y_lower, y_upper),\n                         0, ith_cluster_silhouette_values,\n                         facecolor=color, edgecolor=color, alpha=0.7)\n\n        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i),\n                fontsize=text_fontsize)\n\n        y_lower = y_upper + 10\n\n    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\",\n               label='Silhouette score: {0:0.3f}'.format(silhouette_avg))\n\n    ax.set_yticks([])  # Clear the y-axis labels / ticks\n    ax.set_xticks(np.arange(-0.1, 1.0, 0.2))\n\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n\n    return ax", "response": "Plots a silhouette analysis of a cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\"):\n    \"\"\"Plots elbow curve of different values of K for KMeans clustering.\n\n    Args:\n        clf: Clusterer instance that implements ``fit`` and ``fit_predict``\n            methods and a ``score`` parameter.\n\n        X (array-like, shape (n_samples, n_features)):\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Elbow Plot\"\n\n        cluster_ranges (None or :obj:`list` of int, optional): List of\n            n_clusters for which to plot the explained variances. Defaults to\n            ``range(1, 12, 2)``.\n\n        copy (boolean, optional): Determines whether ``fit`` is used on\n            **clf** or on a copy of **clf**.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> kmeans = KMeans(random_state=1)\n        >>> skplt.plot_elbow_curve(kmeans, cluster_ranges=range(1, 11))\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_elbow_curve.png\n           :align: center\n           :alt: Elbow Curve\n    \"\"\"\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 12, 2)\n    else:\n        cluster_ranges = sorted(cluster_ranges)\n\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('\"n_clusters\" attribute not in classifier. '\n                        'Cannot plot elbow method.')\n\n    clfs = []\n    for i in cluster_ranges:\n        current_clf = clone(clf)\n        setattr(current_clf, \"n_clusters\", i)\n        clfs.append(current_clf.fit(X).score(X))\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.plot(cluster_ranges, np.absolute(clfs), 'b*-')\n    ax.grid(True)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax", "response": "Plots the elbow curve of different values of K for KMeans clustering."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Plots the 2-dimensional projection of PCA on a given dataset.\n\n    Args:\n        clf: Fitted PCA instance that can ``transform`` given data set into 2\n            dimensions.\n\n        X (array-like, shape (n_samples, n_features)):\n            Feature set to project, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y (array-like, shape (n_samples) or (n_samples, n_features)):\n            Target relative to X for labeling.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"PCA 2-D Projection\"\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot.plotters as skplt\n        >>> pca = PCA(random_state=1)\n        >>> pca.fit(X)\n        >>> skplt.plot_pca_2d_projection(pca, X, y)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_pca_2d_projection.png\n           :align: center\n           :alt: PCA 2D Projection\n    \"\"\"\n    transformed_X = clf.transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    classes = np.unique(np.array(y))\n\n    colors = plt.cm.get_cmap(cmap)(np.linspace(0, 1, len(classes)))\n\n    for label, color in zip(classes, colors):\n        ax.scatter(transformed_X[y == label, 0], transformed_X[y == label, 1],\n                   alpha=0.8, lw=2, label=label, color=color)\n    ax.legend(loc='best', shadow=False, scatterpoints=1,\n              fontsize=text_fontsize)\n    ax.set_xlabel('First Principal Component', fontsize=text_fontsize)\n    ax.set_ylabel('Second Principal Component', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax", "response": "Plots the 2 - dimensional projection of a given PCA on a given dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Plots elbow curve of different values of K for KMeans clustering.\n\n    Args:\n        clf: Clusterer instance that implements ``fit``,``fit_predict``, and\n            ``score`` methods, and an ``n_clusters`` hyperparameter.\n            e.g. :class:`sklearn.cluster.KMeans` instance\n\n        X (array-like, shape (n_samples, n_features)):\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Elbow Plot\"\n\n        cluster_ranges (None or :obj:`list` of int, optional): List of\n            n_clusters for which to plot the explained variances. Defaults to\n            ``range(1, 12, 2)``.\n\n        n_jobs (int, optional): Number of jobs to run in parallel. Defaults to\n            1.\n\n        show_cluster_time (bool, optional): Include plot of time it took to\n            cluster for a particular K.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> kmeans = KMeans(random_state=1)\n        >>> skplt.cluster.plot_elbow_curve(kmeans, cluster_ranges=range(1, 30))\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_elbow_curve.png\n           :align: center\n           :alt: Elbow Curve\n    \"\"\"\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 12, 2)\n    else:\n        cluster_ranges = sorted(cluster_ranges)\n\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('\"n_clusters\" attribute not in classifier. '\n                        'Cannot plot elbow method.')\n\n    tuples = Parallel(n_jobs=n_jobs)(delayed(_clone_and_score_clusterer)\n                                     (clf, X, i) for i in cluster_ranges)\n    clfs, times = zip(*tuples)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.plot(cluster_ranges, np.absolute(clfs), 'b*-')\n    ax.grid(True)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    if show_cluster_time:\n        ax2_color = 'green'\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, times, ':', alpha=0.75, color=ax2_color)\n        ax2.set_ylabel('Clustering duration (seconds)',\n                       color=ax2_color, alpha=0.75,\n                       fontsize=text_fontsize)\n        ax2.tick_params(colors=ax2_color, labelsize=text_fontsize)\n\n    return ax", "response": "Plots the elbow curve of different values of K for KMeans clustering."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclone and scores clusterer instance.", "response": "def _clone_and_score_clusterer(clf, X, n_clusters):\n    \"\"\"Clones and scores clusterer instance.\n\n    Args:\n        clf: Clusterer instance that implements ``fit``,``fit_predict``, and\n            ``score`` methods, and an ``n_clusters`` hyperparameter.\n            e.g. :class:`sklearn.cluster.KMeans` instance\n\n        X (array-like, shape (n_samples, n_features)):\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        n_clusters (int): Number of clusters\n\n    Returns:\n        score: Score of clusters\n\n        time: Number of seconds it took to fit cluster\n    \"\"\"\n    start = time.time()\n    clf = clone(clf)\n    setattr(clf, 'n_clusters', n_clusters)\n    return clf.fit(X).score(X), time.time() - start"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        shuffle=False, random_state=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\"):\n    \"\"\"Generates a plot of the train and test learning curves for a classifier.\n\n    Args:\n        clf: Classifier instance that implements ``fit`` and ``predict``\n            methods.\n\n        X (array-like, shape (n_samples, n_features)):\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        y (array-like, shape (n_samples) or (n_samples, n_features)):\n            Target relative to X for classification or regression;\n            None for unsupervised learning.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Learning Curve\"\n\n        cv (int, cross-validation generator, iterable, optional): Determines\n            the cross-validation strategy to be used for splitting.\n\n            Possible inputs for cv are:\n              - None, to use the default 3-fold cross-validation,\n              - integer, to specify the number of folds.\n              - An object to be used as a cross-validation generator.\n              - An iterable yielding train/test splits.\n\n            For integer/None inputs, if ``y`` is binary or multiclass,\n            :class:`StratifiedKFold` used. If the estimator is not a classifier\n            or if ``y`` is neither binary nor multiclass, :class:`KFold` is\n            used.\n\n        shuffle (bool, optional): Used when do_cv is set to True. Determines\n            whether to shuffle the training data before splitting using\n            cross-validation. Default set to True.\n\n        random_state (int :class:`RandomState`): Pseudo-random number generator\n            state used for random sampling.\n\n        train_sizes (iterable, optional): Determines the training sizes used to\n            plot the learning curve. If None, ``np.linspace(.1, 1.0, 5)`` is\n            used.\n\n        n_jobs (int, optional): Number of jobs to run in parallel. Defaults to\n            1.\n\n        scoring (string, callable or None, optional): default: None\n            A string (see scikit-learn model evaluation documentation) or a\n            scorerbcallable object / function with signature\n            scorer(estimator, X, y).\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> rf = RandomForestClassifier()\n        >>> skplt.estimators.plot_learning_curve(rf, X, y)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_learning_curve.png\n           :align: center\n           :alt: Learning Curve\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    if train_sizes is None:\n        train_sizes = np.linspace(.1, 1.0, 5)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n        scoring=scoring, shuffle=shuffle, random_state=random_state)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax", "response": "Generates a plot of the train and test learning curves for a classifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the ROC curves from labels and predicted scores and probabilities.", "response": "def plot_roc(y_true, y_probas, title='ROC Curves',\n                   plot_micro=True, plot_macro=True, classes_to_plot=None,\n                   ax=None, figsize=None, cmap='nipy_spectral',\n                   title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Generates the ROC curves from labels and predicted scores/probabilities\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"ROC Curves\".\n\n        plot_micro (boolean, optional): Plot the micro average ROC curve.\n            Defaults to ``True``.\n\n        plot_macro (boolean, optional): Plot the macro average ROC curve.\n            Defaults to ``True``.\n\n        classes_to_plot (list-like, optional): Classes for which the ROC\n            curve should be plotted. e.g. [0, 'cold']. If given class does not exist,\n            it will be ignored. If ``None``, all classes will be plotted. Defaults to\n            ``None``\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> nb = GaussianNB()\n        >>> nb = nb.fit(X_train, y_train)\n        >>> y_probas = nb.predict_proba(X_test)\n        >>> skplt.metrics.plot_roc(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_roc_curve.png\n           :align: center\n           :alt: ROC Curves\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    classes = np.unique(y_true)\n    probas = y_probas\n\n    if classes_to_plot is None:\n        classes_to_plot = classes\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    fpr_dict = dict()\n    tpr_dict = dict()\n\n    indices_to_plot = np.in1d(classes, classes_to_plot)\n    for i, to_plot in enumerate(indices_to_plot):\n        fpr_dict[i], tpr_dict[i], _ = roc_curve(y_true, probas[:, i],\n                                                pos_label=classes[i])\n        if to_plot:\n            roc_auc = auc(fpr_dict[i], tpr_dict[i])\n            color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n            ax.plot(fpr_dict[i], tpr_dict[i], lw=2, color=color,\n                    label='ROC curve of class {0} (area = {1:0.2f})'\n                          ''.format(classes[i], roc_auc))\n\n    if plot_micro:\n        binarized_y_true = label_binarize(y_true, classes=classes)\n        if len(classes) == 2:\n            binarized_y_true = np.hstack(\n                (1 - binarized_y_true, binarized_y_true))\n        fpr, tpr, _ = roc_curve(binarized_y_true.ravel(), probas.ravel())\n        roc_auc = auc(fpr, tpr)\n        ax.plot(fpr, tpr,\n                label='micro-average ROC curve '\n                      '(area = {0:0.2f})'.format(roc_auc),\n                color='deeppink', linestyle=':', linewidth=4)\n\n    if plot_macro:\n        # Compute macro-average ROC curve and ROC area\n        # First aggregate all false positive rates\n        all_fpr = np.unique(np.concatenate([fpr_dict[x] for x in range(len(classes))]))\n\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(len(classes)):\n            mean_tpr += interp(all_fpr, fpr_dict[i], tpr_dict[i])\n\n        # Finally average it and compute AUC\n        mean_tpr /= len(classes)\n        roc_auc = auc(all_fpr, mean_tpr)\n\n        ax.plot(all_fpr, mean_tpr,\n                label='macro-average ROC curve '\n                      '(area = {0:0.2f})'.format(roc_auc),\n                color='navy', linestyle=':', linewidth=4)\n\n    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate', fontsize=text_fontsize)\n    ax.set_ylabel('True Positive Rate', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='lower right', fontsize=text_fontsize)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the Precision Recall curve from labels and probabilities.", "response": "def plot_precision_recall(y_true, y_probas,\n                          title='Precision-Recall Curve',\n                          plot_micro=True,\n                          classes_to_plot=None, ax=None,\n                          figsize=None, cmap='nipy_spectral',\n                          title_fontsize=\"large\",\n                          text_fontsize=\"medium\"):\n    \"\"\"Generates the Precision Recall Curve from labels and probabilities\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Precision-Recall curve\".\n\n        plot_micro (boolean, optional): Plot the micro average ROC curve.\n            Defaults to ``True``.\n\n        classes_to_plot (list-like, optional): Classes for which the precision-recall\n            curve should be plotted. e.g. [0, 'cold']. If given class does not exist,\n            it will be ignored. If ``None``, all classes will be plotted. Defaults to\n            ``None``.\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> nb = GaussianNB()\n        >>> nb.fit(X_train, y_train)\n        >>> y_probas = nb.predict_proba(X_test)\n        >>> skplt.metrics.plot_precision_recall(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_precision_recall_curve.png\n           :align: center\n           :alt: Precision Recall Curve\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    classes = np.unique(y_true)\n    probas = y_probas\n\n    if classes_to_plot is None:\n        classes_to_plot = classes\n\n    binarized_y_true = label_binarize(y_true, classes=classes)\n    if len(classes) == 2:\n        binarized_y_true = np.hstack(\n            (1 - binarized_y_true, binarized_y_true))\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    indices_to_plot = np.in1d(classes, classes_to_plot)\n    for i, to_plot in enumerate(indices_to_plot):\n        if to_plot:\n            average_precision = average_precision_score(\n                binarized_y_true[:, i],\n                probas[:, i])\n            precision, recall, _ = precision_recall_curve(\n                y_true, probas[:, i], pos_label=classes[i])\n            color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n            ax.plot(recall, precision, lw=2,\n                    label='Precision-recall curve of class {0} '\n                          '(area = {1:0.3f})'.format(classes[i],\n                                                     average_precision),\n                    color=color)\n\n    if plot_micro:\n        precision, recall, _ = precision_recall_curve(\n            binarized_y_true.ravel(), probas.ravel())\n        average_precision = average_precision_score(binarized_y_true,\n                                                    probas,\n                                                    average='micro')\n        ax.plot(recall, precision,\n                label='micro-average Precision-recall curve '\n                      '(area = {0:0.3f})'.format(average_precision),\n                color='navy', linestyle=':', linewidth=4)\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_calibration_curve(y_true, probas_list, clf_names=None, n_bins=10,\n                           title='Calibration plots (Reliability Curves)',\n                           ax=None, figsize=None, cmap='nipy_spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\"):\n    \"\"\"Plots calibration curves for a set of classifier probability estimates.\n\n    Plotting the calibration curves of a classifier is useful for determining\n    whether or not you can interpret their predicted probabilities directly as\n    as confidence level. For instance, a well-calibrated binary classifier\n    should classify the samples such that for samples to which it gave a score\n    of 0.8, around 80% should actually be from the positive class.\n\n    This function currently only works for binary classification.\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        probas_list (list of array-like, shape (n_samples, 2) or (n_samples,)):\n            A list containing the outputs of binary classifiers'\n            :func:`predict_proba` method or :func:`decision_function` method.\n\n        clf_names (list of str, optional): A list of strings, where each string\n            refers to the name of the classifier that produced the\n            corresponding probability estimates in `probas_list`. If ``None``,\n            the names \"Classifier 1\", \"Classifier 2\", etc. will be used.\n\n        n_bins (int, optional): Number of bins. A bigger number requires more\n            data.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Calibration plots (Reliabilirt Curves)\"\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the curve. If None, the plot is drawn on a new set of axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        cmap (string or :class:`matplotlib.colors.Colormap` instance, optional):\n            Colormap used for plotting the projection. View Matplotlib Colormap\n            documentation for available options.\n            https://matplotlib.org/users/colormaps.html\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        :class:`matplotlib.axes.Axes`: The axes on which the plot was drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> rf = RandomForestClassifier()\n        >>> lr = LogisticRegression()\n        >>> nb = GaussianNB()\n        >>> svm = LinearSVC()\n        >>> rf_probas = rf.fit(X_train, y_train).predict_proba(X_test)\n        >>> lr_probas = lr.fit(X_train, y_train).predict_proba(X_test)\n        >>> nb_probas = nb.fit(X_train, y_train).predict_proba(X_test)\n        >>> svm_scores = svm.fit(X_train, y_train).decision_function(X_test)\n        >>> probas_list = [rf_probas, lr_probas, nb_probas, svm_scores]\n        >>> clf_names = ['Random Forest', 'Logistic Regression',\n        ...              'Gaussian Naive Bayes', 'Support Vector Machine']\n        >>> skplt.metrics.plot_calibration_curve(y_test,\n        ...                                      probas_list,\n        ...                                      clf_names)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_calibration_curve.png\n           :align: center\n           :alt: Calibration Curves\n    \"\"\"\n    y_true = np.asarray(y_true)\n    if not isinstance(probas_list, list):\n        raise ValueError('`probas_list` does not contain a list.')\n\n    classes = np.unique(y_true)\n    if len(classes) > 2:\n        raise ValueError('plot_calibration_curve only '\n                         'works for binary classification')\n\n    if clf_names is None:\n        clf_names = ['Classifier {}'.format(x+1)\n                     for x in range(len(probas_list))]\n\n    if len(clf_names) != len(probas_list):\n        raise ValueError('Length {} of `clf_names` does not match length {} of'\n                         ' `probas_list`'.format(len(clf_names),\n                                                 len(probas_list)))\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n\n    for i, probas in enumerate(probas_list):\n        probas = np.asarray(probas)\n        if probas.ndim > 2:\n            raise ValueError('Index {} in probas_list has invalid '\n                             'shape {}'.format(i, probas.shape))\n        if probas.ndim == 2:\n            probas = probas[:, 1]\n\n        if probas.shape != y_true.shape:\n            raise ValueError('Index {} in probas_list has invalid '\n                             'shape {}'.format(i, probas.shape))\n\n        probas = (probas - probas.min()) / (probas.max() - probas.min())\n\n        fraction_of_positives, mean_predicted_value = \\\n            calibration_curve(y_true, probas, n_bins=n_bins)\n\n        color = plt.cm.get_cmap(cmap)(float(i) / len(probas_list))\n\n        ax.plot(mean_predicted_value, fraction_of_positives, 's-',\n                label=clf_names[i], color=color)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    ax.set_xlabel('Mean predicted value', fontsize=text_fontsize)\n    ax.set_ylabel('Fraction of positives', fontsize=text_fontsize)\n\n    ax.set_ylim([-0.05, 1.05])\n    ax.legend(loc='lower right')\n\n    return ax", "response": "Plots calibration curves for a set of binary classifiers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_cumulative_gain(y_true, y_probas, title='Cumulative Gains Curve',\n                         ax=None, figsize=None, title_fontsize=\"large\",\n                         text_fontsize=\"medium\"):\n    \"\"\"Generates the Cumulative Gains Plot from labels and scores/probabilities\n\n    The cumulative gains chart is used to determine the effectiveness of a\n    binary classifier. A detailed explanation can be found at\n    http://mlwiki.org/index.php/Cumulative_Gain_Chart. The implementation\n    here works only for binary classification.\n\n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n\n        y_probas (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Cumulative Gains Curve\".\n\n        ax (:class:`matplotlib.axes.Axes`, optional): The axes upon which to\n            plot the learning curve. If None, the plot is drawn on a new set of\n            axes.\n\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"large\".\n\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values. Defaults to\n            \"medium\".\n\n    Returns:\n        ax (:class:`matplotlib.axes.Axes`): The axes on which the plot was\n            drawn.\n\n    Example:\n        >>> import scikitplot as skplt\n        >>> lr = LogisticRegression()\n        >>> lr = lr.fit(X_train, y_train)\n        >>> y_probas = lr.predict_proba(X_test)\n        >>> skplt.metrics.plot_cumulative_gain(y_test, y_probas)\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n        >>> plt.show()\n\n        .. image:: _static/examples/plot_cumulative_gain.png\n           :align: center\n           :alt: Cumulative Gains Plot\n    \"\"\"\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n\n    classes = np.unique(y_true)\n    if len(classes) != 2:\n        raise ValueError('Cannot calculate Cumulative Gains for data with '\n                         '{} category/ies'.format(len(classes)))\n\n    # Compute Cumulative Gain Curves\n    percentages, gains1 = cumulative_gain_curve(y_true, y_probas[:, 0],\n                                                classes[0])\n    percentages, gains2 = cumulative_gain_curve(y_true, y_probas[:, 1],\n                                                classes[1])\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    ax.plot(percentages, gains1, lw=3, label='Class {}'.format(classes[0]))\n    ax.plot(percentages, gains2, lw=3, label='Class {}'.format(classes[1]))\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.0])\n\n    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Baseline')\n\n    ax.set_xlabel('Percentage of sample', fontsize=text_fontsize)\n    ax.set_ylabel('Gain', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.grid('on')\n    ax.legend(loc='lower right', fontsize=text_fontsize)\n\n    return ax", "response": "Generates the cumulative gains plot from the classification and the predicted probabilities of each class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clustering_factory(clf):\n    required_methods = ['fit', 'fit_predict']\n\n    for method in required_methods:\n        if not hasattr(clf, method):\n            raise TypeError('\"{}\" is not in clf. Did you '\n                            'pass a clusterer instance?'.format(method))\n\n    additional_methods = {\n        'plot_silhouette': plot_silhouette,\n        'plot_elbow_curve': plot_elbow_curve\n    }\n\n    for key, fn in six.iteritems(additional_methods):\n        if hasattr(clf, key):\n            warnings.warn('\"{}\" method already in clf. '\n                          'Overriding anyway. This may '\n                          'result in unintended behavior.'.format(key))\n        setattr(clf, key, types.MethodType(fn, clf))\n    return clf", "response": "Creates a new clusterer instance with the same methods as clf."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the labels passed into the true_labels or pred_labels arguments in the plot_confusion_matrix function.", "response": "def validate_labels(known_classes, passed_labels, argument_name):\n    \"\"\"Validates the labels passed into the true_labels or pred_labels\n    arguments in the plot_confusion_matrix function.\n\n    Raises a ValueError exception if any of the passed labels are not in the\n    set of known classes or if there are duplicate labels. Otherwise returns\n    None.\n\n    Args:\n        known_classes (array-like):\n            The classes that are known to appear in the data.\n        passed_labels (array-like):\n            The labels that were passed in through the argument.\n        argument_name (str):\n            The name of the argument being validated.\n\n    Example:\n        >>> known_classes = [\"A\", \"B\", \"C\"]\n        >>> passed_labels = [\"A\", \"B\"]\n        >>> validate_labels(known_classes, passed_labels, \"true_labels\")\n    \"\"\"\n    known_classes = np.array(known_classes)\n    passed_labels = np.array(passed_labels)\n\n    unique_labels, unique_indexes = np.unique(passed_labels, return_index=True)\n\n    if len(passed_labels) != len(unique_labels):\n        indexes = np.arange(0, len(passed_labels))\n        duplicate_indexes = indexes[~np.in1d(indexes, unique_indexes)]\n        duplicate_labels = [str(x) for x in passed_labels[duplicate_indexes]]\n\n        msg = \"The following duplicate labels were passed into {0}: {1}\" \\\n                .format(argument_name, \", \".join(duplicate_labels))\n        raise ValueError(msg)\n\n    passed_labels_absent = ~np.in1d(passed_labels, known_classes)\n\n    if np.any(passed_labels_absent):\n        absent_labels = [str(x) for x in passed_labels[passed_labels_absent]]\n\n        msg = (\"The following labels \"\n               \"were passed into {0}, \"\n               \"but were not found in \"\n               \"labels: {1}\").format(argument_name, \", \".join(absent_labels))\n        raise ValueError(msg)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cumulative_gain_curve(y_true, y_score, pos_label=None):\n    y_true, y_score = np.asarray(y_true), np.asarray(y_score)\n\n    # ensure binary classification if pos_label is not specified\n    classes = np.unique(y_true)\n    if (pos_label is None and\n        not (np.array_equal(classes, [0, 1]) or\n             np.array_equal(classes, [-1, 1]) or\n             np.array_equal(classes, [0]) or\n             np.array_equal(classes, [-1]) or\n             np.array_equal(classes, [1]))):\n        raise ValueError(\"Data is not binary and pos_label is not specified\")\n    elif pos_label is None:\n        pos_label = 1.\n\n    # make y_true a boolean vector\n    y_true = (y_true == pos_label)\n\n    sorted_indices = np.argsort(y_score)[::-1]\n    y_true = y_true[sorted_indices]\n    gains = np.cumsum(y_true)\n\n    percentages = np.arange(start=1, stop=len(y_true) + 1)\n\n    gains = gains / float(np.sum(y_true))\n    percentages = percentages / float(len(y_true))\n\n    gains = np.insert(gains, 0, [0])\n    percentages = np.insert(percentages, 0, [0])\n\n    return percentages, gains", "response": "This function generates the points necessary to plot the Cumulative Gain Chart."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting allure suites from a longname.", "response": "def get_allure_suites(longname):\n    \"\"\"\n    >>> get_allure_suites('Suite1.Test')\n    [Label(name='suite', value='Suite1')]\n    >>> get_allure_suites('Suite1.Suite2.Test') # doctest: +NORMALIZE_WHITESPACE\n    [Label(name='suite', value='Suite1'), Label(name='subSuite', value='Suite2')]\n    >>> get_allure_suites('Suite1.Suite2.Suite3.Test') # doctest: +NORMALIZE_WHITESPACE\n    [Label(name='parentSuite', value='Suite1'),\n    Label(name='suite', value='Suite2'),\n    Label(name='subSuite', value='Suite3')]\n    \"\"\"\n    labels = []\n    suites = longname.split('.')\n    if len(suites) > 3:\n        labels.append(Label(LabelType.PARENT_SUITE, suites.pop(0)))\n    labels.append(Label(LabelType.SUITE, suites.pop(0)))\n    if len(suites) > 1:\n        labels.append(Label(LabelType.SUB_SUITE, '.'.join(suites[:-1])))\n    return labels"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getargspec(func):\n    # noqa: E731 type: (Any) -> Any\n    if inspect.ismethod(func):\n        func = func.__func__\n    parts = 0, ()  # noqa: E731 type: Tuple[int, Tuple[unicode, ...]]\n    if type(func) is partial:\n        keywords = func.keywords\n        if keywords is None:\n            keywords = {}\n        parts = len(func.args), keywords.keys()\n        func = func.func\n    if not inspect.isfunction(func):\n        raise TypeError('%r is not a Python function' % func)\n    args, varargs, varkw = inspect.getargs(func.__code__)\n    func_defaults = func.__defaults__\n    if func_defaults is None:\n        func_defaults = []\n    else:\n        func_defaults = list(func_defaults)\n    if parts[0]:\n        args = args[parts[0]:]\n    if parts[1]:\n        for arg in parts[1]:\n            i = args.index(arg) - len(args)  # type: ignore\n            del args[i]\n            try:\n                del func_defaults[i]\n            except IndexError:\n                pass\n    return inspect.ArgSpec(args, varargs, varkw, func_defaults)", "response": "Get the signature of a function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef represent(item):\n\n    if six.PY2 and isinstance(item, str):\n        try:\n            item = item.decode(encoding='UTF-8')\n        except UnicodeDecodeError:\n            pass\n\n    if isinstance(item, six.text_type):\n        return u'\\'%s\\'' % item\n    elif isinstance(item, (bytes, bytearray)):\n        return repr(type(item))\n    else:\n        return repr(item)", "response": "Returns a unicode string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict containing key - value pairs for a given key used for items like filters page etc.", "response": "def _get_key_values(self, name):\n        \"\"\"Return a dict containing key / values items for a given key, used for items like filters, page, etc.\n\n        :param str name: name of the querystring parameter\n        :return dict: a dict of key / values items\n        \"\"\"\n        results = {}\n\n        for key, value in self.qs.items():\n            try:\n                if not key.startswith(name):\n                    continue\n\n                key_start = key.index('[') + 1\n                key_end = key.index(']')\n                item_key = key[key_start:key_end]\n\n                if ',' in value:\n                    item_value = value.split(',')\n                else:\n                    item_value = value\n                results.update({item_key: item_value})\n            except Exception:\n                raise BadRequest(\"Parse error\", source={'parameter': key})\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn original querystring but containing only managed keys", "response": "def querystring(self):\n        \"\"\"Return original querystring but containing only managed keys\n\n        :return dict: dict of managed querystring parameter\n        \"\"\"\n        return {key: value for (key, value) in self.qs.items()\n                if key.startswith(self.MANAGED_KEYS) or self._get_key_values('filter[')}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filters(self):\n        results = []\n        filters = self.qs.get('filter')\n        if filters is not None:\n            try:\n                results.extend(json.loads(filters))\n            except (ValueError, TypeError):\n                raise InvalidFilters(\"Parse error\")\n        if self._get_key_values('filter['):\n            results.extend(self._simple_filters(self._get_key_values('filter[')))\n        return results", "response": "Return filters from query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pagination(self):\n        # check values type\n        result = self._get_key_values('page')\n        for key, value in result.items():\n            if key not in ('number', 'size'):\n                raise BadRequest(\"{} is not a valid parameter of pagination\".format(key), source={'parameter': 'page'})\n            try:\n                int(value)\n            except ValueError:\n                raise BadRequest(\"Parse error\", source={'parameter': 'page[{}]'.format(key)})\n\n        if current_app.config.get('ALLOW_DISABLE_PAGINATION', True) is False and int(result.get('size', 1)) == 0:\n            raise BadRequest(\"You are not allowed to disable pagination\", source={'parameter': 'page[size]'})\n\n        if current_app.config.get('MAX_PAGE_SIZE') is not None and 'size' in result:\n            if int(result['size']) > current_app.config['MAX_PAGE_SIZE']:\n                raise BadRequest(\"Maximum page size is {}\".format(current_app.config['MAX_PAGE_SIZE']),\n                                 source={'parameter': 'page[size]'})\n\n        return result", "response": "Return all page parameters as a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fields(self):\n        result = self._get_key_values('fields')\n        for key, value in result.items():\n            if not isinstance(value, list):\n                result[key] = [value]\n\n        for key, value in result.items():\n            schema = get_schema_from_type(key)\n            for obj in value:\n                if obj not in schema._declared_fields:\n                    raise InvalidField(\"{} has no attribute {}\".format(schema.__name__, obj))\n\n        return result", "response": "Return fields wanted by client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sorting(self):\n        if self.qs.get('sort'):\n            sorting_results = []\n            for sort_field in self.qs['sort'].split(','):\n                field = sort_field.replace('-', '')\n                if field not in self.schema._declared_fields:\n                    raise InvalidSort(\"{} has no attribute {}\".format(self.schema.__name__, field))\n                if field in get_relationships(self.schema):\n                    raise InvalidSort(\"You can't sort on {} because it is a relationship field\".format(field))\n                field = get_model_field(self.schema, field)\n                order = 'desc' if sort_field.startswith('-') else 'asc'\n                sorting_results.append({'field': field, 'order': order})\n            return sorting_results\n\n        return []", "response": "Return fields to sort by including sort name for SQLAlchemy and row\n        sort parameter for other ORMs\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning fields to include xid", "response": "def include(self):\n        \"\"\"Return fields to include\n\n        :return list: a list of include information\n        \"\"\"\n        include_param = self.qs.get('include', [])\n\n        if current_app.config.get('MAX_INCLUDE_DEPTH') is not None:\n            for include_path in include_param:\n                if len(include_path.split('.')) > current_app.config['MAX_INCLUDE_DEPTH']:\n                    raise InvalidInclude(\"You can't use include through more than {} relationships\"\n                                         .format(current_app.config['MAX_INCLUDE_DEPTH']))\n\n        return include_param.split(',') if include_param else []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_dict(self):\n        error_dict = {}\n        for field in ('status', 'source', 'title', 'detail', 'id', 'code', 'links', 'meta'):\n            if getattr(self, field, None):\n                error_dict.update({field: getattr(self, field)})\n\n        return error_dict", "response": "Return values of each field of an jsonapi error"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch_request(self, *args, **kwargs):\n        method = getattr(self, request.method.lower(), None)\n        if method is None and request.method == 'HEAD':\n            method = getattr(self, 'get', None)\n        assert method is not None, 'Unimplemented method {}'.format(request.method)\n\n        headers = {'Content-Type': 'application/vnd.api+json'}\n\n        response = method(*args, **kwargs)\n\n        if isinstance(response, Response):\n            response.headers.add('Content-Type', 'application/vnd.api+json')\n            return response\n\n        if not isinstance(response, tuple):\n            if isinstance(response, dict):\n                response.update({'jsonapi': {'version': '1.0'}})\n            return make_response(json.dumps(response, cls=JSONEncoder), 200, headers)\n\n        try:\n            data, status_code, headers = response\n            headers.update({'Content-Type': 'application/vnd.api+json'})\n        except ValueError:\n            pass\n\n        try:\n            data, status_code = response\n        except ValueError:\n            pass\n\n        if isinstance(data, dict):\n            data.update({'jsonapi': {'version': '1.0'}})\n\n        return make_response(json.dumps(data, cls=JSONEncoder), status_code, headers)", "response": "Logic of how to handle a request"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a collection of objects", "response": "def get(self, *args, **kwargs):\n        \"\"\"Retrieve a collection of objects\"\"\"\n        self.before_get(args, kwargs)\n\n        qs = QSManager(request.args, self.schema)\n\n        objects_count, objects = self.get_collection(qs, kwargs)\n\n        schema_kwargs = getattr(self, 'get_schema_kwargs', dict())\n        schema_kwargs.update({'many': True})\n\n        self.before_marshmallow(args, kwargs)\n\n        schema = compute_schema(self.schema,\n                                schema_kwargs,\n                                qs,\n                                qs.include)\n\n        result = schema.dump(objects).data\n\n        view_kwargs = request.view_args if getattr(self, 'view_kwargs', None) is True else dict()\n        add_pagination_links(result,\n                             objects_count,\n                             qs,\n                             url_for(self.view, _external=True, **view_kwargs))\n\n        result.update({'meta': {'count': objects_count}})\n\n        final_result = self.after_get(result)\n\n        return final_result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an object in the resource layer", "response": "def patch(self, *args, **kwargs):\n        \"\"\"Update an object\"\"\"\n        json_data = request.get_json() or {}\n\n        qs = QSManager(request.args, self.schema)\n        schema_kwargs = getattr(self, 'patch_schema_kwargs', dict())\n        schema_kwargs.update({'partial': True})\n\n        self.before_marshmallow(args, kwargs)\n\n        schema = compute_schema(self.schema,\n                                schema_kwargs,\n                                qs,\n                                qs.include)\n\n        try:\n            data, errors = schema.load(json_data)\n        except IncorrectTypeError as e:\n            errors = e.messages\n            for error in errors['errors']:\n                error['status'] = '409'\n                error['title'] = \"Incorrect type\"\n            return errors, 409\n        except ValidationError as e:\n            errors = e.messages\n            for message in errors['errors']:\n                message['status'] = '422'\n                message['title'] = \"Validation error\"\n            return errors, 422\n\n        if errors:\n            for error in errors['errors']:\n                error['status'] = \"422\"\n                error['title'] = \"Validation error\"\n            return errors, 422\n\n        if 'id' not in json_data['data']:\n            raise BadRequest('Missing id in \"data\" node',\n                             source={'pointer': '/data/id'})\n        if (str(json_data['data']['id']) != str(kwargs[getattr(self._data_layer, 'url_field', 'id')])):\n            raise BadRequest('Value of id does not match the resource identifier in url',\n                             source={'pointer': '/data/id'})\n\n        self.before_patch(args, kwargs, data=data)\n\n        obj = self.update_object(data, qs, kwargs)\n\n        result = schema.dump(obj).data\n\n        final_result = self.after_patch(result)\n\n        return final_result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, *args, **kwargs):\n        self.before_get(args, kwargs)\n\n        relationship_field, model_relationship_field, related_type_, related_id_field = self._get_relationship_data()\n\n        obj, data = self._data_layer.get_relationship(model_relationship_field,\n                                                      related_type_,\n                                                      related_id_field,\n                                                      kwargs)\n\n        result = {'links': {'self': request.path,\n                            'related': self.schema._declared_fields[relationship_field].get_related_url(obj)},\n                  'data': data}\n\n        qs = QSManager(request.args, self.schema)\n        if qs.include:\n            schema = compute_schema(self.schema, dict(), qs, qs.include)\n\n            serialized_obj = schema.dump(obj)\n            result['included'] = serialized_obj.data.get('included', dict())\n\n        final_result = self.after_get(result)\n\n        return final_result", "response": "Get a relationship details"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, *args, **kwargs):\n        json_data = request.get_json() or {}\n\n        relationship_field, model_relationship_field, related_type_, related_id_field = self._get_relationship_data()\n\n        if 'data' not in json_data:\n            raise BadRequest('You must provide data with a \"data\" route node', source={'pointer': '/data'})\n        if isinstance(json_data['data'], dict):\n            if 'type' not in json_data['data']:\n                raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n            if 'id' not in json_data['data']:\n                raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n            if json_data['data']['type'] != related_type_:\n                raise InvalidType('The type field does not match the resource type', source={'pointer': '/data/type'})\n        if isinstance(json_data['data'], list):\n            for obj in json_data['data']:\n                if 'type' not in obj:\n                    raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n                if 'id' not in obj:\n                    raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n                if obj['type'] != related_type_:\n                    raise InvalidType('The type provided does not match the resource type',\n                                      source={'pointer': '/data/type'})\n\n        self.before_post(args, kwargs, json_data=json_data)\n\n        obj_, updated = self._data_layer.create_relationship(json_data,\n                                                             model_relationship_field,\n                                                             related_id_field,\n                                                             kwargs)\n\n        status_code = 200\n        result = {'meta': {'message': 'Relationship successfully created'}}\n\n        if updated is False:\n            result = ''\n            status_code = 204\n\n        final_result = self.after_post(result, status_code)\n\n        return final_result", "response": "Add / create relationship"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch(self, *args, **kwargs):\n        json_data = request.get_json() or {}\n\n        relationship_field, model_relationship_field, related_type_, related_id_field = self._get_relationship_data()\n\n        if 'data' not in json_data:\n            raise BadRequest('You must provide data with a \"data\" route node', source={'pointer': '/data'})\n        if isinstance(json_data['data'], dict):\n            if 'type' not in json_data['data']:\n                raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n            if 'id' not in json_data['data']:\n                raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n            if json_data['data']['type'] != related_type_:\n                raise InvalidType('The type field does not match the resource type', source={'pointer': '/data/type'})\n        if isinstance(json_data['data'], list):\n            for obj in json_data['data']:\n                if 'type' not in obj:\n                    raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n                if 'id' not in obj:\n                    raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n                if obj['type'] != related_type_:\n                    raise InvalidType('The type provided does not match the resource type',\n                                      source={'pointer': '/data/type'})\n\n        self.before_patch(args, kwargs, json_data=json_data)\n\n        obj_, updated = self._data_layer.update_relationship(json_data,\n                                                             model_relationship_field,\n                                                             related_id_field,\n                                                             kwargs)\n\n        status_code = 200\n        result = {'meta': {'message': 'Relationship successfully updated'}}\n\n        if updated is False:\n            result = ''\n            status_code = 204\n\n        final_result = self.after_patch(result, status_code)\n\n        return final_result", "response": "Update a resource in the resource layer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, *args, **kwargs):\n        json_data = request.get_json() or {}\n\n        relationship_field, model_relationship_field, related_type_, related_id_field = self._get_relationship_data()\n\n        if 'data' not in json_data:\n            raise BadRequest('You must provide data with a \"data\" route node', source={'pointer': '/data'})\n        if isinstance(json_data['data'], dict):\n            if 'type' not in json_data['data']:\n                raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n            if 'id' not in json_data['data']:\n                raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n            if json_data['data']['type'] != related_type_:\n                raise InvalidType('The type field does not match the resource type', source={'pointer': '/data/type'})\n        if isinstance(json_data['data'], list):\n            for obj in json_data['data']:\n                if 'type' not in obj:\n                    raise BadRequest('Missing type in \"data\" node', source={'pointer': '/data/type'})\n                if 'id' not in obj:\n                    raise BadRequest('Missing id in \"data\" node', source={'pointer': '/data/id'})\n                if obj['type'] != related_type_:\n                    raise InvalidType('The type provided does not match the resource type',\n                                      source={'pointer': '/data/type'})\n\n        self.before_delete(args, kwargs, json_data=json_data)\n\n        obj_, updated = self._data_layer.delete_relationship(json_data,\n                                                             model_relationship_field,\n                                                             related_id_field,\n                                                             kwargs)\n\n        status_code = 200\n        result = {'meta': {'message': 'Relationship successfully updated'}}\n\n        if updated is False:\n            result = ''\n            status_code = 204\n\n        final_result = self.after_delete(result, status_code)\n\n        return final_result", "response": "Delete a resource from the resource layer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting useful data for relationship management", "response": "def _get_relationship_data(self):\n        \"\"\"Get useful data for relationship management\"\"\"\n        relationship_field = request.path.split('/')[-1].replace('-', '_')\n\n        if relationship_field not in get_relationships(self.schema):\n            raise RelationNotFound(\"{} has no attribute {}\".format(self.schema.__name__, relationship_field))\n\n        related_type_ = self.schema._declared_fields[relationship_field].type_\n        related_id_field = self.schema._declared_fields[relationship_field].id_field\n        model_relationship_field = get_model_field(self.schema, relationship_field)\n\n        return relationship_field, model_relationship_field, related_type_, related_id_field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_schema(schema_cls, default_kwargs, qs, include):\n    # manage include_data parameter of the schema\n    schema_kwargs = default_kwargs\n    schema_kwargs['include_data'] = tuple()\n\n    # collect sub-related_includes\n    related_includes = {}\n\n    if include:\n        for include_path in include:\n            field = include_path.split('.')[0]\n\n            if field not in schema_cls._declared_fields:\n                raise InvalidInclude(\"{} has no attribute {}\".format(schema_cls.__name__, field))\n            elif not isinstance(schema_cls._declared_fields[field], Relationship):\n                raise InvalidInclude(\"{} is not a relationship attribute of {}\".format(field, schema_cls.__name__))\n\n            schema_kwargs['include_data'] += (field, )\n            if field not in related_includes:\n                related_includes[field] = []\n            if '.' in include_path:\n                related_includes[field] += ['.'.join(include_path.split('.')[1:])]\n\n    # make sure id field is in only parameter unless marshamllow will raise an Exception\n    if schema_kwargs.get('only') is not None and 'id' not in schema_kwargs['only']:\n        schema_kwargs['only'] += ('id',)\n\n    # create base schema instance\n    schema = schema_cls(**schema_kwargs)\n\n    # manage sparse fieldsets\n    if schema.opts.type_ in qs.fields:\n        tmp_only = set(schema.declared_fields.keys()) & set(qs.fields[schema.opts.type_])\n        if schema.only:\n            tmp_only &= set(schema.only)\n        schema.only = tuple(tmp_only)\n\n        # make sure again that id field is in only parameter unless marshamllow will raise an Exception\n        if schema.only is not None and 'id' not in schema.only:\n            schema.only += ('id',)\n\n    # manage compound documents\n    if include:\n        for include_path in include:\n            field = include_path.split('.')[0]\n            relation_field = schema.declared_fields[field]\n            related_schema_cls = schema.declared_fields[field].__dict__['_Relationship__schema']\n            related_schema_kwargs = {}\n            if 'context' in default_kwargs:\n                related_schema_kwargs['context'] = default_kwargs['context']\n            if isinstance(related_schema_cls, SchemaABC):\n                related_schema_kwargs['many'] = related_schema_cls.many\n                related_schema_cls = related_schema_cls.__class__\n            if isinstance(related_schema_cls, str):\n                related_schema_cls = class_registry.get_class(related_schema_cls)\n            related_schema = compute_schema(related_schema_cls,\n                                            related_schema_kwargs,\n                                            qs,\n                                            related_includes[field] or None)\n            relation_field.__dict__['_Relationship__schema'] = related_schema\n\n    return schema", "response": "Compute a schema around compound documents and sparse fieldsets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the model field of a schema field", "response": "def get_model_field(schema, field):\n    \"\"\"Get the model field of a schema field\n\n    :param Schema schema: a marshmallow schema\n    :param str field: the name of the schema field\n    :return str: the name of the field in the model\n    \"\"\"\n    if schema._declared_fields.get(field) is None:\n        raise Exception(\"{} has no attribute {}\".format(schema.__name__, field))\n\n    if schema._declared_fields[field].attribute is not None:\n        return schema._declared_fields[field].attribute\n    return field"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_nested_fields(schema, model_field=False):\n\n    nested_fields = []\n    for (key, value) in schema._declared_fields.items():\n        if isinstance(value, List) and isinstance(value.container, Nested):\n            nested_fields.append(key)\n        elif isinstance(value, Nested):\n            nested_fields.append(key)\n\n    if model_field is True:\n        nested_fields = [get_model_field(schema, key) for key in nested_fields]\n\n    return nested_fields", "response": "Return a list of nested fields of a schema to support a join\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_relationships(schema, model_field=False):\n    relationships = [key for (key, value) in schema._declared_fields.items() if isinstance(value, Relationship)]\n\n    if model_field is True:\n        relationships = [get_model_field(schema, key) for key in relationships]\n\n    return relationships", "response": "Return a list of relationship fields of a schema\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a schema from the registry by his type", "response": "def get_schema_from_type(resource_type):\n    \"\"\"Retrieve a schema from the registry by his type\n\n    :param str type_: the type of the resource\n    :return Schema: the schema class\n    \"\"\"\n    for cls_name, cls in class_registry._registry.items():\n        try:\n            if cls[0].opts.type_ == resource_type:\n                return cls[0]\n        except Exception:\n            pass\n\n    raise Exception(\"Couldn't find schema for type: {}\".format(resource_type))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_schema_field(schema, field):\n    schema_fields_to_model = {key: get_model_field(schema, key) for (key, value) in schema._declared_fields.items()}\n    for key, value in schema_fields_to_model.items():\n        if value == field:\n            return key\n\n    raise Exception(\"Couldn't find schema field from {}\".format(field))", "response": "Get the schema field of a model field"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbinding additional methods to current instance", "response": "def bound_rewritable_methods(self, methods):\n        \"\"\"Bound additional methods to current instance\n\n        :param class meta: information from Meta class used to configure the data layer instance\n        \"\"\"\n        for key, value in methods.items():\n            if key in self.REWRITABLE_METHODS:\n                setattr(self, key, types.MethodType(value, self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_filters(model, filter_info, resource):\n    filters = []\n    for filter_ in filter_info:\n        filters.append(Node(model, filter_, resource, resource.schema).resolve())\n\n    return filters", "response": "Create a list of nodes that match the given filters information."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve(self):\n        if 'or' not in self.filter_ and 'and' not in self.filter_ and 'not' not in self.filter_:\n            value = self.value\n\n            if isinstance(value, dict):\n                value = Node(self.related_model, value, self.resource, self.related_schema).resolve()\n\n            if '__' in self.filter_.get('name', ''):\n                value = {self.filter_['name'].split('__')[1]: value}\n\n            if isinstance(value, dict):\n                return getattr(self.column, self.operator)(**value)\n            else:\n                return getattr(self.column, self.operator)(value)\n\n        if 'or' in self.filter_:\n            return or_(Node(self.model, filt, self.resource, self.schema).resolve() for filt in self.filter_['or'])\n        if 'and' in self.filter_:\n            return and_(Node(self.model, filt, self.resource, self.schema).resolve() for filt in self.filter_['and'])\n        if 'not' in self.filter_:\n            return not_(Node(self.model, self.filter_['not'], self.resource, self.schema).resolve())", "response": "Create filter for a particular node of the filter tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self):\n        name = self.filter_.get('name')\n\n        if name is None:\n            raise InvalidFilters(\"Can't find name of a filter\")\n\n        if '__' in name:\n            name = name.split('__')[0]\n\n        if name not in self.schema._declared_fields:\n            raise InvalidFilters(\"{} has no attribute {}\".format(self.schema.__name__, name))\n\n        return name", "response": "Return the name of the node or raise a BadRequest exception\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef column(self):\n        field = self.name\n\n        model_field = get_model_field(self.schema, field)\n\n        try:\n            return getattr(self.model, model_field)\n        except AttributeError:\n            raise InvalidFilters(\"{} has no attribute {}\".format(self.model.__name__, model_field))", "response": "Get the column object holding the object s metadata"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the function operator from his name", "response": "def operator(self):\n        \"\"\"Get the function operator from his name\n\n        :return callable: a callable to make operation on a column\n        \"\"\"\n        operators = (self.op, self.op + '_', '__' + self.op + '__')\n\n        for op in operators:\n            if hasattr(self.column, op):\n                return op\n\n        raise InvalidFilters(\"{} has no operator {}\".format(self.column.key, self.op))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self):\n        if self.filter_.get('field') is not None:\n            try:\n                result = getattr(self.model, self.filter_['field'])\n            except AttributeError:\n                raise InvalidFilters(\"{} has no attribute {}\".format(self.model.__name__, self.filter_['field']))\n            else:\n                return result\n        else:\n            if 'val' not in self.filter_:\n                raise InvalidFilters(\"Can't find value or field in a filter\")\n\n            return self.filter_['val']", "response": "Get the value to filter on\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the related model of a relationship field", "response": "def related_model(self):\n        \"\"\"Get the related model of a relationship field\n\n        :return DeclarativeMeta: the related model\n        \"\"\"\n        relationship_field = self.name\n\n        if relationship_field not in get_relationships(self.schema):\n            raise InvalidFilters(\"{} has no relationship attribute {}\".format(self.schema.__name__, relationship_field))\n\n        return getattr(self.model, get_model_field(self.schema, relationship_field)).property.mapper.class_"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef related_schema(self):\n        relationship_field = self.name\n\n        if relationship_field not in get_relationships(self.schema):\n            raise InvalidFilters(\"{} has no relationship attribute {}\".format(self.schema.__name__, relationship_field))\n\n        return self.schema._declared_fields[relationship_field].schema.__class__", "response": "Get the related schema of a relationship field\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_app(self, app=None, blueprint=None, additional_blueprints=None):\n        if app is not None:\n            self.app = app\n\n        if blueprint is not None:\n            self.blueprint = blueprint\n\n        for resource in self.resources:\n            self.route(resource['resource'],\n                       resource['view'],\n                       *resource['urls'],\n                       url_rule_options=resource['url_rule_options'])\n\n        if self.blueprint is not None:\n            self.app.register_blueprint(self.blueprint)\n\n        if additional_blueprints is not None:\n            for blueprint in additional_blueprints:\n                self.app.register_blueprint(blueprint)\n\n        self.app.config.setdefault('PAGE_SIZE', 30)", "response": "Initialize the flask application with our api"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef route(self, resource, view, *urls, **kwargs):\n        resource.view = view\n        url_rule_options = kwargs.get('url_rule_options') or dict()\n\n        view_func = resource.as_view(view)\n\n        if 'blueprint' in kwargs:\n            resource.view = '.'.join([kwargs['blueprint'].name, resource.view])\n            for url in urls:\n                kwargs['blueprint'].add_url_rule(url, view_func=view_func, **url_rule_options)\n        elif self.blueprint is not None:\n            resource.view = '.'.join([self.blueprint.name, resource.view])\n            for url in urls:\n                self.blueprint.add_url_rule(url, view_func=view_func, **url_rule_options)\n        elif self.app is not None:\n            for url in urls:\n                self.app.add_url_rule(url, view_func=view_func, **url_rule_options)\n        else:\n            self.resources.append({'resource': resource,\n                                   'view': view,\n                                   'urls': urls,\n                                   'url_rule_options': url_rule_options})\n\n        self.resource_registry.append(resource)", "response": "Create an api view."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses the oauth manager to enable oauth for API", "response": "def oauth_manager(self, oauth_manager):\n        \"\"\"Use the oauth manager to enable oauth for API\n\n        :param oauth_manager: the oauth manager\n        \"\"\"\n        @self.app.before_request\n        def before_request():\n            endpoint = request.endpoint\n            resource = self.app.view_functions[endpoint].view_class\n\n            if not getattr(resource, 'disable_oauth'):\n                scopes = request.args.get('scopes')\n\n                if getattr(resource, 'schema'):\n                    scopes = [self.build_scope(resource, request.method)]\n                elif scopes:\n                    scopes = scopes.split(',')\n\n                    if scopes:\n                        scopes = scopes.split(',')\n\n                valid, req = oauth_manager.verify_request(scopes)\n\n                for func in oauth_manager._after_request_funcs:\n                    valid, req = func(valid, req)\n\n                if not valid:\n                    if oauth_manager._invalid_response:\n                        return oauth_manager._invalid_response(req)\n                    return abort(401)\n\n                request.oauth = req"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the name of the scope for oauth", "response": "def build_scope(resource, method):\n        \"\"\"Compute the name of the scope for oauth\n\n        :param Resource resource: the resource manager\n        :param str method: an http method\n        :return str: the name of the scope\n        \"\"\"\n        if ResourceList in inspect.getmro(resource) and method == 'GET':\n            prefix = 'list'\n        else:\n            method_to_prefix = {'GET': 'get',\n                                'POST': 'create',\n                                'PATCH': 'update',\n                                'DELETE': 'delete'}\n            prefix = method_to_prefix[method]\n\n            if ResourceRelationship in inspect.getmro(resource):\n                prefix = '_'.join([prefix, 'relationship'])\n\n        return '_'.join([prefix, resource.schema.opts.type_])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permission_manager(self, permission_manager):\n        self.check_permissions = permission_manager\n\n        for resource in self.resource_registry:\n            if getattr(resource, 'disable_permission', None) is not True:\n                for method in getattr(resource, 'methods', ('GET', 'POST', 'PATCH', 'DELETE')):\n                    setattr(resource,\n                            method.lower(),\n                            self.has_permission()(getattr(resource, method.lower())))", "response": "Use permission manager to enable permission for API\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks headers according to jsonapi reference :param callable func: the function to decorate :return callable: the wrapped function", "response": "def check_headers(func):\n    \"\"\"Check headers according to jsonapi reference\n\n    :param callable func: the function to decorate\n    :return callable: the wrapped function\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if request.method in ('POST', 'PATCH'):\n            if 'Content-Type' in request.headers and\\\n                    'application/vnd.api+json' in request.headers['Content-Type'] and\\\n                    request.headers['Content-Type'] != 'application/vnd.api+json':\n                error = json.dumps(jsonapi_errors([{'source': '',\n                                                    'detail': \"Content-Type header must be application/vnd.api+json\",\n                                                    'title': 'Invalid request header',\n                                                    'status': '415'}]), cls=JSONEncoder)\n                return make_response(error, 415, {'Content-Type': 'application/vnd.api+json'})\n        if 'Accept' in request.headers:\n            flag = False\n            for accept in request.headers['Accept'].split(','):\n                if accept.strip() == 'application/vnd.api+json':\n                    flag = False\n                    break\n                if 'application/vnd.api+json' in accept and accept.strip() != 'application/vnd.api+json':\n                    flag = True\n            if flag is True:\n                error = json.dumps(jsonapi_errors([{'source': '',\n                                                    'detail': ('Accept header must be application/vnd.api+json without'\n                                                               'media type parameters'),\n                                                    'title': 'Invalid request header',\n                                                    'status': '406'}]), cls=JSONEncoder)\n                return make_response(error, 406, {'Content-Type': 'application/vnd.api+json'})\n        return func(*args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks methods requirements :param callable func: the function to decorate :return callable: the wrapped function", "response": "def check_method_requirements(func):\n    \"\"\"Check methods requirements\n\n    :param callable func: the function to decorate\n    :return callable: the wrapped function\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        error_message = \"You must provide {error_field} in {cls} to get access to the default {method} method\"\n        error_data = {'cls': args[0].__class__.__name__, 'method': request.method.lower()}\n\n        if request.method != 'DELETE':\n            if not hasattr(args[0], 'schema'):\n                error_data.update({'error_field': 'a schema class'})\n                raise Exception(error_message.format(**error_data))\n\n        return func(*args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an object through sqlalchemy", "response": "def create_object(self, data, view_kwargs):\n        \"\"\"Create an object through sqlalchemy\n\n        :param dict data: the data validated by marshmallow\n        :param dict view_kwargs: kwargs from the resource view\n        :return DeclarativeMeta: an object from sqlalchemy\n        \"\"\"\n        self.before_create_object(data, view_kwargs)\n\n        relationship_fields = get_relationships(self.resource.schema, model_field=True)\n        nested_fields = get_nested_fields(self.resource.schema, model_field=True)\n\n        join_fields = relationship_fields + nested_fields\n\n        obj = self.model(**{key: value\n                            for (key, value) in data.items() if key not in join_fields})\n        self.apply_relationships(data, obj)\n        self.apply_nested_fields(data, obj)\n\n        self.session.add(obj)\n        try:\n            self.session.commit()\n        except JsonApiException as e:\n            self.session.rollback()\n            raise e\n        except Exception as e:\n            self.session.rollback()\n            raise JsonApiException(\"Object creation error: \" + str(e), source={'pointer': '/data'})\n\n        self.after_create_object(obj, data, view_kwargs)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_object(self, view_kwargs, qs=None):\n        self.before_get_object(view_kwargs)\n\n        id_field = getattr(self, 'id_field', inspect(self.model).primary_key[0].key)\n        try:\n            filter_field = getattr(self.model, id_field)\n        except Exception:\n            raise Exception(\"{} has no attribute {}\".format(self.model.__name__, id_field))\n\n        url_field = getattr(self, 'url_field', 'id')\n        filter_value = view_kwargs[url_field]\n\n        query = self.retrieve_object_query(view_kwargs, filter_field, filter_value)\n\n        if qs is not None:\n            query = self.eagerload_includes(query, qs)\n\n        try:\n            obj = query.one()\n        except NoResultFound:\n            obj = None\n\n        self.after_get_object(obj, view_kwargs)\n\n        return obj", "response": "Retrieve an object through sqlalchemy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_collection(self, qs, view_kwargs):\n        self.before_get_collection(qs, view_kwargs)\n\n        query = self.query(view_kwargs)\n\n        if qs.filters:\n            query = self.filter_query(query, qs.filters, self.model)\n\n        if qs.sorting:\n            query = self.sort_query(query, qs.sorting)\n\n        object_count = query.count()\n\n        if getattr(self, 'eagerload_includes', True):\n            query = self.eagerload_includes(query, qs)\n\n        query = self.paginate_query(query, qs.pagination)\n\n        collection = query.all()\n\n        collection = self.after_get_collection(collection, qs, view_kwargs)\n\n        return object_count, collection", "response": "Retrieve a collection of objects through sqlalchemy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an object through sqlalchemy", "response": "def update_object(self, obj, data, view_kwargs):\n        \"\"\"Update an object through sqlalchemy\n\n        :param DeclarativeMeta obj: an object from sqlalchemy\n        :param dict data: the data validated by marshmallow\n        :param dict view_kwargs: kwargs from the resource view\n        :return boolean: True if object have changed else False\n        \"\"\"\n        if obj is None:\n            url_field = getattr(self, 'url_field', 'id')\n            filter_value = view_kwargs[url_field]\n            raise ObjectNotFound('{}: {} not found'.format(self.model.__name__, filter_value),\n                                 source={'parameter': url_field})\n\n        self.before_update_object(obj, data, view_kwargs)\n\n        relationship_fields = get_relationships(self.resource.schema, model_field=True)\n        nested_fields = get_nested_fields(self.resource.schema, model_field=True)\n\n        join_fields = relationship_fields + nested_fields\n\n        for key, value in data.items():\n            if hasattr(obj, key) and key not in join_fields:\n                setattr(obj, key, value)\n\n        self.apply_relationships(data, obj)\n        self.apply_nested_fields(data, obj)\n\n        try:\n            self.session.commit()\n        except JsonApiException as e:\n            self.session.rollback()\n            raise e\n        except Exception as e:\n            self.session.rollback()\n            raise JsonApiException(\"Update object error: \" + str(e), source={'pointer': '/data'})\n\n        self.after_update_object(obj, data, view_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_object(self, obj, view_kwargs):\n        if obj is None:\n            url_field = getattr(self, 'url_field', 'id')\n            filter_value = view_kwargs[url_field]\n            raise ObjectNotFound('{}: {} not found'.format(self.model.__name__, filter_value),\n                                 source={'parameter': url_field})\n\n        self.before_delete_object(obj, view_kwargs)\n\n        self.session.delete(obj)\n        try:\n            self.session.commit()\n        except JsonApiException as e:\n            self.session.rollback()\n            raise e\n        except Exception as e:\n            self.session.rollback()\n            raise JsonApiException(\"Delete object error: \" + str(e))\n\n        self.after_delete_object(obj, view_kwargs)", "response": "Delete an object through sqlalchemy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_relationship(self, json_data, relationship_field, related_id_field, view_kwargs):\n        self.before_create_relationship(json_data, relationship_field, related_id_field, view_kwargs)\n\n        obj = self.get_object(view_kwargs)\n\n        if obj is None:\n            url_field = getattr(self, 'url_field', 'id')\n            filter_value = view_kwargs[url_field]\n            raise ObjectNotFound('{}: {} not found'.format(self.model.__name__, filter_value),\n                                 source={'parameter': url_field})\n\n        if not hasattr(obj, relationship_field):\n            raise RelationNotFound(\"{} has no attribute {}\".format(obj.__class__.__name__, relationship_field))\n\n        related_model = getattr(obj.__class__, relationship_field).property.mapper.class_\n\n        updated = False\n\n        if isinstance(json_data['data'], list):\n            obj_ids = {str(getattr(obj__, related_id_field)) for obj__ in getattr(obj, relationship_field)}\n\n            for obj_ in json_data['data']:\n                if obj_['id'] not in obj_ids:\n                    getattr(obj,\n                            relationship_field).append(self.get_related_object(related_model, related_id_field, obj_))\n                    updated = True\n        else:\n            related_object = None\n\n            if json_data['data'] is not None:\n                related_object = self.get_related_object(related_model, related_id_field, json_data['data'])\n\n            obj_id = getattr(getattr(obj, relationship_field), related_id_field, None)\n            new_obj_id = getattr(related_object, related_id_field, None)\n            if obj_id != new_obj_id:\n                setattr(obj, relationship_field, related_object)\n                updated = True\n\n        try:\n            self.session.commit()\n        except JsonApiException as e:\n            self.session.rollback()\n            raise e\n        except Exception as e:\n            self.session.rollback()\n            raise JsonApiException(\"Create relationship error: \" + str(e))\n\n        self.after_create_relationship(obj, updated, json_data, relationship_field, related_id_field, view_kwargs)\n\n        return obj, updated", "response": "Create a relationship between the resource and the related object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relationship(self, relationship_field, related_type_, related_id_field, view_kwargs):\n        self.before_get_relationship(relationship_field, related_type_, related_id_field, view_kwargs)\n\n        obj = self.get_object(view_kwargs)\n\n        if obj is None:\n            url_field = getattr(self, 'url_field', 'id')\n            filter_value = view_kwargs[url_field]\n            raise ObjectNotFound('{}: {} not found'.format(self.model.__name__, filter_value),\n                                 source={'parameter': url_field})\n\n        if not hasattr(obj, relationship_field):\n            raise RelationNotFound(\"{} has no attribute {}\".format(obj.__class__.__name__, relationship_field))\n\n        related_objects = getattr(obj, relationship_field)\n\n        if related_objects is None:\n            return obj, related_objects\n\n        self.after_get_relationship(obj, related_objects, relationship_field, related_type_, related_id_field,\n                                    view_kwargs)\n\n        if isinstance(related_objects, InstrumentedList):\n            return obj,\\\n                [{'type': related_type_, 'id': getattr(obj_, related_id_field)} for obj_ in related_objects]\n        else:\n            return obj, {'type': related_type_, 'id': getattr(related_objects, related_id_field)}", "response": "Get a relationship between the object and related object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_relationship(self, json_data, relationship_field, related_id_field, view_kwargs):\n        self.before_delete_relationship(json_data, relationship_field, related_id_field, view_kwargs)\n\n        obj = self.get_object(view_kwargs)\n\n        if obj is None:\n            url_field = getattr(self, 'url_field', 'id')\n            filter_value = view_kwargs[url_field]\n            raise ObjectNotFound('{}: {} not found'.format(self.model.__name__, filter_value),\n                                 source={'parameter': url_field})\n\n        if not hasattr(obj, relationship_field):\n            raise RelationNotFound(\"{} has no attribute {}\".format(obj.__class__.__name__, relationship_field))\n\n        related_model = getattr(obj.__class__, relationship_field).property.mapper.class_\n\n        updated = False\n\n        if isinstance(json_data['data'], list):\n            obj_ids = {str(getattr(obj__, related_id_field)) for obj__ in getattr(obj, relationship_field)}\n\n            for obj_ in json_data['data']:\n                if obj_['id'] in obj_ids:\n                    getattr(obj,\n                            relationship_field).remove(self.get_related_object(related_model, related_id_field, obj_))\n                    updated = True\n        else:\n            setattr(obj, relationship_field, None)\n            updated = True\n\n        try:\n            self.session.commit()\n        except JsonApiException as e:\n            self.session.rollback()\n            raise e\n        except Exception as e:\n            self.session.rollback()\n            raise JsonApiException(\"Delete relationship error: \" + str(e))\n\n        self.after_delete_relationship(obj, updated, json_data, relationship_field, related_id_field, view_kwargs)\n\n        return obj, updated", "response": "Delete a resource from the resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a related object from the sqlalchemy object", "response": "def get_related_object(self, related_model, related_id_field, obj):\n        \"\"\"Get a related object\n\n        :param Model related_model: an sqlalchemy model\n        :param str related_id_field: the identifier field of the related model\n        :param DeclarativeMeta obj: the sqlalchemy object to retrieve related objects from\n        :return DeclarativeMeta: a related object\n        \"\"\"\n        try:\n            related_object = self.session.query(related_model)\\\n                                         .filter(getattr(related_model, related_id_field) == obj['id'])\\\n                                         .one()\n        except NoResultFound:\n            raise RelatedObjectNotFound(\"{}.{}: {} not found\".format(related_model.__name__,\n                                                                     related_id_field,\n                                                                     obj['id']))\n\n        return related_object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies relationship provided by data to obj InUse", "response": "def apply_relationships(self, data, obj):\n        \"\"\"Apply relationship provided by data to obj\n\n        :param dict data: data provided by the client\n        :param DeclarativeMeta obj: the sqlalchemy object to plug relationships to\n        :return boolean: True if relationship have changed else False\n        \"\"\"\n        relationships_to_apply = []\n        relationship_fields = get_relationships(self.resource.schema, model_field=True)\n        for key, value in data.items():\n            if key in relationship_fields:\n                related_model = getattr(obj.__class__, key).property.mapper.class_\n                schema_field = get_schema_field(self.resource.schema, key)\n                related_id_field = self.resource.schema._declared_fields[schema_field].id_field\n\n                if isinstance(value, list):\n                    related_objects = []\n\n                    for identifier in value:\n                        related_object = self.get_related_object(related_model, related_id_field, {'id': identifier})\n                        related_objects.append(related_object)\n\n                    relationships_to_apply.append({'field': key, 'value': related_objects})\n                else:\n                    related_object = None\n\n                    if value is not None:\n                        related_object = self.get_related_object(related_model, related_id_field, {'id': value})\n\n                    relationships_to_apply.append({'field': key, 'value': related_object})\n\n        for relationship in relationships_to_apply:\n            setattr(obj, relationship['field'], relationship['value'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_query(self, query, filter_info, model):\n        if filter_info:\n            filters = create_filters(model, filter_info, self.resource)\n            query = query.filter(*filters)\n\n        return query", "response": "Filter the query according to jsonapi 1. 0\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsort query according to jsonapi 1. 0", "response": "def sort_query(self, query, sort_info):\n        \"\"\"Sort query according to jsonapi 1.0\n\n        :param Query query: sqlalchemy query to sort\n        :param list sort_info: sort information\n        :return Query: the sorted query\n        \"\"\"\n        for sort_opt in sort_info:\n            field = sort_opt['field']\n            if not hasattr(self.model, field):\n                raise InvalidSort(\"{} has no attribute {}\".format(self.model.__name__, field))\n            query = query.order_by(getattr(getattr(self.model, field), sort_opt['order'])())\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npaginating query according to jsonapi 1. 0", "response": "def paginate_query(self, query, paginate_info):\n        \"\"\"Paginate query according to jsonapi 1.0\n\n        :param Query query: sqlalchemy queryset\n        :param dict paginate_info: pagination information\n        :return Query: the paginated query\n        \"\"\"\n        if int(paginate_info.get('size', 1)) == 0:\n            return query\n\n        page_size = int(paginate_info.get('size', 0)) or current_app.config['PAGE_SIZE']\n        query = query.limit(page_size)\n        if paginate_info.get('number'):\n            query = query.offset((int(paginate_info['number']) - 1) * page_size)\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses eagerload feature of sqlalchemy to optimize data retrieval for include querystring parameter", "response": "def eagerload_includes(self, query, qs):\n        \"\"\"Use eagerload feature of sqlalchemy to optimize data retrieval for include querystring parameter\n\n        :param Query query: sqlalchemy queryset\n        :param QueryStringManager qs: a querystring manager to retrieve information from url\n        :return Query: the query with includes eagerloaded\n        \"\"\"\n        for include in qs.include:\n            joinload_object = None\n\n            if '.' in include:\n                current_schema = self.resource.schema\n                for obj in include.split('.'):\n                    try:\n                        field = get_model_field(current_schema, obj)\n                    except Exception as e:\n                        raise InvalidInclude(str(e))\n\n                    if joinload_object is None:\n                        joinload_object = joinedload(field)\n                    else:\n                        joinload_object = joinload_object.joinedload(field)\n\n                    related_schema_cls = get_related_schema(current_schema, obj)\n\n                    if isinstance(related_schema_cls, SchemaABC):\n                        related_schema_cls = related_schema_cls.__class__\n                    else:\n                        related_schema_cls = class_registry.get_class(related_schema_cls)\n\n                    current_schema = related_schema_cls\n            else:\n                try:\n                    field = get_model_field(self.resource.schema, include)\n                except Exception as e:\n                    raise InvalidInclude(str(e))\n\n                joinload_object = joinedload(field)\n\n            query = query.options(joinload_object)\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a query to retrieve the object by the field and value", "response": "def retrieve_object_query(self, view_kwargs, filter_field, filter_value):\n        \"\"\"Build query to retrieve object\n\n        :param dict view_kwargs: kwargs from the resource view\n        :params sqlalchemy_field filter_field: the field to filter on\n        :params filter_value: the value to filter with\n        :return sqlalchemy query: a query from sqlalchemy\n        \"\"\"\n        return self.session.query(self.model).filter(filter_field == filter_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_pagination_links(data, object_count, querystring, base_url):\n    links = {}\n    all_qs_args = copy(querystring.querystring)\n\n    links['self'] = base_url\n\n    # compute self link\n    if all_qs_args:\n        links['self'] += '?' + urlencode(all_qs_args)\n\n    if querystring.pagination.get('size') != '0' and object_count > 1:\n        # compute last link\n        page_size = int(querystring.pagination.get('size', 0)) or current_app.config['PAGE_SIZE']\n        last_page = int(ceil(object_count / page_size))\n\n        if last_page > 1:\n            links['first'] = links['last'] = base_url\n\n            all_qs_args.pop('page[number]', None)\n\n            # compute first link\n            if all_qs_args:\n                links['first'] += '?' + urlencode(all_qs_args)\n\n            all_qs_args.update({'page[number]': last_page})\n            links['last'] += '?' + urlencode(all_qs_args)\n\n            # compute previous and next link\n            current_page = int(querystring.pagination.get('number', 0)) or 1\n            if current_page > 1:\n                all_qs_args.update({'page[number]': current_page - 1})\n                links['prev'] = '?'.join((base_url, urlencode(all_qs_args)))\n            if current_page < last_page:\n                all_qs_args.update({'page[number]': current_page + 1})\n                links['next'] = '?'.join((base_url, urlencode(all_qs_args)))\n\n    data['links'] = links", "response": "Add pagination links to result\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate and return a new transaction sending amount from from_ to to.", "response": "def new_transaction(\n        vm: VM,\n        from_: Address,\n        to: Address,\n        amount: int=0,\n        private_key: PrivateKey=None,\n        gas_price: int=10,\n        gas: int=100000,\n        data: bytes=b'') -> BaseTransaction:\n    \"\"\"\n    Create and return a transaction sending amount from <from_> to <to>.\n\n    The transaction will be signed with the given private key.\n    \"\"\"\n    nonce = vm.state.get_nonce(from_)\n    tx = vm.create_unsigned_transaction(\n        nonce=nonce,\n        gas_price=gas_price,\n        gas=gas,\n        to=to,\n        value=amount,\n        data=data,\n    )\n\n    return tx.as_signed_transaction(private_key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef idfn(fixture_params: Iterable[Any]) -> str:\n    return \":\".join((str(item) for item in fixture_params))", "response": "Function for pytest to produce uniform names for fixtures."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the MD5 hash of the fixture files. Used for cache busting.", "response": "def get_fixtures_file_hash(all_fixture_paths: Iterable[str]) -> str:\n    \"\"\"\n    Returns the MD5 hash of the fixture files.  Used for cache busting.\n    \"\"\"\n    hasher = hashlib.md5()\n    for fixture_path in sorted(all_fixture_paths):\n        with open(fixture_path, 'rb') as fixture_file:\n            hasher.update(fixture_file.read())\n    return hasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_unsigned_transaction(cls,\n                                    *,\n                                    nonce: int,\n                                    gas_price: int,\n                                    gas: int,\n                                    to: Address,\n                                    value: int,\n                                    data: bytes) -> 'BaseUnsignedTransaction':\n        \"\"\"\n        Create an unsigned transaction.\n        \"\"\"\n        raise NotImplementedError(\"Must be implemented by subclasses\")", "response": "Create an unsigned transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_genesis_header(cls,\n                            base_db: BaseDB,\n                            genesis_header: BlockHeader) -> 'BaseHeaderChain':\n        \"\"\"\n        Initializes the chain from the genesis header.\n        \"\"\"\n        headerdb = cls.get_headerdb_class()(cast(BaseAtomicDB, base_db))\n        headerdb.persist_header(genesis_header)\n        return cls(base_db, genesis_header)", "response": "Initializes the chain from the given genesis header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport the given header into the canonical chain and returns a new tuple containing the newly imported headers.", "response": "def import_header(self,\n                      header: BlockHeader\n                      ) -> Tuple[Tuple[BlockHeader, ...], Tuple[BlockHeader, ...]]:\n        \"\"\"\n        Direct passthrough to `headerdb`\n\n        Also updates the local `header` property to be the latest canonical head.\n\n        Returns an iterable of headers representing the headers that are newly\n        part of the canonical chain.\n\n        - If the imported header is not part of the canonical chain then an\n          empty tuple will be returned.\n        - If the imported header simply extends the canonical chain then a\n          length-1 tuple with the imported header will be returned.\n        - If the header is part of a non-canonical chain which overtakes the\n          current canonical chain then the returned tuple will contain the\n          headers which are newly part of the canonical chain.\n        \"\"\"\n        new_canonical_headers = self.headerdb.persist_header(header)\n        self.header = self.get_canonical_head()\n        return new_canonical_headers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing a new block header from a parent header.", "response": "def from_parent(cls,\n                    parent: 'BlockHeader',\n                    gas_limit: int,\n                    difficulty: int,\n                    timestamp: int,\n                    coinbase: Address=ZERO_ADDRESS,\n                    nonce: bytes=None,\n                    extra_data: bytes=None,\n                    transaction_root: bytes=None,\n                    receipt_root: bytes=None) -> 'BlockHeader':\n        \"\"\"\n        Initialize a new block header with the `parent` header as the block's\n        parent hash.\n        \"\"\"\n        header_kwargs = {\n            'parent_hash': parent.hash,\n            'coinbase': coinbase,\n            'state_root': parent.state_root,\n            'gas_limit': gas_limit,\n            'difficulty': difficulty,\n            'block_number': parent.block_number + 1,\n            'timestamp': timestamp,\n        }\n        if nonce is not None:\n            header_kwargs['nonce'] = nonce\n        if extra_data is not None:\n            header_kwargs['extra_data'] = extra_data\n        if transaction_root is not None:\n            header_kwargs['transaction_root'] = transaction_root\n        if receipt_root is not None:\n            header_kwargs['receipt_root'] = receipt_root\n\n        header = cls(**header_kwargs)\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_block_uncles(self, uncles_hash: Hash32) -> List[BlockHeader]:\n        validate_word(uncles_hash, title=\"Uncles Hash\")\n        if uncles_hash == EMPTY_UNCLE_HASH:\n            return []\n        try:\n            encoded_uncles = self.db[uncles_hash]\n        except KeyError:\n            raise HeaderNotFound(\n                \"No uncles found for hash {0}\".format(uncles_hash)\n            )\n        else:\n            return rlp.decode(encoded_uncles, sedes=rlp.sedes.CountableList(BlockHeader))", "response": "Returns an iterable of uncle headers specified by the given uncles_hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef persist_block(self,\n                      block: 'BaseBlock'\n                      ) -> Tuple[Tuple[Hash32, ...], Tuple[Hash32, ...]]:\n        \"\"\"\n        Persist the given block's header and uncles.\n\n        Assumes all block transactions have been persisted already.\n        \"\"\"\n        with self.db.atomic_batch() as db:\n            return self._persist_block(db, block)", "response": "Persist the given block to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npersist the list of uncles to the database.", "response": "def persist_uncles(self, uncles: Tuple[BlockHeader]) -> Hash32:\n        \"\"\"\n        Persists the list of uncles to the database.\n\n        Returns the uncles hash.\n        \"\"\"\n        return self._persist_uncles(self.db, uncles)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the given receipt to the provided block header. Returns the updated block header s receipt_root.", "response": "def add_receipt(self, block_header: BlockHeader, index_key: int, receipt: Receipt) -> Hash32:\n        \"\"\"\n        Adds the given receipt to the provided block header.\n\n        Returns the updated `receipts_root` for updated block header.\n        \"\"\"\n        receipt_db = HexaryTrie(db=self.db, root_hash=block_header.receipt_root)\n        receipt_db[index_key] = rlp.encode(receipt)\n        return receipt_db.root_hash"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the given transaction to the provided block header. Returns the root hash of the transaction.", "response": "def add_transaction(self,\n                        block_header: BlockHeader,\n                        index_key: int,\n                        transaction: 'BaseTransaction') -> Hash32:\n        \"\"\"\n        Adds the given transaction to the provided block header.\n\n        Returns the updated `transactions_root` for updated block header.\n        \"\"\"\n        transaction_db = HexaryTrie(self.db, root_hash=block_header.transaction_root)\n        transaction_db[index_key] = rlp.encode(transaction)\n        return transaction_db.root_hash"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterable of transactions for the given block header.", "response": "def get_block_transactions(\n            self,\n            header: BlockHeader,\n            transaction_class: Type['BaseTransaction']) -> Iterable['BaseTransaction']:\n        \"\"\"\n        Returns an iterable of transactions for the block speficied by the\n        given block header.\n        \"\"\"\n        return self._get_block_transactions(header.transaction_root, transaction_class)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterable of the transaction hashes in the specified block header.", "response": "def get_block_transaction_hashes(self, block_header: BlockHeader) -> Iterable[Hash32]:\n        \"\"\"\n        Returns an iterable of the transaction hashes from the block specified\n        by the given block header.\n        \"\"\"\n        return self._get_block_transaction_hashes(self.db, block_header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_receipts(self,\n                     header: BlockHeader,\n                     receipt_class: Type[Receipt]) -> Iterable[Receipt]:\n        \"\"\"\n        Returns an iterable of receipts for the block specified by the given\n        block header.\n        \"\"\"\n        receipt_db = HexaryTrie(db=self.db, root_hash=header.receipt_root)\n        for receipt_idx in itertools.count():\n            receipt_key = rlp.encode(receipt_idx)\n            if receipt_key in receipt_db:\n                receipt_data = receipt_db[receipt_key]\n                yield rlp.decode(receipt_data, sedes=receipt_class)\n            else:\n                break", "response": "Returns an iterable of receipts for the given block header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_transaction_by_index(\n            self,\n            block_number: BlockNumber,\n            transaction_index: int,\n            transaction_class: Type['BaseTransaction']) -> 'BaseTransaction':\n        \"\"\"\n        Returns the transaction at the specified `transaction_index` from the\n        block specified by `block_number` from the canonical chain.\n\n        Raises TransactionNotFound if no block\n        \"\"\"\n        try:\n            block_header = self.get_canonical_block_header_by_number(block_number)\n        except HeaderNotFound:\n            raise TransactionNotFound(\"Block {} is not in the canonical chain\".format(block_number))\n        transaction_db = HexaryTrie(self.db, root_hash=block_header.transaction_root)\n        encoded_index = rlp.encode(transaction_index)\n        if encoded_index in transaction_db:\n            encoded_transaction = transaction_db[encoded_index]\n            return rlp.decode(encoded_transaction, sedes=transaction_class)\n        else:\n            raise TransactionNotFound(\n                \"No transaction is at index {} of block {}\".format(transaction_index, block_number))", "response": "Returns the transaction at the specified index from the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_transaction_index(self, transaction_hash: Hash32) -> Tuple[BlockNumber, int]:\n        key = SchemaV1.make_transaction_hash_to_block_lookup_key(transaction_hash)\n        try:\n            encoded_key = self.db[key]\n        except KeyError:\n            raise TransactionNotFound(\n                \"Transaction {} not found in canonical chain\".format(encode_hex(transaction_hash)))\n\n        transaction_key = rlp.decode(encoded_key, sedes=TransactionKey)\n        return (transaction_key.block_number, transaction_key.index)", "response": "Returns a 2 - tuple of block number and index of the given transaction in the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the Receipt of the transaction at the specified index in the canonical chain.", "response": "def get_receipt_by_index(self,\n                             block_number: BlockNumber,\n                             receipt_index: int) -> Receipt:\n        \"\"\"\n        Returns the Receipt of the transaction at specified index\n        for the block header obtained by the specified block number\n        \"\"\"\n        try:\n            block_header = self.get_canonical_block_header_by_number(block_number)\n        except HeaderNotFound:\n            raise ReceiptNotFound(\"Block {} is not in the canonical chain\".format(block_number))\n\n        receipt_db = HexaryTrie(db=self.db, root_hash=block_header.receipt_root)\n        receipt_key = rlp.encode(receipt_index)\n        if receipt_key in receipt_db:\n            receipt_data = receipt_db[receipt_key]\n            return rlp.decode(receipt_data, sedes=Receipt)\n        else:\n            raise ReceiptNotFound(\n                \"Receipt with index {} not found in block\".format(receipt_index))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_block_transaction_data(db: BaseDB, transaction_root: Hash32) -> Iterable[Hash32]:\n        transaction_db = HexaryTrie(db, root_hash=transaction_root)\n        for transaction_idx in itertools.count():\n            transaction_key = rlp.encode(transaction_idx)\n            if transaction_key in transaction_db:\n                yield transaction_db[transaction_key]\n            else:\n                break", "response": "Returns an iterable of the encoded transactions for the given block header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the transaction specified by the given hash from the canonical chain.", "response": "def _remove_transaction_from_canonical_chain(db: BaseDB, transaction_hash: Hash32) -> None:\n        \"\"\"\n        Removes the transaction specified by the given hash from the canonical\n        chain.\n        \"\"\"\n        db.delete(SchemaV1.make_transaction_hash_to_block_lookup_key(transaction_hash))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_transaction_to_canonical_chain(db: BaseDB,\n                                            transaction_hash: Hash32,\n                                            block_header: BlockHeader,\n                                            index: int) -> None:\n        \"\"\"\n        :param bytes transaction_hash: the hash of the transaction to add the lookup for\n        :param block_header: The header of the block with the txn that is in the canonical chain\n        :param int index: the position of the transaction in the block\n        - add lookup from transaction hash to the block number and index that the body is stored at\n        - remove transaction hash to body lookup in the pending pool\n        \"\"\"\n        transaction_key = TransactionKey(block_header.block_number, index)\n        db.set(\n            SchemaV1.make_transaction_hash_to_block_lookup_key(transaction_hash),\n            rlp.encode(transaction_key),\n        )", "response": "Add a transaction to the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef persist_trie_data_dict(self, trie_data_dict: Dict[Hash32, bytes]) -> None:\n        with self.db.atomic_batch() as db:\n            for key, value in trie_data_dict.items():\n                db[key] = value", "response": "Persist the trie data from a dict to the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the block denoted by the given block header.", "response": "def from_header(cls, header: BlockHeader, chaindb: BaseChainDB) -> BaseBlock:\n        \"\"\"\n        Returns the block denoted by the given block header.\n        \"\"\"\n        if header.uncles_hash == EMPTY_UNCLE_HASH:\n            uncles = []  # type: List[BlockHeader]\n        else:\n            uncles = chaindb.get_block_uncles(header.uncles_hash)\n\n        transactions = chaindb.get_block_transactions(header, cls.get_transaction_class())\n\n        return cls(\n            header=header,\n            transactions=transactions,\n            uncles=uncles,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sub(computation: BaseComputation) -> None:\n    left, right = computation.stack_pop(num_items=2, type_hint=constants.UINT256)\n\n    result = (left - right) & constants.UINT_256_MAX\n\n    computation.stack_push(result)", "response": "Subtracts the last two items of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mod(computation: BaseComputation) -> None:\n    value, mod = computation.stack_pop(num_items=2, type_hint=constants.UINT256)\n\n    if mod == 0:\n        result = 0\n    else:\n        result = value % mod\n\n    computation.stack_push(result)", "response": "Modulo the current value of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmultiplies the current object with the current object.", "response": "def mulmod(computation: BaseComputation) -> None:\n    \"\"\"\n    Modulo Multiplication\n    \"\"\"\n    left, right, mod = computation.stack_pop(num_items=3, type_hint=constants.UINT256)\n\n    if mod == 0:\n        result = 0\n    else:\n        result = (left * right) % mod\n    computation.stack_push(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndivide the current page.", "response": "def div(computation: BaseComputation) -> None:\n    \"\"\"\n    Division\n    \"\"\"\n    numerator, denominator = computation.stack_pop(num_items=2, type_hint=constants.UINT256)\n\n    if denominator == 0:\n        result = 0\n    else:\n        result = (numerator // denominator) & constants.UINT_256_MAX\n\n    computation.stack_push(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsigning Division of the current page.", "response": "def sdiv(computation: BaseComputation) -> None:\n    \"\"\"\n    Signed Division\n    \"\"\"\n    numerator, denominator = map(\n        unsigned_to_signed,\n        computation.stack_pop(num_items=2, type_hint=constants.UINT256),\n    )\n\n    pos_or_neg = -1 if numerator * denominator < 0 else 1\n\n    if denominator == 0:\n        result = 0\n    else:\n        result = (pos_or_neg * (abs(numerator) // abs(denominator)))\n\n    computation.stack_push(signed_to_unsigned(result))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning extend the current node.", "response": "def signextend(computation: BaseComputation) -> None:\n    \"\"\"\n    Signed Extend\n    \"\"\"\n    bits, value = computation.stack_pop(num_items=2, type_hint=constants.UINT256)\n\n    if bits <= 31:\n        testbit = bits * 8 + 7\n        sign_bit = (1 << testbit)\n        if value & sign_bit:\n            result = value | (constants.UINT_256_CEILING - sign_bit)\n        else:\n            result = value & (sign_bit - 1)\n    else:\n        result = value\n\n    computation.stack_push(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_frontier_difficulty(parent_header: BlockHeader, timestamp: int) -> int:\n    validate_gt(timestamp, parent_header.timestamp, title=\"Header timestamp\")\n\n    offset = parent_header.difficulty // DIFFICULTY_ADJUSTMENT_DENOMINATOR\n\n    # We set the minimum to the lowest of the protocol minimum and the parent\n    # minimum to allow for the initial frontier *warming* period during which\n    # the difficulty begins lower than the protocol minimum.\n    difficulty_minimum = min(parent_header.difficulty, DIFFICULTY_MINIMUM)\n\n    if timestamp - parent_header.timestamp < FRONTIER_DIFFICULTY_ADJUSTMENT_CUTOFF:\n        base_difficulty = max(\n            parent_header.difficulty + offset,\n            difficulty_minimum,\n        )\n    else:\n        base_difficulty = max(\n            parent_header.difficulty - offset,\n            difficulty_minimum,\n        )\n\n    # Adjust for difficulty bomb.\n    num_bomb_periods = (\n        (parent_header.block_number + 1) // BOMB_EXPONENTIAL_PERIOD\n    ) - BOMB_EXPONENTIAL_FREE_PERIODS\n\n    if num_bomb_periods >= 0:\n        difficulty = max(\n            base_difficulty + 2**num_bomb_periods,\n            DIFFICULTY_MINIMUM,\n        )\n    else:\n        difficulty = base_difficulty\n\n    return difficulty", "response": "Compute the difficulty for a frontier block based on the parent block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the message to the VM.", "response": "def build_computation(self,\n                          message: Message,\n                          transaction: BaseOrSpoofTransaction) -> BaseComputation:\n        \"\"\"Apply the message to the VM.\"\"\"\n        transaction_context = self.vm_state.get_transaction_context(transaction)\n        if message.is_create:\n            is_collision = self.vm_state.has_code_or_nonce(\n                message.storage_address\n            )\n\n            if is_collision:\n                # The address of the newly created contract has *somehow* collided\n                # with an existing contract address.\n                computation = self.vm_state.get_computation(message, transaction_context)\n                computation._error = ContractCreationCollision(\n                    \"Address collision while creating contract: {0}\".format(\n                        encode_hex(message.storage_address),\n                    )\n                )\n                self.vm_state.logger.debug2(\n                    \"Address collision while creating contract: %s\",\n                    encode_hex(message.storage_address),\n                )\n            else:\n                computation = self.vm_state.get_computation(\n                    message,\n                    transaction_context,\n                ).apply_create_message()\n        else:\n            computation = self.vm_state.get_computation(\n                message,\n                transaction_context).apply_message()\n\n        return computation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push(self, value: Union[int, bytes]) -> None:\n        if len(self.values) > 1023:\n            raise FullStack('Stack limit reached')\n\n        validate_stack_item(value)\n\n        self.values.append(value)", "response": "Push an item onto the stack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self,\n            num_items: int,\n            type_hint: str) -> Union[int, bytes, Tuple[Union[int, bytes], ...]]:\n        \"\"\"\n        Pop an item off the stack.\n\n        Note: This function is optimized for speed over readability.\n        \"\"\"\n        try:\n            if num_items == 1:\n                return next(self._pop(num_items, type_hint))\n            else:\n                return tuple(self._pop(num_items, type_hint))\n        except IndexError:\n            raise InsufficientStack(\"No stack items\")", "response": "Pop an item off the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef swap(self, position: int) -> None:\n        idx = -1 * position - 1\n        try:\n            self.values[-1], self.values[idx] = self.values[idx], self.values[-1]\n        except IndexError:\n            raise InsufficientStack(\"Insufficient stack items for SWAP{0}\".format(position))", "response": "Perform a SWAP operation on the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dup(self, position: int) -> None:\n        idx = -1 * position\n        try:\n            self.push(self.values[idx])\n        except IndexError:\n            raise InsufficientStack(\"Insufficient stack items for DUP{0}\".format(position))", "response": "Perform a DUP operation on the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_canonical_block_hash(self, block_number: BlockNumber) -> Hash32:\n        return self._get_canonical_block_hash(self.db, block_number)", "response": "Returns the block hash for the canonical block at the given number. Raises BlockNotFound if there s no block with the given number in the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_canonical_block_header_by_number(self, block_number: BlockNumber) -> BlockHeader:\n        return self._get_canonical_block_header_by_number(self.db, block_number)", "response": "Returns the block header with the given number in the canonical chain. Raises BlockNotFound if there s no block header with the given number in the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_block_header_by_hash(db: BaseDB, block_hash: Hash32) -> BlockHeader:\n        validate_word(block_hash, title=\"Block Hash\")\n        try:\n            header_rlp = db[block_hash]\n        except KeyError:\n            raise HeaderNotFound(\"No header with hash {0} found\".format(\n                encode_hex(block_hash)))\n        return _decode_block_header(header_rlp)", "response": "Returns the block header as specified by block hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef persist_header_chain(self,\n                             headers: Iterable[BlockHeader]\n                             ) -> Tuple[Tuple[BlockHeader, ...], Tuple[BlockHeader, ...]]:\n        \"\"\"\n        Return two iterable of headers, the first containing the new canonical headers,\n        the second containing the old canonical headers\n        \"\"\"\n        with self.db.atomic_batch() as db:\n            return self._persist_header_chain(db, headers)", "response": "Persist the given headers into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_as_canonical_chain_head(cls, db: BaseDB, block_hash: Hash32\n                                     ) -> Tuple[Tuple[BlockHeader, ...], Tuple[BlockHeader, ...]]:\n        \"\"\"\n        Sets the canonical chain HEAD to the block header as specified by the\n        given block hash.\n\n        :return: a tuple of the headers that are newly in the canonical chain, and the headers that\n            are no longer in the canonical chain\n        \"\"\"\n        try:\n            header = cls._get_block_header_by_hash(db, block_hash)\n        except HeaderNotFound:\n            raise ValueError(\n                \"Cannot use unknown block hash as canonical head: {}\".format(block_hash)\n            )\n\n        new_canonical_headers = tuple(reversed(cls._find_new_ancestors(db, header)))\n        old_canonical_headers = []\n\n        for h in new_canonical_headers:\n            try:\n                old_canonical_hash = cls._get_canonical_block_hash(db, h.block_number)\n            except HeaderNotFound:\n                # no old_canonical block, and no more possible\n                break\n            else:\n                old_canonical_header = cls._get_block_header_by_hash(db, old_canonical_hash)\n                old_canonical_headers.append(old_canonical_header)\n\n        for h in new_canonical_headers:\n            cls._add_block_number_to_hash_lookup(db, h)\n\n        db.set(SchemaV1.make_canonical_head_hash_lookup_key(), header.hash)\n\n        return new_canonical_headers, tuple(old_canonical_headers)", "response": "Sets the canonical chain HEAD to the block header that is newly in the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the chain leading up from the given header until it has a common ancestor.", "response": "def _find_new_ancestors(cls, db: BaseDB, header: BlockHeader) -> Iterable[BlockHeader]:\n        \"\"\"\n        Returns the chain leading up from the given header until (but not including)\n        the first ancestor it has in common with our canonical chain.\n\n        If D is the canonical head in the following chain, and F is the new header,\n        then this function returns (F, E).\n\n        A - B - C - D\n               \\\n                E - F\n        \"\"\"\n        h = header\n        while True:\n            try:\n                orig = cls._get_canonical_block_header_by_number(db, h.block_number)\n            except HeaderNotFound:\n                # This just means the block is not on the canonical chain.\n                pass\n            else:\n                if orig.hash == h.hash:\n                    # Found the common ancestor, stop.\n                    break\n\n            # Found a new ancestor\n            yield h\n\n            if h.parent_hash == GENESIS_PARENT_HASH:\n                break\n            else:\n                h = cls._get_block_header_by_hash(db, h.parent_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a record in the database to allow looking up this header by its block number.", "response": "def _add_block_number_to_hash_lookup(db: BaseDB, header: BlockHeader) -> None:\n        \"\"\"\n        Sets a record in the database to allow looking up this header by its\n        block number.\n        \"\"\"\n        block_number_to_hash_key = SchemaV1.make_block_number_to_hash_lookup_key(\n            header.block_number\n        )\n        db.set(\n            block_number_to_hash_key,\n            rlp.encode(header.hash, sedes=rlp.sedes.binary),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_gas_limit_bounds(parent: BlockHeader) -> Tuple[int, int]:\n    boundary_range = parent.gas_limit // GAS_LIMIT_ADJUSTMENT_FACTOR\n    upper_bound = parent.gas_limit + boundary_range\n    lower_bound = max(GAS_LIMIT_MINIMUM, parent.gas_limit - boundary_range)\n    return lower_bound, upper_bound", "response": "Compute the boundaries for the block gas limit based on the parent block."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the gas limit for a given parent header.", "response": "def compute_gas_limit(parent_header: BlockHeader, gas_limit_floor: int) -> int:\n    \"\"\"\n    A simple strategy for adjusting the gas limit.\n\n    For each block:\n\n    - decrease by 1/1024th of the gas limit from the previous block\n    - increase by 50% of the total gas used by the previous block\n\n    If the value is less than the given `gas_limit_floor`:\n\n    - increase the gas limit by 1/1024th of the gas limit from the previous block.\n\n    If the value is less than the GAS_LIMIT_MINIMUM:\n\n    - use the GAS_LIMIT_MINIMUM as the new gas limit.\n    \"\"\"\n    if gas_limit_floor < GAS_LIMIT_MINIMUM:\n        raise ValueError(\n            \"The `gas_limit_floor` value must be greater than the \"\n            \"GAS_LIMIT_MINIMUM.  Got {0}.  Must be greater than \"\n            \"{1}\".format(gas_limit_floor, GAS_LIMIT_MINIMUM)\n        )\n\n    decay = parent_header.gas_limit // GAS_LIMIT_EMA_DENOMINATOR\n\n    if parent_header.gas_used:\n        usage_increase = (\n            parent_header.gas_used * GAS_LIMIT_USAGE_ADJUSTMENT_NUMERATOR\n        ) // (\n            GAS_LIMIT_USAGE_ADJUSTMENT_DENOMINATOR\n        ) // (\n            GAS_LIMIT_EMA_DENOMINATOR\n        )\n    else:\n        usage_increase = 0\n\n    gas_limit = max(\n        GAS_LIMIT_MINIMUM,\n        parent_header.gas_limit - decay + usage_increase\n    )\n\n    if gas_limit < GAS_LIMIT_MINIMUM:\n        return GAS_LIMIT_MINIMUM\n    elif gas_limit < gas_limit_floor:\n        return parent_header.gas_limit + decay\n    else:\n        return gas_limit"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a new header from the state root and parent header.", "response": "def generate_header_from_parent_header(\n        compute_difficulty_fn: Callable[[BlockHeader, int], int],\n        parent_header: BlockHeader,\n        coinbase: Address,\n        timestamp: Optional[int] = None,\n        extra_data: bytes = b'') -> BlockHeader:\n    \"\"\"\n    Generate BlockHeader from state_root and parent_header\n    \"\"\"\n    if timestamp is None:\n        timestamp = max(int(time.time()), parent_header.timestamp + 1)\n    elif timestamp <= parent_header.timestamp:\n        raise ValueError(\n            \"header.timestamp ({}) should be higher than\"\n            \"parent_header.timestamp ({})\".format(\n                timestamp,\n                parent_header.timestamp,\n            )\n        )\n    header = BlockHeader(\n        difficulty=compute_difficulty_fn(parent_header, timestamp),\n        block_number=(parent_header.block_number + 1),\n        gas_limit=compute_gas_limit(\n            parent_header,\n            gas_limit_floor=GENESIS_GAS_LIMIT,\n        ),\n        timestamp=timestamp,\n        parent_hash=parent_header.hash,\n        state_root=parent_header.state_root,\n        coinbase=coinbase,\n        extra_data=extra_data,\n    )\n\n    return header"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_int(value: IntConvertible) -> int:\n    if is_integer(value):\n        return cast(int, value)\n    elif is_bytes(value):\n        return big_endian_to_int(value)\n    elif is_hex(value) and is_0x_prefixed(value):\n        value = cast(str, value)\n        if len(value) == 2:\n            return 0\n        else:\n            return int(value, 16)\n    elif is_string(value):\n        return int(value)\n    else:\n        raise TypeError(\"Unsupported type: Got `{0}`\".format(type(value)))", "response": "Robust to integer conversion handling hex values string representations and special cases like 0x."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a state definition to the canonical dict form.", "response": "def state_definition_to_dict(state_definition: GeneralState) -> AccountState:\n    \"\"\"Convert a state definition to the canonical dict form.\n\n    State can either be defined in the canonical form, or as a list of sub states that are then\n    merged to one. Sub states can either be given as dictionaries themselves, or as tuples where\n    the last element is the value and all others the keys for this value in the nested state\n    dictionary. Example:\n\n    ```\n        [\n            (\"0xaabb\", \"balance\", 3),\n            (\"0xaabb\", \"storage\", {\n                4: 5,\n            }),\n            \"0xbbcc\", {\n                \"balance\": 6,\n                \"nonce\": 7\n            }\n        ]\n    ```\n    \"\"\"\n    if isinstance(state_definition, Mapping):\n        state_dict = state_definition\n    elif isinstance(state_definition, Iterable):\n        state_dicts = [\n            assoc_in(\n                {},\n                state_item[:-1],\n                state_item[-1]\n            ) if not isinstance(state_item, Mapping) else state_item\n            for state_item\n            in state_definition\n        ]\n        if not is_cleanly_mergable(*state_dicts):\n            raise ValidationError(\"Some state item is defined multiple times\")\n        state_dict = deep_merge(*state_dicts)\n    else:\n        assert TypeError(\"State definition must either be a mapping or a sequence\")\n\n    seen_keys = set(concat(d.keys() for d in state_dict.values()))\n    bad_keys = seen_keys - set([\"balance\", \"nonce\", \"storage\", \"code\"])\n    if bad_keys:\n        raise ValidationError(\n            \"State definition contains the following invalid account fields: {}\".format(\n                \", \".join(bad_keys)\n            )\n        )\n\n    return state_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new changeset.", "response": "def record_changeset(self, custom_changeset_id: uuid.UUID = None) -> uuid.UUID:\n        \"\"\"\n        Creates a new changeset. Changesets are referenced by a random uuid4\n        to prevent collisions between multiple changesets.\n        \"\"\"\n        if custom_changeset_id is not None:\n            if custom_changeset_id in self.journal_data:\n                raise ValidationError(\n                    \"Tried to record with an existing changeset id: %r\" % custom_changeset_id\n                )\n            else:\n                changeset_id = custom_changeset_id\n        else:\n            changeset_id = uuid.uuid4()\n\n        self.journal_data[changeset_id] = {}\n        return changeset_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npops a changeset from the journal.", "response": "def pop_changeset(self, changeset_id: uuid.UUID) -> Dict[bytes, Union[bytes, DeletedEntry]]:\n        \"\"\"\n        Returns all changes from the given changeset.  This includes all of\n        the changes from any subsequent changeset, giving precidence to\n        later changesets.\n        \"\"\"\n        if changeset_id not in self.journal_data:\n            raise KeyError(changeset_id, \"Unknown changeset in JournalDB\")\n\n        all_ids = tuple(self.journal_data.keys())\n        changeset_idx = all_ids.index(changeset_id)\n        changesets_to_pop = all_ids[changeset_idx:]\n        popped_clears = tuple(idx for idx in changesets_to_pop if idx in self._clears_at)\n        if popped_clears:\n            last_clear_idx = changesets_to_pop.index(popped_clears[-1])\n            changesets_to_drop = changesets_to_pop[:last_clear_idx]\n            changesets_to_merge = changesets_to_pop[last_clear_idx:]\n        else:\n            changesets_to_drop = ()\n            changesets_to_merge = changesets_to_pop\n\n        # we pull all of the changesets *after* the changeset we are\n        # reverting to and collapse them to a single set of keys (giving\n        # precedence to later changesets)\n        changeset_data = merge(*(\n            self.journal_data.pop(c_id)\n            for c_id\n            in changesets_to_merge\n        ))\n\n        # drop the changes on the floor if they came before a clear that is being committed\n        for changeset_id in changesets_to_drop:\n            self.journal_data.pop(changeset_id)\n\n        self._clears_at.difference_update(popped_clears)\n        return changeset_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear the current entry from the database.", "response": "def clear(self) -> None:\n        \"\"\"\n        Treat as if the *underlying* database will also be cleared by some other mechanism.\n        We build a special empty changeset just for marking that all previous data should\n        be ignored.\n        \"\"\"\n        # these internal records are used as a way to tell the difference between\n        # changes that came before and after the clear\n        self.record_changeset()\n        self._clears_at.add(self.latest_id)\n        self.record_changeset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commit_changeset(self, changeset_id: uuid.UUID) -> Dict[bytes, Union[bytes, DeletedEntry]]:\n        does_clear = self.has_clear(changeset_id)\n        changeset_data = self.pop_changeset(changeset_id)\n        if not self.is_empty():\n            # we only have to assign changeset data into the latest changeset if\n            # there is one.\n            if does_clear:\n                # if there was a clear and more changesets underneath then clear the latest\n                # changeset, and replace with a new clear changeset\n                self.latest = {}\n                self._clears_at.add(self.latest_id)\n                self.record_changeset()\n                self.latest = changeset_data\n            else:\n                # otherwise, merge in all the current data\n                self.latest = merge(\n                    self.latest,\n                    changeset_data,\n                )\n        return changeset_data", "response": "Commits all changes for the given changeset into the previous changeset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_changeset(self, changeset_id: uuid.UUID) -> None:\n        if not self.journal.has_changeset(changeset_id):\n            raise ValidationError(\"Changeset not found in journal: {0}\".format(\n                str(changeset_id)\n            ))", "response": "Checks to be sure the changeset is known by the journal"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a new recording and returns an id for the associated changeset", "response": "def record(self, custom_changeset_id: uuid.UUID = None) -> uuid.UUID:\n        \"\"\"\n        Starts a new recording and returns an id for the associated changeset\n        \"\"\"\n        return self.journal.record_changeset(custom_changeset_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discard(self, changeset_id: uuid.UUID) -> None:\n        self._validate_changeset(changeset_id)\n        self.journal.pop_changeset(changeset_id)", "response": "Removes all journaled data starting at the given changeset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommitting a given changeset.", "response": "def commit(self, changeset_id: uuid.UUID) -> None:\n        \"\"\"\n        Commits a given changeset. This merges the given changeset and all\n        subsequent changesets into the previous changeset giving precidence\n        to later changesets in case of any conflicting keys.\n\n        If this is the base changeset then all changes will be written to\n        the underlying database and the Journal starts a new recording.\n        Typically, callers won't have access to the base changeset, because\n        it is dropped during .reset() which is called in JournalDB().\n        \"\"\"\n        self._validate_changeset(changeset_id)\n        journal_data = self.journal.commit_changeset(changeset_id)\n\n        if self.journal.is_empty():\n            # Ensure the journal automatically restarts recording after\n            # it has been persisted to the underlying db\n            self.reset()\n\n            for key, value in journal_data.items():\n                try:\n                    if value is DELETED_ENTRY:\n                        del self.wrapped_db[key]\n                    elif value is ERASE_CREATED_ENTRY:\n                        pass\n                    else:\n                        self.wrapped_db[key] = cast(bytes, value)\n                except Exception:\n                    self._reapply_changeset_to_journal(changeset_id, journal_data)\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects all accounts that need to be deleted from the given computation.", "response": "def collect_touched_accounts(computation: BaseComputation) -> Iterable[bytes]:\n    \"\"\"\n    Collect all of the accounts that *may* need to be deleted based on\n    `EIP-161 <https://eips.ethereum.org/EIPS/eip-161>`_.\n\n    Checking whether they *do* need to be deleted happens in the caller.\n\n    See also: https://github.com/ethereum/EIPs/issues/716\n    \"\"\"\n    # collect the coinbase account if it was touched via zero-fee transfer\n    if computation.is_origin_computation and computation.transaction_context.gas_price == 0:\n        yield computation.state.coinbase\n\n    # collect those explicitly marked for deletion (\"beneficiary\" is of SELFDESTRUCT)\n    for beneficiary in sorted(set(computation.accounts_to_delete.values())):\n        if computation.is_error and computation.is_origin_computation:\n            # Special case to account for geth+parity bug\n            # https://github.com/ethereum/EIPs/issues/716\n            if beneficiary == THREE:\n                yield beneficiary\n            continue\n        else:\n            yield beneficiary\n\n    # collect account directly addressed\n    if computation.msg.to != constants.CREATE_CONTRACT_ADDRESS:\n        if computation.is_error and computation.is_origin_computation:\n            # Special case to account for geth+parity bug\n            # https://github.com/ethereum/EIPs/issues/716\n            if computation.msg.to == THREE:\n                yield computation.msg.to\n        else:\n            yield computation.msg.to\n\n    # recurse into nested computations if this one was successful\n    if not computation.is_error:\n        for child in computation.children:\n            yield from collect_touched_accounts(child)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the difficulty of a new entry in the tree.", "response": "def compute_difficulty(\n        bomb_delay: int,\n        parent_header: BlockHeader,\n        timestamp: int) -> int:\n    \"\"\"\n    https://github.com/ethereum/EIPs/issues/100\n    \"\"\"\n    parent_timestamp = parent_header.timestamp\n    validate_gt(timestamp, parent_timestamp, title=\"Header.timestamp\")\n\n    parent_difficulty = parent_header.difficulty\n    offset = parent_difficulty // DIFFICULTY_ADJUSTMENT_DENOMINATOR\n\n    has_uncles = parent_header.uncles_hash != EMPTY_UNCLE_HASH\n    adj_factor = max(\n        (\n            (2 if has_uncles else 1) -\n            ((timestamp - parent_timestamp) // BYZANTIUM_DIFFICULTY_ADJUSTMENT_CUTOFF)\n        ),\n        -99,\n    )\n    difficulty = max(\n        parent_difficulty + offset * adj_factor,\n        min(parent_header.difficulty, DIFFICULTY_MINIMUM)\n    )\n    num_bomb_periods = (\n        max(\n            0,\n            parent_header.block_number + 1 - bomb_delay,\n        ) // BOMB_EXPONENTIAL_PERIOD\n    ) - BOMB_EXPONENTIAL_FREE_PERIODS\n\n    if num_bomb_periods >= 0:\n        return max(difficulty + 2**num_bomb_periods, DIFFICULTY_MINIMUM)\n    else:\n        return difficulty"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FQP_point_to_FQ2_point(pt: Tuple[FQP, FQP, FQP]) -> Tuple[FQ2, FQ2, FQ2]:\n    return (\n        FQ2(pt[0].coeffs),\n        FQ2(pt[1].coeffs),\n        FQ2(pt[2].coeffs),\n    )", "response": "Transform FQP to FQ2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_opcode(cls: Type[T],\n                  logic_fn: Callable[..., Any],\n                  mnemonic: str,\n                  gas_cost: int) -> Type[T]:\n        \"\"\"\n        Class factory method for turning vanilla functions into Opcode classes.\n        \"\"\"\n        if gas_cost:\n            @functools.wraps(logic_fn)\n            def wrapped_logic_fn(computation: 'BaseComputation') -> Any:\n                \"\"\"\n                Wrapper functionf or the logic function which consumes the base\n                opcode gas cost prior to execution.\n                \"\"\"\n                computation.consume_gas(\n                    gas_cost,\n                    mnemonic,\n                )\n                return logic_fn(computation)\n        else:\n            wrapped_logic_fn = logic_fn\n\n        props = {\n            '__call__': staticmethod(wrapped_logic_fn),\n            'mnemonic': mnemonic,\n            'gas_cost': gas_cost,\n        }\n        opcode_cls = type(\"opcode:{0}\".format(mnemonic), (cls,), props)\n        return opcode_cls()", "response": "Returns the class that is used to create a new opcode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wipe_storage(self, address: Address) -> None:\n        account_store = self._get_address_store(address)\n        self._dirty_accounts.add(address)\n        account_store.delete()", "response": "Wipe out the storage for the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_main_filler(name: str, environment: Dict[Any, Any]=None) -> Dict[str, Dict[str, Any]]:\n    return setup_filler(name, merge(DEFAULT_MAIN_ENVIRONMENT, environment or {}))", "response": "Create a new main filler for the test chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines the state prior to the test execution.", "response": "def pre_state(*raw_state: GeneralState, filler: Dict[str, Any]) -> None:\n    \"\"\"\n    Specify the state prior to the test execution. Multiple invocations don't override\n    the state but extend it instead.\n\n    In general, the elements of `state_definitions` are nested dictionaries of the following form:\n\n    .. code-block:: python\n\n        {\n            address: {\n                \"nonce\": <account nonce>,\n                \"balance\": <account balance>,\n                \"code\": <account code>,\n                \"storage\": {\n                    <storage slot>: <storage value>\n                }\n            }\n        }\n\n    To avoid unnecessary nesting especially if only few fields per account are specified, the\n    following and similar formats are possible as well:\n\n    .. code-block:: python\n\n        (address, \"balance\", <account balance>)\n        (address, \"storage\", <storage slot>, <storage value>)\n        (address, \"storage\", {<storage slot>: <storage value>})\n        (address, {\"balance\", <account balance>})\n    \"\"\"\n    @wraps(pre_state)\n    def _pre_state(filler: Dict[str, Any]) -> Dict[str, Any]:\n        test_name = get_test_name(filler)\n\n        old_pre_state = filler[test_name].get(\"pre_state\", {})\n        pre_state = normalize_state(raw_state)\n        defaults = {address: {\n            \"balance\": 0,\n            \"nonce\": 0,\n            \"code\": b\"\",\n            \"storage\": {},\n        } for address in pre_state}\n        new_pre_state = deep_merge(defaults, old_pre_state, pre_state)\n\n        return assoc_in(filler, [test_name, \"pre\"], new_pre_state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expect(post_state: Dict[str, Any]=None,\n           networks: Any=None,\n           transaction: TransactionDict=None) -> Callable[..., Dict[str, Any]]:\n\n    \"\"\"\n    Specify the expected result for the test.\n\n    For state tests, multiple expectations can be given, differing in the transaction data, gas\n    limit, and value, in the applicable networks, and as a result also in the post state. VM tests\n    support only a single expectation with no specified network and no transaction (here, its role\n    is played by :func:`~eth.tools.fixtures.fillers.execution`).\n\n    * ``post_state`` is a list of state definition in the same form as expected\n      by :func:`~eth.tools.fixtures.fillers.pre_state`. State items that are\n      not set explicitly default to their pre state.\n\n    * ``networks`` defines the forks under which the expectation is applicable. It should be a\n        sublist of the following identifiers (also available in `ALL_FORKS`):\n\n      * ``\"Frontier\"``\n      * ``\"Homestead\"``\n      * ``\"EIP150\"``\n      * ``\"EIP158\"``\n      * ``\"Byzantium\"``\n\n    * ``transaction`` is a dictionary coming in two variants. For the main shard:\n\n      +----------------+-------------------------------+\n      | key            | description                   |\n      +================+===============================+\n      | ``\"data\"``     | the transaction data,         |\n      +----------------+-------------------------------+\n      | ``\"gasLimit\"`` | the transaction gas limit,    |\n      +----------------+-------------------------------+\n      | ``\"gasPrice\"`` | the gas price,                |\n      +----------------+-------------------------------+\n      | ``\"nonce\"``    | the transaction nonce,        |\n      +----------------+-------------------------------+\n      | ``\"value\"``    | the transaction value         |\n      +----------------+-------------------------------+\n\n    In addition, one should specify either the signature itself (via keys ``\"v\"``, ``\"r\"``,\n    and ``\"s\"``) or a private key used for signing (via ``\"secretKey\"``).\n    \"\"\"\n    return partial(_expect, post_state, networks, transaction)", "response": "This function returns a function that can be used to test the expectation of the given state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execution(execution: Dict[str, Any], filler: Dict[str, Any]) -> Dict[str, Any]:\n    execution = normalize_execution(execution or {})\n\n    # user caller as origin if not explicitly given\n    if \"caller\" in execution and \"origin\" not in execution:\n        execution = assoc(execution, \"origin\", execution[\"caller\"])\n\n    if \"vyperLLLCode\" in execution:\n        code = compile_vyper_lll(execution[\"vyperLLLCode\"])\n        if \"code\" in execution:\n            if code != execution[\"code\"]:\n                raise ValueError(\"Compiled Vyper LLL code does not match\")\n        execution = assoc(execution, \"code\", code)\n\n    execution = merge(DEFAULT_EXECUTION, execution)\n\n    test_name = get_test_name(filler)\n    return deep_merge(\n        filler,\n        {\n            test_name: {\n                \"exec\": execution,\n            }\n        }\n    )", "response": "This function takes a dictionary containing the code that is being run as well as the current state of the EVM and returns the resulting state of the EVM."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload call data into memory.", "response": "def calldataload(computation: BaseComputation) -> None:\n    \"\"\"\n    Load call data into memory.\n    \"\"\"\n    start_position = computation.stack_pop(type_hint=constants.UINT256)\n\n    value = computation.msg.data_as_bytes[start_position:start_position + 32]\n    padded_value = value.ljust(32, b'\\x00')\n    normalized_value = padded_value.lstrip(b'\\x00')\n\n    computation.stack_push(normalized_value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the code hash for a given address.", "response": "def extcodehash(computation: BaseComputation) -> None:\n    \"\"\"\n    Return the code hash for a given address.\n    EIP: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-1052.md\n    \"\"\"\n    account = force_bytes_to_address(computation.stack_pop(type_hint=constants.BYTES))\n    state = computation.state\n\n    if state.account_is_empty(account):\n        computation.stack_push(constants.NULL_BYTE)\n    else:\n        computation.stack_push(state.get_code_hash(account))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbinds the given value between inclusive_lower_bound and inclusive_upper_bound.", "response": "def clamp(inclusive_lower_bound: int,\n          inclusive_upper_bound: int,\n          value: int) -> int:\n    \"\"\"\n    Bound the given ``value`` between ``inclusive_lower_bound`` and\n    ``inclusive_upper_bound``.\n    \"\"\"\n    if value <= inclusive_lower_bound:\n        return inclusive_lower_bound\n    elif value >= inclusive_upper_bound:\n        return inclusive_upper_bound\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef integer_squareroot(value: int) -> int:\n    if not isinstance(value, int) or isinstance(value, bool):\n        raise ValueError(\n            \"Value must be an integer: Got: {0}\".format(\n                type(value),\n            )\n        )\n    if value < 0:\n        raise ValueError(\n            \"Value cannot be negative: Got: {0}\".format(\n                value,\n            )\n        )\n\n    with decimal.localcontext() as ctx:\n        ctx.prec = 128\n        return int(decimal.Decimal(value).sqrt())", "response": "Return the integer square root of value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting all writes inside the context unless an exception was raised.", "response": "def _commit_unless_raises(cls, write_target_db: BaseDB) -> Iterator['AtomicDBWriteBatch']:\n        \"\"\"\n        Commit all writes inside the context, unless an exception was raised.\n\n        Although this is technically an external API, it (and this whole class) is only intended\n        to be used by AtomicDB.\n        \"\"\"\n        readable_write_batch = cls(write_target_db)     # type: AtomicDBWriteBatch\n        try:\n            yield readable_write_batch\n        except Exception:\n            cls.logger.exception(\n                \"Unexpected error in atomic db write, dropped partial writes: %r\",\n                readable_write_batch._diff(),\n            )\n            raise\n        else:\n            readable_write_batch._commit()\n        finally:\n            # force a shutdown of this batch, to prevent out-of-context usage\n            readable_write_batch._track_diff = None\n            readable_write_batch._write_target_db = None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the current value of the stack is zero.", "response": "def iszero(computation: BaseComputation) -> None:\n    \"\"\"\n    Not\n    \"\"\"\n    value = computation.stack_pop(type_hint=constants.UINT256)\n\n    if value == 0:\n        result = 1\n    else:\n        result = 0\n\n    computation.stack_push(result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting a dotted module path and returns the attribute and class corresponding to that module.", "response": "def import_string(dotted_path: str) -> ModuleType:\n    \"\"\"\n    Source: django.utils.module_loading\n    Import a dotted module path and return the attribute/class designated by the\n    last name in the path. Raise ImportError if the import failed.\n    \"\"\"\n    try:\n        module_path, class_name = dotted_path.rsplit('.', 1)\n    except ValueError:\n        msg = \"%s doesn't look like a module path\" % dotted_path\n        raise ImportError(msg)\n\n    module = import_module(module_path)\n\n    try:\n        return getattr(module, class_name)\n    except AttributeError:\n        msg = 'Module \"%s\" does not define a \"%s\" attribute/class' % (\n            module_path, class_name)\n        raise ImportError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a new object through the series of applicator functions.", "response": "def build(obj: Any, *applicators: Callable[..., Any]) -> Any:\n    \"\"\"\n    Run the provided object through the series of applicator functions.\n\n    If ``obj`` is an instances of :class:`~eth.chains.base.BaseChain` the\n    applicators will be run on a copy of the chain and thus will not mutate the\n    provided chain instance.\n    \"\"\"\n    if isinstance(obj, BaseChain):\n        return pipe(obj, copy(), *applicators)\n    else:\n        return pipe(obj, *applicators)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassign the given name to the chain class.", "response": "def name(class_name: str, chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    \"\"\"\n    Assign the given name to the chain class.\n    \"\"\"\n    return chain_class.configure(__name__=class_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the chain_id for the chain class.", "response": "def chain_id(chain_id: int, chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    \"\"\"\n    Set the ``chain_id`` for the chain class.\n    \"\"\"\n    return chain_class.configure(chain_id=chain_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfork the given VM class at the given block.", "response": "def fork_at(vm_class: Type[BaseVM], at_block: int, chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    \"\"\"\n    Adds the ``vm_class`` to the chain's ``vm_configuration``.\n\n    .. code-block:: python\n\n        from eth.chains.base import MiningChain\n        from eth.tools.builder.chain import build, fork_at\n\n        FrontierOnlyChain = build(MiningChain, fork_at(FrontierVM, 0))\n\n        # these two classes are functionally equivalent.\n        class FrontierOnlyChain(MiningChain):\n            vm_configuration = (\n                (0, FrontierVM),\n            )\n\n    .. note:: This function is curriable.\n\n    The following pre-curried versions of this function are available as well,\n    one for each mainnet fork.\n\n    * :func:`~eth.tools.builder.chain.frontier_at`\n    * :func:`~eth.tools.builder.chain.homestead_at`\n    * :func:`~eth.tools.builder.chain.tangerine_whistle_at`\n    * :func:`~eth.tools.builder.chain.spurious_dragon_at`\n    * :func:`~eth.tools.builder.chain.byzantium_at`\n    * :func:`~eth.tools.builder.chain.constantinople_at`\n    \"\"\"\n    if chain_class.vm_configuration is not None:\n        base_configuration = chain_class.vm_configuration\n    else:\n        base_configuration = tuple()\n\n    vm_configuration = base_configuration + ((at_block, vm_class),)\n    validate_vm_configuration(vm_configuration)\n    return chain_class.configure(vm_configuration=vm_configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disable_dao_fork(chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    homstead_vms_found = any(\n        _is_homestead(vm_class) for _, vm_class in chain_class.vm_configuration\n    )\n    if not homstead_vms_found:\n        raise ValidationError(\"No HomesteadVM found in vm_configuration.\")\n\n    vm_configuration = _set_vm_dao_support_false(chain_class.vm_configuration)\n    return chain_class.configure(vm_configuration=vm_configuration)", "response": "Disables DAO fork on the chain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dao_fork_at(dao_fork_block_number: BlockNumber,\n                chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    \"\"\"\n    Set the block number on which the DAO fork will happen.  Requires that a\n    version of the :class:`~eth.vm.forks.homestead.HomesteadVM` is present in\n    the chain's ``vm_configuration``\n\n    \"\"\"\n    homstead_vms_found = any(\n        _is_homestead(vm_class) for _, vm_class in chain_class.vm_configuration\n    )\n    if not homstead_vms_found:\n        raise ValidationError(\"No HomesteadVM found in vm_configuration.\")\n\n    vm_configuration = _set_vm_dao_fork_block_number(\n        dao_fork_block_number,\n        chain_class.vm_configuration,\n    )\n    return chain_class.configure(vm_configuration=vm_configuration)", "response": "Sets the block number on which the DAO fork will happen."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_pow_mining(chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    if not chain_class.vm_configuration:\n        raise ValidationError(\"Chain class has no vm_configuration\")\n\n    vm_configuration = _mix_in_pow_mining(chain_class.vm_configuration)\n    return chain_class.configure(vm_configuration=vm_configuration)", "response": "Enable proof of work mining on newly\n    mined blocks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisabling the proof of work validation check for each of the chain s vms.", "response": "def disable_pow_check(chain_class: Type[BaseChain]) -> Type[BaseChain]:\n    \"\"\"\n    Disable the proof of work validation check for each of the chain's vms.\n    This allows for block mining without generation of the proof of work seal.\n\n    .. note::\n\n        blocks mined this way will not be importable on any chain that does not\n        have proof of work disabled.\n    \"\"\"\n    if not chain_class.vm_configuration:\n        raise ValidationError(\"Chain class has no vm_configuration\")\n\n    if issubclass(chain_class, NoChainSealValidationMixin):\n        # Seal validation already disabled, hence nothing to change\n        chain_class_without_seal_validation = chain_class\n    else:\n        chain_class_without_seal_validation = type(\n            chain_class.__name__,\n            (chain_class, NoChainSealValidationMixin),\n            {},\n        )\n    return chain_class_without_seal_validation.configure(  # type: ignore\n        vm_configuration=_mix_in_disable_seal_validation(\n            chain_class_without_seal_validation.vm_configuration  # type: ignore\n        ),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the given chain class with the given genesis header parameters and chain state.", "response": "def genesis(chain_class: BaseChain,\n            db: BaseAtomicDB=None,\n            params: Dict[str, HeaderParams]=None,\n            state: GeneralState=None) -> BaseChain:\n    \"\"\"\n    Initialize the given chain class with the given genesis header parameters\n    and chain state.\n    \"\"\"\n    if state is None:\n        genesis_state = {}  # type: AccountState\n    else:\n        genesis_state = _fill_and_normalize_state(state)\n\n    genesis_params_defaults = _get_default_genesis_params(genesis_state)\n\n    if params is None:\n        genesis_params = genesis_params_defaults\n    else:\n        genesis_params = merge(genesis_params_defaults, params)\n\n    if db is None:\n        base_db = AtomicDB()  # type: BaseAtomicDB\n    else:\n        base_db = db\n\n    return chain_class.from_genesis(base_db, genesis_params, genesis_state)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmine a new block on the chain.", "response": "def mine_block(chain: MiningChain, **kwargs: Any) -> MiningChain:\n    \"\"\"\n    Mine a new block on the chain.  Header parameters for the new block can be\n    overridden using keyword arguments.\n\n    \"\"\"\n    if not isinstance(chain, MiningChain):\n        raise ValidationError('`mine_block` may only be used on MiningChain instances')\n    chain.mine_block(**kwargs)\n    return chain"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports the provided block into the chain.", "response": "def import_block(block: BaseBlock, chain: BaseChain) -> BaseChain:\n    \"\"\"\n    Import the provided ``block`` into the chain.\n    \"\"\"\n    chain.import_block(block)\n    return chain"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that imports the given blocks into the chain.", "response": "def import_blocks(*blocks: BaseBlock) -> Callable[[BaseChain], BaseChain]:\n    \"\"\"\n    Variadic argument version of :func:`~eth.tools.builder.chain.import_block`\n    \"\"\"\n    @functools.wraps(import_blocks)\n    def _import_blocks(chain: BaseChain) -> BaseChain:\n        for block in blocks:\n            chain.import_block(block)\n        return chain\n\n    return _import_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a copy of the given chain at the given state.", "response": "def copy(chain: MiningChain) -> MiningChain:\n    \"\"\"\n    Make a copy of the chain at the given state.  Actions performed on the\n    resulting chain will not affect the original chain.\n    \"\"\"\n    if not isinstance(chain, MiningChain):\n        raise ValidationError(\"`at_block_number` may only be used with 'MiningChain\")\n    base_db = chain.chaindb.db\n    if not isinstance(base_db, AtomicDB):\n        raise ValidationError(\"Unsupported database type: {0}\".format(type(base_db)))\n\n    if isinstance(base_db.wrapped_db, MemoryDB):\n        db = AtomicDB(MemoryDB(base_db.wrapped_db.kv_store.copy()))\n    else:\n        raise ValidationError(\"Unsupported wrapped database: {0}\".format(type(base_db.wrapped_db)))\n\n    chain_copy = type(chain)(db, chain.header)\n    return chain_copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chain_split(*splits: Iterable[Callable[..., Any]]) -> Callable[[BaseChain], Iterable[BaseChain]]:   # noqa: E501\n    if not splits:\n        raise ValidationError(\"Cannot use `chain_split` without providing at least one split\")\n\n    @functools.wraps(chain_split)\n    @to_tuple\n    def _chain_split(chain: BaseChain) -> Iterable[BaseChain]:\n        for split_fns in splits:\n            result = build(\n                chain,\n                *split_fns,\n            )\n            yield result\n\n    return _chain_split", "response": "A function that returns a single chain object for each of the given forks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef at_block_number(block_number: BlockNumber, chain: MiningChain) -> MiningChain:\n    if not isinstance(chain, MiningChain):\n        raise ValidationError(\"`at_block_number` may only be used with 'MiningChain\")\n    at_block = chain.get_canonical_block_by_number(block_number)\n\n    db = chain.chaindb.db\n    chain_at_block = type(chain)(db, chain.create_header_from_parent(at_block.header))\n    return chain_at_block", "response": "Rewind the chain back to the given block number."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds all of the fixture files under a given path under the given fixtures base directory.", "response": "def find_fixtures(fixtures_base_dir: str) -> Iterable[Tuple[str, str]]:\n    \"\"\"\n    Finds all of the (fixture_path, fixture_key) pairs for a given path under\n    the JSON test fixtures directory.\n    \"\"\"\n    all_fixture_paths = find_fixture_files(fixtures_base_dir)\n\n    for fixture_path in sorted(all_fixture_paths):\n        with open(fixture_path) as fixture_file:\n            fixtures = json.load(fixture_file)\n\n        for fixture_key in sorted(fixtures.keys()):\n            yield (fixture_path, fixture_key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a fixture file and caches the most recent files it loaded.", "response": "def load_json_fixture(fixture_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Loads a fixture file, caching the most recent files it loaded.\n    \"\"\"\n    with open(fixture_path) as fixture_file:\n        file_fixtures = json.load(fixture_file)\n    return file_fixtures"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_fixture(fixture_path: str,\n                 fixture_key: str,\n                 normalize_fn: Callable[..., Any]=identity) -> Dict[str, Any]:\n    \"\"\"\n    Loads a specific fixture from a fixture file, optionally passing it through\n    a normalization function.\n    \"\"\"\n    file_fixtures = load_json_fixture(fixture_path)\n    fixture = normalize_fn(file_fixtures[fixture_key])\n    return fixture", "response": "Loads a specific fixture from a file optionally passing it through\n    a normalization function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_fixtures(all_fixtures: Iterable[Any],\n                    fixtures_base_dir: str,\n                    mark_fn: Callable[[str, str], bool]=None,\n                    ignore_fn: Callable[..., bool]=None) -> Any:\n    \"\"\"\n    Helper function for filtering test fixtures.\n\n    - `fixtures_base_dir` should be the base directory that the fixtures were collected from.\n    - `mark_fn` should be a function which either returns `None` or a `pytest.mark` object.\n    - `ignore_fn` should be a function which returns `True` for any fixture\n       which should be ignored.\n    \"\"\"\n    import pytest  # noqa: F401\n\n    for fixture_data in all_fixtures:\n        fixture_path = fixture_data[0]\n        fixture_relpath = os.path.relpath(fixture_path, fixtures_base_dir)\n\n        if ignore_fn:\n            if ignore_fn(fixture_relpath, *fixture_data[1:]):\n                continue\n\n        if mark_fn is not None:\n            mark = mark_fn(fixture_relpath, *fixture_data[1:])\n            if mark:\n                yield pytest.param(\n                    (fixture_path, *fixture_data[1:]),\n                    marks=mark,\n                )\n                continue\n\n        yield fixture_data", "response": "Yields all test fixtures in a single order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_fixture_block_to_chain(\n        block_fixture: Dict[str, Any],\n        chain: BaseChain,\n        perform_validation: bool=True) -> Tuple[BaseBlock, BaseBlock, BaseBlock]:\n    \"\"\"\n    :return: (premined_block, mined_block, rlp_encoded_mined_block)\n    \"\"\"\n    # The block to import may be in a different block-class-range than the\n    # chain's current one, so we use the block number specified in the\n    # fixture to look up the correct block class.\n    if 'blockHeader' in block_fixture:\n        block_number = block_fixture['blockHeader']['number']\n        block_class = chain.get_vm_class_for_block_number(block_number).get_block_class()\n    else:\n        block_class = chain.get_vm().get_block_class()\n\n    block = rlp.decode(block_fixture['rlp'], sedes=block_class)\n\n    mined_block, _, _ = chain.import_block(block, perform_validation=perform_validation)\n\n    rlp_encoded_mined_block = rlp.encode(mined_block, sedes=block_class)\n\n    return (block, mined_block, rlp_encoded_mined_block)", "response": "Imports the block from the given block_fixture into the chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs the EVM runtime identifier string for the current version of the EVM.", "response": "def construct_evm_runtime_identifier() -> str:\n    \"\"\"\n    Constructs the EVM runtime identifier string\n\n    e.g. 'Py-EVM/v1.2.3/darwin-amd64/python3.6.5'\n    \"\"\"\n    return \"Py-EVM/{0}/{platform}/{imp.name}{v.major}.{v.minor}.{v.micro}\".format(\n        __version__,\n        platform=sys.platform,\n        v=sys.version_info,\n        # mypy Doesn't recognize the `sys` module as having an `implementation` attribute.\n        imp=sys.implementation,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef binary_gas_search(state: BaseState, transaction: BaseTransaction, tolerance: int=1) -> int:\n    if not hasattr(transaction, 'sender'):\n        raise TypeError(\n            \"Transaction is missing attribute sender.\",\n            \"If sending an unsigned transaction, use SpoofTransaction and provide the\",\n            \"sender using the 'from' parameter\")\n\n    minimum_transaction = SpoofTransaction(\n        transaction,\n        gas=transaction.intrinsic_gas,\n        gas_price=0,\n    )\n\n    if _get_computation_error(state, minimum_transaction) is None:\n        return transaction.intrinsic_gas\n\n    maximum_transaction = SpoofTransaction(\n        transaction,\n        gas=state.gas_limit,\n        gas_price=0,\n    )\n    error = _get_computation_error(state, maximum_transaction)\n    if error is not None:\n        raise error\n\n    minimum_viable = state.gas_limit\n    maximum_out_of_gas = transaction.intrinsic_gas\n    while minimum_viable - maximum_out_of_gas > tolerance:\n        midpoint = (minimum_viable + maximum_out_of_gas) // 2\n        test_transaction = SpoofTransaction(transaction, gas=midpoint)\n        if _get_computation_error(state, test_transaction) is None:\n            minimum_viable = midpoint\n        else:\n            maximum_out_of_gas = midpoint\n\n    return minimum_viable", "response": "Binary gas search for the given transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commit_to(self, db: BaseDB) -> None:\n        self.logger.debug2('persist storage root to data store')\n        if self._trie_nodes_batch is None:\n            raise ValidationError(\n                \"It is invalid to commit an account's storage if it has no pending changes. \"\n                \"Always check storage_lookup.has_changed_root before attempting to commit.\"\n            )\n        self._trie_nodes_batch.commit_to(db, apply_deletes=False)\n        self._clear_changed_root()", "response": "Commit changes to the given database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_flushed(self) -> None:\n        journal_diff = self._journal_storage.diff()\n        if len(journal_diff) > 0:\n            raise ValidationError(\n                \"StorageDB had a dirty journal when it needed to be clean: %r\" % journal_diff\n            )", "response": "Validates that the storage DB has not been flushed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite value into memory.", "response": "def write(self, start_position: int, size: int, value: bytes) -> None:\n        \"\"\"\n        Write `value` into memory.\n        \"\"\"\n        if size:\n            validate_uint256(start_position)\n            validate_uint256(size)\n            validate_is_bytes(value)\n            validate_length(value, length=size)\n            validate_lte(start_position + size, maximum=len(self))\n\n            for idx, v in enumerate(value):\n                self._bytes[start_position + idx] = v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, start_position: int, size: int) -> memoryview:\n        return memoryview(self._bytes)[start_position:start_position + size]", "response": "Return a view into the memoryview"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a value from memory and return a fresh bytes instance", "response": "def read_bytes(self, start_position: int, size: int) -> bytes:\n        \"\"\"\n        Read a value from memory and return a fresh bytes instance\n        \"\"\"\n        return bytes(self._bytes[start_position:start_position + size])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextend the size of the memory to be at minimum start_position + size bytes in length.", "response": "def extend_memory(self, start_position: int, size: int) -> None:\n        \"\"\"\n        Extend the size of the memory to be at minimum ``start_position + size``\n        bytes in length.  Raise `eth.exceptions.OutOfGas` if there is not enough\n        gas to pay for extending the memory.\n        \"\"\"\n        validate_uint256(start_position, title=\"Memory start position\")\n        validate_uint256(size, title=\"Memory size\")\n\n        before_size = ceil32(len(self._memory))\n        after_size = ceil32(start_position + size)\n\n        before_cost = memory_gas_cost(before_size)\n        after_cost = memory_gas_cost(after_size)\n\n        if self.logger.show_debug2:\n            self.logger.debug2(\n                \"MEMORY: size (%s -> %s) | cost (%s -> %s)\",\n                before_size,\n                after_size,\n                before_cost,\n                after_cost,\n            )\n\n        if size:\n            if before_cost < after_cost:\n                gas_fee = after_cost - before_cost\n                self._gas_meter.consume_gas(\n                    gas_fee,\n                    reason=\" \".join((\n                        \"Expanding memory\",\n                        str(before_size),\n                        \"->\",\n                        str(after_size),\n                    ))\n                )\n\n            self._memory.extend(start_position, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef memory_write(self, start_position: int, size: int, value: bytes) -> None:\n        return self._memory.write(start_position, size, value)", "response": "Writes value to memory at start_position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef memory_read(self, start_position: int, size: int) -> memoryview:\n        return self._memory.read(start_position, size)", "response": "Reads and returns a view of size bytes from memory starting at start_position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading and return size bytes from memory starting at start_position.", "response": "def memory_read_bytes(self, start_position: int, size: int) -> bytes:\n        \"\"\"\n        Read and return ``size`` bytes from memory starting at ``start_position``.\n        \"\"\"\n        return self._memory.read_bytes(start_position, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconsumes amount of gas from the remaining gas. Raise eth. exceptions. OutOfGas", "response": "def consume_gas(self, amount: int, reason: str) -> None:\n        \"\"\"\n        Consume ``amount`` of gas from the remaining gas.\n        Raise `eth.exceptions.OutOfGas` if there is not enough gas remaining.\n        \"\"\"\n        return self._gas_meter.consume_gas(amount, reason)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopping and return a number of items equal to num_items from the stack.", "response": "def stack_pop(self, num_items: int=1, type_hint: str=None) -> Any:\n        # TODO: Needs to be replaced with\n        # `Union[int, bytes, Tuple[Union[int, bytes], ...]]` if done properly\n        \"\"\"\n        Pop and return a number of items equal to ``num_items`` from the stack.\n        ``type_hint`` can be either ``'uint256'`` or ``'bytes'``.  The return value\n        will be an ``int`` or ``bytes`` type depending on the value provided for\n        the ``type_hint``.\n\n        Raise `eth.exceptions.InsufficientStack` if there are not enough items on\n        the stack.\n        \"\"\"\n        return self._stack.pop(num_items, type_hint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_push(self, value: Union[int, bytes]) -> None:\n        return self._stack.push(value)", "response": "Pushes a new value onto the stack. Raise eth. exceptions. StackDepthLimit if the stack is full."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares a child message for processing.", "response": "def prepare_child_message(self,\n                              gas: int,\n                              to: Address,\n                              value: int,\n                              data: BytesOrView,\n                              code: bytes,\n                              **kwargs: Any) -> Message:\n        \"\"\"\n        Helper method for creating a child computation.\n        \"\"\"\n        kwargs.setdefault('sender', self.msg.storage_address)\n\n        child_message = Message(\n            gas=gas,\n            to=to,\n            value=value,\n            data=data,\n            code=code,\n            depth=self.msg.depth + 1,\n            **kwargs\n        )\n        return child_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_child_computation(self, child_msg: Message) -> 'BaseComputation':\n        child_computation = self.generate_child_computation(child_msg)\n        self.add_child_computation(child_computation)\n        return child_computation", "response": "Applies the vm message child_msg as a child computation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_log_entries(self) -> List[Tuple[int, bytes, List[int], bytes]]:\n        if self.is_error:\n            return []\n        else:\n            return sorted(itertools.chain(\n                self._log_entries,\n                *(child._get_log_entries() for child in self.children)\n            ))", "response": "Return the log entries for this computation and its children."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_computation(cls,\n                          state: BaseState,\n                          message: Message,\n                          transaction_context: BaseTransactionContext) -> 'BaseComputation':\n        \"\"\"\n        Perform the computation that would be triggered by the VM message.\n        \"\"\"\n        with cls(state, message, transaction_context) as computation:\n            # Early exit on pre-compiles\n            if message.code_address in computation.precompiles:\n                computation.precompiles[message.code_address](computation)\n                return computation\n\n            show_debug2 = computation.logger.show_debug2\n\n            for opcode in computation.code:\n                opcode_fn = computation.get_opcode_fn(opcode)\n\n                if show_debug2:\n                    computation.logger.debug2(\n                        \"OPCODE: 0x%x (%s) | pc: %s\",\n                        opcode,\n                        opcode_fn.mnemonic,\n                        max(0, computation.code.pc - 1),\n                    )\n\n                try:\n                    opcode_fn(computation=computation)\n                except Halt:\n                    break\n        return computation", "response": "Apply the computation that would be triggered by the VM message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the difficulty for a homestead block based on the parent block.", "response": "def compute_homestead_difficulty(parent_header: BlockHeader, timestamp: int) -> int:\n    \"\"\"\n    Computes the difficulty for a homestead block based on the parent block.\n    \"\"\"\n    parent_tstamp = parent_header.timestamp\n    validate_gt(timestamp, parent_tstamp, title=\"Header.timestamp\")\n    offset = parent_header.difficulty // DIFFICULTY_ADJUSTMENT_DENOMINATOR\n    sign = max(\n        1 - (timestamp - parent_tstamp) // HOMESTEAD_DIFFICULTY_ADJUSTMENT_CUTOFF,\n        -99)\n    difficulty = int(max(\n        parent_header.difficulty + offset * sign,\n        min(parent_header.difficulty, DIFFICULTY_MINIMUM)))\n    num_bomb_periods = (\n        (parent_header.block_number + 1) // BOMB_EXPONENTIAL_PERIOD\n    ) - BOMB_EXPONENTIAL_FREE_PERIODS\n    if num_bomb_periods >= 0:\n        return max(difficulty + 2**num_bomb_periods, DIFFICULTY_MINIMUM)\n    else:\n        return difficulty"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_account_db_class(cls) -> Type[BaseAccountDB]:\n        if cls.account_db_class is None:\n            raise AttributeError(\"No account_db_class set for {0}\".format(cls.__name__))\n        return cls.account_db_class", "response": "Returns the class that the account db class uses."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a full snapshot of the current state.", "response": "def snapshot(self) -> Tuple[Hash32, UUID]:\n        \"\"\"\n        Perform a full snapshot of the current state.\n\n        Snapshots are a combination of the :attr:`~state_root` at the time of the\n        snapshot and the id of the changeset from the journaled DB.\n        \"\"\"\n        return self.state_root, self._account_db.record()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreverting the VM to the state at the given snapshot.", "response": "def revert(self, snapshot: Tuple[Hash32, UUID]) -> None:\n        \"\"\"\n        Revert the VM to the state at the snapshot\n        \"\"\"\n        state_root, account_snapshot = snapshot\n\n        # first revert the database state root.\n        self._account_db.state_root = state_root\n        # now roll the underlying database back\n        self._account_db.discard(account_snapshot)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit(self, snapshot: Tuple[Hash32, UUID]) -> None:\n        _, account_snapshot = snapshot\n        self._account_db.commit(account_snapshot)", "response": "Commits the current state of the current snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the hash for the ancestor block with number block_number.", "response": "def get_ancestor_hash(self, block_number: int) -> Hash32:\n        \"\"\"\n        Return the hash for the ancestor block with number ``block_number``.\n        Return the empty bytestring ``b''`` if the block number is outside of the\n        range of available block numbers (typically the last 255 blocks).\n        \"\"\"\n        ancestor_depth = self.block_number - block_number - 1\n        is_ancestor_depth_out_of_range = (\n            ancestor_depth >= MAX_PREV_HEADER_DEPTH or\n            ancestor_depth < 0 or\n            block_number < 0\n        )\n        if is_ancestor_depth_out_of_range:\n            return Hash32(b'')\n\n        try:\n            return nth(ancestor_depth, self.execution_context.prev_hashes)\n        except StopIteration:\n            # Ancestor with specified depth not present\n            return Hash32(b'')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a computation instance for the given message and transaction_context.", "response": "def get_computation(self,\n                        message: Message,\n                        transaction_context: 'BaseTransactionContext') -> 'BaseComputation':\n        \"\"\"\n        Return a computation instance for the given `message` and `transaction_context`\n        \"\"\"\n        if self.computation_class is None:\n            raise AttributeError(\"No `computation_class` has been set for this State\")\n        else:\n            computation = self.computation_class(self, message, transaction_context)\n        return computation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_transaction(\n            self,\n            transaction: BaseOrSpoofTransaction) -> 'BaseComputation':\n        \"\"\"\n        Apply transaction to the vm state\n\n        :param transaction: the transaction to apply\n        :return: the computation\n        \"\"\"\n        if self.state_root != BLANK_ROOT_HASH and not self._account_db.has_root(self.state_root):\n            raise StateRootNotFound(self.state_root)\n        else:\n            return self.execute_transaction(transaction)", "response": "Applies the transaction to the vm state\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the environment variable value.", "response": "def get_env_value(name: str, required: bool=False, default: Any=empty) -> str:\n    \"\"\"\n    Core function for extracting the environment variable.\n\n    Enforces mutual exclusivity between `required` and `default` keywords.\n\n    The `empty` sentinal value is used as the default `default` value to allow\n    other function to handle default/empty logic in the appropriate way.\n    \"\"\"\n    if required and default is not empty:\n        raise ValueError(\"Using `default` with `required=True` is invalid\")\n    elif required:\n        try:\n            value = os.environ[name]\n        except KeyError:\n            raise KeyError(\n                \"Must set environment variable {0}\".format(name)\n            )\n    else:\n        value = os.environ.get(name, default)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef env_int(name: str, required: bool=False, default: Union[Type[empty], int]=empty) -> int:\n    value = get_env_value(name, required=required, default=default)\n    if value is empty:\n        raise ValueError(\n            \"`env_int` requires either a default value to be specified, or for \"\n            \"the variable to be present in the environment\"\n        )\n    return int(value)", "response": "Pulls an environment variable out of the environment and casts it to an integer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef env_float(name: str, required: bool=False, default: Union[Type[empty], float]=empty) -> float:\n    value = get_env_value(name, required=required, default=default)\n    if value is empty:\n        raise ValueError(\n            \"`env_float` requires either a default value to be specified, or for \"\n            \"the variable to be present in the environment\"\n        )\n    return float(value)", "response": "Pulls an environment variable out of the environment and casts it to a float."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npulls an environment variable out of the environment and returns it as a boolean.", "response": "def env_bool(name: str,\n             truthy_values: Iterable[Any]=TRUE_VALUES,\n             required: bool=False,\n             default: Union[Type[empty], bool]=empty) -> bool:\n    \"\"\"Pulls an environment variable out of the environment returning it as a\n    boolean. The strings ``'True'`` and ``'true'`` are the default *truthy*\n    values. If not present in the environment and no default is specified,\n    ``None`` is returned.\n\n    :param name: The name of the environment variable be pulled\n    :type name: str\n\n    :param truthy_values: An iterable of values that should be considered\n    truthy.\n    :type truthy_values: iterable\n\n    :param required: Whether the environment variable is required. If ``True``\n    and the variable is not present, a ``KeyError`` is raised.\n    :type required: bool\n\n    :param default: The value to return if the environment variable is not\n    present. (Providing a default alongside setting ``required=True`` will raise\n    a ``ValueError``)\n    :type default: bool\n    \"\"\"\n    value = get_env_value(name, required=required, default=default)\n    if value is empty:\n        return None\n    return value in TRUE_VALUES"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npull an environment variable out of the environment and returns it as a string.", "response": "def env_string(name: str, required: bool=False, default: Union[Type[empty], str]=empty) -> str:\n    \"\"\"Pulls an environment variable out of the environment returning it as a\n    string. If not present in the environment and no default is specified, an\n    empty string is returned.\n\n    :param name: The name of the environment variable be pulled\n    :type name: str\n\n    :param required: Whether the environment variable is required. If ``True``\n    and the variable is not present, a ``KeyError`` is raised.\n    :type required: bool\n\n    :param default: The value to return if the environment variable is not\n    present. (Providing a default alongside setting ``required=True`` will raise\n    a ``ValueError``)\n    :type default: bool\n    \"\"\"\n    value = get_env_value(name, default=default, required=required)\n    if value is empty:\n        value = ''\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npull an environment variable out of the environment and returns it as a list.", "response": "def env_list(name: str,\n             separator: str =',',\n             required: bool=False,\n             default: Union[Type[empty], List[Any]]=empty) -> List[Any]:\n    \"\"\"Pulls an environment variable out of the environment, splitting it on a\n    separator, and returning it as a list. Extra whitespace on the list values\n    is stripped. List values that evaluate as falsy are removed. If not present\n    and no default specified, an empty list is returned.\n\n    :param name: The name of the environment variable be pulled\n    :type name: str\n\n    :param separator: The separator that the string should be split on.\n    :type separator: str\n\n    :param required: Whether the environment variable is required. If ``True``\n    and the variable is not present, a ``KeyError`` is raised.\n    :type required: bool\n\n    :param default: The value to return if the environment variable is not\n    present. (Providing a default alongside setting ``required=True`` will raise\n    a ``ValueError``)\n    :type default: bool\n    \"\"\"\n    value = get_env_value(name, required=required, default=default)\n    if value is empty:\n        return []\n    # wrapped in list to force evaluation in python 3\n    return list(filter(bool, [v.strip() for v in value.split(separator)]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the receipt resulting from applying the transaction.", "response": "def make_receipt(self,\n                     base_header: BlockHeader,\n                     transaction: BaseTransaction,\n                     computation: BaseComputation,\n                     state: BaseState) -> Receipt:\n        \"\"\"\n        Generate the receipt resulting from applying the transaction.\n\n        :param base_header: the header of the block before the transaction was applied.\n        :param transaction: the transaction used to generate the receipt\n        :param computation: the result of running the transaction computation\n        :param state: the resulting state, after executing the computation\n\n        :return: receipt\n        \"\"\"\n        raise NotImplementedError(\"VM classes must implement this method\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_state(\n            cls,\n            db: BaseAtomicDB,\n            header: BlockHeader,\n            previous_hashes: Iterable[Hash32] = ()) -> BaseState:\n        \"\"\"\n        You probably want `VM().state` instead of this.\n\n        Occasionally, you want to build custom state against a particular header and DB,\n        even if you don't have the VM initialized. This is a convenience method to do that.\n        \"\"\"\n\n        execution_context = header.create_execution_context(previous_hashes)\n        return cls.get_state_class()(db, execution_context, header.state_root)", "response": "Builds a state object from a block header and DB."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply the transaction to the current block.", "response": "def apply_transaction(self,\n                          header: BlockHeader,\n                          transaction: BaseTransaction\n                          ) -> Tuple[Receipt, BaseComputation]:\n        \"\"\"\n        Apply the transaction to the current block. This is a wrapper around\n        :func:`~eth.vm.state.State.apply_transaction` with some extra orchestration logic.\n\n        :param header: header of the block before application\n        :param transaction: to apply\n        \"\"\"\n        self.validate_transaction_against_header(header, transaction)\n        computation = self.state.apply_transaction(transaction)\n        receipt = self.make_receipt(header, transaction, computation, self.state)\n        self.validate_receipt(receipt)\n\n        return receipt, computation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_bytecode(self,\n                         origin: Address,\n                         gas_price: int,\n                         gas: int,\n                         to: Address,\n                         sender: Address,\n                         value: int,\n                         data: bytes,\n                         code: bytes,\n                         code_address: Address=None,\n                         ) -> BaseComputation:\n        \"\"\"\n        Execute raw bytecode in the context of the current state of\n        the virtual machine.\n        \"\"\"\n        if origin is None:\n            origin = sender\n\n        # Construct a message\n        message = Message(\n            gas=gas,\n            to=to,\n            sender=sender,\n            value=value,\n            data=data,\n            code=code,\n            code_address=code_address,\n        )\n\n        # Construction a tx context\n        transaction_context = self.state.get_transaction_context_class()(\n            gas_price=gas_price,\n            origin=origin,\n        )\n\n        # Execute it in the VM\n        return self.state.get_computation(message, transaction_context).apply_computation(\n            self.state,\n            message,\n            transaction_context,\n        )", "response": "Execute raw bytecode in the current state of the virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply all transactions to the base header and returns the final header the receipts and the computations.", "response": "def apply_all_transactions(\n            self,\n            transactions: Tuple[BaseTransaction, ...],\n            base_header: BlockHeader\n    ) -> Tuple[BlockHeader, Tuple[Receipt, ...], Tuple[BaseComputation, ...]]:\n        \"\"\"\n        Determine the results of applying all transactions to the base header.\n        This does *not* update the current block or header of the VM.\n\n        :param transactions: an iterable of all transactions to apply\n        :param base_header: the starting header to apply transactions to\n        :return: the final header, the receipts of each transaction, and the computations\n        \"\"\"\n        if base_header.block_number != self.header.block_number:\n            raise ValidationError(\n                \"This VM instance must only work on block #{}, \"\n                \"but the target header has block #{}\".format(\n                    self.header.block_number,\n                    base_header.block_number,\n                )\n            )\n\n        receipts = []\n        computations = []\n        previous_header = base_header\n        result_header = base_header\n\n        for transaction in transactions:\n            receipt, computation = self.apply_transaction(\n                previous_header,\n                transaction,\n            )\n            result_header = self.add_receipt_to_header(previous_header, receipt)\n            previous_header = result_header\n            receipts.append(receipt)\n            computations.append(computation)\n\n        receipts_tuple = tuple(receipts)\n        computations_tuple = tuple(computations)\n\n        return result_header, receipts_tuple, computations_tuple"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport the given block to the chain.", "response": "def import_block(self, block: BaseBlock) -> BaseBlock:\n        \"\"\"\n        Import the given block to the chain.\n        \"\"\"\n        if self.block.number != block.number:\n            raise ValidationError(\n                \"This VM can only import blocks at number #{}, the attempted block was #{}\".format(\n                    self.block.number,\n                    block.number,\n                )\n            )\n\n        self.block = self.block.copy(\n            header=self.configure_header(\n                coinbase=block.header.coinbase,\n                gas_limit=block.header.gas_limit,\n                timestamp=block.header.timestamp,\n                extra_data=block.header.extra_data,\n                mix_hash=block.header.mix_hash,\n                nonce=block.header.nonce,\n                uncles_hash=keccak(rlp.encode(block.uncles)),\n            ),\n            uncles=block.uncles,\n        )\n        # we need to re-initialize the `state` to update the execution context.\n        self._state = self.build_state(self.chaindb.db, self.header, self.previous_hashes)\n\n        # run all of the transactions.\n        new_header, receipts, _ = self.apply_all_transactions(block.transactions, self.header)\n\n        self.block = self.set_block_transactions(\n            self.block,\n            new_header,\n            block.transactions,\n            receipts,\n        )\n\n        return self.mine_block()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmining the current block. Proxies to self. finalize_block method.", "response": "def mine_block(self, *args: Any, **kwargs: Any) -> BaseBlock:\n        \"\"\"\n        Mine the current block. Proxies to self.pack_block method.\n        \"\"\"\n        packed_block = self.pack_block(self.block, *args, **kwargs)\n\n        final_block = self.finalize_block(packed_block)\n\n        # Perform validation\n        self.validate_block(final_block)\n\n        return final_block"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfinalize the block by performing any necessary finalization steps like awarding the block mining reward and persisting the final state root.", "response": "def finalize_block(self, block: BaseBlock) -> BaseBlock:\n        \"\"\"\n        Perform any finalization steps like awarding the block mining reward,\n        and persisting the final state root.\n        \"\"\"\n        if block.number > 0:\n            self._assign_block_rewards(block)\n\n        # We need to call `persist` here since the state db batches\n        # all writes until we tell it to write to the underlying db\n        self.state.persist()\n\n        return block.copy(header=block.header.copy(state_root=self.state.state_root))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pack_block(self, block: BaseBlock, *args: Any, **kwargs: Any) -> BaseBlock:\n        if 'uncles' in kwargs:\n            uncles = kwargs.pop('uncles')\n            kwargs.setdefault('uncles_hash', keccak(rlp.encode(uncles)))\n        else:\n            uncles = block.uncles\n\n        provided_fields = set(kwargs.keys())\n        known_fields = set(BlockHeader._meta.field_names)\n        unknown_fields = provided_fields.difference(known_fields)\n\n        if unknown_fields:\n            raise AttributeError(\n                \"Unable to set the field(s) {0} on the `BlockHeader` class. \"\n                \"Received the following unexpected fields: {1}.\".format(\n                    \", \".join(known_fields),\n                    \", \".join(unknown_fields),\n                )\n            )\n\n        header = block.header.copy(**kwargs)\n        packed_block = block.copy(uncles=uncles, header=header)\n\n        return packed_block", "response": "Packs the block for mining."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_block_from_parent_header_and_coinbase(cls,\n                                                       parent_header: BlockHeader,\n                                                       coinbase: Address) -> BaseBlock:\n        \"\"\"\n        Generate block from parent header and coinbase.\n        \"\"\"\n        block_header = generate_header_from_parent_header(\n            cls.compute_difficulty,\n            parent_header,\n            coinbase,\n            timestamp=parent_header.timestamp + 1,\n        )\n        block = cls.get_block_class()(\n            block_header,\n            transactions=[],\n            uncles=[],\n        )\n        return block", "response": "Generate block from parent header and coinbase."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the previous 255 block hashes.", "response": "def previous_hashes(self) -> Optional[Iterable[Hash32]]:\n        \"\"\"\n        Convenience API for accessing the previous 255 block hashes.\n        \"\"\"\n        return self.get_prev_hashes(self.header.parent_hash, self.chaindb)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a signed transaction for this VM.", "response": "def create_transaction(self, *args: Any, **kwargs: Any) -> BaseTransaction:\n        \"\"\"\n        Proxy for instantiating a signed transaction for this VM.\n        \"\"\"\n        return self.get_transaction_class()(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_unsigned_transaction(cls,\n                                    *,\n                                    nonce: int,\n                                    gas_price: int,\n                                    gas: int,\n                                    to: Address,\n                                    value: int,\n                                    data: bytes) -> 'BaseUnsignedTransaction':\n        \"\"\"\n        Proxy for instantiating an unsigned transaction for this VM.\n        \"\"\"\n        return cls.get_transaction_class().create_unsigned_transaction(\n            nonce=nonce,\n            gas_price=gas_price,\n            gas=gas,\n            to=to,\n            value=value,\n            data=data\n        )", "response": "Creates an unsigned transaction for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the given block.", "response": "def validate_block(self, block: BaseBlock) -> None:\n        \"\"\"\n        Validate the the given block.\n        \"\"\"\n        if not isinstance(block, self.get_block_class()):\n            raise ValidationError(\n                \"This vm ({0!r}) is not equipped to validate a block of type {1!r}\".format(\n                    self,\n                    block,\n                )\n            )\n\n        if block.is_genesis:\n            validate_length_lte(block.header.extra_data, 32, title=\"BlockHeader.extra_data\")\n        else:\n            parent_header = get_parent_header(block.header, self.chaindb)\n            self.validate_header(block.header, parent_header)\n\n        tx_root_hash, _ = make_trie_root_and_nodes(block.transactions)\n        if tx_root_hash != block.header.transaction_root:\n            raise ValidationError(\n                \"Block's transaction_root ({0}) does not match expected value: {1}\".format(\n                    block.header.transaction_root, tx_root_hash))\n\n        if len(block.uncles) > MAX_UNCLES:\n            raise ValidationError(\n                \"Blocks may have a maximum of {0} uncles.  Found \"\n                \"{1}.\".format(MAX_UNCLES, len(block.uncles))\n            )\n\n        if not self.chaindb.exists(block.header.state_root):\n            raise ValidationError(\n                \"`state_root` was not found in the db.\\n\"\n                \"- state_root: {0}\".format(\n                    block.header.state_root,\n                )\n            )\n        local_uncle_hash = keccak(rlp.encode(block.uncles))\n        if local_uncle_hash != block.header.uncles_hash:\n            raise ValidationError(\n                \"`uncles_hash` and block `uncles` do not match.\\n\"\n                \" - num_uncles       : {0}\\n\"\n                \" - block uncle_hash : {1}\\n\"\n                \" - header uncle_hash: {2}\".format(\n                    len(block.uncles),\n                    local_uncle_hash,\n                    block.header.uncles_hash,\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the given header.", "response": "def validate_header(cls,\n                        header: BlockHeader,\n                        parent_header: BlockHeader,\n                        check_seal: bool = True) -> None:\n        \"\"\"\n        :raise eth.exceptions.ValidationError: if the header is not valid\n        \"\"\"\n        if parent_header is None:\n            # to validate genesis header, check if it equals canonical header at block number 0\n            raise ValidationError(\"Must have access to parent header to validate current header\")\n        else:\n            validate_length_lte(header.extra_data, 32, title=\"BlockHeader.extra_data\")\n\n            validate_gas_limit(header.gas_limit, parent_header.gas_limit)\n\n            if header.block_number != parent_header.block_number + 1:\n                raise ValidationError(\n                    \"Blocks must be numbered consecutively. Block number #{} has parent #{}\".format(\n                        header.block_number,\n                        parent_header.block_number,\n                    )\n                )\n\n            # timestamp\n            if header.timestamp <= parent_header.timestamp:\n                raise ValidationError(\n                    \"timestamp must be strictly later than parent, but is {} seconds before.\\n\"\n                    \"- child  : {}\\n\"\n                    \"- parent : {}. \".format(\n                        parent_header.timestamp - header.timestamp,\n                        header.timestamp,\n                        parent_header.timestamp,\n                    )\n                )\n\n            if check_seal:\n                cls.validate_seal(header)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_seal(cls, header: BlockHeader) -> None:\n        check_pow(\n            header.block_number, header.mining_hash,\n            header.mix_hash, header.nonce, header.difficulty)", "response": "Validate the seal on the given header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_uncle(cls, block: BaseBlock, uncle: BaseBlock, uncle_parent: BaseBlock) -> None:\n        if uncle.block_number >= block.number:\n            raise ValidationError(\n                \"Uncle number ({0}) is higher than block number ({1})\".format(\n                    uncle.block_number, block.number))\n\n        if uncle.block_number != uncle_parent.block_number + 1:\n            raise ValidationError(\n                \"Uncle number ({0}) is not one above ancestor's number ({1})\".format(\n                    uncle.block_number, uncle_parent.block_number))\n        if uncle.timestamp < uncle_parent.timestamp:\n            raise ValidationError(\n                \"Uncle timestamp ({0}) is before ancestor's timestamp ({1})\".format(\n                    uncle.timestamp, uncle_parent.timestamp))\n        if uncle.gas_used > uncle.gas_limit:\n            raise ValidationError(\n                \"Uncle's gas usage ({0}) is above the limit ({1})\".format(\n                    uncle.gas_used, uncle.gas_limit))", "response": "Validate the given uncle in the context of the given block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modexp(computation: BaseComputation) -> BaseComputation:\n    data = computation.msg.data_as_bytes\n\n    gas_fee = _compute_modexp_gas_fee(data)\n    computation.consume_gas(gas_fee, reason='MODEXP Precompile')\n\n    result = _modexp(data)\n\n    _, _, modulus_length = _extract_lengths(data)\n\n    # Modulo 0 is undefined, return zero\n    # https://math.stackexchange.com/questions/516251/why-is-n-mod-0-undefined\n    result_bytes = b'' if modulus_length == 0 else zpad_left(\n        int_to_big_endian(result),\n        to_size=modulus_length\n    )\n\n    computation.output = result_bytes\n    return computation", "response": "Compute the modular expansion of the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that all dictionaries in the given list are cleanedly merged.", "response": "def is_cleanly_mergable(*dicts: Dict[Any, Any]) -> bool:\n    \"\"\"Check that nothing will be overwritten when dictionaries are merged using `deep_merge`.\n\n    Examples:\n\n        >>> is_cleanly_mergable({\"a\": 1}, {\"b\": 2}, {\"c\": 3})\n        True\n        >>> is_cleanly_mergable({\"a\": 1}, {\"b\": 2}, {\"a\": 0, c\": 3})\n        False\n        >>> is_cleanly_mergable({\"a\": 1, \"b\": {\"ba\": 2}}, {\"c\": 3, {\"b\": {\"bb\": 4}})\n        True\n        >>> is_cleanly_mergable({\"a\": 1, \"b\": {\"ba\": 2}}, {\"b\": {\"ba\": 4}})\n        False\n\n    \"\"\"\n    if len(dicts) <= 1:\n        return True\n    elif len(dicts) == 2:\n        if not all(isinstance(d, Mapping) for d in dicts):\n            return False\n        else:\n            shared_keys = set(dicts[0].keys()) & set(dicts[1].keys())\n            return all(is_cleanly_mergable(dicts[0][key], dicts[1][key]) for key in shared_keys)\n    else:\n        dict_combinations = itertools.combinations(dicts, 2)\n        return all(is_cleanly_mergable(*combination) for combination in dict_combinations)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all the keys that have been deleted.", "response": "def deleted_keys(self) -> Iterable[bytes]:\n        \"\"\"\n        List all the keys that have been deleted.\n        \"\"\"\n        for key, value in self._changes.items():\n            if value is DELETED:\n                yield key"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pending_items(self) -> Iterable[Tuple[bytes, bytes]]:\n        for key, value in self._changes.items():\n            if value is not DELETED:\n                yield key, value", "response": "A generator that yields all pending items in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply the changes in this diff to the given database.", "response": "def apply_to(self,\n                 db: Union[BaseDB, ABC_Mutable_Mapping],\n                 apply_deletes: bool = True) -> None:\n        \"\"\"\n        Apply the changes in this diff to the given database.\n        You may choose to opt out of deleting any underlying keys.\n\n        :param apply_deletes: whether the pending deletes should be\n            applied to the database\n        \"\"\"\n        for key, value in self._changes.items():\n            if value is DELETED:\n                if apply_deletes:\n                    try:\n                        del db[key]\n                    except KeyError:\n                        pass\n                else:\n                    pass\n            else:\n                db[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining several DBDiff objects into a single DBDiff object.", "response": "def join(cls, diffs: Iterable['DBDiff']) -> 'DBDiff':\n        \"\"\"\n        Join several DBDiff objects into a single DBDiff object.\n\n        In case of a conflict, changes in diffs that come later\n        in ``diffs`` will overwrite changes from earlier changes.\n        \"\"\"\n        tracker = DBDiffTracker()\n        for diff in diffs:\n            diff.apply_to(tracker)\n        return tracker.diff()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the VM class for the given block number.", "response": "def get_vm_class_for_block_number(cls, block_number: BlockNumber) -> Type['BaseVM']:\n        \"\"\"\n        Returns the VM class for the given block number.\n        \"\"\"\n        if cls.vm_configuration is None:\n            raise AttributeError(\"Chain classes must define the VMs in vm_configuration\")\n\n        validate_block_number(block_number)\n        for start_block, vm_class in reversed(cls.vm_configuration):\n            if block_number >= start_block:\n                return vm_class\n        else:\n            raise VMNotFound(\"No vm available for block #{0}\".format(block_number))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_chain(\n            cls,\n            root: BlockHeader,\n            descendants: Tuple[BlockHeader, ...],\n            seal_check_random_sample_rate: int = 1) -> None:\n        \"\"\"\n        Validate that all of the descendents are valid, given that the root header is valid.\n\n        By default, check the seal validity (Proof-of-Work on Ethereum 1.x mainnet) of all headers.\n        This can be expensive. Instead, check a random sample of seals using\n        seal_check_random_sample_rate.\n        \"\"\"\n\n        all_indices = range(len(descendants))\n        if seal_check_random_sample_rate == 1:\n            indices_to_check_seal = set(all_indices)\n        else:\n            sample_size = len(all_indices) // seal_check_random_sample_rate\n            indices_to_check_seal = set(random.sample(all_indices, sample_size))\n\n        header_pairs = sliding_window(2, concatv([root], descendants))\n\n        for index, (parent, child) in enumerate(header_pairs):\n            if child.parent_hash != parent.hash:\n                raise ValidationError(\n                    \"Invalid header chain; {} has parent {}, but expected {}\".format(\n                        child, child.parent_hash, parent.hash))\n            should_check_seal = index in indices_to_check_seal\n            vm_class = cls.get_vm_class_for_block_number(child.block_number)\n            try:\n                vm_class.validate_header(child, parent, check_seal=should_check_seal)\n            except ValidationError as exc:\n                raise ValidationError(\n                    \"%s is not a valid child of %s: %s\" % (\n                        child,\n                        parent,\n                        exc,\n                    )\n                ) from exc", "response": "Validate that all of the headers in the header chain are valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the Chain from a genesis state.", "response": "def from_genesis(cls,\n                     base_db: BaseAtomicDB,\n                     genesis_params: Dict[str, HeaderParams],\n                     genesis_state: AccountState=None) -> 'BaseChain':\n        \"\"\"\n        Initializes the Chain from a genesis state.\n        \"\"\"\n        genesis_vm_class = cls.get_vm_class_for_block_number(BlockNumber(0))\n\n        pre_genesis_header = BlockHeader(difficulty=0, block_number=-1, gas_limit=0)\n        state = genesis_vm_class.build_state(base_db, pre_genesis_header)\n\n        if genesis_state is None:\n            genesis_state = {}\n\n        # mutation\n        apply_state_dict(state, genesis_state)\n        state.persist()\n\n        if 'state_root' not in genesis_params:\n            # If the genesis state_root was not specified, use the value\n            # computed from the initialized state database.\n            genesis_params = assoc(genesis_params, 'state_root', state.state_root)\n        elif genesis_params['state_root'] != state.state_root:\n            # If the genesis state_root was specified, validate that it matches\n            # the computed state from the initialized state database.\n            raise ValidationError(\n                \"The provided genesis state root does not match the computed \"\n                \"genesis state root.  Got {0}.  Expected {1}\".format(\n                    state.state_root,\n                    genesis_params['state_root'],\n                )\n            )\n\n        genesis_header = BlockHeader(**genesis_params)\n        return cls.from_genesis_header(base_db, genesis_header)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the chain from the given genesis header.", "response": "def from_genesis_header(cls,\n                            base_db: BaseAtomicDB,\n                            genesis_header: BlockHeader) -> 'BaseChain':\n        \"\"\"\n        Initializes the chain from the genesis header.\n        \"\"\"\n        chaindb = cls.get_chaindb_class()(base_db)\n        chaindb.persist_header(genesis_header)\n        return cls(base_db)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_vm(self, at_header: BlockHeader=None) -> 'BaseVM':\n        header = self.ensure_header(at_header)\n        vm_class = self.get_vm_class_for_block_number(header.block_number)\n        return vm_class(header=header, chaindb=self.chaindb)", "response": "Returns the VM instance for the given block number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the block header with the given hash. Raises BlockNotFound if there s no block header with the given hash.", "response": "def get_block_header_by_hash(self, block_hash: Hash32) -> BlockHeader:\n        \"\"\"\n        Returns the requested block header as specified by block hash.\n\n        Raises BlockNotFound if there's no block header with the given hash in the db.\n        \"\"\"\n        validate_word(block_hash, title=\"Block Hash\")\n        return self.chaindb.get_block_header_by_hash(block_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the header if it is not None otherwise return the header of the canonical head.", "response": "def ensure_header(self, header: BlockHeader=None) -> BlockHeader:\n        \"\"\"\n        Return ``header`` if it is not ``None``, otherwise return the header\n        of the canonical head.\n        \"\"\"\n        if header is None:\n            head = self.get_canonical_head()\n            return self.create_header_from_parent(head)\n        else:\n            return header"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns limit number of ancestors blocks from the current canonical head.", "response": "def get_ancestors(self, limit: int, header: BlockHeader) -> Tuple[BaseBlock, ...]:\n        \"\"\"\n        Return `limit` number of ancestor blocks from the current canonical head.\n        \"\"\"\n        ancestor_count = min(header.block_number, limit)\n\n        # We construct a temporary block object\n        vm_class = self.get_vm_class_for_block_number(header.block_number)\n        block_class = vm_class.get_block_class()\n        block = block_class(header=header, uncles=[])\n\n        ancestor_generator = iterate(compose(\n            self.get_block_by_hash,\n            operator.attrgetter('parent_hash'),\n            operator.attrgetter('header'),\n        ), block)\n        # we peel off the first element from the iterator which will be the\n        # temporary block object we constructed.\n        next(ancestor_generator)\n\n        return tuple(take(ancestor_count, ancestor_generator))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_block_by_hash(self, block_hash: Hash32) -> BaseBlock:\n        validate_word(block_hash, title=\"Block Hash\")\n        block_header = self.get_block_header_by_hash(block_hash)\n        return self.get_block_by_header(block_header)", "response": "Returns the requested block as specified by block hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the requested block as specified by the block header.", "response": "def get_block_by_header(self, block_header: BlockHeader) -> BaseBlock:\n        \"\"\"\n        Returns the requested block as specified by the block header.\n        \"\"\"\n        vm = self.get_vm(block_header)\n        return vm.block"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_canonical_block_by_number(self, block_number: BlockNumber) -> BaseBlock:\n        validate_uint256(block_number, title=\"Block Number\")\n        return self.get_block_by_hash(self.chaindb.get_canonical_block_hash(block_number))", "response": "Returns the block with the given number in the canonical chain. Raises BlockNotFound if there s no block with the given number in the canonical chain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_block_with_transactions(\n            self,\n            transactions: Tuple[BaseTransaction, ...],\n            parent_header: BlockHeader=None\n    ) -> Tuple[BaseBlock, Tuple[Receipt, ...], Tuple[BaseComputation, ...]]:\n        \"\"\"\n        Generate a block with the provided transactions. This does *not* import\n        that block into your chain. If you want this new block in your chain,\n        run :meth:`~import_block` with the result block from this method.\n\n        :param transactions: an iterable of transactions to insert to the block\n        :param parent_header: parent of the new block -- or canonical head if ``None``\n        :return: (new block, receipts, computations)\n        \"\"\"\n        base_header = self.ensure_header(parent_header)\n        vm = self.get_vm(base_header)\n\n        new_header, receipts, computations = vm.apply_all_transactions(transactions, base_header)\n        new_block = vm.set_block_transactions(vm.block, new_header, transactions, receipts)\n\n        return new_block, receipts, computations", "response": "Generates a new block with the provided transactions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the canonical transaction with the specified hash.", "response": "def get_canonical_transaction(self, transaction_hash: Hash32) -> BaseTransaction:\n        \"\"\"\n        Returns the requested transaction as specified by the transaction hash\n        from the canonical chain.\n\n        Raises TransactionNotFound if no transaction with the specified hash is\n        found in the main chain.\n        \"\"\"\n        (block_num, index) = self.chaindb.get_transaction_index(transaction_hash)\n        VM_class = self.get_vm_class_for_block_number(block_num)\n\n        transaction = self.chaindb.get_transaction_by_index(\n            block_num,\n            index,\n            VM_class.get_transaction_class(),\n        )\n\n        if transaction.hash == transaction_hash:\n            return transaction\n        else:\n            raise TransactionNotFound(\"Found transaction {} instead of {} in block {} at {}\".format(\n                encode_hex(transaction.hash),\n                encode_hex(transaction_hash),\n                block_num,\n                index,\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_transaction(self, *args: Any, **kwargs: Any) -> BaseTransaction:\n        return self.get_vm().create_transaction(*args, **kwargs)", "response": "Passthrough helper to the current VM class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an unsigned transaction for the current VM.", "response": "def create_unsigned_transaction(self,\n                                    *,\n                                    nonce: int,\n                                    gas_price: int,\n                                    gas: int,\n                                    to: Address,\n                                    value: int,\n                                    data: bytes) -> BaseUnsignedTransaction:\n        \"\"\"\n        Passthrough helper to the current VM class.\n        \"\"\"\n        return self.get_vm().create_unsigned_transaction(\n            nonce=nonce,\n            gas_price=gas_price,\n            gas=gas,\n            to=to,\n            value=value,\n            data=data,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_transaction_result(\n            self,\n            transaction: BaseOrSpoofTransaction,\n            at_header: BlockHeader) -> bytes:\n        \"\"\"\n        Return the result of running the given transaction.\n        This is referred to as a `call()` in web3.\n        \"\"\"\n        with self.get_vm(at_header).state_in_temp_block() as state:\n            computation = state.costless_execute_transaction(transaction)\n\n        computation.raise_if_error()\n        return computation.output", "response": "Returns the result of running the given transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nestimate the amount of gas the given transaction will have at the given header.", "response": "def estimate_gas(\n            self,\n            transaction: BaseOrSpoofTransaction,\n            at_header: BlockHeader=None) -> int:\n        \"\"\"\n        Returns an estimation of the amount of gas the given transaction will\n        use if executed on top of the block specified by the given header.\n        \"\"\"\n        if at_header is None:\n            at_header = self.get_canonical_head()\n        with self.get_vm(at_header).state_in_temp_block() as state:\n            return self.gas_estimator(state, transaction)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_block(self,\n                     block: BaseBlock,\n                     perform_validation: bool=True\n                     ) -> Tuple[BaseBlock, Tuple[BaseBlock, ...], Tuple[BaseBlock, ...]]:\n        \"\"\"\n        Imports a complete block and returns a 3-tuple\n\n        - the imported block\n        - a tuple of blocks which are now part of the canonical chain.\n        - a tuple of blocks which were canonical and now are no longer canonical.\n        \"\"\"\n\n        try:\n            parent_header = self.get_block_header_by_hash(block.header.parent_hash)\n        except HeaderNotFound:\n            raise ValidationError(\n                \"Attempt to import block #{}.  Cannot import block {} before importing \"\n                \"its parent block at {}\".format(\n                    block.number,\n                    block.hash,\n                    block.header.parent_hash,\n                )\n            )\n\n        base_header_for_import = self.create_header_from_parent(parent_header)\n        imported_block = self.get_vm(base_header_for_import).import_block(block)\n\n        # Validate the imported block.\n        if perform_validation:\n            validate_imported_block_unchanged(imported_block, block)\n            self.validate_block(imported_block)\n\n        (\n            new_canonical_hashes,\n            old_canonical_hashes,\n        ) = self.chaindb.persist_block(imported_block)\n\n        self.logger.debug(\n            'IMPORTED_BLOCK: number %s | hash %s',\n            imported_block.number,\n            encode_hex(imported_block.hash),\n        )\n\n        new_canonical_blocks = tuple(\n            self.get_block_by_hash(header_hash)\n            for header_hash\n            in new_canonical_hashes\n        )\n        old_canonical_blocks = tuple(\n            self.get_block_by_hash(header_hash)\n            for header_hash\n            in old_canonical_hashes\n        )\n\n        return imported_block, new_canonical_blocks, old_canonical_blocks", "response": "Imports a complete block and returns a 3 - tuple containing the imported block and the new canonical blocks and the old canonical blocks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming validation on a block that is either being mined or imported. Since block validation (specifically the uncle validation) must have access to the ancestor blocks, this validation must occur at the Chain level. Cannot be used to validate genesis block.", "response": "def validate_block(self, block: BaseBlock) -> None:\n        \"\"\"\n        Performs validation on a block that is either being mined or imported.\n\n        Since block validation (specifically the uncle validation) must have\n        access to the ancestor blocks, this validation must occur at the Chain\n        level.\n\n        Cannot be used to validate genesis block.\n        \"\"\"\n        if block.is_genesis:\n            raise ValidationError(\"Cannot validate genesis block this way\")\n        VM_class = self.get_vm_class_for_block_number(BlockNumber(block.number))\n        parent_block = self.get_block_by_hash(block.header.parent_hash)\n        VM_class.validate_header(block.header, parent_block.header, check_seal=True)\n        self.validate_uncles(block)\n        self.validate_gaslimit(block.header)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the seal on the given header.", "response": "def validate_seal(self, header: BlockHeader) -> None:\n        \"\"\"\n        Validate the seal on the given header.\n        \"\"\"\n        VM_class = self.get_vm_class_for_block_number(BlockNumber(header.block_number))\n        VM_class.validate_seal(header)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_gaslimit(self, header: BlockHeader) -> None:\n        parent_header = self.get_block_header_by_hash(header.parent_hash)\n        low_bound, high_bound = compute_gas_limit_bounds(parent_header)\n        if header.gas_limit < low_bound:\n            raise ValidationError(\n                \"The gas limit on block {0} is too low: {1}. It must be at least {2}\".format(\n                    encode_hex(header.hash), header.gas_limit, low_bound))\n        elif header.gas_limit > high_bound:\n            raise ValidationError(\n                \"The gas limit on block {0} is too high: {1}. It must be at most {2}\".format(\n                    encode_hex(header.hash), header.gas_limit, high_bound))", "response": "Validate the gas limit on the given header."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the uncles for the given block.", "response": "def validate_uncles(self, block: BaseBlock) -> None:\n        \"\"\"\n        Validate the uncles for the given block.\n        \"\"\"\n        has_uncles = len(block.uncles) > 0\n        should_have_uncles = block.header.uncles_hash != EMPTY_UNCLE_HASH\n\n        if not has_uncles and not should_have_uncles:\n            # optimization to avoid loading ancestors from DB, since the block has no uncles\n            return\n        elif has_uncles and not should_have_uncles:\n            raise ValidationError(\"Block has uncles but header suggests uncles should be empty\")\n        elif should_have_uncles and not has_uncles:\n            raise ValidationError(\"Header suggests block should have uncles but block has none\")\n\n        # Check for duplicates\n        uncle_groups = groupby(operator.attrgetter('hash'), block.uncles)\n        duplicate_uncles = tuple(sorted(\n            hash for hash, twins in uncle_groups.items() if len(twins) > 1\n        ))\n        if duplicate_uncles:\n            raise ValidationError(\n                \"Block contains duplicate uncles:\\n\"\n                \" - {0}\".format(' - '.join(duplicate_uncles))\n            )\n\n        recent_ancestors = tuple(\n            ancestor\n            for ancestor\n            in self.get_ancestors(MAX_UNCLE_DEPTH + 1, header=block.header)\n        )\n        recent_ancestor_hashes = {ancestor.hash for ancestor in recent_ancestors}\n        recent_uncle_hashes = _extract_uncle_hashes(recent_ancestors)\n\n        for uncle in block.uncles:\n            if uncle.hash == block.hash:\n                raise ValidationError(\"Uncle has same hash as block\")\n\n            # ensure the uncle has not already been included.\n            if uncle.hash in recent_uncle_hashes:\n                raise ValidationError(\n                    \"Duplicate uncle: {0}\".format(encode_hex(uncle.hash))\n                )\n\n            # ensure that the uncle is not one of the canonical chain blocks.\n            if uncle.hash in recent_ancestor_hashes:\n                raise ValidationError(\n                    \"Uncle {0} cannot be an ancestor of {1}\".format(\n                        encode_hex(uncle.hash), encode_hex(block.hash)))\n\n            # ensure that the uncle was built off of one of the canonical chain\n            # blocks.\n            if uncle.parent_hash not in recent_ancestor_hashes or (\n               uncle.parent_hash == block.header.parent_hash):\n                raise ValidationError(\n                    \"Uncle's parent {0} is not an ancestor of {1}\".format(\n                        encode_hex(uncle.parent_hash), encode_hex(block.hash)))\n\n            # Now perform VM level validation of the uncle\n            self.validate_seal(uncle)\n\n            try:\n                uncle_parent = self.get_block_header_by_hash(uncle.parent_hash)\n            except HeaderNotFound:\n                raise ValidationError(\n                    \"Uncle ancestor not found: {0}\".format(uncle.parent_hash)\n                )\n\n            uncle_vm_class = self.get_vm_class_for_block_number(uncle.block_number)\n            uncle_vm_class.validate_uncle(block, uncle, uncle_parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies the given transaction to the current tip block.", "response": "def apply_transaction(self,\n                          transaction: BaseTransaction\n                          ) -> Tuple[BaseBlock, Receipt, BaseComputation]:\n        \"\"\"\n        Applies the transaction to the current tip block.\n\n        WARNING: Receipt and Transaction trie generation is computationally\n        heavy and incurs significant performance overhead.\n        \"\"\"\n        vm = self.get_vm(self.header)\n        base_block = vm.block\n\n        receipt, computation = vm.apply_transaction(base_block.header, transaction)\n        header_with_receipt = vm.add_receipt_to_header(base_block.header, receipt)\n\n        # since we are building the block locally, we have to persist all the incremental state\n        vm.state.persist()\n        new_header = header_with_receipt.copy(state_root=vm.state.state_root)\n\n        transactions = base_block.transactions + (transaction, )\n        receipts = base_block.get_receipts(self.chaindb) + (receipt, )\n\n        new_block = vm.set_block_transactions(base_block, new_header, transactions, receipts)\n\n        self.header = new_block.header\n\n        return new_block, receipt, computation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mine_block(self, *args: Any, **kwargs: Any) -> BaseBlock:\n        mined_block = self.get_vm(self.header).mine_block(*args, **kwargs)\n\n        self.validate_block(mined_block)\n\n        self.chaindb.persist_block(mined_block)\n        self.header = self.create_header_from_parent(mined_block.header)\n        return mined_block", "response": "Mines the current block. Proxies to the current Virtual Machine."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for a host to respond.", "response": "def wait_for_host(port, interval=1, timeout=30, to_start=True, queue=None,\n                  ssl_pymongo_options=None):\n    \"\"\"\n    Ping server and wait for response.\n\n    Ping a mongod or mongos every `interval` seconds until it responds, or\n    `timeout` seconds have passed. If `to_start` is set to False, will wait for\n    the node to shut down instead. This function can be called as a separate\n    thread.\n\n    If queue is provided, it will place the results in the message queue and\n    return, otherwise it will just return the result directly.\n    \"\"\"\n    host = 'localhost:%i' % port\n    start_time = time.time()\n    while True:\n        if (time.time() - start_time) > timeout:\n            if queue:\n                queue.put_nowait((port, False))\n            return False\n        try:\n            # make connection and ping host\n            con = MongoConnection(host, **(ssl_pymongo_options or {}))\n            con.admin.command('ping')\n\n            if to_start:\n                if queue:\n                    queue.put_nowait((port, True))\n                return True\n            else:\n                time.sleep(interval)\n        except Exception:\n            if to_start:\n                time.sleep(interval)\n            else:\n                if queue:\n                    queue.put_nowait((port, True))\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend shutdown command to a mongod or mongos server on given port.", "response": "def shutdown_host(port, username=None, password=None, authdb=None):\n    \"\"\"\n    Send the shutdown command to a mongod or mongos on given port.\n\n    This function can be called as a separate thread.\n    \"\"\"\n    host = 'localhost:%i' % port\n    try:\n        mc = MongoConnection(host)\n        try:\n            if username and password and authdb:\n                if authdb != \"admin\":\n                    raise RuntimeError(\"given username/password is not for \"\n                                       \"admin database\")\n                else:\n                    try:\n                        mc.admin.authenticate(name=username, password=password)\n                    except OperationFailure:\n                        # perhaps auth is not required\n                        pass\n\n            mc.admin.command('shutdown', force=True)\n        except AutoReconnect:\n            pass\n        except OperationFailure:\n            print(\"Error: cannot authenticate to shut down %s.\" % host)\n            return\n\n    except ConnectionFailure:\n        pass\n    else:\n        mc.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, arguments=None):\n        # set up argument parsing in run, so that subsequent calls\n        # to run can call different sub-commands\n        self.argparser = argparse.ArgumentParser()\n        self.argparser.add_argument('--version', action='version',\n                                    version=\"mtools version {0} || Python {1}\".\n                                    format(__version__, sys.version))\n        self.argparser.add_argument('--no-progressbar', action='store_true',\n                                    default=False,\n                                    help='disables progress bar')\n\n        self.argparser.description = ('script to launch MongoDB stand-alone '\n                                      'servers, replica sets and shards.')\n\n        # make sure init is default command even when specifying\n        # arguments directly\n        if arguments and arguments.startswith('-'):\n            arguments = 'init ' + arguments\n\n        # default sub-command is `init` if none provided\n        elif (len(sys.argv) > 1 and sys.argv[1].startswith('-') and\n                sys.argv[1] not in ['-h', '--help', '--version']):\n            sys.argv = sys.argv[0:1] + ['init'] + sys.argv[1:]\n\n        # create command sub-parsers\n        subparsers = self.argparser.add_subparsers(dest='command')\n        self.argparser._action_groups[0].title = 'commands'\n        self.argparser._action_groups[0].description = \\\n            ('init is the default command and can be omitted. To get help on '\n             'individual commands, run mlaunch <command> --help. Command line '\n             'arguments which are not handled by mlaunch will be passed '\n             'through to mongod/mongos if those options are listed in the '\n             '--help output for the current binary. For example: '\n             '--storageEngine, --logappend, or --config.')\n\n        # init command\n        helptext = ('initialize a new MongoDB environment and start '\n                    'stand-alone instances, replica sets, or sharded '\n                    'clusters.')\n        desc = ('Initialize a new MongoDB environment and start stand-alone '\n                'instances, replica sets, or sharded clusters. Command line '\n                'arguments which are not handled by mlaunch will be passed '\n                'through to mongod/mongos if those options are listed in the '\n                '--help output for the current binary. For example: '\n                '--storageEngine, --logappend, or --config.')\n        init_parser = subparsers.add_parser('init', help=helptext,\n                                            description=desc)\n\n        # either single or replica set\n        me_group = init_parser.add_mutually_exclusive_group(required=True)\n        me_group.add_argument('--single', action='store_true',\n                              help=('creates a single stand-alone mongod '\n                                    'instance'))\n        me_group.add_argument('--replicaset', action='store_true',\n                              help=('creates replica set with several mongod '\n                                    'instances'))\n\n        # replica set arguments\n        init_parser.add_argument('--nodes', action='store', metavar='NUM',\n                                 type=int, default=3,\n                                 help=('adds NUM data nodes to replica set '\n                                       '(requires --replicaset, default=3)'))\n        init_parser.add_argument('--arbiter', action='store_true',\n                                 default=False,\n                                 help=('adds arbiter to replica set '\n                                       '(requires --replicaset)'))\n        init_parser.add_argument('--name', action='store', metavar='NAME',\n                                 default='replset',\n                                 help='name for replica set (default=replset)')\n        init_parser.add_argument('--priority', action='store_true',\n                                 default=False,\n                                 help='make lowest-port member primary')\n\n        # sharded clusters\n        init_parser.add_argument('--sharded', '--shards', action='store',\n                                 nargs='+', metavar='N',\n                                 help=('creates a sharded setup consisting of '\n                                       'several singles or replica sets. '\n                                       'Provide either list of shard names or '\n                                       'number of shards.'))\n        init_parser.add_argument('--config', action='store', default=-1,\n                                 type=int, metavar='NUM',\n                                 help=('adds NUM config servers to sharded '\n                                       'setup (requires --sharded, default=1, '\n                                       'with --csrs default=3)'))\n        init_parser.add_argument('--csrs', default=False, action='store_true',\n                                 help=('deploy config servers as a replica '\n                                       'set (requires MongoDB >= 3.2.0)'))\n        init_parser.add_argument('--mongos', action='store', default=1,\n                                 type=int, metavar='NUM',\n                                 help=('starts NUM mongos processes (requires '\n                                       '--sharded, default=1)'))\n\n        # verbose, port, binary path\n        init_parser.add_argument('--verbose', action='store_true',\n                                 default=False,\n                                 help='outputs more verbose information.')\n        init_parser.add_argument('--port', action='store', type=int,\n                                 default=27017,\n                                 help=('port for mongod, start of port range '\n                                       'in case of replica set or shards '\n                                       '(default=27017)'))\n        init_parser.add_argument('--binarypath', action='store', default=None,\n                                 metavar='PATH',\n                                 help=('search for mongod/s binaries in the '\n                                       'specified PATH.'))\n        init_parser.add_argument('--dir', action='store', default='./data',\n                                 help=('base directory to create db and log '\n                                       'paths (default=./data/)'))\n        init_parser.add_argument('--hostname', action='store',\n                                 default='localhost',\n                                 help=('override hostname for replica set '\n                                       'configuration'))\n\n        # authentication, users, roles\n        self._default_auth_roles = ['dbAdminAnyDatabase',\n                                    'readWriteAnyDatabase',\n                                    'userAdminAnyDatabase',\n                                    'clusterAdmin']\n        init_parser.add_argument('--auth', action='store_true', default=False,\n                                 help=('enable authentication and create a '\n                                       'key file and admin user '\n                                       '(default=user/password)'))\n        init_parser.add_argument('--username', action='store', type=str,\n                                 default='user',\n                                 help=('username to add (requires --auth, '\n                                       'default=user)'))\n        init_parser.add_argument('--password', action='store', type=str,\n                                 default='password',\n                                 help=('password for given username (requires '\n                                       '--auth, default=password)'))\n        init_parser.add_argument('--auth-db', action='store', type=str,\n                                 default='admin', metavar='DB',\n                                 help=('database where user will be added '\n                                       '(requires --auth, default=admin)'))\n        init_parser.add_argument('--auth-roles', action='store',\n                                 default=self._default_auth_roles,\n                                 metavar='ROLE', nargs='*',\n                                 help=('admin user''s privilege roles; note'\n                                       'that the clusterAdmin role is '\n                                       'required to run the stop command '\n                                       '(requires --auth, default=\"%s\")'\n                                       % ' '.join(self._default_auth_roles)))\n        init_parser.add_argument('--auth-role-docs', action='store_true',\n                                 default=False,\n                                 help='auth-roles are json documents')\n        init_parser.add_argument('--no-initial-user', action='store_false',\n                                 default=True, dest='initial-user',\n                                 help=('create an initial user if auth is '\n                                       'enabled (default=true)'))\n\n        # ssl\n        def is_file(arg):\n            if not os.path.exists(os.path.expanduser(arg)):\n                init_parser.error(\"The file [%s] does not exist\" % arg)\n            return arg\n\n        ssl_args = init_parser.add_argument_group('SSL Options')\n        ssl_args.add_argument('--sslCAFile',\n                              help='Certificate Authority file for SSL',\n                              type=is_file)\n        ssl_args.add_argument('--sslCRLFile',\n                              help='Certificate Revocation List file for SSL',\n                              type=is_file)\n        ssl_args.add_argument('--sslAllowInvalidHostnames',\n                              action='store_true',\n                              help=('allow client and server certificates to '\n                                    'provide non-matching hostnames'))\n        ssl_args.add_argument('--sslAllowInvalidCertificates',\n                              action='store_true',\n                              help=('allow client or server connections with '\n                                    'invalid certificates'))\n\n        ssl_server_args = init_parser.add_argument_group('Server SSL Options')\n        ssl_server_args.add_argument('--sslOnNormalPorts', action='store_true',\n                                     help='use ssl on configured ports')\n        ssl_server_args.add_argument('--sslMode',\n                                     help='set the SSL operation mode',\n                                     choices=('disabled allowSSL preferSSL '\n                                              'requireSSL'.split()))\n        ssl_server_args.add_argument('--sslPEMKeyFile',\n                                     help='PEM file for ssl', type=is_file)\n        ssl_server_args.add_argument('--sslPEMKeyPassword',\n                                     help='PEM file password')\n        ssl_server_args.add_argument('--sslClusterFile',\n                                     help=('key file for internal SSL '\n                                           'authentication'), type=is_file)\n        ssl_server_args.add_argument('--sslClusterPassword',\n                                     help=('internal authentication key '\n                                           'file password'))\n        ssl_server_args.add_argument('--sslDisabledProtocols',\n                                     help=('comma separated list of TLS '\n                                           'protocols to disable '\n                                           '[TLS1_0,TLS1_1,TLS1_2]'))\n        ssl_server_args.add_argument('--sslWeakCertificateValidation',\n                                     action='store_true',\n                                     help=('allow client to connect without '\n                                           'presenting a certificate'))\n        ssl_server_args.add_argument(('--sslAllowConnectionsWithout'\n                                      'Certificates'), action='store_true',\n                                     help=('allow client to connect without '\n                                           'presenting a certificate'))\n        ssl_server_args.add_argument('--sslFIPSMode', action='store_true',\n                                     help='activate FIPS 140-2 mode')\n\n        ssl_client_args = init_parser.add_argument_group('Client SSL Options')\n        ssl_client_args.add_argument('--sslClientCertificate',\n                                     help='client certificate file for ssl',\n                                     type=is_file)\n        ssl_client_args.add_argument('--sslClientPEMKeyFile',\n                                     help='client PEM file for ssl',\n                                     type=is_file)\n        ssl_client_args.add_argument('--sslClientPEMKeyPassword',\n                                     help='client PEM file password')\n\n        self.ssl_args = ssl_args\n        self.ssl_client_args = ssl_client_args\n        self.ssl_server_args = ssl_server_args\n\n        # start command\n        start_parser = subparsers.add_parser('start',\n                                             help=('starts existing MongoDB '\n                                                   'instances. Example: '\n                                                   '\"mlaunch start config\" '\n                                                   'will start all config '\n                                                   'servers.'),\n                                             description=('starts existing '\n                                                          'MongoDB instances. '\n                                                          'Example: \"mlaunch '\n                                                          'start config\" will '\n                                                          'start all config '\n                                                          'servers.'))\n        start_parser.add_argument('tags', metavar='TAG', action='store',\n                                  nargs='*', default=[],\n                                  help=('without tags, all non-running nodes '\n                                        'will be restarted. Provide '\n                                        'additional tags to narrow down the '\n                                        'set of nodes to start.'))\n        start_parser.add_argument('--verbose', action='store_true',\n                                  default=False,\n                                  help='outputs more verbose information.')\n        start_parser.add_argument('--dir', action='store', default='./data',\n                                  help=('base directory to start nodes '\n                                        '(default=./data/)'))\n        start_parser.add_argument('--binarypath', action='store',\n                                  default=None, metavar='PATH',\n                                  help=('search for mongod/s binaries in the '\n                                        'specified PATH.'))\n\n        # stop command\n        helptext = ('stops running MongoDB instances. Example: \"mlaunch stop '\n                    'shard 2 secondary\" will stop all secondary nodes '\n                    'of shard 2.')\n        desc = ('stops running MongoDB instances with the shutdown command. '\n                'Example: \"mlaunch stop shard 2 secondary\" will stop all '\n                'secondary nodes of shard 2.')\n        stop_parser = subparsers.add_parser('stop',\n                                            help=helptext,\n                                            description=desc)\n        helptext = ('without tags, all running nodes will be stopped. '\n                    'Provide additional tags to narrow down the set of '\n                    'nodes to stop.')\n        stop_parser.add_argument('tags', metavar='TAG', action='store',\n                                 nargs='*', default=[], help=helptext)\n        stop_parser.add_argument('--verbose', action='store_true',\n                                 default=False,\n                                 help='outputs more verbose information.')\n        stop_parser.add_argument('--dir', action='store', default='./data',\n                                 help=('base directory to stop nodes '\n                                       '(default=./data/)'))\n\n        # restart command\n        desc = ('stops running MongoDB instances with the shutdown command. '\n                'Then restarts the stopped instances.')\n        restart_parser = subparsers.add_parser('restart',\n                                               help=('stops, then restarts '\n                                                     'MongoDB instances.'),\n                                               description=desc)\n        restart_parser.add_argument('tags', metavar='TAG', action='store',\n                                    nargs='*', default=[],\n                                    help=('without tags, all non-running '\n                                          'nodes will be restarted. Provide '\n                                          'additional tags to narrow down the '\n                                          'set of nodes to start.'))\n        restart_parser.add_argument('--verbose', action='store_true',\n                                    default=False,\n                                    help='outputs more verbose information.')\n        restart_parser.add_argument('--dir', action='store', default='./data',\n                                    help=('base directory to restart nodes '\n                                          '(default=./data/)'))\n        restart_parser.add_argument('--binarypath', action='store',\n                                    default=None, metavar='PATH',\n                                    help=('search for mongod/s binaries in '\n                                          'the specified PATH.'))\n\n        # list command\n        list_parser = subparsers.add_parser('list',\n                                            help=('list MongoDB instances of '\n                                                  'this environment.'),\n                                            description=('list MongoDB '\n                                                         'instances of this '\n                                                         'environment.'))\n        list_parser.add_argument('--dir', action='store', default='./data',\n                                 help=('base directory to list nodes '\n                                       '(default=./data/)'))\n        list_parser.add_argument('--tags', action='store_true', default=False,\n                                 help=('outputs the tags for each instance. '\n                                       'Tags can be used to target instances '\n                                       'for start/stop/kill.'))\n        list_parser.add_argument('--startup', action='store_true',\n                                 default=False,\n                                 help=('outputs the startup command lines for '\n                                       'each instance.'))\n        list_parser.add_argument('--verbose', action='store_true',\n                                 default=False, help='alias for --tags.')\n\n        # list command\n        helptext = ('kills (or sends another signal to) MongoDB instances '\n                    'of this environment.')\n        desc = ('kills (or sends another signal to) MongoDB instances '\n                'of this environment.')\n        kill_parser = subparsers.add_parser('kill', help=helptext,\n                                            description=desc)\n        kill_parser.add_argument('tags', metavar='TAG', action='store',\n                                 nargs='*', default=[],\n                                 help=('without tags, all running nodes will '\n                                       'be killed. Provide additional tags to '\n                                       'narrow down the set of nodes to '\n                                       'kill.'))\n        kill_parser.add_argument('--dir', action='store', default='./data',\n                                 help=('base directory to kill nodes '\n                                       '(default=./data/)'))\n        kill_parser.add_argument('--signal', action='store', default=15,\n                                 help=('signal to send to processes, '\n                                       'default=15 (SIGTERM)'))\n        kill_parser.add_argument('--verbose', action='store_true',\n                                 default=False,\n                                 help='outputs more verbose information.')\n\n        # argparser is set up, now call base class run()\n        BaseCmdLineTool.run(self, arguments, get_unknowns=True)\n\n        # conditions on argument combinations\n        if (self.args['command'] == 'init' and\n                'single' in self.args and self.args['single']):\n            if self.args['arbiter']:\n                self.argparser.error(\"can't specify --arbiter for \"\n                                     \"single nodes.\")\n\n        # replace path with absolute path, but store relative path as well\n        self.relative_dir = self.args['dir']\n        self.dir = os.path.abspath(self.args['dir'])\n        self.args['dir'] = self.dir\n\n        # branch out in sub-commands\n        getattr(self, self.args['command'])()", "response": "This method is called by the main run method. It sets up argument parsing and then calls the main run method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init(self):\n        # check for existing environment. Only allow subsequent\n        # 'mlaunch init' if they are identical.\n        if self._load_parameters():\n            if self.loaded_args != self.args:\n                raise SystemExit('A different environment already exists '\n                                 'at %s.' % self.dir)\n            first_init = False\n        else:\n            first_init = True\n\n        self.ssl_pymongo_options = self._get_ssl_pymongo_options(self.args)\n\n        if (self._get_ssl_server_args() and not\n                self.args['sslAllowConnectionsWithoutCertificates'] and not\n                self.args['sslClientCertificate'] and not\n                self.args['sslClientPEMKeyFile']):\n            sys.stderr.write('warning: server requires certificates but no'\n                             ' --sslClientCertificate provided\\n')\n\n        # number of default config servers\n        if self.args['config'] == -1:\n            self.args['config'] = 1\n\n        # Check if config replicaset is applicable to this version\n        current_version = self.getMongoDVersion()\n\n        # Exit with error if --csrs is set and MongoDB < 3.1.0\n        if (self.args['csrs'] and\n                LooseVersion(current_version) < LooseVersion(\"3.1.0\") and\n                LooseVersion(current_version) != LooseVersion(\"0.0.0\")):\n            errmsg = (\" \\n * The '--csrs' option requires MongoDB version \"\n                      \"3.2.0 or greater, the current version is %s.\\n\"\n                      % current_version)\n            raise SystemExit(errmsg)\n\n        # add the 'csrs' parameter as default for MongoDB >= 3.3.0\n        if (LooseVersion(current_version) >= LooseVersion(\"3.3.0\") or\n                LooseVersion(current_version) == LooseVersion(\"0.0.0\")):\n            self.args['csrs'] = True\n\n        # construct startup strings\n        self._construct_cmdlines()\n\n        # write out parameters\n        if self.args['verbose']:\n            print(\"writing .mlaunch_startup file.\")\n        self._store_parameters()\n\n        # exit if running in testing mode\n        if self.test:\n            sys.exit(0)\n\n        # check if authentication is enabled, make key file\n        if self.args['auth'] and first_init:\n            if not os.path.exists(self.dir):\n                os.makedirs(self.dir)\n            keyfile = os.path.join(self.dir, \"keyfile\")\n            os.system('openssl rand -base64 753 > %s' % keyfile)\n            if os.name != 'nt':\n                os.system('chmod 600 %s' % keyfile)\n\n        # if not all ports are free, complain and suggest alternatives.\n        all_ports = self.get_tagged(['all'])\n        ports_avail = self.wait_for(all_ports, 1, 1, to_start=False)\n\n        if not all(map(itemgetter(1), ports_avail)):\n            dir_addon = (' --dir %s' % self.relative_dir\n                         if self.relative_dir != './data' else '')\n            errmsg = ('\\nThe following ports are not available: %s\\n\\n'\n                      % ', '.join([str(p[0])\n                                   for p in ports_avail if not p[1]]))\n            errmsg += (\" * If you want to restart nodes from this \"\n                       \"environment, use 'mlaunch start%s' instead.\\n\"\n                       % dir_addon)\n            errmsg += (\" * If the ports are used by a different mlaunch \"\n                       \"environment, stop those first with 'mlaunch stop \"\n                       \"--dir <env>'.\\n\")\n            errmsg += (\" * You can also specify a different port range with \"\n                       \"an additional '--port <startport>'\\n\")\n            raise SystemExit(errmsg)\n\n        if self.args['sharded']:\n\n            shard_names = self._get_shard_names(self.args)\n\n            # start mongod (shard and config) nodes and wait\n            nodes = self.get_tagged(['mongod', 'down'])\n            self._start_on_ports(nodes, wait=True, override_auth=True)\n\n            # initiate replica sets if init is called for the first time\n            if first_init:\n                if self.args['csrs']:\n                    # Initiate config servers in a replicaset\n                    if self.args['verbose']:\n                        print('Initiating config server replica set.')\n                    members = sorted(self.get_tagged([\"config\"]))\n                    self._initiate_replset(members[0], \"configRepl\")\n                for shard in shard_names:\n                    # initiate replica set on first member\n                    if self.args['verbose']:\n                        print('Initiating shard replica set %s.' % shard)\n                    members = sorted(self.get_tagged([shard]))\n                    self._initiate_replset(members[0], shard)\n\n            # add mongos\n            mongos = sorted(self.get_tagged(['mongos', 'down']))\n            self._start_on_ports(mongos, wait=True, override_auth=True)\n\n            if first_init:\n                # add shards\n                mongos = sorted(self.get_tagged(['mongos']))\n                con = self.client('localhost:%i' % mongos[0])\n\n                shards_to_add = len(self.shard_connection_str)\n                nshards = con['config']['shards'].count()\n                if nshards < shards_to_add:\n                    if self.args['replicaset']:\n                        print(\"adding shards. can take up to 30 seconds...\")\n                    else:\n                        print(\"adding shards.\")\n\n                shard_conns_and_names = list(zip(self.shard_connection_str,\n                                                 shard_names))\n                while True:\n                    try:\n                        nshards = con['config']['shards'].count()\n                    except Exception:\n                        nshards = 0\n                    if nshards >= shards_to_add:\n                        break\n\n                    for conn_str, name in shard_conns_and_names:\n                        try:\n                            res = con['admin'].command(SON([('addShard',\n                                                             conn_str),\n                                                       ('name', name)]))\n                        except Exception as e:\n                            if self.args['verbose']:\n                                print('%s will retry in a moment.' % e)\n                            continue\n\n                        if res['ok']:\n                            if self.args['verbose']:\n                                print(\"shard %s added successfully\" % conn_str)\n                                shard_conns_and_names.remove((conn_str, name))\n                                break\n                        else:\n                            if self.args['verbose']:\n                                print(res + ' - will retry')\n\n                    time.sleep(1)\n\n        elif self.args['single']:\n            # just start node\n            nodes = self.get_tagged(['single', 'down'])\n            self._start_on_ports(nodes, wait=False)\n\n        elif self.args['replicaset']:\n            # start nodes and wait\n            nodes = sorted(self.get_tagged(['mongod', 'down']))\n            self._start_on_ports(nodes, wait=True)\n\n            # initiate replica set\n            if first_init:\n                self._initiate_replset(nodes[0], self.args['name'])\n\n        # wait for all nodes to be running\n        nodes = self.get_tagged(['all'])\n        self.wait_for(nodes)\n\n        # now that nodes are running, add admin user if authentication enabled\n        if self.args['auth'] and self.args['initial-user'] and first_init:\n            self.discover()\n            nodes = []\n\n            if self.args['sharded']:\n                nodes = self.get_tagged(['mongos', 'running'])\n            elif self.args['single']:\n                nodes = self.get_tagged(['single', 'running'])\n            elif self.args['replicaset']:\n                print(\"waiting for primary to add a user.\")\n                if self._wait_for_primary():\n                    nodes = self.get_tagged(['primary', 'running'])\n                else:\n                    raise RuntimeError(\"failed to find a primary, so adding \"\n                                       \"admin user isn't possible\")\n\n            if not nodes:\n                raise RuntimeError(\"can't connect to server, so adding admin \"\n                                   \"user isn't possible\")\n\n            roles = []\n            found_cluster_admin = False\n            if self.args['auth_role_docs']:\n                for role_str in self.args['auth_roles']:\n                    role_doc = json.loads(role_str)\n                    roles.append(role_doc)\n                    if role_doc['role'] == \"clusterAdmin\":\n                        found_cluster_admin = True\n            else:\n                roles = self.args['auth_roles']\n                found_cluster_admin = \"clusterAdmin\" in roles\n\n            if not found_cluster_admin:\n                warnings.warn(\"the stop command will not work with auth \"\n                              \"because the user does not have the \"\n                              \"clusterAdmin role\")\n\n            self._add_user(sorted(nodes)[0], name=self.args['username'],\n                           password=self.args['password'],\n                           database=self.args['auth_db'],\n                           roles=roles)\n\n            if self.args['sharded']:\n                for shard in shard_names:\n                    members = sorted(self.get_tagged([shard]))\n                    if self.args['verbose']:\n                        print(\"adding users to %s\" % shard)\n                    self._add_user(members[0],\n                                   name=self.args['username'],\n                                   password=self.args['password'],\n                                   database=self.args['auth_db'],\n                                   roles=roles)\n\n            if self.args['verbose']:\n                print(\"added user %s on %s database\" % (self.args['username'],\n                                                        self.args['auth_db']))\n\n        # in sharded env, if --mongos 0, kill the dummy mongos\n        if self.args['sharded'] and self.args['mongos'] == 0:\n            port = self.args['port']\n            print(\"shutting down temporary mongos on localhost:%s\" % port)\n            username = self.args['username'] if self.args['auth'] else None\n            password = self.args['password'] if self.args['auth'] else None\n            authdb = self.args['auth_db'] if self.args['auth'] else None\n            shutdown_host(port, username, password, authdb)\n\n        # discover again, to get up-to-date info\n        self.discover()\n\n        # for sharded authenticated clusters, restart after first_init\n        # to enable auth\n        if self.args['sharded'] and self.args['auth'] and first_init:\n            if self.args['verbose']:\n                print(\"restarting cluster to enable auth...\")\n            self.restart()\n\n        if self.args['auth'] and self.args['initial-user']:\n            print('Username \"%s\", password \"%s\"'\n                  % (self.args['username'], self.args['password']))\n\n        if self.args['verbose']:\n            print(\"done.\")", "response": "Sub-command init.\n\n        Branches out to sharded, replicaset or single node methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        self.discover()\n\n        # startup_info only gets loaded from protocol version 2 on,\n        # check if it's loaded\n        if not self.startup_info:\n            # hack to make environment startable with older protocol\n            # versions < 2: try to start nodes via init if all nodes are down\n            if len(self.get_tagged(['down'])) == len(self.get_tagged(['all'])):\n                self.args = self.loaded_args\n                print(\"upgrading mlaunch environment meta-data.\")\n                return self.init()\n            else:\n                raise SystemExit(\"These nodes were created with an older \"\n                                 \"version of mlaunch (v1.1.1 or below). To \"\n                                 \"upgrade this environment and make use of \"\n                                 \"the start/stop/list commands, stop all \"\n                                 \"nodes manually, then run 'mlaunch start' \"\n                                 \"again. You only have to do this once.\")\n\n        # if new unknown_args are present, compare them with loaded ones\n        # (here we can be certain of protocol v2+)\n        if (self.args['binarypath'] is not None or\n                (self.unknown_args and\n                 set(self.unknown_args) != set(self.loaded_unknown_args))):\n\n            # store current args, use self.args from file (self.loaded_args)\n            start_args = self.args\n            self.args = self.loaded_args\n\n            self.args['binarypath'] = start_args['binarypath']\n            # construct new startup strings with updated unknown args.\n            # They are for this start only and will not be persisted in\n            # the .mlaunch_startup file\n            self._construct_cmdlines()\n\n            # reset to original args for this start command\n            self.args = start_args\n\n        matches = self._get_ports_from_args(self.args, 'down')\n        if len(matches) == 0:\n            raise SystemExit('no nodes started.')\n\n        # start config servers first\n        config_matches = self.get_tagged(['config']).intersection(matches)\n        self._start_on_ports(config_matches, wait=True)\n\n        # start shards next\n        mongod_matches = (self.get_tagged(['mongod']) -\n                          self.get_tagged(['config']))\n        mongod_matches = mongod_matches.intersection(matches)\n        self._start_on_ports(mongod_matches, wait=True)\n\n        # now start mongos\n        mongos_matches = self.get_tagged(['mongos']).intersection(matches)\n        self._start_on_ports(mongos_matches)\n\n        # wait for all matched nodes to be running\n        self.wait_for(matches)\n\n        # refresh discover\n        self.discover()", "response": "Sub - command start."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self):\n        self.discover()\n        print_docs = []\n\n        # mongos\n        for node in sorted(self.get_tagged(['mongos'])):\n            doc = OrderedDict([('process', 'mongos'), ('port', node),\n                              ('status', 'running'\n                               if self.cluster_running[node] else 'down')])\n            print_docs.append(doc)\n\n        if len(self.get_tagged(['mongos'])) > 0:\n            print_docs.append(None)\n\n        # configs\n        for node in sorted(self.get_tagged(['config'])):\n            doc = OrderedDict([('process', 'config server'),\n                              ('port', node),\n                              ('status', 'running'\n                               if self.cluster_running[node] else 'down')])\n            print_docs.append(doc)\n\n        if len(self.get_tagged(['config'])) > 0:\n            print_docs.append(None)\n\n        # mongod\n        for shard in self._get_shard_names(self.loaded_args):\n            tags = []\n            replicaset = ('replicaset' in self.loaded_args and\n                          self.loaded_args['replicaset'])\n            padding = ''\n\n            if shard:\n                print_docs.append(shard)\n                tags.append(shard)\n                padding = '    '\n\n            if replicaset:\n                # primary\n                primary = self.get_tagged(tags + ['primary', 'running'])\n                if len(primary) > 0:\n                    node = list(primary)[0]\n                    print_docs.append(OrderedDict\n                                      ([('process', padding + 'primary'),\n                                        ('port', node),\n                                        ('status', 'running'\n                                         if self.cluster_running[node]\n                                         else 'down')]))\n\n                # secondaries\n                secondaries = self.get_tagged(tags + ['secondary', 'running'])\n                for node in sorted(secondaries):\n                    print_docs.append(OrderedDict\n                                      ([('process', padding + 'secondary'),\n                                        ('port', node),\n                                        ('status', 'running'\n                                         if self.cluster_running[node]\n                                         else 'down')]))\n\n                # data-bearing nodes that are down or not in the\n                # replica set yet\n                mongods = self.get_tagged(tags + ['mongod'])\n                arbiters = self.get_tagged(tags + ['arbiter'])\n\n                nodes = sorted(mongods - primary - secondaries - arbiters)\n                for node in nodes:\n                    print_docs.append(OrderedDict\n                                      ([('process', padding + 'mongod'),\n                                        ('port', node),\n                                        ('status', 'running'\n                                         if self.cluster_running[node]\n                                         else 'down')]))\n\n                # arbiters\n                for node in arbiters:\n                    print_docs.append(OrderedDict\n                                      ([('process', padding + 'arbiter'),\n                                        ('port', node),\n                                        ('status', 'running'\n                                         if self.cluster_running[node]\n                                         else 'down')]))\n\n            else:\n                nodes = self.get_tagged(tags + ['mongod'])\n                if len(nodes) > 0:\n                    node = nodes.pop()\n                    print_docs.append(OrderedDict\n                                      ([('process', padding + 'single'),\n                                        ('port', node),\n                                        ('status', 'running'\n                                         if self.cluster_running[node]\n                                         else 'down')]))\n            if shard:\n                print_docs.append(None)\n\n        processes = self._get_processes()\n        startup = self.startup_info\n\n        # print tags as well\n        for doc in [x for x in print_docs if type(x) == OrderedDict]:\n            try:\n                doc['pid'] = processes[doc['port']].pid\n            except KeyError:\n                doc['pid'] = '-'\n\n            if self.args['verbose'] or self.args['tags']:\n                tags = self.get_tags_of_port(doc['port'])\n                doc['tags'] = ', '.join(tags)\n\n            if self.args['startup']:\n                try:\n                    # first try running process (startup may be modified\n                    # via start command)\n                    doc['startup command'] = ' '.join(processes[doc['port']]\n                                                      .cmdline())\n                except KeyError:\n                    # if not running, use stored startup_info\n                    doc['startup command'] = startup[str(doc['port'])]\n\n        print_docs.append(None)\n        print()\n        print_table(print_docs)\n        if self.loaded_args.get('auth'):\n            print('\\tauth: \"%s:%s\"' % (self.loaded_args.get('username'),\n                                       self.loaded_args.get('password')))", "response": "This method will print a table of all the nodes with status and port."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef discover(self):\n        # need self.args['command'] so fail if it's not available\n        if (not self.args or 'command' not in self.args or not\n                self.args['command']):\n            return\n\n        # load .mlaunch_startup file for start, stop, list, use current\n        # parameters for init\n        if self.args['command'] == 'init':\n            self.loaded_args = self.args\n            self.loaded_unknown_args = self.unknown_args\n        else:\n            if not self._load_parameters():\n                startup_file = os.path.join(self.dir, \".mlaunch_startup\")\n                raise SystemExit(\"Can't read %s, use 'mlaunch init ...' first.\"\n                                 % startup_file)\n\n        self.ssl_pymongo_options = self._get_ssl_pymongo_options(\n            self.loaded_args)\n\n        # reset cluster_* variables\n        self.cluster_tree = {}\n        self.cluster_tags = defaultdict(list)\n        self.cluster_running = {}\n\n        # get shard names\n        shard_names = self._get_shard_names(self.loaded_args)\n\n        # some shortcut variables\n        is_sharded = ('sharded' in self.loaded_args and\n                      self.loaded_args['sharded'] is not None)\n        is_replicaset = ('replicaset' in self.loaded_args and\n                         self.loaded_args['replicaset'])\n        is_single = 'single' in self.loaded_args and self.loaded_args['single']\n        has_arbiter = ('arbiter' in self.loaded_args and\n                       self.loaded_args['arbiter'])\n\n        # determine number of nodes to inspect\n        if is_sharded:\n            num_config = self.loaded_args['config']\n            # at least one temp. mongos for adding shards, will be\n            # killed later on\n            num_mongos = max(1, self.loaded_args['mongos'])\n            num_shards = len(shard_names)\n        else:\n            num_shards = 1\n            num_config = 0\n            num_mongos = 0\n\n        num_nodes_per_shard = self.loaded_args['nodes'] if is_replicaset else 1\n        if has_arbiter:\n            num_nodes_per_shard += 1\n\n        num_nodes = num_shards * num_nodes_per_shard + num_config + num_mongos\n\n        current_port = self.loaded_args['port']\n\n        # tag all nodes with 'all'\n        self.cluster_tags['all'].extend(list(range(current_port,\n                                                   current_port + num_nodes)))\n\n        # tag all nodes with their port number (as string) and whether\n        # they are running\n        for port in range(current_port, current_port + num_nodes):\n            self.cluster_tags[str(port)].append(port)\n\n            running = self.is_running(port)\n            self.cluster_running[port] = running\n            self.cluster_tags['running' if running else 'down'].append(port)\n\n        # find all mongos\n        for i in range(num_mongos):\n            port = i + current_port\n\n            # add mongos to cluster tree\n            self.cluster_tree.setdefault('mongos', []).append(port)\n            # add mongos to tags\n            self.cluster_tags['mongos'].append(port)\n\n        current_port += num_mongos\n\n        # find all mongods (sharded, replicaset or single)\n        if shard_names is None:\n            shard_names = [None]\n\n        for shard in shard_names:\n            port_range = list(range(current_port,\n                                    current_port + num_nodes_per_shard))\n\n            # all of these are mongod nodes\n            self.cluster_tags['mongod'].extend(port_range)\n\n            if shard:\n                # if this is a shard, store in cluster_tree and tag shard name\n                self.cluster_tree.setdefault('shard', []).append(port_range)\n                self.cluster_tags[shard].extend(port_range)\n\n            if is_replicaset:\n                # get replica set states\n                rs_name = shard if shard else self.loaded_args['name']\n\n                try:\n                    mrsc = self.client(\n                        ','.join('localhost:%i' % i for i in port_range),\n                        replicaSet=rs_name)\n\n                    # primary, secondaries, arbiters\n                    # @todo: this is no longer working because MongoClient\n                    # is now non-blocking\n                    if mrsc.primary:\n                        self.cluster_tags['primary'].append(mrsc.primary[1])\n                    self.cluster_tags['secondary'].extend(list(map\n                                                          (itemgetter(1),\n                                                           mrsc.secondaries)))\n                    self.cluster_tags['arbiter'].extend(list(map(itemgetter(1),\n                                                             mrsc.arbiters)))\n\n                    # secondaries in cluster_tree (order is now important)\n                    self.cluster_tree.setdefault('secondary', [])\n                    for i, secondary in enumerate(sorted(map\n                                                         (itemgetter(1),\n                                                          mrsc.secondaries))):\n                        if len(self.cluster_tree['secondary']) <= i:\n                            self.cluster_tree['secondary'].append([])\n                        self.cluster_tree['secondary'][i].append(secondary)\n\n                except (ConnectionFailure, ConfigurationError):\n                    pass\n\n            elif is_single:\n                self.cluster_tags['single'].append(current_port)\n\n            # increase current_port\n            current_port += num_nodes_per_shard\n\n        # add config server to cluster tree\n        self.cluster_tree.setdefault('config', []).append(port)\n\n        # If not CSRS, set the number of config servers to be 1 or 3\n        # This is needed, otherwise `mlaunch init --sharded 2 --replicaset\n        # --config 2` on <3.3.0 will crash\n        if not self.args.get('csrs') and self.args['command'] == 'init':\n            if num_config >= 3:\n                num_config = 3\n            else:\n                num_config = 1\n\n        for i in range(num_config):\n            port = i + current_port\n\n            try:\n                mc = self.client('localhost:%i' % port)\n                mc.admin.command('ping')\n                running = True\n\n            except ConnectionFailure:\n                # node not reachable\n                running = False\n\n            # add config server to cluster tree\n            self.cluster_tree.setdefault('config', []).append(port)\n            # add config server to tags\n            self.cluster_tags['config'].append(port)\n            self.cluster_tags['mongod'].append(port)\n\n        current_port += num_mongos", "response": "This function loads the cluster tree tags and ssl_pymongo_options for each process and returns the cluster tree and cluster_tags and cluster_running structures."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if a host on a specific port is running.", "response": "def is_running(self, port):\n        \"\"\"Return True if a host on a specific port is running.\"\"\"\n        try:\n            con = self.client('localhost:%s' % port)\n            con.admin.command('ping')\n            return True\n        except (AutoReconnect, ConnectionFailure, OperationFailure):\n            # Catch OperationFailure to work around SERVER-31916.\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the set of nodes which are tagged with the given tags.", "response": "def get_tagged(self, tags):\n        \"\"\"\n        Tag format.\n\n        The format for the tags list is tuples for tags: mongos, config, shard,\n        secondary tags of the form (tag, number), e.g. ('mongos', 2) which\n        references the second mongos in the list. For all other tags, it is\n        simply the string, e.g. 'primary'.\n        \"\"\"\n        # if tags is a simple string, make it a list (note: tuples like\n        # ('mongos', 2) must be in a surrounding list)\n        if not hasattr(tags, '__iter__') and type(tags) == str:\n            tags = [tags]\n\n        nodes = set(self.cluster_tags['all'])\n\n        for tag in tags:\n            if re.match(r\"\\w+ \\d{1,2}\", tag):\n                # special case for tuple tags: mongos, config, shard,\n                # secondary. These can contain a number\n                tag, number = tag.split()\n\n                try:\n                    branch = self.cluster_tree[tag][int(number) - 1]\n                except (IndexError, KeyError):\n                    continue\n\n                if hasattr(branch, '__iter__'):\n                    subset = set(branch)\n                else:\n                    subset = set([branch])\n            else:\n                # otherwise use tags dict to get the subset\n                subset = set(self.cluster_tags[tag])\n\n            nodes = nodes.intersection(subset)\n\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all tags related to a given port.", "response": "def get_tags_of_port(self, port):\n        \"\"\"\n        Get all tags related to a given port.\n\n        This is the inverse of what is stored in self.cluster_tags).\n        \"\"\"\n        return(sorted([tag for tag in self.cluster_tags\n                       if port in self.cluster_tags[tag]]))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for a list of ports to be available.", "response": "def wait_for(self, ports, interval=1.0, timeout=30, to_start=True):\n        \"\"\"\n        Spawn threads to ping host using a list of ports.\n\n        Returns when all hosts are running (if to_start=True) / shut down (if\n        to_start=False).\n        \"\"\"\n        threads = []\n        queue = Queue.Queue()\n\n        for port in ports:\n            threads.append(threading.Thread(target=wait_for_host, args=(\n                port, interval, timeout, to_start, queue,\n                self.ssl_pymongo_options)))\n\n        if self.args and 'verbose' in self.args and self.args['verbose']:\n            print(\"waiting for nodes %s...\"\n                  % ('to start' if to_start else 'to shutdown'))\n\n        for thread in threads:\n            thread.start()\n\n        for thread in threads:\n            thread.join()\n\n        # get all results back and return tuple\n        return tuple(queue.get_nowait() for _ in ports)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the. mlaunch_startup file that exists in each datadir.", "response": "def _load_parameters(self):\n        \"\"\"\n        Load the .mlaunch_startup file that exists in each datadir.\n\n        Handles different protocol versions.\n        \"\"\"\n        datapath = self.dir\n\n        startup_file = os.path.join(datapath, '.mlaunch_startup')\n        if not os.path.exists(startup_file):\n            return False\n\n        in_dict = json.load(open(startup_file, 'rb'))\n\n        # handle legacy version without versioned protocol\n        if 'protocol_version' not in in_dict:\n            in_dict['protocol_version'] = 1\n            self.loaded_args = in_dict\n            self.startup_info = {}\n            # hostname was added recently\n            self.loaded_args['hostname'] = socket.gethostname()\n\n        elif in_dict['protocol_version'] == 2:\n            self.startup_info = in_dict['startup_info']\n            self.loaded_unknown_args = in_dict['unknown_args']\n            self.loaded_args = in_dict['parsed_args']\n\n        # changed 'authentication' to 'auth', if present (from old env) rename\n        if 'authentication' in self.loaded_args:\n            self.loaded_args['auth'] = self.loaded_args['authentication']\n            del self.loaded_args['authentication']\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore startup params and config in datadir. mlaunch_startup.", "response": "def _store_parameters(self):\n        \"\"\"Store startup params and config in datadir/.mlaunch_startup.\"\"\"\n        datapath = self.dir\n\n        out_dict = {\n            'protocol_version': 2,\n            'mtools_version': __version__,\n            'parsed_args': self.args,\n            'unknown_args': self.unknown_args,\n            'startup_info': self.startup_info\n        }\n\n        if not os.path.exists(datapath):\n            os.makedirs(datapath)\n        try:\n            json.dump(out_dict,\n                      open(os.path.join(datapath,\n                                        '.mlaunch_startup'), 'w'), indent=-1)\n        except Exception as ex:\n            print(\"ERROR STORING Parameters:\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_paths(self, basedir, name=None):\n        if name:\n            datapath = os.path.join(basedir, name)\n        else:\n            datapath = basedir\n\n        dbpath = os.path.join(datapath, 'db')\n        if not os.path.exists(dbpath):\n            os.makedirs(dbpath)\n        if self.args['verbose']:\n            print('creating directory: %s' % dbpath)\n\n        return datapath", "response": "Create datadir and subdir paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _filter_valid_arguments(self, arguments, binary=\"mongod\",\n                                config=False):\n        \"\"\"\n        Return a list of accepted arguments.\n\n        Check which arguments in list are accepted by the specified binary\n        (mongod, mongos). If an argument does not start with '-' but its\n        preceding argument was accepted, then it is accepted as well. Example\n        ['--slowms', '1000'] both arguments would be accepted for a mongod.\n        \"\"\"\n        # get the help list of the binary\n        if self.args and self.args['binarypath']:\n            binary = os.path.join(self.args['binarypath'], binary)\n        ret = (subprocess.Popen(['%s' % binary, '--help'],\n               stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=False))\n\n        out, err = ret.communicate()\n        accepted_arguments = []\n        # extract all arguments starting with a '-'\n        for line in [option for option in out.decode('utf-8').split('\\n')]:\n            line = line.lstrip()\n            if line.startswith('-'):\n                argument = line.split()[0]\n                # exception: don't allow unsupported config server arguments\n                if config and argument in ['--oplogSize', '--storageEngine',\n                                           '--smallfiles', '--nojournal']:\n                    continue\n                accepted_arguments.append(argument)\n\n        # add undocumented options\n        accepted_arguments.append('--setParameter')\n        if binary.endswith('mongod'):\n            accepted_arguments.append('--wiredTigerEngineConfigString')\n\n        # filter valid arguments\n        result = []\n        for i, arg in enumerate(arguments):\n            if arg.startswith('-'):\n                # check if the binary accepts this argument\n                # or special case -vvv for any number of v\n                argname = arg.split('=', 1)[0]\n                if argname in accepted_arguments or re.match(r'-v+', arg):\n                    result.append(arg)\n                elif (binary.endswith('mongod') and\n                      argname in self.UNDOCUMENTED_MONGOD_ARGS):\n                    result.append(arg)\n                elif self.ignored_arguments.get(binary + argname) is None:\n                    # warn once for each combination of binary and unknown arg\n                    self.ignored_arguments[binary + argname] = True\n                    if not (binary.endswith(\"mongos\") and\n                        arg in self.UNSUPPORTED_MONGOS_ARGS):\n                        print(\"warning: ignoring unknown argument %s for %s\" %\n                            (arg, binary))\n            elif i > 0 and arguments[i - 1] in result:\n                # if it doesn't start with a '-', it could be the value of\n                # the last argument, e.g. `--slowms 1000`\n                result.append(arg)\n\n        # return valid arguments as joined string\n        return ' '.join(result)", "response": "Filter out invalid arguments for the specified binary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the shard names based on the args.", "response": "def _get_shard_names(self, args):\n        \"\"\"\n        Get the shard names based on the self.args['sharded'] parameter.\n\n        If it's a number, create shard names of type shard##, where ## is a\n        2-digit number. Returns a list [None] if no shards are present.\n        \"\"\"\n        if 'sharded' in args and args['sharded']:\n            if len(args['sharded']) == 1:\n                try:\n                    # --sharded was a number, name shards shard01, shard02,\n                    # ... (only works with replica sets)\n                    n_shards = int(args['sharded'][0])\n                    shard_names = ['shard%.2i'\n                                   % (i + 1) for i in range(n_shards)]\n                except ValueError:\n                    # --sharded was a string, use it as name for the one shard\n                    shard_names = args['sharded']\n            else:\n                shard_names = args['sharded']\n        else:\n            shard_names = [None]\n        return shard_names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _initiate_replset(self, port, name, maxwait=30):\n        if not self.args['replicaset'] and name != 'configRepl':\n            if self.args['verbose']:\n                print('Skipping replica set initialization for %s' % name)\n            return\n\n        con = self.client('localhost:%i' % port)\n        try:\n            rs_status = con['admin'].command({'replSetGetStatus': 1})\n            return rs_status\n        except OperationFailure as e:\n            # not initiated yet\n            for i in range(maxwait):\n                try:\n                    con['admin'].command({'replSetInitiate':\n                                          self.config_docs[name]})\n                    break\n                except OperationFailure as e:\n                    print(e.message + \" - will retry\")\n                    time.sleep(1)\n\n            if self.args['verbose']:\n                print(\"initializing replica set '%s' with configuration: %s\"\n                      % (name, self.config_docs[name]))\n            print(\"replica set '%s' initialized.\" % name)", "response": "Initiate a replica set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _construct_cmdlines(self):\n        if self.args['sharded']:\n            # construct startup string for sharded environments\n            self._construct_sharded()\n\n        elif self.args['single']:\n            # construct startup string for single node environment\n            self._construct_single(self.dir, self.args['port'])\n\n        elif self.args['replicaset']:\n            # construct startup strings for a non-sharded replica set\n            self._construct_replset(self.dir, self.args['port'],\n                                    self.args['name'],\n                                    list(range(self.args['nodes'])),\n                                    self.args['arbiter'])\n\n        # discover current setup\n        self.discover()", "response": "Construct the command line for the cancelling and replication sets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _construct_sharded(self):\n\n        current_version = self.getMongoDVersion()\n\n        num_mongos = self.args['mongos'] if self.args['mongos'] > 0 else 1\n        shard_names = self._get_shard_names(self.args)\n\n        # create shards as stand-alones or replica sets\n        nextport = self.args['port'] + num_mongos\n        for shard in shard_names:\n            if (self.args['single'] and\n                    LooseVersion(current_version) >= LooseVersion(\"3.6.0\")):\n                errmsg = \" \\n * In MongoDB 3.6 and above a Shard must be \" \\\n                         \"made up of a replica set. Please use --replicaset \" \\\n                         \"option when starting a sharded cluster.*\"\n                raise SystemExit(errmsg)\n\n            elif (self.args['single'] and\n                    LooseVersion(current_version) < LooseVersion(\"3.6.0\")):\n                self.shard_connection_str.append(\n                    self._construct_single(\n                        self.dir, nextport, name=shard, extra='--shardsvr'))\n                nextport += 1\n            elif self.args['replicaset']:\n                self.shard_connection_str.append(\n                    self._construct_replset(\n                        self.dir, nextport, shard,\n                        num_nodes=list(range(self.args['nodes'])),\n                        arbiter=self.args['arbiter'], extra='--shardsvr'))\n                nextport += self.args['nodes']\n                if self.args['arbiter']:\n                    nextport += 1\n\n        # start up config server(s)\n        config_string = []\n\n        # SCCC config servers (MongoDB <3.3.0)\n        if not self.args['csrs'] and self.args['config'] >= 3:\n            config_names = ['config1', 'config2', 'config3']\n        else:\n            config_names = ['config']\n\n        # CSRS config servers (MongoDB >=3.1.0)\n        if self.args['csrs']:\n            config_string.append(self._construct_config(self.dir, nextport,\n                                                        \"configRepl\", True))\n        else:\n            for name in config_names:\n                self._construct_config(self.dir, nextport, name)\n                config_string.append('%s:%i' % (self.args['hostname'],\n                                                nextport))\n                nextport += 1\n\n        # multiple mongos use <datadir>/mongos/ as subdir for log files\n        if num_mongos > 1:\n            mongosdir = os.path.join(self.dir, 'mongos')\n            if not os.path.exists(mongosdir):\n                if self.args['verbose']:\n                    print(\"creating directory: %s\" % mongosdir)\n                os.makedirs(mongosdir)\n\n        # start up mongos, but put them to the front of the port range\n        nextport = self.args['port']\n        for i in range(num_mongos):\n            if num_mongos > 1:\n                mongos_logfile = 'mongos/mongos_%i.log' % nextport\n            else:\n                mongos_logfile = 'mongos.log'\n            self._construct_mongos(os.path.join(self.dir, mongos_logfile),\n                                   nextport, ','.join(config_string))\n\n            nextport += 1", "response": "Construct command line strings for a sharded cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _construct_replset(self, basedir, portstart, name, num_nodes,\n                           arbiter, extra=''):\n        \"\"\"\n        Construct command line strings for a replicaset.\n\n        Handles single set or sharded cluster.\n        \"\"\"\n        self.config_docs[name] = {'_id': name, 'members': []}\n\n        # Construct individual replica set nodes\n        for i in num_nodes:\n            datapath = self._create_paths(basedir, '%s/rs%i' % (name, i + 1))\n            self._construct_mongod(os.path.join(datapath, 'db'),\n                                   os.path.join(datapath, 'mongod.log'),\n                                   portstart + i, replset=name, extra=extra)\n\n            host = '%s:%i' % (self.args['hostname'], portstart + i)\n            member_config = {\n                '_id': len(self.config_docs[name]['members']),\n                'host': host,\n            }\n\n            # First node gets increased priority.\n            if i == 0 and self.args['priority']:\n                member_config['priority'] = 10\n\n            if i >= 7:\n                member_config['votes'] = 0\n                member_config['priority'] = 0\n\n            self.config_docs[name]['members'].append(member_config)\n\n        # launch arbiter if True\n        if arbiter:\n            datapath = self._create_paths(basedir, '%s/arb' % (name))\n            self._construct_mongod(os.path.join(datapath, 'db'),\n                                   os.path.join(datapath, 'mongod.log'),\n                                   portstart + self.args['nodes'],\n                                   replset=name)\n\n            host = '%s:%i' % (self.args['hostname'],\n                              portstart + self.args['nodes'])\n            (self.config_docs[name]['members']\n             .append({'_id': len(self.config_docs[name]['members']),\n                      'host': host,\n                      'arbiterOnly': True}))\n\n        return(name + '/' +\n               ','.join([c['host']\n                         for c in self.config_docs[name]['members']]))", "response": "Construct command line strings for a single set or sharded cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing command line strings for a config server.", "response": "def _construct_config(self, basedir, port, name=None, isreplset=False):\n        \"\"\"Construct command line strings for a config server.\"\"\"\n        if isreplset:\n            return self._construct_replset(basedir=basedir, portstart=port,\n                                           name=name,\n                                           num_nodes=list(range(\n                                               self.args['config'])),\n                                           arbiter=False, extra='--configsvr')\n        else:\n            datapath = self._create_paths(basedir, name)\n            self._construct_mongod(os.path.join(datapath, 'db'),\n                                   os.path.join(datapath, 'mongod.log'),\n                                   port, replset=None, extra='--configsvr')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _construct_single(self, basedir, port, name=None, extra=''):\n        datapath = self._create_paths(basedir, name)\n        self._construct_mongod(os.path.join(datapath, 'db'),\n                               os.path.join(datapath, 'mongod.log'), port,\n                               replset=None, extra=extra)\n\n        host = '%s:%i' % (self.args['hostname'], port)\n\n        return host", "response": "Construct command line strings for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs command line strings for mongod process.", "response": "def _construct_mongod(self, dbpath, logpath, port, replset=None, extra=''):\n        \"\"\"Construct command line strings for mongod process.\"\"\"\n        rs_param = ''\n        if replset:\n            rs_param = '--replSet %s' % replset\n\n        auth_param = ''\n        if self.args['auth']:\n            key_path = os.path.abspath(os.path.join(self.dir, 'keyfile'))\n            auth_param = '--keyFile %s' % key_path\n\n        if self.unknown_args:\n            config = '--configsvr' in extra\n            extra = self._filter_valid_arguments(self.unknown_args, \"mongod\",\n                                                 config=config) + ' ' + extra\n\n        # set WiredTiger cache size to 1 GB by default\n        if ('--wiredTigerCacheSizeGB' not in extra and\n                self._filter_valid_arguments(['--wiredTigerCacheSizeGB'],\n                                             'mongod')):\n            extra += ' --wiredTigerCacheSizeGB 1 '\n\n        current_version = self.getMongoDVersion()\n\n        # Exit with error if hostname is specified but not bind_ip options\n        if (self.args['hostname'] != 'localhost'\n                and LooseVersion(current_version) >= LooseVersion(\"3.6.0\")\n                and (self.args['sharded'] or self.args['replicaset'])\n                and '--bind_ip' not in extra):\n            os.removedirs(dbpath)\n            errmsg = \" \\n * If hostname is specified, please include \"\\\n                \"'--bind_ip_all' or '--bind_ip' options when deploying \"\\\n                \"replica sets or sharded cluster with MongoDB version 3.6.0 \"\\\n                \"or greater\"\n            raise SystemExit(errmsg)\n\n        extra += self._get_ssl_server_args()\n\n        path = self.args['binarypath'] or ''\n        if os.name == 'nt':\n            newdbpath = dbpath.replace('\\\\', '\\\\\\\\')\n            newlogpath = logpath.replace('\\\\', '\\\\\\\\')\n            command_str = (\"start /b \\\"\\\" \\\"%s\\\" %s --dbpath \\\"%s\\\" \"\n                           \" --logpath \\\"%s\\\" --port %i \"\n                           \"%s %s\" % (os.path.join(path, 'mongod.exe'),\n                                      rs_param, newdbpath, newlogpath, port,\n                                      auth_param, extra))\n        else:\n            command_str = (\"\\\"%s\\\" %s --dbpath \\\"%s\\\" --logpath \\\"%s\\\" \"\n                           \"--port %i --fork \"\n                           \"%s %s\" % (os.path.join(path, 'mongod'), rs_param,\n                                      dbpath, logpath, port, auth_param,\n                                      extra))\n\n        # store parameters in startup_info\n        self.startup_info[str(port)] = command_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _construct_mongos(self, logpath, port, configdb):\n        extra = ''\n\n        auth_param = ''\n        if self.args['auth']:\n            key_path = os.path.abspath(os.path.join(self.dir, 'keyfile'))\n            auth_param = '--keyFile %s' % key_path\n\n        if self.unknown_args:\n            extra = self._filter_valid_arguments(self.unknown_args,\n                                                 \"mongos\") + extra\n\n        extra += ' ' + self._get_ssl_server_args()\n\n        path = self.args['binarypath'] or ''\n        if os.name == 'nt':\n            newlogpath = logpath.replace('\\\\', '\\\\\\\\')\n            command_str = (\"start /b %s --logpath \\\"%s\\\" --port %i --configdb %s \"\n                           \"%s %s \" % (os.path.join(path, 'mongos'),\n                                       newlogpath, port, configdb,\n                                       auth_param, extra))\n        else:\n            command_str = (\"%s --logpath \\\"%s\\\" --port %i --configdb %s %s %s \"\n                           \"--fork\" % (os.path.join(path, 'mongos'), logpath,\n                                       port, configdb, auth_param, extra))\n\n        # store parameters in startup_info\n        self.startup_info[str(port)] = command_str", "response": "Construct command line strings for a mongos process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        if self.mloginfo.logfile.repl_set:\n            print(\"    rs name: %s\" % self.mloginfo.logfile.repl_set)\n            print(\" rs members: %s\"\n                  % (self.mloginfo.logfile.repl_set_members\n                     if self.mloginfo.logfile.repl_set_members\n                     else \"unknown\"))\n            print(\" rs version: %s\"\n                  % (self.mloginfo.logfile.repl_set_version\n                     if self.mloginfo.logfile.repl_set_version\n                     else \"unknown\"))\n            print(\"rs protocol: %s\"\n                  % (self.mloginfo.logfile.repl_set_protocol\n                     if self.mloginfo.logfile.repl_set_protocol\n                     else \"unknown\"))\n        else:\n            print(\"  no rs info changes found\")", "response": "Run this section and print out information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addMatch(self, version, filename, lineno, loglevel, trigger):\n        self.versions.add(version)\n        self.matches[version].append((filename, lineno, loglevel, trigger))", "response": "Add a match to the logcode line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the logevent should be accepted False otherwise.", "response": "def accept(self, logevent):\n        \"\"\"\n        Process line.\n\n        Overwrite BaseFilter.accept() and return True if the provided\n        logevent should be accepted (causing output), or False if not.\n        \"\"\"\n        if logevent.duration is not None:\n            return logevent.duration >= self.slowms\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True on match.", "response": "def accept_line(self, logevent):\n        \"\"\"\n        Return True on match.\n\n        Only match log lines containing 'is now in state' (reflects other\n        node's state changes) or of type \"[rsMgr] replSet PRIMARY\" (reflects\n        own state changes).\n        \"\"\"\n        if (\"is now in state\" in logevent.line_str and\n                logevent.split_tokens[-1] in self.states):\n            return True\n\n        if (\"replSet\" in logevent.line_str and\n                logevent.thread == \"rsMgr\" and\n                logevent.split_tokens[-1] in self.states):\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef color_map(cls, group):\n        print(\"Group %s\" % group)\n        \"\"\"\n        Change default color behavior.\n\n        Map certain states always to the same colors (similar to MMS).\n        \"\"\"\n        try:\n            state_idx = cls.states.index(group)\n        except ValueError:\n            # on any unexpected state, return black\n            state_idx = 5\n        return cls.colors[state_idx], cls.markers[0]", "response": "Map states to color markers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall per artist with possibly a list of indices.", "response": "def onpick(self, event):\n        \"\"\"Called per artist (group), with possibly a list of indices.\"\"\"\n        if hasattr(event.artist, '_mt_legend_item'):\n            # legend item, instead of data point\n            idx = event.artist._mt_legend_item\n            try:\n                self.toggle_artist(self.artists[idx])\n            except IndexError:\n                pass\n            return\n\n        # only print logevents of visible points\n        if not event.artist.get_visible():\n            return\n\n        # get PlotType and let it print that event\n        plot_type = event.artist._mt_plot_type\n        plot_type.clicked(event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends log line to this plot type.", "response": "def add_line(self, logevent):\n        \"\"\"Append log line to this plot type.\"\"\"\n        key = None\n        self.empty = False\n        self.groups.setdefault(key, list()).append(logevent)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logevents(self):\n        for key in self.groups:\n            for logevent in self.groups[key]:\n                yield logevent", "response": "Iterate over all logevents in the groups dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngroup all logevents by the given group.", "response": "def group(self):\n        \"\"\"(re-)group all logevents by the given group.\"\"\"\n        if hasattr(self, 'group_by'):\n            group_by = self.group_by\n        else:\n            group_by = self.default_group_by\n            if self.args['group'] is not None:\n                group_by = self.args['group']\n\n        self.groups = Grouping(self.logevents, group_by)\n        self.groups.move_items(None, 'others')\n        self.groups.sort_by_size(group_limit=self.args['group_limit'],\n                                 discard_others=self.args['no_others'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the histogram over all groups.", "response": "def plot(self, axis, ith_plot, total_plots, limits):\n        \"\"\"\n        Plot the histogram as a whole over all groups.\n\n        Do not plot as individual groups like other plot types.\n        \"\"\"\n        print(self.plot_type_str.upper() + \" plot\")\n        print(\"%5s %9s  %s\" % (\"id\", \" #points\", \"group\"))\n\n        for idx, group in enumerate(self.groups):\n            print(\"%5s %9s  %s\" % (idx + 1, len(self.groups[group]), group))\n\n        print('')\n\n        datasets = []\n        colors = []\n        minx = np.inf\n        maxx = -np.inf\n\n        for idx, group in enumerate(self.groups):\n            x = date2num([logevent.datetime\n                          for logevent in self.groups[group]])\n            minx = min(minx, min(x))\n            maxx = max(maxx, max(x))\n            datasets.append(x)\n            color, marker = self.color_map(group)\n            colors.append(color)\n\n        if total_plots > 1:\n            # if more than one plot, move histogram to twin axis on the right\n            twin_axis = axis.twinx()\n            twin_axis.set_ylabel(self.ylabel)\n            axis.set_zorder(twin_axis.get_zorder() + 1)  # put ax ahead of ax2\n            axis.patch.set_visible(False)  # hide the 'canvas'\n            axis = twin_axis\n\n        n_bins = max(1, int((maxx - minx) * 24. * 60. * 60. / self.bucketsize))\n        if n_bins > 1000:\n            # warning for too many buckets\n            print(\"warning: %i buckets, will take a while to render. \"\n                  \"consider increasing --bucketsize.\" % n_bins)\n\n        n, bins, artists = axis.hist(datasets, bins=n_bins, align='mid',\n                                     log=self.logscale,\n                                     histtype=\"barstacked\"\n                                     if self.barstacked else \"bar\",\n                                     color=colors, edgecolor=\"none\",\n                                     linewidth=0, alpha=0.8, picker=True,\n                                     label=map(str, self.groups.keys()))\n\n        # scale current y-axis to match min and max values\n        axis.set_ylim(np.min(n), np.max(n))\n\n        # add meta-data for picking\n        if len(self.groups) > 1:\n            for g, group in enumerate(self.groups.keys()):\n                for i in range(len(artists[g])):\n                    artists[g][i]._mt_plot_type = self\n                    artists[g][i]._mt_group = group\n                    artists[g][i]._mt_n = n[g][i]\n                    if self.barstacked:\n                        artists[g][i]._mt_n -= (n[g - 1][i] if g > 0 else 0)\n\n                    artists[g][i]._mt_bin = bins[i]\n        else:\n            for i in range(len(artists)):\n                artists[i]._mt_plot_type = self\n                artists[i]._mt_group = group\n                artists[i]._mt_n = n[i]\n                artists[i]._mt_bin = bins[i]\n\n        return artists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting group name and number of items in bin.", "response": "def clicked(self, event):\n        \"\"\"Print group name and number of items in bin.\"\"\"\n        group = event.artist._mt_group\n        n = event.artist._mt_n\n        dt = num2date(event.artist._mt_bin)\n        print(\"%4i %s events in %s sec beginning at %s\"\n              % (n, group, self.bucketsize, dt.strftime(\"%b %d %H:%M:%S\")))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake all elements from the from_group and add it to the to_group.", "response": "def move_items(self, from_group, to_group):\n        \"\"\"Take all elements from the from_group and add it to the to_group.\"\"\"\n        if from_group not in self.keys() or len(self.groups[from_group]) == 0:\n            return\n\n        self.groups.setdefault(to_group, list()).extend(self.groups.get\n                                                        (from_group, list()))\n        if from_group in self.groups:\n            del self.groups[from_group]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts the groups by the number of elements they contain descending.", "response": "def sort_by_size(self, group_limit=None, discard_others=False,\n                     others_label='others'):\n        \"\"\"\n        Sort the groups by the number of elements they contain, descending.\n\n        Also has option to limit the number of groups. If this option is\n        chosen, the remaining elements are placed into another group with the\n        name specified with others_label. if discard_others is True, the others\n        group is removed instead.\n        \"\"\"\n        # sort groups by number of elements\n        self.groups = OrderedDict(sorted(six.iteritems(self.groups),\n                                         key=lambda x: len(x[1]),\n                                         reverse=True))\n\n        # if group-limit is provided, combine remaining groups\n        if group_limit is not None:\n\n            # now group together all groups that did not make the limit\n            if not discard_others:\n                group_keys = self.groups.keys()[group_limit - 1:]\n                self.groups.setdefault(others_label, list())\n            else:\n                group_keys = self.groups.keys()[group_limit:]\n\n            # only go to second last (-1), since the 'others' group is now last\n            for g in group_keys:\n                if not discard_others:\n                    self.groups[others_label].extend(self.groups[g])\n                del self.groups[g]\n\n            # remove if empty\n            if (others_label in self.groups and\n                    len(self.groups[others_label]) == 0):\n                del self.groups[others_label]\n\n        # remove others group regardless of limit if requested\n        if discard_others and others_label in self.groups:\n            del self.groups[others_label]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _strip_counters(self, sub_line):\n        try:\n            end = sub_line.rindex('}')\n        except ValueError:\n            return sub_line\n        else:\n            return sub_line[:(end + 1)]", "response": "Find the end of the codeline by taking out the counters and durations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstripping datetime and other parts so that there is no redundancy.", "response": "def _strip_datetime(self, sub_line):\n        \"\"\"Strip datetime and other parts so that there is no redundancy.\"\"\"\n        try:\n            begin = sub_line.index(']')\n        except ValueError:\n            return sub_line\n        else:\n            # create a \"\" in place character for the beginnings..\n            # needed when interleaving the lists\n            sub = sub_line[begin + 1:]\n            return sub"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the variable parts of the code given a tuple of strings pattern.", "response": "def _find_variable(self, pattern, logline):\n        \"\"\"\n        Return the variable parts of the code given a tuple of strings pattern.\n\n        Example: (this, is, a, pattern) -> 'this is a good pattern' -> [good]\n        \"\"\"\n        var_subs = []\n        # find the beginning of the pattern\n        first_index = logline.index(pattern[0])\n        beg_str = logline[:first_index]\n        # strip the beginning substring\n        var_subs.append(self._strip_datetime(beg_str))\n\n        for patt, patt_next in zip(pattern[:-1], pattern[1:]):\n            # regular expression pattern that finds what's in the middle of\n            # two substrings\n            pat = re.escape(patt) + '(.*)' + re.escape(patt_next)\n            # extract whats in the middle of the two substrings\n            between = re.search(pat, logline)\n            try:\n                # add what's in between if the search isn't none\n                var_subs.append(between.group(1))\n            except Exception:\n                pass\n        rest_of_string = logline.rindex(pattern[-1]) + len(pattern[-1])\n\n        # add the rest of the string to end minus the counters and durations\n        end_str = logline[rest_of_string:]\n        var_subs.append(self._strip_counters(end_str))\n\n        # strip whitespace from each string, but keep the strings themselves\n        # var_subs = [v.strip() for v in var_subs]\n\n        return var_subs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _variable_parts(self, line, codeline):\n        var_subs = []\n        # codeline has pattern and then has the outputs in different versions\n        if codeline:\n            var_subs = self._find_variable(codeline.pattern, line)\n        else:\n            # make variable part of the line string without all the other stuff\n            line_str = self._strip_datetime(self._strip_counters(line))\n            var_subs = [line_str.strip()]\n        return var_subs", "response": "Return variable parts of the codeline given the static parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef combine(self, pattern, variable):\n        inter_zip = izip_longest(variable, pattern, fillvalue='')\n        interleaved = [elt for pair in inter_zip for elt in pair]\n        return ''.join(interleaved)", "response": "Combine a pattern and variable parts to be a line string again."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the datetime to unix epoch ( correctly ).", "response": "def _datetime_to_epoch(self, dt):\n        \"\"\"Convert the datetime to unix epoch (properly).\"\"\"\n        if dt:\n            td = (dt - datetime.datetime.fromtimestamp(0, tzutc()))\n            # don't use total_seconds(), that's only available in 2.7\n            total_secs = int((td.microseconds +\n                              (td.seconds + td.days * 24 * 3600) *\n                              10**6) / 10**6)\n            return total_secs\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_progress(self, progress, prefix=''):\n        total_length = 40\n\n        if progress == 1.:\n            sys.stderr.write('\\r' + ' ' * (total_length + len(prefix) + 50))\n            sys.stderr.write('\\n')\n            sys.stderr.flush()\n        else:\n            bar_length = int(round(total_length * progress))\n            sys.stderr.write('\\r%s [%s%s] %.1f %% '\n                             % (prefix, '=' * bar_length,\n                                ' ' * (total_length - bar_length),\n                                progress * 100))\n            sys.stderr.flush()", "response": "Print a progress bar for longer - running scripts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accept_line(self, logevent):\n        if self.regex_mode:\n            return bool(re.search(self.field, logevent.line_str))\n        else:\n            return getattr(logevent, self.field) is not None", "response": "Return True if the log line has the nominated yaxis field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when an event is clicked.", "response": "def clicked(self, event):\n        \"\"\"\n        Call if an element of this plottype is clicked.\n\n        Implement in sub class.\n        \"\"\"\n        group = event.artist._mt_group\n        indices = event.ind\n\n        # double click only supported on 1.2 or later\n        major, minor, _ = mpl_version.split('.')\n        if (int(major), int(minor)) < (1, 2) or not event.mouseevent.dblclick:\n            for i in indices:\n                print(self.groups[group][i].line_str)\n\n        else:\n            # toggle durline\n            first = indices[0]\n            logevent = self.groups[group][first]\n\n            try:\n                # remove triangle for this event\n                idx = map(itemgetter(0), self.durlines).index(logevent)\n                _, poly = self.durlines[idx]\n                poly.remove()\n                plt.gcf().canvas.draw()\n                del self.durlines[idx]\n\n            except ValueError:\n                # construct triangle and add to list of durlines\n\n                if self.args['optime_start']:\n                    pts = [[date2num(logevent.datetime), 0],\n                           [date2num(logevent.datetime), logevent.duration],\n                           [date2num(logevent.datetime +\n                                     timedelta(milliseconds=logevent.duration)\n                                     ), 0]]\n                else:\n                    pts = [[date2num(logevent.datetime), 0],\n                           [date2num(logevent.datetime), logevent.duration],\n                           [date2num(logevent.datetime -\n                                     timedelta(milliseconds=logevent.duration)\n                                     ), 0]]\n\n                poly = Polygon(pts, closed=True, alpha=0.2, linewidth=0,\n                               facecolor=event.artist.get_markerfacecolor(),\n                               edgecolor=None, zorder=-10000)\n\n                ax = plt.gca()\n                ax.add_patch(poly)\n                plt.gcf().canvas.draw()\n\n                self.durlines.append((logevent, poly))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, arguments=None):\n        LogFileTool.run(self, arguments)\n\n        for i, self.logfile in enumerate(self.args['logfile']):\n            if i > 0:\n                print(\"\\n ------------------------------------------\\n\")\n\n            if self.logfile.datetime_format == 'ctime-pre2.4':\n                # no milliseconds when datetime format doesn't support it\n                start_time = (self.logfile.start.strftime(\"%Y %b %d %H:%M:%S\")\n                              if self.logfile.start else \"unknown\")\n                end_time = (self.logfile.end.strftime(\"%Y %b %d %H:%M:%S\")\n                            if self.logfile.start else \"unknown\")\n            else:\n                # include milliseconds\n                start_time = (self.logfile.start.strftime(\"%Y %b %d \"\n                                                          \"%H:%M:%S.%f\")[:-3]\n                              if self.logfile.start else \"unknown\")\n                end_time = (self.logfile.end.strftime(\"%Y %b %d \"\n                                                      \"%H:%M:%S.%f\")[:-3]\n                            if self.logfile.start else \"unknown\")\n\n            print(\"     source: %s\" % self.logfile.name)\n            print(\"       host: %s\"\n                  % (self.logfile.hostname + ':' + str(self.logfile.port)\n                     if self.logfile.hostname else \"unknown\"))\n            print(\"      start: %s\" % (start_time))\n            print(\"        end: %s\" % (end_time))\n\n            # TODO: add timezone if iso8601 format\n            print(\"date format: %s\" % self.logfile.datetime_format)\n            print(\"     length: %s\" % len(self.logfile))\n            print(\"     binary: %s\" % (self.logfile.binary or \"unknown\"))\n\n            version = (' -> '.join(self.logfile.versions) or \"unknown\")\n\n            # if version is unknown, go by date\n            if version == 'unknown':\n                if self.logfile.datetime_format == 'ctime-pre2.4':\n                    version = '< 2.4 (no milliseconds)'\n                elif self.logfile.datetime_format == 'ctime':\n                    version = '>= 2.4.x ctime (milliseconds present)'\n                elif (self.logfile.datetime_format == \"iso8601-utc\" or\n                      self.logfile.datetime_format == \"iso8601-local\"):\n                    if self.logfile.has_level:\n                        version = '>= 3.0 (iso8601 format, level, component)'\n                    else:\n                        version = '= 2.6.x (iso8601 format)'\n\n            print(\"    version: %s\" % version)\n            print(\"    storage: %s\"\n                  % (self.logfile.storage_engine or 'unknown'))\n\n            # now run all sections\n            for section in self.sections:\n                if section.active:\n                    print(\"\\n%s\" % section.name.upper())\n                    section.run()", "response": "Print useful information about the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filesize(self):\n        if self.from_stdin:\n            return None\n        if not self._filesize:\n            self._calculate_bounds()\n        return self._filesize", "response": "Returns the filesize of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef versions(self):\n        versions = []\n        for v, _ in self.restarts:\n            if len(versions) == 0 or v != versions[-1]:\n                versions.append(v)\n        return versions", "response": "Return all version changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next(self):\n        # use readline here because next() iterator uses internal readahead\n        # buffer so seek position is wrong\n        line = self.filehandle.readline()\n        line = line.decode('utf-8', 'replace')\n        if line == '':\n            raise StopIteration\n        line = line.rstrip('\\n')\n        le = LogEvent(line)\n\n        # hint format and nextpos from previous line\n        if self._datetime_format and self._datetime_nextpos is not None:\n            ret = le.set_datetime_hint(self._datetime_format,\n                                       self._datetime_nextpos,\n                                       self.year_rollover)\n            if not ret:\n                # logevent indicates timestamp format has changed,\n                # invalidate hint info\n                self._datetime_format = None\n                self._datetime_nextpos = None\n        elif le.datetime:\n            # gather new hint info from another logevent\n            self._datetime_format = le.datetime_format\n            self._datetime_nextpos = le._datetime_nextpos\n\n        return le", "response": "Get next line from file and return LogEvent object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over the log file and store the state of the log entries.", "response": "def _iterate_lines(self):\n        \"\"\"Count number of lines (can be expensive).\"\"\"\n        self._num_lines = 0\n        self._restarts = []\n        self._rs_state = []\n\n        ln = 0\n        for ln, line in enumerate(self.filehandle):\n            line = line.decode(\"utf-8\", \"replace\")\n            if (self._has_level is None and\n                    line[28:31].strip() in LogEvent.log_levels and\n                    line[31:39].strip() in LogEvent.log_components):\n                self._has_level = True\n\n            # find version string (fast check to eliminate most lines)\n            if \"version\" in line[:100]:\n                logevent = LogEvent(line)\n                restart = self._check_for_restart(logevent)\n                if restart:\n                    self._restarts.append((restart, logevent))\n\n            if \"starting :\" in line or \"starting:\" in line:\n                # look for hostname, port\n                match = re.search('port=(?P<port>\\d+).*host=(?P<host>\\S+)',\n                                  line)\n                if match:\n                    self._hostname = match.group('host')\n                    self._port = match.group('port')\n\n            \"\"\" For 3.0 the \"[initandlisten] options:\" long entry contained the\n                \"engine\" field if WiredTiger was the storage engine. There were\n                only two engines, MMAPv1 and WiredTiger\n            \"\"\"\n            if \"[initandlisten] options:\" in line:\n                match = re.search('replSet: \"(?P<replSet>\\S+)\"', line)\n                if match:\n                    self._repl_set = match.group('replSet')\n\n                match = re.search('engine: \"(?P<engine>\\S+)\"', line)\n                if match:\n                    self._storage_engine = match.group('engine')\n                else:\n                    self._storage_engine = 'mmapv1'\n\n            \"\"\" For 3.2 the \"[initandlisten] options:\" no longer contains the\n                \"engine\" field So now we have to look for the \"[initandlisten]\n                wiredtiger_open config:\" which was present in 3.0, but would\n                now tell us definitively that wiredTiger is being used\n            \"\"\"\n            if \"[initandlisten] wiredtiger_open config:\" in line:\n                self._storage_engine = 'wiredTiger'\n\n            if \"command admin.$cmd command: { replSetInitiate:\" in line:\n                match = re.search('{ _id: \"(?P<replSet>\\S+)\", '\n                                  'members: (?P<replSetMembers>[^]]+ ])', line)\n                if match:\n                    self._repl_set = match.group('replSet')\n                    self._repl_set_members = match.group('replSetMembers')\n\n            # Replica set config logging in MongoDB 3.0+\n            new_config = (\"New replica set config in use: \")\n            if new_config in line:\n                match = re.search('{ _id: \"(?P<replSet>\\S+)\", '\n                                  'version: (?P<replSetVersion>\\d+), '\n                                  '(protocolVersion: (?P<replSetProtocol>\\d+), )?'\n                                  'members: (?P<replSetMembers>[^]]+ ])', line)\n                if match:\n                    self._repl_set = match.group('replSet')\n                    self._repl_set_members = match.group('replSetMembers')\n                    self._repl_set_protocol = match.group('replSetProtocol')\n                    self._repl_set_version = match.group('replSetVersion')\n\n            # if (\"is now in state\" in line and\n            #        next(state for state in states if line.endswith(state))):\n            if \"is now in state\" in line:\n                tokens = line.split()\n                # 2.6\n                if tokens[1].endswith(']'):\n                    pos = 4\n                else:\n                    pos = 5\n                host = tokens[pos]\n                rs_state = tokens[-1]\n                state = (host, rs_state, LogEvent(line))\n                self._rs_state.append(state)\n                continue\n\n            if \"[rsMgr] replSet\" in line:\n                tokens = line.split()\n                if self._hostname:\n                    host = self._hostname + ':' + self._port\n                else:\n                    host = os.path.basename(self.name)\n                host += ' (self)'\n                if tokens[-1] in self.states:\n                    rs_state = tokens[-1]\n                else:\n                    # 2.6\n                    if tokens[1].endswith(']'):\n                        pos = 2\n                    else:\n                        pos = 6\n                    rs_state = ' '.join(tokens[pos:])\n\n                state = (host, rs_state, LogEvent(line))\n                self._rs_state.append(state)\n                continue\n\n        self._num_lines = ln + 1\n\n        # reset logfile\n        self.filehandle.seek(0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate beginning and end of logfile.", "response": "def _calculate_bounds(self):\n        \"\"\"Calculate beginning and end of logfile.\"\"\"\n        if self._bounds_calculated:\n            # Assume no need to recalc bounds for lifetime of a Logfile object\n            return\n\n        if self.from_stdin:\n            return False\n\n        # we should be able to find a valid log line within max_start_lines\n        max_start_lines = 10\n        lines_checked = 0\n\n        # get start datetime\n        for line in self.filehandle:\n            logevent = LogEvent(line)\n            lines_checked += 1\n            if logevent.datetime:\n                self._start = logevent.datetime\n                self._timezone = logevent.datetime.tzinfo\n                self._datetime_format = logevent.datetime_format\n                self._datetime_nextpos = logevent._datetime_nextpos\n                break\n            if lines_checked > max_start_lines:\n                break\n\n        # sanity check before attempting to find end date\n        if (self._start is None):\n            raise SystemExit(\"Error: <%s> does not appear to be a supported \"\n                             \"MongoDB log file format\" % self.filehandle.name)\n\n        # get end datetime (lines are at most 10k,\n        # go back 30k at most to make sure we catch one)\n        self.filehandle.seek(0, 2)\n        self._filesize = self.filehandle.tell()\n        self.filehandle.seek(-min(self._filesize, 30000), 2)\n\n        for line in reversed(self.filehandle.readlines()):\n            logevent = LogEvent(line)\n            if logevent.datetime:\n                self._end = logevent.datetime\n                break\n\n        # if there was a roll-over, subtract 1 year from start time\n        if self._end < self._start:\n            self._start = self._start.replace(year=self._start.year - 1)\n            self._year_rollover = self._end\n        else:\n            self._year_rollover = False\n\n        # reset logfile\n        self.filehandle.seek(0)\n        self._bounds_calculated = True\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_curr_line(self, prev=False):\n        curr_pos = self.filehandle.tell()\n\n        # jump back 15k characters (at most) and find last newline char\n        jump_back = min(self.filehandle.tell(), 15000)\n        self.filehandle.seek(-jump_back, 1)\n        buff = self.filehandle.read(jump_back)\n        self.filehandle.seek(curr_pos, 0)\n\n        if prev and self.prev_pos is not None and self.prev_pos == curr_pos:\n            # Number of characters to show before/after the log offset\n            error_context = 300\n            self.filehandle.seek(-error_context, 1)\n            buff = self.filehandle.read(curr_pos)\n            hr = \"-\" * 60\n            print(\"Fatal log parsing loop detected trying to find previous \"\n                  \"log line near offset %s in %s:\\n\\n%s\\n%s\\n\"\n                  \"<--- (current log parsing offset) \\n%s\\n%s\\n\"\n                  % (curr_pos, self.name, hr, buff[:error_context],\n                     buff[error_context:error_context + 1], hr),\n                  file=sys.stderr)\n            raise SystemExit(\"Cannot parse %s with requested options\"\n                             % self.filehandle.name)\n        else:\n            self.prev_pos = curr_pos\n        buff = buff.decode(\"utf-8\", \"replace\")\n        newline_pos = buff.rfind('\\n')\n        if prev:\n            newline_pos = buff[:newline_pos].rfind('\\n')\n\n        # move back to last newline char\n        if newline_pos == -1:\n            self.filehandle.seek(0)\n            return self.next()\n\n        self.filehandle.seek(newline_pos - jump_back + 1, 1)\n\n        # roll forward until we found a line with a datetime\n        try:\n            logevent = self.next()\n            while not logevent.datetime:\n                logevent = self.next()\n\n            return logevent\n        except StopIteration:\n            # reached end of file\n            return None", "response": "Internal helper function to find the current line in a log file based on the current seek position."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fast_forward(self, start_dt):\n        if self.from_stdin:\n            # skip lines until start_dt is reached\n            return\n\n        else:\n            # fast bisection path\n            max_mark = self.filesize\n            step_size = max_mark\n\n            # check if start_dt is already smaller than first datetime\n            self.filehandle.seek(0)\n            le = self.next()\n            if le.datetime and le.datetime >= start_dt:\n                self.filehandle.seek(0)\n                return\n\n            le = None\n            self.filehandle.seek(0)\n\n            # search for lower bound\n            while abs(step_size) > 100:\n                step_size = ceil(step_size / 2.)\n\n                self.filehandle.seek(step_size, 1)\n                le = self._find_curr_line()\n                if not le:\n                    break\n\n                if le.datetime >= start_dt:\n                    step_size = -abs(step_size)\n                else:\n                    step_size = abs(step_size)\n\n            if not le:\n                return\n\n            # now walk backwards until we found a truly smaller line\n            while self.filehandle.tell() >= 2 and (le.datetime is None or\n                                                   le.datetime >= start_dt):\n                self.filehandle.seek(-2, 1)\n\n                le = self._find_curr_line(prev=True)", "response": "Fast - forward file to given start_dt datetime obj using binary search."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets up the internal properties of the internal object.", "response": "def setup(self):\n        \"\"\"Get start end end date of logfile before starting to parse.\"\"\"\n        if self.mlogfilter.is_stdin:\n            # assume this year (we have no other info)\n            now = datetime.now()\n            self.startDateTime = datetime(now.year, 1, 1, tzinfo=tzutc())\n            self.endDateTime = datetime(MAXYEAR, 12, 31, tzinfo=tzutc())\n\n        else:\n            logfiles = self.mlogfilter.args['logfile']\n            self.startDateTime = min([lf.start +\n                                      timedelta(hours=self\n                                                .mlogfilter\n                                                .args['timezone'][i])\n                                      for i, lf in enumerate(logfiles)])\n            self.endDateTime = max([lf.end +\n                                    timedelta(hours=self\n                                              .mlogfilter.args['timezone'][i])\n                                    for i, lf in enumerate(logfiles)])\n\n        # now parse for further changes to from and to datetimes\n        dtbound = DateTimeBoundaries(self.startDateTime, self.endDateTime)\n        self.fromDateTime, self.toDateTime = dtbound(self.mlogfilter\n                                                     .args['from'] or None,\n                                                     self.mlogfilter\n                                                     .args['to'] or None)\n\n        # define start_limit for mlogfilter's fast_forward method\n        self.start_limit = self.fromDateTime\n\n        # for single logfile, get file seek position of `to` datetime\n        if (len(self.mlogfilter.args['logfile']) == 1 and not\n                self.mlogfilter.is_stdin):\n\n            if self.mlogfilter.args['to'] != \"end\":\n                # fast forward, get seek value, then reset file\n                logfile = self.mlogfilter.args['logfile'][0]\n                logfile.fast_forward(self.toDateTime)\n                self.seek_to = logfile.filehandle.tell()\n                logfile.filehandle.seek(0)\n            else:\n                self.seek_to = -1\n        else:\n            self.seek_to = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the logevent should be accepted False otherwise.", "response": "def accept(self, logevent):\n        \"\"\"\n        Process line.\n\n        Overwrite BaseFilter.accept() and return True if the provided\n        logevent should be accepted (causing output), or False if not.\n        \"\"\"\n        if self.fromReached and self.seek_to:\n            if self.seek_to != -1:\n                self.toReached = (self.mlogfilter.args['logfile'][0]\n                                  .filehandle.tell() >= self.seek_to)\n            return True\n        else:\n            # slow version has to check each datetime\n            dt = logevent.datetime\n\n            # if logevent has no datetime, accept if between --from and --to\n            if dt is None:\n                return self.fromReached\n\n            if self.fromDateTime <= dt <= self.toDateTime:\n                self.toReached = False\n                self.fromReached = True\n                return True\n\n            elif dt > self.toDateTime:\n                self.toReached = True\n                return False\n\n            else:\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accept(self, logevent):\n        ns = logevent.nscanned\n        nr = logevent.nreturned\n\n        if ns is not None and nr is not None:\n            if nr == 0:\n                # avoid division by 0 errors\n                nr = 1\n            return (ns > 10000 and ns / nr > 100)\n\n        return False", "response": "Return True if the provided logevent should be accepted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calculate_bounds(self):\n        # get start datetime\n        first = self.coll_handle.find_one(None, sort=[(\"ts\", ASCENDING)])\n        last = self.coll_handle.find_one(None, sort=[(\"ts\", DESCENDING)])\n\n        self._start = first['ts']\n        if self._start.tzinfo is None:\n            self._start = self._start.replace(tzinfo=tzutc())\n\n        self._end = last['ts']\n        if self._end.tzinfo is None:\n            self._end = self._end.replace(tzinfo=tzutc())\n\n        return True", "response": "Calculate beginning and end of log events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the logevent should be accepted False otherwise.", "response": "def accept(self, logevent):\n        \"\"\"\n        Process line.\n\n        Overwrite BaseFilter.accept() and return True if the provided\n        logevent should be accepted (causing output), or False if not.\n        \"\"\"\n        for word in self.words:\n            if re.search(word, logevent.line_str):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        if ProfileCollection and isinstance(self.mloginfo.logfile,\n                                            ProfileCollection):\n            print(\"\\n    not available for system.profile collections\\n\")\n            return\n\n        codelines = defaultdict(lambda: 0)\n        non_matches = 0\n\n        # get log file information\n        logfile = self.mloginfo.logfile\n        if logfile.start and logfile.end and not self.mloginfo.args['verbose']:\n            progress_start = self.mloginfo._datetime_to_epoch(logfile.start)\n            progress_total = (self.mloginfo._datetime_to_epoch(logfile.end) -\n                              progress_start)\n        else:\n            self.mloginfo.progress_bar_enabled = False\n\n        for i, logevent in enumerate(self.mloginfo.logfile):\n            cl, _ = self.log2code(logevent.line_str)\n\n            # update progress bar every 1000 lines\n            if self.mloginfo.progress_bar_enabled and (i % 1000 == 0):\n                if logevent.datetime:\n                    progress_curr = self.mloginfo._datetime_to_epoch(logevent\n                                                                     .datetime)\n                    (self.mloginfo\n                     .update_progress(float(progress_curr - progress_start) /\n                                      progress_total))\n\n            if cl:\n                codelines[cl.pattern] += 1\n            else:\n                if logevent.operation:\n                    # skip operations (command, insert, update, delete,\n                    # query, getmore)\n                    continue\n                if not logevent.thread:\n                    # skip the lines that don't have a thread name\n                    # (usually map/reduce or assertions)\n                    continue\n                if len(logevent.split_tokens) - logevent.datetime_nextpos <= 1:\n                    # skip empty log messages (after thread name)\n                    continue\n                if (\"warning: log line attempted\" in logevent.line_str and\n                        \"over max size\" in logevent.line_str):\n                    # skip lines that are too long\n                    continue\n\n                # everything else is a real non-match\n                non_matches += 1\n                if self.mloginfo.args['verbose']:\n                    print(\"couldn't match:\" + logevent)\n\n        # clear progress bar again\n        if self.mloginfo.progress_bar_enabled:\n            self.mloginfo.update_progress(1.0)\n\n        if self.mloginfo.args['verbose']:\n            print('')\n\n        for cl in sorted(codelines, key=lambda x: codelines[x], reverse=True):\n            print(\"%8i  %s\" % (codelines[cl], \" ... \".join(cl)))\n\n        print('')\n        if non_matches > 0:\n            print(\"distinct couldn't match %i lines\" % non_matches)\n            if not self.mloginfo.args['verbose']:\n                print(\"to show non-matched lines, run with --verbose.\")", "response": "Run each line through log2code and group by matched pattern."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shell2json(s):\n    replace = {\n        r'BinData\\(.+?\\)': '1',\n        r'(new )?Date\\(.+?\\)': '1',\n        r'Timestamp\\(.+?\\)': '1',\n        r'ObjectId\\(.+?\\)': '1',\n        r'DBRef\\(.+?\\)': '1',\n        r'undefined': '1',\n        r'MinKey': '1',\n        r'MaxKey': '1',\n        r'NumberLong\\(.+?\\)': '1',\n        r'/.+?/\\w*': '1'\n    }\n\n    for key, value in replace.items():\n        s = re.sub(key, value, s)\n\n    return s", "response": "Convert shell syntax to json."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting JSON format to a query pattern.", "response": "def json2pattern(s):\n    \"\"\"\n    Convert JSON format to a query pattern.\n\n    Includes even mongo shell notation without quoted key names.\n    \"\"\"\n    # make valid JSON by wrapping field names in quotes\n    s, _ = re.subn(r'([{,])\\s*([^,{\\s\\'\"]+)\\s*:', ' \\\\1 \"\\\\2\" : ', s)\n    # handle shell values that are not valid JSON\n    s = shell2json(s)\n    # convert to 1 where possible, to get rid of things like new Date(...)\n    s, n = re.subn(r'([:,\\[])\\s*([^{}\\[\\]\"]+?)\\s*([,}\\]])', '\\\\1 1 \\\\3', s)\n    # now convert to dictionary, converting unicode to ascii\n    try:\n        doc = json.loads(s, object_hook=_decode_pattern_dict)\n        return json.dumps(doc, sort_keys=True, separators=(', ', ': '))\n    except ValueError as ex:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a table of dictionaries.", "response": "def print_table(rows, override_headers=None, uppercase_headers=True):\n    \"\"\"All rows need to be a list of dictionaries, all with the same keys.\"\"\"\n    if len(rows) == 0:\n        return\n    keys = list(rows[0].keys())\n    headers = override_headers or keys\n    if uppercase_headers:\n        rows = [dict(zip(keys,\n                         map(lambda x: x.upper(), headers))), None] + rows\n    else:\n        rows = [dict(zip(keys, headers)), None] + rows\n\n    lengths = [max(len(str(row[k]))\n                   for row in rows if hasattr(row, '__iter__')) for k in keys]\n    tmp = ['{%s:%i}' % (h, l) for h, l in zip(keys[: -1], lengths[: -1])]\n    tmp.append('{%s}' % keys[-1])\n    template = (' ' * 4).join(tmp)\n\n    for row in rows:\n        if type(row) == str:\n            print(row)\n        elif row is None:\n            print()\n        elif isinstance(row, dict): \n            row = {k: v if v is not None else 'None' for k, v in row.items()}\n            print(template.format(**row))\n        else:\n            print(\"Unhandled row type:\", row)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef accept(self, logevent):\n        # if several filters are active, all have to agree\n        if self.components and logevent.component not in self.components:\n            return False\n        if self.levels and logevent.level not in self.levels:\n            return False\n        if self.namespaces and logevent.namespace not in self.namespaces:\n            return False\n        if self.commands and logevent.command not in self.commands:\n            return False\n        if self.operations and logevent.operation not in self.operations:\n            return False\n        if self.threads:\n            if (logevent.thread not in self.threads and\n                    logevent.conn not in self.threads):\n                return False\n        if self.pattern and logevent.pattern != self.pattern:\n            return False\n        if (self.planSummaries and\n                logevent.planSummary not in self.planSummaries):\n            return False\n\n        return True", "response": "Return True if the provided logevent should be accepted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset line_str for this LogEvent.", "response": "def set_line_str(self, line_str):\n        \"\"\"\n        Set line_str.\n\n        Line_str is only writeable if LogEvent was created from a string,\n        not from a system.profile documents.\n        \"\"\"\n        if not self.from_string:\n            raise ValueError(\"can't set line_str for LogEvent created from \"\n                             \"system.profile documents.\")\n\n        if line_str != self._line_str:\n            self._line_str = line_str.rstrip()\n            self._reset()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_line_str(self):\n        if self.from_string:\n            return ' '.join([s for s in [self.merge_marker_str,\n                                         self._datetime_str,\n                                         self._line_str] if s])\n        else:\n            return ' '.join([s for s in [self._datetime_str,\n                                         self._line_str] if s])", "response": "Return line_str depending on source logfile or system. profile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_tokens(self):\n        if not self._split_tokens_calculated:\n            # split into items (whitespace split)\n            self._split_tokens = self._line_str.split()\n            self._split_tokens_calculated = True\n\n        return self._split_tokens", "response": "Split string into tokens ( lazy )."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates duration if available ( lazy ).", "response": "def duration(self):\n        \"\"\"Calculate duration if available (lazy).\"\"\"\n        if not self._duration_calculated:\n            self._duration_calculated = True\n\n            # split_tokens = self.split_tokens\n            line_str = self.line_str\n\n            if (line_str\n                and line_str.endswith('ms')\n                and 'Scheduled new oplog query' not in line_str):\n\n                try:\n                    # find duration from end\n                    space_pos = line_str.rfind(\" \")\n                    if space_pos == -1:\n                        return\n                    self._duration = int(line_str[line_str.rfind(\" \") +\n                                                  1:-2].replace(',', ''))\n                except ValueError:\n                    self._duration = None\n            elif \"flushing\" in self.line_str:\n                matchobj = re.search(r'flushing mmaps took (\\d+)ms',\n                                     self.line_str)\n                if matchobj:\n                    self._duration = int(matchobj.group(1))\n\n        return self._duration"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract datetime if available.", "response": "def datetime(self):\n        \"\"\"Extract datetime if available (lazy).\"\"\"\n        if not self._datetime_calculated:\n            self._datetime_calculated = True\n\n            # if no datetime after 10 tokens, break to avoid parsing\n            # very long lines\n            split_tokens = self.split_tokens[:10]\n\n            for offs in range(len(split_tokens)):\n                dt = self._match_datetime_pattern(split_tokens[offs:offs + 4])\n                if dt:\n                    self._datetime = dt\n                    self._datetime_nextpos = offs\n                    if self._datetime_format.startswith(\"iso8601\"):\n                        self._datetime_nextpos += 1\n                    else:\n                        self._datetime_nextpos += 4\n\n                    # separate datetime str and linestr\n                    self._line_str = (' '.join(self.split_tokens\n                                               [self._datetime_nextpos:]))\n\n                    if self.level:\n                        self._datetime_nextpos += 2\n\n                    self._reformat_timestamp(self._datetime_format)\n                    break\n\n        return self._datetime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _match_datetime_pattern(self, tokens):\n        # first check: less than 4 tokens can't be ctime\n        assume_iso8601_format = len(tokens) < 4\n\n        # check for ctime-pre-2.4 or ctime format\n        if not assume_iso8601_format:\n            weekday, month, day, time = tokens[:4]\n            if (len(tokens) < 4 or (weekday not in self.weekdays) or\n                    (month not in self.months) or not day.isdigit()):\n                assume_iso8601_format = True\n\n        if assume_iso8601_format:\n            # sanity check, because the dateutil parser could interpret\n            # any numbers as a valid date\n            if not re.match(r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}',\n                            tokens[0]):\n                return None\n\n            # convinced that this is a ISO-8601 format, the dateutil parser\n            # will do the rest\n            dt = dateutil.parser.parse(tokens[0])\n            self._datetime_format = \"iso8601-utc\" \\\n                if tokens[0].endswith('Z') else \"iso8601-local\"\n\n        else:\n            # assume current year unless self.year_rollover\n            # is set (from LogFile)\n            year = datetime.now().year\n            dt = dateutil.parser.parse(' '.join(tokens[: 4]),\n                                       default=datetime(year, 1, 1))\n\n            if dt.tzinfo is None:\n                dt = dt.replace(tzinfo=tzutc())\n\n            if self._year_rollover and dt > self._year_rollover:\n                dt = dt.replace(year=year - 1)\n\n            self._datetime_format = \"ctime\" \\\n                if '.' in tokens[3] else \"ctime-pre2.4\"\n\n        return dt", "response": "Match the datetime pattern at the beginning of the token list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract thread name if available ( lazy ).", "response": "def thread(self):\n        \"\"\"Extract thread name if available (lazy).\"\"\"\n        if not self._thread_calculated:\n            self._thread_calculated = True\n\n            split_tokens = self.split_tokens\n\n            if not self.datetime_nextpos:\n                return None\n            if len(split_tokens) <= self.datetime_nextpos:\n                return None\n\n            connection_token = split_tokens[self.datetime_nextpos]\n            match = re.match(r'^\\[([^\\]]*)\\]$', connection_token)\n            if match:\n                self._thread = match.group(1)\n\n            if self._thread is not None:\n                if self._thread in ['initandlisten', 'mongosMain']:\n                    if len(split_tokens) >= 5 and split_tokens[-5][0] == '#':\n                        self._conn = 'conn' + split_tokens[-5][1:]\n                elif self._thread.startswith('conn'):\n                    self._conn = self._thread\n        return self._thread"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract operation if available.", "response": "def operation(self):\n        \"\"\"\n        Extract operation if available (lazy).\n\n        Operations: query, insert, update, remove, getmore, command\n        \"\"\"\n        if not self._operation_calculated:\n            self._operation_calculated = True\n            self._extract_operation_and_namespace()\n\n        return self._operation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namespace(self):\n        if not self._operation_calculated:\n            self._operation_calculated = True\n            self._extract_operation_and_namespace()\n\n        return self._namespace", "response": "Extract namespace if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the operation and namespace from a logevent.", "response": "def _extract_operation_and_namespace(self):\n        \"\"\"\n        Helper method to extract both operation and namespace from a logevent.\n\n        It doesn't make sense to only extract one as they appear back to back\n        in the token list.\n        \"\"\"\n        split_tokens = self.split_tokens\n\n        if not self._datetime_nextpos:\n            # force evaluation of thread to get access to datetime_offset and\n            # to protect from changes due to line truncation.\n            _ = self.thread\n\n        if not self._datetime_nextpos or (len(split_tokens) <=\n                                          self._datetime_nextpos + 2):\n            return\n\n        op = split_tokens[self._datetime_nextpos + 1].lower()\n\n        if op == 'warning:':\n            # check if this log line got truncated\n            if (\"warning: log line attempted\" in self._line_str and\n                    \"over max size\" in self._line_str):\n                self._datetime_nextpos = split_tokens.index('...')\n                op = split_tokens[self._datetime_nextpos + 1]\n            else:\n                # unknown warning, bail out\n                return\n\n        if op in self.log_operations:\n            self._operation = op\n            self._namespace = split_tokens[self._datetime_nextpos + 2]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract query pattern from operations.", "response": "def pattern(self):\n        \"\"\"Extract query pattern from operations.\"\"\"\n        if not self._pattern:\n\n            # trigger evaluation of operation\n            if (self.operation in ['query', 'getmore', 'update', 'remove'] or\n                    self.command in ['count', 'findandmodify']):\n                self._pattern = self._find_pattern('query: ')\n            elif self.command == 'find':\n                self._pattern = self._find_pattern('filter: ')\n\n        return self._pattern"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract query pattern from operations.", "response": "def sort_pattern(self):\n        \"\"\"Extract query pattern from operations.\"\"\"\n        if not self._sort_pattern:\n\n            # trigger evaluation of operation\n            if self.operation in ['query', 'getmore']:\n                self._sort_pattern = self._find_pattern('orderby: ')\n\n        return self._sort_pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef actual_query(self):\n        if not self._actual_query:\n\n            # trigger evaluation of operation\n            if (self.operation in ['query', 'getmore', 'update', 'remove'] or\n                    self.command in ['count', 'findandmodify']):\n                self._actual_query = self._find_pattern('query: ', actual=True)\n            elif self.command == 'find':\n                self._actual_query = self._find_pattern('filter: ',\n                                                        actual=True)\n\n        return self._actual_query", "response": "Extract the actual query from operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef actual_sort(self):\n        if not self._actual_sort:\n\n            # trigger evaluation of operation\n            if self.operation in ['query', 'getmore']:\n                self._actual_sort = self._find_pattern('orderby: ',\n                                                        actual=True)\n\n        return self._actual_sort", "response": "Extract the actual sort key from operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract query pattern from operations.", "response": "def command(self):\n        \"\"\"Extract query pattern from operations.\"\"\"\n        if not self._command_calculated:\n\n            self._command_calculated = True\n            if self.operation == 'command':\n                try:\n                    command_idx = self.split_tokens.index('command:')\n                    command = self.split_tokens[command_idx + 1]\n                    if command == '{':\n                        # workaround for <= 2.2 log files,\n                        # where command was not listed separately\n                        command = self.split_tokens[command_idx + 2][:-1]\n                    self._command = command.lower()\n                except ValueError:\n                    pass\n\n        return self._command"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nscanned(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._nscanned", "response": "Extract nscanned or keysExamined counter if available."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nscannedObjects(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._nscannedObjects", "response": "Returns the number of objects that have been scanned."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts ntoreturn counter if available.", "response": "def ntoreturn(self):\n        \"\"\"Extract ntoreturn counter if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._ntoreturn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting ntoreturn counter if available.", "response": "def writeConflicts(self):\n        \"\"\"Extract ntoreturn counter if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._writeConflicts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of returned items in the cache.", "response": "def nreturned(self):\n        \"\"\"\n        Extract counters if available (lazy).\n\n        Looks for nreturned, nReturned, or nMatched counter.\n        \"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._nreturned"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts ninserted or nInserted counter if available.", "response": "def ninserted(self):\n        \"\"\"Extract ninserted or nInserted counter if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._ninserted"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ndeleted(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._ndeleted", "response": "Extract ndeleted or nDeleted counter if available."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts nupdated or nModified counter if available.", "response": "def nupdated(self):\n        \"\"\"Extract nupdated or nModified counter if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._nupdated"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef numYields(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._numYields", "response": "Extract numYields counter if available."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract planSummary if available.", "response": "def planSummary(self):\n        \"\"\"Extract planSummary if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._planSummary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef actualPlanSummary(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._actualPlanSummary", "response": "Extract planSummary including JSON if available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef r(self):\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._r", "response": "Extract read lock ( r ) counter if available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting write lock counter if available.", "response": "def w(self):\n        \"\"\"Extract write lock (w) counter if available (lazy).\"\"\"\n        if not self._counters_calculated:\n            self._counters_calculated = True\n            self._extract_counters()\n\n        return self._w"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract log level if available.", "response": "def level(self):\n        \"\"\"Extract log level if available (lazy).\"\"\"\n        if not self._level_calculated:\n            self._level_calculated = True\n            self._extract_level()\n        return self._level"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extract_level(self):\n        if self._level is None:\n            split_tokens = self.split_tokens\n\n            if not split_tokens:\n                self._level = False\n                self._component = False\n                return\n\n            x = (self.log_levels.index(split_tokens[1])\n                 if split_tokens[1] in self.log_levels else None)\n\n            if x is not None:\n                self._level = split_tokens[1]\n                self._component = split_tokens[2]\n            else:\n                self._level = False\n                self._component = False", "response": "Extract level and component if available."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse all information from the cache.", "response": "def parse_all(self):\n        \"\"\"\n        Trigger extraction of all information.\n\n        These values are usually evaluated lazily.\n        \"\"\"\n        tokens = self.split_tokens\n        duration = self.duration\n        datetime = self.datetime\n        thread = self.thread\n        operation = self.operation\n        namespace = self.namespace\n        pattern = self.pattern\n        nscanned = self.nscanned\n        nscannedObjects = self.nscannedObjects\n        ntoreturn = self.ntoreturn\n        nreturned = self.nreturned\n        ninserted = self.ninserted\n        ndeleted = self.ndeleted\n        nupdated = self.nupdated\n        numYields = self.numYields\n        w = self.w\n        r = self.r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting this LogEvent object to a dictionary.", "response": "def to_dict(self, labels=None):\n        \"\"\"Convert LogEvent object to a dictionary.\"\"\"\n        output = {}\n        if labels is None:\n            labels = ['line_str', 'split_tokens', 'datetime', 'operation',\n                      'thread', 'namespace', 'nscanned', 'ntoreturn',\n                      'nreturned', 'ninserted', 'nupdated', 'ndeleted',\n                      'duration', 'r', 'w', 'numYields']\n\n        for label in labels:\n            value = getattr(self, label, None)\n            if value is not None:\n                output[label] = value\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_json(self, labels=None):\n        output = self.to_dict(labels)\n        return json.dumps(output, cls=DateTimeEncoder, ensure_ascii=False)", "response": "Convert LogEvent object to valid JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the system. profile document and copy all values to member variables.", "response": "def _parse_document(self):\n        \"\"\"Parse system.profile doc, copy all values to member variables.\"\"\"\n        self._reset()\n\n        doc = self._profile_doc\n\n        self._split_tokens_calculated = True\n        self._split_tokens = None\n\n        self._duration_calculated = True\n        self._duration = doc[u'millis']\n\n        self._datetime_calculated = True\n        self._datetime = doc[u'ts']\n        if self._datetime.tzinfo is None:\n            self._datetime = self._datetime.replace(tzinfo=tzutc())\n        self._datetime_format = None\n        self._reformat_timestamp('ctime', force=True)\n\n        self._thread_calculated = True\n        self._thread = doc['thread']\n\n        self._operation_calculated = True\n        self._operation = doc[u'op']\n        self._namespace = doc[u'ns']\n\n        self._command_calculated = True\n        if self.operation == 'command':\n            self._command = doc[u'command'].keys()[0]\n\n        # query pattern for system.profile events, all three cases.\n        # See SERVER-13245\n        if 'query' in doc:\n            if 'query' in doc['query'] and isinstance(doc['query']['query'],\n                                                      dict):\n                self._pattern = str(doc['query']['query']).replace(\"'\", '\"')\n            elif '$query' in doc['query']:\n                self._pattern = str(doc['query']['$query']).replace(\"'\", '\"')\n            else:\n                self._pattern = str(doc['query']).replace(\"'\", '\"')\n\n            # sort pattern\n            if ('orderby' in doc['query'] and\n                    isinstance(doc['query']['orderby'], dict)):\n                self._sort_pattern = str(doc['query']\n                                         ['orderby']).replace(\"'\", '\"')\n            elif '$orderby' in doc['query']:\n                self._sort_pattern = str(doc['query']\n                                         ['$orderby']).replace(\"'\", '\"')\n            else:\n                self._sort_pattern = None\n\n        self._counters_calculated = True\n        self._nscanned = doc[u'nscanned'] if 'nscanned' in doc else None\n        self._ntoreturn = doc[u'ntoreturn'] if 'ntoreturn' in doc else None\n        self._nupdated = doc[u'nupdated'] if 'nupdated' in doc else None\n        self._nreturned = doc[u'nreturned'] if 'nreturned' in doc else None\n        self._ninserted = doc[u'ninserted'] if 'ninserted' in doc else None\n        self._ndeleted = doc[u'ndeleted'] if 'ndeleted' in doc else None\n        self._numYields = doc[u'numYield'] if 'numYield' in doc else None\n\n        if u'lockStats' in doc:\n            self._r = doc[u'lockStats'][u'timeLockedMicros'][u'r']\n            self._w = doc[u'lockStats'][u'timeLockedMicros'][u'w']\n            self._r_acquiring = doc[u'lockStats']['timeAcquiringMicros'][u'r']\n            self._w_acquiring = doc[u'lockStats']['timeAcquiringMicros'][u'w']\n            locks = 'w:%i' % self.w if self.w is not None else 'r:%i' % self.r\n        elif u'locks' in doc:\n            locks = json.dumps(doc[u'locks'])\n        else:\n            locks = ''\n\n        # build a fake line_str\n        payload = ''\n        if 'query' in doc:\n            payload += ('query: %s' % str(doc[u'query'])\n                        .replace(\"u'\", \"'\").replace(\"'\", '\"'))\n        if 'command' in doc:\n            payload += ('command: %s' % str(doc[u'command'])\n                        .replace(\"u'\", \"'\").replace(\"'\", '\"'))\n        if 'updateobj' in doc:\n            payload += (' update: %s' % str(doc[u'updateobj'])\n                        .replace(\"u'\", \"'\").replace(\"'\", '\"'))\n\n        scanned = 'nscanned:%i' % self._nscanned if 'nscanned' in doc else ''\n        yields = 'numYields:%i' % self._numYields if 'numYield' in doc else ''\n        duration = '%ims' % self.duration if self.duration is not None else ''\n\n        self._line_str = (\"[{thread}] {operation} {namespace} {payload} \"\n                          \"{scanned} {yields} locks(micros) {locks} \"\n                          \"{duration}\".format(datetime=self.datetime,\n                                              thread=self.thread,\n                                              operation=self.operation,\n                                              namespace=self.namespace,\n                                              payload=payload, scanned=scanned,\n                                              yields=yields, locks=locks,\n                                              duration=duration))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        grouping = Grouping(group_by=lambda x: (x.namespace, x.operation,\n                                                x.pattern))\n        logfile = self.mloginfo.logfile\n\n        if logfile.start and logfile.end:\n            progress_start = self.mloginfo._datetime_to_epoch(logfile.start)\n            progress_total = (self.mloginfo._datetime_to_epoch(logfile.end) -\n                              progress_start)\n        else:\n            self.mloginfo.progress_bar_enabled = False\n\n        for i, le in enumerate(logfile):\n            # update progress bar every 1000 lines\n            if self.mloginfo.progress_bar_enabled and (i % 1000 == 0):\n                if le.datetime:\n                    progress_curr = self.mloginfo._datetime_to_epoch(le\n                                                                     .datetime)\n                    if progress_total:\n                        (self.mloginfo\n                         .update_progress(float(progress_curr -\n                                                progress_start) /\n                                          progress_total))\n\n            if (le.operation in ['query', 'getmore', 'update', 'remove'] or\n                    le.command in ['count', 'findandmodify',\n                                   'geonear', 'find']):\n                lt = LogTuple(namespace=le.namespace, operation=op_or_cmd(le),\n                              pattern=le.pattern, duration=le.duration)\n                grouping.add(lt)\n\n        grouping.sort_by_size()\n\n        # clear progress bar again\n        if self.mloginfo.progress_bar_enabled:\n            self.mloginfo.update_progress(1.0)\n\n        # no queries in the log file\n        if len(grouping) < 1:\n            print('no queries found.')\n            return\n\n        titles = ['namespace', 'operation', 'pattern', 'count', 'min (ms)',\n                  'max (ms)', 'mean (ms)', '95%-ile (ms)', 'sum (ms)']\n        table_rows = []\n\n        for g in grouping:\n            # calculate statistics for this group\n            namespace, op, pattern = g\n\n            group_events = [le.duration for le in grouping[g]\n                            if le.duration is not None]\n\n            stats = OrderedDict()\n            stats['namespace'] = namespace\n            stats['operation'] = op\n            stats['pattern'] = pattern\n            stats['count'] = len(group_events)\n            stats['min'] = min(group_events) if group_events else '-'\n            stats['max'] = max(group_events) if group_events else '-'\n            stats['mean'] = 0\n            if np:\n                stats['95%'] = (np.percentile(group_events, 95)\n                                if group_events else '-')\n            else:\n                stats['95%'] = 'n/a'\n            stats['sum'] = sum(group_events) if group_events else '-'\n            stats['mean'] = (stats['sum'] / stats['count']\n                             if group_events else '-')\n\n            if self.mloginfo.args['verbose']:\n                stats['example'] = grouping[g][0]\n                titles.append('example')\n\n            table_rows.append(stats)\n\n        # sort order depending on field names\n        reverse = True\n        if self.mloginfo.args['sort'] in ['namespace', 'pattern']:\n            reverse = False\n\n        table_rows = sorted(table_rows,\n                            key=itemgetter(self.mloginfo.args['sort']),\n                            reverse=reverse)\n        print_table(table_rows, titles, uppercase_headers=False)\n        print('')", "response": "Run this section and print out information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef string2dt(self, s, lower_bound=None):\n        original_s = s\n\n        result = {}\n        dt = None\n\n        # if s is completely empty, return start or end,\n        # depending on what parameter is evaluated\n        if s == '':\n            return self.end if lower_bound else self.start\n\n        # first try to match the defined regexes\n        for idx in self.dtRegexes:\n            regex = self.dtRegexes[idx]\n            mo = regex.search(s)\n            # if match was found, cut it out of original string and\n            # store in result\n            if mo:\n                result[idx] = mo\n                s = s[:mo.start(0)] + s[mo.end(0):]\n\n        # handle constants\n        if 'constant' in result:\n            constant = result['constant'].group(0).strip()\n            if constant == 'end':\n                dt = self.end\n            elif constant == 'start':\n                dt = self.start\n            elif constant == 'today':\n                dt = datetime.now().replace(hour=0, minute=0, second=0,\n                                            microsecond=0)\n            elif constant == 'yesterday':\n                dt = datetime.now().replace(hour=0, minute=0, second=0,\n                                            microsecond=0) - timedelta(days=1)\n            elif constant == 'now':\n                dt = datetime.now()\n\n        elif 'weekday' in result:\n                weekday = result['weekday'].group(0).strip()\n                # assume most-recently occured weekday in logfile\n                most_recent_date = self.end.replace(hour=0, minute=0, second=0,\n                                                    microsecond=0)\n                offset = (most_recent_date.weekday() -\n                          self.weekdays.index(weekday)) % 7\n                dt = most_recent_date - timedelta(days=offset)\n\n        # if anything remains unmatched, try parsing it with dateutil's parser\n        if s.strip() != '':\n            try:\n                if dt:\n                    dt = default_tzinfo(parser.parse(s, default=dt), tzutc)\n                else:\n                    # check if it's only time, then use the start dt as\n                    # default, else just use the current year\n                    if re.match('(?P<hour>\\d{1,2}):(?P<minute>\\d{2,2})'\n                                '(?::(?P<second>\\d{2,2})'\n                                '(?:.(?P<microsecond>\\d{3,3}))?)?'\n                                '(?P<timezone>[0-9Z:\\+\\-]+)?$', s):\n                        default = self.end if lower_bound else self.start\n                    else:\n                        default = datetime(self.end.year, 1, 1, 0, 0, 0)\n                    default = default.replace(second=0, microsecond=0)\n\n                    dt = parser.parse(s, default=default)\n\n            except ValueError:\n                raise ValueError(\"Error in DateTimeBoundaries: \"\n                                 \"can't parse datetime from %s\" % s)\n\n        if not dt:\n            dt = lower_bound or self.end\n\n        # if no timezone specified, use the one from the logfile\n        if dt.tzinfo is None:\n            dt = dt.replace(tzinfo=self.start.tzinfo)\n\n        # time is applied separately (not through the parser) so that string\n        # containing only time don't use today as default date\n        # (parser behavior)\n        # if 'time' in result:\n        #     dct = dict((k, int(v))\n        #                for k,v in six.iteritems(result['time'].groupdict(0)))\n        #     dct['microsecond'] *= 1000\n        #     dt = dt.replace(**dct)\n\n        # apply offset\n        if 'offset' in result:\n\n            # separate in operator, value, unit\n            dct = result['offset'].groupdict()\n\n            mult = 1\n            if dct['unit'] in ['s', 'sec', 'secs']:\n                dct['unit'] = 'seconds'\n            elif dct['unit'] in ['m', 'min', 'mins']:\n                dct['unit'] = 'minutes'\n            elif dct['unit'] in ['h', 'hour', 'hours']:\n                dct['unit'] = 'hours'\n            elif dct['unit'] in ['d', 'day', 'days']:\n                dct['unit'] = 'days'\n            elif dct['unit'] in ['w', 'week', 'weeks']:\n                dct['unit'] = 'days'\n                mult = 7\n            elif dct['unit'] in ['mo', 'month', 'months']:\n                dct['unit'] = 'days'\n                mult = 30.43\n            elif dct['unit'] in ['y', 'year', 'years']:\n                dct['unit'] = 'days'\n                mult = 365.24\n\n            if dct['operator'] == '-':\n                mult *= -1\n\n            dt = dt + eval('timedelta(%s=%i)' % (dct['unit'],\n                                                 mult * int(dct['value'])))\n\n        # if parsed datetime is out of bounds and no year specified,\n        # try to adjust year\n        year_present = re.search('\\d{4,4}', original_s)\n\n        if not year_present and 'constant' not in result:\n            if (dt < self.start and\n                    dt.replace(year=dt.year + 1) >= self.start and\n                    dt.replace(year=dt.year + 1) <= self.end):\n                dt = dt.replace(year=dt.year + 1)\n            elif (dt > self.end and\n                    dt.replace(year=dt.year - 1) >= self.start and\n                    dt.replace(year=dt.year - 1) <= self.end):\n                dt = dt.replace(year=dt.year - 1)\n\n        return dt", "response": "Return a datetime from a given string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns this section and print out information.", "response": "def run(self):\n        \"\"\"Run this section and print out information.\"\"\"\n        if ProfileCollection and isinstance(self.mloginfo.logfile,\n                                            ProfileCollection):\n            print(\"\\n    not available for system.profile collections\\n\")\n            return\n\n        for version, logevent in self.mloginfo.logfile.restarts:\n            print(\"   %s version %s\"\n                  % (logevent.datetime.strftime(\"%b %d %H:%M:%S\"), version))\n\n        if len(self.mloginfo.logfile.restarts) == 0:\n            print(\"  no restarts found\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addFilter(self, filterclass):\n        if filterclass not in self.filters:\n            self.filters.append(filterclass)", "response": "Add a filter class to the parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the final line of logevent.", "response": "def _outputLine(self, logevent, length=None, human=False):\n        \"\"\"\n        Print the final line.\n\n        Provides various options (length, human, datetime changes, ...).\n        \"\"\"\n        # adapt timezone output if necessary\n        if self.args['timestamp_format'] != 'none':\n            logevent._reformat_timestamp(self.args['timestamp_format'],\n                                         force=True)\n        if any(self.args['timezone']):\n            if self.args['timestamp_format'] == 'none':\n                self.args['timestamp_format'] = logevent.datetime_format\n            logevent._reformat_timestamp(self.args['timestamp_format'],\n                                         force=True)\n\n        if self.args['json']:\n            print(logevent.to_json())\n            return\n        line = logevent.line_str\n\n        if length:\n            if len(line) > length:\n                line = (line[:int(length / 2 - 2)] + '...' +\n                        line[int(-length / 2 + 1):])\n        if human:\n            line = self._changeMs(line)\n            line = self._formatNumbers(line)\n\n        print(line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _msToString(self, ms):\n        hr, ms = divmod(ms, 3600000)\n        mins, ms = divmod(ms, 60000)\n        secs, mill = divmod(ms, 1000)\n        return \"%ihr %imin %isecs %ims\" % (hr, mins, secs, mill)", "response": "Change milliseconds to hours min sec ms format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the ms part in the string if needed.", "response": "def _changeMs(self, line):\n        \"\"\"Change the ms part in the string if needed.\"\"\"\n        # use the position of the last space instead\n        try:\n            last_space_pos = line.rindex(' ')\n        except ValueError:\n            return line\n        else:\n            end_str = line[last_space_pos:]\n            new_string = line\n            if end_str[-2:] == 'ms' and int(end_str[:-2]) >= 1000:\n                # isolate the number of milliseconds\n                ms = int(end_str[:-2])\n                # create the new string with the beginning part of the\n                # log with the new ms part added in\n                new_string = (line[:last_space_pos] +\n                              ' (' + self._msToString(ms) + ')' +\n                              line[last_space_pos:])\n            return new_string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats the numbers so that there are commas inserted.", "response": "def _formatNumbers(self, line):\n        \"\"\"\n        Format the numbers so that there are commas inserted.\n\n        For example: 1200300 becomes 1,200,300.\n        \"\"\"\n        # below thousands separator syntax only works for\n        # python 2.7, skip for 2.6\n        if sys.version_info < (2, 7):\n            return line\n\n        last_index = 0\n        try:\n            # find the index of the last } character\n            last_index = (line.rindex('}') + 1)\n            end = line[last_index:]\n        except ValueError:\n            return line\n        else:\n            # split the string on numbers to isolate them\n            splitted = re.split(\"(\\d+)\", end)\n            for index, val in enumerate(splitted):\n                converted = 0\n                try:\n                    converted = int(val)\n                # if it's not an int pass and don't change the string\n                except ValueError:\n                    pass\n                else:\n                    if converted > 1000:\n                        splitted[index] = format(converted, \",d\")\n            return line[:last_index] + (\"\").join(splitted)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _datetime_key_for_merge(self, logevent):\n        if not logevent:\n            # if logfile end is reached, return max datetime to never\n            # pick this line\n            return datetime(MAXYEAR, 12, 31, 23, 59, 59, 999999, tzutc())\n\n        # if no datetime present (line doesn't have one) return mindate\n        # to pick this line immediately\n        return logevent.datetime or datetime(MINYEAR, 1, 1, 0, 0, 0, 0,\n                                             tzutc())", "response": "Helper method for ordering log lines correctly during merge."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logfile_generator(self):\n        if not self.args['exclude']:\n            # ask all filters for a start_limit and fast-forward to the maximum\n            start_limits = [f.start_limit for f in self.filters\n                            if hasattr(f, 'start_limit')]\n\n            if start_limits:\n                for logfile in self.args['logfile']:\n                    logfile.fast_forward(max(start_limits))\n\n        if len(self.args['logfile']) > 1:\n            # merge log files by time\n            for logevent in self._merge_logfiles():\n                yield logevent\n        else:\n            # only one file\n            for logevent in self.args['logfile'][0]:\n                if self.args['timezone'][0] != 0 and logevent.datetime:\n                    logevent._datetime = (logevent.datetime +\n                                          timedelta(hours=self\n                                                    .args['timezone'][0]))\n                yield logevent", "response": "Yield each line of the file or the next line if several files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, arguments=None):\n        # add arguments from filter classes before calling superclass run\n        for f in self.filters:\n            for fa in f.filterArgs:\n                self.argparser.add_argument(fa[0], **fa[1])\n        # now parse arguments and post-process\n        LogFileTool.run(self, arguments)\n\n        self.args = dict((k, self.args[k]\n                          if k in ['logfile', 'markers', 'timezone']\n                          else self._arrayToString(self.args[k]))\n                         for k in self.args)\n        # make sure logfile is always a list, even if 1 is provided\n        # through sys.stdin\n        if not isinstance(self.args['logfile'], list):\n            self.args['logfile'] = [self.args['logfile']]\n\n        # require at least 1 log file (either through stdin or as parameter)\n        if len(self.args['logfile']) == 0:\n            raise SystemExit('Error: Need at least 1 log file, either as '\n                             'command line parameter or through stdin.')\n\n        # handle timezone parameter\n        if len(self.args['timezone']) == 1:\n            self.args['timezone'] = (self.args['timezone'] *\n                                     len(self.args['logfile']))\n        elif len(self.args['timezone']) == len(self.args['logfile']):\n            pass\n        elif len(self.args['timezone']) == 0:\n            self.args['timezone'] = [0] * len(self.args['logfile'])\n        else:\n            raise SystemExit('Error: Invalid number of timezone parameters. '\n                             'Use either one parameter (for global '\n                             'adjustment) or the number of log files '\n                             '(for individual adjustments).')\n\n        # create filter objects from classes and pass args\n        self.filters = [f(self) for f in self.filters]\n\n        # remove non-active filter objects\n        self.filters = [f for f in self.filters if f.active]\n\n        # call setup for each active filter\n        for f in self.filters:\n            f.setup()\n\n        if self.args['shorten'] is not False:\n            if self.args['shorten'] is None:\n                self.args['shorten'] = 200\n\n        if self.args['verbose']:\n            print(\"command line arguments\")\n            for a in self.args:\n                print(\"    %s: %s\" % (a, self.args[a]))\n            print(\"\\nactive filters: \" +\n                  \", \".join([f.__class__.__name__ for f in self.filters]))\n            print('\\n====================')\n\n        # handle markers parameter\n        if len(self.args['markers']) == 1:\n            marker = self.args['markers'][0]\n            if marker == 'enum':\n                self.args['markers'] = ['{%i}' % (i + 1)\n                                        for i in range(len(self\n                                                           .args['logfile']))]\n            elif marker == 'alpha':\n                self.args['markers'] = ['{%s}' % chr(97 + i)\n                                        for i in range(len(self\n                                                           .args['logfile']))]\n            elif marker == 'none':\n                self.args['markers'] = [None for _ in self.args['logfile']]\n            elif marker == 'filename':\n                self.args['markers'] = ['{%s}' % logfile.name\n                                        for logfile in self.args['logfile']]\n        elif len(self.args['markers']) == len(self.args['logfile']):\n            pass\n        else:\n            raise SystemExit('Error: Number of markers not the same as '\n                             'number of files.')\n\n        # with --human, change to ctime format if not specified otherwise\n        if self.args['timestamp_format'] == 'none' and self.args['human']:\n            self.args['timestamp_format'] = 'ctime'\n\n        # go through each line and ask each filter if it accepts\n        if 'logfile' not in self.args or not self.args['logfile']:\n            raise SystemExit('no logfile found.')\n\n        for logevent in self.logfile_generator():\n            if self.args['exclude']:\n                # print line if any filter disagrees\n                if any([not f.accept(logevent) for f in self.filters]):\n                    self._outputLine(logevent, self.args['shorten'],\n                                     self.args['human'])\n\n            else:\n                # only print line if all filters agree\n                if all([f.accept(logevent) for f in self.filters]):\n                    self._outputLine(logevent, self.args['shorten'],\n                                     self.args['human'])\n\n                # if at least one filter refuses to accept any\n                # remaining lines, stop\n                if any([f.skipRemaining() for f in self.filters]):\n                    # if input is not stdin\n                    if sys.stdin.isatty():\n                        break", "response": "Parse the logfile and run the filter classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accept(self, logevent):\n        if self.active and logevent.duration is not None:\n            return logevent.duration <= self.fastms\n        return False", "response": "Return True if the logevent should be accepted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup(self):\n        # get start and end of the mask and set a start_limit\n        if not self.mask_source.start:\n            raise SystemExit(\"Can't parse format of %s. Is this a log file or \"\n                             \"system.profile collection?\"\n                             % self.mlogfilter.args['mask'])\n\n        self.mask_half_td = timedelta(seconds=self.mlogfilter.args\n                                      ['mask_size'] / 2)\n\n        # load filter mask file\n        logevent_list = list(self.mask_source)\n\n        # define start and end of total mask\n        self.mask_start = self.mask_source.start - self.mask_half_td\n        self.mask_end = self.mask_source.end + self.mask_half_td\n\n        # consider --mask-center\n        if self.mlogfilter.args['mask_center'] in ['start', 'both']:\n            if logevent_list[0].duration:\n                self.mask_start -= timedelta(milliseconds=logevent_list[0]\n                                             .duration)\n\n        if self.mlogfilter.args['mask_center'] == 'start':\n            if logevent_list[-1].duration:\n                self.mask_end -= timedelta(milliseconds=logevent_list[-1]\n                                           .duration)\n\n        self.start_limit = self.mask_start\n\n        # different center points\n        if 'mask_center' in self.mlogfilter.args:\n            if self.mlogfilter.args['mask_center'] in ['start', 'both']:\n                starts = ([(le.datetime - timedelta(milliseconds=le.duration))\n                          if le.duration is not None else le.datetime\n                          for le in logevent_list if le.datetime])\n\n            if self.mlogfilter.args['mask_center'] in ['end', 'both']:\n                ends = [le.datetime for le in logevent_list if le.datetime]\n\n            if self.mlogfilter.args['mask_center'] == 'start':\n                event_list = sorted(starts)\n            elif self.mlogfilter.args['mask_center'] == 'end':\n                event_list = sorted(ends)\n            elif self.mlogfilter.args['mask_center'] == 'both':\n                event_list = sorted(zip(starts, ends))\n\n        mask_list = []\n\n        if len(event_list) == 0:\n            return\n\n        start_point = end_point = None\n\n        for e in event_list:\n            if start_point is None:\n                start_point, end_point = self._pad_event(e)\n                continue\n\n            next_start = (e[0] if type(e) == tuple else e) - self.mask_half_td\n            if next_start <= end_point:\n                end_point = ((e[1] if type(e) == tuple else e) +\n                             self.mask_half_td)\n            else:\n                mask_list.append((start_point, end_point))\n                start_point, end_point = self._pad_event(e)\n\n        if start_point:\n            mask_list.append((start_point, end_point))\n\n        self.mask_list = mask_list", "response": "Setup the mask list and start and end of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the logevent should be accepted False otherwise.", "response": "def accept(self, logevent):\n        \"\"\"\n        Process line.\n\n        Overwrite BaseFilter.accept() and return True if the provided\n        logevent should be accepted (causing output), or False if not.\n        \"\"\"\n        dt = logevent.datetime\n        if not dt:\n            return False\n\n        mask = next((mask for mask in self.mask_list\n                     if mask[0] < dt and mask[1] > dt), None)\n\n        return True if mask else False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef presplit(host, database, collection, shardkey, shardnumber=None,\n             chunkspershard=1, verbose=False):\n    \"\"\"\n    Presplit chunks for sharding.\n\n    Get information about the number of shards, then split chunks and\n    distribute over shards. Currently assumes shardkey to be hex string, for\n    example ObjectId or UUID.\n\n    host: host and port to connect to, e.g. \"192.168.0.1:27017\",\n          \"localhost:30000\"\n    database: database name to enable sharding\n    collection: collection name to shard\n    shardkey: shardkey to pre-split on (must be hex string, e.g. ObjectId or\n              UUID)\n    shardnumber: if None, automatically presplit over all available shards.\n                 if integer, only presplit over the given number of shards\n                 (maximum is the number of actual shards)\n    \"\"\"\n    con = Connection(host)\n    namespace = '%s.%s' % (database, collection)\n\n    # disable balancer\n    con['config']['settings'].update({'_id': \"balancer\"},\n                                     {'$set': {'stopped': True}}, upsert=True)\n\n    # enable sharding on database if not yet enabled\n    db_info = con['config']['databases'].find_one({'_id': database})\n    if not db_info or db_info['partitioned'] is False:\n        con['admin'].command(SON({'enableSharding': database}))\n\n    # shard collection if not yet sharded\n    coll_info = con['config']['collections'].find_one({'_id': namespace})\n    if coll_info and not coll_info['dropped']:\n        # if it is sharded already, quit. something is not right.\n        if verbose:\n            print(\"collection already sharded.\")\n        return\n    else:\n        con[database][collection].ensure_index(shardkey)\n        con['admin'].command(SON({'shardCollection': namespace,\n                                  'key': {shardkey: 1}}))\n\n    # get shard number and names and calculate split points\n    shards = list(con['config']['shards'].find())\n\n    if len(shards) == 1:\n        if verbose:\n            print(\"only one shard found. no pre-splitting required.\")\n        return\n\n    # limit number of shards if shardnumber given\n    if shardnumber and shardnumber <= len(shards):\n        shards = shards[:shardnumber]\n\n    shard_names = [s['_id'] for s in shards]\n    splits_total = len(shards) * chunkspershard\n    split_interval = 16**4 / splits_total\n    split_points = [\"%0.4x\" % s for s in range(split_interval,\n                                               splits_total * split_interval,\n                                               split_interval)]\n\n    # pre-splitting commands\n    for s in split_points:\n        con['admin'].command(SON([('split', namespace),\n                                  ('middle', {shardkey: s})]))\n\n    split_points = [MinKey()] + split_points\n\n    # move chunks to shards (catch the one error where the chunk resides\n    # on that shard already)\n    for i, s in enumerate(split_points):\n        try:\n            if verbose:\n                print('moving chunk %s in collection %s to shard %s.'\n                      % (s, namespace, shard_names[i % len(shards)]))\n            res = con['admin'].command(SON([('moveChunk', namespace),\n                                            ('find', {shardkey: s}),\n                                            ('to',\n                                             shard_names[i % len(shards)])]))\n        except OperationFailure as e:\n            if verbose:\n                print(e)\n\n    if verbose:\n        print('chunk distribution:', end=' ')\n        chunk_group = (con['config']['chunks']\n                       .group(key={'shard': 1}, condition={'ns': namespace},\n                              initial={'nChunks': 0},\n                              reduce=(\" function (doc, out) \"\n                                      \"{ out.nChunks++; } \")))\n        print(', '.join([\"%s: %i\" % (ch['shard'], ch['nChunks'])\n                         for ch in chunk_group]))", "response": "Presplits a shard into pieces."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef source_files(mongodb_path):\n    for root, dirs, files in os.walk(mongodb_path):\n        for filename in files:\n            # skip files in dbtests folder\n            if 'dbtests' in root:\n                continue\n            if filename.endswith(('.cpp', '.c', '.h')):\n                yield os.path.join(root, filename)", "response": "Find source files in a mongodb path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns this section and print out information.", "response": "def run(self):\n        \"\"\"Run this section and print out information.\"\"\"\n        if ProfileCollection and isinstance(self.mloginfo.logfile,\n                                            ProfileCollection):\n            print(\"\\n    not available for system.profile collections\\n\")\n            return\n\n        ip_opened = defaultdict(lambda: 0)\n        ip_closed = defaultdict(lambda: 0)\n\n        socket_exceptions = 0\n\n        START_TIME_EMPTY = -11\n        END_TIME_ALREADY_FOUND = -111\n        MIN_DURATION_EMPTY = 9999999999\n        MAX_DURATION_EMPTY = -1\n\n        end_connid_pattern = re.compile(r'\\[conn(\\d+)\\]')\n\n        genstats = self.mloginfo.args['connstats']\n        if genstats:\n            connections_start = defaultdict(lambda: START_TIME_EMPTY)\n            ipwise_sum_durations = defaultdict(lambda: 0)\n            ipwise_count = defaultdict(lambda: 0)\n            ipwise_min_connection_duration = defaultdict(lambda:\n                                                         MIN_DURATION_EMPTY)\n            ipwise_max_connection_duration = defaultdict(lambda:\n                                                         MAX_DURATION_EMPTY)\n\n            min_connection_duration = MIN_DURATION_EMPTY\n            max_connection_duration = MAX_DURATION_EMPTY\n\n            sum_durations = 0\n            fullconn_counts = 0\n\n        for logevent in self.mloginfo.logfile:\n            line = logevent.line_str\n\n            pos = line.find('connection accepted')\n            if pos != -1:\n                # connection was opened, increase counter\n                tokens = line[pos:pos + 100].split(' ')\n                if tokens[3] == 'anonymous':\n                    ip = 'anonymous'\n                else:\n                    ip, _ = tokens[3].split(':')\n                ip_opened[ip] += 1\n\n                if genstats:\n                    connid = tokens[4].strip('#')\n                    dt = logevent.datetime\n\n                    # Sanity checks\n                    if connid.isdigit() is False or dt is None:\n                        continue\n\n                    if connections_start[connid] != START_TIME_EMPTY:\n                        errmsg = (\"Multiple start datetimes found for the \"\n                                  \"same connection ID. Consider analysing one \"\n                                  \"log sequence.\")\n                        raise NotImplementedError(errmsg)\n\n                    connections_start[connid] = dt\n\n            pos = line.find('end connection')\n            if pos != -1:\n                # connection was closed, increase counter\n                tokens = line[pos:pos + 100].split(' ')\n                if tokens[2] == 'anonymous':\n                    ip = 'anonymous'\n                else:\n                    ip, _ = tokens[2].split(':')\n                ip_closed[ip] += 1\n\n                if genstats:\n\n                    # Sanity check\n                    if end_connid_pattern.search(line, re.M | re.I) is None:\n                        continue\n\n                    # The connection id value is stored just before end\n                    # connection -> [conn385] end connection\n                    end_connid = (end_connid_pattern.\n                                  search(line, re.M | re.I).group(1))\n                    dt = logevent.datetime\n\n                    # Sanity checks\n                    if (end_connid.isdigit() is False or dt is None or\n                            connections_start[end_connid] == START_TIME_EMPTY):\n                        continue\n\n                    if connections_start[end_connid] == END_TIME_ALREADY_FOUND:\n                        errmsg = (\"Multiple end datetimes found for the same \"\n                                  \"connection ID %s. Consider analysing one \"\n                                  \"log sequence.\")\n                        raise NotImplementedError(errmsg % (end_connid))\n\n                    dur = dt - connections_start[end_connid]\n                    dur_in_sec = dur.seconds\n\n                    if dur_in_sec < min_connection_duration:\n                        min_connection_duration = dur_in_sec\n\n                    if dur_in_sec > max_connection_duration:\n                        max_connection_duration = dur_in_sec\n\n                    if dur_in_sec < ipwise_min_connection_duration[ip]:\n                        ipwise_min_connection_duration[ip] = dur_in_sec\n\n                    if dur_in_sec > ipwise_max_connection_duration[ip]:\n                        ipwise_max_connection_duration[ip] = dur_in_sec\n\n                    sum_durations += dur.seconds\n                    fullconn_counts += 1\n\n                    ipwise_sum_durations[ip] += dur_in_sec\n                    ipwise_count[ip] += 1\n\n                    connections_start[end_connid] = END_TIME_ALREADY_FOUND\n\n            if \"SocketException\" in line:\n                socket_exceptions += 1\n\n        # calculate totals\n        total_opened = sum(ip_opened.values())\n        total_closed = sum(ip_closed.values())\n\n        unique_ips = set(ip_opened.keys())\n        unique_ips.update(ip_closed.keys())\n\n        # output statistics\n        print(\"     total opened: %s\" % total_opened)\n        print(\"     total closed: %s\" % total_closed)\n        print(\"    no unique IPs: %s\" % len(unique_ips))\n        print(\"socket exceptions: %s\" % socket_exceptions)\n        if genstats:\n            if fullconn_counts > 0:\n                print(\"overall average connection duration(s): %s\"\n                      % (sum_durations / fullconn_counts))\n                print(\"overall minimum connection duration(s): %s\"\n                      % min_connection_duration)\n                print(\"overall maximum connection duration(s): %s\"\n                      % max_connection_duration)\n            else:\n                print(\"overall average connection duration(s): -\")\n                print(\"overall minimum connection duration(s): -\")\n                print(\"overall maximum connection duration(s): -\")\n        print('')\n\n        for ip in sorted(unique_ips, key=lambda x: ip_opened[x], reverse=True):\n            opened = ip_opened[ip] if ip in ip_opened else 0\n            closed = ip_closed[ip] if ip in ip_closed else 0\n\n            if genstats:\n                covered_count = (\n                    ipwise_count[ip]\n                    if ip in ipwise_count\n                    else 1)\n                connection_duration_ip = (\n                    ipwise_sum_durations[ip]\n                    if ip in ipwise_sum_durations\n                    else 0)\n                ipwise_min_connection_duration_final = (\n                    ipwise_min_connection_duration[ip]\n                    if ipwise_min_connection_duration[ip] != MIN_DURATION_EMPTY\n                    else 0)\n                ipwise_max_connection_duration_final = (\n                    ipwise_max_connection_duration[ip]\n                    if ipwise_max_connection_duration[ip] != MAX_DURATION_EMPTY\n                    else 0)\n\n                print(\"%-15s  opened: %-8i  closed: %-8i dur-avg(s): %-8i \"\n                      \"dur-min(s): %-8i dur-max(s): %-8i\"\n                      % (ip, opened, closed,\n                         connection_duration_ip / covered_count,\n                         ipwise_min_connection_duration_final,\n                         ipwise_max_connection_duration_final))\n            else:\n                print(\"%-15s  opened: %-8i  closed: %-8i\"\n                      % (ip, opened, closed))\n\n        print('')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun this section and print out information.", "response": "def run(self):\n        \"\"\"Run this section and print out information.\"\"\"\n        titles = ['date', 'host', 'state/message']\n        table_rows = []\n\n        for host, state, logevent in self.mloginfo.logfile.rs_state:\n            stats = OrderedDict()\n            stats['date'] = logevent.datetime.strftime(\"%b %d %H:%M:%S\")\n            stats['host'] = host\n            stats['state/message'] = state\n            table_rows.append(stats)\n\n        print_table(table_rows, titles, uppercase_headers=False)\n\n        if len(self.mloginfo.logfile.rs_state) == 0:\n            print(\"  no rs state changes found\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef index():\n    if current_app.config['ARA_PLAYBOOK_OVERRIDE'] is not None:\n        override = current_app.config['ARA_PLAYBOOK_OVERRIDE']\n        results = (models.TaskResult.query\n                   .join(models.Task)\n                   .filter(models.Task.playbook_id.in_(override)))\n    else:\n        results = models.TaskResult.query.all()\n\n    return render_template('task_result_index.html', results=results)", "response": "This is the main entry point for the task result page. It is used in the context of generating static files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_identifier(result):\n    # Determine the playbook file path to use for the ID\n    if result.task.playbook and result.task.playbook.path:\n        playbook_file = result.task.playbook.path\n    else:\n        playbook_file = ''\n    play_path = u'%s.%s' % (playbook_file, result.task.play.name)\n\n    # Determine the task file path to use for the ID\n    if result.task.file and result.task.file.path:\n        task_file = result.task.file.path\n    else:\n        task_file = ''\n    task_path = u'%s.%s' % (task_file, result.task.name)\n\n    # Combine both of the above for a full path\n    identifier_path = u'%s.%s' % (play_path, task_path)\n\n    # Assign the identifier as a hash of the fully unique path.\n    identifier = hashlib.sha1(encodeutils.to_utf8(identifier_path)).hexdigest()\n\n    return identifier", "response": "Generates a fixed length identifier based on a combined set of playbook and task values which are as close as we can guess to unique for each task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of aggregated statistics for items filtered by attr. For example it will aggregate statistics for a host across all the playbook runs it has been a member of.", "response": "def get_summary_stats(items, attr):\n    \"\"\"\n    Returns a dictionary of aggregated statistics for 'items' filtered by\n    \"attr'. For example, it will aggregate statistics for a host across all\n    the playbook runs it has been a member of, with the following structure:\n\n        data[host.id] = {\n            'ok': 4\n            'changed': 4\n            ...\n        }\n    \"\"\"\n    data = {}\n    for item in items:\n        stats = models.Stats.query.filter_by(**{attr: item.id})\n        data[item.id] = {\n            'ok': sum([int(stat.ok) for stat in stats]),\n            'changed': sum([int(stat.changed) for stat in stats]),\n            'failed': sum([int(stat.failed) for stat in stats]),\n            'skipped': sum([int(stat.skipped) for stat in stats]),\n            'unreachable': sum([int(stat.unreachable) for stat in stats])\n        }\n\n        # If we're aggregating stats for a playbook, also infer status\n        if attr is \"playbook_id\":\n            data[item.id]['status'] = _infer_status(item, data[item.id])\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fast_count(query):\n    count_query = (query\n                   .statement.with_only_columns([func.count()]).order_by(None))\n    count = query.session.execute(count_query).scalar()\n    return count", "response": "This function is a fast version of the count function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a file path returns a JSON structure suitable for bootstrap - treeview mock_os represents a faked filesystem generated from the playbook_treeview method.", "response": "def generate_tree(root, paths, mock_os):\n    \"\"\"\n    Given a file path, returns a JSON structure suitable for bootstrap-treeview\n    mock_os represents a faked filesystem generated from the playbook_treeview\n    method.\n    Credit: Mohammed Naser & David Moreau Simard\n    \"\"\"\n    tree = []\n    dentries = mock_os.listdir(root)\n\n    for d in dentries:\n        full_path = mock_os.path.join(root, d)\n        node = {\n            'text': d,\n            'href': '#%s' % d,\n            'state': {\n                'expanded': True\n            }\n        }\n\n        if mock_os.path.isdir(full_path):\n            node['nodes'] = generate_tree(full_path, paths, mock_os)\n        else:\n            node['icon'] = 'fa fa-file-code-o'\n            node['href'] = '#'\n            node['color'] = '#0088ce'\n            node['dataAttr'] = {\n                'toggle': 'modal',\n                'target': '#file_modal',\n                'load': paths[full_path] + '/'\n            }\n        tree.append(node)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef playbook_treeview(playbook):\n    fs = fake_filesystem.FakeFilesystem()\n    mock_os = fake_filesystem.FakeOsModule(fs)\n\n    files = models.File.query.filter(models.File.playbook_id.in_([playbook]))\n\n    paths = {}\n    for file in files:\n        fs.create_file(file.path)\n        paths[file.path] = file.id\n\n    return jsonutils.dumps(generate_tree('/', paths, mock_os),\n                           sort_keys=True,\n                           indent=2)", "response": "Returns a JSON structure suitable for bootstrap - treeview."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the sha1 hash of the content of the current file content.", "response": "def content_sha1(context):\n    \"\"\"\n    Used by the FileContent model to automatically compute the sha1\n    hash of content before storing it to the database.\n    \"\"\"\n    try:\n        content = context.current_parameters['content']\n    except AttributeError:\n        content = context\n    return hashlib.sha1(encodeutils.to_utf8(content)).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the duration of the object.", "response": "def duration(self):\n        \"\"\"\n        Calculates '(time_end-time_start)' and return the resulting\n        'datetime.timedelta' object.\n        \"\"\"\n        if self.time_end is None or self.time_start is None:\n            return timedelta(seconds=0)\n        else:\n            return self.time_end - self.time_start"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    files = models.File.query\n    hosts = models.Host.query\n    facts = models.HostFacts.query\n    playbooks = models.Playbook.query\n    records = models.Data.query\n    tasks = models.Task.query\n    results = models.TaskResult.query\n\n    if current_app.config['ARA_PLAYBOOK_OVERRIDE'] is not None:\n        override = current_app.config['ARA_PLAYBOOK_OVERRIDE']\n        files = files.filter(models.File.playbook_id.in_(override))\n        facts = (facts\n                 .join(models.Host)\n                 .filter(models.Host.playbook_id.in_(override)))\n        hosts = hosts.filter(models.Host.playbook_id.in_(override))\n        playbooks = playbooks.filter(models.Playbook.id.in_(override))\n        records = records.filter(models.Data.playbook_id.in_(override))\n        tasks = tasks.filter(models.Task.playbook_id.in_(override))\n        results = (results\n                   .join(models.Task)\n                   .filter(models.Task.playbook_id.in_(override)))\n\n    return render_template(\n        'about.html',\n        active='about',\n        files=fast_count(files),\n        hosts=fast_count(hosts),\n        facts=fast_count(facts),\n        playbooks=fast_count(playbooks),\n        records=fast_count(records),\n        tasks=fast_count(tasks),\n        results=fast_count(results)\n    )", "response": "Returns the about page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index():\n    if current_app.config['ARA_PLAYBOOK_OVERRIDE'] is not None:\n        override = current_app.config['ARA_PLAYBOOK_OVERRIDE']\n        hosts = (models.Host.query\n                 .filter(models.Host.playbook_id.in_(override)))\n    else:\n        hosts = models.Host.query.all()\n\n    return render_template('host_index.html', hosts=hosts)", "response": "This is the main entry point for the host page. It is used in the context of generating static files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap around Ansible s get_config backward compatibility", "response": "def ara_config(key, env_var, default, section='ara', value_type=None):\n    \"\"\"\n    Wrapper around Ansible's get_config backward/forward compatibility\n    \"\"\"\n    # Bootstrap Ansible configuration\n    # Ansible >=2.4 takes care of loading the configuration file itself\n    path = find_ini_config_file()\n    config = configparser.ConfigParser()\n    if path is not None:\n        config.read(path)\n\n    return get_config(\n        config, section, key, env_var, default, value_type=value_type\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary for the loaded configuration", "response": "def config(self):\n        \"\"\" Returns a dictionary for the loaded configuration \"\"\"\n        return {\n            key: self.__dict__[key]\n            for key in dir(self)\n            if key.isupper()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index():\n    if current_app.config['ARA_PLAYBOOK_OVERRIDE'] is not None:\n        override = current_app.config['ARA_PLAYBOOK_OVERRIDE']\n        files = (models.File.query\n                 .filter(models.File.playbook_id.in_(override)))\n    else:\n        files = models.File.query.all()\n\n    return render_template('file_index.html', files=files)", "response": "This is the main entry point for the file_index. html view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_file(file_):\n    file_ = (models.File.query.get(file_))\n    if file_ is None:\n        abort(404)\n\n    return render_template('file.html', file_=file_)", "response": "Show details of a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the cache for the current app context", "response": "def configure_cache(app):\n    \"\"\" Sets up an attribute to cache data in the app context \"\"\"\n    log = logging.getLogger('ara.webapp.configure_cache')\n    log.debug('Configuring cache')\n\n    if not getattr(app, '_cache', None):\n        app._cache = {}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bspline_to_nurbs(obj):\n    # B-Spline -> NURBS\n    if isinstance(obj, BSpline.Curve):\n        return _convert.convert_curve(obj, NURBS)\n    elif isinstance(obj, BSpline.Surface):\n        return _convert.convert_surface(obj, NURBS)\n    elif isinstance(obj, BSpline.Volume):\n        return _convert.convert_volume(obj, NURBS)\n    else:\n        raise TypeError(\"Input must be an instance of B-Spline curve, surface or volume\")", "response": "Converts non - rational parametric shapes to rational ones."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a NURBS object to a B - Spline object.", "response": "def nurbs_to_bspline(obj, **kwargs):\n    \"\"\" Extracts the non-rational components from rational parametric shapes, if possible.\n\n    The possibility of converting a rational shape to a non-rational one depends on the weights vector.\n\n    :param obj: NURBS shape\n    :type obj: NURBS.Curve, NURBS.Surface or NURBS.Volume\n    :return: B-Spline shape\n    :rtype: BSpline.Curve, BSpline.Surface or BSpline.Volume\n    :raises: TypeError\n    \"\"\"\n    if not obj.rational:\n        raise TypeError(\"The input must be a rational shape\")\n\n    # Get keyword arguments\n    tol = kwargs.get('tol', 10e-8)\n\n    # Test for non-rational component extraction\n    for w in obj.weights:\n        if abs(w - 1.0) > tol:\n            print(\"Cannot extract non-rational components\")\n            return obj\n\n    # NURBS -> B-Spline\n    if isinstance(obj, NURBS.Curve):\n        return _convert.convert_curve(obj, BSpline)\n    elif isinstance(obj, NURBS.Surface):\n        return _convert.convert_surface(obj, BSpline)\n    elif isinstance(obj, NURBS.Volume):\n        return _convert.convert_volume(obj, BSpline)\n    else:\n        raise TypeError(\"Input must be an instance of NURBS curve, surface or volume\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doolittle(matrix_a):\n    # Initialize L and U matrices\n    matrix_u = [[0.0 for _ in range(len(matrix_a))] for _ in range(len(matrix_a))]\n    matrix_l = [[0.0 for _ in range(len(matrix_a))] for _ in range(len(matrix_a))]\n\n    # Doolittle Method\n    for i in range(0, len(matrix_a)):\n        for k in range(i, len(matrix_a)):\n            # Upper triangular (U) matrix\n            matrix_u[i][k] = float(matrix_a[i][k] - sum([matrix_l[i][j] * matrix_u[j][k] for j in range(0, i)]))\n            # Lower triangular (L) matrix\n            if i == k:\n                matrix_l[i][i] = 1.0\n            else:\n                matrix_l[k][i] = float(matrix_a[k][i] - sum([matrix_l[k][j] * matrix_u[j][i] for j in range(0, i)]))\n                # Handle zero division error\n                try:\n                    matrix_l[k][i] /= float(matrix_u[i][i])\n                except ZeroDivisionError:\n                    matrix_l[k][i] = 0.0\n\n    return matrix_l, matrix_u", "response": "Doolittle s Method for LU - factorization."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pool_context(*args, **kwargs):\n    pool = Pool(*args, **kwargs)\n    try:\n        yield pool\n    except Exception as e:\n        raise e\n    finally:\n        pool.terminate()", "response": "Context manager for multiprocessing. Pool class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export(fn):\n    mod = sys.modules[fn.__module__]\n    if hasattr(mod, '__all__'):\n        mod.__all__.append(fn.__name__)\n    else:\n        mod.__all__ = [fn.__name__]\n    return fn", "response": "Exports a function as a new object in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads files inside the input project directory.", "response": "def read_files(project, ext):\n    \"\"\" Reads files inside the input project directory. \"\"\"\n    project_path = os.path.join(os.path.dirname(__file__), project)\n    file_list = os.listdir(project_path)\n    flist = []\n    flist_path = []\n    for f in file_list:\n        f_path = os.path.join(project_path, f)\n        if os.path.isfile(f_path) and f.endswith(ext) and f != \"__init__.py\":\n            flist.append(f.split('.')[0])\n            flist_path.append(f_path)\n    return flist, flist_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy_files(src, ext, dst):\n    src_path = os.path.join(os.path.dirname(__file__), src)\n    dst_path = os.path.join(os.path.dirname(__file__), dst)\n    file_list = os.listdir(src_path)\n    for f in file_list:\n        if f == '__init__.py':\n            continue\n        f_path = os.path.join(src_path, f)\n        if os.path.isfile(f_path) and f.endswith(ext):\n            shutil.copy(f_path, dst_path)", "response": "Copy files from src to dst."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the project directory for compiled modules.", "response": "def make_dir(project):\n    \"\"\" Creates the project directory for compiled modules. \"\"\"\n    project_path = os.path.join(os.path.dirname(__file__), project)\n    # Delete the directory and the files inside it\n    if os.path.exists(project_path):\n        shutil.rmtree(project_path)\n    # Create the directory\n    os.mkdir(project_path)\n    # We need a __init__.py file inside the directory\n    with open(os.path.join(project_path, '__init__.py'), 'w') as fp:\n        fp.write('__version__ = \"' + str(get_property('__version__', 'geomdl')) + '\"\\n')\n        fp.write('__author__ = \"' + str(get_property('__author__', 'geomdl')) + '\"\\n')\n        fp.write('__license__ = \"' + str(get_property('__license__', 'geomdl')) + '\"\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if any of the elements of the input list is in sys. argv array.", "response": "def in_argv(arg_list):\n    \"\"\" Checks if any of the elements of the input list is in sys.argv array. \"\"\"\n    for arg in sys.argv:\n        for parg in arg_list:\n            if parg == arg or arg.startswith(parg):\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an equally spaced knot vector.", "response": "def generate(degree, num_ctrlpts, **kwargs):\n    \"\"\" Generates an equally spaced knot vector.\n\n    It uses the following equality to generate knot vector: :math:`m = n + p + 1`\n\n    where;\n\n    * :math:`p`, degree\n    * :math:`n + 1`, number of control points\n    * :math:`m + 1`, number of knots\n\n    Keyword Arguments:\n\n        * ``clamped``: Flag to choose from clamped or unclamped knot vector options. *Default: True*\n\n    :param degree: degree\n    :type degree: int\n    :param num_ctrlpts: number of control points\n    :type num_ctrlpts: int\n    :return: knot vector\n    :rtype: list\n    \"\"\"\n    if degree == 0 or num_ctrlpts == 0:\n        raise ValueError(\"Input values should be different than zero.\")\n\n    # Get keyword arguments\n    clamped = kwargs.get('clamped', True)\n\n    # Number of repetitions at the start and end of the array\n    num_repeat = degree\n\n    # Number of knots in the middle\n    num_segments = num_ctrlpts - (degree + 1)\n\n    if not clamped:\n        # No repetitions at the start and end\n        num_repeat = 0\n        # Should conform the rule: m = n + p + 1\n        num_segments = degree + num_ctrlpts - 1\n\n    # First knots\n    knot_vector = [0.0 for _ in range(0, num_repeat)]\n\n    # Middle knots\n    knot_vector += linspace(0.0, 1.0, num_segments + 2)\n\n    # Last knots\n    knot_vector += [1.0 for _ in range(0, num_repeat)]\n\n    # Return auto-generated knot vector\n    return knot_vector"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes the input knot vector to [ 0 1 ) domain.", "response": "def normalize(knot_vector, decimals=18):\n    \"\"\" Normalizes the input knot vector to [0, 1] domain.\n\n    :param knot_vector: knot vector to be normalized\n    :type knot_vector: list, tuple\n    :param decimals: rounding number\n    :type decimals: int\n    :return: normalized knot vector\n    :rtype: list\n    \"\"\"\n    try:\n        if knot_vector is None or len(knot_vector) == 0:\n            raise ValueError(\"Input knot vector cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Knot vector must be a list or tuple\")\n    except Exception:\n        raise\n\n    first_knot = float(knot_vector[0])\n    last_knot = float(knot_vector[-1])\n    denominator = last_knot - first_knot\n\n    knot_vector_out = [float((\"{:.\" + str(decimals) + \"f}\").format((float(kv) - first_knot) / denominator))\n                       for kv in knot_vector]\n\n    return knot_vector_out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the validity of the input knot vector.", "response": "def check(degree, knot_vector, num_ctrlpts):\n    \"\"\" Checks the validity of the input knot vector.\n\n    Please refer to The NURBS Book (2nd Edition), p.50 for details.\n\n    :param degree: degree of the curve or the surface\n    :type degree: int\n    :param knot_vector: knot vector to be checked\n    :type knot_vector: list, tuple\n    :param num_ctrlpts: number of control points\n    :type num_ctrlpts: int\n    :return: True if the knot vector is valid, False otherwise\n    :rtype: bool\n    \"\"\"\n    try:\n        if knot_vector is None or len(knot_vector) == 0:\n            raise ValueError(\"Input knot vector cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Knot vector must be a list or tuple\")\n    except Exception:\n        raise\n\n    # Check the formula; m = p + n + 1\n    if len(knot_vector) != degree + num_ctrlpts + 1:\n        return False\n\n    # Check ascending order\n    prev_knot = knot_vector[0]\n    for knot in knot_vector:\n        if prev_knot > knot:\n            return False\n        prev_knot = knot\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interpolate_curve(points, degree, **kwargs):\n    # Keyword arguments\n    use_centripetal = kwargs.get('centripetal', False)\n\n    # Number of control points\n    num_points = len(points)\n\n    # Get uk\n    uk = compute_params_curve(points, use_centripetal)\n\n    # Compute knot vector\n    kv = compute_knot_vector(degree, num_points, uk)\n\n    # Do global interpolation\n    matrix_a = _build_coeff_matrix(degree, kv, uk, points)\n    ctrlpts = ginterp(matrix_a, points)\n\n    # Generate B-spline curve\n    curve = BSpline.Curve()\n    curve.degree = degree\n    curve.ctrlpts = ctrlpts\n    curve.knotvector = kv\n\n    return curve", "response": "Interpolate the control points of a centripetal parameter into a single B - spline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interpolate_surface(points, size_u, size_v, degree_u, degree_v, **kwargs):\n    # Keyword arguments\n    use_centripetal = kwargs.get('centripetal', False)\n\n    # Get uk and vl\n    uk, vl = compute_params_surface(points, size_u, size_v, use_centripetal)\n\n    # Compute knot vectors\n    kv_u = compute_knot_vector(degree_u, size_u, uk)\n    kv_v = compute_knot_vector(degree_v, size_v, vl)\n\n    # Do global interpolation on the u-direction\n    ctrlpts_r = []\n    for v in range(size_v):\n        pts = [points[v + (size_v * u)] for u in range(size_u)]\n        matrix_a = _build_coeff_matrix(degree_u, kv_u, uk, pts)\n        ctrlpts_r += ginterp(matrix_a, pts)\n\n    # Do global interpolation on the v-direction\n    ctrlpts = []\n    for u in range(size_u):\n        pts = [ctrlpts_r[u + (size_u * v)] for v in range(size_v)]\n        matrix_a = _build_coeff_matrix(degree_v, kv_v, vl, pts)\n        ctrlpts += ginterp(matrix_a, pts)\n\n    # Generate B-spline surface\n    surf = BSpline.Surface()\n    surf.degree_u = degree_u\n    surf.degree_v = degree_v\n    surf.ctrlpts_size_u = size_u\n    surf.ctrlpts_size_v = size_v\n    surf.ctrlpts = ctrlpts\n    surf.knotvector_u = kv_u\n    surf.knotvector_v = kv_v\n\n    return surf", "response": "Interpolate the surface through the data points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef approximate_curve(points, degree, **kwargs):\n    # Number of data points\n    num_dpts = len(points)  # corresponds to variable \"r\" in the algorithm\n\n    # Get keyword arguments\n    use_centripetal = kwargs.get('centripetal', False)\n    num_cpts = kwargs.get('ctrlpts_size', num_dpts - 1)\n\n    # Dimension\n    dim = len(points[0])\n\n    # Get uk\n    uk = compute_params_curve(points, use_centripetal)\n\n    # Compute knot vector\n    kv = compute_knot_vector2(degree, num_dpts, num_cpts, uk)\n\n    # Compute matrix N\n    matrix_n = []\n    for i in range(1, num_dpts - 1):\n        m_temp = []\n        for j in range(1, num_cpts - 1):\n            m_temp.append(helpers.basis_function_one(degree, kv, j, uk[i]))\n        matrix_n.append(m_temp)\n\n    # Compute NT\n    matrix_nt = linalg.matrix_transpose(matrix_n)\n\n    # Compute NTN matrix\n    matrix_ntn = linalg.matrix_multiply(matrix_nt, matrix_n)\n\n    # LU-factorization\n    matrix_l, matrix_u = linalg.lu_decomposition(matrix_ntn)\n\n    # Initialize control points array\n    ctrlpts = [[0.0 for _ in range(dim)] for _ in range(num_cpts)]\n\n    # Fix start and end points\n    ctrlpts[0] = list(points[0])\n    ctrlpts[-1] = list(points[-1])\n\n    # Compute Rk - Eqn 9.63\n    pt0 = points[0]  # Qzero\n    ptm = points[-1]  # Qm\n    rk = []\n    for i in range(1, num_dpts - 1):\n        ptk = points[i]\n        n0p = helpers.basis_function_one(degree, kv, 0, uk[i])\n        nnp = helpers.basis_function_one(degree, kv, num_cpts - 1, uk[i])\n        elem2 = [c * n0p for c in pt0]\n        elem3 = [c * nnp for c in ptm]\n        rk.append([a - b - c for a, b, c in zip(ptk, elem2, elem3)])\n\n    # Compute R - Eqn. 9.67\n    vector_r = [[0.0 for _ in range(dim)] for _ in range(num_cpts - 2)]\n    for i in range(1, num_cpts - 1):\n        ru_tmp = []\n        for idx, pt in enumerate(rk):\n            ru_tmp.append([p * helpers.basis_function_one(degree, kv, i, uk[idx + 1]) for p in pt])\n        for d in range(dim):\n            for idx in range(len(ru_tmp)):\n                vector_r[i - 1][d] += ru_tmp[idx][d]\n\n    # Computer control points\n    for i in range(dim):\n        b = [pt[i] for pt in vector_r]\n        y = linalg.forward_substitution(matrix_l, b)\n        x = linalg.backward_substitution(matrix_u, y)\n        for j in range(1, num_cpts - 1):\n            ctrlpts[j][i] = x[j - 1]\n\n    # Generate B-spline curve\n    curve = BSpline.Curve()\n    curve.degree = degree\n    curve.ctrlpts = ctrlpts\n    curve.knotvector = kv\n\n    return curve", "response": "Calculates the approximate B - Spline curve for a set of data points."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an approximate B - Spline surface for the given set of data points.", "response": "def approximate_surface(points, size_u, size_v, degree_u, degree_v, **kwargs):\n    \"\"\" Surface approximation using least squares method with fixed number of control points.\n\n    This algorithm interpolates the corner control points and approximates the remaining control points. Please refer to\n    Algorithm A9.7 of The NURBS Book (2nd Edition), pp.422-423 for details.\n\n    Keyword Arguments:\n        * ``centripetal``: activates centripetal parametrization method. *Default: False*\n        * ``ctrlpts_size_u``: number of control points on the u-direction. *Default: size_u - 1*\n        * ``ctrlpts_size_v``: number of control points on the v-direction. *Default: size_v - 1*\n\n    :param points: data points\n    :type points: list, tuple\n    :param size_u: number of data points on the u-direction, :math:`r`\n    :type size_u: int\n    :param size_v: number of data points on the v-direction, :math:`s`\n    :type size_v: int\n    :param degree_u: degree of the output surface for the u-direction\n    :type degree_u: int\n    :param degree_v: degree of the output surface for the v-direction\n    :type degree_v: int\n    :return: approximated B-Spline surface\n    :rtype: BSpline.Surface\n    \"\"\"\n    # Keyword arguments\n    use_centripetal = kwargs.get('centripetal', False)\n    num_cpts_u = kwargs.get('ctrlpts_size_u', size_u - 1)  # number of datapts, r + 1 > number of ctrlpts, n + 1\n    num_cpts_v = kwargs.get('ctrlpts_size_v', size_v - 1)  # number of datapts, s + 1 > number of ctrlpts, m + 1\n\n    # Dimension\n    dim = len(points[0])\n\n    # Get uk and vl\n    uk, vl = compute_params_surface(points, size_u, size_v, use_centripetal)\n\n    # Compute knot vectors\n    kv_u = compute_knot_vector2(degree_u, size_u, num_cpts_u, uk)\n    kv_v = compute_knot_vector2(degree_v, size_v, num_cpts_v, vl)\n\n    # Construct matrix Nu\n    matrix_nu = []\n    for i in range(1, size_u - 1):\n        m_temp = []\n        for j in range(1, num_cpts_u - 1):\n            m_temp.append(helpers.basis_function_one(degree_u, kv_u, j, uk[i]))\n        matrix_nu.append(m_temp)\n    # Compute Nu transpose\n    matrix_ntu = linalg.matrix_transpose(matrix_nu)\n    # Compute NTNu matrix\n    matrix_ntnu = linalg.matrix_multiply(matrix_ntu, matrix_nu)\n    # Compute LU-decomposition of NTNu matrix\n    matrix_ntnul, matrix_ntnuu = linalg.lu_decomposition(matrix_ntnu)\n\n    # Fit u-direction\n    ctrlpts_tmp = [[0.0 for _ in range(dim)] for _ in range(num_cpts_u * size_v)]\n    for j in range(size_v):\n        ctrlpts_tmp[j + (size_v * 0)] = list(points[j + (size_v * 0)])\n        ctrlpts_tmp[j + (size_v * (num_cpts_u - 1))] = list(points[j + (size_v * (size_u - 1))])\n        # Compute Rku - Eqn. 9.63\n        pt0 = points[j + (size_v * 0)]  # Qzero\n        ptm = points[j + (size_v * (size_u - 1))]  # Qm\n        rku = []\n        for i in range(1, size_u - 1):\n            ptk = points[j + (size_v * i)]\n            n0p = helpers.basis_function_one(degree_u, kv_u, 0, uk[i])\n            nnp = helpers.basis_function_one(degree_u, kv_u, num_cpts_u - 1, uk[i])\n            elem2 = [c * n0p for c in pt0]\n            elem3 = [c * nnp for c in ptm]\n            rku.append([a - b - c for a, b, c in zip(ptk, elem2, elem3)])\n        # Compute Ru - Eqn. 9.67\n        ru = [[0.0 for _ in range(dim)] for _ in range(num_cpts_u - 2)]\n        for i in range(1, num_cpts_u - 1):\n            ru_tmp = []\n            for idx, pt in enumerate(rku):\n                ru_tmp.append([p * helpers.basis_function_one(degree_u, kv_u, i, uk[idx + 1]) for p in pt])\n            for d in range(dim):\n                for idx in range(len(ru_tmp)):\n                    ru[i - 1][d] += ru_tmp[idx][d]\n        # Get intermediate control points\n        for d in range(dim):\n            b = [pt[d] for pt in ru]\n            y = linalg.forward_substitution(matrix_ntnul, b)\n            x = linalg.backward_substitution(matrix_ntnuu, y)\n            for i in range(1, num_cpts_u - 1):\n                ctrlpts_tmp[j + (size_v * i)][d] = x[i - 1]\n\n    # Construct matrix Nv\n    matrix_nv = []\n    for i in range(1, size_v - 1):\n        m_temp = []\n        for j in range(1, num_cpts_v - 1):\n            m_temp.append(helpers.basis_function_one(degree_v, kv_v, j, vl[i]))\n        matrix_nv.append(m_temp)\n    # Compute Nv transpose\n    matrix_ntv = linalg.matrix_transpose(matrix_nv)\n    # Compute NTNv matrix\n    matrix_ntnv = linalg.matrix_multiply(matrix_ntv, matrix_nv)\n    # Compute LU-decomposition of NTNv matrix\n    matrix_ntnvl, matrix_ntnvu = linalg.lu_decomposition(matrix_ntnv)\n\n    # Fit v-direction\n    ctrlpts = [[0.0 for _ in range(dim)] for _ in range(num_cpts_u * num_cpts_v)]\n    for i in range(num_cpts_u):\n        ctrlpts[0 + (num_cpts_v * i)] = list(ctrlpts_tmp[0 + (size_v * i)])\n        ctrlpts[num_cpts_v - 1 + (num_cpts_v * i)] = list(ctrlpts_tmp[size_v - 1 + (size_v * i)])\n        # Compute Rkv - Eqs. 9.63\n        pt0 = ctrlpts_tmp[0 + (size_v * i)]  # Qzero\n        ptm = ctrlpts_tmp[size_v - 1 + (size_v * i)]  # Qm\n        rkv = []\n        for j in range(1, size_v - 1):\n            ptk = ctrlpts_tmp[j + (size_v * i)]\n            n0p = helpers.basis_function_one(degree_v, kv_v, 0, vl[j])\n            nnp = helpers.basis_function_one(degree_v, kv_v, num_cpts_v - 1, vl[j])\n            elem2 = [c * n0p for c in pt0]\n            elem3 = [c * nnp for c in ptm]\n            rkv.append([a - b - c for a, b, c in zip(ptk, elem2, elem3)])\n        # Compute Rv - Eqn. 9.67\n        rv = [[0.0 for _ in range(dim)] for _ in range(num_cpts_v - 2)]\n        for j in range(1, num_cpts_v - 1):\n            rv_tmp = []\n            for idx, pt in enumerate(rkv):\n                rv_tmp.append([p * helpers.basis_function_one(degree_v, kv_v, j, vl[idx + 1]) for p in pt])\n            for d in range(dim):\n                for idx in range(len(rv_tmp)):\n                    rv[j - 1][d] += rv_tmp[idx][d]\n        # Get intermediate control points\n        for d in range(dim):\n            b = [pt[d] for pt in rv]\n            y = linalg.forward_substitution(matrix_ntnvl, b)\n            x = linalg.backward_substitution(matrix_ntnvu, y)\n            for j in range(1, num_cpts_v - 1):\n                ctrlpts[j + (num_cpts_v * i)][d] = x[j - 1]\n\n    # Generate B-spline surface\n    surf = BSpline.Surface()\n    surf.degree_u = degree_u\n    surf.degree_v = degree_v\n    surf.ctrlpts_size_u = num_cpts_u\n    surf.ctrlpts_size_v = num_cpts_v\n    surf.ctrlpts = ctrlpts\n    surf.knotvector_u = kv_u\n    surf.knotvector_v = kv_v\n\n    return surf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing a knot vector from the parameter list using averaging method.", "response": "def compute_knot_vector(degree, num_points, params):\n    \"\"\" Computes a knot vector from the parameter list using averaging method.\n\n    Please refer to the Equation 9.8 on The NURBS Book (2nd Edition), pp.365 for details.\n\n    :param degree: degree\n    :type degree: int\n    :param num_points: number of data points\n    :type num_points: int\n    :param params: list of parameters, :math:`\\\\overline{u}_{k}`\n    :type params: list, tuple\n    :return: knot vector\n    :rtype: list\n    \"\"\"\n    # Start knot vector\n    kv = [0.0 for _ in range(degree + 1)]\n\n    # Use averaging method (Eqn 9.8) to compute internal knots in the knot vector\n    for i in range(num_points - degree - 1):\n        temp_kv = (1.0 / degree) * sum([params[j] for j in range(i + 1, i + degree + 1)])\n        kv.append(temp_kv)\n\n    # End knot vector\n    kv += [1.0 for _ in range(degree + 1)]\n\n    return kv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_knot_vector2(degree, num_dpts, num_cpts, params):\n    # Start knot vector\n    kv = [0.0 for _ in range(degree + 1)]\n\n    # Compute \"d\" value - Eqn 9.68\n    d = float(num_dpts) / float(num_cpts - degree)\n    # Find internal knots\n    for j in range(1, num_cpts - degree):\n        i = int(j * d)\n        alpha = (j * d) - i\n        temp_kv = ((1.0 - alpha) * params[i - 1]) + (alpha * params[i])\n        kv.append(temp_kv)\n\n    # End knot vector\n    kv += [1.0 for _ in range(degree + 1)]\n\n    return kv", "response": "Compute a knot vector for a given degree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_params_curve(points, centripetal=False):\n    if not isinstance(points, (list, tuple)):\n        raise TypeError(\"Data points must be a list or a tuple\")\n\n    # Length of the points array\n    num_points = len(points)\n\n    # Calculate chord lengths\n    cds = [0.0 for _ in range(num_points + 1)]\n    cds[-1] = 1.0\n    for i in range(1, num_points):\n        distance = linalg.point_distance(points[i], points[i - 1])\n        cds[i] = math.sqrt(distance) if centripetal else distance\n\n    # Find the total chord length\n    d = sum(cds[1:-1])\n\n    # Divide individual chord lengths by the total chord length\n    uk = [0.0 for _ in range(num_points)]\n    for i in range(num_points):\n        uk[i] = sum(cds[0:i + 1]) / d\n\n    return uk", "response": "Computes the parameter array for a given set of points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_params_surface(points, size_u, size_v, centripetal=False):\n    # Compute uk\n    uk = [0.0 for _ in range(size_u)]\n\n    # Compute for each curve on the v-direction\n    uk_temp = []\n    for v in range(size_v):\n        pts_u = [points[v + (size_v * u)] for u in range(size_u)]\n        uk_temp += compute_params_curve(pts_u, centripetal)\n\n    # Do averaging on the u-direction\n    for u in range(size_u):\n        knots_v = [uk_temp[u + (size_u * v)] for v in range(size_v)]\n        uk[u] = sum(knots_v) / size_v\n\n    # Compute vl\n    vl = [0.0 for _ in range(size_v)]\n\n    # Compute for each curve on the u-direction\n    vl_temp = []\n    for u in range(size_u):\n        pts_v = [points[v + (size_v * u)] for v in range(size_v)]\n        vl_temp += compute_params_curve(pts_v, centripetal)\n\n    # Do averaging on the v-direction\n    for v in range(size_v):\n        knots_u = [vl_temp[v + (size_v * u)] for u in range(size_u)]\n        vl[v] = sum(knots_u) / size_u\n\n    return uk, vl", "response": "Compute the parameters of a centripetal parameter set on the n - grams of a given set of points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply global interpolation to the set of data points.", "response": "def ginterp(coeff_matrix, points):\n    \"\"\" Applies global interpolation to the set of data points to find control points.\n\n    :param coeff_matrix: coefficient matrix\n    :type coeff_matrix: list, tuple\n    :param points: data points\n    :type points: list, tuple\n    :return: control points\n    :rtype: list\n    \"\"\"\n    # Dimension\n    dim = len(points[0])\n\n    # Number of data points\n    num_points = len(points)\n\n    # Solve system of linear equations\n    matrix_l, matrix_u = linalg.lu_decomposition(coeff_matrix)\n    ctrlpts = [[0.0 for _ in range(dim)] for _ in range(num_points)]\n    for i in range(dim):\n        b = [pt[i] for pt in points]\n        y = linalg.forward_substitution(matrix_l, b)\n        x = linalg.backward_substitution(matrix_u, y)\n        for j in range(num_points):\n            ctrlpts[j][i] = x[j]\n\n    # Return control points\n    return ctrlpts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_coeff_matrix(degree, knotvector, params, points):\n    # Number of data points\n    num_points = len(points)\n\n    # Set up coefficient matrix\n    matrix_a = [[0.0 for _ in range(num_points)] for _ in range(num_points)]\n    for i in range(num_points):\n        span = helpers.find_span_linear(degree, knotvector, num_points, params[i])\n        matrix_a[i][span-degree:span+1] = helpers.basis_function(degree, knotvector, span, params[i])\n\n    # Return coefficient matrix\n    return matrix_a", "response": "Builds the coefficient matrix for global interpolation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_render_window(actors, callbacks, **kwargs):\n    # Get keyword arguments\n    figure_size = kwargs.get('figure_size', (800, 600))\n    camera_position = kwargs.get('camera_position', (0, 0, 100))\n\n    # Find camera focal point\n    center_points = []\n    for actor in actors:\n        center_points.append(actor.GetCenter())\n    camera_focal_point = linalg.vector_mean(*center_points)\n\n    # Create camera\n    camera = vtk.vtkCamera()\n    camera.SetPosition(*camera_position)\n    camera.SetFocalPoint(*camera_focal_point)\n\n    # Create renderer\n    renderer = vtk.vtkRenderer()\n    renderer.SetActiveCamera(camera)\n    renderer.SetBackground(1.0, 1.0, 1.0)\n\n    # Add actors to the scene\n    for actor in actors:\n        renderer.AddActor(actor)\n\n    # Render window\n    render_window = vtk.vtkRenderWindow()\n    render_window.AddRenderer(renderer)\n    render_window.SetSize(*figure_size)\n\n    # Render window interactor\n    window_interactor = vtk.vtkRenderWindowInteractor()\n    window_interactor.SetRenderWindow(render_window)\n\n    # Add event observers\n    for cb in callbacks:\n        window_interactor.AddObserver(cb, callbacks[cb][0], callbacks[cb][1])  # cb name, cb function ref, cb priority\n\n    # Render actors\n    render_window.Render()\n\n    # Set window name after render() is called\n    render_window.SetWindowName(\"geomdl\")\n\n    # Use trackball camera\n    interactor_style = vtk.vtkInteractorStyleTrackballCamera()\n    window_interactor.SetInteractorStyle(interactor_style)\n\n    # Start interactor\n    window_interactor.Start()\n\n    # Return window interactor instance\n    return window_interactor", "response": "Creates a VTK render window with an interactor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_color(color):\n    if color[0] == \"#\":\n        # Convert hex string to RGB\n        return [int(color[i:i + 2], 16) / 255 for i in range(1, 7, 2)]\n    else:\n        # Create a named colors instance\n        nc = vtk.vtkNamedColors()\n        return nc.GetColor3d(color)", "response": "Creates VTK - compatible RGB color from a color string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_actor_pts(pts, color, **kwargs):\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n    point_size = kwargs.get('size', 5)\n    point_sphere = kwargs.get('point_as_sphere', True)\n\n    # Create points\n    points = vtk.vtkPoints()\n    points.SetData(pts)\n\n    # Create a PolyData object and add points\n    polydata = vtk.vtkPolyData()\n    polydata.SetPoints(points)\n\n    # Run vertex glyph filter on the points array\n    vertex_filter = vtk.vtkVertexGlyphFilter()\n    vertex_filter.SetInputData(polydata)\n\n    # Map ploy data to the graphics primitives\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputConnection(vertex_filter.GetOutputPort())\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n    actor.GetProperty().SetPointSize(point_size)\n    actor.GetProperty().SetRenderPointsAsSpheres(point_sphere)\n\n    # Return the actor\n    return actor", "response": "Creates a VTK actor for rendering scatter plots."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_actor_polygon(pts, color, **kwargs):\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n    line_width = kwargs.get('size', 1.0)\n\n    # Create points\n    points = vtk.vtkPoints()\n    points.SetData(pts)\n\n    # Number of points\n    num_points = points.GetNumberOfPoints()\n\n    # Create lines\n    cells = vtk.vtkCellArray()\n    for i in range(num_points - 1):\n        line = vtk.vtkLine()\n        line.GetPointIds().SetId(0, i)\n        line.GetPointIds().SetId(1, i + 1)\n        cells.InsertNextCell(line)\n\n    # Create a PolyData object and add points & lines\n    polydata = vtk.vtkPolyData()\n    polydata.SetPoints(points)\n    polydata.SetLines(cells)\n\n    # Map poly data to the graphics primitives\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputDataObject(polydata)\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n    actor.GetProperty().SetLineWidth(line_width)\n\n    # Return the actor\n    return actor", "response": "Creates a VTK actor for rendering polygons."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_actor_mesh(pts, lines, color, **kwargs):\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n    line_width = kwargs.get('size', 0.5)\n\n    # Create points\n    points = vtk.vtkPoints()\n    points.SetData(pts)\n\n    # Create lines\n    cells = vtk.vtkCellArray()\n    for line in lines:\n        pline = vtk.vtkPolyLine()\n        pline.GetPointIds().SetNumberOfIds(5)\n        for i in range(len(line)):\n            pline.GetPointIds().SetId(i, line[i])\n        pline.GetPointIds().SetId(4, line[0])\n        cells.InsertNextCell(pline)\n\n    # Create a PolyData object and add points & lines\n    polydata = vtk.vtkPolyData()\n    polydata.SetPoints(points)\n    polydata.SetLines(cells)\n\n    # Map poly data to the graphics primitives\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputDataObject(polydata)\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n    actor.GetProperty().SetLineWidth(line_width)\n\n    # Return the actor\n    return actor", "response": "Creates a VTK actor for rendering quadrilateral plots."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_actor_tri(pts, tris, color, **kwargs):\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n\n    # Create points\n    points = vtk.vtkPoints()\n    points.SetData(pts)\n\n    # Create triangles\n    triangles = vtk.vtkCellArray()\n    for tri in tris:\n        tmp = vtk.vtkTriangle()\n        for i, v in enumerate(tri):\n            tmp.GetPointIds().SetId(i, v)\n        triangles.InsertNextCell(tmp)\n\n    # Create a PolyData object and add points & triangles\n    polydata = vtk.vtkPolyData()\n    polydata.SetPoints(points)\n    polydata.SetPolys(triangles)\n\n    # Map poly data to the graphics primitives\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputDataObject(polydata)\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n\n    # Return the actor\n    return actor", "response": "Creates a VTK actor for rendering triangulated surface plots."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_actor_hexahedron(grid, color, **kwargs):\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n\n    # Create hexahedron elements\n    points = vtk.vtkPoints()\n    hexarray = vtk.vtkCellArray()\n    for j, pt in enumerate(grid):\n        tmp = vtk.vtkHexahedron()\n        fb = pt[0]\n        for i, v in enumerate(fb):\n            points.InsertNextPoint(v)\n            tmp.GetPointIds().SetId(i, i + (j * 8))\n        ft = pt[-1]\n        for i, v in enumerate(ft):\n            points.InsertNextPoint(v)\n            tmp.GetPointIds().SetId(i + 4, i + 4 + (j * 8))\n        hexarray.InsertNextCell(tmp)\n\n    # Create an unstructured grid object and add points & hexahedron elements\n    ugrid = vtk.vtkUnstructuredGrid()\n    ugrid.SetPoints(points)\n    ugrid.SetCells(tmp.GetCellType(), hexarray)\n    # ugrid.InsertNextCell(tmp.GetCellType(), tmp.GetPointIds())\n\n    # Map unstructured grid to the graphics primitives\n    mapper = vtk.vtkDataSetMapper()\n    mapper.SetInputDataObject(ugrid)\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n\n    # Return the actor\n    return actor", "response": "Creates a VTK actor for rendering voxels using hexahedron elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a VTK actor for rendering triangulated plots using Delaunay triangulation.", "response": "def create_actor_delaunay(pts, color, **kwargs):\n    \"\"\" Creates a VTK actor for rendering triangulated plots using Delaunay triangulation.\n\n    Keyword Arguments:\n        * ``d3d``: flag to choose between Delaunay2D (``False``) and Delaunay3D (``True``). *Default: False*\n\n    :param pts: points\n    :type pts: vtkFloatArray\n    :param color: actor color\n    :type color: list\n    :return: a VTK actor\n    :rtype: vtkActor\n    \"\"\"\n    # Keyword arguments\n    array_name = kwargs.get('name', \"\")\n    array_index = kwargs.get('index', 0)\n    use_delaunay3d = kwargs.get(\"d3d\", False)\n\n    # Create points\n    points = vtk.vtkPoints()\n    points.SetData(pts)\n\n    # Create a PolyData object and add points\n    polydata = vtk.vtkPolyData()\n    polydata.SetPoints(points)\n\n    # Apply Delaunay triangulation on the poly data object\n    triangulation = vtk.vtkDelaunay3D() if use_delaunay3d else vtk.vtkDelaunay2D()\n    triangulation.SetInputData(polydata)\n\n    # Map triangulated surface to the graphics primitives\n    mapper = vtk.vtkDataSetMapper()\n    mapper.SetInputConnection(triangulation.GetOutputPort())\n    mapper.SetArrayName(array_name)\n    mapper.SetArrayId(array_index)\n\n    # Create an actor and set its properties\n    actor = vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(*color)\n\n    # Return the actor\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flip_ctrlpts_u(ctrlpts, size_u, size_v):\n    new_ctrlpts = []\n    for i in range(0, size_u):\n        for j in range(0, size_v):\n            temp = [float(c) for c in ctrlpts[i + (j * size_u)]]\n            new_ctrlpts.append(temp)\n\n    return new_ctrlpts", "response": "Flips a list of 1 - dimensional control points from u - row order to v - row order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflip a list of 2 - D control points from u - th to v - th order.", "response": "def flip_ctrlpts2d(ctrlpts2d, size_u=0, size_v=0):\n    \"\"\" Flips a list of surface 2-D control points from *[u][v]* to *[v][u]* order.\n\n    :param ctrlpts2d: 2-D control points\n    :type ctrlpts2d: list, tuple\n    :param size_u: size in U-direction (row length)\n    :type size_u: int\n    :param size_v: size in V-direction (column length)\n    :type size_v: int\n    :return: flipped 2-D control points\n    :rtype: list\n    \"\"\"\n    if size_u <= 0 or size_v <= 0:\n        # Detect array shapes\n        size_u = len(ctrlpts2d)\n        size_v = len(ctrlpts2d[0])\n\n    new_ctrlpts2d = [[[] for _ in range(size_u)] for _ in range(size_v)]\n    for i in range(size_v):\n        for j in range(size_u):\n            new_ctrlpts2d[i][j] = [float(c) for c in ctrlpts2d[j][i]]\n\n    return new_ctrlpts2d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating weighted control points from unweighted ones in 1-D. This function #. Takes in a 1-D control points list whose coordinates are organized in (x, y, z, w) format #. converts into (x*w, y*w, z*w, w) format #. Returns the result :param ctrlpts: 1-D control points (P) :type ctrlpts: list :return: 1-D weighted control points (Pw) :rtype: list", "response": "def generate_ctrlptsw(ctrlpts):\n    \"\"\" Generates weighted control points from unweighted ones in 1-D.\n\n    This function\n\n    #. Takes in a 1-D control points list whose coordinates are organized in (x, y, z, w) format\n    #. converts into (x*w, y*w, z*w, w) format\n    #. Returns the result\n\n    :param ctrlpts: 1-D control points (P)\n    :type ctrlpts: list\n    :return: 1-D weighted control points (Pw)\n    :rtype: list\n    \"\"\"\n    # Multiply control points by weight\n    new_ctrlpts = []\n    for cpt in ctrlpts:\n        temp = [float(pt * cpt[-1]) for pt in cpt]\n        temp[-1] = float(cpt[-1])\n        new_ctrlpts.append(temp)\n\n    return new_ctrlpts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_ctrlpts_weights(ctrlpts):\n    # Divide control points by weight\n    new_ctrlpts = []\n    for cpt in ctrlpts:\n        temp = [float(pt / cpt[-1]) for pt in cpt]\n        temp[-1] = float(cpt[-1])\n        new_ctrlpts.append(temp)\n\n    return new_ctrlpts", "response": "This function generates unweighted control points from weighted ones in 1 - D control points list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_ctrlpts2d_weights(ctrlpts2d):\n    # Divide control points by weight\n    new_ctrlpts2d = []\n    for row in ctrlpts2d:\n        ctrlptsw_v = []\n        for col in row:\n            temp = [float(c / col[-1]) for c in col]\n            temp[-1] = float(col[-1])\n            ctrlptsw_v.append(temp)\n        new_ctrlpts2d.append(ctrlptsw_v)\n\n    return new_ctrlpts2d", "response": "This function generates unweighted control points from weighted ones in 2 - D control points list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine_ctrlpts_weights(ctrlpts, weights=None):\n    if weights is None:\n        weights = [1.0 for _ in range(len(ctrlpts))]\n\n    ctrlptsw = []\n    for pt, w in zip(ctrlpts, weights):\n        temp = [float(c * w) for c in pt]\n        temp.append(float(w))\n        ctrlptsw.append(temp)\n\n    return ctrlptsw", "response": "Multiplies control points by the weights to generate weighted control points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndivide weighted control points by weights to generate unweighted control points and weights vector.", "response": "def separate_ctrlpts_weights(ctrlptsw):\n    \"\"\" Divides weighted control points by weights to generate unweighted control points and weights vector.\n\n    This function is dimension agnostic, i.e. control points can be in any dimension but the last element of the array\n    should indicate the weight.\n\n    :param ctrlptsw: weighted control points\n    :type ctrlptsw: list, tuple\n    :return: unweighted control points and weights vector\n    :rtype: list\n    \"\"\"\n    ctrlpts = []\n    weights = []\n    for ptw in ctrlptsw:\n        temp = [float(pw / ptw[-1]) for pw in ptw[:-1]]\n        ctrlpts.append(temp)\n        weights.append(ptw[-1])\n\n    return [ctrlpts, weights]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflips u and v directions of a 2D control points file and saves flipped coordinates to a file.", "response": "def flip_ctrlpts2d_file(file_in='', file_out='ctrlpts_flip.txt'):\n    \"\"\" Flips u and v directions of a 2D control points file and saves flipped coordinates to a file.\n\n    :param file_in: name of the input file (to be read)\n    :type file_in: str\n    :param file_out: name of the output file (to be saved)\n    :type file_out: str\n    :raises IOError: an error occurred reading or writing the file\n    \"\"\"\n    # Read control points\n    ctrlpts2d, size_u, size_v = _read_ctrltps2d_file(file_in)\n\n    # Flip control points array\n    new_ctrlpts2d = flip_ctrlpts2d(ctrlpts2d, size_u, size_v)\n\n    # Save new control points\n    _save_ctrlpts2d_file(new_ctrlpts2d, size_u, size_v, file_out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_ctrlptsw2d_file(file_in='', file_out='ctrlptsw.txt'):\n    # Read control points\n    ctrlpts2d, size_u, size_v = _read_ctrltps2d_file(file_in)\n\n    # Multiply control points by weight\n    new_ctrlpts2d = generate_ctrlptsw2d(ctrlpts2d)\n\n    # Save new control points\n    _save_ctrlpts2d_file(new_ctrlpts2d, size_u, size_v, file_out)", "response": "This function generates weighted control points from unweighted ones in 2 - D file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_ctrlpts2d_weights_file(file_in='', file_out='ctrlpts_weights.txt'):\n    # Read control points\n    ctrlpts2d, size_u, size_v = _read_ctrltps2d_file(file_in)\n\n    # Divide control points by weight\n    new_ctrlpts2d = generate_ctrlpts2d_weights(ctrlpts2d)\n\n    # Save new control points\n    _save_ctrlpts2d_file(new_ctrlpts2d, size_u, size_v, file_out)", "response": "Generates unweighted control points from weighted ones in 2 - D control points list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef keypress_callback(self, obj, ev):\n        key = obj.GetKeySym()  # pressed key (as str)\n        render_window = obj.GetRenderWindow()  # vtkRenderWindow\n        renderer = render_window.GetRenderers().GetFirstRenderer()  # vtkRenderer\n        picker = obj.GetPicker()  # vtkPropPicker\n        actor = picker.GetActor()  # vtkActor\n\n        # Custom keypress events\n        if key == 'Up':\n            camera = renderer.GetActiveCamera()  # vtkCamera\n            camera.Pitch(2.5)\n        if key == 'Down':\n            camera = renderer.GetActiveCamera()  # vtkCamera\n            camera.Pitch(-2.5)\n        if key == 'Left':\n            camera = renderer.GetActiveCamera()  # vtkCamera\n            camera.Yaw(-2.5)\n        if key == 'Right':\n            camera = renderer.GetActiveCamera()  # vtkCamera\n            camera.Yaw(2.5)\n        if key == 'b':\n            if self._bg_id >= len(self._bg):\n                self._bg_id = 0\n            renderer.SetBackground(*self._bg[self._bg_id])\n            self._bg_id += 1\n        if key == 'm':\n            if actor is not None:\n                actor.GetProperty().SetColor(random(), random(), random())\n        if key == 'd':\n            if actor is not None:\n                print(\"Name:\", actor.GetMapper().GetArrayName())\n                print(\"Index:\", actor.GetMapper().GetArrayId())\n            print(\"Selected point:\", picker.GetSelectionPoint()[0:2])\n            print(\"# of visible actors:\", renderer.VisibleActorCount())\n        if key == 'h':\n            if actor is not None:\n                actor.SetVisibility(not actor.GetVisibility())\n        if key == 'n':\n            actors = renderer.GetActors()  # vtkActorCollection\n            for actor in actors:\n                actor.VisibilityOn()\n\n        # Update render window\n        render_window.Render()", "response": "VTK callback for keypress events.\n\n        Keypress events:\n            * ``e``: exit the application\n            * ``p``: pick object (hover the mouse and then press to pick)\n            * ``f``: fly to point (click somewhere in the window and press to fly)\n            * ``r``: reset the camera\n            * ``s`` and ``w``: switch between solid and wireframe modes\n            * ``b``: change background color\n            * ``m``: change color of the picked object\n            * ``d``: print debug information (of picked object, point, etc.)\n            * ``h``: change object visibility\n            * ``n``: reset object visibility\n            * ``arrow keys``: pan the model\n\n        Please refer to `vtkInteractorStyle <https://vtk.org/doc/nightly/html/classvtkInteractorStyle.html>`_ class\n        reference for more details.\n\n        :param obj: render window interactor\n        :type obj: vtkRenderWindowInteractor\n        :param ev: event name\n        :type ev: str"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the curve and the control points polygon.", "response": "def render(self, **kwargs):\n        \"\"\" Plots the curve and the control points polygon. \"\"\"\n        # Calling parent function\n        super(VisCurve3D, self).render(**kwargs)\n\n        # Initialize a list to store VTK actors\n        vtk_actors = []\n\n        # Start plotting\n        for plot in self._plots:\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                # Points as spheres\n                pts = np.array(plot['ptsarr'], dtype=np.float)\n                # Handle 2-dimensional data\n                if pts.shape[1] == 2:\n                    pts = np.c_[pts, np.zeros(pts.shape[0], dtype=np.float)]\n                vtkpts = numpy_to_vtk(pts, deep=False, array_type=VTK_FLOAT)\n                vtkpts.SetName(plot['name'])\n                actor1 = vtkh.create_actor_pts(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                               name=plot['name'], idx=plot['idx'])\n                vtk_actors.append(actor1)\n                # Lines\n                actor2 = vtkh.create_actor_polygon(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                                   name=plot['name'], index=plot['idx'], size=self.vconf.line_width)\n                vtk_actors.append(actor2)\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                pts = np.array(plot['ptsarr'], dtype=np.float)\n                # Handle 2-dimensional data\n                if pts.shape[1] == 2:\n                    pts = np.c_[pts, np.zeros(pts.shape[0], dtype=np.float)]\n                vtkpts = numpy_to_vtk(pts, deep=False, array_type=VTK_FLOAT)\n                vtkpts.SetName(plot['name'])\n                actor1 = vtkh.create_actor_polygon(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                                   name=plot['name'], index=plot['idx'], size=self.vconf.line_width * 2)\n                vtk_actors.append(actor1)\n\n        # Render actors\n        return vtkh.create_render_window(vtk_actors, dict(KeyPressEvent=(self.vconf.keypress_callback, 1.0)),\n                                         figure_size=self.vconf.figure_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the surface and the control points grid.", "response": "def render(self, **kwargs):\n        \"\"\" Plots the surface and the control points grid. \"\"\"\n        # Calling parent function\n        super(VisSurface, self).render(**kwargs)\n\n        # Initialize a list to store VTK actors\n        vtk_actors = []\n\n        # Start plotting\n        for plot in self._plots:\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                vertices = [v.data for v in plot['ptsarr'][0]]\n                faces = [q.data for q in plot['ptsarr'][1]]\n                # Points as spheres\n                pts = np.array(vertices, dtype=np.float)\n                vtkpts = numpy_to_vtk(pts, deep=False, array_type=VTK_FLOAT)\n                vtkpts.SetName(plot['name'])\n                actor1 = vtkh.create_actor_pts(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                               name=plot['name'], index=plot['idx'])\n                vtk_actors.append(actor1)\n                # Quad mesh\n                lines = np.array(faces, dtype=np.int)\n                actor2 = vtkh.create_actor_mesh(pts=vtkpts, lines=lines, color=vtkh.create_color(plot['color']),\n                                                name=plot['name'], index=plot['idx'], size=self.vconf.line_width)\n                vtk_actors.append(actor2)\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                vertices = [v.data for v in plot['ptsarr'][0]]\n                vtkpts = numpy_to_vtk(vertices, deep=False, array_type=VTK_FLOAT)\n                vtkpts.SetName(plot['name'])\n                faces = [t.data for t in plot['ptsarr'][1]]\n                tris = np.array(faces, dtype=np.int)\n                actor1 = vtkh.create_actor_tri(pts=vtkpts, tris=tris, color=vtkh.create_color(plot['color']),\n                                               name=plot['name'], index=plot['idx'])\n                vtk_actors.append(actor1)\n\n            # Plot trim curves\n            if self.vconf.display_trims:\n                if plot['type'] == 'trimcurve':\n                    pts = np.array(plot['ptsarr'], dtype=np.float)\n                    vtkpts = numpy_to_vtk(pts, deep=False, array_type=VTK_FLOAT)\n                    vtkpts.SetName(plot['name'])\n                    actor1 = vtkh.create_actor_polygon(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                                       name=plot['name'], index=plot['idx'], size=self.vconf.trim_size)\n                    vtk_actors.append(actor1)\n\n        # Render actors\n        return vtkh.create_render_window(vtk_actors, dict(KeyPressEvent=(self.vconf.keypress_callback, 1.0)),\n                                         figure_size=self.vconf.figure_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, **kwargs):\n        # Calling parent function\n        super(VisVoxel, self).render(**kwargs)\n\n        # Initialize a list to store VTK actors\n        vtk_actors = []\n\n        # Start plotting\n        for plot in self._plots:\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                # Points as spheres\n                pts = np.array(plot['ptsarr'], dtype=np.float)\n                vtkpts = numpy_to_vtk(pts, deep=False, array_type=VTK_FLOAT)\n                vtkpts.SetName(plot['name'])\n                temp_actor = vtkh.create_actor_pts(pts=vtkpts, color=vtkh.create_color(plot['color']),\n                                                   name=plot['name'], index=plot['idx'])\n                vtk_actors.append(temp_actor)\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                faces = np.array(plot['ptsarr'][1], dtype=np.float)\n                filled = np.array(plot['ptsarr'][2], dtype=np.int)\n                grid_filled = faces[filled == 1]\n                temp_actor = vtkh.create_actor_hexahedron(grid=grid_filled, color=vtkh.create_color(plot['color']),\n                                                          name=plot['name'], index=plot['idx'])\n                vtk_actors.append(temp_actor)\n\n        # Render actors\n        return vtkh.create_render_window(vtk_actors, dict(KeyPressEvent=(self.vconf.keypress_callback, 1.0)),\n                                         figure_size=self.vconf.figure_size)", "response": "Plots the volume and the control points and the evaluated points."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsingling - threaded ins and outs finding", "response": "def find_inouts_st(voxel_grid, datapts, **kwargs):\n    \"\"\" Single-threaded ins and outs finding (default)\n\n    :param voxel_grid: voxel grid\n    :param datapts: data points\n    :return: in-outs\n    \"\"\"\n    tol = kwargs.get('tol', 10e-8)\n    filled = [0 for _ in range(len(voxel_grid))]\n    for idx, bb in enumerate(voxel_grid):\n        pts_inside = is_point_inside_voxel(bb, datapts, tol=tol)\n        if pts_inside:\n            filled[idx] = 1\n    return filled"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_voxel_grid(bbox, szval, use_cubes=False):\n    # Input validation\n    if szval[0] <= 1 or szval[1] <= 1 or szval[2] <= 1:\n        raise GeomdlException(\"Size values must be bigger than 1\", data=dict(sizevals=szval))\n\n    # Find step size for each direction\n    steps = [float(bbox[1][idx] - bbox[0][idx]) / float(szval[idx] - 1) for idx in range(0, 3)]\n\n    # It is possible to use cubes instead of cuboids\n    if use_cubes:\n        min_val = min(*steps)\n        steps = [min_val for _ in range(0, 3)]\n\n    # Find range in each direction\n    ranges = [list(linalg.frange(bbox[0][idx], bbox[1][idx], steps[idx])) for idx in range(0, 3)]\n\n    voxel_grid = []\n    for u in ranges[0]:\n        for v in ranges[1]:\n            for w in ranges[2]:\n                bbmin = [u, v, w]\n                bbmax = [k + l for k, l in zip(bbmin, steps)]\n                voxel_grid.append([bbmin, bbmax])\n    return voxel_grid", "response": "Generates the voxel grid with the desired size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn 1 if any point is contained inside the voxel boundaries.", "response": "def is_point_inside_voxel(bbox, ptsarr, **kwargs):\n    \"\"\" Finds if any point is contained inside the voxel boundaries (inouts array).\n\n    Ref: https://math.stackexchange.com/a/1552579\n\n    :param bbox: bounding box of the voxel\n    :type bbox: list, tuple\n    :param ptsarr: points to be checked\n    :type ptsarr: list, tuple\n    :return: list of ins and outs\n    :rtype: list\n    \"\"\"\n    # Get keyword arguments\n    tol = kwargs.get('tol', 10e-8)  # padding value\n\n    # Make bounding box vertices more readable\n    bbmin = [b - tol for b in bbox[0]]\n    bbmax = [b + tol for b in bbox[1]]\n\n    # Find basis vectors\n    i = [bbmax[0] - bbmin[0], 0, 0]\n    j = [0, bbmax[1] - bbmin[1], 0]\n    k = [0, 0, bbmax[2] - bbmin[2]]\n\n    # Find dot products\n    idi = linalg.vector_dot(i, i)\n    jdj = linalg.vector_dot(j, j)\n    kdk = linalg.vector_dot(k, k)\n\n    for pt in ptsarr:\n        v = [p - b for p, b in zip(pt, bbmin)]\n        # Bigger than and equal to will include the border and,\n        # since we have a padding on the boundary box, we only\n        # need to include the lower boundary below\n        vdi = linalg.vector_dot(v, i)\n        vdj = linalg.vector_dot(v, j)\n        vdk = linalg.vector_dot(v, k)\n        if idi > vdi >= 0.0 and jdj > vdj >= 0.0 and kdk > vdk >= 0.0:\n            return 1\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess Jinja2 template input file and return the result", "response": "def process_template(file_src):\n    \"\"\" Process Jinja2 template input\n\n    :param file_src: file contents\n    :type file_src: str\n    \"\"\"\n    def tmpl_sqrt(x):\n        \"\"\" Square-root of 'x' \"\"\"\n        return math.sqrt(x)\n\n    def tmpl_cubert(x):\n        \"\"\" Cube-root of 'x' \"\"\"\n        return x ** (1.0 / 3.0) if x >= 0 else -(-x) ** (1.0 / 3.0)\n\n    def tmpl_pow(x, y):\n        \"\"\" 'x' to the power 'y' \"\"\"\n        return math.pow(x, y)\n\n    # Check if it is possible to import 'jinja2'\n    try:\n        import jinja2\n    except ImportError:\n        raise GeomdlException(\"Please install 'jinja2' package to use templated input: pip install jinja2\")\n\n    # Replace jinja2 template tags for compatibility\n    fsrc = file_src.replace(\"{%\", \"<%\").replace(\"%}\", \"%>\").replace(\"{{\", \"<{\").replace(\"}}\", \"}>\")\n\n    # Generate Jinja2 environment\n    env = jinja2.Environment(\n        loader=jinja2.BaseLoader(),\n        trim_blocks=True,\n        block_start_string='<%', block_end_string='%>',\n        variable_start_string='<{', variable_end_string='}>'\n    ).from_string(fsrc)\n\n    # Load custom functions into the Jinja2 environment\n    template_funcs = dict(\n        knot_vector=utilities.generate_knot_vector,\n        sqrt=tmpl_sqrt,\n        cubert=tmpl_cubert,\n        pow=tmpl_pow,\n    )\n    for k, v in template_funcs.items():\n        env.globals[k] = v\n\n    # Process Jinja2 template functions & variables inside the input file\n    return env.render()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports a NURBS surface from a mesh file.", "response": "def import_surf_mesh(file_name):\n    \"\"\" Generates a NURBS surface object from a mesh file.\n\n    :param file_name: input mesh file\n    :type file_name: str\n    :return: a NURBS surface\n    :rtype: NURBS.Surface\n    \"\"\"\n    raw_content = read_file(file_name)\n    raw_content = raw_content.split(\"\\n\")\n    content = []\n    for rc in raw_content:\n        temp = rc.strip().split()\n        content.append(temp)\n\n    # 1st line defines the dimension and it must be 3\n    if int(content[0][0]) != 3:\n        raise TypeError(\"Input mesh '\" + str(file_name) + \"' must be 3-dimensional\")\n\n    # Create a NURBS surface instance and fill with the data read from mesh file\n    surf = shortcuts.generate_surface(rational=True)\n\n    # 2nd line is the degrees\n    surf.degree_u = int(content[1][0])\n    surf.degree_v = int(content[1][1])\n\n    # 3rd line is the number of weighted control points in u and v directions\n    dim_u = int(content[2][0])\n    dim_v = int(content[2][1])\n\n    # Starting from 6th line, we have the weighted control points\n    ctrlpts_end = 5 + (dim_u * dim_v)\n    ctrlpts_mesh = content[5:ctrlpts_end]\n\n    # mesh files have the control points in u-row order format\n    ctrlpts = compatibility.flip_ctrlpts_u(ctrlpts_mesh, dim_u, dim_v)\n\n    # mesh files store control points in format (x, y, z, w)\n    ctrlptsw = compatibility.generate_ctrlptsw(ctrlpts)\n\n    # Set control points\n    surf.set_ctrlpts(ctrlptsw, dim_u, dim_v)\n\n    # 4th and 5th lines are knot vectors\n    surf.knotvector_u = [float(u) for u in content[3]]\n    surf.knotvector_v = [float(v) for v in content[4]]\n\n    # Return the surface instance\n    return surf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_vol_mesh(file_name):\n    raw_content = read_file(file_name)\n    raw_content = raw_content.split(\"\\n\")\n    content = []\n    for rc in raw_content:\n        temp = rc.strip().split()\n        content.append(temp)\n\n    # 1st line defines the dimension and it must be 3\n    if int(content[0][0]) != 3:\n        raise TypeError(\"Input mesh '\" + str(file_name) + \"' must be 3-dimensional\")\n\n    # Create a NURBS surface instance and fill with the data read from mesh file\n    vol = shortcuts.generate_volume(rational=True)\n\n    # 2nd line is the degrees\n    vol.degree_u = int(content[1][0])\n    vol.degree_v = int(content[1][1])\n    vol.degree_w = int(content[1][2])\n\n    # 3rd line is the number of weighted control points in u, v, w directions\n    dim_u = int(content[2][0])\n    dim_v = int(content[2][1])\n    dim_w = int(content[2][2])\n\n    # Starting from 7th line, we have the weighted control points\n    surf_cpts = dim_u * dim_v\n    ctrlpts_end = 6 + (surf_cpts * dim_w)\n    ctrlpts_mesh = content[6:ctrlpts_end]\n\n    # mesh files have the control points in u-row order format\n    ctrlpts = []\n    for i in range(dim_w - 1):\n        ctrlpts += compatibility.flip_ctrlpts_u(ctrlpts_mesh[surf_cpts * i:surf_cpts * (i + 1)], dim_u, dim_v)\n\n    # mesh files store control points in format (x, y, z, w)\n    ctrlptsw = compatibility.generate_ctrlptsw(ctrlpts)\n\n    # Set control points\n    vol.set_ctrlpts(ctrlptsw, dim_u, dim_v, dim_w)\n\n    # 4th, 5th and 6th lines are knot vectors\n    vol.knotvector_u = [float(u) for u in content[3]]\n    vol.knotvector_v = [float(v) for v in content[4]]\n    vol.knotvector_w = [float(w) for w in content[5]]\n\n    # Return the volume instance\n    return vol", "response": "Imports a NURBS volume from a mesh file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting control points from a text file and generates a 1 - dimensional list of control points.", "response": "def import_txt(file_name, two_dimensional=False, **kwargs):\n    \"\"\" Reads control points from a text file and generates a 1-dimensional list of control points.\n\n    The following code examples illustrate importing different types of text files for curves and surfaces:\n\n    .. code-block:: python\n        :linenos:\n\n        # Import curve control points from a text file\n        curve_ctrlpts = exchange.import_txt(file_name=\"control_points.txt\")\n\n        # Import surface control points from a text file (1-dimensional file)\n        surf_ctrlpts = exchange.import_txt(file_name=\"control_points.txt\")\n\n        # Import surface control points from a text file (2-dimensional file)\n        surf_ctrlpts, size_u, size_v = exchange.import_txt(file_name=\"control_points.txt\", two_dimensional=True)\n\n    If argument ``jinja2=True`` is set, then the input file is processed as a `Jinja2 <http://jinja.pocoo.org/>`_\n    template. You can also use the following convenience template functions which correspond to the given mathematical\n    equations:\n\n    * ``sqrt(x)``:  :math:`\\\\sqrt{x}`\n    * ``cubert(x)``: :math:`\\\\sqrt[3]{x}`\n    * ``pow(x, y)``: :math:`x^{y}`\n\n    You may set the file delimiters using the keyword arguments ``separator`` and ``col_separator``, respectively.\n    ``separator`` is the delimiter between the coordinates of the control points. It could be comma\n    ``1, 2, 3`` or space ``1 2 3`` or something else. ``col_separator`` is the delimiter between the control\n    points and is only valid when ``two_dimensional`` is ``True``. Assuming that ``separator`` is set to space, then\n    ``col_operator`` could be semi-colon ``1 2 3; 4 5 6`` or pipe ``1 2 3| 4 5 6`` or comma ``1 2 3, 4 5 6`` or\n    something else.\n\n    The defaults for ``separator`` and ``col_separator`` are *comma (,)* and *semi-colon (;)*, respectively.\n\n    The following code examples illustrate the usage of the keyword arguments discussed above.\n\n    .. code-block:: python\n        :linenos:\n\n        # Import curve control points from a text file delimited with space\n        curve_ctrlpts = exchange.import_txt(file_name=\"control_points.txt\", separator=\" \")\n\n        # Import surface control points from a text file (2-dimensional file) w/ space and comma delimiters\n        surf_ctrlpts, size_u, size_v = exchange.import_txt(file_name=\"control_points.txt\", two_dimensional=True,\n                                                           separator=\" \", col_separator=\",\")\n\n    Please note that this function does not check whether the user set delimiters to the same value or not.\n\n    :param file_name: file name of the text file\n    :type file_name: str\n    :param two_dimensional: type of the text file\n    :type two_dimensional: bool\n    :return: list of control points, if two_dimensional, then also returns size in u- and v-directions\n    :rtype: list\n    :raises GeomdlException: an error occurred reading the file\n    \"\"\"\n    # Read file\n    content = exch.read_file(file_name)\n\n    # Are we using a Jinja2 template?\n    j2tmpl = kwargs.get('jinja2', False)\n    if j2tmpl:\n        content = exch.process_template(content)\n\n    # File delimiters\n    col_sep = kwargs.get('col_separator', \";\")\n    sep = kwargs.get('separator', \",\")\n\n    return exch.import_text_data(content, sep, col_sep, two_dimensional)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_txt(obj, file_name, two_dimensional=False, **kwargs):\n    # Check if the user has set any control points\n    if obj.ctrlpts is None or len(obj.ctrlpts) == 0:\n        raise exch.GeomdlException(\"There are no control points to save!\")\n\n    # Check the usage of two_dimensional flag\n    if obj.pdimension == 1 and two_dimensional:\n        # Silently ignore two_dimensional flag\n        two_dimensional = False\n\n    # File delimiters\n    col_sep = kwargs.get('col_separator', \";\")\n    sep = kwargs.get('separator', \",\")\n\n    content = exch.export_text_data(obj, sep, col_sep, two_dimensional)\n    return exch.write_file(file_name, content)", "response": "Exports control points as a text file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_csv(file_name, **kwargs):\n    # File delimiters\n    sep = kwargs.get('separator', \",\")\n\n    content = exch.read_file(file_name, skip_lines=1)\n    return exch.import_text_data(content, sep)", "response": "Reads control points from a CSV file and generates a 1 - dimensional list of control points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting control points or evaluated points as a CSV file.", "response": "def export_csv(obj, file_name, point_type='evalpts', **kwargs):\n    \"\"\" Exports control points or evaluated points as a CSV file.\n\n    :param obj: a spline geometry object\n    :type obj: abstract.SplineGeometry\n    :param file_name: output file name\n    :type file_name: str\n    :param point_type: ``ctrlpts`` for control points or ``evalpts`` for evaluated points\n    :type point_type: str\n    :raises GeomdlException: an error occurred writing the file\n    \"\"\"\n    if not 0 < obj.pdimension < 3:\n        raise exch.GeomdlException(\"Input object should be a curve or a surface\")\n\n    # Pick correct points from the object\n    if point_type == 'ctrlpts':\n        points = obj.ctrlptsw if obj.rational else obj.ctrlpts\n    elif point_type == 'evalpts':\n        points = obj.evalpts\n    else:\n        raise exch.GeomdlException(\"Please choose a valid point type option. Possible types: ctrlpts, evalpts\")\n\n    # Prepare CSV header\n    dim = len(points[0])\n    line = \"dim \"\n    for i in range(dim-1):\n        line += str(i + 1) + \", dim \"\n    line += str(dim) + \"\\n\"\n\n    # Prepare values\n    for pt in points:\n        line += \",\".join([str(p) for p in pt]) + \"\\n\"\n\n    # Write to file\n    return exch.write_file(file_name, line)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_cfg(file_name, **kwargs):\n    def callback(data):\n        return libconf.loads(data)\n\n    # Check if it is possible to import 'libconf'\n    try:\n        import libconf\n    except ImportError:\n        raise exch.GeomdlException(\"Please install 'libconf' package to use libconfig format: pip install libconf\")\n\n    # Get keyword arguments\n    delta = kwargs.get('delta', -1.0)\n    use_template = kwargs.get('jinja2', False)\n\n    # Read file\n    file_src = exch.read_file(file_name)\n\n    # Import data\n    return exch.import_dict_str(file_src=file_src, delta=delta, callback=callback, tmpl=use_template)", "response": "Imports curves and surfaces from a libconfig file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports curves and surfaces in libconfig format.", "response": "def export_cfg(obj, file_name):\n    \"\"\" Exports curves and surfaces in libconfig format.\n\n    .. note::\n\n        Requires `libconf <https://pypi.org/project/libconf/>`_ package.\n\n    Libconfig format is also used by the `geomdl command-line application <https://github.com/orbingol/geomdl-cli>`_\n    as a way to input shape data from the command line.\n\n    :param obj: input geometry\n    :type obj: abstract.SplineGeometry, multi.AbstractContainer\n    :param file_name: name of the output file\n    :type file_name: str\n    :raises GeomdlException: an error occurred writing the file\n    \"\"\"\n    def callback(data):\n        return libconf.dumps(data)\n\n    # Check if it is possible to import 'libconf'\n    try:\n        import libconf\n    except ImportError:\n        raise exch.GeomdlException(\"Please install 'libconf' package to use libconfig format: pip install libconf\")\n\n    # Export data\n    exported_data = exch.export_dict_str(obj=obj, callback=callback)\n\n    # Write to file\n    return exch.write_file(file_name, exported_data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport curves and surfaces from files in YAML format.", "response": "def import_yaml(file_name, **kwargs):\n    \"\"\" Imports curves and surfaces from files in YAML format.\n\n    .. note::\n\n        Requires `ruamel.yaml <https://pypi.org/project/ruamel.yaml/>`_ package.\n\n    Use ``jinja2=True`` to activate Jinja2 template processing. Please refer to the documentation for details.\n\n    :param file_name: name of the input file\n    :type file_name: str\n    :return: a list of rational spline geometries\n    :rtype: list\n    :raises GeomdlException: an error occurred reading the file\n    \"\"\"\n    def callback(data):\n        yaml = YAML()\n        return yaml.load(data)\n\n    # Check if it is possible to import 'ruamel.yaml'\n    try:\n        from ruamel.yaml import YAML\n    except ImportError:\n        raise exch.GeomdlException(\"Please install 'ruamel.yaml' package to use YAML format: pip install ruamel.yaml\")\n\n    # Get keyword arguments\n    delta = kwargs.get('delta', -1.0)\n    use_template = kwargs.get('jinja2', False)\n\n    # Read file\n    file_src = exch.read_file(file_name)\n\n    # Import data\n    return exch.import_dict_str(file_src=file_src, delta=delta, callback=callback, tmpl=use_template)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_yaml(obj, file_name):\n    def callback(data):\n        # Ref: https://yaml.readthedocs.io/en/latest/example.html#output-of-dump-as-a-string\n        stream = StringIO()\n        yaml = YAML()\n        yaml.dump(data, stream)\n        return stream.getvalue()\n\n    # Check if it is possible to import 'ruamel.yaml'\n    try:\n        from ruamel.yaml import YAML\n    except ImportError:\n        raise exch.GeomdlException(\"Please install 'ruamel.yaml' package to use YAML format: pip install ruamel.yaml\")\n\n    # Export data\n    exported_data = exch.export_dict_str(obj=obj, callback=callback)\n\n    # Write to file\n    return exch.write_file(file_name, exported_data)", "response": "Exports curves and surfaces in YAML format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_json(file_name, **kwargs):\n    def callback(data):\n        return json.loads(data)\n\n    # Get keyword arguments\n    delta = kwargs.get('delta', -1.0)\n    use_template = kwargs.get('jinja2', False)\n\n    # Read file\n    file_src = exch.read_file(file_name)\n\n    # Import data\n    return exch.import_dict_str(file_src=file_src, delta=delta, callback=callback, tmpl=use_template)", "response": "Imports curves and surfaces from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_json(obj, file_name):\n    def callback(data):\n        return json.dumps(data, indent=4)\n\n    # Export data\n    exported_data = exch.export_dict_str(obj=obj, callback=callback)\n\n    # Write to file\n    return exch.write_file(file_name, exported_data)", "response": "Exports curves and surfaces in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading and generates faces from a. obj file and generates faces.", "response": "def import_obj(file_name, **kwargs):\n    \"\"\" Reads .obj files and generates faces.\n\n    Keyword Arguments:\n        * ``callback``: reference to the function that processes the faces for customized output\n\n    The structure of the callback function is shown below:\n\n    .. code-block:: python\n\n        def my_callback_function(face_list):\n            # \"face_list\" will be a list of elements.Face class instances\n            # The function should return a list\n            return list()\n\n    :param file_name: file name\n    :type file_name: str\n    :return: output of the callback function (default is a list of faces)\n    :rtype: list\n    \"\"\"\n    def default_callback(face_list):\n        return face_list\n\n    # Keyword arguments\n    callback_func = kwargs.get('callback', default_callback)\n\n    # Read and process the input file\n    content = exch.read_file(file_name)\n    content_arr = content.split(\"\\n\")\n\n    # Initialize variables\n    on_face = False\n    vertices = []\n    triangles = []\n    faces = []\n\n    # Index values\n    vert_idx = 1\n    tri_idx = 1\n    face_idx = 1\n\n    # Loop through the data\n    for carr in content_arr:\n        carr = carr.strip()\n        data = carr.split(\" \")\n        data = [d.strip() for d in data]\n        if data[0] == \"v\":\n            if on_face:\n                on_face = not on_face\n                face = elements.Face(*triangles, id=face_idx)\n                faces.append(face)\n                face_idx += 1\n                vertices[:] = []\n                triangles[:] = []\n                vert_idx = 1\n                tri_idx = 1\n            vertex = elements.Vertex(*data[1:], id=vert_idx)\n            vertices.append(vertex)\n            vert_idx += 1\n        if data[0] == \"f\":\n            on_face = True\n            triangle = elements.Triangle(*[vertices[int(fidx) - 1] for fidx in data[1:]], id=tri_idx)\n            triangles.append(triangle)\n            tri_idx += 1\n\n    # Process he final face\n    if triangles:\n        face = elements.Face(*triangles, id=face_idx)\n        faces.append(face)\n\n    # Return the output of the callback function\n    return callback_func(faces)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting a single - surface object to a. obj file.", "response": "def export_obj(surface, file_name, **kwargs):\n    \"\"\" Exports surface(s) as a .obj file.\n\n    Keyword Arguments:\n        * ``vertex_spacing``: size of the triangle edge in terms of surface points sampled. *Default: 2*\n        * ``vertex_normals``: if True, then computes vertex normals. *Default: False*\n        * ``parametric_vertices``: if True, then adds parameter space vertices. *Default: False*\n        * ``update_delta``: use multi-surface evaluation delta for all surfaces. *Default: True*\n\n    :param surface: surface or surfaces to be saved\n    :type surface: abstract.Surface or multi.SurfaceContainer\n    :param file_name: name of the output file\n    :type file_name: str\n    :raises GeomdlException: an error occurred writing the file\n    \"\"\"\n    content = export_obj_str(surface, **kwargs)\n    return exch.write_file(file_name, content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport a list of surfaces as a. obj file.", "response": "def export_obj_str(surface, **kwargs):\n    \"\"\" Exports surface(s) as a .obj file (string).\n\n    Keyword Arguments:\n        * ``vertex_spacing``: size of the triangle edge in terms of surface points sampled. *Default: 2*\n        * ``vertex_normals``: if True, then computes vertex normals. *Default: False*\n        * ``parametric_vertices``: if True, then adds parameter space vertices. *Default: False*\n        * ``update_delta``: use multi-surface evaluation delta for all surfaces. *Default: True*\n\n    :param surface: surface or surfaces to be saved\n    :type surface: abstract.Surface or multi.SurfaceContainer\n    :return: contents of the .obj file generated\n    :rtype: str\n    \"\"\"\n    # Get keyword arguments\n    vertex_spacing = int(kwargs.get('vertex_spacing', 1))\n    include_vertex_normal = kwargs.get('vertex_normals', False)\n    include_param_vertex = kwargs.get('parametric_vertices', False)\n    update_delta = kwargs.get('update_delta', True)\n\n    # Input validity checking\n    if surface.pdimension != 2:\n        raise exch.GeomdlException(\"Can only export surfaces\")\n    if vertex_spacing < 1:\n        raise exch.GeomdlException(\"Vertex spacing should be bigger than zero\")\n\n    # Create the string and start adding triangulated surface points\n    line = \"# Generated by geomdl\\n\"\n    vertex_offset = 0  # count the vertices to update the face numbers correctly\n\n    # Initialize lists for geometry data\n    str_v = []  # vertices\n    str_vn = []  # vertex normals\n    str_vp = []  # parameter space vertices\n    str_f = []  # faces\n\n    # Loop through SurfaceContainer object\n    for srf in surface:\n        # Set surface evaluation delta\n        if update_delta:\n            srf.sample_size_u = surface.sample_size_u\n            srf.sample_size_v = surface.sample_size_v\n\n        # Tessellate surface\n        srf.tessellate(vertex_spacing=vertex_spacing)\n        vertices = srf.tessellator.vertices\n        triangles = srf.tessellator.faces\n\n        # Collect vertices\n        for vert in vertices:\n            temp = \"v \" + str(vert.x) + \" \" + str(vert.y) + \" \" + str(vert.z) + \"\\n\"\n            str_v.append(temp)\n\n        # Collect parameter space vertices\n        if include_param_vertex:\n            for vert in vertices:\n                temp = \"vp \" + str(vert.uv[0]) + \" \" + str(vert.uv[1]) + \"\\n\"\n                str_vp.append(temp)\n\n        # Compute vertex normals\n        if include_vertex_normal:\n            for vert in vertices:\n                sn = operations.normal(srf, vert.uv)\n                temp = \"vn \" + str(sn[1][0]) + \" \" + str(sn[1][1]) + \" \" + str(sn[1][2]) + \"\\n\"\n                str_vn.append(temp)\n\n        # Collect faces (1-indexed)\n        for t in triangles:\n            vl = t.data\n            temp = \"f \" + \\\n                   str(vl[0] + 1 + vertex_offset) + \" \" + \\\n                   str(vl[1] + 1 + vertex_offset) + \" \" + \\\n                   str(vl[2] + 1 + vertex_offset) + \"\\n\"\n            str_f.append(temp)\n\n        # Update vertex offset\n        vertex_offset = len(str_v)\n\n    # Write all collected data to the return string\n    for lv in str_v:\n        line += lv\n    for lvn in str_vn:\n        line += lvn\n    for lvp in str_vp:\n        line += lvp\n    for lf in str_f:\n        line += lf\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport a single surface as a. stl file in plain text or binary format.", "response": "def export_stl(surface, file_name, **kwargs):\n    \"\"\" Exports surface(s) as a .stl file in plain text or binary format.\n\n    Keyword Arguments:\n        * ``binary``: flag to generate a binary STL file. *Default: True*\n        * ``vertex_spacing``: size of the triangle edge in terms of points sampled on the surface. *Default: 1*\n        * ``update_delta``: use multi-surface evaluation delta for all surfaces. *Default: True*\n\n    :param surface: surface or surfaces to be saved\n    :type surface: abstract.Surface or multi.SurfaceContainer\n    :param file_name: name of the output file\n    :type file_name: str\n    :raises GeomdlException: an error occurred writing the file\n    \"\"\"\n    binary = kwargs.get('binary', True)\n    if 'binary' in kwargs:\n        kwargs.pop('binary')\n    content = export_stl_str(surface, binary=binary, **kwargs)\n    return exch.write_file(file_name, content, binary=binary)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports a list of surfaces as a. stl file in plain text or binary format.", "response": "def export_stl_str(surface, **kwargs):\n    \"\"\" Exports surface(s) as a .stl file in plain text or binary format (string).\n\n    Keyword Arguments:\n        * ``binary``: flag to generate a binary STL file. *Default: False*\n        * ``vertex_spacing``: size of the triangle edge in terms of points sampled on the surface. *Default: 1*\n        * ``update_delta``: use multi-surface evaluation delta for all surfaces. *Default: False*\n\n    :param surface: surface or surfaces to be saved\n    :type surface: abstract.Surface or multi.SurfaceContainer\n    :return: contents of the .stl file generated\n    :rtype: str\n    \"\"\"\n    binary = kwargs.get('binary', False)\n    vertex_spacing = int(kwargs.get('vertex_spacing', 1))\n    update_delta = kwargs.get('update_delta', True)\n\n    # Input validity checking\n    if surface.pdimension != 2:\n        raise exch.GeomdlException(\"Can only export surfaces\")\n    if vertex_spacing < 1:\n        raise exch.GeomdlException(\"Vertex spacing should be bigger than zero\")\n\n    triangles_list = []\n    for srf in surface:\n        # Set surface evaluation delta\n        if update_delta:\n            srf.sample_size_u = surface.sample_size_u\n            srf.sample_size_v = surface.sample_size_v\n\n        # Tessellate surface\n        srf.tessellate(vertex_spacing=vertex_spacing)\n        triangles = srf.tessellator.faces\n\n        triangles_list += triangles\n\n    # Write triangle list to ASCII or  binary STL file\n    if binary:\n        line = b'\\0' * 80  # header\n        line += struct.pack('<i', len(triangles_list))  # number of triangles\n        for t in triangles_list:\n            line += struct.pack('<3f', *linalg.triangle_normal(t))  # normal\n            for v in t.vertices:\n                line += struct.pack('<3f', *v.data)  # vertices\n            line += b'\\0\\0'  # attribute byte count\n    else:\n        line = \"solid Surface\\n\"\n        for t in triangles_list:\n            nvec = linalg.triangle_normal(t)\n            line += \"\\tfacet normal \" + str(nvec[0]) + \" \" + str(nvec[1]) + \" \" + str(nvec[2]) + \"\\n\"\n            line += \"\\t\\touter loop\\n\"\n            for v in t.vertices:\n                line += \"\\t\\t\\tvertex \" + str(v.x) + \" \" + str(v.y) + \" \" + str(v.z) + \"\\n\"\n            line += \"\\t\\tendloop\\n\"\n            line += \"\\tendfacet\\n\"\n        line += \"endsolid Surface\\n\"\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_off(surface, file_name, **kwargs):\n    content = export_off_str(surface, **kwargs)\n    return exch.write_file(file_name, content)", "response": "Exports a single - surface or multi - surface container as a. off file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport a list of all surfaces in a single - surface.", "response": "def export_off_str(surface, **kwargs):\n    \"\"\" Exports surface(s) as a .off file (string).\n\n    Keyword Arguments:\n        * ``vertex_spacing``: size of the triangle edge in terms of points sampled on the surface. *Default: 1*\n        * ``update_delta``: use multi-surface evaluation delta for all surfaces. *Default: True*\n\n    :param surface: surface or surfaces to be saved\n    :type surface: abstract.Surface or multi.SurfaceContainer\n    :return: contents of the .off file generated\n    :rtype: str\n    \"\"\"\n    # Get keyword arguments\n    vertex_spacing = int(kwargs.get('vertex_spacing', 1))\n    update_delta = kwargs.get('update_delta', True)\n\n    # Input validity checking\n    if surface.pdimension != 2:\n        raise exch.GeomdlException(\"Can only export surfaces\")\n    if vertex_spacing < 1:\n        raise exch.GeomdlException(\"Vertex spacing should be bigger than zero\")\n\n    # Count the vertices to update the face numbers correctly\n    vertex_offset = 0\n\n    # Initialize lists for vertices, vertex normals and faces\n    str_v = []\n    str_f = []\n\n    for srf in surface:\n        # Set surface evaluation delta\n        if update_delta:\n            srf.sample_size_u = surface.sample_size_u\n            srf.sample_size_v = surface.sample_size_v\n\n        # Tessellate surface\n        srf.tessellate(vertex_spacing=vertex_spacing)\n        vertices = srf.tessellator.vertices\n        triangles = srf.tessellator.faces\n\n        # Collect vertices\n        for vert in vertices:\n            line = str(vert.x) + \" \" + str(vert.y) + \" \" + str(vert.z) + \"\\n\"\n            str_v.append(line)\n\n        # Collect faces (zero-indexed)\n        for t in triangles:\n            vl = t.data\n            line = \"3 \" + \\\n                   str(vl[0] + vertex_offset) + \" \" + \\\n                   str(vl[1] + vertex_offset) + \" \" + \\\n                   str(vl[2] + vertex_offset) + \"\\n\"\n            str_f.append(line)\n\n        # Update vertex offset\n        vertex_offset = len(str_v)\n\n    # Write file header\n    line = \"OFF\\n\"\n    line += str(len(str_v)) + \" \" + str(len(str_f)) + \" 0\\n\"\n\n    # Write all collected data to the file\n    for lv in str_v:\n        line += lv\n    for lf in str_f:\n        line += lf\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_smesh(file):\n    imported_elements = []\n    if os.path.isfile(file):\n        imported_elements.append(exch.import_surf_mesh(file))\n    elif os.path.isdir(file):\n        files = sorted([os.path.join(file, f) for f in os.listdir(file)])\n        for f in files:\n            imported_elements.append(exch.import_surf_mesh(f))\n    else:\n        raise exch.GeomdlException(\"Input is not a file or a directory\")\n    return imported_elements", "response": "Imports a NURBS surface from a surface mesh file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_smesh(surface, file_name, **kwargs):\n    # Input validity checking\n    if surface.pdimension != 2:\n        raise exch.GeomdlException(\"Can only export surfaces\")\n\n    # Get keyword arguments\n    decimals = kwargs.get('decimals', 18)\n\n    # Split file name and extension\n    fname, fext = os.path.splitext(file_name)\n\n    # Enumerate file name only if we are working with multiple surfaces\n    numerate_file = True if len(surface) > 1 else False\n\n    for idx, s in enumerate(surface):\n        if s.rational:\n            pts = s.ctrlptsw\n        else:\n            pts = compatibility.combine_ctrlpts_weights(s.ctrlpts)\n        line = str(s.dimension) + \"\\n\"\n        line += str(s.degree_u) + \" \" + str(s.degree_v) + \"\\n\"\n        line += str(s.ctrlpts_size_u) + \" \" + str(s.ctrlpts_size_v) + \"\\n\"\n        line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(k) for k in s.knotvector_u]) + \"\\n\"\n        line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(k) for k in s.knotvector_v]) + \"\\n\"\n        # Flip control points\n        ctrlptsw = compatibility.flip_ctrlpts(pts, s.ctrlpts_size_u, s.ctrlpts_size_v)\n        # Convert control points into (x, y, z, w) format\n        ctrlptsw = compatibility.generate_ctrlpts_weights(ctrlptsw)\n        for ptw in ctrlptsw:\n            line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(p) for p in ptw]) + \"\\n\"\n        # Open or closed?\n        line += \"1\\n\"\n\n        # Write to file\n        fname_curr = fname + \".\" + str(idx + 1) if numerate_file else fname\n        exch.write_file(fname_curr + fext, line)", "response": "Exports a single or multi - surface container as a single smesh file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport NURBS volumes from volume mesh file ( s ) or a single mesh file.", "response": "def import_vmesh(file):\n    \"\"\" Imports NURBS volume(s) from volume mesh (vmesh) file(s).\n\n    :param file: path to a directory containing mesh files or a single mesh file\n    :type file: str\n    :return: list of NURBS volumes\n    :rtype: list\n    :raises GeomdlException: an error occurred reading the file\n    \"\"\"\n    imported_elements = []\n    if os.path.isfile(file):\n        imported_elements.append(exch.import_vol_mesh(file))\n    elif os.path.isdir(file):\n        files = sorted([os.path.join(file, f) for f in os.listdir(file)])\n        for f in files:\n            imported_elements.append(exch.import_vol_mesh(f))\n    else:\n        raise exch.GeomdlException(\"Input is not a file or a directory\")\n    return imported_elements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport a volume as a volume mesh file.", "response": "def export_vmesh(volume, file_name, **kwargs):\n    \"\"\" Exports volume(s) as volume mesh (vmesh) files.\n\n    :param volume: volume(s) to be exported\n    :type volume: abstract.Volume\n    :param file_name: name of the output file\n    :type file_name: str\n    :raises GeomdlException: an error occurred writing the file\n    \"\"\"\n    if volume.pdimension != 3:\n        raise exch.GeomdlException(\"Can only export volumes\")\n\n    # Get keyword arguments\n    decimals = kwargs.get('decimals', 18)\n\n    # Split file name and extension\n    fname, fext = os.path.splitext(file_name)\n\n    # Enumerate file name only if we are working with multiple volumes\n    numerate_file = True if len(volume) > 1 else False\n\n    for idx, v in enumerate(volume):\n        if v.rational:\n            pts = v.ctrlptsw\n        else:\n            pts = compatibility.combine_ctrlpts_weights(v.ctrlpts)\n        line = str(v.dimension) + \"\\n\"\n        line += str(v.degree_u) + \" \" + str(v.degree_v) + \" \" + str(v.degree_w) + \"\\n\"\n        line += str(v.ctrlpts_size_u) + \" \" + str(v.ctrlpts_size_v) + \" \" + str(v.ctrlpts_size_w) + \"\\n\"\n        line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(k) for k in v.knotvector_u]) + \"\\n\"\n        line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(k) for k in v.knotvector_v]) + \"\\n\"\n        line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(k) for k in v.knotvector_w]) + \"\\n\"\n        # Convert control points into (x, y, z, w)\n        ctrlptsw = []\n        for w in range(v.ctrlpts_size_w):\n            srfpts = pts[(w * v.ctrlpts_size_u * v.ctrlpts_size_v):((w + 1) * v.ctrlpts_size_u * v.ctrlpts_size_v)]\n            # Flip control points\n            ctrlptsw += compatibility.flip_ctrlpts(srfpts, v.ctrlpts_size_u, v.ctrlpts_size_v)\n        # Convert control points into (x, y, z, w) format\n        ctrlptsw = compatibility.generate_ctrlpts_weights(ctrlptsw)\n        for ptw in ctrlptsw:\n            line += \" \".join([(\"{:.\" + str(decimals) + \"f}\").format(p) for p in ptw]) + \"\\n\"\n        # Open or closed?\n        line += \"1\\n\"\n\n        # Write to file\n        fname_curr = fname + \".\" + str(idx + 1) if numerate_file else fname\n        exch.write_file(fname_curr + fext, line)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, **kwargs):\n        # Calling parent function\n        super(VisCurve2D, self).render(**kwargs)\n\n        # Initialize variables\n        plot_data = []\n\n        for plot in self._plots:\n            pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                figure = graph_objs.Scatter(\n                    x=pts[:, 0],\n                    y=pts[:, 1],\n                    name=plot['name'],\n                    mode='lines+markers',\n                    line=dict(\n                        color=plot['color'],\n                        width=self.vconf.line_width,\n                        dash='dash'\n                    )\n                )\n                plot_data.append(figure)\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                figure = graph_objs.Scatter(\n                    x=pts[:, 0],\n                    y=pts[:, 1],\n                    name=plot['name'],\n                    mode='lines',\n                    line=dict(\n                        color=plot['color'],\n                        width=self.vconf.line_width\n                    )\n                )\n                plot_data.append(figure)\n\n            # Plot bounding box\n            if plot['type'] == 'bbox' and self.vconf.display_bbox:\n                figure = graph_objs.Scatter(\n                    x=pts[:, 0],\n                    y=pts[:, 1],\n                    name=plot['name'],\n                    line=dict(\n                        color=plot['color'],\n                        width=self.vconf.line_width,\n                        dash='dashdot',\n                    )\n                )\n                plot_data.append(figure)\n\n            # Plot extras\n            if plot['type'] == 'extras':\n                figure = graph_objs.Scatter(\n                    x=pts[:, 0],\n                    y=pts[:, 1],\n                    name=plot['name'],\n                    mode='markers',\n                    marker=dict(\n                        color=plot['color'][0],\n                        size=plot['color'][1],\n                        line=dict(\n                            width=self.vconf.line_width\n                        )\n                    )\n                )\n                plot_data.append(figure)\n\n        plot_layout = dict(\n            width=self.vconf.figure_size[0],\n            height=self.vconf.figure_size[1],\n            autosize=False,\n            showlegend=self.vconf.display_legend,\n            yaxis=dict(\n                scaleanchor=\"x\",\n                showgrid=self.vconf.display_axes,\n                showline=self.vconf.display_axes,\n                zeroline=self.vconf.display_axes,\n                showticklabels=self.vconf.display_axes,\n            ),\n            xaxis=dict(\n                showgrid=self.vconf.display_axes,\n                showline=self.vconf.display_axes,\n                zeroline=self.vconf.display_axes,\n                showticklabels=self.vconf.display_axes,\n            )\n        )\n\n        # Generate the figure\n        fig = graph_objs.Figure(data=plot_data, layout=plot_layout)\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Prepare plot configuration\n        plotfn_dict = {\n            'show_link': False,\n            'filename': self.vconf.figure_filename,\n            'image': None if fig_display else self.vconf.figure_image_format,\n        }\n        if self.vconf.no_ipython:\n            plotfn_dict_extra = {\n                'image_filename': self.vconf.figure_image_filename if fig_filename is None else fig_filename,\n                'auto_open': fig_display,\n            }\n            # Python < 3.5 does not support starred expressions inside dicts\n            plotfn_dict.update(plotfn_dict_extra)\n\n        # Display the plot\n        self.vconf.plotfn(fig, **plotfn_dict)", "response": "Plots the curve and the control points polygon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting item color for plotting.", "response": "def select_color(cpcolor, evalcolor, idx=0):\n    \"\"\" Selects item color for plotting.\n\n    :param cpcolor: color for control points grid item\n    :type cpcolor: str, list, tuple\n    :param evalcolor: color for evaluated points grid item\n    :type evalcolor: str, list, tuple\n    :param idx: index of the current geometry object\n    :type idx: int\n    :return: a list of color values\n    :rtype: list\n    \"\"\"\n    # Random colors by default\n    color = utilities.color_generator()\n\n    # Constant color for control points grid\n    if isinstance(cpcolor, str):\n        color[0] = cpcolor\n\n    # User-defined color for control points grid\n    if isinstance(cpcolor, (list, tuple)):\n        color[0] = cpcolor[idx]\n\n    # Constant color for evaluated points grid\n    if isinstance(evalcolor, str):\n        color[1] = evalcolor\n\n    # User-defined color for evaluated points grid\n    if isinstance(evalcolor, (list, tuple)):\n        color[1] = evalcolor[idx]\n\n    return color"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_elements_surface(elem, mconf, colorval, idx, force_tsl, update_delta, delta, reset_names):\n    if idx < 0:\n        lock.acquire()\n        idx = counter.value\n        counter.value += 1\n        lock.release()\n\n    if update_delta:\n        elem.delta = delta\n    elem.evaluate()\n\n    # Reset element name\n    if reset_names:\n        elem.name = \"surface\"\n\n    # Fix element name\n    if elem.name == \"surface\" and idx >= 0:\n        elem.name = elem.name + \" \" + str(idx)\n\n    # Color selection\n    color = select_color(colorval[0], colorval[1], idx=idx)\n\n    # Initialize the return list\n    rl = []\n\n    # Add control points\n    if mconf['ctrlpts'] == 'points':\n        ret = dict(ptsarr=elem.ctrlpts, name=(elem.name, \"(CP)\"),\n                   color=color[0], plot_type='ctrlpts', idx=idx)\n        rl.append(ret)\n\n    # Add control points as quads\n    if mconf['ctrlpts'] == 'quads':\n        qtsl = tessellate.QuadTessellate()\n        qtsl.tessellate(elem.ctrlpts, size_u=elem.ctrlpts_size_u, size_v=elem.ctrlpts_size_v)\n        ret = dict(ptsarr=[qtsl.vertices, qtsl.faces], name=(elem.name, \"(CP)\"),\n                   color=color[0], plot_type='ctrlpts', idx=idx)\n        rl.append(ret)\n\n    # Add surface points\n    if mconf['evalpts'] == 'points':\n        ret = dict(ptsarr=elem.evalpts, name=(elem.name, idx), color=color[1], plot_type='evalpts', idx=idx)\n        rl.append(ret)\n\n    # Add surface points as quads\n    if mconf['evalpts'] == 'quads':\n        qtsl = tessellate.QuadTessellate()\n        qtsl.tessellate(elem.evalpts, size_u=elem.sample_size_u, size_v=elem.sample_size_v)\n        ret = dict(ptsarr=[qtsl.vertices, qtsl.faces],\n                   name=elem.name, color=color[1], plot_type='evalpts', idx=idx)\n        rl.append(ret)\n\n    # Add surface points as vertices and triangles\n    if mconf['evalpts'] == 'triangles':\n        elem.tessellate(force=force_tsl)\n        ret = dict(ptsarr=[elem.tessellator.vertices, elem.tessellator.faces],\n                   name=elem.name, color=color[1], plot_type='evalpts', idx=idx)\n        rl.append(ret)\n\n    # Add the trim curves\n    for itc, trim in enumerate(elem.trims):\n        ret = dict(ptsarr=elem.evaluate_list(trim.evalpts), name=(\"trim\", itc),\n                   color=colorval[2], plot_type='trimcurve', idx=idx)\n        rl.append(ret)\n\n    # Return the list\n    return rl", "response": "Processes the elements of a single surface and returns a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the span of the knot over the input knot vector using binary search. Implementation of Algorithm A2.1 from The NURBS Book by Piegl & Tiller. The NURBS Book states that the knot span index always starts from zero, i.e. for a knot vector [0, 0, 1, 1]; if FindSpan returns 1, then the knot is between the interval [0, 1). :param degree: degree, :math:`p` :type degree: int :param knot_vector: knot vector, :math:`U` :type knot_vector: list, tuple :param num_ctrlpts: number of control points, :math:`n + 1` :type num_ctrlpts: int :param knot: knot or parameter, :math:`u` :type knot: float :return: knot span :rtype: int", "response": "def find_span_binsearch(degree, knot_vector, num_ctrlpts, knot, **kwargs):\n    \"\"\" Finds the span of the knot over the input knot vector using binary search.\n\n    Implementation of Algorithm A2.1 from The NURBS Book by Piegl & Tiller.\n\n    The NURBS Book states that the knot span index always starts from zero, i.e. for a knot vector [0, 0, 1, 1];\n    if FindSpan returns 1, then the knot is between the interval [0, 1).\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param num_ctrlpts: number of control points, :math:`n + 1`\n    :type num_ctrlpts: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :return: knot span\n    :rtype: int\n    \"\"\"\n    # Get tolerance value\n    tol = kwargs.get('tol', 10e-6)\n\n    # In The NURBS Book; number of knots = m + 1, number of control points = n + 1, p = degree\n    # All knot vectors should follow the rule: m = p + n + 1\n    n = num_ctrlpts - 1\n    if abs(knot_vector[n + 1] - knot) <= tol:\n        return n\n\n    # Set max and min positions of the array to be searched\n    low = degree\n    high = num_ctrlpts\n\n    # The division could return a float value which makes it impossible to use as an array index\n    mid = (low + high) / 2\n    # Direct int casting would cause numerical errors due to discarding the significand figures (digits after the dot)\n    # The round function could return unexpected results, so we add the floating point with some small number\n    # This addition would solve the issues caused by the division operation and how Python stores float numbers.\n    # E.g. round(13/2) = 6 (expected to see 7)\n    mid = int(round(mid + tol))\n\n    # Search for the span\n    while (knot < knot_vector[mid]) or (knot >= knot_vector[mid + 1]):\n        if knot < knot_vector[mid]:\n            high = mid\n        else:\n            low = mid\n        mid = int((low + high) / 2)\n\n    return mid"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the span of a single knot over the knot vector using linear search. Alternative implementation for the Algorithm A2.1 from The NURBS Book by Piegl & Tiller. :param degree: degree, :math:`p` :type degree: int :param knot_vector: knot vector, :math:`U` :type knot_vector: list, tuple :param num_ctrlpts: number of control points, :math:`n + 1` :type num_ctrlpts: int :param knot: knot or parameter, :math:`u` :type knot: float :return: knot span :rtype: int", "response": "def find_span_linear(degree, knot_vector, num_ctrlpts, knot, **kwargs):\n    \"\"\" Finds the span of a single knot over the knot vector using linear search.\n\n    Alternative implementation for the Algorithm A2.1 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param num_ctrlpts: number of control points, :math:`n + 1`\n    :type num_ctrlpts: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :return: knot span\n    :rtype: int\n    \"\"\"\n    span = 0  # Knot span index starts from zero\n    while span < num_ctrlpts and knot_vector[span] <= knot:\n        span += 1\n\n    return span - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds spans of a list of knots over the knot vector.", "response": "def find_spans(degree, knot_vector, num_ctrlpts, knots, func=find_span_linear):\n    \"\"\" Finds spans of a list of knots over the knot vector.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param num_ctrlpts: number of control points, :math:`n + 1`\n    :type num_ctrlpts: int\n    :param knots: list of knots or parameters\n    :type knots: list, tuple\n    :param func: function for span finding, e.g. linear or binary search\n    :return: list of spans\n    :rtype: list\n    \"\"\"\n    spans = []\n    for knot in knots:\n        spans.append(func(degree, knot_vector, num_ctrlpts, knot))\n    return spans"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_multiplicity(knot, knot_vector, **kwargs):\n    # Get tolerance value\n    tol = kwargs.get('tol', 10e-8)\n\n    mult = 0  # initial multiplicity\n\n    for kv in knot_vector:\n        if abs(knot - kv) <= tol:\n            mult += 1\n\n    return mult", "response": "Finds the knot multiplicity over the knot vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the non - vanishing basis functions for a single parameter.", "response": "def basis_function(degree, knot_vector, span, knot):\n    \"\"\" Computes the non-vanishing basis functions for a single parameter.\n\n    Implementation of Algorithm A2.2 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param span: knot span, :math:`i`\n    :type span: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :return: basis functions\n    :rtype: list\n    \"\"\"\n    left = [0.0 for _ in range(degree + 1)]\n    right = [0.0 for _ in range(degree + 1)]\n    N = [1.0 for _ in range(degree + 1)]  # N[0] = 1.0 by definition\n\n    for j in range(1, degree + 1):\n        left[j] = knot - knot_vector[span + 1 - j]\n        right[j] = knot_vector[span + j] - knot\n        saved = 0.0\n        for r in range(0, j):\n            temp = N[r] / (right[r + 1] + left[j - r])\n            N[r] = saved + right[r + 1] * temp\n            saved = left[j - r] * temp\n        N[j] = saved\n\n    return N"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the non - vanishing basis functions for a list of parameters.", "response": "def basis_functions(degree, knot_vector, spans, knots):\n    \"\"\" Computes the non-vanishing basis functions for a list of parameters.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param spans: list of knot spans\n    :type spans:  list, tuple\n    :param knots: list of knots or parameters\n    :type knots: list, tuple\n    :return: basis functions\n    :rtype: list\n    \"\"\"\n    basis = []\n    for span, knot in zip(spans, knots):\n        basis.append(basis_function(degree, knot_vector, span, knot))\n    return basis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing all non - zero basis functions of all degrees from 0 up to the input degree.", "response": "def basis_function_all(degree, knot_vector, span, knot):\n    \"\"\" Computes all non-zero basis functions of all degrees from 0 up to the input degree for a single parameter.\n\n    A slightly modified version of Algorithm A2.2 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector:  knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param span: knot span, :math:`i`\n    :type span: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :return: basis functions\n    :rtype: list\n    \"\"\"\n    N = [[None for _ in range(degree + 1)] for _ in range(degree + 1)]\n    for i in range(0, degree + 1):\n        bfuns = basis_function(i, knot_vector, span, knot)\n        for j in range(0, i + 1):\n            N[j][i] = bfuns[j]\n    return N"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the derivative of the basis functions for a single parameter.", "response": "def basis_function_ders(degree, knot_vector, span, knot, order):\n    \"\"\" Computes derivatives of the basis functions for a single parameter.\n\n    Implementation of Algorithm A2.3 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param span: knot span, :math:`i`\n    :type span: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :param order: order of the derivative\n    :type order: int\n    :return: derivatives of the basis functions\n    :rtype: list\n    \"\"\"\n    # Initialize variables\n    left = [1.0 for _ in range(degree + 1)]\n    right = [1.0 for _ in range(degree + 1)]\n    ndu = [[1.0 for _ in range(degree + 1)] for _ in range(degree + 1)]  # N[0][0] = 1.0 by definition\n\n    for j in range(1, degree + 1):\n        left[j] = knot - knot_vector[span + 1 - j]\n        right[j] = knot_vector[span + j] - knot\n        saved = 0.0\n        r = 0\n        for r in range(r, j):\n            # Lower triangle\n            ndu[j][r] = right[r + 1] + left[j - r]\n            temp = ndu[r][j - 1] / ndu[j][r]\n            # Upper triangle\n            ndu[r][j] = saved + (right[r + 1] * temp)\n            saved = left[j - r] * temp\n        ndu[j][j] = saved\n\n    # Load the basis functions\n    ders = [[0.0 for _ in range(degree + 1)] for _ in range((min(degree, order) + 1))]\n    for j in range(0, degree + 1):\n        ders[0][j] = ndu[j][degree]\n\n    # Start calculating derivatives\n    a = [[1.0 for _ in range(degree + 1)] for _ in range(2)]\n    # Loop over function index\n    for r in range(0, degree + 1):\n        # Alternate rows in array a\n        s1 = 0\n        s2 = 1\n        a[0][0] = 1.0\n        # Loop to compute k-th derivative\n        for k in range(1, order + 1):\n            d = 0.0\n            rk = r - k\n            pk = degree - k\n            if r >= k:\n                a[s2][0] = a[s1][0] / ndu[pk + 1][rk]\n                d = a[s2][0] * ndu[rk][pk]\n            if rk >= -1:\n                j1 = 1\n            else:\n                j1 = -rk\n            if (r - 1) <= pk:\n                j2 = k - 1\n            else:\n                j2 = degree - r\n            for j in range(j1, j2 + 1):\n                a[s2][j] = (a[s1][j] - a[s1][j - 1]) / ndu[pk + 1][rk + j]\n                d += (a[s2][j] * ndu[rk + j][pk])\n            if r <= pk:\n                a[s2][k] = -a[s1][k - 1] / ndu[pk + 1][r]\n                d += (a[s2][k] * ndu[r][pk])\n            ders[k][r] = d\n\n            # Switch rows\n            j = s1\n            s1 = s2\n            s2 = j\n\n    # Multiply through by the the correct factors\n    r = float(degree)\n    for k in range(1, order + 1):\n        for j in range(0, degree + 1):\n            ders[k][j] *= r\n        r *= (degree - k)\n\n    # Return the basis function derivatives list\n    return ders"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the derivatives of the basis functions for a list of parameters.", "response": "def basis_functions_ders(degree, knot_vector, spans, knots, order):\n    \"\"\" Computes derivatives of the basis functions for a list of parameters.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param spans: list of knot spans\n    :type spans:  list, tuple\n    :param knots: list of knots or parameters\n    :type knots: list, tuple\n    :param order: order of the derivative\n    :type order: int\n    :return: derivatives of the basis functions\n    :rtype: list\n    \"\"\"\n    basis_ders = []\n    for span, knot in zip(spans, knots):\n        basis_ders.append(basis_function_ders(degree, knot_vector, span, knot, order))\n    return basis_ders"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the value of a single parameter in a non - zero basis function.", "response": "def basis_function_one(degree, knot_vector, span, knot):\n    \"\"\" Computes the value of a basis function for a single parameter.\n\n    Implementation of Algorithm 2.4 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot vector\n    :type knot_vector: list, tuple\n    :param span: knot span, :math:`i`\n    :type span: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :return: basis function, :math:`N_{i,p}`\n    :rtype: float\n    \"\"\"\n    # Special case at boundaries\n    if (span == 0 and knot == knot_vector[0]) or \\\n            (span == len(knot_vector) - degree - 2) and knot == knot_vector[len(knot_vector) - 1]:\n        return 1.0\n\n    # Knot is outside of span range\n    if knot < knot_vector[span] or knot >= knot_vector[span + degree + 1]:\n        return 0.0\n\n    N = [0.0 for _ in range(degree + span + 1)]\n\n    # Initialize the zeroth degree basis functions\n    for j in range(0, degree + 1):\n        if knot_vector[span + j] <= knot < knot_vector[span + j + 1]:\n            N[j] = 1.0\n\n    # Computing triangular table of basis functions\n    for k in range(1, degree + 1):\n        # Detecting zeros saves computations\n        saved = 0.0\n        if N[0] != 0.0:\n            saved = ((knot - knot_vector[span]) * N[0]) / (knot_vector[span + k] - knot_vector[span])\n\n        for j in range(0, degree - k + 1):\n            Uleft = knot_vector[span + j + 1]\n            Uright = knot_vector[span + j + k + 1]\n\n            # Zero detection\n            if N[j + 1] == 0.0:\n                N[j] = saved\n                saved = 0.0\n            else:\n                temp = N[j + 1] / (Uright - Uleft)\n                N[j] = saved + (Uright - knot) * temp\n                saved = (knot - Uleft) * temp\n\n    return N[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the derivative of one basis function for a single parameter.", "response": "def basis_function_ders_one(degree, knot_vector, span, knot, order):\n    \"\"\" Computes the derivative of one basis functions for a single parameter.\n\n    Implementation of Algorithm A2.5 from The NURBS Book by Piegl & Tiller.\n\n    :param degree: degree, :math:`p`\n    :type degree: int\n    :param knot_vector: knot_vector, :math:`U`\n    :type knot_vector: list, tuple\n    :param span: knot span, :math:`i`\n    :type span: int\n    :param knot: knot or parameter, :math:`u`\n    :type knot: float\n    :param order: order of the derivative\n    :type order: int\n    :return: basis function derivatives\n    :rtype: list\n    \"\"\"\n    ders = [0.0 for _ in range(0, order + 1)]\n\n    # Knot is outside of span range\n    if (knot < knot_vector[span]) or (knot >= knot_vector[span + degree + 1]):\n        for k in range(0, order + 1):\n            ders[k] = 0.0\n\n        return ders\n\n    N = [[0.0 for _ in range(0, degree + 1)] for _ in range(0, degree + 1)]\n\n    # Initializing the zeroth degree basis functions\n    for j in range(0, degree + 1):\n        if knot_vector[span + j] <= knot < knot_vector[span + j + 1]:\n            N[j][0] = 1.0\n\n    # Computing all basis functions values for all degrees inside the span\n    for k in range(1, degree + 1):\n        saved = 0.0\n        # Detecting zeros saves computations\n        if N[0][k - 1] != 0.0:\n            saved = ((knot - knot_vector[span]) * N[0][k - 1]) / (knot_vector[span + k] - knot_vector[span])\n\n        for j in range(0, degree - k + 1):\n            Uleft = knot_vector[span + j + 1]\n            Uright = knot_vector[span + j + k + 1]\n\n            # Zero detection\n            if N[j + 1][k - 1] == 0.0:\n                N[j][k] = saved\n                saved = 0.0\n            else:\n                temp = N[j + 1][k - 1] / (Uright - Uleft)\n                N[j][k] = saved + (Uright - knot) * temp\n                saved = (knot - Uleft) * temp\n\n    # The basis function value is the zeroth derivative\n    ders[0] = N[0][degree]\n\n    # Computing the basis functions derivatives\n    for k in range(1, order + 1):\n        # Buffer for computing the kth derivative\n        ND = [0.0 for _ in range(0, k + 1)]\n\n        # Basis functions values used for the derivative\n        for j in range(0, k + 1):\n            ND[j] = N[j][degree - k]\n\n        # Computing derivatives used for the kth basis function derivative\n\n        # Derivative order for the k-th basis function derivative\n        for jj in range(1, k + 1):\n            if ND[0] == 0.0:\n                saved = 0.0\n            else:\n                saved = ND[0] / (knot_vector[span + degree - k + jj] - knot_vector[span])\n\n            # Index of the Basis function derivatives\n            for j in range(0, k - jj + 1):\n                Uleft = knot_vector[span + j + 1]\n                # Wrong in The NURBS Book: -k is missing.\n                # The right expression is the same as for saved with the added j offset\n                Uright = knot_vector[span + j + degree - k + jj + 1]\n\n                if ND[j + 1] == 0.0:\n                    ND[j] = (degree - k + jj) * saved\n                    saved = 0.0\n                else:\n                    temp = ND[j + 1] / (Uright - Uleft)\n\n                    ND[j] = (degree - k + jj) * (saved - temp)\n                    saved = temp\n\n        ders[k] = ND[0]\n\n    return ders"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef knot_insertion(degree, knotvector, ctrlpts, u, **kwargs):\n    # Get keyword arguments\n    num = kwargs.get('num', 1)  # number of knot insertions\n    s = kwargs.get('s', find_multiplicity(u, knotvector))  # multiplicity\n    k = kwargs.get('span', find_span_linear(degree, knotvector, len(ctrlpts), u))  # knot span\n\n    # Initialize variables\n    np = len(ctrlpts)\n    nq = np + num\n\n    # Initialize new control points array (control points may be weighted or not)\n    ctrlpts_new = [[] for _ in range(nq)]\n\n    # Initialize a local array of length p + 1\n    temp = [[] for _ in range(degree + 1)]\n\n    # Save unaltered control points\n    for i in range(0, k - degree + 1):\n        ctrlpts_new[i] = ctrlpts[i]\n    for i in range(k - s, np):\n        ctrlpts_new[i + num] = ctrlpts[i]\n\n    # Start filling the temporary local array which will be used to update control points during knot insertion\n    for i in range(0, degree - s + 1):\n        temp[i] = deepcopy(ctrlpts[k - degree + i])\n\n    # Insert knot \"num\" times\n    for j in range(1, num + 1):\n        L = k - degree + j\n        for i in range(0, degree - j - s + 1):\n            alpha = knot_insertion_alpha(u, tuple(knotvector), k, i, L)\n            if isinstance(temp[i][0], float):\n                temp[i][:] = [alpha * elem2 + (1.0 - alpha) * elem1 for elem1, elem2 in zip(temp[i], temp[i + 1])]\n            else:\n                for idx in range(len(temp[i])):\n                    temp[i][idx][:] = [alpha * elem2 + (1.0 - alpha) * elem1 for elem1, elem2 in\n                                       zip(temp[i][idx], temp[i + 1][idx])]\n        ctrlpts_new[L] = deepcopy(temp[0])\n        ctrlpts_new[k + num - j - s] = deepcopy(temp[degree - j - s])\n\n    # Load remaining control points\n    L = k - degree + num\n    for i in range(L + 1, k - s):\n        ctrlpts_new[i] = deepcopy(temp[i - L])\n\n    # Return control points after knot insertion\n    return ctrlpts_new", "response": "Computes the control points after a knot insertion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef knot_insertion_alpha(u, knotvector, span, idx, leg):\n    return (u - knotvector[leg + idx]) / (knotvector[idx + span + 1] - knotvector[leg + idx])", "response": "Computes the alpha coefficient for knot insertion algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef knot_insertion_kv(knotvector, u, span, r):\n    # Initialize variables\n    kv_size = len(knotvector)\n    kv_updated = [0.0 for _ in range(kv_size + r)]\n\n    # Compute new knot vector\n    for i in range(0, span + 1):\n        kv_updated[i] = knotvector[i]\n    for i in range(1, r + 1):\n        kv_updated[span + i] = u\n    for i in range(span + 1, kv_size):\n        kv_updated[i + r] = knotvector[i]\n\n    # Return the new knot vector\n    return kv_updated", "response": "Computes the knot vector after knot insertion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the control points of the rational or non - rational spline after a knot removal.", "response": "def knot_removal(degree, knotvector, ctrlpts, u, **kwargs):\n    \"\"\" Computes the control points of the rational/non-rational spline after knot removal.\n\n    Implementation based on Algorithm A5.8 and Equation 5.28 of The NURBS Book by Piegl & Tiller\n\n    Keyword Arguments:\n        * ``num``: number of knot removals\n\n    :param degree: degree\n    :type degree: int\n    :param knotvector: knot vector\n    :type knotvector: list, tuple\n    :param ctrlpts: control points\n    :type ctrlpts: list\n    :param u: knot to be removed\n    :type u: float\n    :return: updated control points\n    :rtype: list\n    \"\"\"\n    tol = kwargs.get('tol', 10e-4)  # Refer to Eq 5.30 for the meaning\n    num = kwargs.get('num', 1)  # number of same knot removals\n    s = kwargs.get('s', find_multiplicity(u, knotvector))  # multiplicity\n    r = kwargs.get('span', find_span_linear(degree, knotvector, len(ctrlpts), u))  # knot span\n\n    # Edge case\n    if num < 1:\n        return ctrlpts\n\n    # Initialize variables\n    first = r - degree\n    last = r - s\n\n    # Don't change input variables, prepare new ones for updating\n    ctrlpts_new = deepcopy(ctrlpts)\n\n    is_volume = True\n    if isinstance(ctrlpts_new[0][0], float):\n        is_volume = False\n\n    # Initialize temp array for storing new control points\n    if is_volume:\n        temp = [[[] for _ in range(len(ctrlpts_new[0]))] for _ in range((2 * degree) + 1)]\n    else:\n        temp = [[] for _ in range((2 * degree) + 1)]\n\n    # Loop for Eqs 5.28 & 5.29\n    for t in range(0, num):\n        temp[0] = ctrlpts[first - 1]\n        temp[last - first + 2] = ctrlpts[last + 1]\n        i = first\n        j = last\n        ii = 1\n        jj = last - first + 1\n        remflag = False\n\n        # Compute control points for one removal step\n        while j - i >= t:\n            alpha_i = knot_removal_alpha_i(u, degree, tuple(knotvector), t, i)\n            alpha_j = knot_removal_alpha_j(u, degree, tuple(knotvector), t, j)\n            if is_volume:\n                for idx in range(len(ctrlpts[0])):\n                    temp[ii][idx] = [(cpt - (1.0 - alpha_i) * ti) / alpha_i for cpt, ti\n                                     in zip(ctrlpts[i][idx], temp[ii - 1][idx])]\n                    temp[jj][idx] = [(cpt - alpha_j * tj) / (1.0 - alpha_j) for cpt, tj\n                                     in zip(ctrlpts[j][idx], temp[jj + 1][idx])]\n            else:\n                temp[ii] = [(cpt - (1.0 - alpha_i) * ti) / alpha_i for cpt, ti in zip(ctrlpts[i], temp[ii - 1])]\n                temp[jj] = [(cpt - alpha_j * tj) / (1.0 - alpha_j) for cpt, tj in zip(ctrlpts[j], temp[jj + 1])]\n            i += 1\n            j -= 1\n            ii += 1\n            jj -= 1\n\n        # Check if the knot is removable\n        if j - i < t:\n            if is_volume:\n                if linalg.point_distance(temp[ii - 1][0], temp[jj + 1][0]) <= tol:\n                    remflag = True\n            else:\n                if linalg.point_distance(temp[ii - 1], temp[jj + 1]) <= tol:\n                    remflag = True\n        else:\n            alpha_i = knot_removal_alpha_i(u, degree, tuple(knotvector), t, i)\n            if is_volume:\n                ptn = [(alpha_i * t1) + ((1.0 - alpha_i) * t2) for t1, t2 in zip(temp[ii + t + 1][0], temp[ii - 1][0])]\n            else:\n                ptn = [(alpha_i * t1) + ((1.0 - alpha_i) * t2) for t1, t2 in zip(temp[ii + t + 1], temp[ii - 1])]\n            if linalg.point_distance(ctrlpts[i], ptn) <= tol:\n                remflag = True\n\n        # Check if we can remove the knot and update new control points array\n        if remflag:\n            i = first\n            j = last\n            while j - i > t:\n                ctrlpts_new[i] = temp[i - first + 1]\n                ctrlpts_new[j] = temp[j - first + 1]\n                i += 1\n                j -= 1\n\n        # Update indices\n        first -= 1\n        last += 1\n\n    # Fix indexing\n    t += 1\n\n    # Shift control points (refer to p.183 of The NURBS Book, 2nd Edition)\n    j = int((2*r - s - degree) / 2)  # first control point out\n    i = j\n    for k in range(1, t):\n        if k % 2 == 1:\n            i += 1\n        else:\n            j -= 1\n    for k in range(i+1, len(ctrlpts)):\n        ctrlpts_new[j] = ctrlpts[k]\n        j += 1\n\n    # Slice to get the new control points\n    ctrlpts_new = ctrlpts_new[0:-t]\n\n    return ctrlpts_new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the alpha coefficient for knot removal algorithm.", "response": "def knot_removal_alpha_i(u, degree, knotvector, num, idx):\n    \"\"\" Computes :math:`\\\\alpha_{i}` coefficient for knot removal algorithm.\n\n    Please refer to Eq. 5.29 of The NURBS Book by Piegl & Tiller, 2nd Edition, p.184 for details.\n\n    :param u: knot\n    :type u: float\n    :param degree: degree\n    :type degree: int\n    :param knotvector: knot vector\n    :type knotvector: tuple\n    :param num: knot removal index\n    :type num: int\n    :param idx: iterator index\n    :type idx: int\n    :return: coefficient value\n    :rtype: float\n    \"\"\"\n    return (u - knotvector[idx]) / (knotvector[idx + degree + 1 + num] - knotvector[idx])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef knot_removal_alpha_j(u, degree, knotvector, num, idx):\n    return (u - knotvector[idx - num]) / (knotvector[idx + degree + 1] - knotvector[idx - num])", "response": "Computes the alpha_j coefficient for knot removal algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the knot vector after a knot removal.", "response": "def knot_removal_kv(knotvector, span, r):\n    \"\"\" Computes the knot vector of the rational/non-rational spline after knot removal.\n\n    Part of Algorithm A5.8 of The NURBS Book by Piegl & Tiller, 2nd Edition.\n\n    :param knotvector: knot vector\n    :type knotvector: list, tuple\n    :param span: knot span\n    :type span: int\n    :param r: number of knot removals\n    :type r: int\n    :return: updated knot vector\n    :rtype: list\n    \"\"\"\n    # Edge case\n    if r < 1:\n        return knotvector\n\n    # Create a deep copy of the input knot  vector\n    kv_updated = deepcopy(knotvector)\n\n    # Shift knots\n    for k in range(span + 1, len(knotvector)):\n        kv_updated[k - r] = knotvector[k]\n\n    # Slice to get the new knot vector\n    kv_updated = kv_updated[0:-r]\n\n    # Return the new knot vector\n    return kv_updated"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the knot vector and the control points of the rational/non-rational spline after knot refinement. Implementation of Algorithm A5.4 of The NURBS Book by Piegl & Tiller, 2nd Edition. The algorithm automatically find the knots to be refined, i.e. the middle knots in the knot vector, and their multiplicities, i.e. number of same knots in the knot vector. This is the basis of knot refinement algorithm. This operation can be overridden by providing a list of knots via ``knot_list`` argument. In addition, users can provide a list of additional knots to be inserted in the knot vector via ``add_knot_list`` argument. Moreover, a numerical ``density`` argument can be used to automate extra knot insertions. If ``density`` is bigger than 1, then the algorithm finds the middle knots in each internal knot span to increase the number of knots to be refined. **Example**: Let the knot vector to be refined is ``[0, 2, 4]`` with the superfluous knots from the start and end are removed: * If ``density`` is 1, knot vector to be refined is ``[0, 2, 4]`` * If ``density`` is 2, knot vector to be refined is ``[0, 1, 2, 3, 4]`` * If ``density`` is 3, knot vector to be refined is ``[0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4]`` Keyword Arguments: * ``knot_list``: knot list to be refined. *Default: list of internal knots* * ``add_knot_list``: additional list of knots to be refined. *Default: []* * ``density``: Density of the knots. *Default: 1* :param degree: degree :type degree: int :param knotvector: knot vector :type knotvector: list, tuple :param ctrlpts: control points :return: updated control points and knot vector :rtype: tuple", "response": "def knot_refinement(degree, knotvector, ctrlpts, **kwargs):\n    \"\"\" Computes the knot vector and the control points of the rational/non-rational spline after knot refinement.\n\n    Implementation of Algorithm A5.4 of The NURBS Book by Piegl & Tiller, 2nd Edition.\n\n    The algorithm automatically find the knots to be refined, i.e. the middle knots in the knot vector, and their\n    multiplicities, i.e. number of same knots in the knot vector. This is the basis of knot refinement algorithm.\n    This operation can be overridden by providing a list of knots via ``knot_list`` argument. In addition, users can\n    provide a list of additional knots to be inserted in the knot vector via ``add_knot_list`` argument.\n\n    Moreover, a numerical ``density`` argument can be used to automate extra knot insertions. If ``density`` is bigger\n    than 1, then the algorithm finds the middle knots in each internal knot span to increase the number of knots to be\n    refined.\n\n    **Example**: Let the knot vector to be refined is ``[0, 2, 4]`` with the superfluous knots from the start and end\n    are removed:\n\n    * If ``density`` is 1, knot vector to be refined is ``[0, 2, 4]``\n    * If ``density`` is 2, knot vector to be refined is ``[0, 1, 2, 3, 4]``\n    * If ``density`` is 3, knot vector to be refined is ``[0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4]``\n\n    Keyword Arguments:\n        * ``knot_list``: knot list to be refined. *Default: list of internal knots*\n        * ``add_knot_list``: additional list of knots to be refined. *Default: []*\n        * ``density``: Density of the knots. *Default: 1*\n\n    :param degree: degree\n    :type degree: int\n    :param knotvector: knot vector\n    :type knotvector: list, tuple\n    :param ctrlpts: control points\n    :return: updated control points and knot vector\n    :rtype: tuple\n    \"\"\"\n    # Get keyword arguments\n    tol = kwargs.get('tol', 10e-8)  # tolerance value for zero equality checking\n    check_num = kwargs.get('check_num', True)  # enables/disables input validity checking\n    knot_list = kwargs.get('knot_list', knotvector[degree:-degree])\n    add_knot_list = kwargs.get('add_knot_list', list())\n    density = kwargs.get('density', 1)\n\n    # Input validity checking\n    if check_num:\n        if not isinstance(density, int):\n            raise GeomdlException(\"Density value must be an integer\", data=dict(density=density))\n\n        if density < 1:\n            raise GeomdlException(\"Density value cannot be less than 1\", data=dict(density=density))\n\n    # Add additional knots to be refined\n    if add_knot_list:\n        knot_list += list(add_knot_list)\n\n    # Sort the list and convert to a set to make sure that the values are unique\n    knot_list = sorted(set(knot_list))\n\n    # Increase knot density\n    for d in range(0, density - 1):\n        rknots = []\n        for i in range(len(knot_list) - 1):\n            knot_tmp = knot_list[i] + ((knot_list[i + 1] - knot_list[i]) / 2.0)\n            rknots.append(knot_list[i])\n            rknots.append(knot_tmp)\n        rknots.append(knot_list[i + 1])\n        knot_list = rknots\n\n    # Find how many knot insertions are necessary\n    X = []\n    for mk in knot_list:\n        s = find_multiplicity(mk, knotvector)\n        r = degree - s\n        X += [mk for _ in range(r)]\n\n    # Check if the knot refinement is possible\n    if not X:\n        raise GeomdlException(\"Cannot refine knot vector on this parametric dimension\")\n\n    # Initialize common variables\n    r = len(X) - 1\n    n = len(ctrlpts) - 1\n    m = n + degree + 1\n    a = find_span_linear(degree, knotvector, n, X[0])\n    b = find_span_linear(degree, knotvector, n, X[r]) + 1\n\n    # Initialize new control points array\n    if isinstance(ctrlpts[0][0], float):\n        new_ctrlpts = [[] for _ in range(n + r + 2)]\n    else:\n        new_ctrlpts = [[[] for _ in range(len(ctrlpts[0]))] for _ in range(n + r + 2)]\n\n    # Fill unchanged control points\n    for j in range(0, a - degree + 1):\n        new_ctrlpts[j] = ctrlpts[j]\n    for j in range(b - 1, n + 1):\n        new_ctrlpts[j + r + 1] = ctrlpts[j]\n\n    # Initialize new knot vector array\n    new_kv = [0.0 for _ in range(m + r + 2)]\n\n    # Fill unchanged knots\n    for j in range(0, a + 1):\n        new_kv[j] = knotvector[j]\n    for j in range(b + degree, m + 1):\n        new_kv[j + r + 1] = knotvector[j]\n\n    # Initialize variables for knot refinement\n    i = b + degree - 1\n    k = b + degree + r\n    j = r\n\n    # Apply knot refinement\n    while j >= 0:\n        while X[j] <= knotvector[i] and i > a:\n            new_ctrlpts[k - degree - 1] = ctrlpts[i - degree - 1]\n            new_kv[k] = knotvector[i]\n            k -= 1\n            i -= 1\n        new_ctrlpts[k - degree - 1] = deepcopy(new_ctrlpts[k - degree])\n        for l in range(1, degree + 1):\n            idx = k - degree + l\n            alpha = new_kv[k + l] - X[j]\n            if abs(alpha) < tol:\n                new_ctrlpts[idx - 1] = deepcopy(new_ctrlpts[idx])\n            else:\n                alpha = alpha / (new_kv[k + l] - knotvector[i - degree + l])\n                if isinstance(ctrlpts[0][0], float):\n                    new_ctrlpts[idx - 1] = [alpha * p1 + (1.0 - alpha) * p2 for p1, p2 in\n                                            zip(new_ctrlpts[idx - 1], new_ctrlpts[idx])]\n                else:\n                    for idx2 in range(len(ctrlpts[0])):\n                        new_ctrlpts[idx - 1][idx2] = [alpha * p1 + (1.0 - alpha) * p2 for p1, p2 in\n                                                      zip(new_ctrlpts[idx - 1][idx2], new_ctrlpts[idx][idx2])]\n        new_kv[k] = X[j]\n        k = k - 1\n        j -= 1\n\n    # Return control points and knot vector after refinement\n    return new_ctrlpts, new_kv"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the control points of the rational or non - rational spline after degree elevation.", "response": "def degree_elevation(degree, ctrlpts, **kwargs):\n    \"\"\" Computes the control points of the rational/non-rational spline after degree elevation.\n\n    Implementation of Eq. 5.36 of The NURBS Book by Piegl & Tiller, 2nd Edition, p.205\n\n    Keyword Arguments:\n        * ``num``: number of degree elevations\n\n    Please note that degree elevation algorithm can only operate on Bezier shapes, i.e. curves, surfaces, volumes.\n\n    :param degree: degree\n    :type degree: int\n    :param ctrlpts: control points\n    :type ctrlpts: list, tuple\n    :return: control points of the degree-elevated shape\n    :rtype: list\n    \"\"\"\n    # Get keyword arguments\n    num = kwargs.get('num', 1)  # number of degree elevations\n    check_op = kwargs.get('check_num', True)  # enable/disable input validation checks\n\n    if check_op:\n        if degree + 1 != len(ctrlpts):\n            raise GeomdlException(\"Degree elevation can only work with Bezier-type geometries\")\n        if num <= 0:\n            raise GeomdlException(\"Cannot degree elevate \" + str(num) + \" times\")\n\n    # Initialize variables\n    num_pts_elev = degree + 1 + num\n    pts_elev = [[0.0 for _ in range(len(ctrlpts[0]))] for _ in range(num_pts_elev)]\n\n    # Compute control points of degree-elevated 1-dimensional shape\n    for i in range(0, num_pts_elev):\n        start = max(0, (i - num))\n        end = min(degree, i)\n        for j in range(start, end + 1):\n            coeff = linalg.binomial_coefficient(degree, j) * linalg.binomial_coefficient(num, (i - j))\n            coeff /= linalg.binomial_coefficient((degree + num), i)\n            pts_elev[i] = [p1 + (coeff * p2) for p1, p2 in zip(pts_elev[i], ctrlpts[j])]\n\n    # Return computed control points after degree elevation\n    return pts_elev"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef degree_reduction(degree, ctrlpts, **kwargs):\n    # Get keyword arguments\n    check_op = kwargs.get('check_num', True)  # enable/disable input validation checks\n\n    if check_op:\n        if degree + 1 != len(ctrlpts):\n            raise GeomdlException(\"Degree reduction can only work with Bezier-type geometries\")\n        if degree < 2:\n            raise GeomdlException(\"Input spline geometry must have degree > 1\")\n\n    # Initialize variables\n    pts_red = [[0.0 for _ in range(len(ctrlpts[0]))] for _ in range(degree)]\n\n    # Fix start and end control points\n    pts_red[0] = ctrlpts[0]\n    pts_red[-1] = ctrlpts[-1]\n\n    # Find if the degree is an even or an odd number\n    p_is_odd = True if degree % 2 != 0 else False\n\n    # Compute control points of degree-reduced 1-dimensional shape\n    r = int((degree - 1) / 2)\n    # Handle a special case when degree = 2\n    if degree == 2:\n        r1 = r - 2\n    else:\n        # Determine r1 w.r.t. degree evenness\n        r1 = r - 1 if p_is_odd else r\n    for i in range(1, r1 + 1):\n        alpha = float(i) / float(degree)\n        pts_red[i] = [(c1 - (alpha * c2)) / (1 - alpha) for c1, c2 in zip(ctrlpts[i], pts_red[i - 1])]\n    for i in range(degree - 2, r1 + 2):\n        alpha = float(i + 1) / float(degree)\n        pts_red[i] = [(c1 - ((1 - alpha) * c2)) / alpha for c1, c2 in zip(ctrlpts[i + 1], pts_red[i + 1])]\n\n    if p_is_odd:\n        alpha = float(r) / float(degree)\n        left = [(c1 - (alpha * c2)) / (1 - alpha) for c1, c2 in zip(ctrlpts[r], pts_red[r - 1])]\n        alpha = float(r + 1) / float(degree)\n        right = [(c1 - ((1 - alpha) * c2)) / alpha for c1, c2 in zip(ctrlpts[r + 1], pts_red[r + 1])]\n        pts_red[r] = [0.5 * (pl + pr) for pl, pr in zip(left, right)]\n\n    # Return computed control points after degree reduction\n    return pts_red", "response": "Computes the control points of the degree - reduced spline."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the control points of all derivative curves up to and including the degree - th derivative.", "response": "def derivatives_ctrlpts(**kwargs):\n        \"\"\" Computes the control points of all derivative curves up to and including the {degree}-th derivative.\n\n        Implementation of Algorithm A3.3 from The NURBS Book by Piegl & Tiller.\n\n        Output is PK[k][i], i-th control point of the k-th derivative curve where 0 <= k <= degree and r1 <= i <= r2-k.\n        \"\"\"\n        # r1 - minimum span, r2 - maximum span\n        r1 = kwargs.get('r1')\n        r2 = kwargs.get('r2')\n        deriv_order = kwargs.get('deriv_order')\n        degree = kwargs.get('degree')\n        knotvector = kwargs.get('knotvector')\n        ctrlpts = kwargs.get('ctrlpts')\n        dimension = kwargs.get('dimension')\n\n        # Algorithm A3.3\n        r = r2 - r1\n        PK = [[[None for _ in range(dimension)] for _ in range(r + 1)] for _ in range(deriv_order + 1)]\n        for i in range(0, r + 1):\n            PK[0][i][:] = [elem for elem in ctrlpts[r1 + i]]\n\n        for k in range(1, deriv_order + 1):\n            tmp = degree - k + 1\n            for i in range(0, r - k + 1):\n                PK[k][i][:] = [tmp * (elem1 - elem2) /\n                               (knotvector[r1 + i + degree + 1] - knotvector[r1 + i + k]) for elem1, elem2\n                               in zip(PK[k - 1][i + 1], PK[k - 1][i])]\n\n        # Return a 2-dimensional list of control points\n        return PK"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates the derivatives at the input parameter.", "response": "def derivatives(self, **kwargs):\n        \"\"\" Evaluates the derivatives at the input parameter. \"\"\"\n        # Call parent method\n        super(CurveEvaluator2, self).derivatives(**kwargs)\n\n        param = kwargs.get('parameter')\n        deriv_order = kwargs.get('deriv_order', 0)\n        degree = kwargs.get('degree')\n        knotvector = kwargs.get('knotvector')\n        ctrlpts = kwargs.get('ctrlpts')\n        dimension = kwargs.get('dimension')\n\n        # Algorithm A3.4\n        du = min(degree, deriv_order)\n\n        CK = [[0.0 for _ in range(dimension)] for _ in range(deriv_order + 1)]\n\n        span = self._span_func(degree, knotvector, len(ctrlpts), param)\n        bfuns = helpers.basis_function_all(degree, tuple(knotvector), span, param)\n\n        # \"derivatives_ctrlpts\" is a static method that could be called like below\n        PK = CurveEvaluator2.derivatives_ctrlpts(r1=(span - degree), r2=span,\n                                                 degree=degree,\n                                                 knotvector=knotvector,\n                                                 ctrlpts=ctrlpts,\n                                                 dimension=dimension,\n                                                 deriv_order=du)\n\n        for k in range(0, du + 1):\n            for j in range(0, degree - k + 1):\n                CK[k][:] = [elem + (bfuns[j][degree - k] * drv_ctl_p) for elem, drv_ctl_p in\n                            zip(CK[k], PK[k][j])]\n\n        # Return the derivatives\n        return CK"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the control points of all derivative surfaces up to and including the degree - th derivative.", "response": "def derivatives_ctrlpts(**kwargs):\n        \"\"\" Computes the control points of all derivative surfaces up to and including the {degree}-th derivative.\n\n        Output is PKL[k][l][i][j], i,j-th control point of the surface differentiated k times w.r.t to u and\n        l times w.r.t v.\n        \"\"\"\n        r1 = kwargs.get('r1')  # minimum span on the u-direction\n        r2 = kwargs.get('r2')  # maximum span on the u-direction\n        s1 = kwargs.get('s1')  # minimum span on the v-direction\n        s2 = kwargs.get('s2')  # maximum span on the v-direction\n\n        deriv_order = kwargs.get('deriv_order')\n        ctrlpts_size = kwargs.get('ctrlpts_size')\n        degree = kwargs.get('degree')\n        knotvector = kwargs.get('knotvector')\n        ctrlpts = kwargs.get('ctrlpts')\n        dimension = kwargs.get('dimension')\n\n        PKL = [[[[[None for _ in range(dimension)]\n                  for _ in range(ctrlpts_size[1])] for _ in range(ctrlpts_size[0])]\n                for _ in range(deriv_order + 1)] for _ in range(deriv_order + 1)]\n\n        du = min(degree[0], deriv_order)\n        dv = min(degree[1], deriv_order)\n\n        r = r2 - r1\n        s = s2 - s1\n\n        # Control points of the U derivatives of every U-curve\n        for j in range(s1, s2 + 1):\n            PKu = CurveEvaluator2.derivatives_ctrlpts(r1=r1, r2=r2,\n                                                      degree=degree[0],\n                                                      knotvector=knotvector[0],\n                                                      ctrlpts=[ctrlpts[j + (ctrlpts_size[1] * i)] for i in range(ctrlpts_size[0])],\n                                                      dimension=dimension,\n                                                      deriv_order=du)\n\n            # Copy into output as the U partial derivatives\n            for k in range(0, du + 1):\n                for i in range(0, r - k + 1):\n                    PKL[k][0][i][j - s1] = PKu[k][i]\n\n        # Control points of the V derivatives of every U-differentiated V-curve\n        for k in range(0, du):\n            for i in range(0, r - k + 1):\n                dd = min(deriv_order - k, dv)\n\n                PKuv = CurveEvaluator2.derivatives_ctrlpts(r1=0, r2=s,\n                                                           degree=degree[1],\n                                                           knotvector=knotvector[1][s1:],\n                                                           ctrlpts=PKL[k][0][i],\n                                                           dimension=dimension,\n                                                           deriv_order=dd)\n\n                # Copy into output\n                for l in range(1, dd + 1):\n                    for j in range(0, s - l + 1):\n                        PKL[k][l][i][j] = PKuv[l][j]\n\n        return PKL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the derivatives at the input parameter.", "response": "def derivatives(self, **kwargs):\n        \"\"\" Evaluates the derivatives at the input parameter. \"\"\"\n        deriv_order = kwargs.get('deriv_order')\n        param = kwargs.get('parameter')\n        degree = kwargs.get('degree')\n        knotvector = kwargs.get('knotvector')\n        ctrlpts_size = kwargs.get('ctrlpts_size')\n        dimension = kwargs.get('dimension')\n\n        SKL = [[[0.0 for _ in range(dimension)] for _ in range(deriv_order + 1)] for _ in range(deriv_order + 1)]\n\n        d = (min(degree[0], deriv_order), min(degree[1], deriv_order))\n\n        span = [0 for _ in range(len(degree))]\n        basis = [[] for _ in range(len(degree))]\n        for idx in range(len(degree)):\n            span[idx] = self._span_func(degree[idx], knotvector[idx], ctrlpts_size[idx], param[idx])\n            basis[idx] = helpers.basis_function_all(degree[idx], knotvector[idx], span[idx], param[idx])\n\n        PKL = self.derivatives_ctrlpts(r1=span[0] - degree[0], r2=span[0],\n                                       s1=span[1] - degree[1], s2=span[1],\n                                       **kwargs)\n\n        # Evaluating the derivative at parameters (u,v) using its control points\n        for k in range(0, d[0] + 1):\n            dd = min(deriv_order - k, d[1])\n\n            for l in range(0, dd + 1):\n                SKL[k][l] = [0.0 for _ in range(dimension)]\n\n                for i in range(0, degree[1] - l + 1):\n                    temp = [0.0 for _ in range(dimension)]\n\n                    for j in range(0, degree[0] - k + 1):\n                        temp[:] = [elem + (basis[0][j][degree[0] - k] * drv_ctl_p) for elem, drv_ctl_p in\n                                   zip(temp, PKL[k][l][j][i])]\n\n                    SKL[k][l][:] = [elem + (basis[1][i][degree[1] - l] * drv_ctl_p) for elem, drv_ctl_p in\n                                    zip(SKL[k][l], temp)]\n\n        return SKL"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets equal aspect ratio across the three axes of a 3D plot.", "response": "def set_axes_equal(ax):\n        \"\"\" Sets equal aspect ratio across the three axes of a 3D plot.\n\n        Contributed by Xuefeng Zhao.\n\n        :param ax: a Matplotlib axis, e.g., as output from plt.gca().\n        \"\"\"\n        bounds = [ax.get_xlim3d(), ax.get_ylim3d(), ax.get_zlim3d()]\n        ranges = [abs(bound[1] - bound[0]) for bound in bounds]\n        centers = [np.mean(bound) for bound in bounds]\n        radius = 0.5 * max(ranges)\n        lower_limits = centers - radius\n        upper_limits = centers + radius\n        ax.set_xlim3d([lower_limits[0], upper_limits[0]])\n        ax.set_ylim3d([lower_limits[1], upper_limits[1]])\n        ax.set_zlim3d([lower_limits[2], upper_limits[2]])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, **kwargs):\n        # Calling parent function\n        super(VisCurve2D, self).render(**kwargs)\n\n        # Initialize variables\n        legend_proxy = []\n        legend_names = []\n\n        # Draw control points polygon and the curve\n        fig = plt.figure(figsize=self.vconf.figure_size, dpi=self.vconf.figure_dpi)\n        ax = fig.gca()\n\n        # Start plotting\n        for plot in self._plots:\n            pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                cpplot, = plt.plot(pts[:, 0], pts[:, 1], color=plot['color'], linestyle='-.', marker='o')\n                legend_proxy.append(cpplot)\n                legend_names.append(plot['name'])\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                curveplt, = plt.plot(pts[:, 0], pts[:, 1], color=plot['color'], linestyle='-', alpha=self.vconf.alpha)\n                legend_proxy.append(curveplt)\n                legend_names.append(plot['name'])\n                # Debugging for curve directions\n                if self.vconf.debug_mode:\n                    plt.quiver(pts[0, 0], pts[0, 1], pts[-1, 0] - pts[0, 0], pts[-1, 1] - pts[0, 1],\n                               color='k', angles='xy', scale_units='xy', scale=1, width=0.003)\n\n            # Plot bounding box\n            if plot['type'] == 'bbox' and self.vconf.display_bbox:\n                bboxplt, = plt.plot(pts[:, 0], pts[:, 1], color=plot['color'], linestyle='--')\n                legend_proxy.append(bboxplt)\n                legend_names.append(plot['name'])\n\n            # Plot extras\n            if plot['type'] == 'extras':\n                extrasplt, = plt.plot(pts[:, 0], pts[:, 1],\n                                      color=plot['color'][0], linestyle='-', linewidth=plot['color'][1])\n                legend_proxy.append(extrasplt)\n                legend_names.append(plot['name'])\n\n        # Add legend\n        if self.vconf.display_legend:\n            plt.legend(legend_proxy, legend_names)\n\n        # Remove axes\n        if not self.vconf.display_axes:\n            plt.axis('off')\n\n        # Set aspect ratio\n        if self.vconf.axes_equal:\n            ax.set_aspect('equal')\n\n        # Axis labels\n        if self.vconf.display_labels:\n            ax.set_xlabel('x')\n            ax.set_ylabel('y')\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Display the plot\n        if fig_display:\n            plt.show()\n        else:\n            fig_filename = self.vconf.figure_image_filename if fig_filename is None else fig_filename\n\n        # Save the figure\n        self.vconf.save_figure_as(fig, fig_filename)", "response": "Plots the 2D curve and the control points polygon and the bounding box and the control points polygon."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef animate(self, **kwargs):\n        # Calling parent render function\n        super(VisSurface, self).render(**kwargs)\n\n        # Colormaps\n        surf_cmaps = kwargs.get('colormap', None)\n\n        # Initialize variables\n        tri_idxs = []\n        vert_coords = []\n        trisurf_params = []\n        frames = []\n        frames_tris = []\n        num_vertices = 0\n\n        # Start plotting of the surface and the control points grid\n        fig = plt.figure(figsize=self.vconf.figure_size, dpi=self.vconf.figure_dpi)\n        ax = Axes3D(fig)\n\n        # Start plotting\n        surf_count = 0\n        for plot in self._plots:\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                # Use internal triangulation algorithm instead of Qhull (MPL default)\n                verts = plot['ptsarr'][0]\n                tris = plot['ptsarr'][1]\n                # Extract zero-indexed vertex number list\n                tri_idxs += [[ti + num_vertices for ti in tri.data] for tri in tris]\n                # Extract vertex coordinates\n                vert_coords += [vert.data for vert in verts]\n                # Update number of vertices\n                num_vertices = len(vert_coords)\n\n                # Determine the color or the colormap of the triangulated plot\n                params = {}\n                if surf_cmaps:\n                    try:\n                        params['cmap'] = surf_cmaps[surf_count]\n                        surf_count += 1\n                    except IndexError:\n                        params['color'] = plot['color']\n                else:\n                    params['color'] = plot['color']\n                trisurf_params += [params for _ in range(len(tris))]\n\n        # Pre-processing for the animation\n        pts = np.array(vert_coords, dtype=self.vconf.dtype)\n\n        # Create the frames (Artists)\n        for tidx, pidx in zip(tri_idxs, trisurf_params):\n            frames_tris.append(tidx)\n            # Create MPL Triangulation object\n            triangulation = mpltri.Triangulation(pts[:, 0], pts[:, 1], triangles=frames_tris)\n            # Use custom Triangulation object and the choice of color/colormap to plot the surface\n            p3df = ax.plot_trisurf(triangulation, pts[:, 2], alpha=self.vconf.alpha, **pidx)\n            # Add to frames list\n            frames.append([p3df])\n\n        # Create MPL ArtistAnimation\n        ani = animation.ArtistAnimation(fig, frames, interval=100, blit=True, repeat_delay=1000)\n\n        # Remove axes\n        if not self.vconf.display_axes:\n            plt.axis('off')\n\n        # Set axes equal\n        if self.vconf.axes_equal:\n            self.vconf.set_axes_equal(ax)\n\n        # Axis labels\n        if self.vconf.display_labels:\n            ax.set_xlabel('x')\n            ax.set_ylabel('y')\n            ax.set_zlabel('z')\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Display the plot\n        if fig_display:\n            plt.show()\n        else:\n            fig_filename = self.vconf.figure_image_filename if fig_filename is None else fig_filename\n\n        # Save the figure\n        self.vconf.save_figure_as(fig, fig_filename)\n\n        # Return the figure object\n        return fig", "response": "Animate the surface and the control points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the surface and the control points grid.", "response": "def render(self, **kwargs):\n        \"\"\" Plots the surface and the control points grid.\n\n        Keyword arguments:\n            * ``colormap``: applies colormap to the surface\n\n        Colormaps are a visualization feature of Matplotlib. They can be used for several types of surface plots via\n        the following import statement: ``from matplotlib import cm``\n\n        The following link displays the list of Matplolib colormaps and some examples on colormaps:\n        https://matplotlib.org/tutorials/colors/colormaps.html\n        \"\"\"\n        # Calling parent function\n        super(VisSurface, self).render(**kwargs)\n\n        # Colormaps\n        surf_cmaps = kwargs.get('colormap', None)\n\n        # Initialize variables\n        legend_proxy = []\n        legend_names = []\n\n        # Start plotting of the surface and the control points grid\n        fig = plt.figure(figsize=self.vconf.figure_size, dpi=self.vconf.figure_dpi)\n        ax = Axes3D(fig)\n\n        surf_count = 0\n        # Start plotting\n        for plot in self._plots:\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                vertices = [v.data for v in plot['ptsarr'][0]]\n                faces = [q.data for q in plot['ptsarr'][1]]\n                for q in faces:\n                    el = np.array([vertices[i] for i in q], dtype=self.vconf.dtype)\n                    el[:, 2] += self._ctrlpts_offset\n                    pc3d = Poly3DCollection([el], alpha=0.0, edgecolors=plot['color'], linewidths=1.0, linestyles='-.')\n                    pc3d.set_facecolor(None)\n                    ax.add_collection3d(pc3d)\n                pts = np.array(vertices, dtype=self.vconf.dtype)\n                pts[:, 2] += self._ctrlpts_offset\n                ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], linestyle='-.', marker='o')\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='-.', color=plot['color'], marker='o')\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                # Use internal triangulation algorithm instead of Qhull (MPL default)\n                verts = plot['ptsarr'][0]\n                tris = plot['ptsarr'][1]\n                # Extract zero-indexed vertex number list\n                tri_idxs = [tri.data for tri in tris]\n                # Extract vertex coordinates\n                vert_coords = [vert.data for vert in verts]\n                pts = np.array(vert_coords, dtype=self.vconf.dtype)\n\n                # Determine the color or the colormap of the triangulated plot\n                trisurf_params = {}\n                if surf_cmaps:\n                    try:\n                        trisurf_params['cmap'] = surf_cmaps[surf_count]\n                        surf_count += 1\n                    except IndexError:\n                        trisurf_params['color'] = plot['color']\n                else:\n                    trisurf_params['color'] = plot['color']\n\n                # Create MPL Triangulation object\n                if pts.size != 0:\n                    triangulation = mpltri.Triangulation(pts[:, 0], pts[:, 1], triangles=tri_idxs)\n                    # Use custom Triangulation object and the choice of color/colormap to plot the surface\n                    ax.plot_trisurf(triangulation, pts[:, 2], alpha=self.vconf.alpha, **trisurf_params)\n                    # Add to legend\n                    plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='^')\n                    legend_proxy.append(plot_proxy)\n                    legend_names.append(plot['name'])\n\n            # Plot bounding box\n            if plot['type'] == 'bbox' and self.vconf.display_bbox:\n                pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], linestyle='--')\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='--', color=plot['color'])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot trim curves\n            if self.vconf.display_trims:\n                if plot['type'] == 'trimcurve':\n                    pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n                    ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], marker='o',\n                               s=self.vconf.trim_size, depthshade=False)\n                    plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='o')\n                    legend_proxy.append(plot_proxy)\n                    legend_names.append(plot['name'])\n\n            # Plot extras\n            if plot['type'] == 'extras':\n                pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2],\n                        color=plot['color'][0], linestyle='-', linewidth=plot['color'][1])\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='-', color=plot['color'][0])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n        # Add legend to 3D plot, @ref: https://stackoverflow.com/a/20505720\n        if self.vconf.display_legend:\n            ax.legend(legend_proxy, legend_names, numpoints=1)\n\n        # Remove axes\n        if not self.vconf.display_axes:\n            plt.axis('off')\n\n        # Set axes equal\n        if self.vconf.axes_equal:\n            self.vconf.set_axes_equal(ax)\n\n        # Axis labels\n        if self.vconf.display_labels:\n            ax.set_xlabel('x')\n            ax.set_ylabel('y')\n            ax.set_zlabel('z')\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Display the plot\n        if fig_display:\n            plt.show()\n        else:\n            fig_filename = self.vconf.figure_image_filename if fig_filename is None else fig_filename\n\n        # Save the figure\n        self.vconf.save_figure_as(fig, fig_filename)\n\n        # Return the figure object\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render(self, **kwargs):\n        # Calling parent function\n        super(VisVolume, self).render(**kwargs)\n\n        # Initialize variables\n        legend_proxy = []\n        legend_names = []\n\n        # Start plotting of the surface and the control points grid\n        fig = plt.figure(figsize=self.vconf.figure_size, dpi=self.vconf.figure_dpi)\n        ax = Axes3D(fig)\n\n        # Start plotting\n        for plot in self._plots:\n            pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], marker='^', s=20, depthshade=True)\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='^')\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2],\n                           color=plot['color'], marker='o', s=10, depthshade=True, alpha=self.vconf.alpha)\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='o')\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot bounding box\n            if plot['type'] == 'bbox' and self.vconf.display_bbox:\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], linestyle='--')\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='--', color=plot['color'])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot extras\n            if plot['type'] == 'extras':\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2],\n                        color=plot['color'][0], linestyle='-', linewidth=plot['color'][1])\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='-', color=plot['color'][0])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n        # Add legend to 3D plot, @ref: https://stackoverflow.com/a/20505720\n        if self.vconf.display_legend:\n            ax.legend(legend_proxy, legend_names, numpoints=1)\n\n        # Remove axes\n        if not self.vconf.display_axes:\n            plt.axis('off')\n\n        # Set axes equal\n        if self.vconf.axes_equal:\n            self.vconf.set_axes_equal(ax)\n\n        # Axis labels\n        if self.vconf.display_labels:\n            ax.set_xlabel('x')\n            ax.set_ylabel('y')\n            ax.set_zlabel('z')\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Display the plot\n        if fig_display:\n            plt.show()\n        else:\n            fig_filename = self.vconf.figure_image_filename if fig_filename is None else fig_filename\n\n        # Save the figure\n        self.vconf.save_figure_as(fig, fig_filename)\n\n        # Return the figure object\n        return fig", "response": "Plots the volume and the control points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self, **kwargs):\n        # Calling parent function\n        super(VisVoxel, self).render(**kwargs)\n\n        # Initialize variables\n        legend_proxy = []\n        legend_names = []\n\n        # Start plotting of the surface and the control points grid\n        fig = plt.figure(figsize=self.vconf.figure_size, dpi=self.vconf.figure_dpi)\n        ax = Axes3D(fig)\n\n        # Start plotting\n        for plot in self._plots:\n            # Plot control points\n            if plot['type'] == 'ctrlpts' and self.vconf.display_ctrlpts:\n                pts = np.array(plot['ptsarr'], dtype=self.vconf.dtype)\n                ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], marker='^', s=20, depthshade=True)\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='^')\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot evaluated points\n            if plot['type'] == 'evalpts' and self.vconf.display_evalpts:\n                faces = np.array(plot['ptsarr'][1], dtype=self.vconf.dtype)\n                filled = np.array(plot['ptsarr'][2], dtype=self.vconf.dtype)\n                # Find filled voxels\n                faces_filled = np.concatenate(faces[filled == 1.0])\n                # Create a single Poly3DCollection object\n                pc3d = Poly3DCollection(faces_filled, facecolors=plot['color'], edgecolors='k')\n                ax.add_collection3d(pc3d)\n                # Set axis limits\n                gf_min = np.amin(faces_filled, axis=(0, 1))\n                gf_max = np.amax(faces_filled, axis=(0, 1))\n                ax.set_xlim([gf_min[0], gf_max[0]])\n                ax.set_ylim([gf_min[1], gf_max[1]])\n                ax.set_zlim([gf_min[2], gf_max[2]])\n                # Legend\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='none', color=plot['color'], marker='o')\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot bounding box\n            if plot['type'] == 'bbox' and self.vconf.display_bbox:\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2], color=plot['color'], linestyle='--')\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='--', color=plot['color'])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n            # Plot extras\n            if plot['type'] == 'extras':\n                ax.plot(pts[:, 0], pts[:, 1], pts[:, 2],\n                        color=plot['color'][0], linestyle='-', linewidth=plot['color'][1])\n                plot_proxy = mpl.lines.Line2D([0], [0], linestyle='-', color=plot['color'][0])\n                legend_proxy.append(plot_proxy)\n                legend_names.append(plot['name'])\n\n        # Add legend to 3D plot, @ref: https://stackoverflow.com/a/20505720\n        if self.vconf.display_legend:\n            ax.legend(legend_proxy, legend_names, numpoints=1)\n\n        # Remove axes\n        if not self.vconf.display_axes:\n            plt.axis('off')\n\n        # Set axes equal\n        if self.vconf.axes_equal:\n            self.vconf.set_axes_equal(ax)\n\n        # Axis labels\n        if self.vconf.display_labels:\n            ax.set_xlabel('x')\n            ax.set_ylabel('y')\n            ax.set_zlabel('z')\n\n        # Process keyword arguments\n        fig_filename = kwargs.get('fig_save_as', None)\n        fig_display = kwargs.get('display_plot', True)\n\n        # Display the plot\n        if fig_display:\n            plt.show()\n        else:\n            fig_filename = self.vconf.figure_image_filename if fig_filename is None else fig_filename\n\n        # Save the figure\n        self.vconf.save_figure_as(fig, fig_filename)\n\n        # Return the figure object\n        return fig", "response": "Displays the voxels and control points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tangent_curve_single_list(obj, param_list, normalize):\n    ret_vector = []\n    for param in param_list:\n        temp = tangent_curve_single(obj, param, normalize)\n        ret_vector.append(temp)\n    return tuple(ret_vector)", "response": "Evaluates the tangent vectors at the given list of parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normal_curve_single(obj, u, normalize):\n    # 2nd derivative of the curve gives the normal\n    ders = obj.derivatives(u, 2)\n\n    point = ders[0]\n    vector = linalg.vector_normalize(ders[2]) if normalize else ders[2]\n\n    return tuple(point), tuple(vector)", "response": "Evaluates the curve normal vector at the input parameter u."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normal_curve_single_list(obj, param_list, normalize):\n    ret_vector = []\n    for param in param_list:\n        temp = normal_curve_single(obj, param, normalize)\n        ret_vector.append(temp)\n    return tuple(ret_vector)", "response": "Evaluates the curve normal vectors at the given list of parameter values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the curve binormal vector at the given u parameter.", "response": "def binormal_curve_single(obj, u, normalize):\n    \"\"\" Evaluates the curve binormal vector at the given u parameter.\n\n    Curve binormal is the cross product of the normal and the tangent vectors.\n    The output returns a list containing the starting point (i.e. origin) of the vector and the vector itself.\n\n    :param obj: input curve\n    :type obj: abstract.Curve\n    :param u: parameter\n    :type u: float\n    :param normalize: if True, the returned vector is converted to a unit vector\n    :type normalize: bool\n    :return: a list containing \"point\" and \"vector\" pairs\n    :rtype: tuple\n    \"\"\"\n    # Cross product of tangent and normal vectors gives binormal vector\n    tan_vector = tangent_curve_single(obj, u, normalize)\n    norm_vector = normal_curve_single(obj, u, normalize)\n\n    point = tan_vector[0]\n    vector = linalg.vector_cross(tan_vector[1], norm_vector[1])\n    vector = linalg.vector_normalize(vector) if normalize else vector\n\n    return tuple(point), tuple(vector)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef binormal_curve_single_list(obj, param_list, normalize):\n    ret_vector = []\n    for param in param_list:\n        temp = binormal_curve_single(obj, param, normalize)\n        ret_vector.append(temp)\n    return tuple(ret_vector)", "response": "Evaluates the curve binormal vectors at the given list of parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tangent_surface_single(obj, uv, normalize):\n    # Tangent is the 1st derivative of the surface\n    skl = obj.derivatives(uv[0], uv[1], 1)\n\n    point = skl[0][0]\n    vector_u = linalg.vector_normalize(skl[1][0]) if normalize else skl[1][0]\n    vector_v = linalg.vector_normalize(skl[0][1]) if normalize else skl[0][1]\n\n    return tuple(point), tuple(vector_u), tuple(vector_v)", "response": "Evaluates the surface tangent vector at the given uv parameter pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the surface tangent vectors at the given list of parameter values.", "response": "def tangent_surface_single_list(obj, param_list, normalize):\n    \"\"\" Evaluates the surface tangent vectors at the given list of parameter values.\n\n    :param obj: input surface\n    :type obj: abstract.Surface\n    :param param_list: parameter list\n    :type param_list: list or tuple\n    :param normalize: if True, the returned vector is converted to a unit vector\n    :type normalize: bool\n    :return: a list containing \"point\" and \"vector\" pairs\n    :rtype: tuple\n    \"\"\"\n    ret_vector = []\n    for param in param_list:\n        temp = tangent_surface_single(obj, param, normalize)\n        ret_vector.append(temp)\n    return tuple(ret_vector)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normal_surface_single(obj, uv, normalize):\n    # Take the 1st derivative of the surface\n    skl = obj.derivatives(uv[0], uv[1], 1)\n\n    point = skl[0][0]\n    vector = linalg.vector_cross(skl[1][0], skl[0][1])\n    vector = linalg.vector_normalize(vector) if normalize else vector\n\n    return tuple(point), tuple(vector)", "response": "Evaluates the surface normal vector at the given uv parameter pair."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating the surface normal vectors at the given list of parameter values.", "response": "def normal_surface_single_list(obj, param_list, normalize):\n    \"\"\" Evaluates the surface normal vectors at the given list of parameter values.\n\n    :param obj: input surface\n    :type obj: abstract.Surface\n    :param param_list: parameter list\n    :type param_list: list or tuple\n    :param normalize: if True, the returned vector is converted to a unit vector\n    :type normalize: bool\n    :return: a list containing \"point\" and \"vector\" pairs\n    :rtype: tuple\n    \"\"\"\n    ret_vector = []\n    for param in param_list:\n        temp = normal_surface_single(obj, param, normalize)\n        ret_vector.append(temp)\n    return tuple(ret_vector)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the control points involved in evaluation of the curve point at the input parameter t.", "response": "def find_ctrlpts_curve(t, curve, **kwargs):\n    \"\"\" Finds the control points involved in the evaluation of the curve point defined by the input parameter.\n\n    This function uses a modified version of the algorithm *A3.1 CurvePoint* from The NURBS Book by Piegl & Tiller.\n\n    :param t: parameter\n    :type t: float\n    :param curve: input curve object\n    :type curve: abstract.Curve\n    :return: 1-dimensional control points array\n    :rtype: list\n    \"\"\"\n    # Get keyword arguments\n    span_func = kwargs.get('find_span_func', helpers.find_span_linear)\n\n    # Find spans and the constant index\n    span = span_func(curve.degree, curve.knotvector, len(curve.ctrlpts), t)\n    idx = span - curve.degree\n\n    # Find control points involved in evaluation of the curve point at the input parameter\n    curve_ctrlpts = [() for _ in range(curve.degree + 1)]\n    for i in range(0, curve.degree + 1):\n        curve_ctrlpts[i] = curve.ctrlpts[idx + i]\n\n    # Return control points array\n    return curve_ctrlpts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the control points involved in the evaluation of the surface point defined by the input parameter pair. This function uses a modified version of the algorithm *A3.5 SurfacePoint* from The NURBS Book by Piegl & Tiller. :param t_u: parameter on the u-direction :type t_u: float :param t_v: parameter on the v-direction :type t_v: float :param surf: input surface :type surf: abstract.Surface :return: 2-dimensional control points array :rtype: list", "response": "def find_ctrlpts_surface(t_u, t_v, surf, **kwargs):\n    \"\"\" Finds the control points involved in the evaluation of the surface point defined by the input parameter pair.\n\n    This function uses a modified version of the algorithm *A3.5 SurfacePoint* from The NURBS Book by Piegl & Tiller.\n\n    :param t_u: parameter on the u-direction\n    :type t_u: float\n    :param t_v: parameter on the v-direction\n    :type t_v: float\n    :param surf: input surface\n    :type surf: abstract.Surface\n    :return: 2-dimensional control points array\n    :rtype: list\n    \"\"\"\n    # Get keyword arguments\n    span_func = kwargs.get('find_span_func', helpers.find_span_linear)\n\n    # Find spans\n    span_u = span_func(surf.degree_u, surf.knotvector_u, surf.ctrlpts_size_u, t_u)\n    span_v = span_func(surf.degree_v, surf.knotvector_v, surf.ctrlpts_size_v, t_v)\n\n    # Constant indices\n    idx_u = span_u - surf.degree_u\n    idx_v = span_v - surf.degree_v\n\n    # Find control points involved in evaluation of the surface point at the input parameter pair (u, v)\n    surf_ctrlpts = [[] for _ in range(surf.degree_u + 1)]\n    for k in range(surf.degree_u + 1):\n        temp = [() for _ in range(surf.degree_v + 1)]\n        for l in range(surf.degree_v + 1):\n            temp[l] = surf.ctrlpts2d[idx_u + k][idx_v + l]\n        surf_ctrlpts[k] = temp\n\n    # Return 2-dimensional control points array\n    return surf_ctrlpts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlink the input curves together.", "response": "def link_curves(*args, **kwargs):\n    \"\"\" Links the input curves together.\n\n    The end control point of the curve k has to be the same with the start control point of the curve k + 1.\n\n    Keyword Arguments:\n        * ``tol``: tolerance value for checking equality. *Default: 10e-8*\n        * ``validate``: flag to enable input validation. *Default: False*\n\n    :return: a tuple containing knot vector, control points, weights vector and knots\n    \"\"\"\n    # Get keyword arguments\n    tol = kwargs.get('tol', 10e-8)\n    validate = kwargs.get('validate', False)\n\n    # Validate input\n    if validate:\n        for idx in range(len(args) - 1):\n            if linalg.point_distance(args[idx].ctrlpts[-1], args[idx + 1].ctrlpts[0]) > tol:\n                raise GeomdlException(\"Curve #\" + str(idx) + \" and Curve #\" + str(idx + 1) + \" don't touch each other\")\n\n    kv = []  # new knot vector\n    cpts = []  # new control points array\n    wgts = []  # new weights array\n    kv_connected = []  # superfluous knots to be removed\n    pdomain_end = 0\n\n    # Loop though the curves\n    for arg in args:\n        # Process knot vectors\n        if not kv:\n            kv += list(arg.knotvector[:-(arg.degree + 1)])  # get rid of the last superfluous knot to maintain split curve notation\n            cpts += list(arg.ctrlpts)\n            # Process control points\n            if arg.rational:\n                wgts += list(arg.weights)\n            else:\n                tmp_w = [1.0 for _ in range(arg.ctrlpts_size)]\n                wgts += tmp_w\n        else:\n            tmp_kv = [pdomain_end + k for k in arg.knotvector[1:-(arg.degree + 1)]]\n            kv += tmp_kv\n            cpts += list(arg.ctrlpts[1:])\n            # Process control points\n            if arg.rational:\n                wgts += list(arg.weights[1:])\n            else:\n                tmp_w = [1.0 for _ in range(arg.ctrlpts_size - 1)]\n                wgts += tmp_w\n\n        pdomain_end += arg.knotvector[-1]\n        kv_connected.append(pdomain_end)\n\n    # Fix curve by appending the last knot to the end\n    kv += [pdomain_end for _ in range(arg.degree + 1)]\n    # Remove the last knot from knot insertion list\n    kv_connected.pop()\n\n    return kv, cpts, wgts, kv_connected"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting knots n - times to a spline geometry object.", "response": "def insert_knot(obj, param, num, **kwargs):\n    \"\"\" Inserts knots n-times to a spline geometry.\n\n    The following code snippet illustrates the usage of this function:\n\n    .. code-block:: python\n\n        # Insert knot u=0.5 to a curve 2 times\n        operations.insert_knot(curve, [0.5], [2])\n\n        # Insert knot v=0.25 to a surface 1 time\n        operations.insert_knot(surface, [None, 0.25], [0, 1])\n\n        # Insert knots u=0.75, v=0.25 to a surface 2 and 1 times, respectively\n        operations.insert_knot(surface, [0.75, 0.25], [2, 1])\n\n        # Insert knot w=0.5 to a volume 1 time\n        operations.insert_knot(volume, [None, None, 0.5], [0, 0, 1])\n\n    Please note that input spline geometry object will always be updated if the knot insertion operation is successful.\n\n    Keyword Arguments:\n        * ``check_num``: enables/disables operation validity checks. *Default: True*\n\n    :param obj: spline geometry\n    :type obj: abstract.SplineGeometry\n    :param param: knot(s) to be inserted in [u, v, w] format\n    :type param: list, tuple\n    :param num: number of knot insertions in [num_u, num_v, num_w] format\n    :type num: list, tuple\n    :return: updated spline geometry\n    \"\"\"\n    # Get keyword arguments\n    check_num = kwargs.get('check_num', True)  # can be set to False when the caller checks number of insertions\n\n    if check_num:\n        # Check the validity of number of insertions\n        if not isinstance(num, (list, tuple)):\n            raise GeomdlException(\"The number of insertions must be a list or a tuple\",\n                                  data=dict(num=num))\n\n        if len(num) != obj.pdimension:\n            raise GeomdlException(\"The length of the num array must be equal to the number of parametric dimensions\",\n                                  data=dict(pdim=obj.pdimension, num_len=len(num)))\n\n        for idx, val in enumerate(num):\n            if val < 0:\n                raise GeomdlException('Number of insertions must be a positive integer value',\n                                      data=dict(idx=idx, num=val))\n\n    # Start curve knot insertion\n    if isinstance(obj, abstract.Curve):\n        if param[0] is not None and num[0] > 0:\n            # Find knot multiplicity\n            s = helpers.find_multiplicity(param[0], obj.knotvector)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[0] > obj.degree - s:\n                raise GeomdlException(\"Knot \" + str(param[0]) + \" cannot be inserted \" + str(num[0]) + \" times\",\n                                      data=dict(knot=param[0], num=num[0], multiplicity=s))\n\n            # Find knot span\n            span = helpers.find_span_linear(obj.degree, obj.knotvector, obj.ctrlpts_size, param[0])\n\n            # Compute new knot vector\n            kv_new = helpers.knot_insertion_kv(obj.knotvector, param[0], span, num[0])\n\n            # Compute new control points\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            cpts_tmp = helpers.knot_insertion(obj.degree, obj.knotvector, cpts, param[0],\n                                              num=num[0], s=s, span=span)\n\n            # Update curve\n            obj.set_ctrlpts(cpts_tmp)\n            obj.knotvector = kv_new\n\n    # Start surface knot insertion\n    if isinstance(obj, abstract.Surface):\n        # u-direction\n        if param[0] is not None and num[0] > 0:\n            # Find knot multiplicity\n            s_u = helpers.find_multiplicity(param[0], obj.knotvector_u)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[0] > obj.degree_u - s_u:\n                raise GeomdlException(\"Knot \" + str(param[0]) + \" cannot be inserted \" + str(num[0]) + \" times (u-dir)\",\n                                      data=dict(knot=param[0], num=num[0], multiplicity=s_u))\n\n            # Find knot span\n            span_u = helpers.find_span_linear(obj.degree_u, obj.knotvector_u, obj.ctrlpts_size_u, param[0])\n\n            # Compute new knot vector\n            kv_u = helpers.knot_insertion_kv(obj.knotvector_u, param[0], span_u, num[0])\n\n            # Get curves\n            cpts_tmp = []\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            for v in range(obj.ctrlpts_size_v):\n                ccu = [cpts[v + (obj.ctrlpts_size_v * u)] for u in range(obj.ctrlpts_size_u)]\n                ctrlpts_tmp = helpers.knot_insertion(obj.degree_u, obj.knotvector_u, ccu, param[0],\n                                                     num=num[0], s=s_u, span=span_u)\n                cpts_tmp += ctrlpts_tmp\n\n            # Update the surface after knot insertion\n            obj.set_ctrlpts(compatibility.flip_ctrlpts_u(cpts_tmp, obj.ctrlpts_size_u + num[0], obj.ctrlpts_size_v),\n                            obj.ctrlpts_size_u + num[0], obj.ctrlpts_size_v)\n            obj.knotvector_u = kv_u\n\n        # v-direction\n        if param[1] is not None and num[1] > 0:\n            # Find knot multiplicity\n            s_v = helpers.find_multiplicity(param[1], obj.knotvector_v)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[1] > obj.degree_v - s_v:\n                raise GeomdlException(\"Knot \" + str(param[1]) + \" cannot be inserted \" + str(num[1]) + \" times (v-dir)\",\n                                      data=dict(knot=param[1], num=num[1], multiplicity=s_v))\n\n            # Find knot span\n            span_v = helpers.find_span_linear(obj.degree_v, obj.knotvector_v, obj.ctrlpts_size_v, param[1])\n\n            # Compute new knot vector\n            kv_v = helpers.knot_insertion_kv(obj.knotvector_v, param[1], span_v, num[1])\n\n            # Get curves\n            cpts_tmp = []\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            for u in range(obj.ctrlpts_size_u):\n                ccv = [cpts[v + (obj.ctrlpts_size_v * u)] for v in range(obj.ctrlpts_size_v)]\n                ctrlpts_tmp = helpers.knot_insertion(obj.degree_v, obj.knotvector_v, ccv, param[1],\n                                                     num=num[1], s=s_v, span=span_v)\n                cpts_tmp += ctrlpts_tmp\n\n            # Update the surface after knot insertion\n            obj.set_ctrlpts(cpts_tmp, obj.ctrlpts_size_u, obj.ctrlpts_size_v + num[1])\n            obj.knotvector_v = kv_v\n\n    # Start volume knot insertion\n    if isinstance(obj, abstract.Volume):\n        # u-direction\n        if param[0] is not None and num[0] > 0:\n            # Find knot multiplicity\n            s_u = helpers.find_multiplicity(param[0], obj.knotvector_u)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[0] > obj.degree_u - s_u:\n                raise GeomdlException(\"Knot \" + str(param[0]) + \" cannot be inserted \" + str(num[0]) + \" times (u-dir)\",\n                                      data=dict(knot=param[0], num=num[0], multiplicity=s_u))\n\n            # Find knot span\n            span_u = helpers.find_span_linear(obj.degree_u, obj.knotvector_u, obj.ctrlpts_size_u, param[0])\n\n            # Compute new knot vector\n            kv_u = helpers.knot_insertion_kv(obj.knotvector_u, param[0], span_u, num[0])\n\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for u in range(obj.ctrlpts_size_u):\n                temp_surf = []\n                for w in range(obj.ctrlpts_size_w):\n                    for v in range(obj.ctrlpts_size_v):\n                        temp_pt = cpts[v + (u * obj.ctrlpts_size_v) + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                        temp_surf.append(temp_pt)\n                cpt2d.append(temp_surf)\n\n            # Compute new control points\n            ctrlpts_tmp = helpers.knot_insertion(obj.degree_u, obj.knotvector_u, cpt2d, param[0],\n                                                 num=num[0], s=s_u, span=span_u)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(obj.ctrlpts_size_w):\n                for u in range(obj.ctrlpts_size_u + num[0]):\n                    for v in range(obj.ctrlpts_size_v):\n                        temp_pt = ctrlpts_tmp[u][v + (w * obj.ctrlpts_size_v)]\n                        ctrlpts_new.append(temp_pt)\n\n            # Update the volume after knot insertion\n            obj.set_ctrlpts(ctrlpts_new, obj.ctrlpts_size_u + num[0], obj.ctrlpts_size_v, obj.ctrlpts_size_w)\n            obj.knotvector_u = kv_u\n\n        # v-direction\n        if param[1] is not None and num[1] > 0:\n            # Find knot multiplicity\n            s_v = helpers.find_multiplicity(param[1], obj.knotvector_v)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[1] > obj.degree_v - s_v:\n                raise GeomdlException(\"Knot \" + str(param[1]) + \" cannot be inserted \" + str(num[1]) + \" times (v-dir)\",\n                                      data=dict(knot=param[1], num=num[1], multiplicity=s_v))\n\n            # Find knot span\n            span_v = helpers.find_span_linear(obj.degree_v, obj.knotvector_v, obj.ctrlpts_size_v, param[1])\n\n            # Compute new knot vector\n            kv_v = helpers.knot_insertion_kv(obj.knotvector_v, param[1], span_v, num[1])\n\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for v in range(obj.ctrlpts_size_v):\n                temp_surf = []\n                for w in range(obj.ctrlpts_size_w):\n                    for u in range(obj.ctrlpts_size_u):\n                        temp_pt = cpts[v + (u * obj.ctrlpts_size_v) + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                        temp_surf.append(temp_pt)\n                cpt2d.append(temp_surf)\n\n            # Compute new control points\n            ctrlpts_tmp = helpers.knot_insertion(obj.degree_v, obj.knotvector_v, cpt2d, param[1],\n                                                 num=num[1], s=s_v, span=span_v)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(obj.ctrlpts_size_w):\n                for u in range(obj.ctrlpts_size_u):\n                    for v in range(obj.ctrlpts_size_v + num[1]):\n                        temp_pt = ctrlpts_tmp[v][u + (w * obj.ctrlpts_size_u)]\n                        ctrlpts_new.append(temp_pt)\n\n            # Update the volume after knot insertion\n            obj.set_ctrlpts(ctrlpts_new, obj.ctrlpts_size_u, obj.ctrlpts_size_v + num[1], obj.ctrlpts_size_w)\n            obj.knotvector_v = kv_v\n\n        # w-direction\n        if param[2] is not None and num[2] > 0:\n            # Find knot multiplicity\n            s_w = helpers.find_multiplicity(param[2], obj.knotvector_w)\n\n            # Check if it is possible add that many number of knots\n            if check_num and num[2] > obj.degree_w - s_w:\n                raise GeomdlException(\"Knot \" + str(param[2]) + \" cannot be inserted \" + str(num[2]) + \" times (w-dir)\",\n                                      data=dict(knot=param[2], num=num[2], multiplicity=s_w))\n\n            # Find knot span\n            span_w = helpers.find_span_linear(obj.degree_w, obj.knotvector_w, obj.ctrlpts_size_w, param[2])\n\n            # Compute new knot vector\n            kv_w = helpers.knot_insertion_kv(obj.knotvector_w, param[2], span_w, num[2])\n\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for w in range(obj.ctrlpts_size_w):\n                temp_surf = [cpts[uv + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)] for uv in\n                             range(obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                cpt2d.append(temp_surf)\n\n            # Compute new control points\n            ctrlpts_tmp = helpers.knot_insertion(obj.degree_w, obj.knotvector_w, cpt2d, param[2],\n                                                 num=num[2], s=s_w, span=span_w)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(obj.ctrlpts_size_w + num[2]):\n                ctrlpts_new += ctrlpts_tmp[w]\n\n            # Update the volume after knot insertion\n            obj.set_ctrlpts(ctrlpts_new, obj.ctrlpts_size_u, obj.ctrlpts_size_v, obj.ctrlpts_size_w + num[2])\n            obj.knotvector_w = kv_w\n\n    # Return updated spline geometry\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refine_knotvector(obj, param, **kwargs):\n    # Get keyword arguments\n    check_num = kwargs.get('check_num', True)  # enables/disables input validity checks\n\n    if check_num:\n        if not isinstance(param, (list, tuple)):\n            raise GeomdlException(\"Parametric dimensions argument (param) must be a list or a tuple\")\n\n        if len(param) != obj.pdimension:\n            raise GeomdlException(\"The length of the param array must be equal to the number of parametric dimensions\",\n                                  data=dict(pdim=obj.pdimension, param_len=len(param)))\n\n    # Start curve knot refinement\n    if isinstance(obj, abstract.Curve):\n        if param[0] > 0:\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            new_cpts, new_kv = helpers.knot_refinement(obj.degree, obj.knotvector, cpts, density=param[0])\n            obj.set_ctrlpts(new_cpts)\n            obj.knotvector = new_kv\n\n    # Start surface knot refinement\n    if isinstance(obj, abstract.Surface):\n        # u-direction\n        if param[0] > 0:\n            # Get curves\n            new_cpts = []\n            new_cpts_size = 0\n            new_kv = []\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            for v in range(obj.ctrlpts_size_v):\n                ccu = [cpts[v + (obj.ctrlpts_size_v * u)] for u in range(obj.ctrlpts_size_u)]\n                ptmp, new_kv = helpers.knot_refinement(obj.degree_u, obj.knotvector_u, ccu, density=param[0])\n                new_cpts_size = len(ptmp)\n                new_cpts += ptmp\n\n            # Update the surface after knot refinement\n            obj.set_ctrlpts(compatibility.flip_ctrlpts_u(new_cpts, new_cpts_size, obj.ctrlpts_size_v),\n                            new_cpts_size, obj.ctrlpts_size_v)\n            obj.knotvector_u = new_kv\n\n        # v-direction\n        if param[1] > 0:\n            # Get curves\n            new_cpts = []\n            new_cpts_size = 0\n            new_kv = []\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n            for u in range(obj.ctrlpts_size_u):\n                ccv = [cpts[v + (obj.ctrlpts_size_v * u)] for v in range(obj.ctrlpts_size_v)]\n                ptmp, new_kv = helpers.knot_refinement(obj.degree_v, obj.knotvector_v, ccv, density=param[1])\n                new_cpts_size = len(ptmp)\n                new_cpts += ptmp\n\n            # Update the surface after knot refinement\n            obj.set_ctrlpts(new_cpts, obj.ctrlpts_size_u, new_cpts_size)\n            obj.knotvector_v = new_kv\n\n    # Start volume knot refinement\n    if isinstance(obj, abstract.Volume):\n        # u-direction\n        if param[0] > 0:\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for u in range(obj.ctrlpts_size_u):\n                temp_surf = []\n                for w in range(obj.ctrlpts_size_w):\n                    for v in range(obj.ctrlpts_size_v):\n                        temp_pt = cpts[v + (u * obj.ctrlpts_size_v) + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                        temp_surf.append(temp_pt)\n                cpt2d.append(temp_surf)\n\n            # Apply knot refinement\n            ctrlpts_tmp, kv_new = helpers.knot_refinement(obj.degree_u, obj.knotvector_u, cpt2d, density=param[0])\n            new_cpts_size = len(ctrlpts_tmp)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(obj.ctrlpts_size_w):\n                for u in range(new_cpts_size):\n                    for v in range(obj.ctrlpts_size_v):\n                        temp_pt = ctrlpts_tmp[u][v + (w * obj.ctrlpts_size_v)]\n                        ctrlpts_new.append(temp_pt)\n\n            # Update the volume after knot removal\n            obj.set_ctrlpts(ctrlpts_new, new_cpts_size, obj.ctrlpts_size_v, obj.ctrlpts_size_w)\n            obj.knotvector_u = kv_new\n\n        # v-direction\n        if param[1] > 0:\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for v in range(obj.ctrlpts_size_v):\n                temp_surf = []\n                for w in range(obj.ctrlpts_size_w):\n                    for u in range(obj.ctrlpts_size_u):\n                        temp_pt = cpts[v + (u * obj.ctrlpts_size_v) + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                        temp_surf.append(temp_pt)\n                cpt2d.append(temp_surf)\n\n            # Apply knot refinement\n            ctrlpts_tmp, kv_new = helpers.knot_refinement(obj.degree_v, obj.knotvector_v, cpt2d, density=param[1])\n            new_cpts_size = len(ctrlpts_tmp)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(obj.ctrlpts_size_w):\n                for u in range(obj.ctrlpts_size_u):\n                    for v in range(new_cpts_size):\n                        temp_pt = ctrlpts_tmp[v][u + (w * obj.ctrlpts_size_u)]\n                        ctrlpts_new.append(temp_pt)\n\n            # Update the volume after knot removal\n            obj.set_ctrlpts(ctrlpts_new, obj.ctrlpts_size_u, new_cpts_size, obj.ctrlpts_size_w)\n            obj.knotvector_v = kv_new\n\n        # w-direction\n        if param[2] > 0:\n            # Use Pw if rational\n            cpts = obj.ctrlptsw if obj.rational else obj.ctrlpts\n\n            # Construct 2-dimensional structure\n            cpt2d = []\n            for w in range(obj.ctrlpts_size_w):\n                temp_surf = [cpts[uv + (w * obj.ctrlpts_size_u * obj.ctrlpts_size_v)] for uv in\n                             range(obj.ctrlpts_size_u * obj.ctrlpts_size_v)]\n                cpt2d.append(temp_surf)\n\n            # Apply knot refinement\n            ctrlpts_tmp, kv_new = helpers.knot_refinement(obj.degree_w, obj.knotvector_w, cpt2d, density=param[2])\n            new_cpts_size = len(ctrlpts_tmp)\n\n            # Flatten to 1-dimensional structure\n            ctrlpts_new = []\n            for w in range(new_cpts_size):\n                ctrlpts_new += ctrlpts_tmp[w]\n\n            # Update the volume after knot removal\n            obj.set_ctrlpts(ctrlpts_new, obj.ctrlpts_size_u, obj.ctrlpts_size_v, new_cpts_size)\n            obj.knotvector_w = kv_new\n\n    # Return updated spline geometry\n    return obj", "response": "This function refines the knot vector of a spline geometry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply degree elevation and degree reduction algorithms to spline geometries.", "response": "def degree_operations(obj, param, **kwargs):\n    \"\"\" Applies degree elevation and degree reduction algorithms to spline geometries.\n\n    :param obj: spline geometry\n    :type obj: abstract.SplineGeometry\n    :param param: operation definition\n    :type param: list, tuple\n    :return: updated spline geometry\n    \"\"\"\n    def validate_reduction(degree):\n        if degree < 2:\n            raise GeomdlException(\"Input spline geometry must have degree > 1\")\n\n    # Start curve degree manipulation operations\n    if isinstance(obj, abstract.Curve):\n        if param[0] is not None and param[0] != 0:\n            # Find multiplicity of the internal knots\n            int_knots = set(obj.knotvector[obj.degree + 1:-(obj.degree + 1)])\n            mult_arr = []\n            for ik in int_knots:\n                s = helpers.find_multiplicity(ik, obj.knotvector)\n                mult_arr.append(s)\n\n            # Decompose the input by knot insertion\n            crv_list = decompose_curve(obj, **kwargs)\n\n            # If parameter is positive, apply degree elevation. Otherwise, apply degree reduction\n            if param[0] > 0:\n                # Loop through to apply degree elevation\n                for crv in crv_list:\n                    cpts = crv.ctrlptsw if crv.rational else crv.ctrlpts\n                    new_cpts = helpers.degree_elevation(crv.degree, cpts, num=param[0])\n                    crv.degree += param[0]\n                    crv.set_ctrlpts(new_cpts)\n                    crv.knotvector = [crv.knotvector[0] for _ in range(param[0])] + list(crv.knotvector) + [crv.knotvector[-1] for _ in range(param[0])]\n\n                # Compute new degree\n                nd = obj.degree + param[0]\n\n                # Number of knot removals\n                num = obj.degree + 1\n            else:\n                # Validate degree reduction operation\n                validate_reduction(obj.degree)\n\n                # Loop through to apply degree reduction\n                for crv in crv_list:\n                    cpts = crv.ctrlptsw if crv.rational else crv.ctrlpts\n                    new_cpts = helpers.degree_reduction(crv.degree, cpts)\n                    crv.degree -= 1 \n                    crv.set_ctrlpts(new_cpts)\n                    crv.knotvector = list(crv.knotvector[1:-1])\n                \n                # Compute new degree\n                nd = obj.degree - 1\n\n                # Number of knot removals\n                num = obj.degree - 1\n            \n            # Link curves together (reverse of decomposition)\n            kv, cpts, ws, knots = ops.link_curves(*crv_list, validate=False)\n            \n            # Organize control points (if necessary)\n            ctrlpts = compatibility.combine_ctrlpts_weights(cpts, ws) if obj.rational else cpts\n\n            # Apply knot removal\n            for k, s in zip(knots, mult_arr):\n                span = helpers.find_span_linear(nd, kv, len(ctrlpts), k)\n                ctrlpts = helpers.knot_removal(nd, kv, ctrlpts, k, num=num-s)\n                kv = helpers.knot_removal_kv(kv, span, num-s)\n            \n            # Update input curve\n            obj.degree = nd\n            obj.set_ctrlpts(ctrlpts)\n            obj.knotvector = kv\n\n    # Start surface degree manipulation operations\n    if isinstance(obj, abstract.Surface):\n        # u-direction\n        if param[0] is not None and param[0] != 0:\n\n            # If parameter is positive, apply degree elevation. Else, apply degree reduction\n            if param[0] > 0:\n                pass\n            else:\n                # Apply degree reduction operation\n                validate_reduction(obj.degree_u)\n\n        # v-direction\n        if param[1] is not None and param[1] != 0:\n\n            # If parameter is positive, apply degree elevation. Otherwise, apply degree reduction\n            if param[1] > 0:\n                pass\n            else:\n                # Validate degree reduction operation\n                validate_reduction(obj.degree_v)\n\n    # Start surface degree manipulation operations\n    if isinstance(obj, abstract.Volume):\n        raise GeomdlException(\"Degree manipulation operations are not available for spline volumes\")\n\n    # Return updated spline geometry\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_dimension(obj, **kwargs):\n    if not isinstance(obj, abstract.SplineGeometry):\n        raise GeomdlException(\"Can only operate on spline geometry objects\")\n\n    # Keyword arguments\n    inplace = kwargs.get('inplace', False)\n    array_init = kwargs.get('array_init', [[] for _ in range(len(obj.ctrlpts))])\n    offset_value = kwargs.get('offset', 0.0)\n\n    # Update control points\n    new_ctrlpts = array_init\n    for idx, point in enumerate(obj.ctrlpts):\n        temp = [float(p) for p in point[0:obj.dimension]]\n        temp.append(offset_value)\n        new_ctrlpts[idx] = temp\n\n    if inplace:\n        obj.ctrlpts = new_ctrlpts\n        return obj\n    else:\n        ret = copy.deepcopy(obj)\n        ret.ctrlpts = new_ctrlpts\n        return ret", "response": "Adds the spatial dimension of the spline geometry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_curve(obj, param, **kwargs):\n    # Validate input\n    if not isinstance(obj, abstract.Curve):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Curve class\")\n\n    if param == obj.knotvector[0] or param == obj.knotvector[-1]:\n        raise GeomdlException(\"Cannot split on the corner points\")\n\n    # Keyword arguments\n    span_func = kwargs.get('find_span_func', helpers.find_span_linear)  # FindSpan implementation\n    insert_knot_func = kwargs.get('insert_knot_func', insert_knot)  # Knot insertion algorithm\n\n    # Find multiplicity of the knot and define how many times we need to add the knot\n    ks = span_func(obj.degree, obj.knotvector, len(obj.ctrlpts), param) - obj.degree + 1\n    s = helpers.find_multiplicity(param, obj.knotvector)\n    r = obj.degree - s\n\n    # Create backups of the original curve\n    temp_obj = copy.deepcopy(obj)\n\n    # Insert knot\n    insert_knot_func(temp_obj, [param], num=[r], check_num=False)\n\n    # Knot vectors\n    knot_span = span_func(temp_obj.degree, temp_obj.knotvector, len(temp_obj.ctrlpts), param) + 1\n    curve1_kv = list(temp_obj.knotvector[0:knot_span])\n    curve1_kv.append(param)\n    curve2_kv = list(temp_obj.knotvector[knot_span:])\n    for _ in range(0, temp_obj.degree + 1):\n        curve2_kv.insert(0, param)\n\n    # Control points (use Pw if rational)\n    cpts = temp_obj.ctrlptsw if obj.rational else temp_obj.ctrlpts\n    curve1_ctrlpts = cpts[0:ks + r]\n    curve2_ctrlpts = cpts[ks + r - 1:]\n\n    # Create a new curve for the first half\n    curve1 = temp_obj.__class__()\n    curve1.degree = temp_obj.degree\n    curve1.set_ctrlpts(curve1_ctrlpts)\n    curve1.knotvector = curve1_kv\n\n    # Create another curve fot the second half\n    curve2 = temp_obj.__class__()\n    curve2.degree = temp_obj.degree\n    curve2.set_ctrlpts(curve2_ctrlpts)\n    curve2.knotvector = curve2_kv\n\n    # Return the split curves\n    ret_val = [curve1, curve2]\n    return ret_val", "response": "Splits the curve at the given parametric coordinate and returns two pieces of the input curve."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decompose_curve(obj, **kwargs):\n    if not isinstance(obj, abstract.Curve):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Curve class\")\n\n    multi_curve = []\n    curve = copy.deepcopy(obj)\n    knots = curve.knotvector[curve.degree + 1:-(curve.degree + 1)]\n    while knots:\n        knot = knots[0]\n        curves = split_curve(curve, param=knot, **kwargs)\n        multi_curve.append(curves[0])\n        curve = curves[1]\n        knots = curve.knotvector[curve.degree + 1:-(curve.degree + 1)]\n    multi_curve.append(curve)\n\n    return multi_curve", "response": "Decomposes the input curve into Bezier curve segments of the same degree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef derivative_curve(obj):\n    if not isinstance(obj, abstract.Curve):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Curve class\")\n\n    # Unfortunately, rational curves do NOT have this property\n    # Ref: https://pages.mtu.edu/~shene/COURSES/cs3621/LAB/curve/1st-2nd.html\n    if obj.rational:\n        warnings.warn(\"Cannot compute hodograph curve for a rational curve\")\n        return obj\n\n    # Find the control points of the derivative curve\n    pkl = evaluators.CurveEvaluator2.derivatives_ctrlpts(r1=0,\n                                                         r2=len(obj.ctrlpts) - 1,  # n + 1 = num of control points\n                                                         degree=obj.degree,\n                                                         knotvector=obj.knotvector,\n                                                         ctrlpts=obj.ctrlpts,\n                                                         dimension=obj.dimension,\n                                                         deriv_order=1)\n\n    # Generate the derivative curve\n    curve = obj.__class__()\n    curve.degree = obj.degree - 1\n    curve.ctrlpts = pkl[1][0:-1]\n    curve.knotvector = obj.knotvector[1:-1]\n    curve.delta = obj.delta\n\n    return curve", "response": "Computes the derivative curve of the input curve."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef length_curve(obj):\n    if not isinstance(obj, abstract.Curve):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Curve class\")\n\n    length = 0.0\n    evalpts = obj.evalpts\n    num_evalpts = len(obj.evalpts)\n    for idx in range(num_evalpts - 1):\n        length += linalg.point_distance(evalpts[idx], evalpts[idx + 1])\n    return length", "response": "Computes the approximate length of the parametric curve."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits the surface at the input parametric coordinate on the u - direction.", "response": "def split_surface_u(obj, param, **kwargs):\n    \"\"\" Splits the surface at the input parametric coordinate on the u-direction.\n\n    This method splits the surface into two pieces at the given parametric coordinate on the u-direction,\n    generates two different surface objects and returns them. It does not modify the input surface.\n\n    Keyword Arguments:\n        * ``find_span_func``: FindSpan implementation. *Default:* :func:`.helpers.find_span_linear`\n        * ``insert_knot_func``: knot insertion algorithm implementation. *Default:* :func:`.operations.insert_knot`\n\n    :param obj: surface\n    :type obj: abstract.Surface\n    :param param: parameter for the u-direction\n    :type param: float\n    :return: a list of surface patches\n    :rtype: list\n    \"\"\"\n    # Validate input\n    if not isinstance(obj, abstract.Surface):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Surface class\")\n\n    if param == obj.knotvector_u[0] or param == obj.knotvector_u[-1]:\n        raise GeomdlException(\"Cannot split on the edge\")\n\n    # Keyword arguments\n    span_func = kwargs.get('find_span_func', helpers.find_span_linear)  # FindSpan implementation\n    insert_knot_func = kwargs.get('insert_knot_func', insert_knot)  # Knot insertion algorithm\n\n    # Find multiplicity of the knot\n    ks = span_func(obj.degree_u, obj.knotvector_u, obj.ctrlpts_size_u, param) - obj.degree_u + 1\n    s = helpers.find_multiplicity(param, obj.knotvector_u)\n    r = obj.degree_u - s\n\n    # Create backups of the original surface\n    temp_obj = copy.deepcopy(obj)\n\n    # Split the original surface\n    insert_knot_func(temp_obj, [param, None], num=[r, 0], check_num=False)\n\n    # Knot vectors\n    knot_span = span_func(temp_obj.degree_u, temp_obj.knotvector_u, temp_obj.ctrlpts_size_u, param) + 1\n    surf1_kv = list(temp_obj.knotvector_u[0:knot_span])\n    surf1_kv.append(param)\n    surf2_kv = list(temp_obj.knotvector_u[knot_span:])\n    for _ in range(0, temp_obj.degree_u + 1):\n        surf2_kv.insert(0, param)\n\n    # Control points\n    surf1_ctrlpts = temp_obj.ctrlpts2d[0:ks + r]\n    surf2_ctrlpts = temp_obj.ctrlpts2d[ks + r - 1:]\n\n    # Create a new surface for the first half\n    surf1 = temp_obj.__class__()\n    surf1.degree_u = temp_obj.degree_u\n    surf1.degree_v = temp_obj.degree_v\n    surf1.ctrlpts2d = surf1_ctrlpts\n    surf1.knotvector_u = surf1_kv\n    surf1.knotvector_v = temp_obj.knotvector_v\n\n    # Create another surface fot the second half\n    surf2 = temp_obj.__class__()\n    surf2.degree_u = temp_obj.degree_u\n    surf2.degree_v = temp_obj.degree_v\n    surf2.ctrlpts2d = surf2_ctrlpts\n    surf2.knotvector_u = surf2_kv\n    surf2.knotvector_v = temp_obj.knotvector_v\n\n    # Return the new surfaces\n    ret_val = [surf1, surf2]\n    return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecomposing the input surface into Bezier surface patches of the same degree.", "response": "def decompose_surface(obj, **kwargs):\n    \"\"\" Decomposes the surface into Bezier surface patches of the same degree.\n\n    This operation does not modify the input surface, instead it returns the surface patches.\n\n    Keyword Arguments:\n        * ``find_span_func``: FindSpan implementation. *Default:* :func:`.helpers.find_span_linear`\n        * ``insert_knot_func``: knot insertion algorithm implementation. *Default:* :func:`.operations.insert_knot`\n\n    :param obj: surface\n    :type obj: abstract.Surface\n    :return: a list of Bezier patches\n    :rtype: list\n    \"\"\"\n    def decompose(srf, idx, split_func_list, **kws):\n        srf_list = []\n        knots = srf.knotvector[idx][srf.degree[idx] + 1:-(srf.degree[idx] + 1)]\n        while knots:\n            knot = knots[0]\n            srfs = split_func_list[idx](srf, param=knot, **kws)\n            srf_list.append(srfs[0])\n            srf = srfs[1]\n            knots = srf.knotvector[idx][srf.degree[idx] + 1:-(srf.degree[idx] + 1)]\n        srf_list.append(srf)\n        return srf_list\n\n    # Validate input\n    if not isinstance(obj, abstract.Surface):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Surface class\")\n\n    # Get keyword arguments\n    decompose_dir = kwargs.get('decompose_dir', 'uv')  # possible directions: u, v, uv\n    if \"decompose_dir\" in kwargs:\n        kwargs.pop(\"decompose_dir\")\n\n    # List of split functions\n    split_funcs = [split_surface_u, split_surface_v]\n\n    # Work with an identical copy\n    surf = copy.deepcopy(obj)\n\n    # Only u-direction\n    if decompose_dir == 'u':\n        return decompose(surf, 0, split_funcs, **kwargs)\n\n    # Only v-direction\n    if decompose_dir == 'v':\n        return decompose(surf, 1, split_funcs, **kwargs)\n\n    # Both u- and v-directions\n    if decompose_dir == 'uv':\n        multi_surf = []\n        # Process u-direction\n        surfs_u = decompose(surf, 0, split_funcs, **kwargs)\n        # Process v-direction\n        for sfu in surfs_u:\n            multi_surf += decompose(sfu, 1, split_funcs, **kwargs)\n        return multi_surf\n    else:\n        raise GeomdlException(\"Cannot decompose in \" + str(decompose_dir) + \" direction. Acceptable values: u, v, uv\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the hodograph (first derivative) surface of the input surface. This function constructs the hodograph (first derivative) surface from the input surface by computing the degrees, knot vectors and the control points of the derivative surface. The return value of this function is a tuple containing the following derivative surfaces in the given order: * U-derivative surface (derivative taken only on the u-direction) * V-derivative surface (derivative taken only on the v-direction) * UV-derivative surface (derivative taken on both the u- and the v-direction) :param obj: input surface :type obj: abstract.Surface :return: derivative surfaces w.r.t. u, v and both u-v :rtype: tuple", "response": "def derivative_surface(obj):\n    \"\"\" Computes the hodograph (first derivative) surface of the input surface.\n\n    This function constructs the hodograph (first derivative) surface from the input surface by computing the degrees,\n    knot vectors and the control points of the derivative surface.\n\n    The return value of this function is a tuple containing the following derivative surfaces in the given order:\n\n    * U-derivative surface (derivative taken only on the u-direction)\n    * V-derivative surface (derivative taken only on the v-direction)\n    * UV-derivative surface (derivative taken on both the u- and the v-direction)\n\n    :param obj: input surface\n    :type obj: abstract.Surface\n    :return: derivative surfaces w.r.t. u, v and both u-v\n    :rtype: tuple\n    \"\"\"\n    if not isinstance(obj, abstract.Surface):\n        raise GeomdlException(\"Input shape must be an instance of abstract.Surface class\")\n\n    if obj.rational:\n        warnings.warn(\"Cannot compute hodograph surface for a rational surface\")\n        return obj\n\n    # Find the control points of the derivative surface\n    d = 2  # 0 <= k + l <= d, see pg. 114 of The NURBS Book, 2nd Ed.\n    pkl = evaluators.SurfaceEvaluator2.derivatives_ctrlpts(r1=0, r2=obj.ctrlpts_size_u - 1,\n                                                           s1=0, s2=obj.ctrlpts_size_v - 1,\n                                                           degree=(obj.degree_u, obj.degree_v),\n                                                           ctrlpts_size=(obj.ctrlpts_size_u,obj.ctrlpts_size_v),\n                                                           knotvector=(obj.knotvector_u, obj.knotvector_v),\n                                                           ctrlpts=obj.ctrlpts,\n                                                           dimension=obj.dimension,\n                                                           deriv_order=d)\n\n    ctrlpts2d_u = []\n    for i in range(0, len(pkl[1][0]) - 1):\n        ctrlpts2d_u.append(pkl[1][0][i])\n\n    surf_u = copy.deepcopy(obj)\n    surf_u.degree_u = obj.degree_u - 1\n    surf_u.ctrlpts2d = ctrlpts2d_u\n    surf_u.knotvector_u = obj.knotvector_u[1:-1]\n    surf_u.delta = obj.delta\n\n    ctrlpts2d_v = []\n    for i in range(0, len(pkl[0][1])):\n        ctrlpts2d_v.append(pkl[0][1][i][0:-1])\n\n    surf_v = copy.deepcopy(obj)\n    surf_v.degree_v = obj.degree_v - 1\n    surf_v.ctrlpts2d = ctrlpts2d_v\n    surf_v.knotvector_v = obj.knotvector_v[1:-1]\n    surf_v.delta = obj.delta\n\n    ctrlpts2d_uv = []\n    for i in range(0, len(pkl[1][1]) - 1):\n        ctrlpts2d_uv.append(pkl[1][1][i][0:-1])\n\n    # Generate the derivative curve\n    surf_uv = obj.__class__()\n    surf_uv.degree_u = obj.degree_u - 1\n    surf_uv.degree_v = obj.degree_v - 1\n    surf_uv.ctrlpts2d = ctrlpts2d_uv\n    surf_uv.knotvector_u = obj.knotvector_u[1:-1]\n    surf_uv.knotvector_v = obj.knotvector_v[1:-1]\n    surf_uv.delta = obj.delta\n\n    return surf_u, surf_v, surf_uv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_ctrlpts(obj, u, v=None, **kwargs):\n    if isinstance(obj, abstract.Curve):\n        return ops.find_ctrlpts_curve(u, obj, **kwargs)\n    elif isinstance(obj, abstract.Surface):\n        if v is None:\n            raise GeomdlException(\"Parameter value for the v-direction must be set for operating on surfaces\")\n        return ops.find_ctrlpts_surface(u, v, obj, **kwargs)\n    else:\n        raise GeomdlException(\"The input must be an instance of abstract.Curve or abstract.Surface\")", "response": "Find the control points involved in the evaluation of the curve or surface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tangent(obj, params, **kwargs):\n    normalize = kwargs.get('normalize', True)\n    if isinstance(obj, abstract.Curve):\n        if isinstance(params, (list, tuple)):\n            return ops.tangent_curve_single_list(obj, params, normalize)\n        else:\n            return ops.tangent_curve_single(obj, params, normalize)\n    if isinstance(obj, abstract.Surface):\n        if isinstance(params[0], float):\n            return ops.tangent_surface_single(obj, params, normalize)\n        else:\n            return ops.tangent_surface_single_list(obj, params, normalize)", "response": "Evaluates the tangent vector of the curves or surfaces at the input parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normal(obj, params, **kwargs):\n    normalize = kwargs.get('normalize', True)\n    if isinstance(obj, abstract.Curve):\n        if isinstance(params, (list, tuple)):\n            return ops.normal_curve_single_list(obj, params, normalize)\n        else:\n            return ops.normal_curve_single(obj, params, normalize)\n    if isinstance(obj, abstract.Surface):\n        if isinstance(params[0], float):\n            return ops.normal_surface_single(obj, params, normalize)\n        else:\n            return ops.normal_surface_single_list(obj, params, normalize)", "response": "Evaluates the normal vector of the curves or surfaces at the input parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef binormal(obj, params, **kwargs):\n    normalize = kwargs.get('normalize', True)\n    if isinstance(obj, abstract.Curve):\n        if isinstance(params, (list, tuple)):\n            return ops.binormal_curve_single_list(obj, params, normalize)\n        else:\n            return ops.binormal_curve_single(obj, params, normalize)\n    if isinstance(obj, abstract.Surface):\n        raise GeomdlException(\"Binormal vector evaluation for the surfaces is not implemented!\")", "response": "Evaluates the binormal vector of the curves or surfaces at the input parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating curves surface or volumes by the input vector.", "response": "def translate(obj, vec, **kwargs):\n    \"\"\" Translates curves, surface or volumes by the input vector.\n\n    Keyword Arguments:\n        * ``inplace``: if False, operation applied to a copy of the object. *Default: False*\n\n    :param obj: input geometry\n    :type obj: abstract.SplineGeometry or multi.AbstractContainer\n    :param vec: translation vector\n    :type vec: list, tuple\n    :return: translated geometry object\n    \"\"\"\n    # Input validity checks\n    if not vec or not isinstance(vec, (tuple, list)):\n        raise GeomdlException(\"The input must be a list or a tuple\")\n\n    # Input validity checks\n    if len(vec) != obj.dimension:\n        raise GeomdlException(\"The input vector must have \" + str(obj.dimension) + \" components\")\n\n    # Keyword arguments\n    inplace = kwargs.get('inplace', False)\n\n    if not inplace:\n        geom = copy.deepcopy(obj)\n    else:\n        geom = obj\n\n    # Translate control points\n    for g in geom:\n        new_ctrlpts = []\n        for pt in g.ctrlpts:\n            temp = [v + vec[i] for i, v in enumerate(pt)]\n            new_ctrlpts.append(temp)\n        g.ctrlpts = new_ctrlpts\n\n    return geom"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rotate(obj, angle, **kwargs):\n    def rotate_x(ncs, opt, alpha):\n        # Generate translation vector\n        translate_vector = linalg.vector_generate(opt, [0.0 for _ in range(ncs.dimension)])\n\n        # Translate to the origin\n        translate(ncs, translate_vector, inplace=True)\n\n        # Then, rotate about the axis\n        rot = math.radians(alpha)\n        new_ctrlpts = [[0.0 for _ in range(ncs.dimension)] for _ in range(len(ncs.ctrlpts))]\n        for idx, pt in enumerate(ncs.ctrlpts):\n            new_ctrlpts[idx][0] = pt[0]\n            new_ctrlpts[idx][1] = (pt[1] * math.cos(rot)) - (pt[2] * math.sin(rot))\n            new_ctrlpts[idx][2] = (pt[2] * math.cos(rot)) + (pt[1] * math.sin(rot))\n        ncs.ctrlpts = new_ctrlpts\n\n        # Finally, translate back to the starting location\n        translate(ncs, [-tv for tv in translate_vector], inplace=True)\n\n    def rotate_y(ncs, opt, alpha):\n        # Generate translation vector\n        translate_vector = linalg.vector_generate(opt, [0.0 for _ in range(ncs.dimension)])\n\n        # Translate to the origin\n        translate(ncs, translate_vector, inplace=True)\n\n        # Then, rotate about the axis\n        rot = math.radians(alpha)\n        new_ctrlpts = [[0.0 for _ in range(ncs.dimension)] for _ in range(len(ncs.ctrlpts))]\n        for idx, pt in enumerate(ncs.ctrlpts):\n            new_ctrlpts[idx][0] = (pt[0] * math.cos(rot)) - (pt[2] * math.sin(rot))\n            new_ctrlpts[idx][1] = pt[1]\n            new_ctrlpts[idx][2] = (pt[2] * math.cos(rot)) + (pt[0] * math.sin(rot))\n        ncs.ctrlpts = new_ctrlpts\n\n        # Finally, translate back to the starting location\n        translate(ncs, [-tv for tv in translate_vector], inplace=True)\n\n    def rotate_z(ncs, opt, alpha):\n        # Generate translation vector\n        translate_vector = linalg.vector_generate(opt, [0.0 for _ in range(ncs.dimension)])\n\n        # Translate to the origin\n        translate(ncs, translate_vector, inplace=True)\n\n        # Then, rotate about the axis\n        rot = math.radians(alpha)\n        new_ctrlpts = [list(ncs.ctrlpts[i]) for i in range(len(ncs.ctrlpts))]\n        for idx, pt in enumerate(ncs.ctrlpts):\n            new_ctrlpts[idx][0] = (pt[0] * math.cos(rot)) - (pt[1] * math.sin(rot))\n            new_ctrlpts[idx][1] = (pt[1] * math.cos(rot)) + (pt[0] * math.sin(rot))\n        ncs.ctrlpts = new_ctrlpts\n\n        # Finally, translate back to the starting location\n        translate(ncs, [-tv for tv in translate_vector], inplace=True)\n\n    # Set rotation axis\n    axis = 2 if obj.dimension == 2 else int(kwargs.get('axis', 2))\n    if not 0 <= axis <= 2:\n        raise GeomdlException(\"Value of the 'axis' argument should be 0, 1 or 2\")\n    rotfunc = (rotate_x, rotate_y, rotate_z)\n\n    # Operate on a copy or the actual object\n    inplace = kwargs.get('inplace', False)\n    if not inplace:\n        geom = copy.deepcopy(obj)\n    else:\n        geom = obj\n\n    # Set a single origin\n    if geom[0].pdimension == 1:\n        params = geom[0].domain[0]\n    else:\n        params = [geom[0].domain[i][0] for i in range(geom[0].pdimension)]\n    origin = geom[0].evaluate_single(params)\n\n    # Start rotation\n    for g in geom:\n        rotfunc[axis](g, origin, angle)\n\n    return geom", "response": "Rotates curves surfaces or volumes about the chosen axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scale(obj, multiplier, **kwargs):\n    # Input validity checks\n    if not isinstance(multiplier, (int, float)):\n        raise GeomdlException(\"The multiplier must be a float or an integer\")\n\n    # Keyword arguments\n    inplace = kwargs.get('inplace', False)\n\n    if not inplace:\n        geom = copy.deepcopy(obj)\n    else:\n        geom = obj\n\n    # Scale control points\n    for g in geom:\n        new_ctrlpts = [[] for _ in range(g.ctrlpts_size)]\n        for idx, pts in enumerate(g.ctrlpts):\n            new_ctrlpts[idx] = [p * float(multiplier) for p in pts]\n        g.ctrlpts = new_ctrlpts\n\n    return geom", "response": "Scales curves surfaces or volumes by the input multiplier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transpose(surf, **kwargs):\n    if surf.pdimension != 2:\n        raise GeomdlException(\"Can only transpose surfaces\")\n\n    # Keyword arguments\n    inplace = kwargs.get('inplace', False)\n\n    if not inplace:\n        geom = copy.deepcopy(surf)\n    else:\n        geom = surf\n\n    for g in geom:\n        # Get existing data\n        degree_u_new = g.degree_v\n        degree_v_new = g.degree_u\n        kv_u_new = g.knotvector_v\n        kv_v_new = g.knotvector_u\n        ctrlpts2d_old = g.ctrlpts2d\n\n        # Find new control points\n        ctrlpts2d_new = []\n        for v in range(0, g.ctrlpts_size_v):\n            ctrlpts_u = []\n            for u in range(0, g.ctrlpts_size_u):\n                temp = ctrlpts2d_old[u][v]\n                ctrlpts_u.append(temp)\n            ctrlpts2d_new.append(ctrlpts_u)\n\n        g.degree_u = degree_u_new\n        g.degree_v = degree_v_new\n        g.ctrlpts2d = ctrlpts2d_new\n        g.knotvector_u = kv_u_new\n        g.knotvector_v = kv_v_new\n\n    return geom", "response": "Transposes the input surface by swapping u and v parametric directions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef voxelize(obj, **kwargs):\n    # Get keyword arguments\n    grid_size = kwargs.pop('grid_size', (8, 8, 8))\n    use_cubes = kwargs.pop('use_cubes', False)\n    num_procs = kwargs.get('num_procs', 1)\n\n    if not isinstance(grid_size, (list, tuple)):\n        raise TypeError(\"Grid size must be a list or a tuple of integers\")\n\n    # Initialize result arrays\n    grid = []\n    filled = []\n\n    # Should also work with multi surfaces and volumes\n    for o in obj:\n        # Generate voxel grid\n        grid_temp = vxl.generate_voxel_grid(o.bbox, grid_size, use_cubes=use_cubes)\n        args = [grid_temp, o.evalpts]\n\n        # Find in-outs\n        filled_temp = vxl.find_inouts_mp(*args, **kwargs) if num_procs > 1 else vxl.find_inouts_st(*args, **kwargs)\n\n        # Add to result arrays\n        grid += grid_temp\n        filled += filled_temp\n\n    # Return result arrays\n    return grid, filled", "response": "Generates binary voxel representation of the surfaces and volumes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a bounding box of all voxels to a list of faces.", "response": "def convert_bb_to_faces(voxel_grid):\n    \"\"\" Converts a voxel grid defined by min and max coordinates to a voxel grid defined by faces.\n\n    :param voxel_grid: voxel grid defined by the bounding box of all voxels\n    :return: voxel grid with face data\n    \"\"\"\n    new_vg = []\n    for v in voxel_grid:\n        # Vertices\n        p1 = v[0]\n        p2 = [v[1][0], v[0][1], v[0][2]]\n        p3 = [v[1][0], v[1][1], v[0][2]]\n        p4 = [v[0][0], v[1][1], v[0][2]]\n        p5 = [v[0][0], v[0][1], v[1][2]]\n        p6 = [v[1][0], v[0][1], v[1][2]]\n        p7 = v[1]\n        p8 = [v[0][0], v[1][1], v[1][2]]\n        # Faces\n        fb = [p1, p2, p3, p4]  # bottom face\n        ft = [p5, p6, p7, p8]  # top face\n        fs1 = [p1, p2, p6, p5]  # side face 1\n        fs2 = [p2, p3, p7, p6]  # side face 2\n        fs3 = [p3, p4, p8, p7]  # side face 3\n        fs4 = [p1, p4, p8, p5]  # side face 4\n        # Append to return list\n        new_vg.append([fb, fs1, fs2, fs3, fs4, ft])\n    return new_vg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_voxel_grid(voxel_grid, file_name):\n    try:\n        with open(file_name, 'wb') as fp:\n            for voxel in voxel_grid:\n                fp.write(struct.pack(\"<I\", voxel))\n    except IOError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise e\n    except Exception:\n        raise", "response": "Saves binary voxel grid as a binary file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the cross product of two input vectors.", "response": "def vector_cross(vector1, vector2):\n    \"\"\" Computes the cross-product of the input vectors.\n\n    :param vector1: input vector 1\n    :type vector1: list, tuple\n    :param vector2: input vector 2\n    :type vector2: list, tuple\n    :return: result of the cross product\n    :rtype: tuple\n    \"\"\"\n    try:\n        if vector1 is None or len(vector1) == 0 or vector2 is None or len(vector2) == 0:\n            raise ValueError(\"Input vectors cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Input must be a list or tuple\")\n    except Exception:\n        raise\n\n    if not 1 < len(vector1) <= 3 or not 1 < len(vector2) <= 3:\n        raise ValueError(\"The input vectors should contain 2 or 3 elements\")\n\n    # Convert 2-D to 3-D, if necessary\n    if len(vector1) == 2:\n        v1 = [float(v) for v in vector1] + [0.0]\n    else:\n        v1 = vector1\n\n    if len(vector2) == 2:\n        v2 = [float(v) for v in vector2] + [0.0]\n    else:\n        v2 = vector2\n\n    # Compute cross product\n    vector_out = [(v1[1] * v2[2]) - (v1[2] * v2[1]),\n                  (v1[2] * v2[0]) - (v1[0] * v2[2]),\n                  (v1[0] * v2[1]) - (v1[1] * v2[0])]\n\n    # Return the cross product of the input vectors\n    return vector_out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vector_dot(vector1, vector2):\n    try:\n        if vector1 is None or len(vector1) == 0 or vector2 is None or len(vector2) == 0:\n            raise ValueError(\"Input vectors cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Input must be a list or tuple\")\n    except Exception:\n        raise\n\n    # Compute dot product\n    prod = 0.0\n    for v1, v2 in zip(vector1, vector2):\n        prod += v1 * v2\n\n    # Return the dot product of the input vectors\n    return prod", "response": "Computes the dot product of two input vectors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsum the vectors. This function computes the result of the vector operation :math:`\\\\overline{v}_{1} + c * \\\\overline{v}_{2}`, where :math:`\\\\overline{v}_{1}` is ``vector1``, :math:`\\\\overline{v}_{2}` is ``vector2`` and :math:`c` is ``coeff``. :param vector1: vector 1 :type vector1: list, tuple :param vector2: vector 2 :type vector2: list, tuple :param coeff: multiplier for vector 2 :type coeff: float :return: updated vector :rtype: list", "response": "def vector_sum(vector1, vector2, coeff=1.0):\n    \"\"\" Sums the vectors.\n\n    This function computes the result of the vector operation :math:`\\\\overline{v}_{1} + c * \\\\overline{v}_{2}`, where\n    :math:`\\\\overline{v}_{1}` is ``vector1``, :math:`\\\\overline{v}_{2}`  is ``vector2`` and :math:`c` is ``coeff``.\n\n    :param vector1: vector 1\n    :type vector1: list, tuple\n    :param vector2: vector 2\n    :type vector2: list, tuple\n    :param coeff: multiplier for vector 2\n    :type coeff: float\n    :return: updated vector\n    :rtype: list\n    \"\"\"\n    summed_vector = [v1 + (coeff * v2) for v1, v2 in zip(vector1, vector2)]\n    return summed_vector"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vector_normalize(vector_in, decimals=18):\n    try:\n        if vector_in is None or len(vector_in) == 0:\n            raise ValueError(\"Input vector cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Input must be a list or tuple\")\n    except Exception:\n        raise\n\n    # Calculate magnitude of the vector\n    magnitude = vector_magnitude(vector_in)\n\n    # Normalize the vector\n    if magnitude > 0:\n        vector_out = []\n        for vin in vector_in:\n            vector_out.append(vin / magnitude)\n\n        # Return the normalized vector and consider the number of significands\n        return [float((\"{:.\" + str(decimals) + \"f}\").format(vout)) for vout in vector_out]\n    else:\n        raise ValueError(\"The magnitude of the vector is zero\")", "response": "Normalizes the vector_in and returns the normalized vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a vector from start_pt to end_pt.", "response": "def vector_generate(start_pt, end_pt, normalize=False):\n    \"\"\" Generates a vector from 2 input points.\n\n    :param start_pt: start point of the vector\n    :type start_pt: list, tuple\n    :param end_pt: end point of the vector\n    :type end_pt: list, tuple\n    :param normalize: if True, the generated vector is normalized\n    :type normalize: bool\n    :return: a vector from start_pt to end_pt\n    :rtype: list\n    \"\"\"\n    try:\n        if start_pt is None or len(start_pt) == 0 or end_pt is None or len(end_pt) == 0:\n            raise ValueError(\"Input points cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Input must be a list or tuple\")\n    except Exception:\n        raise\n\n    ret_vec = []\n    for sp, ep in zip(start_pt, end_pt):\n        ret_vec.append(ep - sp)\n\n    if normalize:\n        ret_vec = vector_normalize(ret_vec)\n    return ret_vec"}
