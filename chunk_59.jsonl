{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vector_mean(*args):\n    sz = len(args)\n    mean_vector = [0.0 for _ in range(len(args[0]))]\n    for input_vector in args:\n        mean_vector = [a+b for a, b in zip(mean_vector, input_vector)]\n    mean_vector = [a / sz for a in mean_vector]\n    return mean_vector", "response": "Compute the mean of a list of vectors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the magnitude of the input vector.", "response": "def vector_magnitude(vector_in):\n    \"\"\" Computes the magnitude of the input vector.\n\n    :param vector_in: input vector\n    :type vector_in: list, tuple\n    :return: magnitude of the vector\n    :rtype: float\n    \"\"\"\n    sq_sum = 0.0\n    for vin in vector_in:\n        sq_sum += vin**2\n    return math.sqrt(sq_sum)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vector_angle_between(vector1, vector2, **kwargs):\n    degrees = kwargs.get('degrees', True)\n    magn1 = vector_magnitude(vector1)\n    magn2 = vector_magnitude(vector2)\n    acos_val = vector_dot(vector1, vector2) / (magn1 * magn2)\n    angle_radians = math.acos(acos_val)\n    if degrees:\n        return math.degrees(angle_radians)\n    else:\n        return angle_radians", "response": "Computes the angle between two input vectors."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the input vector is a zero vector.", "response": "def vector_is_zero(vector_in, tol=10e-8):\n    \"\"\" Checks if the input vector is a zero vector.\n\n    :param vector_in: input vector\n    :type vector_in: list, tuple\n    :param tol: tolerance value\n    :type tol: float\n    :return: True if the input vector is zero, False otherwise\n    :rtype: bool\n    \"\"\"\n    if not isinstance(vector_in, (list, tuple)):\n        raise TypeError(\"Input vector must be a list or a tuple\")\n\n    res = [False for _ in range(len(vector_in))]\n    for idx in range(len(vector_in)):\n        if abs(vector_in[idx]) < tol:\n            res[idx] = True\n    return all(res)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef point_translate(point_in, vector_in):\n    try:\n        if point_in is None or len(point_in) == 0 or vector_in is None or len(vector_in) == 0:\n            raise ValueError(\"Input arguments cannot be empty\")\n    except TypeError as e:\n        print(\"An error occurred: {}\".format(e.args[-1]))\n        raise TypeError(\"Input must be a list or tuple\")\n    except Exception:\n        raise\n\n    # Translate the point using the input vector\n    point_out = [coord + comp for coord, comp in zip(point_in, vector_in)]\n\n    return point_out", "response": "Translate a point using the input vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef point_distance(pt1, pt2):\n    if len(pt1) != len(pt2):\n        raise ValueError(\"The input points should have the same dimension\")\n\n    dist_vector = vector_generate(pt1, pt2, normalize=False)\n    distance = vector_magnitude(dist_vector)\n    return distance", "response": "Computes the distance between two points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef point_mid(pt1, pt2):\n    if len(pt1) != len(pt2):\n        raise ValueError(\"The input points should have the same dimension\")\n\n    dist_vector = vector_generate(pt1, pt2, normalize=False)\n    half_dist_vector = vector_multiply(dist_vector, 0.5)\n    return point_translate(pt1, half_dist_vector)", "response": "Computes the midpoint of the input points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matrix_transpose(m):\n    num_cols = len(m)\n    num_rows = len(m[0])\n    m_t = []\n    for i in range(num_rows):\n        temp = []\n        for j in range(num_cols):\n            temp.append(m[j][i])\n        m_t.append(temp)\n    return m_t", "response": "Transposes the input matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the approximate normal vector of the input triangle.", "response": "def triangle_normal(tri):\n    \"\"\" Computes the (approximate) normal vector of the input triangle.\n\n    :param tri: triangle object\n    :type tri: elements.Triangle\n    :return: normal vector of the triangle\n    :rtype: tuple\n    \"\"\"\n    vec1 = vector_generate(tri.vertices[0].data, tri.vertices[1].data)\n    vec2 = vector_generate(tri.vertices[1].data, tri.vertices[2].data)\n    return vector_cross(vec1, vec2)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef triangle_center(tri, uv=False):\n    if uv:\n        data = [t.uv for t in tri]\n        mid = [0.0, 0.0]\n    else:\n        data = tri.vertices\n        mid = [0.0, 0.0, 0.0]\n    for vert in data:\n        mid = [m + v for m, v in zip(mid, vert)]\n    mid = [float(m) / 3.0 for m in mid]\n    return tuple(mid)", "response": "Computes the center of mass of a triangle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef binomial_coefficient(k, i):\n    # Special case\n    if i > k:\n        return float(0)\n    # Compute binomial coefficient\n    k_fact = math.factorial(k)\n    i_fact = math.factorial(i)\n    k_i_fact = math.factorial(k - i)\n    return float(k_fact / (k_i_fact * i_fact))", "response": "Computes the binomial coefficient of a set of distinct elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lu_decomposition(matrix_a):\n    # Check if the 2-dimensional input matrix is a square matrix\n    q = len(matrix_a)\n    for idx, m_a in enumerate(matrix_a):\n        if len(m_a) != q:\n            raise ValueError(\"The input must be a square matrix. \" +\n                             \"Row \" + str(idx + 1) + \" has a size of \" + str(len(m_a)) + \".\")\n\n    # Return L and U matrices\n    return _linalg.doolittle(matrix_a)", "response": "LU - Factorization method using Doolittle s Method for solution of linear systems."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef forward_substitution(matrix_l, matrix_b):\n    q = len(matrix_b)\n    matrix_y = [0.0 for _ in range(q)]\n    matrix_y[0] = float(matrix_b[0]) / float(matrix_l[0][0])\n    for i in range(1, q):\n        matrix_y[i] = float(matrix_b[i]) - sum([matrix_l[i][j] * matrix_y[j] for j in range(0, i)])\n        matrix_y[i] /= float(matrix_l[i][i])\n    return matrix_y", "response": "Forward substitution method for the solution of linear systems."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backward_substitution(matrix_u, matrix_y):\n    q = len(matrix_y)\n    matrix_x = [0.0 for _ in range(q)]\n    matrix_x[q - 1] = float(matrix_y[q - 1]) / float(matrix_u[q - 1][q - 1])\n    for i in range(q - 2, -1, -1):\n        matrix_x[i] = float(matrix_y[i]) - sum([matrix_u[i][j] * matrix_x[j] for j in range(i, q)])\n        matrix_x[i] /= float(matrix_u[i][i])\n    return matrix_x", "response": "Backward substitution method for the solution of linear systems."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of evenly spaced numbers over a specified interval.", "response": "def linspace(start, stop, num, decimals=18):\n    \"\"\" Returns a list of evenly spaced numbers over a specified interval.\n\n    Inspired from Numpy's linspace function: https://github.com/numpy/numpy/blob/master/numpy/core/function_base.py\n\n    :param start: starting value\n    :type start: float\n    :param stop: end value\n    :type stop: float\n    :param num: number of samples to generate\n    :type num: int\n    :param decimals: number of significands\n    :type decimals: int\n    :return: a list of equally spaced numbers\n    :rtype: list\n    \"\"\"\n    start = float(start)\n    stop = float(stop)\n    if abs(start - stop) <= 10e-8:\n        return [start]\n    num = int(num)\n    if num > 1:\n        div = num - 1\n        delta = stop - start\n        return [float((\"{:.\" + str(decimals) + \"f}\").format((start + (float(x) * float(delta) / float(div)))))\n                for x in range(num)]\n    return [float((\"{:.\" + str(decimals) + \"f}\").format(start))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef frange(start, stop, step=1.0):\n    i = 0.0\n    x = float(start)  # Prevent yielding integers.\n    x0 = x\n    epsilon = step / 2.0\n    yield x  # always yield first value\n    while x + epsilon < stop:\n        i += 1.0\n        x = x0 + i * step\n        yield x\n    if stop > x:\n        yield stop", "response": "A generator that yields the range of the base base."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of points on convex hull in counterclockwise order according to Graham s scan algorithm.", "response": "def convex_hull(points):\n    \"\"\" Returns points on convex hull in counterclockwise order according to Graham's scan algorithm.\n\n    Reference: https://gist.github.com/arthur-e/5cf52962341310f438e96c1f3c3398b8\n\n    .. note:: This implementation only works in 2-dimensional space.\n\n    :param points: list of 2-dimensional points\n    :type points: list, tuple\n    :return: convex hull of the input points\n    :rtype: list\n    \"\"\"\n    turn_left, turn_right, turn_none = (1, -1, 0)\n\n    def cmp(a, b):\n        return (a > b) - (a < b)\n\n    def turn(p, q, r):\n        return cmp((q[0] - p[0])*(r[1] - p[1]) - (r[0] - p[0])*(q[1] - p[1]), 0)\n\n    def keep_left(hull, r):\n        while len(hull) > 1 and turn(hull[-2], hull[-1], r) != turn_left:\n            hull.pop()\n        if not len(hull) or hull[-1] != r:\n            hull.append(r)\n        return hull\n\n    points = sorted(points)\n    l = reduce(keep_left, points, [])\n    u = reduce(keep_left, reversed(points), [])\n    return l.extend(u[i] for i in range(1, len(u) - 1)) or l"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest if a point is Left On or Right of an infinite line.", "response": "def is_left(point0, point1, point2):\n    \"\"\" Tests if a point is Left|On|Right of an infinite line.\n\n    Ported from the C++ version: on http://geomalgorithms.com/a03-_inclusion.html\n\n    .. note:: This implementation only works in 2-dimensional space.\n\n    :param point0: Point P0\n    :param point1: Point P1\n    :param point2: Point P2\n    :return:\n        >0 for P2 left of the line through P0 and P1\n        =0 for P2 on the line\n        <0 for P2 right of the line\n    \"\"\"\n    return ((point1[0] - point0[0]) * (point2[1] - point0[1])) - ((point2[0] - point0[0]) * (point1[1] - point0[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wn_poly(point, vertices):\n    wn = 0  # the winding number counter\n\n    v_size = len(vertices) - 1\n    # loop through all edges of the polygon\n    for i in range(v_size):  # edge from V[i] to V[i+1]\n        if vertices[i][1] <= point[1]:  # start y <= P.y\n            if vertices[i + 1][1] > point[1]:  # an upward crossing\n                if is_left(vertices[i], vertices[i + 1], point) > 0:  # P left of edge\n                    wn += 1  # have a valid up intersect\n        else:  # start y > P.y (no test needed)\n            if vertices[i + 1][1] <= point[1]:  # a downward crossing\n                if is_left(vertices[i], vertices[i + 1], point) < 0:  # P right of edge\n                    wn -= 1  # have a valid down intersect\n    # return wn\n    return bool(wn)", "response": "This function checks if a point is inside the input polygon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a new univariate 2D or rational surface from the input curves.", "response": "def construct_surface(direction, *args, **kwargs):\n    \"\"\" Generates surfaces from curves.\n\n    Arguments:\n        * ``args``: a list of curve instances\n\n    Keyword Arguments (optional):\n        * ``degree``: degree of the 2nd parametric direction\n        * ``knotvector``: knot vector of the 2nd parametric direction\n        * ``rational``: flag to generate rational surfaces\n\n    :param direction: the direction that the input curves lies, i.e. u or v\n    :type direction: str\n    :return: Surface constructed from the curves on the given parametric direction\n    \"\"\"\n    # Input validation\n    possible_dirs = ['u', 'v']\n    if direction not in possible_dirs:\n        raise GeomdlException(\"Possible direction values: \" + \", \".join([val for val in possible_dirs]),\n                              data=dict(input_dir=direction))\n\n    size_other = len(args)\n    if size_other < 2:\n        raise GeomdlException(\"You need to input at least 2 curves\")\n\n    # Get keyword arguments\n    degree_other = kwargs.get('degree', 2)\n    knotvector_other = kwargs.get('knotvector', knotvector.generate(degree_other, size_other))\n    rational = kwargs.get('rational', args[0].rational)\n\n    # Construct the control points of the new surface\n    degree = args[0].degree\n    num_ctrlpts = args[0].ctrlpts_size\n    new_ctrlpts = []\n    new_weights = []\n    for idx, arg in enumerate(args):\n        if degree != arg.degree:\n            raise GeomdlException(\"Input curves must have the same degrees\",\n                                  data=dict(idx=idx, degree=degree, degree_arg=arg.degree))\n        if num_ctrlpts != arg.ctrlpts_size:\n            raise GeomdlException(\"Input curves must have the same number of control points\",\n                                  data=dict(idx=idx, size=num_ctrlpts, size_arg=arg.ctrlpts_size))\n        new_ctrlpts += list(arg.ctrlpts)\n        if rational:\n            if arg.weights is None:\n                raise GeomdlException(\"Expecting a rational curve\",\n                                      data=dict(idx=idx, rational=rational, rational_arg=arg.rational))\n            new_weights += list(arg.weights)\n\n    # Set variables w.r.t. input direction\n    if direction == 'u':\n        degree_u = degree_other\n        degree_v = degree\n        knotvector_u = knotvector_other\n        knotvector_v = args[0].knotvector\n        size_u = size_other\n        size_v = num_ctrlpts\n    else:\n        degree_u = degree\n        degree_v = degree_other\n        knotvector_u = args[0].knotvector\n        knotvector_v = knotvector_other\n        size_u = num_ctrlpts\n        size_v = size_other\n        if rational:\n            ctrlptsw = compatibility.combine_ctrlpts_weights(new_ctrlpts, new_weights)\n            ctrlptsw = compatibility.flip_ctrlpts_u(ctrlptsw, size_u, size_v)\n            new_ctrlpts, new_weights = compatibility.separate_ctrlpts_weights(ctrlptsw)\n        else:\n            new_ctrlpts = compatibility.flip_ctrlpts_u(new_ctrlpts, size_u, size_v)\n\n    # Generate the surface\n    ns = shortcuts.generate_surface(rational)\n    ns.degree_u = degree_u\n    ns.degree_v = degree_v\n    ns.ctrlpts_size_u = size_u\n    ns.ctrlpts_size_v = size_v\n    ns.ctrlpts = new_ctrlpts\n    if rational:\n        ns.weights = new_weights\n    ns.knotvector_u = knotvector_u\n    ns.knotvector_v = knotvector_v\n\n    # Return constructed surface\n    return ns"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a new volume from a list of surfaces.", "response": "def construct_volume(direction, *args, **kwargs):\n    \"\"\" Generates volumes from surfaces.\n\n    Arguments:\n        * ``args``: a list of surface instances\n\n    Keyword Arguments (optional):\n        * ``degree``: degree of the 3rd parametric direction\n        * ``knotvector``: knot vector of the 3rd parametric direction\n        * ``rational``: flag to generate rational volumes\n\n    :param direction: the direction that the input surfaces lies, i.e. u, v, w\n    :type direction: str\n    :return: Volume constructed from the surfaces on the given parametric direction\n    \"\"\"\n    # Input validation\n    possible_dirs = ['u', 'v', 'w']\n    if direction not in possible_dirs:\n        raise GeomdlException(\"Possible direction values: \" + \", \".join([val for val in possible_dirs]),\n                              data=dict(input_dir=direction))\n\n    size_other = len(args)\n    if size_other < 2:\n        raise GeomdlException(\"You need to input at least 2 surfaces\")\n\n    # Get keyword arguments\n    degree_other = kwargs.get('degree', 1)\n    knotvector_other = kwargs.get('knotvector', knotvector.generate(degree_other, size_other))\n    rational = kwargs.get('rational', args[0].rational)\n\n    # Construct the control points of the new volume\n    degree_u, degree_v = args[0].degree_u, args[0].degree_v\n    size_u, size_v = args[0].ctrlpts_size_u, args[0].ctrlpts_size_v\n    new_ctrlpts = []\n    new_weights = []\n    for idx, arg in enumerate(args):\n        if degree_u != arg.degree_u or degree_v != arg.degree_v:\n            raise GeomdlException(\"Input surfaces must have the same degrees\",\n                                  data=dict(idx=idx, degree=(degree_u, degree_v), degree_arg=(arg.degree_u, arg.degree_v)))\n        if size_u != arg.ctrlpts_size_u or size_v != arg.ctrlpts_size_v:\n            raise GeomdlException(\"Input surfaces must have the same number of control points\",\n                                  data=dict(idx=idx, size=(size_u, size_v), size_arg=(arg.ctrlpts_size_u, arg.ctrlpts_size_v)))\n        new_ctrlpts += list(arg.ctrlpts)\n        if rational:\n            if arg.weights is None:\n                raise GeomdlException(\"Expecting a rational surface\",\n                                      data=dict(idx=idx, rational=rational, rational_arg=arg.rational))\n            new_weights += list(arg.weights)\n\n    updated_ctrlpts = []\n    updated_weights = []\n\n    # Set variables w.r.t. input direction\n    if direction == 'u':\n        degree_u, degree_v, degree_w = degree_other, args[0].degree_u, args[0].degree_v\n        size_u, size_v, size_w = size_other, args[0].ctrlpts_size_u, args[0].ctrlpts_size_v\n        kv_u, kv_v, kv_w = knotvector_other, args[0].knotvector_u, args[0].knotvector_v\n        # u => w, v => u, w => v\n        for v in range(0, size_v):\n            for w in range(0, size_w):\n                for u in range(0, size_u):\n                    temp_pt = new_ctrlpts[v + (u * size_v) + (w * size_u * size_v)]\n                    updated_ctrlpts.append(temp_pt)\n                    if rational:\n                        temp_w = new_weights[v + (u * size_v) + (w * size_u * size_v)]\n                        updated_weights.append(temp_w)\n    elif direction == 'v':\n        degree_u, degree_v, degree_w = args[0].degree_u, degree_other, args[0].degree_v\n        size_u, size_v, size_w = args[0].ctrlpts_size_u, size_other, args[0].ctrlpts_size_v\n        kv_u, kv_v, kv_w = args[0].knotvector_u, knotvector_other, args[0].knotvector_v\n        # u => u, v => w, w => v\n        for v in range(0, size_v):\n            for u in range(0, size_u):\n                for w in range(0, size_w):\n                    temp_pt = new_ctrlpts[v + (u * size_v) + (w * size_u * size_v)]\n                    updated_ctrlpts.append(temp_pt)\n                    if rational:\n                        temp_w = new_weights[v + (u * size_v) + (w * size_u * size_v)]\n                        updated_weights.append(temp_w)\n    else:  # direction == 'w'\n        degree_u, degree_v, degree_w = args[0].degree_u, args[0].degree_v, degree_other\n        size_u, size_v, size_w = args[0].ctrlpts_size_u, args[0].ctrlpts_size_v, size_other\n        kv_u, kv_v, kv_w = args[0].knotvector_u, args[0].knotvector_v, knotvector_other\n        updated_ctrlpts = new_ctrlpts\n        if rational:\n            updated_weights = new_weights\n\n    # Generate the volume\n    nv = shortcuts.generate_volume(rational)\n    nv.degree_u = degree_u\n    nv.degree_v = degree_v\n    nv.degree_w = degree_w\n    nv.ctrlpts_size_u = size_u\n    nv.ctrlpts_size_v = size_v\n    nv.ctrlpts_size_w = size_w\n    nv.ctrlpts = updated_ctrlpts\n    if rational:\n        nv.weights = updated_weights\n    nv.knotvector_u = kv_u\n    nv.knotvector_v = kv_v\n    nv.knotvector_w = kv_w\n\n    return nv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_curves(psurf, **kwargs):\n    if psurf.pdimension != 2:\n        raise GeomdlException(\"The input should be a spline surface\")\n    if len(psurf) != 1:\n        raise GeomdlException(\"Can only operate on single spline surfaces\")\n\n    # Get keyword arguments\n    extract_u = kwargs.get('extract_u', True)\n    extract_v = kwargs.get('extract_v', True)\n\n    # Get data from the surface object\n    surf_data = psurf.data\n    rational = surf_data['rational']\n    degree_u = surf_data['degree'][0]\n    degree_v = surf_data['degree'][1]\n    kv_u = surf_data['knotvector'][0]\n    kv_v = surf_data['knotvector'][1]\n    size_u = surf_data['size'][0]\n    size_v = surf_data['size'][1]\n    cpts = surf_data['control_points']\n\n    # Determine object type\n    obj = shortcuts.generate_curve(rational)\n\n    # v-direction\n    crvlist_v = []\n    if extract_v:\n        for u in range(size_u):\n            curve = obj.__class__()\n            curve.degree = degree_v\n            curve.set_ctrlpts([cpts[v + (size_v * u)] for v in range(size_v)])\n            curve.knotvector = kv_v\n            crvlist_v.append(curve)\n\n    # u-direction\n    crvlist_u = []\n    if extract_u:\n        for v in range(size_v):\n            curve = obj.__class__()\n            curve.degree = degree_u\n            curve.set_ctrlpts([cpts[v + (size_v * u)] for u in range(size_u)])\n            curve.knotvector = kv_u\n            crvlist_u.append(curve)\n\n    # Return shapes as a dict object\n    return dict(u=crvlist_u, v=crvlist_v)", "response": "Extracts curves from a single spline surface."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts surfaces from a spline volume.", "response": "def extract_surfaces(pvol):\n    \"\"\" Extracts surfaces from a volume.\n\n    :param pvol: input volume\n    :type pvol: abstract.Volume\n    :return: extracted surface\n    :rtype: dict\n    \"\"\"\n    if pvol.pdimension != 3:\n        raise GeomdlException(\"The input should be a spline volume\")\n    if len(pvol) != 1:\n        raise GeomdlException(\"Can only operate on single spline volumes\")\n\n    # Get data from the volume object\n    vol_data = pvol.data\n    rational = vol_data['rational']\n    degree_u = vol_data['degree'][0]\n    degree_v = vol_data['degree'][1]\n    degree_w = vol_data['degree'][2]\n    kv_u = vol_data['knotvector'][0]\n    kv_v = vol_data['knotvector'][1]\n    kv_w = vol_data['knotvector'][2]\n    size_u = vol_data['size'][0]\n    size_v = vol_data['size'][1]\n    size_w = vol_data['size'][2]\n    cpts = vol_data['control_points']\n\n    # Determine object type\n    obj = shortcuts.generate_surface(rational)\n\n    # u-v plane\n    surflist_uv = []\n    for w in range(size_w):\n        surf = obj.__class__()\n        surf.degree_u = degree_u\n        surf.degree_v = degree_v\n        surf.ctrlpts_size_u = size_u\n        surf.ctrlpts_size_v = size_v\n        surf.ctrlpts2d = [[cpts[v + (size_v * (u + (size_u * w)))] for v in range(size_v)] for u in range(size_u)]\n        surf.knotvector_u = kv_u\n        surf.knotvector_v = kv_v\n        surflist_uv.append(surf)\n\n    # u-w plane\n    surflist_uw = []\n    for v in range(size_v):\n        surf = obj.__class__()\n        surf.degree_u = degree_u\n        surf.degree_v = degree_w\n        surf.ctrlpts_size_u = size_u\n        surf.ctrlpts_size_v = size_w\n        surf.ctrlpts2d = [[cpts[v + (size_v * (u + (size_u * w)))] for w in range(size_w)] for u in range(size_u)]\n        surf.knotvector_u = kv_u\n        surf.knotvector_v = kv_w\n        surflist_uw.append(surf)\n\n    # v-w plane\n    surflist_vw = []\n    for u in range(size_u):\n        surf = obj.__class__()\n        surf.degree_u = degree_v\n        surf.degree_v = degree_w\n        surf.ctrlpts_size_u = size_v\n        surf.ctrlpts_size_v = size_w\n        surf.ctrlpts2d = [[cpts[v + (size_v * (u + (size_u * w)))] for w in range(size_w)] for v in range(size_v)]\n        surf.knotvector_u = kv_v\n        surf.knotvector_v = kv_w\n        surflist_vw.append(surf)\n\n    # Return shapes as a dict object\n    return dict(uv=surflist_uv, uw=surflist_uw, vw=surflist_vw)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the largest isosurface from a parametric volume.", "response": "def extract_isosurface(pvol):\n    \"\"\" Extracts the largest isosurface from a volume.\n\n    The following example illustrates one of the usage scenarios:\n\n    .. code-block:: python\n        :linenos:\n\n        from geomdl import construct, multi\n        from geomdl.visualization import VisMPL\n\n        # Assuming that \"myvol\" variable stores your spline volume information\n        isosrf = construct.extract_isosurface(myvol)\n\n        # Create a surface container to store extracted isosurface\n        msurf = multi.SurfaceContainer(isosrf)\n\n        # Set visualization components\n        msurf.vis = VisMPL.VisSurface(VisMPL.VisConfig(ctrlpts=False))\n\n        # Render isosurface\n        msurf.render()\n\n    :param pvol: input volume\n    :type pvol: abstract.Volume\n    :return: isosurface (as a tuple of surfaces)\n    :rtype: tuple\n    \"\"\"\n    if pvol.pdimension != 3:\n        raise GeomdlException(\"The input should be a spline volume\")\n    if len(pvol) != 1:\n        raise GeomdlException(\"Can only operate on single spline volumes\")\n\n    # Extract surfaces from the parametric volume\n    isosrf = extract_surfaces(pvol)\n\n    # Return the isosurface\n    return isosrf['uv'][0], isosrf['uv'][-1], isosrf['uw'][0], isosrf['uw'][-1], isosrf['vw'][0], isosrf['vw'][-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_multi_trim_curves(obj, **kwargs):\n    if obj.pdimension != 2:\n        raise GeomdlException(\"Can only work with surfaces\")\n\n    # Get keyword arguments\n    tol = kwargs.get('tol', 10e-8)\n    eval_delta = kwargs.get('delta', 0.05)\n\n    # Loop through the surfaces\n    for o in obj:\n        # Get the trims\n        trims = o.trims\n\n        # Initialize a list for the connected trims\n        new_trims = []\n\n        # Traverse through the trims\n        for trim in trims:\n            trim_size = len(trim)\n\n            # Directly add to the new trims array if the trim is a single curve\n            if trim_size == 1:\n                new_trims.append(trim)\n                continue\n\n            new_trim = []\n            for idx in range(0, trim_size):\n                # Close the loop\n                if idx == trim_size - 1:\n                    idx2 = 0\n                else:\n                    idx2 = idx + 1\n\n                ###\n                # Assuming that we have two curves with starting and ending positions defined as P1-P2 and P3-P4,\n                # respectively. There are 5 possibilities:\n                # 1. P2 = P3 (end of 1st and start of 2nd)\n                # 2. P2 = P4 (end of 1st and end of 2nd)\n                # 3. P1 = P3 (start of 1st and start of 2nd)\n                # 4. P1 = P4 (start of 1st and end of 2nd)\n                # 5. the ends of the curves are far away from each other\n                ###\n\n                # End of 1st curve vs start of 2nd curve\n                if abs(trim[idx].evalpts[-1][0] - trim[idx2].evalpts[0][0]) <= tol and \\\n                        abs(trim[idx].evalpts[-1][1] - trim[idx2].evalpts[0][1]) <= tol:\n                    # They are in the same direction\n                    new_trim.append(trim[idx])\n                # End of 1st curve vs end of 2nd curve\n                elif abs(trim[idx].evalpts[-1][0] - trim[idx2].evalpts[-1][0]) <= tol and \\\n                        abs(trim[idx].evalpts[-1][1] - trim[idx2].evalpts[-1][1]) <= tol:\n                    # Reverse the second curve inplace\n                    trim[idx2].reverse()\n                    new_trim.append(trim[idx])\n                # Start of 1st curve and start of 2nd curve\n                elif abs(trim[idx].evalpts[0][0] - trim[idx2].evalpts[0][0]) <= tol and \\\n                        abs(trim[idx].evalpts[0][1] - trim[idx2].evalpts[0][1]) <= tol:\n                    # Reverse the first curve inplace\n                    trim[idx].reverse()\n                    new_trim.append(trim[idx])\n                # Start of 1st curve and end of 2nd curve\n                elif abs(trim[idx].evalpts[0][0] - trim[idx2].evalpts[-1][0]) <= tol and \\\n                        abs(trim[idx].evalpts[0][1] - trim[idx2].evalpts[-1][1]) <= tol:\n                    # Reverse both curves inplace\n                    trim[idx].reverse()\n                    trim[idx2].reverse()\n                    new_trim.append(trim[idx])\n                # The trim curves are far away from each other\n                else:\n                    # Find which end is closer to the current trim curve's end point\n                    dist1 = linalg.point_distance(trim[idx].evalpts[-1], trim[idx2].evalpts[0])\n                    dist2 = linalg.point_distance(trim[idx].evalpts[-1], trim[idx2].evalpts[-1])\n\n                    # Find start and end points of the connector curve\n                    start_pt = trim[idx].evalpts[-1]\n                    if dist1 < dist2:\n                        end_pt = trim[idx2].evalpts[0]\n                    else:\n                        end_pt = trim[idx2].evalpts[-1]\n\n                    # Generate the connector curve\n                    crv = shortcuts.generate_curve()\n                    crv.degree = 1\n                    crv.ctrlpts = [start_pt, end_pt]\n                    crv.knotvector = [0, 0, 1, 1]\n                    crv.opt = ['reversed', trim[idx].opt_get('reversed')]\n\n                    # Add trims\n                    new_trim.append(trim[idx])\n                    new_trim.append(crv)\n\n            # Create a curve container from the new trim list\n            cc = shortcuts.generate_container_curve()\n            cc.add(new_trim)\n            cc.opt = ['reversed', trim.opt_get('reversed')]\n            cc.delta = eval_delta\n\n            # Add curve container to the new trims list\n            new_trims.append(cc)\n\n        # Update input geometry\n        o.trims = new_trims\n\n    return obj", "response": "This function fixes the direction connectivity and similar issues of the multi - trim curves."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_trim_curves(obj):\n    # Validate input\n    if obj.pdimension != 2:\n        raise GeomdlException(\"Input geometry must be a surface\")\n\n    # Get trims of the surface\n    for o in obj:\n        trims = o.trims\n        if not trims:\n            continue\n\n        # Get parameter space bounding box\n        parbox = get_par_box(o.domain, True)\n\n        # Check and update trim curves with respect to the underlying surface\n        updated_trims = []\n        for trim in trims:\n            flag, trm = check_trim_curve(trim, parbox)\n            if flag:\n                if trm:\n                    cont = shortcuts.generate_container_curve()\n                    cont.add(trm)\n                    updated_trims.append(cont)\n                else:\n                    updated_trims.append(trim)\n\n        # Set updated trims\n        obj.trims = updated_trims", "response": "Fixes direction connectivity and similar issues of the trim curves."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_par_box(domain, last=False):\n    u_range = domain[0]\n    v_range = domain[1]\n    verts = [(u_range[0], v_range[0]), (u_range[1], v_range[0]), (u_range[1], v_range[1]), (u_range[0], v_range[1])]\n    if last:\n        verts.append(verts[0])\n    return tuple(verts)", "response": "Returns the bounding box of the parametric domain in ccw direction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect the sense of a 2 - dimensional trim.", "response": "def detect_sense(curve, tol):\n    \"\"\" Detects the sense, i.e. clockwise or counter-clockwise, of the curve.\n\n    :param curve: 2-dimensional trim curve\n    :type curve: abstract.Curve\n    :param tol: tolerance value\n    :type tol: float\n    :return: True if detection is successful, False otherwise\n    :rtype: bool\n    \"\"\"\n    if curve.opt_get('reversed') is None:\n        # Detect sense since it is unset\n        pts = curve.evalpts\n        num_pts = len(pts)\n        for idx in range(1, num_pts - 1):\n            sense = detect_ccw(pts[idx - 1], pts[idx], pts[idx + 1], tol)\n            if sense < 0:  # cw\n                curve.opt = ['reversed', 0]\n                return True\n            elif sense > 0:  # ccw\n                curve.opt = ['reversed', 1]\n                return True\n            else:\n                continue\n        # One final test with random points to determine the orientation\n        sense = detect_ccw(pts[int(num_pts/3)], pts[int(2*num_pts/3)], pts[-int(num_pts/3)], tol)\n        if sense < 0:  # cw\n            curve.opt = ['reversed', 0]\n            return True\n        elif sense > 0:  # ccw\n            curve.opt = ['reversed', 1]\n            return True\n        else:\n            # Cannot determine the sense\n            return False\n    else:\n        # Don't touch the sense value as it has been already set\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind intersection of two rays and returns a tuple of the parameter t for the intersection.", "response": "def intersect(ray1, ray2, **kwargs):\n    \"\"\" Finds intersection of 2 rays.\n\n    This functions finds the parameter values for the 1st and 2nd input rays and returns a tuple of\n    ``(parameter for ray1, parameter for ray2, intersection status)``.\n    ``status`` value is a enum type which reports the case which the intersection operation encounters.\n\n    The intersection operation can encounter 3 different cases:\n\n    * Intersecting: This is the anticipated solution. Returns ``(t1, t2, RayIntersection.INTERSECT)``\n    * Colinear: The rays can be parallel or coincident. Returns ``(t1, t2, RayIntersection.COLINEAR)``\n    * Skew:  The rays are neither parallel nor intersecting. Returns ``(t1, t2, RayIntersection.SKEW)``\n\n    For the colinear case, ``t1`` and ``t2`` are the parameter values that give the starting point of the ray2 and ray1,\n    respectively. Therefore;\n\n    .. code-block:: python\n\n        ray1.eval(t1) == ray2.p\n        ray2.eval(t2) == ray1.p\n\n    Please note that this operation is only implemented for 2- and 3-dimensional rays.\n\n    :param ray1: 1st ray\n    :param ray2: 2nd ray\n    :return: a tuple of the parameter (t) for ray1 and ray2, and status of the intersection\n    :rtype: tuple\n    \"\"\"\n    if not isinstance(ray1, Ray) or not isinstance(ray2, Ray):\n        raise TypeError(\"The input arguments must be instances of the Ray object\")\n\n    if ray1.dimension != ray2.dimension:\n        raise ValueError(\"Dimensions of the input rays must be the same\")\n\n    # Keyword arguments\n    tol = kwargs.get('tol', 10e-17)\n\n    # Call intersection method\n    if ray1.dimension == 2:\n        return _intersect2d(ray1, ray2, tol)\n    elif ray1.dimension == 3:\n        return _intersect3d(ray1, ray2, tol)\n    else:\n        raise NotImplementedError(\"Intersection operation for the current type of rays has not been implemented yet\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evaluate(self, **kwargs):\n        self._eval_points = kwargs.get('points', self._init_array())\n        self._dimension = len(self._eval_points[0])", "response": "Sets the points that form the geometry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport a single polygon object to VTK Polydata format.", "response": "def export_polydata_str(obj, **kwargs):\n    \"\"\" Saves control points or evaluated points in VTK Polydata format (string).\n\n    Please see the following document for details: http://www.vtk.org/VTK/img/file-formats.pdf\n\n    Keyword Arguments:\n        * ``point_type``: **ctrlpts** for control points or **evalpts** for evaluated points\n        * ``tessellate``: tessellates the points (works only for surfaces)\n\n    :param obj: geometry object\n    :type obj: abstract.SplineGeometry, multi.AbstractContainer\n    :return: contents of the VTK file\n    :rtype: str\n    :raises GeomdlException: point type is not supported\n    :raises UserWarning: file title is bigger than 256 characters\n    \"\"\"\n    # Get keyword arguments\n    point_type = kwargs.get('point_type', \"evalpts\")\n    file_title = kwargs.get('title', \"geomdl \" + repr(obj))  # file title\n    tessellate = kwargs.get('tessellate', False)\n\n    # Input validation\n    possible_types = ['ctrlpts', 'evalpts']\n    if point_type not in possible_types:\n        raise exch.GeomdlException(\"Please choose a valid point type option. \" +\n                                   \"Possible types:\", \", \".join([str(t) for t in possible_types]))\n\n    # Check for VTK standards for the file title\n    if len(file_title) >= 256:\n        file_title = file_title[0:255]  # slice the array into 255 characters, we will add new line character later\n        warnings.warn(\"VTK standard restricts the file title with 256 characters. New file title is:\", file_title)\n\n    # Find number of edges in a single tessellated structure\n    tsl_dim = 4 if point_type == \"ctrlpts\" else 3\n\n    # Initialize lists\n    str_p = \"\"\n    str_v = \"\"\n    str_f = \"\"\n\n    # Count number of vertices and faces\n    v_offset = 0\n    f_offset = 0\n\n    # Loop through all geometry objects\n    for o in obj:\n        # Prepare data array\n        if point_type == \"ctrlpts\":\n            if tessellate and o.pdimension == 2:\n                tsl = abstract.tessellate.QuadTessellate()\n                tsl.tessellate(o.ctrlpts, size_u=o.ctrlpts_size_u, size_v=o.ctrlpts_size_v)\n                data_array = ([v.data for v in tsl.vertices], [q.data for q in tsl.faces])\n            else:\n                data_array = (o.ctrlpts, [])\n        elif point_type == \"evalpts\":\n            if tessellate and o.pdimension == 2:\n                o.tessellate()\n                data_array = ([v.data for v in o.vertices], [t.data for t in o.faces])\n            else:\n                data_array = (o.evalpts, [])\n        else:\n            data_array = ([], [])\n\n        # Prepare point and vertex data\n        for ipt, pt in enumerate(data_array[0]):\n            str_p += \" \".join(str(c) for c in pt) + \"\\n\"\n            str_v += \"1 \" + str(ipt + v_offset) + \"\\n\"\n\n        # Prepare polygon data\n        if data_array[1]:\n            for pt in data_array[1]:\n                str_f += str(tsl_dim) + \" \" + \" \".join(str(c + v_offset) for c in pt) + \"\\n\"\n            # Update face offset\n            f_offset += len(data_array[1])\n\n        # Update vertex offset\n        v_offset += len(data_array[0])\n\n    # Start generating the file content\n    line = \"# vtk DataFile Version 3.0\\n\"\n    line += file_title + \"\\n\"\n    line += \"ASCII\\n\"\n\n    # Define geometry/topology\n    line += \"DATASET POLYDATA\\n\"\n\n    # Add point data to the file\n    line += \"POINTS \" + str(v_offset) + \" FLOAT\\n\"\n    line += str_p\n\n    # Add vertex data to the file\n    line += \"VERTICES \" + str(v_offset) + \" \" + str(2 * v_offset) + \"\\n\"\n    line += str_v\n\n    # Add polygon data to the file\n    if tessellate:\n        line += \"POLYGONS \" + str(f_offset) + \" \" + str((tsl_dim + 1) * f_offset) + \"\\n\"\n        line += str_f\n\n    # Add dataset attributes to the file\n    line += \"POINT_DATA \" + str(v_offset) + \"\\n\"\n    if f_offset > 0:\n        line += \"CELL_DATA \" + str(f_offset) + \"\\n\"\n\n    # Return generated file content\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_polydata(obj, file_name, **kwargs):\n    content = export_polydata_str(obj, **kwargs)\n    return exch.write_file(file_name, content)", "response": "Exports control points or evaluated points in VTK Polydata format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef color_generator(seed=None):\n    def r_int():\n        return random.randint(0, 255)\n    if seed is not None:\n        random.seed(seed)\n    color_string = '#%02X%02X%02X'\n    return [color_string % (r_int(), r_int(), r_int()), color_string % (r_int(), r_int(), r_int())]", "response": "Generates random colors for control and evaluated curve and surface points plots."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_zigzag(points, num_cols):\n    new_points = []\n    points_size = len(points)\n    forward = True\n    idx = 0\n    rev_idx = -1\n    while idx < points_size:\n        if forward:\n            new_points.append(points[idx])\n        else:\n            new_points.append(points[rev_idx])\n            rev_idx -= 1\n        idx += 1\n        if idx % num_cols == 0:\n            forward = False if forward else True\n            rev_idx = idx + num_cols - 1\n\n    return new_points", "response": "This function converts a linear sequence of points into a zig - zag shape."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a linear sequence of input points into a quad structure.", "response": "def make_quad(points, size_u, size_v):\n    \"\"\" Converts linear sequence of input points into a quad structure.\n\n    :param points: list of points to be ordered\n    :type points: list, tuple\n    :param size_v: number of elements in a row\n    :type size_v: int\n    :param size_u: number of elements in a column\n    :type size_u: int\n    :return: re-ordered points\n    :rtype: list\n    \"\"\"\n    # Start with generating a zig-zag shape in row direction and then take its reverse\n    new_points = make_zigzag(points, size_v)\n    new_points.reverse()\n\n    # Start generating a zig-zag shape in col direction\n    forward = True\n    for row in range(0, size_v):\n        temp = []\n        for col in range(0, size_u):\n            temp.append(points[row + (col * size_v)])\n        if forward:\n            forward = False\n        else:\n            forward = True\n            temp.reverse()\n        new_points += temp\n\n    return new_points"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_quadtree(points, size_u, size_v, **kwargs):\n    # Get keyword arguments\n    extrapolate = kwargs.get('extrapolate', True)\n\n    # Convert control points array into 2-dimensional form\n    points2d = []\n    for i in range(0, size_u):\n        row_list = []\n        for j in range(0, size_v):\n            row_list.append(points[j + (i * size_v)])\n        points2d.append(row_list)\n\n    # Traverse 2-dimensional control points to find neighbors\n    qtree = []\n    for u in range(size_u):\n        for v in range(size_v):\n            temp = [points2d[u][v]]\n            # Note: negative indexing actually works in Python, so we need explicit checking\n            if u + 1 < size_u:\n                temp.append(points2d[u+1][v])\n            else:\n                if extrapolate:\n                    extrapolated_edge = linalg.vector_generate(points2d[u - 1][v], points2d[u][v])\n                    translated_point = linalg.point_translate(points2d[u][v], extrapolated_edge)\n                    temp.append(translated_point)\n            if v + 1 < size_v:\n                temp.append(points2d[u][v+1])\n            else:\n                if extrapolate:\n                    extrapolated_edge = linalg.vector_generate(points2d[u][v - 1], points2d[u][v])\n                    translated_point = linalg.point_translate(points2d[u][v], extrapolated_edge)\n                    temp.append(translated_point)\n            if u - 1 >= 0:\n                temp.append(points2d[u-1][v])\n            else:\n                if extrapolate:\n                    extrapolated_edge = linalg.vector_generate(points2d[u + 1][v], points2d[u][v])\n                    translated_point = linalg.point_translate(points2d[u][v], extrapolated_edge)\n                    temp.append(translated_point)\n            if v - 1 >= 0:\n                temp.append(points2d[u][v-1])\n            else:\n                if extrapolate:\n                    extrapolated_edge = linalg.vector_generate(points2d[u][v + 1], points2d[u][v])\n                    translated_point = linalg.point_translate(points2d[u][v], extrapolated_edge)\n                    temp.append(translated_point)\n            qtree.append(tuple(temp))\n\n    # Return generated quad-tree\n    return tuple(qtree)", "response": "This function generates a 2 - dimensional quadtree - like structure from a list of control points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the minimum bounding box of the control points.", "response": "def evaluate_bounding_box(ctrlpts):\n    \"\"\" Computes the minimum bounding box of the point set.\n\n    The (minimum) bounding box is the smallest enclosure in which all the input points lie.\n\n    :param ctrlpts: points\n    :type ctrlpts: list, tuple\n    :return: bounding box in the format [min, max]\n    :rtype: tuple\n    \"\"\"\n    # Estimate dimension from the first element of the control points\n    dimension = len(ctrlpts[0])\n\n    # Evaluate bounding box\n    bbmin = [float('inf') for _ in range(0, dimension)]\n    bbmax = [float('-inf') for _ in range(0, dimension)]\n    for cpt in ctrlpts:\n        for i, arr in enumerate(zip(cpt, bbmin)):\n            if arr[0] < arr[1]:\n                bbmin[i] = arr[0]\n        for i, arr in enumerate(zip(cpt, bbmax)):\n            if arr[0] > arr[1]:\n                bbmax[i] = arr[0]\n\n    return tuple(bbmin), tuple(bbmax)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_triangle_mesh(points, size_u, size_v, **kwargs):\n    def fix_numbering(vertex_list, triangle_list):\n        # Initialize variables\n        final_vertices = []\n\n        # Get all vertices inside the triangle list\n        tri_vertex_ids = []\n        for tri in triangle_list:\n            for td in tri.data:\n                if td not in tri_vertex_ids:\n                    tri_vertex_ids.append(td)\n\n        # Find vertices used in triangles\n        seen_vertices = []\n        for vertex in vertex_list:\n            if vertex.id in tri_vertex_ids and vertex.id not in seen_vertices:\n                final_vertices.append(vertex)\n                seen_vertices.append(vertex.id)\n\n        # Fix vertex numbering (automatically fixes triangle vertex numbering)\n        vert_new_id = 0\n        for vertex in final_vertices:\n            vertex.id = vert_new_id\n            vert_new_id += 1\n\n        return final_vertices, triangle_list\n\n    # Vertex spacing for triangulation\n    vertex_spacing = kwargs.get('vertex_spacing', 1)  # defines the size of the triangles\n    trim_curves = kwargs.get('trims', [])\n\n    # Tessellation algorithm\n    tsl_func = kwargs.get('tessellate_func')\n    if tsl_func is None:\n        tsl_func = surface_tessellate\n    tsl_args = kwargs.get('tessellate_args', dict())\n\n    # Numbering\n    vrt_idx = 0  # vertex index numbering start\n    tri_idx = 0  # triangle index numbering start\n\n    # Variable initialization\n    u_jump = (1.0 / float(size_u - 1)) * vertex_spacing  # for computing vertex parametric u value\n    v_jump = (1.0 / float(size_v - 1)) * vertex_spacing  # for computing vertex parametric v value\n    varr_size_u = int(round((float(size_u) / float(vertex_spacing)) + 10e-8))  # vertex array size on the u-direction\n    varr_size_v = int(round((float(size_v) / float(vertex_spacing)) + 10e-8))  # vertex array size on the v-direction\n\n    # Generate vertices directly from input points (preliminary evaluation)\n    vertices = [Vertex() for _ in range(varr_size_v * varr_size_u)]\n    u = 0.0\n    for i in range(0, size_u, vertex_spacing):\n        v = 0.0\n        for j in range(0, size_v, vertex_spacing):\n            idx = j + (i * size_v)\n            vertices[vrt_idx].id = vrt_idx\n            vertices[vrt_idx].data = points[idx]\n            vertices[vrt_idx].uv = [u, v]\n            vrt_idx += 1\n            v += v_jump\n        u += u_jump\n\n    #\n    # Organization of vertices in a quad element on the parametric space:\n    #\n    # v4      v3\n    # o-------o         i\n    # |       |          |\n    # |       |          |\n    # |       |          |_ _ _\n    # o-------o                 j\n    # v1      v2\n    #\n\n    # Generate triangles and final vertices\n    triangles = []\n    for i in range(varr_size_u - 1):\n        for j in range(varr_size_v - 1):\n            # Find vertex indices for a quad element\n            vertex1 = vertices[j + (i * varr_size_v)]\n            vertex2 = vertices[j + ((i + 1) * varr_size_v)]\n            vertex3 = vertices[j + 1 + ((i + 1) * varr_size_v)]\n            vertex4 = vertices[j + 1 + (i * varr_size_v)]\n\n            # Call tessellation function\n            vlst, tlst = tsl_func(vertex1, vertex2, vertex3, vertex4, vrt_idx, tri_idx, trim_curves, tsl_args)\n\n            # Add tessellation results to the return lists\n            vertices += vlst\n            triangles += tlst\n\n            # Increment index values\n            vrt_idx += len(vlst)\n            tri_idx += len(tlst)\n\n    # Fix vertex and triangle numbering (ID values)\n    vertices, triangles = fix_numbering(vertices, triangles)\n\n    return vertices, triangles", "response": "Generates a triangular mesh from an array of points."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef polygon_triangulate(tri_idx, *args):\n    # Initialize variables\n    tidx = 0\n    triangles = []\n\n    # Generate triangles\n    for idx in range(1, len(args) - 1):\n        tri = Triangle()\n        tri.id = tri_idx + tidx\n        tri.add_vertex(args[0], args[idx], args[idx + 1])\n        triangles.append(tri)\n        tidx += 1\n\n    # Return generated triangles\n    return triangles", "response": "Triangulates a monotone polygon defined by a list of vertices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a mesh of quadrilateral elements.", "response": "def make_quad_mesh(points, size_u, size_v):\n    \"\"\" Generates a mesh of quadrilateral elements.\n\n    :param points: list of points\n    :type points: list, tuple\n    :param size_u: number of points on the u-direction (column)\n    :type size_u: int\n    :param size_v: number of points on the v-direction (row)\n    :type size_v: int\n    :return: a tuple containing lists of vertices and quads\n    :rtype: tuple\n    \"\"\"\n    # Numbering\n    vertex_idx = 0\n    quad_idx = 0\n\n    # Generate vertices\n    vertices = []\n    for pt in points:\n        vrt = Vertex(*pt, id=vertex_idx)\n        vertices.append(vrt)\n        vertex_idx += 1\n\n    # Generate quads\n    quads = []\n    for i in range(0, size_u - 1):\n        for j in range(0, size_v - 1):\n            v1 = vertices[j + (size_v * i)]\n            v2 = vertices[j + (size_v * (i + 1))]\n            v3 = vertices[j + 1 + (size_v * (i + 1))]\n            v4 = vertices[j + 1 + (size_v * i)]\n            qd = Quad(v1, v2, v3, v4, id=quad_idx)\n            quads.append(qd)\n            quad_idx += 1\n\n    return vertices, quads"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef surface_trim_tessellate(v1, v2, v3, v4, vidx, tidx, trims, tessellate_args):\n    # Tolerance value\n    tol = 10e-8\n    tols = tol ** 2\n    vtol = ((tols, tols), (-tols, tols), (-tols, -tols), (tols, -tols))\n\n    # Start processing vertices\n    vertices = [v1, v2, v3, v4]\n    for idx in range(len(vertices)):\n        for trim in trims:\n            cf = 1 if trim.opt['reversed'] else -1\n            uv = [p + (cf * t) for p, t in zip(vertices[idx].uv, vtol[idx])]\n            if linalg.wn_poly(uv, trim.evalpts):\n                if trim.opt['reversed']:\n                    if vertices[idx].opt_get('trim') is None or not vertices[idx].opt_get('trim'):\n                        vertices[idx].inside = False\n                        vertices[idx].opt = ['no_trim', True]  # always triangulate\n                else:\n                    vertices[idx].inside = True\n                    vertices[idx].opt = ['trim', True]  # always trim\n            else:\n                if trim.opt['reversed']:\n                    if vertices[idx].opt_get('no_trim') is None or not vertices[idx].opt_get('no_trim'):\n                        vertices[idx].inside = True\n\n    # If all vertices are marked as inside, then don't generate triangles\n    vertices_inside = [v1.inside, v2.inside, v3.inside, v4.inside]\n    if all(vertices_inside):\n        return [], []\n\n    # Generate edges as rays\n    edge1 = ray.Ray(v1.uv, v2.uv)\n    edge2 = ray.Ray(v2.uv, v3.uv)\n    edge3 = ray.Ray(v3.uv, v4.uv)\n    edge4 = ray.Ray(v4.uv, v1.uv)\n\n    # Put all edge rays to a list\n    edges = [edge1, edge2, edge3, edge4]\n\n    # List of intersections\n    intersections = []\n\n    # Loop all trim curves\n    for trim in trims:\n        pts = trim.evalpts\n        for idx in range(len(pts) - 1):\n            # Generate a ray from trim curve's evaluated points\n            trim_ray = ray.Ray(pts[idx], pts[idx + 1])\n\n            # Intersection test of the trim curve's ray with all edges\n            for idx2 in range(len(edges)):\n                t1, t2, status = ray.intersect(edges[idx2], trim_ray)\n                if status == ray.RayIntersection.INTERSECT:\n                    if 0.0 - tol < t1 < 1.0 + tol and 0.0 - tol < t2 < 1.0 + tol:\n                        intersections.append([idx2, t1, edges[idx2].eval(t=t1)])\n\n    # Add first vertex to the end of the list\n    vertices.append(v1)\n\n    # Local vertex numbering index\n    nvi = 0\n\n    # Process vertices and intersections\n    tris_vertices = []\n    for idx in range(0, len(vertices) - 1):\n        # If two consecutively-ordered vertices are inside the trim, there should be no intersection\n        if vertices[idx].inside and vertices[idx + 1].inside:\n            continue\n\n        # If current vertex is not inside the trim, add it to the vertex list\n        if not vertices[idx].inside:\n            tris_vertices.append(vertices[idx])\n\n        # If next vertex is inside the trim, there might be an intersection\n        if (not vertices[idx].inside and vertices[idx + 1].inside) or \\\n                (vertices[idx].inside and not vertices[idx + 1].inside):\n            # Try to find all intersections (multiple intersections are possible)\n            isects = []\n            for isect in intersections:\n                if isect[0] == idx:\n                    isects.append(isect)\n\n            if isects:\n                # Find minimum t value and therefore minimum uv value of the intersection\n                t_min = 1.0 + tol\n                uv_min = []\n                for isect in isects:\n                    if isect[1] < t_min:\n                        t_min = isect[1]\n                        uv_min = isect[2]\n\n                # Check uv for min max\n                for pi in range(2):\n                    if uv_min[pi] - tol <= 0.0 <= uv_min[pi] + tol:\n                        uv_min[pi] = 0.0\n                    elif uv_min[pi] - tol <= 1.0 <= uv_min[pi] + tol:\n                        uv_min[pi] = 1.0\n\n                # Create a vertex with the minimum uv value\n                vert = Vertex()\n                vert.id = vidx + nvi\n                vert.uv = uv_min\n\n                # Add to lists\n                tris_vertices.append(vert)\n\n                # Increment local vertex numbering index\n                nvi += 1\n\n    # Triangulate vertices\n    tris = polygon_triangulate(tidx, *tris_vertices)\n\n    # Check again if the barycentric coordinates of the triangles are inside\n    for idx in range(len(tris)):\n        tri_center = linalg.triangle_center(tris[idx], uv=True)\n        for trim in trims:\n            if linalg.wn_poly(tri_center, trim.evalpts):\n                if trim.opt['reversed']:\n                    if tris[idx].opt_get('trim') is None or not tris[idx].opt_get('trim'):\n                        tris[idx].inside = False\n                        tris[idx].opt = ['no_trim', True]  # always triangulate\n                else:\n                    tris[idx].inside = True\n                    tris[idx].opt = ['trim', True]  # always trim\n            else:\n                if trim.opt['reversed']:\n                    if tris[idx].opt_get('no_trim') is None or not tris[idx].opt_get('no_trim'):\n                        tris[idx].inside = True\n\n    # Extract triangles which are not inside the trim\n    tris_final = []\n    for tri in tris:\n        if not tri.inside:\n            tris_final.append(tri)\n\n    return tris_vertices, tris_final", "response": "This function is used to make a triangular tessellation of a set of vertices in a set of trimmed surfaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to one connection", "response": "def target_message(conn, payload):\r\n    \"\"\"\r\n    Distibuted payload (message) to one connection\r\n    :param conn: connection\r\n    :param payload: payload(json dumpable)\r\n    :return:\r\n    \"\"\"\r\n    try:\r\n        yield from conn.send(json.dumps(payload))\r\n    except Exception as e:\r\n        logger.debug('could not send', e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message to all connected ws", "response": "def fanout_message(connections, payload):\r\n    \"\"\"\r\n    Distributes payload (message) to all connected ws clients\r\n    \"\"\"\r\n    for conn in connections:\r\n        try:\r\n            yield from conn.send(json.dumps(payload))\r\n        except Exception as e:\r\n            logger.debug('could not send', e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator that yields messages that the user has gone online.", "response": "def gone_online(stream):\r\n    \"\"\"\r\n    Distributes the users online status to everyone he has dialog with\r\n    \"\"\"\r\n    while True:\r\n        packet = yield from stream.get()\r\n        session_id = packet.get('session_key')\r\n        if session_id:\r\n            user_owner = get_user_from_session(session_id)\r\n            if user_owner:\r\n                logger.debug('User ' + user_owner.username + ' gone online')\r\n                # find all connections including user_owner as opponent,\r\n                # send them a message that the user has gone online\r\n                online_opponents = list(filter(lambda x: x[1] == user_owner.username, ws_connections))\r\n                online_opponents_sockets = [ws_connections[i] for i in online_opponents]\r\n                yield from fanout_message(online_opponents_sockets,\r\n                                          {'type': 'gone-online', 'usernames': [user_owner.username]})\r\n            else:\r\n                pass  # invalid session id\r\n        else:\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles new messages from the chat.", "response": "def new_messages_handler(stream):\r\n    \"\"\"\r\n    Saves a new chat message to db and distributes msg to connected users\r\n    \"\"\"\r\n    # TODO: handle no user found exception\r\n    while True:\r\n        packet = yield from stream.get()\r\n        session_id = packet.get('session_key')\r\n        msg = packet.get('message')\r\n        username_opponent = packet.get('username')\r\n        if session_id and msg and username_opponent:\r\n            user_owner = get_user_from_session(session_id)\r\n            if user_owner:\r\n                user_opponent = get_user_model().objects.get(username=username_opponent)\r\n                dialog = get_dialogs_with_user(user_owner, user_opponent)\r\n                if len(dialog) > 0:\r\n                    # Save the message\r\n                    msg = models.Message.objects.create(\r\n                        dialog=dialog[0],\r\n                        sender=user_owner,\r\n                        text=packet['message'],\r\n                        read=False\r\n                    )\r\n                    packet['created'] = msg.get_formatted_create_datetime()\r\n                    packet['sender_name'] = msg.sender.username\r\n                    packet['message_id'] = msg.id\r\n\r\n                    # Send the message\r\n                    connections = []\r\n                    # Find socket of the user which sent the message\r\n                    if (user_owner.username, user_opponent.username) in ws_connections:\r\n                        connections.append(ws_connections[(user_owner.username, user_opponent.username)])\r\n                    # Find socket of the opponent\r\n                    if (user_opponent.username, user_owner.username) in ws_connections:\r\n                        connections.append(ws_connections[(user_opponent.username, user_owner.username)])\r\n                    else:\r\n                        # Find sockets of people who the opponent is talking with\r\n                        opponent_connections = list(filter(lambda x: x[0] == user_opponent.username, ws_connections))\r\n                        opponent_connections_sockets = [ws_connections[i] for i in opponent_connections]\r\n                        connections.extend(opponent_connections_sockets)\r\n\r\n                    yield from fanout_message(connections, packet)\r\n                else:\r\n                    pass  # no dialog found\r\n            else:\r\n                pass  # no user_owner\r\n        else:\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef users_changed_handler(stream):\r\n    while True:\r\n        yield from stream.get()\r\n\r\n        # Get list list of current active users\r\n        users = [\r\n            {'username': username, 'uuid': uuid_str}\r\n            for username, uuid_str in ws_connections.values()\r\n        ]\r\n\r\n        # Make packet with list of new users (sorted by username)\r\n        packet = {\r\n            'type': 'users-changed',\r\n            'value': sorted(users, key=lambda i: i['username'])\r\n        }\r\n        logger.debug(packet)\r\n        yield from fanout_message(ws_connections.keys(), packet)", "response": "Handles the users - changed event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_typing_handler(stream):\r\n    while True:\r\n        packet = yield from stream.get()\r\n        session_id = packet.get('session_key')\r\n        user_opponent = packet.get('username')\r\n        typing = packet.get('typing')\r\n        if session_id and user_opponent and typing is not None:\r\n            user_owner = get_user_from_session(session_id)\r\n            if user_owner:\r\n                opponent_socket = ws_connections.get((user_opponent, user_owner.username))\r\n                if typing and opponent_socket:\r\n                    yield from target_message(opponent_socket,\r\n                                              {'type': 'opponent-typing', 'username': user_opponent})\r\n            else:\r\n                pass  # invalid session id\r\n        else:\r\n            pass", "response": "Returns a list of messages that are typing if the user is typing message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a message from the client.", "response": "def read_message_handler(stream):\r\n    \"\"\"\r\n    Send message to user if the opponent has read the message\r\n    \"\"\"\r\n    while True:\r\n        packet = yield from stream.get()\r\n        session_id = packet.get('session_key')\r\n        user_opponent = packet.get('username')\r\n        message_id = packet.get('message_id')\r\n        if session_id and user_opponent and message_id is not None:\r\n            user_owner = get_user_from_session(session_id)\r\n            if user_owner:\r\n                message = models.Message.objects.filter(id=message_id).first()\r\n                if message:\r\n                    message.read = True\r\n                    message.save()\r\n                    logger.debug('Message ' + str(message_id) + ' is now read')\r\n                    opponent_socket = ws_connections.get((user_opponent, user_owner.username))\r\n                    if opponent_socket:\r\n                        yield from target_message(opponent_socket,\r\n                                                  {'type': 'opponent-read-message',\r\n                                                   'username': user_opponent, 'message_id': message_id})\r\n                else:\r\n                    pass  # message not found\r\n            else:\r\n                pass  # invalid session id\r\n        else:\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main_handler(websocket, path):\r\n\r\n    # Get users name from the path\r\n    path = path.split('/')\r\n    username = path[2]\r\n    session_id = path[1]\r\n    user_owner = get_user_from_session(session_id)\r\n    if user_owner:\r\n        user_owner = user_owner.username\r\n        # Persist users connection, associate user w/a unique ID\r\n        ws_connections[(user_owner, username)] = websocket\r\n\r\n        # While the websocket is open, listen for incoming messages/events\r\n        # if unable to listening for messages/events, then disconnect the client\r\n        try:\r\n            while websocket.open:\r\n                data = yield from websocket.recv()\r\n                if not data:\r\n                    continue\r\n                logger.debug(data)\r\n                try:\r\n                    yield from router.MessageRouter(data)()\r\n                except Exception as e:\r\n                    logger.error('could not route msg', e)\r\n\r\n        except websockets.exceptions.InvalidState:  # User disconnected\r\n            pass\r\n        finally:\r\n            del ws_connections[(user_owner, username)]\r\n    else:\r\n        logger.info(\"Got invalid session_id attempt to connect \" + session_id)", "response": "This is the main websocket handler that handles all the messages and routes them to the proper queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the user from current User model using the passed session_key", "response": "def get_user_from_session(session_key):\n    \"\"\"\n    Gets the user from current User model using the passed session_key\n    :param session_key: django.contrib.sessions.models.Session - session_key\n    :return: User instance or None if not found\n    \"\"\"\n    session = Session.objects.get(session_key=session_key)\n    session_data = session.get_decoded()\n    uid = session_data.get('_auth_user_id')\n    user = get_user_model().objects.filter(id=uid).first()  # get object or none\n    return user"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dialogs_with_user(user_1, user_2):\n    return Dialog.objects.filter(\n        Q(owner=user_1, opponent=user_2) | Q(opponent=user_1, owner=user_2))", "response": "get the dialog between user_1 and user_2"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for any word in target_words.", "response": "def anyword_substring_search_inner(query_word, target_words):\n    \"\"\" return True if ANY target_word matches a query_word\n    \"\"\"\n\n    for target_word in target_words:\n\n        if(target_word.startswith(query_word)):\n            return query_word\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef anyword_substring_search(target_words, query_words):\n\n    matches_required = len(query_words)\n    matches_found = 0\n\n    for query_word in query_words:\n\n        reply = anyword_substring_search_inner(query_word, target_words)\n\n        if reply is not False:\n\n            matches_found += 1\n\n        else:\n            # this is imp, otherwise will keep checking\n            # when the final answer is already False\n            return False\n\n    if(matches_found == matches_required):\n        return True\n    else:\n        return False", "response": "Search for any word in query_words in target_words."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for a substring in a list of strings", "response": "def substring_search(query, list_of_strings, limit_results=DEFAULT_LIMIT):\n    \"\"\" main function to call for searching\n    \"\"\"\n\n    matching = []\n\n    query_words = query.split(' ')\n\n    # sort by longest word (higest probability of not finding a match)\n    query_words.sort(key=len, reverse=True)\n\n    counter = 0\n\n    for s in list_of_strings:\n\n        target_words = s.split(' ')\n\n        # the anyword searching function is separate\n        if(anyword_substring_search(target_words, query_words)):\n            matching.append(s)\n\n            # limit results\n            counter += 1\n            if(counter == limit_results):\n                break\n\n    return matching"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_people_by_bio(query, limit_results=DEFAULT_LIMIT,\n                         index=['onename_people_index']):\n    \"\"\" queries lucene index to find a nearest match, output is profile username\n    \"\"\"\n\n    from pyes import QueryStringQuery, ES\n    conn = ES()\n\n    q = QueryStringQuery(query,\n                         search_fields=['username', 'profile_bio'],\n                         default_operator='and')\n\n    results = conn.search(query=q, size=20, indices=index)\n    count = conn.count(query=q)\n    count = count.count\n\n    # having 'or' gives more results but results quality goes down\n    if(count == 0):\n\n        q = QueryStringQuery(query,\n                             search_fields=['username', 'profile_bio'],\n                             default_operator='or')\n\n        results = conn.search(query=q, size=20, indices=index)\n\n    results_list = []\n    counter = 0\n\n    for profile in results:\n\n        username = profile['username']\n        results_list.append(username)\n\n        counter += 1\n\n        if(counter == limit_results):\n            break\n\n    return results_list", "response": "searches lucene index to find a nearest match"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef order_search_results(query, search_results):\n\n    results = search_results\n\n    results_names = []\n    old_query = query\n    query = query.split(' ')\n\n    first_word = ''\n    second_word = ''\n    third_word = ''\n\n    if(len(query) < 2):\n        first_word = old_query\n    else:\n        first_word = query[0]\n        second_word = query[1]\n\n        if(len(query) > 2):\n            third_word = query[2]\n\n    # save results for multiple passes\n    results_second = []\n    results_third = []\n\n    for result in results:\n\n        result_list = result.split(' ')\n\n        try:\n            if(result_list[0].startswith(first_word)):\n                results_names.append(result)\n            else:\n                results_second.append(result)\n        except:\n            results_second.append(result)\n\n    for result in results_second:\n\n        result_list = result.split(' ')\n\n        try:\n            if(result_list[1].startswith(first_word)):\n                results_names.append(result)\n            else:\n                results_third.append(result)\n        except:\n            results_third.append(result)\n\n    # results are either in results_names (filtered)\n    # or unprocessed in results_third (last pass)\n    return results_names + results_third", "response": "order of results in the search_results list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a hash over data for immutable storage.", "response": "def get_data_hash(data_txt):\n    \"\"\"\n    Generate a hash over data for immutable storage.\n    Return the hex string.\n    \"\"\"\n    h = hashlib.sha256()\n    h.update(data_txt)\n    return h.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_zonefile( zonefile_str, value_hash ):\n    zonefile_hash = get_zonefile_data_hash( zonefile_str )\n    if zonefile_hash != value_hash:\n        log.debug(\"Zonefile hash mismatch: expected %s, got %s\" % (value_hash, zonefile_hash))\n        return False \n\n    return True", "response": "Verify that a zonefile is a serialized string and that it has the given hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlocks the global health info table.", "response": "def atlas_peer_table_lock():\n    \"\"\"\n    Lock the global health info table.\n    Return the table.\n    \"\"\"\n    global PEER_TABLE_LOCK, PEER_TABLE, PEER_TABLE_LOCK_HOLDER, PEER_TABLE_LOCK_TRACEBACK\n\n    if PEER_TABLE_LOCK_HOLDER is not None:\n        assert PEER_TABLE_LOCK_HOLDER != threading.current_thread(), \"DEADLOCK\"\n        # log.warning(\"\\n\\nPossible contention: lock from %s (but held by %s at)\\n%s\\n\\n\" % (threading.current_thread(), PEER_TABLE_LOCK_HOLDER, PEER_TABLE_LOCK_TRACEBACK))\n\n    PEER_TABLE_LOCK.acquire()\n    PEER_TABLE_LOCK_HOLDER = threading.current_thread()\n    PEER_TABLE_LOCK_TRACEBACK = traceback.format_stack()\n\n    # log.debug(\"\\n\\npeer table lock held by %s at \\n%s\\n\\n\" % (PEER_TABLE_LOCK_HOLDER, PEER_TABLE_LOCK_TRACEBACK))\n    return PEER_TABLE"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nunlocking the global health info table.", "response": "def atlas_peer_table_unlock():\n    \"\"\"\n    Unlock the global health info table.\n    \"\"\"\n    global PEER_TABLE_LOCK, PEER_TABLE_LOCK_HOLDER, PEER_TABLE_LOCK_TRACEBACK\n    \n    try:\n        assert PEER_TABLE_LOCK_HOLDER == threading.current_thread()\n    except:\n        log.error(\"Locked by %s, unlocked by %s\" % (PEER_TABLE_LOCK_HOLDER, threading.current_thread()))\n        log.error(\"Holder locked from:\\n%s\" % \"\".join(PEER_TABLE_LOCK_TRACEBACK))\n        log.error(\"Errant thread unlocked from:\\n%s\" % \"\".join(traceback.format_stack()))\n        os.abort()\n\n    # log.debug(\"\\n\\npeer table lock released by %s at \\n%s\\n\\n\" % (PEER_TABLE_LOCK_HOLDER, PEER_TABLE_LOCK_TRACEBACK))\n    PEER_TABLE_LOCK_HOLDER = None\n    PEER_TABLE_LOCK_TRACEBACK = None\n    PEER_TABLE_LOCK.release()\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflipping the bits in the inventory vector with the appropriate bits in the inventory vector.", "response": "def atlas_inventory_flip_zonefile_bits( inv_vec, bit_indexes, operation ):\n    \"\"\"\n    Given a list of bit indexes (bit_indexes), set or clear the\n    appropriate bits in the inventory vector (inv_vec).\n    If the bit index is beyond the length of inv_vec, \n    then expand inv_vec to accomodate it.\n\n    If operation is True, then set the bits.\n    If operation is False, then clear the bits\n\n    Return the new inv_vec\n    \"\"\"\n    inv_list = list(inv_vec)\n\n    max_byte_index = max(bit_indexes) / 8 + 1\n    if len(inv_list) <= max_byte_index:\n        inv_list += ['\\0'] * (max_byte_index - len(inv_list))\n\n    for bit_index in bit_indexes:\n        byte_index = bit_index / 8\n        bit_index = 7 - (bit_index % 8)\n        \n        zfbits = ord(inv_list[byte_index])\n\n        if operation:\n            zfbits = zfbits | (1 << bit_index)\n        else:\n            zfbits = zfbits & ~(1 << bit_index)\n\n        inv_list[byte_index] = chr(zfbits)\n\n    return \"\".join(inv_list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrow factory for the atlasdb row types", "response": "def atlasdb_row_factory( cursor, row ):\n    \"\"\"\n    row factory\n    * convert known booleans to booleans\n    \"\"\"\n    d = {}\n    for idx, col in enumerate( cursor.description ):\n        if col[0] in [\"present\", \"tried_storage\"]:\n            if row[idx] == 0:\n                d[col[0]] = False\n            elif row[idx] == 1:\n                d[col[0]] = True\n            else:\n                raise Exception(\"Invalid value for '%s': %s\" % (col[0], row[idx]))\n\n        else:\n            d[col[0]] = row[idx]\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn a query into a string for printing.", "response": "def atlasdb_format_query( query, values ):\n    \"\"\"\n    Turn a query into a string for printing.\n    Useful for debugging.\n    \"\"\"\n    return \"\".join( [\"%s %s\" % (frag, \"'%s'\" % val if type(val) in [str, unicode] else val) for (frag, val) in zip(query.split(\"?\"), values + (\"\",))] )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening the atlas db.", "response": "def atlasdb_open( path ):\n    \"\"\"\n    Open the atlas db.\n    Return a connection.\n    Return None if it doesn't exist\n    \"\"\"\n    if not os.path.exists(path):\n        log.debug(\"Atlas DB doesn't exist at %s\" % path)\n        return None\n\n    con = sqlite3.connect( path, isolation_level=None )\n    con.row_factory = atlasdb_row_factory\n    return con"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a zonefile to the database.", "response": "def atlasdb_add_zonefile_info( name, zonefile_hash, txid, present, tried_storage, block_height, con=None, path=None ):\n    \"\"\"\n    Add a zonefile to the database.\n    Mark it as present or absent.\n    Keep our in-RAM inventory vector up-to-date\n    \"\"\"\n    global ZONEFILE_INV, NUM_ZONEFILES, ZONEFILE_INV_LOCK\n\n    with AtlasDBOpen( con=con, path=path ) as dbcon:\n        with ZONEFILE_INV_LOCK:\n            # need to lock here since someone could call atlasdb_cache_zonefile_info\n            if present:\n                present = 1\n            else:\n                present = 0\n\n            if tried_storage:\n                tried_storage = 1\n            else:\n                tried_storage = 0\n\n            sql = \"UPDATE zonefiles SET name = ?, zonefile_hash = ?, txid = ?, present = ?, tried_storage = ?, block_height = ? WHERE txid = ?;\"\n            args = (name, zonefile_hash, txid, present, tried_storage, block_height, txid )\n\n            cur = dbcon.cursor()\n            update_res = atlasdb_query_execute( cur, sql, args )\n            dbcon.commit()\n\n            if update_res.rowcount == 0:\n                sql = \"INSERT OR IGNORE INTO zonefiles (name, zonefile_hash, txid, present, tried_storage, block_height) VALUES (?,?,?,?,?,?);\"\n                args = (name, zonefile_hash, txid, present, tried_storage, block_height)\n            \n                cur = dbcon.cursor()\n                atlasdb_query_execute( cur, sql, args )\n                dbcon.commit()\n\n            # keep in-RAM zonefile inv coherent\n            zfbits = atlasdb_get_zonefile_bits( zonefile_hash, con=dbcon, path=path )\n\n            inv_vec = None\n            if ZONEFILE_INV is None:\n                inv_vec = \"\"\n            else:\n                inv_vec = ZONEFILE_INV[:]\n\n            ZONEFILE_INV = atlas_inventory_flip_zonefile_bits( inv_vec, zfbits, present )\n            log.debug('Set {} ({}) to {}'.format(zonefile_hash, ','.join(str(i) for i in zfbits), present))\n\n            # keep in-RAM zonefile count coherent\n            NUM_ZONEFILES = atlasdb_zonefile_inv_length( con=dbcon, path=path )\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the highest block height in the atlas db", "response": "def atlasdb_get_lastblock( con=None, path=None ):\n    \"\"\"\n    Get the highest block height in the atlas db\n    \"\"\"\n    row = None\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT MAX(block_height) FROM zonefiles;\"\n        args = ()\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        row = {}\n        for r in res:\n            row.update(r)\n            break\n\n    return row['MAX(block_height)']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a specific zonefile from the database.", "response": "def atlasdb_get_zonefile( zonefile_hash, con=None, path=None ):\n    \"\"\"\n    Look up all information on this zonefile.\n    Returns {'zonefile_hash': ..., 'indexes': [...], etc}\n    Zonefile information will be ordered by inv_index\n    \"\"\"\n    ret = None\n\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT * FROM zonefiles WHERE zonefile_hash = ? ORDER BY inv_index;\"\n        args = (zonefile_hash,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        ret = {\n            'zonefile_hash': zonefile_hash,\n            'indexes': [],\n            'block_heights': [],\n            'present': False,\n            'tried_storage': False\n        }\n\n        for zfinfo in res:\n            ret['indexes'].append( zfinfo['inv_index'] )\n            ret['block_heights'].append( zfinfo['block_height'] )\n            ret['present'] = ret['present'] or zfinfo['present']\n            ret['tried_storage'] = ret['tried_storage'] or zfinfo['tried_storage']\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef atlasdb_get_zonefiles_by_block( from_block, to_block, offset, count, name=None, con=None, path=None ):\n    ret = None\n\n    if count > 100:\n        return {'error' : 'Count must be less than 100'}\n\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = 'SELECT name,zonefile_hash,txid,block_height,inv_index FROM zonefiles WHERE block_height >= ? AND block_height <= ?'\n        args = (from_block, to_block)\n\n        if name:\n            sql += ' AND name = ?'\n            args += (name,)\n\n        sql += 'ORDER BY inv_index LIMIT ? OFFSET ?;'\n        args += (count, offset)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        ret = []\n\n        for zfinfo in res:\n            ret.append({\n                'name' : zfinfo['name'],\n                'zonefile_hash' : zfinfo['zonefile_hash'],\n                'block_height' : zfinfo['block_height'],\n                'txid' : zfinfo['txid'],\n                'inv_index': zfinfo['inv_index'],\n            })\n\n    return ret", "response": "Get a list of all zonefiles in a block range."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a zonefile by txid", "response": "def atlasdb_get_zonefile_by_txid( txid, con=None, path=None ):\n    \"\"\"\n    Look up a zonefile by txid\n    Returns {'zonefile_hash': ..., 'name': ..., etc.}\n    Returns None if not found\n    \"\"\"\n    ret = None\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT * FROM zonefiles WHERE txid = ?;\"\n        args = (txid,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        for zfinfo in res:\n            ret = {}\n            ret.update(zfinfo)\n            break\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a sequence of zone file records by name optionally up to a specific zonefile index", "response": "def atlasdb_get_zonefiles_by_name(name, max_index=None, con=None, path=None):\n    \"\"\"\n    Look up the sequence of zone file records by name, optionally up to a specific zonefile index\n    Returns [{'zonefile_hash': ..., 'txid': ..., 'inv_index': ..., 'block_height': ..., 'present': ..., 'tried_storage': ...}], in blockchain order\n    \"\"\"\n    ret = []\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = 'SELECT * FROM zonefiles WHERE name = ? ORDER BY inv_index'\n        args = (name,)\n\n        if max_index:\n            sql += ' AND inv_index <= ?'\n            args += (max_index,)\n\n        sql += ';'\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute(cur, sql, args)\n\n        for zfinfo in res:\n            row = {}\n            row.update(zfinfo)\n            ret.append(row)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef atlasdb_get_zonefiles_missing_count_by_name(name, max_index=None, indexes_exclude=[], con=None, path=None):\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n        sql = 'SELECT COUNT(*) FROM zonefiles WHERE name = ? AND present = 0 {} {};'.format(\n                'AND inv_index <= ?' if max_index is not None else '',\n                'AND inv_index NOT IN ({})'.format(','.join([str(int(i)) for i in indexes_exclude])) if len(indexes_exclude) > 0 else ''\n                )\n\n        args = (name,)\n        if max_index is not None:\n            args += (max_index,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute(cur, sql, args)\n        for row in res:\n            return row['COUNT(*)']", "response": "Get the number of missing zone files for a particular name optionally up to a maximum zone file index and optionally omitting particular zone files in the count."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef atlasdb_get_zonefiles_by_hash(zonefile_hash, block_height=None, con=None, path=None):\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = 'SELECT * FROM zonefiles WHERE zonefile_hash = ?'\n        args = (zonefile_hash,)\n\n        if block_height:\n            sql += ' AND block_height = ?'\n            args += (block_height,)\n\n        sql += ' ORDER BY inv_index;'\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute(cur, sql, args)\n\n        ret = []\n        for zfinfo in res:\n            row = {}\n            row.update(zfinfo)\n            ret.append(row)\n\n        if len(ret) == 0:\n            return None\n\n        return ret", "response": "Get all zone files with the given hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef atlasdb_set_zonefile_present( zonefile_hash, present, con=None, path=None ):\n    global ZONEFILE_INV, ZONEFILE_INV_LOCK\n\n    was_present = None\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n        with ZONEFILE_INV_LOCK:\n            # need to lock here in case someone tries to call atlasdb_cache_zonefile_info\n            if present:\n                present = 1\n            else:\n                present = 0\n\n            sql = \"UPDATE zonefiles SET present = ? WHERE zonefile_hash = ?;\"\n            args = (present, zonefile_hash)\n\n            cur = dbcon.cursor()\n            res = atlasdb_query_execute( cur, sql, args )\n            dbcon.commit()\n        \n            zfbits = atlasdb_get_zonefile_bits( zonefile_hash, con=dbcon, path=path )\n            \n            inv_vec = None\n            if ZONEFILE_INV is None:\n                inv_vec = \"\"\n            else:\n                inv_vec = ZONEFILE_INV[:]\n\n            # did we know about this?\n            was_present = atlas_inventory_test_zonefile_bits( inv_vec, zfbits )\n\n            # keep our inventory vector coherent.\n            ZONEFILE_INV = atlas_inventory_flip_zonefile_bits( inv_vec, zfbits, present )\n            log.debug('Set {} ({}) to {} (was_present={})'.format(zonefile_hash, ','.join(str(i) for i in zfbits), present, was_present))\n\n    return was_present", "response": "Set the present flag for a zone file. Returns True if the zone file was already present False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlasdb_set_zonefile_tried_storage( zonefile_hash, tried_storage, con=None, path=None ):\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n        if tried_storage:\n            tried_storage = 1\n        else:\n            tried_storage = 0\n\n        sql = \"UPDATE zonefiles SET tried_storage = ? WHERE zonefile_hash = ?;\"\n        args = (tried_storage, zonefile_hash)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n        dbcon.commit()\n\n    return True", "response": "Set the requested zonefile as tried_storage"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets the tried_storage field of zonefiles to 0.", "response": "def atlasdb_reset_zonefile_tried_storage( con=None, path=None ):\n    \"\"\"\n    For zonefiles that we don't have, re-attempt to fetch them from storage.\n    \"\"\"\n\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"UPDATE zonefiles SET tried_storage = ? WHERE present = ?;\"\n        args = (0, 0)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n        dbcon.commit()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef atlasdb_cache_zonefile_info( con=None, path=None ):\n    global ZONEFILE_INV, NUM_ZONEFILES, ZONEFILE_INV_LOCK\n    \n    inv = None\n    with ZONEFILE_INV_LOCK:\n        inv_len = atlasdb_zonefile_inv_length( con=con, path=path )\n        inv = atlas_make_zonefile_inventory( 0, inv_len, con=con, path=path )\n\n        ZONEFILE_INV = inv\n        NUM_ZONEFILES = inv_len\n\n    return inv", "response": "Load up and cache our zonefile inventory from the database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the bit field of the zonefile inventory that a given zonefile hash correspond to? Return the list of bit fields in the bit field.", "response": "def atlasdb_get_zonefile_bits( zonefile_hash, con=None, path=None ):\n    \"\"\"\n    What bit(s) in a zonefile inventory does a zonefile hash correspond to?\n    Return their indexes in the bit field.\n    \"\"\"\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT inv_index FROM zonefiles WHERE zonefile_hash = ?;\"\n        args = (zonefile_hash,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        # NOTE: zero-indexed\n        ret = []\n        for r in res:\n            ret.append( r['inv_index'] - 1 )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef atlasdb_queue_zonefiles( con, db, start_block, zonefile_dir, recover=False, validate=True, end_block=None ):\n    # populate zonefile queue\n    total = 0\n    if end_block is None:\n        end_block = db.lastblock+1\n\n    ret = []    # map zonefile hash to zfinfo\n\n    for block_height in range(start_block, end_block, 1):\n        \n        # TODO: can we do this transactionally?\n        zonefile_info = db.get_atlas_zonefile_info_at( block_height )\n        for name_txid_zfhash in zonefile_info:\n            name = str(name_txid_zfhash['name'])\n            zfhash = str(name_txid_zfhash['value_hash'])\n            txid = str(name_txid_zfhash['txid'])\n            tried_storage = 0\n\n            present = is_zonefile_cached( zfhash, zonefile_dir, validate=validate )\n            zfinfo = atlasdb_get_zonefile( zfhash, con=con )\n            if zfinfo is not None:\n                tried_storage = zfinfo['tried_storage']\n\n            if recover and present:\n                log.debug('Recover: assume that {} is absent so we will reprocess it'.format(zfhash))\n                present = False\n\n            log.debug(\"Add %s %s %s at %s (present: %s, tried_storage: %s)\" % (name, zfhash, txid, block_height, present, tried_storage) )\n            atlasdb_add_zonefile_info( name, zfhash, txid, present, tried_storage, block_height, con=con )\n            total += 1\n\n            ret.append({\n                'name': name,\n                'zonefile_hash': zfhash,\n                'txid': txid,\n                'block_height': block_height,\n                'present': present,\n                'tried_storage': tried_storage\n            })\n\n    log.debug(\"Queued %s zonefiles from %s-%s\" % (total, start_block, db.lastblock))\n    return ret", "response": "Queue all zonefile hashes in the BlockstackDB to the zonefile queue"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsynchronizing atlas DB with name db", "response": "def atlasdb_sync_zonefiles( db, start_block, zonefile_dir, atlas_state, validate=True, end_block=None, path=None, con=None ):\n    \"\"\"\n    Synchronize atlas DB with name db\n\n    NOT THREAD SAFE\n    \"\"\"\n    ret = None\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n        ret = atlasdb_queue_zonefiles( dbcon, db, start_block, zonefile_dir, validate=validate, end_block=end_block )\n        atlasdb_cache_zonefile_info( con=dbcon )\n\n    if atlas_state:\n        # it could have been the case that a zone file we already have was re-announced.\n        # if so, then inform any storage listeners in the crawler thread that this has happened\n        # (such as the subdomain system).\n        crawler_thread = atlas_state['zonefile_crawler']\n        for zfinfo in filter(lambda zfi: zfi['present'], ret):\n            log.debug('Store re-discovered zonefile {} at {}'.format(zfinfo['zonefile_hash'], zfinfo['block_height']))\n            crawler_thread.store_zonefile_cb(zfinfo['zonefile_hash'], zfinfo['block_height'])\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef atlasdb_add_peer( peer_hostport, discovery_time=None, peer_table=None, con=None, path=None, ping_on_evict=True ):\n    \n    # bound the number of peers we add to PEER_MAX_DB\n    assert len(peer_hostport) > 0\n\n    sk = random.randint(0, 2**32)\n    peer_host, peer_port = url_to_host_port( peer_hostport )\n\n    assert len(peer_host) > 0 \n\n    peer_slot = int( hashlib.sha256(\"%s%s\" % (sk, peer_host)).hexdigest(), 16 ) % PEER_MAX_DB\n\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        if discovery_time is None:\n            discovery_time = int(time.time())\n\n        do_evict_and_ping = False\n\n        with AtlasPeerTableLocked(peer_table) as ptbl:\n\n            # if the peer is already present, then we're done\n            if peer_hostport in ptbl.keys():\n                log.debug(\"%s already in the peer table\" % peer_hostport)\n                return True\n           \n            # not in the table yet.  See if we can evict someone\n            if ping_on_evict:\n                do_evict_and_ping = True\n\n\n        if do_evict_and_ping:\n            # evict someone\n            # don't hold the peer table lock across network I/O\n            sql = \"SELECT peer_hostport FROM peers WHERE peer_slot = ?;\"\n            args = (peer_slot,)\n\n            cur = dbcon.cursor()\n            res = atlasdb_query_execute( cur, sql, args )\n\n            old_hostports = []\n            for row in res:\n                old_hostport = res['peer_hostport']\n                old_hostports.append( old_hostport )\n\n            for old_hostport in old_hostports:\n                # is this other peer still alive?\n                # is this other peer part of the same mainnet history?\n                # res = atlas_peer_ping( old_hostport )\n                res = atlas_peer_getinfo(old_hostport)\n                if res:\n                    log.debug(\"Peer %s is still alive; will not replace\" % (old_hostport))\n                    return False\n\n        # insert new peer\n        with AtlasPeerTableLocked(peer_table) as ptbl:\n\n            log.debug(\"Add peer '%s' discovered at %s (slot %s)\" % (peer_hostport, discovery_time, peer_slot))\n\n            # peer is dead (or we don't care).  Can insert or update\n            sql = \"INSERT OR REPLACE INTO peers (peer_hostport, peer_slot, discovery_time) VALUES (?,?,?);\"\n            args = (peer_hostport, peer_slot, discovery_time)\n\n            cur = dbcon.cursor()\n            res = atlasdb_query_execute( cur, sql, args )\n            dbcon.commit()\n\n            # add to peer table as well\n            atlas_init_peer_info( ptbl, peer_hostport, blacklisted=False, whitelisted=False )\n        \n    return True", "response": "Add a peer to the peer table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a peer from the peer db and peer table.", "response": "def atlasdb_remove_peer( peer_hostport, con=None, path=None, peer_table=None ):\n    \"\"\"\n    Remove a peer from the peer db and (if given) peer table.\n    \"\"\"\n    # remove from db\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        log.debug(\"Delete peer '%s'\" % peer_hostport)\n\n        sql = \"DELETE FROM peers WHERE peer_hostport = ?;\"\n        args = (peer_hostport,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n        dbcon.commit()\n\n    # remove from the peer table as well\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n\n        if ptbl.has_key(peer_hostport):\n            if not atlas_peer_is_whitelisted( peer_hostport, peer_table=ptbl ) and not atlas_peer_is_blacklisted( peer_hostport, peer_table=ptbl ):\n                del ptbl[peer_hostport]\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the number of peers in the db?", "response": "def atlasdb_num_peers( con=None, path=None ):\n    \"\"\"\n    How many peers are there in the db?\n    \"\"\"\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT MAX(peer_index) FROM peers;\"\n        args = ()\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        ret = []\n        for row in res:\n            tmp = {}\n            tmp.update(row)\n            ret.append(tmp)\n\n        assert len(ret) == 1\n\n    return ret[0]['MAX(peer_index)']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the given peer s info", "response": "def atlas_get_peer( peer_hostport, peer_table=None ):\n    \"\"\"\n    Get the given peer's info\n    \"\"\"\n\n    ret = None\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        ret = ptbl.get(peer_hostport, None)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a random peer from the db at random Return None if the table is empty", "response": "def atlasdb_get_random_peer( con=None, path=None ):\n    \"\"\"\n    Select a peer from the db at random\n    Return None if the table is empty\n    \"\"\"\n    ret = {}\n\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        num_peers = atlasdb_num_peers( con=con, path=path )\n        if num_peers is None or num_peers == 0:\n            # no peers\n            ret['peer_hostport'] = None\n\n        else:\n            r = random.randint(1, num_peers)\n\n            sql = \"SELECT * FROM peers WHERE peer_index = ?;\"\n            args = (r,)\n\n            cur = dbcon.cursor()\n            res = atlasdb_query_execute( cur, sql, args )\n\n            ret = {'peer_hostport': None}\n            for row in res:\n                ret.update( row )\n                break\n\n\n    return ret['peer_hostport']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget peers older than now - PEER_LIFETIME VIRTUAL", "response": "def atlasdb_get_old_peers( now, con=None, path=None ):\n    \"\"\"\n    Get peers older than now - PEER_LIFETIME\n    \"\"\"\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        if now is None:\n            now = time.time()\n\n        expire = now - atlas_peer_max_age()\n        sql = \"SELECT * FROM peers WHERE discovery_time < ?\";\n        args = (expire,)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        rows = []\n        for row in res:\n            tmp = {}\n            tmp.update(row)\n            rows.append(tmp)\n\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlasdb_renew_peer( peer_hostport, now, con=None, path=None ):\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n        if now is None:\n            now = time.time()\n\n        sql = \"UPDATE peers SET discovery_time = ? WHERE peer_hostport = ?;\"\n        args = (now, peer_hostport)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n        dbcon.commit()\n\n    return True", "response": "Renew a peer s discovery time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef atlasdb_load_peer_table( con=None, path=None ):\n    peer_table = {}\n    \n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT * FROM peers;\"\n        args = ()\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        # build it up \n        count = 0\n        for row in res:\n           if count > 0 and count % 100 == 0:\n               log.debug(\"Loaded %s peers...\" % count)\n\n           atlas_init_peer_info( peer_table, row['peer_hostport'] )\n           count += 1\n\n    return peer_table", "response": "Load a peer table from the peer database"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the atlas database at path.", "response": "def atlasdb_init( path, zonefile_dir, db, peer_seeds, peer_blacklist, recover=False, validate=False):\n    \"\"\"\n    Set up the atlas node:\n    * create the db if it doesn't exist\n    * go through all the names and verify that we have the *current* zonefiles\n    * if we don't, queue them for fetching.\n    * set up the peer db\n\n    @db should be an instance of BlockstackDB\n    @initial_peers should be a list of URLs\n\n    Return the newly-initialized peer table\n    \"\"\"\n    \n    global ATLASDB_SQL\n\n    peer_table = {}\n\n    if os.path.exists( path ):\n        log.debug(\"Atlas DB exists at %s\" % path)\n        \n        con = atlasdb_open( path )\n        atlasdb_last_block = atlasdb_get_lastblock( con=con, path=path )\n        if atlasdb_last_block is None:\n            atlasdb_last_block = FIRST_BLOCK_MAINNET\n\n        log.debug(\"Synchronize zonefiles from %s to %s\" % (atlasdb_last_block, db.lastblock) )\n\n        atlasdb_queue_zonefiles( con, db, atlasdb_last_block, zonefile_dir, recover=recover, validate=validate)\n\n        log.debug(\"Refreshing seed peers\")\n        for peer in peer_seeds:\n            # forcibly add seed peers\n            atlasdb_add_peer( peer, con=con, peer_table=peer_table, ping_on_evict=False )\n\n        # re-try fetching zonefiles from storage if we don't have them yet\n        atlasdb_reset_zonefile_tried_storage( con=con, path=path )\n\n        # load up peer table from the db\n        log.debug(\"Loading peer table\")\n        peer_table = atlasdb_load_peer_table( con=con, path=path )\n\n        # cache zonefile inventory and count\n        atlasdb_cache_zonefile_info( con=con )\n        con.close()\n\n    else:\n\n        log.debug(\"Initializing Atlas DB at %s\" % path)\n\n        lines = [l + \";\" for l in ATLASDB_SQL.split(\";\")]\n        con = sqlite3.connect( path, isolation_level=None )\n\n        for line in lines:\n            db_query_execute(con, line, ())\n\n        con.row_factory = atlasdb_row_factory\n\n        # populate from db\n        log.debug(\"Queuing all zonefiles\")\n        atlasdb_queue_zonefiles( con, db, FIRST_BLOCK_MAINNET, zonefile_dir, recover=recover, validate=validate)\n\n        log.debug(\"Adding seed peers\")\n        for peer in peer_seeds:\n            atlasdb_add_peer( peer, con=con, peer_table=peer_table )\n\n        atlasdb_cache_zonefile_info( con=con )\n        con.close()\n\n    log.debug(\"peer_table: {}\".format(peer_table.keys()))\n\n    # whitelist and blacklist\n    for peer_url in peer_seeds:\n        host, port = url_to_host_port( peer_url )\n        peer_hostport = \"%s:%s\" % (host, port)\n\n        if peer_hostport not in peer_table.keys():\n            atlasdb_add_peer( peer_hostport, path=path, peer_table=peer_table )\n\n        log.debug(\"peer_table: {}\".format(peer_table.keys()))\n        peer_table[peer_hostport]['whitelisted'] = True\n\n    for peer_url in peer_blacklist:\n        host, port = url_to_host_port( peer_url )\n        peer_hostport = \"%s:%s\" % (host, port)\n\n        if peer_hostport not in peer_table.keys():\n            atlasdb_add_peer( peer_hostport, path=path, peer_table=peer_table )\n        \n        log.debug(\"peer_table: {}\".format(peer_table.keys()))\n        peer_table[peer_hostport]['blacklisted'] = True\n\n    return peer_table"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef atlasdb_zonefile_inv_list( bit_offset, bit_length, con=None, path=None ):\n    with AtlasDBOpen(con=con, path=path) as dbcon:\n\n        sql = \"SELECT * FROM zonefiles LIMIT ? OFFSET ?;\"\n        args = (bit_length, bit_offset)\n\n        cur = dbcon.cursor()\n        res = atlasdb_query_execute( cur, sql, args )\n\n        ret = []\n        for row in res:\n            tmp = {}\n            tmp.update(row)\n            ret.append(tmp)\n\n    return ret", "response": "Get an inventory listing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a summary description of the list of zonefiles we have for the given block range.", "response": "def atlas_make_zonefile_inventory( bit_offset, bit_length, con=None, path=None ):\n    \"\"\"\n    Get a summary description of the list of zonefiles we have\n    for the given block range (a \"zonefile inventory\")\n\n    Zonefile present/absent bits are ordered left-to-right,\n    where the leftmost bit is the earliest zonefile in the blockchain.\n\n    Offset and length are in bytes.\n\n    This is slow.  Use the in-RAM zonefile inventory vector whenever possible\n    (see atlas_get_zonefile_inventory).\n    \"\"\"\n    \n    listing = atlasdb_zonefile_inv_list( bit_offset, bit_length, con=con, path=path )\n\n    # serialize to inv\n    bool_vec = [l['present'] for l in listing]\n    if len(bool_vec) % 8 != 0: \n        # pad \n        bool_vec += [False] * (8 - (len(bool_vec) % 8))\n\n    inv = \"\"\n    for i in xrange(0, len(bool_vec), 8):\n        bit_vec = map( lambda b: 1 if b else 0, bool_vec[i:i+8] )\n        next_byte = (bit_vec[0] << 7) | \\\n                    (bit_vec[1] << 6) | \\\n                    (bit_vec[2] << 5) | \\\n                    (bit_vec[3] << 4) | \\\n                    (bit_vec[4] << 3) | \\\n                    (bit_vec[5] << 2) | \\\n                    (bit_vec[6] << 1) | \\\n                    (bit_vec[7])\n        inv += chr(next_byte)\n\n    return inv"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atlas_get_zonefile_inventory( offset=None, length=None ):\n    global ZONEFILE_INV, ZONEFILE_INV_LOCK\n\n    with ZONEFILE_INV_LOCK:\n        try:\n            assert ZONEFILE_INV is not None\n        except AssertionError:\n            log.error(\"FATAL: zonefile inventory not loaded\")\n            os.abort()\n\n        if offset is None:\n            offset = 0\n\n        if length is None:\n            length = len(ZONEFILE_INV) - offset\n\n        if offset >= len(ZONEFILE_INV):\n            return \"\"\n\n        if offset + length > len(ZONEFILE_INV):\n            length = len(ZONEFILE_INV) - offset\n            \n        ret = ZONEFILE_INV[offset:offset+length]\n        return ret", "response": "Get the in - RAM zonefile inventory vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the peer info table entry", "response": "def atlas_init_peer_info( peer_table, peer_hostport, blacklisted=False, whitelisted=False ):\n    \"\"\"\n    Initialize peer info table entry\n    \"\"\"\n    peer_table[peer_hostport] = {\n        \"time\": [],\n        \"zonefile_inv\": \"\",\n        \"blacklisted\": blacklisted,\n        \"whitelisted\": whitelisted\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs a socket exception tastefully", "response": "def atlas_log_socket_error( method_invocation, peer_hostport, se ):\n    \"\"\"\n    Log a socket exception tastefully\n    \"\"\"\n    if isinstance( se, socket.timeout ):\n        log.debug(\"%s %s: timed out (socket.timeout)\" % (method_invocation, peer_hostport))\n\n    elif isinstance( se, socket.gaierror ):\n        log.debug(\"%s %s: failed to query address or info (socket.gaierror)\" % (method_invocation, peer_hostport ))\n\n    elif isinstance( se, socket.herror ):\n        log.debug(\"%s %s: failed to query host info (socket.herror)\" % (method_invocation, peer_hostport ))\n\n    elif isinstance( se, socket.error ):\n        if se.errno == errno.ECONNREFUSED:\n            log.debug(\"%s %s: is unreachable (socket.error ECONNREFUSED)\" % (method_invocation, peer_hostport))\n        elif se.errno == errno.ETIMEDOUT:\n            log.debug(\"%s %s: timed out (socket.error ETIMEDOUT)\" % (method_invocation, peer_hostport))\n        else:\n            log.debug(\"%s %s: socket error\" % (method_invocation, peer_hostport))\n            log.exception(se)\n\n    else:\n        log.debug(\"%s %s: general exception\" % (method_invocation, peer_hostport))\n        log.exception(se)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef atlas_peer_ping( peer_hostport, timeout=None, peer_table=None ):\n    \n    if timeout is None:\n        timeout = atlas_ping_timeout()\n\n    assert not atlas_peer_table_is_locked_by_me()\n\n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout )\n\n    log.debug(\"Ping %s\" % peer_hostport)\n\n    ret = False\n    try:\n        res = blockstack_ping( proxy=rpc ) \n        if 'error' not in res:\n            ret = True\n\n    except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n        atlas_log_socket_error( \"ping(%s)\" % peer_hostport, peer_hostport, se )\n        pass\n\n    except Exception, e:\n        log.exception(e)\n        pass\n\n    # update health\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        atlas_peer_update_health( peer_hostport, ret, peer_table=ptbl )\n\n    return ret", "response": "Ping a host and return True if alive Return False if not"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef atlas_peer_getinfo( peer_hostport, timeout=None, peer_table=None ):\n\n    if timeout is None:\n        timeout = atlas_ping_timeout()\n\n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout )\n\n    assert not atlas_peer_table_is_locked_by_me()\n\n    log.debug(\"getinfo %s\" % peer_hostport)\n    res = None\n\n    try:\n        res = blockstack_getinfo( proxy=rpc )\n        if 'error' in res:\n            log.error(\"Failed to getinfo on %s: %s\" % (peer_hostport, res['error']))\n\n        if 'last_block_processed' not in res:\n            log.error(\"Missing last_block_processed response from {}\".format(peer_hostport))\n            res = {'error': 'Remote peer {} did not rely last_block_processed'.format(peer_hostport)}\n\n        if 'stale' in res and res['stale']:\n            log.error(\"Remote host {} is well behind the chain tip\".format(peer_hostport))\n            res = {'error': 'Remote peer {} is well behind the chain tip'.format(peer_hostport)}\n\n        if 'testnet' in res:\n            if (res['testnet'] and not BLOCKSTACK_TEST and not BLOCKSTACK_PUBLIC_TESTNET) or (not res['testnet'] and (BLOCKSTACK_TEST or BLOCKSTACK_PUBLIC_TESTNET)):\n                if BLOCKSTACK_TEST or BLOCKSTACK_PUBLIC_TESTNET:\n                    log.error(\"Remote host {} is a mainnet host, and we're testnet\".format(peer_hostport))\n                    res = {'error': 'Remote peer {} is a mainnet host, and we\\'re testnet'.format(peer_hostport)}\n                else:\n                    log.error(\"Remote host {} is a testnet host\".format(peer_hostport))\n                    res = {'error': 'Remote peer {} is a testnet host'.format(peer_hostport)}\n\n        else:\n            # assume mainnet \n            if BLOCKSTACK_TEST or BLOCKSTACK_PUBLIC_TESTNET:\n                log.error(\"Remote host {} is a mainnet host, and we're testnet\".format(peer_hostport))\n                res = {'error': 'Remote peer {} is a mainnet host, and we\\'re testnet'.format(peer_hostport)}\n\n    except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n        atlas_log_socket_error( \"getinfo(%s)\" % peer_hostport, peer_hostport, se )\n\n    except AssertionError, ae:\n        log.exception(ae)\n        log.error(\"Invalid server reply for getinfo from %s\" % peer_hostport)\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"Failed to get response from %s\" % peer_hostport)\n  \n    if res is not None:\n        err = False\n        if json_is_error(res):\n            log.error(\"Failed to contact {}: replied error '{}'\".format(peer_hostport, res['error']))\n            err = True\n    \n        if 'stale' in res and res['stale']:\n            # peer is behind the chain tip\n            log.warning(\"Peer {} reports that it is too far behind the chain tip.  Ignoring for now.\".format(peer_hostport))\n            err = True\n\n        if err:\n            res = None\n\n    else:\n        log.error(\"Failed to contact {}: no response\".format(peer_hostport))\n\n    # update health\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if ptbl.has_key(peer_hostport):\n            atlas_peer_update_health( peer_hostport, (res is not None), peer_table=ptbl )\n\n    return res", "response": "Get the info from a peer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atlas_inventory_count_missing( inv1, inv2 ):\n    count = 0\n    common = min(len(inv1), len(inv2))\n    for i in xrange(0, common):\n        for j in xrange(0, 8):\n            if ((1 << (7 - j)) & ord(inv2[i])) != 0 and ((1 << (7 - j)) & ord(inv1[i])) == 0:\n                count += 1\n\n    if len(inv1) < len(inv2):\n        for i in xrange(len(inv1), len(inv2)):\n            for j in xrange(0, 8):\n                if ((1 << (7 - j)) & ord(inv2[i])) != 0:\n                    count += 1\n\n    return count", "response": "Count the number of missing bits in inv2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef atlas_get_live_neighbors( remote_peer_hostport, peer_table=None, min_health=MIN_PEER_HEALTH, min_request_count=1 ):\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        alive_peers = []\n        for peer_hostport in ptbl.keys():\n            if peer_hostport == remote_peer_hostport:\n                continue\n\n            num_reqs = atlas_peer_get_request_count( peer_hostport, peer_table=ptbl )\n            if num_reqs < min_request_count:\n                continue\n\n            health = atlas_peer_get_health( peer_hostport, peer_table=ptbl )\n            if health < min_health:\n                continue\n\n            alive_peers.append( peer_hostport )\n\n    random.shuffle(alive_peers)\n    return alive_peers", "response": "Get a random set of live neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all neighbor information.", "response": "def atlas_get_all_neighbors( peer_table=None ):\n    \"\"\"\n    Get *all* neighbor information.\n    USED ONLY FOR TESTING\n    \"\"\"\n    if os.environ.get(\"BLOCKSTACK_ATLAS_NETWORK_SIMULATION\") != \"1\":\n        raise Exception(\"This method is only available when testing with the Atlas network simulator\")\n\n    ret = {}\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        ret = copy.deepcopy(ptbl)\n\n    # make zonefile inventories printable\n    for peer_hostport in ret.keys():\n        if ret[peer_hostport].has_key('zonefile_inv'):\n            ret[peer_hostport]['zonefile_inv'] = atlas_inventory_to_string( ret[peer_hostport]['zonefile_inv'] )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef atlas_peer_get_health( peer_hostport, peer_table=None ):\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        # availability score: number of responses / number of requests\n        num_responses = 0\n        num_requests = 0\n        if ptbl.has_key(peer_hostport):\n            for (t, r) in ptbl[peer_hostport]['time']:\n                num_requests += 1\n                if r:\n                    num_responses += 1\n\n        availability_score = 0.0\n        if num_requests > 0:\n            availability_score = float(num_responses) / float(num_requests)\n\n    return availability_score", "response": "Get the health score for a peer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the number of times we have contacted this peer?", "response": "def atlas_peer_get_request_count( peer_hostport, peer_table=None ):\n    \"\"\"\n    How many times have we contacted this peer?\n    \"\"\"\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return 0\n\n        count = 0\n        for (t, r) in ptbl[peer_hostport]['time']:\n            if r:\n                count += 1\n\n    return count"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=None ):\n    inv = None\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return None\n\n        inv = ptbl[peer_hostport]['zonefile_inv']\n\n    return inv", "response": "Get the zonefile inventory vector for this peer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlas_peer_set_zonefile_inventory( peer_hostport, peer_inv, peer_table=None ):\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return None \n\n        ptbl[peer_hostport]['zonefile_inv'] = peer_inv\n\n    return peer_inv", "response": "Set this peer s zonefile inventory"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nis a peer whitelisted?", "response": "def atlas_peer_is_whitelisted( peer_hostport, peer_table=None ):\n    \"\"\"\n    Is a peer whitelisted\n    \"\"\"\n    ret = None\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return None \n\n        ret = ptbl[peer_hostport].get(\"whitelisted\", False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the health of a given peer.", "response": "def atlas_peer_update_health( peer_hostport, received_response, peer_table=None ):\n    \"\"\"\n    Mark the given peer as alive at this time.\n    Update times at which we contacted it,\n    and update its health score.\n\n    Use the global health table by default, \n    or use the given health info if set.\n    \"\"\"\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return False\n\n        # record that we contacted this peer, and whether or not we useful info from it\n        now = time_now()\n\n        # update timestamps; remove old data\n        new_times = []\n        for (t, r) in ptbl[peer_hostport]['time']:\n            if t + atlas_peer_lifetime_interval() < now:\n                continue\n            \n            new_times.append((t, r))\n\n        new_times.append((now, received_response))\n        ptbl[peer_hostport]['time'] = new_times\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atlas_peer_get_zonefile_inventory_range( my_hostport, peer_hostport, bit_offset, bit_count, timeout=None, peer_table=None ):\n\n    if timeout is None:\n        timeout = atlas_inv_timeout()\n\n    zf_inv = {}\n    zf_inv_list = None\n    \n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout, src=my_hostport )\n\n    assert not atlas_peer_table_is_locked_by_me()\n\n    zf_inv = None\n\n    log.debug(\"Get zonefile inventory range %s-%s from %s\" % (bit_offset, bit_count, peer_hostport))\n    try:\n        zf_inv = blockstack_get_zonefile_inventory( peer_hostport, bit_offset, bit_count, timeout=timeout, my_hostport=my_hostport, proxy=rpc )\n     \n    except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n        atlas_log_socket_error( \"get_zonefile_inventory(%s, %s, %s)\" % (peer_hostport, bit_offset, bit_count), peer_hostport, se )\n        log.error(\"Failed to ask %s for zonefile inventory over %s-%s (socket-related error)\" % (peer_hostport, bit_offset, bit_count))\n        \n    except Exception, e:\n        if os.environ.get(\"BLOCKSTACK_DEBUG\") == \"1\":\n            log.exception(e)\n\n        log.error(\"Failed to ask %s for zonefile inventory over %s-%s\" % (peer_hostport, bit_offset, bit_count))\n\n    atlas_peer_update_health( peer_hostport, (zf_inv is not None and zf_inv.has_key('status') and zf_inv['status']), peer_table=peer_table )\n\n    if zf_inv is None:\n        log.error(\"No inventory given for %s-%s from %s\" % (bit_offset, bit_count, peer_hostport))\n        return None \n\n    if 'error' in zf_inv:\n        log.error(\"Failed to get inventory for %s-%s from %s: %s\" % (bit_offset, bit_count, peer_hostport, zf_inv['error']))\n        return None\n\n    else:\n        inv_str = atlas_inventory_to_string(zf_inv['inv'])\n        if len(inv_str) > 40:\n            inv_str = inv_str[:40] + \"...\"\n\n        log.debug(\"Zonefile inventory for %s (%s-%s) is '%s'\" % (peer_hostport, bit_offset, bit_count, inv_str))\n        return zf_inv['inv']", "response": "Get the zonefile inventory range for a given peer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads the zonefile inventory from the remote peer", "response": "def atlas_peer_download_zonefile_inventory( my_hostport, peer_hostport, maxlen, bit_offset=0, timeout=None, peer_table={} ):\n    \"\"\"\n    Get the zonefile inventory from the remote peer\n    Start from the given bit_offset\n\n    NOTE: this doesn't update the peer table health by default;\n    you'll have to explicitly pass in a peer table (i.e. setting\n    to {} ensures that nothing happens).\n    \"\"\"\n\n    if timeout is None:\n        timeout = atlas_inv_timeout()\n\n    interval = 524288       # number of bits in 64KB\n    peer_inv = \"\"\n\n    log.debug(\"Download zonefile inventory %s-%s from %s\" % (bit_offset, maxlen, peer_hostport))\n\n    if bit_offset > maxlen:\n        # synced already\n        return peer_inv\n\n    for offset in xrange( bit_offset, maxlen, interval):\n        next_inv = atlas_peer_get_zonefile_inventory_range( my_hostport, peer_hostport, offset, interval, timeout=timeout, peer_table=peer_table )\n        if next_inv is None:\n            # partial failure\n            log.debug(\"Failed to sync inventory for %s from %s to %s\" % (peer_hostport, offset, offset+interval))\n            break\n\n        peer_inv += next_inv\n        if len(next_inv) < interval:\n            # end-of-interval\n            break\n\n    return peer_inv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef atlas_peer_sync_zonefile_inventory( my_hostport, peer_hostport, maxlen, timeout=None, peer_table=None ):\n    if timeout is None:\n        timeout = atlas_inv_timeout()\n\n    peer_inv = \"\"\n    bit_offset = None\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return None \n\n        peer_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n\n        bit_offset = (len(peer_inv) - 1) * 8      # i.e. re-obtain the last byte\n        if bit_offset < 0:\n            bit_offset = 0\n\n        else:\n            peer_inv = peer_inv[:-1]\n\n    peer_inv = atlas_peer_download_zonefile_inventory( my_hostport, peer_hostport, maxlen, bit_offset=bit_offset, timeout=timeout, peer_table=peer_table )\n  \n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            log.debug(\"%s no longer a peer\" % peer_hostport)\n            return None \n\n        inv_str = atlas_inventory_to_string(peer_inv)\n        if len(inv_str) > 40:\n            inv_str = inv_str[:40] + \"...\"\n\n        log.debug(\"Set zonefile inventory %s: %s\" % (peer_hostport, inv_str))\n        atlas_peer_set_zonefile_inventory( peer_hostport, peer_inv, peer_table=ptbl ) # NOTE: may have trailing 0's for padding\n\n    return peer_inv", "response": "Synchronize our knowledge of a peer s zonefiles up to a given byte length."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh a peer s zonefile inventory by removing every bit after byte_offset and re - synchronizing them.", "response": "def atlas_peer_refresh_zonefile_inventory( my_hostport, peer_hostport, byte_offset, timeout=None, peer_table=None, con=None, path=None, local_inv=None ):\n    \"\"\"\n    Refresh a peer's zonefile recent inventory vector entries,\n    by removing every bit after byte_offset and re-synchronizing them.\n\n    The intuition here is that recent zonefiles are much rarer than older\n    zonefiles (which will have been near-100% replicated), meaning the tail\n    of the peer's zonefile inventory is a lot less stable than the head (since\n    peers will be actively distributing recent zonefiles).\n\n    NOT THREAD SAFE; CALL FROM ONLY ONE THREAD.\n\n    Return True if we synced all the way up to the expected inventory length, and update the refresh time in the peer table.\n    Return False if not.\n    \"\"\"\n\n    if timeout is None:\n        timeout = atlas_inv_timeout()\n\n    if local_inv is None:\n        # get local zonefile inv \n        inv_len = atlasdb_zonefile_inv_length( con=con, path=path )\n        local_inv = atlas_make_zonefile_inventory( 0, inv_len, con=con, path=path )\n\n    maxlen = len(local_inv)\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return False\n\n        # reset the peer's zonefile inventory, back to offset\n        cur_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n        atlas_peer_set_zonefile_inventory( peer_hostport, cur_inv[:byte_offset], peer_table=ptbl )\n\n    inv = atlas_peer_sync_zonefile_inventory( my_hostport, peer_hostport, maxlen, timeout=timeout, peer_table=peer_table )\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return False\n\n        # Update refresh time (even if we fail)\n        ptbl[peer_hostport]['zonefile_inventory_last_refresh'] = time_now()\n\n    if inv is not None:\n        inv_str = atlas_inventory_to_string(inv)\n        if len(inv_str) > 40:\n            inv_str = inv_str[:40] + \"...\"\n\n        log.debug(\"%s: inventory of %s is now '%s'\" % (my_hostport, peer_hostport, inv_str))\n\n    if inv is None:\n        return False\n\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the given atlas node has a fresh zonefile inventory.", "response": "def atlas_peer_has_fresh_zonefile_inventory( peer_hostport, peer_table=None ):\n    \"\"\"\n    Does the given atlas node have a fresh zonefile inventory?\n    \"\"\"\n\n    fresh = False\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return False\n\n        now = time_now()\n        peer_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n\n        # NOTE: zero-length or None peer inventory means the peer is simply dead, but we've pinged it\n        if  ptbl[peer_hostport].has_key('zonefile_inventory_last_refresh') and \\\n            ptbl[peer_hostport]['zonefile_inventory_last_refresh'] + atlas_peer_ping_interval() > now:\n\n            fresh = True\n\n    return fresh"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef atlas_peer_set_zonefile_status( peer_hostport, zonefile_hash, present, zonefile_bits=None, peer_table=None, con=None, path=None ):\n    if zonefile_bits is None:\n        zonefile_bits = atlasdb_get_zonefile_bits( zonefile_hash, con=con, path=path )\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if ptbl.has_key(peer_hostport):\n            peer_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n            peer_inv = atlas_inventory_flip_zonefile_bits( peer_inv, zonefile_bits, present )\n            atlas_peer_set_zonefile_inventory( peer_hostport, peer_inv, peer_table=ptbl )\n                \n    return", "response": "Mark a peer s zonefile as present or absent on a peer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef atlas_find_missing_zonefile_availability( peer_table=None, con=None, path=None, missing_zonefile_info=None ):\n\n    # which zonefiles do we have?\n    bit_offset = 0\n    bit_count = 10000\n    missing = []\n    ret = {}\n\n    if missing_zonefile_info is None:\n        while True:\n            zfinfo = atlasdb_zonefile_find_missing( bit_offset, bit_count, con=con, path=path )\n            if len(zfinfo) == 0:\n                break\n\n            missing += zfinfo\n            bit_offset += len(zfinfo)\n\n        if len(missing) > 0:\n            log.debug(\"Missing %s zonefiles\" % len(missing))\n\n    else:\n        missing = missing_zonefile_info\n\n    if len(missing) == 0:\n        # none!\n        return ret\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        # do any other peers have this zonefile?\n        for zfinfo in missing:\n            popularity = 0\n            byte_index = (zfinfo['inv_index'] - 1) / 8\n            bit_index = 7 - ((zfinfo['inv_index'] - 1) % 8)\n            peers = []\n\n            if not ret.has_key(zfinfo['zonefile_hash']):\n                ret[zfinfo['zonefile_hash']] = {\n                    'names': [],\n                    'txid': zfinfo['txid'],\n                    'indexes': [],\n                    'block_heights': [],\n                    'popularity': 0,\n                    'peers': [],\n                    'tried_storage': False\n                }\n\n            for peer_hostport in ptbl.keys():\n                peer_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n                if len(peer_inv) <= byte_index:\n                    # too new for this peer\n                    continue\n\n                if (ord(peer_inv[byte_index]) & (1 << bit_index)) == 0:\n                    # this peer doesn't have it\n                    continue\n\n                if peer_hostport not in ret[zfinfo['zonefile_hash']]['peers']:\n                    popularity += 1\n                    peers.append( peer_hostport )\n\n            ret[zfinfo['zonefile_hash']]['names'].append( zfinfo['name'] )\n            ret[zfinfo['zonefile_hash']]['indexes'].append( zfinfo['inv_index']-1 )\n            ret[zfinfo['zonefile_hash']]['block_heights'].append( zfinfo['block_height'] )\n            ret[zfinfo['zonefile_hash']]['popularity'] += popularity\n            ret[zfinfo['zonefile_hash']]['peers'] += peers\n            ret[zfinfo['zonefile_hash']]['tried_storage'] = zfinfo['tried_storage']\n\n    return ret", "response": "Find the set of missing zonefiles that are not available on the atlas database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlas_peer_has_zonefile( peer_hostport, zonefile_hash, zonefile_bits=None, con=None, path=None, peer_table=None ):\n\n    bits = None\n    if zonefile_bits is None:\n        bits = atlasdb_get_zonefile_bits( zonefile_hash, con=con, path=path )\n        if len(bits) == 0:\n            return None\n\n    else:\n        bits = zonefile_bits\n\n    zonefile_inv = None\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_hostport not in ptbl.keys():\n            return False\n\n        zonefile_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n    \n    res = atlas_inventory_test_zonefile_bits( zonefile_inv, bits )\n    return res", "response": "Returns True if the given peer has the given zonefile defined?"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef atlas_peer_get_neighbors( my_hostport, peer_hostport, timeout=None, peer_table=None, con=None, path=None ):\n   \n    if timeout is None:\n        timeout = atlas_neighbors_timeout()\n\n    peer_list = None\n\n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout, src=my_hostport )\n\n    # sane limits\n    max_neighbors = atlas_max_neighbors()\n\n    assert not atlas_peer_table_is_locked_by_me()\n    \n    try:\n        peer_list = blockstack_atlas_peer_exchange( peer_hostport, my_hostport, timeout=timeout, proxy=rpc )\n        if json_is_exception(peer_list):\n            # fall back to legacy method \n            peer_list = blockstack_get_atlas_peers(peer_hostport, timeout=timeout, proxy=rpc)\n\n    except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n        atlas_log_socket_error( \"atlas_peer_exchange(%s)\" % peer_hostport, peer_hostport, se)\n        log.error(\"Socket error in response from '%s'\" % peer_hostport)\n\n    except Exception, e:\n        if os.environ.get(\"BLOCKSTACK_DEBUG\") == \"1\":\n            log.exception(e)\n        log.error(\"Failed to talk to '%s'\" % peer_hostport)\n   \n    if peer_list is None:\n        log.error(\"Failed to query remote peer %s\" % peer_hostport)\n        atlas_peer_update_health( peer_hostport, False, peer_table=peer_table )\n        return None \n\n    if 'error' in peer_list:\n        log.debug(\"Remote peer error: %s\" % peer_list['error'])\n        log.error(\"Remote peer error on %s\" % peer_hostport)\n        atlas_peer_update_health( peer_hostport, False, peer_table=peer_table )\n        return None\n\n    ret = peer_list['peers']\n    atlas_peer_update_health( peer_hostport, True, peer_table=peer_table )\n    return ret", "response": "Get a list of neighbors from the given peer server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of zonefiles from a given host.", "response": "def atlas_get_zonefiles( my_hostport, peer_hostport, zonefile_hashes, timeout=None, peer_table=None ):\n    \"\"\"\n    Given a list of zonefile hashes.\n    go and get them from the given host.\n\n    Update node health\n\n    Return the newly-fetched zonefiles on success (as a dict mapping hashes to zonefile data)\n    Return None on error.\n    \"\"\"\n\n    if timeout is None:\n        timeout = atlas_zonefiles_timeout()\n\n    zf_payload = None\n    zonefile_datas = {}\n\n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout, src=my_hostport )\n\n    assert not atlas_peer_table_is_locked_by_me()\n\n    # get in batches of 100 or less \n    zf_batches = []\n    for i in xrange(0, len(zonefile_hashes), 100):\n        zf_batches.append(zonefile_hashes[i:i+100])\n\n    for zf_batch in zf_batches:\n        zf_payload = None\n        try:\n            zf_payload = blockstack_get_zonefiles( peer_hostport, zf_batch, timeout=timeout, my_hostport=my_hostport, proxy=rpc )\n\n        except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n            atlas_log_socket_error( \"get_zonefiles(%s)\" % peer_hostport, peer_hostport, se)\n\n        except Exception, e:\n            if os.environ.get(\"BLOCKSTACK_DEBUG\") is not None:\n                log.exception(e)\n\n            log.error(\"Invalid zonefile data from %s\" % peer_hostport)\n\n        if zf_payload is None:\n            log.error(\"Failed to fetch zonefile data from %s\" % peer_hostport)\n            atlas_peer_update_health( peer_hostport, False, peer_table=peer_table )\n            \n            zonefile_datas = None\n            break\n\n        if 'error' in zf_payload.keys():\n            log.error(\"Failed to fetch zonefile data from %s: %s\" % (peer_hostport, zf_payload['error']))\n            atlas_peer_update_health( peer_hostport, False, peer_table=peer_table )\n\n            zonefile_datas = None\n            break\n\n        # success!\n        zonefile_datas.update( zf_payload['zonefiles'] )\n\n    atlas_peer_update_health( peer_hostport, True, peer_table=peer_table )\n    return zonefile_datas"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef atlas_rank_peers_by_health( peer_list=None, peer_table=None, with_zero_requests=False, with_rank=False ):\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_list is None:\n            peer_list = ptbl.keys()[:]\n\n        peer_health_ranking = []    # (health score, peer hostport)\n        for peer_hostport in peer_list:\n            reqcount = atlas_peer_get_request_count( peer_hostport, peer_table=ptbl )\n            if reqcount == 0 and not with_zero_requests:\n                continue\n\n            health_score = atlas_peer_get_health( peer_hostport, peer_table=ptbl)\n            peer_health_ranking.append( (health_score, peer_hostport) )\n    \n    # sort on health\n    peer_health_ranking.sort()\n    peer_health_ranking.reverse()\n\n    if not with_rank:\n        return [peer_hp for _, peer_hp in peer_health_ranking]\n    else:\n        # include the score.\n        return peer_health_ranking", "response": "Rank peers by health."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nranking peers by data availability.", "response": "def atlas_rank_peers_by_data_availability( peer_list=None, peer_table=None, local_inv=None, con=None, path=None ):\n    \"\"\"\n    Get a ranking of peers to contact for a zonefile.\n    Peers are ranked by the number of zonefiles they have\n    which we don't have.\n\n    This is used to select neighbors.\n    \"\"\"\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        if peer_list is None:\n            peer_list = ptbl.keys()[:]\n\n        if local_inv is None:\n            # what's my inventory?\n            inv_len = atlasdb_zonefile_inv_length( con=con, path=path )\n            local_inv = atlas_make_zonefile_inventory( 0, inv_len, con=con, path=path )\n\n        peer_availability_ranking = []    # (health score, peer hostport)\n        for peer_hostport in peer_list:\n\n            peer_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n\n            # ignore peers that we don't have an inventory for\n            if len(peer_inv) == 0:\n                continue\n\n            availability_score = atlas_inventory_count_missing( local_inv, peer_inv )\n            peer_availability_ranking.append( (availability_score, peer_hostport) )\n    \n\n    # sort on availability\n    peer_availability_ranking.sort()\n    peer_availability_ranking.reverse()\n\n    return [peer_hp for _, peer_hp in peer_availability_ranking]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbegin talking to a new peer, if we aren't already. Don't accept this peer if there are already too many peers in the incoming queue (where \"too many\" means \"more than the maximum neighbor set size\") Return True if added Return False if not added", "response": "def atlas_peer_enqueue( peer_hostport, peer_table=None, peer_queue=None, max_neighbors=None ):\n    \"\"\"\n    Begin talking to a new peer, if we aren't already.\n    Don't accept this peer if there are already too many peers in the incoming queue\n    (where \"too many\" means \"more than the maximum neighbor set size\")\n\n    Return True if added\n    Return False if not added\n    \"\"\"\n\n    present = False\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        present = (peer_hostport in ptbl.keys())\n\n    if present:\n        # nothing to do \n        return False\n\n    res = False\n    with AtlasPeerQueueLocked(peer_queue) as pq:\n\n        if not present:\n            if max_neighbors is None:\n                max_neighbors = atlas_max_neighbors()\n\n            if len(pq) < atlas_max_new_peers(max_neighbors):\n                pq.append( peer_hostport )\n                res = True\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef atlas_peer_dequeue_all( peer_queue=None ):\n\n    peers = []\n    with AtlasPeerQueueLocked(peer_queue) as pq:\n        while len(pq) > 0:\n            peers.append( pq.pop(0) )\n\n    return peers", "response": "Get all queued peers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the set of peers that do not have this zonefile.", "response": "def atlas_zonefile_find_push_peers( zonefile_hash, peer_table=None, zonefile_bits=None, con=None, path=None ):\n    \"\"\"\n    Find the set of peers that do *not* have this zonefile.\n    \"\"\"\n\n    if zonefile_bits is None:\n        zonefile_bits = atlasdb_get_zonefile_bits( zonefile_hash, path=path, con=con )\n        if len(zonefile_bits) == 0:\n            # we don't even know about it\n            return []\n\n    push_peers = []\n    \n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        for peer_hostport in ptbl.keys():\n            zonefile_inv = atlas_peer_get_zonefile_inventory( peer_hostport, peer_table=ptbl )\n            res = atlas_inventory_test_zonefile_bits( zonefile_inv, zonefile_bits )\n            if res:\n                push_peers.append( peer_hostport )\n\n    return push_peers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npushing a zonefile to the given peer", "response": "def atlas_zonefile_push( my_hostport, peer_hostport, zonefile_data, timeout=None, peer_table=None ):\n    \"\"\"\n    Push the given zonefile to the given peer\n    Return True on success\n    Return False on failure\n    \"\"\"\n    if timeout is None:\n        timeout = atlas_push_zonefiles_timeout()\n   \n    zonefile_hash = get_zonefile_data_hash(zonefile_data)\n    zonefile_data_b64 = base64.b64encode( zonefile_data )\n\n    host, port = url_to_host_port( peer_hostport )\n    RPC = get_rpc_client_class()\n    rpc = RPC( host, port, timeout=timeout, src=my_hostport )\n\n    status = False\n\n    assert not atlas_peer_table_is_locked_by_me()\n\n    try:\n        push_info = blockstack_put_zonefiles( peer_hostport, [zonefile_data_b64], timeout=timeout, my_hostport=my_hostport, proxy=rpc )\n        if 'error' not in push_info:\n            if push_info['saved'] == 1:\n                # woo!\n                saved = True\n\n    except (socket.timeout, socket.gaierror, socket.herror, socket.error), se:\n        atlas_log_socket_error( \"put_zonefiles(%s)\" % peer_hostport, peer_hostport, se)\n    \n    except AssertionError, ae:\n        log.exception(ae)\n        log.error(\"Invalid server response from %s\" % peer_hostport )\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"Failed to push zonefile %s to %s\" % (zonefile_hash, peer_hostport))\n\n    with AtlasPeerTableLocked(peer_table) as ptbl:\n        atlas_peer_update_health( peer_hostport, status, peer_table=ptbl )\n\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the atlas node.", "response": "def atlas_node_init(my_hostname, my_portnum, atlasdb_path, zonefile_dir, working_dir):\n    \"\"\"\n    Start up the atlas node.\n    Return a bundle of atlas state\n    \"\"\"\n    atlas_state = {}\n    atlas_state['peer_crawler'] = AtlasPeerCrawler(my_hostname, my_portnum, atlasdb_path, working_dir)\n    atlas_state['health_checker'] = AtlasHealthChecker(my_hostname, my_portnum, atlasdb_path)\n    atlas_state['zonefile_crawler'] = AtlasZonefileCrawler(my_hostname, my_portnum, atlasdb_path, zonefile_dir)\n    # atlas_state['zonefile_pusher'] = AtlasZonefilePusher(my_hostname, my_portnum, atlasdb_path, zonefile_dir)\n\n    return atlas_state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart up atlas threads", "response": "def atlas_node_start(atlas_state):\n    \"\"\"\n    Start up atlas threads\n    \"\"\"\n    for component in atlas_state.keys():\n        log.debug(\"Starting Atlas component '%s'\" % component)\n        atlas_state[component].start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a callback to the initialized atlas state", "response": "def atlas_node_add_callback(atlas_state, callback_name, callback):\n    \"\"\"\n    Add a callback to the initialized atlas state\n    \"\"\"\n    if callback_name == 'store_zonefile':\n        atlas_state['zonefile_crawler'].set_store_zonefile_callback(callback)\n\n    else:\n        raise ValueError(\"Unrecognized callback {}\".format(callback_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop the atlas node threads", "response": "def atlas_node_stop( atlas_state ):\n    \"\"\"\n    Stop the atlas node threads\n    \"\"\"\n    for component in atlas_state.keys():\n        log.debug(\"Stopping Atlas component '%s'\" % component)\n        atlas_state[component].ask_join()\n        atlas_state[component].join()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the canonical peer name", "response": "def canonical_peer( self, peer ):\n        \"\"\"\n        Get the canonical peer name\n        \"\"\"\n        their_host, their_port = url_to_host_port( peer )\n\n        if their_host in ['127.0.0.1', '::1']:\n            their_host = 'localhost'\n\n        return \"%s:%s\" % (their_host, their_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget neighbors of this peer.", "response": "def get_neighbors( self, peer_hostport, con=None, path=None, peer_table=None ):\n        \"\"\"\n        Get neighbors of this peer\n        NOTE: don't lock peer table in production\n        \"\"\"\n        if path is None:\n            path = self.atlasdb_path\n\n        if self.neighbors_timeout is None:\n            self.neighbors_timeout = atlas_neighbors_timeout()\n \n        peer_hostport = self.canonical_peer( peer_hostport )\n\n        neighbors = None\n        if peer_hostport == self.my_hostport:\n            neighbors = atlas_get_live_neighbors( None, peer_table=peer_table ) \n        else:\n            neighbors = atlas_peer_get_neighbors( self.my_hostport, peer_hostport, timeout=self.neighbors_timeout, peer_table=peer_table, path=path, con=con )\n\n        if neighbors is not None:\n            log.debug(\"%s: neighbors of %s are (%s): %s\" % (self.my_hostport, peer_hostport, len(neighbors), \",\".join(neighbors)))\n        else:\n            log.error(\"%s: failed to ask %s for neighbors\" % (self.my_hostport, peer_hostport))\n\n        return neighbors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_new_peers( self, count, new_peers, current_peers, con=None, path=None, peer_table=None ):\n\n        if self.ping_timeout is None:\n            self.ping_timeout = atlas_ping_timeout()\n \n        if path is None:\n            path = self.atlasdb_path\n\n        # only handle a few peers for now\n        cnt = 0\n        i = 0\n        added = []\n        present = []\n        filtered = []\n        while i < len(new_peers) and cnt < min(count, len(new_peers)):\n            peer = self.canonical_peer( new_peers[i] )\n            i += 1\n\n            if peer == self.my_hostport:\n                filtered.append(peer)\n                continue\n\n            if peer in current_peers:\n                log.debug(\"%s is already known\" % peer)\n                present.append(peer)\n                continue \n\n            cnt += 1\n\n            # test the peer before adding\n            res = atlas_peer_getinfo( peer, timeout=self.ping_timeout, peer_table=peer_table )\n            if res is None:\n                # didn't respond successfully\n                filtered.append(peer)\n                continue\n\n            if not res.has_key('server_version'):\n                # too old.  TODO: ban them\n                filtered.append(peer)\n                continue\n\n            if (BLOCKSTACK_PUBLIC_TESTNET and res['server_version'] != MIN_ATLAS_VERSION) or (not BLOCKSTACK_PUBLIC_TESTNET and semver_newer(res['server_version'], MIN_ATLAS_VERSION)):\n                # mainnet: too old to be a valid atlas node for this network version\n                # testnet: not the same version == don't connect\n                filtered.append(peer)\n                log.debug(\"%s is too old to be an atlas node (version %s)\" % (peer, res['server_version']))\n\n                # TODO: ban them\n                continue\n            \n            # advance our consensus hashes\n            our_last_block = get_last_block(self.working_dir)\n            if not self.consensus_hashes.has_key(our_last_block):\n                cur_last_block = max(self.consensus_hashes.keys())\n                new_consensus_hashes = get_snapshots(self.working_dir, start_block=cur_last_block, end_block=our_last_block+1)\n                self.consensus_hashes.update(new_consensus_hashes)\n\n            if self.consensus_hashes.has_key(our_last_block):\n\n                their_last_block = res['last_block_processed']\n                if their_last_block <= our_last_block and res['consensus'] not in self.consensus_hashes.values():\n                    # on different consensus rules than us\n                    log.debug(\"Peer {} has ({},{}), but we have ({},{}). Ignoring.\".format(peer, their_last_block, res['consensus'], our_last_block, self.consensus_hashes[our_last_block]))\n\n                    # TODO: drop them from the peer table, and don't reconnect with them for a while.\n                    continue\n\n            if res:\n                log.debug(\"Add newly-discovered peer %s\" % peer)\n                atlasdb_add_peer( peer, con=con, path=path, peer_table=peer_table )\n                added.append(peer)\n            else:\n                filtered.append(peer)\n\n        return added, present, filtered", "response": "Add new peers to the set of known peers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove up to count unhealthy peers", "response": "def remove_unhealthy_peers( self, count, con=None, path=None, peer_table=None, min_request_count=10, min_health=MIN_PEER_HEALTH ):\n        \"\"\"\n        Remove up to @count unhealthy peers\n        Return the list of peers we removed\n        \"\"\"\n        \n        if path is None:\n            path = self.atlasdb_path\n\n        removed = []\n        rank_peer_list = atlas_rank_peers_by_health( peer_table=peer_table, with_rank=True )\n        for rank, peer in rank_peer_list:\n            reqcount = atlas_peer_get_request_count( peer, peer_table=peer_table )\n            if reqcount >= min_request_count and rank < min_health and not atlas_peer_is_whitelisted( peer, peer_table=peer_table ) and not atlas_peer_is_blacklisted( peer, peer_table=peer_table ):\n                removed.append( peer )\n\n        random.shuffle(removed)\n        if len(removed) > count:\n            removed = removed[:count]\n\n        for peer in removed:\n            log.debug(\"Remove unhealthy peer %s\" % (peer))\n            atlasdb_remove_peer( peer, con=con, path=path, peer_table=peer_table )\n\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_walk_graph( self, prev_peer, prev_peer_degree, current_peer, current_peer_neighbors, con=None, path=None, peer_table=None ):\n\n        if path is None:\n            path = self.atlasdb_path\n\n        # the \"next\" current peer\n        ret_current_peer = None\n        ret_current_peer_neighbors = None\n\n        error_ret = (None, None)\n         \n        current_peer_degree = len(current_peer_neighbors)\n        if current_peer_degree == 0:\n            # nowhere to go \n            log.debug(\"%s: current peer degree is 0\" % (self.my_hostport))\n            return error_ret\n\n        next_peer = current_peer_neighbors[ random.randint(0, len(current_peer_neighbors)-1) ]\n        next_peer_neighbors = self.get_neighbors( next_peer, con=con, path=path, peer_table=peer_table )\n        if next_peer_neighbors is None or len(next_peer_neighbors) == 0:\n            # walk failed, or nowhere to go\n            # restart the walk\n            log.debug(\"%s: failed to get neighbors of %s\" % (self.my_hostport, next_peer))\n            return error_ret\n\n        next_peer_degree = len(next_peer_neighbors)\n\n        p = random.random()\n        if p <= min(1.0, float(current_peer_degree) / float(next_peer_degree)):\n            if prev_peer == next_peer and current_peer_degree > 1:\n                # find a different peer\n                search = current_peer_neighbors[:]\n                if next_peer in search:\n                    search.remove(next_peer)\n\n                alt_peer = search[ random.randint(0, len(search)-1) ]\n                alt_peer_neighbors = self.get_neighbors( alt_peer, con=con, path=path, peer_table=peer_table )\n                if alt_peer_neighbors is None or len(alt_peer_neighbors) == 0:\n                    # walk failed, or nowhere to go\n                    # restart the walk\n                    log.debug(\"%s: failed to get neighbors of %s\" % (self.my_hostport, alt_peer))\n                    return error_ret\n\n                alt_peer_degree = len(alt_peer_neighbors)\n\n                q = random.random()\n                if q <= min( 1.0, min( 1.0, (float(current_peer_degree) / float(alt_peer_degree))**2 ), max( 1.0, (float(prev_peer_degree) / float(current_peer_degree))**2 ) ):\n                    # go to the alt peer instead\n                    ret_current_peer = alt_peer\n                    ret_current_peer_neighbors = alt_peer_neighbors\n\n                else:\n                    # go to next peer\n                    ret_current_peer = next_peer\n                    ret_current_peer_neighbors = next_peer_neighbors\n\n            else:\n                # go to next peer\n                ret_current_peer = next_peer\n                ret_current_peer_neighbors = next_peer_neighbors\n        else:\n            # stay here\n            ret_current_peer = current_peer\n            ret_current_peer_neighbors = self.get_neighbors( current_peer, con=con, path=path, peer_table=peer_table )\n            if ret_current_peer_neighbors is None or len(ret_current_peer_neighbors) == 0:\n                # nowhere to go\n                log.debug(\"%s: failed to refresh %s\" % (self.my_hostport, current_peer))\n                return error_ret\n\n        return (ret_current_peer, ret_current_peer_neighbors)", "response": "Random walk of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_current_peers( self, peer_table=None ):\n        # get current peers\n        current_peers = None\n\n        with AtlasPeerTableLocked(peer_table) as ptbl:\n            current_peers = ptbl.keys()[:]\n\n        return current_peers", "response": "Get the current set of peers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef canonical_new_peer_list( self, peers_to_add ):\n        new_peers = list(set(self.new_peers + peers_to_add))\n        random.shuffle( new_peers )\n        \n        # canonicalize\n        tmp = []\n        for peer in new_peers:\n            tmp.append( self.canonical_peer(peer) )\n\n        new_peers = tmp\n\n        # don't talk to myself\n        if self.my_hostport in new_peers:\n            new_peers.remove(self.my_hostport)\n\n        return new_peers", "response": "Make a list of canonical new peers using the\n        self. new_peers and the given peers to add."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_new_peers( self, num_new_peers, current_peers, peer_queue=None, peer_table=None, con=None, path=None ):\n\n        if path is None:\n            path = self.atlasdb_path\n\n        # add newly-discovered peers, but only after we ping them\n        # to make sure they're actually alive.\n        peer_queue = atlas_peer_dequeue_all( peer_queue=peer_queue )\n\n        new_peers = self.canonical_new_peer_list( peer_queue )\n \n        # only handle a few peers for now\n        if len(new_peers) > 0:\n            log.debug(\"Add at most %s new peers out of %s options\" % (num_new_peers, len(new_peers)))\n            \n        added, present, filtered = self.add_new_peers( num_new_peers, new_peers, current_peers, con=con, path=path, peer_table=peer_table )\n        for peer in filtered:\n            if peer in new_peers:\n                new_peers.remove(peer)\n\n        new_peers = self.canonical_new_peer_list( added )\n\n        # DDoS prevention: don't let this get too big\n        max_new_peers = atlas_max_new_peers( self.max_neighbors )\n        if len(new_peers) > max_new_peers:\n            new_peers = new_peers[:max_new_peers]\n\n        self.new_peers = new_peers\n        return len(added)", "response": "Add at most num_new_peers new peers from the pending peer queue to the peer DB and update our new peer table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the set of existing peers with the given number of unhealthy peers.", "response": "def update_existing_peers( self, num_to_remove, peer_table=None, con=None, path=None ):\n        \"\"\"\n        Update the set of existing peers:\n        * revalidate the existing but old peers\n        * remove at most $num_to_remove unhealthy peers\n\n        Return the number of peers removed\n        \"\"\"\n        \n        if path is None:\n            path = self.atlasdb_path\n\n        # remove peers that are too old\n        if self.last_clean_time + atlas_peer_clean_interval() < time_now():\n            # remove stale peers\n            log.debug(\"%s: revalidate old peers\" % self.my_hostport)\n            atlas_revalidate_peers( con=con, path=path, peer_table=peer_table )\n            self.last_clean_time = time_now()\n\n        removed = self.remove_unhealthy_peers( num_to_remove, con=con, path=path, peer_table=peer_table )\n\n        # if they're also in the new set, remove them there too\n        for peer in removed:\n            if peer in self.new_peers:\n                self.new_peers.remove(peer)\n\n        return len(removed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes one round of the MHRWDA algorithm.", "response": "def step( self, local_inv=None, peer_table=None, peer_queue=None, con=None, path=None ):\n        \"\"\"\n        Execute one round of the peer discovery algorithm:\n        * Add at most 10 new peers from the pending peer queue\n        (but ping them first, and drop hosts if the pending queue\n        gets to be too long).\n        * Execute one step of the MHRWDA algorithm.  Add any new\n        peers from the neighbor sets discovered.\n        * Remove at most 10 old, unresponsive peers from the peer DB.\n        \"\"\"\n\n        if path is None:\n            path = self.atlasdb_path\n\n        if self.max_neighbors is None:\n            self.max_neighbors = atlas_max_neighbors()\n            log.debug(\"%s: max neighbors is %s\" % (self.my_hostport, self.max_neighbors))\n\n        current_peers = self.get_current_peers( peer_table=peer_table )\n\n        # add some new peers \n        num_added = self.update_new_peers( 10, current_peers, peer_queue=peer_queue, peer_table=peer_table, con=con, path=path )\n\n        # use MHRWDA to walk the peer graph.\n        # first, begin the walk if we haven't already \n        if self.current_peer is None and len(current_peers) > 0:\n            \n            self.current_peer = current_peers[ random.randint(0,len(current_peers)-1) ]\n            \n            log.debug(\"%s: crawl %s\" % (self.my_hostport, self.current_peer))\n            peer_neighbors = self.get_neighbors( self.current_peer, peer_table=peer_table, path=path, con=con )\n\n            if peer_neighbors is None or len(peer_neighbors) == 0:\n                log.debug(\"%s: no peers from %s\" % (self.my_hostport, self.current_peer))\n\n                # try again later\n                self.random_walk_reset()\n\n            else:\n                # success!\n                self.current_peer_neighbors = [self.canonical_peer(p) for p in peer_neighbors]\n\n                # don't talk to myself\n                if self.my_hostport in self.current_peer_neighbors:\n                    self.current_peer_neighbors.remove(self.my_hostport)\n\n                log.debug(\"%s: neighbors of %s are (%s): %s\" % (self.my_hostport, self.current_peer, len(self.current_peer_neighbors), \",\".join(self.current_peer_neighbors)))\n\n                # remember to contact these peers later\n                self.new_peers = list(set( self.new_peers + peer_neighbors ))\n\n        # can we walk now?\n        if self.current_peer is not None:\n            \n            next_peer, next_peer_neighbors = self.random_walk_graph( self.prev_peer, self.prev_peer_degree, self.current_peer, self.current_peer_neighbors, con=con, path=path, peer_table=peer_table )\n            if next_peer is not None and next_peer_neighbors is not None:\n                # success!\n                self.prev_peer = self.current_peer\n                self.prev_peer_degree = len(self.current_peer_neighbors)\n                self.current_peer = next_peer\n                self.current_peer_neighbors = next_peer_neighbors\n                \n                # crawl new peers\n                self.new_peers = list(set(self.new_peers + self.current_peer_neighbors))\n\n            else:\n                log.error(\"%s: failed to walk from %s\" % (self.my_hostport, self.current_peer))\n                self.random_walk_reset()\n\n\n        # update the existing peer info\n        num_removed = self.update_existing_peers( 10, con=con, path=path, peer_table=peer_table )\n        return num_added, num_removed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh the zonefile inventory for the given peer.", "response": "def step(self, con=None, path=None, peer_table=None, local_inv=None):\n        \"\"\"\n        Find peers with stale zonefile inventory data,\n        and refresh them.\n\n        Return True on success\n        Return False on error\n        \"\"\"\n        if path is None:\n            path = self.atlasdb_path\n\n        peer_hostports = []\n        stale_peers = []\n\n        num_peers = None\n        peer_hostports = None\n\n        with AtlasPeerTableLocked(peer_table) as ptbl:\n            num_peers = len(ptbl.keys())\n            peer_hostports = ptbl.keys()[:]\n\n            # who are we going to ping?\n            # someone we haven't pinged in a while, chosen at random\n            for peer in peer_hostports:\n                if not atlas_peer_has_fresh_zonefile_inventory( peer, peer_table=ptbl ):\n                    # haven't talked to this peer in a while\n                    stale_peers.append(peer)\n                    log.debug(\"Peer %s has a stale zonefile inventory\" % peer)\n\n        if len(stale_peers) > 0:\n            log.debug(\"Refresh zonefile inventories for %s peers\" % len(stale_peers))\n\n        for peer_hostport in stale_peers:\n            # refresh everyone\n            log.debug(\"%s: Refresh zonefile inventory for %s\" % (self.hostport, peer_hostport))\n            res = atlas_peer_refresh_zonefile_inventory( self.hostport, peer_hostport, 0, con=con, path=path, peer_table=peer_table, local_inv=local_inv )\n            if res is None:\n                log.warning(\"Failed to refresh zonefile inventory for %s\" % peer_hostport)\n        \n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloops forever pinging someone every pass.", "response": "def run(self, peer_table=None):\n        \"\"\"\n        Loop forever, pinging someone every pass.\n        \"\"\"\n        self.running = True\n        while self.running:\n            local_inv = atlas_get_zonefile_inventory()\n            t1 = time_now()\n            self.step( peer_table=peer_table, local_inv=local_inv, path=self.atlasdb_path )\n            t2 = time_now()\n\n            # don't go too fast \n            if t2 - t1 < PEER_HEALTH_NEIGHBOR_WORK_INTERVAL:\n                deadline = time_now() + PEER_HEALTH_NEIGHBOR_WORK_INTERVAL - (t2 - t1)\n                while time_now() < deadline and self.running:\n                    time_sleep( self.hostport, self.__class__.__name__, 1.0 )\n\n                if not self.running:\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a zonefile as present and inform the storage listener if it was new.", "response": "def set_zonefile_present(self, zfhash, block_height, con=None, path=None):\n        \"\"\"\n        Set a zonefile as present, and if it was previously absent, inform the storage listener\n        \"\"\"\n        was_present = atlasdb_set_zonefile_present( zfhash, True, con=con, path=path )\n\n        # tell anyone who cares that we got this zone file, if it was new \n        if not was_present and self.store_zonefile_cb:\n            log.debug('{} was new, so passing it along to zonefile storage watchers...'.format(zfhash))\n            self.store_zonefile_cb(zfhash, block_height)\n        else:\n            log.debug('{} was seen before, so not passing it along to zonefile storage watchers'.format(zfhash))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore the fetched zonefile data to storage and cache it locally.", "response": "def store_zonefile_data( self, fetched_zfhash, zonefile_data, min_block_height, peer_hostport, con, path ):\n        \"\"\"\n        Store the fetched zonefile (as a serialized string) to storage and cache it locally.\n        Update internal state to mark it present\n        Return True on success\n        Return False on error\n        \"\"\"\n        rc = add_atlas_zonefile_data( zonefile_data, self.zonefile_dir )\n        if not rc:\n            log.error(\"%s: Failed to store zonefile %s\" % (self.hostport, fetched_zfhash))\n\n        else:\n            # stored! remember it\n            log.debug(\"%s: got %s from %s\" % (self.hostport, fetched_zfhash, peer_hostport))\n\n            # update internal state\n            self.set_zonefile_present(fetched_zfhash, min_block_height, con=con, path=path)\n\n        return rc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store_zonefiles( self, zonefile_names, zonefiles, zonefile_txids, zonefile_block_heights, peer_zonefile_hashes, peer_hostport, path, con=None ):\n        ret = []\n\n        with AtlasDBOpen(con=con, path=path) as dbcon:\n\n            for fetched_zfhash, zonefile_txt in zonefiles.items():\n               \n                if fetched_zfhash not in peer_zonefile_hashes or fetched_zfhash not in zonefile_block_heights:\n                    # unsolicited\n                    log.warn(\"%s: Unsolicited zonefile %s\" % (self.hostport, fetched_zfhash))\n                    continue\n\n                rc = self.store_zonefile_data( fetched_zfhash, zonefile_txt, min(zonefile_block_heights[fetched_zfhash]), peer_hostport, dbcon, path )\n                if rc:\n                    # don't ask for it again\n                    ret.append( fetched_zfhash )\n\n        return ret", "response": "Store a list of zonefiles from the given peer_hostport."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_zonefile_origins( self, missing_zfinfo, peer_hostports ):\n        zonefile_origins = {}   # map peer hostport to list of zonefile hashes\n\n        # which peers can serve each zonefile?\n        for zfhash in missing_zfinfo.keys():\n            for peer_hostport in peer_hostports:\n                if not zonefile_origins.has_key(peer_hostport):\n                    zonefile_origins[peer_hostport] = []\n\n                if peer_hostport in missing_zfinfo[zfhash]['peers']:\n                    zonefile_origins[peer_hostport].append( zfhash )\n\n        return zonefile_origins", "response": "Find out which peers can serve which zonefiles"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step(self, path=None, peer_table=None):\n\n        # if os.environ.get(\"BLOCKSTACK_TEST\", None) == \"1\":\n        #    log.debug(\"%s: %s step\" % (self.hostport, self.__class__.__name__))\n\n        if path is None:\n            path = self.atlasdb_path\n\n        num_fetched = 0\n        missing_zinfo = None\n        peer_hostports = None\n\n        with AtlasPeerTableLocked(peer_table) as ptbl: \n            missing_zfinfo = atlas_find_missing_zonefile_availability( peer_table=ptbl, path=path )\n            peer_hostports = ptbl.keys()[:]\n\n        # ask for zonefiles in rarest-first order\n        zonefile_ranking = [ (missing_zfinfo[zfhash]['popularity'], zfhash) for zfhash in missing_zfinfo.keys() ]\n        zonefile_ranking.sort()\n        zonefile_hashes = list(set([zfhash for (_, zfhash) in zonefile_ranking]))\n        zonefile_names = dict([(zfhash, missing_zfinfo[zfhash]['names']) for zfhash in zonefile_hashes])\n        zonefile_txids = dict([(zfhash, missing_zfinfo[zfhash]['txid']) for zfhash in zonefile_hashes])\n        zonefile_block_heights = dict([(zfhash, missing_zfinfo[zfhash]['block_heights']) for zfhash in zonefile_hashes])\n        zonefile_origins = self.find_zonefile_origins( missing_zfinfo, peer_hostports )\n\n        # filter out the ones that are already cached\n        for i in xrange(0, len(zonefile_hashes)):\n            # is this zonefile already cached?\n            zfhash = zonefile_hashes[i]\n            present = is_zonefile_cached( zfhash, self.zonefile_dir, validate=True )\n            if present:\n                log.debug(\"%s: zonefile %s already cached.  Marking present\" % (self.hostport, zfhash))\n                zonefile_hashes[i] = None\n\n                # mark it as present\n                self.set_zonefile_present(zfhash, min(zonefile_block_heights[zfhash]), path=path)\n\n        zonefile_hashes = filter( lambda zfh: zfh is not None, zonefile_hashes )\n\n        if len(zonefile_hashes) > 0:\n            log.debug(\"%s: missing %s unique zonefiles\" % (self.hostport, len(zonefile_hashes)))\n        \n        while len(zonefile_hashes) > 0 and self.running:\n\n            zfhash = zonefile_hashes[0]\n            zfnames = zonefile_names[zfhash]\n            zftxid = zonefile_txids[zfhash]\n            peers = missing_zfinfo[zfhash]['peers']\n           \n            # try this zonefile's hosts in order by perceived availability\n            peers = atlas_rank_peers_by_health( peer_list=peers, with_zero_requests=True )\n            if len(peers) > 0:\n                log.debug(\"%s: zonefile %s available from %s peers (%s...)\" % (self.hostport, zfhash, len(peers), \",\".join(peers[:min(5, len(peers))])))\n\n            for peer_hostport in peers:\n\n                if zfhash not in zonefile_origins[peer_hostport]:\n                    # not available\n                    log.debug(\"%s not available from %s\" % (zfhash, peer_hostport))\n                    continue\n\n                # what other zonefiles can we get?\n                # only ask for the ones we don't have\n                peer_zonefile_hashes = []\n                for zfh in zonefile_origins[peer_hostport]:\n                    if zfh in zonefile_hashes:\n                        # can ask for this one too\n                        peer_zonefile_hashes.append( zfh )\n\n                if len(peer_zonefile_hashes) == 0:\n                    log.debug(\"%s: No zonefiles available from %s\" % (self.hostport, peer_hostport))\n                    continue\n\n                # get them all\n                log.debug(\"%s: get %s zonefiles from %s\" % (self.hostport, len(peer_zonefile_hashes), peer_hostport))\n                zonefiles = atlas_get_zonefiles( self.hostport, peer_hostport, peer_zonefile_hashes, peer_table=peer_table )\n                if zonefiles is not None:\n\n                    # got zonefiles!\n                    stored_zfhashes = self.store_zonefiles( zonefile_names, zonefiles, zonefile_txids, zonefile_block_heights, peer_zonefile_hashes, peer_hostport, path )\n                    \n                    # don't ask again\n                    log.debug(\"Stored %s zonefiles\" % len(stored_zfhashes))\n                    for zfh in stored_zfhashes:\n                        if zfh in peer_zonefile_hashes:\n                            peer_zonefile_hashes.remove(zfh)\n                        if zfh in zonefile_hashes:\n                            zonefile_hashes.remove(zfh)\n\n                        num_fetched += 1\n                \n                else:\n                    log.debug(\"%s: no data received from %s\" % (self.hostport, peer_hostport))\n\n                with AtlasPeerTableLocked() as ptbl:\n                    # if the node didn't actually have these zonefiles, then \n                    # update their inventories so we don't ask for them again.\n                    # TODO: do NOT ban nodes that repeatedly lie to us, since the \"node\" could be a load-balancer for a set of nodes that may or may not have the zonefile\n                    for zfh in peer_zonefile_hashes:\n                        log.debug(\"%s: %s did not have %s\" % (self.hostport, peer_hostport, zfh))\n                        atlas_peer_set_zonefile_status( peer_hostport, zfh, False, zonefile_bits=missing_zfinfo[zfh]['indexes'], peer_table=ptbl )\n\n                        if zfh in zonefile_origins[peer_hostport]:\n                            zonefile_origins[peer_hostport].remove( zfh )\n\n\n            # done with this zonefile\n            if zfhash in zonefile_hashes:\n                zonefile_hashes.remove(zfhash)\n\n        if len(zonefile_hashes) > 0 or num_fetched > 0:\n            log.debug(\"%s: fetched %s zonefiles\" % (self.hostport, num_fetched))\n\n        return num_fetched", "response": "This method is called by the blockstack module to fetch the set of missing zonefiles for this port."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step( self, peer_table=None, zonefile_queue=None, path=None ):\n        if path is None:\n            path = self.atlasdb_path\n\n        if BLOCKSTACK_TEST:\n            log.debug(\"%s: %s step\" % (self.hostport, self.__class__.__name__))\n\n        if self.push_timeout is None:\n            self.push_timeout = atlas_push_zonefiles_timeout()\n\n        zfinfo = atlas_zonefile_push_dequeue( zonefile_queue=zonefile_queue )\n        if zfinfo is None:\n            return 0\n\n        zfhash = zfinfo['zonefile_hash']\n        zfdata_txt = zfinfo['zonefile']\n        name = zfinfo['name']\n        txid = zfinfo['txid']\n\n        zfbits = atlasdb_get_zonefile_bits( zfhash, path=path )\n        if len(zfbits) == 0:\n            # not recognized \n            return 0\n\n        # it's a valid zonefile.  store it.\n        rc = add_atlas_zonefile_data( str(zfdata_txt), self.zonefile_dir )\n        if not rc:\n            log.error(\"Failed to replicate zonefile %s to external storage\" % zfhash)\n\n        peers = None\n        \n        # see if we can send this somewhere\n        with AtlasPeerTableLocked(peer_table) as ptbl:\n            peers = atlas_zonefile_find_push_peers( zfhash, peer_table=ptbl, zonefile_bits=zfbits )\n\n        if len(peers) == 0:\n            # everyone has it\n            log.debug(\"%s: All peers have zonefile %s\" % (self.hostport, zfhash))\n            return 0\n\n        # push it off\n        ret = 0\n        for peer in peers:\n            log.debug(\"%s: Push to %s\" % (self.hostport, peer))\n            atlas_zonefile_push( self.hostport, peer, zfdata_txt, timeout=self.push_timeout )\n            ret += 1\n\n        return ret", "response": "This method is called by the blockstack module to push the zonefile to all the peers that need it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef queuedb_create(path):\n\n    global QUEUE_SQL, ERROR_SQL\n\n    lines = [l + \";\" for l in QUEUE_SQL.split(\";\")]\n    con = sqlite3.connect( path, isolation_level=None )\n    db_query_execute(con, 'pragma mmap_size=536870912', ())\n    for line in lines:\n        db_query_execute(con, line, ())\n\n    con.commit()\n    con.row_factory = queuedb_row_factory\n    return con", "response": "Create a sqlite3 db at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Dict row factory for the queuedb table.", "response": "def queuedb_row_factory(cursor, row):\n    \"\"\"\n    Dict row factory\n    \"\"\"\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef queuedb_find(path, queue_id, name, offset=None, limit=None):\n    return queuedb_findall(path, queue_id, name=name, offset=offset, limit=limit)", "response": "Find a record by name and queue ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef queuedb_findall(path, queue_id, name=None, offset=None, limit=None):\n    sql = \"SELECT * FROM queue WHERE queue_id = ? ORDER BY rowid ASC\"\n    args = (queue_id,)\n    \n    if name:\n        sql += ' AND name = ?'\n        args += (name,)\n\n    if limit:\n        sql += ' LIMIT ?'\n        args += (limit,)\n    \n    if offset:\n        sql += ' OFFSET ?'\n        args += (offset,)\n\n    sql += ';'\n    \n    db = queuedb_open(path)\n    if db is None:\n        raise Exception(\"Failed to open %s\" % path)\n\n    cur = db.cursor()\n    rows = queuedb_query_execute(cur, sql, args)\n\n    count = 0\n    ret = []\n    for row in rows:\n        dat = {}\n        dat.update(row)\n        ret.append(dat)\n\n    db.close()\n    return ret", "response": "Find all queued entries for a queue and a name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend an element to the back of the queue.", "response": "def queuedb_append(path, queue_id, name, data):\n    \"\"\"\n    Append an element to the back of the queue.\n    Return True on success\n    Raise on error\n    \"\"\"\n    sql = \"INSERT INTO queue VALUES (?,?,?);\"\n    args = (name, queue_id, data)\n\n    db = queuedb_open(path)\n    if db is None:\n        raise Exception(\"Failed to open %s\" % path)\n\n    cur = db.cursor()\n    res = queuedb_query_execute(cur, sql, args)\n\n    db.commit()\n    db.close()\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an element from a queue.", "response": "def queuedb_remove(path, entry, cur=None):\n    \"\"\"\n    Remove an element from a queue.\n    Return True on success\n    Raise on error\n    \"\"\"\n    sql = \"DELETE FROM queue WHERE queue_id = ? AND name = ?;\"\n    args = (entry['queue_id'], entry['name'])\n\n    cursor = None\n    if cur:\n        cursor = cur\n    else:\n        db = queuedb_open(path)\n        if db is None:\n            raise Exception(\"Failed to open %s\" % path)\n\n        cursor = db.cursor()\n\n    res = queuedb_query_execute(cursor, sql, args)\n\n    if cur is None:\n        db.commit()\n        db.close()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all entries from a queue", "response": "def queuedb_removeall(path, entries):\n    \"\"\"\n    Remove all entries from a queue\n    \"\"\"\n    db = queuedb_open(path)\n    if db is None:\n        raise Exception(\"Failed to open %s\" % path)\n\n    cursor = db.cursor()\n    queuedb_query_execute(cursor, 'BEGIN', ())\n\n    for entry in entries:\n        queuedb_remove(path, entry, cur=cursor)\n\n    queuedb_query_execute(cursor, 'END', ())\n    db.commit()\n    db.close()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_renew_burn_info( outputs ):\n    if len(outputs) < 4:\n        raise Exception(\"Malformed renew outputs: don't have 4\")\n\n    burn_addr = virtualchain.script_hex_to_address(outputs[3]['script'])\n    if burn_addr is None:\n        raise Exception(\"Malformed renew inputs: burn output is a nonstandard script\")\n\n    op_fee = outputs[3]['value']\n    return {'burn_address': burn_addr, 'op_fee': op_fee}", "response": "Get the burn address and op_fee from the outputs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of names owned by a given sender.", "response": "def get_num_names_owned( state_engine, checked_ops, sender ):\n    \"\"\"\n    Find out how many preorders a given sender (i.e. a script)\n    actually owns, as of this transaction.\n    \"\"\"\n    \n    count = 0\n    registers = find_by_opcode( checked_ops, \"NAME_REGISTRATION\" )\n\n    for reg in registers:\n        if reg['sender'] == sender:\n            count += 1\n\n    count += len( state_engine.get_names_owned_by_sender( sender ) )\n    log.debug(\"Sender '%s' owns %s names\" % (sender, count))\n    return count"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stacks_payment(state_engine, nameop, state_op_type):\n    token_units = None\n    tokens_paid = None\n    name = nameop['name']\n    token_fee = nameop.get('token_fee', None)\n    tokens_paid = None\n\n    assert token_fee is None or isinstance(token_fee, (int,long)), 'Invalid token fee {} ({})'.format(token_fee, type(token_fee))\n    \n    namespace_id = get_namespace_from_name(name)\n    name_without_namespace = get_name_from_fq_name(name)\n    namespace = state_engine.get_namespace(namespace_id)\n\n    if state_op_type == 'NAME_REGISTRATION':\n        # STACKs would already have been paid by a preorder.\n        # find out how much, if any\n        preorder = state_create_get_preorder(nameop)\n        assert preorder, 'BUG: no preorder set'\n        assert 'token_fee' in preorder, 'BUG: no token_fee set in preorder'\n        assert 'token_units' in preorder, 'BUG: no token_units set in preorder'\n\n        token_units = preorder['token_units']\n        tokens_paid = preorder['token_fee']\n\n        # must have paid STACKs\n        if token_units != TOKEN_TYPE_STACKS:\n            return {'status': False, 'error': 'Name {} paid for in {}, not {}'.format(name, token_units, TOKEN_TYPE_STACKS)}\n\n    elif state_op_type == 'NAME_RENEWAL':\n        # will have paid in Stacks in the nameop (but not yet debited the account, so we'll need to \n        # check the account balance later on in check_renewal())\n        if token_fee is None or token_fee == 0:\n            return {'status': False, 'error': 'No token fee given for {}'.format(name)}\n\n        token_units = TOKEN_TYPE_STACKS\n        tokens_paid = token_fee\n\n    else:\n        raise Exception(\"Unknown state operation type {}\".format(state_op_type))\n\n    return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}", "response": "Get the STACKs payment for a given nameop."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck a token payment was enough and was of the right type", "response": "def check_token_payment(name, token_price, stacks_payment_info):\n    \"\"\"\n    Check a token payment was enough and was of the right type\n    Return {'status': True, 'tokens_paid': ..., 'token_units': ...} if so\n    Return {'status': False} if not\n    \"\"\"\n    token_units = stacks_payment_info['token_units']\n    tokens_paid = stacks_payment_info['tokens_paid']\n    tokens_paid = int(tokens_paid)\n\n    # did the preorder/renewer pay the *right* tokens?\n    if token_units != TOKEN_TYPE_STACKS:\n        log.warning('Account paid in {}, but this namespace only accepts {}'.format(token_units, TOKEN_TYPE_STACKS))\n        return {'status': False}\n\n    # did we pay enough?\n    if tokens_paid < token_price:\n        # not enough!\n        log.warning(\"Name buyer paid {} {}s, but '{}' costs {} units of {}s\".format(tokens_paid, token_units, name, token_price, token_units))\n        return {'status': False}\n\n    return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies that the amount of tokens paid for a name priced in BTC is paid for a namespace type.", "response": "def check_payment_in_stacks(state_engine, nameop, state_op_type, fee_block_id):\n    \"\"\"\n    Verify that if tokens were paid for a name priced in BTC, that enough were paid.\n    Does not check account balances or namespace types; it only inspects the transaction data.\n\n    Returns {'status': True, 'tokens_paid': ..., 'token_units': ...} on success\n    Returns {'status': False} on error\n    \"\"\"\n    name = nameop['name']\n    namespace_id = get_namespace_from_name(name)\n    name_without_namespace = get_name_from_fq_name(name)\n    namespace = state_engine.get_namespace( namespace_id )\n\n    stacks_payment_info = get_stacks_payment(state_engine, nameop, state_op_type)\n    if stacks_payment_info['status']:\n        # got a stacks payment! check price and make sure we paid the right amount\n        tokens_paid = stacks_payment_info['tokens_paid']\n        token_units = stacks_payment_info['token_units']\n\n        log.debug('Transaction pays {} units of {} for {}, even though its namespace was priced in BTC'.format(tokens_paid, token_units, name))\n        \n        stacks_price = price_name_stacks(name_without_namespace, namespace, fee_block_id)   # price in Stacks, but following the BTC-given price curve\n        res = check_token_payment(name, stacks_price, stacks_payment_info)\n        if res['status']:\n            # success\n            return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}\n\n    return {'status': False}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the payment of a nameop is correct and that the nameop paid the right amount of BTC or STACKs.", "response": "def check_payment_v1(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id):\n    \"\"\"\n    Verify that for a version-1 namespace, the nameop paid the right amount of BTC or STACKs.\n    nameop is either a name registration or name renewal\n    Return {'status': True, 'tokens_paid': ..., 'token_units': ...}\n    Return {'status': False} if not\n    \"\"\"\n    # priced in BTC or Stacks\n    assert name_fee is not None\n    assert isinstance(name_fee, (int,long))\n\n    epoch_features = get_epoch_features(block_id)\n    \n    name = nameop['name']\n    namespace_id = get_namespace_from_name(name)\n    name_without_namespace = get_name_from_fq_name(name)\n    namespace = state_engine.get_namespace( namespace_id )\n    assert namespace['version'] == NAMESPACE_VERSION_PAY_TO_BURN\n\n    res = None\n\n    # burn address must be the default burn address\n    if burn_address != BLOCKSTACK_BURN_ADDRESS:\n        log.warning('Buyer of {} used the wrong burn address ({}): expected {}'.format(name, burn_address, BLOCKSTACK_BURN_ADDRESS))\n        return {'status': False}\n\n    # possible that the transaction paid in Stacks?\n    if EPOCH_FEATURE_NAMEOPS_COST_TOKENS in epoch_features:\n        # did we pay any stacks?\n        res = get_stacks_payment(state_engine, nameop, state_op_type)\n        if res['status']:\n            # paid something in Stacks. Will ignore BTC.\n            res = check_payment_in_stacks(state_engine, nameop, state_op_type, fee_block_id)\n            if not res['status']:\n                log.warning(\"Buyer of {} paid in Stacks, but did not pay enough\".format(name))\n                return {'status': False}\n\n            tokens_paid = res['tokens_paid']\n            token_units = res['token_units']\n            return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}\n\n    # did not pay in Stacks.\n    # did the transaction pay in BTC?\n    btc_price = price_name(name_without_namespace, namespace, fee_block_id)  # price in BTC\n    if name_fee < btc_price:\n        log.debug('Paid {} satoshis for {}, but need at least {}.'.format(name_fee, name, btc_price))\n        return {'status': False}\n        \n    # paid in BTC\n    log.debug('Paid {} satoshis for {}'.format(name_fee, name))\n    return {'status': True, 'tokens_paid': name_fee, 'token_units': 'BTC'}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_payment_v2(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id):\n    # priced in BTC only if the namespace creator can receive name fees.\n    # once the namespace switches over to burning, then the name creator can pay in Stacks as well.\n    assert name_fee is not None\n    assert isinstance(name_fee, (int,long))\n\n    epoch_features = get_epoch_features(block_id)\n\n    name = nameop['name']\n    namespace_id = get_namespace_from_name(name)\n    name_without_namespace = get_name_from_fq_name(name)\n    namespace = state_engine.get_namespace( namespace_id )\n    assert namespace['version'] == NAMESPACE_VERSION_PAY_TO_CREATOR\n\n    # need to be in the right epoch--i.e. pay-to-creator needs to be a feature\n    if EPOCH_FEATURE_NAMESPACE_BURN_TO_CREATOR not in epoch_features:\n        log.warning(\"Name '{}' was created in namespace '{}', with cversion bits 0x{:x}, which is not supported in this epoch\".format(name, namespace['namespace_id'], namespace['version']))\n        return {'status': False}\n\n    # check burn address\n    receive_fees_period = get_epoch_namespace_receive_fees_period(block_id, namespace['namespace_id'])\n    expected_burn_address = None\n    tokens_allowed = None\n\n    # can only burn to namespace if the namespace is young enough (starts counting from NAMESPACE_REVEAL)\n    # can only pay in tokens if the register takes place after the pay-to-creator period (receive_fees_period) expires\n    if namespace['reveal_block'] + receive_fees_period >= block_id:\n        log.debug(\"Register must pay to v2 namespace address {}\".format(namespace['address']))\n        expected_burn_address = namespace['address']\n        tokens_allowed = False\n    else:\n        log.debug(\"Register must pay to burn address {}\".format(BLOCKSTACK_BURN_ADDRESS))\n        expected_burn_address = BLOCKSTACK_BURN_ADDRESS\n        tokens_allowed = True\n\n    if burn_address != expected_burn_address:\n        log.warning(\"Buyer of {} used the wrong burn address ({}): expected {}\".format(name, burn_address, expected_burn_address))\n        return {'status': False}\n\n    # allowed to pay in Stacks?\n    if EPOCH_FEATURE_NAMEOPS_COST_TOKENS in epoch_features:\n        # did we pay any stacks?\n        res = get_stacks_payment(state_engine, nameop, state_op_type)\n        if res['status']:\n            # paid something in Stacks. Will ignore BTC.\n            if not tokens_allowed:\n                log.warning('Buyer of {} paid in Stacks, but should have paid in BTC to the namespace creator'.format(name))\n                return {'status': False}\n\n            res = check_payment_in_stacks(state_engine, nameop, state_op_type, fee_block_id)\n            if not res['status']:\n                log.warning(\"Buyer of {} paid in Stacks, but did not pay enough\".format(name))\n                return {'status': False}\n\n            tokens_paid = res['tokens_paid']\n            token_units = res['token_units']\n            return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}\n\n    # did not pay in stacks tokens, or this isn't allowed yet\n    btc_price = price_name(name_without_namespace, namespace, fee_block_id)   # price reflects namespace version\n    \n    # fee must be high enough (either the preorder paid the right fee at the preorder block height,\n    # or the renewal paid the right fee at the renewal height)\n    if name_fee < btc_price:\n        log.warning(\"Name '%s' costs %s satoshis, but paid %s satoshis\" % (name, btc_price, name_fee))\n        return {'status': False}\n\n    log.debug('Paid {} satoshis for {} to {}'.format(name_fee, name, burn_address))\n    return {'status': True, 'tokens_paid': name_fee, 'token_units': 'BTC'}", "response": "Verify that the nameop paid the right amount of BTC or Stacks and if so pay in the right amount of Stacks or registers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that the nameop paid the right amount of STACKs and the burn address of the burn.", "response": "def check_payment_v3(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id):\n    \"\"\"\n    Verify that for a version-3 namespace (burn Stacks), the nameop paid the right amount of STACKs.\n    Return {'status': True, 'tokens_paid': ..., 'token_units': ...} if so\n    Return {'status': False} if not\n    \"\"\"\n    # priced in STACKs only.  Name price will be STACKs\n    epoch_features = get_epoch_features(block_id)\n    \n    name = nameop['name']\n    namespace_id = get_namespace_from_name(name)\n    name_without_namespace = get_name_from_fq_name(name)\n    namespace = state_engine.get_namespace( namespace_id )\n    assert namespace['version'] == NAMESPACE_VERSION_PAY_WITH_STACKS\n\n    # need to be in the right epoch--i.e. need STACKs to exist\n    if EPOCH_FEATURE_NAMESPACE_PAY_WITH_STACKS not in epoch_features:\n        log.warning(\"Name '{}' was created in namespace '{}', with version bits 0x{:x}, which is not supported in this epoch\".format(name, namespace['namespace_id'], namespace['version']))\n        return {'status': False}\n    \n    # burn address must be the default burn address\n    if burn_address != BLOCKSTACK_BURN_ADDRESS:\n        log.warning('Buyer of {} used the wrong burn address ({}): expected {}'.format(name, burn_address, BLOCKSTACK_BURN_ADDRESS))\n        return {'status': False}\n\n    # priced in STACKs only.  Name price will be STACKs, and the preorder or renewal must have spent STACKs.\n    stacks_payment_info = get_stacks_payment(state_engine, nameop, state_op_type)\n    if not stacks_payment_info['status']:\n        # failed to query, and Stacks are required\n        return {'status': False}\n    \n    stacks_price = price_name(name_without_namespace, namespace, fee_block_id)   # price in Stacks, since this is a Stacks namespace\n    res = check_token_payment(name, stacks_price, stacks_payment_info)\n    if not res['status']:\n        # invalid payment\n        return {'status': False}\n\n    tokens_paid = stacks_payment_info['tokens_paid']\n    token_units = stacks_payment_info['token_units']\n\n    return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the right payment was made in the right cryptocurrency units.", "response": "def check_payment(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id):\n    \"\"\"\n    Verify that the right payment was made, in the right cryptocurrency units.\n    Does not check any accounts or modify the nameop in any way; it only checks that the name was paid for by the transaction.\n\n    NOTE: if state_op_type is NAME_REGISTRATION, you will need to have called state_create_put_preorder() before calling this method!\n\n    Returns {'status': True, 'tokens_paid': tokens_paid, 'token_units': ...} if the payment information is correct.\n    Returns {'status': False} if not\n    \"\"\"\n    assert state_op_type in ['NAME_REGISTRATION', 'NAME_RENEWAL'], 'Invalid op type {}'.format(state_op_type)\n\n    assert name_fee is not None\n    assert isinstance(name_fee, (int,long))\n\n    name = nameop['name']\n    namespace_id = get_namespace_from_name(name)\n    namespace = state_engine.get_namespace( namespace_id )\n\n    res = None\n    log.debug('{} is a version-0x{} namespace'.format(namespace['namespace_id'], namespace['version']))\n\n    # check name fee, depending on which version.\n    if namespace['version'] == NAMESPACE_VERSION_PAY_TO_BURN:\n        res = check_payment_v1(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id)\n\n    elif namespace['version'] == NAMESPACE_VERSION_PAY_TO_CREATOR:\n        res = check_payment_v2(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id)\n        \n    elif namespace['version'] == NAMESPACE_VERSION_PAY_WITH_STACKS:\n        res = check_payment_v3(state_engine, state_op_type, nameop, fee_block_id, token_address, burn_address, name_fee, block_id)\n\n    else:\n        # unrecognized namespace rules\n        log.warning(\"Namespace {} has version bits 0x{:x}, which has unknown registration rules\".format(namespace['namespace_id'], namespace['version']))\n        return {'status': False}\n\n    if not res['status']:\n        return res\n\n    tokens_paid = res['tokens_paid']\n    token_units = res['token_units']\n\n    return {'status': True, 'tokens_paid': tokens_paid, 'token_units': token_units}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify validity of a registration nameop.", "response": "def check_register( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify the validity of a registration nameop.\n    * the name must be well-formed\n    * the namespace must be ready\n    * the name does not collide\n    * the name was preordered by the same sender as the last preorder\n    * the Bitcoin or Stacks fee paid by the preorder must be high enough (for some namespace-version-specific definition of \"high enough\")\n\n    NAME_REGISTRATION is not allowed during a namespace import, so the namespace must be ready.\n\n    Return True if accepted.\n    Return False if not.\n    \"\"\"\n\n    from ..nameset import BlockstackDB \n\n    name = nameop['name']\n    sender = nameop['sender']\n\n    # address mixed into the preorder\n    register_addr = nameop.get('recipient_address', None)\n    if register_addr is None:\n        log.warning(\"No registration address given\")\n        return False\n\n    recipient = nameop.get('recipient', None)\n    if recipient is None:\n        log.warning(\"No recipient script given\")\n        return False\n\n    # name must be well-formed\n    if not is_name_valid( name ):\n        log.warning(\"Malformed name '%s'\" % name)\n        return False\n\n    epoch_features = get_epoch_features(block_id)\n\n    name_fee = None\n    namespace = None\n    preorder_hash = None\n    preorder_block_number = None \n    name_block_number = None\n    consensus_hash = None\n    fee_block_id = None         # block ID at which the fee was paid\n    fee_vtxindex = None         # vtxindex at which the fee was paid\n    burn_address = None         # preorder/renew burn address\n    token_address = None        # if we're paying in tokens, this is the token account to debit\n    opcode = nameop['opcode']\n    first_registered = nameop['first_registered']\n\n    # name must be well-formed\n    if not is_b40( name ) or \"+\" in name or name.count(\".\") > 1:\n        log.warning(\"Malformed name '%s': non-base-38 characters\" % name)\n        return False\n\n    # name must not be revoked\n    if state_engine.is_name_revoked( name ):\n        log.warning(\"Name '%s' is revoked\" % name)\n        return False\n\n    namespace_id = get_namespace_from_name( name )\n\n    # namespace must exist and be ready\n    if not state_engine.is_namespace_ready( namespace_id ):\n        log.warning(\"Namespace '%s' is not ready\" % namespace_id)\n        return False\n\n    # get namespace...\n    namespace = state_engine.get_namespace( namespace_id )\n\n    # cannot exceed quota\n    num_names = get_num_names_owned( state_engine, checked_ops, recipient )\n    if num_names >= MAX_NAMES_PER_SENDER:\n        log.warning(\"Recipient '%s' has exceeded quota\" % recipient)\n        return False\n\n    # if multisig is not enabled in this epoch, and the recipient\n    # address is a p2sh address, then reject the transaction.\n    # this if for compatibility with 0.13\n    if virtualchain.is_multisig_address( register_addr ) and not epoch_has_multisig( block_id ):\n        log.warning(\"Multisig registration address %s, but this epoch (%s) does not support multisig\" % (register_addr, get_epoch_number(block_id)))\n        return False\n\n    # get preorder...\n    preorder = state_engine.get_name_preorder( name, sender, register_addr )\n    old_name_rec = state_engine.get_name( name, include_expired=True )\n\n    if preorder is None:\n        # not preordered\n        log.warning(\"Name '%s' does not exist, or is not preordered by %s\" % (name, sender))\n        return False\n\n    # bugfix?\n    if EPOCH_FEATURE_FIX_PREORDER_EXPIRE in epoch_features:\n        # preorder must not be expired\n        if preorder['block_number'] + NAME_PREORDER_EXPIRE < block_id:\n            log.warning(\"Preorder {} is expired\".format(preorder['preorder_hash']))\n            return False\n\n    # can't be registered already \n    if state_engine.is_name_registered( name ):\n        log.warning(\"Name '%s' is already registered\" % name)\n        return False \n\n    # name can't be registered if it was reordered before its namespace was ready\n    if not namespace.has_key('ready_block') or preorder['block_number'] < namespace['ready_block']:\n       log.warning(\"Name '%s' preordered before namespace '%s' was ready\" % (name, namespace_id))\n       return False\n\n    # name must be preordered by the same sender\n    if preorder['sender'] != sender:\n       log.warning(\"Name '%s' was not preordered by %s\" % (name, sender))\n       return False\n\n    # fee was included in the preorder (even if it's just dust)\n    if not 'op_fee' in preorder:\n       log.warning(\"Name '%s' preorder did not pay the fee\" % (name))\n       return False\n\n    name_fee = preorder['op_fee']\n    preorder_hash = preorder['preorder_hash']\n    preorder_block_number = preorder['block_number']\n    fee_block_id = preorder_block_number\n    fee_vtxindex = preorder['vtxindex']\n\n    burn_address = preorder['burn_address']\n    token_address = preorder['address']     # note that the *preorderer* pays for a registration in tokens, just as it is with BTC\n\n    # pass along the preorder\n    state_create_put_preorder( nameop, preorder )\n\n    if old_name_rec is None:\n        # Case 1(a): registered for the first time ever \n        log.debug(\"Registering name '%s'\" % name)\n        name_block_number = preorder['block_number']\n    \n    else:\n        # Case 1(b): name expired, and is now re-registered\n        log.debug(\"Re-registering name '%s'\" % name )\n    \n        # push back preorder block number to the original preorder\n        name_block_number = old_name_rec['block_number']\n\n    # check name payment\n    payment_res = check_payment(state_engine, \"NAME_REGISTRATION\", nameop, fee_block_id, token_address, burn_address, name_fee, block_id)\n    if not payment_res['status']:\n        log.warning(\"Name '{}' did not receive the appropriate payment\".format(name))\n        return False\n\n    log.debug('payment res: {}'.format(payment_res))\n\n    # extract payment info\n    token_fee = payment_res['tokens_paid']\n    token_units = payment_res['token_units']\n\n    if token_units == 'BTC':\n        # name was paid for in the preorder by burning BTC, not by spending Stacks\n        # if we paid tokens *as well*, then figure out how many and record it\n        assert token_fee == name_fee, 'Tokens paid in BTC does not match tokens paid in transaction ({} != {})'.format(token_fee, name_fee)\n\n        # sanity check\n        res = get_stacks_payment(state_engine, nameop, \"NAME_REGISTRATION\")\n        assert not res['status'], \"BUG: we paid in BTC but also Stacks\"\n\n        token_fee = 0\n    \n    else:\n        if EPOCH_FEATURE_NAMEOPS_COST_TOKENS not in epoch_features:\n            # can't do this---tokens aren't active yet\n            log.warning('Tried to pay for {} in Stacks before Stacks exist'.format(name))\n            return False\n\n        # name was paid for in the preorder by burning Stacks\n        assert token_fee is not None\n        assert token_units == TOKEN_TYPE_STACKS\n\n        # sanity check\n        res = get_stacks_payment(state_engine, nameop, \"NAME_REGISTRATION\")\n        assert res['status'], \"BUG: we paid in Stacks but did not\"\n        assert res['tokens_paid'] == token_fee\n        assert res['token_units'] == token_units\n\n    nameop['opcode'] = opcode\n    nameop['op_fee'] = name_fee\n    nameop['token_fee'] = '{}'.format(token_fee)   # NOTE: use a string to prevent integer overflow\n    nameop['preorder_hash'] = preorder_hash\n    nameop['importer'] = None\n    nameop['importer_address'] = None\n    nameop['consensus_hash'] = consensus_hash\n    nameop['revoked'] = False\n    nameop['namespace_block_number'] = namespace['block_number']\n    nameop['first_registered'] = first_registered\n    nameop['last_renewed'] = block_id\n    nameop['preorder_block_number'] = preorder_block_number\n    nameop['block_number'] = name_block_number\n\n    # not consensus-bearing, but required for SNV\n    nameop['last_creation_op'] = NAME_PREORDER \n\n    # propagate new sender information\n    nameop['sender'] = nameop['recipient']\n    nameop['address'] = nameop['recipient_address']\n    del nameop['recipient']\n    del nameop['recipient_address']\n\n    value_hash = nameop['value_hash']\n\n    if value_hash is not None:\n        # deny value hash if we're not in an epoch that supports register/update in one nameop\n        if EPOCH_FEATURE_OP_REGISTER_UPDATE not in epoch_features:\n            log.warning(\"Name '{}' has a zone file hash, but this is not supported in this epoch\".format(nameop['name']))\n            return False\n\n        log.debug(\"Adding value hash {} for name '{}'\".format(value_hash, nameop['name']))\n        \n    nameop['value_hash'] = value_hash\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies validity of a renewal nameop.", "response": "def check_renewal( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify the validity of a renewal nameop.\n    * the name must be well-formed\n    * the namespace must be ready\n    * the request must be sent by the owner.\n    * the mining fee must be high enough.\n    * the name must not be expired\n\n    Return True if accepted.\n    Return False if not.\n    \"\"\"\n\n    name = nameop['name']\n    sender = nameop['sender']\n    address = nameop['address']\n\n    epoch_features = get_epoch_features(block_id)\n\n    # address mixed into the preorder\n    recipient_addr = nameop.get('recipient_address', None)\n    if recipient_addr is None:\n        log.warning(\"No registration address given\")\n        return False\n\n    recipient = nameop.get('recipient', None)\n    if recipient is None:\n        log.warning(\"No recipient given\")\n        return False\n\n    # name must be well-formed\n    if not is_name_valid( name ):\n        log.warning(\"Malformed name '%s'\" % name)\n        return False\n\n    # pre F-day 2017, on renewal, the sender and recipient must be the same \n    # post F-day 2017, the recipient and sender can differ \n    if sender != recipient:\n        if EPOCH_FEATURE_OP_RENEW_TRANSFER_UPDATE not in epoch_features:\n            log.warning(\"Sender '%s' is not the recipient '%s'\" % (sender, recipient))\n            return False \n\n        else:\n            log.debug(\"Transferring '{}' to '{}'\".format(sender, recipient))\n\n    if recipient_addr != address:\n        if EPOCH_FEATURE_OP_RENEW_TRANSFER_UPDATE not in epoch_features:\n            log.warning(\"Sender address '%s' is not the recipient address '%s'\" % (address, recipient_addr))\n            return False\n\n        else:\n            log.debug(\"Transferring '{}' to '{}'\".format(address, recipient_addr))\n                \n    name_fee = None\n    namespace = None\n    preorder_hash = None\n    preorder_block_number = None \n    name_block_number = None\n    opcode = nameop['opcode']\n\n    # name must be well-formed\n    if not is_b40( name ) or \"+\" in name or name.count(\".\") > 1:\n        log.warning(\"Malformed name '%s': non-base-38 characters\" % name)\n        return False\n\n    # name must not be revoked\n    if state_engine.is_name_revoked( name ):\n        log.warning(\"Name '%s' is revoked\" % name)\n        return False\n\n    namespace_id = get_namespace_from_name( name )\n\n    # namespace must exist and be ready\n    if not state_engine.is_namespace_ready( namespace_id ):\n        log.warning(\"Namespace '%s' is not ready\" % namespace_id)\n        return False\n\n    # get namespace...\n    namespace = state_engine.get_namespace( namespace_id )\n\n    # cannot exceed quota\n    num_names = get_num_names_owned( state_engine, checked_ops, recipient )\n    if num_names >= MAX_NAMES_PER_SENDER:\n        log.warning(\"Recipient '%s' has exceeded quota\" % recipient)\n        return False\n\n    # name must be registered already \n    if not state_engine.is_name_registered( name ):\n        log.warning(\"Name '%s' is not registered\" % name)\n        return False\n\n    # pre F-day 2017: name must be owned by the recipient already\n    # post F-day 2017: doesn't matter\n    if not state_engine.is_name_owner( name, recipient ):\n        if EPOCH_FEATURE_OP_RENEW_TRANSFER_UPDATE not in epoch_features:\n            log.warning(\"Renew: Name '%s' not owned by recipient %s\" % (name, recipient))\n            return False\n\n    # name must be owned by the sender\n    if not state_engine.is_name_owner( name, sender ):\n        log.warning(\"Renew: Name '%s' not owned by sender %s\" % (name, sender))\n        return False\n\n    # fee borne by the renewal\n    if not 'op_fee' in nameop or nameop['op_fee'] is None:\n        log.warning(\"Name '%s' renewal did not pay the name registration fee\" % (name))\n        return False\n   \n    prev_name_rec = state_engine.get_name( name )\n    \n    first_registered = prev_name_rec['first_registered']\n    preorder_block_number = prev_name_rec['preorder_block_number']\n    name_block_number = prev_name_rec['block_number']\n    name_fee = nameop['op_fee']\n    preorder_hash = prev_name_rec['preorder_hash']\n    value_hash = prev_name_rec['value_hash']        # use previous name record's value hash by default\n    burn_address = nameop['burn_address']\n\n    fee_block_id = block_id         # fee for this name is paid now\n    fee_vtxindex = nameop['vtxindex']   # fee for this name is paid now\n    token_address = address         # current owner pays tokens to renew\n\n    # check name payment, but note that this does not query the account if we're paying with tokens (this just makes sure the nameop is well-formed)\n    payment_res = check_payment(state_engine, \"NAME_RENEWAL\", nameop, fee_block_id, token_address, burn_address, name_fee, block_id)\n    if not payment_res['status']:\n        log.warning(\"Name '{}' did not receive the appropriate payment\".format(name))\n        return False\n \n    # extract payment info\n    token_fee = payment_res['tokens_paid']\n    token_units = payment_res['token_units']\n\n    if token_units == 'BTC':\n        # paid in BTC\n        assert token_fee == name_fee, 'Tokens paid in BTC does not match tokens paid in transaction ({} != {})'.format(token_fee, name_fee)\n\n        # make sure we did NOT pay in stacks\n        res = get_stacks_payment(state_engine, nameop, \"NAME_RENEWAL\")\n        assert not res['status'], 'BUG: paid in both BTC and Stacks'\n\n        # no Stacks will be spent\n        state_transition_put_account_payment_info(nameop, None, None, None)\n        token_fee = 0\n\n    else:\n        if EPOCH_FEATURE_NAMEOPS_COST_TOKENS not in epoch_features:\n            # can't do this---tokens aren't active yet\n            log.warning('Tried to pay for {} in Stacks before Stacks exist'.format(name))\n            return False\n\n        # paid in tokens.  need to debit if this was a renewal \n        # charge the price of this name when we commit this state-transition\n        assert token_fee is not None\n        assert token_units == TOKEN_TYPE_STACKS, 'BUG: token units must be BTC or STACKS'\n\n        # make sure we did, in fact, pay in Stacks\n        res = get_stacks_payment(state_engine, nameop, 'NAME_RENEWAL')\n        assert res['status'], 'BUG: paid in Stacks but did not'\n        assert res['token_units'] == token_units\n        assert res['tokens_paid'] == token_fee\n\n        # make sure the account in question has enough balance\n        account_info = state_engine.get_account(token_address, token_units)\n        if account_info is None:\n            # no account!\n            log.warning(\"Name buyer {} does not have an account for {}\".format(token_address, token_units))\n            return False\n\n        # can this account afford it?\n        account_balance = state_engine.get_account_balance(account_info)\n        if account_balance < token_fee:\n            # not enough balance\n            log.warning(\"Address {} does not have enough {} tokens for {} (need at least {}, but only have {})\".format(token_address, token_units, name, token_fee, account_balance))\n            return False\n\n        # can afford it! debit this account\n        state_transition_put_account_payment_info(nameop, token_address, token_units, token_fee)\n\n    # if we're in an epoch that allows us to include a value hash in the renewal, and one is given, then set it \n    # instead of the previous name record's value hash.\n    if EPOCH_FEATURE_OP_RENEW_TRANSFER_UPDATE in epoch_features:\n        if nameop.has_key('value_hash') and nameop['value_hash'] is not None:\n            log.debug(\"Adding value hash {} for name '{}'\".format(nameop['value_hash'], nameop['name']))\n            value_hash = nameop['value_hash']\n\n    nameop['op_fee'] = name_fee\n    nameop['token_fee'] = '{}'.format(token_fee)      # NOTE: use a string to prevent integer overflow\n    nameop['preorder_hash'] = preorder_hash\n    nameop['namespace_block_number'] = namespace['block_number']\n    nameop['first_registered'] = first_registered\n    nameop['preorder_block_number'] = preorder_block_number\n    nameop['block_number'] = name_block_number\n    nameop['value_hash'] = value_hash\n\n    # renewal\n    nameop['last_renewed'] = block_id\n\n    # propagate new sender information\n    nameop['sender'] = nameop['recipient']\n    nameop['address'] = nameop['recipient_address']\n    nameop['sender_pubkey'] = prev_name_rec['sender_pubkey']\n\n    del nameop['recipient']\n    del nameop['recipient_address']\n    del nameop['burn_address']\n\n    # renewal!\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tx_extract( payload, senders, inputs, outputs, block_id, vtxindex, txid ):\n  \n    sender_script = None \n    sender_address = None \n    sender_pubkey_hex = None\n\n    recipient = None \n    recipient_address = None \n    burn_address = None\n    op_fee = None\n\n    op = NAME_REGISTRATION\n    opcode = 'NAME_REGISTRATION'\n\n    try:\n       # first 2 outputs matter (op_return, owner addr)\n       assert check_tx_output_types(outputs[:2], block_id)\n\n       recipient = get_registration_recipient_from_outputs( outputs )\n       recipient_address = virtualchain.script_hex_to_address( recipient )\n\n       assert recipient is not None \n       assert recipient_address is not None\n\n       # by construction, the first input comes from the principal\n       # who sent the registration transaction...\n       assert len(senders) > 0\n       assert 'script_pubkey' in senders[0].keys()\n       assert 'addresses' in senders[0].keys()\n\n       sender_script = str(senders[0]['script_pubkey'])\n       sender_address = str(senders[0]['addresses'][0])\n\n       assert sender_script is not None \n       assert sender_address is not None\n\n       if str(senders[0]['script_type']) == 'pubkeyhash':\n          sender_pubkey_hex = get_public_key_hex_from_tx( inputs, sender_address )\n\n       if len(outputs) >= 4:\n          # renewing\n          burn_info = get_renew_burn_info(outputs)\n          burn_address = burn_info['burn_address']\n          op_fee = burn_info['op_fee']\n\n          op = '{}{}'.format(NAME_RENEWAL, NAME_RENEWAL)\n          opcode = 'NAME_RENEWAL'\n\n    except Exception, e:\n       log.exception(e)\n       raise Exception(\"Failed to extract\")\n\n    parsed_payload = parse( payload, block_id )\n    assert parsed_payload is not None \n\n    ret = {\n       \"value_hash\": None,\n       \"sender\": sender_script,\n       \"address\": sender_address,\n       \"recipient\": recipient,\n       \"recipient_address\": recipient_address,\n       \"revoked\": False,\n       \"last_renewed\": block_id,\n       \"vtxindex\": vtxindex,\n       \"txid\": txid,\n       \"op\": op,\n       \"opcode\": opcode,\n    }\n\n    if opcode == 'NAME_REGISTRATION':\n        # registration\n        if parsed_payload['token_fee'] is not None:\n            # registration shouldn't have this field\n            assert parsed_payload['token_fee'] == 0\n\n        ret.update({ \n           'name': parsed_payload['name'],\n           'value_hash': parsed_payload['value_hash'],\n           \"first_registered\": block_id,\n           \"last_renewed\": block_id,\n         })\n\n\n    else:\n        # renewal\n        assert parsed_payload['token_fee'] is not None\n        ret.update({\n           'name': parsed_payload['name'],\n           'value_hash': parsed_payload['value_hash'],\n           'op_fee': op_fee,\n           \"burn_address\": burn_address,\n           'token_fee': parsed_payload['token_fee'],\n        })\n\n    # NOTE: will get deleted if this is a renew\n    if sender_pubkey_hex is not None:\n        ret['sender_pubkey'] = sender_pubkey_hex\n    else:\n        ret['sender_pubkey'] = None\n\n    return ret", "response": "This function extracts the name preorder transaction from the underlying blockchain transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninterpret a block s nulldata into a name.", "response": "def parse(bin_payload, block_height):\n    \"\"\"\n    Interpret a block's nulldata back into a name.  The first three bytes (2 magic + 1 opcode)\n    will not be present in bin_payload.\n \n    The name will be directly represented by the bytes given.\n    \n    This works for registrations and renewals.\n\n    Record format (pre F-day 2017):\n    \n    0    2  3                                  39\n    |----|--|----------------------------------|\n    magic op   name.ns_id (up to 37 bytes)\n\n\n    Record format (post F-day 2017):\n    \n    0    2  3                                  39                  59\n    |----|--|----------------------------------|-------------------|\n    magic op   name.ns_id (37 bytes, 0-padded)    zone file hash\n\n\n    Record format (STACKs phase 1):\n    (for register, tokens burned is ignored)\n    (for renew, tokens burned is the number of tokens to burn)\n    \n    0    2  3                                  39                  59                             67\n    |----|--|----------------------------------|-------------------|------------------------------|\n    magic op   name.ns_id (37 bytes, 0-padded)     zone file hash    tokens burned (big-endian)\n\n    \"\"\"\n    \n    # pre F-day 2017: bin_payload is the name.\n    # post F-day 2017: bin_payload is the name and possibly the update hash\n    # STACKs phase 1: bin_payload possibly has a token burn attached to the end\n    epoch_features = get_epoch_features(block_height)\n    fqn = None\n    value_hash = None\n    tokens_burned = 0\n\n    if EPOCH_FEATURE_OP_REGISTER_UPDATE in epoch_features or EPOCH_FEATURE_OP_RENEW_TRANSFER_UPDATE in epoch_features:\n        # payload is possibly name + zonefile hash, or name + zonefile hash + tokens\n        # if so, it's guaranteed to be max_name_len + value_hash_len bytes long.\n        name_value_len = LENGTHS['blockchain_id_name'] + LENGTHS['value_hash']\n        if len(bin_payload) >= name_value_len:\n            # has name and value hash, and possibly a token burn\n            # get name and value hash\n            value_hash = bin_payload[LENGTHS['blockchain_id_name']: LENGTHS['blockchain_id_name'] + LENGTHS['value_hash']].encode('hex')\n            fqn = bin_payload[:LENGTHS['blockchain_id_name']]\n            fqn = fqn.rstrip('\\x00')\n\n            if EPOCH_FEATURE_NAMEOPS_COST_TOKENS in epoch_features:\n                # might have tokens burned.  If so, it's all or nothing.\n                if len(bin_payload) == name_value_len + LENGTHS['tokens_burnt']:\n                    # we have a token count (this is a name renewal)\n                    bin_tokens = bin_payload[name_value_len: name_value_len + LENGTHS['tokens_burnt']]\n                    tokens_burned = int(bin_tokens.encode('hex'), 16)    # NOTE: big-endian\n\n                else:\n                    # must not have any bits dangling off the end \n                    if len(bin_payload) != name_value_len:\n                        log.warning('Invalid payload {}: expected {} bytes or {} bytes'.format(bin_payload.encode('hex'), name_value_len, name_value_len + LENGTHS['tokens_burnt']))\n                        return None \n\n                    # no token count (might be a register)\n                    tokens_burned = None\n\n            else:\n                # tokens are not active in this epoch.\n                # payload must be *exactly* name + value hash.\n                if len(bin_payload) != name_value_len:\n                    log.warning(\"Invalid payload {}: expected {} bytes\".format(bin_payload.encode('hex'), name_value_len))\n                    return None\n\n        else:\n            # payload is just a name\n            fqn = bin_payload\n\n    else:\n        # payload is only the name\n        fqn = bin_payload\n \n    if not is_name_valid( fqn ):\n        log.warning(\"Invalid name: {} ({})\".format(fqn, fqn.encode('hex')))\n        return None\n\n    return {\n       'opcode': 'NAME_REGISTRATION',       # NOTE: could be NAME_RENEWAL\n       'name': fqn,\n       'value_hash': value_hash,\n       'token_fee': tokens_burned,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check( state_engine, nameop, block_id, checked_ops ):\n\n    namespace_id_hash = nameop['preorder_hash']\n    consensus_hash = nameop['consensus_hash']\n    token_fee = nameop['token_fee']\n\n    # cannot be preordered already\n    if not state_engine.is_new_namespace_preorder( namespace_id_hash ):\n        log.warning(\"Namespace preorder '%s' already in use\" % namespace_id_hash)\n        return False\n\n    # has to have a reasonable consensus hash\n    if not state_engine.is_consensus_hash_valid( block_id, consensus_hash ):\n        valid_consensus_hashes = state_engine.get_valid_consensus_hashes( block_id )\n        log.warning(\"Invalid consensus hash '%s': expected any of %s\" % (consensus_hash, \",\".join( valid_consensus_hashes )) )\n        return False\n\n    # has to have paid a fee\n    if not 'op_fee' in nameop:\n        log.warning(\"Missing namespace preorder fee\")\n        return False\n\n    # paid to the right burn address\n    if nameop['burn_address'] != BLOCKSTACK_BURN_ADDRESS:\n        log.warning(\"Invalid burn address: expected {}, got {}\".format(BLOCKSTACK_BURN_ADDRESS, nameop['burn_address']))\n        return False\n    \n    # token burn fee must be present, if we're in the right epoch for it\n    epoch_features = get_epoch_features(block_id)\n    if EPOCH_FEATURE_STACKS_BUY_NAMESPACES in epoch_features:\n        # must pay in STACKs\n        if 'token_fee' not in nameop:\n            log.warning(\"Missing token fee\")\n            return False\n\n        token_fee = nameop['token_fee']\n        token_address = nameop['address']\n        token_type = TOKEN_TYPE_STACKS\n\n        # was a token fee paid?\n        if token_fee is None:\n            log.warning(\"No tokens paid by this NAMESPACE_PREORDER\")\n            return False\n\n        # does this account have enough balance?\n        account_info = state_engine.get_account(token_address, token_type)\n        if account_info is None:\n            log.warning(\"No account for {} ({})\".format(token_address, token_type))\n            return False\n\n        account_balance = state_engine.get_account_balance(account_info)\n\n        assert isinstance(account_balance, (int,long)), 'BUG: account_balance of {} is {} (type {})'.format(token_address, account_balance, type(account_balance))\n        assert isinstance(token_fee, (int,long)), 'BUG: token_fee is {} (type {})'.format(token_fee, type(token_fee))\n\n        if account_balance < token_fee:\n            # can't afford \n            log.warning(\"Account {} has balance {} {}, but needs to pay {} {}\".format(token_address, account_balance, token_type, token_fee, token_type))\n            return False\n\n        # debit this account when we commit\n        state_preorder_put_account_payment_info(nameop, token_address, token_type, token_fee)\n        \n        # NOTE: must be a string, to avoid overflow\n        nameop['token_fee'] = '{}'.format(token_fee)\n        nameop['token_units'] = TOKEN_TYPE_STACKS\n\n    else:\n        # must pay in BTC\n        # not paying in tokens, but say so!\n        state_preorder_put_account_payment_info(nameop, None, None, None)\n        nameop['token_fee'] = '0'\n        nameop['token_units'] = 'BTC'\n\n    return True", "response": "Check if a NAMESPACE_PREORDER nameop can be preordered."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a set of outputs find the fee sent to our burn address and return the fee and burn address on success as a dict.", "response": "def get_namespace_preorder_burn_info( outputs ):\n    \"\"\"\n    Given the set of outputs, find the fee sent \n    to our burn address.\n    \n    Return the fee and burn address on success as {'op_fee': ..., 'burn_address': ...}\n    Return None if not found\n    \"\"\"\n    if len(outputs) < 3:\n        # not a well-formed preorder \n        return None \n   \n    op_fee = outputs[2]['value']\n    burn_address = None\n\n    try:\n        burn_address = virtualchain.script_hex_to_address(outputs[2]['script'])\n        assert burn_address\n    except:\n        log.warning(\"Invalid burn script: {}\".format(outputs[2]['script']))\n        return None\n\n    return {'op_fee': op_fee, 'burn_address': burn_address}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse( bin_payload, block_height ):\n   \n    if len(bin_payload) < LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']:\n        log.warning(\"Invalid namespace preorder payload length %s\" % len(bin_payload))\n        return None\n\n    namespace_id_hash = bin_payload[ :LENGTHS['preorder_name_hash'] ]\n    consensus_hash = bin_payload[ LENGTHS['preorder_name_hash']: LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] ]\n    tokens_burned = None\n    \n    epoch_features = get_epoch_features(block_height)\n\n    if len(bin_payload) > LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']:\n        if EPOCH_FEATURE_STACKS_BUY_NAMESPACES not in epoch_features:\n            # not allowed--we can't use tokens in this epoch\n            log.warning(\"Invalid payload {}: expected {} bytes\".format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']))\n            return None\n\n        if len(bin_payload) != LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']:\n            # not allowed--invalid length\n            log.warning(\"Invalid payload {}: expected {} bytes\".format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']))\n            return None\n        \n        bin_tokens_burned = bin_payload[LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']: LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']]\n        tokens_burned = int(bin_tokens_burned.encode('hex'), 16)\n  \n    else:\n        # only allow the absence of the tokens field if we're in a pre-STACKs epoch \n        if EPOCH_FEATURE_STACKS_BUY_NAMESPACES in epoch_features:\n            # not allowed---we need the stacks token field\n            log.warning('Invalid payload {}: expected {} bytes'.format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']))\n            return None\n\n    namespace_id_hash = hexlify( namespace_id_hash )\n    consensus_hash = hexlify( consensus_hash )\n   \n    return {\n       'opcode': 'NAMESPACE_PREORDER',\n       'preorder_hash': namespace_id_hash,\n       'consensus_hash': consensus_hash,\n       'token_fee': tokens_burned\n    }", "response": "Parse the binary data into a tree of tokens and their associated namespace identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef snapshot_peek_number( fd, off ):\n    # read number of 8 bytes \n    fd.seek( off - 8, os.SEEK_SET )\n    value_hex = fd.read(8)\n    if len(value_hex) != 8:\n        return None\n    try:\n        value = int(value_hex, 16)\n    except ValueError:\n        return None\n\n    return value", "response": "Read the last 8 bytes of fd\n    and interpret it as an int."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef snapshot_peek_sigb64( fd, off, bytelen ):\n    fd.seek( off - bytelen, os.SEEK_SET )\n    sigb64 = fd.read(bytelen)\n    if len(sigb64) != bytelen:\n        return None\n\n    try:\n        base64.b64decode(sigb64)\n    except:\n        return None\n\n    return sigb64", "response": "Read the last bytes of fd and interpret it as a base64 - encoded base64 - encoded\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the hex - encoded hash of the file - like object fd", "response": "def get_file_hash( fd, hashfunc, fd_len=None ):\n    \"\"\"\n    Get the hex-encoded hash of the fd's data\n    \"\"\"\n\n    h = hashfunc()\n    fd.seek(0, os.SEEK_SET)\n\n    count = 0\n    while True:\n        buf = fd.read(65536)\n        if len(buf) == 0:\n            break\n\n        if fd_len is not None:\n            if count + len(buf) > fd_len:\n                buf = buf[:fd_len - count]\n\n        h.update(buf)\n        count += len(buf)\n\n    hashed = h.hexdigest()\n    return hashed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsigns a file with a given private key.", "response": "def fast_sync_sign_snapshot( snapshot_path, private_key, first=False ):\n    \"\"\"\n    Append a signature to the end of a snapshot path\n    with the given private key.\n\n    If first is True, then don't expect the signature trailer.\n\n    Return True on success\n    Return False on error\n    \"\"\"\n   \n    if not os.path.exists(snapshot_path):\n        log.error(\"No such file or directory: {}\".format(snapshot_path))\n        return False\n\n    file_size = 0\n    payload_size = 0\n    write_offset = 0\n    try:\n        sb = os.stat(snapshot_path)\n        file_size = sb.st_size\n        assert file_size > 8\n    except Exception as e:\n        log.exception(e)\n        return False\n    \n    num_sigs = 0\n    snapshot_hash = None\n    with open(snapshot_path, 'r+') as f:\n\n        if not first:\n            info = fast_sync_inspect(f)\n            if 'error' in info:\n                log.error(\"Failed to inspect {}: {}\".format(snapshot_path, info['error']))\n                return False\n\n            num_sigs = len(info['signatures'])\n            write_offset = info['sig_append_offset']\n            payload_size = info['payload_size']\n \n        else:\n            # no one has signed yet.\n            write_offset = file_size\n            num_sigs = 0\n            payload_size = file_size\n\n        # hash the file and sign the (bin-encoded) hash\n        privkey_hex = keylib.ECPrivateKey(private_key).to_hex()\n        hash_hex = get_file_hash( f, hashlib.sha256, fd_len=payload_size )\n        sigb64 = sign_digest( hash_hex, privkey_hex, hashfunc=hashlib.sha256 )\n      \n        if BLOCKSTACK_TEST:\n            log.debug(\"Signed {} with {} to make {}\".format(hash_hex, keylib.ECPrivateKey(private_key).public_key().to_hex(), sigb64))\n\n        # append\n        f.seek(write_offset, os.SEEK_SET)\n        f.write(sigb64)\n        f.write('{:08x}'.format(len(sigb64)))\n\n        # append number of signatures\n        num_sigs += 1\n        f.write('{:08x}'.format(num_sigs))\n    \n        f.flush()\n        os.fsync(f.fileno())\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive the path to a directory, compress it and export it to the given path. Return {'status': True} on success Return {'error': ...} on failure", "response": "def fast_sync_snapshot_compress( snapshot_dir, export_path ):\n    \"\"\"\n    Given the path to a directory, compress it and export it to the\n    given path.\n\n    Return {'status': True} on success\n    Return {'error': ...} on failure\n    \"\"\"\n\n    snapshot_dir = os.path.abspath(snapshot_dir)\n    export_path = os.path.abspath(export_path)\n    if os.path.exists(export_path):\n        return {'error': 'Snapshot path exists: {}'.format(export_path)}\n\n    old_dir = os.getcwd()\n    \n    count_ref = [0]\n\n    def print_progress(tarinfo):\n        count_ref[0] += 1\n        if count_ref[0] % 100 == 0:\n            log.debug(\"{} files compressed...\".format(count_ref[0]))\n\n        return tarinfo\n\n    try:\n        os.chdir(snapshot_dir)\n        with tarfile.TarFile.bz2open(export_path, \"w\") as f:\n            f.add(\".\", filter=print_progress)\n\n    except:\n        os.chdir(old_dir)\n        raise\n    \n    finally:\n        os.chdir(old_dir)\n\n    return {'status': True}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fast_sync_snapshot_decompress( snapshot_path, output_dir ):\n    if not tarfile.is_tarfile(snapshot_path):\n        return {'error': 'Not a tarfile-compatible archive: {}'.format(snapshot_path)}\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    with tarfile.TarFile.bz2open(snapshot_path, 'r') as f:\n        tarfile.TarFile.extractall(f, path=output_dir)\n\n    return {'status': True}", "response": "Decompress a tarball and write its contents to the given output directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fast_sync_fetch(working_dir, import_url):\n    try:\n        fd, tmppath = tempfile.mkstemp(prefix='.blockstack-fast-sync-', dir=working_dir)\n    except Exception, e:\n        log.exception(e)\n        return None\n    \n    log.debug(\"Fetch {} to {}...\".format(import_url, tmppath))\n\n    try:\n        path, headers = urllib.urlretrieve(import_url, tmppath)\n    except Exception, e:\n        os.close(fd)\n        log.exception(e)\n        return None\n    \n    os.close(fd)\n    return tmppath", "response": "Fetch the data for an import snapshot and store it to a temporary path Return None on error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fast_sync_inspect( fd ):\n    sb = os.fstat(fd.fileno())\n    ptr = sb.st_size\n    if ptr < 8:\n        log.debug(\"fd is {} bytes\".format(ptr))\n        return {'error': 'File is too small to be a snapshot'}\n\n    signatures = []\n    sig_append_offset = 0\n    \n    fd.seek(0, os.SEEK_SET)\n\n    # read number of signatures\n    num_signatures = snapshot_peek_number(fd, ptr)\n    if num_signatures is None or num_signatures > 256:\n        log.error(\"Unparseable num_signatures field\")\n        return {'error': 'Unparseable num_signatures'}\n\n    # consumed\n    ptr -= 8\n\n    # future signatures get written here\n    sig_append_offset = ptr\n\n    # read signatures\n    for i in xrange(0, num_signatures):\n        sigb64_len = snapshot_peek_number(fd, ptr)\n        if sigb64_len is None or sigb64_len > 100:\n            log.error(\"Unparseable signature length field\")\n            return {'error': 'Unparseable signature length'}\n\n        # consumed length\n        ptr -= 8\n\n        sigb64 = snapshot_peek_sigb64(fd, ptr, sigb64_len)\n        if sigb64 is None:\n            log.error(\"Unparseable signature\")\n            return {'error': 'Unparseable signature'}\n\n        # consumed signature\n        ptr -= len(sigb64)\n\n        signatures.append( sigb64 )\n\n    return {'status': True, 'signatures': signatures, 'payload_size': ptr, 'sig_append_offset': sig_append_offset}", "response": "Fast Sync Inspect a snapshot given its file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting useful information about a snapshot", "response": "def fast_sync_inspect_snapshot( snapshot_path ):\n    \"\"\"\n    Inspect a snapshot\n    Return useful information\n    Return {'status': True, 'signatures': ..., 'payload_size': ..., 'sig_append_offset': ..., 'hash': ...} on success\n    Return {'error': ...} on error\n    \"\"\"\n    with open(snapshot_path, 'r') as f:\n        info = fast_sync_inspect( f )\n        if 'error' in info:\n            log.error(\"Failed to inspect snapshot {}: {}\".format(snapshot_path, info['error']))\n            return {'error': 'Failed to inspect snapshot'}\n\n        # get the hash of the file \n        hash_hex = get_file_hash(f, hashlib.sha256, fd_len=info['payload_size'])\n        info['hash'] = hash_hex\n\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfasts - sync import.", "response": "def fast_sync_import(working_dir, import_url, public_keys=config.FAST_SYNC_PUBLIC_KEYS, num_required=len(config.FAST_SYNC_PUBLIC_KEYS), verbose=False):\n    \"\"\"\n    Fast sync import.\n    Verify the given fast-sync file from @import_path using @public_key, and then \n    uncompress it into @working_dir.\n\n    Verify that at least `num_required` public keys in `public_keys` signed.\n    NOTE: `public_keys` needs to be in the same order as the private keys that signed.\n    \"\"\"\n\n    def logmsg(s):\n        if verbose:\n            print s\n        else:\n            log.debug(s)\n\n    def logerr(s):\n        if verbose:\n            print >> sys.stderr, s\n        else:\n            log.error(s)\n\n    if working_dir is None or not os.path.exists(working_dir):\n        logerr(\"No such directory {}\".format(working_dir))\n        return False\n\n    # go get it \n    import_path = fast_sync_fetch(working_dir, import_url)\n    if import_path is None:\n        logerr(\"Failed to fetch {}\".format(import_url))\n        return False\n\n    # format: <signed bz2 payload> <sigb64> <sigb64 length (8 bytes hex)> ... <num signatures>\n    file_size = 0\n    try:\n        sb = os.stat(import_path)\n        file_size = sb.st_size\n    except Exception as e:\n        log.exception(e)\n        return False\n\n    num_signatures = 0\n    ptr = file_size\n    signatures = []\n\n    with open(import_path, 'r') as f:\n        info = fast_sync_inspect( f )\n        if 'error' in info:\n            logerr(\"Failed to inspect snapshot {}: {}\".format(import_path, info['error']))\n            return False\n\n        signatures = info['signatures']\n        ptr = info['payload_size']\n\n        # get the hash of the file \n        hash_hex = get_file_hash(f, hashlib.sha256, fd_len=ptr)\n        \n        # validate signatures over the hash\n        logmsg(\"Verify {} bytes\".format(ptr))\n        key_idx = 0\n        num_match = 0\n        for next_pubkey in public_keys:\n            for sigb64 in signatures:\n                valid = verify_digest( hash_hex, keylib.ECPublicKey(next_pubkey).to_hex(), sigb64, hashfunc=hashlib.sha256 ) \n                if valid:\n                    num_match += 1\n                    if num_match >= num_required:\n                        break\n                    \n                    logmsg(\"Public key {} matches {} ({})\".format(next_pubkey, sigb64, hash_hex))\n                    signatures.remove(sigb64)\n                \n                else:\n                    logmsg(\"Public key {} does NOT match {} ({})\".format(next_pubkey, sigb64, hash_hex))\n\n        # enough signatures?\n        if num_match < num_required:\n            logerr(\"Not enough signatures match (required {}, found {})\".format(num_required, num_match))\n            return False\n\n    # decompress\n    import_path = os.path.abspath(import_path)\n    res = fast_sync_snapshot_decompress(import_path, working_dir)\n    if 'error' in res:\n        logerr(\"Failed to decompress {} to {}: {}\".format(import_path, working_dir, res['error']))\n        return False\n\n    # restore from backup\n    rc = blockstack_backup_restore(working_dir, None)\n    if not rc:\n        logerr(\"Failed to instantiate blockstack name database\")\n        return False\n\n    # success!\n    logmsg(\"Restored to {}\".format(working_dir))\n\n    try:\n        os.unlink(import_path)\n    except:\n        pass\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrestores the database from a backup in the backups directory.", "response": "def blockstack_backup_restore(working_dir, block_number):\n    \"\"\"\n    Restore the database from a backup in the backups/ directory.\n    If block_number is None, then use the latest backup.\n\n    NOT THREAD SAFE\n\n    Return True on success\n    Raise an exception on error\n    \"\"\"\n    db = BlockstackDB.get_readwrite_instance(working_dir, restore=True, restore_block_height=block_number)\n    try:\n        db.db_restore(block_number=block_number)\n    except Exception as e:\n        raise e\n    finally:\n        db.close()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef state_check_collisions( state_engine, nameop, history_id_key, block_id, checked_ops, collision_checker ):\n\n    # verify no collisions against already-accepted names\n    collision_check = getattr( state_engine, collision_checker, None )\n    try:\n        assert collision_check is not None, \"Collision-checker '%s' not defined\" % collision_checker\n        assert hasattr( collision_check, \"__call__\" ), \"Collision-checker '%s' is not callable\" % collision_checker\n        assert history_id_key in nameop.keys(), \"History ID key '%s' not in name operation\" % (history_id_key)\n        assert 'op' in nameop.keys(), \"BUG: no op in nameop\"\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: incorrect state_create() decorator\")\n        sys.exit(1)\n\n    rc = collision_check( nameop[history_id_key], block_id, checked_ops )\n    return rc", "response": "Check if there are no state - creating or state - preordering collisions at this block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef state_preorder(collision_checker):\n    def wrap( check ):\n        def wrapped_check( state_engine, nameop, block_id, checked_ops ):\n            rc = check( state_engine, nameop, block_id, checked_ops )\n            if rc:\n                # verify no duplicates \n                history_id_key = \"preorder_hash\"\n                rc = state_check_collisions( state_engine, nameop, history_id_key, block_id, checked_ops, collision_checker )\n                if rc:\n                    log.debug(\"COLLISION on %s '%s'\" % (history_id_key, nameop[history_id_key]))\n                    rc = False \n                else:\n                    # no collision\n                    rc = True\n\n                # sanity check---we need to have the appropriate metadata for this operation\n                invariant_tags = state_preorder_invariant_tags()\n                for tag in invariant_tags:\n                    assert tag in nameop, \"BUG: missing invariant tag '%s'\" % tag\n\n                # sanity check---all required consensus fields must be present\n                for required_field in CONSENSUS_FIELDS_REQUIRED:\n                    assert required_field in nameop, 'BUG: missing required consensus field {}'.format(required_field)\n\n            return rc\n        return wrapped_check\n    return wrap", "response": "Decorator for the check method on a state - preordering operation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef token_operation(table_name):\n    def wrap( check ):\n        def wrapped_check( state_engine, token_op, block_id, checked_ops ):\n            rc = check( state_engine, token_op, block_id, checked_ops )\n            if rc:\n                token_op['__table__'] = table_name\n                invariant_tags = token_operation_invariant_tags()\n                for tag in invariant_tags:\n                    assert tag in token_op, 'BUG: missing token operation invariant tag {}'.format(tag)\n\n                # sanity check---all required consensus fields must be present\n                for required_field in CONSENSUS_FIELDS_REQUIRED:\n                    assert required_field in token_op, 'BUG: missing required consensus field {}'.format(required_field)\n\n                # sanity check---all required consensus fields for tokens must be present\n                for required_field in CONSENSUS_FIELDS_REQUIRED_TOKENS:\n                    assert required_field in token_op, 'BUG: missing token-specific required consensus field {}'.format(required_field)\n\n            return rc\n        return wrapped_check\n    return wrap", "response": "Decorator for token operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef state_preorder_put_account_payment_info( nameop, account_addr, token_type, amount ):\n    assert amount is None or isinstance(amount, (int,long)), 'Amount is {} (type {})'.format(amount, type(amount))\n    assert account_addr is None or isinstance(account_addr, (str,unicode))\n    assert token_type is None or isinstance(token_type, (str,unicode))\n    nameop['__account_payment_info__'] = {\n            'address': str(account_addr) if account_addr is not None else None,\n            'type': str(token_type) if token_type is not None else None,\n            'amount': int(amount) if amount is not None else None\n    }", "response": "Set the account payment info in the given nameop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a state - create operation is valid.", "response": "def state_create_is_valid( nameop ):\n    \"\"\"\n    Is a nameop a valid state-preorder operation?\n    \"\"\"\n    assert '__state_create__' in nameop, \"Not tagged with @state_create\"\n    assert nameop['__state_create__'], \"BUG: tagged False by @state_create\"\n    assert '__preorder__' in nameop, \"No preorder\"\n    assert '__table__' in nameop, \"No table given\"\n    assert '__history_id_key__' in nameop, \"No history ID key given\"\n    assert nameop['__history_id_key__'] in nameop, \"No history ID given\"\n    assert '__always_set__' in nameop, \"No always-set fields given\"\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a state transition is valid.", "response": "def state_transition_is_valid( nameop ):\n    \"\"\"\n    Is this a valid state transition?\n    \"\"\"\n    assert '__state_transition__' in nameop, \"Not tagged with @state_transition\"\n    assert nameop['__state_transition__'], \"BUG: @state_transition tagged False\"\n    assert '__history_id_key__' in nameop, \"Missing __history_id_key__\"\n    history_id_key = nameop['__history_id_key__']\n    assert history_id_key in [\"name\", \"namespace_id\"], \"Invalid history ID key '%s'\" % history_id_key\n    assert '__table__' in nameop, \"Missing __table__\"\n    assert '__always_set__' in nameop, \"No always-set fields given\"\n    assert '__account_payment_info__' in nameop, 'No account payment information present'\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token_operation_put_account_payment_info(token_op, account_addr, token_type, amount):\n    assert isinstance(amount, (int,long)), \"BUG: amount is {} (type {})\".format(amount, type(amount))\n    assert isinstance(account_addr, (str,unicode)), 'BUG: account is {} (type {})'.format(account_addr, type(account_addr))\n    assert isinstance(token_type, (str,unicode)), 'BUG: token_type is {} (type {})'.format(token_type, type(token_type))\n    token_op['__account_payment_info__'] = {\n            'address': str(account_addr),\n            'type': str(token_type),\n            'amount': int(amount)\n    }", "response": "Adds account payment info to the token operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading and verify an atlas zone file", "response": "def _read_atlas_zonefile( zonefile_path, zonefile_hash ):\n    \"\"\"\n    Read and verify an atlas zone file\n    \"\"\"\n\n    with open(zonefile_path, \"rb\") as f:\n        data = f.read()\n\n    # sanity check \n    if zonefile_hash is not None:\n        if not verify_zonefile( data, zonefile_hash ):\n            log.debug(\"Corrupt zonefile '%s'\" % zonefile_hash)\n            return None\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_atlas_zonefile_data( zonefile_hash, zonefile_dir, check=True ):\n    zonefile_path = atlas_zonefile_path(zonefile_dir, zonefile_hash)\n    zonefile_path_legacy = atlas_zonefile_path_legacy(zonefile_dir, zonefile_hash)\n\n    for zfp in [zonefile_path, zonefile_path_legacy]:\n\n        if not os.path.exists( zfp ):\n            continue\n\n        if check:\n            res = _read_atlas_zonefile(zfp, zonefile_hash)\n        else:\n            res = _read_atlas_zonefile(zfp, None)\n\n        if res:\n            return res\n\n    return None", "response": "Get a serialized cached zonefile from local disk \n    Return None if not found"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atlas_zonefile_path( zonefile_dir, zonefile_hash ):\n    # split into directories, but not too many\n    zonefile_dir_parts = []\n    interval = 2\n    for i in xrange(0, min(len(zonefile_hash), 4), interval):\n        zonefile_dir_parts.append( zonefile_hash[i:i+interval] )\n\n    zonefile_path = os.path.join(zonefile_dir, '/'.join(zonefile_dir_parts), '{}.txt'.format(zonefile_hash))\n    return zonefile_path", "response": "Calculate the on - disk path to store a zonefile."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atlas_zonefile_path_legacy( zonefile_dir, zonefile_hash ):\n\n    # split into directories, so we don't try to cram millions of files into one directory\n    zonefile_dir_parts = []\n    interval = 2\n    for i in xrange(0, len(zonefile_hash), interval):\n        zonefile_dir_parts.append( zonefile_hash[i:i+interval] )\n\n    zonefile_dir_path = os.path.join(zonefile_dir, \"/\".join(zonefile_dir_parts))\n    return os.path.join(zonefile_dir_path, \"zonefile.txt\")", "response": "Calculate the path to store a zone file given a zonefile hash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_zonefile_cached( zonefile_hash, zonefile_dir, validate=False):\n    zonefile_path = atlas_zonefile_path(zonefile_dir, zonefile_hash)\n    zonefile_path_legacy = atlas_zonefile_path_legacy(zonefile_dir, zonefile_hash)\n\n    res = False\n    for zfp in [zonefile_path, zonefile_path_legacy]:\n        \n        if not os.path.exists(zfp):\n            continue\n\n        if validate:\n            data = _read_atlas_zonefile(zfp, zonefile_hash)\n            if data:\n                # yup!\n                res = True\n                break\n\n        else:\n            res = True\n            break\n\n    return res", "response": "Check if a zonefile is cached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring a validated zonefile in a new atlas zonefile. Returns True on success Return False on error", "response": "def store_atlas_zonefile_data(zonefile_data, zonefile_dir, fsync=True):\n    \"\"\"\n    Store a validated zonefile.\n    zonefile_data should be a dict.\n    The caller should first authenticate the zonefile.\n    Return True on success\n    Return False on error\n    \"\"\"\n    if not os.path.exists(zonefile_dir):\n        os.makedirs(zonefile_dir, 0700 )\n\n    zonefile_hash = get_zonefile_data_hash( zonefile_data )\n    \n    # only store to the latest supported directory\n    zonefile_path = atlas_zonefile_path( zonefile_dir, zonefile_hash )\n    zonefile_dir_path = os.path.dirname(zonefile_path)\n\n    if os.path.exists(zonefile_path):\n        # already exists \n        return True\n\n    if not os.path.exists(zonefile_dir_path):\n        os.makedirs(zonefile_dir_path)\n\n    try:\n        with open( zonefile_path, \"wb\" ) as f:\n            f.write(zonefile_data)\n            f.flush()\n            if fsync:\n                os.fsync(f.fileno())\n\n    except Exception, e:\n        log.exception(e)\n        return False\n        \n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a cached zonefile. Returns True if deleted otherwise False.", "response": "def remove_atlas_zonefile_data( zonefile_hash, zonefile_dir ):\n    \"\"\"\n    Remove a cached zonefile.\n    Idempotent; returns True if deleted or it didn't exist.\n    Returns False on error\n    \"\"\"\n    if not os.path.exists(zonefile_dir):\n        return True\n\n    zonefile_path = atlas_zonefile_path( zonefile_dir, zonefile_hash )\n    zonefile_path_legacy = atlas_zonefile_path_legacy( zonefile_dir, zonefile_hash )\n\n    for zfp in [zonefile_path, zonefile_path_legacy]:\n        if not os.path.exists(zonefile_path):\n            continue\n\n        try:\n            os.unlink(zonefile_path)\n        except:\n            log.error(\"Failed to unlink zonefile %s (%s)\" % (zonefile_hash, zonefile_path))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_atlas_zonefile_data(zonefile_text, zonefile_dir, fsync=True):\n\n    rc = store_atlas_zonefile_data(zonefile_text, zonefile_dir, fsync=fsync)\n    if not rc:\n        zonefile_hash = get_zonefile_data_hash( zonefile_text )\n        log.error(\"Failed to save zonefile {}\".format(zonefile_hash))\n        rc = False\n\n    return rc", "response": "Add a zone file to the atlas zonefiles\n    Return True on success Return False on error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transfer_sanity_check( name, consensus_hash ):\n    if name is not None and (not is_b40( name ) or \"+\" in name or name.count(\".\") > 1):\n       raise Exception(\"Name '%s' has non-base-38 characters\" % name)\n    \n    # without the scheme, name must be 37 bytes \n    if name is not None and (len(name) > LENGTHS['blockchain_id_name']):\n       raise Exception(\"Name '%s' is too long; expected %s bytes\" % (name, LENGTHS['blockchain_id_name']))\n    \n    return True", "response": "Verify that the data for a transfer is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_transfer_consensus_hash( name_rec, block_id, vtxindex, nameop_consensus_hash ):\n    # work backwards from the last block\n    for historic_block_number in reversed(sorted(name_rec['history'].keys())):\n        for historic_state in reversed(name_rec['history'][historic_block_number]):\n            if historic_state['block_number'] > block_id or (historic_state['block_number'] == block_id and historic_state['vtxindex'] > vtxindex):\n                # from the future\n                continue\n            \n            if historic_state['op'] in [NAME_REGISTRATION, NAME_IMPORT]:\n                # out of history without finding a NAME_UPDATE\n                return nameop_consensus_hash\n\n            if historic_state['op'] == NAME_UPDATE:\n                # reuse this consensus hash \n                assert historic_state['consensus_hash'] is not None, 'BUG: NAME_UPDATE did not set \"consensus_hash\": {}'.format(historic_state)\n                return historic_state['consensus_hash']\n\n    return nameop_consensus_hash", "response": "Given a NAME_TRANSFER and a block ID and a consensus hash find the last consensus hash that is used in the NAME_TRANSFER."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks validity of a name s transferrance to another private key.", "response": "def check( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify the validity of a name's transferrance to another private key.\n    The name must exist, not be revoked, and be owned by the sender.\n    The recipient must not exceed the maximum allowed number of names per keypair,\n    and the recipient cannot own an equivalent name.\n\n    NAME_TRANSFER isn't allowed during an import, so the name's namespace must be ready.\n\n    Return True if accepted\n    Return False if not\n    \"\"\"\n\n    name_hash = nameop['name_hash128']\n    name = state_engine.get_name_from_name_hash128( name_hash )\n\n    consensus_hash = nameop['consensus_hash']\n    sender = nameop['sender']\n    recipient_address = nameop['recipient_address']\n    recipient = nameop['recipient']\n\n    if name is None:\n        # invalid\n        log.warning(\"No name found for '%s'\" % name_hash )\n        return False\n\n    namespace_id = get_namespace_from_name( name )\n    name_rec = state_engine.get_name( name )\n    \n    if name_rec is None:\n        log.warning(\"Name '%s' does not exist\" % name)\n        return False\n\n    # namespace must be ready\n    if not state_engine.is_namespace_ready( namespace_id ):\n        # non-existent namespace\n        log.warning(\"Namespace '%s' is not ready\" % (namespace_id))\n        return False\n\n    # name must not be revoked\n    if state_engine.is_name_revoked( name ):\n        log.warning(\"Name '%s' is revoked\" % name)\n        return False\n\n    # name must not be expired as of the *last block processed*\n    if state_engine.is_name_expired( name, state_engine.lastblock ):\n        log.warning(\"Name '%s' is expired\" % name)\n        return False\n\n    # name must not be in grace period in this block\n    if state_engine.is_name_in_grace_period(name, block_id):\n        log.warning(\"Name '{}' is in the renewal grace period.  It can only be renewed at this time.\".format(name))\n        return False\n\n    if not state_engine.is_consensus_hash_valid( block_id, consensus_hash ):\n        # invalid concensus hash\n        log.warning(\"Invalid consensus hash '%s'\" % consensus_hash )\n        return False\n\n    if sender == recipient:\n        # nonsensical transfer\n        log.warning(\"Sender is the same as the Recipient (%s)\" % sender )\n        return False\n\n    if not state_engine.is_name_registered( name ):\n        # name is not registered\n        log.warning(\"Name '%s' is not registered\" % name)\n        return False\n\n    if not state_engine.is_name_owner( name, sender ):\n        # sender doesn't own the name\n        log.warning(\"Name '%s' is not owned by %s (but %s)\" % (name, sender, state_engine.get_name_owner(name)))\n        return False\n\n    names_owned = state_engine.get_names_owned_by_sender( recipient )\n    if name in names_owned:\n        # recipient already owns it \n        log.warning(\"Recipient %s already owns '%s'\" % (recipient, name))\n        return False\n\n    if len(names_owned) >= MAX_NAMES_PER_SENDER:\n        # exceeds quota \n        log.warning(\"Recipient %s has exceeded name quota\" % recipient)\n        return False\n\n    # sender cannot be a p2sh script until we're in an epoch that supports multisig.\n    # this is to preserve compatibility with 0.13.\n    if virtualchain.is_multisig_script( sender ) and not epoch_has_multisig( block_id ):\n        log.warning(\"Sender %s is a p2sh script, but multisig is not enabled in epoch %s\" % (sender, get_epoch_number(block_id)))\n        return False\n\n    # the given consensus hash must be valid\n    nameop_consensus_hash = nameop['consensus_hash']\n    transfer_send_block_id = state_engine.get_block_from_consensus(nameop_consensus_hash)\n    if transfer_send_block_id is None:\n        # wrong/invalid consensus hash \n        log.warning(\"Unrecognized consensus hash '%s'\" % nameop_consensus_hash)\n        return False\n    \n    # QUIRK: we hash either the consensus hash from the last non-NAME_TRANSFER\n    # operation, or if there are no such consensus hashes, we hash on the one from the NAME_TRANSFER itself.\n    transfer_consensus_hash = find_transfer_consensus_hash(name_rec, block_id, nameop['vtxindex'], nameop['consensus_hash'])\n\n    # remember the name, so we don't have to look it up later\n    nameop['name'] = name\n\n    # carry out transition, putting the operation into the state to be committed\n    nameop['sender'] = recipient\n    nameop['address'] = recipient_address\n    nameop['sender_pubkey'] = None\n\n    if not nameop['keep_data']:\n        nameop['value_hash'] = None\n        nameop['op'] = \"%s%s\" % (NAME_TRANSFER, TRANSFER_REMOVE_DATA)\n    else:\n        # preserve \n        nameop['value_hash'] = name_rec['value_hash']\n        nameop['op'] = \"%s%s\" % (NAME_TRANSFER, TRANSFER_KEEP_DATA)\n\n    del nameop['recipient']\n    del nameop['recipient_address']\n    del nameop['keep_data']\n    del nameop['name_hash128']\n    \n    # QUIRK examples\n    # example 1: doog.id underwent a NAME_PREORDER, NAME_REGISTRATION, and NAME_TRANSFER (>~).\n    # In the NAME_TRANSFER (>~) at 405088, it should have consensus_hash == CONSNSUS(405079) hashed when the consensus hash is calculated\n    # (i.e. there is no prior non-NAME_TRANSFER stored consensus hash, so the consensus hash comes from the one given in this NAME_TRANSFER).\n    # example 2: doog.id underwent a NAME_PREORDER, NAME_REGISTRATION, NAME_TRANSFER (>~), and NAME_TRANSFER (>~)\n    # In the NAME_TRANSFER (>~) at 405175, it should have consensus_hash == CONSNSUS(405165) hashed when the consensus hash is calculated\n    # (i.e. there is no prior non-NAME_TRANSFER stored consensus hash, so the consensus hash comes from the one given in this NAME_TRANSFER).\n    # example 3: eth3r3um.id underwent a NAME_PREORDER, NAME_REGISTRATION, NAME_UPDATE, and NAME_TRANSFER (>>)\n    # in the NAME_TRANSFER (>>) at 385652, it should have consensus_hash == CONSENSUS(385610) hashed when the consensus hash is calculated\n    # (i.e. this was the prior stored consensus hash at 385610 from a non-NAME_TRANSFER---the one from the earlier NAME_UPDATE)\n    log.debug(\"QUIRK: Hash NAME_TRANSFER consensus hash {} instead of {}\".format(transfer_consensus_hash, nameop_consensus_hash))\n    nameop['consensus_hash'] = transfer_consensus_hash\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tx_extract( payload, senders, inputs, outputs, block_id, vtxindex, txid ):\n  \n    sender = None \n    sender_address = None \n    sender_pubkey_hex = None\n\n    recipient = None \n    recipient_address = None \n\n    try:\n       # first two outputs matter to us (op_return, new recipient)\n       assert check_tx_output_types(outputs[:2], block_id)\n\n       recipient = get_transfer_recipient_from_outputs( outputs )\n       recipient_address = virtualchain.script_hex_to_address( recipient )\n\n       assert recipient is not None \n       assert recipient_address is not None\n\n       # by construction, the first input comes from the principal\n       # who sent the registration transaction...\n       assert len(senders) > 0\n       assert 'script_pubkey' in senders[0].keys()\n       assert 'addresses' in senders[0].keys()\n\n       sender = str(senders[0]['script_pubkey'])\n       sender_address = str(senders[0]['addresses'][0])\n\n       assert sender is not None \n       assert sender_address is not None\n\n       if str(senders[0]['script_type']) == 'pubkeyhash':\n          sender_pubkey_hex = get_public_key_hex_from_tx( inputs, sender_address )\n\n    except Exception, e:\n       log.exception(e)\n       raise Exception(\"Failed to extract\")\n\n    parsed_payload = parse( payload, recipient )\n    assert parsed_payload is not None \n\n    ret = {\n       \"sender\": sender,\n       \"address\": sender_address,\n       \"recipient\": recipient,\n       \"recipient_address\": recipient_address,\n       \"vtxindex\": vtxindex,\n       \"txid\": txid,\n       \"op\": NAME_TRANSFER\n    }\n\n    ret.update( parsed_payload )\n\n    if sender_pubkey_hex is not None:\n        ret['sender_pubkey'] = sender_pubkey_hex\n    else:\n        ret['sender_pubkey'] = None\n\n    return ret", "response": "Extract and return a dict of fields from the underlying blockchain transaction"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(bin_payload, recipient):\n    \n    if len(bin_payload) != 1 + LENGTHS['name_hash'] + LENGTHS['consensus_hash']:\n        log.error(\"Invalid transfer payload length %s\" % len(bin_payload))\n        return None \n\n    disposition_char = bin_payload[0:1]\n    name_hash128 = bin_payload[1:1+LENGTHS['name_hash']]\n    consensus_hash = bin_payload[1+LENGTHS['name_hash']:]\n   \n    if disposition_char not in [TRANSFER_REMOVE_DATA, TRANSFER_KEEP_DATA]:\n        log.error(\"Invalid disposition character\")\n        return None \n\n    # keep data by default \n    disposition = True \n    \n    if disposition_char == TRANSFER_REMOVE_DATA:\n       disposition = False \n   \n    try:\n       rc = transfer_sanity_check( None, consensus_hash )\n       if not rc:\n           raise Exception(\"Invalid transfer data\")\n\n    except Exception, e:\n       log.error(\"Invalid transfer data\")\n       return None\n\n    return {\n        'opcode': 'NAME_TRANSFER',\n        'name_hash128': hexlify( name_hash128 ),\n        'consensus_hash': hexlify( consensus_hash ),\n        'recipient': recipient,\n        'keep_data': disposition\n    }", "response": "Parses the binary data into a dictionary of data structures."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef canonicalize(parsed_op):\n    assert 'op' in parsed_op\n    assert len(parsed_op['op']) == 2\n\n    if parsed_op['op'][1] == TRANSFER_KEEP_DATA:\n        parsed_op['keep_data'] = True\n    elif parsed_op['op'][1] == TRANSFER_REMOVE_DATA:\n        parsed_op['keep_data'] = False\n    else:\n        raise ValueError(\"Invalid op '{}'\".format(parsed_op['op']))\n\n    return parsed_op", "response": "Return the canonical form of this operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets or instantiate our bitcoind client.", "response": "def get_bitcoind( new_bitcoind_opts=None, reset=False, new=False ):\n   \"\"\"\n   Get or instantiate our bitcoind client.\n   Optionally re-set the bitcoind options.\n   \"\"\"\n   global bitcoind\n\n   if reset:\n       bitcoind = None\n\n   elif not new and bitcoind is not None:\n      return bitcoind\n\n   if new or bitcoind is None:\n      if new_bitcoind_opts is not None:\n         set_bitcoin_opts( new_bitcoind_opts )\n\n      bitcoin_opts = get_bitcoin_opts()\n      new_bitcoind = None\n      try:\n\n         try:\n             new_bitcoind = virtualchain.connect_bitcoind( bitcoin_opts )\n         except KeyError, ke:\n             log.exception(ke)\n             log.error(\"Invalid configuration: %s\" % bitcoin_opts)\n             return None\n\n         if new:\n             return new_bitcoind\n\n         else:\n             # save for subsequent reuse\n             bitcoind = new_bitcoind\n             return bitcoind\n\n      except Exception, e:\n         log.exception( e )\n         return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the PID file path.", "response": "def get_pidfile_path(working_dir):\n   \"\"\"\n   Get the PID file path.\n   \"\"\"\n   pid_filename = virtualchain_hooks.get_virtual_chain_name() + \".pid\"\n   return os.path.join( working_dir, pid_filename )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput a PID into a pidfile", "response": "def put_pidfile( pidfile_path, pid ):\n    \"\"\"\n    Put a PID into a pidfile\n    \"\"\"\n    with open( pidfile_path, \"w\" ) as f:\n        f.write(\"%s\" % pid)\n        os.fsync(f.fileno())\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the logfile path for our service endpoint.", "response": "def get_logfile_path(working_dir):\n   \"\"\"\n   Get the logfile path for our service endpoint.\n   \"\"\"\n   logfile_filename = virtualchain_hooks.get_virtual_chain_name() + \".log\"\n   return os.path.join( working_dir, logfile_filename )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_index_range(working_dir):\n\n    bitcoind_session = get_bitcoind(new=True)\n    assert bitcoind_session is not None\n\n    first_block = None\n    last_block = None\n    wait = 1.0\n    while last_block is None and is_running():\n\n        first_block, last_block = virtualchain.get_index_range('bitcoin', bitcoind_session, virtualchain_hooks, working_dir)\n\n        if first_block is None or last_block is None:\n\n            # try to reconnnect\n            log.error(\"Reconnect to bitcoind in {} seconds\".format(wait))\n            time.sleep(wait)\n            wait = min(wait * 2.0 + random.random() * wait, 60)\n\n            bitcoind_session = get_bitcoind( new=True )\n            continue\n\n        else:\n            return first_block, last_block - NUM_CONFIRMATIONS\n\n    return None, None", "response": "Get the bitcoin block index range."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the cost of a name given the fully - qualified name.", "response": "def get_name_cost( db, name ):\n    \"\"\"\n    Get the cost of a name, given the fully-qualified name.\n    Do so by finding the namespace it belongs to (even if the namespace is being imported).\n\n    Return {'amount': ..., 'units': ...} on success\n    Return None if the namespace has not been declared\n    \"\"\"\n    lastblock = db.lastblock\n    namespace_id = get_namespace_from_name( name )\n    if namespace_id is None or len(namespace_id) == 0:\n        log.debug(\"No namespace '%s'\" % namespace_id)\n        return None\n\n    namespace = db.get_namespace( namespace_id )\n    if namespace is None:\n        # maybe importing?\n        log.debug(\"Namespace '{}' is being revealed\".format(namespace_id))\n        namespace = db.get_namespace_reveal( namespace_id )\n\n    if namespace is None:\n        # no such namespace\n        log.debug(\"No namespace '%s'\" % namespace_id)\n        return None\n\n    name_fee = price_name( get_name_from_fq_name( name ), namespace, lastblock )\n    name_fee_units = None\n\n    if namespace['version'] == NAMESPACE_VERSION_PAY_WITH_STACKS:\n        name_fee_units = TOKEN_TYPE_STACKS\n    else:\n        name_fee_units = 'BTC'\n\n    name_fee = int(math.ceil(name_fee))\n    log.debug(\"Cost of '%s' at %s is %s units of %s\" % (name, lastblock, name_fee, name_fee_units))\n\n    return {'amount': name_fee, 'units': name_fee_units}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the cost of a namespace.", "response": "def get_namespace_cost( db, namespace_id ):\n    \"\"\"\n    Get the cost of a namespace.\n    Returns {'amount': ..., 'units': ..., 'namespace': ...}\n    \"\"\"\n    lastblock = db.lastblock\n    namespace_units = get_epoch_namespace_price_units(lastblock)\n    namespace_fee = price_namespace( namespace_id, lastblock, namespace_units )\n    \n    # namespace might exist\n    namespace = db.get_namespace( namespace_id )\n    namespace_fee = int(math.ceil(namespace_fee))\n\n    return {'amount': namespace_fee, 'units': namespace_units, 'namespace': namespace}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the global RPC server", "response": "def rpc_start( working_dir, port, subdomain_index=None, thread=True ):\n    \"\"\"\n    Start the global RPC server thread\n    Returns the RPC server thread\n    \"\"\"\n    rpc_srv = BlockstackdRPCServer( working_dir, port, subdomain_index=subdomain_index )\n    log.debug(\"Starting RPC on port {}\".format(port))\n\n    if thread:\n        rpc_srv.start()\n\n    return rpc_srv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_chain_sync(server_state, new_block_height, finish_time):\n    rpc_srv = server_state['rpc']\n    if rpc_srv is not None:\n        rpc_srv.cache_flush()\n        rpc_srv.set_last_index_time(finish_time)", "response": "Syncs the RPC server cache with the given block height."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc_stop(server_state):\n    rpc_srv = server_state['rpc']\n\n    if rpc_srv is not None:\n        log.info(\"Shutting down RPC\")\n        rpc_srv.stop_server()\n        rpc_srv.join()\n        log.info(\"RPC joined\")\n\n    else:\n        log.info(\"RPC already joined\")\n\n    server_state['rpc'] = None", "response": "Stop the global RPC server thread"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop optimistic GC thread", "response": "def gc_stop():\n    \"\"\"\n    Stop a the optimistic GC thread\n    \"\"\"\n    global gc_thread\n    \n    if gc_thread:\n        log.info(\"Shutting down GC thread\")\n        gc_thread.signal_stop()\n        gc_thread.join()\n        log.info(\"GC thread joined\")\n        gc_thread = None\n    else:\n        log.info(\"GC thread already joined\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the global API server", "response": "def api_start(working_dir, host, port, thread=True):\n    \"\"\"\n    Start the global API server\n    Returns the API server thread\n    \"\"\"\n    api_srv = BlockstackdAPIServer( working_dir, host, port )\n    log.info(\"Starting API server on port {}\".format(port))\n    if thread:\n        api_srv.start()\n\n    return api_srv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the global API server thread", "response": "def api_stop(server_state):\n    \"\"\"\n    Stop the global API server thread\n    \"\"\"\n    api_srv = server_state['api']\n\n    if api_srv is not None:\n        log.info(\"Shutting down API\")\n        api_srv.stop_server()\n        api_srv.join()\n        log.info(\"API server joined\")\n    else:\n        log.info(\"API already joined\")\n\n    server_state['api'] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts up atlas functionality", "response": "def atlas_init(blockstack_opts, db, recover=False, port=None):\n    \"\"\"\n    Start up atlas functionality\n    \"\"\"\n    if port is None:\n        port = blockstack_opts['rpc_port']\n\n    # start atlas node\n    atlas_state = None\n    if is_atlas_enabled(blockstack_opts):\n        atlas_seed_peers = filter( lambda x: len(x) > 0, blockstack_opts['atlas_seeds'].split(\",\"))\n        atlas_blacklist = filter( lambda x: len(x) > 0, blockstack_opts['atlas_blacklist'].split(\",\"))\n        zonefile_dir = blockstack_opts['zonefiles']\n        my_hostname = blockstack_opts['atlas_hostname']\n        my_port = blockstack_opts['atlas_port']\n\n        initial_peer_table = atlasdb_init(blockstack_opts['atlasdb_path'], zonefile_dir, db, atlas_seed_peers, atlas_blacklist, validate=True, recover=recover)\n        atlas_peer_table_init(initial_peer_table)\n\n        atlas_state = atlas_node_init(my_hostname, my_port, blockstack_opts['atlasdb_path'], zonefile_dir, db.working_dir)\n\n    return atlas_state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_pid_file(pidfile_path):\n\n    try:\n        fin = open(pidfile_path, \"r\")\n    except Exception, e:\n        return None\n\n    else:\n        pid_data = fin.read().strip()\n        fin.close()\n\n        try:\n            pid = int(pid_data)\n            return pid\n        except:\n            return None", "response": "Read the PID from the PID file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if a given process is running on the container.", "response": "def check_server_running(pid):\n    \"\"\"\n    Determine if the given process is running\n    \"\"\"\n    if pid == os.getpid():\n        # special case--we're in Docker or some other kind of container\n        # (or we got really unlucky and got the same PID twice).\n        # this PID does not correspond to another running server, either way.\n        return False\n\n    try:\n        os.kill(pid, 0)\n        return True\n    except OSError as oe:\n        if oe.errno == errno.ESRCH:\n            return False\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_server( working_dir, clean=False, kill=False ):\n\n    timeout = 1.0\n    dead = False\n\n    for i in xrange(0, 5):\n        # try to kill the main supervisor\n        pid_file = get_pidfile_path(working_dir)\n        if not os.path.exists(pid_file):\n            dead = True\n            break\n\n        pid = read_pid_file(pid_file)\n        if pid is not None:\n            try:\n               os.kill(pid, signal.SIGTERM)\n            except OSError, oe:\n               if oe.errno == errno.ESRCH:\n                  # already dead\n                  log.info(\"Process %s is not running\" % pid)\n                  try:\n                      os.unlink(pid_file)\n                  except:\n                      pass\n\n                  return\n\n            except Exception, e:\n                log.exception(e)\n                os.abort()\n\n        else:\n            log.info(\"Corrupt PID file.  Please make sure all instances of this program have stopped and remove {}\".format(pid_file))\n            os.abort()\n\n        # is it actually dead?\n        blockstack_opts = get_blockstack_opts()\n        srv = BlockstackRPCClient('localhost', blockstack_opts['rpc_port'], timeout=5, protocol='http')\n        try:\n            res = blockstack_ping(proxy=srv)\n        except socket.error as se:\n            # dead?\n            if se.errno == errno.ECONNREFUSED:\n                # couldn't connect, so infer dead\n                try:\n                    os.kill(pid, 0)\n                    log.info(\"Server %s is not dead yet...\" % pid)\n\n                except OSError, oe:\n                    log.info(\"Server %s is dead to us\" % pid)\n                    dead = True\n                    break\n            else:\n                continue\n\n        log.info(\"Server %s is still running; trying again in %s seconds\" % (pid, timeout))\n        time.sleep(timeout)\n        timeout *= 2\n\n    if not dead and kill:\n        # be sure to clean up the pidfile\n        log.info(\"Killing server %s\" % pid)\n        clean = True\n        try:\n            os.kill(pid, signal.SIGKILL)\n        except Exception, e:\n            pass\n\n    if clean:\n        # blow away the pid file\n        try:\n            os.unlink(pid_file)\n        except:\n            pass\n\n\n    log.debug(\"Blockstack server stopped\")", "response": "Stop the blockstackd server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef blockstack_tx_filter( tx ):\n    if not 'nulldata' in tx:\n        return False\n    \n    if tx['nulldata'] is None:\n        return False\n\n    payload = binascii.unhexlify( tx['nulldata'] )\n    if payload.startswith(blockstack_magic_bytes()):\n        return True\n\n    else:\n        return False", "response": "Filter virtualchain tx by checking if the payload starts with blockstack magic bytes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef index_blockchain(server_state, expected_snapshots=GENESIS_SNAPSHOT):\n    working_dir = server_state['working_dir']\n    log.debug(\"index blockchain in {}\".format(working_dir))\n    blockstack_opts = get_blockstack_opts()\n\n    bt_opts = get_bitcoin_opts()\n    start_block, current_block = get_index_range(working_dir)\n\n    db = get_db_state(working_dir)\n    old_lastblock = db.lastblock\n\n    if start_block is None and current_block is None:\n        log.error(\"Failed to find block range\")\n        db.close()\n        return False\n\n    # sanity check: does the subdomain db exist yet, and are we at the point where we can start indexing them?\n    if is_subdomains_enabled(blockstack_opts):\n        subdomain_last_block = server_state['subdomains'].get_db().get_last_block()\n        if subdomain_last_block < SUBDOMAINS_FIRST_BLOCK and start_block >= SUBDOMAINS_FIRST_BLOCK and not server_state['subdomains_initialized']:\n            # initialize subdomains db\n            log.debug(\"Creating subdomain DB {}\".format(blockstack_opts['subdomaindb_path']))\n            server_state['subdomains'].reindex(current_block)\n            server_state['subdomains_initialized'] = True\n\n    # bring the db up to the chain tip.\n    # NOTE: at each block, the atlas db will be synchronized by virtualchain_hooks\n    log.debug(\"Begin indexing (up to %s)\" % current_block)\n    set_indexing( working_dir, True )\n    rc = virtualchain_hooks.sync_blockchain(working_dir, bt_opts, current_block, server_state, expected_snapshots=expected_snapshots, tx_filter=blockstack_tx_filter)\n    set_indexing( working_dir, False )\n\n    db.close()\n\n    if not rc:\n        log.debug(\"Stopped indexing at %s\" % current_block)\n        return rc\n\n    # uncache state specific to this block\n    rpc_chain_sync(server_state, current_block, time.time())\n\n    log.debug(\"End indexing (up to %s)\" % current_block)\n    return rc", "response": "Index the blockchain:\n    * find the range of blocks\n    * synchronize our state engine up to them\n\n    Return True if we should continue indexing\n    Return False if not\n    Aborts on error"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and instantiate the genesis block.", "response": "def genesis_block_load(module_path=None):\n    \"\"\"\n    Make sure the genesis block is good to go.\n    Load and instantiate it.\n    \"\"\"\n    if os.environ.get('BLOCKSTACK_GENESIS_BLOCK_PATH') is not None:\n        log.warning('Using envar-given genesis block')\n        module_path = os.environ['BLOCKSTACK_GENESIS_BLOCK_PATH']\n\n    genesis_block = None\n    genesis_block_stages = None\n\n    if module_path:\n        log.debug('Load genesis block from {}'.format(module_path))\n        genesis_block_path = module_path\n        try:\n            genesis_block_mod = imp.load_source('genesis_block', genesis_block_path)\n            genesis_block = genesis_block_mod.GENESIS_BLOCK\n            genesis_block_stages = genesis_block_mod.GENESIS_BLOCK_STAGES\n\n            if BLOCKSTACK_TEST:\n                print ''\n                print 'genesis block'\n                print json.dumps(genesis_block, indent=4, sort_keys=True)\n                print ''\n\n        except Exception as e:\n            log.exception(e)\n            log.fatal('Failed to load genesis block')\n            os.abort()\n\n    else:\n        log.debug('Load built-in genesis block')\n        genesis_block = get_genesis_block()\n        genesis_block_stages = get_genesis_block_stages()\n\n    try:\n        for stage in genesis_block_stages:\n            jsonschema.validate(GENESIS_BLOCK_SCHEMA, stage)\n\n        jsonschema.validate(GENESIS_BLOCK_SCHEMA, genesis_block)\n\n        set_genesis_block(genesis_block)\n        set_genesis_block_stages(genesis_block_stages)\n\n        log.debug('Genesis block has {} stages'.format(len(genesis_block_stages)))\n        for i, stage in enumerate(genesis_block_stages):\n            log.debug('Stage {} has {} row(s)'.format(i+1, len(stage['rows'])))\n\n    except Exception as e:\n        log.fatal(\"Invalid genesis block\")\n        os.abort()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting up the server. Start all subsystems, write pid file, set up signal handlers, set up DB. Returns a server instance.", "response": "def server_setup(working_dir, port=None, api_port=None, indexer_enabled=None, indexer_url=None, api_enabled=None, recover=False):\n    \"\"\"\n    Set up the server.\n    Start all subsystems, write pid file, set up signal handlers, set up DB.\n    Returns a server instance.\n    \"\"\"\n    if not is_genesis_block_instantiated():\n        # default genesis block\n        genesis_block_load()\n\n    blockstack_opts = get_blockstack_opts()\n    blockstack_api_opts = get_blockstack_api_opts()\n    pid_file = get_pidfile_path(working_dir)\n\n    indexer_enabled = indexer_enabled if indexer_enabled is not None else blockstack_opts['enabled']\n    api_enabled = api_enabled if api_enabled is not None else blockstack_api_opts['enabled']\n    indexer_url = indexer_url if indexer_url is not None else blockstack_api_opts.get('indexer_url', None)\n\n    # sanity check \n    if api_enabled and not indexer_url:\n        print(\"FATAL: no 'indexer_url' in the config file, and no --indexer_url given in the arguments\")\n        sys.exit(1)\n\n    if port is None:\n        port = blockstack_opts['rpc_port']\n\n    if api_port is None:\n        api_port = blockstack_api_opts['api_port']\n\n    # set up signals\n    signal.signal( signal.SIGINT, blockstack_signal_handler )\n    signal.signal( signal.SIGQUIT, blockstack_signal_handler )\n    signal.signal( signal.SIGTERM, blockstack_signal_handler )\n\n    # put pid file\n    put_pidfile(pid_file, os.getpid())\n\n    # clear indexing state\n    set_indexing(working_dir, False)\n\n    # process overrides\n    if blockstack_opts['enabled'] != indexer_enabled:\n        log.debug(\"Override blockstack.enabled to {}\".format(indexer_enabled))\n        blockstack_opts['enabled'] = indexer_enabled\n        set_blockstack_opts(blockstack_opts)\n\n    if blockstack_api_opts['enabled'] != api_enabled:\n        log.debug(\"Override blockstack-api.enabled to {}\".format(indexer_enabled))\n        blockstack_api_opts['enabled'] = api_enabled\n        set_blockstack_api_opts(blockstack_api_opts)\n\n    if blockstack_api_opts['indexer_url'] != indexer_url:\n        log.debug(\"Override blockstack-api.indexer_url to {}\".format(indexer_url))\n        blockstack_api_opts['indexer_url'] = indexer_url\n        set_blockstack_api_opts(blockstack_api_opts)\n\n    # start API servers\n    rpc_srv = None\n    api_srv = None\n    atlas_state = None\n    subdomain_state = None\n\n    if blockstack_opts['enabled']:\n        # get db state\n        db = get_or_instantiate_db_state(working_dir)\n    \n        # set up atlas state, if we're an indexer\n        atlas_state = atlas_init(blockstack_opts, db, port=port, recover=recover)\n        db.close()\n\n        # set up subdomains state\n        subdomain_state = subdomains_init(blockstack_opts, working_dir, atlas_state)\n    \n        # start atlas node\n        if atlas_state:\n            atlas_node_start(atlas_state)\n        \n        # start back-plane API server\n        rpc_srv = rpc_start(working_dir, port, subdomain_index=subdomain_state, thread=False)\n\n    if blockstack_api_opts['enabled']:\n        # start public RESTful API server\n        api_srv = api_start(working_dir, blockstack_api_opts['api_host'], api_port, thread=False)\n\n    if rpc_srv:\n        rpc_srv.start()\n\n    if api_srv:\n        api_srv.start()\n\n    # start GC\n    gc_start()\n\n    set_running(True)\n\n    # clear any stale indexing state\n    set_indexing(working_dir, False)\n\n    log.debug(\"Server setup: API = {}, Indexer = {}, Indexer URL = {}\".format(blockstack_api_opts['enabled'], blockstack_opts['enabled'], blockstack_api_opts['indexer_url']))\n\n    ret = {\n        'working_dir': working_dir,\n        'atlas': atlas_state,\n        'subdomains': subdomain_state,\n        'subdomains_initialized': False,\n        'rpc': rpc_srv,\n        'api': api_srv,\n        'pid_file': pid_file,\n        'port': port,\n        'api_port': api_port\n    }\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef server_shutdown(server_state):\n    set_running( False )\n\n    # stop API servers\n    rpc_stop(server_state)\n    api_stop(server_state)\n\n    # stop atlas node\n    server_atlas_shutdown(server_state)\n\n    # stopping GC\n    gc_stop()\n\n    # clear PID file\n    try:\n        if os.path.exists(server_state['pid_file']):\n            os.unlink(server_state['pid_file'])\n    except:\n        pass\n\n    return True", "response": "Shut down server subsystems."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning blockstackd. Optionally daemonize. Return 0 on success Return negative on error", "response": "def run_server(working_dir, foreground=False, expected_snapshots=GENESIS_SNAPSHOT, port=None, api_port=None, use_api=None, use_indexer=None, indexer_url=None, recover=False):\n    \"\"\"\n    Run blockstackd.  Optionally daemonize.\n    Return 0 on success\n    Return negative on error\n    \"\"\"\n    global rpc_server\n    global api_server\n\n    indexer_log_path = get_logfile_path(working_dir)\n    \n    logfile = None\n    if not foreground:\n        if os.path.exists(indexer_log_path):\n            logfile = open(indexer_log_path, 'a')\n        else:\n            logfile = open(indexer_log_path, 'a+')\n\n        child_pid = daemonize(logfile)\n        if child_pid < 0:\n            log.error(\"Failed to daemonize: {}\".format(child_pid))\n            return -1\n\n        if child_pid > 0:\n            # we're the parent\n            log.debug(\"Running in the background as PID {}\".format(child_pid))\n            sys.exit(0)\n    \n    server_state = server_setup(working_dir, port=port, api_port=api_port, indexer_enabled=use_indexer, indexer_url=indexer_url, api_enabled=use_api, recover=recover)\n    atexit.register(server_shutdown, server_state)\n\n    rpc_server = server_state['rpc']\n    \n    blockstack_opts = get_blockstack_opts()\n    blockstack_api_opts = get_blockstack_api_opts()\n\n    if blockstack_opts['enabled']:\n        log.debug(\"Begin Indexing\")\n        while is_running():\n            try:\n               running = index_blockchain(server_state, expected_snapshots=expected_snapshots)\n            except Exception, e:\n               log.exception(e)\n               log.error(\"FATAL: caught exception while indexing\")\n               os.abort()\n\n            # wait for the next block\n            deadline = time.time() + REINDEX_FREQUENCY\n            while time.time() < deadline and is_running():\n                try:\n                    time.sleep(1.0)\n                except:\n                    # interrupt\n                    break\n\n        log.debug(\"End Indexing\")\n\n    elif blockstack_api_opts['enabled']:\n        log.debug(\"Begin serving REST requests\")\n        while is_running():\n            try:\n                time.sleep(1.0)\n            except:\n                # interrupt\n                break\n\n        log.debug(\"End serving REST requests\")\n\n    server_shutdown(server_state)\n    \n    # close logfile\n    if logfile is not None:\n        logfile.flush()\n        logfile.close()\n    \n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes one-time initialization. Call this to set up global state.", "response": "def setup(working_dir, interactive=False):\n    \"\"\"\n    Do one-time initialization.\n    Call this to set up global state.\n    \"\"\"\n    # set up our implementation\n    log.debug(\"Working dir: {}\".format(working_dir))\n    if not os.path.exists( working_dir ):\n        os.makedirs( working_dir, 0700 )\n\n    node_config = load_configuration(working_dir)\n    if node_config is None:\n        sys.exit(1)\n\n    log.debug(\"config\\n{}\".format(json.dumps(node_config, indent=4, sort_keys=True)))\n    return node_config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify that a database is consistent with the consensus hash.", "response": "def verify_database(trusted_consensus_hash, consensus_block_height, untrusted_working_dir, trusted_working_dir, start_block=None, expected_snapshots={}):\n    \"\"\"\n    Verify that a database is consistent with a\n    known-good consensus hash.\n    Return True if valid.\n    Return False if not\n    \"\"\"\n    db = BlockstackDB.get_readwrite_instance(trusted_working_dir)\n    consensus_impl = virtualchain_hooks\n    return virtualchain.state_engine_verify(trusted_consensus_hash, consensus_block_height, consensus_impl, untrusted_working_dir, db, start_block=start_block, expected_snapshots=expected_snapshots)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngoes through argv and set any environment variables that affect multiple modules.", "response": "def check_and_set_envars( argv ):\n    \"\"\"\n    Go through argv and find any special command-line flags\n    that set environment variables that affect multiple modules.\n\n    If any of them are given, then set them in this process's\n    environment and re-exec the process without the CLI flags.\n\n    argv should be like sys.argv:  argv[0] is the binary\n\n    Does not return on re-exec.\n    Returns {args} on success\n    Returns False on error.\n    \"\"\"\n    special_flags = {\n        '--debug': {\n            'arg': False,\n            'envar': 'BLOCKSTACK_DEBUG',\n            'exec': True,\n        },\n        '--verbose': {\n            'arg': False,\n            'envar': 'BLOCKSTACK_DEBUG',\n            'exec': True,\n        },\n        '--testnet-id': {\n            'arg': True,\n            'envar': 'BLOCKSTACK_TESTNET_ID',\n            'exec': True,\n        },\n        '--testnet-start-block': {\n            'arg': True,\n            'envar': 'BLOCKSTACK_TESTNET_START_BLOCK',\n            'exec': True,\n        },\n        '--working_dir': {\n            'arg': True,\n            'argname': 'working_dir',\n            'exec': False,\n        },\n        '--working-dir': {\n            'arg': True,\n            'argname': 'working_dir',\n            'exec': False,\n        },\n    }\n\n    cli_envs = {}\n    cli_args = {}\n    new_argv = []\n    stripped_argv = []\n\n    do_exec = False\n    i = 0\n    while i < len(argv):\n\n        arg = argv[i]\n        value = None\n\n        for special_flag in special_flags.keys():\n\n            if not arg.startswith(special_flag):\n                continue\n\n            if special_flags[special_flag]['arg']:\n                if '=' in arg:\n                    argparts = arg.split(\"=\")\n                    value_parts = argparts[1:]\n                    arg = argparts[0]\n                    value = '='.join(value_parts)\n\n                elif i + 1 < len(argv):\n                    value = argv[i+1]\n                    i += 1\n\n                else:\n                    print >> sys.stderr, \"%s requires an argument\" % special_flag\n                    return False\n\n            else:\n                # just set\n                value = \"1\"\n\n            break\n\n        i += 1\n\n        if value is not None:\n            if 'envar' in special_flags[special_flag]:\n                # recognized\n                cli_envs[ special_flags[special_flag]['envar'] ] = value\n            \n            if 'argname' in special_flags[special_flag]:\n                # recognized as special argument\n                cli_args[ special_flags[special_flag]['argname'] ] = value\n                new_argv.append(arg)\n                new_argv.append(value)\n\n            if special_flags[special_flag]['exec']:\n                do_exec = True\n\n        else:\n            # not recognized\n            new_argv.append(arg)\n            stripped_argv.append(arg)\n\n    if do_exec:\n        # re-exec\n        for cli_env, cli_env_value in cli_envs.items():\n            os.environ[cli_env] = cli_env_value\n\n        if os.environ.get(\"BLOCKSTACK_DEBUG\") is not None:\n            print \"Re-exec as {}\".format(\" \".join(new_argv))\n\n        os.execv(new_argv[0], new_argv)\n\n    log.debug(\"Stripped argv: {}\".format(' '.join(stripped_argv)))\n    return cli_args, stripped_argv"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_expected_snapshots( snapshots_path ):\n    # use snapshots?\n    snapshots_path = os.path.expanduser(snapshots_path)\n    expected_snapshots = {}\n\n    # legacy chainstate?\n    try:\n        with open(snapshots_path, \"r\") as f:\n            snapshots_json = f.read()\n        \n        snapshots_data = json.loads(snapshots_json)\n        assert 'snapshots' in snapshots_data.keys(), \"Not a valid snapshots file\"\n\n        # extract snapshots: map int to consensus hash\n        for (block_id_str, consensus_hash) in snapshots_data['snapshots'].items():\n            expected_snapshots[ int(block_id_str) ] = str(consensus_hash)\n        \n        log.debug(\"Loaded expected snapshots from legacy JSON {}; {} entries\".format(snapshots_path, len(expected_snapshots)))\n        return expected_snapshots\n    \n    except ValueError as ve:\n        log.debug(\"Snapshots file {} is not JSON\".format(snapshots_path))\n\n    except Exception as e:\n        if os.environ.get('BLOCKSTACK_DEBUG') == '1':\n            log.exception(e)\n\n        log.debug(\"Failed to read expected snapshots from '{}'\".format(snapshots_path))\n        return None\n\n    try:\n        # sqlite3 db?\n        db_con = virtualchain.StateEngine.db_connect(snapshots_path)\n        expected_snapshots = virtualchain.StateEngine.get_consensus_hashes(None, None, db_con=db_con, completeness_check=False)\n        log.debug(\"Loaded expected snapshots from chainstate DB {}, {} entries\".format(snapshots_path, len(expected_snapshots)))\n        return expected_snapshots\n\n    except:\n        log.debug(\"{} does not appear to be a chainstate DB\".format(snapshots_path))\n\n    return None", "response": "Load expected consensus hashes from a. snapshots file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_genesis_block_audit(genesis_block_path=None, key_id=None):\n    signing_keys = GENESIS_BLOCK_SIGNING_KEYS\n    if genesis_block_path is not None:\n        # alternative genesis block\n        genesis_block_load(genesis_block_path)\n    \n    if key_id is not None:\n        # alternative signing key\n        gpg2_path = find_gpg2()\n        assert gpg2_path, 'You need to install gpg2'\n        p = subprocess.Popen([gpg2_path, '-a', '--export', key_id], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out, err = p.communicate()\n        if p.returncode != 0:\n            log.error('Failed to load key {}\\n{}'.format(key_id, err))\n            return False\n\n        signing_keys = { key_id: out.strip() }\n        \n    res = genesis_block_audit(get_genesis_block_stages(), key_bundle=signing_keys)\n    if not res:\n        log.error('Genesis block is NOT signed by {}'.format(', '.join(signing_keys.keys())))\n        return False\n\n    return True", "response": "Load and audit the given genesis block"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset up the recovery metadata so we can fully recover secondary state, like subdomains.", "response": "def setup_recovery(working_dir):\n    \"\"\"\n    Set up the recovery metadata so we can fully recover secondary state,\n    like subdomains.\n    \"\"\"\n    db = get_db_state(working_dir)\n    bitcoind_session = get_bitcoind(new=True)\n    assert bitcoind_session is not None\n\n    _, current_block = virtualchain.get_index_range('bitcoin', bitcoind_session, virtualchain_hooks, working_dir)\n    assert current_block, 'Failed to connect to bitcoind'\n\n    set_recovery_range(working_dir, db.lastblock, current_block - NUM_CONFIRMATIONS)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_recovery(working_dir):\n    recovery_start_block, recovery_end_block = get_recovery_range(working_dir)\n    if recovery_start_block is not None and recovery_end_block is not None:\n        local_current_block = virtualchain_hooks.get_last_block(working_dir)\n        if local_current_block <= recovery_end_block:\n            return True\n\n        # otherwise, we're outside the recovery range and we can clear it\n        log.debug('Chain state is at block {}, and is outside the recovery window {}-{}'.format(local_current_block, recovery_start_block, recovery_end_block))\n        clear_recovery_range(working_dir)\n        return False\n\n    else:\n        # not recovering\n        return False", "response": "Check if we need to recover on start - up?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_POST(self):\n\n        # Check that the path is legal\n        if not self.is_rpc_path_valid():\n            self.report_404()\n            return\n\n        # reject gzip, so size-caps will work\n        encoding = self.headers.get(\"content-encoding\", \"identity\").lower()\n        if encoding != 'identity':\n            log.error(\"Reject request with encoding '{}'\".format(encoding))\n            self.send_response(501, \"encoding %r not supported\" % encoding)\n            return\n\n        try:\n            size_remaining = int(self.headers[\"content-length\"])\n            if size_remaining > self.MAX_REQUEST_SIZE:\n                if os.environ.get(\"BLOCKSTACK_DEBUG\") == \"1\":\n                    log.error(\"Request is too big!\")\n\n                self.send_response(400)\n                self.send_header('Content-length', '0')\n                self.end_headers()\n                return\n\n            if os.environ.get(\"BLOCKSTACK_DEBUG\") == \"1\":\n                log.debug(\"Message is small enough to parse ({} bytes)\".format(size_remaining))\n\n            # Get arguments by reading body of request.\n            # never read more than our max size\n            L = []\n            while size_remaining:\n                chunk_size = min(size_remaining, self.MAX_REQUEST_SIZE)\n                chunk = self.rfile.read(chunk_size)\n                if not chunk:\n                    break\n                L.append(chunk)\n                size_remaining -= len(L[-1])\n\n            data = ''.join(L)\n\n            data = self.decode_request_content(data)\n            if data is None:\n                return #response has been sent\n\n            # In previous versions of SimpleXMLRPCServer, _dispatch\n            # could be overridden in this class, instead of in\n            # SimpleXMLRPCDispatcher. To maintain backwards compatibility,\n            # check to see if a subclass implements _dispatch and dispatch\n            # using that method if present.\n            response = self.server._marshaled_dispatch(\n                    data, getattr(self, '_dispatch', None), self.path\n                )\n\n        except Exception, e: # This should only happen if the module is buggy\n            # internal error, report as HTTP server error\n            self.send_response(500)\n            self.send_header(\"Content-length\", \"0\")\n            self.end_headers()\n\n        else:\n            # got a valid XML RPC response\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/xml\")\n            if self.encode_threshold is not None:\n                if len(response) > self.encode_threshold:\n                    q = self.accept_encodings().get(\"gzip\", 0)\n                    if q:\n                        try:\n                            response = xmlrpclib.gzip_encode(response)\n                            self.send_header(\"Content-Encoding\", \"gzip\")\n                        except NotImplementedError:\n                            pass\n\n            self.send_header(\"Content-length\", str(len(response)))\n            self.end_headers()\n            self.wfile.write(response)", "response": "Handles HTTP POST requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend back an XMLRPC response saying as much as possible.", "response": "def overloaded(self, client_address):\n        \"\"\"\n        Got too many requests.\n        Send back a (precompiled) XMLRPC response saying as much\n        \"\"\"\n        body = {\n            'status': False,\n            'indexing': False,\n            'lastblock': -1,\n            'error': 'overloaded',\n            'http_status': 429\n        }\n        body_str = json.dumps(body)\n\n        resp = 'HTTP/1.0 200 OK\\r\\nServer: BaseHTTP/0.3 Python/2.7.14+\\r\\nContent-type: text/xml\\r\\nContent-length: {}\\r\\n\\r\\n'.format(len(body_str))\n        resp += '<methodResponse><params><param><value><string>{}</string></value></param></params></methodResponse>'.format(body_str)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef success_response(self, method_resp, **kw):\n        resp = {\n            'status': True,\n            'indexing': config.is_indexing(self.working_dir),\n            'lastblock': virtualchain_hooks.get_last_block(self.working_dir),\n        }\n\n        resp.update(kw)\n        resp.update(method_resp)\n        \n        if self.is_stale():\n            # our state is stale\n            resp['stale'] = True\n            resp['warning'] = 'Daemon has not reindexed since {}'.format(self.last_indexing_time)\n\n        return resp", "response": "Make a standard success response."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsanitizes a name or namespace record before returning it.", "response": "def sanitize_rec(self, rec):\n        \"\"\"\n        sanitize a name/namespace record before returning it.\n        * canonicalize it\n        * remove quirk fields\n        \"\"\"\n        opcode = rec['opcode']\n        canonical_op = op_canonicalize(opcode, rec)\n\n        # don't return internally-used quirk fields\n        quirk_fields = op_get_quirk_fields(opcode)\n        for f in quirk_fields:\n            if f in canonical_op:\n                del canonical_op[f]\n\n        # if we have a 'token_fee', make it a string\n        if 'token_fee' in canonical_op:\n            canonical_op['token_fee'] = str(canonical_op['token_fee'])\n\n        canonical_op['opcode'] = opcode\n        return canonical_op"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_name_info(self, db, name_record):\n        name = str(name_record['name'])\n        name_record = self.sanitize_rec(name_record)\n\n        namespace_id = get_namespace_from_name(name)\n        namespace_record = db.get_namespace(namespace_id, include_history=False)\n        if namespace_record is None:\n            namespace_record = db.get_namespace_reveal(namespace_id, include_history=False)\n\n        if namespace_record is None:\n            # name can't exist (this can be arrived at if we're resolving a DID)\n            return None\n\n        # when does this name expire (if it expires)?\n        if namespace_record['lifetime'] != NAMESPACE_LIFE_INFINITE:\n            deadlines = BlockstackDB.get_name_deadlines(name_record, namespace_record, db.lastblock)\n            if deadlines is not None:\n                name_record['expire_block'] = deadlines['expire_block']\n                name_record['renewal_deadline'] = deadlines['renewal_deadline']\n            else:\n                # only possible if namespace is not yet ready\n                name_record['expire_block'] = -1\n                name_record['renewal_deadline'] = -1\n\n        else:\n            name_record['expire_block'] = -1\n            name_record['renewal_deadline'] = -1\n\n        if name_record['expire_block'] > 0 and name_record['expire_block'] <= db.lastblock:\n            name_record['expired'] = True\n        else:\n            name_record['expired'] = False\n\n        # try to get the zonefile as well \n        if 'value_hash' in name_record and name_record['value_hash'] is not None:\n            conf = get_blockstack_opts()\n            if is_atlas_enabled(conf):\n                zfdata = self.get_zonefile_data(name_record['value_hash'], conf['zonefiles'])\n                if zfdata is not None:\n                    zfdata = base64.b64encode(zfdata)\n                    name_record['zonefile'] = zfdata\n\n        return name_record", "response": "Load some extra name information given a db - loaded name record."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets whois - related info for a name.", "response": "def get_name_record(self, name, include_expired=False, include_history=False):\n        \"\"\"\n        Get the whois-related info for a name (not a subdomain).\n        Optionally include the history.\n        Return {'status': True, 'record': rec} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_name(name):\n            return {'error': 'invalid name', 'http_status': 400}\n        \n        name = str(name)\n\n        db = get_db_state(self.working_dir)\n        name_record = db.get_name(str(name), include_expired=include_expired, include_history=include_history)\n\n        if name_record is None:\n            db.close()\n            return {\"error\": \"Not found.\", 'http_status': 404}\n\n        else:\n            assert 'opcode' in name_record, 'BUG: missing opcode in {}'.format(json.dumps(name_record, sort_keys=True))\n            name_record = self.load_name_info(db, name_record)\n            db.close()\n\n            # also get the subdomain resolver \n            resolver = get_subdomain_resolver(name)\n            name_record['resolver'] = resolver\n            return {'status': True, 'record': name_record}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the whois - related info for a subdomain.", "response": "def get_subdomain_record(self, fqn, include_history=False):\n        \"\"\"\n        Get the whois-related info for a subdomain.\n        Optionally include the history for the domain.\n        Return {'status': True, 'record': rec} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_subdomain(fqn):\n            return {'error': 'invalid subdomain', 'http_status': 400}\n        \n        fqn = str(fqn)\n\n        # get current record\n        subdomain_rec = get_subdomain_info(fqn, check_pending=True)\n        if subdomain_rec is None:\n            return {'error': 'Failed to load subdomain', 'http_status': 404}\n   \n        ret = subdomain_rec.to_json()\n        if include_history:\n            subdomain_hist = get_subdomain_history(fqn, json=True)\n            ret['history'] = subdomain_hist\n\n        return {'status': True, 'record': ret}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc_get_name_record(self, name, **con_info):\n        res = None\n        if check_name(name):\n            res = self.get_name_record(name, include_expired=True, include_history=False)\n        elif check_subdomain(name):\n            res = self.get_subdomain_record(name, include_history=False)\n        else:\n            return {'error': 'Invalid name or subdomain', 'http_status': 400}\n\n        if 'error' in res:\n            return {'error': res['error'], 'http_status': 404}\n\n        # also get a DID\n        did_info = None\n        did = None\n        if check_name(name):\n            did_info = self.get_name_DID_info(name)\n        elif check_subdomain(name):\n            did_info = self.get_subdomain_DID_info(name)\n        else:\n            return {'error': 'Invalid name or subdomain', 'http_status': 400}\n\n        if did_info is not None:\n            did = make_DID(did_info['name_type'], did_info['address'], did_info['index'])\n            res['record']['did'] = did\n\n        return self.success_response({'record': res['record']})", "response": "Get the curernt state of a name or subdomain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_name_DID_info(self, name):\n        db = get_db_state(self.working_dir)\n        did_info = db.get_name_DID_info(name)\n        if did_info is None:\n            return {'error': 'No such name', 'http_status': 404}\n\n        return did_info", "response": "Get a name s DID info Returns None if not found"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpc_get_name_DID(self, name, **con_info):\n        did_info = None\n        if check_name(name):\n            did_info = self.get_name_DID_info(name)\n        elif check_subdomain(name):\n            did_info = self.get_subdomain_DID_info(name)\n        else:\n            return {'error': 'Invalid name or subdomain', 'http_status': 400}\n\n        if did_info is None:\n            return {'error': 'No DID for this name', 'http_status': 404}\n\n        did = make_DID(did_info['name_type'], did_info['address'], did_info['index'])\n        return self.success_response({'did': did})", "response": "Get the DID for a name or subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a DID for a name return the name record.", "response": "def get_name_DID_record(self, did):\n        \"\"\"\n        Given a DID for a name, return the name record.\n        Return {'record': ...} on success\n        Return {'error': ...} on error\n        \"\"\"\n        try:\n            did_info = parse_DID(did)\n            assert did_info['name_type'] == 'name'\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            return {'error': 'Invalid DID', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        rec = db.get_DID_name(did)\n        if rec is None:\n            db.close()\n            return {'error': 'Failed to resolve DID to a non-revoked name', 'http_status': 404}\n\n        name_record = self.load_name_info(db, rec)\n        db.close()\n\n        if name_record is None:\n            return {'error': 'DID does not resolve to an existing name', 'http_status': 404}\n\n        return {'record': name_record}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_subdomain_DID_record(self, did):\n        try:\n            did_info = parse_DID(did)\n            assert did_info['name_type'] == 'subdomain'\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            return {'error': 'Invalid DID', 'http_status': 400}\n\n        subrec = get_DID_subdomain(did, check_pending=True)\n        if subrec is None:\n            return {'error': 'Failed to load subdomain from {}'.format(did), 'http_status': 404}\n\n        return {'record': subrec.to_json()}", "response": "Given a DID for subdomain get the subdomain record"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a DID return the name or subdomain it corresponds to", "response": "def rpc_get_DID_record(self, did, **con_info):\n        \"\"\"\n        Given a DID, return the name or subdomain it corresponds to\n        \"\"\"\n        if not isinstance(did, (str,unicode)):\n            return {'error': 'Invalid DID: not a string', 'http_status': 400}\n\n        try:\n            did_info = parse_DID(did)\n        except:\n            return {'error': 'Invalid DID', 'http_status': 400}\n\n        res = None\n        if did_info['name_type'] == 'name':\n            res = self.get_name_DID_record(did)\n        elif did_info['name_type'] == 'subdomain':\n            res = self.get_subdomain_DID_record(did)\n        \n        if 'error' in res:\n            return {'error': res['error'], 'http_status': res.get('http_status', 404)}\n\n        return self.success_response({'record': res['record']})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpc_get_name_blockchain_record(self, name, **con_info):\n        res = None\n        if check_name(name):\n            res = self.get_name_record(name, include_expired=True, include_history=True)\n        elif check_subdomain(name):\n            res = self.get_subdomain_record(name, include_history=True)\n        else:\n            return {'error': 'Invalid name or subdomain', 'http_status': 400}\n\n        if 'error' in res:\n            return {'error': res['error'], 'http_status': res.get('http_status', 404)}\n\n        return self.success_response({'record': res['record']})", "response": "Get the blockchain record for a name or subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the history entries for a name or subdomain.", "response": "def rpc_get_name_history_page(self, name, page, **con_info):\n        \"\"\"\n        Get the list of history entries for a name or subdomain's history, paginated.\n        Small pages correspond to later history (page = 0 is the page of last updates)\n        Page size is 20 rows.\n        Return {'status': True, 'history': [...]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_name(name) and not check_subdomain(name):\n            return {'error': 'invalid name', 'http_status': 400}\n\n        if not check_count(page):\n            return {'error': 'invalid page', 'http_status': 400}\n\n        offset = page * 20\n        count = (page + 1) * 20\n        history_data = None\n\n        if check_name(name):\n            # on-chain name\n            db = get_db_state(self.working_dir)\n            history_data = db.get_name_history(name, offset, count, reverse=True)\n            db.close()\n\n        else:\n            # off-chain name\n            history_data = get_subdomain_history(name, offset=offset, count=count, json=True, reverse=True)\n\n        if len(history_data) == 0:\n            # name didn't exist \n            return {'error': 'Not found', 'http_status': 404}\n\n        return self.success_response({'history': history_data})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nis a name zone file hash issued by a name? Return True if it was set False otherwise.", "response": "def rpc_is_name_zonefile_hash(self, name, zonefile_hash, **con_info):\n        \"\"\"\n        Was a zone file hash issued by a name?  Return {'result': True/False}\n        \"\"\"\n        if not check_name(name) and not check_subdomain(name):\n            return {'error': 'invalid name', 'http_status': 400}\n\n        if not check_string(zonefile_hash, min_length=LENGTHS['value_hash']*2, max_length=LENGTHS['value_hash']*2, pattern=OP_HEX_PATTERN):\n            return {'error': 'invalid zone file hash', 'http_status': 400}\n        \n        was_set = None\n        if check_name(name):\n            # on-chain name \n            db = get_db_state(self.working_dir)\n            was_set = db.is_name_zonefile_hash(name, zonefile_hash)\n            db.close()\n        else:\n            # off-chain name \n            was_set = is_subdomain_zonefile_hash(name, zonefile_hash)\n\n        return self.success_response({'result': was_set})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rpc_get_name_at( self, name, block_height, **con_info ):\n        if not check_name(name):\n            return {'error': 'invalid name', 'http_status': 400}\n\n        if not check_block(block_height):\n            return self.success_response({'record': None})\n\n        db = get_db_state(self.working_dir)\n        names_at = db.get_name_at( name, block_height, include_expired=False )\n        db.close()\n        \n        ret = []\n        for name_rec in names_at:\n            if 'opcode' not in name_rec:\n                name_rec['opcode'] = op_get_opcode_name(name_rec['op'])\n            \n            ret.append(self.sanitize_rec(name_rec))\n\n        return self.success_response( {'records': ret} )", "response": "Get all the states the name was in at a particular block height."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the number of Blockstack operations that occured at the given block.", "response": "def rpc_get_num_blockstack_ops_at(self, block_id, **con_info):\n        \"\"\"\n        Get the number of Blockstack transactions that occured at the given block.\n        Returns {'count': ..} on success\n        Returns {'error': ...} on error\n        \"\"\"\n        if not check_block(block_id):\n            return {'error': 'Invalid block height', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        count = db.get_num_blockstack_ops_at( block_id )\n        db.close()\n\n        log.debug(\"{} name operations at {}\".format(count, block_id))\n        return self.success_response({'count': count})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the name operations that occured in the given block.", "response": "def rpc_get_blockstack_ops_at(self, block_id, offset, count, **con_info):\n        \"\"\"\n        Get the name operations that occured in the given block.\n        Does not include account operations.\n\n        Returns {'nameops': [...]} on success.\n        Returns {'error': ...} on error\n        \"\"\"\n        if not check_block(block_id):\n            return {'error': 'Invalid block height', 'http_status': 400}\n\n        if not check_offset(offset):\n            return {'error': 'Invalid offset', 'http_status': 400}\n\n        if not check_count(count, 10):\n            return {'error': 'Invalid count', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        nameops = db.get_all_blockstack_ops_at(block_id, offset=offset, count=count)\n        db.close()\n\n        log.debug(\"{} name operations at block {}, offset {}, count {}\".format(len(nameops), block_id, offset, count))\n        ret = []\n        \n        for nameop in nameops:\n            assert 'opcode' in nameop, 'BUG: missing opcode in {}'.format(json.dumps(nameop, sort_keys=True))\n            canonical_op = self.sanitize_rec(nameop)\n            ret.append(canonical_op)\n        \n        return self.success_response({'nameops': ret})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rpc_get_blockstack_ops_hash_at( self, block_id, **con_info ):\n        if not check_block(block_id):\n            return {'error': 'Invalid block height', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        ops_hash = db.get_block_ops_hash( block_id )\n        db.close()\n\n        return self.success_response( {'ops_hash': ops_hash} )", "response": "Get the hash over the sequence of names and namespaces altered at the given block."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets cached bitcoind info.", "response": "def get_cached_bitcoind_info(self):\n        \"\"\"\n        Get cached bitcoind info.\n        Returns {...} on success\n        Return None if it is stale\n        \"\"\"\n        cached_bitcoind_info = self.cache.get('bitcoind_info', None)\n        if cached_bitcoind_info is None:\n            # not cached\n            return None\n\n        now = time.time()\n        if cached_bitcoind_info['time'] + AVERAGE_SECONDS_PER_BLOCK < now:\n            # stale\n            return None\n\n        return cached_bitcoind_info['getinfo']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting cached consensus info.", "response": "def get_cached_consensus_info(self):\n        \"\"\"\n        Get cached consensus info.\n        Returns {...} on success\n        Return None if it is stale\n        \"\"\"\n        cached_consensus_info = self.cache.get('consensus_info', None)\n        if cached_consensus_info is None:\n            # not cached\n            return None\n\n        now = time.time()\n        if cached_consensus_info['time'] + AVERAGE_SECONDS_PER_BLOCK < now:\n            # stale\n            return None\n\n        return cached_consensus_info['info']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget bitcoind info. Try the cache and fetch from bitcoind and cache.", "response": "def get_bitcoind_info(self):\n        \"\"\"\n        Get bitcoind info.  Try the cache, and on cache miss, \n        fetch from bitcoind and cache.\n        \"\"\"\n        cached_bitcoind_info = self.get_cached_bitcoind_info()\n        if cached_bitcoind_info:\n            return cached_bitcoind_info\n\n        bitcoind_opts = default_bitcoind_opts( virtualchain.get_config_filename(virtualchain_hooks, self.working_dir), prefix=True )\n        bitcoind = get_bitcoind( new_bitcoind_opts=bitcoind_opts, new=True )\n\n        if bitcoind is None:\n            return {'error': 'Internal server error: failed to connect to bitcoind'}\n        \n        try:\n            info = bitcoind.getinfo()\n            assert 'error' not in info\n            assert 'blocks' in info\n\n            self.set_cached_bitcoind_info(info)\n            return info\n\n        except Exception as e:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_consensus_info(self):\n        cached_consensus_info = self.get_cached_consensus_info()\n        if cached_consensus_info:\n            return cached_consensus_info\n\n        db = get_db_state(self.working_dir)\n        ch = db.get_current_consensus()\n        block = db.get_current_block()\n        db.close()\n\n        cinfo = {'consensus_hash': ch, 'block_height': block}\n        self.set_cached_consensus_info(cinfo)\n        return cinfo", "response": "Get the consensus hash and block height."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_getinfo(self, **con_info):\n        conf = get_blockstack_opts()\n        info = self.get_bitcoind_info()\n        cinfo = self.get_consensus_info()\n        reply = {}\n        reply['last_block_seen'] = info['blocks']\n\n        reply['consensus'] = cinfo['consensus_hash']\n        reply['server_version'] = \"%s\" % VERSION\n        reply['last_block_processed'] = cinfo['block_height']\n        reply['server_alive'] = True\n        reply['indexing'] = config.is_indexing(self.working_dir)\n\n        # this is a bit janky, but the logic is as follows:\n        # * BLOCKSTACK_TESTNET_ACTIVE means that we've explicitly set an alternative magic bytes, so we should report this.\n        # * BLOCKSTACK_PUBLIC_TESTNET means that we're on the default hosted testnet (e.g. testnet.blockstack.org)\n        # * BLOCKSTACK_TEST or BLOCKSTACK_TESTNET usually means we're running inside an integration test\n        if BLOCKSTACK_TESTNET_ACTIVE:\n            reply['testnet'] = MAGIC_BYTES\n\n        elif BLOCKSTACK_PUBLIC_TESTNET:\n            reply['testnet'] = 'hosted'\n\n        elif BLOCKSTACK_TEST or BLOCKSTACK_TESTNET:\n            reply['testnet'] = True\n\n        else:\n            reply['testnet'] = False\n\n        reply['first_block'] = FIRST_BLOCK_MAINNET\n\n        if conf.get('atlas', False):\n            # return zonefile inv length\n            reply['zonefile_count'] = atlas_get_num_zonefiles()\n\n        if self.is_stale():\n            reply['stale'] = True\n            reply['warning'] = 'Daemon is behind the chain tip.  Do not rely on it for fresh information.'\n\n        return reply", "response": "Get information about the current bitcoind server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the list of subdomains owned by an address.", "response": "def rpc_get_subdomains_owned_by_address(self, address, **con_info):\n        \"\"\"\n        Get the list of subdomains owned by an address.\n        Return {'status': True, 'subdomains': ...} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        res = get_subdomains_owned_by_address(address)\n        return self.success_response({'subdomains': res})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the list of names owned by an address.", "response": "def rpc_get_names_owned_by_address(self, address, **con_info):\n        \"\"\"\n        Get the list of names owned by an address.\n        Return {'status': True, 'names': ...} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        names = db.get_names_owned_by_address( address )\n        db.close()\n\n        if names is None:\n            names = []\n\n        return self.success_response( {'names': names} )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_get_historic_names_by_address(self, address, offset, count, **con_info):\n        if not check_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 10):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        names = db.get_historic_names_by_address(address, offset, count)\n        db.close()\n\n        if names is None:\n            names = []\n\n        return self.success_response( {'names': names} )", "response": "Get the list of names owned by an address throughout history\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the number of names owned by an address throughout history", "response": "def rpc_get_num_historic_names_by_address(self, address, **con_info):\n        \"\"\"\n        Get the number of names owned by an address throughout history\n        Return {'status': True, 'count': ...} on success\n        Return {'error': ...} on failure\n        \"\"\"\n        if not check_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        ret = db.get_num_historic_names_by_address(address)\n        db.close()\n\n        if ret is None:\n            ret = 0\n\n        return self.success_response( {'count': ret} )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_get_name_cost( self, name, **con_info ):\n        if not check_name(name):\n            return {'error': 'Invalid name or namespace', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        ret = get_name_cost( db, name )\n        db.close()\n\n        if ret is None:\n            return {\"error\": \"Unknown/invalid namespace\", 'http_status': 404}\n\n        return self.success_response(ret)", "response": "Get the cost of a given name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the cost of a given namespace including fees.", "response": "def rpc_get_namespace_cost( self, namespace_id, **con_info ):\n        \"\"\"\n        Return the cost of a given namespace, including fees.\n        Returns {'amount': ..., 'units': ...}\n        \"\"\"\n        if not check_namespace(namespace_id):\n            return {'error': 'Invalid namespace', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        res = get_namespace_cost( db, namespace_id )\n        db.close()\n\n        units = res['units']\n        amount = res['amount']\n        ns = res['namespace']\n\n        if amount is None:\n            # invalid \n            return {'error': 'Invalid namespace', 'http_status': 404}\n\n        ret = {\n            'units': units,\n            'amount': amount,\n        }\n\n        if ns is not None:\n            ret['warning'] = 'Namespace already exists'\n\n        return self.success_response( ret )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpc_get_account_tokens(self, address, **con_info):\n        if not check_account_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        # must be b58\n        if is_c32_address(address):\n            address = c32ToB58(address)\n\n        db = get_db_state(self.working_dir)\n        token_list = db.get_account_tokens(address)\n        db.close()\n        return self.success_response({'token_types': token_list})", "response": "Get the types of tokens that an account owns\n        Returns the list on success"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpc_get_account_balance(self, address, token_type, **con_info):\n        if not check_account_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        if not check_token_type(token_type):\n            return {'error': 'Invalid token type', 'http_status': 400}\n\n        # must be b58\n        if is_c32_address(address):\n            address = c32ToB58(address)\n\n        db = get_db_state(self.working_dir)\n        account = db.get_account(address, token_type)\n        if account is None:\n            return self.success_response({'balance': 0})\n\n        balance = db.get_account_balance(account)\n        if balance is None:\n            balance = 0\n\n        db.close()\n        return self.success_response({'balance': balance})", "response": "Get the balance of an account for a particular token type Returns 0 if the balance is 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_account_state(self, account_state):\n        return {\n            'address': account_state['address'],\n            'type': account_state['type'],\n            'credit_value': '{}'.format(account_state['credit_value']),\n            'debit_value': '{}'.format(account_state['debit_value']),\n            'lock_transfer_block_id': account_state['lock_transfer_block_id'],\n            'block_id': account_state['block_id'],\n            'vtxindex': account_state['vtxindex'],\n            'txid': account_state['txid'],\n        }", "response": "Export account state to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the current state of an account record", "response": "def rpc_get_account_record(self, address, token_type, **con_info):\n        \"\"\"\n        Get the current state of an account\n        \"\"\"\n        if not check_account_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        if not check_token_type(token_type):\n            return {'error': 'Invalid token type', 'http_status': 400}\n\n        # must be b58\n        if is_c32_address(address):\n            address = c32ToB58(address)\n\n        db = get_db_state(self.working_dir)\n        account = db.get_account(address, token_type)\n        db.close()\n\n        if account is None:\n            return {'error': 'No such account', 'http_status': 404}\n\n        state = self.export_account_state(account)\n        return self.success_response({'account': state})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the history of an account.", "response": "def rpc_get_account_history(self, address, page, **con_info):\n        \"\"\"\n        Get the history of an account, pagenated over a block range.\n        Returns the sequence of history states on success (can be empty)\n        \"\"\"\n        if not check_account_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        if not check_count(page):\n            return {'error': 'Invalid page', 'http_status': 400}\n\n        # must be b58\n        if is_c32_address(address):\n            address = c32ToB58(address)\n\n        db = get_db_state(self.working_dir)\n        page_size = 20\n        account_history = db.get_account_history(address, offset=(page * page_size), count=page_size)\n        db.close()\n\n        # return credit_value and debit_value as strings, so the unwitting JS developer doesn't get confused\n        # as to why large balances get mysteriously converted to doubles.\n        ret = [self.export_account_state(hist) for hist in account_history]\n        return self.success_response({'history': ret})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_get_account_at(self, address, block_height, **con_info):\n        if not check_account_address(address):\n            return {'error': 'Invalid address', 'http_status': 400}\n\n        if not check_block(block_height):\n            return {'error': 'Invalid start block', 'http_status': 400}\n\n        # must be b58\n        if is_c32_address(address):\n            address = c32ToB58(address)\n    \n        db = get_db_state(self.working_dir)\n        account_states = db.get_account_at(address, block_height)\n        db.close()\n\n        # return credit_value and debit_value as strings, so the unwitting JS developer doesn't get confused\n        # as to why large balances get mysteriously converted to doubles.\n        ret = [self.export_account_state(hist) for hist in account_states]\n        return self.success_response({'history': ret})", "response": "Get the account s statuses at a particular block height."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rpc_get_namespace_blockchain_record( self, namespace_id, **con_info ):\n        if not check_namespace(namespace_id):\n            return {'error': 'Invalid name or namespace', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        ns = db.get_namespace( namespace_id )\n        if ns is None:\n            # maybe revealed?\n            ns = db.get_namespace_reveal( namespace_id )\n            db.close()\n\n            if ns is None:\n                return {\"error\": \"No such namespace\", 'http_status': 404}\n\n            assert 'opcode' in ns, 'BUG: missing opcode in {}'.format(json.dumps(ns, sort_keys=True))\n            ns = self.sanitize_rec(ns)\n\n            ns['ready'] = False\n            return self.success_response( {'record': ns} )\n\n        else:\n            db.close()\n            \n            assert 'opcode' in ns, 'BUG: missing opcode in {}'.format(json.dumps(ns, sort_keys=True))\n            ns = self.sanitize_rec(ns)\n\n            ns['ready'] = True\n            return self.success_response( {'record': ns} )", "response": "Get the namespace blockchain record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the number of names that exist and are not expired", "response": "def rpc_get_num_names( self, **con_info ):\n        \"\"\"\n        Get the number of names that exist and are not expired\n        Return {'status': True, 'count': count} on success\n        Return {'error': ...} on error\n        \"\"\"\n        db = get_db_state(self.working_dir)\n        num_names = db.get_num_names()\n        db.close()\n\n        return self.success_response( {'count': num_names} )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the number of names that have ever existed in the current working directory", "response": "def rpc_get_num_names_cumulative( self, **con_info ):\n        \"\"\"\n        Get the number of names that have ever existed\n        Return {'status': True, 'count': count} on success\n        Return {'error': ...} on error\n        \"\"\"\n        db = get_db_state(self.working_dir)\n        num_names = db.get_num_names(include_expired=True)\n        db.close()\n\n        return self.success_response( {'count': num_names} )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all unexpired names paginated", "response": "def rpc_get_all_names( self, offset, count, **con_info ):\n        \"\"\"\n        Get all unexpired names, paginated\n        Return {'status': true, 'names': [...]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 100):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        num_domains = db.get_num_names()\n        if num_domains > offset:\n           all_domains = db.get_all_names( offset=offset, count=count )\n        else:\n           all_domains = []\n        db.close()\n\n        return self.success_response( {'names': all_domains} )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rpc_get_all_subdomains( self, offset, count, **conf_info):\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 100):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        all_subdomains = get_all_subdomains(offset = offset,\n                                            count = count)\n\n        return self.success_response( {'names': all_subdomains} )", "response": "Get all subdomains, paginated\n        Return {'status': true, 'names': [...]} on success\n        Return {'error': ...} on error"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all names that have ever existed paginated", "response": "def rpc_get_all_names_cumulative( self, offset, count, **con_info ):\n        \"\"\"\n        Get all names that have ever existed, paginated\n        Return {'status': true, 'names': [...]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 100):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        all_names = db.get_all_names( offset=offset, count=count, include_expired=True )\n        db.close()\n\n        return self.success_response( {'names': all_names} )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all namespace names", "response": "def rpc_get_all_namespaces( self, **con_info ):\n        \"\"\"\n        Get all namespace names\n        Return {'status': true, 'namespaces': [...]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        db = get_db_state(self.working_dir)\n        all_namespaces = db.get_all_namespace_ids()\n        db.close()\n\n        return self.success_response( {'namespaces': all_namespaces} )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc_get_num_names_in_namespace( self, namespace_id, **con_info ):\n        if not check_namespace(namespace_id):\n            return {'error': 'Invalid name or namespace', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        num_names = db.get_num_names_in_namespace( namespace_id )\n        db.close()\n\n        return self.success_response( {'count': num_names} )", "response": "Get the number of names in a namespace Return 200 on success Return 400 on error"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets names in a namespace", "response": "def rpc_get_names_in_namespace( self, namespace_id, offset, count, **con_info ):\n        \"\"\"\n        Return all names in a namespace, paginated\n        Return {'status': true, 'names': [...]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_namespace(namespace_id):\n            return {'error': 'Invalid name or namespace', 'http_status': 400}\n\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 100):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        if not is_namespace_valid( namespace_id ):\n            return {'error': 'invalid namespace ID', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        res = db.get_names_in_namespace( namespace_id, offset=offset, count=count )\n        db.close()\n\n        return self.success_response( {'names': res} )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the list of subdomain operations accepted within a given txid.", "response": "def rpc_get_subdomain_ops_at_txid(self, txid, **con_info):\n        \"\"\"\n        Return the list of subdomain operations accepted within a given txid.\n        Return {'status': True, 'subdomain_ops': [{...}]} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_string(txid, min_length=64, max_length=64, pattern='^[0-9a-fA-F]{64}$'):\n            return {'error': 'Not a valid txid', 'http_status': 400}\n       \n        subdomain_ops = get_subdomain_ops_at_txid(txid)\n        return self.success_response( {'subdomain_ops': subdomain_ops} )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the consensus hash at a block number.", "response": "def rpc_get_consensus_at( self, block_id, **con_info ):\n        \"\"\"\n        Return the consensus hash at a block number.\n        Return {'status': True, 'consensus': ...} on success\n        Return {'error': ...} on error\n        \"\"\"\n        if not check_block(block_id):\n            return {'error': 'Invalid block height', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        consensus = db.get_consensus_at( block_id )\n        db.close()\n        return self.success_response( {'consensus': consensus} )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the consensus hashes at multiple block numbers", "response": "def rpc_get_consensus_hashes( self, block_id_list, **con_info ):\n        \"\"\"\n        Return the consensus hashes at multiple block numbers\n        Return a dict mapping each block ID to its consensus hash.\n\n        Returns {'status': True, 'consensus_hashes': dict} on success\n        Returns {'error': ...} on success\n        \"\"\"\n        if type(block_id_list) != list:\n            return {'error': 'Invalid block heights', 'http_status': 400}\n\n        if len(block_id_list) > 32:\n            return {'error': 'Too many block heights', 'http_status': 400}\n\n        for bid in block_id_list:\n            if not check_block(bid):\n                return {'error': 'Invalid block height', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        ret = {}\n        for block_id in block_id_list:\n            ret[block_id] = db.get_consensus_at(block_id)\n\n        db.close()\n\n        return self.success_response( {'consensus_hashes': ret} )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc_get_block_from_consensus( self, consensus_hash, **con_info ):\n        if not check_string(consensus_hash, min_length=LENGTHS['consensus_hash']*2, max_length=LENGTHS['consensus_hash']*2, pattern=OP_CONSENSUS_HASH_PATTERN):\n            return {'error': 'Not a valid consensus hash', 'http_status': 400}\n\n        db = get_db_state(self.working_dir)\n        block_id = db.get_block_from_consensus( consensus_hash )\n        db.close()\n        return self.success_response( {'block_id': block_id} )", "response": "Get the block number from the consensus hash"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the local zonefiles from the local zone set.", "response": "def rpc_get_zonefiles( self, zonefile_hashes, **con_info ):\n        \"\"\"\n        Get zonefiles from the local zonefile set.\n        Only return at most 100 zonefiles.\n        Return {'status': True, 'zonefiles': {zonefile_hash: zonefile}} on success\n        Return {'error': ...} on error\n\n        zonefiles will be serialized to string and base64-encoded\n        \"\"\"\n        conf = get_blockstack_opts()\n        if not is_atlas_enabled(conf):\n            return {'error': 'No data', 'http_status': 400}\n            \n        if 'zonefiles' not in conf:\n            return {'error': 'No zonefiles directory (likely a configuration bug)', 'http_status': 404}\n\n        if type(zonefile_hashes) != list:\n            log.error(\"Not a zonefile hash list\")\n            return {'error': 'Invalid zonefile hashes', 'http_status': 400}\n\n        if len(zonefile_hashes) > 100:\n            log.error(\"Too many requests (%s)\" % len(zonefile_hashes))\n            return {'error': 'Too many requests (no more than 100 allowed)', 'http_status': 400}\n\n        for zfh in zonefile_hashes:\n            if not check_string(zfh, min_length=LENGTHS['value_hash']*2, max_length=LENGTHS['value_hash']*2, pattern=OP_HEX_PATTERN):\n                return {'error': 'Invalid zone file hash', 'http_status': 400}\n\n        ret = {}\n        for zonefile_hash in zonefile_hashes:\n            zonefile_data = self.get_zonefile_data( zonefile_hash, conf['zonefiles'] )\n            if zonefile_data is None:\n                continue\n\n            else:\n                ret[zonefile_hash] = base64.b64encode( zonefile_data )\n\n        log.debug(\"Serve back %s zonefiles\" % len(ret.keys()))\n        return self.success_response( {'zonefiles': ret} )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rpc_put_zonefiles( self, zonefile_datas, **con_info ):\n        conf = get_blockstack_opts()\n        if not is_atlas_enabled(conf):\n            return {'error': 'No data', 'http_status': 400}\n        \n        if 'zonefiles' not in conf:\n            return {'error': 'No zonefiles directory (likely a configuration error)', 'http_status': 400}\n\n        if type(zonefile_datas) != list:\n            return {'error': 'Invalid data', 'http_status': 400}\n\n        if len(zonefile_datas) > 5:\n            return {'error': 'Too many zonefiles', 'http_status': 400}\n\n        for zfd in zonefile_datas:\n            if not check_string(zfd, max_length=((4 * RPC_MAX_ZONEFILE_LEN) / 3) + 3, pattern=OP_BASE64_EMPTY_PATTERN):\n                return {'error': 'Invalid zone file payload (exceeds {} bytes and/or not base64-encoded)'.format(RPC_MAX_ZONEFILE_LEN)}\n\n        zonefile_dir = conf.get(\"zonefiles\", None)\n        saved = []\n\n        for zonefile_data in zonefile_datas:\n\n            # decode\n            try:\n                zonefile_data = base64.b64decode( zonefile_data )\n            except:\n                log.debug(\"Invalid base64 zonefile\")\n                saved.append(0)\n                continue\n\n            if len(zonefile_data) > RPC_MAX_ZONEFILE_LEN:\n                log.debug(\"Zonefile too long\")\n                saved.append(0)\n                continue\n            \n            # is this zone file already discovered?\n            zonefile_hash = get_zonefile_data_hash(str(zonefile_data))\n            zfinfos = atlasdb_get_zonefiles_by_hash(zonefile_hash, path=conf['atlasdb_path'])\n            if not zfinfos:\n                # nope\n                log.debug(\"Unknown zonefile hash {}\".format(zonefile_hash))\n                saved.append(0)\n                continue\n            \n            # keep this zone file\n            rc = store_atlas_zonefile_data( str(zonefile_data), zonefile_dir )\n            if not rc:\n                log.error(\"Failed to store zonefile {}\".format(zonefile_hash))\n                saved.append(0)\n                continue\n             \n            # mark this zone file as present, so we don't ask anyone else for it\n            was_present = atlasdb_set_zonefile_present(zonefile_hash, True, path=conf['atlasdb_path'])\n            if was_present:\n                # we already got this zone file\n                # only process it if it's outside our recovery range \n                recovery_start, recovery_end = get_recovery_range(self.working_dir)\n                current_block = virtualchain_hooks.get_last_block(self.working_dir)\n\n                if recovery_start is not None and recovery_end is not None and recovery_end < current_block:\n                    # no need to process\n                    log.debug(\"Already have zonefile {}\".format(zonefile_hash))\n                    saved.append(1)\n                    continue\n\n            if self.subdomain_index:\n                # got new zonefile\n                # let the subdomain indexer know, along with giving it the minimum block height\n                min_block_height = min([zfi['block_height'] for zfi in zfinfos])\n                log.debug(\"Enqueue {} from {} for subdomain processing\".format(zonefile_hash, min_block_height))\n                self.subdomain_index.enqueue_zonefile(zonefile_hash, min_block_height)\n\n            log.debug(\"Stored new zonefile {}\".format(zonefile_hash))\n            saved.append(1)\n\n        log.debug(\"Saved {} zonefile(s)\".format(sum(saved)))\n        log.debug(\"Reply: {}\".format({'saved': saved}))\n        return self.success_response( {'saved': saved} )", "response": "Store one or more zone files given as serialized strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rpc_get_zonefiles_by_block( self, from_block, to_block, offset, count, **con_info ):\n        conf = get_blockstack_opts()\n        if not is_atlas_enabled(conf):\n            return {'error': 'Not an atlas node', 'http_status': 400}\n\n        if not check_block(from_block):\n            return {'error': 'Invalid from_block height', 'http_status': 400}\n\n        if not check_block(to_block):\n            return {'error': 'Invalid to_block height', 'http_status': 400}\n\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(count, 100):\n            return {'error': 'invalid count', 'http_status': 400}\n\n        zonefile_info = atlasdb_get_zonefiles_by_block(from_block, to_block, offset, count, path=conf['atlasdb_path'])\n        if 'error' in zonefile_info:\n           return zonefile_info\n\n        return self.success_response( {'zonefile_info': zonefile_info } )", "response": "Get information about zonefiles announced in blocks [ from_block to_block offset count - number of records to return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef peer_exchange(self, peer_host, peer_port):\n        # get peers\n        peer_list = atlas_get_live_neighbors( \"%s:%s\" % (peer_host, peer_port) )\n        if len(peer_list) > atlas_max_neighbors():\n            random.shuffle(peer_list)\n            peer_list = peer_list[:atlas_max_neighbors()]\n\n        log.info(\"Enqueue remote peer {}:{}\".format(peer_host, peer_port))\n        atlas_peer_enqueue( \"%s:%s\" % (peer_host, peer_port))\n\n        log.debug(\"Live peers reply to %s:%s: %s\" % (peer_host, peer_port, peer_list))\n        return peer_list", "response": "Exchange a given peer to a list of healthy peers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_get_atlas_peers( self, **con_info ):\n        conf = get_blockstack_opts()\n        if not conf.get('atlas', False):\n            return {'error': 'Not an atlas node', 'http_status': 404}\n\n        # identify the client...\n        client_host = con_info['client_host']\n        client_port = con_info['client_port']\n\n        peers = self.peer_exchange(client_host, client_port)\n        return self.success_response( {'peers': peers} )", "response": "Get the list of peers for atlas nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_atlas_peer_exchange(self, remote_peer, **con_info):\n        conf = get_blockstack_opts()\n        if not conf.get('atlas', False):\n            return {'error': 'Not an atlas node', 'http_status': 404}\n\n        # take the socket-given information if this is not localhost\n        client_host = con_info['client_host']\n        client_port = con_info['client_port']\n\n        peer_host = None\n        peer_port = None\n        \n        LOCALHOST = ['127.0.0.1', '::1', 'localhost']\n        if client_host not in LOCALHOST:\n            # we don't allow a non-localhost peer to insert an arbitrary host\n            peer_host = client_host\n            peer_port = client_port\n\n        else:\n            try:\n                peer_host, peer_port = url_to_host_port(remote_peer)\n                assert peer_host\n                assert peer_port\n            except:\n                # invalid\n                return {'error': 'Invalid remote peer address', 'http_status': 400}\n        \n        peers = self.peer_exchange(peer_host, peer_port)\n        return self.success_response({'peers': peers})", "response": "This function is used to exchange a remote atlas peer and return our list\n        of healthy peers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_get_zonefile_inventory( self, offset, length, **con_info ):\n        conf = get_blockstack_opts()\n        if not is_atlas_enabled(conf):\n            return {'error': 'Not an atlas node', 'http_status': 400}\n\n        if not check_offset(offset):\n            return {'error': 'invalid offset', 'http_status': 400}\n\n        if not check_count(length, 524288):\n            return {'error': 'invalid length', 'http_status': 400}\n\n        zonefile_inv = atlas_get_zonefile_inventory( offset=offset, length=length )\n\n        if BLOCKSTACK_TEST:\n            log.debug(\"Zonefile inventory is '%s'\" % (atlas_inventory_to_string(zonefile_inv)))\n\n        return self.success_response( {'inv': base64.b64encode(zonefile_inv) } )", "response": "Get an inventory bit vector for the zonefiles in the atlas node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping serving. Also stops the thread.", "response": "def stop_server(self):\n        \"\"\"\n        Stop serving.  Also stops the thread.\n        \"\"\"\n        if self.rpc_server is not None:\n            try:\n                self.rpc_server.socket.shutdown(socket.SHUT_RDWR)\n            except:\n                log.warning(\"Failed to shut down server socket\")\n\n            self.rpc_server.shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop_server(self):\n        if self.api_server is not None:\n            try:\n                self.api_server.socket.shutdown(socket.SHUT_RDWR)\n            except:\n                log.warning(\"Failed to shut down API server socket\")\n\n            self.api_server.shutdown()", "response": "Stop serving the API server socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the last block processed by this virtualchain", "response": "def get_last_block(working_dir):\n    \"\"\"\n    Get the last block processed\n    Return the integer on success\n    Return None on error\n    \"\"\"\n\n    # make this usable even if we haven't explicitly configured virtualchain \n    impl = sys.modules[__name__]\n    return BlockstackDB.get_lastblock(impl, working_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_snapshots(working_dir, start_block=None, end_block=None):\n\n    # make this usable even if we haven't explicitly configured virtualchain \n    impl = sys.modules[__name__]\n    return BlockstackDB.get_consensus_hashes(impl, working_dir, start_block_height=start_block, end_block_height=end_block)", "response": "Read the virtualchain snapshots\n    Returns the dict of the snapshots on success Returns None on error"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_db_state(working_dir):\n    impl = sys.modules[__name__]\n    db_inst = BlockstackDB.get_readonly_instance(working_dir)\n    assert db_inst, 'Failed to instantiate database handle'\n    return db_inst", "response": "Returns a handle to the database handle that we can use to store state for this virtual chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a read - only handle to the DB.", "response": "def get_or_instantiate_db_state(working_dir):\n    \"\"\"\n    Get a read-only handle to the DB.\n    Instantiate it first if it doesn't exist.\n\n    DO NOT CALL WHILE INDEXING\n\n    Returns the handle on success\n    Raises on error\n    \"\"\"\n\n    # instantiates\n    new_db = BlockstackDB.borrow_readwrite_instance(working_dir, -1)\n    BlockstackDB.release_readwrite_instance(new_db, -1)\n\n    return get_db_state(working_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a blockstack operation from a transaction.", "response": "def db_parse( block_id, txid, vtxindex, op, data, senders, inputs, outputs, fee, db_state=None, **virtualchain_hints ):\n   \"\"\"\n   (required by virtualchain state engine)\n   \n   Parse a blockstack operation from a transaction.  The transaction fields are as follows:\n   * `block_id` is the blockchain height at which this transaction occurs\n   * `txid` is the transaction ID\n   * `data` is the scratch area of the transaction that contains the actual virtualchain operation (e.g. \"id[opcode][payload]\")\n   * `senders` is a list in 1-to-1 correspondence with `inputs` that contains information about what funded the inputs\n   * `inputs` are the list of inputs to the transaction.  Some blockchains (like Bitcoin) support multiple inputs, whereas others (like Ethereum) support only 1.\n   * `outputs` are the list of outputs of the transaction.  Some blockchains (like Bitcoin) support multiple outputs, whereas others (like Ethereum) support only 1.\n   * `fee` is the transaction fee.\n\n   `db_state` is the StateEngine-derived class.  This is a BlockstackDB instance.\n   `**virtualchain_hints` is a dict with extra virtualchain hints that may be relevant.  We require:\n   * `raw_tx`: the hex-encoded string containing the raw transaction.\n\n   Returns a dict with the parsed operation on success.\n   Return None on error\n   \"\"\"\n   # basic sanity checks \n   if len(senders) == 0:\n       raise Exception(\"No senders given\")\n\n   if not check_tx_sender_types(senders, block_id):\n       log.warning('Invalid senders for {}'.format(txid))\n       return None\n\n   # this virtualchain instance must give the 'raw_tx' hint\n   assert 'raw_tx' in virtualchain_hints, 'BUG: incompatible virtualchain: requires raw_tx support'\n\n   # internal sanity check \n   raw_tx = virtualchain_hints['raw_tx']\n   btc_tx_data = virtualchain.btc_tx_deserialize(raw_tx)\n   test_btc_tx = virtualchain.btc_tx_serialize({'ins': inputs, 'outs': outputs, 'locktime': btc_tx_data['locktime'], 'version': btc_tx_data['version']})\n   assert raw_tx == test_btc_tx, 'TX mismatch: {} != {}'.format(raw_tx, test_btc_tx)\n\n   # make sure each op has all the right fields defined \n   try:\n       opcode = op_get_opcode_name(op)\n       assert opcode is not None, \"Unrecognized opcode '%s'\"  % op\n   except Exception, e:\n       log.exception(e)\n       log.error(\"Skipping unrecognized opcode\")\n       return None\n\n   log.debug(\"PARSE %s at (%s, %s): %s\" % (opcode, block_id, vtxindex, data.encode('hex')))\n\n   # get the data\n   op_data = None\n   try:\n       op_data = op_extract( opcode, data, senders, inputs, outputs, block_id, vtxindex, txid )\n   except Exception, e:\n       log.exception(e)\n       op_data = None\n\n   if op_data is not None:\n       try:\n           assert 'op' in op_data, 'BUG: missing op'\n       except Exception as e:\n           log.exception(e)\n           log.error(\"BUG: missing op\")\n           os.abort()\n\n       original_op_data = copy.deepcopy(op_data)\n\n       # propagate tx data \n       op_data['vtxindex'] = int(vtxindex)\n       op_data['txid'] = str(txid)\n       op_data['__original_op_data__'] = original_op_data\n\n   else:\n       log.error(\"Unparseable op '%s'\" % opcode)\n\n   return op_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_mutate_fields( op, op_data ):\n\n    mutate_fields = op_get_mutate_fields( op )\n    assert mutate_fields is not None, \"No mutate fields defined for %s\" % op\n\n    missing = []\n    for field in mutate_fields:\n        if not op_data.has_key(field):\n            missing.append(field)\n\n    assert len(missing) == 0, \"Missing mutation fields for %s: %s\" % (op, \",\".join(missing))\n    return True", "response": "Verify that all mutate fields are present in the given operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef db_scan_block( block_id, op_list, db_state=None ):\n\n    try:\n        assert db_state is not None, \"BUG: no state given\"\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: no state given\")\n        os.abort()\n\n    log.debug(\"SCAN BEGIN: {} ops at block {}\".format(len(op_list), block_id))\n    checked_ops = []\n    for op_data in op_list:\n\n        try:\n            opcode = op_get_opcode_name( op_data['op'] ) \n            assert opcode is not None, \"BUG: unknown op '%s'\" % op\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: invalid operation\")\n            os.abort()\n\n        if opcode not in OPCODE_CREATION_OPS:\n            continue \n\n        # make sure there are no collisions:\n        # build up our collision table in db_state.\n        op_check( db_state, op_data, block_id, checked_ops )\n        checked_ops.append( op_data )\n\n\n    # get collision information for this block\n    collisions = db_state.find_collisions( checked_ops )\n\n    # reject all operations that will collide \n    db_state.put_collisions( block_id, collisions )\n    log.debug(\"SCAN END: {} ops at block {} ({} collisions)\".format(len(op_list), block_id, len(collisions)))", "response": "Scan the block and return a virtualchain tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef db_check( block_id, new_ops, op, op_data, txid, vtxindex, checked_ops, db_state=None ):\n\n    accept = True \n\n    if db_state is not None:\n        \n        try:\n            assert 'txid' in op_data, \"Missing txid from op\"\n            assert 'vtxindex' in op_data, \"Missing vtxindex from op\"\n            opcode = op_get_opcode_name( op )\n            assert opcode is not None, \"BUG: unknown op '%s'\" % op\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: invalid operation\")\n            os.abort()\n\n        log.debug(\"CHECK %s at (%s, %s)\" % (opcode, block_id, vtxindex))\n        rc = op_check( db_state, op_data, block_id, checked_ops )\n        if rc:\n\n            try:\n                opcode = op_data.get('opcode', None)\n                assert opcode is not None, \"BUG: op_check did not set an opcode\"\n            except Exception, e:\n                log.exception(e)\n                log.error(\"FATAL: no opcode set\")\n                os.abort()\n\n            # verify that all mutate fields are present \n            rc = check_mutate_fields( opcode, op_data )\n            if not rc:\n                log.error(\"FATAL: bug in '%s' check() method did not return all mutate fields\" % opcode)\n                os.abort()\n\n        else:\n            accept = False \n\n    return accept", "response": "This function checks the state of a single operation and returns a boolean indicating if it is valid or not."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that all serialization compatibility quirks have been preserved.", "response": "def check_quirks(block_id, block_op, db_state):\n    \"\"\"\n    Check that all serialization compatibility quirks have been preserved.\n    Used primarily for testing.\n    \"\"\"\n    if op_get_opcode_name(block_op['op']) in OPCODE_NAME_NAMEOPS and op_get_opcode_name(block_op['op']) not in OPCODE_NAME_STATE_PREORDER:\n        assert 'last_creation_op' in block_op, 'QUIRK BUG: missing last_creation_op in {}'.format(op_get_opcode_name(block_op['op']))\n\n        if block_op['last_creation_op'] == NAME_IMPORT:\n            # the op_fee will be a float if the name record was created with a NAME_IMPORT\n            assert isinstance(block_op['op_fee'], float), 'QUIRK BUG: op_fee is not a float when it should be'\n   \n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommitting a given operation to the database.", "response": "def db_commit( block_id, op, op_data, txid, vtxindex, db_state=None ):\n    \"\"\"\n    (required by virtualchain state engine)\n\n    Advance the state of the state engine: get a list of all\n    externally visible state transitions.\n   \n    Given a block ID and checked opcode, record it as \n    part of the database.  This does *not* need to write \n    the data to persistent storage, since save() will be \n    called once per block processed.\n  \n    Returns one or more new name operations on success, which will \n    be fed into virtualchain to translate into a string\n    to be used to generate this block's consensus hash.\n    \"\"\"\n    try:\n        assert db_state is not None\n    except:\n        log.error(\"FATAL: no state given\")\n        os.abort()\n\n    if op != 'virtualchain_final':\n        # ongoing processing.\n        # do sanity checks\n        try:\n            assert '__original_op_data__' in op_data, 'BUG: no __original_op_data__'\n            assert 'txid' in op_data, \"BUG: No txid given\"\n            assert 'vtxindex' in op_data, \"BUG: No vtxindex given\"\n            assert op_data['txid'] == txid, \"BUG: txid mismatch\"\n            assert op_data['vtxindex'] == vtxindex, \"BUG: vtxindex mismatch\"\n            \n            opcode = op_data.get('opcode', None)\n            assert opcode in OPCODE_PREORDER_OPS + OPCODE_CREATION_OPS + OPCODE_TRANSITION_OPS + OPCODE_STATELESS_OPS + OPCODE_TOKEN_OPS, \\\n                            \"BUG: uncategorized opcode '%s'\" % opcode\n\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: failed to commit operation\")\n            os.abort()\n\n        # from db_parse\n        original_op_data = op_data['__original_op_data__']\n        del op_data['__original_op_data__']\n\n        # save, and get the sequence of committed operations\n        consensus_ops = []\n        if opcode in OPCODE_STATELESS_OPS:\n            # state-less operation \n            consensus_ops = []\n\n        else:\n            consensus_op = db_state.commit_operation(original_op_data, op_data, block_id)\n            \n            # make sure compatibility quirks are preserved\n            check_quirks(block_id, consensus_op, db_state)\n\n            consensus_ops = [consensus_op]\n        \n        return consensus_ops\n\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the state of the next block to the database.", "response": "def db_save( block_height, consensus_hash, ops_hash, accepted_ops, virtualchain_ops_hints, db_state=None ):\n   \"\"\"\n   (required by virtualchain state engine)\n   \n   Save all persistent state to stable storage.\n   Called once per block.\n\n   In Blockstack's case, we save transactions as we process them.\n   The only thing to do here is to synchronize the Atlas DB and clean up the \n   BlockstackDB instance in preparation for receiving the next blocks' transactions.\n\n   Return True on success\n   Return False on failure.\n   \"\"\"\n   from ..atlas import atlasdb_sync_zonefiles \n\n   if db_state is not None:\n\n        blockstack_opts = get_blockstack_opts()\n        new_zonefile_infos = None\n\n        # vest any tokens for the next block (so they'll be immediately usable in the next block)\n        try:\n            db_state.commit_account_vesting(block_height+1)\n        except Exception as e:\n            log.exception(e)\n            log.fatal(\"Failed to vest accounts at {}+1\".format(block_height))\n            os.abort()\n\n        try:\n            # flush the database\n            db_state.commit_finished(block_height)\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: failed to commit at block %s\" % block_height )\n            os.abort()\n        \n        try:\n            atlas_state = None\n            if hasattr(db_state, 'atlas_state') and db_state.atlas_state is not None:\n                # normal course of action \n                atlas_state = db_state.atlas_state\n\n            # sync block data to atlas, if enabled\n            if is_atlas_enabled(blockstack_opts):\n                log.debug(\"Synchronize Atlas DB for {}\".format(block_height))\n                zonefile_dir = blockstack_opts['zonefiles']\n                atlasdb_path = blockstack_opts['atlasdb_path']\n\n                # NOTE: set end_block explicitly since db_state.lastblock still points to the previous block height\n                gc.collect()\n                new_zonefile_infos = atlasdb_sync_zonefiles(db_state, block_height, zonefile_dir, atlas_state, path=atlasdb_path, end_block=block_height+1)\n                gc.collect()\n\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: failed to update Atlas db at %s\" % block_height )\n            os.abort()\n        \n        try:\n            # sync subdomain state for this block range, if enabled\n            if is_subdomains_enabled(blockstack_opts):\n                subdomain_index = None\n                instantiated = False\n\n                if hasattr(db_state, 'subdomain_index') and db_state.subdomain_index is not None:\n                    # normal course of action\n                    subdomain_index = db_state.subdomain_index\n                else:\n                    # verifying a database\n                    from ..subdomains import SubdomainIndex\n                    log.warning(\"Instantiating subdomain index\")\n                    subdomain_index = SubdomainIndex(blockstack_opts['subdomaindb_path'], blockstack_opts=blockstack_opts)\n                    instantiated = True\n               \n                log.debug(\"Synchronize subdomain index for {}\".format(block_height))\n\n                gc.collect()\n                subdomain_index.index(block_height, block_height+1)\n                gc.collect()\n\n                if instantiated:\n                    # invalidate \n                    subdomain_index.close()\n                    subdomain_index = None\n\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: failed to update subdomains db at {}\".format(block_height))\n            os.abort()\n\n        return True\n\n   else:\n       log.error(\"FATAL: no state engine given\")\n       os.abort()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef db_continue( block_id, consensus_hash ):\n\n    # every so often, clean up\n    if (block_id % 20) == 0:\n        log.debug(\"Pre-emptive garbage collection at %s\" % block_id)\n        gc.collect(2)\n\n    return is_running() or os.environ.get(\"BLOCKSTACK_TEST\") == \"1\"", "response": "This function is called when the blockstack is ready to continue processing the block."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsynchronizes the blockchain with the given last_block.", "response": "def sync_blockchain( working_dir, bt_opts, last_block, server_state, expected_snapshots={}, **virtualchain_args ):\n    \"\"\"\n    synchronize state with the blockchain.\n    Return True on success\n    Return False if we're supposed to stop indexing\n    Abort on error\n    \"\"\"\n    \n    subdomain_index = server_state['subdomains']\n    atlas_state = server_state['atlas']\n    \n    # make this usable even if we haven't explicitly configured virtualchain \n    impl = sys.modules[__name__]\n    log.info(\"Synchronizing database {} up to block {}\".format(working_dir, last_block))\n\n    # NOTE: this is the only place where a read-write handle should be created,\n    # since this is the only place where the db should be modified.\n    new_db = BlockstackDB.borrow_readwrite_instance(working_dir, last_block, expected_snapshots=expected_snapshots)\n\n    # propagate runtime state to virtualchain callbacks\n    new_db.subdomain_index = subdomain_index\n    new_db.atlas_state = atlas_state\n    \n    rc = virtualchain.sync_virtualchain(bt_opts, last_block, new_db, expected_snapshots=expected_snapshots, **virtualchain_args)\n    \n    BlockstackDB.release_readwrite_instance(new_db, last_block)\n\n    return rc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_to_host_port(url, port=None):\n    if not url.startswith('http://') and not url.startswith('https://'):\n        url = 'http://' + url\n\n    if not port:\n        port = RPC_SERVER_PORT\n\n    urlinfo = urllib2.urlparse.urlparse(url)\n    hostport = urlinfo.netloc\n\n    parts = hostport.split('@')\n    if len(parts) > 2:\n        return None, None\n\n    if len(parts) == 2:\n        hostport = parts[1]\n\n    parts = hostport.split(':')\n    if len(parts) > 2:\n        return None, None\n\n    if len(parts) == 2:\n        try:\n            port = int(parts[1])\n            assert 0 < port and port < 65535, 'Invalid port'\n        except TypeError:\n            return None, None\n\n    return parts[0], port", "response": "Given a URL turn it into a host and port."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the protocol to use for a URL.", "response": "def url_protocol(url, port=None):\n    \"\"\"\n    Get the protocol to use for a URL.\n    return 'http' or 'https' or None\n    \"\"\"\n    if not url.startswith('http://') and not url.startswith('https://'):\n        return None\n\n    urlinfo = urllib2.urlparse.urlparse(url)\n    assert urlinfo.scheme in ['http', 'https'], 'Invalid URL scheme in {}'.format(url)\n    return urlinfo.scheme"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atlas_inventory_to_string( inv ):\n    ret = \"\"\n    for i in range(0, len(inv)):\n        for j in range(0, 8):\n            bit_index = 1 << (7 - j)\n            val = (ord(inv[i]) & bit_index)\n            if val != 0:\n                ret += \"1\"\n            else:\n                ret += \"0\"\n\n    return ret", "response": "Convert an atlas inventory to a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_DID(name_type, address, index):\n    if name_type not in ['name', 'subdomain']:\n        raise ValueError(\"Require 'name' or 'subdomain' for name_type\")\n\n    if name_type == 'name':\n        address = virtualchain.address_reencode(address)\n    else:\n        # what's the current version byte?\n        vb = keylib.b58check.b58check_version_byte(address)\n        if vb == bitcoin_blockchain.version_byte:\n            # singlesig\n            vb = SUBDOMAIN_ADDRESS_VERSION_BYTE\n        else:\n            vb = SUBDOMAIN_ADDRESS_MULTISIG_VERSION_BYTE\n\n        address = virtualchain.address_reencode(address, version_byte=vb)\n\n    return 'did:stack:v0:{}-{}'.format(address, index)", "response": "Make a DID from a name type and address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_DID(did, name_type=None):\n    did_pattern = '^did:stack:v0:({}{{25,35}})-([0-9]+)$'.format(OP_BASE58CHECK_CLASS)\n\n    m = re.match(did_pattern, did)\n    assert m, 'Invalid DID: {}'.format(did)\n\n    original_address = str(m.groups()[0])\n    name_index = int(m.groups()[1])\n    vb = keylib.b58check.b58check_version_byte(original_address)\n    name_type = None\n\n    if vb in [SUBDOMAIN_ADDRESS_VERSION_BYTE, SUBDOMAIN_ADDRESS_MULTISIG_VERSION_BYTE]:\n        name_type = 'subdomain'\n\n        # decode version \n        if vb == SUBDOMAIN_ADDRESS_VERSION_BYTE:\n            vb = bitcoin_blockchain.version_byte\n        else:\n            vb = bitcoin_blockchain.multisig_version_byte\n\n        original_address = virtualchain.address_reencode(original_address, version_byte=vb)\n\n    else:\n        name_type = 'name'\n        original_address = virtualchain.address_reencode(original_address)\n\n    return {'address': original_address, 'index': name_index, 'name_type': name_type}", "response": "Given a DID string parse it into a dictionary of address index and name type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoubles - fork and make a daemon.", "response": "def daemonize(logfile):\n    \"\"\"\n    Double-fork and make a daemon.\n    Have the intermediate child call child_wait()\n    to block its exit until the child is \"ready\"\n    (i.e. child_wait() returns)\n\n    Return 0 if we're the daemon child\n    Return >0 if we're the parent\n    \"\"\"\n    \n    # turn off GC across the fork\n    gc.collect(2)\n    gc.collect(1)\n    gc.collect(0)\n    gc.disable()\n    \n    child_pid = os.fork()\n\n    if child_pid == 0:\n        # child!\n        sys.stdin.close()\n        os.dup2(logfile.fileno(), sys.stdout.fileno())\n        os.dup2(logfile.fileno(), sys.stderr.fileno())\n\n        soft_num_open_files, hard_num_open_files = resource.getrlimit(resource.RLIMIT_NOFILE)\n        if hard_num_open_files == resource.RLIM_INFINITY:\n            # guess\n            hard_num_open_files = 1024\n\n        # we don't have many other fds open yet\n        for i in range(3, hard_num_open_files):\n            if i == logfile.fileno():\n                continue\n\n            try:\n                os.close(i)\n            except:\n                pass\n\n        os.setsid()\n\n        daemon_pid = os.fork()\n        if daemon_pid == 0:\n            # daemon! chdir and return\n            os.chdir('/')\n            gc.enable()\n            gc.collect(2)\n            gc.collect(1)\n            gc.collect(0)\n            return 0\n\n        elif daemon_pid > 0:\n            # parent (intermediate child)\n            sys.exit(0)\n\n        else:\n            # error\n            sys.exit(1)\n\n    elif child_pid > 0:\n        # grand-parent (caller)\n        # re-activate gc\n        gc.enable()\n        gc.collect(2)\n        gc.collect(1)\n        gc.collect(0)\n\n        # wait for intermediate child.\n        # panic if we don't hear back after 5 minutes\n        timeout = 600\n        if BLOCKSTACK_TEST:\n            # wait around so we can attach gdb or whatever\n            timeout = 60000\n\n        for i in range(0, timeout):\n            pid, status = os.waitpid(child_pid, os.WNOHANG)\n            if pid == 0:\n                # still waiting\n                time.sleep(1)\n                log.debug(\"Still waiting on {}\".format(child_pid))\n                continue\n\n            # child has exited!\n            if os.WEXITSTATUS(status) == 0:\n                return child_pid\n            else:\n                log.error(\"Child exit status {}\".format(status))\n                return -1\n\n        # child has not exited yet.  This is not okay.\n        log.error(\"Child PID={} did not exit.  Killing it instead and failing...\".format(child_pid))\n        os.kill(child_pid, signal.SIGKILL)\n        return -1\n    \n    else:\n        # failed to fork \n        log.error(\"Failed to fork\")\n        return -1\n\n    # parent! success\n    return child_pid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_request_thread(self, request, client_address):\n        from ..blockstackd import get_gc_thread\n\n        try:\n            self.finish_request(request, client_address)\n        except Exception:\n            self.handle_error(request, client_address)\n        finally:\n            self.shutdown_request(request)\n\n        shutdown_thread = False\n        with self._thread_guard:\n            if threading.current_thread().ident in self._threads:\n                del self._threads[threading.current_thread().ident]\n                shutdown_thread = True\n\n                if BLOCKSTACK_TEST:\n                    log.debug('{} active threads (removed {})'.format(len(self._threads), threading.current_thread().ident))\n\n        if shutdown_thread:\n            gc_thread = get_gc_thread()\n            if gc_thread:\n                # count this towards our preemptive garbage collection\n                gc_thread.gc_event()", "response": "Process the request thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naccepting a request up to the given number of allowed threads.", "response": "def get_request(self):\n        \"\"\"\n        Accept a request, up to the given number of allowed threads.\n        Defer to self.overloaded if there are already too many pending requests.\n        \"\"\"\n        # Note that this class must be mixed with another class that implements get_request()\n        request, client_addr = super(BoundedThreadingMixIn, self).get_request()\n        overload = False\n        with self._thread_guard:\n            if self._threads is not None and len(self._threads) + 1 > MAX_RPC_THREADS:\n                overload = True\n\n        if overload:\n            res = self.overloaded(client_addr)\n            request.sendall(res)\n\n            sys.stderr.write('{} - - [{}] \"Overloaded\"\\n'.format(client_addr[0], time_str(time.time())))\n            self.shutdown_request(request)\n            return None, None\n\n        return request, client_addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a new thread to process the request.", "response": "def process_request(self, request, client_address):\n        \"\"\"\n        Start a new thread to process the request.\n        \"\"\"\n        if request is None or client_address is None:\n            # request was never initialized, i.e. due to overload\n            return \n\n        t = threading.Thread(target = self.process_request_thread,\n                             args = (request, client_address))\n\n        t.daemon = False\n\n        with self._thread_guard:\n            if self._close:\n                # server is done. do not make more threads\n                self.shutdown_request(request)\n                return \n\n            if self._threads is None:\n                self._threads = {}\n\n            if len(self._threads) + 1 > MAX_RPC_THREADS:\n                # overloaded\n                log.warning(\"Too many outstanding requests ({})\".format(len(self._threads)))\n                self.shutdown_request(request)\n                return\n\n            t.start()\n\n            self._threads[t.ident] = t\n\n            if BLOCKSTACK_TEST:\n                log.debug('{} active threads (added {})'.format(len(self._threads), t.ident))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the epoch number for a given block height", "response": "def get_epoch_number( block_height ):\n    \"\"\"\n    Which epoch are we in?\n    Return integer (>=0) on success\n    \"\"\"\n    global EPOCHS\n\n    if block_height <= EPOCHS[0]['end_block']:\n        return 0\n\n    for i in xrange(1, len(EPOCHS)):\n        if EPOCHS[i-1]['end_block'] < block_height and (block_height <= EPOCHS[i]['end_block'] or EPOCHS[i]['end_block'] == EPOCH_NOW):\n            return i\n\n    # should never happen \n    log.error(\"FATAL: No epoch for %s\" % block_height)\n    os.abort()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_epoch_config( block_height ):\n    global EPOCHS\n    epoch_number = get_epoch_number( block_height )\n\n    if epoch_number < 0 or epoch_number >= len(EPOCHS):\n        log.error(\"FATAL: invalid epoch %s\" % epoch_number)\n        os.abort()\n\n    return EPOCHS[epoch_number]", "response": "Get the epoch config for the given block height"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_epoch_namespace_lifetime_multiplier( block_height, namespace_id ):\n    epoch_config = get_epoch_config( block_height )\n    if epoch_config['namespaces'].has_key(namespace_id):\n        return epoch_config['namespaces'][namespace_id]['NAMESPACE_LIFETIME_MULTIPLIER']\n    else:\n        return epoch_config['namespaces']['*']['NAMESPACE_LIFETIME_MULTIPLIER']", "response": "get the namespace lifetime multipler for this epoch"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_epoch_namespace_lifetime_grace_period( block_height, namespace_id ):\n    epoch_config = get_epoch_config( block_height )\n    if epoch_config['namespaces'].has_key(namespace_id):\n        return epoch_config['namespaces'][namespace_id]['NAMESPACE_LIFETIME_GRACE_PERIOD']\n    else:\n        return epoch_config['namespaces']['*']['NAMESPACE_LIFETIME_GRACE_PERIOD']", "response": "get the namespace lifetime grace period for this epoch"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the name price multiplier for this epoch.", "response": "def get_epoch_price_multiplier( block_height, namespace_id, units ):\n    \"\"\"\n    what's the name price multiplier for this epoch?\n    Not all epochs have one---if this epoch has BLOCKSTACK_INT_DIVISION set, use\n    get_epoch_price_divisor() instead.\n    \"\"\"\n    try:\n        assert units in [TOKEN_TYPE_STACKS, 'BTC'], 'Unknown units {}'.format(units)\n    except AssertionError as ae:\n        log.exception(ae)\n        log.error(\"FATAL: No such units {}\".format(units))\n        os.abort()\n\n    multiplier = 'PRICE_MULTIPLIER' if units == 'BTC' else 'PRICE_MULTIPLIER_STACKS'\n\n    epoch_config = get_epoch_config( block_height )\n    m = None\n\n    if epoch_config['namespaces'].has_key(namespace_id):\n        m = epoch_config['namespaces'][namespace_id][multiplier]\n    else:\n        m = epoch_config['namespaces']['*'][multiplier]\n\n    try:\n        assert m is not None\n    except AssertionError as ae:\n        log.exception(ae)\n        log.error(\"FATAL: Tried to get a price multiplier in an epoch without price multipliers!\")\n        os.abort()\n\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_epoch_price_divisor( block_height, namespace_id, units ):\n    try:\n        assert units in [TOKEN_TYPE_STACKS, 'BTC'], 'Unknown units {}'.format(units)\n    except AssertionError as ae:\n        log.exception(ae)\n        log.error(\"FATAL: No such units {}\".format(units))\n        os.abort()\n\n    divisor = 'PRICE_DIVISOR' if units == 'BTC' else 'PRICE_DIVISOR_STACKS'\n\n    epoch_config = get_epoch_config( block_height )\n    d = None\n\n    if epoch_config['namespaces'].has_key(namespace_id):\n        d = epoch_config['namespaces'][namespace_id][divisor]\n    else:\n        d = epoch_config['namespaces']['*'][divisor]\n\n    try:\n        assert d is not None\n    except AssertionError as ae:\n        log.exception(ae)\n        log.error(\"FATAL: Tried to get a price divisor in an epoch without price divisors!\")\n        os.abort()\n\n    return d", "response": "Get the name price divisor for this epoch."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_epoch_namespace_receive_fees_period( block_height, namespace_id ):\n    epoch_config = get_epoch_config( block_height )\n    if epoch_config['namespaces'].has_key(namespace_id):\n        return epoch_config['namespaces'][namespace_id]['NAMESPACE_RECEIVE_FEES_PERIOD']\n    else:\n        return epoch_config['namespaces']['*']['NAMESPACE_RECEIVE_FEES_PERIOD']", "response": "Get the number of fees that can be received for a namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the list of namespace prices by block height", "response": "def get_epoch_namespace_prices( block_height, units ):\n    \"\"\"\n    get the list of namespace prices by block height\n    \"\"\"\n    assert units in ['BTC', TOKEN_TYPE_STACKS], 'Invalid unit {}'.format(units)\n\n    epoch_config = get_epoch_config( block_height )\n\n    if units == 'BTC':\n        return epoch_config['namespace_prices']\n    else:\n        return epoch_config['namespace_prices_stacks']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef op_get_opcode_name(op_string):\n    global OPCODE_NAMES\n\n    # special case...\n    if op_string == '{}:'.format(NAME_REGISTRATION):\n        return 'NAME_RENEWAL'\n\n    op = op_string[0]\n    if op not in OPCODE_NAMES:\n        raise Exception('No such operation \"{}\"'.format(op))\n\n    return OPCODE_NAMES[op]", "response": "Get the name of an opcode given the opcode byte sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_announce_filename( working_dir ):\n   announce_filepath = os.path.join( working_dir, get_default_virtualchain_impl().get_virtual_chain_name() ) + '.announce'\n   return announce_filepath", "response": "Get the path to the file that stores all of the announcements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_indexing(working_dir):\n    indexing_path = get_indexing_lockfile(working_dir)\n    if os.path.exists( indexing_path ):\n        return True\n    else:\n        return False", "response": "Is the blockstack daemon synchronizing with the blockchain?"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_indexing(working_dir, flag):\n    indexing_path = get_indexing_lockfile(working_dir)\n    if flag:\n        try:\n            fd = open( indexing_path, \"w+\" )\n            fd.close()\n            return True\n        except:\n            return False\n\n    else:\n        try:\n            os.unlink( indexing_path )\n            return True\n        except:\n            return False", "response": "Set a flag in the filesystem as to whether or not we re indexing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the range of blocks for which we are reprocessing transactions on recovery.", "response": "def get_recovery_range(working_dir):\n    \"\"\"\n    Get the range of blocks for which we are reprocessing\n    transactions on recovery.\n    Returns (start_block, end_block) tu\u21b5ple, which will be\n    (None, None) if we're not recovering\n    \"\"\"\n    recovery_range_path = os.path.join(working_dir, '.recovery')\n    if not os.path.exists(recovery_range_path):\n        return (None, None)\n\n    with open(recovery_range_path) as f:\n        data = f.read()\n\n    lines = filter(lambda l: len(l) > 0, map(lambda l2: l2.strip(), data.split()))\n    assert len(lines) == 2, 'Invalid .recovery file'\n    try:\n        start_block = int(lines[0])\n        end_block = int(lines[1])\n    except:\n        raise ValueError('Failed to parse {}'.format(recovery_range_path))\n\n    return (start_block, end_block)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the recovery block range for the current node.", "response": "def set_recovery_range(working_dir, start_block, end_block):\n    \"\"\"\n    Set the recovery block range if we're restoring and reporcessing\n    transactions from a backup.\n\n    Writes the recovery range to the working directory if the working directory is given and persist is True\n    \"\"\"\n    recovery_range_path = os.path.join(working_dir, '.recovery')\n    with open(recovery_range_path, 'w') as f:\n        f.write('{}\\n{}\\n'.format(start_block, end_block))\n        f.flush()\n        os.fsync(f.fileno())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing out our recovery hint", "response": "def clear_recovery_range(working_dir):\n    \"\"\"\n    Clear out our recovery hint\n    \"\"\"\n    recovery_range_path = os.path.join(working_dir, '.recovery')\n    if os.path.exists(recovery_range_path):\n        os.unlink(recovery_range_path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_atlas_enabled(blockstack_opts):\n    if not blockstack_opts['atlas']:\n        log.debug(\"Atlas is disabled\")\n        return False\n\n    if 'zonefiles' not in blockstack_opts:\n        log.debug(\"Atlas is disabled: no 'zonefiles' path set\")\n        return False\n\n    if 'atlasdb_path' not in blockstack_opts:\n        log.debug(\"Atlas is disabled: no 'atlasdb_path' path set\")\n        return False\n\n    return True", "response": "Check if atlas operations are enabled"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_subdomains_enabled(blockstack_opts):\n    if not is_atlas_enabled(blockstack_opts):\n        log.debug(\"Subdomains are disabled\")\n        return False\n\n    if 'subdomaindb_path' not in blockstack_opts:\n        log.debug(\"Subdomains are disabled: no 'subdomaindb_path' path set\")\n        return False\n\n    return True", "response": "Is the current environment supports subdomain operations?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store_announcement( working_dir, announcement_hash, announcement_text, force=False ):\n\n   if not force:\n       # don't store unless we haven't seen it before\n       if announcement_hash in ANNOUNCEMENTS:\n           return\n\n   announce_filename = get_announce_filename( working_dir )\n   announce_filename_tmp = announce_filename + \".tmp\"\n   announce_text = \"\"\n   announce_cleanup_list = []\n\n   # did we try (and fail) to store a previous announcement?  If so, merge them all\n   if os.path.exists( announce_filename_tmp ):\n\n       log.debug(\"Merge announcement list %s\" % announce_filename_tmp )\n\n       with open(announce_filename, \"r\") as f:\n           announce_text += f.read()\n\n       i = 1\n       failed_path = announce_filename_tmp + (\".%s\" % i)\n       while os.path.exists( failed_path ):\n\n           log.debug(\"Merge announcement list %s\" % failed_path )\n           with open(failed_path, \"r\") as f:\n               announce_text += f.read()\n\n           announce_cleanup_list.append( failed_path )\n\n           i += 1\n           failed_path = announce_filename_tmp + (\".%s\" % i)\n\n       announce_filename_tmp = failed_path\n\n   if os.path.exists( announce_filename ):\n       with open(announce_filename, \"r\" ) as f:\n           announce_text += f.read()\n\n   announce_text += (\"\\n%s\\n\" % announcement_hash)\n\n   # filter\n   if not force:\n       announcement_list = announce_text.split(\"\\n\")\n       unseen_announcements = filter( lambda a: a not in ANNOUNCEMENTS, announcement_list )\n       announce_text = \"\\n\".join( unseen_announcements ).strip() + \"\\n\"\n\n   log.debug(\"Store announcement hash to %s\" % announce_filename )\n\n   with open(announce_filename_tmp, \"w\" ) as f:\n       f.write( announce_text )\n       f.flush()\n\n   # NOTE: rename doesn't remove the old file on Windows\n   if sys.platform == 'win32' and os.path.exists( announce_filename_tmp ):\n       try:\n           os.unlink( announce_filename_tmp )\n       except:\n           pass\n\n   try:\n       os.rename( announce_filename_tmp, announce_filename )\n   except:\n       log.error(\"Failed to save announcement %s to %s\" % (announcement_hash, announce_filename ))\n       raise\n\n   # clean up\n   for tmp_path in announce_cleanup_list:\n       try:\n           os.unlink( tmp_path )\n       except:\n           pass\n\n   # put the announcement text\n   announcement_text_dir = os.path.join( working_dir, \"announcements\" )\n   if not os.path.exists( announcement_text_dir ):\n       try:\n           os.makedirs( announcement_text_dir )\n       except:\n           log.error(\"Failed to make directory %s\" % announcement_text_dir )\n           raise\n\n   announcement_text_path = os.path.join( announcement_text_dir, \"%s.txt\" % announcement_hash )\n\n   try:\n       with open( announcement_text_path, \"w\" ) as f:\n           f.write( announcement_text )\n\n   except:\n       log.error(\"Failed to save announcement text to %s\" % announcement_text_path )\n       raise\n\n   log.debug(\"Stored announcement to %s\" % (announcement_text_path))", "response": "Store an announcement locally atomically."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget our default blockstack options from a config file or from sane defaults.", "response": "def default_blockstack_opts( working_dir, config_file=None ):\n   \"\"\"\n   Get our default blockstack opts from a config file\n   or from sane defaults.\n   \"\"\"\n\n   global RPC_SERVER_IP, RPC_SERVER_PORT\n\n   from .util import url_to_host_port\n   from .scripts import is_name_valid\n\n   if config_file is None:\n      config_file = virtualchain.get_config_filename(get_default_virtualchain_impl(), working_dir)\n\n   announce_path = get_announce_filename(working_dir)\n\n   parser = SafeConfigParser()\n   parser.read( config_file )\n\n   blockstack_opts = {}\n   announcers = \"judecn.id,muneeb.id,shea256.id\"\n   announcements = None\n   backup_frequency = 144   # once a day; 10 minute block time\n   backup_max_age = 1008    # one week\n   rpc_port = RPC_SERVER_PORT \n   zonefile_dir = os.path.join( os.path.dirname(config_file), \"zonefiles\")\n   server_version = VERSION\n   atlas_enabled = True\n   atlas_seed_peers = \"node.blockstack.org:%s\" % RPC_SERVER_PORT if not BLOCKSTACK_TESTNET_ACTIVE else \"\"\n   atlasdb_path = os.path.join( os.path.dirname(config_file), \"atlas.db\" )\n   atlas_blacklist = \"\"\n   atlas_hostname = RPC_SERVER_IP\n   real_atlas_hostname = None       # if we need to look it up on-the-fly\n   atlas_port = RPC_SERVER_PORT\n   subdomaindb_path = os.path.join( os.path.dirname(config_file), \"subdomains.db\" )\n   run_indexer = True\n\n   if parser.has_section('blockstack'):\n      if parser.has_option('blockstack', 'enabled'):\n         run_indexer = parser.get('blockstack', 'enabled').lower() in ['1', 'true', 'on']\n\n      if parser.has_option('blockstack', 'backup_frequency'):\n         backup_frequency = int( parser.get('blockstack', 'backup_frequency'))\n\n      if parser.has_option('blockstack', 'backup_max_age'):\n         backup_max_age = int( parser.get('blockstack', 'backup_max_age') )\n\n      if parser.has_option('blockstack', 'rpc_port'):\n         rpc_port = int(parser.get('blockstack', 'rpc_port'))\n\n      if parser.has_option(\"blockstack\", \"zonefiles\"):\n          zonefile_dir = parser.get(\"blockstack\", \"zonefiles\")\n    \n      if parser.has_option('blockstack', 'announcers'):\n         # must be a CSV of blockchain IDs\n         announcer_list_str = parser.get('blockstack', 'announcers')\n         announcer_list = filter( lambda x: len(x) > 0, announcer_list_str.split(\",\") )\n\n         # validate each one\n         valid = True\n         for bid in announcer_list:\n             if not is_name_valid( bid ):\n                 log.error(\"Invalid blockchain ID '%s'\" % bid)\n                 valid = False\n\n         if valid:\n             announcers = \",\".join(announcer_list)\n\n      if parser.has_option('blockstack', 'server_version'):\n         server_version = parser.get('blockstack', 'server_version')\n\n      if parser.has_option('blockstack', 'atlas'):\n         atlas_enabled = parser.get('blockstack', 'atlas')\n         if atlas_enabled.lower() in ['true', '1', 'enabled', 'enabled', 'on']:\n            atlas_enabled = True\n         else:\n            atlas_enabled = False\n\n      if parser.has_option('blockstack', 'atlas_seeds'):\n         atlas_seed_peers = parser.get('blockstack', 'atlas_seeds')\n\n         # must be a CSV of host:port\n         check_hostport_list(atlas_seed_peers)\n\n      if parser.has_option('blockstack', 'atlasdb_path'):\n         atlasdb_path = parser.get('blockstack', 'atlasdb_path')\n\n      if parser.has_option('blockstack', 'atlas_blacklist'):\n         atlas_blacklist = parser.get('blockstack', 'atlas_blacklist')\n\n         # must be a CSV of host:port\n         hostports = filter( lambda x: len(x) > 0, atlas_blacklist.split(\",\") )\n         for hp in hostports:\n             host, port = url_to_host_port( hp )\n             assert host is not None and port is not None\n\n      if parser.has_option('blockstack', 'atlas_hostname'):\n         atlas_hostname = parser.get('blockstack', 'atlas_hostname')\n    \n      if parser.has_option('blockstack', 'atlas_port'):\n         atlas_port = int(parser.get('blockstack', 'atlas_port'))\n\n      if parser.has_option('blockstack', 'subdomaindb_path'):\n         subdomaindb_path = parser.get('blockstack', 'subdomaindb_path')\n\n   if os.environ.get(ATLAS_SEEDS_ENV_VAR, False):\n       atlas_seed_peers = os.environ[ATLAS_SEEDS_ENV_VAR]\n       check_hostport_list(atlas_seed_peers)\n\n   if os.environ.get(ATLAS_HOSTNAME_ENV_VAR, False):\n       atlas_hostname = os.environ[ATLAS_HOSTNAME_ENV_VAR]\n\n   if os.path.exists( announce_path ):\n       # load announcement list\n       with open( announce_path, \"r\" ) as f:\n           announce_text = f.readlines()\n\n       all_announcements = [ a.strip() for a in announce_text ]\n       unseen_announcements = []\n\n       # find announcements we haven't seen yet\n       for a in all_announcements:\n           if a not in ANNOUNCEMENTS:\n               unseen_announcements.append( a )\n\n       announcements = \",\".join( unseen_announcements )\n\n   if zonefile_dir is not None and not os.path.exists( zonefile_dir ):\n       try:\n           os.makedirs( zonefile_dir, 0700 )\n       except:\n           pass\n\n   if RPC_SERVER_IP is None:\n       if atlas_hostname is None or atlas_hostname.lower() == '<stun>':\n           real_atlas_hostname = get_atlas_hostname_stun()\n           RPC_SERVER_IP = real_atlas_hostname\n\n       elif atlas_hostname.lower() == '<host>':\n           real_atlas_hostname = get_atlas_hostname_addrinfo(rpc_port)\n           RPC_SERVER_IP = real_atlas_hostname\n       \n       else:\n           log.debug('Using configuration-given Atlas hostname')\n           real_atlas_hostname = atlas_hostname\n           RPC_SERVER_IP = atlas_hostname\n\n       if atlas_hostname is None and real_atlas_hostname is None:\n           log.warning('No Atlas hostname could be determined, assuming 127.0.0.1')\n           real_atlas_hostname = '127.0.0.1'\n           RPC_SERVER_IP = real_atlas_hostname\n   \n       log.info('Atlas IP address is ({}, {})'.format(RPC_SERVER_IP, rpc_port))\n\n   else:\n       # already set\n       real_atlas_hostname = RPC_SERVER_IP\n\n   atlas_hostname = real_atlas_hostname\n   RPC_SERVER_PORT = rpc_port\n\n   blockstack_opts = {\n       'rpc_port': rpc_port,\n       'announcers': announcers,\n       'announcements': announcements,\n       'backup_frequency': backup_frequency,\n       'backup_max_age': backup_max_age,\n       'server_version': server_version,\n       'atlas': atlas_enabled,\n       'atlas_seeds': atlas_seed_peers,\n       'atlasdb_path': atlasdb_path,\n       'atlas_blacklist': atlas_blacklist,\n       'atlas_hostname': atlas_hostname,\n       'atlas_port': atlas_port,\n       'zonefiles': zonefile_dir,\n       'subdomaindb_path': subdomaindb_path,\n       'enabled': run_indexer\n   }\n\n   # strip Nones\n   for (k, v) in blockstack_opts.items():\n      if v is None:\n         del blockstack_opts[k]\n\n   return blockstack_opts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_blockstack_api_opts(working_dir, config_file=None):\n\n   from .util import url_to_host_port, url_protocol\n\n   if config_file is None:\n      config_file = virtualchain.get_config_filename(get_default_virtualchain_impl(), working_dir)\n\n   parser = SafeConfigParser()\n   parser.read(config_file)\n\n   blockstack_api_opts = {}\n   indexer_url = None\n   api_port = DEFAULT_API_PORT\n   api_host = DEFAULT_API_HOST\n   run_api = True\n\n   if parser.has_section('blockstack-api'):\n      if parser.has_option('blockstack-api', 'enabled'):\n          run_api = parser.get('blockstack-api', 'enabled').lower() in ['true', '1', 'on']\n\n      if parser.has_option('blockstack-api', 'api_port'):\n          api_port = int(parser.get('blockstack-api', 'api_port'))\n\n      if parser.has_option('blockstack-api', 'api_host'):\n          api_host = parser.get('blockstack-api', 'api_host')\n\n      if parser.has_option('blockstack-api', 'indexer_url'):\n          indexer_host, indexer_port = url_to_host_port(parser.get('blockstack-api', 'indexer_url'))\n          indexer_protocol = url_protocol(parser.get('blockstack-api', 'indexer_url'))\n          if indexer_protocol is None:\n              indexer_protocol = 'http'\n\n          indexer_url = parser.get('blockstack-api', 'indexer_url')\n\n   if indexer_url is None:\n       # try defaults\n       indexer_url = 'http://localhost:{}'.format(RPC_SERVER_PORT)\n\n   blockstack_api_opts = {\n        'indexer_url': indexer_url,\n        'api_host': api_host,\n        'api_port': api_port,\n        'enabled': run_api\n   }\n\n   # strip Nones\n   for (k, v) in blockstack_api_opts.items():\n      if v is None:\n         del blockstack_api_opts[k]\n\n   return blockstack_api_opts", "response": "Get our default blockstack RESTful API opts from a config file or from sane defaults."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef interactive_prompt(message, parameters, default_opts):\n\n    # pretty-print the message\n    lines = message.split('\\n')\n    max_line_len = max([len(l) for l in lines])\n\n    print('-' * max_line_len)\n    print(message)\n    print('-' * max_line_len)\n\n    ret = {}\n    for param in parameters:\n        formatted_param = param\n        prompt_str = '{}: '.format(formatted_param)\n        if param in default_opts:\n            prompt_str = '{} (default: \"{}\"): '.format(formatted_param, default_opts[param])\n\n        try:\n            value = raw_input(prompt_str)\n        except KeyboardInterrupt:\n            log.debug('Exiting on keyboard interrupt')\n            sys.exit(0)\n\n        if len(value) > 0:\n            ret[param] = value\n        elif param in default_opts:\n            ret[param] = default_opts[param]\n        else:\n            ret[param] = None\n\n    return ret", "response": "Prompt the user for a series of parameters Return a dict mapping the parameter name to the user - given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds and interactively prompt the user for missing parameters.", "response": "def find_missing(message, all_params, given_opts, default_opts, header=None, prompt_missing=True):\n    \"\"\"\n    Find and interactively prompt the user for missing parameters,\n    given the list of all valid parameters and a dict of known options.\n\n    Return the (updated dict of known options, missing, num_prompted), with the user's input.\n    \"\"\"\n\n    # are we missing anything?\n    missing_params = list(set(all_params) - set(given_opts))\n\n    num_prompted = 0\n\n    if not missing_params:\n        return given_opts, missing_params, num_prompted\n\n    if not prompt_missing:\n        # count the number missing, and go with defaults\n        missing_values = set(default_opts) - set(given_opts)\n        num_prompted = len(missing_values)\n        given_opts.update(default_opts)\n\n    else:\n        if header is not None:\n            print('-' * len(header))\n            print(header)\n\n        missing_values = interactive_prompt(message, missing_params, default_opts)\n        num_prompted = len(missing_values)\n        given_opts.update(missing_values)\n\n    return given_opts, missing_params, num_prompted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef opt_strip(prefix, opts):\n\n    ret = {}\n    for opt_name, opt_value in opts.items():\n        # remove prefix\n        if opt_name.startswith(prefix):\n            opt_name = opt_name[len(prefix):]\n\n        ret[opt_name] = opt_value\n\n    return ret", "response": "Given a dict of options that start with prefix remove the prefix from each of them."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a dict of opts add the given prefix to each key", "response": "def opt_restore(prefix, opts):\n    \"\"\"\n    Given a dict of opts, add the given prefix to each key\n    \"\"\"\n\n    return {prefix + name: value for name, value in opts.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default_bitcoind_opts(config_file=None, prefix=False):\n\n    default_bitcoin_opts = virtualchain.get_bitcoind_config(config_file=config_file)\n\n    # drop dict values that are None\n    default_bitcoin_opts = {k: v for k, v in default_bitcoin_opts.items() if v is not None}\n\n    # strip 'bitcoind_'\n    if not prefix:\n        default_bitcoin_opts = opt_strip('bitcoind_', default_bitcoin_opts)\n\n    return default_bitcoin_opts", "response": "Get our default bitcoind options such as from a config file or from sane defaults."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_working_dir():\n    import nameset.virtualchain_hooks as virtualchain_hooks\n    return os.path.expanduser('~/.{}'.format(virtualchain_hooks.get_virtual_chain_name()))", "response": "Get the default working directory for blockstackd\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure(working_dir, config_file=None, force=False, interactive=False):\n\n   if config_file is None:\n      # get input for everything\n      config_file = virtualchain.get_config_filename(get_default_virtualchain_impl(), working_dir)\n\n   if not os.path.exists( config_file ):\n       # definitely ask for everything\n       force = True\n\n   log.debug(\"Load config from '%s'\" % config_file)\n\n   # get blockstack opts\n   blockstack_opts = {}\n   blockstack_opts_defaults = default_blockstack_opts(working_dir, config_file=config_file)\n   blockstack_params = blockstack_opts_defaults.keys()\n\n   if not force or not interactive:\n       # default blockstack options\n       blockstack_opts = default_blockstack_opts(working_dir, config_file=config_file )\n\n   blockstack_msg = \"Please enter blockstack configuration hints.\"\n\n   blockstack_opts, missing_blockstack_opts, num_blockstack_opts_prompted = find_missing( blockstack_msg, \\\n                                                                                          blockstack_params, \\\n                                                                                          blockstack_opts, \\\n                                                                                          blockstack_opts_defaults, \\\n                                                                                          prompt_missing=interactive )\n\n   blockstack_api_opts = {}\n   blockstack_api_defaults = default_blockstack_api_opts(working_dir, config_file=config_file)\n   blockstack_api_params = blockstack_api_defaults.keys()\n   \n   if not force or not interactive:\n       # default blockstack API options\n       blockstack_api_opts = default_blockstack_api_opts(working_dir, config_file=config_file)\n\n   blockstack_api_msg = \"Please enter blockstack RESTful API configuration hints.\"\n\n   blockstack_api_opts, missing_blockstack_api_opts, num_blockstack_api_opts_prompted = find_missing( blockstack_api_msg, \\\n                                                                                                      blockstack_api_params, \\\n                                                                                                      blockstack_api_opts, \\\n                                                                                                      blockstack_api_defaults, \\\n                                                                                                      prompt_missing=interactive )\n\n   bitcoind_message  = \"Blockstack does not have enough information to connect\\n\"\n   bitcoind_message += \"to bitcoind.  Please supply the following parameters, or\\n\"\n   bitcoind_message += \"press [ENTER] to select the default value.\"\n\n   bitcoind_opts = {}\n   bitcoind_opts_defaults = default_bitcoind_opts( config_file=config_file )\n   bitcoind_params = bitcoind_opts_defaults.keys()\n\n   if not force or not interactive:\n      # get default set of bitcoind opts\n      bitcoind_opts = default_bitcoind_opts( config_file=config_file )\n\n\n   # get any missing bitcoind fields\n   bitcoind_opts, missing_bitcoin_opts, num_bitcoind_prompted = find_missing( bitcoind_message, \\\n                                                                              bitcoind_params, \\\n                                                                              bitcoind_opts, \\\n                                                                              bitcoind_opts_defaults, \\\n                                                                              prompt_missing=interactive )\n\n   if not interactive and (len(missing_bitcoin_opts) > 0 or len(missing_blockstack_opts) > 0 or len(missing_blockstack_api_opts) > 0):\n       # cannot continue\n       raise Exception(\"Missing configuration fields: %s\" % (\",\".join( missing_blockstack_opts + missing_bitcoin_opts + missing_blockstack_api_opts )) )\n\n   ret = {\n      'blockstack': blockstack_opts,\n      'bitcoind': bitcoind_opts,\n      'blockstack-api': blockstack_api_opts\n   }\n\n   # if we prompted, then save\n   if num_bitcoind_prompted > 0 or num_blockstack_opts_prompted > 0 or num_blockstack_api_opts_prompted > 0 or \\\n      (not os.path.exists(config_file) and not interactive):\n       print >> sys.stderr, \"Saving configuration to %s\" % config_file\n   \n       # always set version when writing\n       config_opts = copy.deepcopy(ret)\n       if not config_opts['blockstack'].has_key('server_version'):\n           config_opts['blockstack']['server_version'] = VERSION\n\n       if not config_opts['blockstack-api'].has_key('server_version'):\n           config_opts['blockstack']['server_version'] = VERSION\n\n       # if the config file doesn't exist, then set the version \n       # in ret as well, since it's what's written\n       if not os.path.exists(config_file):\n           ret['blockstack']['server_version'] = VERSION\n           ret['blockstack-api']['server_version'] = VERSION\n\n       write_config_file( config_opts, config_file )\n\n   # prefix our bitcoind options, so they work with virtualchain\n   ret['bitcoind'] = opt_restore(\"bitcoind_\", ret['bitcoind'])\n   return ret", "response": "Configure blockstack with the given configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_config_file(opts, config_file):\n    parser = SafeConfigParser()\n\n    if os.path.exists(config_file):\n        parser.read(config_file)\n\n    for sec_name in opts:\n        sec_opts = opts[sec_name]\n\n        if parser.has_section(sec_name):\n            parser.remove_section(sec_name)\n\n        parser.add_section(sec_name)\n        for opt_name, opt_value in sec_opts.items():\n            if opt_value is None:\n                opt_value = ''\n\n            parser.set(sec_name, opt_name, '{}'.format(opt_value))\n\n    with open(config_file, 'w') as fout:\n        os.fchmod(fout.fileno(), 0600)\n        parser.write(fout)\n\n    return True", "response": "Write our config file with the given options dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify that v1 is newer than v2", "response": "def semver_newer(v1, v2):\n    \"\"\"\n    Verify (as semantic versions) if v1 < v2\n    Patch versions can be different\n    \"\"\"\n    v1_parts = v1.split('.')\n    v2_parts = v2.split('.')\n    if len(v1_parts) < 3 or len(v2_parts) < 3:\n        # one isn't a semantic version\n        return False\n\n    v1_major, v1_minor, v1_patch = get_version_parts(v1_parts, int)\n    v2_major, v2_minor, v2_patch = get_version_parts(v2_parts, int)\n\n    if v1_major > v2_major:\n        return False\n\n    if v1_major == v2_major and v1_minor >= v2_minor:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the system configuration and set global variables returning the configuration of the node on success Return None on failure", "response": "def load_configuration(working_dir):\n    \"\"\"\n    Load the system configuration and set global variables\n    Return the configuration of the node on success.\n    Return None on failure\n    \"\"\"\n\n    import nameset.virtualchain_hooks as virtualchain_hooks\n\n    # acquire configuration, and store it globally\n    opts = configure(working_dir)\n    blockstack_opts = opts.get('blockstack', None)\n    blockstack_api_opts = opts.get('blockstack-api', None)\n    bitcoin_opts = opts['bitcoind']\n\n    # config file version check\n    config_server_version = blockstack_opts.get('server_version', None)\n    if (config_server_version is None or versions_need_upgrade(config_server_version, VERSION)):\n       print >> sys.stderr, \"Obsolete or unrecognizable config file ({}): '{}' != '{}'\".format(virtualchain.get_config_filename(virtualchain_hooks, working_dir), config_server_version, VERSION)\n       print >> sys.stderr, 'Please see the release notes for version {} for instructions to upgrade (in the release-notes/ folder).'.format(VERSION)\n       return None\n\n    # store options\n    set_bitcoin_opts( bitcoin_opts )\n    set_blockstack_opts( blockstack_opts )\n    set_blockstack_api_opts( blockstack_api_opts )\n\n    return {\n        'bitcoind': bitcoin_opts,\n        'blockstack': blockstack_opts,\n        'blockstack-api': blockstack_api_opts\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify validity of a NAMESPACE_READY operation.", "response": "def check( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify the validity of a NAMESPACE_READY operation.\n    It is only valid if it has been imported by the same sender as\n    the corresponding NAMESPACE_REVEAL, and the namespace is still\n    in the process of being imported.\n    \"\"\"\n\n    namespace_id = nameop['namespace_id']\n    sender = nameop['sender']\n\n    # must have been revealed\n    if not state_engine.is_namespace_revealed( namespace_id ):\n       log.warning(\"Namespace '%s' is not revealed\" % namespace_id )\n       return False\n\n    # must have been sent by the same person who revealed it\n    revealed_namespace = state_engine.get_namespace_reveal( namespace_id )\n    if revealed_namespace['recipient'] != sender:\n       log.warning(\"Namespace '%s' is not owned by '%s' (but by %s)\" % (namespace_id, sender, revealed_namespace['recipient']))\n       return False\n\n    # can't be ready yet\n    if state_engine.is_namespace_ready( namespace_id ):\n       # namespace already exists\n       log.warning(\"Namespace '%s' is already registered\" % namespace_id )\n       return False\n\n    # preserve from revealed \n    nameop['sender_pubkey'] = revealed_namespace['sender_pubkey']\n    nameop['address'] = revealed_namespace['address']\n\n    # can commit imported nameops\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the namespace ID from the binary payload.", "response": "def parse( bin_payload ):\n   \"\"\"\n   NOTE: the first three bytes will be missing\n   NOTE: the first byte in bin_payload is a '.'\n   \"\"\"\n  \n   if len(bin_payload) == 0:\n       log.error(\"empty namespace\")\n       return None \n\n   if bin_payload[0] != '.':\n       log.error(\"Missing namespace delimiter '.'\")\n       return None \n\n   namespace_id = bin_payload[ 1: ]\n   \n   # sanity check\n   if not is_b40( namespace_id ) or \"+\" in namespace_id or namespace_id.count(\".\") > 0:\n       log.error(\"Invalid namespace ID '%s'\" % namespace_id)\n       return None\n\n   if len(namespace_id) <= 0 or len(namespace_id) > LENGTHS['blockchain_id_namespace_id']:\n       log.error(\"Invalid namespace of length %s\" % len(namespace_id))\n       return None \n\n   return {\n      'opcode': 'NAMESPACE_READY',\n      'namespace_id': namespace_id\n   }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef int_to_charset(val, charset):\n    if val < 0:\n        raise ValueError('\"val\" must be a non-negative integer.')\n\n    if val == 0:\n        return charset[0]\n\n    output = \"\"\n    while val > 0:\n        val, digit = divmod(val, len(charset))\n        output += charset[digit]\n\n    # reverse the characters in the output and return\n    return output[::-1]", "response": "Converts an integer into a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn a string into a non - negative integer.", "response": "def charset_to_int(s, charset):\n    \"\"\" Turn a string into a non-negative integer.\n\n    >>> charset_to_int('0', B40_CHARS)\n    0\n    >>> charset_to_int('10', B40_CHARS)\n    40\n    >>> charset_to_int('abcd', B40_CHARS)\n    658093\n    >>> charset_to_int('', B40_CHARS)\n    0\n    >>> charset_to_int('muneeb.id', B40_CHARS)\n    149190078205533\n    >>> charset_to_int('A', B40_CHARS)\n    Traceback (most recent call last):\n        ...\n    ValueError: substring not found\n    \"\"\"\n    output = 0\n    for char in s:\n        output = output * len(charset) + charset.index(char)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef change_charset(s, original_charset, target_charset):\n    if not isinstance(s, str):\n        raise ValueError('\"s\" must be a string.')\n\n    intermediate_integer = charset_to_int(s, original_charset)\n    output_string = int_to_charset(intermediate_integer, target_charset)\n    return output_string", "response": "Convert a string from one charset to another charset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef autofill(*autofill_fields):\n    def wrap( reader ):\n        def wrapped_reader( *args, **kw ):\n            rec = reader( *args, **kw )\n            if rec is not None:\n                for field in autofill_fields:\n                    if field == \"opcode\" and 'opcode' not in rec.keys():\n                        assert 'op' in rec.keys(), \"BUG: record is missing 'op'\"\n                        rec['opcode'] = op_get_opcode_name(rec['op'])\n                    else:\n                        raise Exception(\"Unknown autofill field '%s'\" % field)\n\n            return rec\n        return wrapped_reader\n    return wrap", "response": "A decorator to automatically fill in extra useful fields that aren t stored in the db."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_readonly_instance(cls, working_dir, expected_snapshots={}):\n        import virtualchain_hooks\n        db_path = virtualchain.get_db_filename(virtualchain_hooks, working_dir)\n        db = BlockstackDB(db_path, DISPOSITION_RO, working_dir, get_genesis_block(), expected_snapshots={})\n        rc = db.db_setup()\n        if not rc:\n            log.error(\"Failed to set up virtualchain state engine\")\n            return None\n        \n        return db", "response": "Get a read - only handle to the blockstack - specific name db."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a read - write instance of the class.", "response": "def get_readwrite_instance(cls, working_dir, restore=False, restore_block_height=None):\n        \"\"\"\n        Get a read/write instance to the db, without the singleton check.\n        Used for low-level operations like db restore.\n        Not used in the steady state behavior of the system.\n        \"\"\"\n        log.warning(\"!!! Getting raw read/write DB instance !!!\")\n\n        import virtualchain_hooks\n        db_path = virtualchain.get_db_filename(virtualchain_hooks, working_dir)\n        db = BlockstackDB(db_path, DISPOSITION_RW, working_dir, get_genesis_block())\n        rc = db.db_setup()\n        if not rc:\n            if restore:\n                # restore from backup instead of bailing out\n                log.debug(\"Restoring from unclean shutdown\")\n                rc = db.db_restore(block_number=restore_block_height)\n                if rc:\n                    return db\n                else:\n                    log.error(\"Failed to restore from unclean shutdown\")\n\n            db.close()\n            raise Exception(\"Failed to set up db\")\n\n        return db"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef borrow_readwrite_instance(cls, working_dir, block_number, expected_snapshots={}):\n\n        global blockstack_db, blockstack_db_lastblock, blockstack_db_lock\n\n        import virtualchain_hooks\n        db_path = virtualchain.get_db_filename(virtualchain_hooks, working_dir)\n        \n        blockstack_db_lock.acquire()\n\n        try:\n            assert blockstack_db is None, \"Borrowing violation\"\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: Borrowing violation\")\n            os.abort()\n\n        db = BlockstackDB(db_path, DISPOSITION_RW, working_dir, get_genesis_block(), expected_snapshots=expected_snapshots)\n        rc = db.db_setup()\n        if not rc:\n            db.close()\n            blockstack_db_lock.release()\n            log.error(\"Failed to set up virtualchain state engine\")\n            return None\n\n        blockstack_db = db\n        blockstack_db_lastblock = block_number\n        blockstack_db_lock.release()\n\n        return blockstack_db", "response": "Get a handle to a read - write database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef release_readwrite_instance( cls, db_inst, block_number ):\n\n        global blockstack_db, blockstack_db_lastblock, blockstack_db_lock \n\n        blockstack_db_lock.acquire()\n\n        try:\n            assert blockstack_db is not None, \"Borrowing return violation: db is None\"\n            assert blockstack_db == db_inst, \"Borrowing return violation: different instances\"\n            assert blockstack_db_lastblock == block_number, \"Borrowing return violation: different blocks\"\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: Borrowing-release violation\")\n            os.abort()\n\n        blockstack_db.close()\n\n        del blockstack_db\n        del db_inst\n\n        db_inst = None\n        blockstack_db = None\n        blockstack_db_lastblock = None \n\n        blockstack_db_lock.release()\n        return True", "response": "Release the read - write instance of the blockstack database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_opfields( cls ):\n        # construct fields \n        opfields = {}\n        for opname in SERIALIZE_FIELDS.keys():\n            opcode = NAME_OPCODES[opname]\n            opfields[opcode] = SERIALIZE_FIELDS[opname]\n\n        return opfields", "response": "Create the dictionary of the virtulachain - required opfields."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the paths to the relevant db files to back up", "response": "def get_state_paths(cls, impl, working_dir):\n        \"\"\"\n        Get the paths to the relevant db files to back up\n        \"\"\"\n        return super(BlockstackDB, cls).get_state_paths(impl, working_dir) + [\n                os.path.join(working_dir, 'atlas.db'), \n                os.path.join(working_dir, 'subdomains.db'),\n                os.path.join(working_dir, 'subdomains.db.queue')\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing the database and release memory.", "response": "def close( self ):\n        \"\"\"\n        Close the db and release memory\n        \"\"\"\n        if self.db is not None:\n            self.db.commit()\n            self.db.close()\n            self.db = None\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_db(self, dirpath):\n        if self.db is not None:\n            self.db.commit()\n            \n        import virtualchain_hooks\n        \n        db_path = os.path.join(dirpath, os.path.basename(self.get_db_path()))\n        snapshots_path = os.path.join(dirpath, os.path.basename(virtualchain.get_snapshots_filename(virtualchain_hooks, self.working_dir)))\n        atlas_path = os.path.join(dirpath, 'atlas.db')\n        subdomain_path = os.path.join(dirpath, 'subdomains.db')\n        subdomain_queue_path = os.path.join(dirpath, 'subdomains.db.queue')\n\n        src_atlas_path = os.path.join(self.working_dir, 'atlas.db')\n        src_subdomain_path = os.path.join(self.working_dir, 'subdomains.db')\n        src_subdomain_queue_path = os.path.join(self.working_dir, 'subdomains.db.queue')\n        \n        virtualchain.sqlite3_backup(self.get_db_path(), db_path)\n        virtualchain.sqlite3_backup(virtualchain.get_snapshots_filename(virtualchain_hooks, self.working_dir), snapshots_path)\n\n        if os.path.exists(src_atlas_path):\n            virtualchain.sqlite3_backup(src_atlas_path, atlas_path)\n\n        if os.path.exists(src_subdomain_path):\n            virtualchain.sqlite3_backup(src_subdomain_path, subdomain_path)\n\n        if os.path.exists(src_subdomain_queue_path):\n            virtualchain.sqlite3_backup(src_subdomain_queue_path, subdomain_queue_path)", "response": "Export all database info to a given directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_import_keychain_path( cls, keychain_dir, namespace_id ):\n        cached_keychain = os.path.join( keychain_dir, \"{}.keychain\".format(namespace_id) )\n        return cached_keychain", "response": "Get the path to the import keychain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_import_keychain( cls, keychain_dir, namespace_id, pubkey_hex ):\n\n        pubkey_addr = virtualchain.BitcoinPublicKey(str(pubkey_hex)).address()\n\n        # do we have a cached one on disk?\n        cached_keychain = cls.get_import_keychain_path(keychain_dir, namespace_id)\n        if os.path.exists( cached_keychain ):\n\n            child_addrs = []\n            try:\n                lines = []\n                with open(cached_keychain, \"r\") as f:\n                    lines = f.readlines()\n\n                child_attrs = [l.strip() for l in lines]\n\n                log.debug(\"Loaded cached import keychain for '%s' (%s)\" % (pubkey_hex, pubkey_addr))\n                return child_attrs\n\n            except Exception, e:\n                log.exception(e)\n                pass\n\n        pubkey_hex = str(pubkey_hex)\n        public_keychain = keychain.PublicKeychain.from_public_key( pubkey_hex )\n        child_addrs = []\n\n        for i in xrange(0, NAME_IMPORT_KEYRING_SIZE):\n            public_child = public_keychain.child(i)\n            public_child_address = public_child.address()\n\n            # if we're on testnet, then re-encode as a testnet address \n            if virtualchain.version_byte == 111:\n                old_child_address = public_child_address\n                public_child_address = virtualchain.hex_hash160_to_address( virtualchain.address_to_hex_hash160( public_child_address ) )\n                log.debug(\"Re-encode '%s' to '%s'\" % (old_child_address, public_child_address))\n\n            child_addrs.append( public_child_address )\n\n            if i % 20 == 0 and i != 0:\n                log.debug(\"%s children...\" % i)\n\n        # include this address\n        child_addrs.append( pubkey_addr )\n\n        log.debug(\"Done building import keychain for '%s' (%s)\" % (pubkey_hex, pubkey_addr))\n\n        # cache\n        try:\n            with open(cached_keychain, \"w+\") as f:\n                for addr in child_addrs:\n                    f.write(\"%s\\n\" % addr)\n\n                f.flush()\n\n            log.debug(\"Cached keychain to '%s'\" % cached_keychain)\n        except Exception, e:\n            log.exception(e)\n            log.error(\"Unable to cache keychain for '%s' (%s)\" % (pubkey_hex, pubkey_addr))\n\n        return child_addrs", "response": "Build all possible NAME_IMPORT addresses from the NAMESPACE_REVEAL public keychain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_import_keychain( cls, working_dir, namespace_id ):\n      \n        # do we have a cached one on disk?\n        cached_keychain = os.path.join(working_dir, \"%s.keychain\" % namespace_id)\n        if os.path.exists( cached_keychain ):\n\n            log.debug(\"Load import keychain '%s'\" % cached_keychain)\n            child_addrs = []\n            try:\n                lines = []\n                with open(cached_keychain, \"r\") as f:\n                    lines = f.readlines()\n \n                child_attrs = [l.strip() for l in lines]\n \n                log.debug(\"Loaded cached import keychain for '%s'\" % namespace_id)\n                return child_attrs\n \n            except Exception, e:\n                log.exception(e)\n                log.error(\"FATAL: uncaught exception loading the import keychain\")\n                os.abort()\n \n        else:\n            log.debug(\"No import keychain at '%s'\" % cached_keychain)\n\n        return None", "response": "Load an import keychain from disk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when the block is finished.", "response": "def commit_finished( self, block_id ):\n        \"\"\"\n        Called when the block is finished.\n        Commits all data.\n        \"\"\"\n\n        self.db.commit()\n\n        # NOTE: tokens vest for the *next* block in order to make the immediately usable\n        assert block_id+1 in self.vesting, 'BUG: failed to vest at {}'.format(block_id)\n\n        self.clear_collisions( block_id )\n        self.clear_vesting(block_id+1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_commit( self, block_id, vtxindex, op, opcode, op_data ):\n\n        debug_op = self.sanitize_op( op_data )\n        if 'history' in debug_op:\n            del debug_op['history'] \n\n        log.debug(\"COMMIT %s (%s) at (%s, %s) data: %s\", opcode, op, block_id, vtxindex, \n                \", \".join( [\"%s='%s'\" % (k, debug_op[k]) for k in sorted(debug_op.keys())] ) )\n\n        return", "response": "Log a committed operation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging a rejected operation", "response": "def log_reject( self, block_id, vtxindex, op, op_data ):\n        \"\"\"\n        Log a rejected operation\n        \"\"\"\n\n        debug_op = self.sanitize_op( op_data )\n        if 'history' in debug_op:\n            del debug_op['history']\n\n        log.debug(\"REJECT %s at (%s, %s) data: %s\", op_get_opcode_name( op ), block_id, vtxindex,\n                \", \".join( [\"%s='%s'\" % (k, debug_op[k]) for k in sorted(debug_op.keys())] ))\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sanitize_op( self, op_data ):\n        \n        op_data = super(BlockstackDB, self).sanitize_op(op_data)\n\n        # remove invariant tags (i.e. added by our invariant state_* decorators)\n        to_remove = get_state_invariant_tags()\n        for tag in to_remove:\n            if tag in op_data.keys():\n                del op_data[tag]\n\n        # NOTE: this is called the opcode family, because\n        # different operation names can have the same operation code\n        # (such as NAME_RENEWAL and NAME_REGISTRATION).  They must\n        # have the same mutation fields.\n        opcode_family = op_get_opcode_name( op_data['op'] )\n\n        # for each column in the appropriate state table,\n        # if the column is not identified in the operation's\n        # MUTATE_FIELDS list, then set it to None here.\n        mutate_fields = op_get_mutate_fields( opcode_family )\n        for mf in mutate_fields:\n            if not op_data.has_key( mf ):\n                log.debug(\"Adding NULL mutate field '%s.%s'\" % (opcode_family, mf ))\n                op_data[mf] = None\n\n        # TODO: less ad-hoc\n        for extra_field in ['opcode']:\n            if extra_field in op_data:\n                del op_data[extra_field]\n\n        return op_data", "response": "Remove unnecessary fields for an operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a given history ID is already in the given state.", "response": "def check_collision_state( cls, collision_state, history_id_key, history_id, block_id, checked_ops, affected_opcodes ):\n        \"\"\"\n        Given a history ID, see if it already exists\n        at the given block ID (i.e. it's not expired),\n        using the given collision state.\n        Return True if so; False if not.\n        If there is a collision, set the __collided__ field in each checked_ops that\n        has a matching history_id value and has an opcode in affected_opcodes.\n        \"\"\"\n\n        # seen before in this block?\n        if collision_state.has_key( block_id ):\n            if collision_state[block_id].has_key(history_id_key):\n                if history_id in collision_state[block_id][history_id_key]:\n                    rc = True\n\n                else:\n                    collision_state[block_id][history_id_key].append( history_id )\n                    rc = False\n\n            else:\n                collision_state[block_id][history_id_key] = [history_id]\n                rc = False\n\n        else:\n            collision_state[block_id] = { history_id_key: [history_id] }\n            rc = False\n\n        if not rc:\n            # no collision \n            return rc\n\n        # find and mark collided operations \n        for prev_op in checked_ops:\n\n            prev_opcode = op_get_opcode_name( prev_op['op'] )\n            if prev_opcode not in affected_opcodes:\n                # not affected\n                continue \n\n            if history_id_key not in prev_op:\n                # won't match\n                continue\n\n            if prev_op[history_id_key] == history_id:\n                # collision \n                cls.nameop_set_collided( prev_op, history_id_key, history_id )\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a list of checked operations find the ones that collide.", "response": "def find_collisions( self, checked_ops ):\n        \"\"\"\n        Given a list of checked operations, find the ones that collide.\n        Return a dict structured as history_id_key --> [history_id]\n        \"\"\"\n\n        collisions = {}\n        for op in checked_ops:\n            if BlockstackDB.nameop_is_collided( op ):\n                BlockstackDB.nameop_put_collision( collisions, op )\n\n        return collisions"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put_collisions( self, block_id, collisions ):\n        self.collisions[ block_id ] = copy.deepcopy( collisions )", "response": "Put the given collision state for a particular block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_collision( self, history_id_key, history_id, block_id, checked_ops, affected_opcodes ):\n\n        return BlockstackDB.check_collision_state( self.collisions, history_id_key, history_id, block_id, checked_ops, affected_opcodes )", "response": "Check if there is a collision with the given history ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_preorder_collision( self, preorder_hash, block_id, checked_ops ):\n\n        return self.check_collision( \"preorder_hash\", preorder_hash, block_id, checked_ops, OPCODE_PREORDER_OPS )", "response": "Check if there are any preorders in this block with the given hash and the given list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a name is colliding with another name.", "response": "def check_name_collision( self, name, block_id, checked_ops ):\n        \"\"\"\n        Are there any colliding names in this block?\n        Set the '__collided__' flag and related flags if so, so we don't commit them.\n        \n        Not called directly; called by the @state_create() decorator in blockstack.lib.operations.register\n        \"\"\"\n\n        return self.check_collision( \"name\", name, block_id, checked_ops, OPCODE_NAME_STATE_CREATIONS )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if any of the namespaces in the given namespace_id are colliding with the given block.", "response": "def check_namespace_collision( self, namespace_id, block_id, checked_ops ):\n        \"\"\"\n        Are there any colliding namespaces in this block?\n        Set the '__collided__' flag and related flags if so, so we don't commit them\n        \n        Not called directly; called by the @state_create() decorator in blockstack.lib.operations.namespacereveal\n        \"\"\"\n\n        return self.check_collision( \"namespace_id\", namespace_id, block_id, checked_ops, OPCODE_NAMESPACE_STATE_CREATIONS )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the ready namespace op for a namespace ID.", "response": "def get_namespace( self, namespace_id, include_history=True ):\n        \"\"\"\n        Given a namespace ID, get the ready namespace op for it.\n\n        Return the dict with the parameters on success.\n        Return None if the namespace has not yet been revealed.\n        \"\"\"\n\n        cur = self.db.cursor()\n        return namedb_get_namespace_ready( cur, namespace_id, include_history=include_history )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_namespace_op_state( self, namespace_id, block_number, include_expired=False ):\n\n        cur = self.db.cursor()\n        return namedb_get_namespace( cur, namespace_id, block_number, include_expired=include_expired )", "response": "Get the state of a namespace op."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_namespace_by_preorder( self, preorder_hash ):\n        cur = self.db.cursor()\n        return namedb_get_namespace_by_preorder_hash( cur, preorder_hash )", "response": "Given a namespace preorder hash get the associated namespace that has been preorder_hash."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_name_by_preorder( self, preorder_hash ):\n        cur = self.db.cursor()\n        return namedb_get_name_by_preorder_hash( cur, preorder_hash )", "response": "Given a name preorder hash get the associated name record."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a name return the latest version and history of that name", "response": "def get_name( self, name, lastblock=None, include_expired=False, include_history=True ):\n        \"\"\"\n        Given a name, return the latest version and history of\n        the metadata gleaned from the blockchain.\n        Name must be fully-qualified (i.e. name.ns_id)\n        Return None if no such name is currently registered.\n\n        NOTE: returns names that are revoked\n        \"\"\"\n\n        if lastblock is None:\n            lastblock = self.lastblock\n\n        cur = self.db.cursor()\n        name_rec = namedb_get_name( cur, name, lastblock, include_expired=include_expired, include_history=include_history )\n        return name_rec"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a name find its DID information.", "response": "def get_name_DID_info(self, name, lastblock=None):\n        \"\"\"\n        Given a name, find its DID (decentralized identifier) information.\n        Returns {'address': ..., 'index': ...}\n        Returns None if there is no such name\n        \"\"\"\n        if lastblock is None:\n            lastblock = self.lastblock\n\n        cur = self.db.cursor()\n        did_info = namedb_get_name_DID_info(cur, name, lastblock)\n        if did_info is None:\n            return None\n\n        return did_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_DID_name(self, did):\n        did = str(did)\n        did_info = None\n        try:\n            did_info = parse_DID(did)\n            assert did_info['name_type'] == 'name'\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            raise ValueError(\"Invalid DID: {}\".format(did))\n\n        cur = self.db.cursor()\n        historic_name_info = namedb_get_historic_names_by_address(cur, did_info['address'], offset=did_info['index'], count=1)\n        if historic_name_info is None:\n            # no such name\n            return None\n\n        name = historic_name_info[0]['name']\n        block_height = historic_name_info[0]['block_id']\n        vtxindex = historic_name_info[0]['vtxindex']\n                    \n        log.debug(\"DID {} refers to {}-{}-{}\".format(did, name, block_height, vtxindex))\n\n        name_rec = self.get_name(name, include_history=True, include_expired=True)\n        if name_rec is None:\n            # dead\n            return None\n\n        name_rec_latest = None\n        found = False\n\n        for height in sorted(name_rec['history'].keys()):\n            if found:\n                break\n\n            if height < block_height:\n                continue\n\n            for state in name_rec['history'][height]:\n                if height == block_height and state['vtxindex'] < vtxindex:\n                    # too soon\n                    continue\n\n                if state['op'] == NAME_PREORDER:\n                    # looped to the next iteration of this name\n                    found = True\n                    break\n\n                if state['revoked']:\n                    # revoked\n                    log.debug(\"DID {} refers to {}-{}-{}, which is revoked at {}-{}\".format(did, name, block_height, vtxindex, height, state['vtxindex']))\n                    return None\n\n                name_rec_latest = state\n\n        return name_rec_latest", "response": "Given a DID get the name of that DID Return None if not found Raise if the DID is invalid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the list of tokens that this address owns", "response": "def get_account_tokens(self, address):\n        \"\"\"\n        Get the list of tokens that this address owns\n        \"\"\"\n        cur = self.db.cursor()\n        return namedb_get_account_tokens(cur, address)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the state of an account for a given token type", "response": "def get_account(self, address, token_type):\n        \"\"\"\n        Get the state of an account for a given token type\n        \"\"\"\n        cur = self.db.cursor()\n        return namedb_get_account(cur, address, token_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_account_balance(self, account):\n        balance = namedb_get_account_balance(account)\n        assert isinstance(balance, (int,long)), 'BUG: account balance of {} is {} (type {})'.format(account['address'], balance, type(balance))\n        return balance", "response": "Get the balance of an account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_account_delta(self, address, token_type, block_id, vtxindex):\n        cur = self.db.cursor()\n        return namedb_get_account_delta(cur, address, token_type, block_id, vtxindex)", "response": "Get the delta between two consecutive account states at a given block_id and vtxindex."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_account_history(self, address, offset=None, count=None):\n        cur = self.db.cursor()\n        return namedb_get_account_history(cur, address, offset=offset, count=count)", "response": "Get the history of account transactions over a block range"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_name_at( self, name, block_number, include_expired=False ):\n        cur = self.db.cursor()\n        return namedb_get_name_at(cur, name, block_number, include_expired=include_expired)", "response": "Generate and return the sequence of states a name record was in at a particular block number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating and return the sequence of states a namespace record was in at a particular block number.", "response": "def get_namespace_at( self, namespace_id, block_number ):\n        \"\"\"\n        Generate and return the sequence of states a namespace record was in\n        at a particular block number.\n\n        Includes expired namespaces by default.\n        \"\"\"\n        cur = self.db.cursor() \n        return namedb_get_namespace_at(cur, namespace_id, block_number, include_expired=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_account_at(self, address, block_number):\n        cur = self.db.cursor()\n        return namedb_get_account_at(cur, address, block_number)", "response": "Get the sequence of states an account was in at a given block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name_history( self, name, offset=None, count=None, reverse=False):\n        cur = self.db.cursor()\n        name_hist = namedb_get_history( cur, name, offset=offset, count=count, reverse=reverse )\n        return name_hist", "response": "Get the historic states for a name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nis the given name a zone file hash?", "response": "def is_name_zonefile_hash(self, name, zonefile_hash):\n        \"\"\"\n        Was a zone file sent by a name?\n        \"\"\"\n        cur = self.db.cursor()\n        return namedb_is_name_zonefile_hash(cur, name, zonefile_hash)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_blockstack_ops_at( self, block_number, offset=None, count=None, include_history=None, restore_history=None ):\n        if include_history is not None:\n            log.warn(\"DEPRECATED use of include_history\")\n\n        if restore_history is not None:\n            log.warn(\"DEPRECATED use of restore_history\")\n\n        log.debug(\"Get all accepted operations at %s in %s\" % (block_number, self.db_filename))\n        recs = namedb_get_all_blockstack_ops_at( self.db, block_number, offset=offset, count=count )\n\n        # include opcode \n        for rec in recs:\n            assert 'op' in rec\n            rec['opcode'] = op_get_opcode_name(rec['op'])\n\n        return recs", "response": "Get all the blockstack operations affected at a particular block number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name_from_name_hash128( self, name ):\n        cur = self.db.cursor()\n        name = namedb_get_name_from_name_hash128( cur, name, self.lastblock )\n        return name", "response": "Get the name from a name hash128"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_names_owned_by_address( self, address ):\n        cur = self.db.cursor()\n        names = namedb_get_names_owned_by_address( cur, address, self.lastblock )\n        return names", "response": "Get the set of names owned by a particular address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_historic_names_by_address( self, address, offset=None, count=None ):\n        cur = self.db.cursor()\n        names = namedb_get_historic_names_by_address( cur, address, offset=offset, count=count )\n        return names", "response": "Get the list of names owned by an address throughout history"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_num_historic_names_by_address( self, address ):\n        cur = self.db.cursor()\n        count = namedb_get_num_historic_names_by_address( cur, address )\n        return count", "response": "Get the number of names historically owned by an address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the set of names owned by a particular script - pubkey.", "response": "def get_names_owned_by_sender( self, sender_pubkey, lastblock=None ):\n        \"\"\"\n        Get the set of names owned by a particular script-pubkey.\n        \"\"\"\n        cur = self.db.cursor()\n        if lastblock is None:\n            lastblock = self.lastblock \n\n        names = namedb_get_names_by_sender( cur, sender_pubkey, lastblock )\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the number of names that exist in the database.", "response": "def get_num_names( self, include_expired=False ):\n        \"\"\"\n        Get the number of names that exist.\n        \"\"\"\n        cur = self.db.cursor()\n        return namedb_get_num_names( cur, self.lastblock, include_expired=include_expired )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_names( self, offset=None, count=None, include_expired=False ):\n        if offset is not None and offset < 0:\n            offset = None\n\n        if count is not None and count < 0:\n            count = None \n\n        cur = self.db.cursor()\n        names = namedb_get_all_names( cur, self.lastblock, offset=offset, count=count, include_expired=include_expired )\n        return names", "response": "Get the set of all registered names with optional pagination."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_num_names_in_namespace( self, namespace_id ):\n        cur = self.db.cursor()\n        return namedb_get_num_names_in_namespace( cur, namespace_id, self.lastblock )", "response": "Get the number of names in a namespace"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_names_in_namespace( self, namespace_id, offset=None, count=None ):\n        if offset is not None and offset < 0:\n            offset = None \n\n        if count is not None and count < 0:\n            count = None \n\n        cur = self.db.cursor()\n        names = namedb_get_names_in_namespace( cur, namespace_id, self.lastblock, offset=offset, count=count )\n        return names", "response": "Get the set of all registered names in a particular namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the set of all existing READY namespace IDs.", "response": "def get_all_namespace_ids( self ):\n        \"\"\"\n        Get the set of all existing, READY namespace IDs.\n        \"\"\"\n        cur = self.db.cursor()\n        namespace_ids = namedb_get_all_namespace_ids( cur )\n        return namespace_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all revealed namespace IDs that have not expired.", "response": "def get_all_revealed_namespace_ids( self ):\n        \"\"\"\n        Get all revealed namespace IDs that have not expired.\n        \"\"\"\n        cur = self.db.cursor()\n        namespace_ids = namedb_get_all_revealed_namespace_ids( cur, self.lastblock )\n        return namespace_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_preordered_namespace_hashes( self ):\n        cur = self.db.cursor()\n        namespace_hashes = namedb_get_all_preordered_namespace_hashes( cur, self.lastblock )\n        return namespace_hashes", "response": "Get all namespace preorder hashes that have not expired."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_importing_namespace_hashes( self ):\n        cur = self.db.cursor()\n        namespace_hashes = namedb_get_all_importing_namespace_hashes( cur, self.lastblock )\n        return namespace_hashes", "response": "Get the set of all preordered and revealed namespace hashes that have not expired."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the name and consensus hash given a name and the consensus hash.", "response": "def get_name_from_name_consensus_hash( self, name_consensus_hash, sender_script_pubkey, block_id ):\n        \"\"\"\n        Find the name.ns_id from hash( name.ns_id, consensus_hash ), given the sender and\n        block_id, and assuming that name.ns_id is already registered.\n\n        There are only a small number of values this hash can take, so test all of them to\n        see if the hash matches one of them.\n\n        This is used for name updates--we need to ensure that updates have timely consensus\n        hashes, and are on the majority blockchian fork.\n\n        Return (fully-qualified name, consensus hash) on success\n        Return (None, None) if not found.\n        \"\"\"\n        import virtualchain_hooks\n\n        cur = self.db.cursor()\n        names = namedb_get_names_by_sender( cur, sender_script_pubkey, self.lastblock )\n        \n        if names is None:\n            log.error(\"Sender script '%s' owns no names\" % sender_script_pubkey )\n            return (None, None)\n\n        possible_consensus_hashes = []\n        for i in range( block_id - virtualchain_hooks.get_valid_transaction_window(), block_id+1 ):\n            consensus_hash = self.get_consensus_at( i )\n            if consensus_hash is not None and consensus_hash not in possible_consensus_hashes:\n                possible_consensus_hashes.append( str(consensus_hash) )\n    \n        for name in names:\n            for consensus_hash in possible_consensus_hashes:\n                # what would have been the name/consensus_hash?\n                test_name_consensus_hash = hash256_trunc128( str(name) + consensus_hash )\n                if test_name_consensus_hash == name_consensus_hash:\n                    # found!\n                    return name, consensus_hash\n\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name_preorder( self, name, sender_script_pubkey, register_addr, include_failed=False ):\n        # name registered and not expired?\n        name_rec = self.get_name( name )\n        if name_rec is not None and not include_failed:\n            return None\n\n        # what namespace are we in?\n        namespace_id = get_namespace_from_name(name)\n        namespace = self.get_namespace(namespace_id)\n        if namespace is None:\n            return None\n\n        # isn't currently registered, or we don't care\n        preorder_hash = hash_name(name, sender_script_pubkey, register_addr=register_addr)\n        preorder = namedb_get_name_preorder( self.db, preorder_hash, self.lastblock )\n        if preorder is None:\n            # doesn't exist or expired\n            return None\n\n        # preorder must be younger than the namespace lifetime\n        # (otherwise we get into weird conditions where someone can preorder\n        # a name before someone else, and register it after it expires)\n        namespace_lifetime_multiplier = get_epoch_namespace_lifetime_multiplier( self.lastblock, namespace_id )\n        if preorder['block_number'] + (namespace['lifetime'] * namespace_lifetime_multiplier) <= self.lastblock:\n            log.debug(\"Preorder is too old (accepted at {}, namespace lifetime is {}, current block is {})\".format(preorder['block_number'], namespace['lifetime'] * namespace_lifetime_multiplier, self.lastblock))\n            return None\n\n        return preorder", "response": "Get the current preorder for a name given the name the sender s script pubkey and the registration address used to calculate the preorder hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_namespace_preorder( self, namespace_id_hash ):\n        namespace_preorder = namedb_get_namespace_preorder( self.db, namespace_id_hash, self.lastblock ) \n        return namespace_preorder", "response": "Get the NAMESPACE_PREORDER record for a given namespace ID hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_names_with_value_hash( self, value_hash ):\n        cur = self.db.cursor()\n        names = namedb_get_names_with_value_hash( cur, value_hash, self.lastblock )\n        return names", "response": "Get the list of names with the given value hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the blockchain - ordered sequence of names value hashes and txids added at the given block height.", "response": "def get_atlas_zonefile_info_at( self, block_id ):\n        \"\"\"\n        Get the blockchain-ordered sequence of names, value hashes, and txids.\n        added at the given block height.  The order will be\n        in tx-order.\n\n        Return [{'name': name, 'value_hash': value_hash, 'txid': txid}]\n        \"\"\"\n        nameops = self.get_all_blockstack_ops_at( block_id )\n        ret = []\n        for nameop in nameops:\n            if nameop.has_key('op') and op_get_opcode_name(nameop['op']) in ['NAME_UPDATE', 'NAME_IMPORT', 'NAME_REGISTRATION', 'NAME_RENEWAL']:\n\n                assert nameop.has_key('value_hash')\n                assert nameop.has_key('name')\n                assert nameop.has_key('txid')\n\n                if nameop['value_hash'] is not None:\n                    ret.append( {'name': nameop['name'], 'value_hash': nameop['value_hash'], 'txid': nameop['txid']} )\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_name_value_hash_txid( self, name, value_hash ):\n        rec = self.get_name( name )\n        if rec is None:\n            return None \n\n        if rec['revoked']:\n            return None\n        \n        # find the txid of the given value hash\n        if rec['value_hash'] == value_hash:\n            return rec['txid']\n\n        else:\n            # search backwards for it \n            hist = rec['history']\n            flat_hist = namedb_flatten_history( hist )\n            for i in xrange(len(flat_hist)-1, 0, -1):\n                delta = flat_hist[i]\n                if delta['op'] == NAME_PREORDER:\n                    # this name was re-registered. skip\n                    return None \n\n                if delta['value_hash'] == value_hash:\n                    # this is the txid that affected it \n                    return delta['txid']\n\n            # not found\n            return None", "response": "Given a name and a value hash return the txid for the value hash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_namespace_reveal( self, namespace_id, include_history=True ):\n        cur = self.db.cursor()\n        namespace_reveal = namedb_get_namespace_reveal( cur, namespace_id, self.lastblock, include_history=include_history )\n        return namespace_reveal", "response": "Get the revealed record for a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_name_expired( self, name, block_number ):\n        cur = self.db.cursor()\n        return namedb_get_name( cur, name, block_number ) is None", "response": "Given a name and block number determine if it is expired at that block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the expiry and renewal deadlines for a name.", "response": "def get_name_deadlines( self, name_rec, namespace_rec, block_number ):\n        \"\"\"\n        Get the expiry and renewal deadlines for a (registered) name.\n\n        NOTE: expire block here is NOT the block at which the owner loses the name, but the block at which lookups fail.\n        The name owner has until renewal_deadline to renew the name.\n\n        Return {'expire_block': ..., 'renewal_deadline': ...} on success\n        Return None if the namespace isn't ready yet\n        \"\"\"\n        if namespace_rec['op'] != NAMESPACE_READY:\n            # name cannot be in grace period, since the namespace is not ready \n            return None\n\n        namespace_id = namespace_rec['namespace_id']\n        namespace_lifetime_multiplier = get_epoch_namespace_lifetime_multiplier( block_number, namespace_id )\n        namespace_lifetime_grace_period = get_epoch_namespace_lifetime_grace_period( block_number, namespace_id )\n\n        expire_block = max(namespace_rec['ready_block'], name_rec['last_renewed']) + (namespace_rec['lifetime'] * namespace_lifetime_multiplier)\n        renewal_deadline = expire_block + namespace_lifetime_grace_period\n\n        return {'expire_block': expire_block, 'renewal_deadline': renewal_deadline}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_name_in_grace_period(self, name, block_number):\n        cur = self.db.cursor()\n        name_rec = namedb_get_name(cur, name, block_number, include_expired=False)\n        if name_rec is None:\n            # expired already or doesn't exist\n            return False\n\n        namespace_id = get_namespace_from_name(name)\n        namespace_rec = namedb_get_namespace(cur, namespace_id, block_number, include_history=False)\n        if namespace_rec is None:\n            return False\n\n        grace_info = BlockstackDB.get_name_deadlines(name_rec, namespace_rec, block_number)\n        if grace_info is None:\n            # namespace isn't ready yet\n            return False\n\n        return (block_number >= grace_info['expire_block'] and block_number < grace_info['renewal_deadline'])", "response": "Given a name and block number determine if it is in the grace period at that block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_name_registered( self, name ):\n        name_rec = self.get_name( name )    # won't return the name if expired\n        if name_rec is None:\n            return False \n\n        if name_rec['revoked']:\n            return False\n\n        return True", "response": "Given the fully - qualified name checks if it is registered at the current block and returns True if it is revoked and expired."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_namespace_ready( self, namespace_id ):\n        namespace = self.get_namespace( namespace_id )\n        if namespace is not None:\n            return True\n        else:\n            return False", "response": "Determines if the namespace is ready at the current block."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if a namespace preorder hash is preordered.", "response": "def is_namespace_preordered( self, namespace_id_hash ):\n        \"\"\"\n        Given a namespace preorder hash, determine if it is preordered\n        at the current block.\n        \"\"\"\n        namespace_preorder = self.get_namespace_preorder(namespace_id_hash)\n        if namespace_preorder is None:\n            return False \n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_namespace_revealed( self, namespace_id ):\n        namespace_reveal = self.get_namespace_reveal( namespace_id )\n        if namespace_reveal is not None:\n            return True\n        else:\n            return False", "response": "Given the name of a namespace return True if it is revealed False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_name_owner( self, name, sender_script_pubkey ):\n        if not self.is_name_registered( name ):\n            # no one owns it \n            return False \n\n        owner = self.get_name_owner( name )\n        if owner != sender_script_pubkey:\n            return False \n        else:\n            return True", "response": "Given the fully - qualified name and a sender s script pubkey determine if the sender owns the name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a preorder hash of a name determine whether or not it is unseen before.", "response": "def is_new_preorder( self, preorder_hash, lastblock=None ):\n        \"\"\"\n        Given a preorder hash of a name, determine whether or not it is unseen before.\n        \"\"\"\n        if lastblock is None:\n            lastblock = self.lastblock \n\n        preorder = namedb_get_name_preorder( self.db, preorder_hash, lastblock )\n        if preorder is not None:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_new_namespace_preorder( self, namespace_id_hash, lastblock=None ):\n        if lastblock is None:\n            lastblock = self.lastblock \n\n        preorder = namedb_get_namespace_preorder( self.db, namespace_id_hash, lastblock )\n        if preorder is not None:\n            return False \n        else:\n            return True", "response": "Determines whether or not a namespace preorder is unseen before."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_name_revoked( self, name ):\n        name = self.get_name( name )\n        if name is None:\n            return False \n\n        if name['revoked']:\n            return True\n        else:\n            return False", "response": "Determines if a name is revoked at this block."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the list of txids by value hash", "response": "def get_value_hash_txids(self, value_hash):\n        \"\"\"\n        Get the list of txids by value hash\n        \"\"\"\n        cur = self.db.cursor()\n        return namedb_get_value_hash_txids(cur, value_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nameop_set_collided( cls, nameop, history_id_key, history_id ):\n        nameop['__collided__'] = True\n        nameop['__collided_history_id_key__'] = history_id_key \n        nameop['__collided_history_id__'] = history_id", "response": "Mark a nameop as collided"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrecording a nameop as collided with another nameop in this block.", "response": "def nameop_put_collision( cls, collisions, nameop ):\n        \"\"\"\n        Record a nameop as collided with another nameop in this block.\n        \"\"\"\n        # these are supposed to have been put here by nameop_set_collided\n        history_id_key = nameop.get('__collided_history_id_key__', None)\n        history_id = nameop.get('__collided_history_id__', None)\n\n        try:\n            assert cls.nameop_is_collided( nameop ), \"Nameop not collided\"\n            assert history_id_key is not None, \"Nameop missing collision info\"\n            assert history_id is not None, \"Nameop missing collision info\"\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: BUG: bad collision info\")\n            os.abort()\n\n        if not collisions.has_key(history_id_key):\n            collisions[history_id_key] = [history_id]\n        else:\n            collisions[history_id_key].append( history_id )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the name record from the virtualchain operation data.", "response": "def extract_consensus_op(self, opcode, op_data, processed_op_data, current_block_number):\n        \"\"\"\n        Using the operation data extracted from parsing the virtualchain operation (@op_data),\n        and the checked, processed operation (@processed_op_data), return a dict that contains\n        (1) all of the consensus fields to snapshot this operation, and\n        (2) all of the data fields that we need to store for the name record (i.e. quirk fields)\n        \"\"\"\n        ret = {}\n\n        consensus_fields = op_get_consensus_fields(opcode)\n        quirk_fields = op_get_quirk_fields(opcode)\n        for field in consensus_fields + quirk_fields:\n\n            try:\n                # assert field in processed_op_data or field in op_data, 'Missing consensus field \"{}\"'.format(field)\n                assert field in processed_op_data, 'Missing consensus field \"{}\"'.format(field)\n            except Exception as e:\n                # should NEVER happen\n                log.exception(e)\n                log.error(\"FATAL: BUG: missing consensus field {}\".format(field))\n                log.error(\"op_data:\\n{}\".format(json.dumps(op_data, indent=4, sort_keys=True)))\n                log.error(\"processed_op_data:\\n{}\".format(json.dumps(op_data, indent=4, sort_keys=True)))\n                os.abort()\n            \n            ret[field] = processed_op_data[field]\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommits an operation and returns a dict with the new db record fields.", "response": "def commit_operation( self, input_op_data, accepted_nameop, current_block_number ):\n        \"\"\"\n        Commit an operation, thereby carrying out a state transition.\n\n        Returns a dict with the new db record fields\n        \"\"\"\n   \n        # have to have read-write disposition \n        if self.disposition != DISPOSITION_RW:\n            log.error(\"FATAL: borrowing violation: not a read-write connection\")\n            traceback.print_stack()\n            os.abort()\n\n        cur = self.db.cursor()\n        canonical_op = None\n        op_type_str = None      # for debugging\n        opcode = accepted_nameop.get('opcode', None)\n\n        try:\n            assert opcode is not None, \"Undefined op '%s'\" % accepted_nameop['op']\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: unrecognized op '%s'\" % accepted_nameop['op'] )\n            os.abort()\n\n        if opcode in OPCODE_PREORDER_OPS:\n            # preorder\n            canonical_op = self.commit_state_preorder( accepted_nameop, current_block_number )\n            op_type_str = \"state_preorder\"\n            \n        elif opcode in OPCODE_CREATION_OPS:\n            # creation\n            canonical_op = self.commit_state_create( accepted_nameop, current_block_number )\n            op_type_str = \"state_create\"\n           \n        elif opcode in OPCODE_TRANSITION_OPS:\n            # transition \n            canonical_op = self.commit_state_transition( accepted_nameop, current_block_number )\n            op_type_str = \"state_transition\"\n       \n        elif opcode in OPCODE_TOKEN_OPS:\n            # token operation \n            canonical_op = self.commit_token_operation(accepted_nameop, current_block_number)\n            op_type_str = \"token_operation\"\n\n        else:\n            raise Exception(\"Unknown operation {}\".format(opcode))\n\n        if canonical_op is None:\n            log.error(\"FATAL: no canonical op generated (for {})\".format(op_type_str))\n            os.abort()\n        \n        log.debug(\"Extract consensus fields for {} in {}, as part of a {}\".format(opcode, current_block_number, op_type_str))\n        consensus_op = self.extract_consensus_op(opcode, input_op_data, canonical_op, current_block_number)\n        return consensus_op"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommitting the account debit the relevant account.", "response": "def commit_account_debit(self, opcode, account_payment_info, current_block_number, current_vtxindex, current_txid):\n        \"\"\"\n        Given the account info set by a state-create or state-transition or a token-operation,\n        debit the relevant account.\n        \n        Do not call this directly.\n\n        Return True on success\n        Abort on error\n        \"\"\"\n        account_address = account_payment_info['address']\n        account_payment = account_payment_info['amount']\n        account_token_type = account_payment_info['type']\n\n        if account_address is not None and account_payment is not None and account_token_type is not None:\n            # sanity check \n            try:\n                assert account_payment >= 0, 'Negative account payment {}'.format(account_payment)\n                assert self.is_token_type_supported(account_token_type), 'Unsupported token type {}'.format(account_token_type)\n            except Exception as e:\n                log.exception(e)\n                log.fatal(\"Sanity check failed\")\n                os.abort()\n\n            # have to debit this account\n            cur = self.db.cursor()\n            rc = namedb_account_debit(cur, account_address, account_token_type, account_payment, current_block_number, current_vtxindex, current_txid)\n            if not rc:\n                traceback.print_stack()\n                log.fatal(\"Failed to debit address {} {} {}\".format(account_address, account_payment, account_token_type))\n                os.abort()\n\n            log.debug(\"COMMIT DEBIT ACCOUNT {} for {} units of {}(s) for {}\".format(account_address, account_payment, account_token_type, opcode))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit_account_credit(self, opcode, account_credit_info, current_block_number, current_vtxindex, current_txid):\n        account_address = account_credit_info['address']\n        account_credit = account_credit_info['amount']\n        account_token_type = account_credit_info['type']\n\n        if account_address is not None and account_credit is not None and account_token_type is not None:\n            # sanity check \n            try:\n                assert account_credit >= 0, 'Non-positive account credit {}'.format(account_credit)\n                assert self.is_token_type_supported(account_token_type), 'Unsupported token type {}'.format(account_token_type)\n            except Exception as e:\n                log.exception(e)\n                log.fatal(\"Sanity check failed\")\n                os.abort()\n\n            # have to debit this account\n            cur = self.db.cursor()\n            rc = namedb_account_credit(cur, account_address, account_token_type, account_credit, current_block_number, current_vtxindex, current_txid)\n            if not rc:\n                traceback.print_stack()\n                log.fatal(\"Failed to debit address {} {} {}\".format(account_address, account_credit, account_token_type))\n                os.abort()\n\n            log.debug(\"COMMIT CREDIT ACCOUNT {} for {} units of {}(s) for {}\".format(account_address, account_credit, account_token_type, opcode))\n\n        return True", "response": "Commit the account credit for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommit a state preorder.", "response": "def commit_state_preorder( self, nameop, current_block_number ):\n        \"\"\"\n        Commit a state preorder (works for namespace_preorder and name_preorder),\n\n        DO NOT CALL THIS DIRECTLY\n        \"\"\"\n\n        # have to have read-write disposition \n        if self.disposition != DISPOSITION_RW:\n            log.error(\"FATAL: borrowing violation: not a read-write connection\")\n            traceback.print_stack()\n            os.abort()\n        \n        opcode = None\n        try:\n            opcode = nameop.get('opcode')\n            assert opcode is not None, 'BUG: no preorder opcode'\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: no opcode in preorder\")\n            os.abort()\n\n        # did we pay any tokens for this state?\n        account_payment_info = state_preorder_get_account_payment_info(nameop)\n\n        cur = self.db.cursor()\n\n        # cannot have collided \n        if BlockstackDB.nameop_is_collided( nameop ):\n            log.debug(\"Not commiting '%s', since it collided\" % nameop)\n            self.log_reject(current_block_number, nameop['vtxindex'], nameop['op'], nameop)\n            return []\n\n        self.log_accept( current_block_number, nameop['vtxindex'], nameop['op'], nameop )\n\n        commit_preorder = self.sanitize_op( nameop )\n        rc = namedb_preorder_insert( cur, commit_preorder )\n        if not rc:\n            log.error(\"FATAL: failed to commit preorder '%s'\" % commit_preorder['preorder_hash'] )\n            os.abort()\n\n        # debit tokens, if present\n        self.commit_account_debit(opcode, account_payment_info, current_block_number, nameop['vtxindex'], nameop['txid'])\n\n        self.db.commit()\n        return commit_preorder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commit_state_create( self, nameop, current_block_number ):\n\n        # have to have read-write disposition \n        if self.disposition != DISPOSITION_RW:\n            log.error(\"FATAL: borrowing violation: not a read-write connection\")\n            traceback.print_stack()\n            os.abort()\n\n        cur = self.db.cursor()\n        opcode = nameop.get('opcode', None)\n\n        try:\n            assert state_create_is_valid( nameop ), \"Invalid state-creation\"\n            assert opcode is not None, \"BUG: did not set opcode\"\n            \n            preorder = state_create_get_preorder( nameop )\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: missing preorder and/or prior history and/or opcode\")\n            os.abort()\n\n        initial_state = self.sanitize_op( nameop )\n        table = state_create_get_table( nameop )\n        history_id_key = state_create_get_history_id_key( nameop )\n        history_id = nameop[history_id_key]\n        constraints_ignored = state_create_get_always_set( nameop )\n\n        # cannot have collided \n        if BlockstackDB.nameop_is_collided( nameop ):\n            # TODO: is this reachable?\n            log.debug(\"Not commiting '%s' since we're collided\" % history_id)\n            self.log_reject( current_block_number, nameop['vtxindex'], nameop['op'], nameop )\n            return {}\n\n        self.log_accept( current_block_number, nameop['vtxindex'], nameop['op'], nameop )\n        \n        canonical_opdata = None\n\n        if preorder is not None:\n            # preordered a name or a namespace, possibly not for the first time even.\n            try:\n                assert 'preorder_hash' in preorder, 'BUG: missing preorder-hash'\n            except Exception as e:\n                log.exception(e)\n                log.error(\"FATAL: invalid preorder\")\n                os.abort()\n\n            canonical_opdata = namedb_state_create(cur, opcode, initial_state, current_block_number,\n                                                   initial_state['vtxindex'], initial_state['txid'],\n                                                   history_id, preorder, table, constraints_ignored=constraints_ignored)\n\n            if not canonical_opdata:\n                log.error(\"FATAL: failed to create '{}'\".format(history_id))\n                self.db.rollback()\n                os.abort()\n\n            self.db.commit()\n        \n        else:\n            # importing a name\n            try:\n                assert opcode in OPCODE_NAME_STATE_IMPORTS, \"BUG: not an import operation\"\n            except Exception, e:\n                log.exception(e)\n                log.error(\"FATAL: invalid import operation\")\n                os.abort()\n\n            canonical_opdata = namedb_state_create_as_import(self.db, opcode, initial_state, \n                                                             current_block_number, initial_state['vtxindex'], initial_state['txid'],\n                                                             history_id, table, constraints_ignored=constraints_ignored)\n\n            if not canonical_opdata:\n                log.error(\"FATAL: failed to create '{}' as import\".format(history_id))\n                self.db.rollback()\n                os.abort()\n\n            self.db.commit()\n        \n        return canonical_opdata", "response": "Commits a state - creation operation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncommitting a state transition.", "response": "def commit_state_transition( self, nameop, current_block_number ):\n        \"\"\"\n        Commit a state transition (update, transfer, revoke, renew, namespace_ready).\n        \n        Returns the new canonicalized record (with all compatibility quirks preserved)\n\n        DO NOT CALL THIS DIRECTLY\n        \"\"\"\n\n        # have to have read-write disposition \n        if self.disposition != DISPOSITION_RW:\n            log.error(\"FATAL: borrowing violation: not a read-write connection\")\n            traceback.print_stack()\n            os.abort()\n\n        cur = self.db.cursor()\n        opcode = nameop.get('opcode', None)\n        constraints_ignored = state_transition_get_always_set( nameop )\n        transition = self.sanitize_op( nameop )\n        \n        try:\n            assert state_transition_is_valid( nameop ), \"Invalid state-transition\"\n            assert opcode is not None, \"No opcode given\"\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: failed to commit state transition\")\n            self.db.rollback()\n            os.abort()\n\n        table = state_transition_get_table( nameop )\n        history_id_key = state_transition_get_history_id_key( nameop )\n        account_payment_info = state_transition_get_account_payment_info(nameop)\n        history_id = nameop[history_id_key]\n\n        # record must exist...\n        if history_id_key == \"name\":\n            cur_record = namedb_get_name( cur, history_id, current_block_number, include_history=False, include_expired=True )\n\n        elif history_id_key == \"namespace_id\":\n            cur_record = namedb_get_namespace( cur, history_id, current_block_number, include_history=False, include_expired=True )\n\n        else:\n            raise Exception(\"Unknown history ID key '%s'\" % history_id_key)\n\n        try:\n            assert cur_record is not None, \"No such record: %s\" % history_id\n        except Exception, e:\n            # should have been caught earlier\n            log.exception(e)\n            log.error(\"FATAL: failed to lookup existing record '%s'\" % history_id)\n            self.db.rollback()\n            os.abort()\n\n        self.log_accept( current_block_number, nameop['vtxindex'], nameop['op'], nameop )\n\n        canonical_op = namedb_state_transition( cur, opcode, transition, current_block_number, transition['vtxindex'], transition['txid'],\n                                                 history_id, cur_record, table, constraints_ignored=constraints_ignored )\n        if not canonical_op:\n            log.error(\"FATAL: failed to update '%s'\" % history_id)\n            self.db.rollback()\n            os.abort()\n        \n        self.commit_account_debit(opcode, account_payment_info, current_block_number, transition['vtxindex'], transition['txid'])\n\n        return canonical_op"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commit_token_operation(self, token_op, current_block_number):\n        # have to have read-write disposition \n        if self.disposition != DISPOSITION_RW:\n            log.error(\"FATAL: borrowing violation: not a read-write connection\")\n            traceback.print_stack()\n            os.abort()\n\n        cur = self.db.cursor()\n        opcode = token_op.get('opcode', None)\n        clean_token_op = self.sanitize_op(token_op)\n       \n        try:\n            assert token_operation_is_valid(token_op), 'Invalid token operation'\n            assert opcode is not None, 'No opcode given'\n            assert 'txid' in token_op, 'No txid'\n            assert 'vtxindex' in token_op, 'No vtxindex'\n        except Exception as e:\n            log.exception(e)\n            log.error('FATAL: failed to commit token operation')\n            self.db.rollback()\n            os.abort()\n\n        table = token_operation_get_table(token_op)\n        account_payment_info = token_operation_get_account_payment_info(token_op)\n        account_credit_info = token_operation_get_account_credit_info(token_op)\n\n        # fields must be set\n        try:\n            for key in account_payment_info:\n                assert account_payment_info[key] is not None, 'BUG: payment info key {} is None'.format(key)\n\n            for key in account_credit_info:\n                assert account_credit_info[key] is not None, 'BUG: credit info key {} is not None'.format(key)\n\n            # NOTE: do not check token amount and type, since in the future we want to support converting\n            # between tokens\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: invalid token debit or credit info\")\n            os.abort()\n        \n        self.log_accept(current_block_number, token_op['vtxindex'], token_op['op'], token_op)\n        \n        # NOTE: this code is single-threaded, but this code must be atomic\n        self.commit_account_debit(token_op, account_payment_info, current_block_number, token_op['vtxindex'], token_op['txid'])\n        self.commit_account_credit(token_op, account_credit_info, current_block_number, token_op['vtxindex'], token_op['txid'])\n\n        namedb_history_save(cur, opcode, token_op['address'], None, None, current_block_number, token_op['vtxindex'], token_op['txid'], clean_token_op)\n        return clean_token_op", "response": "Commits a token operation that debits one account and credits another. Returns the canonicalized record that is the same as the given token operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncommits all vesting of the account at this block height.", "response": "def commit_account_vesting(self, block_height):\n        \"\"\"\n        vest any tokens at this block height\n        \"\"\"\n        # save all state\n        log.debug(\"Commit all database state before vesting\")\n        self.db.commit()\n\n        if block_height in self.vesting:\n            traceback.print_stack()\n            log.fatal(\"Tried to vest tokens twice at {}\".format(block_height))\n            os.abort()\n\n        # commit all vesting in one transaction\n        cur = self.db.cursor()\n        namedb_query_execute(cur, 'BEGIN', ())\n        res = namedb_accounts_vest(cur, block_height)\n        namedb_query_execute(cur, 'END', ())\n\n        self.vesting[block_height] = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a fully - qualified name is acceptable?", "response": "def is_name_valid(fqn):\n    \"\"\"\n    Is a fully-qualified name acceptable?\n    Return True if so\n    Return False if not\n\n    >>> is_name_valid('abcd')\n    False\n    >>> is_name_valid('abcd.')\n    False\n    >>> is_name_valid('.abcd')\n    False\n    >>> is_name_valid('Abcd.abcd')\n    False\n    >>> is_name_valid('abcd.abc.d')\n    False\n    >>> is_name_valid('abcd.abc+d')\n    False\n    >>> is_name_valid('a.b.c')\n    False\n    >>> is_name_valid(True)\n    False\n    >>> is_name_valid(123)\n    False\n    >>> is_name_valid(None)\n    False\n    >>> is_name_valid('')\n    False\n    >>> is_name_valid('abcdabcdabcdabcdabcdabcdabcdabcda.bcd')\n    True\n    >>> is_name_valid('abcdabcdabcdabcdabcdabcdabcdabcdab.bcd')\n    False\n    >>> is_name_valid('abcdabcdabcdabcdabcdabcdabcdabcdabc.d')\n    True\n    >>> is_name_valid('a+b.c')\n    False\n    >>> is_name_valid('a_b.c')\n    True\n    \"\"\"\n\n    if not isinstance(fqn, (str,unicode)):\n        return False\n\n    if fqn.count( \".\" ) != 1:\n        return False\n\n    name, namespace_id = fqn.split(\".\")\n\n    if len(name) == 0 or len(namespace_id) == 0:\n        return False \n\n    if not is_b40( name ) or \"+\" in name or \".\" in name:\n        return False \n   \n    if not is_namespace_valid( namespace_id ):\n        return False\n\n    if len(fqn) > LENGTHS['blockchain_id_name']:\n       # too long\n       return False \n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nis a namespace ID valid?", "response": "def is_namespace_valid( namespace_id ):\n    \"\"\"\n    Is a namespace ID valid?\n\n    >>> is_namespace_valid('abcd')\n    True\n    >>> is_namespace_valid('+abcd')\n    False\n    >>> is_namespace_valid('abc.def')\n    False\n    >>> is_namespace_valid('.abcd')\n    False\n    >>> is_namespace_valid('abcdabcdabcdabcdabcd')\n    False\n    >>> is_namespace_valid('abcdabcdabcdabcdabc')\n    True\n    \"\"\"\n    if not is_b40( namespace_id ) or \"+\" in namespace_id or namespace_id.count(\".\") > 0:\n        return False\n\n    if len(namespace_id) == 0 or len(namespace_id) > LENGTHS['blockchain_id_namespace_id']:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_address_subdomain(fqa):\n    # do these checks early to avoid pathological names that make re.match take forever\n    if fqa.count(\".\") != 2:\n        return False, None, None\n\n    grp = re.match(OP_SUBDOMAIN_NAME_PATTERN, fqa)\n    if grp is None:\n        return False, None, None\n\n    subdomain_name, domain = grp.groups()\n    if not is_name_valid(domain):\n        return False, None, None\n\n    return True, subdomain_name, domain", "response": "Tests whether a string fqa is a fully - qualified subdomain name. Returns False None None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef price_name(name, namespace, block_height):\n    units = None\n    cost_unit = None\n    epoch_features = get_epoch_features(block_height)\n\n    if namespace['version'] == NAMESPACE_VERSION_PAY_WITH_STACKS:\n        units = 'STACKS'\n        cost_unit = NAME_COST_UNIT_STACKS\n    else:\n        units = 'BTC'\n        cost_unit = NAME_COST_UNIT\n    \n    base = namespace['base']\n    coeff = namespace['coeff']\n    buckets = namespace['buckets']\n\n    bucket_exponent = 0\n    discount = 1.0\n\n    if len(name) < len(buckets):\n        bucket_exponent = buckets[len(name)-1]\n    else:\n        bucket_exponent = buckets[-1]\n\n    # no vowel discount?\n    if sum( [name.lower().count(v) for v in [\"a\", \"e\", \"i\", \"o\", \"u\", \"y\"]] ) == 0:\n        # no vowels!\n        discount = max( discount, namespace['no_vowel_discount'] )\n\n    # non-alpha discount?\n    if sum( [name.lower().count(v) for v in [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"-\", \"_\"]] ) > 0:\n        # non-alpha!\n        discount = max( discount, namespace['nonalpha_discount'] )\n\n    price = None\n    final_price = None\n\n    if EPOCH_FEATURE_INT_DIVISION in epoch_features:\n        # post-Stacks, we can have arbitrarily high prices and valuations.  Use integer division\n        price = long(coeff * (base ** bucket_exponent) * cost_unit) / int(discount)\n\n        if price < cost_unit:\n            price = long(cost_unit)\n\n        # we're using price divisors in this epoch \n        price_divisor = get_epoch_price_divisor(block_height, namespace['namespace_id'], units)\n        final_price = price / price_divisor\n\n        assert isinstance(final_price, (int,long))\n\n    else:\n        # pre-Stacks, this was float, since it was deemed \"safe\" for the size of the numbers we were using.\n        # (wish we knew better then)\n        price = (float(coeff * (base ** bucket_exponent)) / float(discount)) * cost_unit\n        \n        if price < cost_unit:\n            price = cost_unit\n\n        # in this epoch, the price_multiplier is a float coefficient\n        price_multiplier = get_epoch_price_multiplier(block_height, namespace['namespace_id'], units)\n        final_price = price * price_multiplier\n\n    return final_price", "response": "Calculate the price of a name given the namespace parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a name s price in Stacks regardless of whether or not it was created before Stacks are created.", "response": "def price_name_stacks(name, namespace, block_height):\n    \"\"\"\n    Get a name's price in Stacks, regardless of whether or not\n    the namespace it was created in was created before Stacks\n    existed.  This is because any name can be purchased with \n    Stacks.  If the namespace price curve was meant for BTC\n    (per its version bits), then the BTC price will be converted\n    to the Stacks price.\n\n    Returns an integer (microStacks)\n    \"\"\"\n    if namespace['version'] in [NAMESPACE_VERSION_PAY_WITH_STACKS]:\n        # price curve already reflects Stacks prices\n        return price_name(name, namespace, block_height)\n\n    else:\n        # price curve reflects Bitcoin prices.\n        # convert to Stacks prices with (MICROSTACKS_PER_SATOSHI_NUM / MICROSTACKS_PER_SATOSHI_DEN) ratio\n        btc_price = price_name(name, namespace, block_height)\n        btc_price = int(btc_price)\n        return (btc_price * MICROSTACKS_PER_SATOSHI_NUM) / MICROSTACKS_PER_SATOSHI_DEN"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the cost of a namespace.", "response": "def price_namespace( namespace_id, block_height, units ):\n    \"\"\"\n    Calculate the cost of a namespace.\n    Returns the price on success\n    Returns None if the namespace is invalid or if the units are invalid\n    \"\"\"\n    price_table = get_epoch_namespace_prices( block_height, units )\n    if price_table is None:\n        return None\n\n    if len(namespace_id) >= len(price_table) or len(namespace_id) == 0:\n        return None\n\n    return price_table[len(namespace_id)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_by_opcode( checked_ops, opcode ):\n\n    if type(opcode) != list:\n        opcode = [opcode]\n\n    ret = []\n    for opdata in checked_ops:\n        if op_get_opcode_name(opdata['op']) in opcode:\n            ret.append(opdata)\n\n    return ret", "response": "Given all previously - accepted operations in this block find all previously - accepted operations that are of a particular opcode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_public_key_hex_from_tx( inputs, address ):\n\n    ret = None\n    for inp in inputs:\n        input_scriptsig = inp['script']\n        input_script_code = virtualchain.btc_script_deserialize(input_scriptsig)\n        if len(input_script_code) == 2:\n            # signature pubkey\n            pubkey_candidate = input_script_code[1]\n            pubkey = None\n            try:\n                pubkey = virtualchain.BitcoinPublicKey(pubkey_candidate)\n            except Exception as e:\n                traceback.print_exc()\n                log.warn(\"Invalid public key {}\".format(pubkey_candidate))\n                continue\n\n            if address != pubkey.address():\n                continue\n\n            # success!\n            return pubkey_candidate\n\n    return None", "response": "Given a list of inputs and the address of one of the inputs find the public key hex from the input script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the name is well - formed.", "response": "def check_name(name):\n    \"\"\"\n    Verify the name is well-formed\n\n    >>> check_name(123)\n    False\n    >>> check_name('')\n    False\n    >>> check_name('abc')\n    False\n    >>> check_name('abc.def')\n    True\n    >>> check_name('abc.def.ghi')\n    False\n    >>> check_name('abc.d-ef')\n    True\n    >>> check_name('abc.d+ef')\n    False\n    >>> check_name('.abc')\n    False\n    >>> check_name('abc.')\n    False\n    >>> check_name('abcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcd.abcd')\n    False\n    >>> check_name('abcdabcdabcdabcdabcdabcdabcdabcdabc.d')\n    True\n    \"\"\"\n    if type(name) not in [str, unicode]:\n        return False\n\n    if not is_name_valid(name):\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that a namespace ID is well - formed.", "response": "def check_namespace(namespace_id):\n    \"\"\"\n    Verify that a namespace ID is well-formed\n\n    >>> check_namespace(123)\n    False\n    >>> check_namespace(None)\n    False\n    >>> check_namespace('')\n    False\n    >>> check_namespace('abcd')\n    True\n    >>> check_namespace('Abcd')\n    False\n    >>> check_namespace('a+bcd')\n    False\n    >>> check_namespace('.abcd')\n    False\n    >>> check_namespace('abcdabcdabcdabcdabcd')\n    False\n    >>> check_namespace('abcdabcdabcdabcdabc')\n    True\n    \"\"\"\n    if type(namespace_id) not in [str, unicode]:\n        return False\n\n    if not is_namespace_valid(namespace_id):\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_token_type(token_type):\n    return check_string(token_type, min_length=1, max_length=LENGTHS['namespace_id'], pattern='^{}$|{}'.format(TOKEN_TYPE_STACKS, OP_NAMESPACE_PATTERN))", "response": "Verify that a token type is well - formed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_subdomain(fqn):\n    if type(fqn) not in [str, unicode]:\n        return False\n\n    if not is_subdomain(fqn):\n        return False\n\n    return True", "response": "Verify that the given fqn is a subdomain of the current domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that a block ID is valid.", "response": "def check_block(block_id):\n    \"\"\"\n    Verify that a block ID is valid\n\n    >>> check_block(FIRST_BLOCK_MAINNET)\n    True\n    >>> check_block(FIRST_BLOCK_MAINNET-1)\n    False\n    >>> check_block(-1)\n    False\n    >>> check_block(\"abc\")\n    False\n    >>> check_block(int(1e7) + 1)\n    False\n    >>> check_block(int(1e7) - 1)\n    True\n    \"\"\"\n    if type(block_id) not in [int, long]:\n        return False\n\n    if BLOCKSTACK_TEST:\n        if block_id <= 0:\n            return False\n\n    else:\n        if block_id < FIRST_BLOCK_MAINNET:\n            return False\n\n    if block_id > 1e7:\n        # 1 million blocks? not in my lifetime\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that an offset is valid", "response": "def check_offset(offset, max_value=None):\n    \"\"\"\n    Verify that an offset is valid\n\n    >>> check_offset(0)\n    True\n    >>> check_offset(-1)\n    False\n    >>> check_offset(2, max_value=2)\n    True\n    >>> check_offset(0)\n    True\n    >>> check_offset(2, max_value=1)\n    False\n    >>> check_offset('abc')\n    False\n    \"\"\"\n    if type(offset) not in [int, long]:\n        return False\n\n    if offset < 0:\n        return False\n\n    if max_value and offset > max_value:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_count(count, max_value=None):\n    if type(count) not in [int, long]:\n        return False\n\n    if count < 0:\n        return False\n\n    if max_value and count > max_value:\n        return False\n\n    return True", "response": "verify that a count is valid\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_string(value, min_length=None, max_length=None, pattern=None):\n    if type(value) not in [str, unicode]:\n        return False\n\n    if min_length and len(value) < min_length:\n        return False\n\n    if max_length and len(value) > max_length:\n        return False\n\n    if pattern and not re.match(pattern, value):\n        return False\n\n    return True", "response": "Verify that a string is a particular length and conforms to a particular alphabet."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that a string is a base58check address", "response": "def check_address(address):\n    \"\"\"\n    verify that a string is a base58check address\n\n    >>> check_address('16EMaNw3pkn3v6f2BgnSSs53zAKH4Q8YJg')\n    True\n    >>> check_address('16EMaNw3pkn3v6f2BgnSSs53zAKH4Q8YJh')\n    False\n    >>> check_address('mkkJsS22dnDJhD8duFkpGnHNr9uz3JEcWu')\n    True\n    >>> check_address('mkkJsS22dnDJhD8duFkpGnHNr9uz3JEcWv')\n    False\n    >>> check_address('MD8WooqTKmwromdMQfSNh8gPTPCSf8KaZj')\n    True\n    >>> check_address('SSXMcDiCZ7yFSQSUj7mWzmDcdwYhq97p2i')\n    True\n    >>> check_address('SSXMcDiCZ7yFSQSUj7mWzmDcdwYhq97p2j')\n    False\n    >>> check_address('16SuThrz')\n    False\n    >>> check_address('1TGKrgtrQjgoPjoa5BnUZ9Qu')\n    False\n    >>> check_address('1LPckRbeTfLjzrfTfnCtP7z2GxFTpZLafXi')\n    True\n    \"\"\"\n    if not check_string(address, min_length=26, max_length=35, pattern=OP_ADDRESS_PATTERN):\n        return False\n\n    try:\n        keylib.b58check_decode(address)\n        return True\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_account_address(address):\n    if address == 'treasury' or address == 'unallocated':\n        return True\n\n    if address.startswith('not_distributed_') and len(address) > len('not_distributed_'):\n        return True\n\n    if re.match(OP_C32CHECK_PATTERN, address):\n        try:\n            c32addressDecode(address)\n            return True\n        except:\n            pass\n\n    return check_address(address)", "response": "Verify that a string is a valid account address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying that the list of transaction outputs are acceptable.", "response": "def check_tx_output_types(outputs, block_height):\n    \"\"\"\n    Verify that the list of transaction outputs are acceptable\n    \"\"\"\n    # for now, we do not allow nonstandard outputs (all outputs must be p2pkh or p2sh outputs)\n    # this excludes bech32 outputs, for example.\n    supported_output_types = get_epoch_btc_script_types(block_height)\n    for out in outputs:\n        out_type = virtualchain.btc_script_classify(out['script'])\n        if out_type not in supported_output_types:\n            log.warning('Unsupported output type {} ({})'.format(out_type, out['script']))\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the list of transaction senders are acceptable and that they are of the correct type.", "response": "def check_tx_sender_types(senders, block_height):\n    \"\"\"\n    Verify that the list of transaction senders are acceptable\n    * a sender should have 1 address\n    * that address should match the epoch's supported sender types\n    \"\"\"\n    supported_sender_types = get_epoch_btc_sender_types(block_height)\n    for sender in senders:\n        if len(sender['addresses']) != 1:\n            log.warning('Sender has {} addresses'.format(sender['addresses']))\n            return False\n\n        out_type = virtualchain.btc_script_classify(sender['script_pubkey'])\n        if out_type not in supported_sender_types:\n            log.warning('Unsupported sender output type {} ({})'.format(out_type, sender['script_pubkey']))\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a b58check or c32check address return the b58check encoding of the c32 address", "response": "def address_as_b58(addr):\n    \"\"\"\n    Given a b58check or c32check address,\n    return the b58check encoding\n    \"\"\"\n    if is_c32_address(addr):\n        return c32ToB58(addr)\n\n    else:\n        if check_address(addr):\n            return addr\n        else:\n            raise ValueError('Address {} is not b58 or c32'.format(addr))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_markdown_spec(f_out, api_calls):\n    groups = OrderedDict()\n    \n    for api_obj in api_calls:\n        obj = {}\n        obj[\"Method\"] = api_obj[\"title\"]\n        obj[\"API Call\"] = \"{} {}\".format(api_obj[\"method\"],\n                                         api_obj[\"path_template\"])\n        obj[\"Grouping\"] = api_obj[\"grouping\"]\n        obj[\"Notes\"] = api_obj[\"notes\"] if \"notes\" in api_obj else \"\"\n        obj[\"API Family\"] = api_obj[\"family\"] if \"family\" in api_obj else \"-\"\n        obj[\"Subgroup\"] = api_obj[\"subgrouping\"] if \"subgrouping\" in api_obj else \"\"\n        \n        if obj[\"Grouping\"] not in groups:\n            groups[obj[\"Grouping\"]] = MarkdownGroup()\n        groups[obj[\"Grouping\"]].add_to_group(obj, obj[\"Subgroup\"])\n\n        if \"grouping_note\" in api_obj:\n            groups[obj[\"Grouping\"]].notes = api_obj[\"grouping_note\"]\n\n    row_headers = [\"Method\", \"API Call\", \"API Family\", \"Notes\"]\n\n\n    f_out.write(\"# Blockstack Specifications\\n\\n\")\n    for gname, g in groups.items():\n        f_out.write(\"## {}\\n\\n\".format(gname))\n        for sg_name, sg in g.subgroups.items():\n            if len(sg_name) > 0:\n                f_out.write(\"### {}\\n\\n\".format(sg_name))\n            f_out.write(\"| {} |\\n\".format(\" | \".join(row_headers)))\n            f_out.write(\"| {} |\\n\".format(\" | \".join([\"-------------\" for i in row_headers])))\n            for item in sg:\n                f_out.write(\"| {} |\\n\".format(\" | \".join(\n                    [item[k] for k in row_headers])))\n            f_out.write(\"\\n\")\n        if g.notes:\n            f_out.write(\"#### {}\\n\\n\".format(g.notes))", "response": "Writes a markdown spec of the given API calls to the given file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a serialized zone file into a list of Subdomain objects.", "response": "def decode_zonefile_subdomains(domain, zonefile_txt, block_height, zonefile_index, txid):\n    \"\"\"\n    Decode a serialized zone file into a zonefile structure that could contain subdomain info.\n    Ignore duplicate subdomains.  The subdomain with the lower sequence number will be accepted.\n    In the event of a tie, the *first* subdomain will be accepted\n\n    Returns the list of subdomain operations, as Subdomain objects (optionally empty), in the order they appeared in the zone file\n    Returns None if this zone file could not be decoded\n    \"\"\"\n    zonefile_hash = get_zonefile_data_hash(zonefile_txt)\n\n    try:\n        # by default, it's a zonefile-formatted text file\n        zonefile_defaultdict = blockstack_zones.parse_zone_file(zonefile_txt)\n        zonefile_json = dict(zonefile_defaultdict)\n        try:\n            # zonefiles with subdomains have TXT records and URI records\n            jsonschema.validate(zonefile_json, USER_ZONEFILE_SCHEMA)\n        except Exception as e:\n            if BLOCKSTACK_TEST:\n                log.exception(e)\n            \n            log.debug(\"Failed to validate zone file {}\".format(zonefile_hash))\n            raise ValueError(\"Not a user zone file\")\n\n        assert zonefile_json['$origin'] == domain, 'Zonefile does not contain $ORIGIN == {} (but has {} instead)'.format(domain, zonefile_json['$origin'])\n        \n        resolver_url = None\n        if 'uri' in zonefile_json:\n            resolver_urls = [x['target'] for x in zonefile_json['uri'] if x['name'] == SUBDOMAIN_TXT_RR_RESOLVER]\n            if len(resolver_urls) > 0:\n                resolver_url = resolver_urls[0]\n\n        subdomains = {}     # map fully-qualified name to subdomain record with lowest sequence number\n        subdomain_pos = {}  # map fully-qualified name to position in zone file\n        domain_zonefiles_missing = None   # list of zone files declared missing by this domain\n        zonefile_offset = 0\n\n        if \"txt\" in zonefile_json:\n            for i, txt in enumerate(zonefile_json['txt']):\n                if is_subdomain_missing_zonefiles_record(txt):\n                    if domain_zonefiles_missing is not None:\n                        raise ValueError(\"Invalid zone file: multiple RRs for {}\".format(SUBDOMAIN_TXT_RR_MISSING))\n\n                    try:\n                        domain_zonefiles_missing = Subdomain.parse_subdomain_missing_zonefiles_record(txt)\n                    except ParseError as pe:\n                        if BLOCKSTACK_DEBUG:\n                            log.exception(pe)\n\n                        log.warn(\"Invalid missing-zonefiles vector at position {}\".format(i))\n                        continue\n\n            if domain_zonefiles_missing is None:\n                domain_zonefiles_missing = []\n\n            for i, txt in enumerate(zonefile_json['txt']):\n                if is_subdomain_record(txt):\n                    try:\n                        # force lowercase\n                        txt['name'] = txt['name'].lower()\n                        if txt['name'] in SUBDOMAIN_TXT_RR_RESERVED:\n                            continue\n\n                        subrec = Subdomain.parse_subdomain_record(domain, txt, block_height, zonefile_hash, zonefile_index, zonefile_offset, txid, domain_zonefiles_missing, resolver=resolver_url)\n                        zonefile_offset += 1\n                    except ParseError as pe:\n                        if BLOCKSTACK_DEBUG:\n                            log.exception(pe)\n\n                        log.warn(\"Invalid subdomain record at position {}\".format(i))\n                        continue\n\n                    if subrec.get_fqn() in subdomains:\n                        if subrec.n < subdomains[subrec.get_fqn()].n:\n                            # replace\n                            subdomains[subrec.get_fqn()] = subrec\n                            subdomain_pos[subrec.get_fqn()] = i\n\n                        else:\n                            log.warn(\"Ignoring subdomain record '{}' with higher sequence\".format(subrec.get_fqn()))\n\n                    else:\n                        # new\n                        subdomains[subrec.get_fqn()] = subrec\n                        subdomain_pos[subrec.get_fqn()] = i\n       \n        subdomain_list = [subdomains[fqn] for fqn in subdomains]\n        subdomain_list.sort(cmp=lambda subrec1, subrec2: -1 if subdomain_pos[subrec1.get_fqn()] < subdomain_pos[subrec2.get_fqn()] else 0 if subdomain_pos[subrec1.get_fqn()] == subdomain_pos[subrec2.get_fqn()] else 1)\n        return subdomain_list\n\n    except Exception as e:\n        if BLOCKSTACK_TEST:\n            log.exception(e)\n\n        log.debug(\"Failed to parse zone file {}\".format(zonefile_hash))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify(address, plaintext, scriptSigb64):\n    assert isinstance(address, str)\n    assert isinstance(scriptSigb64, str)\n\n    scriptSig = base64.b64decode(scriptSigb64)\n    hash_hex = hashlib.sha256(plaintext).hexdigest()\n\n    vb = keylib.b58check.b58check_version_byte(address)\n\n    if vb == bitcoin_blockchain.version_byte:\n        return verify_singlesig(address, hash_hex, scriptSig)\n    elif vb == bitcoin_blockchain.multisig_version_byte:\n        return verify_multisig(address, hash_hex, scriptSig)\n    else:\n        log.warning(\"Unrecognized address version byte {}\".format(vb))\n        raise NotImplementedError(\"Addresses must be single-sig (version-byte = 0) or multi-sig (version-byte = 5)\")", "response": "Verify that a given plaintext is signed by the given scriptSig."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that a p2pkh address is signed by the given pay - to - pubkey - hash scriptsig", "response": "def verify_singlesig(address, hash_hex, scriptSig):\n    \"\"\"\n    Verify that a p2pkh address is signed by the given pay-to-pubkey-hash scriptsig\n    \"\"\"\n    try:\n        sighex, pubkey_hex = virtualchain.btc_script_deserialize(scriptSig)\n    except:\n        log.warn(\"Wrong signature structure for {}\".format(address))\n        return False\n\n    # verify pubkey_hex corresponds to address\n    if virtualchain.address_reencode(keylib.public_key_to_address(pubkey_hex)) != virtualchain.address_reencode(address):\n        log.warn((\"Address {} does not match signature script {}\".format(address, scriptSig.encode('hex'))))\n        return False\n\n    sig64 = base64.b64encode(binascii.unhexlify(sighex))\n    return virtualchain.ecdsalib.verify_digest(hash_hex, pubkey_hex, sig64)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that a p2sh address is signed by the given scriptsig", "response": "def verify_multisig(address, hash_hex, scriptSig):\n    \"\"\"\n    verify that a p2sh address is signed by the given scriptsig\n    \"\"\"\n    script_parts = virtualchain.btc_script_deserialize(scriptSig)\n    if len(script_parts) < 2:\n        log.warn(\"Verfiying multisig failed, couldn't grab script parts\")\n        return False\n\n    redeem_script = script_parts[-1]\n    script_sigs = script_parts[1:-1]\n\n    if virtualchain.address_reencode(virtualchain.btc_make_p2sh_address(redeem_script)) != virtualchain.address_reencode(address):\n        log.warn((\"Address {} does not match redeem script {}\".format(address, redeem_script)))\n        return False\n\n    m, pubk_hexes = virtualchain.parse_multisig_redeemscript(redeem_script)\n    if len(script_sigs) != m:\n        log.warn(\"Failed to validate multi-sig, not correct number of signatures: have {}, require {}\".format(\n            len(script_sigs), m))\n        return False\n\n    cur_pubk = 0\n    for cur_sig in script_sigs:\n        sig64 = base64.b64encode(binascii.unhexlify(cur_sig))\n        sig_passed = False\n        while not sig_passed:\n            if cur_pubk >= len(pubk_hexes):\n                log.warn(\"Failed to validate multi-signature, ran out of public keys to check\")\n                return False\n            sig_passed = virtualchain.ecdsalib.verify_digest(hash_hex, pubk_hexes[cur_pubk], sig64)\n            cur_pubk += 1\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the given parsed zone file TXT record encode a missing - zonefile vector?", "response": "def is_subdomain_missing_zonefiles_record(rec):\n    \"\"\"\n    Does a given parsed zone file TXT record encode a missing-zonefile vector?\n    Return True if so\n    Return False if not\n    \"\"\"\n    if rec['name'] != SUBDOMAIN_TXT_RR_MISSING:\n        return False\n\n    txt_entry = rec['txt']\n    if isinstance(txt_entry, list):\n        return False\n\n    missing = txt_entry.split(',')\n    try:\n        for m in missing:\n            m = int(m)\n    except ValueError:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_subdomain_record(rec):\n    txt_entry = rec['txt']\n    if not isinstance(txt_entry, list):\n        return False\n\n    has_parts_entry = False\n    has_pk_entry = False\n    has_seqn_entry = False\n    for entry in txt_entry:\n        if entry.startswith(SUBDOMAIN_ZF_PARTS + \"=\"):\n            has_parts_entry = True\n        if entry.startswith(SUBDOMAIN_PUBKEY + \"=\"):\n            has_pk_entry = True\n        if entry.startswith(SUBDOMAIN_N + \"=\"):\n            has_seqn_entry = True\n\n    return (has_parts_entry and has_pk_entry and has_seqn_entry)", "response": "Returns True if the TXT record is a subdomain?"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_subdomain_info(fqn, db_path=None, atlasdb_path=None, zonefiles_dir=None, check_pending=False, include_did=False):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        log.warn(\"Subdomain support is disabled\")\n        return None\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    if atlasdb_path is None:\n        atlasdb_path = opts['atlasdb_path']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    try:\n        subrec = db.get_subdomain_entry(fqn)\n    except SubdomainNotFound:\n        log.warn(\"No such subdomain: {}\".format(fqn))\n        return None\n\n    if check_pending:\n        # make sure that all of the zone files between this subdomain's\n        # domain's creation and this subdomain's zone file index are present,\n        # minus the ones that are allowed to be missing.\n        subrec.pending = db.subdomain_check_pending(subrec, atlasdb_path)\n\n    if include_did:\n        # include the DID \n        subrec.did_info = db.get_subdomain_DID_info(fqn)\n\n    return subrec", "response": "Static method for getting the state of a subdomain given its fully - qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_subdomain_DID_info(fqn, db_path=None, zonefiles_dir=None):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        log.warn(\"Subdomain support is disabled\")\n        return None\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    try:\n        subrec = db.get_subdomain_entry(fqn)\n    except SubdomainNotFound:\n        log.warn(\"No such subdomain: {}\".format(fqn))\n        return None\n    \n    try:\n        return db.get_subdomain_DID_info(fqn)\n    except SubdomainNotFound:\n        return None", "response": "Get a subdomain s DID info. Return None if not found"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_DID_subdomain(did, db_path=None, zonefiles_dir=None, atlasdb_path=None, check_pending=False):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        log.warn(\"Subdomain support is disabled\")\n        return None\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n    \n    if atlasdb_path is None:\n        atlasdb_path = opts['atlasdb_path']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    try:\n        subrec = db.get_DID_subdomain(did)\n    except Exception as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        log.warn(\"Failed to load subdomain for {}\".format(did))\n        return None\n\n    if check_pending:\n        # make sure that all of the zone files between this subdomain's\n        # domain's creation and this subdomain's zone file index are present,\n        # minus the ones that are allowed to be missing.\n        subrec.pending = db.subdomain_check_pending(subrec, atlasdb_path)\n\n    return subrec", "response": "Static method for resolving a DID to a subdomain record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subdomain_history(fqn, offset=None, count=None, reverse=False, db_path=None, zonefiles_dir=None, json=False):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        return []\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n    \n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    recs = db.get_subdomain_history(fqn, offset=offset, count=count)\n\n    if json:\n        recs = [rec.to_json() for rec in recs]\n        ret = {}\n        for rec in recs:\n            if rec['block_number'] not in ret:\n                ret[rec['block_number']] = []\n\n            ret[rec['block_number']].append(rec)\n\n        if reverse:\n            for block_height in ret:\n                ret[block_height].sort(lambda r1, r2: -1 if r1['parent_zonefile_index'] > r2['parent_zonefile_index'] or \n                                                           (r1['parent_zonefile_index'] == r2['parent_zonefile_index'] and r1['zonefile_offset'] > r2['zonefile_offset']) else\n                                                       1 if r1['parent_zonefile_index'] < r2['parent_zonefile_index'] or \n                                                           (r1['parent_zonefile_index'] == r2['parent_zonefile_index'] and r1['zonefile_offset'] < r2['zonefile_offset']) else\n                                                       0)\n        return ret\n\n    else:\n        return recs", "response": "Static method for getting all historic operations on a subdomain"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_subdomains(offset=None, count=None, min_sequence=None, db_path=None, zonefiles_dir=None):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        return []\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    return db.get_all_subdomains(offset=offset, count=count, min_sequence=None)", "response": "Static method for getting the list of all subdomains"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subdomains_owned_by_address(address, db_path=None, zonefiles_dir=None):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        return []\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    return db.get_subdomains_owned_by_address(address)", "response": "Static method for getting the list of subdomains owned by a given address"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_subdomain_last_sequence(db_path=None, zonefiles_dir=None):\n    opts = get_blockstack_opts()\n    if not is_subdomains_enabled(opts):\n        return []\n\n    if db_path is None:\n        db_path = opts['subdomaindb_path']\n\n    if zonefiles_dir is None:\n        zonefiles_dir = opts['zonefiles']\n\n    db = SubdomainDB(db_path, zonefiles_dir)\n    return db.get_last_sequence()", "response": "Static method for getting the last sequence number in the database"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_subdomain_txt(name_or_fqn, domain, address, n, zonefile_str, privkey_bundle):\n    subrec = Subdomain(str(name_or_fqn), str(domain), str(address), int(n), str(zonefile_str), None, None, None, None, None, None)\n    subrec_plaintext = subrec.get_plaintext_to_sign()\n    sig = sign(privkey_bundle, subrec_plaintext)\n    \n    subrec = Subdomain(str(name_or_fqn), str(domain), str(address), int(n), str(zonefile_str), str(sig), None, None, None, None, None)\n    return subrec.serialize_to_txt()", "response": "Make a TXT record for a subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning a plaintext with a private key bundle Returns the base64 - encoded scriptsig", "response": "def sign(privkey_bundle, plaintext):\n    \"\"\"\n    Sign a subdomain plaintext with a private key bundle\n    Returns the base64-encoded scriptsig\n    \"\"\"\n    if virtualchain.is_singlesig(privkey_bundle):\n        return sign_singlesig(privkey_bundle, plaintext)\n    elif virtualchain.is_multisig(privkey_bundle):\n        return sign_multisig(privkey_bundle, plaintext)\n    else:\n        raise ValueError(\"private key bundle is neither a singlesig nor multisig bundle\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign_singlesig(privkey_hex, plaintext):\n    hash_hex = hashlib.sha256(plaintext).hexdigest()\n    b64sig = virtualchain.ecdsalib.sign_digest(hash_hex, privkey_hex)\n    sighex = binascii.hexlify(base64.b64decode(b64sig))\n    pubkey_hex = virtualchain.ecdsalib.ecdsa_private_key(privkey_hex).public_key().to_hex()\n    return base64.b64encode(virtualchain.btc_script_serialize([sighex, pubkey_hex]).decode('hex'))", "response": "Sign a plaintext with a private key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sign_multisig(privkey_bundle, plaintext):\n    hash_hex = hashlib.sha256(plaintext).hexdigest()\n    redeem_script = privkey_bundle['redeem_script']\n    secret_keys = privkey_bundle['private_keys']\n\n    assert len(redeem_script) > 0\n    m, pubk_hexes = virtualchain.parse_multisig_redeemscript(redeem_script)\n\n    privs = {}\n    for sk in secret_keys:\n        pubk = virtualchain.ecdsalib.ecdsa_private_key(sk).public_key().to_hex()\n\n        compressed_pubkey = keylib.key_formatting.compress(pubk)\n        uncompressed_pubkey = keylib.key_formatting.decompress(pubk)\n\n        privs[compressed_pubkey] = sk\n        privs[uncompressed_pubkey] = sk\n\n    used_keys, sigs = [], []\n    for pubk in pubk_hexes:\n        if pubk not in privs:\n            continue\n\n        if len(used_keys) == m:\n            break\n\n        assert pubk not in used_keys, 'Tried to reuse key {}'.format(pubk)\n\n        sk_hex = privs[pubk]\n        used_keys.append(pubk)\n\n        b64sig = virtualchain.ecdsalib.sign_digest(hash_hex, sk_hex)\n        sighex = base64.b64decode(b64sig).encode('hex')\n        sigs.append(sighex)\n\n    assert len(used_keys) == m, 'Missing private keys (used {}, required {})'.format(len(used_keys), m)\n    return base64.b64encode(virtualchain.btc_script_serialize([None] + sigs + [redeem_script]).decode('hex'))", "response": "Sign a plaintext with a multisig key bundle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subdomains_init(blockstack_opts, working_dir, atlas_state):\n    if not is_subdomains_enabled(blockstack_opts):\n        return None\n\n    subdomain_state = SubdomainIndex(blockstack_opts['subdomaindb_path'], blockstack_opts=blockstack_opts)\n    atlas_node_add_callback(atlas_state, 'store_zonefile', subdomain_state.enqueue_zonefile)\n\n    return subdomain_state", "response": "Initialize the subdomain state"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npack all of the data for this subdomain into a list of strings.", "response": "def pack_subdomain(self):\n        \"\"\"\n        Pack all of the data for this subdomain into a list of strings.\n        The list of strings will be given in the order in which they should be signed.\n        That is: NAME, ADDR, N, NUM_ZF_PARTS ZF_PARTS, IN_ORDER_PIECES, (? SIG)\n        \"\"\"\n        output = []\n\n        # name (only fully-qualified if independent of the domain name)\n        if self.independent:\n            output.append(self.fqn)\n        else:\n            _, subdomain_name, _ = is_address_subdomain(self.fqn)\n            output.append(subdomain_name)\n\n        # address\n        output.append(txt_encode_key_value(SUBDOMAIN_PUBKEY, self.address))\n\n        # sequence number \n        output.append(txt_encode_key_value(SUBDOMAIN_N, \"{}\".format(self.n)))\n        \n        # subdomain zone file data, broken into 255-character base64 strings.\n        # let's pack into 250 byte strings -- the entry \"zf99=\" eliminates 5 useful bytes,\n        # and the max is 255.\n        encoded_zf = base64.b64encode(self.zonefile_str)\n        n_pieces = (len(encoded_zf) / 250) + 1\n        if len(encoded_zf) % 250 == 0:\n            n_pieces -= 1\n        \n        # number of pieces\n        output.append(txt_encode_key_value(SUBDOMAIN_ZF_PARTS, \"{}\".format(n_pieces)))\n\n        for i in range(n_pieces):\n            start = i * 250\n            piece_len = min(250, len(encoded_zf[start:]))\n            assert piece_len != 0\n            piece = encoded_zf[start:(start+piece_len)]\n\n            # next piece\n            output.append(txt_encode_key_value(SUBDOMAIN_ZF_PIECE % i, piece))\n\n        # signature (optional)\n        if self.sig is not None:\n            output.append(txt_encode_key_value(SUBDOMAIN_SIG, self.sig))\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying whether or not the given address was signed by this object.", "response": "def verify_signature(self, addr):\n        \"\"\"\n        Given an address, verify whether or not it was signed by it\n        \"\"\"\n        return verify(virtualchain.address_reencode(addr), self.get_plaintext_to_sign(), self.sig)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plaintext_to_sign(self):\n        as_strings = self.pack_subdomain()\n        if self.sig is not None:\n            # don't sign the signature\n            as_strings = as_strings[:-1]\n\n        return \",\".join(as_strings)", "response": "Get back the plaintext that will be signed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize_to_txt(self):\n        txtrec = {\n            'name': self.fqn if self.independent else self.subdomain,\n            'txt': self.pack_subdomain()[1:]\n        }\n        return blockstack_zones.record_processors.process_txt([txtrec], '{txt}').strip()", "response": "Serialize this subdomain record to a TXT record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing to JSON which can be returned e. g. via RPC", "response": "def to_json(self):\n        \"\"\"\n        Serialize to JSON, which can be returned e.g. via RPC\n        \"\"\"\n        ret = {\n            'address': self.address,\n            'domain': self.domain,\n            'block_number': self.block_height,\n            'sequence': self.n,\n            'txid': self.txid,\n            'value_hash': get_zonefile_data_hash(self.zonefile_str),\n            'zonefile': base64.b64encode(self.zonefile_str),\n            'name': self.get_fqn(),\n        }\n        \n        if self.pending is not None:\n            ret['pending'] = self.pending\n\n        if self.resolver is not None:\n            ret['resolver'] = self.resolver\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a missing - zonefiles vector given by the domain.", "response": "def parse_subdomain_missing_zonefiles_record(cls, rec):\n        \"\"\"\n        Parse a missing-zonefiles vector given by the domain.\n        Returns the list of zone file indexes on success\n        Raises ParseError on unparseable records\n        \"\"\"\n        txt_entry = rec['txt']\n        if isinstance(txt_entry, list):\n            raise ParseError(\"TXT entry too long for a missing zone file list\")\n\n        try:\n            return [int(i) for i in txt_entry.split(',')] if txt_entry is not None and len(txt_entry) > 0 else []\n        except ValueError:\n            raise ParseError('Invalid integers')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a subdomain record and verify its signature.", "response": "def parse_subdomain_record(domain_name, rec, block_height, parent_zonefile_hash, parent_zonefile_index, zonefile_offset, txid, domain_zonefiles_missing, resolver=None):\n        \"\"\"\n        Parse a subdomain record, and verify its signature.\n        @domain_name: the stem name\n        @rec: the parsed zone file, with 'txt' records\n\n        Returns a Subdomain object on success\n        Raises an exception on parse error\n        \"\"\"\n        # sanity check: need 'txt' record list\n        txt_entry = rec['txt']\n        if not isinstance(txt_entry, list):\n            raise ParseError(\"Tried to parse a TXT record with only a single <character-string>\")\n       \n        entries = {}    # parts of the subdomain record\n        for item in txt_entry:\n            # coerce string\n            if isinstance(item, unicode):\n                item = str(item)\n\n            key, value = item.split('=', 1)\n            value = value.replace('\\\\=', '=')  # escape '='\n            \n            if key in entries:\n                raise ParseError(\"Duplicate TXT entry '{}'\".format(key))\n\n            entries[key] = value\n\n        pubkey = entries[SUBDOMAIN_PUBKEY]\n        n = entries[SUBDOMAIN_N]\n        if SUBDOMAIN_SIG in entries:\n            sig = entries[SUBDOMAIN_SIG]\n        else:\n            sig = None\n        \n        try:\n            zonefile_parts = int(entries[SUBDOMAIN_ZF_PARTS])\n        except ValueError:\n            raise ParseError(\"Not an int (SUBDOMAIN_ZF_PARTS)\")\n        \n        try:\n            n = int(n)\n        except ValueError:\n            raise ParseError(\"Not an int (SUBDOMAIN_N)\")\n\n        b64_zonefile = \"\".join([entries[SUBDOMAIN_ZF_PIECE % zf_index] for zf_index in range(zonefile_parts)])\n        \n        is_subdomain, _, _ = is_address_subdomain(rec['name'])\n        subd_name = None\n        if not is_subdomain:\n            # not a fully-qualified subdomain, which means it ends with this domain name\n            try:\n                assert is_name_valid(str(domain_name)), domain_name\n                subd_name = str(rec['name'] + '.' + domain_name)\n                assert is_address_subdomain(subd_name)[0], subd_name\n            except AssertionError as ae:\n                if BLOCKSTACK_DEBUG:\n                    log.exception(ae)\n\n                raise ParseError(\"Invalid names: {}\".format(ae))\n\n        else:\n            # already fully-qualified\n            subd_name = rec['name']\n            \n        return Subdomain(str(subd_name), str(domain_name), str(pubkey), int(n), base64.b64decode(b64_zonefile), str(sig), block_height, parent_zonefile_hash, parent_zonefile_index, zonefile_offset, txid, domain_zonefiles_missing=domain_zonefiles_missing, resolver=resolver)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the scriptSig and extract the public key. Raises ValueError if this is a multisig - controlled subdomain.", "response": "def get_public_key(self):\n        \"\"\"\n        Parse the scriptSig and extract the public key.\n        Raises ValueError if this is a multisig-controlled subdomain.\n        \"\"\"\n        res = self.get_public_key_info()\n        if 'error' in res:\n            raise ValueError(res['error'])\n\n        if res['type'] != 'singlesig':\n            raise ValueError(res['error'])\n\n        return res['public_keys'][0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_public_key_info(self):\n        script_parts = virtualchain.btc_script_deserialize(base64.b64decode(self.sig))\n        if len(script_parts) < 2:\n            return {'error': 'Signature script does not appear to encode any public keys'}\n\n        if len(script_parts) == 2:\n            # possibly p2pkh\n            pubkey = script_parts[1].encode('hex')\n            try:\n                pubkey_object = virtualchain.ecdsalib.ecdsa_public_key(pubkey)\n            except:\n                return {'error': 'Could not instantiate public key {}'.format(pubkey)}\n\n            if virtualchain.address_reencode(pubkey_object.address()) != virtualchain.address_reencode(self.address):\n                return {'error': 'Public key does not match owner address {}'.format(self.address)}\n\n            return {'status': True, 'type': 'singlesig', 'public_keys': [pubkey], 'num_sigs': 1}\n\n        else:\n            # possibly p2sh multisig.\n            redeem_script = script_parts[-1]\n\n            if virtualchain.address_reencode(virtualchain.btc_make_p2sh_address(redeem_script)) != virtualchain.address_reencode(self.address):\n                return {'error': 'Multisig redeem script does not match owner address {}'.format(self.address)}\n\n            m, pubkey_hexes = virtualchain.parse_multisig_redeemscript(redeem_script)\n            for pkh in pubkey_hexes:\n                try:\n                    virtualchain.ecdsalib.ecdsa_public_key(pkh)\n                except:\n                    return {'error': 'Invalid public key string in multisig script'}\n\n            return {'status': True, 'type': 'multisig', 'public_keys': pubkey_hexes, 'num_sigs': m}", "response": "Analyze the public key information we have in our scriptSig."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_subdomain_transition(cls, existing_subrec, new_subrec):\n        if existing_subrec.get_fqn() != new_subrec.get_fqn():\n            return False\n\n        if existing_subrec.n + 1 != new_subrec.n:\n            return False\n\n        if not new_subrec.verify_signature(existing_subrec.address):\n            log.debug(\"Invalid signature from {}\".format(existing_subrec.address))\n            return False\n\n        if virtualchain.address_reencode(existing_subrec.address) != virtualchain.address_reencode(new_subrec.address):\n            if new_subrec.independent:\n                log.debug(\"Transfer is independent of domain: {}\".format(new_subrec))\n                return False\n\n        return True", "response": "Check if we can use the new subdomain record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that the first - ever - subdomain record is well - formed.", "response": "def check_initial_subdomain(cls, subdomain_rec):\n        \"\"\"\n        Verify that a first-ever subdomain record is well-formed.\n        * n must be 0\n        * the subdomain must not be independent of its domain\n        \"\"\"\n        if subdomain_rec.n != 0:\n            return False\n       \n        if subdomain_rec.independent:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_zonefile_subdomains(self, block_start, block_end, name=None):\n        assert block_start < block_end\n        \n        subdomain_info = []\n        offset = 0\n        count = 100\n        con = atlasdb_open(self.atlasdb_path)\n\n        while True:\n            # NOTE: filtered on name\n            range_subdomain_info = atlasdb_get_zonefiles_by_block(block_start, block_end-1, offset, count, name=name, con=con)\n            if len(range_subdomain_info) == 0:\n                break\n\n            offset += count\n            subdomain_info += range_subdomain_info\n\n        con.close()\n       \n        log.debug(\"Found {} zonefile hashes between {} and {} for {}\".format(len(subdomain_info), block_start, block_end, '\"{}\"'.format(name) if name is not None else 'all names'))\n\n        # extract sequence of subdomain operations for each zone file discovered\n        for i, sdinfo in enumerate(subdomain_info):\n            # find and parse zone file data\n            sddata = get_atlas_zonefile_data(sdinfo['zonefile_hash'], self.zonefiles_dir)\n            if sddata is None:\n                # no zone file\n                log.debug(\"Missing zonefile {} (at {})\".format(sdinfo['zonefile_hash'], sdinfo['block_height']))\n                subdomain_info[i]['subdomains'] = None\n                continue\n\n            subdomains = decode_zonefile_subdomains(sdinfo['name'], sddata, sdinfo['block_height'], sdinfo['inv_index'], sdinfo['txid'])\n            if subdomains is None:\n                # have zone file, but no subdomains\n                subdomains = []\n\n            log.debug(\"Found {} subdomain record(s) for '{}' in zonefile {} at {} (index {})\".format(len(subdomains), sdinfo['name'], sdinfo['zonefile_hash'], sdinfo['block_height'], sdinfo['inv_index']))\n            subdomain_info[i]['subdomains'] = subdomains\n\n        # group discovered subdomain records by subdomain name\n        subdomain_index = {}\n        for i, zfinfo in enumerate(subdomain_info):\n            if zfinfo['subdomains'] is None:\n                # no zone file\n                continue\n\n            for sd in zfinfo['subdomains']:\n                fqn = sd.get_fqn()\n                if fqn not in subdomain_index:\n                    subdomain_index[fqn] = []\n\n                subdomain_index[fqn].append(i)\n\n        return {'zonefile_info': subdomain_info, 'subdomains': subdomain_index}", "response": "Find the sequence of subdomain operations over a block range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_subdomain_history_neighbors(self, cursor, subdomain_rec):\n        # what's the subdomain's immediate prior history?\n        hist = self.subdomain_db.get_subdomain_history(subdomain_rec.get_fqn(), include_unaccepted=True, start_sequence=subdomain_rec.n-1, end_sequence=subdomain_rec.n, cur=cursor)\n        hist.sort(lambda h1, h2: -1 if h1.n < h2.n or (h1.n == h2.n and h1.parent_zonefile_index < h2.parent_zonefile_index) \\\n                                 else 0 if h1.n == h2.n and h1.parent_zonefile_index == h2.parent_zonefile_index \\\n                                 else 1)\n\n        # what's the subdomain's current and immediate future?\n        fut = self.subdomain_db.get_subdomain_history(subdomain_rec.get_fqn(), include_unaccepted=True, start_sequence=subdomain_rec.n, end_sequence=subdomain_rec.n+2, cur=cursor)\n        fut.sort(lambda h1, h2: -1 if h1.n < h2.n or (h1.n == h2.n and h1.parent_zonefile_index < h2.parent_zonefile_index) \\\n                                 else 0 if h1.n == h2.n and h1.parent_zonefile_index == h2.parent_zonefile_index \\\n                                 else 1)\n\n        # extract the current (conflicting) records from the future\n        cur = []\n        tmp_fut = []\n        for f in fut:\n            if f.n == subdomain_rec.n:\n                cur.append(f)\n            else:\n                tmp_fut.append(f)\n\n        fut = tmp_fut\n\n        ret = {'prev': hist, 'cur': cur, 'fut': fut}\n        return ret", "response": "Given a subdomain record get its neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to insert a subdomain record into the history neighbors.", "response": "def subdomain_try_insert(self, cursor, subdomain_rec, history_neighbors):\n        \"\"\"\n        Try to insert a subdomain record into its history neighbors.\n        This is an optimization that handles the \"usual\" case.\n\n        We can do this without having to rewrite this subdomain's past and future\n        if (1) we can find a previously-accepted subdomain record, and (2) the transition \n        from this subdomain record to a future subdomain record preserves its\n        acceptance as True.  In this case, the \"far\" past and \"far\" future are already\n        consistent.\n        \n        Return True if we succeed in doing so.\n        Return False if not.\n        \"\"\"\n        blockchain_order = history_neighbors['prev'] + history_neighbors['cur'] + history_neighbors['fut']\n\n        last_accepted = -1\n        for i in range(0, len(blockchain_order)):\n            if blockchain_order[i].accepted:\n                last_accepted = i\n                break\n\n            if blockchain_order[i].n > subdomain_rec.n or (blockchain_order[i].n == subdomain_rec.n and blockchain_order[i].parent_zonefile_index > subdomain_rec.parent_zonefile_index):\n                # can't cheaply insert this subdomain record,\n                # since none of its immediate ancestors are accepted.\n                log.debug(\"No immediate ancestors are accepted on {}\".format(subdomain_rec))\n                return False\n\n        if last_accepted < 0:\n            log.debug(\"No immediate ancestors or successors are accepted on {}\".format(subdomain_rec))\n            return False\n\n        # one ancestor was accepted.\n        # work from there.\n\n        chain_tip_status = blockchain_order[-1].accepted\n\n        dirty = []  # to be written\n        for i in range(last_accepted+1, len(blockchain_order)):\n            cur_accepted = blockchain_order[i].accepted\n            new_accepted = self.check_subdomain_transition(blockchain_order[last_accepted], blockchain_order[i])\n            if new_accepted != cur_accepted:\n                blockchain_order[i].accepted = new_accepted\n                log.debug(\"Changed from {} to {}: {}\".format(cur_accepted, new_accepted, blockchain_order[i]))\n                dirty.append(blockchain_order[i])\n\n            if new_accepted:\n                last_accepted = i\n\n        if chain_tip_status != blockchain_order[-1].accepted and len(history_neighbors['fut']) > 0:\n            # deeper reorg\n            log.debug(\"Immediate history chain tip altered from {} to {}: {}\".format(chain_tip_status, blockchain_order[-1].accepted, blockchain_order[-1]))\n            return False\n\n        # localized change.  Just commit the dirty entries\n        for subrec in dirty:\n            log.debug(\"Update to accepted={}: {}\".format(subrec.accepted, subrec))\n            self.subdomain_db.update_subdomain_entry(subrec, cur=cursor)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the subdomain records in the zonefile and stores them in the database.", "response": "def process_subdomains(self, zonefile_subdomain_info):\n        \"\"\"\n        Takes the output of find_zonefile_subdomains, and processes the sequence of subdomain operations.\n        Does state-transitions in a big step:\n        * loads the current subdomain state for each subdomain affected in @zonefile_subdomain_info\n        * computes and executes all valid subdomain creations and subdomain state-transitions on each\n          affected subdomain, in blockchain-given and zonefile-given order.\n        * stores the resulting subdomain state for each affected subdomain to the subdomain DB\n\n        WARNING: NOT THREAD SAFE.  DO NOT CALL FROM MULTIPLE THREADS\n        \"\"\"\n\n        cursor = self.subdomain_db.cursor()\n\n        # we can afford to be fast and loose here since if the host crashes while this is going on,\n        # the node will do a `restore` anyway and wipe this db out.\n        db_query_execute(cursor, 'PRAGMA synchronous = off;', ())\n        db_query_execute(cursor, 'PRAGMA journal_mode = off;', ())\n        db_query_execute(cursor, 'BEGIN', ())\n\n        # no matter what we do, store everything.\n        # but, don't accept it yet.\n        for subinfo in zonefile_subdomain_info:\n            if subinfo['subdomains'] is None:\n                continue\n\n            for subrec in subinfo['subdomains']:\n                subrec.accepted = False\n                log.debug(\"Store {}\".format(subrec))\n                self.subdomain_db.update_subdomain_entry(subrec, cur=cursor)\n\n        # at each zone file, find out if its subdomain creates/updates are valid\n        for subinfo in zonefile_subdomain_info:\n\n            zfhash = subinfo['zonefile_hash']\n            zfindex = subinfo['inv_index']\n\n            log.debug(\"Process subdomain records in zonefile {} ({})\".format(subinfo['zonefile_hash'], subinfo['inv_index']))\n\n            new_subdomain_recs = {}\n\n            # get the set of subdomain records created by this zonefile\n            if subinfo['subdomains']:\n                for subrec in subinfo['subdomains']:\n                    assert subrec.get_fqn() not in new_subdomain_recs, 'BUG: duplicate subdomain record for \"{}\" in {}'.format(subrec.get_fqn(), zfhash)\n                    new_subdomain_recs[subrec.get_fqn()] = subrec\n            \n            for fqn in new_subdomain_recs:\n                immediate_history = self.get_subdomain_history_neighbors(cursor, new_subdomain_recs[fqn])\n                inserted = self.subdomain_try_insert(cursor, new_subdomain_recs[fqn], immediate_history)\n                if inserted:\n                    log.debug(\"Inserted {}\".format(fqn))\n                    continue\n\n                log.debug(\"Rewrite history of {}\".format(fqn))\n\n                new_hist = self.make_new_subdomain_history(cursor, new_subdomain_recs[fqn])\n                for subrec in new_hist:\n                    self.subdomain_db.update_subdomain_entry(subrec, cur=cursor)\n\n                last_accepted = None\n                for h in reversed(new_hist):\n                    if h.accepted:\n                        last_accepted = h\n                        break\n\n                if last_accepted:\n                    new_fut = self.make_new_subdomain_future(cursor, last_accepted)\n                else:\n                    new_fut = []\n\n                for subrec in new_fut:\n                    self.subdomain_db.update_subdomain_entry(subrec, cur=cursor)\n\n        db_query_execute(cursor, 'END', ())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enqueue_zonefile(self, zonefile_hash, block_height):\n        with self.serialized_enqueue_zonefile:\n            log.debug(\"Append {} from {}\".format(zonefile_hash, block_height))\n            queuedb_append(self.subdomain_queue_path, \"zonefiles\", zonefile_hash, json.dumps({'zonefile_hash': zonefile_hash, 'block_height': block_height}))", "response": "Enqueue a zone file for reprocessing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index_blockchain(self, block_start, block_end):\n        log.debug(\"Processing subdomain updates for zonefiles in blocks {}-{}\".format(block_start, block_end))\n        \n        res = self.find_zonefile_subdomains(block_start, block_end)\n        zonefile_subdomain_info = res['zonefile_info']\n\n        self.process_subdomains(zonefile_subdomain_info)", "response": "Go through the sequence of zone files discovered in a block range and reindex the names subdomains."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngoes through the list of zone files we discovered via Atlas, grouped by name and ordered by block height. Find all subsequent zone files for this name, and process all subdomain operations contained within them.", "response": "def index_discovered_zonefiles(self, lastblock):\n        \"\"\"\n        Go through the list of zone files we discovered via Atlas, grouped by name and ordered by block height.\n        Find all subsequent zone files for this name, and process all subdomain operations contained within them.\n        \"\"\"\n        all_queued_zfinfos = []         # contents of the queue\n        subdomain_zonefile_infos = {}   # map subdomain fqn to list of zonefile info bundles, for process_subdomains\n        name_blocks = {}                # map domain name to the block at which we should reprocess its subsequent zone files\n\n        offset = 0\n\n        while True:\n            queued_zfinfos = queuedb_findall(self.subdomain_queue_path, \"zonefiles\", limit=100, offset=offset)\n            if len(queued_zfinfos) == 0:\n                # done!\n                break\n            \n            offset += 100\n            all_queued_zfinfos += queued_zfinfos\n\n            if len(all_queued_zfinfos) >= 1000:\n                # only do so many zone files per block, so we don't stall the node\n                break\n        \n        log.debug(\"Discovered {} zonefiles\".format(len(all_queued_zfinfos)))\n\n        for queued_zfinfo in all_queued_zfinfos:\n            zfinfo = json.loads(queued_zfinfo['data'])\n\n            zonefile_hash = zfinfo['zonefile_hash']\n            block_height = zfinfo['block_height']\n\n            # find out the names that sent this zone file at this block\n            zfinfos = atlasdb_get_zonefiles_by_hash(zonefile_hash, block_height=block_height, path=self.atlasdb_path)\n            if zfinfos is None:\n                log.warn(\"Absent zonefile {}\".format(zonefile_hash))\n                continue\n            \n            # find out for each name block height at which its zone file was discovered.\n            # this is where we'll begin looking for more subdomain updates.\n            for zfi in zfinfos:\n                if zfi['name'] not in name_blocks:\n                    name_blocks[zfi['name']] = block_height\n                else:\n                    name_blocks[zfi['name']] = min(block_height, name_blocks[zfi['name']])\n      \n        for name in name_blocks:\n            if name_blocks[name] >= lastblock:\n                continue\n\n            log.debug(\"Finding subdomain updates for {} at block {}\".format(name, name_blocks[name]))\n            \n            # get the subdomains affected at this block by finding the zonefiles created here.\n            res = self.find_zonefile_subdomains(name_blocks[name], lastblock, name=name)\n            zonefile_subdomain_info = res['zonefile_info']\n            subdomain_index = res['subdomains']\n            \n            # for each subdomain, find the list of zonefiles that contain records for it\n            for fqn in subdomain_index:\n                if fqn not in subdomain_zonefile_infos:\n                    subdomain_zonefile_infos[fqn] = []\n\n                for i in subdomain_index[fqn]:\n                    subdomain_zonefile_infos[fqn].append(zonefile_subdomain_info[i])\n           \n        processed = []\n        for fqn in subdomain_zonefile_infos:\n            subseq = filter(lambda szi: szi['zonefile_hash'] not in processed, subdomain_zonefile_infos[fqn])\n            if len(subseq) == 0:\n                continue\n\n            log.debug(\"Processing {} zone file entries found for {} and others\".format(len(subseq), fqn))\n\n            subseq.sort(cmp=lambda z1, z2: -1 if z1['block_height'] < z2['block_height'] else 0 if z1['block_height'] == z2['block_height'] else 1)\n            self.process_subdomains(subseq)\n            processed += [szi['zonefile_hash'] for szi in subseq]\n\n        # clear queue \n        queuedb_removeall(self.subdomain_queue_path, all_queued_zfinfos)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index(self, block_start, block_end):\n        log.debug(\"BEGIN Processing zonefiles discovered since last re-indexing\")\n        t1 = time.time()\n        self.index_discovered_zonefiles(block_end)\n        t2 = time.time()\n        log.debug(\"END Processing zonefiles discovered since last re-indexing ({} seconds)\".format(t2 - t1))", "response": "Index all zonefiles in the block_start to block_end."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reindex(cls, lastblock, firstblock=None, opts=None):\n        if opts is None:\n            opts = get_blockstack_opts()\n\n        if not is_atlas_enabled(opts):\n            raise Exception(\"Atlas is not enabled\")\n\n        if not is_subdomains_enabled(opts):\n            raise Exception(\"Subdomain support is not enabled\")\n\n        subdomaindb_path = opts['subdomaindb_path']\n        atlasdb_path = opts['atlasdb_path']\n        \n        if not os.path.exists(atlasdb_path):\n            raise Exception(\"No Atlas database at {}\".format(opts['atlasdb_path']))\n        \n        subdomain_indexer = SubdomainIndex(subdomaindb_path, blockstack_opts=opts)\n        subdomain_indexer.subdomain_db.wipe()\n\n        if firstblock is None:\n            start_block = SUBDOMAINS_FIRST_BLOCK\n        else:\n            start_block = firstblock\n\n        for i in range(start_block, lastblock, 100):\n            log.debug(\"Processing all subdomains in blocks {}-{}...\".format(i, i+99))\n            subdomain_indexer.index_blockchain(i, i+100)\n\n        log.debug(\"Finished indexing subdomains in blocks {}-{}\".format(start_block, lastblock))", "response": "Reindex the subdomains of the current class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Dict row factory for subdomains.", "response": "def subdomain_row_factory(cls, cursor, row):\n        \"\"\"\n        Dict row factory for subdomains\n        \"\"\"\n        d = {}\n        for idx, col in enumerate(cursor.description):\n            d[col[0]] = row[idx]\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract a single subdomain from a DB cursor.", "response": "def _extract_subdomain(self, rowdata):\n        \"\"\"\n        Extract a single subdomain from a DB cursor\n        Raise SubdomainNotFound if there are no valid rows\n        \"\"\"\n        name = str(rowdata['fully_qualified_subdomain'])\n        domain = str(rowdata['domain'])\n        n = str(rowdata['sequence'])\n        encoded_pubkey = str(rowdata['owner'])\n        zonefile_hash = str(rowdata['zonefile_hash'])\n        sig = rowdata['signature']\n        block_height = int(rowdata['block_height'])\n        parent_zonefile_hash = str(rowdata['parent_zonefile_hash'])\n        parent_zonefile_index = int(rowdata['parent_zonefile_index'])\n        zonefile_offset = int(rowdata['zonefile_offset'])\n        txid = str(rowdata['txid'])\n        missing = [int(i) for i in rowdata['missing'].split(',')] if rowdata['missing'] is not None and len(rowdata['missing']) > 0 else []\n        accepted = int(rowdata['accepted'])\n        resolver = str(rowdata['resolver']) if rowdata['resolver'] is not None else None\n\n        if accepted == 0:\n            accepted = False\n        else:\n            accepted = True\n\n        if sig == '' or sig is None:\n            sig = None\n        else:\n            sig = str(sig)\n\n        name = str(name)\n        is_subdomain, _, _ = is_address_subdomain(name)\n        if not is_subdomain:\n            raise Exception(\"Subdomain DB lookup returned bad subdomain result {}\".format(name))\n\n        zonefile_str = get_atlas_zonefile_data(zonefile_hash, self.zonefiles_dir)\n        if zonefile_str is None:\n            log.error(\"No zone file for {}\".format(name))\n            raise SubdomainNotFound('{}: missing zone file {}'.format(name, zonefile_hash))\n\n        return Subdomain(str(name), str(domain), str(encoded_pubkey), int(n), str(zonefile_str), sig, block_height, parent_zonefile_hash, parent_zonefile_index, zonefile_offset, txid, domain_zonefiles_missing=missing, accepted=accepted, resolver=resolver)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_subdomains_count(self, accepted=True, cur=None):\n        if accepted:\n            accepted_filter = 'WHERE accepted=1'\n        else:\n            accepted_filter = ''\n\n        get_cmd = \"SELECT COUNT(DISTINCT fully_qualified_subdomain) as count FROM {} {};\".format(\n            self.subdomain_table, accepted_filter)\n\n        cursor = cur\n        if cursor is None:\n            cursor = self.conn.cursor()\n\n        db_query_execute(cursor, get_cmd, ())\n\n        try:\n            rowdata = cursor.fetchone()\n            return rowdata['count']\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n            return 0", "response": "Fetch the number of subdomain names in the current table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget and all subdomains of the current node.", "response": "def get_all_subdomains(self, offset=None, count=None, min_sequence=None, cur=None):\n        \"\"\"\n        Get and all subdomain names, optionally over a range\n        \"\"\"\n        get_cmd = 'SELECT DISTINCT fully_qualified_subdomain FROM {}'.format(self.subdomain_table)\n        args = ()\n\n        if min_sequence is not None:\n            get_cmd += ' WHERE sequence >= ?'\n            args += (min_sequence,)\n\n        if count is not None:\n            get_cmd += ' LIMIT ?'\n            args += (count,)\n\n        if offset is not None:\n            get_cmd += ' OFFSET ?'\n            args += (offset,)\n\n        get_cmd += ';'\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        rows = db_query_execute(cursor, get_cmd, args)\n        subdomains = []\n        for row in rows:\n            subdomains.append(row['fully_qualified_subdomain'])\n\n        return subdomains"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_subdomain_entry(self, fqn, accepted=True, cur=None):\n        get_cmd = \"SELECT * FROM {} WHERE fully_qualified_subdomain=? {} ORDER BY sequence DESC, parent_zonefile_index DESC LIMIT 1;\".format(self.subdomain_table, 'AND accepted=1' if accepted else '')\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (fqn,))\n\n        try:\n            rowdata = cursor.fetchone()\n            assert rowdata\n        except Exception as e:\n            raise SubdomainNotFound(fqn)\n\n        return self._extract_subdomain(rowdata)", "response": "Given a fully - qualified subdomain get its latest subdomain record."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_subdomain_entry_at_sequence(self, fqn, sequence, include_unaccepted=False, cur=None):\n        get_cmd = \"SELECT * FROM {} WHERE fully_qualified_subdomain=? AND sequence = ?\".format(self.subdomain_table)\n        if not include_unaccepted:\n            get_cmd += \" AND accepted=1\"\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (fqn,sequence))\n\n        try:\n            rowdata = cursor.fetchone()\n            assert rowdata\n        except Exception as e:\n            raise SubdomainNotFound(fqn)\n\n        return self._extract_subdomain(rowdata)", "response": "Given a fully - qualified subdomain and a sequence number get its historic subdomain record at that sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a fully - qualified subdomain and a sequence number get its historic subdomain record at that sequence number.", "response": "def get_subdomain_entry_at_zonefile_index(self, fqn, zonefile_index, cur=None):\n        \"\"\"\n        Given a fully-qualified subdomain and a sequence number, get its historic subdomain record at that sequence.\n        Raises SubdomainNotFound if there is no such subdomain\n        \"\"\"\n        get_cmd = \"SELECT * FROM {} WHERE fully_qualified_subdomain=? AND parent_zonefile_index=?\".format(self.subdomain_table)\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (fqn,zonefile_index))\n\n        try:\n            rowdata = cursor.fetchone()\n            assert rowdata\n        except Exception as e:\n            raise SubdomainNotFound(fqn)\n\n        return self._extract_subdomain(rowdata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a txid get all subdomain operations at that txid.", "response": "def get_subdomain_ops_at_txid(self, txid, cur=None):\n        \"\"\"\n        Given a txid, get all subdomain operations at that txid.\n        Include unaccepted operations.\n        Order by zone file index\n        \"\"\"\n        get_cmd = 'SELECT * FROM {} WHERE txid = ? ORDER BY zonefile_offset'.format(self.subdomain_table)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (txid,))\n\n        try:\n            return [x for x in cursor.fetchall()]\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of subdomain names that are owned by a given address.", "response": "def get_subdomains_owned_by_address(self, owner, cur=None):\n        \"\"\"\n        Get the list of subdomain names that are owned by a given address.\n        \"\"\"\n        get_cmd = \"SELECT fully_qualified_subdomain, MAX(sequence) FROM {} WHERE owner = ? AND accepted=1 GROUP BY fully_qualified_subdomain\".format(self.subdomain_table)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (owner,))\n\n        try:\n            return [ x['fully_qualified_subdomain'] for x in cursor.fetchall() ]\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the last - knwon resolver entry for a domain name. Returns None if not found.", "response": "def get_domain_resolver(self, domain_name, cur=None):\n        \"\"\"\n        Get the last-knwon resolver entry for a domain name\n        Returns None if not found.\n        \"\"\"\n        get_cmd = \"SELECT resolver FROM {} WHERE domain=? AND resolver != '' AND accepted=1 ORDER BY sequence DESC, parent_zonefile_index DESC LIMIT 1;\".format(self.subdomain_table)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, get_cmd, (domain_name,))\n\n        rowdata = cursor.fetchone()\n        if not rowdata:\n            return None\n\n        return rowdata['resolver']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_subdomain_DID_info(self, fqn, cur=None):\n        subrec = self.get_subdomain_entry_at_sequence(fqn, 0, cur=cur)\n        cmd = 'SELECT zonefile_offset FROM {} WHERE fully_qualified_subdomain = ? AND owner = ? AND sequence=0 AND parent_zonefile_index <= ? AND accepted=1 ORDER BY parent_zonefile_index, zonefile_offset LIMIT 1;'.format(self.subdomain_table)\n        args = (fqn, subrec.address, subrec.parent_zonefile_index)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        rows = db_query_execute(cursor, cmd, args)\n        \n        zonefile_offset = None\n        for r in rows:\n            zonefile_offset = r['zonefile_offset']\n            break\n\n        if zonefile_offset is None:\n            raise SubdomainNotFound('No rows for {}'.format(fqn))\n\n        cmd = 'SELECT COUNT(*) FROM {} WHERE owner = ? AND sequence=0 AND (parent_zonefile_index < ? OR parent_zonefile_index = ? AND zonefile_offset < ?) AND accepted=1 ORDER BY parent_zonefile_index, zonefile_offset LIMIT 1;'.format(self.subdomain_table)\n        args = (subrec.address, subrec.parent_zonefile_index, subrec.parent_zonefile_index, zonefile_offset)\n\n        rows = db_query_execute(cursor, cmd, args)\n        count = None\n        for r in rows:\n            count = r['COUNT(*)']\n            break\n\n        if count is None:\n            raise SubdomainNotFound('No rows for {}'.format(fqn))\n\n        return {'name_type': 'subdomain', 'address': subrec.address, 'index': count}", "response": "Get the DID information for a subdomain. Raise SubdomainNotFound If there is no such subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_DID_subdomain(self, did, cur=None):\n        did = str(did)\n\n        try:\n            did_info = parse_DID(did)\n            assert did_info['name_type'] == 'subdomain', 'Not a subdomain DID'\n        except:\n            raise ValueError(\"Invalid DID: {}\".format(did))\n        \n        original_address = did_info['address']\n        name_index = did_info['index']\n\n        # find the initial subdomain (the nth subdomain created by this address)\n        cmd = 'SELECT fully_qualified_subdomain FROM {} WHERE owner = ? AND sequence = ? ORDER BY parent_zonefile_index, zonefile_offset LIMIT 1 OFFSET ?;'.format(self.subdomain_table)\n        args = (original_address, 0, name_index)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        subdomain_name = None\n\n        rows = db_query_execute(cursor, cmd, args)\n        for r in rows:\n            subdomain_name = r['fully_qualified_subdomain']\n            break\n\n        if not subdomain_name:\n            raise SubdomainNotFound('Does not correspond to a subdomain: {}'.format(did))\n\n        # get the current form\n        subrec = self.get_subdomain_entry(subdomain_name, cur=cur)\n        subrec.did_info = did_info\n        return subrec", "response": "Get a subdomain given its DID Raise SubdomainNotFound if the DID does not correspond to a subdomain"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if this zone file hash belongs to this subdomain.", "response": "def is_subdomain_zonefile_hash(self, fqn, zonefile_hash, cur=None):\n        \"\"\"\n        Does this zone file hash belong to this subdomain?\n        \"\"\"\n        sql = 'SELECT COUNT(zonefile_hash) FROM {} WHERE fully_qualified_subdomain = ? and zonefile_hash = ?;'.format(self.subdomain_table)\n        args = (fqn,zonefile_hash)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        rows = db_query_execute(cursor, sql, args)\n        \n        count = None\n        for row in rows:\n            count = row['COUNT(zonefile_hash)']\n            break\n\n        return (count > 0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_subdomain_history(self, fqn, start_sequence=None, end_sequence=None, start_zonefile_index=None, end_zonefile_index=None, include_unaccepted=False, offset=None, count=None, cur=None):\n        sql = 'SELECT * FROM {} WHERE fully_qualified_subdomain = ? {} {} {} {} {} ORDER BY parent_zonefile_index ASC'.format(\n                self.subdomain_table,\n                'AND accepted=1' if not include_unaccepted else '',\n                'AND parent_zonefile_index >= ?' if start_zonefile_index is not None else '',\n                'AND parent_zonefile_index < ?' if end_zonefile_index is not None else '',\n                'AND sequence >= ?' if start_sequence is not None else '',\n                'AND sequence < ?' if end_sequence is not None else '')\n\n        args = (fqn,)\n        if start_zonefile_index is not None:\n            args += (start_zonefile_index,)\n\n        if end_zonefile_index is not None:\n            args += (end_zonefile_index,)\n\n        if start_sequence is not None:\n            args += (start_sequence,)\n\n        if end_sequence is not None:\n            args += (end_sequence,)\n        \n        if count is not None:\n            sql += ' LIMIT ?'\n            args += (count,)\n        \n        if offset is not None:\n            sql += ' OFFSET ?'\n            args += (offset,)    \n        \n        sql += ';'\n\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        rowcursor = db_query_execute(cursor, sql, args)\n\n        rows = []\n        for rowdata in rowcursor:\n            # want subdomain rec\n            subrec = self._extract_subdomain(rowdata)\n            rows.append(subrec)\n        \n        return rows", "response": "Get the history of a subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the subdomain entry in the history table for this subdomain entry.", "response": "def update_subdomain_entry(self, subdomain_obj, cur=None):\n        \"\"\"\n        Update the subdomain history table for this subdomain entry.\n        Creates it if it doesn't exist.\n\n        Return True on success\n        Raise exception on error\n        \"\"\"\n        # sanity checks\n        assert isinstance(subdomain_obj, Subdomain)\n       \n        # NOTE: there is no need to call fsync() on the zone file fd here---we already have the data from the on-chain name's zone file fsync'ed,\n        # so this information is already durable (albeit somewhere else) and can ostensibly be restored later.\n        # We get such high subdomain traffic that we cannot call fsync() here each time; otherwise we could stall the node.\n        zonefile_hash = get_zonefile_data_hash(subdomain_obj.zonefile_str)\n        rc = store_atlas_zonefile_data(subdomain_obj.zonefile_str, self.zonefiles_dir, fsync=False)\n        if not rc:\n            raise Exception(\"Failed to store zone file {} from {}\".format(zonefile_hash, subdomain_obj.get_fqn()))\n        \n        write_cmd = 'INSERT OR REPLACE INTO {} VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)'.format(self.subdomain_table)\n        args = (subdomain_obj.get_fqn(), subdomain_obj.domain, subdomain_obj.n, subdomain_obj.address, zonefile_hash,\n                subdomain_obj.sig, subdomain_obj.block_height, subdomain_obj.parent_zonefile_hash,\n                subdomain_obj.parent_zonefile_index, subdomain_obj.zonefile_offset, subdomain_obj.txid, \n                ','.join(str(i) for i in subdomain_obj.domain_zonefiles_missing),\n                1 if subdomain_obj.accepted else 0,\n                subdomain_obj.resolver)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, write_cmd, args)\n        num_rows_written = cursor.rowcount\n        \n        if cur is None:\n            # not part of a transaction\n            self.conn.commit()\n\n        if num_rows_written != 1:\n            raise ValueError(\"No row written: fqn={} seq={}\".format(subdomain_obj.get_fqn(), subdomain_obj.n))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subdomain_check_pending(self, subrec, atlasdb_path, cur=None):\n        _, _, domain = is_address_subdomain(subrec.get_fqn())\n        sql = 'SELECT missing FROM {} WHERE domain = ? ORDER BY parent_zonefile_index DESC LIMIT 1;'.format(self.subdomain_table)\n        args = (domain,)\n\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor= cur\n\n        rows = db_query_execute(cursor, sql, args)\n        missing_str = \"\"\n        try:\n            rowdata = rows.fetchone()\n            assert rowdata\n            missing_str = rowdata['missing']\n        except:\n            pass\n\n        known_missing = [int(i) for i in missing_str.split(',')] if missing_str is not None and len(missing_str) > 0 else []\n        num_missing = atlasdb_get_zonefiles_missing_count_by_name(domain, indexes_exclude=known_missing, path=atlasdb_path)\n        if num_missing > 0:\n            log.debug(\"Subdomain is missing {} zone files: {}\".format(num_missing, subrec))\n\n        return num_missing > 0", "response": "Determine whether or not a subdomain record s domain is missing zone files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_last_block(self, cur=None):\n        sql = 'SELECT MAX(block_height) FROM {};'.format(self.subdomain_table)\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        rows = db_query_execute(cursor, sql, ())\n        height = 0\n        try:\n            rowdata = rows.fetchone()\n            height = rowdata['MAX(block_height)']\n        except:\n            height = 0\n\n        return height", "response": "Get the highest block last processed by the subdomain table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_last_sequence(self, cur=None):\n        sql = 'SELECT sequence FROM {} ORDER BY sequence DESC LIMIT 1;'.format(self.subdomain_table)\n        cursor = None\n        if cur is None:\n            cursor = self.conn.cursor()\n        else:\n            cursor = cur\n\n        db_query_execute(cursor, sql, ())\n        last_seq = None\n        try:\n            last_seq = cursor.fetchone()[0]\n        except:\n            last_seq = 0\n        \n        return int(last_seq)", "response": "Get the highest sequence number in this db"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _drop_tables(self):\n        drop_cmd = \"DROP TABLE IF EXISTS {};\"\n        for table in [self.subdomain_table, self.blocked_table]:\n            cursor = self.conn.cursor()\n            db_query_execute(cursor, drop_cmd.format(table), ())", "response": "Clear the subdomain db s tables\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the tables in the subdomain db.", "response": "def _create_tables(self):\n        \"\"\"\n        Set up the subdomain db's tables\n        \"\"\"\n        cursor = self.conn.cursor()\n\n        create_cmd = \"\"\"CREATE TABLE IF NOT EXISTS {} (\n        fully_qualified_subdomain TEXT NOT NULL,\n        domain TEXT NOT NULL,\n        sequence INTEGER NOT NULL,\n        owner TEXT NOT NULL,\n        zonefile_hash TEXT NOT NULL,\n        signature TEXT NOT NULL,\n        block_height INTEGER NOT NULL,\n        parent_zonefile_hash TEXT NOT NULL,\n        parent_zonefile_index INTEGER NOT NULL,\n        zonefile_offset INTEGER NOT NULL,\n        txid TEXT NOT NULL,\n        missing TEXT NOT NULL,\n        accepted INTEGER NOT NULL,\n        resolver TEXT,\n        PRIMARY KEY(fully_qualified_subdomain,parent_zonefile_index));\n        \"\"\".format(self.subdomain_table)\n        db_query_execute(cursor, create_cmd, ())\n\n        # set up a queue as well\n        queue_con = queuedb_open(self.queue_path)\n        queue_con.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the hash over a name and hex - string script pubkey.", "response": "def hash_name(name, script_pubkey, register_addr=None):\n   \"\"\"\n   Generate the hash over a name and hex-string script pubkey\n   \"\"\"\n   bin_name = b40_to_bin(name)\n   name_and_pubkey = bin_name + unhexlify(script_pubkey)\n   \n   if register_addr is not None:\n       name_and_pubkey += str(register_addr)\n\n   return hex_hash160(name_and_pubkey)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_profile_data_from_file():\n    with open(SEARCH_PROFILE_DATA_FILE, 'r') as fin:\n        profiles = json.load(fin)\n\n    counter = 0\n\n    log.debug(\"-\" * 5)\n    log.debug(\"Fetching profile data from file\")\n\n    for entry in profiles:\n        new_entry = {}\n        new_entry['key'] = entry['fqu']\n        new_entry['value'] = entry['profile']\n\n        try:\n            clean_profile_entries(entry['profile'])\n            profile_data.save(new_entry)\n        except Exception as e:\n            log.exception(e)\n            log.error(\"Exception on entry {}\".format(new_entry))\n\n        counter += 1\n\n        if counter % 1000 == 0:\n            log.debug(\"Processed entries: %s\" % counter)\n\n    profile_data.ensure_index('key')\n\n    return", "response": "takes profile data from file and saves in the profile_data DB\nCTYPE"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a search index for the given user.", "response": "def create_search_index():\n    \"\"\" takes people names from blockchain and writes deduped names in a 'cache'\n    \"\"\"\n\n    # create people name cache\n    counter = 0\n\n    people_names = []\n    twitter_handles = []\n    usernames = []\n\n    log.debug(\"-\" * 5)\n    log.debug(\"Creating search index\")\n\n    for user in namespace.find():\n        # the profile/info to be inserted\n        search_profile = {}\n\n        counter += 1\n\n        if(counter % 1000 == 0):\n            log.debug(\"Processed entries: %s\" % counter)\n\n        if validUsername(user['username']):\n            pass\n        else:\n            continue\n\n        profile = get_json(user['profile'])\n\n\n        hasBazaarId=False\n        # search for openbazaar id in the profile\n        if 'account' in profile:\n            for accounts in profile['account']:\n                if  accounts['service'] == 'openbazaar':\n                   hasBazaarId = True\n                   search_profile['openbazaar']=accounts['identifier']\n\n        if (hasBazaarId == False):\n            search_profile['openbazaar'] = None\n\n        if 'name' in profile:\n            try:\n                name = profile['name']\n            except:\n                continue\n\n            try:\n                name = name['formatted'].lower()\n            except:\n                name = name.lower()\n            people_names.append(name)\n            search_profile['name'] = name\n\n        else:\n            search_profile['name'] = None\n\n        if 'twitter' in profile:\n            twitter_handle = profile['twitter']\n\n            try:\n                twitter_handle = twitter_handle['username'].lower()\n            except:\n                try:\n                    twitter_handle = profile['twitter'].lower()\n                except:\n                    continue\n\n            twitter_handles.append(twitter_handle)\n            search_profile['twitter_handle'] = twitter_handle\n\n        else:\n            search_profile['twitter_handle'] = None\n\n        search_profile['fullyQualifiedName'] = user['fqu']\n        search_profile['username'] = user['username']\n        usernames.append(user['fqu'])\n\n        search_profile['profile'] = profile\n        search_profiles.save(search_profile)\n\n\n    # dedup names\n    people_names = list(set(people_names))\n    people_names = {'name': people_names}\n\n    twitter_handles = list(set(twitter_handles))\n    twitter_handles = {'twitter_handle': twitter_handles}\n\n    usernames = list(set(usernames))\n    usernames = {'username': usernames}\n\n    # save final dedup results to mongodb (using it as a cache)\n    people_cache.save(people_names)\n    twitter_cache.save(twitter_handles)\n    username_cache.save(usernames)\n\n    optimize_db()\n\n    log.debug('Created name/twitter/username search index')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef op_extract(op_name, data, senders, inputs, outputs, block_id, vtxindex, txid):\n    global EXTRACT_METHODS\n\n    if op_name not in EXTRACT_METHODS.keys():\n        raise Exception(\"No such operation '%s'\" % op_name)\n\n    method = EXTRACT_METHODS[op_name]\n    op_data = method( data, senders, inputs, outputs, block_id, vtxindex, txid )\n    return op_data", "response": "Extract an operation from transaction data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef op_canonicalize(op_name, parsed_op):\n    global CANONICALIZE_METHODS\n\n    if op_name not in CANONICALIZE_METHODS:\n        # no canonicalization needed\n        return parsed_op\n    else:\n        return CANONICALIZE_METHODS[op_name](parsed_op)", "response": "Returns the canonical representation of a parsed operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the current representation of a parsed operation's data, given the canonical representation Meant for backwards-compatibility", "response": "def op_decanonicalize(op_name, canonical_op):\n    \"\"\"\n    Get the current representation of a parsed operation's data, given the canonical representation\n    Meant for backwards-compatibility\n    \"\"\"\n    global DECANONICALIZE_METHODS\n\n    if op_name not in DECANONICALIZE_METHODS:\n        # no decanonicalization needed\n        return canonical_op\n    else:\n        return DECANONICALIZE_METHODS[op_name](canonical_op)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef op_canonicalize_quirks(op_name, new_record, current_record):\n    ret = {}\n    ret.update(new_record)\n\n    if op_name in OPCODE_NAME_NAMEOPS and op_name in OPCODE_NAME_STATE_TRANSITIONS:\n        # nameop state transition.  Need to ensure the op_fee is in the right format.\n        # depends on what created it\n        if op_name != 'NAME_IMPORT':\n            # this is some other state transition besides an import.  A prior record must exist.\n            assert current_record\n        \n        if current_record:\n            for f in ['op_fee', 'last_creation_op']:\n                assert f in current_record, 'BUG: missing {} for existing {}'.format(f, op_name)\n\n        # extract quirky values\n        quirk_values = {}\n        for f in ['op_fee', 'last_creation_op']:\n            # get the quirky field, favoring the new record's value over the current record\n            val = new_record.get(f)\n            if val is None and current_record is not None:\n                val = current_record.get(f)\n            \n            assert val is not None, 'Neither new record nor current record has a value for \"{}\"'.format(f)\n            quirk_values[f] = val\n\n        # QUIRK: NAME_IMPORT-created ops need a float(op_fee).  Everyone else just takes it as it is.\n        assert quirk_values['op_fee'] is not None, 'BUG: no op_fee carried over'\n        if quirk_values['last_creation_op'] == NAME_IMPORT:\n            quirk_values['op_fee'] = float(quirk_values['op_fee'])\n        else:\n            quirk_values['op_fee'] = int(quirk_values['op_fee'])\n\n        ret['op_fee'] = quirk_values['op_fee']\n\n        # QUIRK: preserve last_creation_op across records\n        ret['last_creation_op'] = quirk_values['last_creation_op']\n\n    if 'token_fee' in ret and isinstance(ret['token_fee'], (int,long)):\n        ret['token_fee'] = '{}'.format(ret['token_fee'])\n\n    return ret", "response": "This method replaces any quirks that are not part of the canonicalized nameop data with the ones that are not already in the canonicalized nameop data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef op_check( state_engine, nameop, block_id, checked_ops ):\n    global CHECK_METHODS, MUTATE_FIELDS\n\n    nameop_clone = copy.deepcopy( nameop )\n    opcode = None\n\n    if 'opcode' not in nameop_clone.keys():\n        op = nameop_clone.get('op', None)\n        try:\n            assert op is not None, \"BUG: no op defined\"\n            opcode = op_get_opcode_name( op )\n            assert opcode is not None, \"BUG: op '%s' undefined\" % op\n        except Exception, e:\n            log.exception(e)\n            log.error(\"FATAL: BUG: no 'op' defined\")\n            sys.exit(1)\n\n    else:\n        opcode = nameop_clone['opcode']\n\n    check_method = CHECK_METHODS.get( opcode, None )\n    try:\n        assert check_method is not None, \"BUG: no check-method for '%s'\" % opcode\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: BUG: no check-method for '%s'\" % opcode )\n        sys.exit(1)\n\n    rc = check_method( state_engine, nameop_clone, block_id, checked_ops )\n    if not rc:\n        # rejected\n        return False\n\n    # accepted! clean up and canonicalize\n    nameop.clear()\n    nameop.update(nameop_clone)\n\n    # nameop = op_canonicalize(nameop['opcode'], nameop)\n    op_canonicalize(nameop['opcode'], nameop)\n\n    # make sure we don't send unstored fields to the db that are otherwise canonical\n    unstored_canonical_fields = UNSTORED_CANONICAL_FIELDS.get(nameop['opcode'])\n    assert unstored_canonical_fields is not None, \"BUG: no UNSTORED_CANONICAL_FIELDS entry for {}\".format(nameop['opcode'])\n\n    for f in unstored_canonical_fields:\n        if f in nameop:\n            del nameop[f]\n\n    return rc", "response": "Checks if the current operation is accepted by the state engine."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the names of the fields that will be mutated when this operation gets applied to a record.", "response": "def op_get_mutate_fields( op_name ):\n    \"\"\"\n    Get the names of the fields that will change\n    when this operation gets applied to a record.\n    \"\"\"\n    global MUTATE_FIELDS\n\n    if op_name not in MUTATE_FIELDS.keys():\n        raise Exception(\"No such operation '%s'\" % op_name)\n\n    fields = MUTATE_FIELDS[op_name][:]\n    return fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef op_get_consensus_fields( op_name ):\n    global SERIALIZE_FIELDS\n    \n    if op_name not in SERIALIZE_FIELDS.keys():\n        raise Exception(\"No such operation '%s'\" % op_name )\n\n    fields = SERIALIZE_FIELDS[op_name][:]\n    return fields", "response": "Get the set of consensus - generating fields for an operation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking validity of an update to a name s associated data.", "response": "def check(state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify the validity of an update to a name's associated data.\n    Use the nameop's 128-bit name hash to find the name itself.\n\n    NAME_UPDATE isn't allowed during an import, so the name's namespace must be ready.\n\n    Return True if accepted\n    Return False if not.\n    \"\"\"\n\n    name_consensus_hash = nameop['name_consensus_hash']\n    sender = nameop['sender']\n\n    # deny updates if we exceed quota--the only legal operations are to revoke or transfer.\n    sender_names = state_engine.get_names_owned_by_sender( sender )\n    if len(sender_names) > MAX_NAMES_PER_SENDER:\n        log.warning(\"Sender '%s' has exceeded quota: only transfers or revokes are allowed\" % (sender))\n        return False\n\n    name, consensus_hash = state_engine.get_name_from_name_consensus_hash( name_consensus_hash, sender, block_id )\n\n    # name must exist\n    if name is None or consensus_hash is None:\n        log.warning(\"Unable to resolve name consensus hash '%s' to a name owned by '%s'\" % (name_consensus_hash, sender))\n        # nothing to do--write is stale or on a fork\n        return False\n\n    namespace_id = get_namespace_from_name( name )\n    name_rec = state_engine.get_name( name )\n\n    if name_rec is None:\n        log.warning(\"Name '%s' does not exist\" % name)\n        return False\n\n    # namespace must be ready\n    if not state_engine.is_namespace_ready( namespace_id ):\n        # non-existent namespace\n        log.warning(\"Namespace '%s' is not ready\" % (namespace_id))\n        return False\n\n    # name must not be revoked\n    if state_engine.is_name_revoked( name ):\n        log.warning(\"Name '%s' is revoked\" % name)\n        return False\n\n    # name must not be expired as of the *last block processed*\n    if state_engine.is_name_expired( name, state_engine.lastblock ):\n        log.warning(\"Name '%s' is expired\" % name)\n        return False\n\n    # name must not be in grace period in *this* block \n    if state_engine.is_name_in_grace_period(name, block_id):\n        log.warning(\"Name '{}' is in the renewal grace period.  It can only be renewed at this time.\".format(name))\n        return False\n\n    # the name must be registered\n    if not state_engine.is_name_registered( name ):\n        # doesn't exist\n        log.warning(\"Name '%s' is not registered\" % name )\n        return False\n\n    # the name must be owned by the same person who sent this nameop\n    if not state_engine.is_name_owner( name, sender ):\n        # wrong owner\n        log.warning(\"Name '%s' is not owned by '%s'\" % (name, sender))\n        return False\n\n    # remember the name and consensus hash, so we don't have to re-calculate it...\n    nameop['name'] = name\n    nameop['consensus_hash'] = consensus_hash\n    nameop['sender_pubkey'] = name_rec['sender_pubkey']\n\n    # not stored, but re-calculateable\n    del nameop['name_consensus_hash']\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(bin_payload):\n    \n    if len(bin_payload) != LENGTHS['name_consensus_hash'] + LENGTHS['value_hash']:\n        log.error(\"Invalid update length %s\" % len(bin_payload))\n        return None \n\n    name_consensus_hash_bin = bin_payload[:LENGTHS['name_consensus_hash']]\n    value_hash_bin = bin_payload[LENGTHS['name_consensus_hash']:]\n    \n    name_consensus_hash = hexlify( name_consensus_hash_bin )\n    value_hash = hexlify( value_hash_bin )\n  \n    try:\n        rc = update_sanity_test( None, name_consensus_hash, value_hash )\n        if not rc:\n            raise Exception(\"Invalid update data\")\n    except Exception, e:\n        log.error(\"Invalid update data\")\n        return None\n\n    return {\n        'opcode': 'NAME_UPDATE',\n        'name_consensus_hash': name_consensus_hash,\n        'value_hash': value_hash\n    }", "response": "Parse a binary update into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check( state_engine, token_op, block_id, checked_ops ):\n\n    epoch_features = get_epoch_features(block_id)\n    if EPOCH_FEATURE_TOKEN_TRANSFER not in epoch_features:\n        log.warning(\"Token transfers are not enabled in this epoch\")\n        return False\n\n    consensus_hash = token_op['consensus_hash']\n    address = token_op['address']\n    recipient_address = token_op['recipient_address']\n    token_type = token_op['token_units']\n    token_value = token_op['token_fee']\n\n    # token value must be positive\n    if token_value <= 0:\n        log.warning(\"Zero-value token transfer from {}\".format(address))\n        return False\n\n    # can't send to ourselves \n    if address == recipient_address:\n        log.warning('Cannot transfer token from the account to itself ({})'.format(address))\n        return False\n\n    # consensus hash must be valid\n    if not state_engine.is_consensus_hash_valid(block_id, consensus_hash):\n        log.warning('Invalid consensus hash {}'.format(consensus_hash))\n        return False\n\n    # sender account must exist\n    account_info = state_engine.get_account(address, token_type)\n    if account_info is None:\n        log.warning(\"No account for {} ({})\".format(address, token_type))\n        return False\n\n    # sender must not be transfer-locked\n    if block_id < account_info['lock_transfer_block_id']:\n        log.warning('Account {} is blocked from transferring tokens until block height {}'.format(address, account_info['lock_transfer_block_id']))\n        return False\n\n    # sender must have enough balance of the token  \n    account_balance = state_engine.get_account_balance(account_info)\n    if account_balance < token_value:\n        log.warning('Account {} has {} {}; tried to send {}'.format(address, account_balance, token_type, token_value))\n        return False\n    \n    receiver_account = state_engine.get_account(recipient_address, token_type)\n    if receiver_account is not None:\n        if not receiver_account['receive_whitelisted']:\n            log.warning('Receiver account {} is not whitelisted'.format(recipient_address))\n            return False\n\n    log.debug(\"Account {} will pay {} {} to {}\".format(address, token_value, token_type, recipient_address))\n\n    # will execute a debit against the sender address\n    token_operation_put_account_payment_info(token_op, address, token_type, token_value)\n\n    # will execute a credit against the receiver address \n    token_operation_put_account_credit_info(token_op, recipient_address, token_type, token_value)\n\n    # preserve token_fee as a string to prevent overflow\n    token_op['token_fee'] = '{}'.format(token_op['token_fee'])\n    return True", "response": "Verify that a token transfer operation is permitted."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts and return a dict of fields from the underlying blockchain transaction data.", "response": "def tx_extract(payload, senders, inputs, outputs, block_id, vtxindex, txid):\n    \"\"\"\n    Extract and return a dict of fields from the underlying blockchain transaction data\n    that are useful to this operation.\n\n    structure:\n    inputs                                | outputs\n    ------------------------------------------------------------------------------\n    sender scriptsig + scriptPubkey       | OP_RETURN with token transfer payload\n    ------------------------------------------------------------------------------\n                                          | recipient script (DUST_MINIMUM)\n                                          ----------------------------------------\n                                          | sender's change address\n\n    The recipient script identifies the recipient address.  This is its own output\n    to ensure that the underlying blockchain can and will enforce signatures from\n    the recipient on future spend transactions.  Also, it makes it straightforward\n    to track blockstack transactions in existing block explorers.\n\n    Any other inputs and outputs are allowed.\n    \"\"\"\n  \n    sender_script = None\n    sender_address = None\n\n    recipient_script = None\n    recipient_address = None\n\n    try:\n        # first two outputs matter to us\n        assert check_tx_output_types(outputs[:2], block_id)\n\n        assert len(senders) > 0\n        assert 'script_pubkey' in senders[0].keys()\n        assert 'addresses' in senders[0].keys()\n\n        sender_script = str(senders[0]['script_pubkey'])\n        sender_address = str(senders[0]['addresses'][0])\n\n        assert sender_script is not None\n        assert sender_address is not None\n\n        recipient_script = get_token_transfer_recipient_from_outputs(outputs)\n        recipient_address = virtualchain.script_hex_to_address(recipient_script)\n\n        assert recipient_script is not None\n        assert recipient_address is not None\n\n    except Exception, e:\n        log.exception(e)\n        raise Exception(\"Failed to extract\")\n\n    parsed_payload = parse(payload, block_id)\n    assert parsed_payload is not None \n   \n    ret = {}\n    ret.update(parsed_payload)\n    ret.update({\n        'address': sender_address,\n        'sender': sender_script,\n        'recipient_address': recipient_address,\n        'recipient': recipient_script,\n        'op': TOKEN_TRANSFER,\n        'block_id': block_id,\n        'txid': txid,\n        'vtxindex': vtxindex\n    })\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a binary token transfer into a single node record.", "response": "def parse(bin_payload, block_height):\n    \"\"\"\n    Parse a token transfer\n    NOTE: bin_payload *excludes* the leading 3 bytes (magic + op) returned by build.\n\n    Record format:\n   \n    0     2  3              19         38          46                        80\n    |-----|--|--------------|----------|-----------|-------------------------|\n    magic op  consensus_hash token_type amount (BE) scratch area\n                             (ns_id)\n\n    Returns a parsed payload on success\n    Returns None on error\n    \"\"\"\n    \n    epoch_features = get_epoch_features(block_height)\n    if EPOCH_FEATURE_TOKEN_TRANSFER not in epoch_features:\n        log.warning(\"Token transfers are not enabled in this epoch\")\n        return None\n\n    if len(bin_payload) < LENGTHS['consensus_hash'] + LENGTHS['namespace_id'] + LENGTHS['tokens_burnt']:\n        log.warning('Invalid payload {}: expected at least {} bytes'.format(bin_payload.encode('hex'), LENGTHS['consensus_hash'] + LENGTHS['namespace_id'] + LENGTHS['tokens_burnt']))\n        return None\n\n    consensus_hash = bin_payload[0: LENGTHS['consensus_hash']].encode('hex')\n    token_type = bin_payload[LENGTHS['consensus_hash']: LENGTHS['consensus_hash'] + LENGTHS['namespace_id']]\n    amount_str = bin_payload[LENGTHS['consensus_hash'] + LENGTHS['namespace_id']: LENGTHS['consensus_hash'] + LENGTHS['namespace_id'] + LENGTHS['tokens_burnt']].encode('hex')\n    scratch_area = bin_payload[LENGTHS['consensus_hash'] + LENGTHS['namespace_id'] + LENGTHS['tokens_burnt']: ].encode('hex')\n\n    tokens_sent = int(amount_str, 16)\n    token_units = token_type.strip('\\x00')\n\n    return {\n        'opcode': 'TOKEN_TRANSFER',\n        'consensus_hash': consensus_hash,\n        'token_units': token_units,\n        'token_fee': tokens_sent,\n        'scratch_area': scratch_area\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naugments the given list of genesis block stages with the authenticity of the given set of keys.", "response": "def genesis_block_audit(genesis_block_stages, key_bundle=GENESIS_BLOCK_SIGNING_KEYS):\n    \"\"\"\n    Verify the authenticity of the stages of the genesis block, optionally with a given set of keys.\n    Return True if valid\n    Return False if not\n    \"\"\"\n    gpg2_path = find_gpg2()\n    if gpg2_path is None:\n        raise Exception('You must install gpg2 to audit the genesis block, and it must be in your PATH')\n\n    log.debug('Loading {} signing key(s)...'.format(len(key_bundle)))\n    res = load_signing_keys(gpg2_path, [key_bundle[kid] for kid in key_bundle])\n    if not res:\n        raise Exception('Failed to install signing keys')\n\n    log.debug('Verifying {} signing key(s)...'.format(len(key_bundle)))\n    res = check_gpg2_keys(gpg2_path, key_bundle.keys())\n    if not res:\n        raise Exception('Failed to verify installation of signing keys')\n\n    d = tempfile.mkdtemp(prefix='.genesis-block-audit-')\n\n    # each entry in genesis_block_stages is a genesis block with its own history \n    for stage_id, stage in enumerate(genesis_block_stages):\n        log.debug('Verify stage {}'.format(stage_id))\n\n        try:\n            jsonschema.validate(GENESIS_BLOCK_SCHEMA, stage)\n        except jsonschema.ValidationError:\n            shutil.rmtree(d)\n            log.error('Invalid genesis block -- does not match schema')\n            raise ValueError('Invalid genesis block')\n\n        # all history rows must be signed with a trusted key\n        for history_id, history_row in enumerate(stage['history']):\n            with open(os.path.join(d, 'sig'), 'w') as f:\n                f.write(history_row['signature'])\n            with open(os.path.join(d, 'hash'), 'w') as f:\n                f.write(history_row['hash'])\n\n            p = subprocess.Popen([gpg2_path, '--verify', os.path.join(d,'sig'), os.path.join(d,'hash')], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            out, err = p.communicate()\n            if p.returncode != 0:\n                log.error('Failed to verify stage {} history {}'.format(stage_id, history_id))\n                shutil.rmtree(d)\n                return False\n\n        gb_rows_str = json.dumps(stage['rows'], sort_keys=True, separators=(',',':')) + '\\n'\n        gb_rows_hash = hashlib.sha256(gb_rows_str).hexdigest()\n\n        # must match final history row \n        if gb_rows_hash != stage['history'][-1]['hash']:\n            log.error('Genesis block stage {} hash mismatch: {} != {}'.format(stage_id, gb_rows_hash, stage['history'][-1]['hash']))\n            shutil.rmtree(d)\n            return False\n\n    shutil.rmtree(d)\n    log.info('Genesis block is legitimate')\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch proofs for a profile", "response": "def fetch_proofs(profile, username, address, profile_ver=2, zonefile = None):\n    \"\"\" Get proofs for a profile and:\n        a) check cached entries\n        b) check which version of profile we're using\n    \"\"\"\n\n    if 'account' not in profile:\n        return []\n    # fix up missing proofUrls\n    for account in profile['account']:\n        if ('proofType' in account and account['proofType'] == 'http'\n            and 'proofUrl' not in account):\n            site_data_to_fixed_proof_url(account, zonefile)\n\n    if profile_ver == 3:\n        proofs = profile_v3_to_proofs(profile, username, address = address)\n    else:\n        proofs = profile_to_proofs(profile, username, address = address)\n\n    return proofs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nis a given profile JSON object in legacy format?", "response": "def is_profile_in_legacy_format(profile):\n    \"\"\"\n    Is a given profile JSON object in legacy format?\n    \"\"\"\n    if isinstance(profile, dict):\n        pass\n    elif isinstance(profile, (str, unicode)):\n        try:\n            profile = json.loads(profile)\n        except ValueError:\n            return False\n    else:\n        return False\n\n    if \"@type\" in profile:\n        return False\n\n    if \"@context\" in profile:\n        return False\n\n    is_in_legacy_format = False\n\n    if \"avatar\" in profile:\n        is_in_legacy_format = True\n    elif \"cover\" in profile:\n        is_in_legacy_format = True\n    elif \"bio\" in profile:\n        is_in_legacy_format = True\n    elif \"twitter\" in profile:\n        is_in_legacy_format = True\n    elif \"facebook\" in profile:\n        is_in_legacy_format = True\n\n    return is_in_legacy_format"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_profile(profile, fqa, zone_file, address, public_key):\n    \n    # if the zone file is a string, then parse it \n    if isinstance(zone_file, (str,unicode)):\n        try:\n            zone_file = blockstack_zones.parse_zone_file(zone_file)\n        except:\n            # leave as text\n            pass\n\n    data = {'profile' : profile,\n            'zone_file' : zone_file,\n            'public_key': public_key,\n            'owner_address' : address}\n\n    if not fqa.endswith('.id'):\n        data['verifications'] = [\"No verifications for non-id namespaces.\"]\n        return data\n\n    profile_in_legacy_format = is_profile_in_legacy_format(profile)\n\n    if not profile_in_legacy_format:\n        data['verifications'] = fetch_proofs(data['profile'], fqa, address,\n                                             profile_ver=3, zonefile=zone_file)\n    else:\n        if type(profile) is not dict:\n            data['profile'] = json.loads(profile)\n        data['verifications'] = fetch_proofs(data['profile'], fqa, address)\n\n    return data", "response": "Process the profile data and insert verifications into the navigable list of blockstack objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_profile(fqa):\n\n    profile_expired_grace = False\n\n    fqa = fqa.lower()\n\n    try:\n        try:\n            res = blockstack.lib.client.resolve_profile(\n                    fqa, include_name_record=True, hostport=blockstack_indexer_url)\n        except ValueError:\n            # invalid name \n            res = {'error': 'Invalid name', 'status_code': 400}\n\n        if 'error' in res:\n            log.error('Error from profile.get_profile: {}'.format(res['error']))\n            if \"no user record hash defined\" in res['error']:\n                res['status_code'] = 404\n            if \"Failed to load user profile\" in res['error']:\n                res['status_code'] = 404\n\n            if res.get('http_status'):\n                # pass along \n                res['status_code'] = res['http_status']\n                del res['http_status']\n\n            return res\n\n        log.warn(json.dumps(res['name_record']))\n\n        profile = res['profile']\n        zonefile = res['zonefile']\n        public_key = res.get('public_key', None)\n        address = res['name_record']['address']\n\n        if 'expired' in res['name_record'] and res['name_record']['expired']:\n            profile_expired_grace = True\n\n    except Exception as e:\n        log.exception(e)\n        abort(500, json.dumps({'error': 'Server error fetching profile'}))\n\n    if profile is None or 'error' in zonefile:\n        log.error(\"{}\".format(zonefile))\n        abort(404)\n\n    prof_data = {'response' : profile}\n\n    data = format_profile(prof_data['response'], fqa, zonefile, address, public_key)\n\n    if profile_expired_grace:\n        data['expired'] = (\n            'This name has expired! It is still in the renewal grace period, ' +\n            'but must be renewed or it will eventually expire and be available' +\n            ' for others to register.')\n\n    return data", "response": "Given a fully - qualified username get the data associated with that username Return cached entries if possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_users(username):\n    reply = {}\n\n    log.debug('Begin /v[x]/users/' + username)\n\n    if username is None:\n        reply['error'] = \"No username given\"\n        return jsonify(reply), 404\n\n    if ',' in username:\n        reply['error'] = 'Multiple username queries are no longer supported.'\n        return jsonify(reply), 401\n\n\n    if \".\" not in username:\n        fqa = \"{}.{}\".format(username, 'id')\n    else:\n        fqa = username\n\n    profile = get_profile(fqa)\n\n    reply[username] = profile\n    if 'error' in profile:\n        status_code = 200\n        if 'status_code' in profile:\n            status_code = profile['status_code']\n            del profile['status_code']\n        return jsonify(reply), status_code\n    else:\n        return jsonify(reply), 200", "response": "Fetch data from username in. id namespace"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nam nameop1 newer than bock_id and vtxindex?", "response": "def is_earlier_than( nameop1, block_id, vtxindex ):\n    \"\"\"\n    Does nameop1 come before bock_id and vtxindex?\n    \"\"\"\n    return nameop1['block_number'] < block_id or (nameop1['block_number'] == block_id and nameop1['vtxindex'] < vtxindex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check( state_engine, nameop, block_id, checked_ops ):\n\n    from ..nameset import BlockstackDB\n\n    name = str(nameop['name'])\n    sender = str(nameop['sender'])\n    sender_pubkey = None\n    recipient = str(nameop['recipient'])\n    recipient_address = str(nameop['recipient_address'])\n\n    preorder_hash = hash_name( nameop['name'], sender, recipient_address )\n    log.debug(\"preorder_hash = %s (%s, %s, %s)\" % (preorder_hash, nameop['name'], sender, recipient_address))\n\n    preorder_block_number = block_id\n    name_block_number = block_id \n    name_first_registered = block_id\n    name_last_renewed = block_id\n    # transfer_send_block_id = None\n\n    if not nameop.has_key('sender_pubkey'):\n        log.warning(\"Name import requires a sender_pubkey (i.e. use of a p2pkh transaction)\")\n        return False\n\n    # name must be well-formed\n    if not is_name_valid( name ):\n        log.warning(\"Malformed name '%s'\" % name)\n        return False\n\n    name_without_namespace = get_name_from_fq_name( name )\n    namespace_id = get_namespace_from_name( name )\n\n    # namespace must be revealed, but not ready\n    if not state_engine.is_namespace_revealed( namespace_id ):\n        log.warning(\"Namespace '%s' is not revealed\" % namespace_id )\n        return False\n\n    namespace = state_engine.get_namespace_reveal( namespace_id )\n\n    # sender p2pkh script must use a public key derived from the namespace revealer's public key\n    sender_pubkey_hex = str(nameop['sender_pubkey'])\n    sender_pubkey = virtualchain.BitcoinPublicKey( str(sender_pubkey_hex) )\n    sender_address = sender_pubkey.address()\n\n    import_addresses = BlockstackDB.load_import_keychain( state_engine.working_dir, namespace['namespace_id'] )\n    if import_addresses is None:\n\n        # the first name imported must be the revealer's address\n        if sender_address != namespace['recipient_address']:\n            log.warning(\"First NAME_IMPORT must come from the namespace revealer's address\")\n            return False\n\n        # need to generate a keyring from the revealer's public key\n        log.warning(\"Generating %s-key keychain for '%s'\" % (NAME_IMPORT_KEYRING_SIZE, namespace_id))\n        import_addresses = BlockstackDB.build_import_keychain( state_engine.working_dir, namespace['namespace_id'], sender_pubkey_hex )\n\n    # sender must be the same as the the person who revealed the namespace\n    # (i.e. sender's address must be from one of the valid import addresses)\n    if sender_address not in import_addresses:\n        log.warning(\"Sender address '%s' is not in the import keychain\" % (sender_address))\n        return False\n\n    # we can overwrite, but emit a warning\n    # search *current* block as well as last block\n    prev_name_rec = get_prev_imported( state_engine, checked_ops, name )\n    if prev_name_rec is not None and is_earlier_than( prev_name_rec, block_id, nameop['vtxindex'] ):\n\n        log.warning(\"Overwriting already-imported name '%s'\" % name)\n\n        # propagate preorder block number and hash...\n        preorder_block_number = prev_name_rec['preorder_block_number']\n        name_block_number = prev_name_rec['block_number']\n        name_first_registered = prev_name_rec['first_registered']\n        name_last_renewed = prev_name_rec['last_renewed']\n\n        log.debug(\"use previous preorder_hash = %s\" % prev_name_rec['preorder_hash'])\n        preorder_hash = prev_name_rec['preorder_hash']\n\n    # can never have been preordered\n    state_create_put_preorder( nameop, None )\n\n    # carry out the transition \n    del nameop['recipient']\n    del nameop['recipient_address']\n\n    # set op_fee for BTC\n    # set token_fee otherwise\n    bitcoin_price = 0\n    stacks_price = 0\n\n    if namespace['version'] == NAMESPACE_VERSION_PAY_WITH_STACKS:\n        # make sure we're in the right epoch \n        epoch_features = get_epoch_features(block_id)\n        if EPOCH_FEATURE_STACKS_BUY_NAMESPACES not in epoch_features or EPOCH_FEATURE_NAMEOPS_COST_TOKENS not in epoch_features:\n            log.fatal('Have a namespace with STACKs enabled, but we\\'re in the wrong epoch!')\n            os.abort()\n\n        stacks_price = price_name(name_without_namespace, namespace, block_id)\n        stacks_price = int(stacks_price)\n\n    else:\n        # QUIRK: keep this as a float due to backwards-compatibility\n        bitcoin_price = price_name(name_without_namespace, namespace, block_id)\n        bitcoin_price = float(bitcoin_price)\n\n    nameop['sender'] = recipient\n    nameop['address'] = recipient_address\n    nameop['importer'] = sender\n    nameop['importer_address'] = sender_address\n    nameop['op_fee'] = bitcoin_price\n    nameop['token_fee'] = '{}'.format(stacks_price)\n    nameop['namespace_block_number'] = namespace['block_number']\n    nameop['consensus_hash'] = None \n    nameop['preorder_hash'] = preorder_hash\n    nameop['block_number'] = name_block_number\n    nameop['first_registered'] = name_first_registered\n    nameop['last_renewed'] = name_last_renewed\n    nameop['preorder_block_number'] = preorder_block_number\n    nameop['opcode'] = \"NAME_IMPORT\"\n\n    # not required for consensus, but for SNV\n    nameop['last_creation_op'] = NAME_IMPORT\n    \n    # good!\n    return True", "response": "Check if a NAME_IMPORT nameop is valid and if so check if it is ready to be imported."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts and return a dict of fields from the underlying blockchain transaction", "response": "def tx_extract( payload, senders, inputs, outputs, block_id, vtxindex, txid ):\n    \"\"\"\n    Extract and return a dict of fields from the underlying blockchain transaction data\n    that are useful to this operation.\n\n    Required (+ parse)\n    sender:  the script_pubkey (as a hex string) of the principal that sent the name import transaction\n    address:  the address from the sender script\n    recipient:  the script_pubkey (as a hex string) of the principal that is meant to receive the name\n    recipient_address:  the address from the recipient script\n    import_update_hash:  the hash of the data belonging to the recipient\n    sender_pubkey_hex: the public key of the sender\n    \"\"\"\n  \n    sender = None \n    sender_address = None \n    sender_pubkey_hex = None\n\n    recipient = None \n    recipient_address = None \n\n    import_update_hash = None\n\n    try:\n       # first three outputs matter to us\n       assert check_tx_output_types(outputs[:3], block_id)\n\n       recipient = get_import_recipient_from_outputs( outputs )\n       recipient_address = virtualchain.script_hex_to_address( recipient )\n\n       assert recipient is not None \n       assert recipient_address is not None\n       \n       import_update_hash = get_import_update_hash_from_outputs( outputs )\n       assert import_update_hash is not None\n       assert is_hex( import_update_hash )\n\n       # by construction, the first input comes from the principal\n       # who sent the registration transaction...\n       assert len(senders) > 0\n       assert 'script_pubkey' in senders[0].keys()\n       assert 'addresses' in senders[0].keys()\n\n       sender = str(senders[0]['script_pubkey'])\n       sender_address = str(senders[0]['addresses'][0])\n\n       assert sender is not None \n       assert sender_address is not None\n\n       if str(senders[0]['script_type']) == 'pubkeyhash':\n          sender_pubkey_hex = get_public_key_hex_from_tx( inputs, sender_address )\n\n    except Exception, e:\n       log.exception(e)\n       raise Exception(\"Failed to extract\")\n\n    parsed_payload = parse( payload, recipient, import_update_hash )\n    assert parsed_payload is not None \n\n    ret = {\n       \"sender\": sender,\n       \"address\": sender_address,\n       \"recipient\": recipient,\n       \"recipient_address\": recipient_address,\n       \"value_hash\": import_update_hash,\n       \"revoked\": False,\n       \"vtxindex\": vtxindex,\n       \"txid\": txid,\n       \"first_registered\": block_id,        # NOTE: will get deleted if this is a re-import\n       \"last_renewed\": block_id,            # NOTE: will get deleted if this is a re-import\n       \"op\": NAME_IMPORT,\n       \"opcode\": \"NAME_IMPORT\"\n    }\n\n    ret.update( parsed_payload )\n\n    if sender_pubkey_hex is not None:\n        ret['sender_pubkey'] = sender_pubkey_hex\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(bin_payload, recipient, update_hash ):\n    \n    fqn = bin_payload\n    if not is_name_valid( fqn ): \n        log.warning(\"Name '%s' is invalid\" % fqn)\n        return None \n\n    return {\n        'opcode': 'NAME_IMPORT',\n        'name': fqn,\n        'recipient': recipient,\n        'value_hash': update_hash\n    }", "response": "Parse the NAME_IMPORT command into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namespacereveal_sanity_check( namespace_id, version, lifetime, coeff, base, bucket_exponents, nonalpha_discount, no_vowel_discount ):\n   # sanity check \n   if not is_b40( namespace_id ) or \"+\" in namespace_id or namespace_id.count(\".\") > 0:\n      raise Exception(\"Namespace ID '%s' has non-base-38 characters\" % namespace_id)\n  \n   if len(namespace_id) > LENGTHS['blockchain_id_namespace_id']:\n      raise Exception(\"Invalid namespace ID length for '%s' (expected length between 1 and %s)\" % (namespace_id, LENGTHS['blockchain_id_namespace_id']))\n    \n   if version not in [NAMESPACE_VERSION_PAY_TO_BURN, NAMESPACE_VERSION_PAY_TO_CREATOR, NAMESPACE_VERSION_PAY_WITH_STACKS]:\n      raise Exception(\"Invalid namespace version bits {:x}\".format(version))\n\n   if lifetime < 0 or lifetime > (2**32 - 1):\n      lifetime = NAMESPACE_LIFE_INFINITE \n\n   if coeff < 0 or coeff > 255:\n      raise Exception(\"Invalid cost multiplier %s: must be in range [0, 256)\" % coeff)\n  \n   if base < 0 or base > 255:\n      raise Exception(\"Invalid base price %s: must be in range [0, 256)\" % base)\n \n   if type(bucket_exponents) != list:\n        raise Exception(\"Bucket exponents must be a list\")\n\n   if len(bucket_exponents) != 16:\n        raise Exception(\"Exactly 16 buckets required\")\n\n   for i in xrange(0, len(bucket_exponents)):\n       if bucket_exponents[i] < 0 or bucket_exponents[i] > 15:\n          raise Exception(\"Invalid bucket exponent %s (must be in range [0, 16)\" % bucket_exponents[i])\n   \n   if nonalpha_discount <= 0 or nonalpha_discount > 15:\n        raise Exception(\"Invalid non-alpha discount %s: must be in range [0, 16)\" % nonalpha_discount)\n    \n   if no_vowel_discount <= 0 or no_vowel_discount > 15:\n        raise Exception(\"Invalid no-vowel discount %s: must be in range [0, 16)\" % no_vowel_discount)\n\n   return True", "response": "Verify validity of a namespace reveal."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks a NAMESPACE_REVEAL operation to the name database.", "response": "def check( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Check a NAMESPACE_REVEAL operation to the name database.\n    It is only valid if it is the first such operation\n    for this namespace, and if it was sent by the same\n    sender who sent the NAMESPACE_PREORDER.\n\n    Return True if accepted\n    Return False if not\n    \"\"\"\n\n    epoch_features = get_epoch_features(block_id)\n\n    namespace_id = nameop['namespace_id']\n    namespace_id_hash = nameop['preorder_hash']\n    sender = nameop['sender']\n    namespace_preorder = None\n\n    if not nameop.has_key('sender_pubkey'):\n       log.warning(\"Namespace reveal requires a sender_pubkey (i.e. a p2pkh transaction)\")\n       return False\n\n    if not nameop.has_key('recipient'):\n       log.warning(\"No recipient script for namespace '%s'\" % namespace_id)\n       return False\n\n    if not nameop.has_key('recipient_address'):\n       log.warning(\"No recipient address for namespace '%s'\" % namespace_id)\n       return False\n\n    # well-formed?\n    if not is_b40( namespace_id ) or \"+\" in namespace_id or namespace_id.count(\".\") > 0:\n       log.warning(\"Malformed namespace ID '%s': non-base-38 characters\")\n       return False\n\n    # can't be revealed already\n    if state_engine.is_namespace_revealed( namespace_id ):\n       # this namespace was already revealed\n       log.warning(\"Namespace '%s' is already revealed\" % namespace_id )\n       return False\n\n    # can't be ready already\n    if state_engine.is_namespace_ready( namespace_id ):\n       # this namespace already exists (i.e. was already begun)\n       log.warning(\"Namespace '%s' is already registered\" % namespace_id )\n       return False\n\n    # must currently be preordered\n    namespace_preorder = state_engine.get_namespace_preorder( namespace_id_hash )\n    if namespace_preorder is None:\n       # not preordered\n       log.warning(\"Namespace '%s' is not preordered (no preorder %s)\" % (namespace_id, namespace_id_hash) )\n       return False\n\n    # must be sent by the same principal who preordered it\n    if namespace_preorder['sender'] != sender:\n       # not sent by the preorderer\n       log.warning(\"Namespace '%s' is not preordered by '%s'\" % (namespace_id, sender))\n       return False\n\n    # must be a version we support\n    # pre F-day 2017: only support names that send payment to the burn address\n    # post F-day 2017: support both pay-to-burn and pay-to-creator\n    # 2018 phase 1: support paying for names with STACKs tokens\n    namespace_version_bits = int(nameop['version'])\n    if namespace_version_bits == NAMESPACE_VERSION_PAY_TO_CREATOR:\n        # need to be in post F-day 2017 or later\n        if EPOCH_FEATURE_NAMESPACE_BURN_TO_CREATOR not in epoch_features:\n            log.warning(\"pay-to-creator is not supported in this epoch\")\n            return False\n\n    elif namespace_version_bits == NAMESPACE_VERSION_PAY_WITH_STACKS:\n        # need to be in 2018 phase 1 or later\n        if EPOCH_FEATURE_NAMESPACE_PAY_WITH_STACKS not in epoch_features:\n            log.warning(\"pay-with-STACKs-tokens is not supported in this epoch\")\n            return False\n\n    elif namespace_version_bits != NAMESPACE_VERSION_PAY_TO_BURN:\n        # not supported at all\n        log.warning(\"Unsupported namespace version {:x}\".format(namespace_version_bits))\n        return False\n\n    # what units did the namespace preorderer pay?\n    units = namespace_preorder['token_units']\n    tokens_paid = 0\n\n    if units == 'STACKS':\n        # namespace creator paid in STACKs\n        if EPOCH_FEATURE_STACKS_BUY_NAMESPACES not in epoch_features:\n            traceback.print_stack()\n            log.fatal(\"Namespaces must be bought in STACKs, but this epoch does not support it!\")\n            os.abort()\n\n        # how much did the NAMESPACE_PREORDER pay?\n        if 'token_fee' not in namespace_preorder:\n            log.warning(\"Namespace {} did not pay the token fee\".format(namespace_id))\n            return False\n\n        tokens_paid = namespace_preorder['token_fee']\n        assert isinstance(tokens_paid, (int,long))\n\n        token_namespace_fee = price_namespace(namespace_id, block_id, units)\n        if token_namespace_fee is None:\n            log.warning(\"Invalid namespace ID {}\".format(namespace_id))\n            return False\n\n        if tokens_paid < token_namespace_fee:\n            # not enough!\n            log.warning(\"Namespace buyer paid {} tokens, but '{}' costs {} tokens\".format(tokens_paid, namespace_id, token_namespace_fee))\n            return False\n\n    elif units == 'BTC':\n        # namespace creator paid in BTC\n        # check fee...\n        if not 'op_fee' in namespace_preorder:\n           log.warning(\"Namespace '%s' preorder did not pay the fee\" % (namespace_id))\n           return False\n\n        namespace_fee = namespace_preorder['op_fee']\n\n        # must have paid enough\n        if namespace_fee < price_namespace(namespace_id, block_id, units):\n           # not enough money\n           log.warning(\"Namespace '%s' costs %s, but sender paid %s\" % (namespace_id, price_namespace(namespace_id, block_id, units), namespace_fee))\n           return False\n\n    else:\n        traceback.print_stack()\n        log.fatal(\"Unknown payment unit {}\".format(units))\n        os.abort()\n\n    # is this the first time this namespace has been revealed?\n    old_namespace = state_engine.get_namespace_op_state( namespace_id, block_id, include_expired=True )\n    namespace_block_number = None\n    preorder_block_number = namespace_preorder['block_number']\n    \n    if old_namespace is None:\n        # revealed for the first time\n        log.warning(\"Revealing for the first time: '%s'\" % namespace_id)\n        namespace_block_number = namespace_preorder['block_number']\n        \n    else:\n        # revealed for the 2nd or later time\n        log.warning(\"Re-revealing namespace '%s'\" % namespace_id )\n        \n        # push back preorder block number to the original preorder\n        namespace_block_number = old_namespace['block_number']\n\n    # record preorder\n    nameop['block_number'] = namespace_block_number \n    nameop['reveal_block'] = block_id\n    state_create_put_preorder( nameop, namespace_preorder )\n\n    # NOTE: not fed into the consensus hash, but necessary for database constraints:\n    nameop['ready_block'] = 0\n    nameop['op_fee'] = namespace_preorder['op_fee']\n    \n    nameop['token_fee'] = '{}'.format(tokens_paid)      # NOTE: avoids overflow\n    # can begin import\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse( bin_payload, sender_script, recipient_address ):\n   \n   if len(bin_payload) < MIN_OP_LENGTHS['namespace_reveal']:\n       raise AssertionError(\"Payload is too short to be a namespace reveal\")\n\n   off = 0\n   life = None \n   coeff = None \n   base = None \n   bucket_hex = None\n   buckets = []\n   discount_hex = None\n   nonalpha_discount = None \n   no_vowel_discount = None\n   version = None\n   namespace_id = None \n   namespace_id_hash = None\n   \n   life = int( hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_life']]), 16 )\n   \n   off += LENGTHS['blockchain_id_namespace_life']\n   \n   coeff = int( hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_coeff']]), 16 )\n   \n   off += LENGTHS['blockchain_id_namespace_coeff']\n   \n   base = int( hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_base']]), 16 )\n   \n   off += LENGTHS['blockchain_id_namespace_base']\n   \n   bucket_hex = hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_buckets']])\n   \n   off += LENGTHS['blockchain_id_namespace_buckets']\n   \n   discount_hex = hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_discounts']])\n   \n   off += LENGTHS['blockchain_id_namespace_discounts']\n   \n   version = int( hexlify(bin_payload[off:off+LENGTHS['blockchain_id_namespace_version']]), 16)\n   \n   off += LENGTHS['blockchain_id_namespace_version']\n   \n   namespace_id = bin_payload[off:]\n   namespace_id_hash = None\n   try:\n       namespace_id_hash = hash_name( namespace_id, sender_script, register_addr=recipient_address )\n   except:\n       log.error(\"Invalid namespace ID and/or sender script\")\n       return None\n   \n   # extract buckets \n   buckets = [int(x, 16) for x in list(bucket_hex)]\n   \n   # extract discounts\n   nonalpha_discount = int( list(discount_hex)[0], 16 )\n   no_vowel_discount = int( list(discount_hex)[1], 16 )\n  \n   try:\n       rc = namespacereveal_sanity_check( namespace_id, version, life, coeff, base, buckets, nonalpha_discount, no_vowel_discount )\n       if not rc:\n           raise Exception(\"Invalid namespace parameters\")\n\n   except Exception, e:\n       if BLOCKSTACK_TEST:\n           log.exception(e)\n\n       log.error(\"Invalid namespace parameters\")\n       return None \n\n   return {\n      'opcode': 'NAMESPACE_REVEAL',\n      'lifetime': life,\n      'coeff': coeff,\n      'base': base,\n      'buckets': buckets,\n      'version': version,\n      'nonalpha_discount': nonalpha_discount,\n      'no_vowel_discount': no_vowel_discount,\n      'namespace_id': namespace_id,\n      'preorder_hash': namespace_id_hash\n   }", "response": "Parse a namespace reveal from a binary payload."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_namespace():\n    resp = blockstack.lib.client.get_all_names(hostport=blockstack_indexer_url)\n    subdomain_names = blockstack.lib.subdomains.get_all_subdomains()\n\n    all_names = list(resp) + list(subdomain_names)\n\n    with open(SEARCH_BLOCKCHAIN_DATA_FILE, 'w') as fout:\n        fout.write(json.dumps(all_names))", "response": "Fetch all names in a namespace that should be indexed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_profiles(max_to_fetch = None, just_test_set = False):\n\n    with open(SEARCH_BLOCKCHAIN_DATA_FILE, 'r') as fin:\n        all_names = json.load(fin)\n\n    info_resp = blockstack.lib.client.getinfo(hostport=blockstack_indexer_url)\n    last_block_processed = info_resp['last_block_processed']\n\n    all_profiles = []\n\n    if max_to_fetch == None:\n        max_to_fetch = len(all_names)\n\n    if just_test_set:\n        from api.tests.search_tests import SEARCH_TEST_USERS\n        all_names = [\"{}.id\".format(u) for u in SEARCH_TEST_USERS]\n\n    for ix, fqu in enumerate(all_names):\n        if ix % 100 == 0:\n            print_status_bar(ix, max_to_fetch)\n        if ix >= max_to_fetch:\n            break\n\n        resp = {}\n        resp['fqu'] = fqu\n\n        try:\n            resp['profile'] = blockstack.lib.client.resolve_profile(\n                    fqu, hostport=blockstack_indexer_url)['profile']\n\n            all_profiles.append(resp)\n        except KeyboardInterrupt as e:\n            raise e\n        except:\n            pass\n\n    attempts = 0\n    while not obtain_lockfile():\n        attempts += 1\n        time.sleep(5)\n        if attempts > 10:\n            print \"ERROR! Could not obtain lockfile\"\n            return\n\n    last_subdomain_seq = blockstack.lib.subdomains.get_subdomain_last_sequence()\n\n    with open(SEARCH_PROFILE_DATA_FILE, 'w') as fout:\n        json.dump(all_profiles, fout)\n    with open(SEARCH_LAST_INDEX_DATA_FILE, 'w') as fout:\n        search_index_data = {\n            'last_block_height' : last_block_processed,\n            'last_full_index' : datetime.now().isoformat(),\n            'last_subdomain_seq' : last_subdomain_seq\n        }\n        json.dump(search_index_data, fout)", "response": "Fetch all the profiles from Blockstack Core and save them in the data directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check( state_engine, nameop, block_id, checked_ops ):\n\n    name = nameop['name']\n    sender = nameop['sender']\n    namespace_id = get_namespace_from_name( name )\n\n    # name must be well-formed\n    if not is_b40( name ) or \"+\" in name or name.count(\".\") > 1:\n        log.warning(\"Malformed name '%s': non-base-38 characters\" % name)\n        return False\n\n    # name must exist\n    name_rec = state_engine.get_name( name )\n    if name_rec is None:\n        log.warning(\"Name '%s' does not exist\" % name)\n        return False\n\n    # namespace must be ready\n    if not state_engine.is_namespace_ready( namespace_id ):\n        log.warning(\"Namespace '%s' is not ready\" % namespace_id )\n        return False\n\n    # name must not be revoked\n    if state_engine.is_name_revoked( name ):\n        log.warning(\"Name '%s' is revoked\" % name)\n        return False\n\n    # name must not be expired as of *this* block\n    if state_engine.is_name_expired( name, block_id ):\n        log.warning(\"Name '%s' is expired\" % name)\n        return False\n\n    # name must not be in grace period in this block\n    if state_engine.is_name_in_grace_period(name, block_id):\n        log.warning(\"Name '{}' is in the renewal grace period.  It can only be renewed at this time.\".format(name))\n        return False\n\n    # the name must be registered\n    if not state_engine.is_name_registered( name ):\n        log.warning(\"Name '%s' is not registered\" % name )\n        return False\n\n    # the sender must own this name\n    if not state_engine.is_name_owner( name, sender ):\n        log.warning(\"Name '%s' is not owned by %s\" % (name, sender))\n        return False\n\n    # apply state transition \n    nameop['revoked'] = True\n    nameop['value_hash'] = None\n    return True", "response": "Check if a name is valid and return True if it is valid False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying that a name at a particular block number is well - formed and that all of the operations in checked_ops are incorporated into the order they are in.", "response": "def check( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Verify that a preorder of a name at a particular block number is well-formed\n\n    NOTE: these *can't* be incorporated into namespace-imports,\n    since we have no way of knowning which namespace the\n    nameop belongs to (it is blinded until registration).\n    But that's okay--we don't need to preorder names during\n    a namespace import, because we will only accept names\n    sent from the importer until the NAMESPACE_REVEAL operation\n    is sent.\n\n    Return True if accepted\n    Return False if not.\n    \"\"\"\n\n    from .register import get_num_names_owned\n\n    preorder_name_hash = nameop['preorder_hash']\n    consensus_hash = nameop['consensus_hash']\n    sender = nameop['sender']\n\n    token_fee = nameop['token_fee']\n    token_type = nameop['token_units']\n    token_address = nameop['address']\n\n    # must be unique in this block\n    # NOTE: now checked externally in the @state_preorder decorator\n\n    # must be unique across all pending preorders\n    if not state_engine.is_new_preorder( preorder_name_hash ):\n        log.warning(\"Name hash '%s' is already preordered\" % preorder_name_hash )\n        return False\n\n    # must have a valid consensus hash\n    if not state_engine.is_consensus_hash_valid( block_id, consensus_hash ):\n        log.warning(\"Invalid consensus hash '%s'\" % consensus_hash )\n        return False\n\n    # sender must be beneath quota\n    num_names = get_num_names_owned( state_engine, checked_ops, sender ) \n    if num_names >= MAX_NAMES_PER_SENDER:\n        log.warning(\"Sender '%s' exceeded name quota of %s\" % (sender, MAX_NAMES_PER_SENDER ))\n        return False \n\n    # burn fee must be present\n    if not 'op_fee' in nameop:\n        log.warning(\"Missing preorder fee\")\n        return False\n\n    epoch_features = get_epoch_features(block_id)\n    if EPOCH_FEATURE_NAMEOPS_COST_TOKENS in epoch_features and token_type is not None and token_fee is not None:\n        # does this account have enough balance?\n        account_info = state_engine.get_account(token_address, token_type)\n        if account_info is None:\n            log.warning(\"No account for {} ({})\".format(token_address, token_type))\n            return False\n\n        account_balance = state_engine.get_account_balance(account_info)\n\n        assert isinstance(account_balance, (int,long)), 'BUG: account_balance of {} is {} (type {})'.format(token_address, account_balance, type(account_balance))\n        assert isinstance(token_fee, (int,long)), 'BUG: token_fee is {} (type {})'.format(token_fee, type(token_fee))\n\n        if account_balance < token_fee:\n            # can't afford \n            log.warning(\"Account {} has balance {} {}, but needs to pay {} {}\".format(token_address, account_balance, token_type, token_fee, token_type))\n            return False\n\n        # must be the black hole address, regardless of namespace version (since we don't yet support pay-stacks-to-namespace-creator)\n        if nameop['burn_address'] != BLOCKSTACK_BURN_ADDRESS:\n            # not sent to the right address\n            log.warning('Preorder burned to {}, but expected {}'.format(nameop['burn_address'], BLOCKSTACK_BURN_ADDRESS))\n            return False\n\n        # for now, this must be Stacks\n        if nameop['token_units'] != TOKEN_TYPE_STACKS:\n            # can't use any other token (yet)\n            log.warning('Preorder burned unrecognized token unit \"{}\"'.format(nameop['token_units']))\n            return False\n\n        # debit this account when we commit\n        state_preorder_put_account_payment_info(nameop, token_address, token_type, token_fee)\n        \n        # NOTE: must be a string, to avoid overflow\n        nameop['token_fee'] = '{}'.format(token_fee)\n\n    else:\n        # not paying in tokens, but say so!\n        state_preorder_put_account_payment_info(nameop, None, None, None)\n        nameop['token_fee'] = '0'\n        nameop['token_units'] = 'BTC'\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_preorder_burn_info( outputs ):\n    \n    if len(outputs) != 3:\n        # not a well-formed preorder \n        return None \n   \n    op_fee = outputs[2]['value']\n    burn_address = None\n\n    try:\n        burn_address = virtualchain.script_hex_to_address(outputs[2]['script'])\n        assert burn_address\n    except:\n        log.error(\"Not a well-formed preorder burn: {}\".format(outputs[2]['script']))\n        return None\n\n    return {'op_fee': op_fee, 'burn_address': burn_address}", "response": "Given a set of outputs find the fee sent \n    to our burn address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a name preorder.", "response": "def parse(bin_payload, block_height):\n    \"\"\"\n    Parse a name preorder.\n    NOTE: bin_payload *excludes* the leading 3 bytes (magic + op) returned by build.\n\n    Record format:\n    \n    0     2  3                                              23             39\n    |-----|--|----------------------------------------------|--------------|\n    magic op  hash(name.ns_id,script_pubkey,register_addr)   consensus hash\n    \n    Record format when burning STACKs (STACKS Phase 1):\n    0     2  3                                              23                 39                            47                      66\n    |-----|--|----------------------------------------------|------------------|-----------------------------|-----------------------|\n    magic op  hash(name.ns_id,script_pubkey,register_addr)   consensus hash     tokens to burn (big-endian)  token units (0-padded)\n\n    Returns {\n        opcode: NAME_PREORDER,\n        preorder_hash: the hash of the name, scriptPubKey, and register address\n        consensus_hash: the consensus hash\n        token_fee: the amount of tokens to burn (will be None if not given)\n        token_units: the type of tokens to burn (will be None if not given)\n    }\n    \"\"\"\n    \n    epoch_features = get_epoch_features(block_height)\n\n    if len(bin_payload) < LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']:\n        log.warning(\"Invalid payload {}: expected at least {} bytes\".format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']))\n        return None \n\n    name_hash = hexlify( bin_payload[0:LENGTHS['preorder_name_hash']] )\n    consensus_hash = hexlify( bin_payload[LENGTHS['preorder_name_hash']: LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']] )\n    tokens_burned = None\n    token_units = None\n\n    if len(bin_payload) > LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']:\n        # only acceptable if there's a token burn\n        if EPOCH_FEATURE_NAMEOPS_COST_TOKENS not in epoch_features:\n            # not enabled yet\n            log.warning(\"Invalid payload {}: expected {} bytes\".format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']))\n            return None\n\n        if len(bin_payload) != LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt'] + LENGTHS['namespace_id']:\n            # invalid\n            log.warning(\"Invalid payload {}: expected {} bytes\".format(bin_payload.encode('hex'), LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']))\n            return None\n\n        at_tokens_burnt = LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash']\n        at_token_units = LENGTHS['preorder_name_hash'] + LENGTHS['consensus_hash'] + LENGTHS['tokens_burnt']\n\n        bin_tokens_burnt = bin_payload[at_tokens_burnt: at_tokens_burnt + LENGTHS['tokens_burnt']]\n        bin_token_units = bin_payload[at_token_units: at_token_units + LENGTHS['namespace_id']]\n\n        tokens_burned = int(bin_tokens_burnt.encode('hex'), 16)\n        token_units = bin_token_units.strip('\\x00')\n\n    return {\n        'opcode': 'NAME_PREORDER',\n        'preorder_hash': name_hash,\n        'consensus_hash': consensus_hash,\n        'token_fee': tokens_burned,\n        'token_units': token_units,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding a string of hex to a list of unique names.", "response": "def c32encode(input_hex, min_length=None):\n    \"\"\"\n    >>> c32encode('a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    'MHQZH246RBQSERPSE2TD5HHPF21NQMWX'\n    >>> c32encode('')\n    ''\n    >>> c32encode('0000000000000000000000000000000000000000', 20)\n    '00000000000000000000'\n    >>> c32encode('0000000000000000000000000000000000000001', 20)\n    '00000000000000000001'\n    >>> c32encode('1000000000000000000000000000000000000001', 32)\n    '20000000000000000000000000000001'\n    >>> c32encode('1000000000000000000000000000000000000000', 32)\n    '20000000000000000000000000000000'\n    >>> c32encode('1')\n    '1'\n    >>> c32encode('22')\n    '12'\n    >>> c32encode('001')\n    '01'\n    >>> c32encode('0001')\n    '01'\n    >>> c32encode('00001')\n    '001'\n    >>> c32encode('000001')\n    '001'\n    >>> c32encode('10')\n    'G'\n    >>> c32encode('100')\n    '80'\n    >>> c32encode('1000')\n    '400'\n    >>> c32encode('10000')\n    '2000'\n    >>> c32encode('100000')\n    '10000'\n    >>> c32encode('1000000')\n    'G0000'\n    \"\"\"\n    if len(input_hex) == 0:\n        return ''\n\n    if not re.match(r'^[0-9a-fA-F]+$', input_hex):\n        raise ValueError('Requires a hex string')\n\n    if len(input_hex) % 2 != 0:\n        input_hex = '0{}'.format(input_hex)\n\n    input_hex = input_hex.lower()\n    \n    res = []\n    carry = 0\n    for i in range(len(input_hex) - 1, -1, -1):\n        if (carry < 4):\n            current_code = HEX.index(input_hex[i]) >> carry\n            next_code = 0\n            if i != 0:\n                next_code = HEX.index(input_hex[i-1])\n\n            # carry = 0, next_bits is 1, carry = 1, next_bits = 2\n            next_bits = 1 + carry\n            next_low_bits = (next_code % (1 << next_bits)) << (5 - next_bits)\n            cur_c32_digit = C32[current_code + next_low_bits]\n            carry = next_bits\n            res = [cur_c32_digit] + res\n        else:\n            carry = 0\n\n    # fix padding\n    # -- strip leading c32 zeros\n    # -- add leading hex zeros\n    c32_leading_zeros = 0\n    for i in range(0, len(res)):\n        if res[i] != '0':\n            break\n\n        c32_leading_zeros += 1\n\n    res = res[c32_leading_zeros:]\n\n    num_leading_hex_zeros = 0\n    num_leading_byte_zeros = 0\n    for i in range(0, len(input_hex)):\n        if input_hex[i] != '0':\n            break\n\n        num_leading_hex_zeros += 1\n\n    num_leading_byte_zeros = num_leading_hex_zeros / 2\n    res = ['0'] * num_leading_byte_zeros + res\n\n    if min_length > 0:\n        count = min_length - len(res)\n        if count > 0:\n            res = ['0'] * count + res\n\n    return ''.join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a c32 - encoded string into a list of strings", "response": "def c32decode(c32input, min_length=0):\n    \"\"\"\n    >>> c32decode('MHQZH246RBQSERPSE2TD5HHPF21NQMWX')\n    'a46ff88886c2ef9762d970b4d2c63678835bd39d'\n    >>> c32decode('')\n    ''\n    >>> c32decode('00000000000000000000', 20)\n    '0000000000000000000000000000000000000000'\n    >>> c32decode('00000000000000000001', 20)\n    '0000000000000000000000000000000000000001'\n    >>> c32decode('20000000000000000000000000000001', 20)\n    '1000000000000000000000000000000000000001'\n    >>> c32decode('20000000000000000000000000000000', 20)\n    '1000000000000000000000000000000000000000'\n    >>> c32decode('1')\n    '01'\n    >>> c32decode('12')\n    '22'\n    >>> c32decode('01')\n    '0001'\n    >>> c32decode('001')\n    '000001'\n    >>> c32decode('G')\n    '10'\n    >>> c32decode('80')\n    '0100'\n    >>> c32decode('400')\n    '1000'\n    >>> c32decode('2000')\n    '010000'\n    >>> c32decode('10000')\n    '100000'\n    >>> c32decode('G0000')\n    '01000000'\n    \"\"\"\n\n    if len(c32input) == 0:\n        return ''\n\n    c32input = c32normalize(c32input)\n    if not re.match(r'^[' + C32 + ']*$', c32input):\n        raise ValueError('Not a c32-encoded string')\n\n    num_leading_zero_bytes = 0\n    for i in range(0, len(c32input)):\n        if c32input[i] != C32[0]:\n            break\n\n        num_leading_zero_bytes += 1\n\n    res = []\n    carry = 0\n    carry_bits = 0\n    for i in range(len(c32input) - 1, -1, -1):\n        if carry_bits == 4:\n            res = [HEX[carry]] + res\n            carry_bits = 0\n            carry = 0\n\n        current_code = C32.index(c32input[i]) << carry_bits\n        current_value = current_code + carry\n        current_hex_digit = HEX[current_value % len(HEX)]\n\n        carry_bits += 1\n        carry = current_value >> 4\n\n        if carry > (1 << carry_bits):\n            raise Exception('Panic error in decoding')\n\n        res = [current_hex_digit] + res\n\n    # one last carry\n    res = [HEX[carry]] + res\n\n    if len(res) % 2 == 1:\n        res = [HEX[0]] + res\n\n    # remove all leading zeros while keeping the string even-length\n    hex_leading_zeros = 0\n    for i in range(0, len(res)):\n        if res[i] != '0':\n            break\n\n        hex_leading_zeros += 1\n\n    res = res[hex_leading_zeros - (hex_leading_zeros % 2):]\n    hexstr = ''.join(res)\n\n    # add back leading zero bytes from the c32 string\n    for i in range(0, num_leading_zero_bytes):\n        hexstr = '00{}'.format(hexstr)\n\n    if min_length > 0:\n        count = min_length * 2 - len(hexstr)\n        hexstr = '00' * (count / 2) + hexstr\n\n    return hexstr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the data is correct.", "response": "def c32checkEncode(version, data):\n    \"\"\"\n    >>> c32checkEncode(22, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    'P2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKNRV9EJ7'\n    >>> c32checkEncode(0, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    '02J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKPVKG2CE'\n    >>> c32checkEncode(31, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    'Z2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQ9H6DPR'\n    >>> c32checkEncode(11, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    'B2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKNGTQ5XV'\n    >>> c32checkEncode(17, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    'H2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKPZJKGHG'\n    >>> c32checkEncode(2, 'a46ff88886c2ef9762d970b4d2c63678835bd39d')\n    '22J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKMQMB2T9'\n    >>> c32checkEncode(22, '')\n    'P37JJX3D'\n    >>> c32checkEncode(22, '0000000000000000000000000000000000000000')\n    'P000000000000000000002Q6VF78'\n    >>> c32checkEncode(22, '0000000000000000000000000000000000000001')\n    'P00000000000000000005JA84HQ'\n    >>> c32checkEncode(22, '1000000000000000000000000000000000000001')\n    'P80000000000000000000000000000004R0CMNV'\n    >>> c32checkEncode(22, '1000000000000000000000000000000000000000')\n    'P800000000000000000000000000000033H8YKK'\n    >>> c32checkEncode(0, '1')\n    '04C407K6'\n    >>> c32checkEncode(0, '22')\n    '049Q1W6AP'\n    >>> c32checkEncode(0, '001')\n    '006NZP224'\n    >>> c32checkEncode(31, '00001')\n    'Z004720442'\n    >>> c32checkEncode(31, '000001')\n    'Z004720442'\n    >>> c32checkEncode(31, '0000001')\n    'Z00073C2AR7'\n    >>> c32checkEncode(11, '10')\n    'B20QX4FW0'\n    >>> c32checkEncode(11, '100')\n    'B102PC6RCC'\n    >>> c32checkEncode(11, '1000')\n    'BG02G1QXCQ'\n    >>> c32checkEncode(17, '100000')\n    'H40003YJA8JD'\n    >>> c32checkEncode(17, '1000000')\n    'H200001ZTRYYH'\n    >>> c32checkEncode(17, '10000000')\n    'H1000002QFX7E6'\n    >>> c32checkEncode(2, '100000000')\n    '2G000003FNKA3P'\n    \"\"\"\n    if version < 0 or version >= len(C32):\n        raise ValueError('Invalid version -- must be between 0 and {}'.format(len(C32)-1))\n\n    if not re.match(r'^[0-9a-fA-F]*$', data):\n        raise ValueError('Invalid data -- must be hex')\n\n    data = data.lower()\n    if len(data) % 2 != 0:\n        data = '0{}'.format(data)\n\n    version_hex = '{:02x}'.format(version)\n    checksum_hex = c32checksum('{}{}'.format(version_hex, data))\n    c32str = c32encode('{}{}'.format(data, checksum_hex))\n    return '{}{}'.format(C32[version], c32str)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef c32address(version, hash160hex):\n    if not re.match(r'^[0-9a-fA-F]{40}$', hash160hex):\n        raise ValueError('Invalid argument: not a hash160 hex string')\n\n    c32string = c32checkEncode(version, hash160hex)\n    return 'S{}'.format(c32string)", "response": "Return the c32 address for the given hash160 hex string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a base58check to a base32 string.", "response": "def b58ToC32(b58check, version=-1):\n    \"\"\"\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d')\n    'SP2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKNRV9EJ7'\n    >>> b58ToC32('3GgUssdoWh5QkoUDXKqT6LMESBDf8aqp2y')\n    'SM2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQVX8X0G'\n    >>> b58ToC32('mvWRFPELmpCHSkFQ7o9EVdCd9eXeUTa9T8')\n    'ST2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQYAC0RQ'\n    >>> b58ToC32('2N8EgwcZq89akxb6mCTTKiHLVeXRpxjuy98')\n    'SN2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKP6D2ZK9'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 22)\n    'SP2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKNRV9EJ7'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 0)\n    'S02J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKPVKG2CE'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 31)\n    'SZ2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQ9H6DPR'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 20)\n    'SM2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQVX8X0G'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 26)\n    'ST2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKQYAC0RQ'\n    >>> b58ToC32('1FzTxL9Mxnm2fdmnQEArfhzJHevwbvcH6d', 21)\n    'SN2J6ZY48GV1EZ5V2V5RB9MP66SW86PYKKP6D2ZK9'\n    \"\"\"\n    addr_version_byte, addr_bin, addr_checksum = keylib.b58check.b58check_unpack(b58check)\n    addr_version = ord(addr_version_byte)\n    addr_hash160 = addr_bin.encode('hex')\n\n    stacks_version = None\n    if version < 0:\n        stacks_version = addr_version\n        if ADDR_BITCOIN_TO_STACKS.get(addr_version) is not None:\n            stacks_version = ADDR_BITCOIN_TO_STACKS[addr_version]\n\n    else:\n        stacks_version = version\n\n    return c32address(stacks_version, addr_hash160)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef c32ToB58(c32string, version=-1):\n    addr_version, addr_hash160 = c32addressDecode(c32string)\n\n    bitcoin_version = None\n    if version < 0:\n        bitcoin_version = addr_version\n        if ADDR_STACKS_TO_BITCOIN.get(addr_version) is not None:\n            bitcoin_version = ADDR_STACKS_TO_BITCOIN[addr_version]\n\n    else:\n        bitcoin_version = version\n\n    return keylib.b58check.b58check_encode(addr_hash160.decode('hex'), bitcoin_version)", "response": "Convert a 32 - bit string to B58."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_genesis_txid(address, metadata):\n    preimage = '{} genesis {}'.format(address, metadata)\n    return virtualchain.lib.hashing.bin_double_sha256(preimage).encode('hex')", "response": "Make a fake txid for a genesis block entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a fake txid for a vesting transaction.", "response": "def namedb_vesting_txid(address, token_type, token_amount, block_height):\n    \"\"\"\n    Make a \"fake\" txid for a vesting transaction.\n    Returns a 32-byte hash (double-sha256), hex-encoded\n    \"\"\"\n    preimage = '{} vesting {} {} at {}'.format(address, token_type, token_amount, block_height)\n    return virtualchain.lib.hashing.bin_double_sha256(preimage).encode('hex')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a 32 - byte hash for the genesis block history", "response": "def namedb_genesis_block_history_hash(genesis_block_history):\n    \"\"\"\n    Make a \"fake\" txid for the genesis block history\n    Returns a 32-byte hash (single sha256), hex-encoded\n    (single sha256 so it can be easily verified against our genesis block tooling)\n    \"\"\"\n    # no-whitespace sorted serialization\n    preimage = json.dumps(genesis_block_history, sort_keys=True, separators=(',',':'))\n    h = hashlib.sha256(preimage).hexdigest()\n    return h"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the initial block balances for the blockstack Token LLC.", "response": "def namedb_create_token_genesis(con, initial_account_balances, genesis_block_history):\n    \"\"\"\n    Create the initial account balances.\n    All accounts will be locked, and will have been created at the genesis date\n    for Blockstack (i.e. FIRST_BLOCK_MAINNET)\n\n    The genesis block has multiple \"stages\" that encode the transfer of tokens from\n    Blockstack Token LLC to the various investors, GPs, etc.  For the initial genesis\n    block for the accredited token sale, there should be four such stages.\n\n    @initial_account_balances is the final genesis block stage that encodes the\n    token allocations and unlock periods for each initial account holder (i.e. the\n    initial investors)\n\n    @genesis_block_history is a sequence of signed hashes over each stage.\n    \n    @initial_count_balances is a list of dicts:\n    [\n        {\n            'address': ...,\n            'type': ...,\n            'value': ...,\n            'vesting': {\n                block_height: value\n            },\n            'vesting_total': ...,\n            'lock_send': ... (optional; block height)\n            'receive_whitelisted': ... (optional; bool)\n            'metadata': ... (optional)\n        },\n        {...}\n    ]\n    @genesis_block_history this structure:\n    [\n        {\n            \"hash\": ...,\n            \"signature\": ...\n        },\n    ]\n    We'll store the genesis block history's canonical hash as the first transaction.\n    \"\"\"\n    namedb_query_execute(con, \"BEGIN\", ())\n    for account_info in initial_account_balances:\n        # check required fields \n        for f in ['address', 'type', 'value']:\n            assert f in account_info, 'BUG: missing {} in {}'.format(f, account_info)\n\n        metadata = None\n        address = None\n\n        try:\n            address = account_info['address']\n            if is_c32_address(address):\n                address = address_as_b58(address)\n\n            address = virtualchain.address_reencode(address)\n        except ValueError:\n            assert account_info.get('receive_whitelisted') == False, 'Unspendable address \"{}\" must be explicitly marked as not receive-whitelisted'.format(account_info['address'])\n\n            log.warning('Using unspendable address \"{}\"'.format(account_info['address']))\n            address = account_info['address']\n\n        if 'metadata' in account_info and account_info['metadata'] is not None:\n            metadata = account_info['metadata']\n            log.debug('Grant {} to {} (originally: {}, metadata: {})'.format(account_info['value'], address, account_info['address'], metadata))\n\n        else:\n            log.debug('Grant {} to {}'.format(account_info['value'], address))\n            metadata = '' \n\n        lock_send = account_info.get('lock_send', 0)\n        assert lock_send >= 0, 'Invalid lock_send: {}'.format(lock_send)\n\n        receive_whitelisted = account_info.get('receive_whitelisted', True)     # whitelist by default for now\n\n        # set up initial account balances\n        sql = 'INSERT INTO accounts VALUES (?,?,?,?,?,?,?,?,?,?);'\n\n        fake_txid = namedb_genesis_txid(address, metadata)\n\n        args = (address, account_info['type'], '{}'.format(account_info['value']), '0', lock_send, receive_whitelisted, metadata, FIRST_BLOCK_MAINNET, fake_txid, 0)\n        namedb_query_execute(con, sql, args)\n\n        # set up vesting period\n        if 'vesting' in account_info:\n            assert 'vesting_total' in account_info, 'BUG: vesting is present but vesting_total is not'\n\n            vesting_sum = sum([account_info['vesting'][h] for h in account_info['vesting']]) \n            assert vesting_sum == account_info['vesting_total'], 'BUG: vesting mismatch on {}: {} != {} ({})'.format(address, vesting_sum, account_info['vesting_total'], account_info['vesting'])\n\n            for block_height in account_info['vesting']:\n                sql = 'INSERT INTO account_vesting VALUES (?,?,?,?);'\n                args = (address, account_info['type'], '{}'.format(account_info['vesting'][block_height]), int(block_height))\n                namedb_query_execute(con, sql, args)\n\n    # insert genesis history \n    genesis_hash = namedb_genesis_block_history_hash(genesis_block_history)\n    sql = 'INSERT INTO accounts VALUES (?,?,?,?,?,?,?,?,?,?);'\n    args = (BLOCKSTACK_BURN_ADDRESS, 'GENESIS', '0', '0', True, False, genesis_hash, FIRST_BLOCK_MAINNET, genesis_hash, 0)\n    namedb_query_execute(con, sql, args)\n\n    namedb_query_execute(con, \"END\", ())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_get_version(con):\n    sql = 'SELECT version FROM db_version;'\n    args = ()\n\n    try:\n        rowdata = namedb_query_execute(con, sql, args, abort=False)\n        row = rowdata.fetchone()\n        return row['version']\n    except:\n        # no version defined\n        return '0.0.0.0'", "response": "Get the db version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the db version", "response": "def namedb_read_version(path):\n    \"\"\"\n    Get the db version\n    \"\"\"\n    con = sqlite3.connect( path, isolation_level=None, timeout=2**30 )\n    con.row_factory = namedb_row_factory\n\n    sql = 'SELECT version FROM db_version;'\n    args = ()\n\n    try:\n        rowdata = namedb_query_execute(con, sql, args, abort=False)\n        row = rowdata.fetchone()\n        return row['version']\n    except:\n        # no version defined\n        return '0.0.0.0'\n    finally:\n        con.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a sqlite3 db at the given path.", "response": "def namedb_create(path, genesis_block):\n    \"\"\"\n    Create a sqlite3 db at the given path.\n    Create all the tables and indexes we need.\n    \"\"\"\n\n    global BLOCKSTACK_DB_SCRIPT\n\n    if os.path.exists( path ):\n        raise Exception(\"Database '%s' already exists\" % path)\n\n    lines = [l + \";\" for l in BLOCKSTACK_DB_SCRIPT.split(\";\")]\n    con = sqlite3.connect( path, isolation_level=None, timeout=2**30 )\n\n    for line in lines:\n        db_query_execute(con, line, ())\n\n    con.row_factory = namedb_row_factory\n\n    # create genesis block\n    namedb_create_token_genesis(con, genesis_block['rows'], genesis_block['history'])\n    return con"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_open( path ):\n    con = sqlite3.connect( path, isolation_level=None, timeout=2**30 )\n    db_query_execute(con, 'pragma mmap_size=536870912', ())\n    con.row_factory = namedb_row_factory\n\n    version = namedb_get_version(con)\n    if not semver_equal(version, VERSION):\n        # wrong version\n        raise Exception('Database has version {}, but this node is version {}.  Please update your node database (such as with fast_sync).'.format(version, VERSION))\n\n    return con", "response": "Open a connection to our database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of the row factor for a namedb table.", "response": "def namedb_row_factory( cursor, row ):\n    \"\"\"\n    Row factor to enforce some additional types:\n    * force 'revoked' to be a bool\n    \"\"\"\n    d = {}\n    for idx, col in enumerate( cursor.description ):\n        if col[0] in ['revoked', 'locked', 'receive_whitelisted']:\n            if row[idx] == 0:\n                d[col[0]] = False\n            elif row[idx] == 1:\n                d[col[0]] = True\n            elif row[idx] is None:\n                d[col[0]] = None\n            else:\n                raise Exception(\"Invalid value for 'revoked': %s\" % row[idx])\n\n        elif col[0] in ['credit_value', 'debit_value', 'vesting_value', 'token_fee']:\n            # convert back to int.\n            # this is safe in Python, since Python ints don't overflow\n            try:\n                d[col[0]] = int(row[idx]) if row[idx] is not None else None\n            except ValueError as ve:\n                log.exception(ve)\n                log.fatal(\"Caught exception while converting '{}' to an int\".format(row[idx]))\n                os.abort()\n\n        else:\n            d[col[0]] = row[idx]\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_find_missing_and_extra(cur, record, table_name):\n    rec_missing = []\n    rec_extra = []\n    \n    # sanity check: all fields must be defined\n    name_fields_rows = db_query_execute(cur, 'PRAGMA table_info({})'.format(table_name), ())\n    name_fields = []\n    for row in name_fields_rows:\n        name_fields.append( row['name'] )\n\n    # make sure each column has a record field\n    for f in name_fields:\n        if f not in record.keys():\n            rec_missing.append( f )\n\n    # make sure each record field has a column\n    for k in record.keys():\n        if k not in name_fields:\n            rec_extra.append( k )\n\n    return rec_missing, rec_extra", "response": "Find the set of fields missing from record and set of extra fields from record based on the db schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_assert_fields_match( cur, record, table_name, record_matches_columns=True, columns_match_record=True ):\n    rec_missing, rec_extra = namedb_find_missing_and_extra(cur, record, table_name)\n    if (len(rec_missing) > 0 and columns_match_record) or (len(rec_extra) > 0 and record_matches_columns):\n        raise Exception(\"Invalid record: missing = %s, extra = %s\" % \n                        (\",\".join(rec_missing), \",\".join(rec_extra)))\n\n    return True", "response": "Ensures that the fields of a given record match all columns of a given table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing to insert a record into a table.", "response": "def namedb_insert_prepare( cur, record, table_name ):\n    \"\"\"\n    Prepare to insert a record, but make sure\n    that all of the column names have values first!\n\n    Return an INSERT INTO statement on success.\n    Raise an exception if not.\n    \"\"\"\n\n    namedb_assert_fields_match( cur, record, table_name )\n     \n    columns = record.keys()\n    columns.sort()\n\n    values = []\n    for c in columns:\n        if record[c] == False:\n            values.append(0)\n        elif record[c] == True:\n            values.append(1)\n        else:\n            values.append(record[c])\n    \n    values = tuple(values)\n\n    field_placeholders = \",\".join( [\"?\"] * len(columns) )\n\n    query = \"INSERT INTO %s (%s) VALUES (%s);\" % (table_name, \",\".join(columns), field_placeholders)\n    log.debug(namedb_format_query(query, values))\n\n    return (query, values)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing to update a record.", "response": "def namedb_update_prepare( cur, primary_key_or_keys, input_record, table_name, must_equal=[], only_if={} ):\n    \"\"\"\n    Prepare to update a record, but make sure that the fields in input_record\n    correspond to acual columns.\n    Also, enforce any fields that must be equal to the fields\n    in the given record (must_equal), and require that certian fields in record\n    have certain values first (only_if)\n\n    Return an UPDATE ... SET ... WHERE statement on success.\n    Raise an exception if not.\n\n    DO NOT CALL THIS METHOD DIRECTLY\n    \"\"\"\n\n    record = copy.deepcopy( input_record )\n    must_equal_dict = dict( [(c, None) for c in must_equal] )\n\n    # extract primary key\n    # sanity check: primary key cannot be mutated\n    primary_keys = []\n    if isinstance(primary_key_or_keys, (str,unicode)):\n        primary_keys = [primary_key_or_keys]\n    else:\n        primary_keys = primary_key_or_keys\n\n    for primary_key_col in primary_keys:\n        primary_key_value = record.get(primary_key_col, None)\n        assert primary_key_value is not None, \"BUG: no primary key value given in record\"\n        assert primary_key_col in must_equal, \"BUG: primary key set to change\"\n\n    assert len(must_equal) > 0, \"BUG: no identifying information for this record\"\n\n    # find set of columns that will change \n    update_columns = []\n    for k in input_record.keys():\n        if k not in must_equal:\n            update_columns.append( k )\n\n    # record keys correspond to real columns\n    namedb_assert_fields_match( cur, record, table_name, columns_match_record=False )\n\n    # must_equal keys correspond to real columns\n    namedb_assert_fields_match( cur, must_equal_dict, table_name, columns_match_record=False )\n\n    # only_if keys correspond to real columns \n    namedb_assert_fields_match( cur, only_if, table_name, columns_match_record=False )\n\n    # only_if does not overlap with must_equal\n    assert len( set(must_equal).intersection(only_if.keys()) ) == 0, \"BUG: only_if and must_equal overlap\"\n\n    update_values = []\n    for c in update_columns:\n        if record[c] == False:\n            update_values.append(0)\n        elif record[c] == True:\n            update_values.append(1)\n        else:\n            update_values.append(record[c])\n\n    update_values = tuple(update_values)\n    update_set = [(\"%s = ?\" % c) for c in update_columns]\n\n    where_set = []\n    where_values = []\n    for c in must_equal:\n        if record[c] is None:\n            where_set.append( \"%s IS NULL\" % c )\n        elif record[c] == True:\n            where_set.append( \"%s = 1\" % c )\n        elif record[c] == False:\n            where_set.append( \"%s = 0\" % c )\n        else:\n            where_set.append( \"%s = ?\" % c)\n            where_values.append( record[c] )\n\n\n    for c in only_if.keys():\n        if only_if[c] is None:\n            where_set.append( \"%s IS NULL\" % c)\n        elif record[c] == True:\n            where_set.append( \"%s = 1\" % c )\n        elif record[c] == False:\n            where_set.append( \"%s = 0\" % c )\n        else:\n            where_set.append( \"%s = ?\" % c)\n            where_values.append( only_if[c] )\n\n    where_values = tuple(where_values)\n\n    query = \"UPDATE %s SET %s WHERE %s\" % (table_name, \", \".join(update_set), \" AND \".join(where_set))\n\n    log.debug(namedb_format_query(query, update_values + where_values))\n\n    return (query, update_values + where_values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_update_must_equal( rec, change_fields ):\n    \n    must_equal = []\n    if len(change_fields) != 0:\n        given = rec.keys()\n        for k in given:\n            if k not in change_fields:\n                must_equal.append(k)\n\n    return must_equal", "response": "Generate the set of fields that must stay the same across an update."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_delete_prepare( cur, primary_key, primary_key_value, table_name ):\n    # primary key corresponds to a real column \n    namedb_assert_fields_match( cur, {primary_key: primary_key_value}, table_name, columns_match_record=False )\n\n    query = \"DELETE FROM %s WHERE %s = ?;\" % (table_name, primary_key)\n    values = (primary_key_value,)\n    return (query, values)", "response": "Prepare to delete a record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namedb_query_execute( cur, query, values, abort=True):\n    return db_query_execute(cur, query, values, abort=abort)", "response": "Execute a query.  If it fails, abort.  Retry with timeouts on lock\n\n    DO NOT CALL THIS DIRECTLY."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_preorder_insert( cur, preorder_rec ):\n\n    preorder_row = copy.deepcopy( preorder_rec )\n    \n    assert 'preorder_hash' in preorder_row, \"BUG: missing preorder_hash\"\n\n    try:\n        preorder_query, preorder_values = namedb_insert_prepare( cur, preorder_row, \"preorders\" )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: Failed to insert name preorder '%s'\" % preorder_row['preorder_hash']) \n        os.abort()\n\n    namedb_query_execute( cur, preorder_query, preorder_values )\n    return True", "response": "Insert a name or namespace preorder record into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef namedb_preorder_remove( cur, preorder_hash ):\n    try:\n        query, values = namedb_delete_prepare( cur, 'preorder_hash', preorder_hash, 'preorders' )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: Failed to delete preorder with hash '%s'\" % preorder_hash )\n        os.abort()\n\n    log.debug(namedb_format_query(query, values))\n    namedb_query_execute( cur, query, values )\n    return True", "response": "Remove a preorder hash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_name_fields_check( name_rec ):\n\n    if not name_rec.has_key('name'):\n        raise Exception(\"BUG: name record has no name\")\n\n    # extract namespace ID if it's not already there \n    if not name_rec.has_key('namespace_id'):\n        name_rec['namespace_id'] = get_namespace_from_name( name_rec['name'] )\n\n    # extract name_hash if it's not already there \n    if not name_rec.has_key('name_hash128'):\n        name_rec['name_hash128'] = hash256_trunc128( name_rec['name'] )\n\n    return True", "response": "Check that a name record has some fields that must always be present."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_name_insert( cur, input_name_rec ):\n   \n    name_rec = copy.deepcopy( input_name_rec )\n    namedb_name_fields_check( name_rec )\n\n    try:\n        query, values = namedb_insert_prepare( cur, name_rec, \"name_records\" )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: Failed to insert name '%s'\" % name_rec['name'])\n        os.abort()\n\n    namedb_query_execute( cur, query, values )\n\n    return True", "response": "Insert a new name record into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_name_update( cur, opcode, input_opdata, only_if={}, constraints_ignored=[] ):\n\n    opdata = copy.deepcopy( input_opdata )\n    namedb_name_fields_check( opdata )\n    mutate_fields = op_get_mutate_fields( opcode )\n\n    if opcode not in OPCODE_CREATION_OPS:\n        assert 'name' not in mutate_fields, \"BUG: 'name' listed as a mutate field for '%s'\" % (opcode)\n\n    # reduce opdata down to the given fields....\n    must_equal = namedb_update_must_equal( opdata, mutate_fields )\n    must_equal += ['name','block_number']\n\n    for ignored in constraints_ignored:\n        if ignored in must_equal:\n            # ignore this constraint \n            must_equal.remove( ignored )\n\n    try:\n        query, values = namedb_update_prepare( cur, ['name', 'block_number'], opdata, \"name_records\", must_equal=must_equal, only_if=only_if )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: failed to update name '%s'\" % opdata['name'])\n        os.abort()\n\n    namedb_query_execute( cur, query, values )\n\n    try:\n        assert cur.rowcount == 1, \"Updated %s row(s)\" % cur.rowcount \n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: failed to update name '%s'\" % opdata['name'])\n        log.error(\"Query: %s\", \"\".join( [\"%s %s\" % (frag, \"'%s'\" % val if type(val) in [str, unicode] else val) for (frag, val) in zip(query.split(\"?\"), values + (\"\",))] ))\n        os.abort()\n\n    return True", "response": "Update an existing name in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the required fields are present in the namespace record.", "response": "def namedb_namespace_fields_check( namespace_rec ):\n    \"\"\"\n    Given a namespace record, make sure the following fields are present:\n    * namespace_id\n    * buckets\n\n    Makes the record suitable for insertion/update.\n    NOTE: MODIFIES namespace_rec\n    \"\"\"\n\n    assert namespace_rec.has_key('namespace_id'), \"BUG: namespace record has no ID\"\n    assert namespace_rec.has_key('buckets'), 'BUG: missing price buckets'\n    assert isinstance(namespace_rec['buckets'], str), 'BUG: namespace data is not in canonical form'\n\n    return namespace_rec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_namespace_insert( cur, input_namespace_rec ):\n\n    namespace_rec = copy.deepcopy( input_namespace_rec )\n\n    namedb_namespace_fields_check( namespace_rec )\n\n    try:\n        query, values = namedb_insert_prepare( cur, namespace_rec, \"namespaces\" )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: Failed to insert revealed namespace '%s'\" % namespace_rec['namespace_id']) \n        os.abort()\n\n    namedb_query_execute( cur, query, values )\n    return True", "response": "Insert a new namespace into the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_state_mutation_sanity_check( opcode, op_data ):\n\n    # sanity check:  each mutate field in the operation must be defined in op_data, even if it's null.\n    missing = []\n    mutate_fields = op_get_mutate_fields( opcode )\n    for field in mutate_fields:\n        if field not in op_data.keys():\n            missing.append( field )\n\n    assert len(missing) == 0, (\"BUG: operation '%s' is missing the following fields: %s\" % (opcode, \",\".join(missing)))\n    return True", "response": "Sanity check for the state mutation operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an operation (opcode, op_data), a point in time (block_id, vtxindex, txid), and a current record (history_id, cur_record), apply the operation to the record and save the delta to the record's history. Also, insert or update the new record into the db. The cur_record must exist already. Return the newly updated record on success, with all compatibility quirks preserved. Raise an exception on failure. DO NOT CALL THIS METHOD DIRECTLY.", "response": "def namedb_state_transition( cur, opcode, op_data, block_id, vtxindex, txid, history_id, cur_record, record_table, constraints_ignored=[] ):\n    \"\"\"\n    Given an operation (opcode, op_data), a point in time (block_id, vtxindex, txid), and a current\n    record (history_id, cur_record), apply the operation to the record and save the delta to the record's\n    history.  Also, insert or update the new record into the db.\n\n    The cur_record must exist already.\n\n    Return the newly updated record on success, with all compatibility quirks preserved.\n    Raise an exception on failure.\n\n    DO NOT CALL THIS METHOD DIRECTLY.\n    \"\"\"\n    \n    # sanity check: must be a state-transitioning operation\n    try:\n        assert opcode in OPCODE_NAME_STATE_TRANSITIONS + OPCODE_NAMESPACE_STATE_TRANSITIONS, \"BUG: opcode '%s' is not a state-transition\"\n        assert 'opcode' not in op_data, 'BUG: opcode not allowed in op_data'\n    except Exception, e:\n        log.exception(e)\n        log.error(\"BUG: opcode '%s' is not a state-transition operation\" % opcode)\n        os.abort()\n\n    # make sure we have a name/namespace_id and block number\n    op_data_name = copy.deepcopy(op_data)\n\n    if opcode in OPCODE_NAME_STATE_TRANSITIONS:\n        # name state transition \n        op_data_name['name'] = history_id\n\n    elif opcode in OPCODE_NAMESPACE_STATE_TRANSITIONS:\n        # namespace state transition \n        op_data_name['namespace_id'] = history_id\n\n    # sanity check make sure we got valid state transition data\n    try:\n        assert cur_record.has_key('block_number'), 'current record does not have a block number'\n        op_data_name['block_number'] = cur_record['block_number']\n\n        rc = namedb_state_transition_sanity_check( opcode, op_data_name, history_id, cur_record, record_table )\n        if not rc:\n            raise Exception(\"State transition sanity checks failed\")\n\n        rc = namedb_state_mutation_sanity_check( opcode, op_data_name )\n        if not rc:\n            raise Exception(\"State mutation sanity checks failed\")\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: state transition sanity checks failed\")\n        os.abort()\n\n    # 1. generate the new record that will be used for consensus.\n    # It will be the new data overlayed on the current record, with all quirks applied.\n    new_record = {}\n    new_record.update(cur_record)\n    new_record.update(op_data_name)\n    new_record['opcode'] = opcode\n\n    canonicalized_record = op_canonicalize_quirks(opcode, new_record, cur_record)\n    canonicalized_record['opcode'] = opcode\n    \n    rc = namedb_history_save(cur, opcode, history_id, None, new_record.get('value_hash', None), block_id, vtxindex, txid, canonicalized_record)\n    if not rc:\n        log.error(\"FATAL: failed to save history for '%s' at (%s, %s)\" % (history_id, block_id, vtxindex))\n        os.abort()\n\n    rc = False\n    merged_new_record = None\n    \n    # 2. Store the actual op_data, to be returned on name lookups\n    # Don't store extra fields that don't belong in the db (i.e. that we don't have colunms for), but preserve them across the write.\n    stored_op_data = {}\n    stored_op_data.update(op_data_name)\n\n    # separate out the extras\n    _, op_data_extra = namedb_find_missing_and_extra(cur, stored_op_data, record_table)\n    if len(op_data_extra) > 0:\n        log.debug(\"Remove extra fields: {}\".format(','.join(op_data_extra)))\n        for extra in op_data_extra:\n            del stored_op_data[extra]\n    \n    if opcode in OPCODE_NAME_STATE_TRANSITIONS:\n        # name state transition \n        rc = namedb_name_update( cur, opcode, stored_op_data, constraints_ignored=constraints_ignored )\n        if not rc:\n            log.error(\"FATAL: opcode is not a state-transition operation on names\")\n            os.abort()\n\n        merged_new_record = namedb_get_name(cur, history_id, block_id, include_history=False, include_expired=True)\n\n    elif opcode in OPCODE_NAMESPACE_STATE_TRANSITIONS:\n        # namespace state transition \n        rc = namedb_namespace_update( cur, opcode, stored_op_data, constraints_ignored=constraints_ignored )\n        if not rc:\n            log.error(\"FATAL: opcode is not a state-transition operation on namespaces\")\n            os.abort()\n\n        merged_new_record = namedb_get_namespace(cur, history_id, block_id, include_history=False, include_expired=True)\n\n    # 3. success! make sure the merged_new_record is consistent with canonicalized_record\n    for f in merged_new_record:\n        if f not in canonicalized_record:\n            raise Exception(\"canonicalized record is missing {}\".format(f))\n\n    return canonicalized_record"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_state_create_sanity_check( opcode, op_data, history_id, preorder_record, record_table ):\n\n    namedb_op_sanity_check( opcode, op_data, preorder_record )\n    preorder_opcode = op_get_opcode_name(preorder_record['op'])\n\n    if opcode in OPCODE_NAME_STATE_CREATIONS:\n        # name state transition \n        assert record_table == \"name_records\", \"BUG: name state transition opcode (%s) on table %s\" % (opcode, record_table)\n        assert preorder_opcode in OPCODE_NAME_STATE_PREORDER, \"BUG: preorder record opcode '%s' is not a name preorder\" % (preorder_opcode)\n\n        assert 'name' in op_data, 'BUG: no name in op_data'\n        assert 'block_number' in op_data, 'BUG: no block_number in op_data'\n\n    elif opcode in OPCODE_NAMESPACE_STATE_CREATIONS:\n        # namespace state transition \n        assert record_table == \"namespaces\", \"BUG: namespace state transition opcode (%s) on table %s\" % (opcode, record_table)\n        assert preorder_opcode in OPCODE_NAMESPACE_STATE_PREORDER, \"BUG: preorder record opcode '%s' is not a namespace preorder\" % (preorder_opcode)\n        \n        assert 'namespace_id' in op_data, 'BUG: no namespace_id in op_data'\n        assert 'block_number' in op_data, 'BUG: no block_number in op_data'\n\n    return True", "response": "Sanity checks on a state - creation operation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_state_create( cur, opcode, new_record, block_id, vtxindex, txid, history_id, preorder_record, record_table, constraints_ignored=[] ):\n\n    # sanity check: must be a state-creation operation \n    if opcode not in OPCODE_NAME_STATE_CREATIONS + OPCODE_NAMESPACE_STATE_CREATIONS or opcode in OPCODE_NAME_STATE_IMPORTS:\n        log.error(\"FATAL: Opcode '%s' is not a state-creating operation\" % opcode)\n        os.abort()\n    \n    # did this name or namespace previously exist?\n    exists = False\n    prev_rec = None\n    if opcode in OPCODE_NAMESPACE_STATE_CREATIONS:\n        prev_rec = namedb_get_namespace(cur, history_id, block_id, include_expired=True, include_history=False)\n        if prev_rec is not None:\n            exists = True\n\n    elif opcode in OPCODE_NAME_STATE_CREATIONS or opcode in OPCODE_NAME_STATE_IMPORTS:\n        prev_rec = namedb_get_name(cur, history_id, block_id, include_expired=True, include_history=False)\n        if prev_rec is not None:\n            exists = True\n    \n    # the record we insert into the history table\n    preorder_record_history = {}\n    preorder_record_history.update(preorder_record)\n\n    try:\n        assert 'op' in preorder_record_history.keys(), 'BUG: no preorder op'\n        assert 'preorder_hash' in preorder_record_history.keys(), \"BUG: no preorder hash\"\n        assert 'block_number' in preorder_record_history.keys(), \"BUG: preorder has no block number\"\n        assert 'vtxindex' in preorder_record_history.keys(), \"BUG: preorder has no vtxindex\"\n        assert 'txid' in preorder_record_history.keys(), \"BUG: preorder has no txid\"\n        assert 'burn_address' in preorder_record_history.keys(), 'BUG: preorder has no burn address'\n        assert 'token_fee' in preorder_record_history.keys(), 'BUG: preorder has no token fee'\n        assert 'op_fee' in preorder_record_history.keys(), 'BUG: preorder has no op fee'\n\n        if prev_rec is not None:\n            # block_number cannot change\n            assert prev_rec['block_number'] == new_record['block_number'], 'BUG: trying to change block number from {} to {} for \"{}\"'.format(prev_rec['block_number'], new_record['block_number'], history_id)\n\n        # convert token fee to string, always\n        if isinstance(preorder_record_history['token_fee'], (int,long)):\n            preorder_record_history['token_fee'] = '{}'.format(preorder_record_history['token_fee'])\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: no preorder hash\")\n        os.abort()\n        \n    try:\n        if not exists:\n            # sanity check to make sure we got valid state-creation data\n            rc = namedb_state_create_sanity_check( opcode, new_record, history_id, preorder_record, record_table )\n            if not rc:\n                raise Exception(\"state-creation sanity check on '%s' failed\" % opcode )\n\n        rc = namedb_state_mutation_sanity_check( opcode, new_record )\n        if not rc:\n            raise Exception(\"State mutation sanity checks failed\")\n\n        assert 'opcode' not in new_record, 'BUG: opcode not allowed in op_data'\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: state-creation sanity check failed\")\n        os.abort()\n\n    # save the preorder as history.\n    rc = namedb_history_save(cur, preorder_record['opcode'], history_id, None, None, preorder_record['block_number'], preorder_record['vtxindex'], preorder_record['txid'], preorder_record_history)\n    if not rc:\n        log.error(\"FATAL: failed to save preorder for {} at ({}, {})\".format(history_id, preorder_record['block_number'], preorder_record['vtxindex']))\n        os.abort()\n\n    # save new record\n    history_data = {}\n    history_data.update(new_record)\n    history_data['opcode'] = opcode\n    \n    canonicalized_record = op_canonicalize_quirks(opcode, history_data, prev_rec)\n    canonicalized_record['opcode'] = opcode\n\n    rc = namedb_history_save(cur, opcode, history_id, history_data['address'], history_data.get('value_hash', None), block_id, vtxindex, txid, canonicalized_record)\n    if not rc:\n        log.error(\"FATAL: failed to save history for '%s' at (%s, %s)\" % (history_id, block_id, vtxindex))\n        os.abort()\n\n    rc = False\n    if opcode in OPCODE_NAME_STATE_CREATIONS:\n        # name state transition \n        if exists:\n            # update existing name entry (i.e. re-registering it)\n            rc = namedb_name_update(cur, opcode, new_record, constraints_ignored=constraints_ignored)\n        else:\n            # insert new entry\n            rc = namedb_name_insert(cur, new_record)\n\n    elif opcode in OPCODE_NAMESPACE_STATE_CREATIONS:\n        # namespace state transition \n        if exists:\n            # update existing namespace entry (i.e. re-revealing it) \n            rc = namedb_namespace_update(cur, opcode, new_record, constraints_ignored=constraints_ignored)\n        else:\n            # insert new entry\n            rc = namedb_namespace_insert(cur, new_record)\n    \n    if not rc:\n        log.error(\"FATAL: opcode is not a state-creation operation\")\n        os.abort()\n\n    # clear the associated preorder \n    rc = namedb_preorder_remove( cur, preorder_record['preorder_hash'] )\n    if not rc:\n        log.error(\"FATAL: failed to remove preorder\")\n        os.abort()\n\n    # success!  canonicalize and preserve quirks\n    return canonicalized_record", "response": "Create a new state - creating record for a given operation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namedb_name_import_sanity_check( cur, opcode, op_data, history_id, block_id, vtxindex, prior_import, record_table):\n\n    assert opcode in OPCODE_NAME_STATE_IMPORTS, \"BUG: opcode '%s' does not import a name\" % (opcode)\n    assert record_table == \"name_records\", \"BUG: wrong table %s\" % record_table\n    assert namedb_is_history_snapshot( op_data ), \"BUG: import is incomplete\"\n    \n    namedb_op_sanity_check( opcode, op_data, op_data )\n\n    # must be the only such existant name, if prior_import is None\n    name_rec = namedb_get_name( cur, history_id, block_id )\n    if prior_import is None:\n        assert name_rec is None, \"BUG: trying to import '%s' for the first time, again\" % history_id\n    else:\n        assert name_rec is not None, \"BUG: trying to overwrite non-existent import '%s'\" % history_id\n        assert prior_import['name'] == history_id, \"BUG: trying to overwrite import for different name '%s'\" % history_id\n        \n        # must actually be prior\n        assert prior_import['block_number'] < block_id or (prior_import['block_number'] == block_id and prior_import['vtxindex'] < vtxindex), \\\n                \"BUG: prior_import comes after op_data\"\n\n    return True", "response": "Sanity check for name - import operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_get_last_name_import(cur, name, block_id, vtxindex):\n    query = 'SELECT history_data FROM history WHERE history_id = ? AND (block_id < ? OR (block_id = ? AND vtxindex < ?)) ' + \\\n            'ORDER BY block_id DESC,vtxindex DESC LIMIT 1;'\n\n    args = (name, block_id, block_id, vtxindex)\n\n    history_rows = namedb_query_execute(cur, query, args)\n\n    for row in history_rows:\n        history_data = json.loads(row['history_data'])\n        return history_data\n\n    return None", "response": "Get the last name import for this name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_state_create_as_import( db, opcode, new_record, block_id, vtxindex, txid, history_id, record_table, constraints_ignored=[] ):\n\n    # sanity check: must be a name, and must be an import\n    if opcode not in OPCODE_NAME_STATE_IMPORTS:\n        log.error(\"FATAL: Opcode '%s' is not a state-importing operation\" % opcode)\n        os.abort()\n\n    cur = db.cursor()\n\n    # does a previous version of this record exist?\n    prior_import = namedb_get_last_name_import(cur, history_id, block_id, vtxindex)\n\n    try:\n\n        # sanity check to make sure we got valid state-import data\n        rc = namedb_name_import_sanity_check( cur, opcode, new_record, history_id, block_id, vtxindex, prior_import, record_table )\n        if not rc:\n            raise Exception(\"state-import sanity check on '%s' failed\" % opcode )\n\n        rc = namedb_state_mutation_sanity_check( opcode, new_record )\n        if not rc:\n            raise Exception(\"State mutation sanity checks failed\")\n        \n        assert 'opcode' not in new_record, 'BUG: opcode in new_record'\n\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: state-import sanity check failed\")\n        os.abort()\n\n    cur = db.cursor()\n    creator_address = None\n    if prior_import is None:\n        # creating for the first time\n        creator_address = new_record['address']\n\n    history_data = {}\n    history_data.update(new_record)\n    history_data['opcode'] = opcode\n\n    canonicalized_record = op_canonicalize_quirks(opcode, new_record, prior_import)\n    canonicalized_record['opcode'] = opcode\n\n    rc = namedb_history_save(cur, opcode, history_id, creator_address, history_data.get('value_hash', None), block_id, vtxindex, txid, canonicalized_record)\n    if not rc:\n        log.error(\"FATAL: failed to save history snapshot for '%s' at (%s, %s)\" % (history_id, block_id, vtxindex))\n        os.abort()\n\n    if prior_import is None:\n        # creating for the first time\n        cur = db.cursor()\n        rc = namedb_name_insert(cur, new_record)\n\n    else:\n        # updating an existing import \n        rc = namedb_name_update(cur, opcode, new_record, constraints_ignored=constraints_ignored)\n\n    if not rc:\n        log.error(\"FATAL: failed to execute import operation\")\n        os.abort()\n\n    # success!  canonicalize and preserve quirks\n    return canonicalized_record", "response": "Create a new name as an import."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the state of an account at a particular point in time.", "response": "def namedb_account_transaction_save(cur, address, token_type, new_credit_value, new_debit_value, block_id, vtxindex, txid, existing_account):\n    \"\"\"\n    Insert the new state of an account at a particular point in time.\n\n    The data must be for a never-before-seen (txid,block_id,vtxindex) set in the accounts table, but must\n    correspond to an entry in the history table.\n\n    If existing_account is not None, then copy all other remaining fields from it.\n\n    Return True on success\n    Raise an Exception on error\n    \"\"\"\n    if existing_account is None:\n        existing_account = {}\n\n    accounts_insert = {\n        'address': address,\n        'type': token_type,\n        'credit_value': '{}'.format(new_credit_value),\n        'debit_value': '{}'.format(new_debit_value),\n        'lock_transfer_block_id': existing_account.get('lock_transfer_block_id', 0),        # unlocks immediately if the account doesn't exist\n        'receive_whitelisted': existing_account.get('receive_whitelisted', True),           # new accounts are whitelisted by default (for now)\n        'metadata': existing_account.get('metadata', None),\n        'block_id': block_id,\n        'txid': txid,\n        'vtxindex': vtxindex\n    }\n\n    try:\n        query, values = namedb_insert_prepare(cur, accounts_insert, 'accounts')\n    except Exception as e:\n        log.exception(e)\n        log.fatal('FATAL: failed to append account history record for {} at ({},{})'.format(address, block_id, vtxindex))\n        os.abort()\n    \n    namedb_query_execute(cur, query, values)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndecreases an account at a particular point in time by the given amount.", "response": "def namedb_account_debit(cur, account_addr, token_type, amount, block_id, vtxindex, txid):\n    \"\"\"\n    Debit an account at a particular point in time by the given amount.\n    Insert a new history entry for the account into the accounts table.\n\n    The account must exist\n\n    Abort the program if the account balance goes negative, or the count does not exist\n    \"\"\"\n    account = namedb_get_account(cur, account_addr, token_type)\n    if account is None:\n        traceback.print_stack()\n        log.fatal('Account {} does not exist'.format(account_addr))\n        os.abort()\n\n    new_credit_value = account['credit_value']\n    new_debit_value = account['debit_value'] + amount\n\n    # sanity check\n    if new_debit_value > new_credit_value:\n        traceback.print_stack()\n        log.fatal('Account {} for \"{}\" tokens overdrew (debits = {}, credits = {})'.format(account_addr, token_type, new_debit_value, new_credit_value))\n        os.abort()\n\n    new_balance = new_credit_value - new_debit_value\n    log.debug(\"Account balance of units of '{}' for {} is now {}\".format(token_type, account_addr, new_balance))\n\n    res = namedb_account_transaction_save(cur, account_addr, token_type, new_credit_value, new_debit_value, block_id, vtxindex, txid, account)\n    if not res:\n        traceback.print_stack()\n        log.fatal('Failed to save new account state for {}'.format(account_addr))\n        os.abort()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvest tokens at this block to all recipients.", "response": "def namedb_accounts_vest(cur, block_height):\n    \"\"\"\n    Vest tokens at this block to all recipients.\n    Goes through the vesting table and debits each account that should vest on this block.\n    \"\"\"\n    sql = 'SELECT * FROM account_vesting WHERE block_id = ?'\n    args = (block_height,)\n\n    vesting_rows = namedb_query_execute(cur, sql, args)\n    rows = []\n    for row in vesting_rows:\n        tmp = {}\n        tmp.update(row)\n        rows.append(tmp)\n\n    for row in rows:\n        addr = row['address']\n        token_type = row['type']\n        token_amount = row['vesting_value']\n\n        log.debug(\"Vest {} with {} {}\".format(addr, token_amount, token_type))\n        \n        fake_txid = namedb_vesting_txid(addr, token_type, token_amount, block_height)\n\n        res = namedb_account_credit(cur, addr, token_type, token_amount, block_height, 0, fake_txid)\n        if not res:\n            traceback.print_stack()\n            log.fatal('Failed to vest {} {} to {}'.format(token_amount, token_type, addr))\n            os.abort()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying that a given dict is a history snapshot.", "response": "def namedb_is_history_snapshot( history_snapshot ):\n    \"\"\"\n    Given a dict, verify that it is a history snapshot.\n    It must have all consensus fields.\n    Return True if so.\n    Raise an exception of it doesn't.\n    \"\"\"\n    \n    # sanity check:  each mutate field in the operation must be defined in op_data, even if it's null.\n    missing = []\n\n    assert 'op' in history_snapshot.keys(), \"BUG: no op given\"\n\n    opcode = op_get_opcode_name( history_snapshot['op'] )\n    assert opcode is not None, \"BUG: unrecognized op '%s'\" % history_snapshot['op']\n\n    consensus_fields = op_get_consensus_fields( opcode )\n    for field in consensus_fields:\n        if field not in history_snapshot.keys():\n            missing.append( field )\n\n    assert len(missing) == 0, (\"BUG: operation '%s' is missing the following fields: %s\" % (opcode, \",\".join(missing)))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_history_save( cur, opcode, history_id, creator_address, value_hash, block_id, vtxindex, txid, accepted_rec, history_snapshot=False ):\n\n    assert 'op' in accepted_rec, \"Malformed record at ({},{}): missing op\".format(block_id, accepted_rec['vtxindex'])\n    \n    op = accepted_rec['op']\n   \n    record_data = op_canonicalize(opcode, accepted_rec)\n    record_txt = json.dumps(record_data, sort_keys=True)\n\n    history_insert = {\n        \"txid\": txid,\n        \"history_id\": history_id,\n        \"creator_address\": creator_address,\n        \"block_id\": block_id,\n        \"vtxindex\": vtxindex,\n        \"op\": op,\n        \"opcode\": opcode,\n        \"history_data\": record_txt,\n        'value_hash': value_hash\n    }\n\n    try:\n        query, values = namedb_insert_prepare( cur, history_insert, \"history\" )\n    except Exception, e:\n        log.exception(e)\n        log.error(\"FATAL: failed to append history record for '%s' at (%s, %s)\" % (history_id, block_id, vtxindex))\n        os.abort()\n\n    namedb_query_execute( cur, query, values )\n    return True", "response": "Save a record into the state engine s history."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the history for a name or namespace from the history table.", "response": "def namedb_get_history_rows( cur, history_id, offset=None, count=None, reverse=False ):\n    \"\"\"\n    Get the history for a name or namespace from the history table.\n    Use offset/count if given.\n    \"\"\"\n    ret = []\n    if not reverse:\n        select_query = \"SELECT * FROM history WHERE history_id = ? ORDER BY block_id ASC, vtxindex ASC\"\n    else:\n        select_query = \"SELECT * FROM history WHERE history_id = ? ORDER BY block_id DESC, vtxindex DESC\"\n\n    args = (history_id,)\n\n    if count is not None:\n        select_query += \" LIMIT ?\"\n        args += (count,)\n\n        if offset is not None:\n            select_query += \" OFFSET ?\"\n            args += (offset,)\n\n    select_query += \";\"\n\n    history_rows = namedb_query_execute( cur, select_query, args)\n    for r in history_rows:\n        rd = dict(r)\n        ret.append(rd)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_num_history_rows( cur, history_id ):\n    ret = []\n    select_query = \"SELECT COUNT(*) FROM history WHERE history_id = ? ORDER BY block_id ASC, vtxindex ASC;\"\n    args = (history_id,)\n\n    count = namedb_select_count_rows( cur, select_query, args )\n    return count", "response": "Get the number of history rows for a given history_id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all of the history for a given name or namespace.", "response": "def namedb_get_history( cur, history_id, offset=None, count=None, reverse=False ):\n    \"\"\"\n    Get all of the history for a name or namespace.\n    Returns a dict keyed by block heights, paired to lists of changes (see namedb_history_extract)\n    \"\"\"\n    # get history in increasing order by block_id and then vtxindex\n    history_rows = namedb_get_history_rows( cur, history_id, offset=offset, count=count, reverse=reverse )\n    return namedb_history_extract( history_rows )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_history_extract( history_rows ):\n\n    history = {}\n    for history_row in history_rows:\n\n        block_id = history_row['block_id']\n        data_json = history_row['history_data']\n        hist = json.loads( data_json )\n        \n        hist['opcode'] = op_get_opcode_name( hist['op'] )\n        hist = op_decanonicalize(hist['opcode'], hist)\n\n        if history.has_key( block_id ):\n            history[ block_id ].append( hist )\n        else:\n            history[ block_id ] = [ hist ]\n\n    return history", "response": "Given the rows of history for a name extract them into a history dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a name s history flatten it into a list of deltas.", "response": "def namedb_flatten_history( hist ):\n    \"\"\"\n    Given a name's history, flatten it into a list of deltas.\n    They will be in *increasing* order.\n    \"\"\"\n    ret = []\n    block_ids = sorted(hist.keys())\n    for block_id in block_ids:\n        vtxinfos = hist[block_id]\n        for vtxinfo in vtxinfos:\n            info = copy.deepcopy(vtxinfo)\n            ret.append(info)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_account_tokens(cur, address):\n    sql = 'SELECT DISTINCT type FROM accounts WHERE address = ?;'\n    args = (address,)\n\n    rows = namedb_query_execute(cur, sql, args)\n    ret = []\n    for row in rows:\n        ret.append(row['type'])\n\n    return ret", "response": "Get an account s tokens\n    Returns the list of tokens on success Returns None if not found"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an account given the address and token type. Returns None if not found", "response": "def namedb_get_account(cur, address, token_type):\n    \"\"\"\n    Get an account, given the address.\n    Returns the account row on success\n    Returns None if not found\n    \"\"\"\n    sql = 'SELECT * FROM accounts WHERE address = ? AND type = ? ORDER BY block_id DESC, vtxindex DESC LIMIT 1;'\n    args = (address,token_type)\n\n    rows = namedb_query_execute(cur, sql, args)\n    row = rows.fetchone()\n    if row is None:\n        return None\n\n    ret = {}\n    ret.update(row)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the expenditure difference between two accounts.", "response": "def namedb_get_account_diff(current, prior):\n    \"\"\"\n    Figure out what the expenditure difference is between two accounts.\n    They must be for the same token type and address.\n    Calculates current - prior\n    \"\"\"\n    if current['address'] != prior['address'] or current['type'] != prior['type']:\n        raise ValueError(\"Accounts for two different addresses and/or token types\")\n\n    # NOTE: only possible since Python doesn't overflow :P\n    return namedb_get_account_balance(current) - namedb_get_account_balance(prior)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_get_account_history(cur, address, offset=None, count=None):\n    sql = 'SELECT * FROM accounts WHERE address = ? ORDER BY block_id DESC, vtxindex DESC'\n    args = (address,)\n\n    if count is not None:\n        sql += ' LIMIT ?'\n        args += (count,)\n\n    if offset is not None:\n        sql += ' OFFSET ?'\n        args += (offset,)\n\n    sql += ';'\n    rows = namedb_query_execute(cur, sql, args)\n\n    ret = []\n    for rowdata in rows:\n        tmp = {}\n        tmp.update(rowdata)\n        ret.append(tmp)\n\n    return ret", "response": "Get the history of an account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest ONLY get all account addresses", "response": "def namedb_get_all_account_addresses(cur):\n    \"\"\"\n    TESTING ONLY\n    get all account addresses\n    \"\"\"\n    assert BLOCKSTACK_TEST, 'BUG: this method is only available in test mode'\n    sql = 'SELECT DISTINCT address FROM accounts;'\n    args = ()\n    rows = namedb_query_execute(cur, sql, args)\n\n    ret = []\n    for rowdata in rows:\n        ret.append(rowdata['address'])\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a namespace by its ID and optionally its history.", "response": "def namedb_get_namespace( cur, namespace_id, current_block, include_expired=False, include_history=True, only_revealed=True):\n    \"\"\"\n    Get a namespace (revealed or ready) and optionally its history.\n    Only return an expired namespace if asked.\n    If current_block is None, any namespace is returned (expired or not)\n    If current_block is not None and only_revealed is False, then a namespace can be returned before it was revealed.\n    -- if include_expired is False, then a namespace can be returned only if current_block is less than the expire block\n    -- otherwise, any namespace can be returned\n    \"\"\"\n\n    include_expired_query = \"\"\n    include_expired_args = ()\n\n    min_age_query = \"\"\n    min_age_args = ()\n\n    if only_revealed:\n        # requier lower bound on age\n        min_age_query = \" AND namespaces.reveal_block <= ?\"\n        min_age_args = (current_block,)\n\n    if not include_expired:\n        assert current_block is not None\n        # require upper bound on age\n        include_expired_query = \" AND ? < namespaces.reveal_block + ?\"\n        include_expired_args = (current_block, NAMESPACE_REVEAL_EXPIRE)\n\n    if current_block is None:\n        # no bounds on age\n        min_age_query = \"\"\n        min_age_args = ()\n\n    select_query = \"SELECT * FROM namespaces WHERE namespace_id = ? AND \" + \\\n                   \"((op = ?) OR (op = ? %s %s))\" % (min_age_query, include_expired_query)\n\n    args = (namespace_id, NAMESPACE_READY, NAMESPACE_REVEAL) + min_age_args + include_expired_args\n\n    log.debug(namedb_format_query(select_query, args))\n\n    namespace_rows = namedb_query_execute( cur, select_query, args )\n\n    namespace_row = namespace_rows.fetchone()\n    if namespace_row is None:\n        # no such namespace \n        return None \n\n    namespace = {}\n    namespace.update( namespace_row )\n\n    if include_history:\n        hist = namedb_get_history( cur, namespace_id )\n        namespace['history'] = hist\n\n    namespace = op_decanonicalize(op_get_opcode_name(namespace['op']), namespace)\n    return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_get_namespace_by_preorder_hash( cur, preorder_hash, include_history=True ):\n\n    select_query = \"SELECT * FROM namespaces WHERE preorder_hash = ?;\"\n    namespace_rows = namedb_query_execute( cur, select_query, (preorder_hash,))\n\n    namespace_row = namespace_rows.fetchone()\n    if namespace_row is None:\n        # no such namespace \n        return None \n\n    namespace = {}\n    namespace.update( namespace_row )\n\n    if include_history:\n        hist = namedb_get_history( cur, namespace['namespace_id'] )\n        namespace['history'] = hist\n\n    namespace = op_decanonicalize(op_get_opcode_name(namespace['op']), namespace)\n    return namespace", "response": "Get a namespace by its preorder hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a name by its preorder hash.", "response": "def namedb_get_name_by_preorder_hash( cur, preorder_hash, include_history=True ):\n    \"\"\"\n    Get a name by its preorder hash (regardless of whether or not it was expired or revoked.)\n    \"\"\"\n\n    select_query = \"SELECT * FROM name_records WHERE preorder_hash = ?;\"\n    name_rows = namedb_query_execute( cur, select_query, (preorder_hash,))\n\n    name_row = name_rows.fetchone()\n    if name_row is None:\n        # no such preorder\n        return None \n\n    namerec = {}\n    namerec.update( name_row )\n\n    if include_history:\n        hist = namedb_get_history( cur, namerec['name'] )\n        namerec['history'] = hist\n\n    return namerec"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef namedb_select_where_unexpired_names(current_block, only_registered=True):\n\n    ns_lifetime_multiplier = get_epoch_namespace_lifetime_multiplier(current_block, '*')\n    ns_grace_period = get_epoch_namespace_lifetime_grace_period(current_block, '*')\n\n    unexpired_query_fragment =  \"(\" + \\\n                                    \"(\" + \\\n                                        \"namespaces.op = ? AND \" + \\\n                                        \"(\" + \\\n                                            \"(namespaces.ready_block + ((namespaces.lifetime * {}) + {}) > ?) OR \".format(ns_lifetime_multiplier, ns_grace_period) + \\\n                                            \"(name_records.last_renewed + ((namespaces.lifetime * {}) + {}) >= ?)\".format(ns_lifetime_multiplier, ns_grace_period) + \\\n                                        \")\" + \\\n                                    \") OR \" + \\\n                                    \"(\" + \\\n                                        \"namespaces.op = ? AND namespaces.reveal_block <= ? AND ? < namespaces.reveal_block + ?\" + \\\n                                    \")\" + \\\n                                \")\"\n\n    unexpired_query_args = (NAMESPACE_READY, \n                                current_block,\n                                current_block,\n                            NAMESPACE_REVEAL, current_block, current_block, NAMESPACE_REVEAL_EXPIRE)\n\n    if only_registered:\n        # also limit to only names registered before this block\n        unexpired_query_fragment = '(name_records.first_registered <= ? AND {})'.format(unexpired_query_fragment)\n        unexpired_query_args = (current_block,) + unexpired_query_args\n\n    return (unexpired_query_fragment, unexpired_query_args)", "response": "Generate a WHERE clause that selects names that are not expired at the current block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a name and all of its history.", "response": "def namedb_get_name(cur, name, current_block, include_expired=False, include_history=True, only_registered=True):\n    \"\"\"\n    Get a name and all of its history.  Note: will return a revoked name\n    Return the name + history on success\n    Return None if the name doesn't exist, or is expired (NOTE: will return a revoked name)\n    \"\"\"\n\n    if not include_expired:\n\n        unexpired_fragment, unexpired_args = namedb_select_where_unexpired_names(current_block, only_registered=only_registered)\n        select_query = \"SELECT name_records.* FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n                       \"WHERE name = ? AND \" + unexpired_fragment + \";\"\n        args = (name, ) + unexpired_args\n\n    else:\n        select_query = \"SELECT * FROM name_records WHERE name = ?;\"\n        args = (name,)\n\n    # log.debug(namedb_format_query(select_query, args))\n\n    name_rows = namedb_query_execute( cur, select_query, args )\n    name_row = name_rows.fetchone()\n    if name_row is None:\n        # no such name\n        return None \n\n    name_rec = {}\n    name_rec.update( name_row )\n    \n    if include_history:\n        name_history = namedb_get_history( cur, name )\n        name_rec['history'] = name_history\n\n    return name_rec"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a name and a DB cursor find out its DID info at the given block. Returns None if there is no such name.", "response": "def namedb_get_name_DID_info(cur, name, block_height):\n    \"\"\"\n    Given a name and a DB cursor, find out its DID info at the given block.\n    Returns {'name_type': ..., 'address': ..., 'index': ...} on success\n    Return None if there is no such name\n    \"\"\"\n    # get the latest creator addresses for this name, as well as where this name was created in the blockchain\n    sql = \"SELECT name_records.name,history.creator_address,history.block_id,history.vtxindex FROM name_records JOIN history ON name_records.name = history.history_id \" + \\\n          \"WHERE name = ? AND creator_address IS NOT NULL AND history.block_id <= ? ORDER BY history.block_id DESC, history.vtxindex DESC LIMIT 1;\"\n    args = (name,block_height)\n\n    # log.debug(namedb_format_query(sql, args))\n    rows = namedb_query_execute(cur, sql, args)\n    row = rows.fetchone()\n    if row is None:\n        return None\n    \n    creator_address = row['creator_address']\n    latest_block_height = row['block_id']\n    latest_vtxindex = row['vtxindex']\n\n    # how many names has this address created up to this name?\n    query = \"SELECT COUNT(*) FROM name_records JOIN history ON name_records.name = history.history_id \" + \\\n            \"WHERE history.creator_address = ? AND (history.block_id < ? OR (history.block_id = ? AND history.vtxindex <= ?));\"\n\n    args = (creator_address,latest_block_height,latest_block_height,latest_vtxindex)\n\n    # log.debug(namedb_format_query(query, args))\n    count_rows = namedb_query_execute(cur, query, args)\n    count_row = count_rows.fetchone()\n    if count_row is None:\n        return None\n\n    count = count_row['COUNT(*)'] - 1\n\n    return {'name_type': 'name', 'address': str(creator_address), 'index': count}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_record_states_at(cur, history_id, block_number):\n    query = 'SELECT block_id,history_data FROM history WHERE history_id = ? AND block_id == ? ORDER BY block_id DESC,vtxindex DESC'\n    args = (history_id, block_number)\n    history_rows = namedb_query_execute(cur, query, args)\n    ret = []\n\n    for row in history_rows:\n        history_data = simplejson.loads(row['history_data'])\n        ret.append(history_data)\n\n    if len(ret) > 0:\n        # record changed in this block\n        return ret\n    \n    # if the record did not change in this block, then find the last version of the record\n    query = 'SELECT block_id,history_data FROM history WHERE history_id = ? AND block_id < ? ORDER BY block_id DESC,vtxindex DESC LIMIT 1'\n    args = (history_id, block_number)\n    history_rows = namedb_query_execute(cur, query, args)\n    \n    for row in history_rows:\n        history_data = simplejson.loads(row['history_data'])\n        ret.append(history_data)\n\n    return ret", "response": "Get the states that the given history record was in at a given block height."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the states that a given account was in at a given block height", "response": "def namedb_get_account_at(cur, address, block_number):\n    \"\"\"\n    Get the state(s) that a given account was in at a given block height\n    Normally this is one state if nothing happened in this block.\n    Otherwise, this is one or more states.\n\n    Returns an array of states\n    \"\"\"\n    query = 'SELECT * FROM accounts WHERE address = ? AND block_id = ? ORDER BY block_id DESC, vtxindex DESC'\n    args = (address, block_number)\n    history_rows = namedb_query_execute(cur, query, args)\n    ret = []\n\n    for row in history_rows:\n        tmp = {}\n        tmp.update(row)\n        ret.append(tmp)\n\n    if len(ret) > 0:\n        # account changed in this block\n        return ret\n    \n    # if the account did not change in this block, then find the latest version of this account at this block\n    query = 'SELECT * from accounts WHERE address = ? AND block_id < ? ORDER BY block_id DESC,vtxindex DESC LIMIT 1'\n    args = (address, block_number)\n    history_rows = namedb_query_execute(cur, query, args)\n\n    for row in history_rows:\n        tmp = {}\n        tmp.update(row)\n        ret.append(tmp)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the sequence of states that a name record was in at a particular block height.", "response": "def namedb_get_name_at(cur, name, block_number, include_expired=False):\n    \"\"\"\n    Get the sequence of states that a name record was in at a particular block height.\n    There can be more than one if the name changed during the block.\n\n    Returns only unexpired names by default.  Can return expired names with include_expired=True\n    Returns None if this name does not exist at this block height.\n    \"\"\"\n    if not include_expired:\n        # don't return anything if this name is expired.\n        # however, we don't care if the name hasn't been created as of this block_number either, since we might return its preorder (hence only_registered=False)\n        name_rec = namedb_get_name(cur, name, block_number, include_expired=False, include_history=False, only_registered=False)\n        if name_rec is None:\n            # expired at this block.\n            return None\n\n    history_rows = namedb_get_record_states_at(cur, name, block_number)\n    if len(history_rows) == 0:\n        # doesn't exist\n        return None\n    else:\n        return history_rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namedb_get_namespace_at(cur, namespace_id, block_number, include_expired=False):\n    if not include_expired:\n        # don't return anything if the namespace was expired at this block.\n        # (but do return something here even if the namespace was created after this block, so we can potentially pick up its preorder (hence only_revealed=False))\n        namespace_rec = namedb_get_namespace(cur, namespace_id, block_number, include_expired=False, include_history=False, only_revealed=False)\n        if namespace_rec is None:\n            # expired at this block\n            return None\n\n    history_rows = namedb_get_record_states_at(cur, namespace_id, block_number)\n    if len(history_rows) == 0:\n        # doesn't exist yet \n        return None\n    else:\n        return history_rows", "response": "Get the sequence of states that a namespace record was in at a particular block height."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the balance of an account for a particular type of token.", "response": "def namedb_get_account_balance(account):\n    \"\"\"\n    Get the balance of an account for a particular type of token.\n    This is its credits minus its debits.\n    Returns the current balance on success.\n    Aborts on error, or if the balance is somehow negative.\n    \"\"\"\n    # NOTE: this is only possible because Python does not overflow :P\n    balance = account['credit_value'] - account['debit_value']\n    if balance < 0:\n        log.fatal(\"Balance of {} is {} (credits = {}, debits = {})\".format(account['address'], balance, account['credit_value'], account['debit_value']))\n        traceback.print_stack()\n        os.abort()\n\n    return balance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_get_preorder(cur, preorder_hash, current_block_number, include_expired=False, expiry_time=None):\n\n    select_query = None \n    args = None \n\n    if include_expired:\n        select_query = \"SELECT * FROM preorders WHERE preorder_hash = ?;\"\n        args = (preorder_hash,)\n\n    else:\n        assert expiry_time is not None, \"expiry_time is required with include_expired\"\n        select_query = \"SELECT * FROM preorders WHERE preorder_hash = ? AND block_number < ?;\"\n        args = (preorder_hash, expiry_time + current_block_number)\n\n    preorder_rows = namedb_query_execute( cur, select_query, (preorder_hash,))\n    preorder_row = preorder_rows.fetchone()\n    if preorder_row is None:\n        # no such preorder \n        return None\n\n    preorder_rec = {}\n    preorder_rec.update( preorder_row )\n    \n    return preorder_rec", "response": "Get a preorder record by hash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_names_owned_by_address( cur, address, current_block ):\n\n    unexpired_fragment, unexpired_args = namedb_select_where_unexpired_names( current_block )\n\n    select_query = \"SELECT name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n                   \"WHERE name_records.address = ? AND name_records.revoked = 0 AND \" + unexpired_fragment + \";\"\n    args = (address,) + unexpired_args\n\n    name_rows = namedb_query_execute( cur, select_query, args )\n\n    names = []\n    for name_row in name_rows:\n        names.append( name_row['name'] )\n\n    if len(names) == 0:\n        return None \n    else:\n        return names", "response": "Get the list of non - expired non - revoked names owned by an address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_get_num_historic_names_by_address( cur, address ):\n\n    select_query = \"SELECT COUNT(*) FROM name_records JOIN history ON name_records.name = history.history_id \" + \\\n                   \"WHERE history.creator_address = ?;\"\n\n    args = (address,)\n\n    count = namedb_select_count_rows( cur, select_query, args )\n    return count", "response": "Get the number of names owned by an address throughout history\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_historic_names_by_address( cur, address, offset=None, count=None ):\n\n    query = \"SELECT name_records.name,history.block_id,history.vtxindex FROM name_records JOIN history ON name_records.name = history.history_id \" + \\\n            \"WHERE history.creator_address = ? ORDER BY history.block_id, history.vtxindex \"\n\n    args = (address,)\n\n    offset_count_query, offset_count_args = namedb_offset_count_predicate( offset=offset, count=count )\n    query += offset_count_query + \";\"\n    args += offset_count_args\n\n    name_rows = namedb_query_execute( cur, query, args )\n\n    names = []\n    for name_row in name_rows:\n        info = {\n            'name': name_row['name'], \n            'block_id': name_row['block_id'], \n            'vtxindex': name_row['vtxindex']\n        }\n\n        names.append( info )\n\n    if len(names) == 0:\n        return None \n    else:\n        return names", "response": "Get the list of all names ever owned by this address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an offset count predicate even if offset = None count = None.", "response": "def namedb_offset_count_predicate( offset=None, count=None ):\n    \"\"\"\n    Make an offset/count predicate\n    even if offset=None or count=None.\n\n    Return (query, args)\n    \"\"\"\n    offset_count_query = \"\"\n    offset_count_args = ()\n\n    if count is not None:\n        offset_count_query += \"LIMIT ? \"\n        offset_count_args += (count,)\n\n    if count is not None and offset is not None:\n        offset_count_query += \"OFFSET ? \"\n        offset_count_args += (offset,)\n\n    return (offset_count_query, offset_count_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namedb_select_count_rows( cur, query, args, count_column='COUNT(*)' ):\n    count_rows = namedb_query_execute( cur, query, args )\n    count = 0\n    for r in count_rows:\n        count = r[count_column]\n        break\n\n    return count", "response": "Execute a SELECT COUNT(*)... query\n    and return the number of rows."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_all_blockstack_ops_at(db, block_id, offset=None, count=None):\n    assert (count is None and offset is None) or (count is not None and offset is not None), 'Invalid arguments: expect both offset/count or neither offset/count'\n\n    ret = []\n    cur = db.cursor()\n\n    # how many preorders at this block?\n    offset_count_query, offset_count_args = namedb_offset_count_predicate(offset=offset, count=count)\n\n    preorder_count_rows_query = \"SELECT COUNT(*) FROM preorders WHERE block_number = ? ORDER BY vtxindex \" + \" \" + offset_count_query + \";\"\n    preorder_count_rows_args = (block_id,) + offset_count_args\n\n    # log.debug(namedb_format_query(preorder_count_rows_query, preorder_count_rows_args))\n\n    num_preorders = namedb_select_count_rows(cur, preorder_count_rows_query, preorder_count_rows_args)\n\n    # get preorders at this block\n    offset_count_query, offset_count_args = namedb_offset_count_predicate(offset=offset, count=count)\n\n    preorder_rows_query = \"SELECT * FROM preorders WHERE block_number = ? \" + \" \" + offset_count_query + \";\"\n    preorder_rows_args = (block_id,) + offset_count_args\n\n    # log.debug(namedb_format_query(preorder_rows_query, preorder_rows_args))\n\n    preorder_rows = namedb_query_execute(cur, preorder_rows_query, preorder_rows_args)\n\n    cnt = 0\n    for preorder in preorder_rows:\n        preorder_rec = {}\n        preorder_rec.update( preorder )\n        \n        ret.append( preorder_rec )\n        cnt += 1\n\n    log.debug(\"{} preorders created at {}\".format(cnt, block_id))\n\n    # don't return too many rows, and slide down the offset window\n    if count is not None and offset is not None:\n        offset = max(0, offset - num_preorders)\n        count -= num_preorders\n        if count <= 0:\n            # done!\n            return ret\n\n    # get all other operations at this block (name ops, namespace ops, token ops)\n    offset_count_query, offset_count_args = namedb_offset_count_predicate(offset=offset, count=count)\n    query = \"SELECT history_data FROM history WHERE block_id = ? ORDER BY vtxindex \" + offset_count_query + \";\"\n    args = (block_id,) + offset_count_args\n\n    # log.debug(namedb_format_query(query, args))\n\n    rows_result = namedb_query_execute(cur, query, args)\n\n    # extract rows\n    cnt = 0\n    for r in rows_result:\n        history_data_str = r['history_data']\n\n        try:\n            history_data = json.loads(history_data_str)\n        except Exception as e:\n            log.exception(e)\n            log.error(\"FATAL: corrupt JSON string '{}'\".format(history_data_str))\n            os.abort()\n\n        ret.append(history_data)\n        cnt += 1\n\n    log.debug(\"{} non-preorder operations at {}\".format(cnt, block_id))\n    return ret", "response": "Get the list of all blockstack operations at a given block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the number of name namespace token operations that occurred at a particular block.", "response": "def namedb_get_num_blockstack_ops_at( db, block_id ):\n    \"\"\"\n    Get the number of name/namespace/token operations that occurred at a particular block.\n    \"\"\"\n    cur = db.cursor()\n\n    # preorders at this block\n    preorder_count_rows_query = \"SELECT COUNT(*) FROM preorders WHERE block_number = ?;\"\n    preorder_count_rows_args = (block_id,)\n    \n    num_preorders = namedb_select_count_rows(cur, preorder_count_rows_query, preorder_count_rows_args)\n\n    # committed operations at this block\n    query = \"SELECT COUNT(*) FROM history WHERE block_id = ?;\"\n    args = (block_id,)\n\n    rows_result = namedb_query_execute(cur, query, args)\n\n    count = 0\n    for r in rows_result:\n        count = r['COUNT(*)']\n        break\n\n    log.debug(\"{} preorders; {} history rows at {}\".format(num_preorders, count, block_id))\n    return count + num_preorders"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namedb_get_num_names( cur, current_block, include_expired=False ):\n    unexpired_query = \"\"\n    unexpired_args = ()\n\n    if not include_expired:\n        # count all names, including expired ones\n        unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n        unexpired_query = 'WHERE {}'.format(unexpired_query)\n\n    query = \"SELECT COUNT(name_records.name) FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + unexpired_query + \";\"\n    args = unexpired_args\n\n    num_rows = namedb_select_count_rows( cur, query, args, count_column='COUNT(name_records.name)' )\n    return num_rows", "response": "Get the number of names that exist at the current block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_get_all_names( cur, current_block, offset=None, count=None, include_expired=False ):\n\n    unexpired_query = \"\"\n    unexpired_args = ()\n\n    if not include_expired:\n        # all names, including expired ones\n        unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n        unexpired_query = 'WHERE {}'.format(unexpired_query)\n\n    query = \"SELECT name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + unexpired_query + \" ORDER BY name \"\n    args = unexpired_args\n\n    offset_count_query, offset_count_args = namedb_offset_count_predicate( offset=offset, count=count )\n    query += offset_count_query + \";\"\n    args += offset_count_args\n\n    name_rows = namedb_query_execute( cur, query, tuple(args) )\n    ret = []\n    for name_row in name_rows:\n        rec = {}\n        rec.update( name_row )\n        ret.append( rec['name'] )\n\n    return ret", "response": "Get a list of all names in the database optionally with offset and count."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the number of names in a given namespace", "response": "def namedb_get_num_names_in_namespace( cur, namespace_id, current_block ):\n    \"\"\"\n    Get the number of names in a given namespace\n    \"\"\"\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n\n    query = \"SELECT COUNT(name_records.name) FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id WHERE name_records.namespace_id = ? AND \" + unexpired_query + \" ORDER BY name;\"\n    args = (namespace_id,) + unexpired_args\n\n    num_rows = namedb_select_count_rows( cur, query, args, count_column='COUNT(name_records.name)' )\n    return num_rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_get_names_in_namespace( cur, namespace_id, current_block, offset=None, count=None ):\n\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n\n    query = \"SELECT name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id WHERE name_records.namespace_id = ? AND \" + unexpired_query + \" ORDER BY name \"\n    args = (namespace_id,) + unexpired_args\n\n    offset_count_query, offset_count_args = namedb_offset_count_predicate( offset=offset, count=count )\n    query += offset_count_query + \";\"\n    args += offset_count_args\n\n    name_rows = namedb_query_execute( cur, query, tuple(args) )\n    ret = []\n    for name_row in name_rows:\n        rec = {}\n        rec.update( name_row )\n        ret.append( rec['name'] )\n\n    return ret", "response": "Get a list of all names in a namespace optionally filtered with offset and count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all READY namespace IDs.", "response": "def namedb_get_all_namespace_ids( cur ):\n    \"\"\"\n    Get a list of all READY namespace IDs.\n    \"\"\"\n\n    query = \"SELECT namespace_id FROM namespaces WHERE op = ?;\"\n    args = (NAMESPACE_READY,)\n\n    namespace_rows = namedb_query_execute( cur, query, args )\n    ret = []\n    for namespace_row in namespace_rows:\n        ret.append( namespace_row['namespace_id'] )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef namedb_get_all_preordered_namespace_hashes( cur, current_block ):\n    query = \"SELECT preorder_hash FROM preorders WHERE op = ? AND block_number >= ? AND block_number < ?;\"\n    args = (NAMESPACE_PREORDER, current_block, current_block + NAMESPACE_PREORDER_EXPIRE )\n\n    namespace_rows = namedb_query_execute( cur, query, args )\n    ret = []\n    for namespace_row in namespace_rows:\n        ret.append( namespace_row['preorder_hash'] )\n\n    return ret", "response": "Get a list of all preordered namespace hashes that have not expired yet."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all non - expired revealed namespaces.", "response": "def namedb_get_all_revealed_namespace_ids( self, current_block ):\n    \"\"\"\n    Get all non-expired revealed namespaces.\n    \"\"\"\n    \n    query = \"SELECT namespace_id FROM namespaces WHERE op = ? AND reveal_block < ?;\"\n    args = (NAMESPACE_REVEAL, current_block + NAMESPACE_REVEAL_EXPIRE )\n\n    namespace_rows = namedb_query_execute( cur, query, args )\n    ret = []\n    for namespace_row in namespace_rows:\n        ret.append( namespace_row['namespace_id'] )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namedb_get_all_importing_namespace_hashes( self, current_block ):\n\n    query = \"SELECT preorder_hash FROM namespaces WHERE (op = ? AND reveal_block < ?) OR (op = ? AND block_number < ?);\"\n    args = (NAMESPACE_REVEAL, current_block + NAMESPACE_REVEAL_EXPIRE, NAMESPACE_PREORDER, current_block + NAMESPACE_PREORDER_EXPIRE )\n\n    namespace_rows = namedb_query_execute( cur, query, args )\n    ret = []\n    for namespace_row in namespace_rows:\n        ret.append( namespace_row['preorder_hash'] )\n\n    return ret", "response": "Get the list of all non - expired preordered and revealed namespace hashes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namedb_get_names_by_sender( cur, sender, current_block ):\n\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n\n    query = \"SELECT name_records.name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n            \"WHERE name_records.sender = ? AND name_records.revoked = 0 AND \" + unexpired_query + \";\"\n\n    args = (sender,) + unexpired_args\n\n    name_rows = namedb_query_execute( cur, query, args )\n    names = []\n\n    for name_row in name_rows:\n        names.append( name_row['name'] )\n\n    return names", "response": "Given a sender pubkey script find all the non - expired non - revoked names owned by it. Return None if the sender owns no names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namedb_get_name_preorder( db, preorder_hash, current_block ):\n\n    select_query = \"SELECT * FROM preorders WHERE preorder_hash = ? AND op = ? AND block_number < ?;\"\n    args = (preorder_hash, NAME_PREORDER, current_block + NAME_PREORDER_EXPIRE)\n\n    cur = db.cursor()\n    preorder_rows = namedb_query_execute( cur, select_query, args )\n    \n    preorder_row = preorder_rows.fetchone()\n    if preorder_row is None:\n        # no such preorder \n        return None \n\n    preorder_rec = {}\n    preorder_rec.update( preorder_row )\n\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( current_block )\n\n    # make sure that the name doesn't already exist \n    select_query = \"SELECT name_records.preorder_hash \" + \\\n                   \"FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n                   \"WHERE name_records.preorder_hash = ? AND \" + \\\n                   unexpired_query + \";\"\n\n    args = (preorder_hash,) + unexpired_args\n    \n    cur = db.cursor()\n    nm_rows = namedb_query_execute( cur, select_query, args )\n\n    nm_row = nm_rows.fetchone()\n    if nm_row is not None:\n        # name with this preorder exists \n        return None \n\n    return preorder_rec", "response": "Get a name preorder record outstanding at the given block."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a namespace preorder given its hash.", "response": "def namedb_get_namespace_preorder( db, namespace_preorder_hash, current_block ):\n    \"\"\"\n    Get a namespace preorder, given its hash.\n\n    Return the preorder record on success.\n    Return None if not found, or if it expired, or if the namespace was revealed or readied.\n    \"\"\"\n\n    cur = db.cursor()\n    select_query = \"SELECT * FROM preorders WHERE preorder_hash = ? AND op = ? AND block_number < ?;\"\n    args = (namespace_preorder_hash, NAMESPACE_PREORDER, current_block + NAMESPACE_PREORDER_EXPIRE)\n    preorder_rows = namedb_query_execute( cur, select_query, args )\n\n    preorder_row = preorder_rows.fetchone()\n    if preorder_row is None:\n        # no such preorder \n        return None \n\n    preorder_rec = {}\n    preorder_rec.update( preorder_row )\n\n    # make sure that the namespace doesn't already exist \n    cur = db.cursor()\n    select_query = \"SELECT preorder_hash FROM namespaces WHERE preorder_hash = ? AND ((op = ?) OR (op = ? AND reveal_block < ?));\"\n    args = (namespace_preorder_hash, NAMESPACE_READY, NAMESPACE_REVEAL, current_block + NAMESPACE_REVEAL_EXPIRE)\n    ns_rows = namedb_query_execute( cur, select_query, args )\n\n    ns_row = ns_rows.fetchone()\n    if ns_row is not None:\n        # exists\n        return None \n\n    return preorder_rec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namedb_get_namespace_reveal( cur, namespace_id, current_block, include_history=True ):\n\n    select_query = \"SELECT * FROM namespaces WHERE namespace_id = ? AND op = ? AND reveal_block <= ? AND ? < reveal_block + ?;\"\n    args = (namespace_id, NAMESPACE_REVEAL, current_block, current_block, NAMESPACE_REVEAL_EXPIRE)\n\n    namespace_reveal_rows = namedb_query_execute( cur, select_query, args )\n\n    namespace_reveal_row = namespace_reveal_rows.fetchone()\n    if namespace_reveal_row is None:\n        # no such reveal \n        return None \n\n    reveal_rec = {}\n    reveal_rec.update( namespace_reveal_row )\n\n    if include_history:\n        hist = namedb_get_history( cur, namespace_id )\n        reveal_rec['history'] = hist\n    \n    reveal_rec = op_decanonicalize('NAMESPACE_REVEAL', reveal_rec)\n    return reveal_rec", "response": "Get a namespace reveal and optionally its history given its namespace ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a ready namespace and optionally its history.", "response": "def namedb_get_namespace_ready( cur, namespace_id, include_history=True ):\n    \"\"\"\n    Get a ready namespace, and optionally its history.\n    Only return a namespace if it is ready.\n    \"\"\"\n\n    select_query = \"SELECT * FROM namespaces WHERE namespace_id = ? AND op = ?;\"\n    namespace_rows = namedb_query_execute( cur, select_query, (namespace_id, NAMESPACE_READY))\n\n    namespace_row = namespace_rows.fetchone()\n    if namespace_row is None:\n        # no such namespace \n        return None \n\n    namespace = {}\n    namespace.update( namespace_row )\n\n    if include_history:\n        hist = namedb_get_history( cur, namespace_id )\n        namespace['history'] = hist\n\n    namespace = op_decanonicalize('NAMESPACE_READY', namespace)\n    return namespace"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive the hexlified 128 - bit hash of a name get the name.", "response": "def namedb_get_name_from_name_hash128( cur, name_hash128, block_number ):\n    \"\"\"\n    Given the hexlified 128-bit hash of a name, get the name.\n    \"\"\"\n\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( block_number )\n\n    select_query = \"SELECT name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n                   \"WHERE name_hash128 = ? AND revoked = 0 AND \" + unexpired_query + \";\"\n\n    args = (name_hash128,) + unexpired_args\n    name_rows = namedb_query_execute( cur, select_query, args )\n\n    name_row = name_rows.fetchone()\n    if name_row is None:\n        # no such namespace \n        return None \n\n    return name_row['name']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the names with the given value hash.", "response": "def namedb_get_names_with_value_hash( cur, value_hash, block_number ):\n    \"\"\"\n    Get the names with the given value hash.  Only includes current, non-revoked names.\n    Return None if there are no names.\n    \"\"\"\n\n    unexpired_query, unexpired_args = namedb_select_where_unexpired_names( block_number )\n    select_query = \"SELECT name FROM name_records JOIN namespaces ON name_records.namespace_id = namespaces.namespace_id \" + \\\n                   \"WHERE value_hash = ? AND revoked = 0 AND \" + unexpired_query + \";\"\n\n    args = (value_hash,) + unexpired_args\n    name_rows = namedb_query_execute( cur, select_query, args )\n    names = []\n\n    for name_row in name_rows:\n        names.append( name_row['name'] )\n\n    if len(names) == 0:\n        return None\n    else:\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the list of txs that sent this value hash.", "response": "def namedb_get_value_hash_txids(cur, value_hash):\n    \"\"\"\n    Get the list of txs that sent this value hash, ordered by block and vtxindex\n    \"\"\"\n    query = 'SELECT txid FROM history WHERE value_hash = ? ORDER BY block_id,vtxindex;'\n    args = (value_hash,)\n\n    rows = namedb_query_execute(cur, query, args)\n    txids = []\n    \n    for r in rows:\n        # present\n        txid = str(r['txid'])\n        txids.append(txid)\n\n    return txids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of virtual transactions for this block.", "response": "def namedb_get_num_block_vtxs( cur, block_number ):\n    \"\"\"\n    How many virtual transactions were processed for this block?\n    \"\"\" \n    select_query = \"SELECT vtxindex FROM history WHERE history_id = ?;\"\n    args = (block_number,)\n\n    rows = namedb_query_execute( cur, select_query, args )\n    count = 0\n    for r in rows:\n        count += 1\n\n    return count"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a zone file hash was sent by a name.", "response": "def namedb_is_name_zonefile_hash(cur, name, zonefile_hash):\n    \"\"\"\n    Determine if a zone file hash was sent by a name.\n    Return True if so, false if not\n    \"\"\"\n    select_query = 'SELECT COUNT(value_hash) FROM history WHERE history_id = ? AND value_hash = ?'\n    select_args = (name,zonefile_hash)\n\n    rows = namedb_query_execute(cur, select_query, select_args)\n    count = None\n\n    for r in rows:\n        count = r['COUNT(value_hash)']\n        break\n\n    return count > 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_announcement( sender_namerec, op, working_dir ):\n    node_config = get_blockstack_opts()\n\n    # valid announcement\n    announce_hash = op['message_hash']\n    announcer_id = op['announcer_id']\n   \n    # verify that it came from this individual\n    name_history = sender_namerec['history']\n    allowed_value_hashes = []\n    for block_height in name_history.keys():\n        for historic_namerec in name_history[block_height]:\n            if historic_namerec.get('value_hash'):\n                allowed_value_hashes.append(historic_namerec['value_hash'])\n\n    if announce_hash not in allowed_value_hashes:\n        # this individual did not send this announcement\n        log.warning(\"Announce hash {} not found in name history for {}\".format(announce_hash, announcer_id))\n        return \n\n    # go get it from Atlas\n    zonefiles_dir = node_config.get('zonefiles', None)\n    if not zonefiles_dir:\n        log.warning(\"This node does not store zone files, so no announcement can be found\")\n        return \n\n    announce_text = get_atlas_zonefile_data(announce_hash, zonefiles_dir)\n    if announce_text is None:\n        log.warning(\"No zone file {} found\".format(announce_hash))\n        return\n\n    # go append it \n    log.critical(\"ANNOUNCEMENT (from %s): %s\\n------BEGIN MESSAGE------\\n%s\\n------END MESSAGE------\\n\" % (announcer_id, announce_hash, announce_text))         \n    store_announcement( working_dir, announce_hash, announce_text )", "response": "Process an announcement from the given sender namerec and store it in the given working directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tx_extract( payload, senders, inputs, outputs, block_id, vtxindex, txid ):\n  \n    sender_script = None \n    sender_address = None \n    sender_pubkey_hex = None\n\n    try:\n\n       # by construction, the first input comes from the principal\n       # who sent the registration transaction...\n       assert len(senders) > 0\n       assert 'script_pubkey' in senders[0].keys()\n       assert 'addresses' in senders[0].keys()\n\n       sender_script = str(senders[0]['script_pubkey'])\n       sender_address = str(senders[0]['addresses'][0])\n\n       assert sender_script is not None \n       assert sender_address is not None\n\n       if str(senders[0]['script_type']) == 'pubkeyhash':\n          sender_pubkey_hex = get_public_key_hex_from_tx( inputs, sender_address )\n\n    except Exception, e:\n       log.exception(e)\n       raise Exception(\"Failed to extract\")\n\n    parsed_payload = parse( payload )\n    assert parsed_payload is not None \n\n    ret = {\n       \"sender\": sender_script,\n       \"address\": sender_address,\n       \"block_number\": block_id,\n       \"vtxindex\": vtxindex,\n       \"txid\": txid,\n       \"op\": ANNOUNCE\n    }\n\n    ret.update( parsed_payload )\n\n    if sender_pubkey_hex is not None:\n        ret['sender_pubkey'] = sender_pubkey_hex\n\n    return ret", "response": "Extract and return a dict of fields from the underlying blockchain transaction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninterpret a nulldata block into a SHA256 hash.", "response": "def parse(bin_payload):    \n    \"\"\"\n    Interpret a block's nulldata back into a SHA256.  The first three bytes (2 magic + 1 opcode)\n    will not be present in bin_payload.\n    \"\"\"\n    \n    message_hash = hexlify(bin_payload)\n    if not is_hex( message_hash ):\n        log.warning(\"Not a message hash\")\n        return None \n\n    if len(message_hash) != 40:\n        log.warning(\"Not a 160-bit hash\")\n        return None \n\n    return {\n       'opcode': 'ANNOUNCE',\n       'message_hash': message_hash\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if an announcement is correct.", "response": "def check( state_engine, nameop, block_id, checked_ops ):\n    \"\"\"\n    Log an announcement from the blockstack developers,\n    but first verify that it is correct.\n    Return True if the announcement came from the announce IDs whitelist\n    Return False otherwise\n    \"\"\"\n\n    sender = nameop['sender']\n    sending_blockchain_id = None\n    found = False\n    blockchain_namerec = None\n\n    for blockchain_id in state_engine.get_announce_ids():\n        blockchain_namerec = state_engine.get_name( blockchain_id )\n        if blockchain_namerec is None:\n            # this name doesn't exist yet, or is expired or revoked\n            continue\n\n        if str(sender) == str(blockchain_namerec['sender']):\n            # yup!\n            found = True\n            sending_blockchain_id = blockchain_id\n            break\n\n    if not found:\n        log.warning(\"Announcement not sent from our whitelist of blockchain IDs\")\n        return False\n\n    nameop['announcer_id'] = sending_blockchain_id\n    process_announcement( blockchain_namerec, nameop, state_engine.working_dir )\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bitcoind_client():\n    bitcoind_opts = get_bitcoin_opts()\n    bitcoind_host = bitcoind_opts['bitcoind_server']\n    bitcoind_port = bitcoind_opts['bitcoind_port']\n    bitcoind_user = bitcoind_opts['bitcoind_user']\n    bitcoind_passwd = bitcoind_opts['bitcoind_passwd']\n    \n    return create_bitcoind_service_proxy(bitcoind_user, bitcoind_passwd, server=bitcoind_host, port=bitcoind_port)", "response": "Connect to the bitcoind node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a txid get its block s data.", "response": "def txid_to_block_data(txid, bitcoind_proxy, proxy=None):\n    \"\"\"\n    Given a txid, get its block's data.\n\n    Use SPV to verify the information we receive from the (untrusted)\n    bitcoind host.\n\n    @bitcoind_proxy must be a BitcoindConnection (from virtualchain.lib.session)\n\n    Return the (block hash, block data, txdata) on success\n    Return (None, None, None) on error\n    \"\"\"\n\n    proxy = get_default_proxy() if proxy is None else proxy\n\n    timeout = 1.0\n    while True:\n        try:\n            untrusted_tx_data = bitcoind_proxy.getrawtransaction(txid, 1)\n            untrusted_block_hash = untrusted_tx_data['blockhash']\n            untrusted_block_data = bitcoind_proxy.getblock(untrusted_block_hash)\n            break\n        except (OSError, IOError) as ie:\n            log.exception(ie)\n            log.error('Network error; retrying...')\n            timeout = timeout * 2 + random.randint(0, timeout)\n            continue\n        except Exception as e:\n            log.exception(e)\n            return None, None, None\n\n    bitcoind_opts = get_bitcoin_opts()\n    spv_headers_path = bitcoind_opts['bitcoind_spv_path']\n\n    # first, can we trust this block? is it in the SPV headers?\n    untrusted_block_header_hex = virtualchain.block_header_to_hex(\n        untrusted_block_data, untrusted_block_data['previousblockhash']\n    )\n\n    block_id = SPVClient.block_header_index(\n        spv_headers_path,\n        ('{}00'.format(untrusted_block_header_hex)).decode('hex')\n    )\n\n    if block_id < 0:\n        # bad header\n        log.error('Block header \"{}\" is not in the SPV headers ({})'.format(\n            untrusted_block_header_hex, spv_headers_path\n        ))\n\n        return None, None, None\n\n    # block header is trusted.  Is the transaction data consistent with it?\n    verified_block_header = virtualchain.block_verify(untrusted_block_data)\n\n    if not verified_block_header:\n        msg = (\n            'Block transaction IDs are not consistent '\n            'with the Merkle root of the trusted header'\n        )\n\n        log.error(msg)\n\n        return None, None, None\n\n    # verify block hash\n    verified_block_hash = virtualchain.block_header_verify(\n        untrusted_block_data, untrusted_block_data['previousblockhash'], untrusted_block_hash\n    )\n\n    if not verified_block_hash:\n        log.error('Block hash is not consistent with block header')\n        return None, None, None\n\n    # we trust the block hash, block data, and txids\n    block_hash = untrusted_block_hash\n    block_data = untrusted_block_data\n    tx_data = untrusted_tx_data\n\n    return block_hash, block_data, tx_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serial_number_to_tx(serial_number, bitcoind_proxy, proxy=None):\n\n    proxy = get_default_proxy() if proxy is None else proxy\n\n    parts = serial_number.split('-')\n    block_id, tx_index = int(parts[0]), int(parts[1])\n\n    timeout = 1.0\n    while True:\n        try:\n            block_hash = bitcoind_proxy.getblockhash(block_id)\n            block_data = bitcoind_proxy.getblock(block_hash)\n            break\n        except Exception as e:\n            log.error('Unable to obtain block data; retrying...')\n            time.sleep(timeout)\n            timeout = timeout * 2 + random.random() * timeout\n\n    bitcoind_opts = get_bitcoin_opts()\n    spv_headers_path = bitcoind_opts['bitcoind_spv_path']\n    bitcoind_server = bitcoind_opts['bitcoind_server']\n\n    rc = SPVClient.sync_header_chain(\n        spv_headers_path, bitcoind_server, block_id\n    )\n\n    if not rc:\n        msg = 'Failed to synchronize SPV header chain up to {}'\n        log.error(msg.format(block_id))\n        return None\n\n    # verify block header\n    rc = SPVClient.block_header_verify(spv_headers_path, block_id, block_hash, block_data)\n    if not rc:\n        msg = 'Failed to verify block header for {} against SPV headers'\n        log.error(msg.format(block_id))\n        return None\n\n    # verify block txs\n    rc = SPVClient.block_verify(block_data, block_data['tx'])\n    if not rc:\n        msg = 'Failed to verify block transaction IDs for {} against SPV headers'\n        log.error(msg.format(block_id))\n        return None\n\n    # sanity check\n    if tx_index >= len(block_data['tx']):\n        msg = 'Serial number {} references non-existant transaction {} (out of {} txs)'\n        log.error(msg.format(serial_number, tx_index, len(block_data['tx'])))\n        return None\n\n    # obtain transaction\n    txid = block_data['tx'][tx_index]\n    tx = bitcoind_proxy.getrawtransaction(txid, 1)\n\n    # verify tx\n    rc = SPVClient.tx_verify(block_data['tx'], tx)\n    if not rc:\n        msg = 'Failed to verify block transaction {} against SPV headers'\n        log.error(msg.format(txid))\n        return None\n\n    # verify tx index\n    if tx_index != SPVClient.tx_index(block_data['tx'], tx):\n        msg = (\n            'TX index mismatch: serial number identifies '\n            'transaction number {} ({}), but got transaction {}'\n        )\n\n        log.error(msg.format(\n            tx_index, block_data['tx'][tx_index],\n            block_data['tx'][SPVClient.tx_index(block_data['tx'], tx)]\n        ))\n        return None\n\n    # success!\n    return tx", "response": "Convert a serial number into a transaction in the blockchain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_tx_op_return(tx):\n\n    # find OP_RETURN output\n    op_return = None\n    outputs = tx['vout']\n    for out in outputs:\n        script_key = out['scriptPubKey']['hex']\n        if int(script_key[0:2], 16) == virtualchain.OPCODE_VALUES['OP_RETURN']:\n            op_return = script_key.decode('hex')\n            break\n\n    if op_return is None:\n        msg = 'transaction has no OP_RETURN output'\n        log.error(msg)\n        log.debug('{}:\\n{}'.format(msg, simplejson.dumps(tx)))\n        return None, None\n\n    # [0] is OP_RETURN, [1] is the length; [2:4] are 'id', [4] is opcode\n    magic = op_return[2:4]\n\n    if magic != blockstack_magic_bytes():\n        # not a blockchain ID operation\n        msg = 'OP_RETURN output does not encode a blockchain ID operation'\n        log.error(msg)\n        return None, None\n\n    opcode, payload = op_return[4], op_return[5:]\n\n    return (opcode, payload)", "response": "Given a transaction locate its OP_RETURN and parse it out its opcode and payload."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_consensus_hash_from_tx(tx):\n\n    opcode, payload = parse_tx_op_return(tx)\n    if opcode is None or payload is None:\n        return None\n\n    # only present in NAME_PREORDER, NAMESPACE_PREORDER, NAME_TRANSFER\n    if opcode in [NAME_PREORDER, NAMESPACE_PREORDER, NAME_TRANSFER]:\n        consensus_hash = payload[-16:].encode('hex')\n        return consensus_hash\n\n    msg = (\n        'Blockchain ID transaction is not a '\n        'NAME_PREORDER, NAMESPACE_PROERDER or NAME_TRANSFER'\n    )\n\n    log.error(msg)\n\n    return None", "response": "Given an SPV - verified transaction extract its consensus hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef snv_get_blockstack_ops_at(current_block_id, current_consensus_hash, block_id, consensus_hash, proxy=None):\n    import blockstack\n\n    log.debug('verify {}-{} to {}-{}'.format(\n        current_block_id, current_consensus_hash, block_id, consensus_hash\n    ))\n\n    proxy = get_default_proxy() if proxy is None else proxy\n\n    # work backwards in time, using a Merkle skip-list constructed\n    # by blockstackd over the set of consensus hashes.\n    next_block_id = current_block_id\n\n    prev_blockstack_ops_hashes = {}\n    prev_consensus_hashes = {\n        next_block_id: current_consensus_hash\n    }\n\n    # print 'next_block_id = {}, block_id = {}'.format(next_block_id, block_id)\n    while next_block_id >= block_id:\n        # get blockstack_ops_at[ next_block_id ], and all consensus_hash[ next_block_id - 2^i ]\n        # such that block_id - 2*i > block_id (start at i = 1)\n        i = 0\n        blockstack_ops_hash = None\n\n        if next_block_id in prev_blockstack_ops_hashes:\n            blockstack_ops_hash = prev_blockstack_ops_hashes[next_block_id]\n        else:\n            blockstack_ops_resp = get_blockstack_ops_hash_at(next_block_id, proxy=proxy)\n\n            if 'error' in blockstack_ops_resp:\n                log.error('get_blockstack_ops_hash_at: {}'.format(blockstack_ops_resp['error']))\n                return {'error': 'Failed to get nameops: {}'.format(blockstack_ops_resp['error'])}\n\n            blockstack_ops_hash = str(blockstack_ops_resp)\n            prev_blockstack_ops_hashes[next_block_id] = blockstack_ops_hash\n\n        log.debug('nameops hash at {}: {}'.format(next_block_id, blockstack_ops_hash))\n\n        # find out which consensus hashes we'll need\n        to_fetch = []\n        ch_block_ids = []\n        while next_block_id - (2 ** (i + 1) - 1) >= FIRST_BLOCK_MAINNET:\n            i += 1\n            prev_block_id = next_block_id - (2 ** i - 1)\n            ch_block_ids.append(prev_block_id)\n\n            if prev_block_id not in prev_consensus_hashes:\n                to_fetch.append(prev_block_id)\n\n        # get the consensus hashes\n        chs = {}\n        if to_fetch:\n            chs = get_consensus_hashes(to_fetch, proxy=proxy)\n            if 'error' in chs:\n                msg = 'Failed to get consensus hashes for {}: {}'\n                log.error(msg.format(to_fetch, chs['error']))\n                return {'error': 'Failed to get consensus hashes'}\n\n        prev_consensus_block_ids = []\n        for b in ch_block_ids:\n            # NOTE: we process to_fetch *in decreasing order* so we know when we're missing data\n            if b not in chs and b not in prev_consensus_hashes:\n                msg = 'Missing consensus hash response for {} (chs={}, prev_chs={})'\n                log.error(msg.format(b, chs, prev_consensus_hashes))\n                return {'error': 'Server did not reply valid data'}\n\n            prev_consensus_block_ids.append(b)\n            if b in prev_consensus_hashes:\n                # already got this one\n                continue\n\n            ch = chs[b]\n            if ch is not None:\n                prev_consensus_hashes[b] = str(ch)\n            else:\n                # no consensus hash for this block and all future blocks\n                prev_consensus_block_ids.pop()\n                break\n\n        # prev_consensus_hashes_list = [ prev_consensus_hashes[b] for b in ch_block_ids ]\n        prev_consensus_hashes_list = [\n            prev_consensus_hashes[b] for b in prev_consensus_block_ids\n        ]\n\n        # calculate the snapshot, and see if it matches\n        ch = virtualchain.StateEngine.make_snapshot_from_ops_hash(\n            blockstack_ops_hash, prev_consensus_hashes_list\n        )\n\n        expected_ch = prev_consensus_hashes[next_block_id]\n        if ch != expected_ch:\n            msg = 'Consensus hash mismatch at {}: expected {}, got {} (from {}, {})'\n            log.error(msg.format(next_block_id, expected_ch, ch, blockstack_ops_hash, prev_consensus_hashes))\n            return {'error': 'Consensus hash mismatch'}\n\n        # advance!\n        # find the smallest known consensus hash whose block is greater than block_id\n        current_candidate = next_block_id\n        found_any = False\n        for candidate_block_id in prev_consensus_hashes:\n            if candidate_block_id < block_id:\n                continue\n\n            if candidate_block_id < current_candidate:\n                current_candidate = candidate_block_id\n                found_any = True\n\n        if not found_any:\n            break\n\n        next_block_id = current_candidate\n\n    # get the final nameops\n    historic_nameops = get_blockstack_transactions_at(block_id, proxy=proxy)\n    if isinstance(historic_nameops, dict) and 'error' in historic_nameops:\n        log.error('Failed to get nameops at {}: {}'.format(block_id, historic_nameops['error']))\n        return {'error': 'BUG: no nameops found'}\n\n    log.debug(\"nameops at {}\\n{}\".format(block_id, json.dumps(historic_nameops, sort_keys=True)))\n\n    # sanity check...\n    for historic_op in historic_nameops:\n        if 'opcode' not in historic_op:\n            return {'error': 'Invalid/corrupt name operations detected'}\n\n        # recover binary op string\n        if 'op' not in historic_op:\n            historic_op['op'] = NAME_OPCODES[str(historic_op['opcode'])]\n\n    # check integrity\n    opfields = blockstack.lib.virtualchain_hooks.get_opfields()\n    serialized_historic_nameops = [\n        virtualchain.StateEngine.serialize_op(\n            str(op['op'][0]), op, opfields, verbose=True\n        ) for op in historic_nameops\n    ]\n\n    historic_blockstack_ops_hash = virtualchain.StateEngine.make_ops_snapshot(serialized_historic_nameops)\n\n    if block_id not in prev_blockstack_ops_hashes:\n        return {'error': 'Previous block/consensus hash is unreachable from trusted block/consensus hash'}\n\n    if historic_blockstack_ops_hash != prev_blockstack_ops_hashes[block_id]:\n        log.error(\"historic nameops hash at {}: {}\".format(block_id, historic_blockstack_ops_hash))\n        log.error(\"prev_blockstack_ops_hashes:\\n{}\".format(json.dumps(prev_blockstack_ops_hashes, indent=4, sort_keys=True)))\n        return {\n            'error': 'Hash mismatch: failed to get operations at {}-{} from {}-{} ({} != {})'.format(\n                block_id, consensus_hash, current_block_id, current_consensus_hash, historic_blockstack_ops_hash, prev_blockstack_ops_hashes[block_id]\n            )\n        }\n\n    log.debug('{} nameops at {}'.format(len(historic_nameops), block_id))\n\n    # strip history\n    for hn in historic_nameops:\n        if 'history' in hn.keys():\n            del hn['history']\n\n    return historic_nameops", "response": "This function is used to get the set of name operations from the past given the current consensus hash and block ID and consensus hash."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that a name existed at a particular block ID in the past.", "response": "def snv_name_verify(name, current_block_id, current_consensus_hash, block_id,\n                    consensus_hash, trusted_txid=None, trusted_txindex=None, proxy=None):\n    \"\"\"\n    Use SNV to verify that a name existed at a particular block ID in the past,\n    given a later known-good block ID and consensus hash (as well as the previous\n    untrusted consensus hash)\n\n    Return the name's historic nameop(s) on success.\n    If there are multiple matches, multiple nameops will be returned.\n    The return value takes the form of {'status': True, 'nameops': [...]}\n    Return a dict with {'error'} on error\n    \"\"\"\n\n    proxy = get_default_proxy() if proxy is None else proxy\n\n    historic_nameops = snv_get_blockstack_ops_at(\n        current_block_id, current_consensus_hash,\n        block_id, consensus_hash, proxy=proxy\n    )\n\n    if 'error' in historic_nameops:\n        return historic_nameops\n\n    matching_nameops = []\n\n    # find the one we asked for\n    for nameop in historic_nameops:\n        # select on more-accurate filters first\n        if trusted_txindex is not None and nameop['vtxindex'] == trusted_txindex:\n            matching_nameops = [nameop]\n            break\n\n        if trusted_txid is not None and nameop['txid'] == trusted_txid:\n            matching_nameops = [nameop]\n            break\n\n        if 'name' not in nameop:\n            continue\n\n        if str(nameop['name']) == str(name):\n            # success!\n            matching_nameops.append(nameop)\n            continue\n\n    if matching_nameops:\n        return {'status': True, 'nameops': matching_nameops}\n\n    # not found\n    log.error('Not found at block {}: \"{}\"'.format(block_id, name))\n    return {'error': 'Name not found'}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef snv_lookup(verify_name, verify_block_id,\n               trusted_serial_number_or_txid_or_consensus_hash, hostport=None, proxy=None, trusted_txid=None):\n\n    \"\"\"\n    High-level call to simple name verification:\n    Given a trusted serial number, txid, or consensus_hash, use it as a trust root to verify that\n    a previously-registered but untrusted name (@verify_name) exists and was processed\n    at a given block (@verify_block_id)\n\n    Basically, use the trust root to derive a \"current\" block ID and consensus hash, and\n    use the untrusted (name, block_id) pair to derive an earlier untrusted block ID and\n    consensus hash.  Then, use the snv_get_blockstack_ops_at() method to verify that the name\n    existed at the given block ID.\n\n    The Blockstack node is not trusted.  This algorithm prevents a malicious Blockstack node\n    from getting the caller to falsely trust @verify_name and @verify_block_id by\n    using SNV to confirm that:\n    * the consensus hash at the trust root's block is consistent with @verify_name's\n    corresponding NAMESPACE_PREORDER or NAME_PREORDER;\n    * the consensus hash at @trusted_serial_number's block is consistent with @verify_name's\n    consensus hash (from @verify_serial_number)\n\n    The only way a Blockstack node working with a malicious Sybil can trick the caller is if\n    both can create a parallel history of name operations such that the final consensus hash\n    at @trusted_serial_number's block collides.  This is necessary, since the client uses\n    the hash over a block's operations and prior consensus hashes to transitively trust\n    prior consensus hashes--if the later consensus hash is assumed out-of-band to be valid,\n    then the transitive closure of all prior consensus hashes will be assumed valid as well.\n    This means that the only way to drive the valid consensus hash from a prior invalid\n    consensus hash is to force a hash collision somewhere in the transitive closure, which is infeasible.\n\n    NOTE: @trusted_txid is needed for isolating multiple operations in the same name within a single block.\n\n    Return the list of nameops in the given verify_block_id that match.\n    \"\"\"\n\n    proxy = get_default_proxy(hostport) if proxy is None else proxy\n\n    trusted_serial_number_or_txid_or_consensus_hash = str(trusted_serial_number_or_txid_or_consensus_hash)\n\n    bitcoind_proxy = get_bitcoind_client()\n    trusted_serial_number = None\n    trusted_tx_index = None\n    trusted_consensus_hash = None\n    trusted_block_id = None\n\n    # what did we get?\n    hash_len_64 = len(trusted_serial_number_or_txid_or_consensus_hash) == 64\n    hash_len_32 = len(trusted_serial_number_or_txid_or_consensus_hash) == 32\n    hash_parts_2 = len(trusted_serial_number_or_txid_or_consensus_hash.split('-')) == 2\n    hash_is_hex = is_hex(trusted_serial_number_or_txid_or_consensus_hash)\n\n    if hash_len_64 and hash_is_hex:\n        # txid: convert to trusted block ID and consensus hash\n        trusted_txid = trusted_serial_number_or_txid_or_consensus_hash\n        trusted_block_hash, trusted_block_data, trusted_tx = txid_to_block_data(trusted_txid, bitcoind_proxy)\n        if trusted_block_hash is None or trusted_block_data is None or trusted_tx is None:\n            return {'error': 'Unable to look up given transaction ID'}\n\n        # must have a consensus hash\n        # TOOD: Check why return values are ignored\n        op, payload = parse_tx_op_return(trusted_tx)\n        trusted_consensus_hash = get_consensus_hash_from_tx(trusted_tx)\n        if trusted_consensus_hash is None:\n            return {'error': 'Tx does not refer to a consensus-bearing transaction'}\n\n        # find the block for this consensus hash (it's not the same as the serial number's block ID,\n        # but that's okay--if the consensus hash in this tx is inauthentic, it will be unreachable\n        # from the other consensus hash [short of a SHA256 collision])\n        trusted_block_id = get_block_from_consensus(trusted_consensus_hash, proxy=proxy)\n\n    elif hash_len_32 and hash_is_hex:\n        # consensus hash\n        trusted_consensus_hash = trusted_serial_number_or_txid_or_consensus_hash\n        trusted_block_id = get_block_from_consensus(trusted_consensus_hash, proxy=proxy)\n        if isinstance(trusted_block_id, dict) and 'error' in trusted_block_id:\n            # got error back\n            return trusted_block_id\n        \n    elif hash_parts_2:\n        # must be a serial number\n        parts = trusted_serial_number_or_txid_or_consensus_hash.split('-')\n        try:\n            trusted_block_id = int(parts[0])\n            trusted_tx_index = int(parts[1])\n        except:\n            log.error('Malformed serial number \"{}\"'.format(trusted_serial_number_or_txid_or_consensus_hash))\n            return {'error': 'Did not receive a valid serial number'}\n\n        trusted_tx = serial_number_to_tx(trusted_serial_number_or_txid_or_consensus_hash, bitcoind_proxy)\n        if trusted_tx is None:\n            return {'error': 'Unable to convert given serial number into transaction'}\n\n        # tx must have a consensus hash\n        # TOOD: Check why return values are ignored\n        op, payload = parse_tx_op_return(trusted_tx)\n        trusted_consensus_hash = get_consensus_hash_from_tx(trusted_tx)\n        if trusted_consensus_hash is None:\n            return {'error': 'Tx does not refer to a consensus-bearing transaction'}\n\n        # find the block for this consensus hash (it's not the same as the serial number's block ID,\n        # but that's okay--if the consensus hash in this tx is inauthentic, it will be unreachable\n        # from the other consensus hash [short of a SHA256 collision])\n        trusted_block_id = get_block_from_consensus(trusted_consensus_hash, proxy=proxy)\n        if isinstance(trusted_block_id, dict) and 'error' in trusted_block_id:\n            # got error back\n            return trusted_block_id\n    else:\n        msg = 'Did not receive a valid txid, consensus hash, or serial number ({})'\n        return {'error': msg.format(trusted_serial_number_or_txid_or_consensus_hash)}\n\n    if trusted_block_id < verify_block_id:\n        msg = 'Trusted block/consensus hash came before the untrusted block/consensus hash'\n        return {'error': msg}\n\n    # go verify the name\n    verify_consensus_hash = get_consensus_at(verify_block_id, proxy=proxy)\n    historic_namerecs = snv_name_verify(\n        verify_name, trusted_block_id, trusted_consensus_hash,\n        verify_block_id, verify_consensus_hash,\n        trusted_txid=trusted_txid, trusted_txindex=trusted_tx_index\n    )\n\n    if 'error' in historic_namerecs:\n        return historic_namerecs\n\n    return historic_namerecs['nameops']", "response": "This function is used to perform simple name verification on a given untrusted name and block ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the given response is an exception traceback", "response": "def json_is_exception(resp):\n    \"\"\"\n    Is the given response object\n    an exception traceback?\n\n    Return True if so\n    Return False if not\n    \"\"\"\n    if not json_is_error(resp):\n        return False\n\n    if 'traceback' not in resp.keys() or 'error' not in resp.keys():\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_validate(schema, resp):\n    # is this an error?\n    try:\n        json_validate_error(resp)\n    except ValidationError:\n        if json_is_exception(resp):\n            # got a traceback \n            if BLOCKSTACK_TEST:\n                log.error('\\n{}'.format(resp['traceback']))\n\n            return {'error': 'Blockstack Core encountered an exception. See `traceback` for details', 'traceback': resp['traceback'], 'http_status': 500}\n\n        if 'error' in resp and 'http_status' not in resp:\n            # bad error message\n            raise \n\n        # not an error.\n        jsonschema.validate(resp, schema)\n\n    return resp", "response": "Validate an RPC response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a stack trace as a JSON - formatted error message.", "response": "def json_traceback(error_msg=None):\n    \"\"\"\n    Generate a stack trace as a JSON-formatted error message.\n    Optionally use error_msg as the error field.\n    Return {'error': ..., 'traceback'...}\n    \"\"\"\n\n    exception_data = traceback.format_exc().splitlines()\n    if error_msg is None:\n        error_msg = '\\n'.join(exception_data)\n    else:\n        error_msg = 'Remote RPC error: {}'.format(error_msg)\n\n    return {\n        'error': error_msg,\n        'traceback': exception_data\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_response_schema( expected_object_schema ):\n    schema = {\n        'type': 'object',\n        'properties': {\n            'status': {\n                'type': 'boolean',\n            },\n            'indexing': {\n                'type': 'boolean',\n            },\n            'lastblock': {\n                'anyOf': [\n                    {\n                        'type': 'integer',\n                        'minimum': 0,\n                    },\n                    {\n                        'type': 'null',\n                    },\n                ],\n            },\n        },\n        'required': [\n            'status',\n            'indexing',\n            'lastblock'\n        ],\n    }\n\n    # fold in the given object schema\n    schema['properties'].update( expected_object_schema['properties'] )\n    schema['required'] = list(set( schema['required'] + expected_object_schema['required'] ))\n\n    return schema", "response": "Make a schema for a standard server response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_hostport(hostport, timeout=RPC_DEFAULT_TIMEOUT, my_hostport=None):\n    host, port = url_to_host_port(hostport)\n\n    assert host is not None and port is not None\n\n    protocol = url_protocol(hostport)\n    if protocol is None:\n        log.warning(\"No scheme given in {}. Guessing by port number\".format(hostport))\n        if port == RPC_SERVER_PORT or port == RPC_SERVER_TEST_PORT:\n            protocol = 'http'\n        else:\n            protocol = 'https'\n\n    proxy = BlockstackRPCClient(host, port, timeout=timeout, src=my_hostport, protocol=protocol)\n    return proxy", "response": "Connect to the given host and port string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nping the Blockstack node.", "response": "def ping(proxy=None, hostport=None):\n    \"\"\"\n    rpc_ping\n    Returns {'alive': True} on succcess\n    Returns {'error': ...} on error\n    \"\"\"\n    schema = {\n        'type': 'object',\n        'properties': {\n            'status': {\n                'type': 'string'\n            },\n        },\n        'required': [\n            'status'\n        ]\n    }\n\n    assert proxy or hostport, 'Need either proxy handle or hostport string'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    resp = {}\n\n    try:\n        resp = proxy.ping()\n        resp = json_validate( schema, resp )\n        if json_is_error(resp):\n            return resp\n\n        assert resp['status'] == 'alive'\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the atlas zonefile inventory from the given peer.", "response": "def get_zonefile_inventory(hostport, offset, count, timeout=30, my_hostport=None, proxy=None):\n    \"\"\"\n    Get the atlas zonefile inventory from the given peer.\n    offset/count are in bytes.\n    Return {'status': True, 'inv': inventory} on success.\n    Return {'error': ...} on error\n    \"\"\"\n    \n    assert hostport or proxy, 'Need either hostport or proxy'\n\n    inv_schema = {\n        'type': 'object',\n        'properties': {\n            'inv': {\n                'type': 'string',\n                'pattern': OP_BASE64_EMPTY_PATTERN\n            },\n        },\n        'required': [\n            'inv'\n        ]\n    }\n\n    schema = json_response_schema( inv_schema )\n\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    zf_inv = None\n    try:\n        zf_inv = proxy.get_zonefile_inventory(offset, count)\n        zf_inv = json_validate(schema, zf_inv)\n        if json_is_error(zf_inv):\n            return zf_inv\n\n        # decode\n        zf_inv['inv'] = base64.b64decode(str(zf_inv['inv']))\n\n        # make sure it corresponds to this range\n        assert len(zf_inv['inv']) <= count, 'Zonefile inventory in is too long (got {} bytes)'.format(len(zf_inv['inv']))\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except AssertionError as ae:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ae)\n\n        resp = {'error': 'Server replied an invalid zone file inventory vector'}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return zf_inv"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_atlas_peers(hostport, timeout=30, my_hostport=None, proxy=None):\n    assert hostport or proxy, 'need either hostport or proxy'\n\n    peers_schema = {\n        'type': 'object',\n        'properties': {\n            'peers': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'pattern': '^([^:]+):([1-9][0-9]{1,4})$',\n                },\n            },\n        },\n        'required': [\n            'peers'\n        ],\n    }\n\n    schema = json_response_schema( peers_schema )\n\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    peers = None\n    try:\n        peer_list_resp = proxy.get_atlas_peers()\n        peer_list_resp = json_validate(schema, peer_list_resp)\n        if json_is_error(peer_list_resp):\n            return peer_list_resp\n\n        # verify that all strings are host:ports\n        for peer_hostport in peer_list_resp['peers']:\n            peer_host, peer_port = url_to_host_port(peer_hostport)\n            if peer_host is None or peer_port is None:\n                return {'error': 'Server did not return valid Atlas peers', 'http_status': 503}\n\n        peers = peer_list_resp\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node {}.  Try again with `--debug`.'.format(hostport), 'http_status': 500}\n        return resp\n\n    return peers", "response": "Get an atlas peer s neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a set of zonefiles from the given server.", "response": "def get_zonefiles(hostport, zonefile_hashes, timeout=30, my_hostport=None, proxy=None):\n    \"\"\"\n    Get a set of zonefiles from the given server.  Used primarily by Atlas.\n    Return {'status': True, 'zonefiles': {hash: data, ...}} on success\n    Return {'error': ...} on error\n    \"\"\"\n\n    assert hostport or proxy, 'need either hostport or proxy'\n\n    zonefiles_schema = {\n        'type': 'object',\n        'properties': {\n            'zonefiles': {\n                'type': 'object',\n                'patternProperties': {\n                    OP_ZONEFILE_HASH_PATTERN: {\n                        'type': 'string',\n                        'pattern': OP_BASE64_EMPTY_PATTERN\n                    },\n                },\n            },\n        },\n        'required': [\n            'zonefiles',\n        ]\n    }\n\n    schema = json_response_schema( zonefiles_schema )\n\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    zonefiles = None\n    try:\n        zf_payload = proxy.get_zonefiles(zonefile_hashes)\n        zf_payload = json_validate(schema, zf_payload)\n        if json_is_error(zf_payload):\n            return zf_payload\n\n        decoded_zonefiles = {}\n\n        for zf_hash, zf_data_b64 in zf_payload['zonefiles'].items():\n            zf_data = base64.b64decode( zf_data_b64 )\n            assert verify_zonefile( zf_data, zf_hash ), \"Zonefile data mismatch\"\n\n            # valid\n            decoded_zonefiles[ zf_hash ] = zf_data\n\n        # return this\n        zf_payload['zonefiles'] = decoded_zonefiles\n        zonefiles = zf_payload\n\n    except AssertionError as ae:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ae)\n\n        zonefiles = {'error': 'Zonefile data mismatch'}\n        return zonefiles\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        zonefiles = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return zonefiles\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return zonefiles"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npushing one or more zonefiles to the given server.", "response": "def put_zonefiles(hostport, zonefile_data_list, timeout=30, my_hostport=None, proxy=None):\n    \"\"\"\n    Push one or more zonefiles to the given server.\n    Each zone file in the list must be base64-encoded\n\n    Return {'status': True, 'saved': [...]} on success\n    Return {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'need either hostport or proxy'\n\n    saved_schema = {\n        'type': 'object',\n        'properties': {\n            'saved': {\n                'type': 'array',\n                'items': {\n                    'type': 'integer',\n                    'minimum': 0,\n                    'maximum': 1,\n                },\n                'minItems': len(zonefile_data_list),\n                'maxItems': len(zonefile_data_list)\n            },\n        },\n        'required': [\n            'saved'\n        ]\n    }\n\n    schema = json_response_schema( saved_schema )\n    \n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    push_info = None\n    try:\n        push_info = proxy.put_zonefiles(zonefile_data_list)\n        push_info = json_validate(schema, push_info)\n        if json_is_error(push_info):\n            return push_info\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return push_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_zonefiles_by_block(from_block, to_block, hostport=None, proxy=None):\n    assert hostport or proxy, 'need either hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    zonefile_info_schema = {\n        'type' : 'array',\n        'items' : {\n            'type' : 'object',\n            'properties' : {\n                'name' : {'type' : 'string'},\n                'zonefile_hash' : { 'type' : 'string',\n                                    'pattern' : OP_ZONEFILE_HASH_PATTERN },\n                'txid' : {'type' : 'string',\n                          'pattern' : OP_TXID_PATTERN},\n                'block_height' : {'type' : 'integer'}\n            },\n            'required' : [ 'zonefile_hash', 'txid', 'block_height' ]\n        }\n    }\n    response_schema = {\n        'type' : 'object',\n        'properties' : {\n            'lastblock' : {'type' : 'integer'},\n            'zonefile_info' : zonefile_info_schema\n        },\n        'required' : ['lastblock', 'zonefile_info']\n    }\n\n    offset = 0\n    output_zonefiles = []\n    last_server_block = 0\n\n    resp = {'zonefile_info': []}\n\n    while offset == 0 or len(resp['zonefile_info']) > 0:\n\n        resp = proxy.get_zonefiles_by_block(from_block, to_block, offset, 100)\n        if 'error' in resp:\n            return resp\n\n        resp = json_validate(response_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        output_zonefiles += resp['zonefile_info']\n        offset += 100\n        last_server_block = max(resp['lastblock'], last_server_block)\n\n    return { 'last_block' : last_server_block,\n             'zonefile_info' : output_zonefiles }", "response": "Get the zonefiles announced in [ from_block to_block"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_name_record(name, include_history=False, include_expired=False, include_grace=True, proxy=None, hostport=None,\n                    history_page=None):\n    \"\"\"\n    Get the record for a name or a subdomain.  Optionally include its history, and optionally return an expired name or a name in its grace period.\n    Return the blockchain-extracted information on success.\n    Return {'error': ...} on error\n        In particular, return {'error': 'Not found.'} if the name isn't registered\n\n    If include_expired is True, then a name record will be returned even if it expired\n    If include_expired is False, but include_grace is True, then the name record will be returned even if it is expired and in the grace period\n    \"\"\"\n    if isinstance(name, (str,unicode)):\n        # coerce string\n        name = str(name)\n\n    assert proxy or hostport, 'Need either proxy handle or hostport string'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n    \n    # what do we expect?\n    required = None\n    is_blockstack_id = False\n    is_blockstack_subdomain = False\n\n    if is_name_valid(name):\n        # full name\n        required = NAMEOP_SCHEMA_REQUIRED[:]\n        is_blockstack_id = True\n\n    elif is_subdomain(name):\n        # subdomain \n        required = SUBDOMAIN_SCHEMA_REQUIRED[:]\n        is_blockstack_subdomain = True\n\n    else:\n        # invalid\n        raise ValueError(\"Not a valid name or subdomain: {}\".format(name))\n        \n    if include_history:\n        required += ['history']\n\n    nameop_schema = {\n        'type': 'object',\n        'properties': NAMEOP_SCHEMA_PROPERTIES,\n        'required': required\n    }\n\n    rec_schema = {\n        'type': 'object',\n        'properties': {\n            'record': nameop_schema,\n        },\n        'required': [\n            'record'\n        ],\n    }\n\n    resp_schema = json_response_schema(rec_schema)\n\n    resp = {}\n    lastblock = None\n    try:\n        if include_history:\n            resp = get_name_and_history(name, proxy=proxy, history_page=history_page)\n            if 'error' in resp:\n                # fall back to legacy path\n                log.debug(resp)\n                resp = proxy.get_name_blockchain_record(name)\n        else:\n            resp = proxy.get_name_record(name)\n\n        resp = json_validate(resp_schema, resp)\n        if json_is_error(resp):\n            if resp['error'] == 'Not found.':\n                return {'error': 'Not found.', 'http_status': resp.get('http_status', 404)}\n\n            return resp\n\n        lastblock = resp['lastblock']\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n    \n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    if not include_expired and is_blockstack_id:\n        # check expired\n        if lastblock is None:\n            return {'error': 'No lastblock given from server', 'http_status': 503}\n\n        if include_grace:\n            # only care if the name is beyond the grace period\n            if lastblock >= int(resp['record']['renewal_deadline']) and int(resp['record']['renewal_deadline']) > 0:\n                return {'error': 'Name expired', 'http_status': 404}\n\n            elif int(resp['record']['renewal_deadline']) > 0 and lastblock >= int(resp['record']['expire_block']) and lastblock < int(resp['record']['renewal_deadline']):\n                resp['record']['grace_period'] = True\n\n            else:\n                resp['record']['grace_period'] = False\n\n        else:\n            # only care about expired, even if it's in the grace period\n            if lastblock > int(resp['record']['expire_block']) and int(resp['record']['expire_block']) > 0:\n                return {'error': 'Name expired', 'http_status': 404}\n\n    return resp['record']", "response": "Get the name record for a name or subdomain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_namespace_record(namespace_id, proxy=None, hostport=None):\n\n    assert proxy or hostport, 'Need either proxy handle or hostport string'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n    \n    namespace_schema = {\n        'type': 'object',\n        'properties': NAMESPACE_SCHEMA_PROPERTIES,\n        'required': NAMESPACE_SCHEMA_REQUIRED\n    }\n\n    rec_schema = {\n        'type': 'object',\n        'properties': {\n            'record': namespace_schema,\n        },\n        'required': [\n            'record',\n        ],\n    }\n\n    resp_schema = json_response_schema( rec_schema )\n            \n    ret = {}\n    try:\n        ret = proxy.get_namespace_blockchain_record(namespace_id)\n        ret = json_validate(resp_schema, ret)\n        if json_is_error(ret):\n            return ret\n\n        ret = ret['record']\n\n        # this isn't needed\n        ret.pop('opcode', None)\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return ret", "response": "Get the blockchain record for a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the name cost info on success Return the name cost info on success Return error on error", "response": "def get_name_cost(name, proxy=None, hostport=None):\n    \"\"\"\n    name_cost\n    Returns the name cost info on success\n    Returns {'amount': ..., 'units': ...} on success\n    Returns {'error': ...} on error\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    cost_schema_v1 = {\n        'type': 'object',\n        'properties': {\n            'satoshis': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'satoshis'\n        ]\n    }\n\n    cost_schema_v2 = {\n        'type': 'object',\n        'properties': {\n            'units': {\n                'type': 'string',\n            },\n            'amount': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'units',\n            'amount',\n        ]\n    }\n\n    resp_version = None\n    resp_schema_v1 = json_response_schema(cost_schema_v1)\n    resp_schema_v2 = json_response_schema(cost_schema_v2)\n\n    resp = {}\n    try:\n        resp = proxy.get_name_cost(name)\n        try:\n            resp = json_validate(resp_schema_v2, resp)\n        except:\n            resp = json_validate(resp_schema_v1, resp)\n            if not json_is_error(resp):\n                resp = {'units': 'BTC', 'amount': resp['satoshis']}\n\n        if json_is_error(resp):\n            return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the cost of a namespace.", "response": "def get_namespace_cost(namespace_id, proxy=None, hostport=None):\n    \"\"\"\n    namespace_cost\n    Returns the namespace cost info on success.\n    Returns {'amount': ..., 'units': ...} on success (optionally with 'satoshis': ... if the namespace is priced in BTC)\n    Returns {'error': ...} on error\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    cost_schema_v1 = {\n        'type': 'object',\n        'properties': {\n            'satoshis': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'satoshis'\n        ],\n    }\n\n    cost_schema_v2 = {\n        'type': 'object',\n        'properties': {\n            'units': {\n                'type': 'string',\n                'pattern': '^BTC$|^{}$'.format(TOKEN_TYPE_STACKS),\n            },\n            'amount': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'units',\n            'amount',\n        ],\n    }\n\n    schema_v1 = json_response_schema(cost_schema_v1)\n    schema_v2 = json_response_schema(cost_schema_v2)\n\n    resp = {}\n    try:\n        resp = proxy.get_namespace_cost(namespace_id)\n        try:\n            resp = json_validate(cost_schema_v2, resp)\n        except:\n            resp = json_validate(cost_schema_v1, resp)\n            if not json_is_error(resp):\n                resp = {'units': 'BTC', 'amount': resp['satoshis']}\n\n        if json_is_error(resp):\n            return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the types of tokens that an address owns Returns a list of token types", "response": "def get_account_tokens(address, hostport=None, proxy=None):\n    \"\"\"\n    Get the types of tokens that an address owns\n    Returns a list of token types\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    tokens_schema = {\n        'type': 'object',\n        'properties': {\n            'token_types': {\n                'type': 'array',\n                'pattern': '^(.+){1,19}',\n            },\n        },\n        'required': [\n            'token_types',\n        ]\n    }\n\n    schema = json_response_schema(tokens_schema)\n\n    try:\n        resp = proxy.get_account_tokens(address)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except AssertionError as ae:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ae)\n\n        resp = json_traceback(resp.get('error'))\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    resp['token_types'].sort()\n    return resp['token_types']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the balance of an account for a particular token", "response": "def get_account_balance(address, token_type, hostport=None, proxy=None):\n    \"\"\"\n    Get the balance of an account for a particular token\n    Returns an int\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    balance_schema = {\n        'type': 'object',\n        'properties': {\n            'balance': {\n                'type': 'integer',\n            },\n        },\n        'required': [\n            'balance',\n        ],\n    }\n\n    schema = json_response_schema(balance_schema)\n\n    try:\n        resp = proxy.get_account_balance(address, token_type)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['balance']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_names_page(offset, count, include_expired=False, hostport=None, proxy=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    page_schema = {\n        'type': 'object',\n        'properties': {\n            'names': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'uniqueItems': True\n                },\n            },\n        },\n        'required': [\n            'names',\n        ],\n    }\n\n    schema = json_response_schema(page_schema)\n\n    try:\n        assert count <= 100, 'Page too big: {}'.format(count)\n    except AssertionError as ae:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ae)\n\n        return {'error': 'Invalid page', 'http_status': 400}\n\n    resp = {}\n    try:\n        if include_expired:\n            resp = proxy.get_all_names_cumulative(offset, count)\n        else:\n            resp = proxy.get_all_names(offset, count)\n\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        # must be valid names\n        valid_names = []\n        for n in resp['names']:\n            if not is_name_valid(str(n)):\n                log.error('Invalid name \"{}\"'.format(str(n)))\n            else:\n                valid_names.append(n)\n\n        resp['names'] = valid_names\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n        \n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['names']", "response": "get a page of all the names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_num_names(include_expired=False, proxy=None, hostport=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    schema = {\n        'type': 'object',\n        'properties': {\n            'count': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'count',\n        ],\n    }\n\n    count_schema = json_response_schema(schema)\n\n    resp = {}\n    try:\n        if include_expired:\n            resp = proxy.get_num_names_cumulative()\n        else:\n            resp = proxy.get_num_names()\n\n        resp = json_validate(count_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['count']", "response": "Get the number of names optionally counting the expired ones"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_subdomains(offset=0, count=100, proxy=None, hostport=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    offset = int(offset)\n    count = int(count)\n\n    page_schema = {\n        'type': 'object',\n        'properties': {\n            'names': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'uniqueItems': True\n                },\n            },\n        },\n        'required': [\n            'names',\n        ],\n    }\n\n    schema = json_response_schema(page_schema)\n\n    try:\n        resp = proxy.get_all_subdomains(offset, count)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        for name in resp['names']:\n            if not is_subdomain(str(name)):\n                raise ValidationError('Not a valid subdomain: {}'.format(str(name)))\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['names']", "response": "Get all subdomains within the given range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all names within the given range.", "response": "def get_all_names(offset=None, count=None, include_expired=False, proxy=None, hostport=None):\n    \"\"\"\n    Get all names within the given range.\n    Return the list of names on success\n    Return {'error': ...} on failure\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    offset = 0 if offset is None else offset\n\n    if count is None:\n        # get all names after this offset\n        count = get_num_names(proxy=proxy, hostport=hostport)\n        if json_is_error(count):\n            # error\n            return count\n\n        count -= offset\n\n    page_size = 100\n    all_names = []\n    while len(all_names) < count:\n        request_size = page_size\n        if count - len(all_names) < request_size:\n            request_size = count - len(all_names)\n\n        page = get_all_names_page(offset + len(all_names), request_size, include_expired=include_expired, proxy=proxy, hostport=hostport)\n        if json_is_error(page):\n            # error\n            return page\n\n        if len(page) > request_size:\n            # error\n            error_str = 'server replied too much data'\n            return {'error': error_str, 'http_status': 503}\n        elif len(page) == 0:\n            # end-of-table\n            break\n\n        all_names += page\n\n    return all_names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_namespaces(offset=None, count=None, proxy=None, hostport=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    offset = 0 if offset is None else offset\n\n    schema = {\n        'type': 'object',\n        'properties': {\n            'namespaces': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'pattern': OP_NAMESPACE_PATTERN,\n                },\n            },\n        },\n        'required': [\n            'namespaces'\n        ],\n    }\n\n    namespaces_schema = json_response_schema(schema)\n\n    resp = {}\n    try:\n        resp = proxy.get_all_namespaces()\n        resp = json_validate(namespaces_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    stride = len(resp['namespaces']) if count is None else offset + count\n    return resp['namespaces'][offset:stride]", "response": "Get all namespaces in a single page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a page of names in a namespace.", "response": "def get_names_in_namespace_page(namespace_id, offset, count, proxy=None, hostport=None):\n    \"\"\"\n    Get a page of names in a namespace\n    Returns the list of names on success\n    Returns {'error': ...} on error\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    assert count <= 100, 'Page too big: {}'.format(count)\n\n    names_schema = {\n        'type': 'object',\n        'properties': {\n            'names': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'uniqueItems': True\n                },\n            },\n        },\n        'required': [\n            'names',\n        ],\n    }\n\n    schema = json_response_schema( names_schema )\n    resp = {}\n    try:\n        resp = proxy.get_names_in_namespace(namespace_id, offset, count)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        # must be valid names\n        valid_names = []\n        for n in resp['names']:\n            if not is_name_valid(str(n)):\n                log.error('Invalid name \"{}\"'.format(str(n)))\n            else:\n                valid_names.append(n)\n\n        return valid_names\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_names_owned_by_address(address, proxy=None, hostport=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    owned_schema = {\n        'type': 'object',\n        'properties': {\n            'names': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                    'uniqueItems': True\n                },\n            },\n        },\n        'required': [\n            'names',\n        ],\n    }\n\n    schema = json_response_schema( owned_schema )\n\n    resp = {}\n    try:\n        resp = proxy.get_names_owned_by_address(address)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        # names must be valid\n        for n in resp['names']:\n            assert is_name_valid(str(n)), ('Invalid name \"{}\"'.format(str(n)))\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except AssertionError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Got an invalid name from the server'}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['names']", "response": "Get the names owned by an address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the list of subdomain operations added by a txid", "response": "def get_subdomain_ops_at_txid(txid, proxy=None, hostport=None):\n    \"\"\"\n    Get the list of subdomain operations added by a txid\n    Returns the list of operations ([{...}]) on success\n    Returns {'error': ...} on failure\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    subdomain_ops_schema = {\n        'type': 'object',\n        'properties': {\n            'subdomain_ops': {\n                'type': 'array',\n                'items': {\n                    'type': 'object',\n                    'properties': OP_HISTORY_SCHEMA['properties'],\n                    'required': SUBDOMAIN_HISTORY_REQUIRED,\n                },\n            },\n        },\n        'required': ['subdomain_ops'],\n    }\n\n    schema = json_response_schema(subdomain_ops_schema)\n\n    resp = {}\n    try:\n        resp = proxy.get_subdomain_ops_at_txid(txid)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        # names must be valid\n        for op in resp['subdomain_ops']:\n            assert is_subdomain(str(op['fully_qualified_subdomain'])), ('Invalid subdomain \"{}\"'.format(op['fully_qualified_subdomain']))\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except AssertionError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response included an invalid subdomain', 'http_status': 500}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['subdomain_ops']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the DID for a name or subdomain.", "response": "def get_name_DID(name, proxy=None, hostport=None):\n    \"\"\"\n    Get the DID for a name or subdomain\n    Return the DID string on success\n    Return None if not found\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    did_schema = {\n        'type': 'object',\n        'properties': {\n            'did': {\n                'type': 'string'\n            }\n        },\n        'required': [ 'did' ],\n    }\n\n    schema = json_response_schema(did_schema)\n    resp = {}\n    try:\n        resp = proxy.get_name_DID(name)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n        # DID must be well-formed\n        assert parse_DID(resp['did'])\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n    \n    except AssertionError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server replied an unparseable DID'}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['did']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves a Blockstack decentralized identifier to its blockchain record.", "response": "def get_DID_record(did, proxy=None, hostport=None):\n    \"\"\"\n    Resolve a Blockstack decentralized identifier (DID) to its blockchain record.\n    Works for names and subdomains.\n\n    DID format: did:stack:v0:${address}-${name_index}, where:\n    * address is the address that created the name this DID references (version byte 0 or 5)\n    * name_index is the nth name ever created by this address.\n\n    Returns the blockchain record on success\n    Returns {'error': ...} on failure\n    \"\"\"\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n \n    # what do we expect?\n    required = None\n    is_blockstack_id = False\n    is_blockstack_subdomain = False\n\n    did_info = parse_DID(did)\n    if did_info['name_type'] == 'name':\n        # full name\n        required = NAMEOP_SCHEMA_REQUIRED[:]\n        is_blockstack_id = True\n        \n    elif did_info['name_type'] == 'subdomain':\n        # subdomain \n        required = SUBDOMAIN_SCHEMA_REQUIRED[:]\n        is_blockstack_subdomain = True\n\n    else:\n        # invalid\n        raise ValueError(\"Not a valid name or subdomain DID: {}\".format(did))\n        \n    nameop_schema = {\n        'type': 'object',\n        'properties': NAMEOP_SCHEMA_PROPERTIES,\n        'required': required\n    }\n\n    rec_schema = {\n        'type': 'object',\n        'properties': {\n            'record': nameop_schema,\n        },\n        'required': [\n            'record'\n        ],\n    }\n\n    resp_schema = json_response_schema(rec_schema)\n    resp = {}\n\n    try:\n        resp = proxy.get_DID_record(did)\n        resp = json_validate(resp_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    final_name_state = resp['record']\n\n    # remove extra fields that shouldn't be present\n    for extra_field in ['expired', 'expire_block', 'renewal_deadline']:\n        if extra_field in final_name_state:\n            del final_name_state[extra_field]\n\n    return final_name_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the consensus hash at a block_height", "response": "def get_consensus_at(block_height, proxy=None, hostport=None):\n    \"\"\"\n    Get consensus at a block\n    Returns the consensus hash on success\n    Returns {'error': ...} on error\n    \"\"\"\n    assert proxy or hostport, 'Need either proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    consensus_schema = {\n        'type': 'object',\n        'properties': {\n            'consensus': {\n                'anyOf': [\n                    {\n                        'type': 'string',\n                        'pattern': OP_CONSENSUS_HASH_PATTERN,\n                    },\n                    {\n                        'type': 'null'\n                    },\n                ],\n            },\n        },\n        'required': [\n            'consensus',\n        ],\n    }\n\n    resp_schema = json_response_schema( consensus_schema )\n    resp = {}\n    try:\n        resp = proxy.get_consensus_at(block_height)\n        resp = json_validate(resp_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    if resp['consensus'] is None:\n        # node hasn't processed this block \n        return {'error': 'The node has not processed block {}'.format(block_height), 'http_status': 503}\n\n    return resp['consensus']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_blockstack_transactions_at(block_id, proxy=None, hostport=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    history_schema = {\n        'type': 'array',\n        'items': {\n            'type': 'object',\n            'properties': OP_HISTORY_SCHEMA['properties'],\n            'required': [\n                'op',\n                'opcode',\n                'txid',\n                'vtxindex',\n            ]\n        }\n    }\n\n    nameop_history_schema = {\n        'type': 'object',\n        'properties': {\n            'nameops': history_schema,\n        },\n        'required': [\n            'nameops',\n        ],\n    }\n\n    history_count_schema = {\n        'type': 'object',\n        'properties': {\n            'count': {\n                'type': 'integer',\n                'minimum': 0,\n            },\n        },\n        'required': [\n            'count',\n        ],\n    }\n    \n    count_schema = json_response_schema( history_count_schema )\n    nameop_schema = json_response_schema( nameop_history_schema )\n\n    # how many nameops?\n    num_nameops = None\n    try:\n        num_nameops = proxy.get_num_blockstack_ops_at(block_id)\n        num_nameops = json_validate(count_schema, num_nameops)\n        if json_is_error(num_nameops):\n            return num_nameops\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    num_nameops = num_nameops['count']\n\n    # grab at most 10 of these at a time\n    all_nameops = []\n    page_size = 10\n    while len(all_nameops) < num_nameops:\n        resp = {}\n        try:\n            resp = proxy.get_blockstack_ops_at(block_id, len(all_nameops), page_size)\n            resp = json_validate(nameop_schema, resp)\n            if json_is_error(resp):\n                return resp\n\n            if len(resp['nameops']) == 0:\n                return {'error': 'Got zero-length nameops reply', 'http_status': 503}\n\n            all_nameops += resp['nameops']\n\n        except ValidationError as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n            return resp\n\n        except socket.timeout:\n            log.error(\"Connection timed out\")\n            resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n            return resp\n\n        except socket.error as se:\n            log.error(\"Connection error {}\".format(se.errno))\n            resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n            return resp\n\n        except Exception as ee:\n            if BLOCKSTACK_DEBUG:\n                log.exception(ee)\n\n            log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n            resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n            return resp\n\n    return all_nameops", "response": "Get the prior states of the blockstack records affected at the given block height."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_consensus_hashes(block_heights, hostport=None, proxy=None):\n    assert proxy or hostport, 'Need proxy or hostport'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    consensus_hashes_schema = {\n        'type': 'object',\n        'properties': {\n            'consensus_hashes': {\n                'type': 'object',\n                'patternProperties': {\n                    '^([0-9]+)$': {\n                        'type': 'string',\n                        'pattern': OP_CONSENSUS_HASH_PATTERN,\n                    },\n                },\n            },\n        },\n        'required': [\n            'consensus_hashes',\n        ],\n    }\n\n    resp_schema = json_response_schema( consensus_hashes_schema )\n    resp = {}\n    try:\n        resp = proxy.get_consensus_hashes(block_heights)\n        resp = json_validate(resp_schema, resp)\n        if json_is_error(resp):\n            log.error('Failed to get consensus hashes for {}: {}'.format(block_heights, resp['error']))\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    consensus_hashes = resp['consensus_hashes']\n\n    # hard to express as a JSON schema, but the format is thus:\n    # { block_height (str): consensus_hash (str) }\n    # need to convert all block heights to ints\n\n    try:\n        ret = {int(k): v for k, v in consensus_hashes.items()}\n        log.debug('consensus hashes: {}'.format(ret))\n        return ret\n    except ValueError:\n        return {'error': 'Server returned invalid data: expected int', 'http_status': 503}", "response": "Get the consensus hashes for a list of blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a block height from a consensus hash", "response": "def get_block_from_consensus(consensus_hash, hostport=None, proxy=None):\n    \"\"\"\n    Get a block height from a consensus hash\n    Returns the block height on success\n    Returns {'error': ...} on failure\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    consensus_schema = {\n        'type': 'object',\n        'properties': {\n            'block_id': {\n                'anyOf': [\n                    {\n                        'type': 'integer',\n                        'minimum': 0,\n                    },\n                    {\n                        'type': 'null',\n                    },\n                ],\n            },\n        },\n        'required': [\n            'block_id'\n        ],\n    }\n\n    schema = json_response_schema( consensus_schema )\n    resp = {}\n    try:\n        resp = proxy.get_block_from_consensus(consensus_hash)\n        resp = json_validate( schema, resp )\n        if json_is_error(resp):\n            log.error(\"Failed to find block ID for %s\" % consensus_hash)\n            return resp\n\n    except ValidationError as ve:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ve)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n    \n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['block_id']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_name_history_page(name, page, hostport=None, proxy=None):\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    name_required = ['op', 'opcode', 'txid', 'vtxindex']\n    subdomain_required = ['txid']\n    required = None\n    if check_subdomain(name):\n        log.debug('Subdomain: {}'.format(name))\n        required = subdomain_required\n    else:\n        log.debug('Name: {}'.format(name))\n        required = name_required\n\n    hist_schema = {\n        'type': 'object',\n        'patternProperties': {\n            '^[0-9]+$': {\n                'type': 'array',\n                'items': {\n                    'type': 'object',\n                    'properties': OP_HISTORY_SCHEMA['properties'],\n                    'required': required\n                },\n            },\n        },\n    }\n\n    hist_resp_schema = {\n        'type': 'object',\n        'properties': {\n            'history': hist_schema,\n        },\n        'required': [ 'history' ],\n    }\n\n    resp_schema = json_response_schema(hist_resp_schema)\n    resp = {}\n    lastblock = None\n    indexin = None\n\n    try:\n        _resp = proxy.get_name_history_page(name, page)\n        resp = json_validate(resp_schema, _resp)\n        if json_is_error(resp):\n            return resp\n\n        lastblock = _resp['lastblock']\n        indexing = _resp['indexing']\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = json_traceback(resp.get('error'))\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.'}\n        return resp\n\n    return {'status': True, 'history': resp['history'], 'lastblock': lastblock, 'indexing': indexing}", "response": "Get a page of the name s history Returns a dictionary of status = True history =... indexin =... lastblock =... indexin =... lastblock =... indexin =... lastblock =... indexin =..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef name_history_merge(h1, h2):\n    ret = {}\n    blocks_1 = [int(b) for b in h1.keys()]\n    blocks_2 = [int(b) for b in h2.keys()]\n\n    # find overlapping blocks\n    overlap = list(set(blocks_1).intersection(set(blocks_2)))\n    if len(overlap) > 0:\n        for b in overlap:\n            h = h1[str(b)] + h2[str(b)]\n            h.sort(lambda v1, v2: -1 if v1['vtxindex'] < v2['vtxindex'] else 1)\n            \n            uniq = []\n            last_vtxindex = None\n            for i in range(0, len(h)):\n                if h[i]['vtxindex'] != last_vtxindex:\n                    uniq.append(h[i])\n                    last_vtxindex = h[i]['vtxindex']\n                \n            ret[str(b)] = uniq\n    \n    all_blocks = list(set(blocks_1 + blocks_2))\n    for b in all_blocks:\n        if b in overlap:\n            continue\n\n        if b in blocks_1:\n            ret[str(b)] = h1[str(b)]\n        else:\n            ret[str(b)] = h2[str(b)]\n\n    return ret", "response": "Given two name histories ( grouped by block ) merge them into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the full history of a name", "response": "def get_name_history(name, hostport=None, proxy=None, history_page=None):\n    \"\"\"\n    Get the full history of a name\n    Returns {'status': True, 'history': ...} on success, where history is grouped by block\n    Returns {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    hist = {}\n    indexing = None\n    lastblock = None\n\n    if history_page != None:\n        resp = get_name_history_page(name, history_page, proxy=proxy)\n        if 'error' in resp:\n            return resp\n\n        indexing = resp['indexing']\n        lastblock = resp['lastblock']\n\n        return {'status': True, 'history': resp['history'], 'indexing': indexing, 'lastblock': lastblock}\n\n    for i in range(0, 100000000):       # this is obviously too big\n        resp = get_name_history_page(name, i, proxy=proxy)\n        if 'error' in resp:\n            return resp\n\n        indexing = resp['indexing']\n        lastblock = resp['lastblock']\n\n        if len(resp['history']) == 0:\n            # caught up \n            break\n\n        hist = name_history_merge(hist, resp['history'])\n\n    return {'status': True, 'history': hist, 'indexing': indexing, 'lastblock': lastblock}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name_and_history(name, include_expired=False, include_grace=True, hostport=None, proxy=None, history_page=None):\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    hist = get_name_history(name, proxy=proxy, history_page=history_page)\n    if 'error' in hist:\n        return hist\n\n    # just the name\n    rec = get_name_record(name, include_history=False, include_expired=include_expired, include_grace=include_grace, proxy=proxy)\n    if 'error' in rec:\n        return rec\n\n    rec['history'] = hist['history']\n    return {'status': True, 'record': rec, 'lastblock': hist['lastblock'], 'indexing': hist['indexing']}", "response": "Get the current name record and its history"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the name as it was at a particular height.", "response": "def get_name_at(name, block_id, include_expired=False, hostport=None, proxy=None):\n    \"\"\"\n    Get the name as it was at a particular height.\n    Returns the name record states at this block height on success (an array)\n    Returns {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    namerec_schema = {\n        'type': 'object',\n        'properties': NAMEOP_SCHEMA_PROPERTIES,\n        'required': NAMEOP_SCHEMA_REQUIRED\n    }\n\n    namerec_list_schema = {\n        'type': 'object',\n        'properties': {\n            'records': {\n                'anyOf': [\n                    {\n                        'type': 'array',\n                        'items': namerec_schema\n                    },\n                    {\n                        'type': 'null',\n                    },\n                ],\n            },\n        },\n        'required': [\n            'records'\n        ],\n    }\n\n    resp_schema = json_response_schema( namerec_list_schema )\n    resp = {}\n    try:\n        if include_expired:\n            resp = proxy.get_historic_name_at(name, block_id)\n        if not include_expired or 'KeyError' in resp.get('error', ''):\n            resp = proxy.get_name_at(name, block_id)\n\n        assert resp, \"No such name {} at block {}\".format(name, block_id)\n\n        resp = json_validate(resp_schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return resp['records']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if a name set a given zone file hash.", "response": "def is_name_zonefile_hash(name, zonefile_hash, hostport=None, proxy=None):\n    \"\"\"\n    Determine if a name set a given zone file hash.\n    Return {'result': True/False} if so\n    Return {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n    if proxy is None:\n        proxy = connect_hostport(hostport)\n\n    zonefile_check_schema = {\n        'type': 'object',\n        'properties': {\n            'result': {\n                'type': 'boolean'\n            }\n        },\n        'required': [ 'result' ]\n    }\n\n    schema = json_response_schema(zonefile_check_schema)\n    resp = {}\n    try:\n        resp = proxy.is_name_zonefile_hash(name, zonefile_hash)\n        resp = json_validate(schema, resp)\n        if json_is_error(resp):\n            return resp\n\n    except ValidationError as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        resp = {'error': 'Server response did not match expected schema.  You are likely communicating with an out-of-date Blockstack node.', 'http_status': 502}\n        return resp\n\n    except socket.timeout:\n        log.error(\"Connection timed out\")\n        resp = {'error': 'Connection to remote host timed out.', 'http_status': 503}\n        return resp\n\n    except socket.error as se:\n        log.error(\"Connection error {}\".format(se.errno))\n        resp = {'error': 'Connection to remote host failed.', 'http_status': 502}\n        return resp\n\n    except Exception as ee:\n        if BLOCKSTACK_DEBUG:\n            log.exception(ee)\n\n        log.error(\"Caught exception while connecting to Blockstack node: {}\".format(ee))\n        resp = {'error': 'Failed to contact Blockstack node.  Try again with `--debug`.', 'http_status': 500}\n        return resp\n\n    return {'result': resp['result']}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_JWT(url, address=None):\n    jwt_txt = None\n    jwt = None\n\n    log.debug(\"Try {}\".format(url))\n\n    # special case: handle file://\n    urlinfo = urllib2.urlparse.urlparse(url)\n    if urlinfo.scheme == 'file':\n        # points to a path on disk\n        try:\n            with open(urlinfo.path, 'r') as f:\n                jwt_txt = f.read()\n\n        except Exception as e:\n            if BLOCKSTACK_TEST:\n                log.exception(e)\n\n            log.warning(\"Failed to read {}\".format(url))\n            return None\n\n    else:\n        # http(s) URL or similar\n        try:\n            resp = requests.get(url)\n            assert resp.status_code == 200, 'Bad status code on {}: {}'.format(url, resp.status_code)\n            jwt_txt = resp.text\n\n        except Exception as e:\n            if BLOCKSTACK_TEST:\n                log.exception(e)\n\n            log.warning(\"Unable to resolve {}\".format(url))\n            return None\n\n    try:\n        # one of two things are possible:\n        # * this is a JWT string\n        # * this is a serialized JSON string whose first item is a dict that has 'token' as key,\n        # and that key is a JWT string.\n        try:\n            jwt_txt = json.loads(jwt_txt)[0]['token']\n        except:\n            pass\n\n        jwt = jsontokens.decode_token(jwt_txt)\n    except Exception as e:\n        if BLOCKSTACK_TEST:\n            log.exception(e)\n\n        log.warning(\"Unable to decode token at {}\".format(url))\n        return None\n\n    try:\n        # must be well-formed\n        assert isinstance(jwt, dict)\n        assert 'payload' in jwt, jwt\n        assert isinstance(jwt['payload'], dict)\n        assert 'issuer' in jwt['payload'], jwt\n        assert isinstance(jwt['payload']['issuer'], dict)\n        assert 'publicKey' in jwt['payload']['issuer'], jwt\n        assert virtualchain.ecdsalib.ecdsa_public_key(str(jwt['payload']['issuer']['publicKey']))\n\n    except AssertionError as ae:\n        if BLOCKSTACK_TEST or BLOCKSTACK_DEBUG:\n            log.exception(ae)\n\n        log.warning(\"JWT at {} is malformed\".format(url))\n        return None\n\n    if address is not None:\n        public_key = str(jwt['payload']['issuer']['publicKey'])\n        addrs = [virtualchain.address_reencode(virtualchain.ecdsalib.ecdsa_public_key(keylib.key_formatting.decompress(public_key)).address()),\n                 virtualchain.address_reencode(virtualchain.ecdsalib.ecdsa_public_key(keylib.key_formatting.compress(public_key)).address())]\n\n        if virtualchain.address_reencode(address) not in addrs:\n            # got a JWT, but it doesn't match the address\n            log.warning(\"Found JWT at {}, but its public key has addresses {} and {} (expected {})\".format(url, addrs[0], addrs[1], address))\n            return None\n\n        verifier = jsontokens.TokenVerifier()\n        if not verifier.verify(jwt_txt, public_key):\n            # got a JWT, and the address matches, but the signature does not\n            log.warning(\"Found JWT at {}, but it was not signed by {} ({})\".format(url, public_key, address))\n            return None\n\n    return jwt", "response": "Given a URL fetch and decode the JWT and return the JWT."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresolving a name to its profile.", "response": "def resolve_profile(name, include_expired=False, include_name_record=False, hostport=None, proxy=None):\n    \"\"\"\n    Resolve a name to its profile.\n    This is a multi-step process:\n    1. get the name record\n    2. get the zone file\n    3. parse the zone file to get its URLs (if it's not well-formed, then abort)\n    4. fetch and authenticate the JWT at each URL (abort if there are none)\n    5. extract the profile JSON and return that, along with the zone file and public key\n\n    Return {'profile': ..., 'zonefile': ..., 'public_key': ...['name_rec': ...]} on success\n    Return {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n    \n    name_rec = get_name_record(name, include_history=False, include_expired=include_expired, include_grace=False, proxy=proxy, hostport=hostport)\n    if 'error' in name_rec:\n        log.error(\"Failed to get name record for {}: {}\".format(name, name_rec['error']))\n        return {'error': 'Failed to get name record: {}'.format(name_rec['error']), 'http_status': name_rec.get('http_status', 500)}\n   \n    if 'grace_period' in name_rec and name_rec['grace_period']:\n        log.error(\"Name {} is in the grace period\".format(name))\n        return {'error': 'Name {} is not yet expired, but is in the renewal grace period.'.format(name), 'http_status': name_rec.get('http_status', 404)}\n        \n    if 'value_hash' not in name_rec:\n        log.error(\"Name record for {} has no zone file hash\".format(name))\n        return {'error': 'No zone file hash in name record for {}'.format(name), 'http_status': 404}\n\n    zonefile_hash = name_rec['value_hash']\n    zonefile_res = get_zonefiles(hostport, [zonefile_hash], proxy=proxy)\n    if 'error' in zonefile_res:\n        log.error(\"Failed to get zone file for {} for name {}: {}\".format(zonefile_hash, name, zonefile_res['error']))\n        return {'error': 'Failed to get zone file for {}'.format(name), 'http_status': 404}\n\n    zonefile_txt = zonefile_res['zonefiles'][zonefile_hash]\n    log.debug(\"Got {}-byte zone file {}\".format(len(zonefile_txt), zonefile_hash))\n\n    try:\n        zonefile_data = blockstack_zones.parse_zone_file(zonefile_txt)\n        zonefile_data = dict(zonefile_data)\n        assert 'uri' in zonefile_data\n        if len(zonefile_data['uri']) == 0:\n            return {'error': 'No URI records in zone file {} for {}'.format(zonefile_hash, name), 'http_status': 404}\n\n    except Exception as e:\n        if BLOCKSTACK_TEST:\n            log.exception(e)\n\n        return {'error': 'Failed to parse zone file {} for {}'.format(zonefile_hash, name), 'http_status': 404}\n\n    urls = [uri['target'] for uri in zonefile_data['uri']]\n    for url in urls:\n        jwt = get_JWT(url, address=str(name_rec['address']))\n        if not jwt:\n            continue\n\n        if 'claim' not in jwt['payload']:\n            # not something we produced\n            log.warning(\"No 'claim' field in payload for {}\".format(url))\n            continue\n\n        # success!\n        profile_data = jwt['payload']['claim']\n        public_key = str(jwt['payload']['issuer']['publicKey'])\n\n        # return public key that matches address \n        pubkeys = [virtualchain.ecdsalib.ecdsa_public_key(keylib.key_formatting.decompress(public_key)),\n                   virtualchain.ecdsalib.ecdsa_public_key(keylib.key_formatting.compress(public_key))]\n\n        if name_rec['address'] == pubkeys[0].address():\n            public_key = pubkeys[0].to_hex()\n        else:\n            public_key = pubkeys[1].to_hex()\n\n        ret = {\n            'profile': profile_data,\n            'zonefile': zonefile_txt,\n            'public_key': public_key,\n        }\n\n        if include_name_record:\n            ret['name_record'] = name_rec\n\n        return ret\n\n    log.error(\"No zone file URLs resolved to a JWT with the public key whose address is {}\".format(name_rec['address']))\n    return {'error': 'No profile found for this name', 'http_status': 404}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve a DID to a public key.", "response": "def resolve_DID(did, hostport=None, proxy=None):\n    \"\"\"\n    Resolve a DID to a public key.\n    This is a multi-step process:\n    1. get the name record\n    2. get the zone file\n    3. parse the zone file to get its URLs (if it's not well-formed, then abort)\n    4. fetch and authenticate the JWT at each URL (abort if there are none)\n    5. extract the public key from the JWT and return that.\n\n    Return {'public_key': ..., 'document': ...} on success\n    Return {'error': ...} on error\n    \"\"\"\n    assert hostport or proxy, 'Need hostport or proxy'\n\n    did_rec = get_DID_record(did, hostport=hostport, proxy=proxy)\n    if 'error' in did_rec:\n        log.error(\"Failed to get DID record for {}: {}\".format(did, did_rec['error']))\n        return {'error': 'Failed to get DID record: {}'.format(did_rec['error']), 'http_status': did_rec.get('http_status', 500)}\n    \n    if 'value_hash' not in did_rec:\n        log.error(\"DID record for {} has no zone file hash\".format(did))\n        return {'error': 'No zone file hash in name record for {}'.format(did), 'http_status': 404}\n\n    zonefile_hash = did_rec['value_hash']\n    zonefile_res = get_zonefiles(hostport, [zonefile_hash], proxy=proxy)\n    if 'error' in zonefile_res:\n        log.error(\"Failed to get zone file for {} for DID {}: {}\".format(zonefile_hash, did, zonefile_res['error']))\n        return {'error': 'Failed to get zone file for {}'.format(did), 'http_status': 404}\n\n    zonefile_txt = zonefile_res['zonefiles'][zonefile_hash]\n    log.debug(\"Got {}-byte zone file {}\".format(len(zonefile_txt), zonefile_hash))\n\n    try:\n        zonefile_data = blockstack_zones.parse_zone_file(zonefile_txt)\n        zonefile_data = dict(zonefile_data)\n        assert 'uri' in zonefile_data\n        if len(zonefile_data['uri']) == 0:\n            return {'error': 'No URI records in zone file {} for {}'.format(zonefile_hash, did), 'http_status': 404}\n\n    except Exception as e:\n        if BLOCKSTACK_TEST:\n            log.exception(e)\n\n        return {'error': 'Failed to parse zone file {} for {}'.format(zonefile_hash, did), 'http_status': 404}\n\n    urls = [uri['target'] for uri in zonefile_data['uri']]\n    for url in urls:\n        jwt = get_JWT(url, address=str(did_rec['address']))\n        if not jwt:\n            continue\n\n        if 'payload' not in jwt:\n            log.error('Invalid JWT at {}: no payload'.format(url))\n            continue\n\n        if 'issuer' not in jwt['payload']:\n            log.error('Invalid JWT at {}: no issuer'.format(url))\n            continue\n\n        if 'publicKey' not in jwt['payload']['issuer']:\n            log.error('Invalid JWT at {}: no public key'.format(url))\n            continue\n\n        if 'claim' not in jwt['payload']:\n            log.error('Invalid JWT at {}: no claim'.format(url))\n            continue\n\n        if not isinstance(jwt['payload'], dict):\n            log.error('Invalid JWT at {}: claim is malformed'.format(url))\n            continue\n\n        # found!\n        public_key = str(jwt['payload']['issuer']['publicKey'])\n        document = jwt['payload']['claim']\n\n        # make sure it's a well-formed DID\n        document['@context'] = 'https://w3id.org/did/v1'\n        document['publicKey'] = [\n            {\n                'id': did,\n                'type': 'secp256k1',\n                'publicKeyHex': public_key\n            }\n        ]\n\n        return {'public_key': public_key, 'document': document}\n\n    log.error(\"No zone file URLs resolved to a JWT with the public key whose address is {}\".format(did_rec['address']))\n    return {'error': 'No public key found for the given DID', 'http_status': 404}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a zone file for a name.", "response": "def decode_name_zonefile(name, zonefile_txt):\n    \"\"\"\n    Decode a zone file for a name.\n    Must be either a well-formed DNS zone file, or a legacy Onename profile.\n    Return None on error\n    \"\"\"\n\n    user_zonefile = None\n    try:\n        # by default, it's a zonefile-formatted text file\n        user_zonefile_defaultdict = blockstack_zones.parse_zone_file(zonefile_txt)\n\n        # force dict\n        user_zonefile = dict(user_zonefile_defaultdict)\n\n    except (IndexError, ValueError, blockstack_zones.InvalidLineException):\n        # might be legacy profile\n        log.debug('WARN: failed to parse user zonefile; trying to import as legacy')\n        try:\n            user_zonefile = json.loads(zonefile_txt)\n            if not isinstance(user_zonefile, dict):\n                log.debug('Not a legacy user zonefile')\n                return None\n\n        except Exception as e:\n            log.error('Failed to parse non-standard zonefile')\n            return None\n\n    except Exception as e:\n        if BLOCKSTACK_DEBUG:\n            log.exception(e)\n\n        log.error('Failed to parse zonefile')\n        return None\n\n    if user_zonefile is None:\n        return None \n\n    return user_zonefile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the unspents into a list of dicts.", "response": "def format_unspents(unspents):\n    \"\"\"\n    Used for testing only!\n    \"\"\"\n    assert BLOCKSTACK_TEST, 'format_unspents can only be used in test mode!'\n    return [{\n        \"transaction_hash\": s[\"txid\"],\n        \"outpoint\": {\n            'hash': s['txid'],\n            'index': s[\"vout\"],\n        },\n        \"value\": int(Decimal(s[\"amount\"]*SATOSHIS_PER_COIN)),\n        \"out_script\": s[\"scriptPubKey\"],\n        \"confirmations\": s[\"confirmations\"]\n        }\n        for s in unspents\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the unspent transaction outputs for the given address.", "response": "def get_unspents(address, bitcoind):\n    \"\"\"\n    Used for testing only!\n\n    Get the spendable transaction outputs, also known as UTXOs or\n    unspent transaction outputs.\n\n    NOTE: this will only return unspents if the address provided is present\n    in the bitcoind server.\n    \"\"\"\n    assert BLOCKSTACK_TEST, 'get_unspents can only be used in test mode!'\n\n    addresses = [address]\n    \n    min_confirmations = 0\n    max_confirmation = 2000000000  # just a very large number for max\n    unspents = bitcoind.listunspent(min_confirmations, max_confirmation, addresses)\n\n    if BLOCKSTACK_TEST and len(unspents) == 0:\n        try:\n            bitcoind.importaddress(str(address))\n            unspents = bitcoind.listunspent(min_confirmations, max_confirmation, addresses)\n        except Exception as e:\n            return format_unspents([])\n\n    return format_unspents(unspents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_headers(self, status_code=200, content_type='application/json', more_headers={}):\n        self.send_response(status_code)\n        self.send_header('content-type', content_type)\n        self.send_header('Access-Control-Allow-Origin', '*')    # CORS\n        for (hdr, val) in more_headers.items():\n            self.send_header(hdr, val)\n\n        self.end_headers()", "response": "Send the headers to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reply_json(self, json_payload, status_code=200):\n        self._send_headers(status_code=status_code)\n        json_str = json.dumps(json_payload)\n        self.wfile.write(json_str)", "response": "Reply to the log file with a JSON - serializable data structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the raw uploaded data.", "response": "def _read_payload(self, maxlen=None):\n        \"\"\"\n        Read raw uploaded data.\n        Return the data on success\n        Return None on I/O error, or if maxlen is not None and the number of bytes read is too big\n        \"\"\"\n\n        client_address_str = \"{}:{}\".format(self.client_address[0], self.client_address[1])\n\n        # check length\n        read_len = self.headers.get('content-length', None)\n        if read_len is None:\n            log.error(\"No content-length given from {}\".format(client_address_str))\n            return None\n\n        try:\n            read_len = int(read_len)\n        except:\n            log.error(\"Invalid content-length\")\n            return None\n\n        if maxlen is not None and read_len >= maxlen:\n            log.error(\"Request from {} is too long ({} >= {})\".format(client_address_str, read_len, maxlen))\n            return None\n\n        # get the payload\n        request_str = self.rfile.read(read_len)\n        return request_str"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_json(self, schema=None, maxlen=JSONRPC_MAX_SIZE):\n        # JSON post?\n        request_type = self.headers.get('content-type', None)\n        client_address_str = \"{}:{}\".format(self.client_address[0], self.client_address[1])\n\n        if request_type != 'application/json':\n            log.error(\"Invalid request of type {} from {}\".format(request_type, client_address_str))\n            return None\n\n        request_str = self._read_payload(maxlen=maxlen)\n        if request_str is None:\n            log.error(\"Failed to read request\")\n            return None\n\n        # parse the payload\n        request = None\n        try:\n            request = json.loads( request_str )\n            if schema is not None:\n                jsonschema.validate( request, schema )\n\n        except ValidationError as ve:\n            if BLOCKSTACK_DEBUG:\n                log.exception(ve)\n\n            log.error(\"Validation error on request {}...\".format(request_str[:15]))\n\n            if ve.validator == \"maxLength\":\n                return {\"error\" : \"maxLength\"}\n\n        except (TypeError, ValueError) as ve:\n            if BLOCKSTACK_DEBUG:\n                log.exception(ve)\n\n            return None\n\n        return request", "response": "Read a JSON payload from the requester and return the parsed payload on success Return None on error"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_qs(self, qs):\n        qs_state = urllib2.urlparse.parse_qs(qs)\n        ret = {}\n        for qs_var, qs_value_list in qs_state.items():\n            if len(qs_value_list) > 1:\n                return None\n\n            ret[qs_var] = qs_value_list[0]\n\n        return ret", "response": "Parse a query string and return a dict with the variables that are set in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_path_and_qs(self):\n        path_parts = self.path.split(\"?\", 1)\n\n        if len(path_parts) > 1:\n            qs = path_parts[1].split(\"#\", 1)[0]\n        else:\n            qs = \"\"\n\n        path = path_parts[0].split(\"#\", 1)[0]\n        path = posixpath.normpath(urllib.unquote(path))\n\n        qs_values = self.parse_qs( qs )\n        if qs_values is None:\n            return {'error': 'Failed to parse query string'}\n\n        parts = path.strip('/').split('/')\n\n        return {'path': path, 'qs_values': qs_values, 'parts': parts}", "response": "Parse and obtain the path and query values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _route_match( self, method_name, path_info, route_table ):\n        path = path_info['path']\n\n        for route_path, route_info in route_table.items():\n            if method_name not in route_info['routes'].keys():\n                continue\n\n            grps = re.match(route_path, path)\n            if grps is None:\n                continue\n\n            groups = grps.groups()\n            return {\n                'route': route_info,\n                'method': route_info['routes'][method_name],\n                'args': groups,\n            }\n\n        return None", "response": "Return the route info and its arguments on success Return None on error"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OPTIONS_preflight( self, path_info ):\n        self.send_response(200)\n        self.send_header('Access-Control-Allow-Origin', '*')    # CORS\n        self.send_header('Access-Control-Allow-Methods', 'GET, PUT, POST, DELETE')\n        self.send_header('Access-Control-Allow-Headers', 'content-type, authorization, range')\n        self.send_header('Access-Control-Expose-Headers', 'content-length, content-range')\n        self.send_header('Access-Control-Max-Age', 21600)\n        self.end_headers()\n        return", "response": "Send CORS preflight check headers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GET_names_owned_by_address( self, path_info, blockchain, address ):\n        if not check_address(address):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        if blockchain != 'bitcoin':\n            return self._reply_json({'error': 'Unsupported blockchain'}, status_code=404)\n\n        blockstackd_url = get_blockstackd_url()\n        address = str(address)\n\n        subdomain_names = blockstackd_client.get_subdomains_owned_by_address(address, hostport=blockstackd_url)\n        if json_is_error(subdomain_names):\n            log.error(\"Failed to fetch subdomains owned by address\")\n            log.error(subdomain_names)\n            subdomain_names = []\n        \n        # make sure we have the right encoding\n        new_addr = virtualchain.address_reencode(address)\n        if new_addr != address:\n            log.debug(\"Re-encode {} to {}\".format(new_addr, address))\n            address = new_addr\n        \n        res = blockstackd_client.get_names_owned_by_address(address, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to get names owned by address\")\n            self._reply_json({'error': 'Failed to list names by address'}, status_code=res.get('http_status', 502))\n            return\n\n        self._reply_json({'names': res + subdomain_names})\n        return", "response": "Get all names owned by an address"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all token types that an address owns Returns a json response containing the list of tokens that an address owns", "response": "def GET_account_tokens(self, path_info, account_addr):\n        \"\"\"\n        Get all token types that an address owns\n        Returns {'tokens': [...]}\n        \"\"\"\n        if not check_account_address(account_addr):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_account_tokens(account_addr, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to load tokens for {}: {}\".format(account_addr, res['error']))\n            return self._reply_json({'error': 'Failed to load tokens for {}: {}'.format(account_addr, res['error'])}, status_code=res.get('http_status', 500))\n\n        self._reply_json({'tokens': res})\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the state of a particular token account", "response": "def GET_account_record(self, path_info, account_addr, token_type):\n        \"\"\"\n        Get the state of a particular token account\n        Returns the account\n        \"\"\"\n        if not check_account_address(account_addr):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        if not check_token_type(token_type):\n            return self._reply_json({'error': 'Invalid token type'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_account_record(account_addr, token_type, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to get account state for {} {}: {}\".format(account_addr, token_type, res['error']))\n            return self._reply_json({'error': 'Failed to get account record for {} {}: {}'.format(token_type, account_addr, res['error'])}, status_code=res.get('http_status', 500))\n\n        self._reply_json(res)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GET_account_balance(self, path_info, account_addr, token_type):\n        if not check_account_address(account_addr):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        if not check_token_type(token_type):\n            return self._reply_json({'error': 'Invalid token type'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_account_balance(account_addr, token_type, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to get account balance for {} {}: {}\".format(account_addr, token_type, res['error']))\n            return self._reply_json({'error': 'Failed to get balance of {} for {}: {}'.format(token_type, account_addr, res['error'])}, status_code=res.get('http_status', 500))\n\n        self._reply_json({'balance': str(res)})     # NOTE: use a string, since this can be too big for js clients to parse\n        return", "response": "Get the balance of a particular token"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GET_account_history(self, path_info, account_addr):\n        if not check_account_address(account_addr):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        qs_values = path_info['qs_values']\n        page = qs_values.get('page', None)\n\n        if page is None:\n            page = \"0\" # compatibility\n\n        try:\n            assert len(page) < 10\n            page = int(page)\n\n            assert page >= 0\n        except:\n            return self._reply_json({'error': 'Invalid start block or end block or invalid page'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_account_history_page(account_addr, page, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to list account history for {} at page {}: {}\".format(account_addr, page, res['error']))\n            return self._reply_json({'error': 'Failed to list account history for {} at page {}'.format(account_addr, page)}, status_code=res.get('http_status', 500))\n\n        self._reply_json(res)\n        return", "response": "Get the history of an account at a given page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the state of an account at a particular point in history Returns a list of the state of the account at a particular point in history Returns a JSON object containing the state of the account at a particular point in history Returns a 400 if the account is not in the state of the blockstackd server", "response": "def GET_account_at(self, path_info, account_addr, block_height):\n        \"\"\"\n        Get the state(s) of an account at a particular point in history\n        Returns [{...}]\n        \"\"\"\n        if not check_account_address(account_addr):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        try:\n            block_height = int(block_height)\n            assert check_block(block_height)\n        except:\n            return self._reply_json({'error': 'Invalid block height'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_account_at(account_addr, block_height, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to list account history for {} at {}: {}\".format(account_addr, block_height, res['error']))\n            return self._reply_json({'error': 'Failed to get account state for {} at {}'.format(account_addr, block_height)}, status_code=res.get('http_status', 500))\n\n        self._reply_json(res)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all names in existence.", "response": "def GET_names( self, path_info ):\n        \"\"\"\n        Get all names in existence\n        If `all=true` is set, then include expired names.\n        Returns the list on success\n        Returns 400 on invalid arguments\n        Returns 502 on failure to get names\n        \"\"\"\n\n        include_expired = False\n\n        qs_values = path_info['qs_values']\n        page = qs_values.get('page', None)\n        if page is None:\n            log.error(\"Page required\")\n            return self._reply_json({'error': 'page= argument required'}, status_code=400)\n\n        try:\n            page = int(page)\n            if page < 0:\n                raise ValueError(\"Page is negative\")\n\n        except ValueError:\n            log.error(\"Invalid page\")\n            return self._reply_json({'error': 'Invalid page= value'}, status_code=400)\n\n        if qs_values.get('all', '').lower() in ['1', 'true']:\n            include_expired = True\n\n        offset = page * 100\n        count = 100\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_all_names(offset, count, include_expired=include_expired, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error(\"Failed to list all names (offset={}, count={}): {}\".format(offset, count, res['error']))\n            return self._reply_json({'error': 'Failed to list all names'}, status_code=res.get('http_status', 502))\n\n        return self._reply_json(res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all subdomains in existence.", "response": "def GET_subdomains( self, path_info ):\n        \"\"\"\n        Get all subdomains in existence.\n        Requires page={int}\n        Returns the list on success\n        Returns 400 on invalid arguments\n        Returns 502 on failure to get names\n        \"\"\"\n        qs_values = path_info['qs_values']\n        page = qs_values.get('page', None)\n        if page is None:\n            log.error(\"Page required\")\n            return self._reply_json({'error': 'page= argument required'}, status_code=400)\n\n        try:\n            page = int(page)\n            assert page >= 0\n        except Exception:\n            log.error(\"Invalid page\")\n            return self._reply_json({'error': 'Invalid page= value'}, status_code=400)\n\n        offset = page * 100\n        count = 100\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_all_subdomains(offset, count, hostport=blockstackd_url)\n\n        if json_is_error(res):\n            log.error(\"Failed to list all subdomains (offset={}, count={}): {}\".format(offset, count, res['error']))\n            return self._reply_json({'error': 'Failed to list all names'}, status_code=res.get('http_status', 406))\n\n        return self._reply_json(res)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GET_subdomain_ops(self, path_info, txid):\n        blockstackd_url = get_blockstackd_url()\n        subdomain_ops = None\n        try:\n            subdomain_ops = blockstackd_client.get_subdomain_ops_at_txid(txid, hostport=blockstackd_url)\n        except ValueError:\n            return self._reply_json({'error': 'Invalid argument: not a well-formed txid'}, status_code=400)\n\n        if json_is_error(subdomain_ops):\n            log.error('Failed to get subdomain operations at {}: {}'.format(txid, subdomain_ops['error']))\n            return self._reply_json({'error': 'Failed to get subdomain operations'}, status_code=subdomain_ops.get('http_status', 500))\n\n        return self._reply_json(subdomain_ops)", "response": "Get all subdomain operations processed in a given transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting information about a name. Reply status zone hash address and last TXID Reply status can be available registered revoked or pending Reply status can be available pending", "response": "def GET_name_info( self, path_info, name ):\n        \"\"\"\n        Look up a name's zonefile, address, and last TXID\n        Reply status, zonefile, zonefile hash, address, and last TXID.\n        'status' can be 'available', 'registered', 'revoked', or 'pending'\n        \"\"\"\n        if not check_name(name) and not check_subdomain(name):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n\n        name_rec = None\n        try:\n            name_rec = blockstackd_client.get_name_record(name, include_history=False, hostport=blockstackd_url)\n        except ValueError:\n            return self._reply_json({'error': 'Invalid argument: not a well-formed name or subdomain'}, status_code=400)\n\n        if 'error' in name_rec:\n            if 'not found' in name_rec['error'].lower():\n                return self._reply_json({'status': 'available'}, status_code=404)\n\n            elif 'failed to load subdomain' in name_rec['error'].lower():\n\n                # try to redirect to resolver, if given\n                _, _, domain_name = blockstackd_scripts.is_address_subdomain(name)\n                domain_rec = blockstackd_client.get_name_record(domain_name, include_history=False, hostport=blockstackd_url)\n\n                if 'error' in domain_rec:\n                    # no resolver known for on-chain name\n                    return self._reply_json({'status': 'available', 'more': 'failed to look up parent domain'}, status_code=404)\n\n                resolver_target = domain_rec.get('resolver', None)\n                if resolver_target is None:\n                    # no _resolver\n                    return self._reply_json({'status': 'available',  'more': 'failed to find parent domain\\'s resolver'}, status_code=404)\n\n                redirect_location = resolver_target + '/v1/names/' + name\n                log.debug(\"Redirect lookup on {} to {}\".format(name, redirect_location))\n\n                self._send_headers(status_code=301, more_headers={ 'Location': redirect_location })\n                return self.wfile.write(json.dumps({'status': 'redirect'}))\n\n            elif 'expired' in name_rec['error'].lower():\n                return self._reply_json({'error': name_rec['error']}, status_code=404)\n\n            else:\n                return self._reply_json({'error': 'Blockstack daemon error: {}'.format(name_rec['error'])}, status_code=name_rec.get('http_status', 502))\n\n\n        zonefile_txt = None\n\n        if 'zonefile' in name_rec:\n            zonefile_txt = base64.b64decode(name_rec['zonefile'])\n\n        ret = {}\n\n        if blockstackd_scripts.is_subdomain(name):\n            # subdomain\n            address = name_rec['address']\n            if address:\n                address = virtualchain.address_reencode(str(address))\n\n            log.debug(\"{} is registered_subdomain\".format(name))\n            ret = {\n                'status': 'registered_subdomain',\n                'zonefile': zonefile_txt,\n                'zonefile_hash': name_rec['value_hash'],\n                'address': name_rec['address'],\n                'blockchain': 'bitcoin',\n                'last_txid': name_rec['txid'],\n                'did': name_rec.get('did', {'error': 'Not supported for this name'})\n            }\n\n        else:\n            status = 'revoked' if name_rec['revoked'] else 'registered'\n            address = name_rec['address']\n            if address:\n                address = virtualchain.address_reencode(str(address))\n\n            log.debug(\"{} is {}\".format(name, status))\n            ret = {\n                'status': status,\n                'zonefile': zonefile_txt,\n                'zonefile_hash': name_rec['value_hash'],\n                'address': address,\n                'last_txid': name_rec['txid'],\n                'blockchain': 'bitcoin',\n                'expire_block': name_rec['expire_block'],      # expire_block is what blockstack.js expects\n                'renewal_deadline': name_rec['renewal_deadline'],\n                'grace_period': name_rec.get('grace_period', False),\n                'resolver': name_rec.get('resolver', None),\n                'did': name_rec.get('did', {'error': 'Not supported for this name'})\n            }\n\n        return self._reply_json(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GET_name_history(self, path_info, name):\n        if not check_name(name) and not check_subdomain(name):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n\n        qs_values = path_info['qs_values']\n        page = qs_values.get('page', None)\n\n        if page is None:\n            page = \"0\"        # compatibility \n\n        try:\n            assert len(page) < 10\n            page = int(page)\n            assert page >= 0\n            assert page <= 2**32 - 1\n        except:\n            log.error(\"Invalid page\")\n            self._reply_json({'error': 'Invalid page'}, status_code=400)\n            return\n\n        blockstackd_url = get_blockstackd_url()\n        res = blockstackd_client.get_name_history_page(name, page, hostport=blockstackd_url)\n        if json_is_error(res):\n            log.error('Failed to get name history for {}: {}'.format(name, res['error']))\n            return self._reply_json({'error': res['error']}, status_code=res.get('http_status', 502))\n\n        return self._reply_json(res['history'])", "response": "Get the history of a name or subdomain. Requires page in the query string. Requires page in the query string. Returns 502 on failure to query blockstack server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GET_name_zonefile( self, path_info, name ):\n        if not check_name(name) and not check_subdomain(name):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n\n        raw = path_info['qs_values'].get('raw', '')\n        raw = (raw.lower() in ['1', 'true'])\n        \n        if not blockstackd_scripts.is_name_valid(name) and not blockstackd_scripts.is_subdomain(name):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        resp = blockstackd_client.get_name_record(name, include_history=False, hostport=blockstackd_url)\n        if json_is_error(resp):\n            log.error(\"Failed to load zone file for {}: {}\".format(name, resp['error']))\n            return self._reply_json({\"error\": resp['error']}, status_code=resp.get('http_status', 502))\n\n        if 'zonefile' not in resp or resp['zonefile'] is None:\n            log.error(\"No zone file for {}\".format(name))\n            return self._reply_json({'error': 'No zone file for name'}, status_code=404)\n\n        try:\n            zonefile_txt = base64.b64decode(resp['zonefile'])\n        except:\n            log.error(\"Zone file data is not serialized properly\")\n            return self._reply_json({'error': 'Zone file is not serialized properly'}, status_code=400)\n\n        if raw:\n            self._send_headers(status_code=200, content_type='application/octet-stream')\n            self.wfile.write(zonefile_txt)\n            return\n\n        else:\n            res = decode_name_zonefile(name, zonefile_txt)\n            if res is None:\n                log.error(\"Failed to parse zone file for {}\".format(name))\n                return self._reply_json({'error': 'Non-standard zone file.  Try passing raw=1 to get the raw zone file.'}) \n\n            # successfully decodes.  Safe to return as a JSON object.\n            return self._reply_json({'zonefile': zonefile_txt})", "response": "Get the name s current zonefile data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish a zonefile which has already been announced.", "response": "def POST_zonefile(self, path_info):\n        \"\"\"\n        Publish a zonefile which has *already* been announced.\n        Return 200 and {'status': True, 'servers': [...]} on success\n        Return 400 on invalid request, such as invalid JSON, JSON that doesn't match the schema, etc.\n        Return 502 on failure to replicate the zone file\n        \"\"\"\n        request_schema = {\n            'type': 'object',\n            'properties': {\n                'zonefile': {\n                    'type': 'string',\n                    'maxLength': RPC_MAX_ZONEFILE_LEN\n                },\n                'zonefile_b64': {\n                    'type': 'string',\n                    'pattern': OP_BASE64_EMPTY_PATTERN,\n                    'maxLength': (RPC_MAX_ZONEFILE_LEN * 4) / 3 + 1,\n                }\n            }\n        }\n        blockstackd_url = get_blockstackd_url()\n        zonefile_json = self._read_json(schema=request_schema)\n        if zonefile_json is None:\n            return self._reply_json({'error': 'Invalid request'}, status_code=400)\n\n        elif 'error' in zonefile_json:\n            log.error(\"Failed to parse JSON\")\n            return self._reply_json({'error': 'Invalid request'}, status_code=400)\n        \n        zonefile_str = zonefile_json.get('zonefile', False)\n        zonefile_hash = None \n\n        if zonefile_str:\n            # base64-encode \n            zonefile_hash = storage.get_zonefile_data_hash(zonefile_str)\n            zonefile_str = base64.b64encode(zonefile_str)\n\n        else:\n            # already given as b64-encoded?\n            zonefile_str = zonefile_json.get('zonefile_b64', False)\n            if not zonefile_str:\n                # neither given\n                return self._reply_json({'error': 'Invalid request'}, status_code=400)\n\n            zonefile_hash = storage.get_zonefile_data_hash(base64.b64decode(zonefile_json['zonefile_b64']))\n\n        zonefiles_b64 = [zonefile_str]\n        resp = blockstackd_client.put_zonefiles(blockstackd_url, zonefiles_b64)\n        if json_is_error(resp):\n            log.error(\"Failed to put {}: {}\".format(zonefile_hash, resp['error']))\n            return self._reply_json({'error': resp['error']}, status_code=resp.get('http_status', 502))\n\n        if len(resp['saved']) != 1:\n            log.error(\"Did not save {}, saved is {}\".format(zonefile_hash, resp['saved']))\n            return self._reply_json({'error': 'Blockstack node did not save the zone file'}, status_code=400)\n\n        return self._reply_json({'status': True, 'servers': [blockstackd_url]}, status_code=200)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a historic zonefile for a name.", "response": "def GET_name_zonefile_by_hash( self, path_info, name, zonefile_hash ):\n        \"\"\"\n        Get a historic zonefile for a name\n        With `raw=1` on the query string, return the raw zone file\n\n        Reply 200 with {'zonefile': zonefile} on success\n        Reply 204 with {'error': ...} if the zone file is non-standard\n        Reply 404 on not found\n        Reply 502 on failure to fetch data\n        \"\"\"\n        if not check_name(name) and not check_subdomain(name):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n        \n        if not check_string(zonefile_hash, pattern=OP_ZONEFILE_HASH_PATTERN):\n            return self._reply_json({'error': 'Invalid zone file hash'}, status_code=400)\n\n        raw = path_info['qs_values'].get('raw', '')\n        raw = (raw.lower() in ['1', 'true'])\n\n        blockstack_hostport = get_blockstackd_url()\n        was_set = blockstackd_client.is_name_zonefile_hash(name, zonefile_hash, hostport=blockstack_hostport)\n        if json_is_error(was_set):\n            return self._reply_json({'error': was_set['error']}, status_code=was_set.get('http_status', 502))\n\n        if not was_set['result']:\n            self._reply_json({'error': 'No such zonefile'}, status_code=404)\n            return\n\n        resp = blockstackd_client.get_zonefiles(blockstack_hostport, [str(zonefile_hash)])\n        if json_is_error(resp):\n            self._reply_json({'error': resp['error']}, status_code=resp.get('http_status', 502))\n            return\n\n        if str(zonefile_hash) not in resp['zonefiles']:\n            return self._reply_json({'error': 'Blockstack does not have this zonefile.  Try again later.'}, status_code=404)\n\n        if raw:\n            self._send_headers(status_code=200, content_type='application/octet-stream')\n            self.wfile.write(resp['zonefiles'][str(zonefile_hash)])\n\n        else:\n            # make sure it's valid\n            if str(zonefile_hash) not in resp['zonefiles']:\n                log.debug('Failed to find zonefile hash {}, possess {}'.format(\n                    str(zonefile_hash), resp['zonefiles'].keys()))\n                return self._reply_json({'error': 'No such zonefile'}, status_code=404)\n\n            zonefile_txt = resp['zonefiles'][str(zonefile_hash)]\n            res = decode_name_zonefile(name, zonefile_txt)\n            if res is None:\n                log.error(\"Failed to parse zone file for {}\".format(name))\n                self._reply_json({'error': 'Non-standard zone file for {}'.format(name)}, status_code=204)\n                return\n\n            self._reply_json({'zonefile': zonefile_txt})\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a user profile. Reply the user profile on success Return 404 on failure", "response": "def GET_did(self, path_info, did):\n        \"\"\"\n        Get a user profile.\n        Reply the profile on success\n        Return 404 on failure to load\n        \"\"\"\n        try:\n            did_info = parse_DID(did)\n            assert did_info['name_type'] in ('name', 'subdomain')\n        except Exception as e:\n            if BLOCKSTACK_DEBUG:\n                log.exception(e)\n\n            return self._reply_json({'error': 'Invalid DID'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        resp = blockstackd_client.resolve_DID(did, hostport=blockstackd_url)\n        if json_is_error(resp):\n            return self._reply_json({'error': resp['error']}, status_code=404)\n\n        return self._reply_json({'public_key': resp['public_key'], 'document': resp['document']})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GET_user_profile( self, path_info, user_id ):\n        if not check_name(user_id) and not check_subdomain(user_id):\n            return self._reply_json({'error': 'Invalid name or subdomain'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        resp = blockstackd_client.resolve_profile(user_id, hostport=blockstackd_url)\n        if json_is_error(resp):\n            self._reply_json({'error': resp['error']}, status_code=404)\n            return\n\n        self._reply_json(resp['profile'])\n        return", "response": "Get a user s profile Reply the user profile on success Return 404 on failure"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GET_prices_name( self, path_info, name ):\n        if not check_name(name):\n            return self._reply_json({'error': 'Invalid name'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        price_info = blockstackd_client.get_name_cost(name, hostport=blockstackd_url)\n        if json_is_error(price_info):\n            # error\n            status_code = price_info.get('http_status', 502)\n            return self._reply_json({'error': price_info['error']}, status_code=status_code)\n\n        ret = {\n            'amount': str(price_info['amount']),        # helps JS clients that can't parse big ints\n            'units': price_info['units'],\n        }\n        if ret['units'] == 'BTC':\n            # v1 compat\n            ret['satoshis'] = price_info['amount']\n\n        return self._reply_json({'name_price': ret})", "response": "Get the price for a name in a namespace Reply 404 if the name doesn t exist Reply 502 if the name is not in BT Reply 400 if the server doesn t respond with 400"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GET_namespace_num_names(self, path_info, namespace_id):\n        if not check_namespace(namespace_id):\n            return self._reply_json({'error': 'Invalid namespace'}, status_code=400)\n\n        blockstackd_url = get_blockstackd_url()\n        name_count = blockstackd_client.get_num_names_in_namespace(namespace_id, hostport=blockstackd_url)\n        if json_is_error(name_count):\n            log.error(\"Failed to load namespace count for {}: {}\".format(namespace_id, name_count['error']))\n            return self._reply_json({'error': 'Failed to load namespace count: {}'.format(name_count['error'])}, status_code=404)\n\n        self._reply_json({'names_count': name_count})", "response": "Get the number of names in a namespace Reply 200 on success Reply 502 on failure Reply 400 on error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GET_namespace_names( self, path_info, namespace_id ):\n        if not check_namespace(namespace_id):\n            return self._reply_json({'error': 'Invalid namespace'}, status_code=400)\n\n        qs_values = path_info['qs_values']\n        page = qs_values.get('page', None)\n        if page is None:\n            log.error(\"Page required\")\n            return self._reply_json({'error': 'page= argument required'}, status_code=400)\n\n        try:\n            page = int(page)\n            if page < 0:\n                raise ValueError()\n\n        except ValueError:\n            log.error(\"Invalid page\")\n            return self._reply_json({'error': 'Invalid page= value'}, status_code=400)\n\n        offset = page * 100\n        count = 100\n\n        blockstackd_url = get_blockstackd_url()\n        namespace_names = blockstackd_client.get_names_in_namespace(namespace_id, offset=offset, count=count, hostport=blockstackd_url)\n        if json_is_error(namespace_names):\n            # error\n            status_code = namespace_names.get('http_status', 502)\n            return self._reply_json({'error': namespace_names['error']}, status_code=status_code)\n\n        self._reply_json(namespace_names)\n        return", "response": "Get the list of names in a namespace Reply 404 if the namespace doesn t exist Reply 502 if the namespace doesn t exist Reply 502 if the namespace doesn t exist Reply 400 if the request is not authorized"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the name s historic name operations at the given block height Reply 404 for blockchains other than those supported Reply 502 for any error we have in talking to the blockstack server Reply 400 for invalid blockchain", "response": "def GET_blockchain_ops( self, path_info, blockchain_name, blockheight ):\n        \"\"\"\n        Get the name's historic name operations\n        Reply the list of nameops at the given block height\n        Reply 404 for blockchains other than those supported\n        Reply 502 for any error we have in talking to the blockstack server\n        \"\"\"\n        try:\n            blockheight = int(blockheight)\n            assert check_block(blockheight)\n        except:\n            return self._reply_json({'error': 'Invalid block'}, status_code=400)\n\n        if blockchain_name != 'bitcoin':\n            # not supported\n            return self._reply_json({'error': 'Unsupported blockchain'}, status_code=404)\n        \n        blockstackd_url = get_blockstackd_url()\n        nameops = blockstackd_client.get_blockstack_transactions_at(int(blockheight), hostport=blockstackd_url)\n        if json_is_error(nameops):\n            # error\n            status_code = nameops.get('http_status', 502)\n            return self._reply_json({'error': nameops['error']}, status_code=status_code)\n\n        self._reply_json(nameops)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the number of names on this blockchain", "response": "def GET_blockchain_num_names( self, path_info, blockchain_name ):\n        \"\"\"\n        Handle GET /blockchains/:blockchainID/name_count\n        Takes `all=true` to include expired names\n        Reply with the number of names on this blockchain\n        \"\"\"\n        if blockchain_name != 'bitcoin':\n            # not supported\n            self._reply_json({'error': 'Unsupported blockchain'}, status_code=404)\n            return\n\n        include_expired = False\n        \n        qs_values = path_info['qs_values']\n        if qs_values.get('all', '').lower() in ['1', 'true']:\n            include_expired = True\n\n        blockstackd_url = get_blockstackd_url()\n        num_names = blockstackd_client.get_num_names(include_expired=include_expired, hostport=blockstackd_url)\n        if json_is_error(num_names):\n            # error\n            status_code = num_names.get('http_status', 502)\n            return self._reply_json({'error': num_names['error']}, status_code=status_code)\n\n        self._reply_json({'names_count': num_names})\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the number of subdomains on this blockchain", "response": "def GET_blockchain_num_subdomains( self, path_info, blockchain_name ):\n        \"\"\"\n        Handle GET /blockchains/:blockchainID/subdomains_count\n        Takes `all=true` to include expired names\n        Reply with the number of names on this blockchain\n        \"\"\"\n        if blockchain_name != 'bitcoin':\n            # not supported\n            self._reply_json({'error': 'Unsupported blockchain'}, status_code=404)\n            return\n\n        blockstackd_url = get_blockstackd_url()\n        num_names = blockstackd_client.get_num_subdomains(hostport=blockstackd_url)\n        if json_is_error(num_names):\n            if json_is_exception(num_names):\n                status_code = 406\n            else:\n                status_code = 404\n\n            self._reply_json({'error': num_names['error']}, status_code=status_code)\n            return\n\n        self._reply_json({'names_count': num_names})\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_balance( self, get_address, min_confs ):\n        bitcoind_opts = get_bitcoin_opts()\n        bitcoind_host = bitcoind_opts['bitcoind_server']\n        bitcoind_port = bitcoind_opts['bitcoind_port']\n        bitcoind_user = bitcoind_opts['bitcoind_user']\n        bitcoind_passwd = bitcoind_opts['bitcoind_passwd']\n\n        bitcoind = create_bitcoind_service_proxy(bitcoind_user, bitcoind_passwd, server=bitcoind_host, port=bitcoind_port)\n        address = virtualchain.address_reencode(get_address)\n\n        try:\n            unspents = get_unspents(address, bitcoind)\n        except Exception as e:\n            log.exception(e)\n            return {'error': 'Failed to get unspents for {}'.format(get_address)}\n\n        satoshis_confirmed = sum(confirmed_utxo['value'] for confirmed_utxo in \n                                 filter(lambda utxo: utxo['confirmations'] >= min_confs, unspents))\n\n        return {'balance': satoshis_confirmed}", "response": "Get the confirmed balance for an address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the confirmed balance of an insight.", "response": "def GET_confirmed_balance_insight( self, path_info, address ):\n        \"\"\"\n        Works only in test mode!\n        Handle GET /insight-api/addr/:address/balance\n        \"\"\"\n        if not BLOCKSTACK_TEST:\n            return self._send_headers(status_code=404, content_type='text/plain')\n\n        if not check_address(address):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        res = self._get_balance(address, 1)\n        if 'error' in res:\n            return self._reply_json(res, status_code=502)\n\n        return self._reply_json(res['balance'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the unspent utxo entries for an address", "response": "def GET_utxos_insight( self, path_info, address ):\n        \"\"\"\n        Handle GET /insight-api/addr/:address/utxo\n        NOTE: this is not compatible with the Bitcore Insight API method of the same name\n        \"\"\"\n        if not BLOCKSTACK_TEST:\n            return self._send_headers(status_code=404, content_type='text/plain')\n\n        if not check_address(address):\n            return self._reply_json({'error': 'Invalid address'}, status_code=400)\n\n        bitcoind_opts = get_bitcoin_opts()\n        bitcoind_host = bitcoind_opts['bitcoind_server']\n        bitcoind_port = bitcoind_opts['bitcoind_port']\n        bitcoind_user = bitcoind_opts['bitcoind_user']\n        bitcoind_passwd = bitcoind_opts['bitcoind_passwd']\n\n        bitcoind = create_bitcoind_service_proxy(bitcoind_user, bitcoind_passwd, server=bitcoind_host, port=bitcoind_port)\n        address = virtualchain.address_reencode(address)\n        utxos = get_unspents(address, bitcoind)\n        return self._reply_json(utxos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets info from blockstackd", "response": "def GET_getinfo(self, path_info):\n        \"\"\"\n        getinfo\n        \"\"\"\n        blockstackd_url = get_blockstackd_url()\n        info = blockstackd_client.getinfo(hostport=blockstackd_url)\n        if json_is_error(info):\n            # error\n            status_code = info.get('http_status', 502)\n            return self._reply_json({'error': info['error']}, status_code=status_code)\n\n        return self._reply_json(info)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndispatch the method_name to the base class.", "response": "def _dispatch(self, method_name):\n        \"\"\"\n        Top-level dispatch method\n        \"\"\"\n        URLENCODING_CLASS = r'[a-zA-Z0-9\\-_.~%]'\n\n        routes = {\n            r'^/v1/ping$': {\n                'routes': {\n                    'GET': self.GET_ping,\n                },\n            },\n            r'^/v1/info$': {\n                'routes': {\n                    'GET': self.GET_getinfo,\n                },\n            },\n            r'^/v1/addresses/({}{{1,256}})/({}{{1,40}})$'.format(URLENCODING_CLASS, URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_names_owned_by_address,\n                },\n            },\n            r'^/v1/accounts/({}{{1,256}})/tokens$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_account_tokens,\n                },\n            },\n            r'^/v1/accounts/({}{{1,256}})/({}{{1,40}})/status$'.format(URLENCODING_CLASS, URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_account_record,\n                },\n            },\n            r'^/v1/accounts/({}{{1,256}})/({}{{1,40}})/balance$'.format(URLENCODING_CLASS, URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_account_balance,\n                },\n            },\n            r'^/v1/accounts/({}{{1,256}})/history/([0-9]+)$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_account_at,\n                },\n            },\n            r'^/v1/accounts/({}{{1,256}})/history$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_account_history,\n                 },\n            },\n            r'^/v1/blockchains/({}{{1,40}})/name_count'.format(URLENCODING_CLASS) : {\n                'routes': {\n                    'GET': self.GET_blockchain_num_names\n                },\n            },\n            r'^/v1/blockchains/({}{{1,256}})/subdomains_count'.format(URLENCODING_CLASS) : {\n                'routes': {\n                    'GET': self.GET_blockchain_num_subdomains\n                },\n            },\n            r'^/v1/blockchains/({}{{1,40}})/operations/([0-9]+)$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_blockchain_ops\n                },\n            },\n            r'^/v1/blockchains/({}{{1,40}})/names/({}{{1,40}})$'.format(URLENCODING_CLASS, URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_blockchain_name_record,\n                },\n            },\n            r'^/v1/blockchains/({}{{1,40}})/consensus$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_blockchain_consensus,\n                },\n            },\n            r'^/v1/dids/(did:stack:v0:{}+-[0-9]+)$'.format(OP_BASE58CHECK_CLASS): {\n                'routes': {\n                    'GET': self.GET_did,\n                },\n            },\n            r'^/v1/names$': {\n                'routes': {\n                    'GET': self.GET_names,\n                },\n            },\n            r'^/v1/names/({}{{1,256}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_name_info,\n                },\n            },\n            r'^/v1/names/({}{{1,256}})/history$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_name_history,\n                },\n            },\n            r'^/v1/names/({}{{1,256}})/zonefile$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_name_zonefile,\n                },\n            },\n            r'^/v1/names/({}{{1,256}})/zonefile/([0-9a-fA-F]{{{}}})$'.format(URLENCODING_CLASS, LENGTHS['value_hash'] * 2): {\n                'routes': {\n                    'GET': self.GET_name_zonefile_by_hash,     # returns a zonefile\n                },\n            },\n            r'^/v1/namespaces$': {\n                'routes': {\n                    'GET': self.GET_namespaces,\n                },\n            },\n            r'^/v1/namespaces/({}{{1,40}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_namespace_info,\n                },\n            },\n            r'^/v1/namespaces/({}{{1,40}})/names$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_namespace_names,\n                },\n            },\n            r'^/v1/namespaces/({}{{1,40}})/name_count$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_namespace_num_names,\n                },\n            },\n            r'^/v1/node/ping$': {\n                'routes': {\n                    'GET': self.GET_ping,\n                },\n            },\n            r'^/v1/prices/namespaces/({}{{1,40}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_prices_namespace,\n                },\n            },\n            r'^/v1/prices/names/({}{{1,256}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_prices_name,\n                },\n            },\n            r'^/v2/prices/namespaces/({}{{1,40}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_prices_namespace,\n                },\n            },\n            r'^/v2/prices/names/({}{{1,256}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_prices_name,\n                },\n            },\n            r'^/v1/subdomains$': {\n                'routes': {\n                    'GET': self.GET_subdomains\n                },\n            },\n            r'^/v1/subdomains/([0-9a-fA-F]{64})$': {\n                'routes': {\n                    'GET': self.GET_subdomain_ops,\n                },\n            },\n            r'^/v1/users/({}{{1,256}})$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_user_profile,\n                },\n            },\n            r'^/insight-api/addr/({}{{1,40}})/balance$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_confirmed_balance_insight,\n                },\n            },\n            r'^/insight-api/addr/({}{{1,40}})/unconfirmedBalance$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_unconfirmed_balance_insight,\n                },\n            },\n            r'^/insight-api/addr/({}{{1,40}})/utxo$'.format(URLENCODING_CLASS): {\n                'routes': {\n                    'GET': self.GET_utxos_insight,\n                },\n            },\n            r'^/v1/zonefiles/([0-9a-fA-F]{{{}}})$'.format(LENGTHS['value_hash']*2): {\n                'routes': {\n                    'GET': self.GET_zonefile,\n                },\n            },\n            r'^/v1/zonefile$': {\n                'routes': {\n                    'POST': self.POST_zonefile,\n                },\n            },\n            r'^/v1/.*$': {\n                'routes': {\n                    'OPTIONS': self.OPTIONS_preflight,\n                },\n            },\n            r'^/v2/.*$': {\n                'routes': {\n                    'OPTIONS': self.OPTIONS_preflight,\n                },\n            },\n        }\n        \n        conf = get_blockstack_api_opts()\n        if not conf['enabled']:\n            # this feature is not enabled\n            self._send_headers(status_code=404, content_type='text/plain')\n            return \n\n        path_info = self.get_path_and_qs()\n        if 'error' in path_info:\n            self._send_headers(status_code=400, content_type='text/plain')\n            return\n\n        qs_values = path_info['qs_values']\n\n        route_info = self._route_match( method_name, path_info, routes )\n        if route_info is None:\n            if BLOCKSTACK_DEBUG and BLOCKSTACK_TEST:\n                log.warning(\"Unmatched route: {} '{}'\".format(method_name, path_info['path']))\n\n            routes = routes.keys()\n            routes.sort()\n            log.debug(json.dumps(routes, sort_keys=True, indent=4))\n            return self._reply_json({'error': 'No such endpoint'}, status_code=404)\n\n        route_args = route_info['args']\n        route_method = route_info['method']\n        route = route_info['route']\n\n        if BLOCKSTACK_TEST:\n            log.debug(\"\\nfull path: {}\\nmethod: {}\\npath: {}\\nqs: {}\\nheaders:\\n{}\\n\".format(self.path, method_name, path_info['path'], qs_values, '\\n'.join( '{}: {}'.format(k, v) for (k, v) in self.headers.items() )))\n\n        try:\n            return route_method( path_info, *route_args )\n        except Exception as e:\n            log.exception(e)\n            return self._send_headers(status_code=500, content_type='text/plain')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bind(self):\n        log.debug(\"Set SO_REUSADDR\")\n        self.socket.setsockopt( socket.SOL_SOCKET, socket.SO_REUSEADDR, 1 )\n        \n        # we want daemon threads, so we join on abrupt shutdown (applies if multithreaded) \n        self.daemon_threads = True\n\n        self.server_bind()\n        self.server_activate()", "response": "Bind to our port and activate the daemon threads"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string that contains the overloaded HTTP response.", "response": "def overloaded(self, client_addr):\n        \"\"\"\n        Deflect if we have too many inbound requests\n        \"\"\"\n        overloaded_txt = 'HTTP/1.0 429 Too Many Requests\\r\\nServer: BaseHTTP/0.3 Python/2.7.14+\\r\\nContent-type: text/plain\\r\\nContent-length: 17\\r\\n\\r\\nToo many requests'\n        if BLOCKSTACK_TEST:\n            log.warn('Too many requests; deflecting {}'.format(client_addr))\n\n        return overloaded_txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an object to a byte string.", "response": "def to_bytes(obj, encoding='utf-8', errors=None, nonstring='simplerepr'):\n    \"\"\"Make sure that a string is a byte string\n\n    :arg obj: An object to make sure is a byte string.  In most cases this\n        will be either a text string or a byte string.  However, with\n        ``nonstring='simplerepr'``, this can be used as a traceback-free\n        version of ``str(obj)``.\n    :kwarg encoding: The encoding to use to transform from a text string to\n        a byte string.  Defaults to using 'utf-8'.\n    :kwarg errors: The error handler to use if the text string is not\n        encodable using the specified encoding.  Any valid `codecs error\n        handler <https://docs.python.org/2/library/codecs.html#codec-base-classes>`_\n        may be specified. There are three additional error strategies\n        specifically aimed at helping people to port code.  The first two are:\n\n            :surrogate_or_strict: Will use ``surrogateescape`` if it is a valid\n                handler, otherwise it will use ``strict``\n            :surrogate_or_replace: Will use ``surrogateescape`` if it is a valid\n                handler, otherwise it will use ``replace``.\n\n        Because ``surrogateescape`` was added in Python3 this usually means that\n        Python3 will use ``surrogateescape`` and Python2 will use the fallback\n        error handler. Note that the code checks for ``surrogateescape`` when the\n        module is imported.  If you have a backport of ``surrogateescape`` for\n        Python2, be sure to register the error handler prior to importing this\n        module.\n\n        The last error handler is:\n\n            :surrogate_then_replace: Will use ``surrogateescape`` if it is a valid\n                handler.  If encoding with ``surrogateescape`` would traceback,\n                surrogates are first replaced with a replacement characters\n                and then the string is encoded using ``replace`` (which replaces\n                the rest of the nonencodable bytes).  If ``surrogateescape`` is\n                not present it will simply use ``replace``.  (Added in Ansible 2.3)\n                This strategy is designed to never traceback when it attempts\n                to encode a string.\n\n        The default until Ansible-2.2 was ``surrogate_or_replace``\n        From Ansible-2.3 onwards, the default is ``surrogate_then_replace``.\n\n    :kwarg nonstring: The strategy to use if a nonstring is specified in\n        ``obj``.  Default is 'simplerepr'.  Valid values are:\n\n        :simplerepr: The default.  This takes the ``str`` of the object and\n            then returns the bytes version of that string.\n        :empty: Return an empty byte string\n        :passthru: Return the object passed in\n        :strict: Raise a :exc:`TypeError`\n\n    :returns: Typically this returns a byte string.  If a nonstring object is\n        passed in this may be a different type depending on the strategy\n        specified by nonstring.  This will never return a text string.\n\n    .. note:: If passed a byte string, this function does not check that the\n        string is valid in the specified encoding.  If it's important that the\n        byte string is in the specified encoding do::\n\n            encoded_string = to_bytes(to_text(input_string, 'latin-1'), 'utf-8')\n\n    .. version_changed:: 2.3\n\n        Added the ``surrogate_then_replace`` error handler and made it the default error handler.\n    \"\"\"\n    if isinstance(obj, binary_type):\n        return obj\n\n    # We're given a text string\n    # If it has surrogates, we know because it will decode\n    original_errors = errors\n    if errors in _COMPOSED_ERROR_HANDLERS:\n        if HAS_SURROGATEESCAPE:\n            errors = 'surrogateescape'\n        elif errors == 'surrogate_or_strict':\n            errors = 'strict'\n        else:\n            errors = 'replace'\n\n    if isinstance(obj, text_type):\n        try:\n            # Try this first as it's the fastest\n            return obj.encode(encoding, errors)\n        except UnicodeEncodeError:\n            if original_errors in (None, 'surrogate_then_replace'):\n                # Slow but works\n                return_string = obj.encode('utf-8', 'surrogateescape')\n                return_string = return_string.decode('utf-8', 'replace')\n                return return_string.encode(encoding, 'replace')\n            raise\n\n    # Note: We do these last even though we have to call to_bytes again on the\n    # value because we're optimizing the common case\n    if nonstring == 'simplerepr':\n        try:\n            value = str(obj)\n        except UnicodeError:\n            try:\n                value = repr(obj)\n            except UnicodeError:\n                # Giving up\n                return to_bytes('')\n    elif nonstring == 'passthru':\n        return obj\n    elif nonstring == 'empty':\n        # python2.4 doesn't have b''\n        return to_bytes('')\n    elif nonstring == 'strict':\n        raise TypeError('obj must be a string type')\n    else:\n        raise TypeError('Invalid value %s for to_bytes\\' nonstring parameter' % nonstring)\n\n    return to_bytes(value, encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an object to a text string.", "response": "def to_text(obj, encoding='utf-8', errors=None, nonstring='simplerepr'):\n    \"\"\"Make sure that a string is a text string\n\n    :arg obj: An object to make sure is a text string.  In most cases this\n        will be either a text string or a byte string.  However, with\n        ``nonstring='simplerepr'``, this can be used as a traceback-free\n        version of ``str(obj)``.\n    :kwarg encoding: The encoding to use to transform from a byte string to\n        a text string.  Defaults to using 'utf-8'.\n    :kwarg errors: The error handler to use if the byte string is not\n        decodable using the specified encoding.  Any valid `codecs error\n        handler <https://docs.python.org/2/library/codecs.html#codec-base-classes>`_\n        may be specified.   We support three additional error strategies\n        specifically aimed at helping people to port code:\n\n            :surrogate_or_strict: Will use surrogateescape if it is a valid\n                handler, otherwise it will use strict\n            :surrogate_or_replace: Will use surrogateescape if it is a valid\n                handler, otherwise it will use replace.\n            :surrogate_then_replace: Does the same as surrogate_or_replace but\n                `was added for symmetry with the error handlers in\n                :func:`ansible.module_utils._text.to_bytes` (Added in Ansible 2.3)\n\n        Because surrogateescape was added in Python3 this usually means that\n        Python3 will use `surrogateescape` and Python2 will use the fallback\n        error handler. Note that the code checks for surrogateescape when the\n        module is imported.  If you have a backport of `surrogateescape` for\n        python2, be sure to register the error handler prior to importing this\n        module.\n\n        The default until Ansible-2.2 was `surrogate_or_replace`\n        In Ansible-2.3 this defaults to `surrogate_then_replace` for symmetry\n        with :func:`ansible.module_utils._text.to_bytes` .\n    :kwarg nonstring: The strategy to use if a nonstring is specified in\n        ``obj``.  Default is 'simplerepr'.  Valid values are:\n\n        :simplerepr: The default.  This takes the ``str`` of the object and\n            then returns the text version of that string.\n        :empty: Return an empty text string\n        :passthru: Return the object passed in\n        :strict: Raise a :exc:`TypeError`\n\n    :returns: Typically this returns a text string.  If a nonstring object is\n        passed in this may be a different type depending on the strategy\n        specified by nonstring.  This will never return a byte string.\n        From Ansible-2.3 onwards, the default is `surrogate_then_replace`.\n\n    .. version_changed:: 2.3\n\n        Added the surrogate_then_replace error handler and made it the default error handler.\n    \"\"\"\n    if isinstance(obj, text_type):\n        return obj\n\n    if errors in _COMPOSED_ERROR_HANDLERS:\n        if HAS_SURROGATEESCAPE:\n            errors = 'surrogateescape'\n        elif errors == 'surrogate_or_strict':\n            errors = 'strict'\n        else:\n            errors = 'replace'\n\n    if isinstance(obj, binary_type):\n        # Note: We don't need special handling for surrogate_then_replace\n        # because all bytes will either be made into surrogates or are valid\n        # to decode.\n        return obj.decode(encoding, errors)\n\n    # Note: We do these last even though we have to call to_text again on the\n    # value because we're optimizing the common case\n    if nonstring == 'simplerepr':\n        try:\n            value = str(obj)\n        except UnicodeError:\n            try:\n                value = repr(obj)\n            except UnicodeError:\n                # Giving up\n                return u''\n    elif nonstring == 'passthru':\n        return obj\n    elif nonstring == 'empty':\n        return u''\n    elif nonstring == 'strict':\n        raise TypeError('obj must be a string type')\n    else:\n        raise TypeError('Invalid value %s for to_text\\'s nonstring parameter' % nonstring)\n\n    return to_text(value, encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npushing images to a registry", "response": "def hostcmd_push(base_path, project_name, engine_name, vars_files=None, config_file=None, **kwargs):\n    \"\"\"\n    Push images to a registry. Requires authenticating with the registry prior to starting\n    the push. If your engine's config file does not already contain an authorization for the\n    registry, pass username and/or password. If you exclude password, you will be prompted.\n    \"\"\"\n    assert_initialized(base_path, config_file)\n    config = get_config(base_path, vars_files=vars_files, engine_name=engine_name, project_name=project_name,\n                        config_file=config_file)\n\n    engine_obj = load_engine(['LOGIN', 'PUSH'],\n                             engine_name, config.project_name,\n                             config['services'], **kwargs)\n    logger.debug('PROJECT NAME', project_name=config.project_name)\n    push_images(base_path,\n                config.image_namespace,\n                engine_obj,\n                config,\n                save_conductor=config.save_conductor,\n                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push_images(base_path, image_namespace, engine_obj, config, **kwargs):\n    config_path = kwargs.get('config_path', engine_obj.auth_config_path)\n    username = kwargs.get('username')\n    password = kwargs.get('password')\n    push_to = kwargs.get('push_to')\n    url = engine_obj.default_registry_url\n    registry_name = engine_obj.default_registry_name\n    namespace = image_namespace\n    save_conductor = config.save_conductor\n    repository_prefix = None\n    pull_from_url = None\n\n    if push_to:\n        if config.get('registries', dict()).get(push_to):\n            url = config['registries'][push_to].get('url')\n            namespace = config['registries'][push_to].get('namespace', namespace)\n            repository_prefix = config['registries'][push_to].get('repository_prefix')\n            pull_from_url = config['registries'][push_to].get('pull_from_url')\n            if not url:\n                raise AnsibleContainerRegistryAttributeException(\n                    u\"Registry {} missing required attribute 'url'\".format(push_to)\n                )\n        else:\n            url, namespace = resolve_push_to(push_to, engine_obj.default_registry_url, namespace)\n\n    if username and not password:\n        # If a username was supplied without a password, prompt for it\n        if url != engine_obj.default_registry_url:\n            registry_name = url\n        while not password:\n            password = getpass.getpass(u\"Enter password for {0} at {1}: \".format(username, registry_name))\n\n    if config_path:\n        # Make sure the config_path exists\n        #  - gives us a chance to create the file with correct permissions, if it does not exists\n        #  - makes sure we mount a path to the conductor for a specific file\n        config_path = os.path.normpath(os.path.expanduser(config_path))\n        if os.path.exists(config_path) and os.path.isdir(config_path):\n            raise AnsibleContainerException(\n                u\"Expecting --config-path to be a path to a file, not a directory\"\n            )\n        elif not os.path.exists(config_path):\n            # Make sure the directory path exists\n            if not os.path.exists(os.path.dirname(config_path)):\n                try:\n                    os.makedirs(os.path.dirname(config_path), 0o750)\n                except OSError:\n                    raise AnsibleContainerException(\n                        u\"Failed to create the requested the path {}\".format(os.path.dirname(config_path))\n                    )\n            # Touch the file\n            open(config_path, 'w').close()\n\n    # If you ran build with --save-build-container, then you're broken without first removing\n    #  the old build container.\n    remove_existing_container(engine_obj, 'conductor', remove_volumes=True)\n\n    push_params = {}\n    push_params.update(kwargs)\n    push_params['config_path'] = config_path\n    push_params['password'] = password\n    push_params['url'] = url\n    push_params['namespace'] = namespace\n    push_params['repository_prefix'] = repository_prefix\n    push_params['pull_from_url'] = pull_from_url\n\n    # Push\n    engine_obj.await_conductor_command('push', dict(config), base_path, push_params, save_container=save_conductor)\n\n    return {'url': url,\n            'namespace': namespace,\n            'repository_prefix': repository_prefix,\n            'pull_from_url': pull_from_url }", "response": "Pushes images to a Docker registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_existing_container(engine_obj, service_name, remove_volumes=False):\n    conductor_container_id = engine_obj.get_container_id_for_service(service_name)\n    if engine_obj.service_is_running(service_name):\n        engine_obj.stop_container(conductor_container_id, forcefully=True)\n    if conductor_container_id:\n        engine_obj.delete_container(conductor_container_id, remove_volumes=remove_volumes)", "response": "Remove an existing conductor container for an existing service. Handy for removing an existing conductor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a push - to value return the registry and namespace.", "response": "def resolve_push_to(push_to, default_url, default_namespace):\n    '''\n    Given a push-to value, return the registry and namespace.\n\n    :param push_to: string: User supplied --push-to value.\n    :param default_url: string: Container engine's default_index value (e.g. docker.io).\n    :return: tuple: registry_url, namespace\n    '''\n    protocol = 'http://' if push_to.startswith('http://') else 'https://'\n    url = push_to = REMOVE_HTTP.sub('', push_to)\n    namespace = default_namespace\n    parts = url.split('/', 1)\n    special_set = {'.', ':'}\n    char_set = set([c for c in parts[0]])\n\n    if len(parts) == 1:\n        if not special_set.intersection(char_set) and parts[0] != 'localhost':\n            registry_url = default_url\n            namespace = push_to\n        else:\n            registry_url = protocol + parts[0]\n    else:\n        registry_url = protocol + parts[0]\n        namespace = parts[1]\n    return registry_url, namespace"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_path_ownership(path, uid, gid):\n    os.chown(path, uid, gid)\n    for root, dirs, files in os.walk(path):\n        for d in dirs:\n            if not(os.path.islink(os.path.join(root, d))):\n                os.chown(os.path.join(root, d), uid, gid)\n        for f in files:\n            if not(os.path.islink(os.path.join(root, f))):\n                os.chown(os.path.join(root, f), uid, gid)", "response": "Sets the user and group ownership of the files and subdirectories in the path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npush images to a registry", "response": "def conductorcmd_push(engine_name, project_name, services, **kwargs):\n    \"\"\" Push images to a registry \"\"\"\n    username = kwargs.pop('username')\n    password = kwargs.pop('password')\n    email = kwargs.pop('email')\n    url = kwargs.pop('url')\n    namespace = kwargs.pop('namespace')\n    tag = kwargs.pop('tag')\n    config_path = kwargs.pop('config_path')\n    repository_prefix =kwargs.pop('repository_prefix')\n\n    engine = load_engine(['PUSH', 'LOGIN'], engine_name, project_name, services)\n    logger.info(u'Engine integration loaded. Preparing push.',\n                engine=engine.display_name)\n\n    # Verify that we can authenticate with the registry\n    username, password = engine.login(username, password, email, url, config_path)\n\n    # Push each image that has been built using Ansible roles\n    for name, service in iteritems(services):\n        if service.get('containers'):\n            for c in service['containers']:\n                if 'roles' in c:\n                    cname = '%s-%s' % (name, c['container_name'])\n                    image_id = engine.get_latest_image_id_for_service(cname)\n                    engine.push(image_id, cname, url=url, tag=tag, namespace=namespace, username=username,\n                                password=password, repository_prefix=repository_prefix)\n        elif 'roles' in service:\n            # if the service has roles, it's an image we should push\n            image_id = engine.get_latest_image_id_for_service(name)\n            engine.push(image_id, name, url=url, tag=tag, namespace=namespace, username=username,\n                        password=password, repository_prefix=repository_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_on_hosts(hosts, max_attempts=3, sleep_time=1):\n    '''\n    Wait for a container to have a State.Running value = true.\n    :param hosts: list of service names taken from container.yml\n    :param max_attempts: Max number of times to inspect the container and check State.Running\n    :param sleep_time: Number of seconds to wait between attempts.\n    :return: dict of host:running pairs\n    '''\n    results = {}\n    for host in hosts:\n        container = \"ansible_{}_1\".format(host)\n        tries = max_attempts\n        host_ready = False\n        output = None\n        results[host] = False\n        while tries > 0 and not host_ready:\n            try:\n                output = subprocess.check_output([\"docker\", \"inspect\", \"--format\", \"{{ .State.Running }}\",\n                                                  container], stderr=STDOUT)\n            except CalledProcessError:\n                pass\n            tries -= 1\n            if output and 'true' in output:\n                host_ready = True\n                results[host] = True\n            else:\n                sleep(sleep_time)\n    return results", "response": "Wait until a container is ready on a list of hosts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lines_iter(self):\n        '''\n        Returns contents of the Dockerfile as an array, where each line in the file is an element in the array.\n        :return: list\n        '''\n        # Convert unicode chars to string\n        byte_to_string = lambda x: x.strip().decode(u'utf-8') if isinstance(x, bytes) else x.strip()\n\n        # Read the entire contents of the Dockerfile, decoding each line, and return the result as an array\n        with open(self.docker_file_path, u'r') as f:\n            for line in f:\n                yield byte_to_string(line)", "response": "Returns the contents of the Dockerfile as an array where each line in the file is an element in the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preparse_iter(self):\n        to_yield = {}\n        last_directive = None\n        lines_processed = 0\n        for line in self.lines_iter():\n            if not line:\n                continue\n            if line.startswith(u'#'):\n                comment = line.lstrip('#').strip()\n                # Directives have to precede any instructions\n                if lines_processed == 1:\n                    if comment.startswith(u'escape='):\n                        self.escape_char = comment.split(u'=', 1)[1]\n                        continue\n                to_yield.setdefault('comments', []).append(comment)\n            else:\n                # last_directive being set means the previous line ended with a\n                # newline escape\n                if last_directive:\n                    directive, payload = last_directive, line\n                else:\n                    directive, payload = line.split(u' ', 1)\n                if line.endswith(self.escape_char):\n                    payload = payload.rstrip(self.escape_char)\n                    last_directive = directive\n                else:\n                    last_directive = None\n                to_yield['directive'] = directive\n                to_yield['payload'] = payload.strip()\n                yield to_yield\n                to_yield = {}", "response": "Iterate over the lines of the Dockerfile and yield the information that can be used to generate the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates roles and role structure from template.", "response": "def create_role_from_template(self):\n        '''\n        Create roles/dockerfile-to-ansible path and role structure.\n        :return: None\n        '''\n        description = u\"Imported Dockerfile for {}\".format(self.project_name)\n\n        create_role_from_templates(role_name=os.path.basename(self.import_from),\n                                   role_path=self.role_path,\n                                   project_name=self.project_name,\n                                   description=description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_container(self, image_id, service_name, **kwargs):\n        run_kwargs = self.run_kwargs_for_service(service_name)\n        run_kwargs.update(kwargs, relax=True)\n        logger.debug('Running container in docker', image=image_id, params=run_kwargs)\n\n        container_obj = self.client.containers.run(\n            image=image_id,\n            detach=True,\n            **run_kwargs\n        )\n\n        log_iter = container_obj.logs(stdout=True, stderr=True, stream=True)\n        mux = logmux.LogMultiplexer()\n        mux.add_iterator(log_iter, plainLogger)\n        return container_obj.id", "response": "Run a particular container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the top - level secrets directive to the Docker format", "response": "def _get_top_level_secrets(self):\n        \"\"\"\n        Convert the top-level 'secrets' directive to the Docker format\n        :return: secrets dict\n        \"\"\"\n        top_level_secrets = dict()\n        if self.secrets:\n            for secret, secret_definition in iteritems(self.secrets):\n                if isinstance(secret_definition, dict):\n                    for key, value in iteritems(secret_definition):\n                        name = '{}_{}'.format(secret, key)\n                        top_level_secrets[name] = dict(external=True)\n                elif isinstance(secret_definition, string_types):\n                    top_level_secrets[secret] = dict(external=True)\n        return top_level_secrets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_orchestration_playbook(self, url=None, namespace=None, vault_files=None, **kwargs):\n        states = ['start', 'restart', 'stop', 'destroy']\n        service_def = {}\n        for service_name, service in iteritems(self.services):\n            service_definition = {}\n            if service.get('roles'):\n                if url and namespace:\n                    # Reference previously pushed image\n                    service_definition[u'image'] = '{}/{}/{}'.format(re.sub(r'/$', '', url), namespace,\n                                                                     self.image_name_for_service(service_name))\n                else:\n                    # Check that the image was built\n                    image = self.get_latest_image_for_service(service_name)\n                    if image is None:\n                        raise exceptions.AnsibleContainerConductorException(\n                            u\"No image found for service {}, make sure you've run `ansible-container \"\n                            u\"build`\".format(service_name)\n                        )\n                    service_definition[u'image'] = image.tags[0]\n            else:\n                try:\n                    # Check if the image is already local\n                    image = self.client.images.get(service['from'])\n                    image_from = image.tags[0]\n                except docker.errors.ImageNotFound:\n                    image_from = service['from']\n                    logger.warning(u\"Image {} for service {} not found. \"\n                                   u\"An attempt will be made to pull it.\".format(service['from'], service_name))\n                service_definition[u'image'] = image_from\n\n            for extra in self.COMPOSE_WHITELIST:\n                if extra in service:\n                    service_definition[extra] = service[extra]\n\n            if 'secrets' in service:\n                service_secrets = []\n                for secret, secret_engines in iteritems(service[u'secrets']):\n                    if 'docker' in secret_engines:\n                        service_secrets += secret_engines[u'docker']\n                if service_secrets:\n                    service_definition[u'secrets'] = service_secrets\n                if self.CAP_SIM_SECRETS:\n                    # Simulate external secrets using a Docker volume\n                    if not 'volumes' in service_definition:\n                        service_definition['volumes'] = []\n                    service_definition['volumes'].append(\"{}:/run/secrets:ro\".format(self.secrets_volume_name))\n\n            logger.debug(u'Adding new service to definition',\n                         service=service_name, definition=service_definition)\n            service_def[service_name] = service_definition\n\n        tasks = []\n\n        top_level_secrets = self._get_top_level_secrets()\n        if self.CAP_SIM_SECRETS and top_level_secrets:\n            # Let compose know that we're using a named volume to simulate external secrets\n            if not isinstance(self.volumes, dict):\n                self.volumes = dict()\n            self.volumes[self.secrets_volume_name] = dict(external=True)\n\n        for desired_state in states:\n            task_params = {\n                u'project_name': self.project_name,\n                u'definition': {\n                    u'version': u'3.1' if top_level_secrets else u'2',\n                    u'services': service_def,\n                }\n            }\n            if self.secrets:\n                task_params[u'definition'][u'secrets'] = top_level_secrets\n            if self.volumes:\n                task_params[u'definition'][u'volumes'] = dict(self.volumes)\n\n            if desired_state in {'restart', 'start', 'stop'}:\n                task_params[u'state'] = u'present'\n                if desired_state == 'restart':\n                    task_params[u'restarted'] = True\n                if desired_state == 'stop':\n                    task_params[u'stopped'] = True\n            elif desired_state == 'destroy':\n                task_params[u'state'] = u'absent'\n                task_params[u'remove_volumes'] = u'yes'\n\n            tasks.append({u'docker_service': task_params, u'tags': [desired_state]})\n\n        playbook = []\n\n        if self.secrets and self.CAP_SIM_SECRETS:\n            playbook.append(self.generate_secrets_play(vault_files=vault_files))\n\n        playbook.append(CommentedMap([\n            (u'name', 'Deploy {}'.format(self.project_name)),\n            (u'hosts', u'localhost'),\n            (u'gather_facts', False)\n        ]))\n\n        if vault_files:\n            playbook[len(playbook) - 1][u'vars_files'] = [os.path.normpath(os.path.abspath(v)) for v in vault_files]\n        playbook[len(playbook) - 1][u'tasks'] = tasks\n\n        for service in list(self.services.keys()) + ['conductor']:\n            image_name = self.image_name_for_service(service)\n            for image in self.client.images.list(name=image_name):\n                logger.debug('Found image for service', tags=image.tags, id=image.short_id)\n                for tag in image.tags:\n                    if tag.startswith(self.project_name):\n                        logger.debug('Adding task to destroy image', tag=tag)\n                        playbook[len(playbook) - 1][u'tasks'].append({\n                            u'docker_image': {\n                                u'name': tag,\n                                u'state': u'absent',\n                                u'force': u'yes'\n                            },\n                            u'tags': u'destroy'\n                        })\n\n        if self.secrets and self.CAP_SIM_SECRETS:\n            playbook.append(self.generate_remove_volume_play())\n\n        logger.debug(u'Created playbook to run project', playbook=playbook)\n        return playbook", "response": "Generate an Ansible playbook to orchestrate services."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, image_id, service_name, tag=None, namespace=None, url=None, username=None, password=None,\n             repository_prefix=None, **kwargs):\n        \"\"\"\n        Push an image to a remote registry.\n        \"\"\"\n        auth_config = {\n            'username': username,\n            'password': password\n        }\n\n        build_stamp = self.get_build_stamp_for_image(image_id)\n        tag = tag or build_stamp\n\n        if repository_prefix:\n            image_name = \"{}-{}\".format(repository_prefix, service_name)\n        elif repository_prefix is None:\n            image_name = \"{}-{}\".format(self.project_name, service_name)\n        elif repository_prefix == '':\n            image_name = service_name\n        repository = \"{}/{}\".format(namespace, image_name)\n\n        if url != self.default_registry_url:\n            url = REMOVE_HTTP.sub('', url)\n            repository = \"%s/%s\" % (url.rstrip('/'), repository)\n\n        logger.info('Tagging %s' % repository)\n        self.client.api.tag(image_id, repository, tag=tag)\n\n        logger.info('Pushing %s:%s...' % (repository, tag))\n        stream = self.client.api.push(repository, tag=tag, stream=True, auth_config=auth_config)\n\n        last_status = None\n        for data in stream:\n            data = data.splitlines()\n            for line in data:\n                line = json.loads(line)\n                if type(line) is dict and 'error' in line:\n                    plainLogger.error(line['error'])\n                    raise exceptions.AnsibleContainerException(\n                        \"Failed to push image. {}\".format(line['error'])\n                    )\n                elif type(line) is dict and 'status' in line:\n                    if line['status'] != last_status:\n                        plainLogger.info(line['status'])\n                    last_status = line['status']\n                else:\n                    plainLogger.debug(line)", "response": "Push an image to a remote registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs-in to the registry.", "response": "def login(self, username, password, email, url, config_path):\n        \"\"\"\n        If username and password are provided, authenticate with the registry.\n        Otherwise, check the config file for existing authentication data.\n        \"\"\"\n        if username and password:\n            try:\n                self.client.login(username=username, password=password, email=email,\n                                  registry=url, reauth=True)\n            except docker_errors.APIError as exc:\n                raise exceptions.AnsibleContainerConductorException(\n                    u\"Error logging into registry: {}\".format(exc)\n                )\n            except Exception:\n                raise\n\n            self._update_config_file(username, password, email, url, config_path)\n\n        username, password = self._get_registry_auth(url, config_path)\n        if not username:\n            raise exceptions.AnsibleContainerConductorException(\n                u'Please provide login credentials for registry {}.'.format(url))\n        return username, password"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the config file with the authorization.", "response": "def _update_config_file(username, password, email, url, config_path):\n        \"\"\"Update the config file with the authorization.\"\"\"\n        try:\n            # read the existing config\n            config = json.load(open(config_path, \"r\"))\n        except ValueError:\n            config = dict()\n\n        if not config.get('auths'):\n            config['auths'] = dict()\n\n        if not config['auths'].get(url):\n            config['auths'][url] = dict()\n        encoded_credentials = dict(\n            auth=base64.b64encode(username + b':' + password),\n            email=email\n        )\n        config['auths'][url] = encoded_credentials\n        try:\n            json.dump(config, open(config_path, \"w\"), indent=5, sort_keys=True)\n        except Exception as exc:\n            raise exceptions.AnsibleContainerConductorException(\n                u\"Failed to write registry config to {0} - {1}\".format(config_path, exc)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_registry_auth(registry_url, config_path):\n        username = None\n        password = None\n        try:\n            docker_config = json.load(open(config_path))\n        except ValueError:\n            # The configuration file is empty\n            return username, password\n        if docker_config.get('auths'):\n            docker_config = docker_config['auths']\n        auth_key = docker_config.get(registry_url, {}).get('auth', None)\n        if auth_key:\n            username, password = base64.b64decode(auth_key).split(':', 1)\n        return username, password", "response": "Retrieve from the config file the current authentication for a given URL and return the username and password of the current user and password of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset default values for options.", "response": "def initialize_options(self):\n        \"\"\"Set default values for options.\"\"\"\n        # Each user option must be listed here with their default value.\n        self.debug = False\n        self.ignore_errors = False\n        self.distros = ''\n        self.conductor_provider = 'ansible'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new role from a list of templates.", "response": "def create_role_from_templates(role_name=None, role_path=None,\n                               project_name=None, description=None):\n    \"\"\"\n    Create a new role with initial files from templates.\n    :param role_name: Name of the role\n    :param role_path: Full path to the role\n    :param project_name: Name of the project, or the base path name.\n    :param description: One line description of the role.\n    :return: None\n    \"\"\"\n    context = locals()\n    templates_path = os.path.join(conductor_dir, 'templates', 'role')\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%s')\n\n    logger.debug('Role template location', path=templates_path)\n    for rel_path, templates in [(os.path.relpath(path, templates_path), files)\n                                for (path, _, files) in os.walk(templates_path)]:\n        target_dir = os.path.join(role_path, rel_path)\n        dir_util.mkpath(target_dir)\n        for template in templates:\n            template_rel_path = os.path.join(rel_path, template)\n            target_name = template.replace('.j2', '')\n            target_path = os.path.join(target_dir, target_name)\n            if os.path.exists(target_path):\n                backup_path = u'%s_%s' % (target_path, timestamp)\n                logger.debug(u'Found existing file. Backing target to backup',\n                    target=target_path, backup=backup_path)\n                os.rename(target_path, backup_path)\n            logger.debug(\"Rendering template for %s/%s\" % (target_dir, template))\n            jinja_render_to_temp(templates_path,\n                                 template_rel_path,\n                                 target_dir,\n                                 target_name,\n                                 **context)\n\n    new_file_name = \"main_{}.yml\".format(datetime.today().strftime('%y%m%d%H%M%S'))\n    new_tasks_file = os.path.join(role_path, 'tasks', new_file_name)\n    tasks_file = os.path.join(role_path, 'tasks', 'main.yml')\n\n    if os.path.exists(tasks_file):\n        os.rename(tasks_file, new_tasks_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a role definition returns the file path to the role", "response": "def resolve_role_to_path(role):\n    \"\"\"\n    Given a role definition from a service's list of roles, returns the file path to the role\n    \"\"\"\n    loader = DataLoader()\n    try:\n        variable_manager = VariableManager(loader=loader)\n    except TypeError:\n        # If Ansible prior to ansible/ansible@8f97aef1a365\n        variable_manager = VariableManager()\n    role_obj = RoleInclude.load(data=role, play=None,\n                                variable_manager=variable_manager,\n                                loader=loader)\n    return role_obj._role_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_role_fingerprint(role, service_name, config_vars):\n    def hash_file(hash_obj, file_path):\n        blocksize = 64 * 1024\n        with open(file_path, 'rb') as ifs:\n            while True:\n                data = ifs.read(blocksize)\n                if not data:\n                    break\n                hash_obj.update(data)\n                hash_obj.update('::')\n\n    def hash_dir(hash_obj, dir_path):\n        for root, dirs, files in os.walk(dir_path, topdown=True):\n            for file_path in files:\n                abs_file_path = os.path.join(root, file_path)\n                hash_obj.update(abs_file_path.encode('utf-8'))\n                hash_obj.update('::')\n                hash_file(hash_obj, abs_file_path)\n\n    def hash_role(hash_obj, role_path):\n        # Role content is easy to hash - the hash of the role content with the\n        # hash of any role dependencies it has\n        hash_dir(hash_obj, role_path)\n        for dependency in get_dependencies_for_role(role_path):\n            if dependency:\n                dependency_path = resolve_role_to_path(dependency)\n                hash_role(hash_obj, dependency_path)\n        # However tasks within that role might reference files outside of the\n        # role, like source code\n        loader = DataLoader()\n        var_man = VariableManager(loader=loader)\n        play = Play.load(generate_playbook_for_role(service_name, config_vars, role)[0],\n                         variable_manager=var_man, loader=loader)\n        play_context = PlayContext(play=play)\n        inv_man = InventoryManager(loader, sources=['%s,' % service_name])\n        host = Host(service_name)\n        iterator = PlayIterator(inv_man, play, play_context, var_man, config_vars)\n        while True:\n            _, task = iterator.get_next_task_for_host(host)\n            if task is None: break\n            if task.action in FILE_COPY_MODULES:\n                src = task.args.get('src')\n                if src is not None:\n                    if not os.path.exists(src) or not src.startswith(('/', '..')): continue\n                    src = os.path.realpath(src)\n                    if os.path.isfile(src):\n                        hash_file(hash_obj, src)\n                    else:\n                        hash_dir(hash_obj, src)\n\n    def get_dependencies_for_role(role_path):\n        meta_main_path = os.path.join(role_path, 'meta', 'main.yml')\n        if os.path.exists(meta_main_path):\n            meta_main = yaml.safe_load(open(meta_main_path))\n            if meta_main:\n                for dependency in meta_main.get('dependencies', []):\n                    yield dependency.get('role', None)\n\n    hash_obj = hashlib.sha256()\n    # Account for variables passed to the role by including the invocation string\n    hash_obj.update((json.dumps(role) if not isinstance(role, string_types) else role) + '::')\n    # Add each of the role's files and directories\n    hash_role(hash_obj, resolve_role_to_path(role))\n    return hash_obj.hexdigest()", "response": "Given a role definition returns a fingerprint based on the role contents and the hexdigest of each dependency."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn decorator for backoff and retry triggered by predicate. Args: wait_gen: A generator yielding successive wait times in seconds. predicate: A function which when called on the return value of the target function will trigger backoff when considered truthily. If not specified, the default behavior is to backoff on falsey return values. max_tries: The maximum number of attempts to make before giving up. In the case of failure, the result of the last attempt will be returned. The default value of None means there is no limit to the number of tries. If a callable is passed, it will be evaluated at runtime and its return value used. max_time: The maximum total amount of time to try for before giving up. If this time expires, the result of the last attempt will be returned. If a callable is passed, it will be evaluated at runtime and its return value used. jitter: A function of the value yielded by wait_gen returning the actual time to wait. This distributes wait times stochastically in order to avoid timing collisions across concurrent clients. Wait times are jittered by default using the full_jitter function. Jittering may be disabled altogether by passing jitter=None. on_success: Callable (or iterable of callables) with a unary signature to be called in the event of success. The parameter is a dict containing details about the invocation. on_backoff: Callable (or iterable of callables) with a unary signature to be called in the event of a backoff. The parameter is a dict containing details about the invocation. on_giveup: Callable (or iterable of callables) with a unary signature to be called in the event that max_tries is exceeded. The parameter is a dict containing details about the invocation. logger: Name of logger or Logger object to log to. Defaults to 'backoff'. **wait_gen_kwargs: Any additional keyword args specified will be passed to wait_gen when it is initialized. Any callable args will first be evaluated and their return values passed. This is useful for runtime configuration.", "response": "def on_predicate(wait_gen,\n                 predicate=operator.not_,\n                 max_tries=None,\n                 max_time=None,\n                 jitter=full_jitter,\n                 on_success=None,\n                 on_backoff=None,\n                 on_giveup=None,\n                 logger='backoff',\n                 **wait_gen_kwargs):\n    \"\"\"Returns decorator for backoff and retry triggered by predicate.\n\n    Args:\n        wait_gen: A generator yielding successive wait times in\n            seconds.\n        predicate: A function which when called on the return value of\n            the target function will trigger backoff when considered\n            truthily. If not specified, the default behavior is to\n            backoff on falsey return values.\n        max_tries: The maximum number of attempts to make before giving\n            up. In the case of failure, the result of the last attempt\n            will be returned. The default value of None means there\n            is no limit to the number of tries. If a callable is passed,\n            it will be evaluated at runtime and its return value used.\n        max_time: The maximum total amount of time to try for before\n            giving up. If this time expires, the result of the last\n            attempt will be returned. If a callable is passed, it will\n            be evaluated at runtime and its return value used.\n        jitter: A function of the value yielded by wait_gen returning\n            the actual time to wait. This distributes wait times\n            stochastically in order to avoid timing collisions across\n            concurrent clients. Wait times are jittered by default\n            using the full_jitter function. Jittering may be disabled\n            altogether by passing jitter=None.\n        on_success: Callable (or iterable of callables) with a unary\n            signature to be called in the event of success. The\n            parameter is a dict containing details about the invocation.\n        on_backoff: Callable (or iterable of callables) with a unary\n            signature to be called in the event of a backoff. The\n            parameter is a dict containing details about the invocation.\n        on_giveup: Callable (or iterable of callables) with a unary\n            signature to be called in the event that max_tries\n            is exceeded.  The parameter is a dict containing details\n            about the invocation.\n        logger: Name of logger or Logger object to log to. Defaults to\n            'backoff'.\n        **wait_gen_kwargs: Any additional keyword args specified will be\n            passed to wait_gen when it is initialized.  Any callable\n            args will first be evaluated and their return values passed.\n            This is useful for runtime configuration.\n    \"\"\"\n    def decorate(target):\n        # change names because python 2.x doesn't have nonlocal\n        logger_ = logger\n        if isinstance(logger_, basestring):\n            logger_ = logging.getLogger(logger_)\n        on_success_ = _config_handlers(on_success)\n        on_backoff_ = _config_handlers(on_backoff, _log_backoff, logger_)\n        on_giveup_ = _config_handlers(on_giveup, _log_giveup, logger_)\n\n        retry = None\n        if sys.version_info >= (3, 5):  # pragma: python=3.5\n            import asyncio\n\n            if asyncio.iscoroutinefunction(target):\n                import backoff._async\n                retry = backoff._async.retry_predicate\n\n            elif _is_event_loop() and _is_current_task():\n                # Verify that sync version is not being run from coroutine\n                # (that would lead to event loop hiccups).\n                raise TypeError(\n                    \"backoff.on_predicate applied to a regular function \"\n                    \"inside coroutine, this will lead to event loop \"\n                    \"hiccups. Use backoff.on_predicate on coroutines in \"\n                    \"asynchronous code.\")\n\n        if retry is None:\n            retry = _sync.retry_predicate\n\n        return retry(target, wait_gen, predicate,\n                     max_tries, max_time, jitter,\n                     on_success_, on_backoff_, on_giveup_,\n                     wait_gen_kwargs)\n\n    # Return a function which decorates a target with a retry loop.\n    return decorate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_exception(wait_gen,\n                 exception,\n                 max_tries=None,\n                 max_time=None,\n                 jitter=full_jitter,\n                 giveup=lambda e: False,\n                 on_success=None,\n                 on_backoff=None,\n                 on_giveup=None,\n                 logger='backoff',\n                 **wait_gen_kwargs):\n    \"\"\"Returns decorator for backoff and retry triggered by exception.\n\n    Args:\n        wait_gen: A generator yielding successive wait times in\n            seconds.\n        exception: An exception type (or tuple of types) which triggers\n            backoff.\n        max_tries: The maximum number of attempts to make before giving\n            up. Once exhausted, the exception will be allowed to escape.\n            The default value of None means their is no limit to the\n            number of tries. If a callable is passed, it will be\n            evaluated at runtime and its return value used.\n        max_time: The maximum total amount of time to try for before\n            giving up. Once expired, the exception will be allowed to\n            escape. If a callable is passed, it will be\n            evaluated at runtime and its return value used.\n        jitter: A function of the value yielded by wait_gen returning\n            the actual time to wait. This distributes wait times\n            stochastically in order to avoid timing collisions across\n            concurrent clients. Wait times are jittered by default\n            using the full_jitter function. Jittering may be disabled\n            altogether by passing jitter=None.\n        giveup: Function accepting an exception instance and\n            returning whether or not to give up. Optional. The default\n            is to always continue.\n        on_success: Callable (or iterable of callables) with a unary\n            signature to be called in the event of success. The\n            parameter is a dict containing details about the invocation.\n        on_backoff: Callable (or iterable of callables) with a unary\n            signature to be called in the event of a backoff. The\n            parameter is a dict containing details about the invocation.\n        on_giveup: Callable (or iterable of callables) with a unary\n            signature to be called in the event that max_tries\n            is exceeded.  The parameter is a dict containing details\n            about the invocation.\n        logger: Name or Logger object to log to. Defaults to 'backoff'.\n        **wait_gen_kwargs: Any additional keyword args specified will be\n            passed to wait_gen when it is initialized.  Any callable\n            args will first be evaluated and their return values passed.\n            This is useful for runtime configuration.\n    \"\"\"\n    def decorate(target):\n        # change names because python 2.x doesn't have nonlocal\n        logger_ = logger\n        if isinstance(logger_, basestring):\n            logger_ = logging.getLogger(logger_)\n        on_success_ = _config_handlers(on_success)\n        on_backoff_ = _config_handlers(on_backoff, _log_backoff, logger_)\n        on_giveup_ = _config_handlers(on_giveup, _log_giveup, logger_)\n\n        retry = None\n        if sys.version_info[:2] >= (3, 5):   # pragma: python=3.5\n            import asyncio\n\n            if asyncio.iscoroutinefunction(target):\n                import backoff._async\n                retry = backoff._async.retry_exception\n            elif _is_event_loop() and _is_current_task():\n                # Verify that sync version is not being run from coroutine\n                # (that would lead to event loop hiccups).\n                raise TypeError(\n                    \"backoff.on_exception applied to a regular function \"\n                    \"inside coroutine, this will lead to event loop \"\n                    \"hiccups. Use backoff.on_exception on coroutines in \"\n                    \"asynchronous code.\")\n\n        if retry is None:\n            retry = _sync.retry_exception\n\n        return retry(target, wait_gen, exception,\n                     max_tries, max_time, jitter, giveup,\n                     on_success_, on_backoff_, on_giveup_,\n                     wait_gen_kwargs)\n\n    # Return a function which decorates a target with a retry loop.\n    return decorate", "response": "Decorator for backoff and retry triggered by exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expo(base=2, factor=1, max_value=None):\n    n = 0\n    while True:\n        a = factor * base ** n\n        if max_value is None or a < max_value:\n            yield a\n            n += 1\n        else:\n            yield max_value", "response": "Generator for exponential decay."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fibo(max_value=None):\n    a = 1\n    b = 1\n    while True:\n        if max_value is None or a < max_value:\n            yield a\n            a, b = b, a + b\n        else:\n            yield max_value", "response": "Generator for fibonaccial decay."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_incorrect_erc20_interface(contract):\n        functions = [f for f in contract.functions if f.contract == contract and \\\n                     IncorrectERC20InterfaceDetection.incorrect_erc20_interface(f.signature)]\n        return functions", "response": "Detect incorrect ERC20 interface returning a list of functions that are not in the correct ERC20 interface"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _detect(self):\n        results = []\n        for c in self.contracts:\n            functions = IncorrectERC20InterfaceDetection.detect_incorrect_erc20_interface(c)\n            if functions:\n                info = \"{} ({}) has incorrect ERC20 function interface(s):\\n\"\n                info = info.format(c.name,\n                                   c.source_mapping_str)\n                for function in functions:\n                    info += \"\\t-{} ({})\\n\".format(function.name, function.source_mapping_str)\n                json = self.generate_json_result(info)\n                self.add_functions_to_json(functions, json)\n                results.append(json)\n\n        return results", "response": "Detect incorrect erc20 interface and return a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect if functions access modifiers events state variables and local variables are named after the contract reserved keywords. Any such definitions are returned in a list.", "response": "def detect_shadowing_definitions(self, contract):\n        \"\"\" Detects if functions, access modifiers, events, state variables, and local variables are named after\n        reserved keywords. Any such definitions are returned in a list.\n\n        Returns:\n            list of tuple: (type, contract name, definition)\"\"\"\n        result = []\n\n        # Loop through all functions + modifiers in this contract.\n        for function in contract.functions + contract.modifiers:\n            # We should only look for functions declared directly in this contract (not in a base contract).\n            if function.contract != contract:\n                continue\n\n            # This function was declared in this contract, we check what its local variables might shadow.\n            for variable in function.variables:\n                overshadowed = []\n                for scope_contract in [contract] + contract.inheritance:\n                    # Check functions\n                    for scope_function in scope_contract.functions:\n                        if variable.name == scope_function.name and scope_function.contract == scope_contract:\n                            overshadowed.append((self.OVERSHADOWED_FUNCTION, scope_contract.name, scope_function))\n                    # Check modifiers\n                    for scope_modifier in scope_contract.modifiers:\n                        if variable.name == scope_modifier.name and scope_modifier.contract == scope_contract:\n                            overshadowed.append((self.OVERSHADOWED_MODIFIER, scope_contract.name, scope_modifier))\n                    # Check events\n                    for scope_event in scope_contract.events:\n                        if variable.name == scope_event.name and scope_event.contract == scope_contract:\n                            overshadowed.append((self.OVERSHADOWED_EVENT, scope_contract.name, scope_event))\n                    # Check state variables\n                    for scope_state_variable in scope_contract.variables:\n                        if variable.name == scope_state_variable.name and scope_state_variable.contract == scope_contract:\n                            overshadowed.append((self.OVERSHADOWED_STATE_VARIABLE, scope_contract.name, scope_state_variable))\n\n                # If we have found any overshadowed objects, we'll want to add it to our result list.\n                if overshadowed:\n                    result.append((contract.name, function.name, variable, overshadowed))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _detect(self):\n\n        results = []\n        for contract in self.contracts:\n            shadows = self.detect_shadowing_definitions(contract)\n            if shadows:\n                for shadow in shadows:\n                    local_parent_name = shadow[1]\n                    local_variable = shadow[2]\n                    overshadowed = shadow[3]\n                    info = '{}.{}.{} (local variable @ {}) shadows:\\n'.format(contract.name,\n                                                                              local_parent_name,\n                                                                              local_variable.name,\n                                                                              local_variable.source_mapping_str)\n                    for overshadowed_entry in overshadowed:\n                        info += \"\\t- {}.{} ({} @ {})\\n\".format(overshadowed_entry[1],\n                                                               overshadowed_entry[2],\n                                                               overshadowed_entry[0],\n                                                               overshadowed_entry[2].source_mapping_str)\n\n\n                    # Generate relevant JSON data for this shadowing definition.\n                    json = self.generate_json_result(info)\n                    self.add_variable_to_json(local_variable, json)\n                    for overshadowed_entry in overshadowed:\n                        if overshadowed_entry[0] in [self.OVERSHADOWED_FUNCTION, self.OVERSHADOWED_MODIFIER,\n                                                     self.OVERSHADOWED_EVENT]:\n                            self.add_function_to_json(overshadowed_entry[2], json)\n                        elif overshadowed_entry[0] == self.OVERSHADOWED_STATE_VARIABLE:\n                            self.add_variable_to_json(overshadowed_entry[2], json)\n                    results.append(json)\n\n        return results", "response": "Detect shadowing local variables recursively visit the calls\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_detector(self, detector_class):\n        self._check_common_things('detector', detector_class, AbstractDetector, self._detectors)\n\n        instance = detector_class(self, logger_detector)\n        self._detectors.append(instance)", "response": "Register a detector class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new printer class.", "response": "def register_printer(self, printer_class):\n        \"\"\"\n        :param printer_class: Class inheriting from `AbstractPrinter`.\n        \"\"\"\n        self._check_common_things('printer', printer_class, AbstractPrinter, self._printers)\n\n        instance = printer_class(self, logger_printer)\n        self._printers.append(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_detectors(self):\n\n        self.load_previous_results()\n        results = [d.detect() for d in self._detectors]\n        self.write_results_to_hide()\n        return results", "response": "Runs all the detectors in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect state variables that could be const", "response": "def _detect(self):\n        \"\"\" Detect state variables that could be const\n        \"\"\"\n        results = []\n        all_info = ''\n\n        all_variables = [c.state_variables for c in self.slither.contracts]\n        all_variables = set([item for sublist in all_variables for item in sublist])\n        all_non_constant_elementary_variables = set([v for v in all_variables\n                                                     if self._valid_candidate(v)])\n\n        all_functions = [c.all_functions_called for c in self.slither.contracts]\n        all_functions = list(set([item for sublist in all_functions for item in sublist]))\n\n        all_variables_written = [f.state_variables_written for f in all_functions]\n        all_variables_written = set([item for sublist in all_variables_written for item in sublist])\n\n        constable_variables = [v for v in all_non_constant_elementary_variables\n                               if (not v in all_variables_written) and self._constant_initial_expression(v)]\n        # Order for deterministic results\n        constable_variables = sorted(constable_variables, key=lambda x: x.canonical_name)\n        for v in constable_variables:\n            info = \"{}.{} should be constant ({})\\n\".format(v.contract.name,\n                                                            v.name,\n                                                            v.source_mapping_str)\n            all_info += info\n        if all_info != '':\n            json = self.generate_json_result(all_info)\n            self.add_variables_to_json(constable_variables, json)\n            results.append(json)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output(self, _filename):\n\n        for contract in self.slither.contracts_derived:\n            txt = \"\\nContract %s\"%contract.name\n            table = PrettyTable([\"Function\",\n                                 \"Modifiers\"])\n            for function in contract.functions:\n                modifiers = function.modifiers\n                for call in function.all_internal_calls():\n                    if isinstance(call, Function):\n                        modifiers += call.modifiers\n                for (_, call) in function.all_library_calls():\n                    if isinstance(call, Function):\n                        modifiers += call.modifiers\n                table.add_row([function.name, [m.name for m in set(modifiers)]])\n            txt += \"\\n\"+str(table)\n            self.info(txt)", "response": "Output the list of functions in the current language."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_suicidal_func(func):\n\n        if func.is_constructor:\n            return False\n\n        if func.visibility != 'public':\n            return False\n\n        calls = [c.name for c in func.internal_calls]\n        if not ('suicide(address)' in calls or 'selfdestruct(address)' in calls):\n            return False\n\n        if func.is_protected():\n            return False\n\n        return True", "response": "Detects if the function is suicidal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting the suicidal functions and add them to the json result", "response": "def _detect(self):\n        \"\"\" Detect the suicidal functions\n        \"\"\"\n        results = []\n        for c in self.contracts:\n            functions = self.detect_suicidal(c)\n            for func in functions:\n\n                txt = \"{}.{} ({}) allows anyone to destruct the contract\\n\"\n                info = txt.format(func.contract.name,\n                                  func.name,\n                                  func.source_mapping_str)\n\n                json = self.generate_json_result(info)\n                self.add_function_to_json(func, json)\n                results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing dominators of a set of nodes.", "response": "def compute_dominators(nodes):\n    '''\n        Naive implementation of Cooper, Harvey, Kennedy algo\n        See 'A Simple,Fast Dominance Algorithm'\n\n        Compute strict domniators\n    '''\n    changed = True\n\n    for n in nodes:\n        n.dominators = set(nodes)\n\n    while changed:\n        changed = False\n\n        for node in nodes:\n            new_set = intersection_predecessor(node).union({node})\n            if new_set != node.dominators:\n                node.dominators = new_set\n                changed = True\n\n    # compute immediate dominator\n    for node in nodes:\n        idom_candidates = set(node.dominators)\n        idom_candidates.remove(node)\n\n        for dominator in node.dominators:\n            if dominator != node:\n                [idom_candidates.remove(d) for d in dominator.dominators if d in idom_candidates and d!=dominator]\n\n        assert len(idom_candidates)<=1\n        if idom_candidates:\n            idom = idom_candidates.pop()\n            node.immediate_dominator = idom\n            idom.dominator_successors.add(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_dominance_frontier(nodes):\n    '''\n        Naive implementation of Cooper, Harvey, Kennedy algo\n        See 'A Simple,Fast Dominance Algorithm'\n\n        Compute dominance frontier\n    '''\n    for node in nodes:\n        if len(node.fathers) >= 2:\n            for father in node.fathers:\n                runner = father\n                # Corner case: if there is a if without else\n                # we need to add update the conditional node \n                if runner == node.immediate_dominator and runner.type == NodeType.IF and node.type == NodeType.ENDIF:\n                    runner.dominance_frontier = runner.dominance_frontier.union({node})\n                while runner != node.immediate_dominator:\n                    runner.dominance_frontier = runner.dominance_frontier.union({node})\n                    runner = runner.immediate_dominator", "response": "Compute dominance frontier for a list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint out the output of the log file.", "response": "def output(self, _filename):\n        \"\"\"\n            _filename is not used\n            Args:\n                _filename(string)\n        \"\"\"\n\n        for contract in self.slither.contracts_derived:\n            txt = \"\\nContract %s\"%contract.name\n            table = PrettyTable([\"Function\",\n                                 \"require or assert\"])\n            for function in contract.functions:\n                require = function.all_slithir_operations()\n                require = [ir for ir in require if isinstance(ir, SolidityCall) and ir.function in require_or_assert]\n                require = [ir.node for ir in require]\n                table.add_row([function.name, self._convert([str(m.expression) for m in set(require)])])\n            txt += \"\\n\"+str(table)\n            self.info(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect which return values are unused in a call", "response": "def detect_unused_return_values(self, f):\n        \"\"\"\n            Return the nodes where the return value of a call is unused\n        Args:\n            f (Function)\n        Returns:\n            list(Node)\n        \"\"\"\n        values_returned = []\n        nodes_origin = {}\n        for n in f.nodes:\n            for ir in n.irs:\n                if isinstance(ir, HighLevelCall):\n                    # if a return value is stored in a state variable, it's ok\n                    if ir.lvalue and not isinstance(ir.lvalue, StateVariable):\n                        values_returned.append(ir.lvalue)\n                        nodes_origin[ir.lvalue] = ir\n                for read in ir.read:\n                    if read in values_returned:\n                        values_returned.remove(read)\n\n        return [nodes_origin[value].node for value in values_returned]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _detect(self):\n        results = []\n        for c in self.slither.contracts:\n            for f in c.functions + c.modifiers:\n                if f.contract != c:\n                    continue\n                unused_return = self.detect_unused_return_values(f)\n                if unused_return:\n                    info = \"{}.{} ({}) does not use the value returned by external calls:\\n\"\n                    info = info.format(f.contract.name,\n                                       f.name,\n                                       f.source_mapping_str)\n                    for node in unused_return:\n                        info += \"\\t-{} ({})\\n\".format(node.expression, node.source_mapping_str)\n\n                    json = self.generate_json_result(info)\n                    self.add_function_to_json(f, json)\n                    self.add_nodes_to_json(unused_return, json)\n                    results.append(json)\n\n        return results", "response": "Detect high level calls which return a value that are never used\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_complex_code(self, contract):\n\n        is_complex = self._is_complex_code(contract)\n\n        result = red('Yes') if is_complex else green('No')\n\n        return \"\\tComplex code? {}\\n\".format(result)", "response": "Check if the code is complex"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output(self, _filename):\n\n        txt = \"Analyze of {}\\n\".format(self.slither.filename)\n        txt += self.get_detectors_result()\n        for contract in self.slither.contracts_derived:\n            txt += \"\\nContract {}\\n\".format(contract.name)\n            txt += self.is_complex_code(contract)\n            is_erc20 = contract.is_erc20()\n            txt += '\\tNumber of functions:{}'.format(self._number_functions(contract))\n            txt += \"\\tIs ERC20 token: {}\\n\".format(contract.is_erc20())\n            if is_erc20:\n                txt += self.get_summary_erc20(contract)\n\n        self.info(txt)", "response": "Output the result of an analysis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_indirect_shadowing_information(contract):\n        # If this variable is an overshadowing variable, we'll want to return information describing it.\n        result = []\n        indirect_shadows = detect_c3_function_shadowing(contract)\n        if indirect_shadows:\n            for collision_set in sorted(indirect_shadows, key=lambda x: x[0][1].name):\n                winner = collision_set[-1][1].contract.name\n                collision_steps = [colliding_function.contract.name for _, colliding_function in collision_set]\n                collision_steps = ', '.join(collision_steps)\n                result.append(f\"'{collision_set[0][1].full_name}' collides in inherited contracts {collision_steps} where {winner} is chosen.\")\n        return '\\n'.join(result)", "response": "Return a string describing the indirect shadowing information for the given variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _summary(self, contract):\n        ret = ''\n\n        # Add arrows (number them if there is more than one path so we know order of declaration for inheritance).\n        if len(contract.immediate_inheritance) == 1:\n            ret += '%s -> %s;\\n' % (contract.name, contract.immediate_inheritance[0])\n        else:\n            for i in range(0, len(contract.immediate_inheritance)):\n                ret += '%s -> %s [ label=\"%s\" ];\\n' % (contract.name, contract.immediate_inheritance[i], i + 1)\n\n        # Functions\n        visibilities = ['public', 'external']\n        public_functions = [self._get_pattern_func(f, contract) for f in contract.functions if\n                            not f.is_constructor and f.contract == contract and f.visibility in visibilities]\n        public_functions = ''.join(public_functions)\n        private_functions = [self._get_pattern_func(f, contract) for f in contract.functions if\n                             not f.is_constructor and f.contract == contract and f.visibility not in visibilities]\n        private_functions = ''.join(private_functions)\n\n        # Modifiers\n        modifiers = [self._get_pattern_func(m, contract) for m in contract.modifiers if m.contract == contract]\n        modifiers = ''.join(modifiers)\n\n        # Public variables\n        public_variables = [self._get_pattern_var(v, contract) for v in contract.variables if\n                            v.contract == contract and v.visibility in visibilities]\n        public_variables = ''.join(public_variables)\n\n        private_variables = [self._get_pattern_var(v, contract) for v in contract.variables if\n                             v.contract == contract and v.visibility not in visibilities]\n        private_variables = ''.join(private_variables)\n\n        # Obtain any indirect shadowing information for this node.\n        indirect_shadowing_information = self._get_indirect_shadowing_information(contract)\n\n        # Build the node label\n        ret += '%s[shape=\"box\"' % contract.name\n        ret += 'label=< <TABLE border=\"0\">'\n        ret += '<TR><TD align=\"center\"><B>%s</B></TD></TR>' % contract.name\n        if public_functions:\n            ret += '<TR><TD align=\"left\"><I>Public Functions:</I></TD></TR>'\n            ret += '%s' % public_functions\n        if private_functions:\n            ret += '<TR><TD align=\"left\"><I>Private Functions:</I></TD></TR>'\n            ret += '%s' % private_functions\n        if modifiers:\n            ret += '<TR><TD align=\"left\"><I>Modifiers:</I></TD></TR>'\n            ret += '%s' % modifiers\n        if public_variables:\n            ret += '<TR><TD align=\"left\"><I>Public Variables:</I></TD></TR>'\n            ret += '%s' % public_variables\n        if private_variables:\n            ret += '<TR><TD align=\"left\"><I>Private Variables:</I></TD></TR>'\n            ret += '%s' % private_variables\n\n        if indirect_shadowing_information:\n            ret += '<TR><TD><BR/></TD></TR><TR><TD align=\"left\" border=\"1\"><font color=\"#777777\" point-size=\"10\">%s</font></TD></TR>' % indirect_shadowing_information.replace('\\n', '<BR/>')\n        ret += '</TABLE> >];\\n'\n\n        return ret", "response": "Builds summary using HTML"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output(self, filename):\n        if filename == '':\n            filename = 'contracts.dot'\n        if not filename.endswith('.dot'):\n            filename += \".dot\"\n        info = 'Inheritance Graph: ' + filename\n        self.info(info)\n        with open(filename, 'w', encoding='utf8') as f:\n            f.write('digraph \"\" {\\n')\n            for c in self.contracts:\n                f.write(self._summary(c))\n            f.write('}')", "response": "Output the inheritance graph in filename"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output(self, _filename):\n\n        txt = \"\"\n        for c in self.contracts:\n            (name, _inheritance, _var, func_summaries, _modif_summaries) = c.get_summary()\n            txt += blue(\"\\n+ Contract %s\\n\"%name)\n            # (c_name, f_name, visi, _, _, _, _, _) in func_summaries\n            public = [(elem[0], (elem[1], elem[2]) ) for elem in func_summaries]\n\n            collect = collections.defaultdict(list)\n            for a,b in public:\n                collect[a].append(b)\n            public = list(collect.items())\n\n            for contract, functions in public:\n                txt += blue(\"  - From {}\\n\".format(contract))\n                functions = sorted(functions)\n                for (function, visi) in functions:\n                    if visi in ['external', 'public']:\n                        txt += green(\"    - {} ({})\\n\".format(function, visi))\n                for (function, visi) in functions:\n                    if visi in ['internal', 'private']:\n                        txt += magenta(\"    - {} ({})\\n\".format(function, visi))\n                for (function, visi) in functions:\n                    if visi not in ['external', 'public', 'internal', 'private']:\n                        txt += \"    - {} \u00a0({})\\n\".format(function, visi)\n\n        self.info(txt)", "response": "Output the list of public and private functions of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the size in bits Return None if the size is not known", "response": "def size(self):\n        '''\n            Return the size in bits\n            Return None if the size is not known\n        Returns:\n            int\n        '''\n        t = self._type\n        if t.startswith('uint'):\n            return int(t[len('uint'):])\n        if t.startswith('int'):\n            return int(t[len('int'):])\n        if t == 'bool':\n            return int(8)\n        if t == 'address':\n            return int(160)\n        if t.startswith('bytes'):\n            return int(t[len('bytes'):])\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detect_builtin_shadowing_locals(self, function_or_modifier):\n\n        results = []\n        for local in function_or_modifier.variables:\n            if self.is_builtin_symbol(local.name):\n                results.append((self.SHADOWING_LOCAL_VARIABLE, local, function_or_modifier))\n        return results", "response": "Detects if local variables in a given function or modifier are named after built - in symbols."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_builtin_shadowing_definitions(self, contract):\n\n        result = []\n\n        # Loop through all functions, modifiers, variables (state and local) to detect any built-in symbol keywords.\n        for function in contract.functions:\n            if function.contract == contract:\n                if self.is_builtin_symbol(function.name):\n                    result.append((self.SHADOWING_FUNCTION, function, None))\n                result += self.detect_builtin_shadowing_locals(function)\n        for modifier in contract.modifiers:\n            if modifier.contract == contract:\n                if self.is_builtin_symbol(modifier.name):\n                    result.append((self.SHADOWING_MODIFIER, modifier, None))\n                result += self.detect_builtin_shadowing_locals(modifier)\n        for variable in contract.variables:\n            if variable.contract == contract:\n                if self.is_builtin_symbol(variable.name):\n                    result.append((self.SHADOWING_STATE_VARIABLE, variable, None))\n        for event in contract.events:\n            if event.contract == contract:\n                if self.is_builtin_symbol(event.name):\n                    result.append((self.SHADOWING_EVENT, event, None))\n\n        return result", "response": "Detects if functions modifiers events state variables or local variables are named after built - in symbols. Any such definitions are returned in a list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetecting shadowing of built - in symbols recursively visit the calls", "response": "def _detect(self):\n        \"\"\" Detect shadowing of built-in symbols\n\n        Recursively visit the calls\n        Returns:\n            list: {'vuln', 'filename,'contract','func', 'shadow'}\n\n        \"\"\"\n\n        results = []\n        for contract in self.contracts:\n            shadows = self.detect_builtin_shadowing_definitions(contract)\n            if shadows:\n                for shadow in shadows:\n                    # Obtain components\n                    shadow_type = shadow[0]\n                    shadow_object = shadow[1]\n                    local_variable_parent = shadow[2]\n\n                    # Build the path for our info string\n                    local_variable_path = contract.name + \".\"\n                    if local_variable_parent is not None:\n                        local_variable_path += local_variable_parent.name + \".\"\n                    local_variable_path += shadow_object.name\n\n                    info = '{} ({} @ {}) shadows built-in symbol \\\"{}\"\\n'.format(local_variable_path,\n                                                                                 shadow_type,\n                                                                                 shadow_object.source_mapping_str,\n                                                                                 shadow_object.name)\n\n                    # Generate relevant JSON data for this shadowing definition.\n                    json = self.generate_json_result(info)\n                    if shadow_type in [self.SHADOWING_FUNCTION, self.SHADOWING_MODIFIER, self.SHADOWING_EVENT]:\n                        self.add_function_to_json(shadow_object, json)\n                    elif shadow_type in [self.SHADOWING_STATE_VARIABLE, self.SHADOWING_LOCAL_VARIABLE]:\n                        self.add_variable_to_json(shadow_object, json)\n                    results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output(self, _filename):\n\n        txt = ''\n        for contract in self.slither.contracts_derived:\n            txt += '\\n{}:\\n'.format(contract.name)\n            table = PrettyTable(['Name', 'ID'])\n            for function in contract.functions:\n                if function.visibility in ['public', 'external']:\n                    table.add_row([function.full_name, hex(get_function_id(function.full_name))])\n            for variable in contract.state_variables:\n                if variable.visibility in ['public']:\n                    variable_getter_args = \"\"\n                    if type(variable.type) is ArrayType:\n                        length = 0\n                        v = variable\n                        while type(v.type) is ArrayType:\n                            length += 1\n                            v = v.type\n                        variable_getter_args = ','.join([\"uint256\"]*length)\n                    elif type(variable.type) is MappingType:\n                        variable_getter_args = variable.type.type_from\n\n                    table.add_row([f\"{variable.name}({variable_getter_args})\", hex(get_function_id(f\"{variable.name}({variable_getter_args})\"))])\n            txt += str(table) + '\\n'\n\n        self.info(txt)", "response": "Output the state of the object in a human readable format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef output(self, _filename):\n\n        for c in self.contracts:\n            (name, inheritance, var, func_summaries, modif_summaries) = c.get_summary()\n            txt = \"\\nContract %s\"%name\n            txt += '\\nContract vars: '+str(var)\n            txt += '\\nInheritance:: '+str(inheritance)\n            table = PrettyTable([\"Function\",\n                                 \"Visibility\",\n                                 \"Modifiers\",\n                                 \"Read\",\n                                 \"Write\",\n                                 \"Internal Calls\",\n                                 \"External Calls\"])\n            for (_c_name, f_name, visi, modifiers, read, write, internal_calls, external_calls) in func_summaries:\n                read = self._convert(read)\n                write = self._convert(write)\n                internal_calls = self._convert(internal_calls)\n                external_calls = self._convert(external_calls)\n                table.add_row([f_name, visi, modifiers, read, write, internal_calls, external_calls])\n            txt += \"\\n \\n\"+str(table)\n            table = PrettyTable([\"Modifiers\",\n                                 \"Visibility\",\n                                 \"Read\",\n                                 \"Write\",\n                                 \"Internal Calls\",\n                                 \"External Calls\"])\n            for (_c_name, f_name, visi, _, read, write, internal_calls, external_calls) in modif_summaries:\n                read = self._convert(read)\n                write = self._convert(write)\n                internal_calls = self._convert(internal_calls)\n                external_calls = self._convert(external_calls)\n                table.add_row([f_name, visi, read, write, internal_calls, external_calls])\n            txt += \"\\n\\n\"+str(table)\n            txt += \"\\n\"\n            self.info(txt)", "response": "Output the contracts and modif summaries."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the function id of the given signature", "response": "def get_function_id(sig):\n    ''''\n        Return the function id of the given signature\n    Args:\n        sig (str)\n    Return:\n        (int)\n    '''\n    s = sha3.keccak_256()\n    s.update(sig.encode('utf-8'))\n    return int(\"0x\" + s.hexdigest()[:8], 16)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noutputting the graph in filename", "response": "def output(self, filename):\n        \"\"\"\n            Output the graph in filename\n            Args:\n                filename(string)\n        \"\"\"\n\n        if not filename.endswith('.dot'):\n            filename += '.dot'\n        if filename == \".dot\":\n            filename = \"all_contracts.dot\"\n\n        with open(filename, 'w', encoding='utf8') as f:\n            self.info(f'Call Graph: {filename}')\n            f.write('\\n'.join(['strict digraph {'] + [self._process_functions(self.slither.functions)] +  ['}']))\n\n\n        for derived_contract in self.slither.contracts_derived:\n            with open(f'{derived_contract.name}.dot', 'w', encoding='utf8') as f:\n                self.info(f'Call Graph: {derived_contract.name}.dot')\n                f.write('\\n'.join(['strict digraph {'] + [self._process_functions(derived_contract.functions)] +  ['}']))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting out the information of the current state of the object.", "response": "def output(self, _filename):\n        \"\"\"\n            _filename is not used\n            Args:\n                _filename(string)\n        \"\"\"\n\n        txt = \"\"\n        for contract in self.contracts:\n            print('Contract {}'.format(contract.name))\n            for function in contract.functions:\n                if function.contract == contract:\n                    print('\\tFunction {}'.format(function.full_name))\n                    for node in function.nodes:\n                        if node.expression:\n                            print('\\t\\tExpression: {}'.format(node.expression))\n                            print('\\t\\tIRs:')\n                            for ir in node.irs:\n                                print('\\t\\t\\t{}'.format(ir))\n                        elif node.irs:\n                            print('\\t\\tIRs:')\n                            for ir in node.irs:\n                                print('\\t\\t\\t{}'.format(ir))\n            for modifier in contract.modifiers:\n                if modifier.contract == contract:\n                    print('\\tModifier {}'.format(modifier.full_name))\n                    for node in modifier.nodes:\n                        print(node)\n                        if node.expression:\n                            print('\\t\\tExpression: {}'.format(node.expression))\n                            print('\\t\\tIRs:')\n                            for ir in node.irs:\n                                print('\\t\\t\\t{}'.format(ir))\n        self.info(txt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetects and obtains functions which are shadowed via multiple inheritance by C3 linearization.", "response": "def detect_c3_function_shadowing(contract):\n    \"\"\"\n    Detects and obtains functions which are indirectly shadowed via multiple inheritance by C3 linearization\n    properties, despite not directly inheriting from each other.\n\n    :param contract: The contract to check for potential C3 linearization shadowing within.\n    :return: A list of list of tuples: (contract, function), where each inner list describes colliding functions.\n    The later elements in the inner list overshadow the earlier ones. The contract-function pair's function does not\n    need to be defined in its paired contract, it may have been inherited within it.\n    \"\"\"\n\n    # Loop through all contracts, and all underlying functions.\n    results = {}\n    for i in range(0, len(contract.immediate_inheritance) - 1):\n        inherited_contract1 = contract.immediate_inheritance[i]\n\n        for function1 in inherited_contract1.functions_and_modifiers:\n            # If this function has already be handled or is unimplemented, we skip it\n            if function1.full_name in results or function1.is_constructor or not function1.is_implemented:\n                continue\n\n            # Define our list of function instances which overshadow each other.\n            functions_matching = [(inherited_contract1, function1)]\n            already_processed = set([function1])\n\n            # Loop again through other contracts and functions to compare to.\n            for x in range(i + 1, len(contract.immediate_inheritance)):\n                inherited_contract2 = contract.immediate_inheritance[x]\n\n                # Loop for each function in this contract\n                for function2 in inherited_contract2.functions_and_modifiers:\n                    # Skip this function if it is the last function that was shadowed.\n                    if function2 in already_processed or function2.is_constructor or not function2.is_implemented:\n                        continue\n\n                    # If this function does have the same full name, it is shadowing through C3 linearization.\n                    if function1.full_name == function2.full_name:\n                        functions_matching.append((inherited_contract2, function2))\n                        already_processed.add(function2)\n\n            # If we have more than one definition matching the same signature, we add it to the results.\n            if len(functions_matching) > 1:\n                results[function1.full_name] = functions_matching\n\n    return list(results.values())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect and obtains functions which are shadowed immediately by the provided ancestor contract.", "response": "def detect_direct_function_shadowing(contract):\n    \"\"\"\n    Detects and obtains functions which are shadowed immediately by the provided ancestor contract.\n    :param contract: The ancestor contract which we check for function shadowing within.\n    :return: A list of tuples (overshadowing_function, overshadowed_immediate_base_contract, overshadowed_function)\n    -overshadowing_function is the function defined within the provided contract that overshadows another\n    definition.\n    -overshadowed_immediate_base_contract is the immediate inherited-from contract that provided the shadowed\n    function (could have provided it through inheritance, does not need to directly define it).\n    -overshadowed_function is the function definition which is overshadowed by the provided contract's definition.\n    \"\"\"\n    functions_declared = {function.full_name: function for function in contract.functions_and_modifiers_not_inherited}\n    results = {}\n    for base_contract in reversed(contract.immediate_inheritance):\n        for base_function in base_contract.functions_and_modifiers:\n\n            # We already found the most immediate shadowed definition for this function, skip to the next.\n            if base_function.full_name in results:\n                continue\n\n            # If this function is implemented and it collides with a definition in our immediate contract, we add\n            # it to our results.\n            if base_function.is_implemented and base_function.full_name in functions_declared:\n                results[base_function.full_name] = (functions_declared[base_function.full_name], base_contract, base_function)\n\n    return list(results.values())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_function_shadowing(contracts, direct_shadowing=True, indirect_shadowing=True):\n    results = set()\n    for contract in contracts:\n\n        # Detect immediate inheritance shadowing.\n        if direct_shadowing:\n            shadows = detect_direct_function_shadowing(contract)\n            for (overshadowing_function, overshadowed_base_contract, overshadowed_function) in shadows:\n                results.add((contract, contract, overshadowing_function, overshadowed_base_contract,\n                             overshadowed_function))\n\n        # Detect c3 linearization shadowing (multi inheritance shadowing).\n        if indirect_shadowing:\n            shadows = detect_c3_function_shadowing(contract)\n            for colliding_functions in shadows:\n                for x in range(0, len(colliding_functions) - 1):\n                    for y in range(x + 1, len(colliding_functions)):\n                        # The same function definition can appear more than once in the inheritance chain,\n                        # overshadowing items between, so it is important to remember to filter it out here.\n                        if colliding_functions[y][1].contract != colliding_functions[x][1].contract:\n                            results.add((contract, colliding_functions[y][0], colliding_functions[y][1],\n                                         colliding_functions[x][0], colliding_functions[x][1]))\n\n    return results", "response": "Detects all functions that are shadowed within a given contract."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetecting all overshadowing and overshadowed state variables in the provided contracts.", "response": "def detect_state_variable_shadowing(contracts):\n    \"\"\"\n    Detects all overshadowing and overshadowed state variables in the provided contracts.\n    :param contracts: The contracts to detect shadowing within.\n    :return: Returns a set of tuples (overshadowing_contract, overshadowing_state_var, overshadowed_contract,\n    overshadowed_state_var).\n    The contract-variable pair's variable does not need to be defined in its paired contract, it may have been\n    inherited. The contracts are simply included to denote the immediate inheritance path from which the shadowed\n    variable originates.\n    \"\"\"\n    results = set()\n    for contract in contracts:\n        variables_declared = {variable.name: variable for variable in contract.variables\n                              if variable.contract == contract}\n        for immediate_base_contract in contract.immediate_inheritance:\n            for variable in immediate_base_contract.variables:\n                if variable.name in variables_declared:\n                    results.add((contract, variables_declared[variable.name], immediate_base_contract, variable))\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _detect(self):\n        # Detect all version related pragmas and check if they are disallowed.\n        results = []\n        pragma = self.slither.pragma_directives\n        disallowed_pragmas = []\n        detected_version = False\n        for p in pragma:\n            # Skip any pragma directives which do not refer to version\n            if len(p.directive) < 1 or p.directive[0] != \"solidity\":\n                continue\n\n            # This is version, so we test if this is disallowed.\n            detected_version = True\n            reason = self._check_pragma(p.version)\n            if reason:\n                disallowed_pragmas.append((reason, p))\n\n        # If we found any disallowed pragmas, we output our findings.\n        if disallowed_pragmas:\n            info = \"Detected issues with version pragma in {}:\\n\".format(self.filename)\n            for (reason, p) in disallowed_pragmas:\n                info += \"\\t- {} ({}): {}\\n\".format(p, p.source_mapping_str, reason)\n\n            json = self.generate_json_result(info)\n\n            # follow the same format than add_nodes_to_json\n            json['elements'] = [{'type': 'expression',\n                                 'expression': p.version,\n                                 'source_mapping': p.source_mapping} for (reason, p) in disallowed_pragmas]\n            results.append(json)\n\n        return results", "response": "Detects pragmas that allow for outdated solc versions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _analyze_variable_attributes(self, attributes):\n\n        # Check for the indexed attribute\n        if 'indexed' in attributes:\n            self._indexed = attributes['indexed']\n\n        super(EventVariableSolc, self)._analyze_variable_attributes(attributes)", "response": "Analyze the event variable attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects dangerous timestamps for a given contract.", "response": "def detect_dangerous_timestamp(self, contract):\n        \"\"\"\n        Args:\n            contract (Contract)\n        Returns:\n            list((Function), (list (Node)))\n        \"\"\"\n        ret = []\n        for f in [f for f in contract.functions if f.contract == contract]:\n            nodes = self.timestamp(f)\n            if nodes:\n                ret.append((f, nodes))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning true if the variable is located in storage See https://solidity.readthedocs. io / en / v0. 4. 24. html?highlight = storage%20location#data - location - location", "response": "def is_storage(self):\n        \"\"\"\n            Return true if the variable is located in storage\n            See https://solidity.readthedocs.io/en/v0.4.24/types.html?highlight=storage%20location#data-location\n        Returns:\n            (bool)\n        \"\"\"\n        if self.location == 'memory':\n            return False\n        # Use by slithIR SSA\n        if self.location == 'reference_to_storage':\n            return False\n        if self.location == 'storage':\n            return True\n\n        if isinstance(self.type, (ArrayType, MappingType)):\n            return True\n\n        if isinstance(self.type, UserDefinedType):\n            return isinstance(self.type.type, Structure)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect uninitialized state variables recursively visit the calls", "response": "def _detect(self):\n        \"\"\" Detect uninitialized state variables\n\n        Recursively visit the calls\n        Returns:\n            dict: [contract name] = set(state variable uninitialized)\n        \"\"\"\n        results = []\n        for c in self.slither.contracts_derived:\n            ret = self.detect_uninitialized(c)\n            for variable, functions in ret:\n                info = \"{}.{} ({}) is never initialized. It is used in:\\n\"\n                info = info.format(variable.contract.name,\n                                   variable.name,\n                                   variable.source_mapping_str)\n                for f in functions:\n                    info += \"\\t- {} ({})\\n\".format(f.name, f.source_mapping_str)\n\n                source = [variable.source_mapping]\n                source += [f.source_mapping for f in functions]\n\n                json = self.generate_json_result(info)\n                self.add_variable_to_json(variable, json)\n                self.add_functions_to_json(functions, json)\n                results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting shadowing Recursively visit the calls", "response": "def _detect(self):\n        \"\"\" Detect shadowing\n\n        Recursively visit the calls\n        Returns:\n            list: {'vuln', 'filename,'contract','func', 'shadow'}\n\n        \"\"\"\n        results = []\n        for c in self.contracts:\n            shadowing = self.detect_shadowing(c)\n            if shadowing:\n                for all_variables in shadowing:\n                    shadow = all_variables[0]\n                    variables = all_variables[1:]\n                    info = '{}.{} ({}) shadows:\\n'.format(shadow.contract.name,\n                                                        shadow.name,\n                                                        shadow.source_mapping_str)\n                    for var in variables:\n                        info += \"\\t- {}.{} ({})\\n\".format(var.contract.name,\n                                                       var.name,\n                                                       var.source_mapping_str)\n\n                    json = self.generate_json_result(info)\n                    self.add_variables_to_json(all_variables, json)\n                    results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the function signature", "response": "def signature(self):\n        ''' Return the function signature\n        Returns:\n            (str, list(str)): name, list parameters type\n        '''\n        return self.name, [str(x.type) for x in self.elems]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detect_functions_called(contract):\n        result = []\n\n        # Obtain all functions reachable by this contract.\n        for func in contract.all_functions_called:\n            # Loop through all nodes in the function, add all calls to a list.\n            for node in func.nodes:\n                for ir in node.irs:\n                    if isinstance(ir, (InternalCall, SolidityCall)):\n                        result.append(ir.function)\n        return result", "response": "Returns a list of all InternallCall and SolidityCall functions made in a function\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a contract contains a dynamic call either in a direct definition or through inheritance.", "response": "def _contains_internal_dynamic_call(contract):\n        \"\"\"\n        Checks if a contract contains a dynamic call either in a direct definition, or through inheritance.\n\n        Returns:\n            (boolean): True if this contract contains a dynamic call (including through inheritance).\n        \"\"\"\n        for func in contract.all_functions_called:\n            for node in func.nodes:\n                for ir in node.irs:\n                    if isinstance(ir, (InternalDynamicCall)):\n                        return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the base - most function definition for the provided function.", "response": "def get_base_most_function(function):\n        \"\"\"\n        Obtains the base function definition for the provided function. This could be used to obtain the original\n        definition of a function, if the provided function is an override.\n\n        Returns:\n            (function): Returns the base-most function of a provided function. (The original definition).\n        \"\"\"\n        # Loop through the list of inherited contracts and this contract, to find the first function instance which\n        # matches this function's signature. Note here that `inheritance` is in order from most basic to most extended.\n        for contract in function.contract.inheritance + [function.contract]:\n\n            # Loop through the functions not inherited (explicitly defined in this contract).\n            for f in contract.functions_not_inherited:\n\n                # If it matches names, this is the base most function.\n                if f.full_name == function.full_name:\n                    return f\n\n        # Somehow we couldn't resolve it, which shouldn't happen, as the provided function should be found if we could\n        # not find some any more basic.\n        raise Exception(\"Could not resolve the base-most function for the provided function.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_function_definitions(base_most_function):\n        # We assume the provided function is the base-most function, so we check all derived contracts\n        # for a redefinition\n        return [base_most_function] + [function for derived_contract in base_most_function.contract.derived_contracts\n                                       for function in derived_contract.functions\n                                       if function.full_name == base_most_function.full_name]", "response": "Returns all function definitions given a base - most function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef output(self, _filename):\n\n        txt = ''\n        for c in self.contracts:\n            txt += \"\\nContract %s\\n\"%c.name\n            table = PrettyTable(['Variable', 'Dependencies'])\n            for v in c.state_variables:\n                table.add_row([v.name, _get(v, c)])\n\n            txt += str(table)\n\n            txt += \"\\n\"\n            for f in c.functions_and_modifiers_not_inherited:\n                txt += \"\\nFunction %s\\n\"%f.full_name\n                table = PrettyTable(['Variable', 'Dependencies'])\n                for v in f.variables:\n                    table.add_row([v.name, _get(v, f)])\n                for v in c.state_variables:\n                    table.add_row([v.canonical_name, _get(v, f)])\n                txt += str(table)\n            self.info(txt)", "response": "Output the state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detect_complex_func(func):\n        result = []\n        code_complexity = compute_cyclomatic_complexity(func)\n\n        if code_complexity > ComplexFunction.MAX_CYCLOMATIC_COMPLEXITY:\n            result.append({\n                \"func\": func,\n                \"cause\": ComplexFunction.CAUSE_CYCLOMATIC\n            })\n\n        \"\"\"Detect the number of external calls in the func\n           shouldn't be greater than 5\n        \"\"\"\n        count = 0\n        for node in func.nodes:\n            for ir in node.irs:\n                if isinstance(ir, (HighLevelCall, LowLevelCall, LibraryCall)):\n                    count += 1\n\n        if count > ComplexFunction.MAX_EXTERNAL_CALLS:\n            result.append({\n                \"func\": func,\n                \"cause\": ComplexFunction.CAUSE_EXTERNAL_CALL\n            })\n\n        \"\"\"Checks the number of the state variables written\n           shouldn't be greater than 10\n        \"\"\"\n        if len(func.state_variables_written) > ComplexFunction.MAX_STATE_VARIABLES:\n            result.append({\n                \"func\": func,\n                \"cause\": ComplexFunction.CAUSE_STATE_VARS\n            })\n\n        return result", "response": "Detects the cyclomatic complexity of the contract functions\n           shouldn t be greater than 7"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport the slithir_cfg file to a. dot file", "response": "def output(self, original_filename):\n        \"\"\"\n            _filename is not used\n            Args:\n                _filename(string)\n        \"\"\"\n\n        for contract in self.contracts:\n            for function in contract.functions + contract.modifiers:\n                filename = \"{}-{}-{}.dot\".format(original_filename, contract.name, function.full_name)\n                self.info('Export {}'.format(filename))\n                function.slithir_cfg_to_dot(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting unused state variables and return a list of json result", "response": "def _detect(self):\n        \"\"\" Detect unused state variables\n        \"\"\"\n        results = []\n        for c in self.slither.contracts_derived:\n            unusedVars = self.detect_unused(c)\n            if unusedVars:\n                info = ''\n                for var in unusedVars:\n                    info += \"{}.{} ({}) is never used in {}\\n\".format(var.contract.name,\n                                                                      var.name,\n                                                                      var.source_mapping_str,\n                                                                      c.name)\n\n\n                json = self.generate_json_result(info)\n                self.add_variables_to_json(unusedVars, json)\n                results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting uninitialized local variables and return a dictionary of the JSON representation of the local variables.", "response": "def _detect(self):\n        \"\"\" Detect uninitialized local variables\n\n        Recursively visit the calls\n        Returns:\n            dict: [contract name] = set(local variable uninitialized)\n        \"\"\"\n        results = []\n\n        self.results = []\n        self.visited_all_paths = {}\n\n        for contract in self.slither.contracts:\n            for function in contract.functions:\n                if function.is_implemented and function.contract == contract:\n                    if function.contains_assembly:\n                        continue\n                    # dont consider storage variable, as they are detected by another detector\n                    uninitialized_local_variables = [v for v in function.local_variables if not v.is_storage and v.uninitialized]\n                    function.entry_point.context[self.key] = uninitialized_local_variables\n                    self._detect_uninitialized(function, function.entry_point, [])\n        all_results = list(set(self.results))\n        for(function, uninitialized_local_variable) in all_results:\n            var_name = uninitialized_local_variable.name\n\n            info = \"{} in {}.{} ({}) is a local variable never initialiazed\\n\"\n            info = info.format(var_name,\n                               function.contract.name,\n                               function.name,\n                               uninitialized_local_variable.source_mapping_str)\n\n\n            json = self.generate_json_result(info)\n            self.add_variable_to_json(uninitialized_local_variable, json)\n            self.add_function_to_json(function, json)\n            results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects un - indexed ERC20 event parameters in a given contract.", "response": "def detect_erc20_unindexed_event_params(contract):\n        \"\"\"\n        Detect un-indexed ERC20 event parameters in a given contract.\n        :param contract: The contract to check ERC20 events for un-indexed parameters in.\n        :return: A list of tuple(event, parameter) of parameters which should be indexed.\n        \"\"\"\n        # Create our result array\n        results = []\n\n        # If this contract isn't an ERC20 token, we return our empty results.\n        if not contract.is_erc20():\n            return results\n\n        # Loop through all events to look for poor form.\n        for event in contract.events:\n\n            # Only handle events which are declared in this contract.\n            if event.contract != contract:\n                continue\n\n            # If this is transfer/approval events, expect the first two parameters to be indexed.\n            if event.full_name in [\"Transfer(address,address,uint256)\",\n                                   \"Approval(address,address,uint256)\"]:\n                if not event.elems[0].indexed:\n                    results.append((event, event.elems[0]))\n                if not event.elems[1].indexed:\n                    results.append((event, event.elems[1]))\n\n        # Return the results.\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects un - indexed ERC20 event parameters in all contracts.", "response": "def _detect(self):\n        \"\"\"\n        Detect un-indexed ERC20 event parameters in all contracts.\n        \"\"\"\n        results = []\n        for c in self.contracts:\n            unindexed_params = self.detect_erc20_unindexed_event_params(c)\n            if unindexed_params:\n                info = \"{} ({}) does not mark important ERC20 parameters as 'indexed':\\n\"\n                info = info.format(c.name, c.source_mapping_str)\n                for (event, parameter) in unindexed_params:\n                    info += \"\\t-{} ({}) does not index parameter '{}'\\n\".format(event.name, event.source_mapping_str, parameter.name)\n\n                # Add the events to the JSON (note: we do not add the params/vars as they have no source mapping).\n                json = self.generate_json_result(info)\n                self.add_functions_to_json([event for event, _ in unindexed_params], json)\n                results.append(json)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming slithIR vars to SSA", "response": "def transform_slithir_vars_to_ssa(function):\n    \"\"\"\n        Transform slithIR vars to SSA (TemporaryVariable, ReferenceVariable, TupleVariable)\n    \"\"\"\n    variables = []\n    for node in function.nodes:\n        for ir in node.irs_ssa:\n            if isinstance(ir, OperationWithLValue) and not ir.lvalue in variables:\n                variables += [ir.lvalue]\n\n    tmp_variables = [v for v in variables if isinstance(v, TemporaryVariable)]\n    for idx in range(len(tmp_variables)):\n        tmp_variables[idx].index = idx\n    ref_variables = [v for v in variables if isinstance(v, ReferenceVariable)]\n    for idx in range(len(ref_variables)):\n        ref_variables[idx].index = idx\n    tuple_variables = [v for v in variables if isinstance(v, TupleVariable)]\n    for idx in range(len(tuple_variables)):\n        tuple_variables[idx].index = idx"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the SSA version of the IR function to the internal structure.", "response": "def add_ssa_ir(function, all_state_variables_instances):\n    '''\n        Add SSA version of the IR\n    Args:\n        function\n        all_state_variables_instances\n    '''\n\n    if not function.is_implemented:\n        return\n\n    init_definition = dict()\n    for v in function.parameters:\n        if v.name:\n            init_definition[v.name] = (v, function.entry_point)\n            function.entry_point.add_ssa_ir(Phi(LocalIRVariable(v), set()))\n\n    for v in function.returns:\n        if v.name:\n            init_definition[v.name] = (v, function.entry_point)\n\n    # We only add phi function for state variable at entry node if\n    # The state variable is used\n    # And if the state variables is written in another function (otherwise its stay at index 0)\n    for (_, variable_instance) in all_state_variables_instances.items():\n        if is_used_later(function.entry_point, variable_instance):\n            # rvalues are fixed in solc_parsing.declaration.function\n            function.entry_point.add_ssa_ir(Phi(StateIRVariable(variable_instance), set()))\n\n    add_phi_origins(function.entry_point, init_definition, dict())\n\n\n    for node in function.nodes:\n        for (variable, nodes) in node.phi_origins_local_variables.values():\n            if len(nodes)<2:\n                continue\n            if not is_used_later(node, variable):\n                continue\n            node.add_ssa_ir(Phi(LocalIRVariable(variable), nodes))\n        for (variable, nodes) in node.phi_origins_state_variables.values():\n            if len(nodes)<2:\n                continue\n            #if not is_used_later(node, variable.name, []):\n            #    continue\n            node.add_ssa_ir(Phi(StateIRVariable(variable), nodes))\n\n    init_local_variables_instances = dict()\n    for v in function.parameters:\n        if v.name:\n            new_var = LocalIRVariable(v)\n            function.add_parameter_ssa(new_var)\n            if new_var.is_storage:\n                fake_variable = LocalIRVariable(v)\n                fake_variable.name = 'STORAGE_'+fake_variable.name\n                fake_variable.set_location('reference_to_storage')\n                new_var.refers_to = {fake_variable}\n                init_local_variables_instances[fake_variable.name] = fake_variable\n            init_local_variables_instances[v.name] = new_var\n\n    for v in function.returns:\n        if v.name:\n            new_var = LocalIRVariable(v)\n            function.add_return_ssa(new_var)\n            if new_var.is_storage:\n                fake_variable = LocalIRVariable(v)\n                fake_variable.name = 'STORAGE_'+fake_variable.name\n                fake_variable.set_location('reference_to_storage')\n                new_var.refers_to = {fake_variable}\n                init_local_variables_instances[fake_variable.name] = fake_variable\n            init_local_variables_instances[v.name] = new_var\n\n    all_init_local_variables_instances = dict(init_local_variables_instances)\n\n    init_state_variables_instances = dict(all_state_variables_instances)\n\n    initiate_all_local_variables_instances(function.nodes, init_local_variables_instances, all_init_local_variables_instances)\n\n    generate_ssa_irs(function.entry_point,\n                     dict(init_local_variables_instances),\n                     all_init_local_variables_instances,\n                     dict(init_state_variables_instances),\n                     all_state_variables_instances,\n                     init_local_variables_instances,\n                     [])\n\n    fix_phi_rvalues_and_storage_ref(function.entry_point,\n                                    dict(init_local_variables_instances),\n                                    all_init_local_variables_instances,\n                                    dict(init_state_variables_instances),\n                                    all_state_variables_instances,\n                                    init_local_variables_instances)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a copy of the given operation into a new version of the current version of the current version.", "response": "def copy_ir(ir, *instances):\n    '''\n    Args:\n        ir (Operation)\n        local_variables_instances(dict(str -> LocalVariable))\n        state_variables_instances(dict(str -> StateVariable))\n        temporary_variables_instances(dict(int -> Variable))\n        reference_variables_instances(dict(int -> Variable))\n\n    Note: temporary and reference can be indexed by int, as they dont need phi functions\n    '''\n    if isinstance(ir, Assignment):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        rvalue = get_variable(ir, lambda x: x.rvalue, *instances)\n        variable_return_type = ir.variable_return_type\n        return Assignment(lvalue, rvalue, variable_return_type)\n    elif isinstance(ir, Balance):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        value = get_variable(ir, lambda x: x.value, *instances)\n        return Balance(value, lvalue)\n    elif isinstance(ir, Binary):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        variable_left = get_variable(ir, lambda x: x.variable_left, *instances)\n        variable_right = get_variable(ir, lambda x: x.variable_right, *instances)\n        operation_type = ir.type\n        return Binary(lvalue, variable_left, variable_right, operation_type)\n    elif isinstance(ir, Condition):\n        val = get_variable(ir, lambda x: x.value, *instances)\n        return Condition(val)\n    elif isinstance(ir, Delete):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        variable = get_variable(ir, lambda x: x.variable, *instances)\n        return Delete(lvalue, variable)\n    elif isinstance(ir, EventCall):\n        name = ir.name\n        return EventCall(name)\n    elif isinstance(ir, HighLevelCall): # include LibraryCall\n        destination = get_variable(ir, lambda x: x.destination, *instances)\n        function_name = ir.function_name\n        nbr_arguments = ir.nbr_arguments\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        type_call = ir.type_call\n        if isinstance(ir, LibraryCall):\n            new_ir = LibraryCall(destination, function_name, nbr_arguments, lvalue, type_call)\n        else:\n            new_ir = HighLevelCall(destination, function_name, nbr_arguments, lvalue, type_call)\n        new_ir.call_id = ir.call_id\n        new_ir.call_value = get_variable(ir, lambda x: x.call_value, *instances)\n        new_ir.call_gas = get_variable(ir, lambda x: x.call_gas, *instances)\n        new_ir.arguments = get_arguments(ir, *instances)\n        new_ir.function = ir.function\n        return new_ir\n    elif isinstance(ir, Index):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        variable_left = get_variable(ir, lambda x: x.variable_left, *instances)\n        variable_right = get_variable(ir, lambda x: x.variable_right, *instances)\n        index_type = ir.index_type\n        return Index(lvalue, variable_left, variable_right, index_type)\n    elif isinstance(ir, InitArray):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        init_values = get_rec_values(ir, lambda x: x.init_values, *instances)\n        return InitArray(init_values, lvalue)\n    elif isinstance(ir, InternalCall):\n        function = ir.function\n        nbr_arguments = ir.nbr_arguments\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        type_call = ir.type_call\n        new_ir = InternalCall(function, function.contract, nbr_arguments, lvalue, type_call)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, InternalDynamicCall):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        function = get_variable(ir, lambda x: x.function, *instances)\n        function_type = ir.function_type\n        new_ir = InternalDynamicCall(lvalue, function, function_type)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, LowLevelCall):\n        destination = get_variable(ir, lambda x: x.destination, *instances)\n        function_name = ir.function_name\n        nbr_arguments = ir.nbr_arguments\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        type_call = ir.type_call\n        new_ir = LowLevelCall(destination, function_name, nbr_arguments, lvalue, type_call)\n        new_ir.call_id = ir.call_id\n        new_ir.call_value = get_variable(ir, lambda x: x.call_value, *instances)\n        new_ir.call_gas = get_variable(ir, lambda x: x.call_gas, *instances)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, Member):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        variable_left = get_variable(ir, lambda x: x.variable_left, *instances)\n        variable_right = get_variable(ir, lambda x: x.variable_right, *instances)\n        return Member(variable_left, variable_right, lvalue)\n    elif isinstance(ir, NewArray):\n        depth = ir.depth\n        array_type = ir.array_type\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        new_ir = NewArray(depth, array_type, lvalue)\n        new_ir.arguments = get_rec_values(ir, lambda x: x.arguments, *instances)\n        return new_ir\n    elif isinstance(ir, NewElementaryType):\n        new_type = ir.type\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        new_ir = NewElementaryType(new_type, lvalue)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, NewContract):\n        contract_name = ir.contract_name\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        new_ir = NewContract(contract_name, lvalue)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, NewStructure):\n        structure = ir.structure\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        new_ir = NewStructure(structure, lvalue)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, Push):\n        array = get_variable(ir, lambda x: x.array, *instances)\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        return Push(array, lvalue)\n    elif isinstance(ir, Return):\n        values = get_rec_values(ir, lambda x: x.values, *instances)\n        return Return(values)\n    elif isinstance(ir, Send):\n        destination = get_variable(ir, lambda x: x.destination, *instances)\n        value = get_variable(ir, lambda x: x.call_value, *instances)\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        return Send(destination, value, lvalue)\n    elif isinstance(ir, SolidityCall):\n        function = ir.function\n        nbr_arguments = ir.nbr_arguments\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        type_call = ir.type_call\n        new_ir = SolidityCall(function, nbr_arguments, lvalue, type_call)\n        new_ir.arguments = get_arguments(ir, *instances)\n        return new_ir\n    elif isinstance(ir, Transfer):\n        destination = get_variable(ir, lambda x: x.destination, *instances)\n        value = get_variable(ir, lambda x: x.call_value, *instances)\n        return Transfer(destination, value)\n    elif isinstance(ir, TypeConversion):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        variable = get_variable(ir, lambda x: x.variable, *instances)\n        variable_type = ir.type\n        return TypeConversion(lvalue, variable, variable_type)\n    elif isinstance(ir, Unary):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        rvalue = get_variable(ir, lambda x: x.rvalue, *instances)\n        operation_type = ir.type\n        return Unary(lvalue, rvalue, operation_type)\n    elif isinstance(ir, Unpack):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        tuple_var = get_variable(ir, lambda x: x.tuple, *instances)\n        idx = ir.index\n        return Unpack(lvalue, tuple_var, idx)\n    elif isinstance(ir, Length):\n        lvalue = get_variable(ir, lambda x: x.lvalue, *instances)\n        value = get_variable(ir, lambda x: x.value, *instances)\n        return Length(value, lvalue)\n\n\n    logger.error('Impossible ir copy on {} ({})'.format(ir, type(ir)))\n    exit(-1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_function_definitions(function):\n    return [function] + [f for c in function.contract.inheritance\n                         for f in c.functions_and_modifiers_not_inherited\n                         if f.full_name == function.full_name]", "response": "Returns a list of representing this function and any base definitions that are not inherited from the provided function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind all target paths that can be called by the target functions.", "response": "def find_target_paths(target_functions):\n    \"\"\"\n    Obtains all functions which can lead to any of the target functions being called.\n    :param target_functions: The functions we are interested in reaching.\n    :return: Returns a list of all functions which can reach any of the target_functions.\n    \"\"\"\n    # Create our results list\n    results = set()\n\n    # Loop for each target function\n    for target_function in target_functions:\n        results = results.union(__find_target_paths(target_function))\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects arbitrary send Args: contract (Contract) Returns: list((Function), (list (Node)))", "response": "def detect_arbitrary_send(self, contract):\n        \"\"\"\n            Detect arbitrary send\n        Args:\n            contract (Contract)\n        Returns:\n            list((Function), (list (Node)))\n        \"\"\"\n        ret = []\n        for f in [f for f in contract.functions if f.contract == contract]:\n            nodes = self.arbitrary_send(f)\n            if nodes:\n                ret.append((f, nodes))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving a function instance given a contract name and function name.", "response": "def resolve_function(slither, contract_name, function_name):\n    \"\"\"\n    Resolves a function instance, given a contract name and function.\n    :param contract_name: The name of the contract the function is declared in.\n    :param function_name: The name of the function to resolve.\n    :return: Returns the resolved function, raises an exception otherwise.\n    \"\"\"\n    # Obtain the target contract\n    contract = slither.get_contract_from_name(contract_name)\n\n    # Verify the contract was resolved successfully\n    if contract is None:\n        raise ResolveFunctionException(f\"Could not resolve target contract: {contract_name}\")\n\n    # Obtain the target function\n    target_function = next((function for function in contract.functions if function.name == function_name), None)\n\n    # Verify we have resolved the function specified.\n    if target_function is None:\n        raise ResolveFunctionException(f\"Could not resolve target function: {contract_name}.{function_name}\")\n\n    # Add the resolved function to the new list.\n    return target_function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_functions(slither, functions):\n    # Create the resolved list.\n    resolved = []\n\n    # Verify that the provided argument is a list.\n    if not isinstance(functions, list):\n        raise ResolveFunctionException(\"Provided functions to resolve must be a list type.\")\n\n    # Loop for each item in the list.\n    for item in functions:\n        if isinstance(item, str):\n            # If the item is a single string, we assume it is of form 'ContractName.FunctionName'.\n            parts = item.split('.')\n            if len(parts) < 2:\n                raise ResolveFunctionException(\"Provided string descriptor must be of form 'ContractName.FunctionName'\")\n            resolved.append(resolve_function(slither, parts[0], parts[1]))\n        elif isinstance(item, tuple):\n            # If the item is a tuple, it should be a 2-tuple providing contract and function names.\n            if len(item) != 2:\n                raise ResolveFunctionException(\"Provided tuple descriptor must provide a contract and function name.\")\n            resolved.append(resolve_function(slither, item[0], item[1]))\n        else:\n            raise ResolveFunctionException(f\"Unexpected function descriptor type to resolve in list: {type(item)}\")\n\n    # Return the resolved list.\n    return resolved", "response": "Resolves the provided function descriptors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contracts_derived(self):\n        inheritance = (x.inheritance for x in self.contracts)\n        inheritance = [item for sublist in inheritance for item in sublist]\n        return [c for c in self._contracts.values() if c not in inheritance]", "response": "list of contracts that are derived and not inherited"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a contract from a name", "response": "def get_contract_from_name(self, contract_name):\n        \"\"\"\n            Return a contract from a name\n        Args:\n            contract_name (str): name of the contract\n        Returns:\n            Contract\n        \"\"\"\n        return next((c for c in self.contracts if c.name == contract_name), None)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_functions(self, d):\n        for c in self.contracts:\n            for f in c.functions:\n                f.cfg_to_dot(os.path.join(d, '{}.{}.dot'.format(c.name, f.name)))", "response": "Export all the functions to dot files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the result is valid for this run.", "response": "def valid_result(self, r):\n        '''\n            Check if the result is valid\n            A result is invalid if:\n                - All its source paths belong to the source path filtered\n                - Or a similar result was reported and saved during a previous run\n        '''\n        source_mapping_elements = [elem['source_mapping']['filename_absolute'] for elem in r['elements'] if 'source_mapping' in elem]\n        if r['elements'] and all((any(path in src_mapping for path in self._paths_to_filter) for src_mapping in source_mapping_elements)):\n            return False\n        return not r['description'] in [pr['description'] for pr in self._previous_results]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output(self, filename):\n        info = 'Inheritance\\n'\n\n        if not self.contracts:\n            return\n\n        info += blue('Child_Contract -> ') + green('Immediate_Base_Contracts')\n        info += green(' [Not_Immediate_Base_Contracts]')\n        for child in self.contracts:\n            info += blue(f'\\n+ {child.name}')\n            if child.inheritance:\n                immediate = child.immediate_inheritance\n                not_immediate = [i for i in child.inheritance if i not in immediate]\n                info += ' -> ' + green(\", \".join(map(str, immediate)))\n                if not_immediate:\n                    info += \", [\"+ green(\", \".join(map(str, not_immediate))) + \"]\"\n\n        info += green('\\n\\nBase_Contract -> ') + blue('Immediate_Child_Contracts')\n        info += blue(' [Not_Immediate_Child_Contracts]')\n        for base in self.contracts:\n            info += green(f'\\n+ {base.name}')\n            children = list(self._get_child_contracts(base))\n            if children:\n                immediate = [child for child in children if base in child.immediate_inheritance]\n                not_immediate = [child for child in children if not child in immediate]\n                info += ' -> ' + blue(\", \".join(map(str, immediate)))\n                if not_immediate:\n                    info += ', [' + blue(\", \".join(map(str, not_immediate))) + ']'\n        self.info(info)", "response": "Output the inheritance relation of the base and child contracts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the variable is dependent on the source.", "response": "def is_dependent(variable, source, context, only_unprotected=False):\n    '''\n    Args:\n        variable (Variable)\n        source (Variable)\n        context (Contract|Function)\n        only_unprotected (bool): True only unprotected function are considered\n    Returns:\n        bool\n    '''\n    assert isinstance(context, (Contract, Function))\n    if isinstance(variable, Constant):\n        return False\n    if variable == source:\n        return True\n    context = context.context\n\n    if only_unprotected:\n        return variable in context[KEY_NON_SSA_UNPROTECTED] and source in context[KEY_NON_SSA_UNPROTECTED][variable]\n    return variable in context[KEY_NON_SSA] and source in context[KEY_NON_SSA][variable]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the variable is dependent on the source.", "response": "def is_dependent_ssa(variable, source, context, only_unprotected=False):\n    '''\n    Args:\n        variable (Variable)\n        taint (Variable)\n        context (Contract|Function)\n        only_unprotected (bool): True only unprotected function are considered\n    Returns:\n        bool\n    '''\n    assert isinstance(context, (Contract, Function))\n    context = context.context\n    if isinstance(variable, Constant):\n        return False\n    if variable == source:\n        return True\n    if only_unprotected:\n        return variable in context[KEY_SSA_UNPROTECTED] and source in context[KEY_SSA_UNPROTECTED][variable]\n    return variable in context[KEY_SSA] and source in context[KEY_SSA][variable]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_tainted(variable, context, only_unprotected=False, ignore_generic_taint=False):\n    '''\n        Args:\n        variable\n        context (Contract|Function)\n        only_unprotected (bool): True only unprotected function are considered\n    Returns:\n        bool\n    '''\n    assert isinstance(context, (Contract, Function))\n    assert isinstance(only_unprotected, bool)\n    if isinstance(variable, Constant):\n        return False\n    slither = context.slither\n    taints = slither.context[KEY_INPUT]\n    if not ignore_generic_taint:\n        taints |= GENERIC_TAINT\n    return variable in taints or any(is_dependent(variable, t, context, only_unprotected) for t in taints)", "response": "Returns True if the variable is tainted by the context."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the variable is tainted by the context.", "response": "def is_tainted_ssa(variable, context, only_unprotected=False, ignore_generic_taint=False):\n    '''\n    Args:\n        variable\n        context (Contract|Function)\n        only_unprotected (bool): True only unprotected function are considered\n    Returns:\n        bool\n    '''\n    assert isinstance(context, (Contract, Function))\n    assert isinstance(only_unprotected, bool)\n    if isinstance(variable, Constant):\n        return False\n    slither = context.slither\n    taints = slither.context[KEY_INPUT_SSA]\n    if not ignore_generic_taint:\n        taints |= GENERIC_TAINT\n    return variable in taints or any(is_dependent_ssa(variable, t, context, only_unprotected) for t in taints)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dependencies(variable, context, only_unprotected=False):\n    '''\n    Args:\n        variable\n        context (Contract|Function)\n        only_unprotected (bool): True only unprotected function are considered\n    Returns:\n        list(Variable)\n    '''\n    assert isinstance(context, (Contract, Function))\n    assert isinstance(only_unprotected, bool)\n    if only_unprotected:\n        return context.context[KEY_NON_SSA].get(variable, [])\n    return context.context[KEY_NON_SSA_UNPROTECTED].get(variable, [])", "response": "Returns the list of dependencies of the given variable in the given context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _detect(self):\n        results = []\n\n        self.results = []\n        self.visited_all_paths = {}\n\n        for contract in self.slither.contracts:\n            for function in contract.functions:\n                if function.is_implemented:\n                    uninitialized_storage_variables = [v for v in function.local_variables if v.is_storage and v.uninitialized]\n                    function.entry_point.context[self.key] = uninitialized_storage_variables\n                    self._detect_uninitialized(function, function.entry_point, [])\n\n        for(function, uninitialized_storage_variable) in self.results:\n            var_name = uninitialized_storage_variable.name\n\n            info = \"{} in {}.{} ({}) is a storage variable never initialiazed\\n\"\n            info = info.format(var_name, function.contract.name, function.name, uninitialized_storage_variable.source_mapping_str)\n\n\n            json = self.generate_json_result(info)\n            self.add_variable_to_json(uninitialized_storage_variable, json)\n            self.add_function_to_json(function, json)\n            results.append(json)\n\n        return results", "response": "Detect uninitialized storage variables and return a dictionary of the JSON representation of the uninitialized storage variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting if the node can be called by the callback", "response": "def _can_callback(self, irs):\n        \"\"\"\n            Detect if the node contains a call that can\n            be used to re-entrance\n\n            Consider as valid target:\n            - low level call\n            - high level call\n\n            Do not consider Send/Transfer as there is not enough gas\n        \"\"\"\n        for ir in irs:\n            if isinstance(ir, LowLevelCall):\n                return True\n            if isinstance(ir, HighLevelCall) and not isinstance(ir, LibraryCall):\n                # If solidity >0.5, STATICCALL is used\n                if self.slither.solc_version and self.slither.solc_version.startswith('0.5.'):\n                    if isinstance(ir.function, Function) and (ir.function.view or ir.function.pure):\n                        continue\n                    if isinstance(ir.function, Variable):\n                        continue\n                # If there is a call to itself\n                # We can check that the function called is\n                # reentrancy-safe\n                if ir.destination == SolidityVariable('this'):\n                    if isinstance(ir.function, Variable):\n                        continue\n                    if not ir.function.all_high_level_calls():\n                        if not ir.function.all_low_level_calls():\n                            continue\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _can_send_eth(irs):\n        for ir in irs:\n            if isinstance(ir, (HighLevelCall, LowLevelCall, Transfer, Send)):\n                if ir.call_value:\n                    return True\n        return False", "response": "Detect if the node can send eth"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters out the if statement.", "response": "def _filter_if(self, node):\n        \"\"\"\n            Check if the node is a condtional node where\n            there is an external call checked\n            Heuristic:\n                - The call is a IF node\n                - It contains a, external call\n                - The condition is the negation (!)\n\n            This will work only on naive implementation\n        \"\"\"\n        return isinstance(node.expression, UnaryOperation)\\\n            and node.expression.type == UnaryOperationType.BANG"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexplore the CFG and look for re-entrancy Heuristic: There is a re-entrancy if a state variable is written after an external call node.context will contains the external calls executed It contains the calls executed in father nodes if node.context is not empty, and variables are written, a re-entrancy is possible", "response": "def _explore(self, node, visited, skip_father=None):\n        \"\"\"\n            Explore the CFG and look for re-entrancy\n            Heuristic: There is a re-entrancy if a state variable is written\n                        after an external call\n\n            node.context will contains the external calls executed\n            It contains the calls executed in father nodes\n\n            if node.context is not empty, and variables are written, a re-entrancy is possible\n        \"\"\"\n        if node in visited:\n            return\n\n        visited = visited + [node]\n\n        # First we add the external calls executed in previous nodes\n        # send_eth returns the list of calls sending value\n        # calls returns the list of calls that can callback\n        # read returns the variable read\n        # read_prior_calls returns the variable read prior a call\n        fathers_context = {'send_eth':set(), 'calls':set(), 'read':set(), 'read_prior_calls':{}}\n\n        for father in node.fathers:\n            if self.KEY in father.context:\n                fathers_context['send_eth'] |= set([s for s in father.context[self.KEY]['send_eth'] if s!=skip_father])\n                fathers_context['calls'] |= set([c for c in father.context[self.KEY]['calls'] if c!=skip_father])\n                fathers_context['read'] |= set(father.context[self.KEY]['read'])\n                fathers_context['read_prior_calls'] = union_dict(fathers_context['read_prior_calls'], father.context[self.KEY]['read_prior_calls'])\n\n        # Exclude path that dont bring further information\n        if node in self.visited_all_paths:\n            if all(call in self.visited_all_paths[node]['calls'] for call in fathers_context['calls']):\n                if all(send in self.visited_all_paths[node]['send_eth'] for send in fathers_context['send_eth']):\n                    if all(read in self.visited_all_paths[node]['read'] for read in fathers_context['read']):\n                        if dict_are_equal(self.visited_all_paths[node]['read_prior_calls'], fathers_context['read_prior_calls']):\n                            return\n        else:\n            self.visited_all_paths[node] = {'send_eth':set(), 'calls':set(), 'read':set(), 'read_prior_calls':{}}\n\n        self.visited_all_paths[node]['send_eth'] = set(self.visited_all_paths[node]['send_eth'] | fathers_context['send_eth'])\n        self.visited_all_paths[node]['calls'] = set(self.visited_all_paths[node]['calls'] | fathers_context['calls'])\n        self.visited_all_paths[node]['read'] = set(self.visited_all_paths[node]['read'] | fathers_context['read'])\n        self.visited_all_paths[node]['read_prior_calls'] = union_dict(self.visited_all_paths[node]['read_prior_calls'], fathers_context['read_prior_calls'])\n\n        node.context[self.KEY] = fathers_context\n\n        state_vars_read = set(node.state_variables_read)\n\n        # All the state variables written\n        state_vars_written = set(node.state_variables_written)\n        slithir_operations = []\n        # Add the state variables written in internal calls\n        for internal_call in node.internal_calls:\n            # Filter to Function, as internal_call can be a solidity call\n            if isinstance(internal_call, Function):\n                state_vars_written |= set(internal_call.all_state_variables_written())\n                state_vars_read |= set(internal_call.all_state_variables_read())\n                slithir_operations += internal_call.all_slithir_operations()\n\n        contains_call = False\n        node.context[self.KEY]['written'] = set(state_vars_written)\n        if self._can_callback(node.irs + slithir_operations):\n            node.context[self.KEY]['calls'] = set(node.context[self.KEY]['calls'] | {node})\n            node.context[self.KEY]['read_prior_calls'][node] = set(node.context[self.KEY]['read_prior_calls'].get(node, set()) | node.context[self.KEY]['read'] |state_vars_read)\n            contains_call = True\n        if self._can_send_eth(node.irs + slithir_operations):\n            node.context[self.KEY]['send_eth'] = set(node.context[self.KEY]['send_eth'] | {node})\n\n        node.context[self.KEY]['read'] = set(node.context[self.KEY]['read'] | state_vars_read)\n\n        sons = node.sons\n        if contains_call and node.type in [NodeType.IF, NodeType.IFLOOP]:\n            if self._filter_if(node):\n                son = sons[0]\n                self._explore(son, visited, node)\n                sons = sons[1:]\n            else:\n                son = sons[1]\n                self._explore(son, visited, node)\n                sons = [sons[0]]\n\n\n        for son in sons:\n            self._explore(son, visited)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the block and return the node.", "response": "def _parse_block(self, block, node):\n        '''\n        Return:\n            Node\n        '''\n        assert block[self.get_key()] == 'Block'\n\n        if self.is_compact_ast:\n            statements = block['statements']\n        else:\n            statements = block[self.get_children('children')]\n\n        for statement in statements:\n            node = self._parse_statement(statement, node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_alone_endif(self):\n        prev_nodes = []\n        while set(prev_nodes) != set(self.nodes):\n            prev_nodes = self.nodes\n            to_remove = []\n            for node in self.nodes:\n                if node.type == NodeType.ENDIF and not node.fathers:\n                    for son in node.sons:\n                        son.remove_father(node)\n                    node.set_sons([])\n                    to_remove.append(node)\n            self._nodes = [n for n in self.nodes if not n in to_remove]", "response": "Remove the ENDIF node that is not part of a Father."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints out the contents of the log file.", "response": "def output(self, _filename):\n        \"\"\"\n            _filename is not used\n            Args:\n                _filename(string)\n        \"\"\"\n\n        for contract in self.contracts:\n            txt = \"\\nContract %s\\n\"%contract.name\n            table = PrettyTable([\"Function\", \"State variables written\", \"Conditions on msg.sender\"])\n            for function in contract.functions:\n\n                state_variables_written = [v.name for v in function.all_state_variables_written()]\n                msg_sender_condition = self.get_msg_sender_checks(function)\n                table.add_row([function.name, str(state_variables_written), str(msg_sender_condition)])\n            self.info(txt + str(table))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the node is an IF node", "response": "def contains_if(self, include_loop=True):\n        \"\"\"\n            Check if the node is a IF node\n        Returns:\n            bool: True if the node is a conditional node (IF or IFLOOP)\n        \"\"\"\n        if include_loop:\n            return self.type in [NodeType.IF, NodeType.IFLOOP]\n        return self.type == NodeType.IF"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the node is a conditional node", "response": "def is_conditional(self, include_loop=True):\n        \"\"\"\n            Check if the node is a conditional node\n            A conditional node is either a IF or a require/assert or a RETURN bool\n        Returns:\n            bool: True if the node is a conditional node\n        \"\"\"\n        if self.contains_if(include_loop) or self.contains_require_or_assert():\n            return True\n        if self.irs:\n            last_ir = self.irs[-1]\n            if last_ir:\n                if isinstance(last_ir, Return):\n                    for r in last_ir.read:\n                        if r.type == ElementaryType('bool'):\n                            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the father node from the list. Do nothing if the father node is not a father node.", "response": "def remove_father(self, father):\n        \"\"\" Remove the father node. Do nothing if the node is not a father\n\n        Args:\n            fathers: list of fathers to add\n        \"\"\"\n        self._fathers = [x for x in self._fathers if x.node_id != father.node_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the son node from the list of fathers. Do nothing if the node is not a son node. Do nothing if the node is a son node. Do nothing if the node is a son node.", "response": "def remove_son(self, son):\n        \"\"\" Remove the son node. Do nothing if the node is not a son\n\n        Args:\n            fathers: list of fathers to add\n        \"\"\"\n        self._sons = [x for x in self._sons if x.node_id != son.node_id]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting if an expression makes use of any deprecated standards.", "response": "def detect_deprecation_in_expression(self, expression):\n        \"\"\" Detects if an expression makes use of any deprecated standards.\n\n        Returns:\n            list of tuple: (detecting_signature, original_text, recommended_text)\"\"\"\n        # Perform analysis on this expression\n        export = ExportValues(expression)\n        export_values = export.result()\n\n        # Define our results list\n        results = []\n\n        # Check if there is usage of any deprecated solidity variables or functions\n        for dep_var in self.DEPRECATED_SOLIDITY_VARIABLE:\n            if SolidityVariableComposed(dep_var[0]) in export_values:\n                results.append(dep_var)\n        for dep_func in self.DEPRECATED_SOLIDITY_FUNCTIONS:\n            if SolidityFunction(dep_func[0]) in export_values:\n                results.append(dep_func)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect if a node makes use of any deprecated standards.", "response": "def detect_deprecated_references_in_node(self, node):\n        \"\"\" Detects if a node makes use of any deprecated standards.\n\n        Returns:\n            list of tuple: (detecting_signature, original_text, recommended_text)\"\"\"\n        # Define our results list\n        results = []\n\n        # If this node has an expression, we check the underlying expression.\n        if node.expression:\n            results += self.detect_deprecation_in_expression(node.expression)\n\n        # Check if there is usage of any deprecated solidity variables or functions\n        for dep_node in self.DEPRECATED_NODE_TYPES:\n            if node.type == dep_node[0]:\n                results.append(dep_node)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_deprecated_references_in_contract(self, contract):\n        results = []\n\n        for state_variable in contract.variables:\n            if state_variable.contract != contract:\n                continue\n            if state_variable.expression:\n                deprecated_results = self.detect_deprecation_in_expression(state_variable.expression)\n                if deprecated_results:\n                    results.append((state_variable, deprecated_results))\n\n        # Loop through all functions + modifiers in this contract.\n        for function in contract.functions + contract.modifiers:\n            # We should only look for functions declared directly in this contract (not in a base contract).\n            if function.contract != contract:\n                continue\n\n            # Loop through each node in this function.\n            for node in function.nodes:\n                # Detect deprecated references in the node.\n                deprecated_results = self.detect_deprecated_references_in_node(node)\n\n                # Detect additional deprecated low-level-calls.\n                for ir in node.irs:\n                    if isinstance(ir, LowLevelCall):\n                        for dep_llc in self.DEPRECATED_LOW_LEVEL_CALLS:\n                            if ir.function_name == dep_llc[0]:\n                                deprecated_results.append(dep_llc)\n\n                # If we have any results from this iteration, add them to our results list.\n                if deprecated_results:\n                    results.append((node, deprecated_results))\n\n        return results", "response": "Detects usage of any deprecated built - in symbols in a contract."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _detect(self):\n        results = []\n        for contract in self.contracts:\n            deprecated_references = self.detect_deprecated_references_in_contract(contract)\n            if deprecated_references:\n                for deprecated_reference in deprecated_references:\n                    source_object = deprecated_reference[0]\n                    deprecated_entries = deprecated_reference[1]\n                    info = 'Deprecated standard detected @ {}:\\n'.format(source_object.source_mapping_str)\n\n                    for (dep_id, original_desc, recommended_disc) in deprecated_entries:\n                        info += \"\\t- Usage of \\\"{}\\\" should be replaced with \\\"{}\\\"\\n\".format(original_desc,\n                                                                                              recommended_disc)\n\n\n                    # Generate relevant JSON data for this deprecated standard.\n                    json = self.generate_json_result(info)\n                    if isinstance(source_object, StateVariableSolc) or isinstance(source_object, StateVariable):\n                        self.add_variable_to_json(source_object, json)\n                    else:\n                        self.add_nodes_to_json([source_object], json)\n\n                    results.append(json)\n\n        return results", "response": "Detects if an expression makes use of any deprecated standards."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_detectors_and_printers():\n\n    detectors = [getattr(all_detectors, name) for name in dir(all_detectors)]\n    detectors = [d for d in detectors if inspect.isclass(d) and issubclass(d, AbstractDetector)]\n\n    printers = [getattr(all_printers, name) for name in dir(all_printers)]\n    printers = [p for p in printers if inspect.isclass(p) and issubclass(p, AbstractPrinter)]\n\n    # Handle plugins!\n    for entry_point in iter_entry_points(group='slither_analyzer.plugin', name=None):\n        make_plugin = entry_point.load()\n\n        plugin_detectors, plugin_printers = make_plugin()\n\n        if not all(issubclass(d, AbstractDetector) for d in plugin_detectors):\n            raise Exception('Error when loading plugin %s, %r is not a detector' % (entry_point, d))\n\n        if not all(issubclass(p, AbstractPrinter) for p in plugin_printers):\n            raise Exception('Error when loading plugin %s, %r is not a printer' % (entry_point, p))\n\n        # We convert those to lists in case someone returns a tuple\n        detectors += list(plugin_detectors)\n        printers += list(plugin_printers)\n\n    return detectors, printers", "response": "Get all detectors and printers from all_detectors and all_printers attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main_impl(all_detector_classes, all_printer_classes):\n    args = parse_args(all_detector_classes, all_printer_classes)\n\n    # Set colorization option\n    set_colorization_enabled(not args.disable_color)\n\n    printer_classes = choose_printers(args, all_printer_classes)\n    detector_classes = choose_detectors(args, all_detector_classes)\n\n    default_log = logging.INFO if not args.debug else logging.DEBUG\n\n    for (l_name, l_level) in [('Slither', default_log),\n                              ('Contract', default_log),\n                              ('Function', default_log),\n                              ('Node', default_log),\n                              ('Parsing', default_log),\n                              ('Detectors', default_log),\n                              ('FunctionSolc', default_log),\n                              ('ExpressionParsing', default_log),\n                              ('TypeParsing', default_log),\n                              ('SSA_Conversion', default_log),\n                              ('Printers', default_log),\n                              #('CryticCompile', default_log)\n                              ]:\n        l = logging.getLogger(l_name)\n        l.setLevel(l_level)\n\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n\n    console_handler.setFormatter(FormatterCryticCompile())\n\n    crytic_compile_error = logging.getLogger(('CryticCompile'))\n    crytic_compile_error.addHandler(console_handler)\n    crytic_compile_error.propagate = False\n    crytic_compile_error.setLevel(logging.INFO)\n\n    try:\n        filename = args.filename\n\n        globbed_filenames = glob.glob(filename, recursive=True)\n\n        if os.path.isfile(filename) or is_supported(filename):\n            (results, number_contracts) = process(filename, args, detector_classes, printer_classes)\n\n        elif os.path.isdir(filename) or len(globbed_filenames) > 0:\n            extension = \"*.sol\" if not args.solc_ast else \"*.json\"\n            filenames = glob.glob(os.path.join(filename, extension))\n            if not filenames:\n                filenames = globbed_filenames\n            number_contracts = 0\n            results = []\n            if args.splitted and args.solc_ast:\n                (results, number_contracts) = process_files(filenames, args, detector_classes, printer_classes)\n            else:\n                for filename in filenames:\n                    (results_tmp, number_contracts_tmp) = process(filename, args, detector_classes, printer_classes)\n                    number_contracts += number_contracts_tmp\n                    results += results_tmp\n\n        else:\n            raise Exception(\"Unrecognised file/dir path: '#{filename}'\".format(filename=filename))\n\n        if args.json:\n            output_json(results, args.json)\n        if args.checklist:\n            output_results_to_markdown(results)\n        # Dont print the number of result for printers\n        if number_contracts == 0:\n            logger.warn(red('No contract was analyzed'))\n        if printer_classes:\n            logger.info('%s analyzed (%d contracts)', filename, number_contracts)\n        else:\n            logger.info('%s analyzed (%d contracts), %d result(s) found', filename, number_contracts, len(results))\n        if args.ignore_return_value:\n            return\n        exit(results)\n\n    except Exception:\n        logging.error('Error in %s' % args.filename)\n        logging.error(traceback.format_exc())\n        sys.exit(-1)", "response": "Main function for the crytic compile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _detect(self):\n        results = []\n        for c in self.contracts:\n            for f in c.functions:\n                if f.contract != c:\n                    continue\n                if f.view or f.pure:\n                    if f.contains_assembly:\n                        attr = 'view' if f.view else 'pure'\n                        info = '{}.{} ({}) is declared {} but contains assembly code\\n'\n                        info = info.format(f.contract.name, f.name, f.source_mapping_str, attr)\n                        json = self.generate_json_result(info)\n                        self.add_function_to_json(f, json)\n                        json['elements'].append({'type': 'info',\n                                                 'contains_assembly' : True})\n                        results.append(json)\n\n                    variables_written = f.all_state_variables_written()\n                    if variables_written:\n                        attr = 'view' if f.view else 'pure'\n                        info = '{}.{} ({}) is declared {} but changes state variables:\\n'\n                        info = info.format(f.contract.name, f.name, f.source_mapping_str, attr)\n                        for variable_written in variables_written:\n                            info += '\\t- {}.{}\\n'.format(variable_written.contract.name,\n                                                         variable_written.name)\n\n\n                        json = self.generate_json_result(info)\n                        self.add_function_to_json(f, json)\n                        self.add_variables_to_json(variables_written, json)\n                        json['elements'].append({'type': 'info',\n                                                  'contains_assembly' : False})\n                        results.append(json)\n\n        return results", "response": "Detect the constant function changing the state\nResourceException"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_number_edges(function):\n    n = 0\n    for node in function.nodes:\n        n += len(node.sons)\n    return n", "response": "Compute the number of edges of a CFG"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_strongly_connected_components(function):\n    visited = {n:False for n in function.nodes}\n    assigned = {n:False for n in function.nodes}\n    components = []\n    l = []\n\n    def visit(node):\n        if not visited[node]:\n            visited[node] = True\n            for son in node.sons:\n                visit(son)\n            l.append(node)\n\n    for n in function.nodes:\n        visit(n)\n\n    def assign(node, root):\n        if not assigned[node]:\n            assigned[node] = True\n            root.append(node)\n            for father in node.fathers:\n                assign(father, root)\n\n    for n in l:\n        component = []\n        assign(n, component)\n        if component:\n            components.append(component)\n\n    return components", "response": "Compute strongly connected components based on Kosaraju s algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_cyclomatic_complexity(function):\n    # from https://en.wikipedia.org/wiki/Cyclomatic_complexity\n    # M = E - N + 2P\n    # where M is the complexity\n    # E number of edges\n    # N number of nodes\n    # P number of connected components\n\n    E = compute_number_edges(function)\n    N = len(function.nodes)\n    P = len(compute_strongly_connected_components(function))\n    return E - N + 2 * P", "response": "Compute the cyclomatic complexity of a function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints out the state of the items in the log file.", "response": "def output(self, _filename):\n        \"\"\"\n            _filename is not used\n            Args:\n                _filename(string)\n        \"\"\"\n\n        txt = ''\n        for contract in self.slither.contracts_derived:\n            txt += '\\n{}:\\n'.format(contract.name)\n            table = PrettyTable(['Name', 'Type'])\n            for variable in contract.state_variables:\n                if not variable.is_constant:\n                    table.add_row([variable.name, str(variable.type)])\n            txt += str(table) + '\\n'\n\n        self.info(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the parameters signature without the return statetement", "response": "def parameters_signature(self):\n        '''\n            Return the parameters signature(without the return statetement)\n        '''\n        # Use x.type\n        # x.name may be empty\n        params = \",\".join([str(x.type) for x in self._params])\n        return '({})'.format(params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slithir_variables(self):\n        '''\n            List all of the slithir variables (non SSA)\n        '''\n        slithir_variables = [f.slithir_variables for f in self.functions + self.modifiers]\n        slithir_variables = [item for sublist in slithir_variables for item in sublist]\n        return list(set(slithir_variables))", "response": "List all of the slithir variables in the system"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the immediate constructor of the c3 linearization.", "response": "def constructor(self):\n        '''\n            Return the contract's immediate constructor.\n            If there is no immediate constructor, returns the first constructor\n            executed, following the c3 linearization\n            Return None if there is no constructor.\n        '''\n        cst = self.constructor_not_inherited\n        if cst:\n            return cst\n        for inherited_contract in self.inheritance:\n            cst = inherited_contract.constructor_not_inherited\n            if cst:\n                return cst\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of contracts derived from self", "response": "def derived_contracts(self):\n        '''\n            list(Contract): Return the list of contracts derived from self\n        '''\n        candidates = self.slither.contracts\n        return [c for c in candidates if self in c.inheritance]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_functions_reading_from_variable(self, variable):\n        '''\n            Return the functions reading the variable\n        '''\n        return [f for f in self.functions if f.is_reading(variable)]", "response": "Return the functions reading the variable\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the functions writting the variable", "response": "def get_functions_writing_to_variable(self, variable):\n        '''\n            Return the functions writting the variable\n        '''\n        return [f for f in self.functions if f.is_writing(variable)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_source_var_declaration(self, var):\n        return next((x.source_mapping for x in self.variables if x.name == var))", "response": "Returns the source mapping where the variable is declared\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_source_event_declaration(self, event):\n        return next((x.source_mapping for x in self.events if x.name == event))", "response": "Returns the source mapping where the event is declared\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_function_from_signature(self, function_signature):\n        return next((f for f in self.functions if f.full_name == function_signature), None)", "response": "Returns a function from a signature"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_modifier_from_signature(self, modifier_signature):\n        return next((m for m in self.modifiers if m.full_name == modifier_signature), None)", "response": "Returns a modifier from a signature"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_state_variable_from_name(self, variable_name):\n        return next((v for v in self.state_variables if v.name == variable_name), None)", "response": "Returns a state variable from a name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a structure from a name", "response": "def get_structure_from_name(self, structure_name):\n        \"\"\"\n            Return a structure from a name\n        Args:\n            structure_name (str): name of the structure\n        Returns:\n            Structure\n        \"\"\"\n        return next((st for st in self.structures if st.name == structure_name), None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a structure from a canonical name", "response": "def get_structure_from_canonical_name(self, structure_name):\n        \"\"\"\n            Return a structure from a canonical name\n        Args:\n            structure_name (str): canonical name of the structure\n        Returns:\n            Structure\n        \"\"\"\n        return next((st for st in self.structures if st.canonical_name == structure_name), None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an event from a name", "response": "def get_event_from_name(self, event_name):\n        \"\"\"\n            Return an event from a name\n        Args:\n            event_name (str): name of the event\n        Returns:\n            Event\n        \"\"\"\n        return next((e for e in self.events if e.name == event_name), None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_enum_from_name(self, enum_name):\n        return next((e for e in self.enums if e.name == enum_name), None)", "response": "Returns an enum from a name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_enum_from_canonical_name(self, enum_name):\n        return next((e for e in self.enums if e.canonical_name == enum_name), None)", "response": "Returns an enum from a canonical name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of functions overriden by the function", "response": "def get_functions_overridden_by(self, function):\n        '''\n            Return the list of functions overriden by the function\n        Args:\n            (core.Function)\n        Returns:\n            list(core.Function)\n\n        '''\n        candidates = [c.functions_not_inherited for c in self.inheritance]\n        candidates = [candidate for sublist in candidates for candidate in sublist]\n        return [f for f in candidates if f.full_name == function.full_name]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_functions_called(self):\n        '''\n            list(Function): List of functions reachable from the contract (include super)\n        '''\n        all_calls = [f.all_internal_calls() for f in self.functions + self.modifiers] + [self.functions + self.modifiers]\n        all_calls = [item for sublist in all_calls for item in sublist] + self.functions\n        all_calls = list(set(all_calls))\n\n        all_constructors = [c.constructor for c in self.inheritance]\n        all_constructors = list(set([c for c in all_constructors if c]))\n\n        all_calls = set(all_calls+all_constructors)\n\n        return [c for c in all_calls if isinstance(c, Function)]", "response": "Returns a list of all functions called by the contract"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_state_variables_written(self):\n        '''\n            list(StateVariable): List all of the state variables written\n        '''\n        all_state_variables_written = [f.all_state_variables_written() for f in self.functions + self.modifiers]\n        all_state_variables_written = [item for sublist in all_state_variables_written for item in sublist]\n        return list(set(all_state_variables_written))", "response": "List all of the state variables written by this class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_state_variables_read(self):\n        '''\n            list(StateVariable): List all of the state variables read\n        '''\n        all_state_variables_read = [f.all_state_variables_read() for f in self.functions + self.modifiers]\n        all_state_variables_read = [item for sublist in all_state_variables_read for item in sublist]\n        return list(set(all_state_variables_read))", "response": "List all of the state variables read by this class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_summary(self):\n        func_summaries = [f.get_summary() for f in self.functions]\n        modif_summaries = [f.get_summary() for f in self.modifiers]\n        return (self.name, [str(x) for x in self.inheritance], [str(x) for x in self.variables], func_summaries, modif_summaries)", "response": "Return the function summary"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the contract is an erc20 token", "response": "def is_erc20(self):\n        \"\"\"\n            Check if the contract is an erc20 token\n\n            Note: it does not check for correct return values\n        Returns:\n            bool\n        \"\"\"\n        full_names = [f.full_name for f in self.functions]\n        return 'transfer(address,uint256)' in full_names and\\\n               'transferFrom(address,address,uint256)' in full_names and\\\n               'approve(address,uint256)' in full_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_line(source_code, start, length):\n        total_length = len(source_code)\n        source_code = source_code.splitlines(True)\n        counter = 0\n        i = 0\n        lines = []\n        starting_column = None\n        ending_column = None\n        while counter < total_length:\n            # Determine the length of the line, and advance the line number\n            lineLength = len(source_code[i])\n            i = i + 1\n\n            # Determine our column numbers.\n            if starting_column is None and counter + lineLength > start:\n                starting_column = (start - counter) + 1\n            if starting_column is not None and ending_column is None and counter + lineLength > start + length:\n                ending_column = ((start + length) - counter) + 1\n\n            # Advance the current position counter, and determine line numbers.\n            counter += lineLength\n            if counter > start:\n                lines.append(i)\n\n            # If our advanced position for the next line is out of range, stop.\n            if counter > start + length:\n                break\n\n        return (lines, starting_column, ending_column)", "response": "Compute line numbers starting and ending columns from a start and length."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a text offset to a real offset", "response": "def _convert_source_mapping(offset, slither):\n        '''\n        Convert a text offset to a real offset\n        see https://solidity.readthedocs.io/en/develop/miscellaneous.html#source-mappings\n        Returns:\n            (dict): {'start':0, 'length':0, 'filename': 'file.sol'}\n        '''\n        sourceUnits = slither.source_units\n\n        position = re.findall('([0-9]*):([0-9]*):([-]?[0-9]*)', offset)\n        if len(position) != 1:\n            return {}\n\n        s, l, f = position[0]\n        s = int(s)\n        l = int(l)\n        f = int(f)\n\n        if f not in sourceUnits:\n            return {'start':s, 'length':l}\n        filename_used = sourceUnits[f]\n        filename_absolute = None\n        filename_relative = None\n        filename_short = None\n\n        lines = []\n\n        # If possible, convert the filename to its absolute/relative version\n        if slither.crytic_compile:\n            filenames = slither.crytic_compile.filename_lookup(filename_used)\n            filename_absolute = filenames.absolute\n            filename_relative = filenames.relative\n            filename_short = filenames.short\n\n            if filename_absolute in slither.source_code:\n                filename = filename_absolute\n            elif filename_relative in slither.source_code:\n                filename = filename_relative\n            elif filename_short in slither.source_code:\n                filename = filename_short\n            else:#\n                filename = filename_used.used\n        else:\n            filename = filename_used\n\n        if filename in slither.source_code:\n            source_code = slither.source_code[filename]\n            (lines, starting_column, ending_column) = SourceMapping._compute_line(source_code,\n                                                                                  s,\n                                                                                  l)\n        else:\n            (lines, starting_column, ending_column) = ([], None, None)\n\n\n        return {'start':s,\n                'length':l,\n                'filename_used': filename_used,\n                'filename_relative': filename_relative,\n                'filename_absolute': filename_absolute,\n                'filename_short': filename_short,\n                'lines' : lines,\n                'starting_column': starting_column,\n                'ending_column': ending_column\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of potential signature", "response": "def get_sig(ir, name):\n    '''\n        Return a list of potential signature\n        It is a list, as Constant variables can be converted to int256\n    Args:\n        ir (slithIR.operation)\n    Returns:\n        list(str)\n    '''\n    sig = '{}({})'\n\n    # list of list of arguments\n    argss = convert_arguments(ir.arguments)\n    return [sig.format(name, ','.join(args)) for args in argss]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nintegrate value and gas temporary arguments to call instruction", "response": "def integrate_value_gas(result):\n    '''\n        Integrate value and gas temporary arguments to call instruction\n    '''\n    was_changed = True\n\n    calls = []\n\n    while was_changed:\n        # We loop until we do not find any call to value or gas\n        was_changed = False\n\n        # Find all the assignments\n        assigments = {}\n        for i in result:\n            if isinstance(i, OperationWithLValue):\n                assigments[i.lvalue.name] = i\n            if isinstance(i, TmpCall):\n                if isinstance(i.called, Variable) and i.called.name in assigments:\n                    ins_ori = assigments[i.called.name]\n                    i.set_ori(ins_ori)\n\n        to_remove = []\n        variable_to_replace = {}\n\n        # Replace call to value, gas to an argument of the real call\n        for idx in range(len(result)):\n            ins = result[idx]\n            # value can be shadowed, so we check that the prev ins\n            # is an Argument\n            if is_value(ins) and isinstance(result[idx-1], Argument):\n                was_changed = True\n                result[idx-1].set_type(ArgumentType.VALUE)\n                result[idx-1].call_id = ins.ori.variable_left.name\n                calls.append(ins.ori.variable_left)\n                to_remove.append(ins)\n                variable_to_replace[ins.lvalue.name] = ins.ori.variable_left\n            elif is_gas(ins) and isinstance(result[idx-1], Argument):\n                was_changed = True\n                result[idx-1].set_type(ArgumentType.GAS)\n                result[idx-1].call_id = ins.ori.variable_left.name\n                calls.append(ins.ori.variable_left)\n                to_remove.append(ins)\n                variable_to_replace[ins.lvalue.name] = ins.ori.variable_left\n\n        # Remove the call to value/gas instruction\n        result = [i for i in result if not i in to_remove]\n\n        # update the real call \n        for ins in result:\n            if isinstance(ins, TmpCall):\n                # use of while if there redirections\n                while ins.called.name in variable_to_replace:\n                    was_changed = True\n                    ins.call_id = variable_to_replace[ins.called.name].name\n                    calls.append(ins.called)\n                    ins.called = variable_to_replace[ins.called.name]\n            if isinstance(ins, Argument):\n                while ins.call_id in variable_to_replace:\n                    was_changed = True\n                    ins.call_id = variable_to_replace[ins.call_id].name\n\n    calls = list(set([str(c) for c in calls]))\n    idx = 0\n    calls_d = {}\n    for call in calls:\n        calls_d[str(call)] = idx\n        idx = idx+1\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npropagates the types variables and convert tmp call to real call operation", "response": "def propagate_type_and_convert_call(result, node):\n    '''\n        Propagate the types variables and convert tmp call to real call operation\n    '''\n    calls_value = {}\n    calls_gas = {}\n\n    call_data = []\n\n    idx = 0\n    # use of while len() as result can be modified during the iteration\n    while idx < len(result):\n        ins = result[idx]\n\n        if isinstance(ins, TmpCall):\n            new_ins = extract_tmp_call(ins, node.function.contract)\n            if new_ins:\n                new_ins.set_node(ins.node)\n                ins = new_ins\n                result[idx] = ins\n\n        if isinstance(ins, Argument):\n            if ins.get_type() in [ArgumentType.GAS]:\n                assert not ins.call_id in calls_gas\n                calls_gas[ins.call_id] = ins.argument\n            elif ins.get_type() in [ArgumentType.VALUE]:\n                assert not ins.call_id in calls_value\n                calls_value[ins.call_id] = ins.argument\n            else:\n                assert ins.get_type() == ArgumentType.CALL\n                call_data.append(ins.argument)\n\n        if isinstance(ins, (HighLevelCall, NewContract, InternalDynamicCall)):\n            if ins.call_id in calls_value:\n                ins.call_value = calls_value[ins.call_id]\n            if ins.call_id in calls_gas:\n                ins.call_gas = calls_gas[ins.call_id]\n\n        if isinstance(ins, (Call, NewContract, NewStructure)):\n            ins.arguments = call_data\n            call_data = []\n\n        if is_temporary(ins):\n            del result[idx]\n            continue\n\n        new_ins = propagate_types(ins, node)\n        if new_ins:\n            if isinstance(new_ins, (list,)):\n                if len(new_ins) == 2:\n                    new_ins[0].set_node(ins.node)\n                    new_ins[1].set_node(ins.node)\n                    del result[idx]\n                    result.insert(idx, new_ins[0])\n                    result.insert(idx+1, new_ins[1])\n                    idx = idx + 1\n                else:\n                    assert len(new_ins) == 3\n                    new_ins[0].set_node(ins.node)\n                    new_ins[1].set_node(ins.node)\n                    new_ins[2].set_node(ins.node)\n                    del result[idx]\n                    result.insert(idx, new_ins[0])\n                    result.insert(idx+1, new_ins[1])\n                    result.insert(idx+2, new_ins[2])\n                    idx = idx + 2\n            else:\n                new_ins.set_node(ins.node)\n                result[idx] = new_ins\n        idx = idx +1\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_to_low_level(ir):\n    if ir.function_name == 'transfer':\n        assert len(ir.arguments) == 1\n        ir = Transfer(ir.destination, ir.arguments[0])\n        return ir\n    elif ir.function_name == 'send':\n        assert len(ir.arguments) == 1\n        ir = Send(ir.destination, ir.arguments[0], ir.lvalue)\n        ir.lvalue.set_type(ElementaryType('bool'))\n        return ir\n    elif ir.destination.name ==  'abi' and ir.function_name in ['encode',\n                                                                'encodePacked',\n                                                                'encodeWithSelector',\n                                                                'encodeWithSignature',\n                                                                'decode']:\n\n        call = SolidityFunction('abi.{}()'.format(ir.function_name))\n        new_ir = SolidityCall(call, ir.nbr_arguments, ir.lvalue, ir.type_call)\n        new_ir.arguments = ir.arguments\n        if isinstance(call.return_type, list) and len(call.return_type) == 1:\n            new_ir.lvalue.set_type(call.return_type[0])\n        else:\n            new_ir.lvalue.set_type(call.return_type)\n        return new_ir\n    elif ir.function_name in ['call',\n                              'delegatecall',\n                              'callcode',\n                              'staticcall']:\n        new_ir = LowLevelCall(ir.destination,\n                          ir.function_name,\n                          ir.nbr_arguments,\n                          ir.lvalue,\n                          ir.type_call)\n        new_ir.call_gas = ir.call_gas\n        new_ir.call_value = ir.call_value\n        new_ir.arguments = ir.arguments\n        new_ir.lvalue.set_type(ElementaryType('bool'))\n        return new_ir\n    logger.error('Incorrect conversion to low level {}'.format(ir))\n    exit(-1)", "response": "Convert a single IR to a transfer send or low level call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a call to a PUSH operaitonIR", "response": "def convert_to_push(ir, node):\n    \"\"\"\n    Convert a call to a PUSH operaiton\n\n    The funciton assume to receive a correct IR\n    The checks must be done by the caller\n\n    May necessitate to create an intermediate operation (InitArray)\n    Necessitate to return the lenght (see push documentation)\n    As a result, the function return may return a list\n    \"\"\"\n\n\n    lvalue = ir.lvalue\n    if isinstance(ir.arguments[0], list):\n        ret = []\n\n        val = TemporaryVariable(node)\n        operation = InitArray(ir.arguments[0], val)\n        ret.append(operation)\n\n        ir = Push(ir.destination, val)\n\n        length = Literal(len(operation.init_values))\n        t = operation.init_values[0].type\n        ir.lvalue.set_type(ArrayType(t, length))\n\n        ret.append(ir)\n\n        if lvalue:\n            length = Length(ir.array, lvalue)\n            length.lvalue.points_to = ir.lvalue\n            ret.append(length)\n\n        return ret\n\n    ir = Push(ir.destination, ir.arguments[0])\n\n    if lvalue:\n        ret = []\n        ret.append(ir)\n\n        length = Length(ir.array, lvalue)\n        length.lvalue.points_to = ir.lvalue\n        ret.append(length)\n        return ret\n\n    return ir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a type to a str", "response": "def get_type(t):\n    \"\"\"\n        Convert a type to a str\n        If the instance is a Contract, return 'address' instead\n    \"\"\"\n    if isinstance(t, UserDefinedType):\n        if isinstance(t.type, Contract):\n            return 'address'\n    return str(t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_references_origin(irs):\n    for ir in irs:\n        if isinstance(ir, (Index, Member)):\n            ir.lvalue.points_to = ir.variable_left", "response": "Find all references origin of the given irs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_ir_heuristics(irs, node):\n\n    irs = integrate_value_gas(irs)\n\n    irs = propagate_type_and_convert_call(irs, node)\n    irs = remove_unused(irs)\n    find_references_origin(irs)\n\n\n    return irs", "response": "Apply a set of heuristic to improve slithIR\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nanalyze the variable attributes.", "response": "def _analyze_variable_attributes(self, attributes):\n        ''''\n            Variable Location\n            Can be storage/memory or default\n        '''\n        if 'storageLocation' in attributes:\n            location = attributes['storageLocation']\n            self._location = location\n        else:\n            if 'memory' in attributes['type']:\n                self._location = 'memory'\n            elif'storage' in attributes['type']:\n                self._location = 'storage'\n            else:\n                self._location = 'default'\n\n        super(LocalVariableSolc, self)._analyze_variable_attributes(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_windows_virtual_terminal_sequences():\n\n    try:\n        from ctypes import windll, byref\n        from ctypes.wintypes import DWORD, HANDLE\n\n        kernel32 = windll.kernel32\n        virtual_terminal_flag = 0x04  # ENABLE_VIRTUAL_TERMINAL_PROCESSING\n\n        # Obtain our stdout/stderr handles.\n        # Reference: https://docs.microsoft.com/en-us/windows/console/getstdhandle\n        handle_stdout = kernel32.GetStdHandle(-11)\n        handle_stderr = kernel32.GetStdHandle(-12)\n\n        # Loop for each stdout/stderr handle.\n        for current_handle in [handle_stdout, handle_stderr]:\n\n            # If we get a null handle, or fail any subsequent calls in this scope, we do not colorize any output.\n            if current_handle is None or current_handle == HANDLE(-1):\n                return False\n\n            # Try to obtain the current flags for the console.\n            current_mode = DWORD()\n            if not kernel32.GetConsoleMode(current_handle, byref(current_mode)):\n                return False\n\n            # If the virtual terminal sequence processing is not yet enabled, we enable it.\n            if (current_mode.value & virtual_terminal_flag) == 0:\n                if not kernel32.SetConsoleMode(current_handle, current_mode.value | virtual_terminal_flag):\n                    return False\n    except:\n        # Any generic failure (possibly from calling these methods on older Windows builds where they do not exist)\n        # will fall back onto disabling colorization.\n        return False\n\n    return True", "response": "Sets the appropriate flags to enable virtual terminal sequences in a Windows command prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the enabled state of output colorization.", "response": "def set_colorization_enabled(enabled):\n    \"\"\"\n    Sets the enabled state of output colorization.\n    :param enabled: Boolean indicating whether output should be colorized.\n    :return: None\n    \"\"\"\n    # If color is supposed to be enabled and this is windows, we have to enable console virtual terminal sequences:\n    if enabled and platform.system() == 'Windows':\n        Colors.COLORIZATION_ENABLED = enable_windows_virtual_terminal_sequences()\n    else:\n        # This is not windows so we can enable color immediately.\n        Colors.COLORIZATION_ENABLED = enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the full name of the function signature without the return values", "response": "def full_name(self):\n        \"\"\"\n            str: func_name(type1,type2)\n            Return the function signature without the return values\n        \"\"\"\n        name, parameters, _ = self.signature\n        return name+'('+','.join(parameters)+')'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef return_type(self):\n        returns = self.returns\n        if returns:\n            return [r.type for r in returns]\n        return None", "response": "Return the list of return type of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef local_variables(self):\n        return list(set(self.variables) - set(self.returns) - set(self.parameters))", "response": "Return all local variables that are not in the current state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expressions(self):\n        if self._expressions is None:\n            expressions = [n.expression for n in self.nodes]\n            expressions = [e for e in expressions if e]\n            self._expressions = expressions\n        return self._expressions", "response": "Returns a list of the expressions that are associated with this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of the return values of the current node.", "response": "def return_values(self):\n        \"\"\"\n            list(Return Values): List of the return values\n        \"\"\"\n        from slither.core.cfg.node import NodeType\n        from slither.slithir.operations import Return\n        from slither.slithir.variables import Constant\n\n        if self._return_values is None:\n            return_values = list()\n            returns = [n for n in self.nodes if n.type == NodeType.RETURN]\n            [return_values.extend(ir.values) for node in returns for ir in node.irs if isinstance(ir, Return)]\n            self._return_values = list(set([x for x in return_values if not isinstance(x, Constant)]))\n        return self._return_values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of the return values in SSA form", "response": "def return_values_ssa(self):\n        \"\"\"\n            list(Return Values in SSA form): List of the return values in ssa form\n        \"\"\"\n        from slither.core.cfg.node import NodeType\n        from slither.slithir.operations import Return\n        from slither.slithir.variables import Constant\n\n        if self._return_values_ssa is None:\n            return_values_ssa = list()\n            returns = [n for n in self.nodes if n.type == NodeType.RETURN]\n            [return_values_ssa.extend(ir.values) for node in returns for ir in node.irs_ssa if isinstance(ir, Return)]\n            self._return_values_ssa = list(set([x for x in return_values_ssa if not isinstance(x, Constant)]))\n        return self._return_values_ssa"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef slithir_operations(self):\n        if self._slithir_operations is None:\n            operations = [n.irs for n in self.nodes]\n            operations = [item for sublist in operations for item in sublist if item]\n            self._slithir_operations = operations\n        return self._slithir_operations", "response": "List of the slithir operations in this node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signature(self):\n        return self.name, [str(x.type) for x in self.parameters], [str(x.type) for x in self.returns]", "response": "(str, list(str), list(str)): Function signature as\n            (name, list parameters type, list return values type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef signature_str(self):\n        name, parameters, returnVars = self.signature\n        return name+'('+','.join(parameters)+') returns('+','.join(returnVars)+')'", "response": "Returns the function signature as a str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef functions_shadowed(self):\n        '''\n            Return the list of functions shadowed\n        Returns:\n            list(core.Function)\n\n        '''\n        candidates = [c.functions_not_inherited for c in self.contract.inheritance]\n        candidates = [candidate for sublist in candidates for candidate in sublist]\n        return [f for f in candidates if f.full_name == self.full_name]", "response": "Return the list of functions shadowed by this entry point"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_state_variables_read(self):\n        if self._all_state_variables_read is None:\n            self._all_state_variables_read = self._explore_functions(\n                lambda x: x.state_variables_read)\n        return self._all_state_variables_read", "response": "recursive version of variables_read\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_solidity_variables_read(self):\n        if self._all_solidity_variables_read is None:\n            self._all_solidity_variables_read = self._explore_functions(\n                lambda x: x.solidity_variables_read)\n        return self._all_solidity_variables_read", "response": "recursive version of solidity_read\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_expressions(self):\n        if self._all_expressions is None:\n            self._all_expressions = self._explore_functions(lambda x: x.expressions)\n        return self._all_expressions", "response": "recursive version of variables_read\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_internal_calls(self):\n        if self._all_internals_calls is None:\n            self._all_internals_calls = self._explore_functions(lambda x: x.internal_calls)\n        return self._all_internals_calls", "response": "recursive version of internal_calls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_low_level_calls(self):\n        if self._all_low_level_calls is None:\n            self._all_low_level_calls = self._explore_functions(lambda x: x.low_level_calls)\n        return self._all_low_level_calls", "response": "recursive version of low_level calls\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_library_calls(self):\n        if self._all_library_calls is None:\n            self._all_library_calls = self._explore_functions(lambda x: x.library_calls)\n        return self._all_library_calls", "response": "recursive version of library calls\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_conditional_state_variables_read(self, include_loop=True):\n        if include_loop:\n            if self._all_conditional_state_variables_read_with_loop is None:\n                self._all_conditional_state_variables_read_with_loop = self._explore_functions(\n                    lambda x: self._explore_func_cond_read(x,\n                                                           include_loop))\n            return self._all_conditional_state_variables_read_with_loop\n        else:\n            if self._all_conditional_state_variables_read is None:\n                self._all_conditional_state_variables_read = self._explore_functions(\n                    lambda x: self._explore_func_cond_read(x,\n                                                           include_loop))\n            return self._all_conditional_state_variables_read", "response": "Returns the state variable used in a condition\n            Over approximate and also return index access\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Soldiity variables directly used in a condtion node", "response": "def all_conditional_solidity_variables_read(self, include_loop=True):\n        \"\"\"\n            Return the Soldiity variables directly used in a condtion\n\n            Use of the IR to filter index access\n            Assumption: the solidity vars are used directly in the conditional node\n            It won't work if the variable is assigned to a temp variable\n        \"\"\"\n        if include_loop:\n            if self._all_conditional_solidity_variables_read_with_loop is None:\n                self._all_conditional_solidity_variables_read_with_loop = self._explore_functions(\n                    lambda x: self._explore_func_conditional(x,\n                                                             self._solidity_variable_in_binary,\n                                                             include_loop))\n            return self._all_conditional_solidity_variables_read_with_loop\n        else:\n            if self._all_conditional_solidity_variables_read is None:\n                self._all_conditional_solidity_variables_read = self._explore_functions(\n                    lambda x: self._explore_func_conditional(x,\n                                                             self._solidity_variable_in_binary,\n                                                             include_loop))\n            return self._all_conditional_solidity_variables_read"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_solidity_variables_used_as_args(self):\n        if self._all_solidity_variables_used_as_args is None:\n            self._all_solidity_variables_used_as_args = self._explore_functions(\n                lambda x: self._explore_func_nodes(x, self._solidity_variable_in_internal_calls))\n        return self._all_solidity_variables_used_as_args", "response": "Return the Soldiity variables used in a call to a call to a call to a call to a call to a call to a call to a call to a call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_visitor(self, Visitor):\n        expressions = self.expressions\n        v = [Visitor(e).result() for e in expressions]\n        return [item for sublist in v for item in sublist]", "response": "Applies a visitor to all the function expressions\n        Returns a list of the results of the visitor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a local variable from a name", "response": "def get_local_variable_from_name(self, variable_name):\n        \"\"\"\n            Return a local variable from a name\n        Args:\n            varible_name (str): name of the variable\n        Returns:\n            LocalVariable\n        \"\"\"\n        return next((v for v in self.variables if v.name == variable_name), None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cfg_to_dot(self, filename):\n        with open(filename, 'w', encoding='utf8') as f:\n            f.write('digraph{\\n')\n            for node in self.nodes:\n                f.write('{}[label=\"{}\"];\\n'.format(node.node_id, str(node)))\n                for son in node.sons:\n                    f.write('{}->{};\\n'.format(node.node_id, son.node_id))\n\n            f.write(\"}\\n\")", "response": "Export the function to a dot file\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slithir_cfg_to_dot(self, filename):\n        from slither.core.cfg.node import NodeType\n        with open(filename, 'w', encoding='utf8') as f:\n            f.write('digraph{\\n')\n            for node in self.nodes:\n                label = 'Node Type: {} {}\\n'.format(NodeType.str(node.type), node.node_id)\n                if node.expression:\n                    label += '\\nEXPRESSION:\\n{}\\n'.format(node.expression)\n                if node.irs:\n                    label += '\\nIRs:\\n' + '\\n'.join([str(ir) for ir in node.irs])\n                f.write('{}[label=\"{}\"];\\n'.format(node.node_id, label))\n                for son in node.sons:\n                    f.write('{}->{};\\n'.format(node.node_id, son.node_id))\n\n            f.write(\"}\\n\")", "response": "Export the function to a dot file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting the dominator tree of the function to a dot file", "response": "def dominator_tree_to_dot(self, filename):\n        \"\"\"\n            Export the dominator tree of the function to a dot file\n        Args:\n            filename (str)\n        \"\"\"\n        def description(node):\n            desc ='{}\\n'.format(node)\n            desc += 'id: {}'.format(node.node_id)\n            if node.dominance_frontier:\n                desc += '\\ndominance frontier: {}'.format([n.node_id for n in node.dominance_frontier])\n            return desc\n        with open(filename, 'w', encoding='utf8') as f:\n            f.write('digraph{\\n')\n            for node in self.nodes:\n                f.write('{}[label=\"{}\"];\\n'.format(node.node_id, description(node)))\n                if node.immediate_dominator:\n                    f.write('{}->{};\\n'.format(node.immediate_dominator.node_id, node.node_id))\n\n            f.write(\"}\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the function reads the variable in a IF node", "response": "def is_reading_in_conditional_node(self, variable):\n        \"\"\"\n            Check if the function reads the variable in a IF node\n        Args:\n            variable (Variable):\n        Returns:\n            bool: True if the variable is read\n        \"\"\"\n        variables_read = [n.variables_read for n in self.nodes if n.contains_if()]\n        variables_read = [item for sublist in variables_read for item in sublist]\n        return variable in variables_read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_reading_in_require_or_assert(self, variable):\n        variables_read = [n.variables_read for n in self.nodes if n.contains_require_or_assert()]\n        variables_read = [item for sublist in variables_read for item in sublist]\n        return variable in variables_read", "response": "Checks if the function reads the variable in an assert or require node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_summary(self):\n        return (self.contract.name, self.full_name, self.visibility,\n                [str(x) for x in self.modifiers],\n                [str(x) for x in self.state_variables_read + self.solidity_variables_read],\n                [str(x) for x in self.state_variables_written],\n                [str(x) for x in self.internal_calls],\n                [str(x) for x in self.external_calls_as_expressions])", "response": "Returns the function summary of the current object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if the function is protected using a check on msg. sender", "response": "def is_protected(self):\n        \"\"\"\n            Determine if the function is protected using a check on msg.sender\n\n            Only detects if msg.sender is directly used in a condition\n            For example, it wont work for:\n                address a = msg.sender\n                require(a == owner)\n        Returns\n            (bool)\n        \"\"\"\n\n        if self.is_constructor:\n            return True\n        conditional_vars = self.all_conditional_solidity_variables_read(include_loop=False)\n        args_vars = self.all_solidity_variables_used_as_args()\n        return SolidityVariableComposed('msg.sender') in conditional_vars + args_vars"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes variables read and write for the current read and write nodes.", "response": "def _analyze_read_write(self):\n        \"\"\" Compute variables read/written/...\n\n        \"\"\"\n        write_var = [x.variables_written_as_expression for x in self.nodes]\n        write_var = [x for x in write_var if x]\n        write_var = [item for sublist in write_var for item in sublist]\n        write_var = list(set(write_var))\n        # Remove dupplicate if they share the same string representation\n        write_var = [next(obj) for i, obj in groupby(sorted(write_var, key=lambda x: str(x)), lambda x: str(x))]\n        self._expression_vars_written =  write_var\n\n        write_var = [x.variables_written for x in self.nodes]\n        write_var = [x for x in write_var if x]\n        write_var = [item for sublist in write_var for item in sublist]\n        write_var = list(set(write_var))\n        # Remove dupplicate if they share the same string representation\n        write_var = [next(obj) for i, obj in\\\n                    groupby(sorted(write_var, key=lambda x: str(x)), lambda x: str(x))]\n        self._vars_written = write_var\n\n        read_var = [x.variables_read_as_expression for x in self.nodes]\n        read_var = [x for x in read_var if x]\n        read_var = [item for sublist in read_var for item in sublist]\n        # Remove dupplicate if they share the same string representation\n        read_var = [next(obj) for i, obj in\\\n                    groupby(sorted(read_var, key=lambda x: str(x)), lambda x: str(x))]\n        self._expression_vars_read = read_var\n\n        read_var = [x.variables_read for x in self.nodes]\n        read_var = [x for x in read_var if x]\n        read_var = [item for sublist in read_var for item in sublist]\n        # Remove dupplicate if they share the same string representation\n        read_var = [next(obj) for i, obj in\\\n                    groupby(sorted(read_var, key=lambda x: str(x)), lambda x: str(x))]\n        self._vars_read = read_var\n\n        self._state_vars_written = [x for x in self.variables_written if\\\n                                    isinstance(x, StateVariable)]\n        self._state_vars_read = [x for x in self.variables_read if\\\n                                    isinstance(x, (StateVariable))]\n        self._solidity_vars_read = [x for x in self.variables_read if\\\n                                    isinstance(x, (SolidityVariable))]\n\n        self._vars_read_or_written = self._vars_written + self._vars_read\n\n        slithir_variables = [x.slithir_variables for x in self.nodes]\n        slithir_variables = [x for x in slithir_variables if x]\n        self._slithir_variables = [item for sublist in slithir_variables for item in sublist]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nauthenticating based on username and token which is base64 - encoded", "response": "def auth_string(self):\n        '''\n        Authenticate based on username and token which is base64-encoded\n        '''\n\n        username_token = '{username}:{token}'.format(username=self.username, token=self.token)\n        b64encoded_string = b64encode(username_token)\n        auth_string = 'Token {b64}'.format(b64=b64encoded_string)\n\n        return auth_string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding related objects through SoltraEdge API", "response": "def api_related(self, query):\n        '''\n        Find related objects through SoltraEdge API\n        '''\n\n        url = \"{0}/{1}/related/?format=json\".format(self.base_url, query)\n        response = requests.get(url, headers=self.headers, verify=self.verify_ssl)\n\n        if response.status_code == 200:\n            return response.json()\n        else:\n            self.error('Received status code: {0} from Soltra Server. Content:\\n{1}'.format(\n                response.status_code, response.text)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tlp_classifiers(self, name_tlp, val_tlp):\n        '''\n        Classifier between Cortex and Soltra.\n        Soltra uses name-TLP, and Cortex \"value-TLP\"\n        '''\n\n        classifier = {\n            \"WHITE\": 0,\n            \"GREEN\": 1,\n            \"AMBER\": 2,\n            \"RED\": 3\n        }\n\n        valid = True\n\n        if classifier[name_tlp] > val_tlp:\n            valid = False\n\n        return valid", "response": "Return a boolean indicating if a TLP is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npop the object element if the object contains a higher TLP value higher than allowed.", "response": "def pop_object(self, element):\n        '''\n        Pop the object element if the object contains an higher TLP then allowed.\n        '''\n\n        redacted_text = \"Redacted. Object contained TLP value higher than allowed.\"\n\n        element['id'] = ''\n        element['url'] = ''\n        element['type'] = ''\n        element['tags'] = []\n        element['etlp'] = None\n        element['title'] = redacted_text\n        element['tlpColor'] = element['tlpColor']\n        element['uploaded_on'] = ''\n        element['uploaded_by'] = ''\n        element['description'] = redacted_text\n        element['children_types'] = []\n\n        element['summary']['type'] = ''\n        element['summary']['value'] = ''\n        element['summary']['title'] = redacted_text\n        element['summary']['description'] = redacted_text\n\n        return element"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representation of the requested filename.", "response": "def _getStringStream(self, filename, prefer='unicode'):\n        \"\"\"Gets a string representation of the requested filename.\n        Checks for both ASCII and Unicode representations and returns\n        a value if possible.  If there are both ASCII and Unicode\n        versions, then the parameter /prefer/ specifies which will be\n        returned.\n        \"\"\"\n\n        if isinstance(filename, list):\n            # Join with slashes to make it easier to append the type\n            filename = \"/\".join(filename)\n\n        asciiVersion = self._getStream(filename + '001E')\n        unicodeVersion = windowsUnicode(self._getStream(filename + '001F'))\n        if asciiVersion is None:\n            return unicodeVersion\n        elif unicodeVersion is None:\n            return asciiVersion.decode('ascii', 'ignore')\n        else:\n            if prefer == 'unicode':\n                return unicodeVersion\n            else:\n                return asciiVersion.decode('ascii', 'ignore')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __query(domain, limit=100):\n    s = check_output(['{}'.format(os.path.join(os.path.dirname(__file__), 'whois.sh')), '--limit {} {}'.format(limit, domain)], universal_newlines=True)\n    return s", "response": "Query pdns. cert. at"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __process_results(results):\n    if 'no match' in results and 'returning 0 elements' in results:\n        return []\n\n    result_list = []\n\n    # Splts the result and cuts first and last dataset which are comments\n    split = results.split(sep='\\n\\n')[1:-1]\n\n    for entry in split:\n        entry_dict = {}\n        for value in entry.split('\\n'):\n            if len(value) < 1:\n                continue\n            (desc, val) = value.split(': ')\n            entry_dict[desc.replace('-', '')] = val.strip(' ')\n        result_list.append(entry_dict)\n    return result_list", "response": "Processes the results from __query to get valid json from every entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nanalyze a given sample for malicious vba.", "response": "def analyze_vba(self, path):\n        \"\"\"Analyze a given sample for malicious vba.\"\"\"\n\n        try:\n\n            vba_parser = VBA_Parser_CLI(path, relaxed=True)\n            vbaparser_result = vba_parser.process_file_json(show_decoded_strings=True,\n                                                            display_code=True,\n                                                            hide_attributes=False,\n                                                            vba_code_only=False,\n                                                            show_deobfuscated_code=True,\n                                                            deobfuscate=True)\n\n            self.add_result_subsection('Olevba', vbaparser_result)\n        except TypeError:\n            self.add_result_subsection('Oletools VBA Analysis failed', 'Analysis failed due to an filetype error.'\n                                                                       'The file does not seem to be a valid MS-Office '\n                                                                       'file.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the record for the given IP address in the MaxMind database", "response": "def get(self, ip_address):\n        \"\"\"Return the record for the ip_address in the MaxMind DB\n\n\n        Arguments:\n        ip_address -- an IP address in the standard string notation\n        \"\"\"\n        address = ipaddress.ip_address(ip_address)\n\n        if address.version == 6 and self._metadata.ip_version == 4:\n            raise ValueError('Error looking up {0}. You attempted to look up '\n                             'an IPv6 address in an IPv4-only database.'.format(\n                                 ip_address))\n        pointer = self._find_address_in_tree(address)\n\n        return self._resolve_data_pointer(pointer) if pointer else None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, domain, wildcard=True):\n        base_url = \"https://crt.sh/?q={}&output=json\"\n        if wildcard:\n            domain = \"%25.{}\".format(domain)\n        url = base_url.format(domain)\n\n        ua = 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1'\n        req = requests.get(url, headers={'User-Agent': ua})\n\n        if req.ok:\n            try:\n                content = req.content.decode('utf-8')\n                data = json.loads(content.replace('}{', '},{'))\n                return data\n            except Exception:\n                self.error(\"Error retrieving information.\")\n        return None", "response": "Search crt. sh for the given domain and return a list of certificate dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __misphashtypes():\n        hashtypes = ['md5', 'sha1', 'sha256', 'ssdeep', 'sha224', 'sha384', 'sha512', 'sha512/224', 'sha512/256',\n                     'tlsh', 'authentihash']\n        filenames = []\n        for h in hashtypes:\n            filenames.append('filename|{0}'.format(h))\n        return hashtypes + filenames", "response": "Just for better readability all __misp * type methods return just a list of MISP hash data types"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip the related_events from the output for lighter output.", "response": "def __clean_relatedevent(self, related_events):\n        \"\"\"\n        Strip relatedevent sub content of event for lighter output.\n        \n        :param related_events: \n        :return: \n        \"\"\"\n\n        response = []\n        for event in related_events:\n            ev = {\n                'info': event['Event']['info'],\n                'id': event['Event']['id']\n            }\n            response.append(ev)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __clean_event(self, misp_event):\n\n        filters = ['Attribute',\n                   'ShadowAttribute',\n                   'Org',\n                   'ShadowAttribute',\n                   'SharingGroup',\n                   'sharing_group_id',\n                   'disable_correlation',\n                   'locked',\n                   'publish_timestamp',\n                   'attribute_count',\n                   'attribute_count',\n                   'analysis',\n                   'published',\n                   'distribution',\n                   'proposal_email_lock']\n\n        for filter in filters:\n            if filter in misp_event:\n                del misp_event[filter]\n\n        if 'RelatedEvent' in misp_event:\n            misp_event['RelatedEvent'] = self.__clean_relatedevent(misp_event['RelatedEvent'])\n\n        return misp_event", "response": "Remove event data for lighter output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean the response from the server", "response": "def __clean(self, misp_response):\n        \"\"\"\n        \n        :param misp_response: \n        :return: \n        \"\"\"\n        response = []\n\n        for event in misp_response.get('response', []):\n            response.append(self.__clean_event(event['Event']))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __search(self, value, type_attribute):\n        results = []\n        if not value:\n            raise EmptySearchtermError\n        for idx, connection in enumerate(self.misp_connections):\n            misp_response = connection.search(type_attribute=type_attribute, values=value)\n\n            # Fixes #94\n            if isinstance(self.misp_name, list):\n                name = self.misp_name[idx]\n            else:\n                name = self.misp_name\n\n            results.append({'url': connection.root_url,\n                            'name': name,\n                            'result': self.__clean(misp_response)})\n        return results", "response": "Search method call wrapper.\n\n        :param value: value to search for.\n        :type value: str\n        :param type_attribute: attribute types to search for.\n        :type type_attribute: [list, none]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_url(self, searchterm):\n        return self.__search(type_attribute=self.__mispurltypes(), value=searchterm)", "response": "Search for URLs in the cache"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for hashes :type searchterm: str :rtype: list", "response": "def search_hash(self, searchterm):\n        \"\"\"Search for hashes\n        \n        :type searchterm: str\n        :rtype: list\n        \"\"\"\n        return self.__search(type_attribute=self.__misphashtypes(), value=searchterm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_domain(self, searchterm):\n        return self.__search(type_attribute=self.__mispdomaintypes(), value=searchterm)", "response": "Search for domains in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches for emails :type searchterm: str :rtype: list", "response": "def search_mail(self, searchterm):\n        \"\"\"Search for emails\n        \n        :type searchterm: str\n        :rtype: list\n        \"\"\"\n        return self.__search(type_attribute=self.__mispmailtypes(), value=searchterm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_ip(self, searchterm):\n        return self.__search(type_attribute=self.__mispiptypes(), value=searchterm)", "response": "Search for ips\n        \n        :type searchterm: str\n        :rtype: list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for registry keys and values with a searchterm", "response": "def search_registry(self, searchterm):\n        \"\"\"Search for registry keys and values\n        \n        :type searchterm: str\n        :rtype: list\n        \"\"\"\n        return self.__search(type_attribute=self.__mispregistrytypes(), value=searchterm)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_filename(self, searchterm):\n        return self.__search(type_attribute=self.__mispfilenametypes(), value=searchterm)", "response": "Search for filenames\n        \n        :type searchterm: str\n        :rtype: list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch an artifact to see if it is a known tor exit node.", "response": "def search_tor_node(self, data_type, data):\n        \"\"\"Lookup an artifact to check if it is a known tor exit node.\n\n        :param data_type: The artifact type. Must be one of 'ip', 'fqdn'\n                          or 'domain'\n        :param data: The artifact to lookup\n        :type data_type: str\n        :type data: str\n        :return: Data relative to the tor node. If the looked-up artifact is\n                 related to a tor exit node it will contain a `nodes` array.\n                 That array will contains a list of nodes containing the\n                 following keys:\n                 - name: name given to the router\n                 - ip: their IP address\n                 - hostname: Hostname of the router\n                 - country_code: ISO2 code of the country hosting the router\n                 - as_name: ASName registering the router\n                 - as_number: ASNumber registering the router\n                  Otherwise, `nodes` will be empty.\n        :rtype: list\n        \"\"\"\n        results = []\n        if data_type == 'ip':\n            results = self._get_node_from_ip(data)\n        elif data_type == 'fqdn':\n            results = self._get_node_from_fqdn(data)\n        elif data_type == 'domain':\n            results = self._get_node_from_domain(data)\n        else:\n            pass\n        return {\"nodes\": results}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(self, file):\n        result = []\n        for rule in self.ruleset:\n            matches = rule.match(file)\n            for match in matches:\n                result.append(str(match))\n\n        return result", "response": "Checks a given file against all available yara ruleset and returns a list of the results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying Circl. lu Passive SSL for an ip using PyPSSL class. Returns error if nothing is found.", "response": "def query_ip(self, ip):\n        \"\"\"\n        Queries Circl.lu Passive SSL for an ip using PyPSSL class. Returns error if nothing is found.\n\n        :param ip: IP to query for\n        :type ip: str\n        :returns: python dict of results\n        :rtype: dict\n        \"\"\"\n        try:\n            result = self.pssl.query(ip)\n        except:\n            self.error('Exception during processing with passiveSSL. '\n                       'Please check the format of ip.')\n\n        # Check for empty result\n        # result is always assigned, self.error exits the function.\n        if not result.get(ip, None):\n            certificates = []\n        else:\n            certificates = list(result.get(ip).get('certificates'))\n\n        newresult = {'ip': ip,\n                     'certificates': []}\n        for cert in certificates:\n            newresult['certificates'].append({'fingerprint': cert,\n                                              'subject': result.get(ip).get('subjects').get(cert).get('values')[0]})\n        return newresult"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_certificate(self, cert_hash):\n        try:\n            cquery = self.pssl.query_cert(cert_hash)\n        except Exception:\n            self.error('Exception during processing with passiveSSL. '\n                       'This happens if the given hash is not sha1 or contains dashes/colons etc. '\n                       'Please make sure to submit a clean formatted sha1 hash.')\n\n        # fetch_cert raises an error if no certificate was found.\n        try:\n            cfetch = self.pssl.fetch_cert(cert_hash, make_datetime=False)\n        except Exception:\n            cfetch = {}\n\n        return {'query': cquery,\n                'cert': cfetch}", "response": "Queries Circl. lu Passive SSL for a certificate hash using PyPSSL class. Returns error if no certificate was found."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nspecialize wrapper arround the requests module to request data from Onyphe s API.", "response": "def _request(self, path: str, query_params: dict={}):\n        \"\"\"Specialized wrapper arround the requests module to request data from Onyphe\n        :param path: The URL path after the onyphe FQDN\n        :type path: str\n        :param query_params: The dictionnary of query parameters that gets appended to the URL\n        :type query_params: str\n        \"\"\"\n        query_params[\"apikey\"] = self.api_key\n        url = urljoin(self.base_url, path)\n        response = self._session.get(url=url, data=query_params)\n\n        if response.status_code == 429:\n            raise APIRateLimiting(response.text)\n        try:\n            response_data = response.json()\n        except:\n            raise APIError(\"Couldn't parse response JSON\")\n\n        if response_data[\"error\"] > 0:\n            raise APIError(\"got error {}: {}\".format(\n                response_data[\"error\"], response_data[\"message\"]))\n\n        return response_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns geolocate information from ip address", "response": "def geolocate(self, ip: str):\n        \"\"\"Return geolocate information from ip address (Geolocate doesn't need apikey !!)\n        \"\"\"\n        url_path = \"/api/geoloc/{ip}\".format(ip=ip)\n        return self._request_without_api(path=url_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef threatlist(self, ip: str):\n        url_path = \"/api/threatlist/{ip}\".format(ip=ip)\n        return self._request(path=url_path)", "response": "Return the threatlist information we have for the given IPv4 address with history of changes of changes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning datascan information we have for the given IPv4 4 6 address or string with history of changes of changes of changes of the datascan", "response": "def datascan(self, search: str):\n        \"\"\"Return datascan information we have for the given IPv{4,6} address or string with history of changes\n        \"\"\"\n        url_path = \"/api/datascan/{search}\".format(search=search)\n        return self._request(path=url_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reverse(self, search: str):\n        url_path = \"/api/reverse/{search}\".format(search=search)\n        return self._request(path=url_path)", "response": "Return reverse DNS lookup information for the given IPv446 address with history of changes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forward(self, search: str):\n        url_path = \"/api/forward/{search}\".format(search=search)\n        return self._request(path=url_path)", "response": "Return the forward DNS lookup information we have for the given IPv446 address with history of changes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(self, file):\n        result = []\n        all_matches = []\n        for filerules in os.listdir(self.rulepaths):\n            try:\n                rule = yara.compile(os.path.join(self.rulepaths, filerules))\n            except yara.SyntaxError:\n                continue\n            matches = rule.match(file)\n            if len(matches) > 0:\n                for rulem in matches:\n                    rule_family = \"_\".join([x for x in rulem.rule.replace(\"_\", \".\", 1).split(\"_\")[:-1]])\n                    if rule_family not in all_matches:\n                        all_matches.append(rule_family)\n        for rule_family in all_matches:\n            rules_info_txt = requests.get('{}/family/{}'.format(self.baseurl, rule_family),\n                                          auth=HTTPBasicAuth(self.user, self.pwd))\n            rules_info_json = json.loads(rules_info_txt.text)\n            result.append({\n                'family': rule_family,\n                'common_name': rules_info_json['common_name'],\n                'description': rules_info_json['description'],\n                'attribution': rules_info_json['attribution'],\n                'alt_names': rules_info_json['alt_names'],\n                'urls': rules_info_json['urls']\n            })\n\n        return result", "response": "Checks a given file against all available yara rules and returns a list with matched rules info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_ip(self, ip):\n\n        # hits will be the variable to store all matches\n        hits = []\n        description = {}\n        file_date = {}\n        # Check for lock\n        while os.path.isfile('{}/.lock'.format(self.path)):\n            sleep(10)\n\n        # First: check the ipsets\n        for ipset in self.ipsets:\n            with open('{}/{}'.format(self.path, ipset)) as afile:\n                ipsetname = ipset.split('.')[0]\n                description.update({ipsetname: ''})\n                file_date.update({ipsetname: ''})\n                for l in afile:\n                    if l[0] == '#':\n                        # Check for date and break if too old\n                        if '# Source File Date: ' in l:\n                            datestr = re.sub('# Source File Date: ', '', l.rstrip('\\n'))\n                            date = parse(datestr)\n                            file_date[ipsetname] = str(date)\n                            if (self.now - date).days > self.ignoreolderthandays:\n                                break\n                        description[ipsetname] += re.sub(r'^\\[.*\\] \\(.*\\) [a-zA-Z0-9.\\- ]*$', '', l.lstrip('# '))\\\n                            .replace('\\n\\n', '\\n')\n                    else:\n                        if ip in l:\n                            # On match append to hits and break; next file!\n                            hits.append({'list': ipsetname, 'description': description.get(ipsetname),\n                                         'file_date': file_date.get(ipsetname)})\n                            break\n\n        # Second: check the netsets\n        for netset in self.netsets:\n            with open('{}/{}'.format(self.path, netset)) as afile:\n                netsetname = netset.split('.')[0]\n                description.update({netsetname: ''})\n                file_date.update({netsetname: ''})\n                for l in afile:\n                    if l[0] == '#':\n                        # Check for date and break if too old\n                        if '# Source File Date: ' in l:\n                            datestr = re.sub('# Source File Date: ', '', l.rstrip('\\n'))\n                            date = parse(datestr)\n                            file_date[netsetname] = str(date)\n                            if (self.now - date).days > self.ignoreolderthandays:\n                                break\n                        description[netsetname] += re.sub(r'^\\[.*\\] \\(.*\\) [a-zA-Z0-9.\\- ]*$', '', l.lstrip('# '))\\\n                            .replace('\\n\\n', '\\n')\n                    else:\n                        try:\n                            if ipaddress.ip_address(ip) in ipaddress.ip_network(u'{}'.format(l.split('\\n')[0])):\n                                hits.append({'list': netsetname, 'description': description.get(netsetname),\n                                             'file_date': file_date.get(netsetname)})\n                                break\n                        except ValueError as e:\n                            self.error('ValueError occured. Used values: ipnetwork {}, ip to check {}, file {}.'\n                                       'Error message: {}'.format(l, ip, netset, e))\n\n        return hits", "response": "Checks if the given IP is in the lock file and if so checks if the file is too old and report the results."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap GreyNoise intentions to Cortex level and intention values.", "response": "def _get_level(current_level, new_intention):\n        \"\"\"\n        Map GreyNoise intentions to Cortex maliciousness levels.\n        Accept a Cortex level and a GreyNoise intention, the return the more malicious of the two.\n\n        :param current_level: A Cortex maliciousness level\n            https://github.com/TheHive-Project/CortexDocs/blob/master/api/how-to-create-an-analyzer.md#output\n        :param new_intention: An intention field value from a GreyNoise record\n            https://github.com/GreyNoise-Intelligence/api.greynoise.io#v1queryip\n        :return: The more malicious of the 2 submitted values as a Cortex maliciousness level\n        \"\"\"\n\n        intention_level_map = OrderedDict([\n            ('info', 'info'),\n            ('benign', 'safe'),\n            ('suspicious', 'suspicious'),\n            ('malicious', 'malicious')\n        ])\n        levels = intention_level_map.values()\n\n        new_level = intention_level_map.get(new_intention, 'info')\n        new_index = levels.index(new_level)\n\n        try:\n            current_index = levels.index(current_level)\n        except ValueError:  # There is no existing level\n            current_index = -1\n\n        return new_level if new_index > current_index else current_level"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns one taxonomy summarizing the reported tags", "response": "def summary(self, raw):\n        \"\"\"\n        Return one taxonomy summarizing the reported tags\n            If there is only one tag, use it as the predicate\n            If there are multiple tags, use \"entries\" as the predicate\n            Use the total count as the value\n            Use the most malicious level found\n\n\n        Examples:\n\n\n        Input\n        {\n            \"name\": SCANNER1,\n            \"intention\": \"\"\n        }\n        Output\n        GreyNoise:SCANNER1 = 1 (info)\n\n\n        Input\n        {\n            \"name\": SCANNER1,\n            \"intention\": \"malicious\"\n        },\n        {\n            \"name\": SCANNER1,\n            \"intention\": \"benign\"\n        }\n        Output\n        GreyNoise:SCANNER1 = 2 (malicious)\n\n\n        Input\n        {\n            \"name\": SCANNER1,\n            \"intention\": \"\"\n        },\n        {\n            \"name\": SCANNER1,\n            \"intention\": \"safe\"\n        },\n        {\n            \"name\": SCANNER2,\n            \"intention\": \"\"\n        }\n        Output\n        GreyNoise:entries = 3 (safe)\n        \"\"\"\n\n        try:\n            taxonomies = []\n            if raw.get('records'):\n                final_level = None\n                taxonomy_data = defaultdict(int)\n                for record in raw.get('records', []):\n                    name = record.get('name', 'unknown')\n                    intention = record.get('intention', 'unknown')\n                    taxonomy_data[name] += 1\n                    final_level = self._get_level(final_level, intention)\n\n                if len(taxonomy_data) > 1:  # Multiple tags have been found\n                    taxonomies.append(self.build_taxonomy(final_level, 'GreyNoise', 'entries', len(taxonomy_data)))\n                else:  # There is only one tag found, possibly multiple times\n                    for name, count in taxonomy_data.iteritems():\n                        taxonomies.append(self.build_taxonomy(final_level, 'GreyNoise', name, count))\n\n            else:\n                taxonomies.append(self.build_taxonomy('info', 'GreyNoise', 'Records', 'None'))\n\n            return {\"taxonomies\": taxonomies}\n\n        except Exception as e:\n            self.error('Summary failed\\n{}'.format(e.message))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting the requests response JSON and status code.", "response": "def _return_response_and_status_code(response):\n    \"\"\" Output the requests response JSON and status code\n\n    :rtype : dict\n    :param response: requests response object\n    :return: dict containing the JSON response and/or the status code with error string.\n    \"\"\"\n    if response.status_code == requests.codes.ok:\n        return dict(results=response.json(), response_code=response.status_code)\n    elif response.status_code == 204:\n        return dict(error='You exceeded the public API request rate limit (4 requests of any nature per minute)',\n                    response_code=response.status_code)\n    elif response.status_code == 403:\n        return dict(error='You tried to perform calls to functions for which you require a Private API key.',\n                    response_code=response.status_code)\n    else:\n        return dict(response_code=response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan_file(self, this_file):\n        params = {'apikey': self.api_key}\n        try:\n            if type(this_file) == str and os.path.isfile(this_file):\n                files = {'file': (this_file, open(this_file, 'rb'))}\n            elif isinstance(this_file, StringIO.StringIO):\n                files = {'file': this_file.read()}\n            else:\n                files = {'file': this_file}\n        except TypeError as e:\n            return dict(error=e.message)\n\n        try:\n            response = requests.post(self.base + 'file/scan', files=files, params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Submit a file to be scanned by VirusTotal\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scan_url(self, this_url):\n        params = {'apikey': self.api_key, 'url': this_url}\n\n        try:\n            response = requests.post(self.base + 'url/scan', params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Submit a URL to be scanned by VirusTotal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan_file(self, this_file, notify_url=None, notify_changes_only=None):\n        params = {'apikey': self.api_key}\n        files = {'file': (this_file, open(this_file, 'rb'))}\n\n        try:\n            response = requests.post(self.base + 'file/scan', files=files, params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Submit a file to be scanned by VirusTotal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload a file from VirusTotal s store given a hash.", "response": "def get_file(self, this_hash):\n        \"\"\" Download a file by its hash.\n\n        Downloads a file from VirusTotal's store given one of its hashes. This call can be used in conjuction with\n        the file searching call in order to download samples that match a given set of criteria.\n\n        :param this_hash: The md5/sha1/sha256 hash of the file you want to download.\n        :return: Downloaded file in response.content\n        \"\"\"\n        params = {'apikey': self.api_key, 'hash': this_hash}\n\n        try:\n            response = requests.get(self.base + 'file/download', params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        if response.status_code == requests.codes.ok:\n            return response.content\n        elif response.status_code == 403:\n            return dict(error='You tried to perform calls to functions for which you require a Private API key.',\n                        response_code=response.status_code)\n        elif response.status_code == 404:\n            return dict(error='File not found.', response_code=response.status_code)\n        else:\n            return dict(response_code=response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_url_report(self, this_url, scan='0', allinfo=1):\n\n        params = {'apikey': self.api_key, 'resource': this_url, 'scan': scan, 'allinfo': allinfo}\n\n        try:\n            response = requests.get(self.base + 'url/report', params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Get the most recent report for a given URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_comments(self, resource, before=None):\n        params = dict(apikey=self.api_key, resource=resource, before=before)\n\n        try:\n            response = requests.get(self.base + 'comments/get', params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Get a list of VirusTotal Community comments for a given file or URL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_hashes_from_search(self, query, page=None):\n        params = {'query': query, 'apikey': self.api_key, 'page': page}\n\n        try:\n            response = requests.get(self.base + 'search/programmatic/', params=params, proxies=self.proxies)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return response.json()['next_page'], response", "response": "Get the hashes from a file search query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file(self, file_hash, save_file_at):\n        params = {'hash': file_hash, 'apikey': self.api_key}\n\n        try:\n            response = requests.get(self.base + 'download/', params=params, proxies=self.proxies, stream=True)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        if response.status_code == requests.codes.ok:\n            self.save_downloaded_file(file_hash, save_file_at, response.content)\n            return response.content\n        elif response.status_code == 403:\n            return dict(error='You tried to perform calls to functions for which you require a Private API key.',\n                        response_code=response.status_code)\n        elif response.status_code == 404:\n            return dict(error='File not found.', response_code=response.status_code)\n        else:\n            return dict(response_code=response.status_code)", "response": "Get the contents of a file from the VirusTotal storage."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_file_report_pages(self, query):\n        responses = []\n        next_page, response = self.get_hashes_from_search(self, query)\n        responses.append(_return_response_and_status_code(response))\n        while next_page:\n            next_page, response = self.get_hashes_from_search(query, next_page)\n            responses.append(_return_response_and_status_code(response))\n        return dict(results=responses)", "response": "Get all file report pages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the downloaded file to disk", "response": "def save_downloaded_file(filename, save_file_at, file_stream):\n        \"\"\" Save Downloaded File to Disk Helper Function\n\n        :param save_file_at: Path of where to save the file.\n        :param file_stream: File stream\n        :param filename: Name to save the file.\n        \"\"\"\n        filename = os.path.join(save_file_at, filename)\n        with open(filename, 'wb') as f:\n            f.write(file_stream)\n            f.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses and format and return scan summary.", "response": "def summary(self, raw):\n        \"\"\"Parse, format and return scan summary.\"\"\"\n        taxonomies = []\n        level = \"info\"\n        namespace = \"Patrowl\"\n\n        # getreport service\n        if self.service == 'getreport':\n            if 'risk_level' in raw and raw['risk_level']:\n                risk_level = raw['risk_level']\n\n                # Grade\n                if risk_level['grade'] in [\"A\", \"B\"]:\n                    level = \"safe\"\n                else:\n                    level = \"suspicious\"\n                \n                taxonomies.append(self.build_taxonomy(level, namespace, \"Grade\", risk_level['grade']))\n\n                # Findings\n                if risk_level['high'] > 0:\n                    level = \"malicious\"\n                elif risk_level['medium'] > 0 or risk_level['low'] > 0:\n                    level = \"suspicious\"\n                else:\n                    level = \"info\"\n\n                taxonomies.append(self.build_taxonomy(\n                    level, namespace, \"Findings\", \"{}/{}/{}/{}\".format(\n                        risk_level['high'],\n                        risk_level['medium'],\n                        risk_level['low'],\n                        risk_level['info']\n                    )))\n        #todo: add_asset service\n\n        return {\"taxonomies\": taxonomies}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        kwargs = {'query': self.get_data()}\n        if self.data_type == \"ip\":\n            kwargs.update({'query_type': 'ip'})\n        elif self.data_type == \"network\":\n            kwargs.update({'query_type': 'network'})\n        elif self.data_type == 'autonomous-system':\n            kwargs.update({'query_type': 'asn'})\n        elif self.data_type == 'port':\n            kwargs.update({'query_type': 'port'})\n        else:\n            self.notSupported()\n            return False\n\n        if self.service == 'observations':\n            response = self.bs.get_observations(**kwargs)\n            self.report(response)\n        elif self.service == 'enrichment':\n            response = self.bs.enrich(**kwargs)\n            self.report(response)\n        else:\n            self.report({'error': 'Invalid service defined.'})", "response": "Run the process to get observation data from Backscatter. io."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse the Backscatter. io summary data to create a view.", "response": "def summary(self, raw):\n        \"\"\"Use the Backscatter.io summary data to create a view.\"\"\"\n        taxonomies = list()\n        level = 'info'\n        namespace = 'Backscatter.io'\n\n        if self.service == 'observations':\n            summary = raw.get('results', dict()).get('summary', dict())\n            taxonomies = taxonomies + [\n                self.build_taxonomy(level, namespace, 'Observations', summary.get('observations_count', 0)),\n                self.build_taxonomy(level, namespace, 'IP Addresses', summary.get('ip_address_count', 0)),\n                self.build_taxonomy(level, namespace, 'Networks', summary.get('network_count', 0)),\n                self.build_taxonomy(level, namespace, 'AS', summary.get('autonomous_system_count', 0)),\n                self.build_taxonomy(level, namespace, 'Ports', summary.get('port_count', 0)),\n                self.build_taxonomy(level, namespace, 'Protocols', summary.get('protocol_count', 0))\n            ]\n        elif self.service == 'enrichment':\n            summary = raw.get('results', dict())\n            if self.data_type == 'ip':\n                taxonomies = taxonomies + [\n                    self.build_taxonomy(level, namespace, 'Network', summary.get('network')),\n                    self.build_taxonomy(level, namespace, 'Network Broadcast', summary.get('network_broadcast')),\n                    self.build_taxonomy(level, namespace, 'Network Size', summary.get('network_size')),\n                    self.build_taxonomy(level, namespace, 'Country', summary.get('country_name')),\n                    self.build_taxonomy(level, namespace, 'AS Number', summary.get('as_num')),\n                    self.build_taxonomy(level, namespace, 'AS Name', summary.get('as_name')),\n                ]\n            elif self.data_type == 'network':\n                taxonomies = taxonomies + [\n                    self.build_taxonomy(level, namespace, 'Network Size', summary.get('network_size'))\n                ]\n            elif self.data_type == 'autonomous-system':\n                taxonomies = taxonomies + [\n                    self.build_taxonomy(level, namespace, 'Prefix Count', summary.get('prefix_count')),\n                    self.build_taxonomy(level, namespace, 'AS Number', summary.get('as_num')),\n                    self.build_taxonomy(level, namespace, 'AS Name', summary.get('as_name'))\n                ]\n            elif self.data_type == 'port':\n                for result in raw.get('results', list()):\n                    display = \"%s (%s)\" % (result.get('service'), result.get('protocol'))\n                    taxonomies.append(self.build_taxonomy(level, namespace, 'Service', display))\n            else:\n                pass\n        else:\n            pass\n        return {\"taxonomies\": taxonomies}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(self, offset):\n        new_offset = offset + 1\n        (ctrl_byte,) = struct.unpack(b'!B', self._buffer[offset:new_offset])\n        type_num = ctrl_byte >> 5\n        # Extended type\n        if not type_num:\n            (type_num, new_offset) = self._read_extended(new_offset)\n\n        (size, new_offset) = self._size_from_ctrl_byte(\n            ctrl_byte, new_offset, type_num)\n        return self._type_decoder[type_num](self, size, new_offset)", "response": "Decodes a section of the data section starting at offset returning a new object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sample(self, samplehash):\n        apiurl = '/rest/sample/'\n        if len(samplehash) == 32:  # MD5\n            apiurl += 'md5/'\n        elif len(samplehash) == 40:  # SHA1\n            apiurl += 'sha1/'\n        elif len(samplehash) == 64:  # SHA256\n            apiurl += 'sha256/'\n        else:\n            raise UnknownHashTypeError('Sample hash has an unknown length.')\n\n        res = self.session.get(self.url + apiurl + samplehash)\n        if res.status_code == 200:\n            return json.loads(res.text)\n        else:\n            raise BadResponseError('Response from VMRay was not HTTP 200.'\n                                   ' Responsecode: {}; Text: {}'.format(res.status_code, res.text))", "response": "Downloads information about a sample using a given hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef submit_sample(self, filepath, filename, tags=['TheHive']):\n        apiurl = '/rest/sample/submit?sample_file'\n        params = {'sample_filename_b64enc': base64.b64encode(filename.encode('utf-8')),\n                  'reanalyze': self.reanalyze}\n        if tags:\n            params['tags'] = ','.join(tags)\n\n        if os.path.isfile(filepath):\n            res = self.session.post(url=self.url + apiurl,\n                                    files=[('sample_file', open(filepath, mode='rb'))],\n                                    params=params)\n            if res.status_code == 200:\n                return json.loads(res.text)\n            else:\n                raise BadResponseError('Response from VMRay was not HTTP 200.'\n                                       ' Responsecode: {}; Text: {}'.format(res.status_code, res.text))\n        else:\n            raise SampleFileNotFoundError('Given sample file was not found.')", "response": "Uploads a new sample to the VMRay API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries vmray to check status of a job.", "response": "def query_job_status(self, submissionid):\n        \"\"\"\n        Queries vmray to check id a job was \n        \n        :param submissionid: ID of the job/submission\n        :type submissionid: int\n        :returns: True if job finished, false if not\n        :rtype: bool\n        \"\"\"\n\n        apiurl = '/rest/submission/'\n        result = self.session.get('{}{}{}'.format(self.url, apiurl, submissionid))\n        if result.status_code == 200:\n            submission_info = json.loads(result.text)\n            if submission_info.get('data', {}).get('submission_finished', False):  # Or something like that\n                return True\n        else:\n            raise UnknownSubmissionIdError('Submission id seems invalid, response was not HTTP 200.')\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_results(self, results):\n        self.add_result_subsection(\n            'Exploit mitigation techniques',\n            {\n                'level': results.get('Plugins', {}).get('mitigation', {}).get('level', None),\n                'summary': results.get('Plugins', {}).get('mitigation', {}).get('summary', None),\n                'content': results.get('Plugins', {}).get('mitigation', {}).get('plugin_output', None)\n            }\n        )\n        self.add_result_subsection(\n            'Suspicious strings',\n            {\n                'level': results.get('Plugins', {}).get('strings', {}).get('level', None),\n                'summary': results.get('Plugins', {}).get('strings', {}).get('summary', None),\n                'content': results.get('Plugins', {}).get('strings', {}).get('plugin_output', None)\n            }\n        )\n        self.add_result_subsection(\n            'Suspicious imports',\n            {\n                'level': results.get('Plugins', {}).get('imports', {}).get('level', None),\n                'summary': results.get('Plugins', {}).get('imports', {}).get('summary', None),\n                'content': results.get('Plugins', {}).get('imports', {}).get('plugin_output', None)\n            }\n        )\n        self.add_result_subsection(\n            'Packer',\n            {\n                'level': results.get('Plugins', {}).get('packer', {}).get('level', None),\n                'summary': results.get('Plugins', {}).get('packer', {}).get('summary', None),\n                'content': results.get('Plugins', {}).get('packer', {}).get('plugin_output', None)\n            }\n        )\n        self.add_result_subsection(\n            'Clamav',\n            {\n                'level': results.get('Plugins', {}).get('clamav', {}).get('level', None),\n                'summary': results.get('Plugins', {}).get('clamav', {}).get('summary', None),\n                'content': results.get('Plugins', {}).get('clamav', {}).get('plugin_output', None)\n            }\n        )\n        self.add_result_subsection('Manalyze raw output', json.dumps(results, indent=4))", "response": "Properly format the results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes an IP string or integer and return an object of the correct type.", "response": "def IPAddress(address, version=None):\n    \"\"\"Take an IP string/int and return an object of the correct type.\n\n    Args:\n        address: A string or integer, the IP address.  Either IPv4 or\n          IPv6 addresses may be supplied; integers less than 2**32 will\n          be considered to be IPv4 by default.\n        version: An Integer, 4 or 6. If set, don't try to automatically\n          determine what the IP address type is. important for things\n          like IPAddress(1), which could be IPv4, '0.0.0.1',  or IPv6,\n          '::1'.\n\n    Returns:\n        An IPv4Address or IPv6Address object.\n\n    Raises:\n        ValueError: if the string passed isn't either a v4 or a v6\n          address.\n\n    \"\"\"\n    if version:\n        if version == 4:\n            return IPv4Address(address)\n        elif version == 6:\n            return IPv6Address(address)\n\n    try:\n        return IPv4Address(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    try:\n        return IPv6Address(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    raise ValueError('%r does not appear to be an IPv4 or IPv6 address' %\n                     address)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef IPNetwork(address, version=None, strict=False):\n    if version:\n        if version == 4:\n            return IPv4Network(address, strict)\n        elif version == 6:\n            return IPv6Network(address, strict)\n\n    try:\n        return IPv4Network(address, strict)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    try:\n        return IPv6Network(address, strict)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    raise ValueError('%r does not appear to be an IPv4 or IPv6 network' %\n                     address)", "response": "Take an IP string or integer and return an object of the correct type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef v4_int_to_packed(address):\n    if address > _BaseV4._ALL_ONES:\n        raise ValueError('Address too large for IPv4')\n    return Bytes(struct.pack('!I', address))", "response": "Convert an integer representation of an IPv4 IP address into a packed version of the address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of leading bits that are the same for two numbers.", "response": "def _get_prefix_length(number1, number2, bits):\n    \"\"\"Get the number of leading bits that are same for two numbers.\n\n    Args:\n        number1: an integer.\n        number2: another integer.\n        bits: the maximum number of bits to compare.\n\n    Returns:\n        The number of leading bits that are the same for two numbers.\n\n    \"\"\"\n    for i in range(bits):\n        if number1 >> i == number2 >> i:\n            return bits - i\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsummarizing a network range given the first and last IP addresses.", "response": "def summarize_address_range(first, last):\n    \"\"\"Summarize a network range given the first and last IP addresses.\n\n    Example:\n        >>> summarize_address_range(IPv4Address('1.1.1.0'),\n            IPv4Address('1.1.1.130'))\n        [IPv4Network('1.1.1.0/25'), IPv4Network('1.1.1.128/31'),\n        IPv4Network('1.1.1.130/32')]\n\n    Args:\n        first: the first IPv4Address or IPv6Address in the range.\n        last: the last IPv4Address or IPv6Address in the range.\n\n    Returns:\n        The address range collapsed to a list of IPv4Network's or\n        IPv6Network's.\n\n    Raise:\n        TypeError:\n            If the first and last objects are not IP addresses.\n            If the first and last objects are not the same version.\n        ValueError:\n            If the last object is not greater than the first.\n            If the version is not 4 or 6.\n\n    \"\"\"\n    if not (isinstance(first, _BaseIP) and isinstance(last, _BaseIP)):\n        raise TypeError('first and last must be IP addresses, not networks')\n    if first.version != last.version:\n        raise TypeError(\"%s and %s are not of the same version\" % (\n                str(first), str(last)))\n    if first > last:\n        raise ValueError('last IP address must be greater than first')\n\n    networks = []\n\n    if first.version == 4:\n        ip = IPv4Network\n    elif first.version == 6:\n        ip = IPv6Network\n    else:\n        raise ValueError('unknown IP version')\n\n    ip_bits = first._max_prefixlen\n    first_int = first._ip\n    last_int = last._ip\n    while first_int <= last_int:\n        nbits = _count_righthand_zero_bits(first_int, ip_bits)\n        current = None\n        while nbits >= 0:\n            addend = 2**nbits - 1\n            current = first_int + addend\n            nbits -= 1\n            if current <= last_int:\n                break\n        prefix = _get_prefix_length(first_int, current, ip_bits)\n        net = ip('%s/%d' % (str(first), prefix))\n        networks.append(net)\n        if current == ip._ALL_ONES:\n            break\n        first_int = current + 1\n        first = IPAddress(first_int, version=first._version)\n    return networks"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloops through the addresses, collapsing concurrent netblocks. Example: ip1 = IPv4Network('1.1.0.0/24') ip2 = IPv4Network('1.1.1.0/24') ip3 = IPv4Network('1.1.2.0/24') ip4 = IPv4Network('1.1.3.0/24') ip5 = IPv4Network('1.1.4.0/24') ip6 = IPv4Network('1.1.0.1/22') _collapse_address_list_recursive([ip1, ip2, ip3, ip4, ip5, ip6]) -> [IPv4Network('1.1.0.0/22'), IPv4Network('1.1.4.0/24')] This shouldn't be called directly; it is called via collapse_address_list([]). Args: addresses: A list of IPv4Network's or IPv6Network's Returns: A list of IPv4Network's or IPv6Network's depending on what we were passed.", "response": "def _collapse_address_list_recursive(addresses):\n    \"\"\"Loops through the addresses, collapsing concurrent netblocks.\n\n    Example:\n\n        ip1 = IPv4Network('1.1.0.0/24')\n        ip2 = IPv4Network('1.1.1.0/24')\n        ip3 = IPv4Network('1.1.2.0/24')\n        ip4 = IPv4Network('1.1.3.0/24')\n        ip5 = IPv4Network('1.1.4.0/24')\n        ip6 = IPv4Network('1.1.0.1/22')\n\n        _collapse_address_list_recursive([ip1, ip2, ip3, ip4, ip5, ip6]) ->\n          [IPv4Network('1.1.0.0/22'), IPv4Network('1.1.4.0/24')]\n\n        This shouldn't be called directly; it is called via\n          collapse_address_list([]).\n\n    Args:\n        addresses: A list of IPv4Network's or IPv6Network's\n\n    Returns:\n        A list of IPv4Network's or IPv6Network's depending on what we were\n        passed.\n\n    \"\"\"\n    ret_array = []\n    optimized = False\n\n    for cur_addr in addresses:\n        if not ret_array:\n            ret_array.append(cur_addr)\n            continue\n        if cur_addr in ret_array[-1]:\n            optimized = True\n        elif cur_addr == ret_array[-1].supernet().subnet()[1]:\n            ret_array.append(ret_array.pop().supernet())\n            optimized = True\n        else:\n            ret_array.append(cur_addr)\n\n    if optimized:\n        return _collapse_address_list_recursive(ret_array)\n\n    return ret_array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collapse_address_list(addresses):\n    i = 0\n    addrs = []\n    ips = []\n    nets = []\n\n    # split IP addresses and networks\n    for ip in addresses:\n        if isinstance(ip, _BaseIP):\n            if ips and ips[-1]._version != ip._version:\n                raise TypeError(\"%s and %s are not of the same version\" % (\n                        str(ip), str(ips[-1])))\n            ips.append(ip)\n        elif ip._prefixlen == ip._max_prefixlen:\n            if ips and ips[-1]._version != ip._version:\n                raise TypeError(\"%s and %s are not of the same version\" % (\n                        str(ip), str(ips[-1])))\n            ips.append(ip.ip)\n        else:\n            if nets and nets[-1]._version != ip._version:\n                raise TypeError(\"%s and %s are not of the same version\" % (\n                        str(ip), str(nets[-1])))\n            nets.append(ip)\n\n    # sort and dedup\n    ips = sorted(set(ips))\n    nets = sorted(set(nets))\n\n    while i < len(ips):\n        (first, last) = _find_address_range(ips[i:])\n        i = ips.index(last) + 1\n        addrs.extend(summarize_address_range(first, last))\n\n    return _collapse_address_list_recursive(sorted(\n        addrs + nets, key=_BaseNet._get_networks_key))", "response": "Collapse a list of IP objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a key suitable for sorting between networks and addresses.", "response": "def get_mixed_type_key(obj):\n    \"\"\"Return a key suitable for sorting between networks and addresses.\n\n    Address and Network objects are not sortable by default; they're\n    fundamentally different so the expression\n\n        IPv4Address('1.1.1.1') <= IPv4Network('1.1.1.1/24')\n\n    doesn't make any sense.  There are some times however, where you may wish\n    to have ipaddr sort these for you anyway. If you need to do this, you\n    can use this function as the key= argument to sorted().\n\n    Args:\n      obj: either a Network or Address object.\n    Returns:\n      appropriate key.\n\n    \"\"\"\n    if isinstance(obj, _BaseNet):\n        return obj._get_networks_key()\n    elif isinstance(obj, _BaseIP):\n        return obj._get_address_key()\n    return NotImplemented"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef overlaps(self, other):\n        return self.network in other or self.broadcast in other or (\n            other.network in self or other.broadcast in self)", "response": "Tells if self is partly contained in other."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef address_exclude(self, other):\n        if not self._version == other._version:\n            raise TypeError(\"%s and %s are not of the same version\" % (\n                str(self), str(other)))\n\n        if not isinstance(other, _BaseNet):\n            raise TypeError(\"%s is not a network object\" % str(other))\n\n        if other not in self:\n            raise ValueError('%s not contained in %s' % (str(other),\n                                                         str(self)))\n        if other == self:\n            return []\n\n        ret_addrs = []\n\n        # Make sure we're comparing the network of other.\n        other = IPNetwork('%s/%s' % (str(other.network), str(other.prefixlen)),\n                   version=other._version)\n\n        s1, s2 = self.subnet()\n        while s1 != other and s2 != other:\n            if other in s1:\n                ret_addrs.append(s2)\n                s1, s2 = s1.subnet()\n            elif other in s2:\n                ret_addrs.append(s1)\n                s1, s2 = s2.subnet()\n            else:\n                # If we got here, there's a bug somewhere.\n                assert True == False, ('Error performing exclusion: '\n                                       's1: %s s2: %s other: %s' %\n                                       (str(s1), str(s2), str(other)))\n        if s1 == other:\n            ret_addrs.append(s2)\n        elif s2 == other:\n            ret_addrs.append(s1)\n        else:\n            # If we got here, there's a bug somewhere.\n            assert True == False, ('Error performing exclusion: '\n                                   's1: %s s2: %s other: %s' %\n                                   (str(s1), str(s2), str(other)))\n\n        return sorted(ret_addrs, key=_BaseNet._get_networks_key)", "response": "Returns a list of addresses which are not part of self plus other."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompare two IP objects. This is only concerned about the comparison of the integer representation of the network addresses. This means that the host bits aren't considered at all in this method. If you want to compare host bits, you can easily enough do a 'HostA._ip < HostB._ip' Args: other: An IP object. Returns: If the IP versions of self and other are the same, returns: -1 if self < other: eg: IPv4('1.1.1.0/24') < IPv4('1.1.2.0/24') IPv6('1080::200C:417A') < IPv6('1080::200B:417B') 0 if self == other eg: IPv4('1.1.1.1/24') == IPv4('1.1.1.2/24') IPv6('1080::200C:417A/96') == IPv6('1080::200C:417B/96') 1 if self > other eg: IPv4('1.1.1.0/24') > IPv4('1.1.0.0/24') IPv6('1080::1:200C:417A/112') > IPv6('1080::0:200C:417A/112') If the IP versions of self and other are different, returns: -1 if self._version < other._version eg: IPv4('10.0.0.1/24') < IPv6('::1/128') 1 if self._version > other._version eg: IPv6('::1/128') > IPv4('255.255.255.0/24')", "response": "def compare_networks(self, other):\n        \"\"\"Compare two IP objects.\n\n        This is only concerned about the comparison of the integer\n        representation of the network addresses.  This means that the\n        host bits aren't considered at all in this method.  If you want\n        to compare host bits, you can easily enough do a\n        'HostA._ip < HostB._ip'\n\n        Args:\n            other: An IP object.\n\n        Returns:\n            If the IP versions of self and other are the same, returns:\n\n            -1 if self < other:\n              eg: IPv4('1.1.1.0/24') < IPv4('1.1.2.0/24')\n              IPv6('1080::200C:417A') < IPv6('1080::200B:417B')\n            0 if self == other\n              eg: IPv4('1.1.1.1/24') == IPv4('1.1.1.2/24')\n              IPv6('1080::200C:417A/96') == IPv6('1080::200C:417B/96')\n            1 if self > other\n              eg: IPv4('1.1.1.0/24') > IPv4('1.1.0.0/24')\n              IPv6('1080::1:200C:417A/112') >\n              IPv6('1080::0:200C:417A/112')\n\n            If the IP versions of self and other are different, returns:\n\n            -1 if self._version < other._version\n              eg: IPv4('10.0.0.1/24') < IPv6('::1/128')\n            1 if self._version > other._version\n              eg: IPv6('::1/128') > IPv4('255.255.255.0/24')\n\n        \"\"\"\n        if self._version < other._version:\n            return -1\n        if self._version > other._version:\n            return 1\n        # self._version == other._version below here:\n        if self.network < other.network:\n            return -1\n        if self.network > other.network:\n            return 1\n        # self.network == other.network below here:\n        if self.netmask < other.netmask:\n            return -1\n        if self.netmask > other.netmask:\n            return 1\n        # self.network == other.network and self.netmask == other.netmask\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the prefix length from a netmask.", "response": "def _prefix_from_ip_int(self, ip_int):\n        \"\"\"Return prefix length from a bitwise netmask.\n\n        Args:\n            ip_int: An integer, the netmask in expanded bitwise format.\n\n        Returns:\n            An integer, the prefix length.\n\n        Raises:\n            NetmaskValueError: If the input is not a valid netmask.\n\n        \"\"\"\n        prefixlen = self._max_prefixlen\n        while prefixlen:\n            if ip_int & 1:\n                break\n            ip_int >>= 1\n            prefixlen -= 1\n\n        if ip_int == (1 << prefixlen) - 1:\n            return prefixlen\n        else:\n            raise NetmaskValueError('Bit pattern does not match /1*0*/')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn a prefix length string into an integer.", "response": "def _prefix_from_prefix_string(self, prefixlen_str):\n        \"\"\"Turn a prefix length string into an integer.\n\n        Args:\n            prefixlen_str: A decimal string containing the prefix length.\n\n        Returns:\n            The prefix length as an integer.\n\n        Raises:\n            NetmaskValueError: If the input is malformed or out of range.\n\n        \"\"\"\n        try:\n            if not _BaseV4._DECIMAL_DIGITS.issuperset(prefixlen_str):\n                raise ValueError\n            prefixlen = int(prefixlen_str)\n            if not (0 <= prefixlen <= self._max_prefixlen):\n               raise ValueError\n        except ValueError:\n            raise NetmaskValueError('%s is not a valid prefix length' %\n                                    prefixlen_str)\n        return prefixlen"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prefix_from_ip_string(self, ip_str):\n        # Parse the netmask/hostmask like an IP address.\n        try:\n            ip_int = self._ip_int_from_string(ip_str)\n        except AddressValueError:\n            raise NetmaskValueError('%s is not a valid netmask' % ip_str)\n\n        # Try matching a netmask (this would be /1*0*/ as a bitwise regexp).\n        # Note that the two ambiguous cases (all-ones and all-zeroes) are\n        # treated as netmasks.\n        try:\n            return self._prefix_from_ip_int(ip_int)\n        except NetmaskValueError:\n            pass\n\n        # Invert the bits, and try matching a /0+1+/ hostmask instead.\n        ip_int ^= self._ALL_ONES\n        try:\n            return self._prefix_from_ip_int(ip_int)\n        except NetmaskValueError:\n            raise NetmaskValueError('%s is not a valid netmask' % ip_str)", "response": "Turn a netmask or hostmask string into a prefix length."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over the subnets of the current netblock.", "response": "def iter_subnets(self, prefixlen_diff=1, new_prefix=None):\n        \"\"\"The subnets which join to make the current subnet.\n\n        In the case that self contains only one IP\n        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128\n        for IPv6), return a list with just ourself.\n\n        Args:\n            prefixlen_diff: An integer, the amount the prefix length\n              should be increased by. This should not be set if\n              new_prefix is also set.\n            new_prefix: The desired new prefix length. This must be a\n              larger number (smaller prefix) than the existing prefix.\n              This should not be set if prefixlen_diff is also set.\n\n        Returns:\n            An iterator of IPv(4|6) objects.\n\n        Raises:\n            ValueError: The prefixlen_diff is too small or too large.\n                OR\n            prefixlen_diff and new_prefix are both set or new_prefix\n              is a smaller number than the current prefix (smaller\n              number means a larger network)\n\n        \"\"\"\n        if self._prefixlen == self._max_prefixlen:\n            yield self\n            return\n\n        if new_prefix is not None:\n            if new_prefix < self._prefixlen:\n                raise ValueError('new prefix must be longer')\n            if prefixlen_diff != 1:\n                raise ValueError('cannot set prefixlen_diff and new_prefix')\n            prefixlen_diff = new_prefix - self._prefixlen\n\n        if prefixlen_diff < 0:\n            raise ValueError('prefix length diff must be > 0')\n        new_prefixlen = self._prefixlen + prefixlen_diff\n\n        if new_prefixlen > self._max_prefixlen:\n            raise ValueError(\n                'prefix length diff %d is invalid for netblock %s' % (\n                    new_prefixlen, str(self)))\n\n        first = IPNetwork('%s/%s' % (str(self.network),\n                                     str(self._prefixlen + prefixlen_diff)),\n                         version=self._version)\n\n        yield first\n        current = first\n        while True:\n            broadcast = current.broadcast\n            if broadcast == self.broadcast:\n                return\n            new_addr = IPAddress(int(broadcast) + 1, version=self._version)\n            current = IPNetwork('%s/%s' % (str(new_addr), str(new_prefixlen)),\n                                version=self._version)\n\n            yield current"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the network object with the host bits masked out.", "response": "def masked(self):\n        \"\"\"Return the network object with the host bits masked out.\"\"\"\n        return IPNetwork('%s/%d' % (self.network, self._prefixlen),\n                         version=self._version)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a supernet containing the current network.", "response": "def supernet(self, prefixlen_diff=1, new_prefix=None):\n        \"\"\"The supernet containing the current network.\n\n        Args:\n            prefixlen_diff: An integer, the amount the prefix length of\n              the network should be decreased by.  For example, given a\n              /24 network and a prefixlen_diff of 3, a supernet with a\n              /21 netmask is returned.\n\n        Returns:\n            An IPv4 network object.\n\n        Raises:\n            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have a\n              negative prefix length.\n                OR\n            If prefixlen_diff and new_prefix are both set or new_prefix is a\n              larger number than the current prefix (larger number means a\n              smaller network)\n\n        \"\"\"\n        if self._prefixlen == 0:\n            return self\n\n        if new_prefix is not None:\n            if new_prefix > self._prefixlen:\n                raise ValueError('new prefix must be shorter')\n            if prefixlen_diff != 1:\n                raise ValueError('cannot set prefixlen_diff and new_prefix')\n            prefixlen_diff = self._prefixlen - new_prefix\n\n\n        if self.prefixlen - prefixlen_diff < 0:\n            raise ValueError(\n                'current prefixlen is %d, cannot have a prefixlen_diff of %d' %\n                (self.prefixlen, prefixlen_diff))\n        return IPNetwork('%s/%s' % (str(self.network),\n                                    str(self.prefixlen - prefixlen_diff)),\n                         version=self._version)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ip_int_from_string(self, ip_str):\n        octets = ip_str.split('.')\n        if len(octets) != 4:\n            raise AddressValueError(ip_str)\n\n        packed_ip = 0\n        for oc in octets:\n            try:\n                packed_ip = (packed_ip << 8) | self._parse_octet(oc)\n            except ValueError:\n                raise AddressValueError(ip_str)\n        return packed_ip", "response": "Turn the given string into an integer for comparison."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_octet(self, octet_str):\n        # Whitelist the characters, since int() allows a lot of bizarre stuff.\n        if not self._DECIMAL_DIGITS.issuperset(octet_str):\n            raise ValueError\n        octet_int = int(octet_str, 10)\n        # Disallow leading zeroes, because no clear standard exists on\n        # whether these should be interpreted as decimal or octal.\n        if octet_int > 255 or (octet_str[0] == '0' and len(octet_str) > 1):\n            raise ValueError\n        return octet_int", "response": "Convert a decimal octet into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a 32 - bit integer into a dotted decimal notation.", "response": "def _string_from_ip_int(self, ip_int):\n        \"\"\"Turns a 32-bit integer into dotted decimal notation.\n\n        Args:\n            ip_int: An integer, the IP address.\n\n        Returns:\n            The IP address as a string in dotted decimal notation.\n\n        \"\"\"\n        octets = []\n        for _ in xrange(4):\n            octets.insert(0, str(ip_int & 0xFF))\n            ip_int >>= 8\n        return '.'.join(octets)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ip_int_from_string(self, ip_str):\n        parts = ip_str.split(':')\n\n        # An IPv6 address needs at least 2 colons (3 parts).\n        if len(parts) < 3:\n            raise AddressValueError(ip_str)\n\n        # If the address has an IPv4-style suffix, convert it to hexadecimal.\n        if '.' in parts[-1]:\n            ipv4_int = IPv4Address(parts.pop())._ip\n            parts.append('%x' % ((ipv4_int >> 16) & 0xFFFF))\n            parts.append('%x' % (ipv4_int & 0xFFFF))\n\n        # An IPv6 address can't have more than 8 colons (9 parts).\n        if len(parts) > self._HEXTET_COUNT + 1:\n            raise AddressValueError(ip_str)\n\n        # Disregarding the endpoints, find '::' with nothing in between.\n        # This indicates that a run of zeroes has been skipped.\n        try:\n            skip_index, = (\n                [i for i in xrange(1, len(parts) - 1) if not parts[i]] or\n                [None])\n        except ValueError:\n            # Can't have more than one '::'\n            raise AddressValueError(ip_str)\n\n        # parts_hi is the number of parts to copy from above/before the '::'\n        # parts_lo is the number of parts to copy from below/after the '::'\n        if skip_index is not None:\n            # If we found a '::', then check if it also covers the endpoints.\n            parts_hi = skip_index\n            parts_lo = len(parts) - skip_index - 1\n            if not parts[0]:\n                parts_hi -= 1\n                if parts_hi:\n                    raise AddressValueError(ip_str)  # ^: requires ^::\n            if not parts[-1]:\n                parts_lo -= 1\n                if parts_lo:\n                    raise AddressValueError(ip_str)  # :$ requires ::$\n            parts_skipped = self._HEXTET_COUNT - (parts_hi + parts_lo)\n            if parts_skipped < 1:\n                raise AddressValueError(ip_str)\n        else:\n            # Otherwise, allocate the entire address to parts_hi.  The endpoints\n            # could still be empty, but _parse_hextet() will check for that.\n            if len(parts) != self._HEXTET_COUNT:\n                raise AddressValueError(ip_str)\n            parts_hi = len(parts)\n            parts_lo = 0\n            parts_skipped = 0\n\n        try:\n            # Now, parse the hextets into a 128-bit integer.\n            ip_int = 0L\n            for i in xrange(parts_hi):\n                ip_int <<= 16\n                ip_int |= self._parse_hextet(parts[i])\n            ip_int <<= 16 * parts_skipped\n            for i in xrange(-parts_lo, 0):\n                ip_int <<= 16\n                ip_int |= self._parse_hextet(parts[i])\n            return ip_int\n        except ValueError:\n            raise AddressValueError(ip_str)", "response": "Turn an IPv6 string into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an IPv6 hextet string into an integer.", "response": "def _parse_hextet(self, hextet_str):\n        \"\"\"Convert an IPv6 hextet string into an integer.\n\n        Args:\n            hextet_str: A string, the number to parse.\n\n        Returns:\n            The hextet as an integer.\n\n        Raises:\n            ValueError: if the input isn't strictly a hex number from [0..FFFF].\n\n        \"\"\"\n        # Whitelist the characters, since int() allows a lot of bizarre stuff.\n        if not self._HEX_DIGITS.issuperset(hextet_str):\n            raise ValueError\n        if len(hextet_str) > 4:\n          raise ValueError\n        hextet_int = int(hextet_str, 16)\n        if hextet_int > 0xFFFF:\n            raise ValueError\n        return hextet_int"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompressing a list of hextets.", "response": "def _compress_hextets(self, hextets):\n        \"\"\"Compresses a list of hextets.\n\n        Compresses a list of strings, replacing the longest continuous\n        sequence of \"0\" in the list with \"\" and adding empty strings at\n        the beginning or at the end of the string such that subsequently\n        calling \":\".join(hextets) will produce the compressed version of\n        the IPv6 address.\n\n        Args:\n            hextets: A list of strings, the hextets to compress.\n\n        Returns:\n            A list of strings.\n\n        \"\"\"\n        best_doublecolon_start = -1\n        best_doublecolon_len = 0\n        doublecolon_start = -1\n        doublecolon_len = 0\n        for index in range(len(hextets)):\n            if hextets[index] == '0':\n                doublecolon_len += 1\n                if doublecolon_start == -1:\n                    # Start of a sequence of zeros.\n                    doublecolon_start = index\n                if doublecolon_len > best_doublecolon_len:\n                    # This is the longest sequence of zeros so far.\n                    best_doublecolon_len = doublecolon_len\n                    best_doublecolon_start = doublecolon_start\n            else:\n                doublecolon_len = 0\n                doublecolon_start = -1\n\n        if best_doublecolon_len > 1:\n            best_doublecolon_end = (best_doublecolon_start +\n                                    best_doublecolon_len)\n            # For zeros at the end of the address.\n            if best_doublecolon_end == len(hextets):\n                hextets += ['']\n            hextets[best_doublecolon_start:best_doublecolon_end] = ['']\n            # For zeros at the beginning of the address.\n            if best_doublecolon_start == 0:\n                hextets = [''] + hextets\n\n        return hextets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning a 128 - bit integer into hexadecimal notation.", "response": "def _string_from_ip_int(self, ip_int=None):\n        \"\"\"Turns a 128-bit integer into hexadecimal notation.\n\n        Args:\n            ip_int: An integer, the IP address.\n\n        Returns:\n            A string, the hexadecimal representation of the address.\n\n        Raises:\n            ValueError: The address is bigger than 128 bits of all ones.\n\n        \"\"\"\n        if not ip_int and ip_int != 0:\n            ip_int = int(self._ip)\n\n        if ip_int > self._ALL_ONES:\n            raise ValueError('IPv6 address is too large')\n\n        hex_str = '%032x' % ip_int\n        hextets = []\n        for x in range(0, 32, 4):\n            hextets.append('%x' % int(hex_str[x:x+4], 16))\n\n        hextets = self._compress_hextets(hextets)\n        return ':'.join(hextets)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _explode_shorthand_ip_string(self):\n        if isinstance(self, _BaseNet):\n            ip_str = str(self.ip)\n        else:\n            ip_str = str(self)\n\n        ip_int = self._ip_int_from_string(ip_str)\n        parts = []\n        for i in xrange(self._HEXTET_COUNT):\n            parts.append('%04x' % (ip_int & 0xFFFF))\n            ip_int >>= 16\n        parts.reverse()\n        if isinstance(self, _BaseNet):\n            return '%s/%d' % (':'.join(parts), self.prefixlen)\n        return ':'.join(parts)", "response": "Explode a shortened IPv6 address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntest if the address is otherwise IETF reserved.", "response": "def is_reserved(self):\n        \"\"\"Test if the address is otherwise IETF reserved.\n\n        Returns:\n            A boolean, True if the address is within one of the\n            reserved IPv6 Network ranges.\n\n        \"\"\"\n        return (self in IPv6Network('::/8') or\n                self in IPv6Network('100::/8') or\n                self in IPv6Network('200::/7') or\n                self in IPv6Network('400::/6') or\n                self in IPv6Network('800::/5') or\n                self in IPv6Network('1000::/4') or\n                self in IPv6Network('4000::/3') or\n                self in IPv6Network('6000::/3') or\n                self in IPv6Network('8000::/3') or\n                self in IPv6Network('A000::/3') or\n                self in IPv6Network('C000::/3') or\n                self in IPv6Network('E000::/4') or\n                self in IPv6Network('F000::/5') or\n                self in IPv6Network('F800::/6') or\n                self in IPv6Network('FE00::/9'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noutputting the requests response JSON and status code and error string.", "response": "def _return_response_and_status_code(response):\n    \"\"\" Output the requests response JSON and status code\n\n    :rtype : dict\n    :param response: requests response object\n    :return: dict containing the JSON response and/or the status code with error string.\n    \"\"\"\n\n    result_codes = {\n        \"-11\": \"No matching data to API Key API Key error\",\n        \"-12\": \"No authority to use No authority to use\",\n        \"-13\": \"Expired API Key API Key expired\",\n        \"-14\": \"Over the daily request limit Request limit per daily exceeded\",\n        \"-15\": \"Over the hourly request limit Request limit per hour exceeded\",\n        \"-1\": \"Invalid Parameters / Invalid Request\",\n        \"-25\": \"File Upload Quota Limit Error in file size to upload\",\n        \"-2\": \"Invalid URL Error in URL type\",\n        \"-31\": \"Invalid type of hash error in Hash type\",\n        \"-400\": \"No file attached No file attached\",\n        \"-404\": \"No result No result\",\n        \"-415\": \"Ectype of upload form is not multipart/form-data Error in upload form type\",\n        \"-41\": \"Invalid type of url Error in URL type\",\n        \"-500\": \"Internal Server Error System error\",\n        \"-51\": \"Invalid type of ip Error in IP type\",\n        \"-61\": \"Invalid type of hostname Error in Hostname type\",\n        \"0\": \"Data is not exist No information found in DB.\",\n        \"1\": \"Data exists / Analysis request succeeded /Successful upload (new)\",\n        \"2\": \"Analysis in progress / Successful upload (duplicated)\",\n        \"-999\": \"Error\"\n\n    }\n\n    results = response.json()\n\n    result_code = str(response.json().get('result_code', '-999'))\n    result_message = result_codes[result_code]\n    return dict(results=results, response_code=result_code, result_message=result_message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scan_file(self, this_file, this_filename):\n        params = {\n            'api_key': self.api_key,\n            'filename': this_filename\n        }\n        try:\n            files = {'file': (this_file.name, open(this_file.name, 'rb'), 'application/octet-stream')}\n        except TypeError as e:\n            return dict(error=e.message)\n\n        try:\n            response = requests.post(self.base + 'file/upload', files=files, data=params)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        return _return_response_and_status_code(response)", "response": "Submit a file to be scanned by Malwares."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the scan results for a file.", "response": "def get_file_report(self, this_hash):\n        \"\"\" Get the scan results for a file.\n\n        :param this_hash: The md5/sha1/sha256/scan_ids hash of the file whose dynamic behavioural report you want to\n                            retrieve or scan_ids from a previous call to scan_file.\n        :return:\n        \"\"\"\n        params = {'api_key': self.api_key, 'hash': this_hash}\n\n        try:\n            response_info = requests.get(self.base + 'file/mwsinfo', params=params)\n            response_additional = requests.get(self.base + 'file/addinfo', params=params)\n        except requests.RequestException as e:\n            return dict(error=e.message)\n\n        ri = _return_response_and_status_code(response_info)\n        ra = _return_response_and_status_code(response_additional)\n\n        if ri['response_code'] == '1' and ra['response_code'] == '1':  # both ok\n            both = ri['results'].copy()\n            both.update(ra['results'])\n            response = dict(results=both, response_code=1)\n        elif ri['response_code'] == '1' and ra['response_code'] == '0':  # advance non exists but standard ok\n            response = ri\n        elif ri['response_code'] == '2':  # main is still loading\n            response = dict(results={}, response_code=2)\n        else:  # error generic\n            response = ri\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __prepare_body(self, search_value, search_type='url'):\n        body = {\n            'client': {\n                'clientId': self.client_id,\n                'clientVersion': self.client_version\n            }\n        }\n        if search_type == 'url':\n            data = {\n                'threatTypes': [\n                    'MALWARE', 'SOCIAL_ENGINEERING', 'UNWANTED_SOFTWARE', 'POTENTIALLY_HARMFUL_APPLICATION'\n                ],\n                'platformTypes': ['ANY_PLATFORM', 'ALL_PLATFORMS', 'WINDOWS', 'LINUX', 'OSX', 'ANDROID', 'IOS'],\n                'threatEntryTypes': ['URL']\n            }\n        elif search_type == 'ip':\n            data = {\n                'threatTypes': ['MALWARE'],\n                'platformTypes': ['WINDOWS', 'LINUX', 'OSX'],\n                'threatEntryTypes': ['IP_RANGE']\n            }\n        else:\n            raise SearchTypeNotSupportedError('Currently supported search types are \\'url\\' and \\'ip\\'.')\n\n        # TODO: Only found threatEntry 'url' in the docs. What to use for ip_range?\n        data['threatEntries'] = [{'url': search_value}]\n        body['threatInfo'] = data\n        return body", "response": "Prepares the http body for querying safebrowsing api."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_rpdns(self):\n        results = requests.get('https://freeapi.robtex.com/pdns/reverse/{}'.format(self.get_data())).text.split('\\r\\n')\n        jsonresults = []\n        for idx, r in enumerate(results):\n            if len(r) > 0:\n                jsonresults.append(json.loads(r))\n        return jsonresults", "response": "Queries robtex reverse pdns - api using an ip as parameter\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef module_summary(self):\n        suspicious = 0\n        malicious = 0\n        count = 0\n        cve = False\n        taxonomies = []\n\n        for section in self.results:\n            if section['submodule_section_content']['class'] == 'malicious':\n                malicious += 1\n            elif section['submodule_section_content']['class'] == 'suspicious':\n                suspicious += 1\n\n            if 'CVE' in section['submodule_section_content']['clsid_description']:\n                cve = True\n            count += 1\n\n        if malicious > 0:\n            taxonomies.append(self.build_taxonomy('malicious', 'FileInfo', 'MaliciousRTFObjects', malicious))\n\n        if suspicious > 0:\n            taxonomies.append(self.build_taxonomy('suspicious', 'FileInfo', 'SuspiciousRTFObjects', suspicious))\n\n        if cve:\n            taxonomies.append(self.build_taxonomy('malicious', 'FileInfo', 'PossibleCVEExploit', 'True'))\n\n        taxonomies.append(self.build_taxonomy('info', 'FileInfo', 'RTFObjects', count))\n\n        self.summary['taxonomies'] = taxonomies\n        return self.summary", "response": "Count the malicious and suspicious sections check for CVE description"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_tor_node(self, ip):\n        data = {}\n        tmp = {}\n        present = datetime.utcnow().replace(tzinfo=pytz.utc)\n        for line in self._get_raw_data().splitlines():\n            params = line.split(' ')\n            if params[0] == 'ExitNode':\n                tmp['node'] = params[1]\n            elif params[0] == 'ExitAddress':\n                tmp['last_status'] = params[2] + 'T' + params[3] + '+0000'\n                last_status = parse(tmp['last_status'])\n                if (self.delta is None or\n                   (present - last_status) < self.delta):\n                    data[params[1]] = tmp\n                tmp = {}\n            else:\n                pass\n        return data.get(ip, {})", "response": "Search an IP address to see if it is a tor exit node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches hosts using its ipv4 address as string", "response": "def search_hosts(self, ip):\n        \"\"\"\n        Searches for a host using its ipv4 address\n\n        :param ip: ipv4 address as string\n        :type ip: str\n        :return: dict\n        \"\"\"\n        c = CensysIPv4(api_id=self.__uid, api_secret=self.__api_key)\n        return c.view(ip)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for a specific certificate using its hash", "response": "def search_certificate(self, hash):\n        \"\"\"\n        Searches for a specific certificate using its hash\n\n        :param hash: certificate hash\n        :type hash: str\n        :return: dict\n        \"\"\"\n        c = CensysCertificates(api_id=self.__uid, api_secret=self.__api_key)\n        return c.view(hash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_website(self, dom):\n        c = CensysWebsites(api_id=self.__uid, api_secret=self.__api_key)\n        return c.view(dom)", "response": "Search for a website using the domainname\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_taxonomy(self, level, namespace, predicate, value):\n        return {\n                'level': level,\n                'namespace': namespace,\n                'predicate': predicate,\n                'value': value\n                }", "response": "Build a taxonomy from the level namespace predicate and value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_data(self, datatype, data):\n        result = {}\n        params = StopforumspamClient._set_payload(datatype, data)\n        response = self.client.get(\n            'https://api.stopforumspam.org/api',\n            params=params, proxies=self.proxies)\n        response.raise_for_status()\n        report = response.json()\n        if report['success']:\n            data = report[StopforumspamClient._type_conversion[datatype]]\n            result = self._data_conversion(data)\n        else:\n            pass\n        return result", "response": "Look for an IP address or email address in the spammer database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new factory container.", "response": "def construct(cls, faker, path_to_factories=None):\n        \"\"\"\n        Create a new factory container.\n\n        :param faker: A faker generator instance\n        :type faker: faker.Generator\n\n        :param path_to_factories: The path to factories\n        :type path_to_factories: str\n\n        :rtype: Factory\n        \"\"\"\n        factory = faker.__class__()\n\n        if path_to_factories is not None and os.path.isdir(path_to_factories):\n            for filename in os.listdir(path_to_factories):\n                if os.path.isfile(filename):\n                    cls._resolve(path_to_factories, filename)\n\n        return factory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef define(self, klass, name=\"default\"):\n\n        def decorate(func):\n            @wraps(func)\n            def wrapped(*args, **kwargs):\n                return func(*args, **kwargs)\n\n            self.register(klass, func, name=name)\n\n            return wrapped\n\n        return decorate", "response": "Define a class with a given set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a class with a function.", "response": "def register(self, klass, callback, name=\"default\"):\n        \"\"\"\n        Register a class with a function.\n\n        :param klass: The class\n        :type klass: class\n\n        :param callback: The callable\n        :type callback: callable\n\n        :param name: The short name\n        :type name: str\n        \"\"\"\n        if klass not in self._definitions:\n            self._definitions[klass] = {}\n\n        self._definitions[klass][name] = callback"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_as(self, klass, name, callback):\n        return self.register(klass, callback, name)", "response": "Register a class with a function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an instance of the given model and type and persist it to the database.", "response": "def create_as(self, klass, name, **attributes):\n        \"\"\"\n        Create an instance of the given model and type and persist it to the database.\n\n        :param klass: The class\n        :type klass: class\n\n        :param name: The type\n        :type name: str\n\n        :param attributes: The instance attributes\n        :type attributes: dict\n\n        :return: mixed\n        \"\"\"\n        return self.of(klass, name).create(**attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_as(self, klass, name, **attributes):\n        return self.of(klass, name).make(**attributes)", "response": "Create an instance of the given model and type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the raw attribute dict for a given named model.", "response": "def raw_of(self, klass, name, **attributes):\n        \"\"\"\n        Get the raw attribute dict for a given named model.\n\n        :param klass: The class\n        :type klass: class\n\n        :param name: The type\n        :type name: str\n\n        :param attributes: The instance attributes\n        :type attributes: dict\n\n        :return: dict\n        \"\"\"\n        return self.raw(klass, _name=name, **attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the raw attribute dict for a given named model.", "response": "def raw(self, klass, _name=\"default\", **attributes):\n        \"\"\"\n        Get the raw attribute dict for a given named model.\n\n        :param klass: The class\n        :type klass: class\n\n        :param _name: The type\n        :type _name: str\n\n        :param attributes: The instance attributes\n        :type attributes: dict\n\n        :return: dict\n        \"\"\"\n        raw = self._definitions[klass][_name](self._faker)\n\n        raw.update(attributes)\n\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a factory builder for the given model.", "response": "def of(self, klass, name=\"default\"):\n        \"\"\"\n        Create a builder for the given model.\n\n        :param klass: The class\n        :type klass: class\n\n        :param name: The type\n        :type name: str\n\n        :return: orator.orm.factory_builder.FactoryBuilder\n        \"\"\"\n        return FactoryBuilder(\n            klass, name, self._definitions, self._faker, self._resolver\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a factory builder with a specified amount.", "response": "def build(self, klass, name=\"default\", amount=None):\n        \"\"\"\n        Makes a factory builder with a specified amount.\n\n        :param klass: The class\n        :type klass: class\n\n        :param name: The type\n        :type name: str\n\n        :param amount: The number of models to create\n        :type amount: int\n\n        :return: mixed\n        \"\"\"\n        if amount is None:\n            if isinstance(name, int):\n                amount = name\n                name = \"default\"\n            else:\n                amount = 1\n\n        return self.of(klass, name).times(amount)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resolve(cls, path, factory_file):\n        variables = {}\n\n        name = factory_file\n        factory_file = os.path.join(path, factory_file)\n\n        with open(factory_file) as fh:\n            exec(fh.read(), {}, variables)\n\n        klass = variables[inflection.camelize(name)]\n\n        instance = klass()\n\n        return instance", "response": "Resolve a migration instance from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_relation(self, models, relation):\n        for model in models:\n            model.set_relation(\n                relation, Result(self._related.new_collection(), self, model)\n            )\n\n        return models", "response": "Initialize the relation on a set of models."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmatches the eagerly loaded results to their parents.", "response": "def match(self, models, results, relation):\n        \"\"\"\n        Match the eagerly loaded results to their parents.\n\n        :type models: list\n        :type results: Collection\n        :type relation:  str\n        \"\"\"\n        return self.match_many(models, results, relation)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompiling a rename column command.", "response": "def compile_rename_column(self, blueprint, command, connection):\n        \"\"\"\n        Compile a rename column command.\n\n        :param blueprint: The blueprint\n        :type blueprint: Blueprint\n\n        :param command: The command\n        :type command: Fluent\n\n        :param connection: The connection\n        :type connection: orator.connections.Connection\n\n        :rtype: list\n        \"\"\"\n        schema = connection.get_schema_manager()\n\n        table = self.get_table_prefix() + blueprint.get_table()\n\n        column = connection.get_column(table, command.from_)\n\n        table_diff = self._get_renamed_diff(blueprint, command, column, schema)\n\n        return schema.get_database_platform().get_alter_table_sql(table_diff)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_renamed_diff(self, blueprint, command, column, schema):\n        table_diff = self._get_table_diff(blueprint, schema)\n\n        return self._set_renamed_columns(table_diff, command, column)", "response": "Get a new column instance with the new column name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the renamed columns on the table diff.", "response": "def _set_renamed_columns(self, table_diff, command, column):\n        \"\"\"\n        Set the renamed columns on the table diff.\n\n        :rtype: orator.dbal.TableDiff\n        \"\"\"\n        new_column = Column(command.to, column.get_type(), column.to_dict())\n\n        table_diff.renamed_columns = {command.from_: new_column}\n\n        return table_diff"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the command with the given name.", "response": "def _get_command_by_name(self, blueprint, name):\n        \"\"\"\n        Get the primary key command it it exists.\n        \"\"\"\n        commands = self._get_commands_by_name(blueprint, name)\n\n        if len(commands):\n            return commands[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_commands_by_name(self, blueprint, name):\n        return list(filter(lambda value: value.name == name, blueprint.get_commands()))", "response": "Get all of the commands with a given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a prefix to a list of values.", "response": "def prefix_list(self, prefix, values):\n        \"\"\"\n        Add a prefix to a list of values.\n        \"\"\"\n        return list(map(lambda value: prefix + \" \" + value, values))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a value so that it can be used in default clauses.", "response": "def _get_default_value(self, value):\n        \"\"\"\n        Format a value so that it can be used in \"default\" clauses.\n        \"\"\"\n        if isinstance(value, QueryExpression):\n            return value\n\n        if isinstance(value, bool):\n            return \"'%s'\" % int(value)\n\n        return \"'%s'\" % value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_change(self, blueprint, command, connection):\n        schema = connection.get_schema_manager()\n\n        table_diff = self._get_changed_diff(blueprint, schema)\n\n        if table_diff:\n            sql = schema.get_database_platform().get_alter_table_sql(table_diff)\n\n            if isinstance(sql, list):\n                return sql\n\n            return [sql]\n\n        return []", "response": "Compile a change column command into a series of SQL statements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_changed_diff(self, blueprint, schema):\n        table = schema.list_table_details(\n            self.get_table_prefix() + blueprint.get_table()\n        )\n\n        return Comparator().diff_table(\n            table, self._get_table_with_column_changes(blueprint, table)\n        )", "response": "Get the table diffrence for the given changes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_table_with_column_changes(self, blueprint, table):\n        table = table.clone()\n\n        for fluent in blueprint.get_changed_columns():\n            column = self._get_column_for_change(table, fluent)\n\n            for key, value in fluent.get_attributes().items():\n                option = self._map_fluent_option(key)\n\n                if option is not None:\n                    method = \"set_%s\" % option\n\n                    if hasattr(column, method):\n                        getattr(column, method)(self._map_fluent_value(option, value))\n\n        return table", "response": "Get a copy of the given table after making the column changes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the column instance for a column change.", "response": "def _get_column_for_change(self, table, fluent):\n        \"\"\"\n        Get the column instance for a column change.\n\n        :type table: orator.dbal.table.Table\n\n        :rtype: orator.dbal.column.Column\n        \"\"\"\n        return table.change_column(\n            fluent.name, self._get_column_change_options(fluent)\n        ).get_column(fluent.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the column change options.", "response": "def _get_column_change_options(self, fluent):\n        \"\"\"\n        Get the column change options.\n        \"\"\"\n        options = {\n            \"name\": fluent.name,\n            \"type\": self._get_dbal_column_type(fluent.type),\n            \"default\": fluent.get(\"default\"),\n        }\n\n        if fluent.type in [\"string\"]:\n            options[\"length\"] = fluent.length\n\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_dbal_column_type(self, type_):\n        type_ = type_.lower()\n\n        if type_ == \"big_integer\":\n            type_ = \"bigint\"\n        elif type == \"small_integer\":\n            type_ = \"smallint\"\n        elif type_ in [\"medium_text\", \"long_text\"]:\n            type_ = \"text\"\n\n        return type_", "response": "Get the dbal column type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the keys for a save update query.", "response": "def _set_keys_for_save_query(self, query):\n        \"\"\"\n        Set the keys for a save update query.\n\n        :param query: A Builder instance\n        :type query: orator.orm.Builder\n\n        :return: The Builder instance\n        :rtype: orator.orm.Builder\n        \"\"\"\n        query.where(self.__foreign_key, self.get_attribute(self.__foreign_key))\n\n        return query.where(self.__other_key, self.get_attribute(self.__other_key))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the query builder for a delete operation on the pivot.", "response": "def _get_delete_query(self):\n        \"\"\"\n        Get the query builder for a delete operation on the pivot.\n\n        :rtype: orator.orm.Builder\n        \"\"\"\n        foreign = self.get_attribute(self.__foreign_key)\n\n        query = self.new_query().where(self.__foreign_key, foreign)\n\n        return query.where(self.__other_key, self.get_attribute(self.__other_key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_pivot_keys(self, foreign_key, other_key):\n        self.__foreign_key = foreign_key\n        self.__other_key = other_key\n\n        return self", "response": "Set the key names for the pivot model instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a collection of models and persist them to the database.", "response": "def create(self, **attributes):\n        \"\"\"\n        Create a collection of models and persist them to the database.\n\n        :param attributes: The models attributes\n        :type attributes: dict\n\n        :return: mixed\n        \"\"\"\n        results = self.make(**attributes)\n\n        if self._amount == 1:\n            if self._resolver:\n                results.set_connection_resolver(self._resolver)\n\n            results.save()\n        else:\n            if self._resolver:\n                results.each(lambda r: r.set_connection_resolver(self._resolver))\n\n            for result in results:\n                result.save()\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make(self, **attributes):\n        if self._amount == 1:\n            return self._make_instance(**attributes)\n        else:\n            results = []\n\n            for _ in range(self._amount):\n                results.append(self._make_instance(**attributes))\n\n            return Collection(results)", "response": "Create a collection of models."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake an instance of the model with the given attributes.", "response": "def _make_instance(self, **attributes):\n        \"\"\"\n        Make an instance of the model with the given attributes.\n\n        :param attributes: The models attributes\n        :type attributes: dict\n\n        :return: mixed\n        \"\"\"\n        definition = self._definitions[self._klass][self._name](self._faker)\n        definition.update(attributes)\n\n        instance = self._klass()\n        instance.force_fill(**definition)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(wrapped):\n\n    @wraps(wrapped)\n    def _run(self, query, bindings=None, *args, **kwargs):\n        self._reconnect_if_missing_connection()\n\n        start = time.time()\n        try:\n            result = wrapped(self, query, bindings, *args, **kwargs)\n        except Exception as e:\n            result = self._try_again_if_caused_by_lost_connection(\n                e, query, bindings, wrapped\n            )\n\n        t = self._get_elapsed_time(start)\n        self.log_query(query, bindings, t)\n\n        return result\n\n    return _run", "response": "A query decorator that wraps a query method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbegins a fluent query", "response": "def query(self):\n        \"\"\"\n        Begin a fluent query\n\n        :return: A QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        query = self._builder_class(\n            self,\n            self._query_grammar,\n            self._post_processor,\n            **self._builder_default_kwargs\n        )\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef where_pivot(self, column, operator=None, value=None, boolean=\"and\"):\n        self._pivot_wheres.append([column, operator, value, boolean])\n\n        return self._query.where(\n            \"%s.%s\" % (self._table, column), operator, value, boolean\n        )", "response": "Sets a where clause for a pivot table column."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets an or where clause for a pivot table column.", "response": "def or_where_pivot(self, column, operator=None, value=None):\n        \"\"\"\n        Set an or where clause for a pivot table column.\n\n        :param column: The column of the where clause, can also be a QueryBuilder instance for sub where\n        :type column: str|Builder\n\n        :param operator: The operator of the where clause\n        :type operator: str\n\n        :param value: The value of the where clause\n        :type value: mixed\n\n        :return: self\n        :rtype: BelongsToMany\n        \"\"\"\n        return self.where_pivot(column, operator, value, \"or\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the query and get the first result.", "response": "def first(self, columns=None):\n        \"\"\"\n        Execute the query and get the first result.\n\n        :type columns: list\n        \"\"\"\n        self._query.take(1)\n\n        results = self.get(columns)\n\n        if len(results) > 0:\n            return results.first()\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the query and get the first result or raise an exception.", "response": "def first_or_fail(self, columns=None):\n        \"\"\"\n        Execute the query and get the first result or raise an exception.\n\n        :type columns: list\n\n        :raises: ModelNotFound\n        \"\"\"\n        model = self.first(columns)\n        if model is not None:\n            return model\n\n        raise ModelNotFound(self._parent.__class__)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the query as a select statement.", "response": "def get(self, columns=None):\n        \"\"\"\n        Execute the query as a \"select\" statement.\n\n        :type columns: list\n\n        :rtype: orator.Collection\n        \"\"\"\n        if columns is None:\n            columns = [\"*\"]\n\n        if self._query.get_query().columns:\n            columns = []\n\n        select = self._get_select_columns(columns)\n\n        models = self._query.add_select(*select).get_models()\n\n        self._hydrate_pivot_relation(models)\n\n        if len(models) > 0:\n            models = self._query.eager_load_relations(models)\n\n        return self._related.new_collection(models)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhydrates the pivot table relationship on the models.", "response": "def _hydrate_pivot_relation(self, models):\n        \"\"\"\n        Hydrate the pivot table relationship on the models.\n\n        :type models: list\n        \"\"\"\n        for model in models:\n            pivot = self.new_existing_pivot(self._clean_pivot_attributes(model))\n\n            model.set_relation(\"pivot\", pivot)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_relation_count_query(self, query, parent):\n        if parent.get_query().from__ == query.get_query().from__:\n            return self.get_relation_count_query_for_self_join(query, parent)\n\n        self._set_join(query)\n\n        return super(BelongsToMany, self).get_relation_count_query(query, parent)", "response": "Add the constraints for a relationship count query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_where(self):\n        foreign = self.get_foreign_key()\n\n        self._query.where(foreign, \"=\", self._parent.get_key())\n\n        return self", "response": "Sets the where clause for the relation query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_eager_constraints(self, models):\n        self._query.where_in(self.get_foreign_key(), self.get_keys(models))", "response": "Add constraints for an eager load of the relation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_dictionary(self, results):\n        foreign = self._foreign_key\n\n        dictionary = {}\n\n        for result in results:\n            key = getattr(result.pivot, foreign)\n            if key not in dictionary:\n                dictionary[key] = []\n\n            dictionary[key].append(result)\n\n        return dictionary", "response": "Builds the model dictionary keyed by the relation s foreign key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef touch(self):\n        key = self.get_related().get_key_name()\n\n        columns = self.get_related_fresh_update()\n\n        ids = self.get_related_ids()\n\n        if len(ids) > 0:\n            self.get_related().new_query().where_in(key, ids).update(columns)", "response": "Touch all of the related models of the relationship."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all of the IDs for the related models.", "response": "def get_related_ids(self):\n        \"\"\"\n        Get all of the IDs for the related models.\n\n        :rtype: list\n        \"\"\"\n        related = self.get_related()\n\n        full_key = related.get_qualified_key_name()\n\n        return self.get_query().select(full_key).lists(related.get_key_name())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_many(self, models, joinings=None):\n        if joinings is None:\n            joinings = {}\n\n        for key, model in enumerate(models):\n            self.save(model, joinings.get(key), False)\n\n        self.touch_if_touching()\n\n        return models", "response": "Save a list of new models and attach them to the parent model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_or_new(self, id, columns=None):\n        instance = self._query.find(id, columns)\n        if instance is None:\n            instance = self.get_related().new_instance()\n\n        return instance", "response": "Find a model by its primary key or return a new instance of the related model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the first related model record matching the attributes or create it.", "response": "def first_or_create(\n        self, _attributes=None, _joining=None, _touch=True, **attributes\n    ):\n        \"\"\"\n        Get the first related model record matching the attributes or create it.\n\n        :param attributes:  The attributes\n        :type attributes: dict\n\n        :rtype: Model\n        \"\"\"\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self._query.where(attributes).first()\n        if instance is None:\n            instance = self.create(attributes, _joining or {}, _touch)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating or update a related record matching the attributes and fill it with values.", "response": "def update_or_create(self, attributes, values=None, joining=None, touch=True):\n        \"\"\"\n        Create or update a related record matching the attributes, and fill it with values.\n\n        :param attributes: The attributes\n        :type attributes: dict\n\n        :param values: The values\n        :type values: dict\n\n        :rtype: Model\n        \"\"\"\n        if values is None:\n            values = {}\n\n        instance = self._query.where(attributes).first()\n\n        if instance is None:\n            return self.create(values, joining, touch)\n\n        instance.fill(**values)\n\n        instance.save({\"touch\": False})\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new instance of the related model.", "response": "def create(self, _attributes=None, _joining=None, _touch=True, **attributes):\n        \"\"\"\n        Create a new instance of the related model.\n\n        :param attributes: The attributes\n        :type attributes: dict\n\n        :rtype: orator.orm.Model\n        \"\"\"\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self._related.new_instance(attributes)\n\n        instance.save({\"touch\": False})\n\n        self.attach(instance.get_key(), _joining, _touch)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a list of new instances of the related model.", "response": "def create_many(self, records, joinings=None):\n        \"\"\"\n        Create a list of new instances of the related model.\n        \"\"\"\n        if joinings is None:\n            joinings = []\n\n        instances = []\n\n        for key, record in enumerate(records):\n            instances.append(self.create(record), joinings[key], False)\n\n        self.touch_if_touching()\n\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sync(self, ids, detaching=True):\n        changes = {\"attached\": [], \"detached\": [], \"updated\": []}\n\n        if isinstance(ids, Collection):\n            ids = ids.model_keys()\n\n        current = self._new_pivot_query().lists(self._other_key).all()\n\n        records = self._format_sync_list(ids)\n\n        detach = [x for x in current if x not in records.keys()]\n\n        if detaching and len(detach) > 0:\n            self.detach(detach)\n\n            changes[\"detached\"] = detach\n\n        changes.update(self._attach_new(records, current, False))\n\n        if len(changes[\"attached\"]) or len(changes[\"updated\"]):\n            self.touch_if_touching()\n\n        return changes", "response": "Sync the intermediate tables with a list of IDs or collection of models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the sync list so that it is keyed by ID.", "response": "def _format_sync_list(self, records):\n        \"\"\"\n        Format the sync list so that it is keyed by ID.\n        \"\"\"\n        results = {}\n\n        for attributes in records:\n            if not isinstance(attributes, dict):\n                id, attributes = attributes, {}\n            else:\n                id = list(attributes.keys())[0]\n                attributes = attributes[id]\n\n            results[id] = attributes\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attach(self, id, attributes=None, touch=True):\n        if isinstance(id, orator.orm.Model):\n            id = id.get_key()\n\n        query = self.new_pivot_statement()\n\n        if not isinstance(id, list):\n            id = [id]\n\n        query.insert(self._create_attach_records(id, attributes))\n\n        if touch:\n            self.touch_if_touching()", "response": "Attach a model to the parent."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a list of records to insert into the pivot table.", "response": "def _create_attach_records(self, ids, attributes):\n        \"\"\"\n        Create a list of records to insert into the pivot table.\n        \"\"\"\n        records = []\n\n        timed = self._has_pivot_column(self.created_at()) or self._has_pivot_column(\n            self.updated_at()\n        )\n\n        for key, value in enumerate(ids):\n            records.append(self._attacher(key, value, attributes, timed))\n\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _attacher(self, key, value, attributes, timed):\n        id, extra = self._get_attach_id(key, value, attributes)\n\n        record = self._create_attach_record(id, timed)\n\n        if extra:\n            record.update(extra)\n\n        return record", "response": "Create a full attachment record payload."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_attach_id(self, key, value, attributes):\n        if isinstance(value, dict):\n            key = list(value.keys())[0]\n            attributes.update(value[key])\n\n            return [key, attributes]\n\n        return value, attributes", "response": "Get the attach record ID and extra attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new pivot attachement record.", "response": "def _create_attach_record(self, id, timed):\n        \"\"\"\n        Create a new pivot attachement record.\n        \"\"\"\n        record = {}\n\n        record[self._foreign_key] = self._parent.get_key()\n\n        record[self._other_key] = id\n\n        if timed:\n            record = self._set_timestamps_on_attach(record)\n\n        return record"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_timestamps_on_attach(self, record, exists=False):\n        fresh = self._parent.fresh_timestamp()\n\n        if not exists and self._has_pivot_column(self.created_at()):\n            record[self.created_at()] = fresh\n\n        if self._has_pivot_column(self.updated_at()):\n            record[self.updated_at()] = fresh\n\n        return record", "response": "Set the creation an update timestamps on an attach record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detach(self, ids=None, touch=True):\n        if isinstance(ids, orator.orm.model.Model):\n            ids = ids.get_key()\n\n        if ids is None:\n            ids = []\n\n        query = self._new_pivot_query()\n\n        if not isinstance(ids, list):\n            ids = [ids]\n\n        if len(ids) > 0:\n            query.where_in(self._other_key, ids)\n\n        if touch:\n            self.touch_if_touching()\n\n        results = query.delete()\n\n        return results", "response": "Detach models from the relationship."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntouching if the parent model is being touched.", "response": "def touch_if_touching(self):\n        \"\"\"\n        Touch if the parent model is being touched.\n        \"\"\"\n        if self._touching_parent():\n            self.get_parent().touch()\n\n        if self.get_parent().touches(self._relation_name):\n            self.touch()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _new_pivot_query(self):\n        query = self.new_pivot_statement()\n\n        for where_args in self._pivot_wheres:\n            query.where(*where_args)\n\n        return query.where(self._foreign_key, self._parent.get_key())", "response": "Create a new query builder for the pivot table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new pivot model instance.", "response": "def new_pivot(self, attributes=None, exists=False):\n        \"\"\"\n        Create a new pivot model instance.\n        \"\"\"\n        pivot = self._related.new_pivot(self._parent, attributes, self._table, exists)\n\n        return pivot.set_pivot_keys(self._foreign_key, self._other_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef with_pivot(self, *columns):\n        columns = list(columns)\n\n        self._pivot_columns += columns\n\n        return self", "response": "Set the columns on the pivot table to retrieve."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef with_timestamps(self, created_at=None, updated_at=None):\n        if not created_at:\n            created_at = self.created_at()\n\n        if not updated_at:\n            updated_at = self.updated_at()\n\n        return self.with_pivot(created_at, updated_at)", "response": "Returns a new instance with the specified timestamps."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile a rename column command.", "response": "def compile_rename_column(self, blueprint, command, connection):\n        \"\"\"\n        Compile a rename column command.\n\n        :param blueprint: The blueprint\n        :type blueprint: Blueprint\n\n        :param command: The command\n        :type command: Fluent\n\n        :param connection: The connection\n        :type connection: orator.connections.Connection\n\n        :rtype: list\n        \"\"\"\n        table = self.get_table_prefix() + blueprint.get_table()\n\n        column = self.wrap(command.from_)\n\n        return \"ALTER TABLE %s RENAME COLUMN %s TO %s\" % (\n            table,\n            column,\n            self.wrap(command.to),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_create(self, blueprint, command, _):\n        columns = \", \".join(self._get_columns(blueprint))\n\n        return \"CREATE TABLE %s (%s)\" % (self.wrap_table(blueprint), columns)", "response": "Compile a create table command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_dbal_column_type(self, type_):\n        type_ = type_.lower()\n\n        if type_ == \"enum\":\n            return \"string\"\n\n        return super(PostgresSchemaGrammar, self)._get_dbal_column_type(type_)", "response": "Get the dbal column type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_where(self):\n        super(MorphToMany, self)._set_where()\n\n        self._query.where(\"%s.%s\" % (self._table, self._morph_type), self._morph_name)", "response": "Sets the where clause for the relation query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _new_pivot_query(self):\n        query = super(MorphToMany, self)._new_pivot_query()\n\n        return query.where(self._morph_type, self._morph_name)", "response": "Create a new query builder for the pivot table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_pivot(self, attributes=None, exists=False):\n        from .morph_pivot import MorphPivot\n\n        pivot = MorphPivot(self._parent, attributes, self._table, exists)\n\n        pivot.set_pivot_keys(self._foreign_key, self._other_key).set_morph_type(\n            self._morph_type\n        ).set_morph_name(self._morph_name)\n\n        return pivot", "response": "Create a new pivot model instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd constraints on the relation query.", "response": "def add_constraints(self):\n        \"\"\"\n        Set the base constraints on the relation query.\n\n        :rtype: None\n        \"\"\"\n        if self._constraints:\n            foreign_key = getattr(self._parent, self._foreign_key, None)\n            if foreign_key is None:\n                self._query = None\n            else:\n                table = self._related.get_table()\n\n                self._query.where(\n                    \"{}.{}\".format(table, self._other_key), \"=\", foreign_key\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds constraints for an eager load of the relation.", "response": "def add_eager_constraints(self, models):\n        \"\"\"\n        Set the constraints for an eager load of the relation.\n\n        :type models: list\n        \"\"\"\n        key = \"%s.%s\" % (self._related.get_table(), self._other_key)\n\n        self._query.where_in(key, self._get_eager_model_keys(models))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_eager_model_keys(self, models):\n        keys = []\n\n        for model in models:\n            value = getattr(model, self._foreign_key)\n\n            if value is not None and value not in keys:\n                keys.append(value)\n\n        if not len(keys):\n            return [0]\n\n        return keys", "response": "Gather the keys from a list of related models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the relation on a set of models.", "response": "def init_relation(self, models, relation):\n        \"\"\"\n        Initialize the relation on a set of models.\n\n        :type models: list\n        :type relation:  str\n        \"\"\"\n        for model in models:\n            model.set_relation(relation, Result(None, self, model))\n\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, _attributes=None, **attributes):\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self.get_results()\n\n        return instance.fill(attributes).save()", "response": "Update the parent model on the relationship."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd constraints for an eager load of the relation.", "response": "def add_eager_constraints(self, models):\n        \"\"\"\n        Set the constraints for an eager load of the relation.\n\n        :type models: list\n        \"\"\"\n        self._models = Collection.make(models)\n        self._build_dictionary(models)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _build_dictionary(self, models):\n        for model in models:\n            key = getattr(model, self._morph_type, None)\n            if key:\n                foreign = getattr(model, self._foreign_key)\n                if key not in self._dictionary:\n                    self._dictionary[key] = {}\n\n                if foreign not in self._dictionary[key]:\n                    self._dictionary[key][foreign] = []\n\n                self._dictionary[key][foreign].append(model)", "response": "Builds a dictionary with the models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef associate(self, model):\n        self._parent.set_attribute(self._foreign_key, model.get_key())\n        self._parent.set_attribute(self._morph_type, model.get_morph_name())\n\n        return self._parent.set_relation(\n            self._relation, Result(model, self, self._parent)\n        )", "response": "Associate the given model instance with the given parent instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_eager(self):\n        for type in self._dictionary.keys():\n            self._match_to_morph_parents(type, self._get_results_by_type(type))\n\n        return self._models", "response": "Get the relationship for eager loading."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _match_to_morph_parents(self, type, results):\n        for result in results:\n            if result.get_key() in self._dictionary.get(type, []):\n                for model in self._dictionary[type][result.get_key()]:\n                    model.set_relation(\n                        self._relation, Result(result, self, model, related=result)\n                    )", "response": "Match the results for a given type to their parents."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all the relation results for a type.", "response": "def _get_results_by_type(self, type):\n        \"\"\"\n        Get all the relation results for a type.\n\n        :param type: The type\n        :type type: str\n\n        :rtype: Collection\n        \"\"\"\n        instance = self._create_model_by_type(type)\n\n        key = instance.get_key_name()\n\n        query = instance.new_query()\n\n        query = self._use_with_trashed(query)\n\n        return query.where_in(key, self._gather_keys_by_type(type).all()).get()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngathers all of the foreign keys for a given type.", "response": "def _gather_keys_by_type(self, type):\n        \"\"\"\n        Gather all of the foreign keys for a given type.\n\n        :param type: The type\n        :type type: str\n\n        :rtype: BaseCollection\n        \"\"\"\n        foreign = self._foreign_key\n\n        keys = (\n            BaseCollection.make(list(self._dictionary[type].values()))\n            .map(lambda models: getattr(models[0], foreign))\n            .unique()\n        )\n\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the primary key of the current object.", "response": "def set_primary_key(self, columns, index_name=False):\n        \"\"\"\n        Set the primary key.\n\n        :type columns: list\n        :type index_name: str or bool\n\n        :rtype: Table\n        \"\"\"\n        self._add_index(\n            self._create_index(columns, index_name or \"primary\", True, True)\n        )\n\n        for column_name in columns:\n            column = self.get_column(column_name)\n            column.set_notnull(True)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndrop an index from this table.", "response": "def drop_index(self, name):\n        \"\"\"\n        Drops an index from this table.\n\n        :param name: The index name\n        :type name: str\n        \"\"\"\n        name = self._normalize_identifier(name)\n        if not self.has_index(name):\n            raise IndexDoesNotExist(name, self._name)\n\n        del self._indexes[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename_index(self, old_name, new_name=None):\n        old_name = self._normalize_identifier(old_name)\n        normalized_new_name = self._normalize_identifier(new_name)\n\n        if old_name == normalized_new_name:\n            return self\n\n        if not self.has_index(old_name):\n            raise IndexDoesNotExist(old_name, self._name)\n\n        if self.has_index(normalized_new_name):\n            raise IndexAlreadyExists(normalized_new_name, self._name)\n\n        old_index = self._indexes[old_name]\n\n        if old_index.is_primary():\n            self.drop_primary_key()\n\n            return self.set_primary_key(old_index.get_columns(), new_name)\n\n        del self._indexes[old_name]\n\n        if old_index.is_unique():\n            return self.add_unique_index(old_index.get_columns(), new_name)\n\n        return self.add_index(old_index.get_columns(), new_name, old_index.get_flags())", "response": "Renames an index.\n\n        :param old_name: The name of the index to rename from.\n        :type old_name: str\n\n        :param new_name: The name of the index to rename to.\n        :type new_name: str or None\n\n        :rtype: Table"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if an index begins in the order of the given columns.", "response": "def columns_are_indexed(self, columns):\n        \"\"\"\n        Checks if an index begins in the order of the given columns.\n\n        :type columns: list\n\n        :rtype: bool\n        \"\"\"\n        for index in self._indexes.values():\n            if index.spans_columns(columns):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_index(\n        self, columns, name, is_unique, is_primary, flags=None, options=None\n    ):\n        \"\"\"\n        Creates an Index instance.\n\n        :param columns: The index columns\n        :type columns: list\n\n        :param name: The index name\n        :type name: str\n\n        :param is_unique: Whether the index is unique or not\n        :type is_unique: bool\n\n        :param is_primary: Whether the index is primary or not\n        :type is_primary: bool\n\n        :param flags: The index flags\n        :type: dict\n\n        :param options: The options\n        :type options: dict\n\n        :rtype: Index\n        \"\"\"\n        if re.match(\"[^a-zA-Z0-9_]+\", self._normalize_identifier(name)):\n            raise IndexNameInvalid(name)\n\n        for column in columns:\n            if isinstance(column, dict):\n                column = list(column.keys())[0]\n\n            if not self.has_column(column):\n                raise ColumnDoesNotExist(column, self._name)\n\n        return Index(name, columns, is_unique, is_primary, flags, options)", "response": "Creates an index instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new column to the table.", "response": "def add_column(self, name, type_name, options=None):\n        \"\"\"\n        Adds a new column.\n\n        :param name: The column name\n        :type name: str\n\n        :param type_name: The column type\n        :type type_name: str\n\n        :param options: The column options\n        :type options: dict\n\n        :rtype: Column\n        \"\"\"\n        column = Column(name, type_name, options)\n\n        self._add_column(column)\n\n        return column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the options of a column.", "response": "def change_column(self, name, options):\n        \"\"\"\n        Changes column details.\n\n        :param name: The column to change.\n        :type name: str\n\n        :param options: The new options.\n        :type options: str\n\n        :rtype: Table\n        \"\"\"\n        column = self.get_column(name)\n        column.set_options(options)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_column(self, name):\n        name = self._normalize_identifier(name)\n        del self._columns[name]\n\n        return self", "response": "Drops a Column from the Table\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a foreign key constraint to the related tables.", "response": "def add_foreign_key_constraint(\n        self,\n        foreign_table,\n        local_columns,\n        foreign_columns,\n        options=None,\n        constraint_name=None,\n    ):\n        \"\"\"\n        Adds a foreign key constraint.\n\n        Name is inferred from the local columns.\n\n        :param foreign_table: Table instance or table name\n        :type foreign_table: Table or str\n\n        :type local_columns: list\n\n        :type foreign_columns: list\n\n        :type options: dict\n\n        :type constraint_name: str or None\n\n        :rtype: Table\n        \"\"\"\n        if not constraint_name:\n            constraint_name = self._generate_identifier_name(\n                [self.get_name()] + local_columns,\n                \"fk\",\n                self._get_max_identifier_length(),\n            )\n\n        return self.add_named_foreign_key_constraint(\n            constraint_name, foreign_table, local_columns, foreign_columns, options\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_named_foreign_key_constraint(\n        self, name, foreign_table, local_columns, foreign_columns, options\n    ):\n        \"\"\"\n        Adds a foreign key constraint with a given name.\n\n        :param name: The constraint name\n        :type name: str\n\n        :param foreign_table: Table instance or table name\n        :type foreign_table: Table or str\n\n        :type local_columns: list\n\n        :type foreign_columns: list\n\n        :type options: dict\n\n        :rtype: Table\n        \"\"\"\n        if isinstance(foreign_table, Table):\n            for column in foreign_columns:\n                if not foreign_table.has_column(column):\n                    raise ColumnDoesNotExist(column, foreign_table.get_name())\n\n        for column in local_columns:\n            if not self.has_column(column):\n                raise ColumnDoesNotExist(column, self._name)\n\n        constraint = ForeignKeyConstraint(\n            local_columns, foreign_table, foreign_columns, name, options\n        )\n\n        self._add_foreign_key_constraint(constraint)\n\n        return self", "response": "Adds a foreign key constraint with a given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an index to the table.", "response": "def _add_index(self, index):\n        \"\"\"\n        Adds an index to the table.\n\n        :param index: The index to add\n        :type index: Index\n\n        :rtype: Table\n        \"\"\"\n        index_name = index.get_name()\n        index_name = self._normalize_identifier(index_name)\n        replaced_implicit_indexes = []\n\n        for name, implicit_index in self._implicit_indexes.items():\n            if implicit_index.is_fullfilled_by(index) and name in self._indexes:\n                replaced_implicit_indexes.append(name)\n\n        already_exists = (\n            index_name in self._indexes\n            and index_name not in replaced_implicit_indexes\n            or self._primary_key_name is not False\n            and index.is_primary()\n        )\n        if already_exists:\n            raise IndexAlreadyExists(index_name, self._name)\n\n        for name in replaced_implicit_indexes:\n            del self._indexes[name]\n            del self._implicit_indexes[name]\n\n        if index.is_primary():\n            self._primary_key_name = index_name\n\n        self._indexes[index_name] = index\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_foreign_key_constraint(self, constraint):\n        constraint.set_local_table(self)\n\n        if constraint.get_name():\n            name = constraint.get_name()\n        else:\n            name = self._generate_identifier_name(\n                [self.get_name()] + constraint.get_local_columns(),\n                \"fk\",\n                self._get_max_identifier_length(),\n            )\n\n        name = self._normalize_identifier(name)\n\n        self._fk_constraints[name] = constraint\n\n        # Add an explicit index on the foreign key columns.\n        # If there is already an index that fulfils this requirements drop the request.\n        # In the case of __init__ calling this method during hydration from schema-details\n        # all the explicitly added indexes lead to duplicates.\n        # This creates computation overhead in this case, however no duplicate indexes\n        # are ever added (based on columns).\n        index_name = self._generate_identifier_name(\n            [self.get_name()] + constraint.get_columns(),\n            \"idx\",\n            self._get_max_identifier_length(),\n        )\n        index_candidate = self._create_index(\n            constraint.get_columns(), index_name, False, False\n        )\n\n        for existing_index in self._indexes.values():\n            if index_candidate.is_fullfilled_by(existing_index):\n                return\n\n        # self._add_index(index_candidate)\n        # self._implicit_indexes[self._normalize_identifier(index_name)] = index_candidate\n\n        return self", "response": "Adds a foreign key constraint to the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_foreign_key(self, name):\n        name = self._normalize_identifier(name)\n\n        return name in self._fk_constraints", "response": "Returns whether this table has a foreign key constraint with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_foreign_key(self, name):\n        name = self._normalize_identifier(name)\n\n        if not self.has_foreign_key(name):\n            raise ForeignKeyDoesNotExist(name, self._name)\n\n        return self._fk_constraints[name]", "response": "Returns the foreign key constraint with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_foreign_key(self, name):\n        name = self._normalize_identifier(name)\n\n        if not self.has_foreign_key(name):\n            raise ForeignKeyDoesNotExist(name, self._name)\n\n        del self._fk_constraints[name]", "response": "Removes the foreign key constraint with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_primary_key_columns(self):\n        if not self.has_primary_key():\n            raise DBALException('Table \"%s\" has no primary key.' % self.get_name())\n\n        return self.get_primary_key().get_columns()", "response": "Returns the primary key columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether this table has an Index with the given name.", "response": "def has_index(self, name):\n        \"\"\"\n        Returns whether this table has an Index with the given name.\n\n        :param name: The index name\n        :type name: str\n\n        :rtype: bool\n        \"\"\"\n        name = self._normalize_identifier(name)\n\n        return name in self._indexes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the index with the given name.", "response": "def get_index(self, name):\n        \"\"\"\n        Returns the Index with the given name.\n\n        :param name: The index name\n        :type name: str\n\n        :rtype: Index\n        \"\"\"\n        name = self._normalize_identifier(name)\n        if not self.has_index(name):\n            raise IndexDoesNotExist(name, self._name)\n\n        return self._indexes[name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the keys for a save update query.", "response": "def _set_keys_for_save_query(self, query):\n        \"\"\"\n        Set the keys for a save update query.\n\n        :param query: A Builder instance\n        :type query: orator.orm.Builder\n\n        :return: The Builder instance\n        :rtype: orator.orm.Builder\n        \"\"\"\n        query.where(self._morph_type, self._morph_name)\n\n        return super(MorphPivot, self)._set_keys_for_save_query(query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        query = self._get_delete_query()\n\n        query.where(self._morph_type, self._morph_name)\n\n        return query.delete()", "response": "Delete the pivot model record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef without_global_scope(self, scope):\n        if isinstance(scope, basestring):\n            del self._scopes[scope]\n\n            return self\n\n        keys = []\n        for key, value in self._scopes.items():\n            if scope == value.__class__ or isinstance(scope, value.__class__):\n                keys.append(key)\n\n        for key in keys:\n            del self._scopes[key]\n\n        return self", "response": "Removes a registered global scope from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind a model by its primary key value.", "response": "def find(self, id, columns=None):\n        \"\"\"\n        Find a model by its primary key\n\n        :param id: The primary key value\n        :type id: mixed\n\n        :param columns: The columns to retrieve\n        :type columns: list\n\n        :return: The found model\n        :rtype: orator.Model\n        \"\"\"\n        if columns is None:\n            columns = [\"*\"]\n\n        if isinstance(id, list):\n            return self.find_many(id, columns)\n\n        self._query.where(self._model.get_qualified_key_name(), \"=\", id)\n\n        return self.first(columns)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_many(self, id, columns=None):\n        if columns is None:\n            columns = [\"*\"]\n\n        if not id:\n            return self._model.new_collection()\n\n        self._query.where_in(self._model.get_qualified_key_name(), id)\n\n        return self.get(columns)", "response": "Find a model by its primary key values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_or_fail(self, id, columns=None):\n        result = self.find(id, columns)\n\n        if isinstance(id, list):\n            if len(result) == len(set(id)):\n                return result\n        elif result:\n            return result\n\n        raise ModelNotFound(self._model.__class__)", "response": "Find a model by its primary key or raise an exception"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the query and get the first result or raise an exception", "response": "def first_or_fail(self, columns=None):\n        \"\"\"\n        Execute the query and get the first result or raise an exception\n\n        :param columns: The columns to get\n        :type columns: list\n\n        :return: The result\n        :rtype: mixed\n        \"\"\"\n        model = self.first(columns)\n\n        if model is not None:\n            return model\n\n        raise ModelNotFound(self._model.__class__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, columns=None):\n        models = self.get_models(columns)\n\n        # If we actually found models we will also eager load any relationships that\n        # have been specified as needing to be eager loaded, which will solve the\n        # n+1 query issue for the developers to avoid running a lot of queries.\n        if len(models) > 0:\n            models = self.eager_load_relations(models)\n\n        collection = self._model.new_collection(models)\n\n        return collection", "response": "Execute the query as a select statement."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pluck(self, column):\n        result = self.first([column])\n\n        if result:\n            return result[column]", "response": "Pluck a single column from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield a list of count items from the query", "response": "def chunk(self, count):\n        \"\"\"\n        Chunk the results of the query\n\n        :param count: The chunk size\n        :type count: int\n\n        :return: The current chunk\n        :rtype: list\n        \"\"\"\n        connection = self._model.get_connection_name()\n        for results in self.apply_scopes().get_query().chunk(count):\n            models = self._model.hydrate(results, connection)\n\n            # If we actually found models we will also eager load any relationships that\n            # have been specified as needing to be eager loaded, which will solve the\n            # n+1 query issue for the developers to avoid running a lot of queries.\n            if len(models) > 0:\n                models = self.eager_load_relations(models)\n\n            collection = self._model.new_collection(models)\n\n            yield collection"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npaginate the given query.", "response": "def paginate(self, per_page=None, current_page=None, columns=None):\n        \"\"\"\n        Paginate the given query.\n\n        :param per_page: The number of records per page\n        :type per_page: int\n\n        :param current_page: The current page of results\n        :type current_page: int\n\n        :param columns: The columns to return\n        :type columns: list\n\n        :return: The paginator\n        \"\"\"\n        if columns is None:\n            columns = [\"*\"]\n\n        total = self.to_base().get_count_for_pagination()\n\n        page = current_page or Paginator.resolve_current_page()\n        per_page = per_page or self._model.get_per_page()\n        self._query.for_page(page, per_page)\n\n        return LengthAwarePaginator(self.get(columns).all(), total, per_page, page)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npaginates the given query.", "response": "def simple_paginate(self, per_page=None, current_page=None, columns=None):\n        \"\"\"\n        Paginate the given query.\n\n        :param per_page: The number of records per page\n        :type per_page: int\n\n        :param current_page: The current page of results\n        :type current_page: int\n\n        :param columns: The columns to return\n        :type columns: list\n\n        :return: The paginator\n        \"\"\"\n        if columns is None:\n            columns = [\"*\"]\n\n        page = current_page or Paginator.resolve_current_page()\n        per_page = per_page or self._model.get_per_page()\n\n        self.skip((page - 1) * per_page).take(per_page + 1)\n\n        return Paginator(self.get(columns).all(), per_page, page)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a record in the database.", "response": "def update(self, _values=None, **values):\n        \"\"\"\n        Update a record in the database\n\n        :param values: The values of the update\n        :type values: dict\n\n        :return: The number of records affected\n        :rtype: int\n        \"\"\"\n        if _values is not None:\n            values.update(_values)\n\n        return self._query.update(self._add_updated_at_column(values))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef increment(self, column, amount=1, extras=None):\n        if extras is None:\n            extras = {}\n\n        extras = self._add_updated_at_column(extras)\n\n        return self.to_base().increment(column, amount, extras)", "response": "Increment a column s value by a given amount"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_updated_at_column(self, values):\n        if not self._model.uses_timestamps():\n            return values\n\n        column = self._model.get_updated_at_column()\n\n        if \"updated_at\" not in values:\n            values.update({column: self._model.fresh_timestamp_string()})\n\n        return values", "response": "Adds the updated_at column to a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        if self._on_delete is not None:\n            return self._on_delete(self)\n\n        return self._query.delete()", "response": "Delete a record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_models(self, columns=None):\n        results = self.apply_scopes().get_query().get(columns).all()\n\n        connection = self._model.get_connection_name()\n\n        models = self._model.hydrate(results, connection)\n\n        return models", "response": "Get the hydrated models without eager loading."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the relation instance for the given relation name.", "response": "def get_relation(self, relation):\n        \"\"\"\n        Get the relation instance for the given relation name.\n\n        :rtype: orator.orm.relations.Relation\n        \"\"\"\n        from .relations import Relation\n\n        with Relation.no_constraints(True):\n            rel = getattr(self.get_model(), relation)()\n\n        nested = self._nested_relations(relation)\n\n        if len(nested) > 0:\n            rel.get_query().with_(nested)\n\n        return rel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the deeply nested relations for a given top - level relation.", "response": "def _nested_relations(self, relation):\n        \"\"\"\n        Get the deeply nested relations for a given top-level relation.\n\n        :rtype: dict\n        \"\"\"\n        nested = {}\n\n        for name, constraints in self._eager_load.items():\n            if self._is_nested(name, relation):\n                nested[name[len(relation + \".\") :]] = constraints\n\n        return nested"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_nested(self, name, relation):\n        dots = name.find(\".\")\n\n        return dots and name.startswith(relation + \".\")", "response": "Determines if the name is nested."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef where(self, column, operator=Null(), value=None, boolean=\"and\"):\n        if isinstance(column, Builder):\n            self._query.add_nested_where_query(column.get_query(), boolean)\n        else:\n            self._query.where(column, operator, value, boolean)\n\n        return self", "response": "Adds a where clause to the query"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an exists clause to the query.", "response": "def where_exists(self, query, boolean=\"and\", negate=False):\n        \"\"\"\n        Add an exists clause to the query.\n\n        :param query: The exists query\n        :type query: Builder or QueryBuilder\n\n        :type boolean: str\n\n        :type negate: bool\n\n        :rtype: Builder\n        \"\"\"\n        if isinstance(query, Builder):\n            query = query.get_query()\n\n        self.get_query().where_exists(query, boolean, negate)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has(self, relation, operator=\">=\", count=1, boolean=\"and\", extra=None):\n        if relation.find(\".\") >= 0:\n            return self._has_nested(relation, operator, count, boolean, extra)\n\n        relation = self._get_has_relation_query(relation)\n\n        query = relation.get_relation_count_query(\n            relation.get_related().new_query(), self\n        )\n\n        # TODO: extra query\n        if extra:\n            if callable(extra):\n                extra(query)\n\n        return self._add_has_where(\n            query.apply_scopes(), relation, operator, count, boolean\n        )", "response": "Add a relationship count condition to the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_has_where(self, has_query, relation, operator, count, boolean):\n        self._merge_model_defined_relation_wheres_to_has_query(has_query, relation)\n\n        if isinstance(count, basestring) and count.isdigit():\n            count = QueryExpression(count)\n\n        return self.where(\n            QueryExpression(\"(%s)\" % has_query.to_sql()), operator, count, boolean\n        )", "response": "Add the has condition where clause to the query."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge the wheres from a relation query to a has query.", "response": "def _merge_model_defined_relation_wheres_to_has_query(self, has_query, relation):\n        \"\"\"\n        Merge the \"wheres\" from a relation query to a has query.\n\n        :param has_query: The has query\n        :type has_query: Builder\n\n        :param relation: The relation to count\n        :type relation: orator.orm.relations.Relation\n        \"\"\"\n        relation_query = relation.get_base_query()\n\n        has_query.merge_wheres(relation_query.wheres, relation_query.get_bindings())\n\n        self._query.add_binding(has_query.get_query().get_bindings(), \"where\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef with_(self, *relations):\n        if not relations:\n            return self\n\n        eagers = self._parse_with_relations(list(relations))\n\n        self._eager_load.update(eagers)\n\n        return self", "response": "Sets the eager load relationships for this Builder instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a list of relations into individual related objects.", "response": "def _parse_with_relations(self, relations):\n        \"\"\"\n        Parse a list of relations into individuals.\n\n        :param relations: The relation to parse\n        :type relations: list\n\n        :rtype: dict\n        \"\"\"\n        results = {}\n\n        for relation in relations:\n            if isinstance(relation, dict):\n                for name, constraints in relation.items():\n                    results = self._parse_nested_with(name, results)\n\n                    results[name] = constraints\n\n                continue\n            else:\n                name = relation\n                constraints = self.__class__(self.get_query().new_query())\n\n            results = self._parse_nested_with(name, results)\n\n            results[name] = constraints\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _call_scope(self, scope, *args, **kwargs):\n        query = self.get_query()\n\n        # We will keep track of how many wheres are on the query before running the\n        # scope so that we can properly group the added scope constraints in the\n        # query as their own isolated nested where statement and avoid issues.\n        original_where_count = len(query.wheres)\n\n        result = getattr(self._model, scope)(self, *args, **kwargs)\n\n        if self._should_nest_wheres_for_scope(query, original_where_count):\n            self._nest_wheres_for_scope(\n                query, [0, original_where_count, len(query.wheres)]\n            )\n\n        return result or self", "response": "Call the given model scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_scopes(self):\n        if not self._scopes:\n            return self\n\n        builder = copy.copy(self)\n\n        query = builder.get_query()\n\n        # We will keep track of how many wheres are on the query before running the\n        # scope so that we can properly group the added scope constraints in the\n        # query as their own isolated nested where statement and avoid issues.\n        original_where_count = len(query.wheres)\n\n        where_counts = [0, original_where_count]\n\n        for scope in self._scopes.values():\n            self._apply_scope(scope, builder)\n\n            # Again, we will keep track of the count each time we add where clauses so that\n            # we will properly isolate each set of scope constraints inside of their own\n            # nested where clause to avoid any conflicts or issues with logical order.\n            where_counts.append(len(query.wheres))\n\n        if self._should_nest_wheres_for_scope(query, original_where_count):\n            self._nest_wheres_for_scope(query, Collection(where_counts).unique().all())\n\n        return builder", "response": "Returns a new Builder instance with applied global scopes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a single scope on the given builder instance.", "response": "def _apply_scope(self, scope, builder):\n        \"\"\"\n        Apply a single scope on the given builder instance.\n\n        :param scope: The scope to apply\n        :type scope: callable or Scope\n\n        :param builder: The builder to apply the scope to\n        :type builder: Builder\n        \"\"\"\n        if callable(scope):\n            scope(builder)\n        elif isinstance(scope, Scope):\n            scope.apply(builder, self.get_model())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnest where conditions of the builder and each global scope.", "response": "def _nest_wheres_for_scope(self, query, where_counts):\n        \"\"\"\n        Nest where conditions of the builder and each global scope.\n\n        :type query: QueryBuilder\n        :type where_counts: list\n        \"\"\"\n        # Here, we totally remove all of the where clauses since we are going to\n        # rebuild them as nested queries by slicing the groups of wheres into\n        # their own sections. This is to prevent any confusing logic order.\n        wheres = query.wheres\n\n        query.wheres = []\n\n        # We will take the first offset (typically 0) of where clauses and start\n        # slicing out every scope's where clauses into their own nested where\n        # groups for improved isolation of every scope's added constraints.\n        previous_count = where_counts.pop(0)\n\n        for where_count in where_counts:\n            query.wheres.append(\n                self._slice_where_conditions(\n                    wheres, previous_count, where_count - previous_count\n                )\n            )\n\n            previous_count = where_count"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _slice_where_conditions(self, wheres, offset, length):\n        where_group = self.get_query().for_nested_where()\n        where_group.wheres = wheres[offset : (offset + length)]\n\n        return {\"type\": \"nested\", \"query\": where_group, \"boolean\": \"and\"}", "response": "Slice the where conditions into a nested where list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the model instance for the current builder instance.", "response": "def set_model(self, model):\n        \"\"\"\n        Set a model instance for the model being queried.\n\n        :param model: The model instance\n        :type model: orator.orm.Model\n\n        :return: The current Builder instance\n        :rtype: Builder\n        \"\"\"\n        self._model = model\n\n        self._query.from_(model.get_table())\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile_insert(self, query, values):\n        table = self.wrap_table(query.from__)\n\n        if not isinstance(values, list):\n            values = [values]\n\n        # If there is only one row to insert, we just use the normal grammar\n        if len(values) == 1:\n            return super(SQLiteQueryGrammar, self).compile_insert(query, values)\n\n        names = self.columnize(values[0].keys())\n\n        columns = []\n\n        # SQLite requires us to build the multi-row insert as a listing of select with\n        # unions joining them together. So we'll build out this list of columns and\n        # then join them all together with select unions to complete the queries.\n        for column in values[0].keys():\n            columns.append(\"%s AS %s\" % (self.get_marker(), self.wrap(column)))\n\n        columns = [\", \".join(columns)] * len(values)\n\n        return \"INSERT INTO %s (%s) SELECT %s\" % (\n            table,\n            names,\n            \" UNION ALL SELECT \".join(columns),\n        )", "response": "Compile an insert statement into SQLite"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_truncate(self, query):\n        sql = {\n            \"DELETE FROM sqlite_sequence WHERE name = %s\"\n            % self.get_marker(): [query.from__]\n        }\n\n        sql[\"DELETE FROM %s\" % self.wrap_table(query.from__)] = []\n\n        return sql", "response": "Compile a truncate statement into SQL"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the blueprint against the database.", "response": "def build(self, connection, grammar):\n        \"\"\"\n        Execute the blueprint against the database.\n\n        :param connection: The connection to use\n        :type connection: orator.connections.Connection\n\n        :param grammar: The grammar to user\n        :type grammar: orator.query.grammars.QueryGrammar\n        \"\"\"\n        for statement in self.to_sql(connection, grammar):\n            connection.statement(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the raw SQL statements for the blueprint.", "response": "def to_sql(self, connection, grammar):\n        \"\"\"\n        Get the raw SQL statements for the blueprint.\n\n        :param connection: The connection to use\n        :type connection: orator.connections.Connection\n\n        :param grammar: The grammar to user\n        :type grammar: orator.schema.grammars.SchemaGrammar\n\n        :rtype: list\n        \"\"\"\n        self._add_implied_commands()\n\n        statements = []\n\n        for command in self._commands:\n            method = \"compile_%s\" % command.name\n\n            if hasattr(grammar, method):\n                sql = getattr(grammar, method)(self, command, connection)\n                if sql is not None:\n                    if isinstance(sql, list):\n                        statements += sql\n                    else:\n                        statements.append(sql)\n\n        return statements"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the commands that are implied by the blueprint.", "response": "def _add_implied_commands(self):\n        \"\"\"\n        Add the commands that are implied by the blueprint.\n        \"\"\"\n        if len(self.get_added_columns()) and not self._creating():\n            self._commands.insert(0, self._create_command(\"add\"))\n\n        if len(self.get_changed_columns()) and not self._creating():\n            self._commands.insert(0, self._create_command(\"change\"))\n\n        return self._add_fluent_indexes()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop one or more columns from the current set of key - value pairs.", "response": "def drop_column(self, *columns):\n        \"\"\"\n        Indicates that the given columns should be dropped.\n\n        :param columns: The columns to drop\n        :type columns: tuple\n\n        :rtype: Fluent\n        \"\"\"\n        columns = list(columns)\n\n        return self._add_command(\"drop_column\", columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new integer column on the table.", "response": "def integer(self, column, auto_increment=False, unsigned=False):\n        \"\"\"\n        Create a new integer column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type auto_increment: bool\n\n        :type unsigned: bool\n\n        :rtype: Fluent\n        \"\"\"\n        return self._add_column(\n            \"integer\", column, auto_increment=auto_increment, unsigned=unsigned\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef small_integer(self, column, auto_increment=False, unsigned=False):\n        return self._add_column(\n            \"small_integer\", column, auto_increment=auto_increment, unsigned=unsigned\n        )", "response": "Create a new small integer column on the table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new unisgned integer column on the table.", "response": "def unsigned_integer(self, column, auto_increment=False):\n        \"\"\"\n        Create a new unisgned integer column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type auto_increment: bool\n\n        :rtype: Fluent\n        \"\"\"\n        return self.integer(column, auto_increment, True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new unsigned big integer column on the table.", "response": "def unsigned_big_integer(self, column, auto_increment=False):\n        \"\"\"\n        Create a new unsigned big integer column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type auto_increment: bool\n\n        :rtype: Fluent\n        \"\"\"\n        return self.big_integer(column, auto_increment, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new float column on the table.", "response": "def float(self, column, total=8, places=2):\n        \"\"\"\n        Create a new float column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type total: int\n\n        :type places: 2\n\n        :rtype: Fluent\n        \"\"\"\n        return self._add_column(\"float\", column, total=total, places=places)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef double(self, column, total=None, places=None):\n        return self._add_column(\"double\", column, total=total, places=places)", "response": "Create a new double column on the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new decimal column on the table.", "response": "def decimal(self, column, total=8, places=2):\n        \"\"\"\n        Create a new decimal column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type total: int\n\n        :type places: 2\n\n        :rtype: Fluent\n        \"\"\"\n        return self._add_column(\"decimal\", column, total=total, places=places)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timestamps(self, use_current=True):\n        if use_current:\n            self.timestamp(\"created_at\").use_current()\n            self.timestamp(\"updated_at\").use_current()\n        else:\n            self.timestamp(\"created_at\")\n            self.timestamp(\"updated_at\")", "response": "Create creation and update timestamps to the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the proper columns for a polymorphic table.", "response": "def morphs(self, name, index_name=None):\n        \"\"\"\n        Add the proper columns for a polymorphic table.\n\n        :type name: str\n\n        :type index_name: str\n        \"\"\"\n        self.unsigned_integer(\"%s_id\" % name)\n        self.string(\"%s_type\" % name)\n        self.index([\"%s_id\" % name, \"%s_type\" % name], index_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _drop_index_command(self, command, type, index):\n        columns = []\n\n        if isinstance(index, list):\n            columns = index\n\n            index = self._create_index_name(type, columns)\n\n        return self._index_command(command, columns, index)", "response": "Create a new drop index command on the blueprint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _index_command(self, type, columns, index):\n        if not isinstance(columns, list):\n            columns = [columns]\n\n        if not index:\n            index = self._create_index_name(type, columns)\n\n        return self._add_command(type, index=index, columns=columns)", "response": "Add a new index command to the blueprint."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a column from the blueprint.", "response": "def _remove_column(self, name):\n        \"\"\"\n        Removes a column from the blueprint.\n\n        :param name: The column name\n        :type name: str\n\n        :rtype: Blueprint\n        \"\"\"\n        self._columns = filter(lambda c: c.name != name, self._columns)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_command(self, name, **parameters):\n        command = self._create_command(name, **parameters)\n        self._commands.append(command)\n\n        return command", "response": "Add a new command to the blueprint."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the quoted representation of the column names .", "response": "def get_quoted_columns(self, platform):\n        \"\"\"\n        Returns the quoted representation of the column names\n        the constraint is associated with.\n\n        But only if they were defined with one or a column name\n        is a keyword reserved by the platform.\n        Otherwise the plain unquoted value as inserted is returned.\n\n        :param platform: The platform to use for quotation.\n        :type platform: Platform\n\n        :rtype: list\n        \"\"\"\n        columns = []\n\n        for column in self._columns.values():\n            columns.append(column.get_quoted_name(platform))\n\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_column_at_position(self, column_name, pos=0):\n        column_name = self._trim_quotes(column_name.lower())\n        index_columns = [c.lower() for c in self.get_unquoted_columns()]\n\n        return index_columns.index(column_name) == pos", "response": "Returns True if the column_name is at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spans_columns(self, column_names):\n        columns = self.get_columns()\n        number_of_columns = len(columns)\n        same_columns = True\n\n        for i in range(number_of_columns):\n            column = self._trim_quotes(columns[i].lower())\n            if i >= len(column_names) or column != self._trim_quotes(\n                column_names[i].lower()\n            ):\n                same_columns = False\n\n        return same_columns", "response": "Checks if this index exactly spans the given column names in the correct order."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the other index already fulfills all the indexing and constraint needs of the current one.", "response": "def is_fullfilled_by(self, other):\n        \"\"\"\n        Checks if the other index already fulfills\n        all the indexing and constraint needs of the current one.\n\n        :param other: The other index\n        :type other: Index\n\n        :rtype: bool\n        \"\"\"\n        # allow the other index to be equally large only. It being larger is an option\n        # but it creates a problem with scenarios of the kind PRIMARY KEY(foo,bar) UNIQUE(foo)\n        if len(other.get_columns()) != len(self.get_columns()):\n            return False\n\n        # Check if columns are the same, and even in the same order\n        if not self.spans_columns(other.get_columns()):\n            return False\n\n        if not self.same_partial_index(other):\n            return False\n\n        if self.is_simple_index():\n            # this is a special case: If the current key is neither primary or unique,\n            # any unique or primary key will always have the same effect\n            # for the index and there cannot be any constraint overlaps.\n            # This means a primary or unique index can always fulfill\n            # the requirements of just an index that has no constraints.\n            return True\n\n        if other.is_primary() != self.is_primary():\n            return False\n\n        if other.is_unique() != self.is_unique():\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning whether the two indexes have the same partial index.", "response": "def same_partial_index(self, other):\n        \"\"\"\n        Return whether the two indexes have the same partial index\n\n        :param other: The other index\n        :type other: Index\n\n        :rtype: bool\n        \"\"\"\n        if (\n            self.has_option(\"where\")\n            and other.has_option(\"where\")\n            and self.get_option(\"where\") == other.get_option(\"where\")\n        ):\n            return True\n\n        if not self.has_option(\"where\") and not other.has_option(\"where\"):\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect if the other index is a non - unique non - primary index that can be overwritten by this one.", "response": "def overrules(self, other):\n        \"\"\"\n        Detects if the other index is a non-unique, non primary index\n        that can be overwritten by this one.\n\n        :param other: The other index\n        :type other: Index\n\n        :rtype: bool\n        \"\"\"\n        if other.is_primary():\n            return False\n        elif self.is_simple_index() and other.is_unique():\n            return False\n\n        same_columns = self.spans_columns(other.get_columns())\n        if (\n            same_columns\n            and (self.is_primary() or self.is_unique())\n            and self.same_partial_index(other)\n        ):\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a flag from the set.", "response": "def remove_flag(self, flag):\n        \"\"\"\n        Removes a flag.\n\n        :type flag: str\n        \"\"\"\n        if self.has_flag(flag):\n            del self._flags[flag.lower()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the current page for the request.", "response": "def _set_current_page(self, current_page, last_page):\n        \"\"\"\n        Get the current page for the request.\n\n        :param current_page: The current page of results\n        :type current_page: int\n\n        :param last_page: The last page of results\n        :type last_page: int\n\n        :rtype: int\n        \"\"\"\n        if not current_page:\n            current_page = self.resolve_current_page()\n\n        if current_page > last_page:\n            if last_page > 0:\n                return last_page\n\n            return 1\n\n        if not self._is_valid_page_number(current_page):\n            return 1\n\n        return current_page"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompiles a create table command.", "response": "def compile_create(self, blueprint, command, connection):\n        \"\"\"\n        Compile a create table command.\n        \"\"\"\n        columns = \", \".join(self._get_columns(blueprint))\n\n        sql = \"CREATE TABLE %s (%s)\" % (self.wrap_table(blueprint), columns)\n\n        sql = self._compile_create_encoding(sql, connection, blueprint)\n\n        if blueprint.engine:\n            sql += \" ENGINE = %s\" % blueprint.engine\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles the create encoding command.", "response": "def _compile_create_encoding(self, sql, connection, blueprint):\n        \"\"\"\n        Append the character set specifications to a command.\n\n        :type sql: str\n        :type connection: orator.connections.Connection\n        :type blueprint: Blueprint\n\n        :rtype: str\n        \"\"\"\n        charset = blueprint.charset or connection.get_config(\"charset\")\n        if charset:\n            sql += \" DEFAULT CHARACTER SET %s\" % charset\n\n        collation = blueprint.collation or connection.get_config(\"collation\")\n        if collation:\n            sql += \" COLLATE %s\" % collation\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_column_change_options(self, fluent):\n        options = super(MySQLSchemaGrammar, self)._get_column_change_options(fluent)\n\n        if fluent.type == \"enum\":\n            options[\"extra\"] = {\n                \"definition\": \"('{}')\".format(\"','\".join(fluent.allowed))\n            }\n\n        return options", "response": "Get the column change options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the destination class path.", "response": "def _get_path(self, name):\n        \"\"\"\n        Get the destination class path.\n\n        :param name: The name\n        :type name: str\n\n        :rtype: str\n        \"\"\"\n        path = self.option(\"path\")\n        if path is None:\n            path = self._get_seeders_path()\n\n        return os.path.join(path, \"%s.py\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_constraints(self):\n        if self._constraints:\n            self._query.where(self._foreign_key, \"=\", self.get_parent_key())", "response": "Add constraints to the query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_eager_constraints(self, models):\n        return self._query.where_in(\n            self._foreign_key, self.get_keys(models, self._local_key)\n        )", "response": "Add constraints for an eager load of the relation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _match_one_or_many(self, models, results, relation, type_):\n        dictionary = self._build_dictionary(results)\n\n        for model in models:\n            key = model.get_attribute(self._local_key)\n\n            if key in dictionary:\n                value = Result(\n                    self._get_relation_value(dictionary, key, type_), self, model\n                )\n            else:\n                if type_ == \"one\":\n                    value = Result(None, self, model)\n                else:\n                    value = Result(self._related.new_collection(), self, model)\n\n            model.set_relation(relation, value)\n\n        return models", "response": "Match the eargerly loaded resuls to their single parents."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, model):\n        model.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        if model.save():\n            return model\n\n        return False", "response": "Save a model instance to the parent models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_or_new(self, id, columns=None):\n        if columns is None:\n            columns = [\"*\"]\n\n        instance = self._query.find(id, columns)\n\n        if instance is None:\n            instance = self._related.new_instance()\n            instance.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        return instance", "response": "Find a model by its primary key or return a new instance of the related model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_or_create(self, attributes, values=None):\n        instance = self.first_or_new(**attributes)\n\n        instance.fill(values)\n\n        instance.save()\n\n        return instance", "response": "Create or update a related record matching the attributes and fill it with values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, _attributes=None, **attributes):\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self._related.new_instance(attributes)\n\n        instance.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        instance.save()\n\n        return instance", "response": "Create a new instance of the related model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a list of new instances of the related model.", "response": "def create_many(self, records):\n        \"\"\"\n        Create a list of new instances of the related model.\n\n        :param records: instances attributes\n        :type records: list\n\n        :rtype: list\n        \"\"\"\n        instances = []\n\n        for record in records:\n            instances.append(self.create(**record))\n\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform an update on all the related models.", "response": "def update(self, _attributes=None, **attributes):\n        \"\"\"\n        Perform an update on all the related models.\n\n        :param attributes: The attributes\n        :type attributes: dict\n\n        :rtype: int\n        \"\"\"\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        if self._related.uses_timestamps():\n            attributes[self.get_related_updated_at()] = self._related.fresh_timestamp()\n\n        return self._query.update(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dialect(self):\n\n        if \"+\" not in self.drivername:\n            name = self.drivername\n        else:\n            name = self.drivername.replace(\"+\", \".\")\n        cls = registry.load(name)\n        # check for legacy dialects that\n        # would return a module with 'dialect' as the\n        # actual class\n        if (\n            hasattr(cls, \"dialect\")\n            and isinstance(cls.dialect, type)\n            and issubclass(cls.dialect, Dialect)\n        ):\n            return cls.dialect\n        else:\n            return cls", "response": "Return the SQLAlchemy database dialect class corresponding\n        to this URL s driver name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_connect_args(self, names=[], **kw):\n\n        translated = {}\n        attribute_names = [\"host\", \"database\", \"username\", \"password\", \"port\"]\n        for sname in attribute_names:\n            if names:\n                name = names.pop(0)\n            elif sname in kw:\n                name = kw[sname]\n            else:\n                name = sname\n            if name is not None and getattr(self, sname, False):\n                translated[name] = getattr(self, sname)\n        return translated", "response": "Translate url attributes into a dictionary of connection arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_check_declaration_sql(self, definition):\n        constraints = []\n        for field, def_ in definition.items():\n            if isinstance(def_, basestring):\n                constraints.append(\"CHECK (%s)\" % def_)\n            else:\n                if \"min\" in def_:\n                    constraints.append(\"CHECK (%s >= %s)\" % (field, def_[\"min\"]))\n\n                if \"max\" in def_:\n                    constraints.append(\"CHECK (%s <= %s)\" % (field, def_[\"max\"]))\n\n        return \", \".join(constraints)", "response": "Returns the SQL code portion needed to set a CHECK constraint for the given DBMS check definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the SQL code portion needed to set a unique constraint declaration.", "response": "def get_unique_constraint_declaration_sql(self, name, index):\n        \"\"\"\n        Obtains DBMS specific SQL code portion needed to set a unique\n        constraint declaration to be used in statements like CREATE TABLE.\n\n        :param name: The name of the unique constraint.\n        :type name: str\n\n        :param index: The index definition\n        :type index: Index\n\n        :return: DBMS specific SQL code portion needed to set a constraint.\n        :rtype: str\n        \"\"\"\n        columns = index.get_quoted_columns(self)\n        name = Identifier(name)\n\n        if not columns:\n            raise DBALException('Incomplete definition. \"columns\" required.')\n\n        return \"CONSTRAINT %s UNIQUE (%s)%s\" % (\n            name.get_quoted_name(self),\n            self.get_index_field_declaration_list_sql(columns),\n            self.get_partial_index_sql(index),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_index_declaration_sql(self, name, index):\n        columns = index.get_quoted_columns(self)\n        name = Identifier(name)\n\n        if not columns:\n            raise DBALException('Incomplete definition. \"columns\" required.')\n\n        return \"%sINDEX %s (%s)%s\" % (\n            self.get_create_index_sql_flags(index),\n            name.get_quoted_name(self),\n            self.get_index_field_declaration_list_sql(columns),\n            self.get_partial_index_sql(index),\n        )", "response": "Gets the SQL code needed to set an index declaration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the SQL code needed to set the FOREIGN KEY constraint of a field declaration.", "response": "def get_foreign_key_declaration_sql(self, foreign_key):\n        \"\"\"\n        Obtain DBMS specific SQL code portion needed to set the FOREIGN KEY constraint\n        of a field declaration to be used in statements like CREATE TABLE.\n\n        :param foreign_key: The foreign key\n        :type foreign_key: ForeignKeyConstraint\n\n        :rtype: str\n        \"\"\"\n        sql = self.get_foreign_key_base_declaration_sql(foreign_key)\n        sql += self.get_advanced_foreign_key_options_sql(foreign_key)\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_advanced_foreign_key_options_sql(self, foreign_key):\n        query = \"\"\n        if self.supports_foreign_key_on_update() and foreign_key.has_option(\n            \"on_update\"\n        ):\n            query += \" ON UPDATE %s\" % self.get_foreign_key_referential_action_sql(\n                foreign_key.get_option(\"on_update\")\n            )\n\n        if foreign_key.has_option(\"on_delete\"):\n            query += \" ON DELETE %s\" % self.get_foreign_key_referential_action_sql(\n                foreign_key.get_option(\"on_delete\")\n            )\n\n        return query", "response": "Returns the FOREIGN KEY query section dealing with non - standard options\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_foreign_key_referential_action_sql(self, action):\n        action = action.upper()\n        if action not in [\n            \"CASCADE\",\n            \"SET NULL\",\n            \"NO ACTION\",\n            \"RESTRICT\",\n            \"SET DEFAULT\",\n        ]:\n            raise DBALException(\"Invalid foreign key action: %s\" % action)\n\n        return action", "response": "Returns the given referential action in uppercase if valid otherwise throws an exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the SQL code portion needed to set the FOREIGN KEY constraint of a field declaration.", "response": "def get_foreign_key_base_declaration_sql(self, foreign_key):\n        \"\"\"\n        Obtains DBMS specific SQL code portion needed to set the FOREIGN KEY constraint\n        of a field declaration to be used in statements like CREATE TABLE.\n\n        :param foreign_key: The foreign key\n        :type foreign_key: ForeignKeyConstraint\n\n        :rtype: str\n        \"\"\"\n        sql = \"\"\n        if foreign_key.get_name():\n            sql += \"CONSTRAINT %s \" % foreign_key.get_quoted_name(self)\n\n        sql += \"FOREIGN KEY (\"\n\n        if not foreign_key.get_local_columns():\n            raise DBALException('Incomplete definition. \"local\" required.')\n\n        if not foreign_key.get_foreign_columns():\n            raise DBALException('Incomplete definition. \"foreign\" required.')\n\n        if not foreign_key.get_foreign_table_name():\n            raise DBALException('Incomplete definition. \"foreign_table\" required.')\n\n        sql += \"%s) REFERENCES %s (%s)\" % (\n            \", \".join(foreign_key.get_quoted_local_columns(self)),\n            foreign_key.get_quoted_foreign_table_name(self),\n            \", \".join(foreign_key.get_quoted_foreign_columns(self)),\n        )\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets declaration of a number of fields in bulk.", "response": "def get_column_declaration_list_sql(self, fields):\n        \"\"\"\n        Gets declaration of a number of fields in bulk.\n        \"\"\"\n        query_fields = []\n\n        for name, field in fields.items():\n            query_fields.append(self.get_column_declaration_sql(name, field))\n\n        return \", \".join(query_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_index_field_declaration_list_sql(self, fields):\n        ret = []\n\n        for field in fields:\n            ret.append(field)\n\n        return \", \".join(ret)", "response": "Returns the SQL code portion needed to set an index\n            declaration to be used in statements like CREATE TABLE."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_create_index_sql(self, index, table):\n        if isinstance(table, Table):\n            table = table.get_quoted_name(self)\n\n        name = index.get_quoted_name(self)\n        columns = index.get_quoted_columns(self)\n\n        if not columns:\n            raise DBALException('Incomplete definition. \"columns\" required.')\n\n        if index.is_primary():\n            return self.get_create_primary_key_sql(index, table)\n\n        query = \"CREATE %sINDEX %s ON %s\" % (\n            self.get_create_index_sql_flags(index),\n            name,\n            table,\n        )\n        query += \" (%s)%s\" % (\n            self.get_index_field_declaration_list_sql(columns),\n            self.get_partial_index_sql(index),\n        )\n\n        return query", "response": "Returns the SQL to create an index on a table on this platform."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_create_primary_key_sql(self, index, table):\n        return \"ALTER TABLE %s ADD PRIMARY KEY (%s)\" % (\n            table,\n            self.get_index_field_declaration_list_sql(index.get_quoted_columns(self)),\n        )", "response": "Returns the SQL to create an unnamed primary key constraint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the SQL to create a new foreign key.", "response": "def get_create_foreign_key_sql(self, foreign_key, table):\n        \"\"\"\n        Returns the SQL to create a new foreign key.\n\n        :rtype: sql\n        \"\"\"\n        if isinstance(table, Table):\n            table = table.get_quoted_name(self)\n\n        query = \"ALTER TABLE %s ADD %s\" % (\n            table,\n            self.get_foreign_key_declaration_sql(foreign_key),\n        )\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the SQL snippet to drop an existing table.", "response": "def get_drop_table_sql(self, table):\n        \"\"\"\n        Returns the SQL snippet to drop an existing table.\n\n        :param table: The table\n        :type table: Table or str\n\n        :rtype: str\n        \"\"\"\n        if isinstance(table, Table):\n            table = table.get_quoted_name(self)\n\n        return \"DROP TABLE %s\" % table"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the SQL to drop an index from a table.", "response": "def get_drop_index_sql(self, index, table=None):\n        \"\"\"\n        Returns the SQL to drop an index from a table.\n\n        :param index: The index\n        :type index: Index or str\n\n        :param table: The table\n        :type table: Table or str or None\n\n        :rtype: str\n        \"\"\"\n        if isinstance(index, Index):\n            index = index.get_quoted_name(self)\n\n        return \"DROP INDEX %s\" % index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the SQL statement to create a table with the specified name columns and constraints on this platform.", "response": "def get_create_table_sql(self, table, create_flags=CREATE_INDEXES):\n        \"\"\"\n        Returns the SQL statement(s) to create a table\n        with the specified name, columns and constraints\n        on this platform.\n\n        :param table: The table\n        :type table: Table\n\n        :type create_flags: int\n\n        :rtype: str\n        \"\"\"\n        table_name = table.get_quoted_name(self)\n        options = dict((k, v) for k, v in table.get_options().items())\n\n        options[\"unique_constraints\"] = OrderedDict()\n        options[\"indexes\"] = OrderedDict()\n        options[\"primary\"] = []\n\n        if create_flags & self.CREATE_INDEXES > 0:\n            for index in table.get_indexes().values():\n                if index.is_primary():\n                    options[\"primary\"] = index.get_quoted_columns(self)\n                    options[\"primary_index\"] = index\n                else:\n                    options[\"indexes\"][index.get_quoted_name(self)] = index\n\n        columns = OrderedDict()\n\n        for column in table.get_columns().values():\n            column_data = column.to_dict()\n            column_data[\"name\"] = column.get_quoted_name(self)\n            if column.has_platform_option(\"version\"):\n                column_data[\"version\"] = column.get_platform_option(\"version\")\n            else:\n                column_data[\"version\"] = False\n\n            # column_data['comment'] = self.get_column_comment(column)\n\n            if column_data[\"type\"] == \"string\" and column_data[\"length\"] is None:\n                column_data[\"length\"] = 255\n\n            if column.get_name() in options[\"primary\"]:\n                column_data[\"primary\"] = True\n\n            columns[column_data[\"name\"]] = column_data\n\n        if create_flags & self.CREATE_FOREIGNKEYS > 0:\n            options[\"foreign_keys\"] = []\n            for fk in table.get_foreign_keys().values():\n                options[\"foreign_keys\"].append(fk)\n\n        sql = self._get_create_table_sql(table_name, columns, options)\n\n        # Comments?\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the SQL used to create a table.", "response": "def _get_create_table_sql(self, table_name, columns, options=None):\n        \"\"\"\n        Returns the SQL used to create a table.\n\n        :param table_name: The name of the table to create\n        :type table_name: str\n\n        :param columns: The table columns\n        :type columns: dict\n\n        :param options: The options\n        :type options: dict\n\n        :rtype: str\n        \"\"\"\n        options = options or {}\n\n        column_list_sql = self.get_column_declaration_list_sql(columns)\n\n        if options.get(\"unique_constraints\"):\n            for name, definition in options[\"unique_constraints\"].items():\n                column_list_sql += \", %s\" % self.get_unique_constraint_declaration_sql(\n                    name, definition\n                )\n\n        if options.get(\"primary\"):\n            column_list_sql += \", PRIMARY KEY(%s)\" % \", \".join(options[\"primary\"])\n\n        if options.get(\"indexes\"):\n            for index, definition in options[\"indexes\"]:\n                column_list_sql += \", %s\" % self.get_index_declaration_sql(\n                    index, definition\n                )\n\n        query = \"CREATE TABLE %s (%s\" % (table_name, column_list_sql)\n\n        check = self.get_check_declaration_sql(columns)\n        if check:\n            query += \", %s\" % check\n\n        query += \")\"\n\n        sql = [query]\n\n        if options.get(\"foreign_keys\"):\n            for definition in options[\"foreign_keys\"]:\n                sql.append(self.get_create_foreign_key_sql(definition, table_name))\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quote_identifier(self, string):\n        if \".\" in string:\n            parts = list(map(self.quote_single_identifier, string.split(\".\")))\n\n            return \".\".join(parts)\n\n        return self.quote_single_identifier(string)", "response": "Quotes a string so that it can be safely used as a table or column name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nquotes a single identifier.", "response": "def quote_single_identifier(self, string):\n        \"\"\"\n        Quotes a single identifier (no dot chain separation).\n\n        :param string: The identifier name to be quoted.\n        :type string: str\n\n        :return: The quoted identifier string.\n        :rtype: str\n        \"\"\"\n        c = self.get_identifier_quote_character()\n\n        return \"%s%s%s\" % (c, string.replace(c, c + c), c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects and sets the database platform.", "response": "def _detect_database_platform(self):\n        \"\"\"\n        Detects and sets the database platform.\n\n        Evaluates custom platform class and version in order to set the correct platform.\n\n        :raises InvalidPlatformSpecified: if an invalid platform was specified for this connection.\n        \"\"\"\n        version = self._get_database_platform_version()\n\n        if version is not None:\n            self._platform = self._create_database_platform_for_version(version)\n        else:\n            self._platform = self.get_dbal_platform()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the current page for the request.", "response": "def _set_current_page(self, current_page):\n        \"\"\"\n        Get the current page for the request.\n\n        :param current_page: The current page of results\n        :type current_page: int\n\n        :rtype: int\n        \"\"\"\n        if not current_page:\n            self.resolve_current_page()\n\n        if not self._is_valid_page_number(current_page):\n            return 1\n\n        return current_page"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_for_more_pages(self):\n        self._has_more = len(self._items) > self.per_page\n\n        self._items = self._items[0 : self.per_page]", "response": "Check for more pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diff_table(self, table1, table2):\n        changes = 0\n        table_differences = TableDiff(table1.get_name())\n        table_differences.from_table = table1\n\n        table1_columns = table1.get_columns()\n        table2_columns = table2.get_columns()\n\n        # See if all the fields in table1 exist in table2\n        for column_name, column in table2_columns.items():\n            if not table1.has_column(column_name):\n                table_differences.added_columns[column_name] = column\n                changes += 1\n\n        # See if there are any removed fields in table2\n        for column_name, column in table1_columns.items():\n            if not table2.has_column(column_name):\n                table_differences.removed_columns[column_name] = column\n                changes += 1\n                continue\n\n            # See if column has changed properties in table2\n            changed_properties = self.diff_column(\n                column, table2.get_column(column_name)\n            )\n\n            if changed_properties:\n                column_diff = ColumnDiff(\n                    column.get_name(),\n                    table2.get_column(column_name),\n                    changed_properties,\n                )\n                column_diff.from_column = column\n                table_differences.changed_columns[column.get_name()] = column_diff\n                changes += 1\n\n        self.detect_column_renamings(table_differences)\n\n        table1_indexes = table1.get_indexes()\n        table2_indexes = table2.get_indexes()\n\n        # See if all the fields in table1 exist in table2\n        for index_name, index in table2_indexes.items():\n            if (\n                index.is_primary() and not table1.has_primary_key()\n            ) or table1.has_index(index_name):\n                continue\n\n            table_differences.added_indexes[index_name] = index\n            changes += 1\n\n        # See if there are any removed fields in table2\n        for index_name, index in table1_indexes.items():\n            if (index.is_primary() and not table2.has_primary_key()) or (\n                not index.is_primary() and not table2.has_index(index_name)\n            ):\n                table_differences.removed_indexes[index_name] = index\n                changes += 1\n                continue\n\n            # See if index has changed in table 2\n            if index.is_primary():\n                table2_index = table2.get_primary_key()\n            else:\n                table2_index = table2.get_index(index_name)\n\n            if self.diff_index(index, table2_index):\n                table_differences.changed_indexes[index_name] = index\n                changes += 1\n\n        self.detect_index_renamings(table_differences)\n\n        from_fkeys = OrderedDict([(k, v) for k, v in table1.get_foreign_keys().items()])\n        to_fkeys = OrderedDict([(k, v) for k, v in table2.get_foreign_keys().items()])\n\n        for key1, constraint1 in table1.get_foreign_keys().items():\n            for key2, constraint2 in table2.get_foreign_keys().items():\n                if self.diff_foreign_key(constraint1, constraint2) is False:\n                    del from_fkeys[key1]\n                    del to_fkeys[key2]\n                else:\n                    if constraint1.get_name().lower() == constraint2.get_name().lower():\n                        table_differences.changed_foreign_keys.append(constraint2)\n                        changes += 1\n                        del from_fkeys[key1]\n                        del to_fkeys[key2]\n\n        for constraint1 in from_fkeys.values():\n            table_differences.removed_foreign_keys.append(constraint1)\n            changes += 1\n\n        for constraint2 in to_fkeys.values():\n            table_differences.added_foreign_keys.append(constraint2)\n            changes += 1\n\n        if changes:\n            return table_differences\n\n        return False", "response": "Returns the difference between the tables table1 and table2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect if there are ambiguous or not renamed indexes in the table_differences.", "response": "def detect_index_renamings(self, table_differences):\n        \"\"\"\n        Try to find indexes that only changed their name,\n        rename operations maybe cheaper than add/drop\n        however ambiguities between different possibilities\n        should not lead to renaming at all.\n\n        :type table_differences: TableDiff\n        \"\"\"\n        rename_candidates = OrderedDict()\n\n        # Gather possible rename candidates by comparing\n        # each added and removed index based on semantics.\n        for added_index_name, added_index in table_differences.added_indexes.items():\n            for removed_index in table_differences.removed_indexes.values():\n                if not self.diff_index(added_index, removed_index):\n                    if added_index.get_name() not in rename_candidates:\n                        rename_candidates[added_index.get_name()] = []\n\n                    rename_candidates[added_index.get_name()].append(\n                        (removed_index, added_index, added_index_name)\n                    )\n\n        for candidate_indexes in rename_candidates.values():\n            # If the current rename candidate contains exactly one semantically equal index,\n            # we can safely rename it.\n            # Otherwise it is unclear if a rename action is really intended,\n            # therefore we let those ambiguous indexes be added/dropped.\n            if len(candidate_indexes) == 1:\n                removed_index, added_index, _ = candidate_indexes[0]\n\n                removed_index_name = removed_index.get_name().lower()\n                added_index_name = added_index.get_name().lower()\n\n                if not removed_index_name in table_differences.renamed_indexes:\n                    table_differences.renamed_indexes[removed_index_name] = added_index\n                    del table_differences.added_indexes[added_index_name]\n                    del table_differences.removed_indexes[removed_index_name]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff_foreign_key(self, key1, key2):\n        key1_unquoted_local_columns = [\n            c.lower() for c in key1.get_unquoted_local_columns()\n        ]\n        key2_unquoted_local_columns = [\n            c.lower() for c in key2.get_unquoted_local_columns()\n        ]\n\n        if key1_unquoted_local_columns != key2_unquoted_local_columns:\n            return True\n\n        key1_unquoted_foreign_columns = [\n            c.lower() for c in key1.get_unquoted_foreign_columns()\n        ]\n        key2_unquoted_foreign_columns = [\n            c.lower() for c in key2.get_unquoted_foreign_columns()\n        ]\n\n        if key1_unquoted_foreign_columns != key2_unquoted_foreign_columns:\n            return True\n\n        if (\n            key1.get_unqualified_foreign_table_name()\n            != key2.get_unqualified_foreign_table_name()\n        ):\n            return True\n\n        if key1.on_update() != key2.on_update():\n            return True\n\n        if key1.on_delete() != key2.on_delete():\n            return True\n\n        return False", "response": "Returns True if the foreign key of the given key1 and key2 are not the same."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diff_index(self, index1, index2):\n        if index1.is_fullfilled_by(index2) and index2.is_fullfilled_by(index1):\n            return False\n\n        return True", "response": "Returns True if there are any differences between the indexes index1 and index2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the column listing for a given table.", "response": "def get_column_listing(self, table):\n        \"\"\"\n        Get the column listing for a given table.\n\n        :param table: The table\n        :type table: str\n\n        :rtype: list\n        \"\"\"\n        sql = self._grammar.compile_column_exists()\n        database = self._connection.get_database_name()\n        table = self._connection.get_table_prefix() + table\n\n        results = []\n        for result in self._connection.select(sql, [database, table]):\n            new_result = {}\n            for key, value in result.items():\n                new_result[key.lower()] = value\n\n            results.append(new_result)\n\n        return self._connection.get_post_processor().process_column_listing(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef call(self, klass):\n        self._resolve(klass).run()\n\n        if self._command:\n            self._command.line(\"<info>Seeded:</info> <fg=cyan>%s</>\" % klass.__name__)", "response": "Runs the given class s Seeder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves an instance of the given seeder klass.", "response": "def _resolve(self, klass):\n        \"\"\"\n        Resolve an instance of the given seeder klass.\n\n        :param klass: The Seeder class\n        :type klass: class\n        \"\"\"\n        resolver = None\n\n        if self._resolver:\n            resolver = self._resolver\n        elif self._command:\n            resolver = self._command.resolver\n\n        instance = klass()\n        instance.set_connection_resolver(resolver)\n\n        if self._command:\n            instance.set_command(self._command)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select(self, *columns):\n        if not columns:\n            columns = [\"*\"]\n\n        self.columns = list(columns)\n\n        return self", "response": "Sets the columns to be selected"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef select_raw(self, expression, bindings=None):\n        self.add_select(QueryExpression(expression))\n\n        if bindings:\n            self.add_binding(bindings, \"select\")\n\n        return self", "response": "Adds a new raw select expression to the current QueryBuilder instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a subselect expression to the query", "response": "def select_sub(self, query, as_):\n        \"\"\"\n        Add a subselect expression to the query\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param as_: The subselect alias\n        :type as_: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        if isinstance(query, QueryBuilder):\n            bindings = query.get_bindings()\n\n            query = query.to_sql()\n        elif isinstance(query, basestring):\n            bindings = []\n        else:\n            raise ArgumentError(\"Invalid subselect\")\n\n        return self.select_raw(\n            \"(%s) AS %s\" % (query, self._grammar.wrap(as_)), bindings\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_select(self, *column):\n        if not column:\n            column = []\n\n        self.columns += list(column)\n\n        return self", "response": "Adds a new select column to the query"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a left join where clause to the current QueryBuilder instance", "response": "def left_join_where(self, table, one, operator, two):\n        \"\"\"\n        Add a \"left join where\" clause to the query\n\n        :param table: The table to join with, can also be a JoinClause instance\n        :type table: str or JoinClause\n\n        :param one: The first column of the join condition\n        :type one: str\n\n        :param operator: The operator of the join condition\n        :type operator: str\n\n        :param two: The second column of the join condition\n        :type two: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        return self.join_where(table, one, operator, two, \"left\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef right_join(self, table, one=None, operator=None, two=None):\n        if isinstance(table, JoinClause):\n            table.type = \"right\"\n\n        return self.join(table, one, operator, two, \"right\")", "response": "Add a right join to the current QueryBuilder instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a right join where clause to the current QueryBuilder instance", "response": "def right_join_where(self, table, one, operator, two):\n        \"\"\"\n        Add a \"right join where\" clause to the query\n\n        :param table: The table to join with, can also be a JoinClause instance\n        :type table: str or JoinClause\n\n        :param one: The first column of the join condition\n        :type one: str\n\n        :param operator: The operator of the join condition\n        :type operator: str\n\n        :param two: The second column of the join condition\n        :type two: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        return self.join_where(table, one, operator, two, \"right\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a where clause to the query", "response": "def where(self, column, operator=Null(), value=None, boolean=\"and\"):\n        \"\"\"\n        Add a where clause to the query\n\n        :param column: The column of the where clause, can also be a QueryBuilder instance for sub where\n        :type column: str or QueryBuilder\n\n        :param operator: The operator of the where clause\n        :type operator: str\n\n        :param value: The value of the where clause\n        :type value: mixed\n\n        :param boolean: The boolean of the where clause\n        :type boolean: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        # If the column is an array, we will assume it is an array of key-value pairs\n        # and can add them each as a where clause. We will maintain the boolean we\n        # received when the method was called and pass it into the nested where.\n        if isinstance(column, dict):\n            nested = self.new_query()\n            for key, value in column.items():\n                nested.where(key, \"=\", value)\n\n            return self.where_nested(nested, boolean)\n\n        if isinstance(column, QueryBuilder):\n            return self.where_nested(column, boolean)\n\n        if isinstance(column, list):\n            nested = self.new_query()\n            for condition in column:\n                if isinstance(condition, list) and len(condition) == 3:\n                    nested.where(condition[0], condition[1], condition[2])\n                else:\n                    raise ArgumentError(\"Invalid conditions in where() clause\")\n            return self.where_nested(nested, boolean)\n\n        if value is None:\n            if not isinstance(operator, Null):\n                value = operator\n                operator = \"=\"\n            else:\n                raise ArgumentError(\"Value must be provided\")\n\n        if operator not in self._operators:\n            value = operator\n            operator = \"=\"\n\n        if isinstance(value, QueryBuilder):\n            return self._where_sub(column, operator, value, boolean)\n\n        if value is None:\n            return self.where_null(column, boolean, operator != \"=\")\n\n        type = \"basic\"\n\n        self.wheres.append(\n            {\n                \"type\": type,\n                \"column\": column,\n                \"operator\": operator,\n                \"value\": value,\n                \"boolean\": boolean,\n            }\n        )\n\n        if not isinstance(value, QueryExpression):\n            self.add_binding(value, \"where\")\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef group_by(self, *columns):\n        for column in columns:\n            self.groups.append(column)\n\n        return self", "response": "Adds a group by clause to the query"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef having(self, column, operator=None, value=None, boolean=\"and\"):\n        type = \"basic\"\n\n        self.havings.append(\n            {\n                \"type\": type,\n                \"column\": column,\n                \"operator\": operator,\n                \"value\": value,\n                \"boolean\": boolean,\n            }\n        )\n\n        if not isinstance(value, QueryExpression):\n            self.add_binding(value, \"having\")\n\n        return self", "response": "Adds a having clause to the current QueryBuilder instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a raw having clause to the query set", "response": "def having_raw(self, sql, bindings=None, boolean=\"and\"):\n        \"\"\"\n        Add a raw having clause to the query\n\n        :param sql: The raw query\n        :type sql: str\n\n        :param bindings: The query bindings\n        :type bindings: list\n\n        :param boolean: Boolean joiner type\n        :type boolean: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        type = \"raw\"\n\n        self.havings.append({\"type\": type, \"sql\": sql, \"boolean\": boolean})\n\n        self.add_binding(bindings, \"having\")\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a order by clause to the current QueryBuilder instance.", "response": "def order_by(self, column, direction=\"asc\"):\n        \"\"\"\n        Add a \"order by\" clause to the query\n\n        :param column: The order by column\n        :type column: str\n\n        :param direction: The direction of the order\n        :type direction: str\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        if self.unions:\n            prop = \"union_orders\"\n        else:\n            prop = \"orders\"\n\n        if direction.lower() == \"asc\":\n            direction = \"asc\"\n        else:\n            direction = \"desc\"\n\n        getattr(self, prop).append({\"column\": column, \"direction\": direction})\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a raw order by clause to the query.", "response": "def order_by_raw(self, sql, bindings=None):\n        \"\"\"\n        Add a raw \"order by\" clause to the query\n\n        :param sql: The raw clause\n        :type sql: str\n\n        :param bindings: The bdings\n        :param bindings: list\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        if bindings is None:\n            bindings = []\n\n        type = \"raw\"\n\n        self.orders.append({\"type\": type, \"sql\": sql})\n\n        self.add_binding(bindings, \"order\")\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the query and get the first result", "response": "def first(self, limit=1, columns=None):\n        \"\"\"\n        Execute the query and get the first results\n\n        :param limit: The number of results to get\n        :type limit: int\n\n        :param columns: The columns to get\n        :type columns: list\n\n        :return: The result\n        :rtype: mixed\n        \"\"\"\n        if not columns:\n            columns = [\"*\"]\n\n        return self.take(limit).get(columns).first()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the query as a select statement and return the result.", "response": "def get(self, columns=None):\n        \"\"\"\n        Execute the query as a \"select\" statement\n\n        :param columns: The columns to get\n        :type columns: list\n\n        :return: The result\n        :rtype: Collection\n        \"\"\"\n        if not columns:\n            columns = [\"*\"]\n\n        original = self.columns\n\n        if not original:\n            self.columns = columns\n\n        results = self._processor.process_select(self, self._run_select())\n\n        self.columns = original\n\n        return Collection(results)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the query as a select statement against the connection.", "response": "def _run_select(self):\n        \"\"\"\n        Run the query as a \"select\" statement against the connection.\n\n        :return: The result\n        :rtype: list\n        \"\"\"\n        return self._connection.select(\n            self.to_sql(), self.get_bindings(), not self._use_write_connection\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef paginate(self, per_page=15, current_page=None, columns=None):\n        if columns is None:\n            columns = [\"*\"]\n\n        page = current_page or Paginator.resolve_current_page()\n\n        total = self.get_count_for_pagination()\n\n        results = self.for_page(page, per_page).get(columns)\n\n        return LengthAwarePaginator(results, total, per_page, page)", "response": "Paginate the given query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npaginating the given query.", "response": "def simple_paginate(self, per_page=15, current_page=None, columns=None):\n        \"\"\"\n        Paginate the given query.\n\n        :param per_page: The number of records per page\n        :type per_page: int\n\n        :param current_page: The current page of results\n        :type current_page: int\n\n        :param columns: The columns to return\n        :type columns: list\n\n        :return: The paginator\n        :rtype: Paginator\n        \"\"\"\n        if columns is None:\n            columns = [\"*\"]\n\n        page = current_page or Paginator.resolve_current_page()\n\n        self.skip((page - 1) * per_page).take(per_page + 1)\n\n        return Paginator(self.get(columns), per_page, page)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chunk(self, count):\n        for chunk in self._connection.select_many(\n            count, self.to_sql(), self.get_bindings(), not self._use_write_connection\n        ):\n            yield chunk", "response": "Returns a list of count items from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list with the values of a given column and key.", "response": "def lists(self, column, key=None):\n        \"\"\"\n        Get a list with the values of a given column\n\n        :param column: The column to get the values for\n        :type column: str\n\n        :param key: The key\n        :type key: str\n\n        :return: The list of values\n        :rtype: Collection or dict\n        \"\"\"\n        columns = self._get_list_select(column, key)\n\n        if key is not None:\n            results = {}\n            for result in self.get(columns):\n                results[result[key]] = result[column]\n        else:\n            results = Collection(list(map(lambda x: x[column], self.get(columns))))\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(self):\n        limit = self.limit_\n\n        result = self.limit(1).count() > 0\n\n        self.limit(limit)\n\n        return result", "response": "Determines if any rows exist for the current query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the count result of the query", "response": "def count(self, *columns):\n        \"\"\"\n        Retrieve the \"count\" result of the query\n\n        :param columns: The columns to get\n        :type columns: tuple\n\n        :return: The count\n        :rtype: int\n        \"\"\"\n        if not columns and self.distinct_:\n            columns = self.columns\n\n        if not columns:\n            columns = [\"*\"]\n\n        return int(self.aggregate(\"count\", *columns))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aggregate(self, func, *columns):\n        if not columns:\n            columns = [\"*\"]\n\n        self.aggregate_ = {\"function\": func, \"columns\": columns}\n\n        previous_columns = self.columns\n\n        results = self.get(*columns).all()\n\n        self.aggregate_ = None\n\n        self.columns = previous_columns\n\n        if len(results) > 0:\n            return dict((k.lower(), v) for k, v in results[0].items())[\"aggregate\"]", "response": "Execute an aggregate function against the database and return the aggregate result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert(self, _values=None, **values):\n        if not values and not _values:\n            return True\n\n        if not isinstance(_values, list):\n            if _values is not None:\n                values.update(_values)\n\n            values = [values]\n        else:\n            values = _values\n            for i, value in enumerate(values):\n                values[i] = OrderedDict(sorted(value.items()))\n\n        bindings = []\n\n        for record in values:\n            for value in record.values():\n                bindings.append(value)\n\n        sql = self._grammar.compile_insert(self, values)\n\n        bindings = self._clean_bindings(bindings)\n\n        return self._connection.insert(sql, bindings)", "response": "Insert a new record into the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a new record and get the value of the primary key", "response": "def insert_get_id(self, values, sequence=None):\n        \"\"\"\n        Insert a new record and get the value of the primary key\n\n        :param values: The new record values\n        :type values: dict\n\n        :param sequence: The name of the primary key\n        :type sequence: str\n\n        :return: The value of the primary key\n        :rtype: int\n        \"\"\"\n        values = OrderedDict(sorted(values.items()))\n\n        sql = self._grammar.compile_insert_get_id(self, values, sequence)\n\n        values = self._clean_bindings(values.values())\n\n        return self._processor.process_insert_get_id(self, sql, values, sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, _values=None, **values):\n        if _values is not None:\n            values.update(_values)\n\n        values = OrderedDict(sorted(values.items()))\n\n        bindings = list(values.values()) + self.get_bindings()\n\n        sql = self._grammar.compile_update(self, values)\n\n        return self._connection.update(sql, self._clean_bindings(bindings))", "response": "Update a record in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncate(self):\n        for sql, bindings in self._grammar.compile_truncate(self).items():\n            self._connection.statement(sql, bindings)", "response": "Run a truncate statement on the table\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all of the expressions from the bindings", "response": "def _clean_bindings(self, bindings):\n        \"\"\"\n        Remove all of the expressions from bindings\n\n        :param bindings: The bindings to clean\n        :type bindings: list\n\n        :return: The cleaned bindings\n        :rtype: list\n        \"\"\"\n        return list(filter(lambda b: not isinstance(b, QueryExpression), bindings))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge another query with this one.", "response": "def merge(self, query):\n        \"\"\"\n        Merge current query with another.\n\n        :param query: The query to merge with\n        :type query: QueryBuilder\n        \"\"\"\n        self.columns += query.columns\n        self.joins += query.joins\n        self.wheres += query.wheres\n        self.groups += query.groups\n        self.havings += query.havings\n        self.orders += query.orders\n        self.distinct_ = query.distinct_\n\n        if self.columns:\n            self.columns = Collection(self.columns).unique().all()\n\n        if query.limit_:\n            self.limit_ = query.limit_\n\n        if query.offset_:\n            self.offset_ = None\n\n        self.unions += query.unions\n\n        if query.union_limit:\n            self.union_limit = query.union_limit\n\n        if query.union_offset:\n            self.union_offset = query.union_offset\n\n        self.union_orders += query.union_orders\n\n        self.merge_bindings(query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_name(self, name):\n        if self._is_identifier_quoted(name):\n            self._quoted = True\n            name = self._trim_quotes(name)\n\n        if \".\" in name:\n            parts = name.split(\".\", 1)\n            self._namespace = parts[0]\n            name = parts[1]\n\n        self._name = name", "response": "Sets the name of this asset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate an identifier name from a list of column names obeying a certain length.", "response": "def _generate_identifier_name(self, columns, prefix=\"\", max_size=30):\n        \"\"\"\n        Generates an identifier from a list of column names obeying a certain string length.\n        \"\"\"\n        hash = \"\"\n        for column in columns:\n            hash += \"%x\" % binascii.crc32(encode(str(column)))\n\n        return (prefix + \"_\" + hash)[:max_size]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef force_delete(self):\n        self.__force_deleting__ = True\n\n        self.delete()\n\n        self.__force_deleting__ = False", "response": "Force a soft delete on a soft deleted model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the soft delete query on this model instance.", "response": "def _run_soft_delete(self):\n        \"\"\"\n        Perform the actual delete query on this model instance.\n        \"\"\"\n        query = self.new_query().where(self.get_key_name(), self.get_key())\n\n        time = self.fresh_timestamp()\n        setattr(self, self.get_deleted_at_column(), time)\n\n        query.update({self.get_deleted_at_column(): self.from_datetime(time)})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore a soft - deleted model instance.", "response": "def restore(self):\n        \"\"\"\n        Restore a soft-deleted model instance.\n        \"\"\"\n        if self._fire_model_event(\"restoring\") is False:\n            return False\n\n        setattr(self, self.get_deleted_at_column(), None)\n\n        self.set_exists(True)\n\n        result = self.save()\n\n        self._fire_model_event(\"restored\")\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Query builder that only includes soft deletes at the specified soft deletes column.", "response": "def only_trashed(cls):\n        \"\"\"\n        Get a new query builder that only includes soft deletes\n\n        :type cls: orator.orm.model.Model\n\n        :rtype: orator.orm.builder.Builder\n        \"\"\"\n        instance = cls()\n\n        column = instance.get_qualified_deleted_at_column()\n\n        return instance.new_query_without_scope(SoftDeletingScope()).where_not_null(\n            column\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile a rename column command.", "response": "def compile_rename_column(self, blueprint, command, connection):\n        \"\"\"\n        Compile a rename column command.\n\n        :param blueprint: The blueprint\n        :type blueprint: Blueprint\n\n        :param command: The command\n        :type command: Fluent\n\n        :param connection: The connection\n        :type connection: orator.connections.Connection\n\n        :rtype: list\n        \"\"\"\n        sql = []\n        # If foreign keys are on, we disable them\n        foreign_keys = self._connection.select(\"PRAGMA foreign_keys\")\n        if foreign_keys:\n            foreign_keys = bool(foreign_keys[0])\n            if foreign_keys:\n                sql.append(\"PRAGMA foreign_keys = OFF\")\n\n        sql += super(SQLiteSchemaGrammar, self).compile_rename_column(\n            blueprint, command, connection\n        )\n\n        if foreign_keys:\n            sql.append(\"PRAGMA foreign_keys = ON\")\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_dbal_column_type(self, type_):\n        type_ = type_.lower()\n\n        if type_ == \"enum\":\n            return \"string\"\n\n        return super(SQLiteSchemaGrammar, self)._get_dbal_column_type(type_)", "response": "Get the dbal column type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connection(self, name=None):\n        name, type = self._parse_connection_name(name)\n\n        if name not in self._connections:\n            logger.debug(\"Initiating connection %s\" % name)\n            connection = self._make_connection(name)\n\n            self._set_connection_for_type(connection, type)\n\n            self._connections[name] = self._prepare(connection)\n\n        return self._connections[name]", "response": "Get a database connection instance for the given name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply(self, builder, model):\n        builder.where_null(model.get_qualified_deleted_at_column())\n\n        self.extend(builder)", "response": "Applies the scope to a given query builder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_deleted_at_column(self, builder):\n        if len(builder.get_query().joins) > 0:\n            return builder.get_model().get_qualified_deleted_at_column()\n        else:\n            return builder.get_model().get_deleted_at_column()", "response": "Get the deleted at column for the builder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _restore(self, builder):\n        builder.with_trashed()\n\n        return builder.update({builder.get_model().get_deleted_at_column(): None})", "response": "The restore extension.\n        method is used to restore the base record set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match(self, models, results, relation):\n        return self.match_one(models, results, relation)", "response": "Match the eagerly loaded results to their parents."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_table(self, table):\n        sql = self._grammar.compile_table_exists()\n\n        table = self._connection.get_table_prefix() + table\n\n        return len(self._connection.select(sql, [table])) > 0", "response": "Determines if the given table exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_column(self, table, column):\n        column = column.lower()\n\n        return column in list(map(lambda x: x.lower(), self.get_column_listing(table)))", "response": "Determines if the given table has a given column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the column listing for a given table.", "response": "def get_column_listing(self, table):\n        \"\"\"\n        Get the column listing for a given table.\n\n        :param table: The table\n        :type table: str\n\n        :rtype: list\n        \"\"\"\n        table = self._connection.get_table_prefix() + table\n\n        results = self._connection.select(self._grammar.compile_column_exists(table))\n\n        return self._connection.get_post_processor().process_column_listing(results)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef table(self, table):\n        try:\n            blueprint = self._create_blueprint(table)\n\n            yield blueprint\n        except Exception as e:\n            raise\n\n        try:\n            self._build(blueprint)\n        except Exception:\n            raise", "response": "Modify a table on the schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef drop(self, table):\n        blueprint = self._create_blueprint(table)\n\n        blueprint.drop()\n\n        self._build(blueprint)", "response": "Drop a table from the schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef drop_if_exists(self, table):\n        blueprint = self._create_blueprint(table)\n\n        blueprint.drop_if_exists()\n\n        self._build(blueprint)", "response": "Drop a table from the schema."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrename a table on the schema.", "response": "def rename(self, from_, to):\n        \"\"\"\n        Rename a table on the schema.\n        \"\"\"\n        blueprint = self._create_blueprint(from_)\n\n        blueprint.rename(to)\n\n        self._build(blueprint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_insert_get_id(self, query, sql, values, sequence=None):\n        result = query.get_connection().select_from_write_connection(sql, values)\n\n        id = result[0][0]\n\n        if isinstance(id, int):\n            return id\n\n        if str(id).isdigit():\n            return int(id)\n\n        return id", "response": "Process an insert get ID query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_migration(self, creator, name, table, create, path):\n        file_ = os.path.basename(creator.create(name, path, table, create))\n\n        return file_", "response": "Write the migration file to disk."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, *relations):\n        if len(self.items) > 0:\n            query = self.first().new_query().with_(*relations)\n\n            self._set_items(query.eager_load_relations(self.items))\n\n        return self", "response": "Load a set of relationships onto the collection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_select(self, query):\n        sql = super(MySQLQueryGrammar, self).compile_select(query)\n\n        if query.unions:\n            sql = \"(%s) %s\" % (sql, self._compile_unions(query))\n\n        return sql", "response": "Compile a select query into SQL\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompiling a delete statement into SQL", "response": "def compile_delete(self, query):\n        \"\"\"\n        Compile a delete statement into SQL\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :return: The compiled update\n        :rtype: str\n        \"\"\"\n        table = self.wrap_table(query.from__)\n\n        if isinstance(query.wheres, list):\n            wheres = self._compile_wheres(query)\n        else:\n            wheres = \"\"\n\n        if query.joins:\n            joins = \" %s\" % self._compile_joins(query, query.joins)\n\n            sql = \"DELETE %s FROM %s%s %s\" % (table, table, joins, wheres)\n        else:\n            sql = \"DELETE FROM %s %s\" % (table, wheres)\n\n        sql = sql.strip()\n\n        if query.orders:\n            sql += \" %s\" % self._compile_orders(query, query.orders)\n\n        if query.limit_:\n            sql += \" %s\" % self._compile_limit(query, query.limit_)\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_config(self):\n        current_path = os.path.relpath(os.getcwd())\n\n        accepted_files = [\"orator.yml\", \"orator.py\"]\n        for accepted_file in accepted_files:\n            config_file = os.path.join(current_path, accepted_file)\n            if os.path.exists(config_file):\n                if self._handle_config(config_file):\n                    return True\n\n        return False", "response": "Check presence of default config files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck and handle a config file.", "response": "def _handle_config(self, config_file):\n        \"\"\"\n        Check and handle a config file.\n\n        :param config_file: The path to the config file\n        :type config_file: str\n\n        :rtype: bool\n        \"\"\"\n        config = self._get_config(config_file)\n\n        self.resolver = DatabaseManager(\n            config.get(\"databases\", config.get(\"DATABASES\", {}))\n        )\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_config(self, path=None):\n        if not path and not self.option(\"config\"):\n            raise Exception(\"The --config|-c option is missing.\")\n\n        if not path:\n            path = self.option(\"config\")\n\n        filename, ext = os.path.splitext(path)\n        if ext in [\".yml\", \".yaml\"]:\n            with open(path) as fd:\n                config = yaml.load(fd)\n        elif ext in [\".py\"]:\n            config = {}\n\n            with open(path) as fh:\n                exec(fh.read(), {}, config)\n        else:\n            raise RuntimeError(\"Config file [%s] is not supported.\" % path)\n\n        return config", "response": "Get the config.\n\n        :rtype: dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds constraints for an eager load of the relation.", "response": "def add_eager_constraints(self, models):\n        \"\"\"\n        Set the constraints for an eager load of the relation.\n\n        :type models: list\n        \"\"\"\n        table = self._parent.get_table()\n\n        self._query.where_in(\"%s.%s\" % (table, self._first_key), self.get_keys(models))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_dictionary(self, results):\n        foreign = self._first_key\n\n        dictionary = {}\n\n        for result in results:\n            key = getattr(result, foreign)\n            if key not in dictionary:\n                dictionary[key] = []\n\n            dictionary[key].append(result)\n\n        return dictionary", "response": "Builds the model dictionary keyed by the relation s foreign key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_select_columns(self, columns=None):\n        if columns == [\"*\"] or columns is None:\n            columns = [\"%s.*\" % self._related.get_table()]\n\n        return columns + [\"%s.%s\" % (self._parent.get_table(), self._first_key)]", "response": "Set the select clause for the relation query."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs that a migration was run.", "response": "def log(self, file, batch):\n        \"\"\"\n        Log that a migration was run.\n\n        :type file: str\n        :type batch: int\n        \"\"\"\n        record = {\"migration\": file, \"batch\": batch}\n\n        self.table().insert(**record)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the migration repository data store.", "response": "def create_repository(self):\n        \"\"\"\n        Create the migration repository data store.\n        \"\"\"\n        schema = self.get_connection().get_schema_builder()\n\n        with schema.create(self._table) as table:\n            # The migrations table is responsible for keeping track of which of the\n            # migrations have actually run for the application. We'll create the\n            # table to hold the migration file's path as well as the batch ID.\n            table.string(\"migration\")\n            table.integer(\"batch\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the repository exists.", "response": "def repository_exists(self):\n        \"\"\"\n        Determine if the repository exists.\n\n        :rtype: bool\n        \"\"\"\n        schema = self.get_connection().get_schema_builder()\n\n        return schema.has_table(self._table)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd constraints to the query", "response": "def add_constraints(self):\n        \"\"\"\n        Set the base constraints of the relation query\n        \"\"\"\n        if self._constraints:\n            super(MorphOneOrMany, self).add_constraints()\n\n            self._query.where(self._morph_type, self._morph_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves a new instance of the current record in the parent models.", "response": "def save(self, model):\n        \"\"\"\n        Attach a model instance to the parent models.\n\n        :param model: The model instance to attach\n        :type model: Model\n\n        :rtype: Model\n        \"\"\"\n        model.set_attribute(self.get_plain_morph_type(), self._morph_name)\n\n        return super(MorphOneOrMany, self).save(model)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef first_or_new(self, _attributes=None, **attributes):\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self._query.where(attributes).first()\n\n        if instance is None:\n            instance = self._related.new_instance()\n            self._set_foreign_attributes_for_create(instance)\n\n        return instance", "response": "Get the first related model record matching the attributes or instantiate it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, _attributes=None, **attributes):\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self._related.new_instance(attributes)\n\n        self._set_foreign_attributes_for_create(instance)\n\n        instance.save()\n\n        return instance", "response": "Create a new instance of the related model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the foreign ID and type for creation a related model.", "response": "def _set_foreign_attributes_for_create(self, model):\n        \"\"\"\n        Set the foreign ID and type for creation a related model.\n        \"\"\"\n        model.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        model.set_attribute(self.get_plain_morph_type(), self._morph_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new migration at the given path.", "response": "def create(self, name, path, table=None, create=False):\n        \"\"\"\n        Create a new migration at the given path.\n\n        :param name: The name of the migration\n        :type name: str\n        :param path: The path of the migrations\n        :type path: str\n        :param table: The table name\n        :type table: str\n        :param create: Whether it's a create migration or not\n        :type create: bool\n\n        :rtype: str\n        \"\"\"\n        path = self._get_path(name, path)\n        if not os.path.exists(os.path.dirname(path)):\n            mkdir_p(os.path.dirname(path))\n\n        parent = os.path.join(os.path.dirname(path), \"__init__.py\")\n        if not os.path.exists(parent):\n            with open(parent, \"w\"):\n                pass\n\n        stub = self._get_stub(table, create)\n\n        with open(path, \"w\") as fh:\n            fh.write(self._populate_stub(name, stub, table))\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the migration stub template", "response": "def _get_stub(self, table, create):\n        \"\"\"\n        Get the migration stub template\n\n        :param table: The table name\n        :type table: str\n\n        :param create: Whether it's a create migration or not\n        :type create: bool\n\n        :rtype: str\n        \"\"\"\n        if table is None:\n            return BLANK_STUB\n        else:\n            if create:\n                stub = CREATE_STUB\n            else:\n                stub = UPDATE_STUB\n\n            return stub"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an insert get ID query.", "response": "def process_insert_get_id(self, query, sql, values, sequence=None):\n        \"\"\"\n        Process an \"insert get ID\" query.\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param sql: The sql query to execute\n        :type sql: str\n\n        :param values: The value bindings\n        :type values: list\n\n        :param sequence: The ids sequence\n        :type sequence: str\n\n        :return: The inserted row id\n        :rtype: int\n        \"\"\"\n        query.get_connection().insert(sql, values)\n\n        id = query.get_connection().get_cursor().lastrowid\n\n        if isinstance(id, int):\n            return id\n\n        if str(id).isdigit():\n            return int(id)\n\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_quoted_local_columns(self, platform):\n        columns = []\n\n        for column in self._local_column_names.values():\n            columns.append(column.get_quoted_name(platform))\n\n        return columns", "response": "Returns the quoted representation of the referencing table column names\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_quoted_foreign_columns(self, platform):\n        columns = []\n\n        for column in self._foreign_column_names.values():\n            columns.append(column.get_quoted_name(platform))\n\n        return columns", "response": "Returns the quoted representation of the foreign key columns associated with the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_event(self, event):\n        if self.has_option(event):\n            on_event = self.get_option(event).upper()\n\n            if on_event not in [\"NO ACTION\", \"RESTRICT\"]:\n                return on_event\n\n        return False", "response": "Returns the referential action for a given database operation and event."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, path, pretend=False):\n        self._notes = []\n\n        files = self._get_migration_files(path)\n\n        ran = self._repository.get_ran()\n\n        migrations = [f for f in files if f not in ran]\n\n        self.run_migration_list(path, migrations, pretend)", "response": "Runs the migrations for a given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a list of migrations.", "response": "def run_migration_list(self, path, migrations, pretend=False):\n        \"\"\"\n        Run a list of migrations.\n\n        :type migrations: list\n\n        :type pretend: bool\n        \"\"\"\n        if not migrations:\n            self._note(\"<info>Nothing to migrate</info>\")\n\n            return\n\n        batch = self._repository.get_next_batch_number()\n\n        for f in migrations:\n            self._run_up(path, f, batch, pretend)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_up(self, path, migration_file, batch, pretend=False):\n        migration = self._resolve(path, migration_file)\n\n        if pretend:\n            return self._pretend_to_run(migration, \"up\")\n\n        if migration.transactional:\n            with migration.db.transaction():\n                migration.up()\n        else:\n            migration.up()\n\n        self._repository.log(migration_file, batch)\n\n        self._note(\n            decode(\"[<info>OK</>] <info>Migrated</info> \")\n            + \"<fg=cyan>%s</>\" % migration_file\n        )", "response": "Run an up migration instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self, path, pretend=False):\n        self._notes = []\n\n        migrations = sorted(self._repository.get_ran(), reverse=True)\n\n        count = len(migrations)\n\n        if count == 0:\n            self._note(\"<info>Nothing to rollback.</info>\")\n        else:\n            for migration in migrations:\n                self._run_down(path, {\"migration\": migration}, pretend)\n\n        return count", "response": "Rolls all of the currently applied migrations back."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_down(self, path, migration, pretend=False):\n        migration_file = migration[\"migration\"]\n\n        instance = self._resolve(path, migration_file)\n\n        if pretend:\n            return self._pretend_to_run(instance, \"down\")\n\n        if instance.transactional:\n            with instance.db.transaction():\n                instance.down()\n        else:\n            instance.down()\n\n        self._repository.delete(migration)\n\n        self._note(\n            decode(\"[<info>OK</>] <info>Rolled back</info> \")\n            + \"<fg=cyan>%s</>\" % migration_file\n        )", "response": "Run down a migration instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_migration_files(self, path):\n        files = glob.glob(os.path.join(path, \"[0-9]*_*.py\"))\n\n        if not files:\n            return []\n\n        files = list(map(lambda f: os.path.basename(f).replace(\".py\", \"\"), files))\n\n        files = sorted(files)\n\n        return files", "response": "Get all of the migration files in a given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pretend_to_run(self, migration, method):\n        self._note(\"\")\n        names = []\n        for query in self._get_queries(migration, method):\n            name = migration.__class__.__name__\n            bindings = None\n\n            if isinstance(query, tuple):\n                query, bindings = query\n\n            query = highlight(query, SqlLexer(), CommandFormatter()).strip()\n\n            if bindings:\n                query = (query, bindings)\n\n            if name not in names:\n                self._note(\"[<info>{}</info>]\".format(name))\n                names.append(name)\n\n            self._note(query)", "response": "Pretend to run the migration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_queries(self, migration, method):\n        connection = migration.get_connection()\n        db = connection\n\n        with db.pretend():\n            getattr(migration, method)()\n\n        return db.get_logged_queries()", "response": "Get all of the queries that would be run for a migration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolve(self, path, migration_file):\n        name = \"_\".join(migration_file.split(\"_\")[4:])\n        migration_file = os.path.join(path, \"%s.py\" % migration_file)\n\n        # Loading parent module\n        parent = os.path.join(path, \"__init__.py\")\n        if not os.path.exists(parent):\n            with open(parent, \"w\"):\n                pass\n\n        load_module(\"migrations\", parent)\n\n        # Loading module\n        mod = load_module(\"migrations.%s\" % name, migration_file)\n\n        klass = getattr(mod, inflection.camelize(name))\n\n        instance = klass()\n        instance.set_connection(self.get_repository().get_connection())\n\n        return instance", "response": "Resolve a migration instance from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_pre_alter_table_index_foreign_key_sql(self, diff):\n        if not isinstance(diff.from_table, Table):\n            raise DBALException(\n                \"Sqlite platform requires for alter table the table\"\n                \"diff with reference to original table schema\"\n            )\n\n        sql = []\n        for index in diff.from_table.get_indexes().values():\n            if not index.is_primary():\n                sql.append(self.get_drop_index_sql(index, diff.name))\n\n        return sql", "response": "Returns the SQL to drop foreign key indexes from the table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_post_alter_table_index_foreign_key_sql(self, diff):\n        if not isinstance(diff.from_table, Table):\n            raise DBALException(\n                \"Sqlite platform requires for alter table the table\"\n                \"diff with reference to original table schema\"\n            )\n\n        sql = []\n\n        if diff.new_name:\n            table_name = diff.get_new_name()\n        else:\n            table_name = diff.get_name(self)\n\n        for index in self._get_indexes_in_altered_table(diff).values():\n            if index.is_primary():\n                continue\n\n            sql.append(\n                self.get_create_index_sql(index, table_name.get_quoted_name(self))\n            )\n\n        return sql", "response": "Returns the SQL to create foreign key for alter table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the ALTER TABLE SQL statement for the given table diff.", "response": "def get_alter_table_sql(self, diff):\n        \"\"\"\n        Get the ALTER TABLE SQL statement\n\n        :param diff: The table diff\n        :type diff: orator.dbal.table_diff.TableDiff\n\n        :rtype: list\n        \"\"\"\n        sql = self._get_simple_alter_table_sql(diff)\n        if sql is not False:\n            return sql\n\n        from_table = diff.from_table\n        if not isinstance(from_table, Table):\n            raise DBALException(\n                \"SQLite platform requires for the alter table the table diff \"\n                \"referencing the original table\"\n            )\n\n        table = from_table.clone()\n        columns = OrderedDict()\n        old_column_names = OrderedDict()\n        new_column_names = OrderedDict()\n        column_sql = []\n        for column_name, column in table.get_columns().items():\n            column_name = column_name.lower()\n            columns[column_name] = column\n            old_column_names[column_name] = column.get_quoted_name(self)\n            new_column_names[column_name] = column.get_quoted_name(self)\n\n        for column_name, column in diff.removed_columns.items():\n            column_name = column_name.lower()\n            if column_name in columns:\n                del columns[column_name]\n                del old_column_names[column_name]\n                del new_column_names[column_name]\n\n        for old_column_name, column in diff.renamed_columns.items():\n            old_column_name = old_column_name.lower()\n            if old_column_name in columns:\n                del columns[old_column_name]\n\n            columns[column.get_name().lower()] = column\n\n            if old_column_name in new_column_names:\n                new_column_names[old_column_name] = column.get_quoted_name(self)\n\n        for old_column_name, column_diff in diff.changed_columns.items():\n            if old_column_name in columns:\n                del columns[old_column_name]\n\n            columns[column_diff.column.get_name().lower()] = column_diff.column\n\n            if old_column_name in new_column_names:\n                new_column_names[old_column_name] = column_diff.column.get_quoted_name(\n                    self\n                )\n\n        for column_name, column in diff.added_columns.items():\n            columns[column_name.lower()] = column\n\n        table_sql = []\n\n        data_table = Table(\"__temp__\" + table.get_name())\n        new_table = Table(\n            table.get_quoted_name(self),\n            columns,\n            self._get_primary_index_in_altered_table(diff),\n            self._get_foreign_keys_in_altered_table(diff),\n            table.get_options(),\n        )\n        new_table.add_option(\"alter\", True)\n\n        sql = self.get_pre_alter_table_index_foreign_key_sql(diff)\n        sql.append(\n            \"CREATE TEMPORARY TABLE %s AS SELECT %s FROM %s\"\n            % (\n                data_table.get_quoted_name(self),\n                \", \".join(old_column_names.values()),\n                table.get_quoted_name(self),\n            )\n        )\n        sql.append(self.get_drop_table_sql(from_table))\n\n        sql += self.get_create_table_sql(new_table)\n        sql.append(\n            \"INSERT INTO %s (%s) SELECT %s FROM %s\"\n            % (\n                new_table.get_quoted_name(self),\n                \", \".join(new_column_names.values()),\n                \", \".join(old_column_names.values()),\n                data_table.get_name(),\n            )\n        )\n        sql.append(self.get_drop_table_sql(data_table))\n\n        sql += self.get_post_alter_table_index_foreign_key_sql(diff)\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_indexes_in_altered_table(self, diff):\n        indexes = diff.from_table.get_indexes()\n        column_names = self._get_column_names_in_altered_table(diff)\n\n        for key, index in OrderedDict([(k, v) for k, v in indexes.items()]).items():\n            for old_index_name, renamed_index in diff.renamed_indexes.items():\n                if key.lower() == old_index_name.lower():\n                    del indexes[key]\n\n            changed = False\n            index_columns = []\n            for column_name in index.get_columns():\n                normalized_column_name = column_name.lower()\n                if normalized_column_name not in column_names:\n                    del indexes[key]\n                    break\n                else:\n                    index_columns.append(column_names[normalized_column_name])\n                    if column_name != column_names[normalized_column_name]:\n                        changed = True\n\n            if changed:\n                indexes[key] = Index(\n                    index.get_name(),\n                    index_columns,\n                    index.is_unique(),\n                    index.is_primary(),\n                    index.get_flags(),\n                )\n\n            for index in diff.removed_indexes.values():\n                index_name = index.get_name().lower()\n                if index_name and index_name in indexes:\n                    del indexes[index_name]\n\n            changed_indexes = (\n                list(diff.changed_indexes.values())\n                + list(diff.added_indexes.values())\n                + list(diff.renamed_indexes.values())\n            )\n            for index in changed_indexes:\n                index_name = index.get_name().lower()\n                if index_name:\n                    indexes[index_name] = index\n                else:\n                    indexes[len(indexes)] = index\n\n        return indexes", "response": "Returns a dict of all indexes in the table that have been changed or removed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_column_names_in_altered_table(self, diff):\n        columns = OrderedDict()\n\n        for column_name, column in diff.from_table.get_columns().items():\n            columns[column_name.lower()] = column.get_name()\n\n        for column_name, column in diff.removed_columns.items():\n            column_name = column_name.lower()\n            if column_name in columns:\n                del columns[column_name]\n\n        for old_column_name, column in diff.renamed_columns.items():\n            column_name = column.get_name()\n            columns[old_column_name.lower()] = column_name\n            columns[column_name.lower()] = column_name\n\n        for old_column_name, column_diff in diff.changed_columns.items():\n            column_name = column_diff.column.get_name()\n            columns[old_column_name.lower()] = column_name\n            columns[column_name.lower()] = column_name\n\n        for column_name, column in diff.added_columns.items():\n            columns[column_name.lower()] = column_name\n\n        return columns", "response": "Returns a dictionary of column names in the given table diff."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of foreign keys in the table that have been changed or added or removed.", "response": "def _get_foreign_keys_in_altered_table(self, diff):\n        \"\"\"\n        :param diff: The table diff\n        :type diff: orator.dbal.table_diff.TableDiff\n\n        :rtype: dict\n        \"\"\"\n        foreign_keys = diff.from_table.get_foreign_keys()\n        column_names = self._get_column_names_in_altered_table(diff)\n\n        for key, constraint in foreign_keys.items():\n            changed = False\n            local_columns = []\n            for column_name in constraint.get_local_columns():\n                normalized_column_name = column_name.lower()\n                if normalized_column_name not in column_names:\n                    del foreign_keys[key]\n                    break\n                else:\n                    local_columns.append(column_names[normalized_column_name])\n                    if column_name != column_names[normalized_column_name]:\n                        changed = True\n\n            if changed:\n                foreign_keys[key] = ForeignKeyConstraint(\n                    local_columns,\n                    constraint.get_foreign_table_name(),\n                    constraint.get_foreign_columns(),\n                    constraint.get_name(),\n                    constraint.get_options(),\n                )\n\n        for constraint in diff.removed_foreign_keys:\n            constraint_name = constraint.get_name().lower()\n            if constraint_name and constraint_name in foreign_keys:\n                del foreign_keys[constraint_name]\n\n        foreign_keys_diff = diff.changed_foreign_keys + diff.added_foreign_keys\n        for constraint in foreign_keys_diff:\n            constraint_name = constraint.get_name().lower()\n            if constraint_name:\n                foreign_keys[constraint_name] = constraint\n            else:\n                foreign_keys[len(foreign_keys)] = constraint\n\n        return foreign_keys"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the primary index in the given table diff.", "response": "def _get_primary_index_in_altered_table(self, diff):\n        \"\"\"\n        :param diff: The table diff\n        :type diff: orator.dbal.table_diff.TableDiff\n\n        :rtype: dict\n        \"\"\"\n        primary_index = {}\n\n        for index in self._get_indexes_in_altered_table(diff).values():\n            if index.is_primary():\n                primary_index = {index.get_name(): index}\n\n        return primary_index"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompiles an update statement into SQL", "response": "def compile_update(self, query, values):\n        \"\"\"\n        Compile an update statement into SQL\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param values: The update values\n        :type values: dict\n\n        :return: The compiled update\n        :rtype: str\n        \"\"\"\n        table = self.wrap_table(query.from__)\n\n        columns = self._compile_update_columns(values)\n\n        from_ = self._compile_update_from(query)\n\n        where = self._compile_update_wheres(query)\n\n        return (\"UPDATE %s SET %s%s %s\" % (table, columns, from_, where)).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compile_update_columns(self, values):\n        columns = []\n\n        for key, value in values.items():\n            columns.append(\"%s = %s\" % (self.wrap(key), self.parameter(value)))\n\n        return \", \".join(columns)", "response": "Compile the columns for the update statement\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compile_update_from(self, query):\n        if not query.joins:\n            return \"\"\n\n        froms = []\n\n        for join in query.joins:\n            froms.append(self.wrap_table(join.table))\n\n        if len(froms):\n            return \" FROM %s\" % \", \".join(froms)\n\n        return \"\"", "response": "Compile the from clause for an update with a join."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compile_update_wheres(self, query):\n        base_where = self._compile_wheres(query)\n\n        if not query.joins:\n            return base_where\n\n        join_where = self._compile_update_join_wheres(query)\n\n        if not base_where.strip():\n            return \"WHERE %s\" % self._remove_leading_boolean(join_where)\n\n        return \"%s %s\" % (base_where, join_where)", "response": "Compile the additional where clauses for updates with joins."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile the join clauses for an update.", "response": "def _compile_update_join_wheres(self, query):\n        \"\"\"\n        Compile the \"join\" clauses for an update.\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :return: The compiled sql\n        :rtype: str\n        \"\"\"\n        join_wheres = []\n\n        for join in query.joins:\n            for clause in join.clauses:\n                join_wheres.append(self._compile_join_constraints(clause))\n\n        return \" \".join(join_wheres)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompiles an insert and get ID statement into SQL.", "response": "def compile_insert_get_id(self, query, values, sequence=None):\n        \"\"\"\n        Compile an insert and get ID statement into SQL.\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param values: The values to insert\n        :type values: dict\n\n        :param sequence: The id sequence\n        :type sequence: str\n\n        :return: The compiled statement\n        :rtype: str\n        \"\"\"\n        if sequence is None:\n            sequence = \"id\"\n\n        return \"%s RETURNING %s\" % (\n            self.compile_insert(query, values),\n            self.wrap(sequence),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef qmark(cls, query):\n\n        def sub_sequence(m):\n            s = m.group(0)\n            if s == \"??\":\n                return \"?\"\n            if s == \"%\":\n                return \"%%\"\n            else:\n                return \"%s\"\n\n        return cls.RE_QMARK.sub(sub_sequence, query)", "response": "Convert a qmark query into a format style."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef touch(self):\n        column = self.get_related().get_updated_at_column()\n\n        self.raw_update({column: self.get_related().fresh_timestamp()})", "response": "Touch all of the related models for the relationship."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a raw update against the base query.", "response": "def raw_update(self, attributes=None):\n        \"\"\"\n        Run a raw update against the base query.\n\n        :type attributes: dict\n\n        :rtype: int\n        \"\"\"\n        if attributes is None:\n            attributes = {}\n\n        if self._query is not None:\n            return self._query.update(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the constraints for a relationship count query.", "response": "def get_relation_count_query(self, query, parent):\n        \"\"\"\n        Add the constraints for a relationship count query.\n\n        :type query: Builder\n        :type parent: Builder\n\n        :rtype: Builder\n        \"\"\"\n        query.select(QueryExpression(\"COUNT(*)\"))\n\n        key = self.wrap(self.get_qualified_parent_key_name())\n\n        return query.where(self.get_has_compare_key(), \"=\", QueryExpression(key))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a callback with constraints disabled on the relation.", "response": "def no_constraints(cls, with_subclasses=False):\n        \"\"\"\n        Runs a callback with constraints disabled on the relation.\n        \"\"\"\n        cls._constraints = False\n\n        if with_subclasses:\n            for klass in cls.__subclasses__():\n                klass._constraints = False\n\n        try:\n            yield cls\n        except Exception:\n            raise\n        finally:\n            cls._constraints = True\n            if with_subclasses:\n                for klass in cls.__subclasses__():\n                    klass._constraints = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap(self, value):\n        return self._parent.new_query().get_query().get_grammar().wrap(value)", "response": "Wrap the given value with the parent s query grammar."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(template):\n\n    try:\n        data = load_json(template)\n        return data, \"json\"\n    except ValueError as e:\n        try:\n            data = load_yaml(template)\n            return data, \"yaml\"\n        except Exception:\n            raise e", "response": "Try to guess the input format\n    Try to guess the input format\n            Try to guess the input format\nBridge"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump some data into a YAML file.", "response": "def dump_yaml(data, clean_up=False, long_form=False):\n    \"\"\"\n    Output some YAML\n    \"\"\"\n\n    return yaml.dump(\n        data,\n        Dumper=get_dumper(clean_up, long_form),\n        default_flow_style=False,\n        allow_unicode=True\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_json(template, clean_up=False):\n\n    data = load_yaml(template)\n\n    if clean_up:\n        data = clean(data)\n\n    return dump_json(data)", "response": "Convert a YAML file to JSON."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a JSON object to YAML.", "response": "def to_yaml(template, clean_up=False, long_form=False):\n    \"\"\"\n    Assume the input is JSON and convert to YAML\n    \"\"\"\n\n    data = load_json(template)\n\n    if clean_up:\n        data = clean(data)\n\n    return dump_yaml(data, clean_up, long_form)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flip(template, in_format=None, out_format=None, clean_up=False, no_flip=False, long_form=False):\n\n    # Do we need to figure out the input format?\n    if not in_format:\n        # Load the template as JSON?\n        if (out_format == \"json\" and no_flip) or (out_format == \"yaml\" and not no_flip):\n            in_format = \"json\"\n        elif (out_format == \"yaml\" and no_flip) or (out_format == \"json\" and not no_flip):\n            in_format = \"yaml\"\n\n    # Load the data\n    if in_format == \"json\":\n        data = load_json(template)\n    elif in_format == \"yaml\":\n        data = load_yaml(template)\n    else:\n        data, in_format = load(template)\n\n    # Clean up?\n    if clean_up:\n        data = clean(data)\n\n    # Figure out the output format\n    if not out_format:\n        if (in_format == \"json\" and no_flip) or (in_format == \"yaml\" and not no_flip):\n            out_format = \"json\"\n        else:\n            out_format = \"yaml\"\n\n    # Finished!\n    if out_format == \"json\":\n        if sys.version[0] == \"3\":\n            return dump_json(data)\n        else:\n            return dump_json(data).encode('utf-8')\n\n    return dump_yaml(data, clean_up, long_form)", "response": "Flips the input format and converts the data to the output format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a Join expression into a single string.", "response": "def convert_join(value):\n    \"\"\"\n    Fix a Join ;)\n    \"\"\"\n\n    if not isinstance(value, list) or len(value) != 2:\n        # Cowardly refuse\n        return value\n\n    sep, parts = value[0], value[1]\n\n    if isinstance(parts, six.string_types):\n        return parts\n\n    if not isinstance(parts, list):\n        # This looks tricky, just return the join as it was\n        return {\n            \"Fn::Join\": value,\n        }\n\n    plain_string = True\n\n    args = ODict()\n    new_parts = []\n\n    for part in parts:\n        part = clean(part)\n\n        if isinstance(part, dict):\n            plain_string = False\n\n            if \"Ref\" in part:\n                new_parts.append(\"${{{}}}\".format(part[\"Ref\"]))\n            elif \"Fn::GetAtt\" in part:\n                params = part[\"Fn::GetAtt\"]\n                new_parts.append(\"${{{}}}\".format(\".\".join(params)))\n            else:\n                for key, val in args.items():\n                    # we want to bail if a conditional can evaluate to AWS::NoValue\n                    if isinstance(val, dict):\n                        if \"Fn::If\" in val and \"AWS::NoValue\" in str(val[\"Fn::If\"]):\n                            return {\n                                \"Fn::Join\": value,\n                            }\n\n                    if val == part:\n                        param_name = key\n                        break\n                else:\n                    param_name = \"Param{}\".format(len(args) + 1)\n                    args[param_name] = part\n\n                new_parts.append(\"${{{}}}\".format(param_name))\n\n        elif isinstance(part, six.string_types):\n            new_parts.append(part.replace(\"${\", \"${!\"))\n\n        else:\n            # Doing something weird; refuse\n            return {\n                \"Fn::Join\": value\n            }\n\n    source = sep.join(new_parts)\n\n    if plain_string:\n        return source\n\n    if args:\n        return ODict((\n            (\"Fn::Sub\", [source, args]),\n        ))\n\n    return ODict((\n        (\"Fn::Sub\", source),\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans up the source dict", "response": "def clean(source):\n    \"\"\"\n    Clean up the source:\n    * Replace use of Fn::Join with Fn::Sub\n    \"\"\"\n\n    if isinstance(source, dict):\n        for key, value in source.items():\n            if key == \"Fn::Join\":\n                return convert_join(value)\n            else:\n                source[key] = clean(value)\n\n    elif isinstance(source, list):\n        return [clean(item) for item in source]\n\n    return source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_representer(dumper, value):\n\n    value = ODict(value.items())\n\n    if len(value.keys()) == 1:\n        key = list(value.keys())[0]\n\n        if key in CONVERTED_SUFFIXES:\n            return fn_representer(dumper, key, value[key])\n\n        if key.startswith(FN_PREFIX):\n            return fn_representer(dumper, key[4:], value[key])\n\n    return dumper.represent_mapping(TAG_MAP, value, flow_style=False)", "response": "Deal with!Ref style function format and OrderedDict\n    Deal with!Ref style function format and OrderedDict\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreconstructing !GetAtt into a list", "response": "def construct_getatt(node):\n    \"\"\"\n    Reconstruct !GetAtt into a list\n    \"\"\"\n\n    if isinstance(node.value, six.text_type):\n        return node.value.split(\".\", 1)\n    elif isinstance(node.value, list):\n        return [s.value for s in node.value]\n    else:\n        raise ValueError(\"Unexpected node type: {}\".format(type(node.value)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_mapping(self, node, deep=False):\n\n    mapping = ODict()\n\n    for key_node, value_node in node.value:\n        key = self.construct_object(key_node, deep=deep)\n        value = self.construct_object(value_node, deep=deep)\n\n        mapping[key] = value\n\n    return mapping", "response": "Construct a mapping from a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates versions of the credential - store", "response": "def updateVersions(region=\"us-east-1\", table=\"credential-store\"):\n    '''\n    do a full-table scan of the credential-store,\n    and update the version format of every credential if it is an integer\n    '''\n    dynamodb = boto3.resource('dynamodb', region_name=region)\n    secrets = dynamodb.Table(table)\n\n    response = secrets.scan(ProjectionExpression=\"#N, version, #K, contents, hmac\",\n                            ExpressionAttributeNames={\"#N\": \"name\", \"#K\": \"key\"})\n\n    items = response[\"Items\"]\n\n    for old_item in items:\n        if isInt(old_item['version']):\n            new_item = copy.copy(old_item)\n            new_item['version'] = credstash.paddedInt(new_item['version'])\n            if new_item['version'] != old_item['version']:\n                secrets.put_item(Item=new_item)\n                secrets.delete_item(Key={'name': old_item['name'], 'version': old_item['version']})\n        else:\n            print \"Skipping item: %s, %s\" % (old_item['name'], old_item['version'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string that contains i left - padded with 0 s up to PAD_LEN digits.", "response": "def paddedInt(i):\n    '''\n    return a string that contains `i`, left-padded with 0's up to PAD_LEN digits\n    '''\n    i_str = str(i)\n    pad = PAD_LEN - len(i_str)\n    return (pad * \"0\") + i_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the highest version of name in the table", "response": "def getHighestVersion(name, region=None, table=\"credential-store\",\n                      **kwargs):\n    '''\n    Return the highest version of `name` in the table\n    '''\n    session = get_session(**kwargs)\n\n    dynamodb = session.resource('dynamodb', region_name=region)\n    secrets = dynamodb.Table(table)\n\n    response = secrets.query(Limit=1,\n                             ScanIndexForward=False,\n                             ConsistentRead=True,\n                             KeyConditionExpression=boto3.dynamodb.conditions.Key(\n                                 \"name\").eq(name),\n                             ProjectionExpression=\"version\")\n\n    if response[\"Count\"] == 0:\n        return 0\n    return response[\"Items\"][0][\"version\"]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_fail(func):\n    '''\n    A decorator to cleanly exit on a failed call to AWS.\n    catch a `botocore.exceptions.ClientError` raised from an action.\n    This sort of error is raised if you are targeting a region that\n    isn't set up (see, `credstash setup`.\n    '''\n    def func_wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except botocore.exceptions.ClientError as e:\n            print(str(e), file=sys.stderr)\n            sys.exit(1)\n    return func_wrapper", "response": "A decorator to cleanly exit on a failed call to AWS."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo a full - table scan of the credential - store and return the names and versions of every credential - langgear object", "response": "def listSecrets(region=None, table=\"credential-store\", **kwargs):\n    '''\n    do a full-table scan of the credential-store,\n    and return the names and versions of every credential\n    '''\n    session = get_session(**kwargs)\n\n    dynamodb = session.resource('dynamodb', region_name=region)\n    secrets = dynamodb.Table(table)\n\n    last_evaluated_key = True\n    items = []\n\n    while last_evaluated_key:\n        params = dict(\n            ProjectionExpression=\"#N, version, #C\",\n            ExpressionAttributeNames={\"#N\": \"name\", \"#C\": \"comment\"}\n        )\n        if last_evaluated_key is not True:\n            params['ExclusiveStartKey'] = last_evaluated_key\n\n        response = secrets.scan(**params)\n\n        last_evaluated_key = response.get('LastEvaluatedKey')  # will set last evaluated key to a number\n        items.extend(response['Items'])\n\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef putSecret(name, secret, version=\"\", kms_key=\"alias/credstash\",\n              region=None, table=\"credential-store\", context=None,\n              digest=DEFAULT_DIGEST, comment=\"\", **kwargs):\n    '''\n    put a secret called `name` into the secret-store,\n    protected by the key kms_key\n    '''\n    if not context:\n        context = {}\n    session = get_session(**kwargs)\n    kms = session.client('kms', region_name=region)\n    key_service = KeyService(kms, kms_key, context)\n    sealed = seal_aes_ctr_legacy(\n        key_service,\n        secret,\n        digest_method=digest,\n    )\n\n    dynamodb = session.resource('dynamodb', region_name=region)\n    secrets = dynamodb.Table(table)\n\n    data = {\n        'name': name,\n        'version': paddedInt(version),\n    }\n    if comment:\n        data['comment'] = comment\n    data.update(sealed)\n\n    return secrets.put_item(Item=data, ConditionExpression=Attr('name').not_exists())", "response": "Put a secret into the secret - store"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAllSecrets(version=\"\", region=None, table=\"credential-store\",\n                  context=None, credential=None, session=None, **kwargs):\n    '''\n    fetch and decrypt all secrets\n    '''\n    if session is None:\n        session = get_session(**kwargs)\n    dynamodb = session.resource('dynamodb', region_name=region)\n    kms = session.client('kms', region_name=region)\n    secrets = listSecrets(region, table, **kwargs)\n\n    # Only return the secrets that match the pattern in `credential`\n    # This already works out of the box with the CLI get action,\n    # but that action doesn't support wildcards when using as library\n    if credential and WILDCARD_CHAR in credential:\n        names = set(expand_wildcard(credential,\n                                    [x[\"name\"]\n                                     for x in secrets]))\n    else:\n        names = set(x[\"name\"] for x in secrets)\n\n    pool = ThreadPool(min(len(names), THREAD_POOL_MAX_SIZE))\n    results = pool.map(\n        lambda credential: getSecret(credential, version, region, table, context, dynamodb, kms, **kwargs),\n        names)\n    pool.close()\n    pool.join()\n    return dict(zip(names, results))", "response": "fetch and decrypt all secrets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching and decrypt the secret called name", "response": "def getSecret(name, version=\"\", region=None,\n              table=\"credential-store\", context=None,\n              dynamodb=None, kms=None, **kwargs):\n    '''\n    fetch and decrypt the secret called `name`\n    '''\n    if not context:\n        context = {}\n\n    # Can we cache\n    if dynamodb is None or kms is None:\n        session = get_session(**kwargs)\n        if dynamodb is None:\n            dynamodb = session.resource('dynamodb', region_name=region)\n        if kms is None:\n            kms = session.client('kms', region_name=region)\n\n    secrets = dynamodb.Table(table)\n\n    if version == \"\":\n        # do a consistent fetch of the credential with the highest version\n        response = secrets.query(Limit=1,\n                                 ScanIndexForward=False,\n                                 ConsistentRead=True,\n                                 KeyConditionExpression=boto3.dynamodb.conditions.Key(\"name\").eq(name))\n        if response[\"Count\"] == 0:\n            raise ItemNotFound(\"Item {'name': '%s'} couldn't be found.\" % name)\n        material = response[\"Items\"][0]\n    else:\n        response = secrets.get_item(Key={\"name\": name, \"version\": version})\n        if \"Item\" not in response:\n            raise ItemNotFound(\n                \"Item {'name': '%s', 'version': '%s'} couldn't be found.\" % (name, version))\n        material = response[\"Item\"]\n\n    key_service = KeyService(kms, None, context)\n\n    return open_aes_ctr_legacy(key_service, material)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createDdbTable(region=None, table=\"credential-store\", **kwargs):\n    '''\n    create the secret store table in DDB in the specified region\n    '''\n    session = get_session(**kwargs)\n    dynamodb = session.resource(\"dynamodb\", region_name=region)\n    if table in (t.name for t in dynamodb.tables.all()):\n        print(\"Credential Store table already exists\")\n        return\n\n    print(\"Creating table...\")\n    dynamodb.create_table(\n        TableName=table,\n        KeySchema=[\n            {\n                \"AttributeName\": \"name\",\n                \"KeyType\": \"HASH\",\n            },\n            {\n                \"AttributeName\": \"version\",\n                \"KeyType\": \"RANGE\",\n            }\n        ],\n        AttributeDefinitions=[\n            {\n                \"AttributeName\": \"name\",\n                \"AttributeType\": \"S\",\n            },\n            {\n                \"AttributeName\": \"version\",\n                \"AttributeType\": \"S\",\n            },\n        ],\n        ProvisionedThroughput={\n            \"ReadCapacityUnits\": 1,\n            \"WriteCapacityUnits\": 1,\n        }\n    )\n\n    print(\"Waiting for table to be created...\")\n    client = session.client(\"dynamodb\", region_name=region)\n\n    response = client.describe_table(TableName=table)\n\n    client.get_waiter(\"table_exists\").wait(TableName=table)\n\n    print(\"Adding tag...\")\n\n    client.tag_resource(\n        ResourceArn=response[\"Table\"][\"TableArn\"],\n        Tags=[\n            {\n                'Key': \"Name\",\n                'Value': \"credstash\"\n            },\n        ]\n    )\n\n    print(\"Table has been created. \"\n          \"Go read the README about how to create your KMS key\")", "response": "create the secret store table in the specified region"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen AES key using legacy key service.", "response": "def open_aes_ctr_legacy(key_service, material):\n    \"\"\"\n    Decrypts secrets stored by `seal_aes_ctr_legacy`.\n    Assumes that the plaintext is unicode (non-binary).\n    \"\"\"\n    key = key_service.decrypt(b64decode(material['key']))\n    digest_method = material.get('digest', DEFAULT_DIGEST)\n    ciphertext = b64decode(material['contents'])\n    if hasattr(material['hmac'], \"value\"):\n        hmac = codecs.decode(material['hmac'].value, \"hex\")\n    else:\n        hmac = codecs.decode(material['hmac'], \"hex\")\n    return _open_aes_ctr(key, LEGACY_NONCE, ciphertext, hmac, digest_method).decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencrypts secret using the key service.", "response": "def seal_aes_ctr_legacy(key_service, secret, digest_method=DEFAULT_DIGEST):\n    \"\"\"\n    Encrypts `secret` using the key service.\n    You can decrypt with the companion method `open_aes_ctr_legacy`.\n    \"\"\"\n    # generate a a 64 byte key.\n    # Half will be for data encryption, the other half for HMAC\n    key, encoded_key = key_service.generate_key_data(64)\n    ciphertext, hmac = _seal_aes_ctr(\n        secret, key, LEGACY_NONCE, digest_method,\n    )\n    return {\n        'key': b64encode(encoded_key).decode('utf-8'),\n        'contents': b64encode(ciphertext).decode('utf-8'),\n        'hmac': codecs.encode(hmac, \"hex_codec\"),\n        'digest': digest_method,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parser():\n    parsers = {}\n    parsers['super'] = argparse.ArgumentParser(\n        description=\"A credential/secret storage system\")\n\n    parsers['super'].add_argument(\"-r\", \"--region\",\n                                  help=\"the AWS region in which to operate. \"\n                                  \"If a region is not specified, credstash \"\n                                  \"will use the value of the \"\n                                  \"AWS_DEFAULT_REGION env variable, \"\n                                  \"or if that is not set, the value in \"\n                                  \"`~/.aws/config`. As a last resort, \"\n                                  \"it will use \" + DEFAULT_REGION)\n    parsers['super'].add_argument(\"-t\", \"--table\", default=\"credential-store\",\n                                  help=\"DynamoDB table to use for \"\n                                  \"credential storage\")\n    role_parse = parsers['super'].add_mutually_exclusive_group()\n    role_parse.add_argument(\"-p\", \"--profile\", default=None,\n                            help=\"Boto config profile to use when \"\n                            \"connecting to AWS\")\n    role_parse.add_argument(\"-n\", \"--arn\", default=None,\n                            help=\"AWS IAM ARN for AssumeRole\")\n    subparsers = parsers['super'].add_subparsers(help='Try commands like '\n                                                 '\"{name} get -h\" or \"{name} '\n                                                 'put --help\" to get each '\n                                                 'sub command\\'s options'\n                                                 .format(name=sys.argv[0]))\n\n    action = 'delete'\n    parsers[action] = subparsers.add_parser(action,\n                                            help='Delete a credential from the store')\n    parsers[action].add_argument(\"credential\", type=str,\n                                 help=\"the name of the credential to delete\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'get'\n    parsers[action] = subparsers.add_parser(action, help=\"Get a credential \"\n                                            \"from the store\")\n    parsers[action].add_argument(\"credential\", type=str,\n                                 help=\"the name of the credential to get. \"\n                                 \"Using the wildcard character '%s' will \"\n                                 \"search for credentials that match the \"\n                                 \"pattern\" % WILDCARD_CHAR)\n    parsers[action].add_argument(\"context\", type=key_value_pair,\n                                 action=KeyValueToDictionary, nargs='*',\n                                 help=\"encryption context key/value pairs \"\n                                 \"associated with the credential in the form \"\n                                 \"of \\\"key=value\\\"\")\n    parsers[action].add_argument(\"-n\", \"--noline\", action=\"store_true\",\n                                 help=\"Don't append newline to returned \"\n                                 \"value (useful in scripts or with \"\n                                 \"binary files)\")\n    parsers[action].add_argument(\"-v\", \"--version\", default=\"\",\n                                 help=\"Get a specific version of the \"\n                                 \"credential (defaults to the latest version)\")\n    parsers[action].add_argument(\"-f\", \"--format\", default=\"json\",\n                                 choices=[\"json\", \"csv\", \"dotenv\"] +\n                                 ([] if NO_YAML else [\"yaml\"]),\n                                 help=\"Output format. json(default) \" +\n                                 (\"\" if NO_YAML else \"yaml \") + \" csv or dotenv.\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'getall'\n    parsers[action] = subparsers.add_parser(action,\n                                            help=\"Get all credentials from \"\n                                            \"the store\")\n    parsers[action].add_argument(\"context\", type=key_value_pair,\n                                 action=KeyValueToDictionary, nargs='*',\n                                 help=\"encryption context key/value pairs \"\n                                 \"associated with the credential in the form \"\n                                 \"of \\\"key=value\\\"\")\n    parsers[action].add_argument(\"-v\", \"--version\", default=\"\",\n                                 help=\"Get a specific version of the \"\n                                 \"credential (defaults to the latest version)\")\n    parsers[action].add_argument(\"-f\", \"--format\", default=\"json\",\n                                 choices=[\"json\", \"csv\", \"dotenv\"] +\n                                 ([] if NO_YAML else [\"yaml\"]),\n                                 help=\"Output format. json(default) \" +\n                                 (\"\" if NO_YAML else \"yaml \") + \" csv or dotenv.\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'keys'\n    parsers[action] = subparsers.add_parser(action,\n                                            help=\"List all keys in the store\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'list'\n    parsers[action] = subparsers.add_parser(action,\n                                            help=\"list credentials and \"\n                                            \"their versions\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'put'\n    parsers[action] = subparsers.add_parser(action,\n                                            help=\"Put a credential into \"\n                                            \"the store\")\n    parsers[action].add_argument(\"credential\", type=str,\n                                 help=\"the name of the credential to store\")\n    parsers[action].add_argument(\"value\", type=value_or_filename,\n                                 help=\"the value of the credential to store \"\n                                 \"or, if beginning with the \\\"@\\\" character, \"\n                                 \"the filename of the file containing \"\n                                 \"the value, or pass \\\"-\\\" to read the value \"\n                                 \"from stdin\", default=\"\", nargs=\"?\")\n    parsers[action].add_argument(\"context\", type=key_value_pair,\n                                 action=KeyValueToDictionary, nargs='*',\n                                 help=\"encryption context key/value pairs \"\n                                 \"associated with the credential in the form \"\n                                 \"of \\\"key=value\\\"\")\n    parsers[action].add_argument(\"-k\", \"--key\", default=\"alias/credstash\",\n                                 help=\"the KMS key-id of the master key \"\n                                 \"to use. See the README for more \"\n                                 \"information. Defaults to alias/credstash\")\n    parsers[action].add_argument(\"-c\", \"--comment\", type=str,\n                                 help=\"Include reference information or a comment about \"\n                                 \"value to be stored.\")\n    parsers[action].add_argument(\"-v\", \"--version\", default=\"1\",\n                                 help=\"Put a specific version of the \"\n                                 \"credential (update the credential; \"\n                                 \"defaults to version `1`).\")\n    parsers[action].add_argument(\"-a\", \"--autoversion\", action=\"store_true\",\n                                 help=\"Automatically increment the version of \"\n                                 \"the credential to be stored. This option \"\n                                 \"causes the `-v` flag to be ignored. \"\n                                 \"(This option will fail if the currently stored \"\n                                 \"version is not numeric.)\")\n    parsers[action].add_argument(\"-d\", \"--digest\", default=DEFAULT_DIGEST,\n                                 choices=HASHING_ALGORITHMS,\n                                 help=\"the hashing algorithm used to \"\n                                 \"to encrypt the data. Defaults to SHA256\")\n    parsers[action].add_argument(\"-P\", \"--prompt\", action=\"store_true\",\n                                 help=\"Prompt for secret\")\n    parsers[action].set_defaults(action=action)\n\n    action = 'putall'\n    parsers[action] = subparsers.add_parser(action,\n                                            help=\"Put credentials from json into \"\n                                                 \"the store\")\n    parsers[action].add_argument(\"credentials\", type=value_or_filename,\n                                 help=\"the value of the credential to store \"\n                                      \"or, if beginning with the \\\"@\\\" character, \"\n                                      \"the filename of the file containing \"\n                                      \"the values, or pass \\\"-\\\" to read the values \"\n                                      \"from stdin. Should be in json format.\", default=\"\")\n    parsers[action].add_argument(\"context\", type=key_value_pair,\n                                 action=KeyValueToDictionary, nargs='*',\n                                 help=\"encryption context key/value pairs \"\n                                      \"associated with the credential in the form \"\n                                      \"of \\\"key=value\\\"\")\n    parsers[action].add_argument(\"-k\", \"--key\", default=\"alias/credstash\",\n                                 help=\"the KMS key-id of the master key \"\n                                      \"to use. See the README for more \"\n                                      \"information. Defaults to alias/credstash\")\n    parsers[action].add_argument(\"-v\", \"--version\", default=\"\",\n                                 help=\"Put a specific version of the \"\n                                      \"credential (update the credential; \"\n                                      \"defaults to version `1`).\")\n    parsers[action].add_argument(\"-a\", \"--autoversion\", action=\"store_true\",\n                                 help=\"Automatically increment the version of \"\n                                      \"the credential to be stored. This option \"\n                                      \"causes the `-v` flag to be ignored. \"\n                                      \"(This option will fail if the currently stored \"\n                                      \"version is not numeric.)\")\n    parsers[action].add_argument(\"-d\", \"--digest\", default=\"SHA256\",\n                                 choices=HASHING_ALGORITHMS,\n                                 help=\"the hashing algorithm used to \"\n                                      \"to encrypt the data. Defaults to SHA256\")\n    parsers[action].set_defaults(action=action)\n    action = 'setup'\n    parsers[action] = subparsers.add_parser(action,\n                                            help='setup the credential store')\n    parsers[action].set_defaults(action=action)\n    return parsers", "response": "get the parsers dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_status(self):\n        logger.debug(\"Checking for a broker_url on django settings...\")\n\n        broker_url = getattr(settings, \"BROKER_URL\", None)\n\n        logger.debug(\"Got %s as the broker_url. Connecting to rabbit...\", broker_url)\n\n        logger.debug(\"Attempting to connect to rabbit...\")\n        try:\n            # conn is used as a context to release opened resources later\n            with Connection(broker_url) as conn:\n                conn.connect()  # exceptions may be raised upon calling connect\n        except ConnectionRefusedError as e:\n            self.add_error(ServiceUnavailable(\"Unable to connect to RabbitMQ: Connection was refused.\"), e)\n\n        except AccessRefused as e:\n            self.add_error(ServiceUnavailable(\"Unable to connect to RabbitMQ: Authentication error.\"), e)\n\n        except IOError as e:\n            self.add_error(ServiceUnavailable(\"IOError\"), e)\n\n        except BaseException as e:\n            self.add_error(ServiceUnavailable(\"Unknown error\"), e)\n        else:\n            logger.debug(\"Connection estabilished. RabbitMQ is healthy.\")", "response": "Check RabbitMQ service by opening and closing a broker channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_string(cls, value):\n        match = cls.pattern.search(value)\n        if match is None:\n            raise ValueError('\"%s\" is not a valid media type' % value)\n        try:\n            return cls(match.group('mime_type'), float(match.group('weight') or 1))\n        except ValueError:\n            return cls(value)", "response": "Return single instance parsed from given accept header string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing HTTP Accept header and return instances sorted by weight.", "response": "def parse_header(cls, value='*/*'):\n        \"\"\"Parse HTTP accept header and return instances sorted by weight.\"\"\"\n        yield from sorted((\n            cls.from_string(token.strip())\n            for token in value.split(',')\n            if token.strip()\n        ), reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_to_timezone_naive(time_to_freeze):\n    if time_to_freeze.tzinfo:\n        time_to_freeze -= time_to_freeze.utcoffset()\n        time_to_freeze = time_to_freeze.replace(tzinfo=None)\n    return time_to_freeze", "response": "Converts a potentially timezone - aware datetime to a naive UTC datetime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_time_to_freeze(time_to_freeze_str):\n    if time_to_freeze_str is None:\n        time_to_freeze_str = datetime.datetime.utcnow()\n\n    if isinstance(time_to_freeze_str, datetime.datetime):\n        time_to_freeze = time_to_freeze_str\n    elif isinstance(time_to_freeze_str, datetime.date):\n        time_to_freeze = datetime.datetime.combine(time_to_freeze_str, datetime.time())\n    elif isinstance(time_to_freeze_str, datetime.timedelta):\n        time_to_freeze = datetime.datetime.utcnow() + time_to_freeze_str\n    else:\n        time_to_freeze = parser.parse(time_to_freeze_str)\n\n    return convert_to_timezone_naive(time_to_freeze)", "response": "Parses all the possible inputs for freeze_time\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef move_to(self, target_datetime):\n        target_datetime = _parse_time_to_freeze(target_datetime)\n        delta = target_datetime - self.time_to_freeze\n        self.tick(delta=delta)", "response": "Moves frozen date to the given datetime"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing data nodes RPCs and notifications in a single module.", "response": "def process_module(self, yam):\n        \"\"\"Process data nodes, RPCs and notifications in a single module.\"\"\"\n        for ann in yam.search((\"ietf-yang-metadata\", \"annotation\")):\n            self.process_annotation(ann)\n        for ch in yam.i_children[:]:\n            if ch.keyword == \"rpc\":\n                self.process_rpc(ch)\n            elif ch.keyword == \"notification\":\n                self.process_notification(ch)\n            else:\n                continue\n            yam.i_children.remove(ch)\n        self.process_children(yam, \"//nc:*\", 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing input and output parts of rpc.", "response": "def process_rpc(self, rpc):\n        \"\"\"Process input and output parts of `rpc`.\"\"\"\n        p = \"/nc:rpc/\" + self.qname(rpc)\n        tmpl = self.xsl_template(p)\n        inp = rpc.search_one(\"input\")\n        if inp is not None:\n            ct = self.xsl_calltemplate(\"rpc-input\", tmpl)\n            self.xsl_withparam(\"nsid\", rpc.i_module.i_modulename + \":\", ct)\n            self.process_children(inp, p, 2)\n        outp = rpc.search_one(\"output\")\n        if outp is not None:\n            self.process_children(outp, \"/nc:rpc-reply\", 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing event notification ntf.", "response": "def process_notification(self, ntf):\n        \"\"\"Process event notification `ntf`.\"\"\"\n        p = \"/en:notification/\" + self.qname(ntf)\n        tmpl = self.xsl_template(p)\n        ct = self.xsl_calltemplate(\"container\", tmpl)\n        self.xsl_withparam(\"level\", \"1\", ct)\n        if ntf.arg == \"eventTime\":            # local name collision\n            self.xsl_withparam(\"nsid\", ntf.i_module.i_modulename + \":\", ct)\n        self.process_children(ntf, p, 2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_children(self, node, path, level, parent=None):\n        data_parent = parent if parent else node\n        chs = node.i_children\n        for ch in chs:\n            if ch.keyword in [\"choice\", \"case\"]:\n                self.process_children(ch, path, level, node)\n                continue\n            p = path + \"/\" + self.qname(ch)\n            tmpl = self.xsl_template(p)\n            ct = self.xsl_calltemplate(ch.keyword, tmpl)\n            self.xsl_withparam(\"level\", \"%d\" % level, ct)\n            if (data_parent.i_module is None or\n                ch.i_module.i_modulename != data_parent.i_module.i_modulename):\n                self.xsl_withparam(\"nsid\", ch.i_module.i_modulename + \":\", ct)\n            if ch.keyword in [\"leaf\", \"leaf-list\"]:\n                self.type_param(ch, ct)\n            elif ch.keyword != \"anyxml\":\n                offset = 2 if ch.keyword == \"list\" else 1\n                self.process_children(ch, p, level + offset)", "response": "Processes all children of node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves the type of a leaf or leaf - list node for JSON.", "response": "def type_param(self, node, ct):\n        \"\"\"Resolve the type of a leaf or leaf-list node for JSON.\n        \"\"\"\n        types = self.get_types(node)\n        ftyp = types[0]\n        if len(types) == 1:\n            if ftyp in type_class:\n                jtyp = type_class[ftyp]\n            else:\n                jtyp = \"other\"\n            self.xsl_withparam(\"type\", jtyp, ct)\n        elif ftyp in [\"string\", \"enumeration\", \"bits\", \"binary\",\n                      \"identityref\", \"instance-identifier\"]:\n            self.xsl_withparam(\"type\", \"string\", ct)\n        else:\n            opts = []\n            for t in types:\n                if t in union_class:\n                    ut = union_class[t]\n                elif t in [\"int64\", \"uint64\"] or t.startswith(\"decimal@\"):\n                    ut = t\n                else:\n                    ut = \"other\"\n                if ut not in opts:\n                    opts.append(ut)\n                    if ut == \"other\": break\n                    if ut == \"decimal\" and \"integer\" not in opts:\n                        opts.append(\"integer\")\n            self.xsl_withparam(\"type\", \"union\", ct)\n            self.xsl_withparam(\"options\", \",\".join(opts) + \",\", ct)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs an XSLT text element containing text.", "response": "def xsl_text(self, text, parent):\n        \"\"\"Construct an XSLT 'text' element containing `text`.\n\n        `parent` is this element's parent.\n        \"\"\"\n        res = ET.SubElement(parent, \"text\")\n        res.text = text\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xsl_withparam(self, name, value, parent):\n        res = ET.SubElement(parent, \"with-param\", name=name)\n        res.text = value\n        return res", "response": "Construct an XSLT with - param element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the SMIv2 plugin.", "response": "def pyang_plugin_init():\n    \"\"\"Called by pyang plugin framework at to initialize the plugin.\"\"\"\n\n    # Register the plugin\n    plugin.register_plugin(SMIPlugin())\n\n    # Add our special argument syntax checkers\n    syntax.add_arg_type('smi-oid', _chk_smi_oid)\n    syntax.add_arg_type('smi-max-access', _chk_smi_max_access)\n\n    # Register that we handle extensions from the YANG module 'ietf-yang-smiv2'\n    grammar.register_extension_module(smi_module_name)\n\n    # Register the special grammar\n    for (stmt, occurance, (arg, rules), add_to_stmts) in smi_stmts:\n        grammar.add_stmt((smi_module_name, stmt), (arg, rules))\n        grammar.add_to_stmts_rules(add_to_stmts,\n                                   [((smi_module_name, stmt), occurance)])\n\n    # Add validation step\n    statements.add_validation_phase('smi_set_oid', after='inherit_properties')\n    statements.add_validation_fun('smi_set_oid',\n                                  [(smi_module_name, 'oid')],\n                                  v_set_oid)\n    statements.add_validation_fun('smi_set_oid',\n                                  [(smi_module_name, 'subid')],\n                                  v_set_subid)\n\n    # Register special error codes\n    error.add_error_code('SMIv2_BAD_SUBID', 1,\n                         \"subid needs an oid or subid statement in an ancestor\")\n    error.add_error_code('SMIv2_SUBID_AND_OID', 1,\n                         \"subid and oid cannot be given at the same time\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef element(cls, name, parent=None, interleave=None, occur=0):\n        node = cls(\"element\", parent, interleave=interleave)\n        node.attr[\"name\"] = name\n        node.occur = occur\n        return node", "response": "Create an element node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef leaf_list(cls, name, parent=None, interleave=None):\n        node = cls(\"_list_\", parent, interleave=interleave)\n        node.attr[\"name\"] = name\n        node.keys = None\n        node.minEl = \"0\"\n        node.maxEl = None\n        node.occur = 3\n        return node", "response": "Create _list_ node for a leaf - list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating _list_ node for a list.", "response": "def list(cls, name, parent=None, interleave=None):\n        \"\"\"Create _list_ node for a list.\"\"\"\n        node = cls.leaf_list(name, parent, interleave=interleave)\n        node.keys = []\n        node.keymap = {}\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef define(cls, name, parent=None, interleave=False):\n        node = cls(\"define\", parent, interleave=interleave)\n        node.occur = 0\n        node.attr[\"name\"] = name\n        return node", "response": "Create a define node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninherits interleave status from parent.", "response": "def adjust_interleave(self, interleave):\n        \"\"\"Inherit interleave status from parent if undefined.\"\"\"\n        if interleave == None and self.parent:\n            self.interleave = self.parent.interleave\n        else:\n            self.interleave = interleave"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking node receiver s child.", "response": "def subnode(self, node):\n        \"\"\"Make `node` receiver's child.\"\"\"\n        self.children.append(node)\n        node.parent = self\n        node.adjust_interleave(node.interleave)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef annot(self, node):\n        self.annots.append(node)\n        node.parent = self", "response": "Add node as an annotation of the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_tag(self, alt=None, empty=False):\n        if alt:\n            name = alt\n        else:\n            name = self.name\n        result = \"<\" + name\n        for it in self.attr:\n            result += ' %s=\"%s\"' % (it, escape(self.attr[it], {'\"':\"&quot;\", '%': \"%%\"}))\n        if empty:\n            return result + \"/>%s\"\n        else:\n            return result + \">\"", "response": "Return XML start tag for the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef end_tag(self, alt=None):\n        if alt:\n            name = alt\n        else:\n            name = self.name\n        return \"</\" + name + \">\"", "response": "Return XML end tag for the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns RELAX NG representation of the receiver and subtree.", "response": "def serialize(self, occur=None):\n        \"\"\"Return RELAX NG representation of the receiver and subtree.\n        \"\"\"\n        fmt = self.ser_format.get(self.name, SchemaNode._default_format)\n        return fmt(self, occur) % (escape(self.text) +\n                                   self.serialize_children())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _default_format(self, occur):\n        if self.text or self.children:\n            return self.start_tag() + \"%s\" + self.end_tag()\n        return self.start_tag(empty=True)", "response": "Return the default serialization format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _define_format(self, occur):\n        if hasattr(self, \"default\"):\n            self.attr[\"nma:default\"] = self.default\n        middle = self._chorder() if self.rng_children() else \"<empty/>%s\"\n        return (self.start_tag() + self.serialize_annots().replace(\"%\", \"%%\")\n                + middle + self.end_tag())", "response": "Return the serialization format for a define node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the serialization format for an element node.", "response": "def _element_format(self, occur):\n        \"\"\"Return the serialization format for an element node.\"\"\" \n        if occur:\n            occ = occur\n        else:\n            occ = self.occur\n        if occ == 1:\n            if hasattr(self, \"default\"):\n                self.attr[\"nma:default\"] = self.default\n            else:\n                self.attr[\"nma:implicit\"] = \"true\"\n        middle = self._chorder() if self.rng_children() else \"<empty/>%s\"\n        fmt = (self.start_tag() + self.serialize_annots().replace(\"%\", \"%%\") +\n               middle + self.end_tag())\n        if (occ == 2 or self.parent.name == \"choice\"\n            or self.parent.name == \"case\" and len(self.parent.children) == 1):\n            return fmt\n        else:\n            return \"<optional>\" + fmt + \"</optional>\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _chorder(self):\n        if (self.interleave and\n            len([ c for c in self.children if \":\" not in c.name ]) > 1):\n            return \"<interleave>%s</interleave>\"\n        return \"%s\"", "response": "Return the order of the child elements in the URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the serialization format for a _list_ node.", "response": "def _list_format(self, occur):\n        \"\"\"Return the serialization format for a _list_ node.\"\"\" \n        if self.keys:\n            self.attr[\"nma:key\"] = \" \".join(self.keys)\n            keys = ''.join([self.keymap[k].serialize(occur=2)\n                            for k in self.keys])\n        else:\n            keys = \"\"\n        if self.maxEl:\n            self.attr[\"nma:max-elements\"] = self.maxEl\n        if int(self.minEl) == 0:\n            ord_ = \"zeroOrMore\"\n        else:\n            ord_ = \"oneOrMore\"\n            if int(self.minEl) > 1:\n                self.attr[\"nma:min-elements\"] = self.minEl\n        middle = self._chorder() if self.rng_children() else \"<empty/>%s\"\n        return (\"<\" + ord_ + \">\" + self.start_tag(\"element\") +\n                (self.serialize_annots() + keys).replace(\"%\", \"%%\")  +\n                middle + self.end_tag(\"element\") + \"</\" + ord_ + \">\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _choice_format(self, occur):\n        middle = \"%s\" if self.rng_children() else \"<empty/>%s\"\n        fmt = self.start_tag() + middle + self.end_tag()\n        if self.occur != 2:\n            return \"<optional>\" + fmt + \"</optional>\"\n        else:\n            return fmt", "response": "Return the serialization format for a choice node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _case_format(self, occur):\n        if self.occur == 1:\n            self.attr[\"nma:implicit\"] = \"true\"\n        ccnt = len(self.rng_children())\n        if ccnt == 0: return \"<empty/>%s\"\n        if ccnt == 1 or not self.interleave:\n            return self.start_tag(\"group\") + \"%s\" + self.end_tag(\"group\")\n        return (self.start_tag(\"interleave\") + \"%s\" +\n                self.end_tag(\"interleave\"))", "response": "Return the serialization format for a case node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_children(self, node, parent, pmod):\n        for ch in node.i_children:\n            if ch.keyword in [\"rpc\", \"notification\"]: continue\n            if ch.keyword in [\"choice\", \"case\"]:\n                self.process_children(ch, parent, pmod)\n                continue\n            if ch.i_module.i_modulename == pmod:\n                nmod = pmod\n                nodename = ch.arg\n            else:\n                nmod = ch.i_module.i_modulename\n                nodename = \"%s:%s\" % (nmod, ch.arg)\n            ndata = [ch.keyword]\n            if ch.keyword == \"container\":\n                ndata.append({})\n                self.process_children(ch, ndata[1], nmod)\n            elif ch.keyword == \"list\":\n                ndata.append({})\n                self.process_children(ch, ndata[1], nmod)\n                ndata.append([(k.i_module.i_modulename, k.arg)\n                              for k in ch.i_key])\n            elif ch.keyword in [\"leaf\", \"leaf-list\"]:\n                ndata.append(self.base_type(ch.search_one(\"type\")))\n            modname = ch.i_module.i_modulename\n            parent[nodename] = ndata", "response": "Processes all children of node except rpc and notification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef base_type(self, type):\n        while 1:\n            if type.arg == \"leafref\":\n                node = type.i_type_spec.i_target_node\n            elif type.i_typedef is None:\n                break\n            else:\n                node = type.i_typedef\n            type = node.search_one(\"type\")\n        if type.arg == \"decimal64\":\n            return [type.arg, int(type.search_one(\"fraction-digits\").arg)]\n        elif type.arg == \"union\":\n            return [type.arg, [self.base_type(x) for x in type.i_type_spec.types]]\n        else:\n            return type.arg", "response": "Return the base type of type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skip(self):\n        buflen = len(self.buf)\n\n        while True:\n            self.buf = self.buf.lstrip()\n            if self.buf == '':\n                self.readline()\n                buflen = len(self.buf)\n            else:\n                self.offset += (buflen - len(self.buf))\n                break\n\n        # do not keep comments in the syntax tree\n        if not self.keep_comments:\n            # skip line comment\n            if self.buf[0] == '/':\n                if self.buf[1] == '/':\n                    self.readline()\n                    return self.skip()\n            # skip block comment\n                elif self.buf[1] == '*':\n                    i = self.buf.find('*/')\n                    while i == -1:\n                        self.readline()\n                        i = self.buf.find('*/')\n                    self.set_buf(i+2)\n                    return self.skip()", "response": "Skip whitespace and count position"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comment(self):\n        self.skip()\n        offset = self.offset\n        m = syntax.re_comment.match(self.buf)\n        if m == None:\n            return None\n        else:\n            cmt = m.group(0)\n            self.set_buf(m.end())\n            # look for a multiline comment\n            if cmt[:2] == '/*' and cmt[-2:] != '*/':\n                i = self.buf.find('*/')\n                while i == -1:\n                    self.readline()\n                    # remove at most the same number of whitespace as\n                    # the comment start was indented\n                    j = 0\n                    while (j < offset and j < len(self.buf) and\n                           self.buf[j].isspace()):\n                        j = j + 1\n                    self.buf = self.buf[j:]\n                    cmt += '\\n'+self.buf.replace('\\n','')\n                    i = self.buf.find('*/')\n                self.set_buf(i+2)\n            self.skip()\n            return cmt", "response": "return the comment of the current line of the buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_keyword(self):\n        self.skip()\n\n        m = syntax.re_keyword.match(self.buf)\n        if m == None:\n            error.err_add(self.errors, self.pos,\n                          'SYNTAX_ERROR', 'illegal keyword: ' + self.buf)\n            raise error.Abort\n        else:\n            self.set_buf(m.end())\n            # check the separator\n            if (self.buf[0].isspace() or\n                (self.buf[0] == '/' and self.buf[1] in ('/', '*')) or\n                (self.buf[0] in (';','{'))):\n                pass\n            else:\n                error.err_add(self.errors, self.pos,\n                              'SYNTAX_ERROR', 'expected separator, got: \"' +\n                              self.buf[:6] + '...\"')\n                raise error.Abort\n\n            if m.group(2) == None: # no prefix\n                return m.group(3)\n            else:\n                return (m.group(2), m.group(3))", "response": "get_keyword - Gets the keyword from the buffer and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the string text containing a YANG statement.", "response": "def parse(self, ctx, ref, text):\n        \"\"\"Parse the string `text` containing a YANG statement.\n\n        Return a Statement on success or None on failure\n        \"\"\"\n\n        self.ctx = ctx\n        self.pos = error.Position(ref)\n        self.top = None\n        try:\n            self.tokenizer = YangTokenizer(text, self.pos, ctx.errors,\n                                           ctx.max_line_len, ctx.keep_comments,\n                                           not ctx.lax_quote_checks)\n            stmt = self._parse_statement(None)\n        except error.Abort:\n            return None\n        except error.Eof as e:\n            error.err_add(self.ctx.errors, self.pos, 'EOF_ERROR', ())\n            return None\n        try:\n            # we expect a error.Eof at this point, everything else is an error\n            self.tokenizer.peek()\n        except error.Eof:\n            return stmt\n        except:\n            pass\n        error.err_add(self.ctx.errors, self.pos, 'TRAILING_GARBAGE', ())\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_validation_phase(phase, before=None, after=None):\n    idx = 0\n    for x in _validation_phases:\n        if x == before:\n            _validation_phases.insert(idx, phase)\n            return\n        elif x == after:\n            _validation_phases.insert(idx+1, phase)\n            return\n        idx = idx + 1\n    # otherwise append at the end\n    _validation_phases.append(phase)", "response": "Add a validation phase to the framework."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a validation function to some phase in the framework.", "response": "def add_validation_fun(phase, keywords, f):\n    \"\"\"Add a validation function to some phase in the framework.\n\n    Function `f` is called for each valid occurance of each keyword in\n    `keywords`.\n    Can be used by plugins to do special validation of extensions.\"\"\"\n    for keyword in keywords:\n        if (phase, keyword) in _validation_map:\n            oldf = _validation_map[(phase, keyword)]\n            def newf(ctx, s):\n                oldf(ctx, s)\n                f(ctx, s)\n            _validation_map[(phase, keyword)] = newf\n        else:\n            _validation_map[(phase, keyword)] = f"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_refinement_element(keyword, element, merge = False, v_fun=None):\n    for (key, valid_keywords, m, v_fun) in _refinements:\n        if key == keyword:\n            valid_keywords.append(element)\n            return\n    _refinements.append((keyword, [element], merge, v_fun))", "response": "Add an element to the list of refinements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_deviation_element(keyword, element):\n  if keyword in _valid_deviations:\n      _valid_deviations[keyword].append(element)\n  else:\n      _valid_deviations[keyword] = [element]", "response": "Add an element to the list of deviations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_module(ctx, module):\n\n    if module.i_is_validated:\n        return\n\n    def iterate(stmt, phase):\n        # if the grammar is not yet checked or if it is checked and\n        # valid, then we continue.\n        if (hasattr(stmt, 'is_grammatically_valid') and\n            stmt.is_grammatically_valid == False):\n            return\n        # first check an exact match\n        key = (phase, stmt.keyword)\n        res = 'recurse'\n        if key in _validation_map:\n            f = _validation_map[key]\n            res = f(ctx, stmt)\n            if res == 'stop':\n                raise Abort\n        # then also run match by special variable\n        for (var_name, var_f) in _validation_variables:\n            key = (phase, var_name)\n            if key in _validation_map and var_f(stmt.keyword) == True:\n                f = _validation_map[key]\n                res = f(ctx, stmt)\n                if res == 'stop':\n                    raise Abort\n        # then run wildcard\n        wildcard = (phase, '*')\n        if wildcard in _validation_map:\n            f = _validation_map[wildcard]\n            res = f(ctx, stmt)\n            if res == 'stop':\n                raise Abort\n        if res == 'continue':\n            pass\n        else:\n            # default is to recurse\n            if phase in _v_i_children:\n                if stmt.keyword == 'grouping':\n                    return\n                if stmt.i_module is not None and stmt.i_module != module:\n                    # this means that the stmt is from an included, expanded\n                    # submodule - already validated.\n                    return\n                if hasattr(stmt, 'i_children'):\n                    for s in stmt.i_children:\n                        iterate(s, phase)\n                for s in stmt.substmts:\n                    if (hasattr(s, 'i_has_i_children') or\n                        (phase, s.keyword) in _v_i_children_keywords):\n                        iterate(s, phase)\n            else:\n                for s in stmt.substmts:\n                    iterate(s, phase)\n\n    module.i_is_validated = 'in_progress'\n    try:\n        for phase in _validation_phases:\n            iterate(module, phase)\n    except Abort:\n        pass\n    module.i_is_validated = True", "response": "Validate a module which is a Statement representing a sub - module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the extension of the current module.", "response": "def v_init_extension(ctx, stmt):\n    \"\"\"find the modulename of the prefix, and set `stmt.keyword`\"\"\"\n    (prefix, identifier) = stmt.raw_keyword\n    (modname, revision) = \\\n        prefix_to_modulename_and_revision(stmt.i_module, prefix,\n                                          stmt.pos, ctx.errors)\n    stmt.keyword = (modname, identifier)\n    stmt.i_extension_modulename = modname\n    stmt.i_extension_revision = revision\n    stmt.i_extension = None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that all typedefs and groupings are unique.", "response": "def v_grammar_unique_defs(ctx, stmt):\n    \"\"\"Verify that all typedefs and groupings are unique\n    Called for every statement.\n    Stores all typedefs in stmt.i_typedef, groupings in stmt.i_grouping\n    \"\"\"\n    defs = [('typedef', 'TYPE_ALREADY_DEFINED', stmt.i_typedefs),\n            ('grouping', 'GROUPING_ALREADY_DEFINED', stmt.i_groupings)]\n    if stmt.parent is None:\n        defs.extend(\n            [('feature', 'FEATURE_ALREADY_DEFINED', stmt.i_features),\n             ('identity', 'IDENTITY_ALREADY_DEFINED', stmt.i_identities),\n             ('extension', 'EXTENSION_ALREADY_DEFINED', stmt.i_extensions)])\n    for (keyword, errcode, dict) in defs:\n        for definition in stmt.search(keyword):\n            if definition.arg in dict:\n                other = dict[definition.arg]\n                err_add(ctx.errors, definition.pos,\n                        errcode, (definition.arg, other.pos))\n            else:\n                dict[definition.arg] = definition"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef v_type_extension(ctx, stmt):\n    (modulename, identifier) = stmt.keyword\n    revision = stmt.i_extension_revision\n    module = modulename_to_module(stmt.i_module, modulename, revision)\n    if module is None:\n        return\n    if identifier not in module.i_extensions:\n        if module.i_modulename == stmt.i_orig_module.i_modulename:\n            # extension defined in current submodule\n            if identifier not in stmt.i_orig_module.i_extensions:\n                err_add(ctx.errors, stmt.pos, 'EXTENSION_NOT_DEFINED',\n                        (identifier, module.arg))\n                return\n            else:\n                stmt.i_extension = stmt.i_orig_module.i_extensions[identifier]\n        else:\n            err_add(ctx.errors, stmt.pos, 'EXTENSION_NOT_DEFINED',\n                    (identifier, module.arg))\n            return\n    else:\n        stmt.i_extension = module.i_extensions[identifier]\n    ext_arg = stmt.i_extension.search_one('argument')\n    if stmt.arg is not None and ext_arg is None:\n        err_add(ctx.errors, stmt.pos, 'EXTENSION_ARGUMENT_PRESENT',\n                identifier)\n    elif stmt.arg is None and ext_arg is not None:\n        err_add(ctx.errors, stmt.pos, 'EXTENSION_NO_ARGUMENT_PRESENT',\n                identifier)", "response": "verify that the extension definition matches the extension definition"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef v_type_if_feature(ctx, stmt, no_error_report=False):\n    stmt.i_feature = None\n    # Verify the argument type\n    expr = syntax.parse_if_feature_expr(stmt.arg)\n    if stmt.i_module.i_version == '1':\n        # version 1 allows only a single value as if-feature\n        if type(expr) != type(''):\n            err_add(ctx.errors, stmt.pos,\n                    'BAD_VALUE', (stmt.arg, 'identifier-ref'))\n            return\n\n    def eval(expr):\n        if type(expr) == type(''):\n            return has_feature(expr)\n        else:\n            (op, op1, op2) = expr\n            if op == 'not':\n                return not eval(op1)\n            elif op == 'and':\n                return eval(op1) and eval(op2)\n            elif op == 'or':\n                return eval(op1) or eval(op2)\n\n    def has_feature(name):\n        # raises Abort if the feature is not defined\n        # returns True if we compile with the feature\n        # returns False if we compile without the feature\n        found = None\n        if name.find(\":\") == -1:\n            prefix = None\n        else:\n            [prefix, name] = name.split(':', 1)\n        if prefix is None or stmt.i_module.i_prefix == prefix:\n            # check local features\n            pmodule = stmt.i_module\n        else:\n            # this is a prefixed name, check the imported modules\n            pmodule = prefix_to_module(stmt.i_module, prefix,\n                                       stmt.pos, ctx.errors)\n            if pmodule is None:\n                raise Abort\n        if name in pmodule.i_features:\n            f = pmodule.i_features[name]\n            if prefix is None and not is_submodule_included(stmt, f):\n                pass\n            else:\n                found = pmodule.i_features[name]\n                v_type_feature(ctx, found)\n                if pmodule.i_modulename in ctx.features:\n                    if name not in ctx.features[pmodule.i_modulename]:\n                        return False\n\n        if found is None and no_error_report == False:\n            err_add(ctx.errors, stmt.pos,\n                    'FEATURE_NOT_FOUND', (name, pmodule.arg))\n            raise Abort\n        return found is not None\n\n    # Evaluate the if-feature expression, and verify that all\n    # referenced features exist.\n    try:\n        if eval(expr) == False:\n            # prune the parent.\n            # since the parent can have more than one if-feature\n            # statement, we must check if the parent\n            # already has been scheduled for removal\n            if stmt.parent not in stmt.i_module.i_prune:\n                stmt.i_module.i_prune.append(stmt.parent)\n    except Abort:\n        pass", "response": "verify that the referenced feature exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying that the referenced identity exists.", "response": "def v_type_base(ctx, stmt, no_error_report=False):\n    \"\"\"verify that the referenced identity exists.\"\"\"\n    # Find the identity\n    name = stmt.arg\n    stmt.i_identity = None\n    if name.find(\":\") == -1:\n        prefix = None\n    else:\n        [prefix, name] = name.split(':', 1)\n    if prefix is None or stmt.i_module.i_prefix == prefix:\n        # check local identities\n        pmodule = stmt.i_module\n    else:\n        # this is a prefixed name, check the imported modules\n        pmodule = prefix_to_module(stmt.i_module, prefix, stmt.pos, ctx.errors)\n        if pmodule is None:\n            return\n    if name in pmodule.i_identities:\n        i = pmodule.i_identities[name]\n        if prefix is None and not is_submodule_included(stmt, i):\n            pass\n        else:\n            stmt.i_identity = i\n            v_type_identity(ctx, stmt.i_identity)\n    if stmt.i_identity is None and no_error_report == False:\n        err_add(ctx.errors, stmt.pos,\n                'IDENTITY_NOT_FOUND', (name, pmodule.arg))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake sure that all top - level definitions in a module are unique.", "response": "def v_unique_name_defintions(ctx, stmt):\n    \"\"\"Make sure that all top-level definitions in a module are unique\"\"\"\n    defs = [('typedef', 'TYPE_ALREADY_DEFINED', stmt.i_typedefs),\n            ('grouping', 'GROUPING_ALREADY_DEFINED', stmt.i_groupings)]\n    def f(s):\n        for (keyword, errcode, dict) in defs:\n            if s.keyword == keyword and s.arg in dict:\n                err_add(ctx.errors, dict[s.arg].pos,\n                        errcode, (s.arg, s.pos))\n\n    for i in stmt.search('include'):\n        submodulename = i.arg\n        subm = ctx.get_module(submodulename)\n        if subm is not None:\n            for s in subm.substmts:\n                for ss in s.substmts:\n                    iterate_stmt(ss, f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef v_unique_name_children(ctx, stmt):\n\n    def sort_pos(p1, p2):\n        if p1.line < p2.line:\n            return (p1,p2)\n        else:\n            return (p2,p1)\n\n    dict = {}\n    chs = stmt.i_children\n\n    def check(c):\n        key = (c.i_module.i_modulename, c.arg)\n        if key in dict:\n            dup = dict[key]\n            (minpos, maxpos) = sort_pos(c.pos, dup.pos)\n            pos = chk_uses_pos(c, maxpos)\n            err_add(ctx.errors, pos,\n                    'DUPLICATE_CHILD_NAME', (stmt.arg, stmt.pos, c.arg, minpos))\n        else:\n            dict[key] = c\n        # also check all data nodes in the cases\n        if c.keyword == 'choice':\n            for case in c.i_children:\n                for cc in case.i_children:\n                    check(cc)\n\n    for c in chs:\n        check(c)", "response": "Make sure that each child of stmt has a unique name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef v_unique_name_leaf_list(ctx, stmt):\n\n    if not stmt.i_config:\n        return\n    seen = []\n    for defval in stmt.i_default:\n        if defval in seen:\n            err_add(ctx.errors, stmt.pos, 'DUPLICATE_DEFAULT', (defval))\n        else:\n            seen.append(defval)", "response": "Make sure that leaf - lists do not have duplicate defaults"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking sure that the default case exists and that the mandatory nodes in the default case are not set.", "response": "def v_reference_choice(ctx, stmt):\n    \"\"\"Make sure that the default case exists\"\"\"\n    d = stmt.search_one('default')\n    if d is not None:\n        m = stmt.search_one('mandatory')\n        if m is not None and m.arg == 'true':\n            err_add(ctx.errors, stmt.pos, 'DEFAULT_AND_MANDATORY', ())\n        ptr = attrsearch(d.arg, 'arg', stmt.i_children)\n        if ptr is None:\n            err_add(ctx.errors, d.pos, 'DEFAULT_CASE_NOT_FOUND', d.arg)\n        else:\n            # make sure there are no mandatory nodes in the default case\n            def chk_no_defaults(s):\n                for c in s.i_children:\n                    if c.keyword in ('leaf', 'choice'):\n                        m = c.search_one('mandatory')\n                        if m is not None and m.arg == 'true':\n                            err_add(ctx.errors, c.pos,\n                                    'MANDATORY_NODE_IN_DEFAULT_CASE', ())\n                    elif c.keyword in ('list', 'leaf-list'):\n                        m = c.search_one('min-elements')\n                        if m is not None and int(m.arg) > 0:\n                            err_add(ctx.errors, c.pos,\n                                    'MANDATORY_NODE_IN_DEFAULT_CASE', ())\n                    elif c.keyword == 'container':\n                        p = c.search_one('presence')\n                        if p == None or p.arg == 'false':\n                            chk_no_defaults(c)\n            chk_no_defaults(ptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that all leafrefs in a leaf - list have correct path", "response": "def v_reference_leaf_leafref(ctx, stmt):\n    \"\"\"Verify that all leafrefs in a leaf or leaf-list have correct path\"\"\"\n\n    if (hasattr(stmt, 'i_leafref') and\n        stmt.i_leafref is not None and\n        stmt.i_leafref_expanded is False):\n        path_type_spec = stmt.i_leafref\n        not_req_inst = not(path_type_spec.require_instance)\n        x = validate_leafref_path(ctx, stmt,\n                                  path_type_spec.path_spec,\n                                  path_type_spec.path_,\n                                  accept_non_config_target=not_req_inst\n        )\n        if x is None:\n            return\n        ptr, expanded_path, path_list = x\n        path_type_spec.i_target_node = ptr\n        path_type_spec.i_expanded_path = expanded_path\n        path_type_spec.i_path_list = path_list\n        stmt.i_leafref_expanded = True\n        if ptr is not None:\n            chk_status(ctx, stmt, ptr)\n            stmt.i_leafref_ptr = (ptr, path_type_spec.pos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn type with name if type has name as one of its base types and name is in the names list. If type has name as one of its base types and name is in the names list return None.", "response": "def has_type(type, names):\n    \"\"\"Return type with name if `type` has name as one of its base types,\n    and name is in the `names` list.  otherwise, return None.\"\"\"\n    if type.arg in names:\n        return type\n    for t in type.search('type'): # check all union's member types\n        r = has_type(t, names)\n        if r is not None:\n            return r\n    if not hasattr(type, 'i_typedef'):\n        return None\n    if (type.i_typedef is not None and\n        hasattr(type.i_typedef, 'i_is_circular') and\n        type.i_typedef.i_is_circular == False):\n        t = type.i_typedef.search_one('type')\n        if t is not None:\n            return has_type(t, names)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_typedef(stmt, name):\n    mod = stmt.i_orig_module\n    while stmt is not None:\n        if name in stmt.i_typedefs:\n            t = stmt.i_typedefs[name]\n            if (mod is not None and\n                mod != t.i_orig_module and\n                t.i_orig_module.keyword == 'submodule'):\n                # make sure this submodule is included\n                if mod.search_one('include', t.i_orig_module.arg) is None:\n                    return None\n            return t\n        stmt = stmt.parent\n    return None", "response": "Search for a typedef in scope\n    First search the hierarchy then the module and its submodules. Then the module and its submodules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_grouping(stmt, name):\n    mod = stmt.i_orig_module\n    while stmt is not None:\n        if name in stmt.i_groupings:\n            g = stmt.i_groupings[name]\n            if (mod is not None and\n                mod != g.i_orig_module and\n                g.i_orig_module.keyword == 'submodule'):\n                # make sure this submodule is included\n                if mod.search_one('include', g.i_orig_module.arg) is None:\n                    return None\n            return g\n        stmt = stmt.parent\n    return None", "response": "Search for a grouping in scope\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the tgt s submodule is included by src if they belong to the same module.", "response": "def is_submodule_included(src, tgt):\n    \"\"\"Check that the tgt's submodule is included by src, if they belong\n    to the same module.\"\"\"\n    if tgt is None or not hasattr(tgt, 'i_orig_module'):\n        return True\n    if (tgt.i_orig_module.keyword == 'submodule' and\n        src.i_orig_module != tgt.i_orig_module and\n        src.i_orig_module.i_modulename == tgt.i_orig_module.i_modulename):\n        if src.i_orig_module.search_one('include',\n                                        tgt.i_orig_module.arg) is None:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates that the path points to a leaf and returns the expanded path arg.", "response": "def validate_leafref_path(ctx, stmt, path_spec, path,\n                          accept_non_leaf_target=False,\n                          accept_non_config_target=False):\n    \"\"\"Return the leaf that the path points to and the expanded path arg,\n    or None on error.\"\"\"\n\n    pathpos = path.pos\n\n    # Unprefixed paths in typedefs in YANG 1 were underspecified.  In\n    # YANG 1.1 the semantics are defined.  The code below is compatible\n    # with old pyang for YANG 1 modules.\n\n    # If an un-prefixed identifier is found, it defaults to the\n    # module where the path is defined, except if found within\n    # a grouping, in which case it defaults to the module where the\n    # grouping is used.\n    if (path.parent.parent is not None and\n        path.parent.parent.keyword == 'typedef'):\n        if path.i_module.i_version == '1':\n            local_module = path.i_module\n        else:\n            local_module = stmt.i_module\n    elif stmt.keyword == 'module':\n        local_module = stmt\n    else:\n        local_module = stmt.i_module\n    if stmt.keyword == 'typedef':\n        in_typedef = True\n    else:\n        in_typedef = False\n\n    def find_identifier(identifier):\n        if util.is_prefixed(identifier):\n            (prefix, name) = identifier\n            pmodule = prefix_to_module(path.i_module, prefix, stmt.pos,\n                                       ctx.errors)\n            if pmodule is None:\n                raise NotFound\n            return (pmodule, name)\n        elif in_typedef and stmt.i_module.i_version != '1':\n            raise Abort\n        else: # local identifier\n            return (local_module, identifier)\n\n    def is_identifier(x):\n        if util.is_local(x):\n            return True\n        if type(x) == type(()) and len(x) == 2:\n            return True\n        return False\n\n    def is_predicate(x):\n        if type(x) == type(()) and len(x) == 4 and x[0] == 'predicate':\n            return True\n        return False\n\n    def follow_path(ptr, up, dn):\n        path_list = []\n        last_skipped = None\n        if up == -1: # absolute path\n            (pmodule, name) = find_identifier(dn[0])\n            ptr = search_child(pmodule.i_children, pmodule.i_modulename, name)\n            if not is_submodule_included(path, ptr):\n                ptr = None\n            if ptr is None:\n                # check all our submodules\n                for inc in path.i_orig_module.search('include'):\n                    submod = ctx.get_module(inc.arg)\n                    if submod is not None:\n                        ptr = search_child(submod.i_children,\n                                           submod.arg, name)\n                        if ptr is not None:\n                            break\n                if ptr is None:\n                    err_add(ctx.errors, pathpos, 'LEAFREF_IDENTIFIER_NOT_FOUND',\n                            (pmodule.arg, name, stmt.arg, stmt.pos))\n                    raise NotFound\n            path_list.append(('dn', ptr))\n            dn = dn[1:]\n        else:\n            while up > 0:\n                if ptr is None:\n                    err_add(ctx.errors, pathpos, 'LEAFREF_TOO_MANY_UP',\n                            (stmt.arg, stmt.pos))\n                    raise NotFound\n                if ptr.keyword in ('augment', 'grouping'):\n                    # don't check the path here - check in the expanded tree\n                    raise Abort\n                ptr = ptr.parent\n                if ptr is None:\n                    err_add(ctx.errors, pathpos, 'LEAFREF_TOO_MANY_UP',\n                            (stmt.arg, stmt.pos))\n                    raise NotFound\n                while ptr.keyword in ['case', 'choice', 'input', 'output']:\n                    if ptr.keyword in ['input', 'output']:\n                        last_skipped = ptr.keyword\n                    ptr = ptr.parent\n                    if ptr is None:\n                        err_add(ctx.errors, pathpos, 'LEAFREF_TOO_MANY_UP',\n                                (stmt.arg, stmt.pos))\n                        raise NotFound\n                    # continue after the case, maybe also skip the choice\n                if ptr is None:\n                    err_add(ctx.errors, pathpos, 'LEAFREF_TOO_MANY_UP',\n                            (stmt.arg, stmt.pos))\n                    raise NotFound\n                path_list.append(('up', ptr))\n                up = up - 1\n            if ptr is None: # or ptr.keyword == 'grouping':\n                err_add(ctx.errors, pathpos, 'LEAFREF_TOO_MANY_UP',\n                        (stmt.arg, stmt.pos))\n                raise NotFound\n        if ptr.keyword in ('augment', 'grouping'):\n            # don't check the path here - check in the expanded tree\n            raise Abort\n        i = 0\n        key_list = None\n        keys = []\n        while i < len(dn):\n            if is_identifier(dn[i]) == True:\n                (pmodule, name) = find_identifier(dn[i])\n                module_name = pmodule.i_modulename\n            elif ptr.keyword == 'list': # predicate on a list, good\n                key_list = ptr\n                keys = []\n                # check each predicate\n                while i < len(dn) and is_predicate(dn[i]) == True:\n                    # unpack the predicate\n                    (_tag, keyleaf, pup, pdn) = dn[i]\n                    (pmodule, pname) = find_identifier(keyleaf)\n                    # make sure the keyleaf is really a key in the list\n                    pleaf = search_child(ptr.i_key, pmodule.i_modulename, pname)\n                    if pleaf is None:\n                        err_add(ctx.errors, pathpos, 'LEAFREF_NO_KEY',\n                                (pmodule.arg, pname, stmt.arg, stmt.pos))\n                        raise NotFound\n                    # make sure it's not already referenced\n                    if keyleaf in keys:\n                        err_add(ctx.errors, pathpos, 'LEAFREF_MULTIPLE_KEYS',\n                                (pmodule.arg, pname, stmt.arg, stmt.pos))\n                        raise NotFound\n                    keys.append((pmodule.arg, pname))\n                    if pup == 0:\n                        i = i + 1\n                        break\n                    # check what this predicate refers to; make sure it's\n                    # another leaf; either of type leafref to keyleaf, OR same\n                    # type as the keyleaf\n                    (xkey_list, x_key, xleaf, _x) = follow_path(stmt, pup, pdn)\n                    stmt.i_derefed_leaf = xleaf\n                    if xleaf.keyword != 'leaf':\n                        err_add(ctx.errors, pathpos,\n                                'LEAFREF_BAD_PREDICATE_PTR',\n                                (pmodule.arg, pname, xleaf.arg, xleaf.pos))\n                        raise NotFound\n                    i = i + 1\n                continue\n            else:\n                err_add(ctx.errors, pathpos, 'LEAFREF_BAD_PREDICATE',\n                        (ptr.i_module.arg, ptr.arg, stmt.arg, stmt.pos))\n                raise NotFound\n            if ptr.keyword in _keyword_with_children:\n                ptr = search_data_node(ptr.i_children, module_name, name,\n                                       last_skipped)\n                if not is_submodule_included(path, ptr):\n                    ptr = None\n                if ptr is None:\n                    err_add(ctx.errors, pathpos, 'LEAFREF_IDENTIFIER_NOT_FOUND',\n                            (module_name, name, stmt.arg, stmt.pos))\n                    raise NotFound\n            else:\n                err_add(ctx.errors, pathpos, 'LEAFREF_IDENTIFIER_BAD_NODE',\n                        (module_name, name, stmt.arg, stmt.pos,\n                         util.keyword_to_str(ptr.keyword)))\n                raise NotFound\n            path_list.append(('dn', ptr))\n            i = i + 1\n        return (key_list, keys, ptr, path_list)\n\n    try:\n        if path_spec is None: # e.g. invalid path\n            return None\n        (up, dn, derefup, derefdn) = path_spec\n        if derefup > 0:\n            # first follow the deref\n            (key_list, keys, ptr, _x) = follow_path(stmt, derefup, derefdn)\n            if ptr.keyword != 'leaf':\n                err_add(ctx.errors, pathpos, 'LEAFREF_DEREF_NOT_LEAFREF',\n                        (ptr.arg, ptr.pos))\n                return None\n            if ptr.i_leafref is None:\n                err_add(ctx.errors, pathpos, 'LEAFREF_DEREF_NOT_LEAFREF',\n                        (ptr.arg, ptr.pos))\n                return None\n            stmt.i_derefed_leaf = ptr\n            # make sure the referenced leaf is expanded\n            if ptr.i_leafref_expanded is False:\n                v_reference_leaf_leafref(ctx, ptr)\n            if ptr.i_leafref_ptr is None:\n                return None\n            (derefed_stmt, _pos) = ptr.i_leafref_ptr\n            if derefed_stmt is None:\n                # FIXME: what is this??\n                return None\n            if not hasattr(derefed_stmt, 'i_is_key'):\n                # it follows from the YANG spec which says that predicates\n                # are only used for constraining keys that the derefed stmt\n                # must be a key\n                err_add(ctx.errors, pathpos, 'LEAFREF_DEREF_NOT_KEY',\n                        (ptr.arg, ptr.pos,\n                         derefed_stmt.arg, derefed_stmt.pos))\n                return None\n            # split ptr's leafref path into two parts:\n            # '/a/b/c' --> '/a/b', 'c'\n            m = re_path.match(ptr.i_leafref.i_expanded_path)\n            s1 = m.group(1)\n            s2 = m.group(2)\n            # split the deref path into two parts:\n            # 'deref(../a)/b' --> '../a', 'b'\n            m = re_deref.match(path.arg)\n            d1 = m.group(1)\n            d2 = m.group(2)\n            expanded_path = \"%s[%s = current()/%s]/%s\" % \\\n                (s1, s2, d1, d2)\n            (key_list, keys, ptr, path_list) = follow_path(derefed_stmt, up, dn)\n        else:\n            (key_list, keys, ptr, path_list) = follow_path(stmt, up, dn)\n            expanded_path = path.arg\n        # ptr is now the node that the leafref path points to\n        # check that it is a leaf\n        if (ptr.keyword not in ('leaf', 'leaf-list') and\n            not accept_non_leaf_target):\n            err_add(ctx.errors, pathpos, 'LEAFREF_NOT_LEAF',\n                    (stmt.arg, stmt.pos))\n            return None\n        if (key_list == ptr.parent and\n            (ptr.i_module.i_modulename, ptr.arg) in keys):\n            err_add(ctx.errors, pathpos, 'LEAFREF_MULTIPLE_KEYS',\n                    (ptr.i_module.i_modulename, ptr.arg, stmt.arg, stmt.pos))\n        if ((hasattr(stmt, 'i_config') and stmt.i_config == True) and\n            hasattr(ptr, 'i_config') and ptr.i_config == False\n            and not accept_non_config_target):\n            err_add(ctx.errors, pathpos, 'LEAFREF_BAD_CONFIG',\n                    (stmt.arg, ptr.arg, ptr.pos))\n        if ptr == stmt:\n            err_add(ctx.errors, pathpos, 'CIRCULAR_DEPENDENCY',\n                    ('leafref', path.arg))\n            return None\n        return ptr, expanded_path, path_list\n    except NotFound:\n        return None\n    except Abort:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mk_path_list(stmt):\n    resolved_names = []\n    def resolve_stmt(stmt, resolved_names):\n        if stmt.keyword in ['choice', 'case']:\n            resolve_stmt(stmt.parent, resolved_names)\n            return\n        def qualified_name_elements(stmt):\n            \"\"\"(module name, prefix, name)\"\"\"\n            return (stmt.i_module.arg, stmt.i_module.i_prefix, stmt.arg)\n        if stmt.parent.keyword in ['module', 'submodule']:\n            resolved_names.append(qualified_name_elements(stmt))\n            return\n        else:\n            resolve_stmt(stmt.parent, resolved_names)\n            resolved_names.append(qualified_name_elements(stmt))\n            return\n    resolve_stmt(stmt, resolved_names)\n    return resolved_names", "response": "Derives a list of tuples containing tuples containing\n    module name prefix xpath"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mk_path_str(stmt,\n                with_prefixes=False,\n                prefix_onchange=False,\n                prefix_to_module=False,\n                resolve_top_prefix_to_module=False):\n    \"\"\"Returns the XPath path of the node.\n    with_prefixes indicates whether or not to prefix every node.\n\n    prefix_onchange modifies the behavior of with_prefixes and\n      only adds prefixes when the prefix changes mid-XPath.\n\n    prefix_to_module replaces prefixes with the module name of the prefix.\n\n    resolve_top_prefix_to_module resolves the module-level prefix\n      to the module name.\n\n    Prefixes may be included in the path if the prefix changes mid-path.\n    \"\"\"\n    resolved_names = mk_path_list(stmt)\n    xpath_elements = []\n    last_prefix = None\n    for index, resolved_name in enumerate(resolved_names):\n        module_name, prefix, node_name = resolved_name\n        xpath_element = node_name\n        if with_prefixes or (prefix_onchange and prefix != last_prefix):\n            new_prefix = prefix\n            if (prefix_to_module or\n                (index == 0 and resolve_top_prefix_to_module)):\n                new_prefix = module_name\n            xpath_element = '%s:%s' % (new_prefix, node_name)\n        xpath_elements.append(xpath_element)\n        last_prefix = prefix\n    return '/%s' % '/'.join(xpath_elements)", "response": "Returns the XPath path of the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the XPath of the statement.", "response": "def get_xpath(stmt, qualified=False, prefix_to_module=False):\n    \"\"\"Gets the XPath of the statement.\n    Unless qualified=True, does not include prefixes unless the prefix\n      changes mid-XPath.\n\n    qualified will add a prefix to each node.\n\n    prefix_to_module will resolve prefixes to module names instead.\n\n    For RFC 8040, set prefix_to_module=True:\n      /prefix:root/node/prefix:node/...\n\n    qualified=True:\n      /prefix:root/prefix:node/prefix:node/...\n\n    qualified=True, prefix_to_module=True:\n      /module:root/module:node/module:node/...\n    prefix_to_module=True: /module:root/node/module:node/...\n    \"\"\"\n    return mk_path_str(stmt, with_prefixes=qualified,\n                       prefix_onchange=True, prefix_to_module=prefix_to_module)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the qualified type of the node.", "response": "def get_qualified_type(stmt):\n    \"\"\"Gets the qualified, top-level type of the node.\n    This enters the typedef if defined instead of using the prefix\n    to ensure absolute distinction.\n    \"\"\"\n    type_obj = stmt.search_one('type')\n    fq_type_name = None\n    if type_obj:\n        if getattr(type_obj, 'i_typedef', None):\n            # If type_obj has typedef, substitute.\n            # Absolute module:type instead of prefix:type\n            type_obj = type_obj.i_typedef\n        type_name = type_obj.arg\n        if check_primitive_type(type_obj):\n            # Doesn't make sense to qualify a primitive..I think.\n            fq_type_name = type_name\n        else:\n            type_module = type_obj.i_orig_module.arg\n            fq_type_name = '%s:%s' % (type_module, type_name)\n    return fq_type_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self, keyword, children=None, arg=None):\n        if children is None:\n            children = self.substmts\n        return [ ch for ch in children\n                 if (ch.keyword == keyword and\n                     (arg is None or ch.arg == arg))]", "response": "Return list of receiver s substmts with keyword."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches receiver s substmt with keyword and optionally arg.", "response": "def search_one(self, keyword, arg=None, children=None):\n        \"\"\"Return receiver's substmt with `keyword` and optionally `arg`.\n        \"\"\"\n        if children is None:\n            children = self.substmts\n        for ch in children:\n            if ch.keyword == keyword and (arg is None or ch.arg == arg):\n                return ch\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the main module to which the receiver belongs.", "response": "def main_module(self):\n        \"\"\"Return the main module to which the receiver belongs.\"\"\"\n        if self.i_module.keyword == \"submodule\":\n            return self.i_module.i_ctx.get_module(\n                self.i_module.i_including_modulename)\n        return self.i_module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndebugging function prints the current object", "response": "def pprint(self, indent='', f=None):\n        \"\"\"debug function\"\"\"\n        if self.arg is not None:\n          print(indent + util.keyword_to_str(self.keyword) + \" \" + self.arg)\n        else:\n          print(indent + util.keyword_to_str(self.keyword))\n        if f is not None:\n             f(self, indent)\n        for x in self.substmts:\n            x.pprint(indent + ' ', f)\n        if hasattr(self, 'i_children') and len(self.i_children) > 0:\n           print(indent + '--- BEGIN i_children ---')\n           for x in self.i_children:\n               x.pprint(indent + ' ', f)\n           print(indent + '--- END i_children ---')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding prefix to all unprefixed names in s", "response": "def add_prefix(prefix, s):\n    \"Add `prefix` to all unprefixed names in `s`\"\n    # tokenize the XPath expression\n    toks = xpath_lexer.scan(s)\n    # add default prefix to unprefixed names\n    toks2 = [_add_prefix(prefix, tok) for tok in toks]\n    # build a string of the patched expression\n    ls = [x.value for x in toks2]\n    return ''.join(ls)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chk_date_arg(s):\n    if re_date.search(s) is None:\n        return False\n    comp = s.split('-')\n    try:\n        dt = datetime.date(int(comp[0]), int(comp[1]), int(comp[2]))\n        return True\n    except Exception as e:\n        return False", "response": "Checks if the string s is a valid date string. Returns True of False."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chk_enum_arg(s):\n\n    if len(s) == 0 or s[0].isspace() or s[-1].isspace():\n        return False\n    else:\n        return True", "response": "Checks if the string s is a valid enum string. Returns True or False."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chk_fraction_digits_arg(s):\n    try:\n        v = int(s)\n        if v >= 1 and v <= 18:\n            return True\n        else:\n            return False\n    except ValueError:\n        return False", "response": "Checks if the string s is a valid fraction - digits argument. Return True or False."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd patch. plist to self. plist.", "response": "def combine(self, patch):\n        \"\"\"Add `patch.plist` to `self.plist`.\"\"\"\n        exclusive = set([\"config\", \"default\", \"mandatory\", \"presence\",\n                     \"min-elements\", \"max-elements\"])\n        kws = set([s.keyword for s in self.plist]) & exclusive\n        add = [n for n in patch.plist if n.keyword not in kws]\n        self.plist.extend(add)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(self):\n        res = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n        for ns in self.namespaces:\n            self.top_grammar.attr[\"xmlns:\" + self.namespaces[ns]] = ns\n        res += self.top_grammar.start_tag()\n        for ch in self.top_grammar.children:\n            res += ch.serialize()\n        res += self.tree.serialize()\n        for d in self.global_defs:\n            res += self.global_defs[d].serialize()\n        for i in self.identities:\n            res += self.identities[i].serialize()\n        return res + self.top_grammar.end_tag()", "response": "Return the string representation of the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the instance representing mapped input modules.", "response": "def from_modules(self, modules, no_dc=False, no_a=False,\n                     record_defs=False, lax_yang_version=False, debug=0):\n        \"\"\"Return the instance representing mapped input modules.\"\"\"\n        self.namespaces = {\n            \"urn:ietf:params:xml:ns:netmod:dsdl-annotations:1\" : \"nma\",\n        }\n        if not no_dc: self.namespaces[self.dc_uri] = \"dc\"\n        if not no_a: self.namespaces[self.a_uri] = \"a\"\n        self.global_defs = {}\n        self.all_defs = {}\n        self.identity_deps = {}\n        self.identities = {}\n        self.debug = debug\n        self.module_prefixes = {}\n        gpset = {}\n        self.gg_level = 0\n        metadata = []\n        self.has_meta = False\n        for module in modules[0].i_ctx.modules.values():\n            yver = module.search_one(\"yang-version\")\n            if yver and float(yver.arg) > 1.0 and not lax_yang_version:\n                raise error.EmitError(\n                    \"DSDL plugin supports only YANG version 1.\")\n            if module.keyword == \"module\":\n                for idn in module.i_identities.values():\n                    self.register_identity(idn)\n        for module in modules:\n            self.add_namespace(module)\n            self.module = module\n            annots = module.search((\"ietf-yang-metadata\", \"annotation\"))\n            for ann in annots:\n                aname = (self.module_prefixes[ann.main_module().arg] + \":\" +\n                         ann.arg)\n                optel = SchemaNode(\"optional\")\n                atel = SchemaNode(\"attribute\", optel).set_attr(\"name\", aname)\n                self.handle_substmts(ann, atel)\n                metadata.append(optel)\n        if metadata:\n            self.has_meta = True\n            metel = SchemaNode.define(\"__yang_metadata__\")\n            self.global_defs[\"__yang_metadata__\"] = metel\n            for mattr in metadata:\n                metel.subnode(mattr)\n        for module in modules:\n            self.module = module\n            self.prefix_stack = [self.module_prefixes[module.arg]]\n            for aug in module.search(\"augment\"):\n                self.add_patch(gpset, aug)\n            for sub in [ module.i_ctx.get_module(inc.arg)\n                         for inc in module.search(\"include\") ]:\n                for aug in sub.search(\"augment\"):\n                    self.add_patch(gpset, aug)\n        self.setup_top()\n        for module in modules:\n            self.module = module\n            self.local_defs = {}\n            if record_defs: self.preload_defs()\n            self.prefix_stack = [self.module_prefixes[module.arg]]\n            self.create_roots(module)\n            self.lookup_expand(module, list(gpset.keys()))\n            self.handle_substmts(module, self.data, gpset)\n            for d in list(self.local_defs.values()):\n                self.local_grammar.subnode(d)\n            self.tree.subnode(self.local_grammar)\n            self.all_defs.update(self.local_defs)\n        self.all_defs.update(self.global_defs)\n        self.dc_element(self.top_grammar, \"date\", time.strftime(\"%Y-%m-%d\"))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates top - level elements of the hybrid schema.", "response": "def setup_top(self):\n        \"\"\"Create top-level elements of the hybrid schema.\"\"\"\n        self.top_grammar = SchemaNode(\"grammar\")\n        self.top_grammar.attr = {\n            \"xmlns\": \"http://relaxng.org/ns/structure/1.0\",\n            \"datatypeLibrary\": \"http://www.w3.org/2001/XMLSchema-datatypes\"}\n        self.tree = SchemaNode(\"start\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the top - level structure for module yam.", "response": "def create_roots(self, yam):\n        \"\"\"Create the top-level structure for module `yam`.\"\"\"\n        self.local_grammar = SchemaNode(\"grammar\")\n        self.local_grammar.attr = {\n            \"ns\": yam.search_one(\"namespace\").arg,\n            \"nma:module\": self.module.arg}\n        src_text = \"YANG module '%s'\" % yam.arg\n        revs = yam.search(\"revision\")\n        if len(revs) > 0:\n            src_text += \" revision %s\" % self.current_revision(revs)\n        self.dc_element(self.local_grammar, \"source\", src_text)\n        start = SchemaNode(\"start\", self.local_grammar)\n        self.data = SchemaNode(\"nma:data\", start, interleave=True)\n        self.data.occur = 2\n        self.rpcs = SchemaNode(\"nma:rpcs\", start, interleave=False)\n        self.notifications = SchemaNode(\"nma:notifications\", start,\n                                        interleave=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform YANG s xpath to a form suitable for Schematron.", "response": "def yang_to_xpath(self, xpe):\n        \"\"\"Transform YANG's `xpath` to a form suitable for Schematron.\n\n        1. Prefixes are added to unprefixed local names. Inside global\n           groupings, the prefix is represented as the variable\n           '$pref' which is substituted via Schematron abstract\n           patterns.\n        2. '$root' is prepended to every absolute location path.\n        \"\"\"\n        if self.gg_level:\n            pref = \"$pref:\"\n        else:\n            pref = self.prefix_stack[-1] + \":\"\n        toks = xpath_lexer.scan(xpe)\n        prev = None\n        res = \"\"\n        for tok in toks:\n            if (tok.type == \"SLASH\" and\n                prev not in (\"DOT\", \"DOTDOT\", \"RPAREN\", \"RBRACKET\", \"name\",\n                             \"wildcard\", \"prefix_test\")):\n                res += \"$root\"\n            elif tok.type == \"name\" and \":\" not in tok.value:\n                res += pref\n            res += tok.value\n            if tok.type != \"_whitespace\": prev = tok.type\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the namespace for the module to self. namespaces.", "response": "def add_namespace(self, module):\n        \"\"\"Add item uri:prefix for `module` to `self.namespaces`.\n\n        The prefix to be actually used for `uri` is returned.  If the\n        namespace is already present, the old prefix is used.  Prefix\n        clashes are resolved by disambiguating `prefix`.\n        \"\"\"\n        uri = module.search_one(\"namespace\").arg\n        prefix = module.search_one(\"prefix\").arg\n        if uri in self.namespaces: return self.namespaces[uri]\n        end = 1\n        new = prefix\n        while new in list(self.namespaces.values()):\n            new = \"%s%x\" % (prefix,end)\n            end += 1\n        self.namespaces[uri] = new\n        self.module_prefixes[module.arg] = new\n        for inc in module.search(\"include\"):\n            self.module_prefixes[inc.arg] = new\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering id_stmt with its base identity.", "response": "def register_identity(self, id_stmt):\n        \"\"\"Register `id_stmt` with its base identity, if any.\n        \"\"\"\n        bst = id_stmt.search_one(\"base\")\n        if bst:\n            bder = self.identity_deps.setdefault(bst.i_identity, [])\n            bder.append(id_stmt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding pattern def for id_stmt and all derived identities.", "response": "def add_derived_identity(self, id_stmt):\n        \"\"\"Add pattern def for `id_stmt` and all derived identities.\n\n        The corresponding \"ref\" pattern is returned.\n        \"\"\"\n        p = self.add_namespace(id_stmt.main_module())\n        if id_stmt not in self.identities:   # add named pattern def\n            self.identities[id_stmt] = SchemaNode.define(\"__%s_%s\" %\n                                                         (p, id_stmt.arg))\n            parent = self.identities[id_stmt]\n            if id_stmt in self.identity_deps:\n                parent = SchemaNode.choice(parent, occur=2)\n                for i in self.identity_deps[id_stmt]:\n                    parent.subnode(self.add_derived_identity(i))\n            idval = SchemaNode(\"value\", parent, p+\":\"+id_stmt.arg)\n            idval.attr[\"type\"] = \"QName\"\n        res = SchemaNode(\"ref\")\n        res.attr[\"name\"] = self.identities[id_stmt].attr[\"name\"]\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_prefix(self, name, stmt):\n        if self.gg_level: return name\n        pref, colon, local = name.partition(\":\")\n        if colon:\n            return (self.module_prefixes[stmt.i_module.i_prefixes[pref][0]]\n                    + \":\" + local)\n        else:\n            return self.prefix_stack[-1] + \":\" + pref", "response": "Return name prepended with correct prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the qualified name of stmt.", "response": "def qname(self, stmt):\n        \"\"\"Return (prefixed) node name of `stmt`.\n\n        The result is prefixed with the local prefix unless we are\n        inside a global grouping.\n        \"\"\"\n        if self.gg_level: return stmt.arg\n        return self.prefix_stack[-1] + \":\" + stmt.arg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd DC element name containing text to parent.", "response": "def dc_element(self, parent, name, text):\n        \"\"\"Add DC element `name` containing `text` to `parent`.\"\"\"\n        if self.dc_uri in self.namespaces:\n            dcel = SchemaNode(self.namespaces[self.dc_uri] + \":\" + name,\n                              text=text)\n            parent.children.insert(0,dcel)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default(self, stmt, refd):\n        if refd[\"default\"]:\n                return refd[\"default\"]\n        defst = stmt.search_one(\"default\")\n        if defst:\n            return defst.arg\n        return None", "response": "Return default value for stmt node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmangles the name of stmt and return the mangled name and dictionary where the definition is located.", "response": "def unique_def_name(self, stmt, inrpc=False):\n        \"\"\"Mangle the name of `stmt` (typedef or grouping).\n\n        Return the mangled name and dictionary where the definition is\n        to be installed. The `inrpc` flag indicates when we are inside\n        an RPC, in which case the name gets the \"__rpc\" suffix.\n        \"\"\"\n        module = stmt.main_module()\n        name = \"\"\n        while True:\n            pref = stmt.arg if stmt.arg else stmt.keyword\n            name = \"__\" + pref + name\n            if stmt.keyword == \"grouping\": name = \"_\" + name\n            if stmt.parent.parent is None: break\n            stmt = stmt.parent\n        defs = (self.global_defs\n                if stmt.keyword in (\"grouping\", \"typedef\")\n                else self.local_defs)\n        if inrpc: name += \"__rpc\"\n        return (module.arg + name, defs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_patch(self, pset, augref):\n        try:\n            path = [ self.add_prefix(c, augref)\n                     for c in augref.arg.split(\"/\") if c ]\n        except KeyError:\n            # augment of a module that's not among input modules\n            return\n        car = path[0]\n        patch = Patch(path[1:], augref)\n        if car in pset:\n            sel = [ x for x in pset[car] if patch.path == x.path ]\n            if sel:\n                sel[0].combine(patch)\n            else:\n                pset[car].append(patch)\n        else:\n            pset[car] = [patch]", "response": "Add patch corresponding to augref to pset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles substatements of augments from auglist.", "response": "def apply_augments(self, auglist, p_elem, pset):\n        \"\"\"Handle substatements of augments from `auglist`.\n\n        The augments are applied in the context of `p_elem`.  `pset`\n        is a patch set containing patches that may be applicable to\n        descendants.\n        \"\"\"\n        for a in auglist:\n            par = a.parent\n            if a.search_one(\"when\") is None:\n                wel = p_elem\n            else:\n                if p_elem.interleave:\n                    kw = \"interleave\"\n                else:\n                    kw = \"group\"\n                wel = SchemaNode(kw, p_elem, interleave=p_elem.interleave)\n                wel.occur = p_elem.occur\n            if par.keyword == \"uses\":\n                self.handle_substmts(a, wel, pset)\n                continue\n            if par.keyword == \"submodule\":\n                mnam = par.i_including_modulename\n            else:\n                mnam = par.arg\n            if self.prefix_stack[-1] == self.module_prefixes[mnam]:\n                self.handle_substmts(a, wel, pset)\n            else:\n                self.prefix_stack.append(self.module_prefixes[mnam])\n                self.handle_substmts(a, wel, pset)\n                self.prefix_stack.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npicking the most recent revision date.", "response": "def current_revision(self, r_stmts):\n        \"\"\"Pick the most recent revision date.\n\n        `r_stmts` is a list of 'revision' statements.\n        \"\"\"\n        cur = max([[int(p) for p in r.arg.split(\"-\")] for r in r_stmts])\n        return \"%4d-%02d-%02d\" % tuple(cur)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a docstring to p_elem.", "response": "def insert_doc(self, p_elem, docstring):\n        \"\"\"Add <a:documentation> with `docstring` to `p_elem`.\"\"\"\n        dtag = self.namespaces[self.a_uri] + \":documentation\"\n        elem = SchemaNode(dtag, text=docstring)\n        p_elem.annots.append(elem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls a definition into the appropriate dictionary.", "response": "def install_def(self, name, dstmt, def_map, interleave=False):\n        \"\"\"Install definition `name` into the appropriate dictionary.\n\n        `dstmt` is the definition statement ('typedef' or 'grouping')\n        that is to be mapped to a RELAX NG named pattern '<define\n        name=\"`name`\">'. `def_map` must be either `self.local_defs` or\n        `self.global_defs`. `interleave` determines the interleave\n        status inside the definition.\n        \"\"\"\n        delem = SchemaNode.define(name, interleave=interleave)\n        delem.attr[\"name\"] = name\n        def_map[name] = delem\n        if def_map is self.global_defs: self.gg_level += 1\n        self.handle_substmts(dstmt, delem)\n        if def_map is self.global_defs: self.gg_level -= 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rng_annotation(self, stmt, p_elem):\n        ext = stmt.i_extension\n        prf, extkw = stmt.raw_keyword\n        (modname,rev)=stmt.i_module.i_prefixes[prf]\n        prefix = self.add_namespace(\n            statements.modulename_to_module(self.module,modname,rev))\n        eel = SchemaNode(prefix + \":\" + extkw, p_elem)\n        argst = ext.search_one(\"argument\")\n        if argst:\n            if argst.search_one(\"yin-element\", \"true\"):\n                SchemaNode(prefix + \":\" + argst.arg, eel, stmt.arg)\n            else:\n                eel.attr[argst.arg] = stmt.arg\n        self.handle_substmts(stmt, eel)", "response": "Append YIN representation of extension statement stmt."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npropagate occurence value to node and its ancestors.", "response": "def propagate_occur(self, node, value):\n        \"\"\"Propagate occurence `value` to `node` and its ancestors.\n\n        Occurence values are defined and explained in the SchemaNode\n        class.\n        \"\"\"\n        while node.occur < value:\n            node.occur = value\n            if node.name == \"define\":\n                break\n            node = node.parent"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_patches(self, pset, stmt, elem, altname=None):\n        if altname:\n            name = altname\n        else:\n            name = stmt.arg\n        new_pset = {}\n        augments = []\n        refine_dict = dict.fromkeys((\"presence\", \"default\", \"mandatory\",\n                                     \"min-elements\", \"max-elements\"))\n        for p in pset.pop(self.add_prefix(name, stmt), []):\n            if p.path:\n                head = p.pop()\n                if head in new_pset:\n                    new_pset[head].append(p)\n                else:\n                    new_pset[head] = [p]\n            else:\n                for refaug in p.plist:\n                    if refaug.keyword == \"augment\":\n                        augments.append(refaug)\n                    else:\n                        for s in refaug.substmts:\n                            if s.keyword == \"description\":\n                                self.description_stmt(s, elem, None)\n                            elif s.keyword == \"reference\":\n                                self.reference_stmt(s, elem, None)\n                            elif s.keyword == \"must\":\n                                self.must_stmt(s, elem, None)\n                            elif s.keyword == \"config\":\n                                self.nma_attribute(s, elem)\n                            elif refine_dict.get(s.keyword, False) is None:\n                                refine_dict[s.keyword] = s.arg\n        return (refine_dict, augments, new_pset)", "response": "Process patches for data node names from pset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn pair of ( min max ) values for stmt.", "response": "def get_minmax(self, stmt, refine_dict):\n        \"\"\"Return pair of (min,max)-elements values for `stmt`.\n\n        `stmt` must be a 'list' or 'leaf-list'. Applicable refinements\n        from `refine_dict` are also taken into account.\n        \"\"\"\n        minel = refine_dict[\"min-elements\"]\n        maxel = refine_dict[\"max-elements\"]\n        if minel is None:\n            minst = stmt.search_one(\"min-elements\")\n            if minst:\n                minel = minst.arg\n            else:\n                minel = \"0\"\n        if maxel is None:\n            maxst = stmt.search_one(\"max-elements\")\n            if maxst:\n                maxel = maxst.arg\n        if maxel == \"unbounded\": maxel = None\n        return (minel, maxel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind schema nodes under stmt also in used groupings.", "response": "def lookup_expand(self, stmt, names):\n        \"\"\"Find schema nodes under `stmt`, also in used groupings.\n\n        `names` is a list with qualified names of the schema nodes to\n        look up. All 'uses'/'grouping' pairs between `stmt` and found\n        schema nodes are marked for expansion.\n        \"\"\"\n        if not names: return []\n        todo = [stmt]\n        while todo:\n            pst = todo.pop()\n            for sub in pst.substmts:\n                if sub.keyword in self.schema_nodes:\n                    qname = self.qname(sub)\n                    if qname in names:\n                        names.remove(qname)\n                        par = sub.parent\n                        while hasattr(par,\"d_ref\"): # par must be grouping\n                            par.d_ref.d_expand = True\n                            par = par.d_ref.parent\n                        if not names: return [] # all found\n                elif sub.keyword == \"uses\":\n                    g = sub.i_grouping\n                    g.d_ref = sub\n                    todo.append(g)\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef type_with_ranges(self, tchain, p_elem, rangekw, gen_data):\n        ranges = self.get_ranges(tchain, rangekw)\n        if not ranges: return p_elem.subnode(gen_data())\n        if len(ranges) > 1:\n            p_elem = SchemaNode.choice(p_elem)\n            p_elem.occur = 2\n        for r in ranges:\n            d_elem = gen_data()\n            for p in self.range_params(r, rangekw):\n                d_elem.subnode(p)\n            p_elem.subnode(d_elem)", "response": "Handle types with range or length restrictions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of ranges defined in tchain.", "response": "def get_ranges(self, tchain, kw):\n        \"\"\"Return list of ranges defined in `tchain`.\n\n        `kw` is the statement keyword determining the type of the\n        range, i.e. 'range' or 'length'. `tchain` is the chain of type\n        definitions from which the resulting range is obtained.\n\n        The returned value is a list of tuples containing the segments\n        of the resulting range.\n        \"\"\"\n        (lo, hi) = (\"min\", \"max\")\n        ran = None\n        for t in tchain:\n            rstmt = t.search_one(kw)\n            if rstmt is None: continue\n            parts = [ p.strip() for p in rstmt.arg.split(\"|\") ]\n            ran = [ [ i.strip() for i in p.split(\"..\") ] for p in parts ]\n            if ran[0][0] != 'min': lo = ran[0][0]\n            if ran[-1][-1] != 'max': hi = ran[-1][-1]\n        if ran is None: return None\n        if len(ran) == 1:\n            return [(lo, hi)]\n        else:\n            return [(lo, ran[0][-1])] + ran[1:-1] + [(ran[-1][0], hi)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of <param >s corresponding to range ran.", "response": "def range_params(self, ran, kw):\n        \"\"\"Return list of <param>s corresponding to range `ran`.\n\n        `kw` is the statement keyword determining the type of the\n        range, i.e. 'range' or 'length'. `ran` is the internal\n        representation of a range as constructed by the `get_ranges`\n        method.\n        \"\"\"\n        if kw == \"length\":\n            if ran[0][0] != \"m\" and (len(ran) == 1 or ran[0] == ran[1]):\n                elem = SchemaNode(\"param\").set_attr(\"name\",\"length\")\n                elem.text = ran[0]\n                return [elem]\n            min_ = SchemaNode(\"param\").set_attr(\"name\",\"minLength\")\n            max_ = SchemaNode(\"param\").set_attr(\"name\",\"maxLength\")\n        else:\n            if len(ran) == 1: ran *= 2 # duplicating the value\n            min_ = SchemaNode(\"param\").set_attr(\"name\",\"minInclusive\")\n            max_ = SchemaNode(\"param\").set_attr(\"name\",\"maxInclusive\")\n        res = []\n        if ran[0][0] != \"m\":\n            elem = min_\n            elem.text = ran[0]\n            res.append(elem)\n        if ran[1][0] != \"m\":\n            elem = max_\n            elem.text = ran[1]\n            res.append(elem)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_stmt(self, stmt, p_elem, pset={}):\n        if self.debug > 0:\n            sys.stderr.write(\"Handling '%s %s'\\n\" %\n                             (util.keyword_to_str(stmt.raw_keyword), stmt.arg))\n        try:\n            method = self.stmt_handler[stmt.keyword]\n        except KeyError:\n            if isinstance(stmt.keyword, tuple):\n                try:\n                    method = self.ext_handler[stmt.keyword[0]][stmt.keyword[1]]\n                except KeyError:\n                    method = self.rng_annotation\n                method(stmt, p_elem)\n                return\n            else:\n                raise error.EmitError(\n                    \"Unknown keyword %s - this should not happen.\\n\"\n                    % stmt.keyword)\n        method(stmt, p_elem, pset)", "response": "Handles a single statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_substmts(self, stmt, p_elem, pset={}):\n        for sub in stmt.substmts:\n            self.handle_stmt(sub, p_elem, pset)", "response": "Handle all substatements of stmt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping stmt to a NETMOD - specific attribute.", "response": "def nma_attribute(self, stmt, p_elem, pset=None):\n        \"\"\"Map `stmt` to a NETMOD-specific attribute.\n\n        The name of the attribute is the same as the 'keyword' of\n        `stmt`.\n        \"\"\"\n        att = \"nma:\" + stmt.keyword\n        if att not in p_elem.attr:\n            p_elem.attr[att] = stmt.arg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling ``type`` statement. Built-in types are handled by one of the specific type callback methods defined below.", "response": "def type_stmt(self, stmt, p_elem, pset):\n        \"\"\"Handle ``type`` statement.\n\n        Built-in types are handled by one of the specific type\n        callback methods defined below.\n        \"\"\"\n        typedef = stmt.i_typedef\n        if typedef and not stmt.i_is_derived: # just ref\n            uname, dic = self.unique_def_name(typedef)\n            if uname not in dic:\n                self.install_def(uname, typedef, dic)\n            SchemaNode(\"ref\", p_elem).set_attr(\"name\", uname)\n            defst = typedef.search_one(\"default\")\n            if defst:\n                dic[uname].default = defst.arg\n                occur = 1\n            else:\n                occur = dic[uname].occur\n            if occur > 0: self.propagate_occur(p_elem, occur)\n            return\n        chain = [stmt]\n        tdefault = None\n        while typedef:\n            type_ = typedef.search_one(\"type\")\n            chain.insert(0, type_)\n            if tdefault is None:\n                tdef = typedef.search_one(\"default\")\n                if tdef:\n                    tdefault = tdef.arg\n            typedef = type_.i_typedef\n        if tdefault and p_elem.occur == 0:\n            p_elem.default = tdefault\n            self.propagate_occur(p_elem, 1)\n        self.type_handler[chain[0].arg](chain, p_elem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choice_type(self, tchain, p_elem):\n        elem = SchemaNode.choice(p_elem, occur=2)\n        self.handle_substmts(tchain[0], elem)", "response": "Handle enumeration and union types."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mapped_type(self, tchain, p_elem):\n        SchemaNode(\"data\", p_elem).set_attr(\"type\",\n                                            self.datatype_map[tchain[0].arg])", "response": "Handle types that are simply mapped to RELAX NG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pyang_plugin_init():\n\n    # Register the plugin\n    plugin.register_plugin(MDPlugin())\n\n    # Register that we handle extensions from the YANG module\n    # 'ietf-yang-metadata'\n    grammar.register_extension_module(md_module_name)\n\n    # Register the special grammar\n    for (stmt, occurance, (arg, rules), add_to_stmts) in md_stmts:\n        grammar.add_stmt((md_module_name, stmt), (arg, rules))\n        grammar.add_to_stmts_rules(add_to_stmts,\n                                   [((md_module_name, stmt), occurance)])", "response": "Called by pyang plugin framework at to initialize the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse by plugins to add grammar for an extension statement.", "response": "def add_stmt(stmt, arg_rules):\n    \"\"\"Use by plugins to add grammar for an extension statement.\"\"\"\n    (arg, rules) = arg_rules\n    stmt_map[stmt] = (arg, rules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses by plugins to add extra rules to the existing rules for a statement.", "response": "def add_to_stmts_rules(stmts, rules):\n    \"\"\"Use by plugins to add extra rules to the existing rules for\n    a statement.\"\"\"\n    def is_rule_less_than(ra, rb):\n        rka = ra[0]\n        rkb = rb[0]\n        if not util.is_prefixed(rkb):\n            # old rule is non-prefixed; append new rule after\n            return False\n        if not util.is_prefixed(rka):\n            # old rule prefixed, but new rule is not, insert\n            return True\n        # both are prefixed, compare modulename\n        return rka[0] < rkb[0]\n    for s in stmts:\n        (arg, rules0) = stmt_map[s]\n        for r in rules:\n            i = 0\n            while i < len(rules0):\n                if is_rule_less_than(r, rules0[i]):\n                    rules0.insert(i, r)\n                    break\n                i += 1\n            if i == len(rules0):\n                rules0.insert(i, r)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chk_module_statements(ctx, module_stmt, canonical=False):\n    return chk_statement(ctx, module_stmt, top_stmts, canonical)", "response": "Validate the top_stmts of a module statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates a single statement according to a grammar.", "response": "def chk_statement(ctx, stmt, grammar, canonical=False):\n    \"\"\"Validate `stmt` according to `grammar`.\n\n    Marks each statement in the hierearchy with stmt.is_grammatically_valid,\n    which is a boolean.\n\n    Return True if stmt is valid, False otherwise.\n    \"\"\"\n    n = len(ctx.errors)\n    if canonical == True:\n        canspec = grammar\n    else:\n        canspec = []\n    _chk_stmts(ctx, stmt.pos, [stmt], None, (grammar, canspec), canonical)\n    return n == len(ctx.errors)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmatch stmt against the spec.", "response": "def _match_stmt(ctx, stmt, specs, canonical):\n    \"\"\"Match stmt against the spec.\n\n    Return None | spec'\n    spec' is an updated spec with the matching spec consumed\n    \"\"\"\n    (spec, canspec) = specs\n    i = 0\n    while i < len(spec):\n        (keywd, occurance) = spec[i]\n        if keywd == '$any':\n            return (spec, canspec)\n        if keywd == '$1.1':\n            (keywd, occurance) = occurance\n            if (stmt.i_module.i_version == '1' and\n                keywd == stmt.keyword):\n                return None\n        if keywd == stmt.keyword:\n            if occurance == '1' or occurance == '?':\n                # consume this match\n                if canonical == True:\n                    return (spec[i+1:], spec_del_kwd(keywd, canspec))\n                else:\n                    return (spec[:i] + spec[i+1:], canspec)\n            if occurance == '+':\n                # mark that we have found the one that was needed\n                c = (keywd, '*')\n                if canonical == True:\n                    return ([c] + spec[i+1:], canspec)\n                else:\n                    return (spec[:i] + [c] + spec[i+1:], canspec)\n            else:\n                # occurane == '*'\n                if canonical == True:\n                    return (spec[i:], canspec)\n                else:\n                    return (spec, canspec)\n        elif keywd == '$choice':\n            cases = occurance\n            j = 0\n            while j < len(cases):\n                # check if this alternative matches - check for a\n                # match with each optional keyword\n                save_errors = copy.copy(ctx.errors)\n                if spec == top_stmts:\n                    match_res = _match_stmt(ctx, stmt, (cases[j],[]), False)\n                else:\n                    match_res = _match_stmt(ctx, stmt, (cases[j],cases[j]),\n                                            canonical)\n                if match_res != None:\n                    # this case branch matched, use it.\n                    # remove the choice and add res to the spec.\n                    nspec = spec[:i] + match_res[0] + spec[i+1:]\n                    return (nspec, canspec)\n                # we must not report errors on non-matching branches\n                ctx.errors = save_errors\n                j += 1\n        elif keywd == '$interleave':\n            cspec = occurance\n            match_res = _match_stmt(ctx, stmt, (cspec, cspec), canonical)\n            if match_res != None:\n                # we got a match\n                return (spec, canspec)\n        elif util.is_prefixed(stmt.keyword):\n            # allow extension statements mixed with these\n            # set canonical to False in this call to just remove the\n            # matching stmt from the spec\n            match_res = _match_stmt(ctx, stmt, (spec[i+1:], canspec), False)\n            if match_res != None:\n                return (spec[:i+1] + match_res[0], canspec)\n            else:\n                return None\n        elif keywd == '$cut':\n            # any non-optional statements left are errors\n            for (keywd, occurance) in spec[:i]:\n                if occurance == '1' or occurance == '+':\n                    error.err_add(ctx.errors, stmt.pos, 'UNEXPECTED_KEYWORD_1',\n                                  (util.keyword_to_str(stmt.raw_keyword),\n                                   util.keyword_to_str(keywd)))\n            # consume them so we don't report the same error again\n            spec = spec[i:]\n            i = 0\n        elif canonical == True:\n            if occurance == '1' or occurance == '+':\n                error.err_add(ctx.errors, stmt.pos,\n                              'UNEXPECTED_KEYWORD_CANONICAL_1',\n                              (util.keyword_to_str(stmt.raw_keyword),\n                               util.keyword_to_str(keywd)))\n                # consume it so we don't report the same error again\n                spec = spec[i:]\n                i = 0\n        # check next in spec\n        i += 1\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sort_canonical(keyword, stmts):\n\n    try:\n        (_arg_type, subspec) = stmt_map[keyword]\n    except KeyError:\n        return stmts\n    res = []\n    # keep the order of data definition statements and case\n    keep = [s[0] for s in data_def_stmts] + ['case']\n    for (kw, _spec) in flatten_spec(subspec):\n        # keep comments before a statement together with that statement\n        comments = []\n        for s in stmts:\n            if s.keyword == '_comment':\n                comments.append(s)\n            elif s.keyword == kw and kw not in keep:\n                res.extend(comments)\n                comments = []\n                res.append(s)\n            else:\n                comments = []\n\n    # then copy all other statements (extensions)\n    res.extend([stmt for stmt in stmts if stmt not in res])\n    return res", "response": "Sort all statements in the canonical order defined by keyword."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_step_7(p):\n    'Step : AbbreviatedStep PredicateList'\n    if p[1][1] == 'self':\n        a = \".\"\n        x = \"self::node()\"\n    else:\n        a = \"..\"\n        x = \"parent::node()\"\n    msg = \"%s[<pred>] is illegal syntax.  use %s[<pred>] instead,\" % (a, x)\n    raise xpath_lexer.XPathError(msg, 1, 1)", "response": "Step : AbbreviatedStep PredicateList"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscan the string s for tokens and return a list of tokens or raise SyntaxError on failure.", "response": "def scan(s):\n    \"\"\"Return a list of tokens, or throw SyntaxError on failure.\n    \"\"\"\n    line = 1\n    linepos = 1\n    pos = 0\n    toks = []\n    while pos < len(s):\n        matched = False\n        for (tokname, r) in patterns:\n            m = r.match(s, pos)\n            if m is not None:\n                # found a matching token\n                v = m.group(0)\n                prec = _preceding_token(toks)\n                if tokname == 'STAR' and prec is not None and _is_special(prec):\n                    # XPath 1.0 spec, 3.7 special rule 1a\n                    # interpret '*' as a wildcard\n                    tok = XPathTok('wildcard', v, line, linepos)\n                elif (tokname == 'name' and\n                      prec is not None and not _is_special(prec) and\n                      v in operators):\n                    # XPath 1.0 spec, 3.7 special rule 1b\n                    # interpret the name as an operator\n                    tok = XPathTok(operators[v], v, line, linepos)\n                elif tokname == 'name':\n                    # check if next token is '('\n                    if re_open_para.match(s, pos + len(v)):\n                        # XPath 1.0 spec, 3.7 special rule 2\n                        if v in node_types:\n                            # XPath 1.0 spec, 3.7 special rule 2a\n                            tok = XPathTok('node_type', v, line, linepos)\n                        else:\n                            # XPath 1.0 spec, 3.7 special rule 2b\n                            tok = XPathTok('function_name', v, line, linepos)\n                    # check if next token is '::'\n                    elif re_axis.match(s, pos + len(v)):\n                        # XPath 1.0 spec, 3.7 special rule 3\n                        if v in axes:\n                            tok = XPathTok('axis', v, line, linepos)\n                        else:\n                            e = \"unknown axis %s\" % v\n                            raise XPathError(e, line, linepos)\n                    else:\n                        tok = XPathTok('name', v, line, linepos)\n                else:\n                    tok = XPathTok(tokname, v, line, linepos)\n                if tokname == '_whitespace':\n                    n = v.count('\\n')\n                    if n > 0:\n                        line = line + n\n                        linepos = len(v) - v.rfind('\\n')\n                    else:\n                        linepos += len(v)\n                else:\n                    linepos += len(v)\n                pos += len(v)\n                toks.append(tok)\n                matched = True\n                break\n        if matched == False:\n            # no patterns matched\n            raise XPathError('syntax error', line, linepos)\n    return toks"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of YANG module names with revisions.", "response": "def yang_modules(self):\n        \"\"\"\n        Return a list of advertised YANG module names with revisions.\n\n        Avoid repeated modules.\n        \"\"\"\n        res = {}\n        for c in self.capabilities:\n            m = c.parameters.get(\"module\")\n            if m is None or m in res: continue\n            res[m] = c.parameters.get(\"revision\")\n        return res.items()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_features(self, yam):\n        mcap = [ c for c in self.capabilities\n                 if c.parameters.get(\"module\", None) == yam ][0]\n        if not mcap.parameters.get(\"features\"): return []\n        return mcap.parameters[\"features\"].split(\",\")", "response": "Return list of features declared for module yam."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registered_capabilities(self):\n        return dict ([ (CAPABILITIES[c.id],c) for c in self.capabilities\n                 if c.id in CAPABILITIES ])", "response": "Return dictionary of non - VAULT capabilities."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef guess_format(text):\n    format = 'yang'\n    i = 0\n    while i < len(text) and text[i].isspace():\n        i += 1\n    if i < len(text):\n        if text[i] == '<':\n            format = 'yin'\n    return format", "response": "Guess YANG format from text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new list with x removed from xs", "response": "def listsdelete(x, xs):\n    \"\"\"Return a new list with x removed from xs\"\"\"\n    i = xs.index(x)\n    return xs[:i] + xs[(i+1):]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unique_prefixes(context):\n    res = {}\n    for m in context.modules.values():\n        if m.keyword == \"submodule\": continue\n        prf = new = m.i_prefix\n        suff = 0\n        while new in res.values():\n            suff += 1\n            new = \"%s%x\" % (prf, suff)\n        res[m] = new\n    return res", "response": "Return a dictionary with unique prefixes for modules in context."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the installation prefix where necessary.", "response": "def preprocess_files(self, prefix):\n            \"\"\"Change the installation prefix where necessary.\n            \"\"\"\n            if prefix is None: return\n            files = (\"bin/yang2dsdl\", \"man/man1/yang2dsdl.1\",\n                     \"pyang/plugins/jsonxsl.py\")\n            regex = re.compile(\"^(.*)/usr/local(.*)$\")\n            for f in files:\n                  inf = open(f)\n                  cnt = inf.readlines()\n                  inf.close()\n                  ouf = open(f,\"w\")\n                  for line in cnt:\n                        mo = regex.search(line)\n                        if mo is None:\n                              ouf.write(line)\n                        else:\n                              ouf.write(mo.group(1) + prefix + mo.group(2) +\n                                        \"\\n\")\n                  ouf.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a module text and add the module data to the context.", "response": "def add_module(self, ref, text, format=None,\n                   expect_modulename=None, expect_revision=None,\n                   expect_failure_error=True):\n        \"\"\"Parse a module text and add the module data to the context\n\n        `ref` is a string which is used to identify the source of\n              the text for the user.  used in error messages\n        `text` is the raw text data\n        `format` is one of 'yang' or 'yin'.\n\n        Returns the parsed and validated module on success, and None on error.\n        \"\"\"\n        if format == None:\n            format = util.guess_format(text)\n\n        if format == 'yin':\n            p = yin_parser.YinParser()\n        else:\n            p = yang_parser.YangParser()\n\n        module = p.parse(self, ref, text)\n        if module is None:\n            return None\n\n        if expect_modulename is not None:\n            if not re.match(syntax.re_identifier, expect_modulename):\n                error.err_add(self.errors, module.pos,\n                              'FILENAME_BAD_MODULE_NAME',\n                              (ref, expect_modulename, syntax.identifier))\n            elif expect_modulename != module.arg:\n                if expect_failure_error:\n                    error.err_add(self.errors, module.pos, 'BAD_MODULE_NAME',\n                                  (module.arg, ref, expect_modulename))\n                    return None\n                else:\n                    error.err_add(self.errors, module.pos, 'WBAD_MODULE_NAME',\n                                  (module.arg, ref, expect_modulename))\n\n        latest_rev = util.get_latest_revision(module)\n        if expect_revision is not None:\n            if not re.match(syntax.re_date, expect_revision):\n                error.err_add(self.errors, module.pos, 'FILENAME_BAD_REVISION',\n                              (ref, expect_revision, 'YYYY-MM-DD'))\n            elif expect_revision != latest_rev:\n                if expect_failure_error:\n                    error.err_add(self.errors, module.pos, 'BAD_REVISION',\n                                  (latest_rev, ref, expect_revision))\n                    return None\n                else:\n                    error.err_add(self.errors, module.pos, 'WBAD_REVISION',\n                                  (latest_rev, ref, expect_revision))\n\n        if module.arg not in self.revs:\n            self.revs[module.arg] = []\n            revs = self.revs[module.arg]\n            revs.append((latest_rev, None))\n\n        return self.add_parsed_module(module)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef del_module(self, module):\n        rev = util.get_latest_revision(module)\n        del self.modules[(module.arg, rev)]", "response": "Remove a module from the context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_module(self, modulename, revision=None):\n        if revision is None and modulename in self.revs:\n            (revision, _handle) = self._get_latest_rev(self.revs[modulename])\n        if revision is not None:\n            if (modulename,revision) in self.modules:\n                return self.modules[(modulename, revision)]\n        else:\n            return None", "response": "Return the module if it exists in the context or None if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_module(self, pos, modulename, revision=None):\n\n        if modulename not in self.revs:\n            # this module doesn't exist in the repos at all\n            error.err_add(self.errors, pos, 'MODULE_NOT_FOUND', modulename)\n            # keep track of this to avoid multiple errors\n            self.revs[modulename] = []\n            return None\n        elif self.revs[modulename] == []:\n            # this module doesn't exist in the repos at all, error reported\n            return None\n\n        if revision is not None:\n            if (modulename,revision) in self.modules:\n                return self.modules[(modulename, revision)]\n            self._ensure_revs(self.revs[modulename])\n            x = util.keysearch(revision, 0, self.revs[modulename])\n            if x is not None:\n                (_revision, handle) = x\n                if handle == None:\n                    # this revision doesn't exist in the repos, error reported\n                    return None\n            else:\n                # this revision doesn't exist in the repos\n                error.err_add(self.errors, pos, 'MODULE_NOT_FOUND_REV',\n                              (modulename, revision))\n                # keep track of this to avoid multiple errors\n                self.revs[modulename].append((revision, None))\n                return None\n        else:\n            # get the latest revision\n            (revision, handle) = self._get_latest_rev(self.revs[modulename])\n            if (modulename, revision) in self.modules:\n                return self.modules[(modulename, revision)]\n\n        if handle is None:\n            module = None\n        elif handle[0] == 'parsed':\n            module = handle[1]\n            ref = handle[2]\n            yintext = handle[3]\n            if modulename != module.arg:\n                error.err_add(self.errors, module.pos, 'BAD_MODULE_NAME',\n                              (module.arg, ref, modulename))\n                module = None\n            elif yintext is None:\n                module = self.add_parsed_module(handle[1])\n            else:\n                p = yin_parser.YinParser()\n                self.yin_module_map[module.arg] = []\n                module = p.parse(self, ref, yintext)\n                if module is not None:\n                    module = self.add_parsed_module(module)\n        else:\n            # get it from the repos\n            try:\n                r = self.repository.get_module_from_handle(handle)\n                (ref, format, text) = r\n                module = self.add_module(ref, text, format,\n                                         modulename, revision)\n            except self.repository.ReadError as ex:\n                error.err_add(self.errors, pos, 'READ_ERROR', str(ex))\n                module = None\n\n        if module == None:\n            return None\n        # if modulename != module.arg:\n        #     error.err_add(self.errors, module.pos, 'BAD_MODULE_FILENAME',\n        #                   (module.arg, ref, modulename))\n        #     latest_rev = util.get_latest_revision(module)\n\n        #     if revision is not None and revision != latest_rev:\n        #         error.err_add(self.errors, module.pos, 'BAD_REVISION',\n        #                       (latest_rev, ref, revision))\n\n        #     self.del_module(module)\n        #     self.modules[(modulename, latest_rev)] = None\n        #     return None\n        return module", "response": "Searches for a module named modulename in the repository and returns the module if found or None if not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_module(self, modulename, revision=None, extra={}):\n\n        if modulename not in self.revs:\n            # this module doesn't exist in the repos at all\n            return None\n        elif self.revs[modulename] == []:\n            # this module doesn't exist in the repos at all, error reported\n            return None\n\n        if revision is not None:\n            if (modulename,revision) in self.modules:\n                return self.modules[(modulename, revision)]\n            self._ensure_revs(self.revs[modulename])\n            x = util.keysearch(revision, 1, self.revs[modulename])\n            if x is not None:\n                (_revision, handle) = x\n                if handle == None:\n                    # this revision doesn't exist in the repos, error reported\n                    return None\n            else:\n                # this revision doesn't exist in the repos\n                return None\n        else:\n            # get the latest revision\n            (revision, handle) = self._get_latest_rev(self.revs[modulename])\n            if (modulename, revision) in self.modules:\n                return self.modules[(modulename, revision)]\n\n        if handle[0] == 'parsed':\n            module = handle[1]\n            return module\n        else:\n            # get it from the repos\n            try:\n                r = self.repository.get_module_from_handle(handle)\n                (ref, format, text) = r\n                if format == None:\n                    format = util.guess_format(text)\n\n                if format == 'yin':\n                    p = yin_parser.YinParser(extra)\n                else:\n                    p = yang_parser.YangParser(extra)\n\n                return p.parse(self, ref, text)\n            except self.repository.ReadError as ex:\n                return None", "response": "Searches for a module named modulename in the repository at all and returns the module if found or None if not compiled at all."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(plugindirs=[]):\n\n    # initialize the builtin plugins\n    from .translators import yang,yin,dsdl\n    yang.pyang_plugin_init()\n    yin.pyang_plugin_init()\n    dsdl.pyang_plugin_init()\n\n    # initialize installed plugins\n    for ep in pkg_resources.iter_entry_points(group='pyang.plugin'):\n        plugin_init = ep.load()\n        plugin_init()\n\n    # search for plugins in std directories (plugins directory first)\n    basedir = os.path.split(sys.modules['pyang'].__file__)[0]\n    plugindirs.insert(0, basedir + \"/transforms\")\n    plugindirs.insert(0, basedir + \"/plugins\")\n\n    # add paths from env\n    pluginpath = os.getenv('PYANG_PLUGINPATH')\n    if pluginpath is not None:\n        plugindirs.extend(pluginpath.split(os.pathsep))\n\n    syspath = sys.path\n    for plugindir in plugindirs:\n        sys.path = [plugindir] + syspath\n        try:\n            fnames = os.listdir(plugindir)\n        except OSError:\n            continue\n        modnames = []\n        for fname in fnames:\n            if (fname.startswith(\".#\") or\n                fname.startswith(\"__init__.py\") or\n                fname.endswith(\"_flymake.py\") or\n                fname.endswith(\"_flymake.pyc\")):\n                pass\n            elif fname.endswith(\".py\"):\n                modname = fname[:-3]\n                if modname not in modnames:\n                    modnames.append(modname)\n            elif fname.endswith(\".pyc\"):\n                modname = fname[:-4]\n                if modname not in modnames:\n                    modnames.append(modname)\n        for modname in modnames:\n            pluginmod = __import__(modname)\n            try:\n                pluginmod.pyang_plugin_init()\n            except AttributeError as s:\n                print(pluginmod.__dict__)\n                raise AttributeError(pluginmod.__file__ + ': ' + str(s))\n        sys.path = syspath", "response": "Initialize the plugin framework"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_qname(qname):\n        res = qname.split(YinParser.ns_sep)\n        if len(res) == 1:       # no namespace\n            return None, res[0]\n        else:\n            return res", "response": "Split qname into namespace URI and local name as a tuple. This is a static\n        method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the string text containing a YIN module. Return a Statement on success Return None on failure.", "response": "def parse(self, ctx, ref, text):\n        \"\"\"Parse the string `text` containing a YIN (sub)module.\n\n        Return a Statement on success or None on failure.\n        \"\"\"\n\n        self.ctx = ctx\n        self.pos = error.Position(ref)\n        self.top = None\n        self.top_element = None\n\n        self.uri = None\n        self.nsmap = {}\n        self.prefixmap = {}\n        self.included = []\n        self.extensions = {}\n\n        self.data = ''\n        self.element_stack = []\n\n        try:\n            self.parser.Parse(text.encode('utf-8'), True)\n        except error.Abort:\n            return None\n        except expat.ExpatError as ex:\n            self.pos.line = ex.lineno\n            error.err_add(self.ctx.errors, self.pos, 'SYNTAX_ERROR',\n                          str(ex).split(\":\")[0])\n            return None\n\n        self.look_ahead()\n        self.create_statement(self.top_element, None)\n        return self.top"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_attr(self, pos, attrs):\n\n        for at in attrs:\n            (ns, local_name) = self.split_qname(at)\n            if ns is None:\n                error.err_add(self.ctx.errors, pos,\n                              'UNEXPECTED_ATTRIBUTE', local_name)\n            elif ns == yin_namespace:\n                error.err_add(self.ctx.errors, pos,\n                              'UNEXPECTED_ATTRIBUTE', \"{\"+at)", "response": "Check for unknown attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for a defintion with keyword name", "response": "def search_definition(self, module, keyword, arg):\n        \"\"\"Search for a defintion with `keyword` `name`\n        Search the module and its submodules.\"\"\"\n        r = module.search_one(keyword, arg)\n        if r is not None:\n            return r\n        for i in module.search('include'):\n            modulename = i.arg\n            m = self.ctx.search_module(i.pos, modulename)\n            if m is not None:\n                r = m.search_one(keyword, arg)\n                if r is not None:\n                    return r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef emit_arg(keywordstr, stmt, fd, indent, indentstep, max_line_len, line_len):\n    arg = escape_str(stmt.arg)\n    lines = arg.splitlines(True)\n    if len(lines) <= 1:\n        if len(arg) > 0 and arg[-1] == '\\n':\n            arg = arg[:-1] + r'\\n'\n        if (stmt.keyword in _force_newline_arg or\n            need_new_line(max_line_len, line_len, arg)):\n            fd.write('\\n' + indent + indentstep + '\"' + arg + '\"')\n            return True\n        else:\n            fd.write(' \"' + arg + '\"')\n            return False\n    else:\n        need_nl = False\n        if stmt.keyword in _force_newline_arg:\n            need_nl = True\n        elif len(keywordstr) > 8:\n            # Heuristics: multi-line after a \"long\" keyword looks better\n            # than after a \"short\" keyword (compare 'when' and 'error-message')\n            need_nl = True\n        else:\n            for line in lines:\n                if need_new_line(max_line_len, line_len + 1, line):\n                    need_nl = True\n                    break\n        if need_nl:\n            fd.write('\\n' + indent + indentstep)\n            prefix = indent + indentstep\n        else:\n            fd.write(' ')\n            prefix = indent + len(keywordstr) * ' ' + ' '\n        fd.write('\"' + lines[0])\n        for line in lines[1:-1]:\n            if line[0] == '\\n':\n                fd.write('\\n')\n            else:\n                fd.write(prefix + ' ' + line)\n        # write last line\n        fd.write(prefix + ' ' + lines[-1])\n        if lines[-1][-1] == '\\n':\n            # last line ends with a newline, indent the ending quote\n            fd.write(prefix + '\"')\n        else:\n            fd.write('\"')\n        return True", "response": "Print the argument string with double quotes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef emit(self, ctx, modules, fd):\n        if ctx.opts.sample_path is not None:\n            path = ctx.opts.sample_path.split('/')\n            if path[0] == '':\n                path = path[1:]\n        else:\n            path = []\n\n        for (epos, etag, eargs) in ctx.errors:\n            if error.is_error(error.err_level(etag)):\n                raise error.EmitError(\n                    \"sample-xml-skeleton plugin needs a valid module\")\n        self.doctype = ctx.opts.doctype\n        if self.doctype not in (\"config\", \"data\"):\n            raise error.EmitError(\"Unsupported document type: %s\" %\n                                  self.doctype)\n        self.annots = ctx.opts.sample_annots\n        self.defaults = ctx.opts.sample_defaults\n        self.node_handler = {\n            \"container\": self.container,\n            \"leaf\": self.leaf,\n            \"anyxml\": self.anyxml,\n            \"choice\": self.process_children,\n            \"case\": self.process_children,\n            \"list\": self.list,\n            \"leaf-list\": self.leaf_list\n        }\n        self.ns_uri = {}\n        for yam in modules:\n            self.ns_uri[yam] = yam.search_one(\"namespace\").arg\n        self.top = etree.Element(\n            self.doctype,\n            {\"xmlns\": \"urn:ietf:params:xml:ns:netconf:base:1.0\"})\n        tree = etree.ElementTree(self.top)\n        for yam in modules:\n            self.process_children(yam, self.top, None, path)\n        if sys.version > \"3\":\n            fd.write(str(etree.tostring(tree, pretty_print=True,\n                                        encoding=\"UTF-8\",\n                                        xml_declaration=True), \"UTF-8\"))\n        elif sys.version > \"2.7\":\n            tree.write(fd, encoding=\"UTF-8\", pretty_print=True,\n                       xml_declaration=True)\n        else:\n            tree.write(fd, pretty_print=True, encoding=\"UTF-8\")", "response": "This function is called by the XML parser to generate the sample XML document."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess all children of node.", "response": "def process_children(self, node, elem, module, path, omit=[]):\n        \"\"\"Proceed with all children of `node`.\"\"\"\n        for ch in node.i_children:\n            if ch not in omit and (ch.i_config or self.doctype == \"data\"):\n                self.node_handler.get(ch.keyword, self.ignore)(\n                    ch, elem, module, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef container(self, node, elem, module, path):\n        nel, newm, path = self.sample_element(node, elem, module, path)\n        if path is None:\n            return\n        if self.annots:\n            pres = node.search_one(\"presence\")\n            if pres is not None:\n                nel.append(etree.Comment(\" presence: %s \" % pres.arg))\n        self.process_children(node, nel, newm, path)", "response": "Create a sample container element and proceed with its children."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a sample leaf element.", "response": "def leaf(self, node, elem, module, path):\n        \"\"\"Create a sample leaf element.\"\"\"\n        if node.i_default is None:\n            nel, newm, path = self.sample_element(node, elem, module, path)\n            if path is None:\n                return\n            if self.annots:\n                nel.append(etree.Comment(\n                    \" type: %s \" % node.search_one(\"type\").arg))\n        elif self.defaults:\n            nel, newm, path = self.sample_element(node, elem, module, path)\n            if path is None:\n                return\n            nel.text = str(node.i_default_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef anyxml(self, node, elem, module, path):\n        nel, newm, path = self.sample_element(node, elem, module, path)\n        if path is None:\n            return\n        if self.annots:\n            nel.append(etree.Comment(\" anyxml \"))", "response": "Create a sample anyxml element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate sample entries of a list.", "response": "def list(self, node, elem, module, path):\n        \"\"\"Create sample entries of a list.\"\"\"\n        nel, newm, path = self.sample_element(node, elem, module, path)\n        if path is None:\n            return\n        for kn in node.i_key:\n            self.node_handler.get(kn.keyword, self.ignore)(\n                kn, nel, newm, path)\n        self.process_children(node, nel, newm, path, node.i_key)\n        minel = node.search_one(\"min-elements\")\n        self.add_copies(node, elem, nel, minel)\n        if self.annots:\n            self.list_comment(node, nel, minel)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef leaf_list(self, node, elem, module, path):\n        nel, newm, path = self.sample_element(node, elem, module, path)\n        if path is None:\n            return\n        minel = node.search_one(\"min-elements\")\n        self.add_copies(node, elem, nel, minel)\n        self.list_comment(node, nel, minel)", "response": "Create sample entries of a leaf - list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates element under parent.", "response": "def sample_element(self, node, parent, module, path):\n        \"\"\"Create element under `parent`.\n\n        Declare new namespace if necessary.\n        \"\"\"\n        if path is None:\n            return parent, module, None\n        elif path == []:\n            # GO ON\n            pass\n        else:\n            if node.arg == path[0]:\n                path = path[1:]\n            else:\n                return parent, module, None\n\n        res = etree.SubElement(parent, node.arg)\n        mm = node.main_module()\n        if mm != module:\n            res.attrib[\"xmlns\"] = self.ns_uri[mm]\n            module = mm\n        return res, module, path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_copies(self, node, parent, elem, minel):\n        rep = 0 if minel is None else int(minel.arg) - 1\n        for i in range(rep):\n            parent.append(copy.deepcopy(elem))", "response": "Add appropriate number of elem copies to parent."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds list annotation to elem.", "response": "def list_comment(self, node, elem, minel):\n        \"\"\"Add list annotation to `elem`.\"\"\"\n        lo = \"0\" if minel is None else minel.arg\n        maxel = node.search_one(\"max-elements\")\n        hi = \"\" if maxel is None else maxel.arg\n        elem.insert(0, etree.Comment(\n            \" # entries: %s..%s \" % (lo, hi)))\n        if node.keyword == 'list':\n            elem.insert(0, etree.Comment(\n                \" # keys: \" + \",\".join([k.arg for k in node.i_key])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pyang_plugin_init():\n\n    # Register the plugin\n    plugin.register_plugin(RESTCONFPlugin())\n\n    # Register that we handle extensions from the YANG module 'ietf-restconf'\n    grammar.register_extension_module(restconf_module_name)\n\n    yd = (restconf_module_name, 'yang-data')\n    statements.add_data_keyword(yd)\n    statements.add_keyword_with_children(yd)\n    statements.add_keywords_with_no_explicit_config(yd)\n\n    # Register the special grammar\n    for (stmt, occurance, (arg, rules), add_to_stmts) in restconf_stmts:\n        grammar.add_stmt((restconf_module_name, stmt), (arg, rules))\n        grammar.add_to_stmts_rules(add_to_stmts,\n                                   [((restconf_module_name, stmt), occurance)])\n\n    # Add validation functions\n    statements.add_validation_fun('expand_2',\n                                  [yd],\n                                  v_yang_data)\n\n    # Register special error codes\n    error.add_error_code('RESTCONF_YANG_DATA_CHILD', 1,\n                         \"the 'yang-data' extension must have exactly one \" +\n                         \"child that is a container\")", "response": "Called by pyang plugin framework at to initialize the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef slugify(value, separator='-', max_length=0, word_boundary=False,\n            entities=True, decimal=True, hexadecimal=True):\n    '''Normalizes string, removes non-alpha characters,\n    and converts spaces to ``separator`` character\n    '''\n    value = normalize('NFKD', to_string(value, 'utf-8', 'ignore'))\n    if unidecode:\n        value = unidecode(value)\n\n    # character entity reference\n    if entities:\n        value = CHAR_ENTITY_REXP.sub(\n            lambda m: chr(name2codepoint[m.group(1)]), value)\n\n    # decimal character reference\n    if decimal:\n        try:\n            value = DECIMAL_REXP.sub(lambda m: chr(int(m.group(1))), value)\n        except Exception:\n            pass\n\n    # hexadecimal character reference\n    if hexadecimal:\n        try:\n            value = HEX_REXP.sub(lambda m: chr(int(m.group(1), 16)), value)\n        except Exception:\n            pass\n\n    value = value.lower()\n\n    value = REPLACE1_REXP.sub('', value)\n    value = REPLACE2_REXP.sub('-', value)\n\n    # remove redundant -\n    value = REMOVE_REXP.sub('-', value).strip('-')\n\n    # smart truncate if requested\n    if max_length > 0:\n        value = smart_truncate(value, max_length, word_boundary, '-')\n\n    if separator != '-':\n        value = value.replace('-', separator)\n\n    return value", "response": "Normalizes string removes non - alpha characters and converts spaces to separator character\n and converts spaces to separator character\n "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruncating a string to a maximum length.", "response": "def smart_truncate(value, max_length=0, word_boundaries=False, separator=' '):\n    \"\"\" Truncate a string \"\"\"\n\n    value = value.strip(separator)\n\n    if not max_length:\n        return value\n\n    if len(value) < max_length:\n        return value\n\n    if not word_boundaries:\n        return value[:max_length].strip(separator)\n\n    if separator not in value:\n        return value[:max_length]\n\n    truncated = ''\n    for word in value.split(separator):\n        if word:\n            next_len = len(truncated) + len(word) + len(separator)\n            if next_len <= max_length:\n                truncated += '{0}{1}'.format(word, separator)\n    if not truncated:\n        truncated = value[:max_length]\n    return truncated.strip(separator)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling by the protocol consumer to get a new instance of the class.", "response": "def get(self):\n        '''Called by the protocol consumer'''\n        if self._current:\n            return self._resume(self._current, False)\n        else:\n            return self._get(None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multi_bulk(self, args):\n        '''Multi bulk encoding for list/tuple ``args``\n        '''\n        return null_array if args is None else b''.join(self._pack(args))", "response": "Multi bulk encoding for list / tuple args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npacking pipeline commands into bytes.", "response": "def pack_pipeline(self, commands):\n        '''Packs pipeline commands into bytes.'''\n        return b''.join(\n            starmap(lambda *args: b''.join(self._pack_command(args)),\n                    (a for a, _ in commands)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pypi_release(self):\n        meta = self.distribution.metadata\n        pypi = ServerProxy(self.pypi_index_url)\n        releases = pypi.package_releases(meta.name)\n        if releases:\n            return next(iter(sorted(releases, reverse=True)))", "response": "Get the latest pypi release"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_mainthread(thread=None):\n    '''Check if thread is the main thread.\n\n    If ``thread`` is not supplied check the current thread\n    '''\n    thread = thread if thread is not None else current_thread()\n    return isinstance(thread, threading._MainThread)", "response": "Check if thread is the main thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the current process local data dictionary.", "response": "def process_data(name=None):\n    '''Fetch the current process local data dictionary.\n\n    If ``name`` is not ``None`` it returns the value at``name``,\n    otherwise it return the process data dictionary\n    '''\n    ct = current_process()\n    if not hasattr(ct, '_pulsar_local'):\n        ct._pulsar_local = {}\n    loc = ct._pulsar_local\n    return loc.get(name) if name else loc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef thread_data(name, value=NOTHING, ct=None):\n    '''Set or retrieve an attribute ``name`` from thread ``ct``.\n\n    If ``ct`` is not given used the current thread. If ``value``\n    is None, it will get the value otherwise it will set the value.\n    '''\n    ct = ct or current_thread()\n    if is_mainthread(ct):\n        loc = process_data()\n    elif not hasattr(ct, '_pulsar_local'):\n        ct._pulsar_local = loc = {}\n    else:\n        loc = ct._pulsar_local\n    if value is not NOTHING:\n        if name in loc:\n            if loc[name] is not value:\n                raise RuntimeError(\n                    '%s is already available on this thread' % name)\n        else:\n            loc[name] = value\n    return loc.get(name)", "response": "Set or retrieve an attribute name from thread ct."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an internet address netloc and return a tuple with ``host and port.", "response": "def parse_address(netloc, default_port=8000):\n    '''Parse an internet address ``netloc`` and return a tuple with\n``host`` and ``port``.'''\n    if isinstance(netloc, tuple):\n        if len(netloc) != 2:\n            raise ValueError('Invalid address %s' % str(netloc))\n        return netloc\n    #\n    netloc = native_str(netloc)\n    auth = None\n    # Check if auth is available\n    if '@' in netloc:\n        auth, netloc = netloc.split('@')\n    if netloc.startswith(\"unix:\"):\n        host = netloc.split(\"unix:\")[1]\n        return '%s@%s' % (auth, host) if auth else host\n    # get host\n    if '[' in netloc and ']' in netloc:\n        host = netloc.split(']')[0][1:].lower()\n    elif ':' in netloc:\n        host = netloc.split(':')[0].lower()\n    elif netloc == \"\":\n        host = \"0.0.0.0\"\n    else:\n        host = netloc.lower()\n    # get port\n    netloc = netloc.split(']')[-1]\n    if \":\" in netloc:\n        port = netloc.split(':', 1)[1]\n        if not port.isdigit():\n            raise ValueError(\"%r is not a valid port number.\" % port)\n        port = int(port)\n    else:\n        port = default_port\n    return ('%s@%s' % (auth, host) if auth else host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_connection_string(connection_string, default_port=8000):\n    if '://' not in connection_string:\n        connection_string = 'dummy://%s' % connection_string\n    scheme, host, path, query, fragment = urlsplit(connection_string)\n    if not scheme and not host:\n        host, path = path, ''\n    elif path and not query:\n        query, path = path, ''\n        if query:\n            if query.find('?'):\n                path = query\n            else:\n                query = query[1:]\n    if path:\n        raise ValueError(\"Address must not have a path. Found '%s'\" % path)\n    if query:\n        params = dict(parse_qsl(query))\n    else:\n        params = {}\n    if scheme == 'dummy':\n        scheme = ''\n    return scheme, parse_address(host, default_port), params", "response": "Parses a connection string into a three elements tuple containing scheme host params."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if socket is closed.", "response": "def is_socket_closed(sock):     # pragma    nocover\n    \"\"\"Check if socket ``sock`` is closed.\"\"\"\n    if not sock:\n        return True\n    try:\n        if not poll:    # pragma nocover\n            if not select:\n                return False\n            try:\n                return bool(select([sock], [], [], 0.0)[0])\n            except socket.error:\n                return True\n        # This version is better on platforms that support it.\n        p = poll()\n        p.register(sock, POLLIN)\n        for (fno, ev) in p.poll(0.0):\n            if fno == sock.fileno():\n                # Either data is buffered (bad), or the connection is dropped.\n                return True\n    except Exception:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def rpc_server_info(self, request):\n        '''Return a dictionary of information regarding the server and workers.\n\n        It invokes the :meth:`extra_server_info` for adding custom\n        information.\n        '''\n        info = await send('arbiter', 'info')\n        info = self.extra_server_info(request, info)\n        try:\n            info = await info\n        except TypeError:\n            pass\n        return info", "response": "Return a dictionary of information regarding the server and workers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bind(self, callback):\n        handlers = self._handlers\n        if self._self is None:\n            raise RuntimeError('%s already fired, cannot add callbacks' % self)\n        if handlers is None:\n            handlers = []\n            self._handlers = handlers\n        handlers.append(callback)", "response": "Bind a callback to this event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a callback from the list of handlers", "response": "def unbind(self, callback):\n        \"\"\"Remove a callback from the list\n        \"\"\"\n        handlers = self._handlers\n        if handlers:\n            filtered_callbacks = [f for f in handlers if f != callback]\n            removed_count = len(handlers) - len(filtered_callbacks)\n            if removed_count:\n                self._handlers = filtered_callbacks\n            return removed_count\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfires an event with an exception or data.", "response": "def fire(self, exc=None, data=None):\n        \"\"\"Fire the event\n\n        :param exc: fire the event with an exception\n        :param data: fire an event with data\n        \"\"\"\n        o = self._self\n\n        if o is not None:\n            handlers = self._handlers\n            if self._onetime:\n                self._handlers = None\n                self._self = None\n\n            if handlers:\n                if exc is not None:\n                    for hnd in handlers:\n                        hnd(o, exc=exc)\n                elif data is not None:\n                    for hnd in handlers:\n                        hnd(o, data=data)\n                else:\n                    for hnd in handlers:\n                        hnd(o)\n\n            if self._waiter:\n                if exc:\n                    self._waiter.set_exception(exc)\n                else:\n                    self._waiter.set_result(data if data is not None else o)\n                self._waiter = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a future called back once the event has been fired.", "response": "def waiter(self):\n        \"\"\"Return a :class:`~asyncio.Future` called back once the event\n        has been fired.\n        If the event has been fired already return a resolved future.\n\n        This method is available only for one-time events\n        \"\"\"\n        assert self._onetime, 'One time events only can invoke waiter'\n        if not self._waiter:\n            self._waiter = get_event_loop().create_future()\n            if self.fired():\n                self._waiter.set_result(None)\n        return self._waiter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef event(self, name):\n        events = self.events()\n        if name not in events:\n            events[name] = Event(name, self, 0)\n        return events[name]", "response": "Returns the Event object at name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfire an event at the given name.", "response": "def fire_event(self, name, exc=None, data=None):\n        \"\"\"Fire event at ``name`` if it is registered\n        \"\"\"\n        if self._events and name in self._events:\n            self._events[name].fire(exc=exc, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbind all known events found in events key - valued parameters.", "response": "def bind_events(self, events):\n        '''Register all known events found in ``events`` key-valued parameters.\n        '''\n        evs = self._events\n        if evs and events:\n            for event in evs.values():\n                if event.name in events:\n                    event.bind(events[event.name])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy many times events from self to other.", "response": "def copy_many_times_events(self, other):\n        '''Copy :ref:`many times events <many-times-event>` from  ``other``.\n\n        All many times events of ``other`` are copied to this handler\n        provided the events handlers already exist.\n        '''\n        events = self.events()\n        other_events = other.events()\n        if events and other_events:\n            for name, event in other_events.items():\n                handlers = event.handlers()\n                if not event.onetime() and handlers:\n                    ev = events.get(name)\n                    # If the event is available add it\n                    if ev:\n                        for callback in handlers:\n                            ev.bind(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef frame_parser(version=None, kind=0, extensions=None, protocols=None):\n    '''Create a new :class:`FrameParser` instance.\n\n    :param version: protocol version, the default is 13\n    :param kind: the kind of parser, and integer between 0 and 3 (check the\n        :class:`FrameParser` documentation for details)\n    :param extensions: not used at the moment\n    :param protocols: not used at the moment\n    :param pyparser: if ``True`` (default ``False``) uses the python frame\n        parser implementation rather than the much faster cython\n        implementation.\n    '''\n    version = get_version(version)\n    # extensions, protocols\n    return FrameParser(version, kind, ProtocolError, close_codes=CLOSE_CODES)", "response": "Create a new FrameParser instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_close(data):\n    '''Parse the body of a close :class:`Frame`.\n\n    Returns a tuple (``code``, ``reason``) if successful otherwise\n    raise :class:`.ProtocolError`.\n    '''\n    length = len(data)\n    if length == 0:\n        return 1005, ''\n    elif length == 1:\n        raise ProtocolError(\"Close frame too short\")\n    else:\n        code, = unpack('!H', data[:2])\n        if not (code in CLOSE_CODES or 3000 <= code < 5000):\n            raise ProtocolError(\"Invalid status code for websocket\")\n        reason = data[2:].decode('utf-8')\n        return code, reason", "response": "Parse the body of a close frame. Returns a tuple of code and reason."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the executable that is used for reloading the application.", "response": "def _get_args_for_reloading():\n    \"\"\"Returns the executable. This contains a workaround for windows\n    if the executable is incorrectly reported to not have the .exe\n    extension which can cause bugs on reloading.\n    \"\"\"\n    rv = [sys.executable]\n    py_script = sys.argv[0]\n    if os.name == 'nt' and not os.path.exists(py_script) and \\\n       os.path.exists(py_script + '.exe'):\n        py_script += '.exe'\n    rv.append(py_script)\n    rv.extend(sys.argv[1:])\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restart_with_reloader(self):\n        while True:\n            LOGGER.info('Restarting with %s reloader' % self.name)\n            args = _get_args_for_reloading()\n            new_environ = os.environ.copy()\n            new_environ[PULSAR_RUN_MAIN] = 'true'\n            exit_code = subprocess.call(args, env=new_environ, close_fds=False)\n            if exit_code != EXIT_CODE:\n                return exit_code", "response": "Spawn a new Python interpreter with the same arguments as this one\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninvoking the stop on the event loop method.", "response": "def kill(self, sig):\n        '''Invoke the stop on the event loop method.'''\n        if self.is_alive() and self._loop:\n            self._loop.call_soon_threadsafe(self._loop.stop)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling by the client to encode Authentication header.", "response": "def encode(self, method, uri):\n        '''Called by the client to encode Authentication header.'''\n        if not self.username or not self.password:\n            return\n        o = self.options\n        qop = o.get('qop')\n        realm = o.get('realm')\n        nonce = o.get('nonce')\n        entdig = None\n        p_parsed = urlparse(uri)\n        path = p_parsed.path\n        if p_parsed.query:\n            path += '?' + p_parsed.query\n        ha1 = self.ha1(realm, self.password)\n        ha2 = self.ha2(qop, method, path)\n        if qop == 'auth':\n            if nonce == self.last_nonce:\n                self.nonce_count += 1\n            else:\n                self.nonce_count = 1\n            ncvalue = '%08x' % self.nonce_count\n            s = str(self.nonce_count).encode('utf-8')\n            s += nonce.encode('utf-8')\n            s += time.ctime().encode('utf-8')\n            s += os.urandom(8)\n            cnonce = sha1(s).hexdigest()[:16]\n            noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, qop, ha2)\n            respdig = self.KD(ha1, noncebit)\n        elif qop is None:\n            respdig = self.KD(ha1, \"%s:%s\" % (nonce, ha2))\n        else:\n            # XXX handle auth-int.\n            return\n        base = ('username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", '\n                'response=\"%s\"' % (self.username, realm, nonce, path, respdig))\n        opaque = o.get('opaque')\n        if opaque:\n            base += ', opaque=\"%s\"' % opaque\n        if entdig:\n            base += ', digest=\"%s\"' % entdig\n            base += ', algorithm=\"%s\"' % self.algorithm\n        if qop:\n            base += ', qop=%s, nc=%s, cnonce=\"%s\"' % (qop, ncvalue, cnonce)\n        return 'Digest %s' % base"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_401(self, response, exc=None):\n        if response.status_code == 401:\n            s_auth = response.headers.get('www-authenticate', '')\n            if 'digest' not in s_auth.lower():\n                return\n            request = response.request\n            if not request.headers.get('authorization'):\n                self.options = parse_dict_header(s_auth.replace('Digest ', ''))\n                authorization = self.encode(request.method, request.url)\n                params = request.inp_params.copy()\n                headers = params.pop('headers', [])\n                headers.append(('authorization', authorization))\n                params['headers'] = headers\n                response.request_again = request_again(request.method,\n                                                       request.url,\n                                                       params)", "response": "Takes the given response and tries digest - auth if needed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_wsgi_error(environ, exc):\n    '''The default error handler while serving a WSGI request.\n\n    :param environ: The WSGI environment.\n    :param exc: the exception\n    :return: a :class:`.WsgiResponse`\n    '''\n    if isinstance(exc, tuple):\n        exc_info = exc\n        exc = exc[1]\n    else:\n        exc_info = True\n    request = wsgi_request(environ)\n    request.cache.handle_wsgi_error = True\n    old_response = request.cache.pop('response', None)\n    response = request.response\n    if old_response:\n        response.content_type = old_response.content_type\n    logger = request.logger\n    #\n    if isinstance(exc, HTTPError):\n        response.status_code = exc.code or 500\n    else:\n        response.status_code = getattr(exc, 'status', 500)\n    response.headers.update(getattr(exc, 'headers', None) or ())\n    status = response.status_code\n    if status >= 500:\n        logger.critical('%s - @ %s.\\n%s', exc, request.first_line,\n                        dump_environ(environ), exc_info=exc_info)\n    else:\n        log_wsgi_info(logger.warning, environ, response.status, exc)\n    if has_empty_content(status, request.method) or status in REDIRECT_CODES:\n        response.content_type = None\n        response.content = None\n    else:\n        request.cache.pop('html_document', None)\n        renderer = environ.get('error.handler') or render_error\n        try:\n            content = renderer(request, exc)\n        except Exception:\n            logger.critical('Error while rendering error', exc_info=True)\n            response.content_type = 'text/plain'\n            content = 'Critical server error'\n        if content is not response:\n            response.content = content\n    return response", "response": "The default error handler while serving a WSGI request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_error(request, exc):\n    '''Default renderer for errors.'''\n    cfg = request.get('pulsar.cfg')\n    debug = cfg.debug if cfg else False\n    response = request.response\n    if not response.content_type:\n        content_type = request.get('default.content_type')\n        response.content_type = request.content_types.best_match(\n            as_tuple(content_type or DEFAULT_RESPONSE_CONTENT_TYPES)\n        )\n    content_type = None\n    if response.content_type:\n        content_type = response.content_type.split(';')[0]\n    is_html = content_type == 'text/html'\n\n    if debug:\n        msg = render_error_debug(request, exc, is_html)\n    else:\n        msg = escape(error_messages.get(response.status_code) or exc)\n        if is_html:\n            msg = textwrap.dedent(\"\"\"\n                <h1>{0[reason]}</h1>\n                {0[msg]}\n                <h3>{0[version]}</h3>\n            \"\"\").format({\"reason\": response.status, \"msg\": msg,\n                         \"version\": request.environ['SERVER_SOFTWARE']})\n    #\n    if content_type == 'text/html':\n        doc = HtmlDocument(title=response.status)\n        doc.head.embedded_css.append(error_css)\n        doc.body.append(Html('div', msg, cn='pulsar-error'))\n        return doc.to_bytes(request)\n    elif content_type in JSON_CONTENT_TYPES:\n        return json.dumps({'status': response.status_code,\n                           'message': msg})\n    else:\n        return '\\n'.join(msg) if isinstance(msg, (list, tuple)) else msg", "response": "Default renderer for errors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_error_debug(request, exception, is_html):\n    '''Render the ``exception`` traceback\n    '''\n    error = Html('div', cn='well well-lg') if is_html else []\n    for trace in format_traceback(exception):\n        counter = 0\n        for line in trace.split('\\n'):\n            if line.startswith('  '):\n                counter += 1\n                line = line[2:]\n            if line:\n                if is_html:\n                    line = Html('p', escape(line), cn='text-danger')\n                    if counter:\n                        line.css({'margin-left': '%spx' % (20*counter)})\n                error.append(line)\n    if is_html:\n        error = Html('div', Html('h1', request.response.status), error)\n    return error", "response": "Render the exception traceback as a well - lg error."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a chunk to a list of chunks.", "response": "def chunk_encoding(chunks, chunk):\n    '''Write a chunk::\n        chunk-size(hex) CRLF\n        chunk-data CRLF\n    If the size is 0, this is the last chunk, and an extra CRLF is appended.\n    '''\n    chunks.extend((\"%X\\r\\n\" % len(chunk)).encode('utf-8'))\n    chunks.extend(chunk)\n    chunks.extend(CRLF)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef arbiter(**params):\n    '''Obtain the ``arbiter``.\n\n    It returns the arbiter instance only if we are on the arbiter\n    context domain, otherwise it returns nothing.\n    '''\n    arbiter = get_actor()\n    if arbiter is None:\n        # Create the arbiter\n        return set_actor(_spawn_actor('arbiter', None, **params))\n    elif arbiter.is_arbiter():\n        return arbiter", "response": "Obtain the arbiter instance. It returns the arbiter instance only if we are on the arbiter context domain otherwise it returns nothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nspawns a new Actor and return its .", "response": "def spawn(self, monitor, kind=None, **params):\n        '''Spawn a new :class:`Actor` and return its\n        :class:`.ActorProxyMonitor`.\n        '''\n        proxy = _spawn_actor(kind, monitor, **params)\n        # Add to the list of managed actors if this is a remote actor\n        if isinstance(proxy, Actor):\n            self._register(proxy)\n            return proxy\n        else:\n            proxy.monitor = monitor\n            self.managed_actors[proxy.aid] = proxy\n            future = actor_proxy_future(proxy)\n            proxy.start()\n            return future"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef manage_actors(self, monitor, stop=False):\n        '''Remove :class:`Actor` which are not alive from the\n        :class:`PoolMixin.managed_actors` and return the number of actors\n        still alive.\n\n        :parameter stop: if ``True`` stops all alive actor.\n        '''\n        alive = 0\n        if self.managed_actors:\n            for aid, actor in list(self.managed_actors.items()):\n                alive += self.manage_actor(monitor, actor, stop)\n        return alive", "response": "Manage the actors in the pool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef manage_actor(self, monitor, actor, stop=False):\n        '''If an actor failed to notify itself to the arbiter for more than\n        the timeout, stop the actor.\n\n        :param actor: the :class:`Actor` to manage.\n        :param stop: if ``True``, stop the actor.\n        :return: if the actor is alive 0 if it is not.\n        '''\n        if not monitor.is_running():\n            stop = True\n        if not actor.is_alive():\n            if not actor.should_be_alive() and not stop:\n                return 1\n            actor.join()\n            self._remove_monitored_actor(monitor, actor)\n            return 0\n        timeout = None\n        started_stopping = bool(actor.stopping_start)\n        # if started_stopping is True, set stop to True\n        stop = stop or started_stopping\n        if not stop and actor.notified:\n            gap = time() - actor.notified\n            stop = timeout = gap > actor.cfg.timeout\n        if stop:   # we are stopping the actor\n            dt = actor.should_terminate()\n            if not actor.mailbox or dt:\n                if not actor.mailbox:\n                    monitor.logger.warning('kill %s - no mailbox.', actor)\n                else:\n                    monitor.logger.warning('kill %s - could not stop '\n                                           'after %.2f seconds.', actor, dt)\n                actor.kill()\n                self._remove_monitored_actor(monitor, actor)\n                return 0\n            elif not started_stopping:\n                if timeout:\n                    monitor.logger.warning('Stopping %s. Timeout %.2f',\n                                           actor, timeout)\n                else:\n                    monitor.logger.info('Stopping %s.', actor)\n                actor.stop()\n        return 1", "response": "This function is called by the actor manager to manage the actor s status."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spawn_actors(self, monitor):\n        '''Spawn new actors if needed.\n        '''\n        to_spawn = monitor.cfg.workers - len(self.managed_actors)\n        if monitor.cfg.workers and to_spawn > 0:\n            for _ in range(to_spawn):\n                monitor.spawn()", "response": "Spawn new actors if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop_actors(self, monitor):\n        if monitor.cfg.workers:\n            num_to_kill = len(self.managed_actors) - monitor.cfg.workers\n            for i in range(num_to_kill, 0, -1):\n                w, kage = 0, sys.maxsize\n                for worker in self.managed_actors.values():\n                    age = worker.impl.age\n                    if age < kage:\n                        w, kage = worker, age\n                self.manage_actor(monitor, w, True)", "response": "Stop the workers that are not in the pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new monitor.", "response": "def add_monitor(self, actor, monitor_name, **params):\n        '''Add a new ``monitor``.\n\n        :param monitor_class: a :class:`.Monitor` class.\n        :param monitor_name: a unique name for the monitor.\n        :param kwargs: dictionary of key-valued parameters for the monitor.\n        :return: the :class:`.Monitor` added.\n        '''\n        if monitor_name in self.registered:\n            raise KeyError('Monitor \"%s\" already available' % monitor_name)\n        params.update(actor.actorparams())\n        params['name'] = monitor_name\n        params['kind'] = 'monitor'\n        return actor.spawn(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def periodic_task(self, actor, **kw):\n        while True:\n            interval = 0\n            #\n            if actor.started():\n                # managed actors job\n                self.manage_actors(actor)\n                for m in list(self.monitors.values()):\n                    _remove_monitor(m)\n\n                interval = MONITOR_TASK_PERIOD\n                #\n                actor.event('periodic_task').fire()\n\n            if actor.cfg.reload and autoreload.check_changes():\n                # reload changes\n                actor.stop(exit_code=autoreload.EXIT_CODE)\n\n            if not actor.stopped():\n                try:\n                    await asyncio.sleep(interval)\n                except asyncio.CancelledError:\n                    break", "response": "Override the : meth :. Concurrency. periodic_task to implement the actor - periodic - task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new store for a valid url.", "response": "def create_store(url, **kw):\n    '''Create a new :class:`Store` for a valid ``url``.\n\n    :param url: a valid ``url`` takes the following forms:\n\n        :ref:`Pulsar datastore <store_pulsar>`::\n\n            pulsar://user:password@127.0.0.1:6410\n\n        :ref:`Redis <store_redis>`::\n\n            redis://user:password@127.0.0.1:6500/11?namespace=testdb\n\n    :param kw: additional key-valued parameters to pass to the :class:`.Store`\n        initialisation method. It can contains parameters such as\n        ``database``, ``user`` and ``password`` to override the\n        ``url`` values. Additional parameters are processed by the\n        :meth:`.Store._init` method.\n    :return: a :class:`Store`.\n    '''\n    if isinstance(url, Store):\n        return url\n    scheme, address, params = parse_store_url(url)\n    dotted_path = data_stores.get(scheme)\n    if not dotted_path:\n        raise NoSuchStore('%s store not available' % scheme)\n    store_class = module_attribute(dotted_path, safe=True)\n    if not store_class:\n        raise ImproperlyConfigured('\"%s\" store not available' % dotted_path)\n    if not store_class.registered:\n        store_class.registered = True\n        store_class.register()\n    params.update(kw)\n    return store_class(scheme, address, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish_event(self, channel, event, message):\n        '''Publish a new event ``message`` to a ``channel``.\n        '''\n        assert self.protocol is not None, \"Protocol required\"\n        msg = {'event': event, 'channel': channel}\n        if message:\n            msg['data'] = message\n        return self.publish(channel, msg)", "response": "Publish a new event to a channel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef broadcast(self, response):\n        '''Broadcast ``message`` to all :attr:`clients`.'''\n        remove = set()\n        channel = to_string(response[0])\n        message = response[1]\n        if self.protocol:\n            try:\n                message = self.protocol.decode(message)\n            except ProtocolError:\n                self.logger.exception('Could not decode message')\n                return\n        for client in self._clients:\n            try:\n                client(channel, message)\n            except IOError:\n                remove.add(client)\n            except Exception:\n                self._loop.logger.exception(\n                    'Exception while processing pub/sub client. Removing it.')\n                remove.add(client)\n        self._clients.difference_update(remove)", "response": "Broadcasts a message to all clients."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef response_error(response):\n    \"Parse an error response\"\n    response = response.split(' ')\n    error_code = response[0]\n    if error_code not in EXCEPTION_CLASSES:\n        error_code = 'ERR'\n    response = ' '.join(response[1:])\n    return EXCEPTION_CLASSES[error_code](response)", "response": "Parse an error response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spawn(self, actor, aid=None, **params):\n        '''Spawn a new actor from ``actor``.\n        '''\n        aid = aid or create_aid()\n        future = actor.send('arbiter', 'spawn', aid=aid, **params)\n        return actor_proxy_future(aid, future)", "response": "Spawn a new actor from actor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_actor(self, actor):\n        '''Start running the ``actor``.\n        '''\n        set_actor(actor)\n        if not actor.mailbox.address:\n            address = ('127.0.0.1', 0)\n            actor._loop.create_task(\n                actor.mailbox.start_serving(address=address)\n            )\n        actor._loop.run_forever()", "response": "Start running the actor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_event_loop(self, actor):\n        '''Set up the event loop for ``actor``.\n        '''\n        actor.logger = self.cfg.configured_logger('pulsar.%s' % actor.name)\n        try:\n            loop = asyncio.get_event_loop()\n        except RuntimeError:\n            if self.cfg and self.cfg.concurrency == 'thread':\n                loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(loop)\n            else:\n                raise\n        if not hasattr(loop, 'logger'):\n            loop.logger = actor.logger\n        actor.mailbox = self.create_mailbox(actor, loop)\n        return loop", "response": "Setup the event loop for actor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming the hand shake for actor.", "response": "def hand_shake(self, actor, run=True):\n        '''Perform the hand shake for ``actor``\n\n        The hand shake occurs when the ``actor`` is in starting state.\n        It performs the following actions:\n\n        * set the ``actor`` as the actor of the current thread\n        * bind two additional callbacks to the ``start`` event\n        * fire the ``start`` event\n\n        If the hand shake is successful, the actor will eventually\n        results in a running state.\n        '''\n        try:\n            assert actor.state == ACTOR_STATES.STARTING\n            if actor.cfg.debug:\n                actor.logger.debug('starting handshake')\n            actor.event('start').fire()\n            if run:\n                self._switch_to_run(actor)\n        except Exception as exc:\n            actor.stop(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the mailbox for actor.", "response": "def create_mailbox(self, actor, loop):\n        '''Create the mailbox for ``actor``.'''\n        client = MailboxClient(actor.monitor.address, actor, loop)\n        loop.call_soon_threadsafe(self.hand_shake, actor)\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving an actor unique id return the actor proxy.", "response": "def get_actor(self, actor, aid, check_monitor=True):\n        '''Given an actor unique id return the actor proxy.'''\n        a = super().get_actor(actor, aid)\n        if a is None:\n            if aid in self.monitors:  # Check in monitors aid\n                return self.monitors[aid]\n            elif aid in self.managed_actors:\n                return self.managed_actors[aid]\n            elif aid in self.registered:\n                return self.registered[aid]\n            else:  # Finally check in workers in monitors\n                for m in self.monitors.values():\n                    a = m.get_actor(aid, check_monitor=False)\n                    if a is not None:\n                        return a\n        else:\n            return a"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride : meth :. Concurrency. create_mailbox to create the mailbox server.", "response": "def create_mailbox(self, actor, loop):\n        '''Override :meth:`.Concurrency.create_mailbox` to create the\n        mailbox server.\n        '''\n        mailbox = TcpServer(mailbox_protocol, loop=loop, name='mailbox')\n        # when the mailbox stop, close the event loop too\n        mailbox.event('stop').bind(lambda _, **kw: loop.stop())\n        mailbox.event('start').bind(\n            lambda _, **kw: loop.call_soon(self.hand_shake, actor)\n        )\n        return mailbox"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an HTTP basic or digest authorisation header.", "response": "def parse_authorization_header(value, charset='utf-8'):\n    '''Parse an HTTP basic/digest authorisation header.\n\n    :param value: the authorisation header to parse.\n    :return: either `None` if the header was invalid or\n        not given, otherwise an :class:`Auth` object.\n    '''\n    if not value:\n        return\n    try:\n        auth_type, auth_info = value.split(None, 1)\n        auth_type = auth_type.lower()\n    except ValueError:\n        return\n    if auth_type == 'basic':\n        try:\n            up = b64decode(auth_info.encode(CHARSET)).decode(charset)\n            username, password = up.split(':', 1)\n        except Exception:\n            return\n        return BasicAuth(username, password)\n    elif auth_type == 'digest':\n        auth_map = parse_dict_header(auth_info)\n        if not digest_parameters.difference(auth_map):\n            return DigestAuth(auth_map.pop('username'), options=auth_map)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _auth_header(self, type, **options):\n        return '%s %s' % (type.title(), ', '.join((\n            '%s=%s' % (key, quote_header_value(\n                value, allow_token=key not in _require_quoting))\n            for key, value in options.items()\n        )))", "response": "Convert the stored values into a WWW - Authenticate header."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticated(self, environ, username=None, password=None, **params):\n        '''Called by the server to check if client is authenticated.'''\n        if username != self.username:\n            return False\n        o = self.options\n        qop = o.get('qop')\n        method = environ['REQUEST_METHOD']\n        uri = environ.get('PATH_INFO', '')\n        ha1 = self.ha1(o['realm'], password)\n        ha2 = self.ha2(qop, method, uri)\n        if qop is None:\n            response = hexmd5(\":\".join((ha1, self.nonce, ha2)))\n        elif qop == 'auth' or qop == 'auth-int':\n            response = hexmd5(\":\".join((ha1, o['nonce'], o['nc'],\n                                        o['cnonce'], qop, ha2)))\n        else:\n            raise ValueError(\"qop value are wrong\")\n        return o['response'] == response", "response": "Called by the server to check if client is authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def register(self, channel, event, callback):\n        channel = self.channel(channel)\n        event = channel.register(event, callback)\n        await channel.connect(event.name)\n        return channel", "response": "Register a callback to the channel_name and event."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def unregister(self, channel, event, callback):\n        channel = self.channel(channel, create=False)\n        if channel:\n            channel.unregister(event, callback)\n            if not channel:\n                await channel.disconnect()\n                self.channels.pop(channel.name)\n        return channel", "response": "Safely unregister a callback from the list of event callbacks for channel_name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting with store :return: a coroutine and therefore it must be awaited", "response": "async def connect(self, next_time=None):\n        \"\"\"Connect with store\n\n        :return: a coroutine and therefore it must be awaited\n        \"\"\"\n        if self.status in can_connect:\n            loop = self._loop\n            if loop.is_running():\n                self.status = StatusType.connecting\n                await self._connect(next_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a callback for an event.", "response": "def register(self, event, callback):\n        \"\"\"Register a ``callback`` for ``event``\n        \"\"\"\n        pattern = self.channels.event_pattern(event)\n        entry = self.callbacks.get(pattern)\n        if not entry:\n            entry = event_callbacks(event, pattern, re.compile(pattern), [])\n            self.callbacks[entry.pattern] = entry\n\n        if callback not in entry.callbacks:\n            entry.callbacks.append(callback)\n\n        return entry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chain_future(future, callback=None, errback=None, next=None):\n    '''Chain a :class:`~asyncio.Future` to an existing ``future``.\n\n    This function `chain` the ``next`` future to an existing ``future``.\n    When the input ``future`` receive a result the optional\n    ``callback`` is executed and its result set as the results of ``next``.\n    If an exception occurs the optional ``errback`` is executed.\n\n    :param future: the original :class:`~asyncio.Future` (can be a coroutine)\n    :param callback: optional callback to execute on the result of ``future``\n    :param errback: optional callback to execute on the exception of ``future``\n    :param next: optional :class:`~asyncio.Future` to chain.\n        If not provided a new future is created\n    :return: the future ``next``\n    '''\n    loop = next._loop if next else None\n    future = ensure_future(future, loop=loop)\n    if next is None:\n        next = create_future(future._loop)\n\n    def _callback(fut):\n        try:\n            try:\n                result = future.result()\n            except Exception as exc:\n                if errback:\n                    result = errback(exc)\n                    exc = None\n                else:\n                    raise\n            else:\n                if callback:\n                    result = callback(result)\n        except Exception as exc:\n            next.set_exception(exc)\n        else:\n            if isinstance(result, Future):\n                chain_future(result, next=next)\n            else:\n                next.set_result(result)\n\n    future.add_done_callback(_callback)\n    return next", "response": "Chain a future to an existing future."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_errback(future, callback, loop=None):\n    '''Add a ``callback`` to a ``future`` executed only if an exception\n    or cancellation has occurred.'''\n    def _error_back(fut):\n        if fut._exception:\n            callback(fut.exception())\n        elif fut.cancelled():\n            callback(CancelledError())\n\n    future = ensure_future(future, loop=None)\n    future.add_done_callback(_error_back)\n    return future", "response": "Add a callback to a future executed only if an exception\n    or cancellation has occurred."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads all content in the cache.", "response": "async def read(self, n=None):\n        \"\"\"Read all content\n        \"\"\"\n        if self._streamed:\n            return b''\n        buffer = []\n        async for body in self:\n            buffer.append(body)\n        return b''.join(buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(request, callable, *args, **kwargs):\n    '''Execute a python *callable*.'''\n    return callable(request.actor, *args, **kwargs)", "response": "Execute a python callable."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkills an actor with id aid.", "response": "async def kill_actor(request, aid, timeout=5):\n    '''Kill an actor with id ``aid``.\n    This command can only be executed by the arbiter,\n    therefore a valid sintax is only::\n\n        send('arbiter', 'kill_actor', 'abc')\n\n    Return 'killed abc` if successful, otherwise it returns ``None``.\n    '''\n    arb = request.actor\n    if arb.is_arbiter():\n        await arb.send(aid, 'stop')\n        proxy = await async_while(timeout, arb.get_actor, aid)\n        if proxy:\n            arb.logger.warning('Could not kill actor %s', aid)\n        else:\n            return 'killed %s' % aid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites data into the wire. Returns an empty tuple or a asyncio. Future that is cancelled if the connection has paused writing.", "response": "def write(self, data):\n        \"\"\"Write ``data`` into the wire.\n\n        Returns an empty tuple or a :class:`~asyncio.Future` if this\n        protocol has paused writing.\n        \"\"\"\n        if self.closed:\n            raise ConnectionResetError(\n                'Transport closed - cannot write on %s' % self\n            )\n        else:\n            t = self.transport\n            if self._paused or self._buffer:\n                self._buffer.appendleft(data)\n                self._buffer_size += len(data)\n                self._write_from_buffer()\n                if self._buffer_size > 2 * self._b_limit:\n                    if self._waiter and not self._waiter.cancelled():\n                        self.logger.warning(\n                            '%s buffer size is %d: limit is %d ',\n                            self._buffer_size, self._b_limit\n                        )\n                    else:\n                        t.pause_reading()\n                        self._waiter = self._loop.create_future()\n            else:\n                t.write(data)\n            self.changed()\n            return self._waiter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresume writing. Successive calls to this method will fails unless :meth:`pause_writing` is called first.", "response": "def resume_writing(self, exc=None):\n        '''Resume writing.\n\n        Successive calls to this method will fails unless\n        :meth:`pause_writing` is called first.\n        '''\n        assert self._paused\n        self._paused = False\n        waiter = self._waiter\n        if waiter is not None:\n            self._waiter = None\n            if not waiter.done():\n                if exc is None:\n                    waiter.set_result(None)\n                else:\n                    waiter.set_exception(exc)\n            self.transport.resume_reading()\n        self._write_from_buffer()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a new timeout for this protocol.", "response": "def timeout(self, timeout):\n        '''Set a new :attr:`timeout` for this protocol\n        '''\n        if self._timeout is None:\n            self.event('connection_made').bind(self._add_timeout)\n            self.event('connection_lost').bind(self._cancel_timeout)\n        self._timeout = timeout or 0\n        self._add_timeout(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pipeline(self, consumer):\n        if self._pipeline is None:\n            self._pipeline = ResponsePipeline(self)\n            self.event('connection_lost').bind(self._close_pipeline)\n        self._pipeline.put(consumer)", "response": "Add a consumer to the pipeline"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a close : class : Frame.", "response": "def close(self, code=None):\n        '''return a `close` :class:`Frame`.\n        '''\n        code = code or 1000\n        body = pack('!H', code)\n        body += self._close_codes.get(code, '').encode('utf-8')\n        return self.encode(body, opcode=0x8)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef continuation(self, body=None, final=True):\n        '''return a `continuation` :class:`Frame`.'''\n        return self.encode(body, opcode=0, final=final)", "response": "return a `continuation` :class:`Frame`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self, message, final=True, masking_key=None,\n               opcode=None, rsv1=0, rsv2=0, rsv3=0):\n        '''Encode a ``message`` for writing into the wire.\n\n        To produce several frames for a given large message use\n        :meth:`multi_encode` method.\n        '''\n        fin = 1 if final else 0\n        opcode, masking_key, data = self._info(message, opcode, masking_key)\n        return self._encode(data, opcode, masking_key, fin,\n                            rsv1, rsv2, rsv3)", "response": "Encode a large message into a new wire format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a message into several frames depending on size.", "response": "def multi_encode(self, message, masking_key=None, opcode=None,\n                     rsv1=0, rsv2=0, rsv3=0, max_payload=0):\n        '''Encode a ``message`` into several frames depending on size.\n\n        Returns a generator of bytes to be sent over the wire.\n        '''\n        max_payload = max(2, max_payload or self._max_payload)\n        opcode, masking_key, data = self._info(message, opcode, masking_key)\n        #\n        while data:\n            if len(data) >= max_payload:\n                chunk, data, fin = (data[:max_payload],\n                                    data[max_payload:], 0)\n            else:\n                chunk, data, fin = data, b'', 1\n            yield self._encode(chunk, opcode, masking_key, fin,\n                               rsv1, rsv2, rsv3)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_return_tuples(response, groups=None, **options):\n    if not response or not groups:\n        return response\n    return list(zip(*[response[i::groups] for i in range(groups)]))", "response": "Sort the response list by the number of groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value at key name to value.", "response": "def set(self, name, value, ex=None, px=None, nx=False, xx=False):\n        \"\"\"Set the value at key ``name`` to ``value``\n\n        :param ex: sets an expire flag on key ``name`` for ``ex`` seconds.\n        :param px: sets an expire flag on key ``name`` for ``px`` milliseconds.\n        :param nx: if set to True, set the value at key ``name`` to ``value``\n            if it does not already exist.\n        :param xx: if set to True, set the value at key ``name`` to ``value``\n            if it already exists.\n        \"\"\"\n        pieces = [name, value]\n        if ex:\n            pieces.append('EX')\n            if isinstance(ex, datetime.timedelta):\n                ex = ex.seconds + ex.days * 24 * 3600\n            pieces.append(ex)\n        if px:\n            pieces.append('PX')\n            if isinstance(px, datetime.timedelta):\n                ms = int(px.microseconds / 1000)\n                px = (px.seconds + px.days * 24 * 3600) * 1000 + ms\n            pieces.append(px)\n\n        if nx:\n            pieces.append('NX')\n        if xx:\n            pieces.append('XX')\n        return self.execute('set', *pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zadd(self, name, *args, **kwargs):\n        pieces = []\n        if args:\n            if len(args) % 2 != 0:\n                raise ValueError(\"ZADD requires an equal number of \"\n                                 \"values and scores\")\n            pieces.extend(args)\n        for pair in kwargs.items():\n            pieces.append(pair[1])\n            pieces.append(pair[0])\n        return self.execute_command('ZADD', name, *pieces)", "response": "Add any number of element - name pairs to the key name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sort(self, key, start=None, num=None, by=None, get=None,\n             desc=False, alpha=False, store=None, groups=False):\n        '''Sort and return the list, set or sorted set at ``key``.\n\n        ``start`` and ``num`` allow for paging through the sorted data\n\n        ``by`` allows using an external key to weight and sort the items.\n            Use an \"*\" to indicate where in the key the item value is located\n\n        ``get`` allows for returning items from external keys rather than the\n            sorted data itself.  Use an \"*\" to indicate where int he key\n            the item value is located\n\n        ``desc`` allows for reversing the sort\n\n        ``alpha`` allows for sorting lexicographically rather than numerically\n\n        ``store`` allows for storing the result of the sort into\n            the key ``store``\n\n        ``groups`` if set to True and if ``get`` contains at least two\n            elements, sort will return a list of tuples, each containing the\n            values fetched from the arguments to ``get``.\n\n        '''\n        if ((start is not None and num is None) or\n                (num is not None and start is None)):\n            raise CommandError(\"``start`` and ``num`` must both be specified\")\n\n        pieces = [key]\n        if by is not None:\n            pieces.append('BY')\n            pieces.append(by)\n        if start is not None and num is not None:\n            pieces.append('LIMIT')\n            pieces.append(start)\n            pieces.append(num)\n        if get is not None:\n            # If get is a string assume we want to get a single value.\n            # Otherwise assume it's an interable and we want to get multiple\n            # values. We can't just iterate blindly because strings are\n            # iterable.\n            if isinstance(get, str):\n                pieces.append('GET')\n                pieces.append(get)\n            else:\n                for g in get:\n                    pieces.append('GET')\n                    pieces.append(g)\n        if desc:\n            pieces.append('DESC')\n        if alpha:\n            pieces.append('ALPHA')\n        if store is not None:\n            pieces.append('STORE')\n            pieces.append(store)\n\n        if groups:\n            if not get or isinstance(get, str) or len(get) < 2:\n                raise CommandError('when using \"groups\" the \"get\" argument '\n                                   'must be specified and contain at least '\n                                   'two keys')\n\n        options = {'groups': len(get) if groups else None}\n        return self.execute_command('SORT', *pieces, **options)", "response": "Sort and return the list set or sorted set at key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commit(self, raise_on_error=True):\n        '''Send commands to redis.\n        '''\n        cmds = list(chain([(('multi',), {})],\n                          self.command_stack, [(('exec',), {})]))\n        self.reset()\n        return self.store.execute_pipeline(cmds, raise_on_error)", "response": "Send commands to redis.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef server(name=None, description=None, **kwargs):\n    '''Create the :class:`.SocketServer` with :class:`EchoServerProtocol`\n    as protocol factory.\n    '''\n    name = name or 'echoserver'\n    description = description or 'Echo Server'\n    return SocketServer(EchoServerProtocol, name=name,\n                        description=description, **kwargs)", "response": "Create the : class :. SocketServer with protocol factory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef feed_data(self, data):\n        '''Implements the :meth:`~.ProtocolConsumer.data_received` method.\n\n        It simply search for the :attr:`separator` and, if found, it invokes\n        the :meth:`response` method with the value of the message.\n        '''\n        if self.buffer is None:\n            self.buffer = bytearray(data)\n        else:\n            self.buffer.extend(data)\n        data = self.buffer\n\n        idx = data.find(self.separator)\n        if idx >= 0:    # we have a full message\n            idx += len(self.separator)\n            data, rest = data[:idx], data[idx:]\n            self.buffer = self.response(data, rest)\n            self.event('post_request').fire()\n            return rest", "response": "Implements the ~. ProtocolConsumer. data_received method. It looks for the separator and invokes the response method with the value of the message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef response(self, data, rest):\n        '''Override :meth:`~EchoProtocol.response` method by writing the\n        ``data`` received back to the client.\n        '''\n        self.connection.write(data)\n        data = data[:-len(self.separator)]\n        # If we get a QUIT message, close the connection\n        # Used by the test suite.\n        if data == b'QUIT':\n            self.connection.close()\n        return data", "response": "Override this method by writing the data received back to the client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating this. attr:`Config with data.", "response": "def update(self, data, default=False):\n        \"\"\"Update this :attr:`Config` with ``data``.\n\n        :param data: must be a ``Mapping`` like object exposing the ``item``\n            method for iterating through key-value pairs.\n        :param default: if ``True`` the updated :attr:`settings` will also\n            set their :attr:`~Setting.default` attribute with the\n            updating value (provided it is a valid one).\n        \"\"\"\n        for name, value in data.items():\n            if value is not None:\n                self.set(name, value, default)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_globals(self, cfg):\n        for name, setting in cfg.settings.items():\n            csetting = self.settings.get(name)\n            if (setting.is_global and csetting is not None and\n                    not csetting.modified):\n                csetting.set(setting.get())", "response": "Copy global settings from cfg to this config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, name, default=None):\n        try:\n            return self._get(name, default)\n        except KeyError:\n            return default", "response": "Get the value at name for this container\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, name, value, default=False, imported=False):\n        if name in self.__dict__:\n            self.__dict__[name] = value\n            return\n\n        if name not in self.settings and self.prefix:\n            prefix_name = '%s_%s' % (self.prefix, name)\n            if prefix_name in self.settings:\n                return  # don't do anything\n\n        if name in self.settings:\n            self.settings[name].set(value, default=default, imported=imported)\n        elif not imported:\n            self.params[name] = value", "response": "Set the value of the named setting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the argparser_ for this configuration by adding all settings via the Setting. add_argument method.", "response": "def parser(self):\n        \"\"\"Create the argparser_ for this configuration by adding all\n        settings via the :meth:`Setting.add_argument` method.\n\n        :rtype: an instance of :class:`ArgumentParser`.\n        \"\"\"\n        parser = argparse.ArgumentParser(description=self.description,\n                                         epilog=self.epilog)\n        parser.add_argument('--version',\n                            action='version',\n                            version=self.version)\n        return self.add_to_parser(parser)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd this container s settings to an existing parser.", "response": "def add_to_parser(self, parser):\n        \"\"\"Add this container :attr:`settings` to an existing ``parser``.\n        \"\"\"\n        setts = self.settings\n\n        def sorter(x):\n            return (setts[x].section, setts[x].order)\n\n        for k in sorted(setts, key=sorter):\n            setts[k].add_argument(parser)\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_command_line(self, argv=None):\n        if self.config:\n            parser = argparse.ArgumentParser(add_help=False)\n            self.settings['config'].add_argument(parser)\n            opts, _ = parser.parse_known_args(argv)\n            if opts.config is not None:\n                self.set('config', opts.config)\n\n            self.params.update(self.import_from_module())\n\n        parser = self.parser()\n        opts = parser.parse_args(argv)\n        for k, v in opts.__dict__.items():\n            if v is None:\n                continue\n            self.set(k.lower(), v)", "response": "Parse the command line"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef address(self):\n        bind = self.settings.get('bind')\n        if bind:\n            return parse_address(to_bytes(bind.get()))", "response": "An address to bind to"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self, name=None, prefix=None):\n        cls = self.__class__\n        me = cls.__new__(cls)\n        me.__dict__.update(self.__dict__)\n        if prefix:\n            me.prefix = prefix\n        settings = me.settings\n        me.settings = {}\n        for setting in settings.values():\n            setting = setting.copy(name, prefix)\n            me.settings[setting.name] = setting\n        me.params = me.params.copy()\n        return me", "response": "A copy of this : class : Config container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a logger object with the specified name.", "response": "def configured_logger(self, name=None):\n        \"\"\"Configured logger.\n        \"\"\"\n        log_handlers = self.log_handlers\n        # logname\n        if not name:\n            # base name is always pulsar\n            basename = 'pulsar'\n            # the namespace name for this config\n            name = self.name\n            if name and name != basename:\n                name = '%s.%s' % (basename, name)\n            else:\n                name = basename\n        #\n        namespaces = {}\n\n        for log_level in self.log_level or ():\n            bits = log_level.split('.')\n            namespaces['.'.join(bits[:-1]) or ''] = bits[-1]\n\n        for namespace in sorted(namespaces):\n            if self.daemon:     # pragma    nocover\n                handlers = []\n                for hnd in log_handlers:\n                    if hnd != 'console':\n                        handlers.append(hnd)\n                if not handlers:\n                    handlers.append('file')\n                log_handlers = handlers\n            configured_logger(namespace,\n                              config=self.log_config,\n                              level=namespaces[namespace],\n                              handlers=log_handlers)\n        return logging.getLogger(name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, val, default=False, imported=False):\n        if hasattr(self.validator, '__call__'):\n            try:\n                val = self.validator(val)\n            except Exception as exc:\n                raise type(exc)(\n                    'Could not validate value for \"%s\" setting: %s' %\n                    (self.name, exc)\n                ) from None\n        self.value = val\n        self.imported = imported\n        if default:\n            self.default = val\n        self.modified = True", "response": "Set the value of this setting."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_argument(self, parser, set_default=False):\n        default = self.default if set_default else None\n        kwargs = dict(\n            nargs=self.nargs,\n            default=default,\n            help=\"%s [%s]\" % (self.short, default)\n        )\n        kwargs.update(self.extra)\n        if self.flags:\n            args = tuple(self.flags)\n            kwargs.update({'dest': self.name,\n                           'action': self.action or \"store\"})\n            if kwargs[\"action\"] != \"store\":\n                kwargs.pop(\"type\", None)\n                kwargs.pop(\"nargs\", None)\n        elif self.nargs and self.name:\n            args = (self.name,)\n            kwargs.update({'metavar': self.meta or None})\n        else:\n            # Not added to argparser\n            return\n        if self.meta:\n            kwargs['metavar'] = self.meta\n        parser.add_argument(*args, **kwargs)", "response": "Add this : class:`Setting to the parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self, name=None, prefix=None):\n        setting = self.__class__.__new__(self.__class__)\n        setting.__dict__.update(self.__dict__)\n        # Keep the modified flag?\n        # setting.modified = False\n        if prefix and not setting.is_global:\n            flags = setting.flags\n            # Prefix a setting\n            setting.orig_name = setting.name\n            setting.name = '%s_%s' % (prefix, setting.name)\n            if flags and flags[-1].startswith('--'):\n                setting.flags = ['--%s-%s' % (prefix, flags[-1][2:])]\n        if name and not setting.is_global:\n            setting.short = '%s application. %s' % (name, setting.short)\n        return setting", "response": "Copy this : class : SettingBase"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_params(self, *args, **kwargs):\n        '''\n        Create an array or positional or named parameters\n        Mixing positional and named parameters in one\n        call is not possible.\n        '''\n        kwargs.update(self._data)\n        if args and kwargs:\n            raise ValueError('Cannot mix positional and named parameters')\n        if args:\n            return list(args)\n        else:\n            return kwargs", "response": "Create an array or positional or named parameters in one\n        call is not possible."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the server.", "response": "def send(self, command, sender, target, args, kwargs):\n        \"\"\"Used by the server to send messages to the client.\n        Returns a future.\n        \"\"\"\n        command = get_command(command)\n        data = {'command': command.__name__,\n                'id': create_aid(),\n                'sender': actor_identity(sender),\n                'target': actor_identity(target),\n                'args': args if args is not None else (),\n                'kwargs': kwargs if kwargs is not None else {}}\n\n        waiter = self._loop.create_future()\n        ack = None\n        if command.ack:\n            ack = create_aid()\n            data['ack'] = ack\n            self.pending_responses[ack] = waiter\n\n        try:\n            self.write(data)\n        except Exception as exc:\n            waiter.set_exception(exc)\n            if ack:\n                self.pending_responses.pop(ack, None)\n        else:\n            if not ack:\n                waiter.set_result(None)\n        return waiter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef server(name=None, description=None, **kwargs):\n    '''Create the :class:`.UdpSocketServer`.\n    '''\n    return UdpSocketServer(\n        EchoServerProtocol,\n        name=name or 'echoudpserver',\n        description=description or 'Echo Udp Server',\n        **kwargs\n    )", "response": "Create the UdpSocketServer object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the pidfile and return the ID of the old one if needed", "response": "def read(self):\n        \"\"\" Validate pidfile and make it stale if needed\"\"\"\n        if not self.fname:\n            return\n        try:\n            with open(self.fname, \"r\") as f:\n                wpid = int(f.read() or 0)\n                if wpid <= 0:\n                    return\n                return wpid\n        except IOError:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nacquiring the lock if in the unlocked state otherwise switch back to the parent coroutine.", "response": "def acquire(self, timeout=None):\n        \"\"\"Acquires the lock if in the unlocked state otherwise switch\n        back to the parent coroutine.\n        \"\"\"\n        green = getcurrent()\n        parent = green.parent\n        if parent is None:\n            raise MustBeInChildGreenlet('GreenLock.acquire in main greenlet')\n\n        if self._local.locked:\n            future = create_future(self._loop)\n            self._queue.append(future)\n            parent.switch(future)\n\n        self._local.locked = green\n        return self.locked()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef release(self):\n        if self._local.locked:\n            while self._queue:\n                future = self._queue.popleft()\n                if not future.done():\n                    return future.set_result(None)\n            self._local.locked = None\n        else:\n            raise RuntimeError('release unlocked lock')", "response": "Release the lock.\n\n        This method should only be called in the locked state;\n        it changes the state to unlocked and returns immediately.\n        If an attempt is made to release an unlocked lock,\n        a RuntimeError will be raised."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_and_files(self, data=True, files=True, stream=None):\n        if self.method in ENCODE_URL_METHODS:\n            value = {}, None\n        else:\n            value = self.cache.get('data_and_files')\n\n        if not value:\n            return self._data_and_files(data, files, stream)\n        elif data and files:\n            return value\n        elif data:\n            return value[0]\n        elif files:\n            return value[1]\n        else:\n            return None", "response": "Retrieve body data.\n\n        Returns a two-elements tuple of a\n        :class:`~.MultiValueDict` containing data from\n        the request body, and data from uploaded files.\n\n        If the body data is not ready, return a :class:`~asyncio.Future`\n        which results in the tuple.\n\n        The result is cached."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the HTTP host using the environment or request headers.", "response": "def get_host(self, use_x_forwarded=True):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if use_x_forwarded and ('HTTP_X_FORWARDED_HOST' in self.environ):\n            host = self.environ['HTTP_X_FORWARDED_HOST']\n            port = self.environ.get('HTTP_X_FORWARDED_PORT')\n            if port and port != ('443' if self.is_secure else '80'):\n                host = '%s:%s' % (host, port)\n            return host\n        elif 'HTTP_HOST' in self.environ:\n            host = self.environ['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.environ['SERVER_NAME']\n            server_port = str(self.environ['SERVER_PORT'])\n            if server_port != ('443' if self.is_secure else '80'):\n                host = '%s:%s' % (host, server_port)\n        return host"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_client_address(self, use_x_forwarded=True):\n        xfor = self.environ.get('HTTP_X_FORWARDED_FOR')\n        if use_x_forwarded and xfor:\n            return xfor.split(',')[-1].strip()\n        else:\n            return self.environ['REMOTE_ADDR']", "response": "Obtain the client IP address from the environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a full path to the resource with the given query", "response": "def full_path(self, *args, **query):\n        \"\"\"Return a full path\"\"\"\n        path = None\n        if args:\n            if len(args) > 1:\n                raise TypeError(\"full_url() takes exactly 1 argument \"\n                                \"(%s given)\" % len(args))\n            path = args[0]\n        if not path:\n            path = self.path\n        elif not path.startswith('/'):\n            path = remove_double_slash('%s/%s' % (self.path, path))\n        return iri_to_uri(path, query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds an absolute URI from location and scheme.", "response": "def absolute_uri(self, location=None, scheme=None, **query):\n        \"\"\"Builds an absolute URI from ``location`` and variables\n        available in this request.\n\n        If no ``location`` is specified, the relative URI is built from\n        :meth:`full_path`.\n        \"\"\"\n        if not is_absolute_uri(location):\n            if location or location is None:\n                location = self.full_path(location, **query)\n            if not scheme:\n                scheme = self.is_secure and 'https' or 'http'\n            base = '%s://%s' % (scheme, self.get_host())\n            return '%s%s' % (base, location)\n        elif not scheme:\n            return iri_to_uri(location)\n        else:\n            raise ValueError('Absolute location with scheme not valid')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_response_content_type(self, response_content_types=None):\n        '''Evaluate the content type for the response to a client ``request``.\n\n        The method uses the :attr:`response_content_types` parameter of\n        accepted content types and the content types accepted by the client\n        ``request`` and figures out the best match.\n        '''\n        request_content_types = self.content_types\n        if request_content_types:\n            ct = request_content_types.best_match(response_content_types)\n            if ct and '*' in ct:\n                ct = None\n            if not ct and response_content_types:\n                raise HttpException(status=415, msg=request_content_types)\n            self.response.content_type = ct", "response": "Evaluate the content type for the response to a client request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if arguments respect a given function arity and return an error message if the check did not pass None otherwise it returns None.", "response": "def checkarity(func, args, kwargs, discount=0):\n    '''Check if arguments respect a given function arity and return\n    an error message if the check did not pass,\n    otherwise it returns ``None``.\n\n    :parameter func: the function.\n    :parameter args: function arguments.\n    :parameter kwargs: function key-valued parameters.\n    :parameter discount: optional integer which discount the number of\n                         positional argument to check. Default ``0``.\n    '''\n    spec = inspect.getargspec(func)\n    self = getattr(func, '__self__', None)\n    if self and spec.args:\n        discount += 1\n    args = list(args)\n    defaults = list(spec.defaults or ())\n    len_defaults = len(defaults)\n    len_args = len(spec.args) - discount\n    len_args_input = len(args)\n    minlen = len_args - len_defaults\n    totlen = len_args_input + len(kwargs)\n    maxlen = len_args\n    if spec.varargs or spec.keywords:\n        maxlen = None\n        if not minlen:\n            return\n\n    if not spec.defaults and maxlen:\n        start = '\"{0}\" takes'.format(func.__name__)\n    else:\n        if maxlen and totlen > maxlen:\n            start = '\"{0}\" takes at most'.format(func.__name__)\n        else:\n            start = '\"{0}\" takes at least'.format(func.__name__)\n\n    if totlen < minlen:\n        return '{0} {1} parameters. {2} given.'.format(start, minlen, totlen)\n    elif maxlen and totlen > maxlen:\n        return '{0} {1} parameters. {2} given.'.format(start, maxlen, totlen)\n\n    # Length of parameter OK, check names\n    if len_args_input < len_args:\n        le = minlen - len_args_input\n        for arg in spec.args[discount:]:\n            if args:\n                args.pop(0)\n            else:\n                if le > 0:\n                    if defaults:\n                        defaults.pop(0)\n                    elif arg not in kwargs:\n                        return ('\"{0}\" has missing \"{1}\" parameter.'\n                                .format(func.__name__, arg))\n                kwargs.pop(arg, None)\n            le -= 1\n        if kwargs and maxlen:\n            s = ''\n            if len(kwargs) > 1:\n                s = 's'\n            p = ', '.join('\"{0}\"'.format(p) for p in kwargs)\n            return ('\"{0}\" does not accept {1} parameter{2}.'\n                    .format(func.__name__, p, s))\n    elif len_args_input > len_args + len_defaults:\n        n = len_args + len_defaults\n        start = '\"{0}\" takes'.format(func.__name__)\n        return ('{0} {1} positional parameters. {2} given.'\n                .format(start, n, len_args_input))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sphinx_extension(app, exception):\n    \"Wrapped up as a Sphinx Extension\"\n    if not app.builder.name in (\"html\", \"dirhtml\"):\n        return\n\n    if not app.config.sphinx_to_github:\n        if app.config.sphinx_to_github_verbose:\n            print(\"Sphinx-to-github: Disabled, doing nothing.\")\n        return\n\n    if exception:\n        if app.config.sphinx_to_github_verbose:\n            print(\"Sphinx-to-github: Exception raised in main build, doing nothing.\")\n        return\n\n    dir_helper = DirHelper(\n            os.path.isdir,\n            os.listdir,\n            os.walk,\n            shutil.rmtree\n            )\n\n    file_helper = FileSystemHelper(\n            open,\n            os.path.join,\n            shutil.move,\n            os.path.exists\n            )\n\n    operations_factory = OperationsFactory()\n    handler_factory = HandlerFactory()\n\n    layout_factory = LayoutFactory(\n            operations_factory,\n            handler_factory,\n            file_helper,\n            dir_helper,\n            app.config.sphinx_to_github_verbose,\n            sys.stdout,\n            force=True\n            )\n\n    layout = layout_factory.create_layout(app.outdir)\n    layout.process()", "response": "Wrapped up as a Sphinx Extension"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a rule and return it as generator. Each iteration yields tuples in the form converter parameters variable.", "response": "def parse_rule(rule):\n    \"\"\"Parse a rule and return it as generator. Each iteration yields tuples\n    in the form ``(converter, parameters, variable)``. If the converter is\n    `None` it's a static url part, otherwise it's a dynamic one.\n\n    :internal:\n    \"\"\"\n    m = _rule_re.match(rule)\n    if m is None or m.end() < len(rule):\n        raise ValueError('Error while parsing rule {0}'.format(rule))\n    data = m.groupdict()\n    converter = data['converter'] or 'default'\n    return converter, data['args'] or None, data['variable']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a url from urlargs key - value parameters", "response": "def url(self, **urlargs):\n        '''Build a ``url`` from ``urlargs`` key-value parameters\n        '''\n        if self.defaults:\n            d = self.defaults.copy()\n            d.update(urlargs)\n            urlargs = d\n        url = '/'.join(self._url_generator(urlargs))\n        if not url:\n            return '/'\n        else:\n            url = '/' + url\n            return url if self.is_leaf else url + '/'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match(self, path):\n        '''Match a path and return ``None`` if no matching, otherwise\n        a dictionary of matched variables with values. If there is more\n        to be match in the path, the remaining string is placed in the\n        ``__remaining__`` key of the dictionary.'''\n        match = self._regex.search(path)\n        if match is not None:\n            remaining = path[match.end():]\n            groups = match.groupdict()\n            result = {}\n            for name, value in groups.items():\n                try:\n                    value = self._converters[name].to_python(value)\n                except Http404:\n                    return\n                result[str(name)] = value\n            if remaining:\n                result['__remaining__'] = remaining\n            return result", "response": "Match a path and return a dictionary of matched variables with values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a two element tuple containing the parent route and the last url bit as route.", "response": "def split(self):\n        '''Return a two element tuple containing the parent route and\n        the last url bit as route. If this route is the root route, it returns\n        the root route and ``None``. '''\n        rule = self.rule\n        if not self.is_leaf:\n            rule = rule[:-1]\n        if not rule:\n            return Route('/'), None\n        bits = ('/' + rule).split('/')\n        last = Route(bits[-1] if self.is_leaf else bits[-1] + '/')\n        if len(bits) > 1:\n            return Route('/'.join(bits[:-1]) + '/'), last\n        else:\n            return last, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef was_modified_since(header=None, mtime=0, size=0):\n    '''Check if an item was modified since the user last downloaded it\n\n    :param header: the value of the ``If-Modified-Since`` header.\n        If this is ``None``, simply return ``True``\n    :param mtime: the modification time of the item in question.\n    :param size: the size of the item.\n    '''\n    header_mtime = modified_since(header, size)\n    if header_mtime and header_mtime <= mtime:\n        return False\n    return True", "response": "Check if an item was modified since the user last downloaded it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef router(self, rule, methods=['get']):\n        '''Map a function to :class:`Router` and add to the :attr:`routes` list.\n\n        Typical usage::\n\n            app = Router('/')\n\n            @app.router('/hello', methods=['post'])\n            def world(request):\n                return wsgi.WsgiResponse(200, 'world')\n        '''\n        def handler(fn):\n            for method in methods:\n                self.add_child(\n                    self.make_router(rule, method.lower(), fn,\n                                     name=fn.__name__))\n            return fn\n        return handler", "response": "Map a function to Router and add it to the routes list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef full_route(self):\n        '''The full :attr:`route` for this :class:`.Router`.\n\n        It includes the :attr:`parent` portion of the route if a parent\n        router is available.\n        '''\n        if self._parent:\n            return self._parent.full_route + self._route\n        else:\n            return self._route", "response": "The full route for this : class :. Router."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _resolve(self, path, method, urlargs=None):\n        '''Resolve a path and return a ``(handler, urlargs)`` tuple or\n        ``None`` if the path could not be resolved.\n        '''\n        match = self.route.match(path)\n        if match is None:\n            if not self.route.is_leaf:  # no match\n                return\n        elif '__remaining__' in match:\n            path = match.pop('__remaining__')\n            urlargs = update_args(urlargs, match)\n        else:\n            handler = getattr(self, method, None)\n            if handler is None:\n                raise MethodNotAllowed\n            response_wrapper = self.response_wrapper\n            if response_wrapper:\n                handler = partial(response_wrapper, handler)\n            return Handler(self, handler, update_args(urlargs, match))\n        #\n        for handler in self.routes:\n            view_args = handler._resolve(path, method, urlargs)\n            if view_args is None:\n                continue\n            return view_args", "response": "Resolve a path and return a tuple or\n            None if the path could not be resolved."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new router to the list of routes.", "response": "def add_route(self, router, index=None):\n        '''Add a new :class:`Router` to the :attr:`routes` list.\n        '''\n        assert isinstance(router, Router), 'Not a valid Router'\n        assert router is not self, 'cannot add self to children'\n\n        for r in self.routes:\n            if r == router:\n                return r\n            elif r._route == router._route:\n                raise ValueError('Cannot add route %s. Already avalable' %\n                                 r._route)\n        #\n        # Remove from previous parent\n        if router.parent:\n            router.parent.remove_child(router)\n        router._parent = self\n        if index is None:\n            self.routes.append(router)\n        else:\n            self.routes.insert(index, router)\n        return router"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a router from the routes list.", "response": "def remove_child(self, router):\n        '''remove a :class:`Router` from the :attr:`routes` list.'''\n        if router in self.routes:\n            self.routes.remove(router)\n            router._parent = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_route(self, name):\n        '''Get a child :class:`Router` by its :attr:`name`.\n\n        This method search child routes recursively.\n        '''\n        for route in self.routes:\n            if route.name == name:\n                return route\n        for child in self.routes:\n            route = child.get_route(name)\n            if route:\n                return route", "response": "Get a child route by its name. This method search child routes recursively."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef link(self, *args, **urlargs):\n        '''Return an anchor :class:`Html` element with the `href` attribute\n        set to the url of this :class:`Router`.'''\n        if len(args) > 1:\n            raise ValueError\n        url = self.route.url(**urlargs)\n        if len(args) == 1:\n            text = args[0]\n        else:\n            text = url\n        return Html('a', text, href=url)", "response": "Return an anchor : class : Html element with the href attribute set to the url of this Router."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if router is self or a parent of self.", "response": "def has_parent(self, router):\n        '''Check if ``router`` is ``self`` or a parent or ``self``\n        '''\n        parent = self\n        while parent and parent is not router:\n            parent = parent._parent\n        return parent is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Router object from a rule and parameters.", "response": "def make_router(self, rule, method=None, handler=None, cls=None,\n                    name=None, **params):\n        '''Create a new :class:`.Router` from a ``rule`` and parameters.\n\n        This method is used during initialisation when building child\n        Routers from the :attr:`rule_methods`.\n        '''\n        cls = cls or Router\n        router = cls(rule, name=name, **params)\n        for r in self.routes:\n            if r._route == router._route:\n                if isinstance(r, cls):\n                    router = r\n                    router._set_params(params)\n                    break\n        if method and handler:\n            if isinstance(method, tuple):\n                for m in method:\n                    setattr(router, m, handler)\n            else:\n                setattr(router, method, handler)\n        return router"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_bytes(array):\n    '''Count the number of bits in a byte ``array``.\n\n    It uses the Hamming weight popcount algorithm\n    '''\n    # this algorithm can be rewritten as\n    # for i in array:\n    #     count += sum(b=='1' for b in bin(i)[2:])\n    # but this version is almost 2 times faster\n    count = 0\n    for i in array:\n        i = i - ((i >> 1) & 0x55555555)\n        i = (i & 0x33333333) + ((i >> 2) & 0x33333333)\n        count += (((i + (i >> 4)) & 0x0F0F0F0F) * 0x01010101) >> 24\n    return count", "response": "Count the number of bits in a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a new message into the wire.", "response": "def write(self, message, opcode=None, encode=True, **kw):\n        '''Write a new ``message`` into the wire.\n\n        It uses the :meth:`~.FrameParser.encode` method of the\n        websocket :attr:`parser`.\n\n        :param message: message to send, must be a string or bytes\n        :param opcode: optional ``opcode``, if not supplied it is set to 1\n            if ``message`` is a string, otherwise ``2`` when the message\n            are bytes.\n         '''\n        if encode:\n            message = self.parser.encode(message, opcode=opcode, **kw)\n        result = self.connection.write(message)\n        if opcode == 0x8:\n            self.connection.close()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a ping frame.", "response": "def ping(self, message=None):\n        '''Write a ping ``frame``.\n        '''\n        return self.write(self.parser.ping(message), encode=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a pong frame.", "response": "def pong(self, message=None):\n        '''Write a pong ``frame``.\n        '''\n        return self.write(self.parser.pong(message), encode=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a close frame with code.", "response": "def write_close(self, code=None):\n        '''Write a close ``frame`` with ``code``.\n        '''\n        return self.write(self.parser.close(code), opcode=0x8, encode=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the given HTML with ampersands quotes and angle brackets encoded.", "response": "def escape(html, force=False):\n    \"\"\"Returns the given HTML with ampersands,\n    quotes and angle brackets encoded.\"\"\"\n    if hasattr(html, '__html__') and not force:\n        return html\n    if html in NOTHING:\n        return ''\n    else:\n        return to_string(html).replace('&', '&amp;').replace(\n            '<', '&lt;').replace('>', '&gt;').replace(\"'\", '&#39;').replace(\n            '\"', '&quot;')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncapitalising the first letter of x.", "response": "def capfirst(x):\n    '''Capitalise the first letter of ``x``.\n    '''\n    x = to_string(x).strip()\n    if x:\n        return x[0].upper() + x[1:].lower()\n    else:\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nicename(name):\n    '''Make ``name`` a more user friendly string.\n\n    Capitalise the first letter and replace dash and underscores with a space\n    '''\n    name = to_string(name)\n    return capfirst(' '.join(name.replace('-', ' ').replace('_', ' ').split()))", "response": "Make name a more user friendly string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, key, value):\n        task = Task.current_task()\n        try:\n            context = task._context\n        except AttributeError:\n            task._context = context = {}\n        context[key] = value", "response": "Set a value in the task context\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npush a value onto the task context stack.", "response": "def stack_push(self, key, value):\n        \"\"\"Set a value in a task context stack\n        \"\"\"\n        task = Task.current_task()\n        try:\n            context = task._context_stack\n        except AttributeError:\n            task._context_stack = context = {}\n        if key not in context:\n            context[key] = []\n        context[key].append(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a value in a task context stack", "response": "def stack_get(self, key):\n        \"\"\"Set a value in a task context stack\n        \"\"\"\n        task = Task.current_task()\n        try:\n            context = task._context_stack\n        except AttributeError:\n            return\n        if key in context:\n            return context[key][-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_pop(self, key):\n        task = Task.current_task()\n        try:\n            context = task._context_stack\n        except AttributeError:\n            raise KeyError('pop from empty stack') from None\n        value = context[key]\n        stack_value = value.pop()\n        if not value:\n            context.pop(key)\n        return stack_value", "response": "Remove a value from a task context stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_star(mod_name):\n    expanded = []\n    mod_dir = os.path.dirname(\n        __import__(mod_name[:-2], {}, {}, ['']).__file__)\n    for f in glob.glob1(mod_dir, \"[!_]*.py\"):\n        expanded.append('%s.%s' % (mod_name[:-2], f[:-3]))\n    return expanded", "response": "Expand something like unuk. tasks. 1. 0 into a list of all the modules\n    there."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef module_attribute(dotpath, default=None, safe=False):\n    '''Load an attribute from a module.\n\n    If the module or the attribute is not available, return the default\n    argument if *safe* is `True`.\n    '''\n    if dotpath:\n        bits = str(dotpath).split(':')\n        try:\n            if len(bits) == 2:\n                attr = bits[1]\n                module_name = bits[0]\n            else:\n                bits = bits[0].split('.')\n                if len(bits) > 1:\n                    attr = bits[-1]\n                    module_name = '.'.join(bits[:-1])\n                else:\n                    raise ValueError('Could not find attribute in %s'\n                                     % dotpath)\n\n            module = import_module(module_name)\n            return getattr(module, attr)\n        except Exception:\n            if not safe:\n                raise\n            return default\n    else:\n        if not safe:\n            raise ImportError\n        return default", "response": "Load an attribute from a module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a message to target.", "response": "def send(target, action, *args, **params):\n    '''Send a :ref:`message <api-remote_commands>` to ``target``\n\n    The message is to perform a given ``action``. The actor sending the\n    message is obtained via the :func:`get_actor` function.\n\n    :parameter target: the :class:`Actor` id or an :class:`.ActorProxy` or\n        name of the target actor which will receive the message.\n    :parameter action: the :ref:`remote command <api-remote_commands>`\n        to perform in the ``target`` :class:`Actor`.\n    :parameter args: positional arguments to pass to the\n        :ref:`remote command <api-remote_commands>` ``action``.\n    :parameter params: dictionary of parameters to pass to\n        :ref:`remote command <api-remote_commands>` ``action``.\n    :return: an :class:`~asyncio.Future` if the action acknowledge the\n        caller or `None`.\n\n    Typical example::\n\n        >>> r = send(p,'ping')\n        >>> r.result()\n        'pong'\n    '''\n    actor = get_actor()\n    if not actor:\n        raise RuntimeError('No actor available, cannot send messages')\n    else:\n        return actor.send(target, action, *args, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, exit=True):\n        '''Called after forking to start the actor's life.\n\n        This is where logging is configured, the :attr:`mailbox` is\n        registered and the :attr:`_loop` is initialised and\n        started. Calling this method more than once does nothing.\n        '''\n        if self.state == ACTOR_STATES.INITIAL:\n            self._concurrency.before_start(self)\n            self._concurrency.add_events(self)\n            try:\n                self.cfg.when_ready(self)\n            except Exception:   # pragma    nocover\n                self.logger.exception('Unhandled exception in when_ready hook')\n            self._started = self._loop.time()\n            self._exit = exit\n            self.state = ACTOR_STATES.STARTING\n            self._run()", "response": "Called after forking to start the actor s life."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a message to target to perform action with givenargs and kwargs. Returns a coroutine or a Future.", "response": "def send(self, target, action, *args, **kwargs):\n        '''Send a message to ``target`` to perform ``action`` with given\n        positional ``args`` and key-valued ``kwargs``.\n        Returns a coroutine or a Future.\n        '''\n        target = self.monitor if target == 'monitor' else target\n        mailbox = self.mailbox\n        if isinstance(target, ActorProxyMonitor):\n            mailbox = target.mailbox\n        else:\n            actor = self.get_actor(target)\n            if isinstance(actor, Actor):\n                # this occur when sending a message from arbiter to monitors or\n                # vice-versa.\n                return command_in_context(action, self, actor, args, kwargs)\n            elif isinstance(actor, ActorProxyMonitor):\n                mailbox = actor.mailbox\n        if hasattr(mailbox, 'send'):\n            # if not mailbox.closed:\n            return mailbox.send(action, self, target, args, kwargs)\n        else:\n            raise CommandError('Cannot execute \"%s\" in %s. Unknown actor %s.'\n                               % (action, self, target))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self, exc=None, exit_code=None):\n        '''Gracefully stop the :class:`Actor`.\n\n        Implemented by the :meth:`.Concurrency.stop` method of the\n        :attr:`concurrency` attribute.\n        '''\n        return self._concurrency.stop(self, exc, exit_code)", "response": "Gracefully stop the actor s current concurrency."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an actor unique id return the actor proxy.", "response": "def get_actor(self, aid, check_monitor=True):\n        '''Given an actor unique id return the actor proxy.\n        '''\n        aid = actor_identity(aid)\n        return self._concurrency.get_actor(self, aid,\n                                           check_monitor=check_monitor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(self):\n        '''Return a nested dictionary of information related to the actor\n        status and performance. The dictionary contains the following entries:\n\n        * ``actor`` a dictionary containing information regarding the type of\n          actor and its status.\n        * ``events`` a dictionary of information about the\n          :ref:`event loop <asyncio-event-loop>` running the actor.\n        * ``extra`` the :attr:`extra` attribute (you can use it to add stuff).\n        * ``system`` system info.\n\n        This method is invoked when you run the\n        :ref:`info command <actor_info_command>` from another actor.\n        '''\n        if not self.started():\n            return\n        isp = self.is_process()\n        actor = {'name': self.name,\n                 'state': self.info_state,\n                 'actor_id': self.aid,\n                 'uptime':  self._loop.time() - self._started,\n                 'thread_id': self.tid,\n                 'process_id': self.pid,\n                 'is_process': isp,\n                 'age': self.concurrency.age}\n        data = {'actor': actor,\n                'extra': self.extra}\n        if isp:\n            data['system'] = system.process_info(self.pid)\n        self.event('on_info').fire(data=data)\n        return data", "response": "Return a nested dictionary of information related to the actor and its status and performance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html_factory(tag, **defaults):\n    '''Returns an :class:`Html` factory function for ``tag`` and a given\n    dictionary of ``defaults`` parameters. For example::\n\n    >>> input_factory = html_factory('input', type='text')\n    >>> html = input_factory(value='bla')\n\n    '''\n    def html_input(*children, **params):\n        p = defaults.copy()\n        p.update(params)\n        return Html(tag, *children, **p)\n    return html_input", "response": "Returns an HTML factory function for tag and a given\n    dictionary of defaults parameters. For example :: html_factory = html_factory_input_type_text >>>"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert a new child into the list of children at the specified index.", "response": "def insert(self, index, child):\n        '''Insert ``child`` into the list of :attr:`children` at ``index``.\n\n        :param index: The index (positive integer) where to insert ``child``.\n        :param child: String, bytes or another :class:`String`.\n            If it is an :class:`.String`, this instance will be set as\n            its :attr:`parent`.\n            If ``child`` is ``None``, this method does nothing.\n        '''\n        # make sure that child is not in child\n        if child not in (None, self):\n            if isinstance(child, String):\n                child_parent = child._parent\n                if self._parent is child:\n                    # the parent is the child we are appending.\n                    # remove from the child\n                    child.remove(self)\n                    if child_parent:\n                        index = child_parent.children.index(child)\n                        child_parent.remove(child)\n                        child_parent.insert(index, self)\n                elif child_parent:\n                    child_parent.remove(child)\n                child._parent = self\n            if index is None:\n                self.children.append(child)\n            else:\n                self.children.insert(index, child)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a child from the list of children.", "response": "def remove(self, child):\n        '''Remove a ``child`` from the list of :attr:`children`.'''\n        try:\n            self.children.remove(child)\n            if isinstance(child, String):\n                child._parent = None\n        except ValueError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterable over strings.", "response": "def stream(self, request, counter=0):\n        '''Returns an iterable over strings.\n        '''\n        if self._children:\n            for child in self._children:\n                if isinstance(child, String):\n                    yield from child.stream(request, counter+1)\n                else:\n                    yield child"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a : class :. WSGIResponse or a : class : ~asyncio. Future.", "response": "def http_response(self, request):\n        '''Return a :class:`.WsgiResponse` or a :class:`~asyncio.Future`.\n\n        This method asynchronously wait for :meth:`stream` and subsequently\n        returns a :class:`.WsgiResponse`.\n        '''\n        content_types = request.content_types\n        if not content_types or self._content_type in content_types:\n            response = request.response\n            response.content_type = self._content_type\n            response.encoding = self.charset\n            response.content = self.to_bytes()\n            return response\n        else:\n            raise HttpException(status=415, msg=request.content_types)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_bytes(self, request=None):\n        '''Called to transform the collection of\n        ``streams`` into the content string.\n        This method can be overwritten by derived classes.\n\n        :param streams: a collection (list or dictionary) containing\n            ``strings/bytes`` used to build the final ``string/bytes``.\n        :return: a string or bytes\n        '''\n        data = bytearray()\n        for chunk in self.stream(request):\n            if isinstance(chunk, str):\n                chunk = chunk.encode(self.charset)\n            data.extend(chunk)\n        return bytes(data)", "response": "Called to transform the collection of\n            strings into the content string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the specific attribute to the attribute dictionary with key name and value and return self.", "response": "def attr(self, *args):\n        '''Add the specific attribute to the attribute dictionary\n        with key ``name`` and value ``value`` and return ``self``.'''\n        attr = self._attr\n        if not args:\n            return attr or {}\n        result, adding = self._attrdata('attr', *args)\n        if adding:\n            for key, value in result.items():\n                if DATARE.match(key):\n                    self.data(key[5:], value)\n                else:\n                    if attr is None:\n                        self._extra['attr'] = attr = {}\n                    attr[key] = value\n            result = self\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds or retrieve data values for this : class:`Html`.", "response": "def data(self, *args):\n        '''Add or retrieve data values for this :class:`Html`.'''\n        data = self._data\n        if not args:\n            return data or {}\n        result, adding = self._attrdata('data', *args)\n        if adding:\n            if data is None:\n                self._extra['data'] = {}\n            add = self._visitor.add_data\n            for key, value in result.items():\n                add(self, key, value)\n            return self\n        else:\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addClass(self, cn):\n        '''Add the specific class names to the class set and return ``self``.\n        '''\n        if cn:\n            if isinstance(cn, (tuple, list, set, frozenset)):\n                add = self.addClass\n                for c in cn:\n                    add(c)\n            else:\n                classes = self._classes\n                if classes is None:\n                    self._extra['classes'] = classes = set()\n                add = classes.add\n                for cn in cn.split():\n                    add(slugify(cn))\n        return self", "response": "Add the specific class names to the class set and return self."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef removeClass(self, cn):\n        '''Remove classes'''\n        if cn:\n            ks = self._classes\n            if ks:\n                for cn in cn.split():\n                    if cn in ks:\n                        ks.remove(cn)\n        return self", "response": "Remove class from the set of active classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatatt(self, **attr):\n        '''Return a string with attributes to add to the tag'''\n        cs = ''\n        attr = self._attr\n        classes = self._classes\n        data = self._data\n        css = self._css\n        attr = attr.copy() if attr else {}\n        if classes:\n            cs = ' '.join(classes)\n            attr['class'] = cs\n        if css:\n            attr['style'] = ' '.join(('%s:%s;' % (k, v) for\n                                      k, v in css.items()))\n        if data:\n            for k, v in data.items():\n                attr['data-%s' % k] = dump_data_value(v)\n        if attr:\n            return ''.join(attr_iter(attr))\n        else:\n            return ''", "response": "Return a string with attributes to add to the tag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the css dictionary if mapping is a dictionary otherwise return the whole css dictionary.", "response": "def css(self, mapping=None):\n        '''Update the css dictionary if ``mapping`` is a dictionary, otherwise\n        return the css value at ``mapping``.\n\n        If ``mapping`` is not given, return the whole ``css`` dictionary\n        if available.\n        '''\n        css = self._css\n        if mapping is None:\n            return css\n        elif isinstance(mapping, Mapping):\n            if css is None:\n                self._extra['css'] = css = {}\n            css.update(mapping)\n            return self\n        else:\n            return css.get(mapping) if css else None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef absolute_path(self, path, minify=True):\n        '''Return a suitable absolute url for ``path``.\n\n        If ``path`` :meth:`is_relative` build a suitable url by prepending\n        the :attr:`media_path` attribute.\n\n        :return: A url path to insert in a HTML ``link`` or ``script``.\n        '''\n        if minify:\n            ending = '.%s' % self.mediatype\n            if not path.endswith(ending):\n                if self.minified:\n                    path = '%s.min' % path\n                path = '%s%s' % (path, ending)\n        #\n        if self.is_relative(path) and self.media_path:\n            return '%s%s' % (self.media_path, path)\n        elif self.asset_protocol and path.startswith('//'):\n            return '%s%s' % (self.asset_protocol, path)\n        else:\n            return path", "response": "Return a suitable absolute url for path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(self, index, child, rel=None, type=None, media=None,\n               condition=None, **kwargs):\n        '''Append a link to this container.\n\n        :param child: a string indicating the location of the linked\n            document\n        :param rel: Specifies the relationship between the document\n            and the linked document. If not given ``stylesheet`` is used.\n        :param type: Specifies the content type of the linked document.\n            If not given ``text/css`` is used. It an empty string is given,\n            it won't be added.\n        :param media: Specifies on what device the linked document will be\n            displayed. If not given or ``all``, the media is for all devices.\n        :param kwargs: additional attributes\n        '''\n        if child:\n            srel = 'stylesheet'\n            stype = 'text/css'\n            minify = rel in (None, srel) and type in (None, stype)\n            path = self.absolute_path(child, minify=minify)\n            if path.endswith('.css'):\n                rel = rel or srel\n                type = type or stype\n            value = Html('link', href=path, rel=rel, **kwargs)\n            if type:\n                value.attr('type', type)\n            if media not in (None, 'all'):\n                value.attr('media', media)\n            if condition:\n                value = Html(None, '<!--[if %s]>\\n' % condition,\n                             value, '<![endif]-->\\n')\n            value = value.to_string()\n            if value not in self.children:\n                if index is None:\n                    self.children.append(value)\n                else:\n                    self.children.insert(index, value)", "response": "Append a link to this container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new script to the container.", "response": "def insert(self, index, child, **kwargs):\n        '''add a new script to the container.\n\n        :param child: a ``string`` representing an absolute path to the script\n            or relative path (does not start with ``http`` or ``/``), in which\n            case the :attr:`Media.media_path` attribute is prepended.\n        '''\n        if child:\n            script = self.script(child, **kwargs)\n            if script not in self.children:\n                if index is None:\n                    self.children.append(script)\n                else:\n                    self.children.insert(index, script)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the content attribute of a meta tag with the given name.", "response": "def get_meta(self, name, meta_key=None):\n        '''Get the ``content`` attribute of a meta tag ``name``.\n\n        For example::\n\n            head.get_meta('decription')\n\n        returns the ``content`` attribute of the meta tag with attribute\n        ``name`` equal to ``description`` or ``None``.\n        If a different meta key needs to be matched, it can be specified via\n        the ``meta_key`` parameter::\n\n            head.get_meta('og:title', meta_key='property')\n        '''\n        meta_key = meta_key or 'name'\n        for child in self.meta._children:\n            if isinstance(child, Html) and child.attr(meta_key) == name:\n                return child.attr('content')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_meta(self, name, content=None, meta_key=None):\n        '''Replace the ``content`` attribute of meta tag ``name``\n\n        If the meta with ``name`` is not available, it is added, otherwise\n        its content is replaced. If ``content`` is not given or it is empty\n        the meta tag with ``name`` is removed.\n        '''\n        children = self.meta._children\n        if not content:     # small optimazation\n            children = tuple(children)\n        meta_key = meta_key or 'name'\n        for child in children:\n            if child.attr(meta_key) == name:\n                if content:\n                    child.attr('content', content)\n                else:\n                    self.meta._children.remove(child)\n                return\n        if content:\n            self.add_meta(**{meta_key: name, 'content': content})", "response": "Replace the content attribute of meta tag name with content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef randompaths(request, num_paths=1, size=250, mu=0, sigma=1):\n    '''Lists of random walks.'''\n    r = []\n    for p in range(num_paths):\n        v = 0\n        path = [v]\n        r.append(path)\n        for t in range(size):\n            v += normalvariate(mu, sigma)\n            path.append(v)\n    return r", "response": "Lists of random walks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls once to setup the list of wsgi middleware.", "response": "def setup(self, environ):\n        '''Called once to setup the list of wsgi middleware.'''\n        json_handler = Root().putSubHandler('calc', Calculator())\n        middleware = wsgi.Router('/', post=json_handler,\n                                 accept_content_types=JSON_CONTENT_TYPES)\n        response = [wsgi.GZipMiddleware(200)]\n        return wsgi.WsgiHandler(middleware=[wsgi.wait_for_body_middleware,\n                                            middleware],\n                                response_middleware=response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AsyncResponseMiddleware(environ, resp):\n    '''This is just for testing the asynchronous response middleware\n    '''\n    future = create_future()\n    future._loop.call_soon(future.set_result, resp)\n    return future", "response": "This is just for testing the asynchronous response middleware\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode a message when publishing.", "response": "def encode(self, message):\n        '''Encode a message when publishing.'''\n        if not isinstance(message, dict):\n            message = {'message': message}\n        message['time'] = time.time()\n        return json.dumps(message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_open(self, websocket):\n        '''When a new websocket connection is established it creates a\n        new :class:`ChatClient` and adds it to the set of clients of the\n        :attr:`pubsub` handler.'''\n        self.pubsub.add_client(ChatClient(websocket, self.channel))", "response": "When a new websocket connection is established it creates a\n        new ChatClient and adds it to the set of clients of the tornado. iostream. WebSocketHandler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_message(self, websocket, msg):\n        '''When a new message arrives, it publishes to all listening clients.\n        '''\n        if msg:\n            lines = []\n            for li in msg.split('\\n'):\n                li = li.strip()\n                if li:\n                    lines.append(li)\n            msg = ' '.join(lines)\n            if msg:\n                return self.pubsub.publish(self.channel, msg)", "response": "When a new message arrives it publishes to all listening clients."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def rpc_message(self, request, message):\n        '''Publish a message via JSON-RPC'''\n        await self.pubsub.publish(self.channel, message)\n        return 'OK'", "response": "Publish a message via JSON - RPC"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall once only to setup the WSGI application handler.", "response": "def setup(self, environ):\n        '''Called once only to setup the WSGI application handler.\n\n        Check :ref:`lazy wsgi handler <wsgi-lazy-handler>`\n        section for further information.\n        '''\n        request = wsgi_request(environ)\n        cfg = request.cache.cfg\n        loop = request.cache._loop\n        self.store = create_store(cfg.data_store, loop=loop)\n        pubsub = self.store.pubsub(protocol=Protocol())\n        channel = '%s_webchat' % self.name\n        ensure_future(pubsub.subscribe(channel), loop=loop)\n        return WsgiHandler([Router('/', get=self.home_page),\n                            WebSocket('/message', Chat(pubsub, channel)),\n                            Router('/rpc', post=Rpc(pubsub, channel),\n                                   response_content_types=JSON_CONTENT_TYPES)],\n                           [AsyncResponseMiddleware,\n                            GZipMiddleware(min_length=20)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a cookie key into the cookies dictionary.", "response": "def set_cookie(cookies, key, value='', max_age=None, expires=None, path='/',\n               domain=None, secure=False, httponly=False):\n    '''Set a cookie key into the cookies dictionary *cookies*.'''\n    cookies[key] = value\n    if expires is not None:\n        if isinstance(expires, datetime):\n            now = (expires.now(expires.tzinfo) if expires.tzinfo else\n                   expires.utcnow())\n            delta = expires - now\n            # Add one second so the date matches exactly (a fraction of\n            # time gets lost between converting to a timedelta and\n            # then the date string).\n            delta = delta + timedelta(seconds=1)\n            # Just set max_age - the max_age logic will set expires.\n            expires = None\n            max_age = max(0, delta.days * 86400 + delta.seconds)\n        else:\n            cookies[key]['expires'] = expires\n    if max_age is not None:\n        cookies[key]['max-age'] = max_age\n        # IE requires expires, so set it if hasn't been already.\n        if not expires:\n            cookies[key]['expires'] = http_date(time.time() + max_age)\n    if path is not None:\n        cookies[key]['path'] = path\n    if domain is not None:\n        cookies[key]['domain'] = domain\n    if secure:\n        cookies[key]['secure'] = True\n    if httponly:\n        cookies[key]['httponly'] = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_headers(self, environ):\n        headers = self.headers\n        method = environ['REQUEST_METHOD']\n\n        if has_empty_content(self.status_code, method) and method != HEAD:\n            headers.pop('content-type', None)\n            headers.pop('content-length', None)\n            self._content = ()\n        else:\n            if not self.is_streamed():\n                cl = reduce(count_len, self._content, 0)\n                headers['content-length'] = str(cl)\n            ct = headers.get('content-type')\n            # content type encoding available\n            if self.encoding:\n                ct = ct or 'text/plain'\n                if ';' not in ct:\n                    ct = '%s; charset=%s' % (ct, self.encoding)\n            if ct:\n                headers['content-type'] = ct\n            if method == HEAD:\n                self._content = ()\n        # Cookies\n        if (self.status_code < 400 and self._can_store_cookies and\n                self._cookies):\n            for c in self.cookies.values():\n                headers.add('set-cookie', c.OutputString())\n        return headers.items()", "response": "Returns a list of headers for this response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpc_method(func, doc=None, format='json', request_handler=None):\n    '''A decorator which exposes a function ``func`` as an rpc function.\n\n    :param func: The function to expose.\n    :param doc: Optional doc string. If not provided the doc string of\n        ``func`` will be used.\n    :param format: Optional output format.\n    :param request_handler: function which takes ``request``, ``format``\n        and ``kwargs`` and return a new ``kwargs`` to be passed to ``func``.\n        It can be used to add additional parameters based on request and\n        format.\n    '''\n    def _(self, *args, **kwargs):\n        request = args[0]\n        if request_handler:\n            kwargs = request_handler(request, format, kwargs)\n        try:\n            return func(*args, **kwargs)\n        except TypeError:\n            msg = checkarity(func, args, kwargs)\n            if msg:\n                raise InvalidParams('Invalid Parameters. %s' % msg)\n            else:\n                raise\n\n    _.__doc__ = doc or func.__doc__\n    _.__name__ = func.__name__\n    _.FromApi = True\n    return _", "response": "A decorator which exposes a function as an rpc function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef putSubHandler(self, prefix, handler):\n        '''Add a sub :class:`RpcHandler` with prefix ``prefix``.\n\n        :keyword prefix: a string defining the prefix of the subhandler\n        :keyword handler: the sub-handler.\n        '''\n        self.subHandlers[prefix] = handler\n        handler._parent = self\n        return self", "response": "Add a sub - handler with prefix prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning url from double slashes and redirect if needed.", "response": "def clean_path_middleware(environ, start_response=None):\n    '''Clean url from double slashes and redirect if needed.'''\n    path = environ['PATH_INFO']\n    if path and '//' in path:\n        url = re.sub(\"/+\", '/', path)\n        if not url.startswith('/'):\n            url = '/%s' % url\n        qs = environ['QUERY_STRING']\n        if qs:\n            url = '%s?%s' % (url, qs)\n        raise HttpRedirect(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authorization_middleware(environ, start_response=None):\n    '''Parse the ``HTTP_AUTHORIZATION`` key in the ``environ``.\n\n    If available, set the ``http.authorization`` key in ``environ`` with\n    the result obtained from :func:`~.parse_authorization_header` function.\n    '''\n    key = 'http.authorization'\n    c = environ.get(key)\n    if c is None:\n        code = 'HTTP_AUTHORIZATION'\n        if code in environ:\n            environ[key] = parse_authorization_header(environ[code])", "response": "Parse the HTTP_AUTHORIZATION key in the environ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def wait_for_body_middleware(environ, start_response=None):\n    '''Use this middleware to wait for the full body.\n\n    This middleware wait for the full body to be received before letting\n    other middleware to be processed.\n\n    Useful when using synchronous web-frameworks such as :django:`django <>`.\n    '''\n    if environ.get('wsgi.async'):\n        try:\n            chunk = await environ['wsgi.input'].read()\n        except TypeError:\n            chunk = b''\n        environ['wsgi.input'] = BytesIO(chunk)\n        environ.pop('wsgi.async')", "response": "Use this middleware to wait for the full body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef middleware_in_executor(middleware):\n    '''Use this middleware to run a synchronous middleware in the event loop\n    executor.\n\n    Useful when using synchronous web-frameworks such as :django:`django <>`.\n    '''\n    @wraps(middleware)\n    def _(environ, start_response):\n        loop = get_event_loop()\n        return loop.run_in_executor(None, middleware, environ, start_response)\n\n    return _", "response": "Use this middleware to run a synchronous middleware in the event loop\n    executor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def eat(self, philosopher):\n        '''The ``philosopher`` performs one of these two actions:\n\n        * eat, if he has both forks and then :meth:`release_forks`.\n        * try to :meth:`pickup_fork`, if he has fewer than 2 forks.\n        '''\n        loop = philosopher._loop\n        while True:\n            forks = self.forks\n            if forks:\n                #\n                # Two forks. Eat!\n                if len(forks) == 2:\n                    self.thinking = 0\n                    self.eaten += 1\n                    philosopher.logger.info(\"eating... So far %s times\",\n                                            self.eaten)\n                    eat_time = 2*self.cfg.eating_period*random.random()\n                    await sleep(eat_time)\n                    await self.release_forks(philosopher)\n                #\n                # One fork only! release fork or try to pick one up\n                elif len(forks) == 1:\n                    waiting_period = 2*self.cfg.waiting_period*random.random()\n                    if self.started_waiting == 0:\n                        self.started_waiting = loop.time()\n                    elif loop.time() - self.started_waiting > waiting_period:\n                        philosopher.logger.debug(\"tired of waiting\")\n                        await self.release_forks(philosopher)\n                #\n                # this should never happen\n                elif len(forks) > 2:    # pragma    nocover\n                    philosopher.logger.critical('more than 2 forks!!!')\n                    await self.release_forks(philosopher)\n            else:\n                if not self.thinking:\n                    philosopher.logger.warning('thinking...')\n                self.thinking += 1\n            await self.pickup_fork(philosopher)", "response": "Eat the current page of the page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the : class :. WSGIServer running hello.", "response": "def server(description=None, **kwargs):\n    '''Create the :class:`.WSGIServer` running :func:`hello`.'''\n    description = description or 'Pulsar Hello World Application'\n    return wsgi.WSGIServer(hello, description=description, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the connection if open and make sure the other_side connection is closed too.", "response": "def close(self, other_side=True):\n        \"\"\"Close the connection\n\n        Close the pipeline if open and make sure the other connection\n        is closed too.\n\n        :param other_side: if True close the other_side connection too.\n            used to avoid infinite loop\n        \"\"\"\n        waiters = [self.close_pipeline()]\n        if self.other_side and other_side:\n            waiters.append(self.other_side.close(False))\n        if self.transport:\n            self.transport.close()\n        waiters = [w for w in waiters if w]\n        if waiters:\n            return waiters[0] if len(waiters) == 1 else gather(*waiters)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a pulsar store.", "response": "async def start_store(app, url, workers=0, **kw):\n    '''Equivalent to :func:`.create_store` for most cases excepts when the\n    ``url`` is for a pulsar store not yet started.\n    In this case, a :class:`.PulsarDS` is started.\n    '''\n    store = create_store(url, **kw)\n    if store.name == 'pulsar':\n        client = store.client()\n        try:\n            await client.ping()\n        except ConnectionRefusedError:\n            host = localhost(store._host)\n            if not host:\n                raise\n            cfg = await send('arbiter', 'run', start_pulsar_ds,\n                             host, workers)\n            store._host = cfg.addresses[0]\n            dsn = store.buildurl()\n            store = create_store(dsn, **kw)\n    app.cfg.set('data_store', store.dsn)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing form data from a request and return a tuple of forms files and options.", "response": "def parse_form_data(request, stream=None, **kw):\n    '''Parse form data from an request and return a (forms, files) tuple.\n\n    Both tuple values are dictionaries with the form-field name as a key\n    (unicode) and lists as values (multiple values per key are possible).\n    The forms-dictionary contains form-field values as unicode strings.\n    The files-dictionary contains :class:`MultipartPart` instances, either\n    because the form-field was a file-upload or the value is to big to fit\n    into memory limits.\n\n    :parameter request: Request object (WSGI environ wrapper).\n    :parameter stream: Optional callable accepting one parameter only, the\n        instance of :class:`FormDecoder` being parsed. If provided, the\n        callable is invoked when data or partial data has been successfully\n        parsed.\n    '''\n    if request.method not in ENCODE_BODY_METHODS:\n        raise HttpException(status=422)\n\n    content_type = request.get('CONTENT_TYPE')\n    if content_type:\n        content_type, options = parse_options_header(content_type)\n        options.update(kw)\n    else:\n        options = kw\n\n    if content_type == 'multipart/form-data':\n        decoder = MultipartDecoder(request, options, stream)\n    elif content_type in FORM_ENCODED_TYPES:\n        decoder = UrlEncodedDecoder(request, options, stream)\n    elif content_type in JSON_CONTENT_TYPES:\n        decoder = JsonDecoder(request, options, stream)\n    else:\n        decoder = BytesDecoder(request, options, stream)\n\n    return decoder.parse()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def parse_headers(fp, _class=HTTPMessage):\n    headers = []\n    while True:\n        line = await fp.readline()\n        headers.append(line)\n        if len(headers) > _MAXHEADERS:\n            raise HttpException(\"got more than %d headers\" % _MAXHEADERS)\n        if line in (b'\\r\\n', b'\\n', b''):\n            break\n    hstring = b''.join(headers).decode('iso-8859-1')\n    return email.parser.Parser(_class=_class).parsestr(hstring)", "response": "Parses only RFC2822 headers from a file pointer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _waiting_expect(self):\n        '''``True`` when the client is waiting for 100 Continue.\n        '''\n        if self._expect_sent is None:\n            if self.environ.get('HTTP_EXPECT', '').lower() == '100-continue':\n                return True\n            self._expect_sent = ''\n        return False", "response": "True when the client is waiting for 100 Continue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feed_data(self, data):\n        if data:\n            self._bytes.append(data)\n            if self.parser.stream:\n                self.parser.stream(self)\n            else:\n                self.parser.buffer.extend(data)", "response": "Feed new data into the MultiPart parser or the data stream"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to Create a WSGI Proxy Server.", "response": "def server(name='proxy-server', headers_middleware=None,\n           server_software=None, **kwargs):\n    '''Function to Create a WSGI Proxy Server.'''\n    if headers_middleware is None:\n        headers_middleware = [x_forwarded_for]\n    wsgi_proxy = ProxyServerWsgiHandler(headers_middleware)\n    kwargs['server_software'] = server_software or SERVER_SOFTWARE\n    return wsgi.WSGIServer(wsgi_proxy, name=name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform the Http request to the upstream server", "response": "async def request(self):\n        '''Perform the Http request to the upstream server\n        '''\n        request_headers = self.request_headers()\n        environ = self.environ\n        method = environ['REQUEST_METHOD']\n        data = None\n        if method in ENCODE_BODY_METHODS:\n            data = DataIterator(self)\n        http = self.wsgi.http_client\n        try:\n            await http.request(method,\n                               environ['RAW_URI'],\n                               data=data,\n                               headers=request_headers,\n                               version=environ['SERVER_PROTOCOL'],\n                               pre_request=self.pre_request)\n        except Exception as exc:\n            self.error(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfills request headers from the environ dictionary and sets them to the target uri.", "response": "def request_headers(self):\n        '''Fill request headers from the environ dictionary and\n        modify them via the list of :attr:`headers_middleware`.\n        The returned headers will be sent to the target uri.\n        '''\n        headers = CIMultiDict()\n        for k in self.environ:\n            if k.startswith('HTTP_'):\n                head = k[5:].replace('_', '-')\n                headers[head] = self.environ[k]\n        for head in ENVIRON_HEADERS:\n            k = head.replace('-', '_').upper()\n            v = self.environ.get(k)\n            if v:\n                headers[head] = v\n        for middleware in self.wsgi.headers_middleware:\n            middleware(self.environ, headers)\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the tunnel. This is a callback fired once a connection with upstream server is established.", "response": "def pre_request(self, response, exc=None):\n        \"\"\"Start the tunnel.\n\n        This is a callback fired once a connection with upstream server is\n        established.\n        \"\"\"\n        if response.request.method == 'CONNECT':\n            self.start_response(\n                '200 Connection established',\n                [('content-length', '0')]\n            )\n            # send empty byte so that headers are sent\n            self.future.set_result([b''])\n            # proxy - server connection\n            upstream = response.connection\n            # client - proxy connection\n            dostream = self.connection\n            # Upgrade downstream connection\n            dostream.upgrade(partial(StreamTunnel.create, upstream))\n            #\n            # upstream upgrade\n            upstream.upgrade(partial(StreamTunnel.create, dostream))\n            response.fire_event('post_request')\n            # abort the event\n            raise AbortEvent\n        else:\n            response.event('data_processed').bind(self.data_processed)\n            response.event('post_request').bind(self.post_request)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new protocol via the protocol_factory method.", "response": "def create_protocol(self):\n        \"\"\"Create a new protocol via the :attr:`protocol_factory`\n\n        This method increase the count of :attr:`sessions` and build\n        the protocol passing ``self`` as the producer.\n        \"\"\"\n        self.sessions += 1\n        protocol = self.protocol_factory(self)\n        protocol.copy_many_times_events(self)\n        return protocol"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the transport and address of the connection.", "response": "def connection_made(self, transport):\n        \"\"\"Sets the :attr:`transport`, fire the ``connection_made`` event\n        and adds a :attr:`timeout` for idle connections.\n        \"\"\"\n        self.transport = transport\n        addr = self.transport.get_extra_info('peername')\n        if not addr:\n            addr = self.transport.get_extra_info('sockname')\n        self.address = addr\n        sock = transport.get_extra_info('socket')\n        if sock:\n            try:\n                sock.setsockopt(SOL_SOCKET, SO_KEEPALIVE, 1)\n            except (OSError, NameError):\n                pass\n        self.changed()\n        self.producer.logger.debug('new connection %s', self)\n        # let everyone know we have a connection with endpoint\n        self.event('connection_made').fire()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiring the connection_lost event.", "response": "def connection_lost(self, exc=None):\n        \"\"\"Fires the ``connection_lost`` event.\n        \"\"\"\n        if self._loop.get_debug():\n            self.producer.logger.debug('connection lost %s', self)\n        self.event('connection_lost').fire(exc=exc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelegate handling of data received from the current consumer.", "response": "def data_received(self, data):\n        \"\"\"Delegates handling of data to the :meth:`current_consumer`.\n        Once done set a timeout for idle connections when a\n        :attr:`~Protocol.timeout` is a positive number (of seconds).\n        \"\"\"\n        try:\n            self.data_received_count += 1\n            while data:\n                consumer = self.current_consumer()\n                if not consumer.request:\n                    consumer.start()\n                toprocess = consumer.feed_data(data)\n                consumer.fire_event('data_processed', data=data, exc=None)\n                data = toprocess\n            self.changed()\n        except Exception:\n            if self.transport:\n                self.transport.abort()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts processing the request for this protocol consumer.", "response": "def start(self, request=None):\n        \"\"\"Starts processing the request for this protocol consumer.\n\n        There is no need to override this method,\n        implement :meth:`start_request` instead.\n        If either :attr:`connection` or :attr:`transport` are missing, a\n        :class:`RuntimeError` occurs.\n\n        For server side consumer, this method simply fires the ``pre_request``\n        event.\n        \"\"\"\n        self.connection.processed += 1\n        self.producer.requests_processed += 1\n        self.event('post_request').bind(self.finished_reading)\n        self.request = request or self.create_request()\n        try:\n            self.fire_event('pre_request')\n        except AbortEvent:\n            if self._loop.get_debug():\n                self.producer.logger.debug('Abort request %s', request)\n        else:\n            self.start_request()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_global(name, val=None, setval=False):\n    '''Access and set global variables for the current process.'''\n    p = current_process()\n    if not hasattr(p, '_pulsar_globals'):\n        p._pulsar_globals = {'lock': Lock()}\n    if setval:\n        p._pulsar_globals[name] = val\n    else:\n        return p._pulsar_globals.get(name)", "response": "Access and set global variables for the current process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configured_logger(name=None, config=None, level=None, handlers=None):\n    '''Configured logger.\n    '''\n    name = name or ''\n    with process_global('lock'):\n        logconfig = process_global('_config_logging')\n        # if the logger was not configured, do so.\n        if not logconfig:\n            logconfig = deepcopy(config or LOGGING_CONFIG)\n            logconfig['configured'] = set()\n            process_global('_config_logging', logconfig, True)\n        else:\n            configured = logconfig.get('configured')\n            if name in configured:\n                return logging.getLogger(name)\n\n        level = get_level(level)\n        # No loggers configured. This means no logconfig setting\n        # parameter was used. Set up the root logger with default\n        # loggers\n        if level == logging.NOTSET:\n            handlers = ['silent']\n\n        level = logging.getLevelName(level)\n        cfg = {'level': level, 'propagate': False}\n        if handlers:\n            cfg['handlers'] = handlers\n\n        config = copy(logconfig)\n        configured = config.pop('configured')\n        configured.add(name)\n\n        if name:\n            config.pop('root', None)\n            loggers = config.pop('logger', {})\n            if name in loggers:\n                loggers[name].update(cfg)\n                cfg = loggers[name]\n            config['loggers'] = {name: cfg}\n        else:\n            if 'root' in config:\n                config['root'].update(cfg)\n                cfg = config['root']\n            if 'handlers' not in cfg:\n                cfg['handlers'] = ['console']\n            config['root'] = cfg\n        #\n        dictConfig(config)\n        return logging.getLogger(name)", "response": "Returns a logger with the given name and configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an Internationalised Resource Identifier ( IRI ) portion to a URI portion that is suitable for inclusion in a URL.", "response": "def iri_to_uri(iri, kwargs=None):\n    '''Convert an Internationalised Resource Identifier (IRI) portion\n    to a URI portion that is suitable for inclusion in a URL.\n    This is the algorithm from section 3.1 of RFC 3987.\n    Returns an ASCII native string containing the encoded result.\n    '''\n    if iri is None:\n        return iri\n    if kwargs:\n        iri = '%s?%s' % (to_string(iri, 'latin1'),\n                         '&'.join(('%s=%s' % kv for kv in kwargs.items())))\n    return urlquote(unquote_unreserved(iri))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quote_header_value(value, extra_chars='', allow_token=True):\n    value = to_string(value)\n    if allow_token:\n        token_chars = HEADER_TOKEN_CHARS | set(extra_chars)\n        if set(value).issubset(token_chars):\n            return value\n    return '\"%s\"' % value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')", "response": "Quote a header value if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_dict_header(value):\n    result = {}\n    for item in parse_http_list(value):\n        if '=' not in item:\n            result[item] = None\n            continue\n        name, value = item.split('=', 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result", "response": "Parse a string with a python dict containing the key value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_environ_proxies():\n\n    proxy_keys = [\n        'all',\n        'http',\n        'https',\n        'ftp',\n        'socks',\n        'ws',\n        'wss',\n        'no'\n    ]\n\n    def get_proxy(k):\n        return os.environ.get(k) or os.environ.get(k.upper())\n\n    proxies = [(key, get_proxy(key + '_proxy')) for key in proxy_keys]\n    return dict([(key, val) for (key, val) in proxies if val])", "response": "Return a dict of environment proxies. From requests_."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_multipart_formdata(fields, boundary=None, charset=None):\n    charset = charset or 'utf-8'\n    body = BytesIO()\n    if boundary is None:\n        boundary = choose_boundary()\n    for fieldname, value in mapping_iterator(fields):\n        body.write(('--%s\\r\\n' % boundary).encode(charset))\n        if isinstance(value, tuple):\n            filename, data = value\n            body.write(('Content-Disposition: form-data; name=\"%s\"; '\n                        'filename=\"%s\"\\r\\n' % (fieldname, filename))\n                       .encode(charset))\n            body.write(('Content-Type: %s\\r\\n\\r\\n' %\n                       (get_content_type(filename))).encode(charset))\n        else:\n            data = value\n            body.write(('Content-Disposition: form-data; name=\"%s\"\\r\\n'\n                        % (fieldname)).encode(charset))\n            body.write(b'Content-Type: text/plain\\r\\n\\r\\n')\n        body.write(to_bytes(data))\n        body.write(b'\\r\\n')\n    body.write(('--%s--\\r\\n' % (boundary)).encode(charset))\n    content_type = 'multipart/form-data; boundary=%s' % boundary\n    return body.getvalue(), content_type", "response": "Encode a dictionary of fields using the multipart - form - data format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_cookie(name, value, **kwargs):\n    result = dict(\n        version=0,\n        name=name,\n        value=value,\n        port=None,\n        domain='',\n        path='/',\n        secure=False,\n        expires=None,\n        discard=True,\n        comment=None,\n        comment_url=None,\n        rest={'HttpOnly': None},\n        rfc2109=False,)\n    badargs = set(kwargs) - set(result)\n    if badargs:\n        err = 'create_cookie() got unexpected keyword arguments: %s'\n        raise TypeError(err % list(badargs))\n    result.update(kwargs)\n    result['port_specified'] = bool(result['port'])\n    result['domain_specified'] = bool(result['domain'])\n    result['domain_initial_dot'] = result['domain'].startswith('.')\n    result['path_specified'] = bool(result['path'])\n    return Cookie(**result)", "response": "Create a Cookie object from underspecified parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cookiejar_from_dict(*cookie_dicts):\n    cookie_dicts = tuple((d for d in cookie_dicts if d))\n    if len(cookie_dicts) == 1 and isinstance(cookie_dicts[0], CookieJar):\n        return cookie_dicts[0]\n    cookiejar = CookieJar()\n    for cookie_dict in cookie_dicts:\n        if isinstance(cookie_dict, CookieJar):\n            for cookie in cookie_dict:\n                cookiejar.set_cookie(cookie)\n        else:\n            for name in cookie_dict:\n                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))\n    return cookiejar", "response": "Returns a CookieJar from a key - value dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the Vary header in the given HttpResponse object.", "response": "def patch_vary_headers(response, newheaders):\n    \"\"\"Adds (or updates) the \"Vary\" header in the given HttpResponse object.\n\n    newheaders is a list of header names that should be in \"Vary\". Existing\n    headers in \"Vary\" aren't removed.\n\n    For information on the Vary header, see:\n\n        http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.44\n    \"\"\"\n    # Note that we need to keep the original order intact, because cache\n    # implementations may rely on the order of the Vary contents in, say,\n    # computing an MD5 hash.\n    if 'Vary' in response:\n        vary_headers = cc_delim_re.split(response['Vary'])\n    else:\n        vary_headers = []\n    # Use .lower() here so we treat headers as case-insensitive.\n    existing_headers = set([header.lower() for header in vary_headers])\n    additional_headers = [newheader for newheader in newheaders\n                          if newheader.lower() not in existing_headers]\n    response['Vary'] = ', '.join(vary_headers + additional_headers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking to see if the response has a given header name in its Vary header.", "response": "def has_vary_header(response, header_query):\n    \"\"\"\n    Checks to see if the response has a given header name in its Vary header.\n    \"\"\"\n    if not response.has_header('Vary'):\n        return False\n    vary_headers = cc_delim_re.split(response['Vary'])\n    existing_headers = set([header.lower() for header in vary_headers])\n    return header_query.lower() in existing_headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a new request.", "response": "def execute(self, request):\n        '''Execute a new ``request``.\n        '''\n        handle = None\n        if request:\n            request[0] = command = to_string(request[0]).lower()\n            info = COMMANDS_INFO.get(command)\n            if info:\n                handle = getattr(self.store, info.method_name)\n            #\n            if self.channels or self.patterns:\n                if command not in self.store.SUBSCRIBE_COMMANDS:\n                    return self.reply_error(self.store.PUBSUB_ONLY)\n            if self.blocked:\n                return self.reply_error('Blocked client cannot request')\n            if self.transaction is not None and command not in 'exec':\n                self.transaction.append((handle, request))\n                return self.connection.write(self.store.QUEUED)\n        self.execute_command(handle, request)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a *dte* into a valid unix timestamp.", "response": "def date2timestamp(dte):\n    '''Convert a *dte* into a valid unix timestamp.'''\n    seconds = mktime(dte.timetuple())\n    if isinstance(dte, datetime):\n        return seconds + dte.microsecond / 1000000.0\n    else:\n        return int(seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if this : class:`Path` is a python module.", "response": "def ispymodule(self):\n        '''Check if this :class:`Path` is a python module.'''\n        if self.isdir():\n            return os.path.isfile(os.path.join(self, '__init__.py'))\n        elif self.isfile():\n            return self.endswith('.py')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a directory to the python path.", "response": "def add2python(self, module=None, up=0, down=None, front=False,\n                   must_exist=True):\n        '''Add a directory to the python path.\n\n        :parameter module: Optional module name to try to import once we\n            have found the directory\n        :parameter up: number of level to go up the directory three from\n            :attr:`local_path`.\n        :parameter down: Optional tuple of directory names to travel down\n            once we have gone *up* levels.\n        :parameter front: Boolean indicating if we want to insert the new\n            path at the front of ``sys.path`` using\n            ``sys.path.insert(0,path)``.\n        :parameter must_exist: Boolean indicating if the module must exists.\n        '''\n        if module:\n            try:\n                return import_module(module)\n            except ImportError:\n                pass\n        dir = self.dir().ancestor(up)\n        if down:\n            dir = dir.join(*down)\n        if dir.isdir():\n            if dir not in sys.path:\n                if front:\n                    sys.path.insert(0, dir)\n                else:\n                    sys.path.append(dir)\n        elif must_exist:\n            raise ImportError('Directory {0} not available'.format(dir))\n        else:\n            return None\n        if module:\n            try:\n                return import_module(module)\n            except ImportError:\n                if must_exist:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stats(self, request):\n        '''Live stats for the server.\n\n        Try sending lots of requests\n        '''\n        # scheme = 'wss' if request.is_secure else 'ws'\n        # host = request.get('HTTP_HOST')\n        # address = '%s://%s/stats' % (scheme, host)\n        doc = HtmlDocument(title='Live server stats', media_path='/assets/')\n        # docs.head.scripts\n        return doc.http_response(request)", "response": "Live stats for the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of basic information about the given process object.", "response": "def get_preparation_data(name):\r\n    '''\r\n    Return info about parent needed by child to unpickle process object.\r\n    Monkey-patch from\r\n    '''\r\n    d = dict(\r\n        name=name,\r\n        sys_path=sys.path,\r\n        sys_argv=sys.argv,\r\n        log_to_stderr=_log_to_stderr,\r\n        orig_dir=process.ORIGINAL_DIR,\r\n        authkey=process.current_process().authkey,\r\n    )\r\n\r\n    if _logger is not None:\r\n        d['log_level'] = _logger.getEffectiveLevel()\r\n\r\n    if not WINEXE:\r\n        main_path = getattr(sys.modules['__main__'], '__file__', None)\r\n        if not main_path and sys.argv[0] not in ('', '-c'):\r\n            main_path = sys.argv[0]\r\n        if main_path is not None:\r\n            if (not os.path.isabs(main_path) and process.ORIGINAL_DIR\r\n                    is not None):\r\n                main_path = os.path.join(process.ORIGINAL_DIR, main_path)\r\n            if not main_path.endswith('.exe'):\r\n                d['main_path'] = os.path.normpath(main_path)\r\n\r\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the command function name *name*'", "response": "def get_command(name):\n    '''Get the command function *name*'''\n    command = global_commands_table.get(name.lower())\n    if not command:\n        raise CommandNotFound(name)\n    return command"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remote_call(request, cls, method, args, kw):\n    '''Command for executing remote calls on a remote object\n    '''\n    actor = request.actor\n    name = 'remote_%s' % cls.__name__\n    if not hasattr(actor, name):\n        object = cls(actor)\n        setattr(actor, name, object)\n    else:\n        object = getattr(actor, name)\n    method_name = '%s%s' % (PREFIX, method)\n    return getattr(object, method_name)(request, *args, **kw)", "response": "Command for executing remote calls on a remote object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclears the container from all data.", "response": "def clear(self):\n        '''Clear the container from all data.'''\n        self._size = 0\n        self._level = 1\n        self._head = Node('HEAD', None,\n                          [None]*SKIPLIST_MAXLEVEL,\n                          [1]*SKIPLIST_MAXLEVEL)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextend this skiplist with an iterable over score values.", "response": "def extend(self, iterable):\n        '''Extend this skiplist with an iterable over\n        ``score``, ``value`` pairs.\n        '''\n        i = self.insert\n        for score_values in iterable:\n            i(*score_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rank(self, score):\n        '''Return the 0-based index (rank) of ``score``.\n\n        If the score is not available it returns a negative integer which\n        absolute score is the right most closest index with score less than\n        ``score``.\n        '''\n        node = self._head\n        rank = 0\n        for i in range(self._level-1, -1, -1):\n            while node.next[i] and node.next[i].score < score:\n                rank += node.width[i]\n                node = node.next[i]\n        node = node.next[0]\n        if node and node.score == score:\n            return rank\n        else:\n            return -2 - rank", "response": "Return the 0 - based index of score which is the right most closest index with score less than score."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_range(self, start, end, callback=None):\n        '''Remove a range by rank.\n\n        This is equivalent to perform::\n\n            del l[start:end]\n\n        on a python list.\n        It returns the number of element removed.\n        '''\n        N = len(self)\n        if start < 0:\n            start = max(N + start, 0)\n        if start >= N:\n            return 0\n        if end is None:\n            end = N\n        elif end < 0:\n            end = max(N + end, 0)\n        else:\n            end = min(end, N)\n        if start >= end:\n            return 0\n        node = self._head\n        index = 0\n        chain = [None] * self._level\n        for i in range(self._level-1, -1, -1):\n            while node.next[i] and (index + node.width[i]) <= start:\n                index += node.width[i]\n                node = node.next[i]\n            chain[i] = node\n        node = node.next[0]\n        initial = self._size\n        while node and index < end:\n            next = node.next[0]\n            self._remove_node(node, chain)\n            index += 1\n            if callback:\n                callback(node.score, node.value)\n            node = next\n        return initial - self._size", "response": "Remove a range by rank."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a range with scores between minval and maxval.", "response": "def remove_range_by_score(self, minval, maxval, include_min=True,\n                              include_max=True, callback=None):\n        '''Remove a range with scores between ``minval`` and ``maxval``.\n\n        :param minval: the start value of the range to remove\n        :param maxval: the end value of the range to remove\n        :param include_min: whether or not to include ``minval`` in the\n            values to remove\n        :param include_max: whether or not to include ``maxval`` in the\n            scores to to remove\n        :param callback: optional callback function invoked for each\n            score, value pair removed.\n        :return: the number of elements removed.\n        '''\n        node = self._head\n        chain = [None] * self._level\n        if include_min:\n            for i in range(self._level-1, -1, -1):\n                while node.next[i] and node.next[i].score < minval:\n                    node = node.next[i]\n                chain[i] = node\n        else:\n            for i in range(self._level-1, -1, -1):\n                while node.next[i] and node.next[i].score <= minval:\n                    node = node.next[i]\n                chain[i] = node\n        node = node.next[0]\n        initial = self._size\n        while node and node.score >= minval:\n            if ((include_max and node.score > maxval) or\n                    (not include_max and node.score >= maxval)):\n                break\n            next = node.next[0]\n            self._remove_node(node, chain)\n            if callback:\n                callback(node.score, node.value)\n            node = next\n        return initial - self._size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of elements in the skiplist with a score between min and max.", "response": "def count(self, minval, maxval, include_min=True, include_max=True):\n        '''Returns the number of elements in the skiplist with a score\n        between min and max.\n        '''\n        rank1 = self.rank(minval)\n        if rank1 < 0:\n            rank1 = -rank1 - 1\n        elif not include_min:\n            rank1 += 1\n        rank2 = self.rank(maxval)\n        if rank2 < 0:\n            rank2 = -rank2 - 1\n        elif include_max:\n            rank2 += 1\n        return max(rank2 - rank1, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a connection from the pool.", "response": "async def connect(self):\n        '''Get a connection from the pool.\n\n        The connection is either a new one or retrieved from the\n        :attr:`available` connections in the pool.\n\n        :return: a :class:`~asyncio.Future` resulting in the connection.\n        '''\n        assert not self.closed\n        connection = await self._get()\n        return PoolConnection(self, connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses all connections and return a future called once all connections have closed", "response": "def close(self):\n        '''Close all connections\n\n        Return a :class:`~asyncio.Future` called once all connections\n        have closed\n        '''\n        if not self.closed:\n            waiters = []\n            queue = self._queue\n            while queue.qsize():\n                connection = queue.get_nowait()\n                if connection:\n                    closed = connection.close()\n                    if closed:\n                        waiters.append(closed)\n            in_use = self._in_use_connections\n            self._in_use_connections = set()\n            for connection in in_use:\n                if connection:\n                    waiters.append(connection.close())\n            self._closed = asyncio.gather(*waiters, loop=self._loop)\n        return self._closed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing this pool connection by releasing the underlying . connection and returning the new connection.", "response": "def close(self, discard=False):\n        '''Close this pool connection by releasing the underlying\n        :attr:`connection` back to the :attr:`pool`.\n        '''\n        if self.pool is not None:\n            self.pool._put(self.connection, discard)\n            self.pool = None\n            conn, self.connection = self.connection, None\n            return conn"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetaches the underlying connection from the pool.", "response": "async def detach(self, discard=True):\n        '''Remove the underlying :attr:`connection` from the connection\n        :attr:`pool`.\n        '''\n        if discard:\n            return self.close(True)\n        else:\n            self.connection._exit_ = False\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def create_connection(self, address=None, protocol_factory=None,\n                                **kwargs):\n        \"\"\"Helper method for creating a connection to an ``address``.\n        \"\"\"\n        loop = self._loop\n        protocol_factory = protocol_factory or self.create_protocol\n        if isinstance(address, tuple):\n            kwargs['host'] = address[0]\n            kwargs['port'] = address[1]\n        _, protocol = await loop.create_connection(protocol_factory, **kwargs)\n        event = protocol.event('connection_made')\n        if not event.fired():\n            await event.waiter()\n        return protocol", "response": "Helper method for creating a connection to an address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create_datagram_endpoint(self, protocol_factory=None, **kw):\n        '''Helper method for creating a connection to an ``address``.\n        '''\n        protocol_factory = protocol_factory or self.create_protocol\n        _, protocol = await self._loop.create_datagram_endpoint(\n            protocol_factory, **kw)\n        event = protocol.event('connection_made')\n        if not event.fired():\n            await event.waiter()\n        return protocol", "response": "Helper method for creating a datagram endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the quality of the key.", "response": "def quality(self, key):\n        \"\"\"Returns the quality of the key.\n\n        .. versionadded:: 0.6\n           In previous versions you had to use the item-lookup syntax\n           (eg: ``obj[key]`` instead of ``obj.quality(key)``)\n        \"\"\"\n        for item, quality in self:\n            if self._value_matches(key, item):\n                return quality\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the index of an entry in the list or raise ValueError.", "response": "def index(self, key):\n        \"\"\"Get the position of an entry or raise :exc:`ValueError`.\n\n        :param key: The key to be looked up.\n\n        .. versionchanged:: 0.5\n           This used to raise :exc:`IndexError`, which was inconsistent\n           with the list API.\n        \"\"\"\n        if isinstance(key, str):\n            for idx, (item, quality) in enumerate(self):\n                if self._value_matches(key, item):\n                    return idx\n            raise ValueError(key)\n        return list.index(self, key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_header(self):\n        result = []\n        for value, quality in self:\n            if quality != 1:\n                value = '%s;q=%s' % (value, quality)\n            result.append(value)\n        return ','.join(result)", "response": "Convert the header set into an HTTP header string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef best_match(self, matches, default=None):\n        if matches:\n            best_quality = -1\n            result = default\n            for client_item, quality in self:\n                for server_item in matches:\n                    if quality <= best_quality:\n                        break\n                    if self._value_matches(server_item, client_item):\n                        best_quality = quality\n                        result = server_item\n            return result\n        else:\n            return self.best", "response": "Returns the best match from a list of possible matches based on the quality of the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a number of bytes into a human readable memory usage bytes", "response": "def convert_bytes(b):\n    '''Convert a number of bytes into a human readable memory usage, bytes,\nkilo, mega, giga, tera, peta, exa, zetta, yotta'''\n    if b is None:\n        return '#NA'\n    for s in reversed(memory_symbols):\n        if b >= memory_size[s]:\n            value = float(b) / memory_size[s]\n            return '%.1f%sB' % (value, s)\n    return \"%sB\" % b"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of system information for the process pid.", "response": "def process_info(pid=None):\n    '''Returns a dictionary of system information for the process ``pid``.\n\n    It uses the psutil_ module for the purpose. If psutil_ is not available\n    it returns an empty dictionary.\n\n    .. _psutil: http://code.google.com/p/psutil/\n    '''\n    if psutil is None:  # pragma    nocover\n        return {}\n    pid = pid or os.getpid()\n    try:\n        p = psutil.Process(pid)\n    # this fails on platforms which don't allow multiprocessing\n    except psutil.NoSuchProcess:  # pragma    nocover\n        return {}\n    else:\n        mem = p.memory_info()\n        return {'memory': convert_bytes(mem.rss),\n                'memory_virtual': convert_bytes(mem.vms),\n                'cpu_percent': p.cpu_percent(),\n                'nice': p.nice(),\n                'num_threads': p.num_threads()}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(self):\n        if not self._closed:\n            closed = False\n            event = self.event('connection_lost')\n            if self.transport:\n                if self._loop.get_debug():\n                    self.logger.debug('Closing connection %s', self)\n                if self.transport.can_write_eof():\n                    try:\n                        self.transport.write_eof()\n                    except Exception:\n                        pass\n                try:\n                    worker = self.close_pipeline()\n                    self.transport.close()\n                    closed = self._loop.create_task(\n                        self._close(event.waiter(), worker)\n                    )\n                except Exception:\n                    pass\n            self._closed = closed or True\n            if not closed:\n                event.fire()\n        return self._closed", "response": "Close the connection by closing the transport."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef abort(self):\n        if self.transport:\n            self.transport.abort()\n        self.event('connection_lost').fire()", "response": "Abort by aborting the transport"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart serving. :param address: optional address to bind to :param sockets: optional list of sockets to bind to :param backlog: Number of maximum connections :param sslcontext: optional SSLContext object", "response": "async def start_serving(self, address=None, sockets=None,\n                            backlog=100, sslcontext=None):\n        \"\"\"Start serving.\n\n        :param address: optional address to bind to\n        :param sockets: optional list of sockets to bind to\n        :param backlog: Number of maximum connections\n        :param sslcontext: optional SSLContext object\n        \"\"\"\n        if self._server:\n            raise RuntimeError('Already serving')\n        create_server = self._loop.create_server\n        server = None\n        if sockets:\n            for sock in sockets:\n                srv = await create_server(self.create_protocol,\n                                          sock=sock,\n                                          backlog=backlog,\n                                          ssl=sslcontext)\n                if server:\n                    server.sockets.extend(srv.sockets)\n                else:\n                    server = srv\n        elif isinstance(address, tuple):\n            server = await create_server(self.create_protocol,\n                                         host=address[0],\n                                         port=address[1],\n                                         backlog=backlog,\n                                         ssl=sslcontext)\n        else:\n            raise RuntimeError('sockets or address must be supplied')\n        self._set_server(server)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops serving the server and close all connections.", "response": "async def close(self):\n        \"\"\"Stop serving the :attr:`.Server.sockets`.\n        \"\"\"\n        if self._server:\n            self._server.close()\n            self._server = None\n            coro = self._close_connections()\n            if coro:\n                await coro\n            self.logger.debug('%s closed', self)\n            self.event('stop').fire()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses ``connection`` if specified, otherwise close all connections. Return a list of :class:`.Future` called back once the connection/s are closed.", "response": "def _close_connections(self, connection=None, timeout=5):\n        \"\"\"Close ``connection`` if specified, otherwise close all connections.\n\n        Return a list of :class:`.Future` called back once the connection/s\n        are closed.\n        \"\"\"\n        all = []\n        if connection:\n            waiter = connection.event('connection_lost').waiter()\n            if waiter:\n                all.append(waiter)\n                connection.close()\n        else:\n            connections = list(self._concurrent_connections)\n            self._concurrent_connections = set()\n            for connection in connections:\n                waiter = connection.event('connection_lost').waiter()\n                if waiter:\n                    all.append(waiter)\n                    connection.close()\n        if all:\n            self.logger.info('%s closing %d connections', self, len(all))\n            return asyncio.wait(all, timeout=timeout, loop=self._loop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop serving the server. sockets and close all concurrent connections.", "response": "def close(self):\n        \"\"\"Stop serving the :attr:`.Server.sockets` and close all\n        concurrent connections.\n        \"\"\"\n        transports, self.transports = self.transports, []\n        for transport in transports:\n            transport.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts serving the datagrams or sockets.", "response": "async def start_serving(self, address=None, sockets=None, **kw):\n        \"\"\"create the server endpoint.\n        \"\"\"\n        if self._server:\n            raise RuntimeError('Already serving')\n        server = DGServer(self._loop)\n        loop = self._loop\n        if sockets:\n            for sock in sockets:\n                transport, _ = await loop.create_datagram_endpoint(\n                    self.create_protocol, sock=sock)\n                server.transports.append(transport)\n        elif isinstance(address, tuple):\n            transport, _ = await loop.create_datagram_endpoint(\n                self.create_protocol, local_addr=address)\n            server.transports.append(transport)\n        else:\n            raise RuntimeError('sockets or address must be supplied')\n        self._set_server(server)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping serving the server and close all the concurrent connections.", "response": "async def close(self):\n        \"\"\"Stop serving the :attr:`.Server.sockets` and close all\n        concurrent connections.\n        \"\"\"\n        if self._server:\n            self._server.close()\n            self._server = None\n            self.event('stop').fire()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_open(self, websocket):\n        '''When a new websocket connection is established it creates a\n        new :class:`ChatClient` and adds it to the set of clients of the\n        :attr:`pubsub` handler.'''\n        LOGGER.info('New websocket opened. Add client to %s on \"%s\" channel',\n                    self.pubsub, self.channel)\n        self.pubsub.add_client(self.client(websocket, self.channel))", "response": "When a new websocket connection is established it creates a\n        new ChatClient and adds it to the set of clients of the daemon handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def monitor_start(self, monitor):\n        '''Create the socket listening to the ``bind`` address.\n\n        If the platform does not support multiprocessing sockets set the\n        number of workers to 0.\n        '''\n        cfg = self.cfg\n        if (not platform.has_multiprocessing_socket or\n                cfg.concurrency == 'thread'):\n            cfg.set('workers', 0)\n        servers = await self.binds(monitor)\n        if not servers:\n            raise ImproperlyConfigured('Could not open a socket. '\n                                       'No address to bind to')\n        addresses = []\n        for server in servers.values():\n            addresses.extend(server.addresses)\n        self.cfg.addresses = addresses", "response": "Create the socket listening to the bind address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def worker_start(self, worker, exc=None):\n        '''Start the worker by invoking the :meth:`create_server` method.\n        '''\n        if not exc and self.name not in worker.servers:\n            servers = await self.binds(worker, worker.sockets)\n            for server in servers.values():\n                server.event('stop').bind(lambda _, **kw: worker.stop())", "response": "Start the worker by invoking the create_server method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def create_server(self, worker, protocol_factory, address=None,\n                            sockets=None, idx=0):\n        '''Create the Server which will listen for requests.\n\n        :return: a :class:`.TcpServer`.\n        '''\n        cfg = self.cfg\n        max_requests = cfg.max_requests\n        if max_requests:\n            max_requests = int(lognormvariate(log(max_requests), 0.2))\n        server = self.server_factory(\n            protocol_factory,\n            loop=worker._loop,\n            max_requests=max_requests,\n            keep_alive=cfg.keep_alive,\n            name=self.name,\n            logger=self.logger,\n            server_software=cfg.server_software,\n            cfg=cfg,\n            idx=idx\n        )\n        for event in ('connection_made', 'pre_request', 'post_request',\n                      'connection_lost'):\n            callback = getattr(cfg, event)\n            if callback != pass_through:\n                server.event(event).bind(callback)\n        await server.start_serving(\n            sockets=sockets,\n            address=address,\n            backlog=cfg.backlog,\n            sslcontext=self.sslcontext()\n        )\n        return server", "response": "Create the Server which will listen for requests."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist the currently active channels matching pattern.", "response": "def channels(self, pattern=None):\n        '''Lists the currently active channels matching ``pattern``\n        '''\n        if pattern:\n            return self.store.execute('PUBSUB', 'CHANNELS', pattern)\n        else:\n            return self.store.execute('PUBSUB', 'CHANNELS')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop listening for messages.", "response": "async def close(self):\n        '''Stop listening for messages.\n        '''\n        if self.push_connection:\n            self._execute('PUNSUBSCRIBE')\n            self._execute('UNSUBSCRIBE')\n            await self.push_connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def publish(self, channel, event, data=None):\n        msg = {'event': event, 'channel': channel}\n        if data:\n            msg['data'] = data\n        try:\n            await self.pubsub.publish(self.prefixed(channel), msg)\n        except ConnectionRefusedError:\n            self.connection_error = True\n            self.logger.critical(\n                '%s cannot publish on \"%s\" channel - connection error',\n                self,\n                channel\n            )\n        else:\n            self.connection_ok()", "response": "Publish a new event on a channel"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def close(self):\n        push_connection = self.pubsub.push_connection\n        self.status = self.statusType.closed\n        if push_connection:\n            push_connection.event('connection_lost').unbind(\n                self._connection_lost\n            )\n            await self.pubsub.close()", "response": "Close channels and underlying pubsub handler\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the : class : zset with an iterable over pairs of Scores and values.", "response": "def update(self, score_vals):\n        '''Update the :class:`zset` with an iterable over pairs of\nscores and values.'''\n        add = self.add\n        for score, value in score_vals:\n            add(score, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, item):\n        '''Remove ``item`` for the :class:`zset` it it exists.\n        If found it returns the score of the item removed.\n        '''\n        score = self._dict.pop(item, None)\n        if score is not None:\n            index = self._sl.rank(score)\n            assert index >= 0, 'could not find start range'\n            for i, v in enumerate(self._sl.range(index)):\n                if v == item:\n                    assert self._sl.remove_range(index + i, index+i + 1) == 1\n                    return score\n            assert False, 'could not find element'", "response": "Remove an item from the zset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a range by score.", "response": "def remove_range(self, start, end):\n        '''Remove a range by score.\n        '''\n        return self._sl.remove_range(\n            start, end, callback=lambda sc, value: self._dict.pop(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a range by score.", "response": "def remove_range_by_score(self, minval, maxval,\n                              include_min=True, include_max=True):\n        '''Remove a range by score.\n        '''\n        return self._sl.remove_range_by_score(\n            minval, maxval, include_min=include_min, include_max=include_max,\n            callback=lambda sc, value: self._dict.pop(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rank(self, item):\n        '''Return the rank (index) of ``item`` in this :class:`zset`.'''\n        score = self._dict.get(item)\n        if score is not None:\n            return self._sl.rank(score)", "response": "Return the rank of item in this : class : zset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to guess the filename of the given object.", "response": "def guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, 'name', None)\n    if name and name[0] != '<' and name[-1] != '>':\n        return os.path.basename(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequires by Cookies handlers", "response": "def origin_req_host(self):\n        \"\"\"Required by Cookies handlers\n        \"\"\"\n        if self.history:\n            return self.history[0].request.origin_req_host\n        else:\n            return scheme_host_port(self.url)[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode(self):\n        # Call body before fist_line in case the query is changes.\n        first_line = self.first_line()\n        if self.body and self.wait_continue:\n            self.headers['expect'] = '100-continue'\n        headers = self.headers\n        if self.unredirected_headers:\n            headers = self.unredirected_headers.copy()\n            headers.update(self.headers)\n        buffer = [first_line.encode('ascii'), b'\\r\\n']\n        buffer.extend((('%s: %s\\r\\n' % (name, value)).encode(CHARSET)\n                      for name, value in headers.items()))\n        buffer.append(b'\\r\\n')\n        return b''.join(buffer)", "response": "Returns the bytes representation of this request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the value of a header from this request s headers.", "response": "def get_header(self, header_name, default=None):\n        \"\"\"Retrieve ``header_name`` from this request headers.\n        \"\"\"\n        return self.headers.get(\n            header_name, self.unredirected_headers.get(header_name, default))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_header(self, header_name):\n        val1 = self.headers.pop(header_name, None)\n        val2 = self.unredirected_headers.pop(header_name, None)\n        return val1 or val2", "response": "Remove the header with the given name from this request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef links(self):\n        headers = self.headers or {}\n        header = headers.get('link')\n        li = {}\n        if header:\n            links = parse_header_links(header)\n            for link in links:\n                key = link.get('rel') or link.get('url')\n                li[key] = link\n        return li", "response": "Returns the parsed header links of the response if any\n        is set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text(self):\n        data = self.content\n        return data.decode(self.encoding or 'utf-8') if data else ''", "response": "Decode content as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_content(self):\n        ct = self.headers.get('content-type')\n        if ct:\n            ct, options = parse_options_header(ct)\n            charset = options.get('charset')\n            if ct in JSON_CONTENT_TYPES:\n                return self.json()\n            elif ct.startswith('text/'):\n                return self.text\n            elif ct == FORM_URL_ENCODED:\n                return parse_qsl(self.content.decode(charset),\n                                 keep_blank_values=True)\n        return self.content", "response": "Return the best possible representation of the response body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raise_for_status(self):\n        if not self.ok:\n            reason = self.reason or 'No response from %s' % self.url\n            if not self.status_code:\n                raise HttpConnectionError(reason, response=self)\n\n            if 400 <= self.status_code < 500:\n                http_error_msg = '%s Client Error - %s - %s %s' % (\n                    self.status_code, reason, self.request.method, self.url)\n            else:\n                http_error_msg = '%s Server Error - %s - %s %s' % (\n                    self.status_code, reason, self.request.method, self.url)\n\n            raise HttpRequestException(http_error_msg, response=self)", "response": "Raises stored HTTPError or HttpRequestException depending on status code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request(self, method, url, **params):\n        response = self._request(method, url, **params)\n        if not self._loop.is_running():\n            return self._loop.run_until_complete(response)\n        else:\n            return response", "response": "Constructs and sends a request to a remote server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclose all connections and return a list of all waiters.", "response": "def close(self):\n        \"\"\"Close all connections\n        \"\"\"\n        waiters = []\n        for p in self.connection_pools.values():\n            waiters.append(p.close())\n        self.connection_pools.clear()\n        return asyncio.gather(*waiters, loop=self._loop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ssl_context(self, verify=True, cert_reqs=None,\n                    check_hostname=False, certfile=None, keyfile=None,\n                    cafile=None, capath=None, cadata=None, **kw):\n        \"\"\"Create a SSL context object.\n\n        This method should not be called by from user code\n        \"\"\"\n        assert ssl, 'SSL not supported'\n        cafile = cafile or DEFAULT_CA_BUNDLE_PATH\n\n        if verify is True:\n            cert_reqs = ssl.CERT_REQUIRED\n            check_hostname = True\n\n        if isinstance(verify, str):\n            cert_reqs = ssl.CERT_REQUIRED\n            if os.path.isfile(verify):\n                cafile = verify\n            elif os.path.isdir(verify):\n                capath = verify\n\n        return ssl._create_unverified_context(cert_reqs=cert_reqs,\n                                              check_hostname=check_hostname,\n                                              certfile=certfile,\n                                              keyfile=keyfile,\n                                              cafile=cafile,\n                                              capath=capath,\n                                              cadata=cadata)", "response": "Create an SSL context object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a tunnel connection.", "response": "async def create_tunnel_connection(self, req):\n        \"\"\"Create a tunnel connection\n        \"\"\"\n        tunnel_address = req.tunnel_address\n        connection = await self.create_connection(tunnel_address)\n        response = connection.current_consumer()\n        for event in response.events().values():\n            event.clear()\n        response.start(HttpTunnel(self, req))\n        await response.event('post_request').waiter()\n        if response.status_code != 200:\n            raise ConnectionRefusedError(\n                'Cannot connect to tunnel: status code %s'\n                % response.status_code\n            )\n        raw_sock = connection.transport.get_extra_info('socket')\n        if raw_sock is None:\n            raise RuntimeError('Transport without socket')\n        # duplicate socket so we can close transport\n        raw_sock = raw_sock.dup()\n        connection.transport.close()\n        await connection.event('connection_lost').waiter()\n        self.sessions -= 1\n        self.requests_processed -= 1\n        #\n        connection = await self.create_connection(\n            sock=raw_sock, ssl=req.ssl(self), server_hostname=req.netloc\n        )\n        return connection"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_application(name):\n    actor = get_actor()\n\n    if actor:\n        if actor.is_arbiter():\n            return _get_app(actor, name, False)\n        else:\n            return _get_remote_app(actor, name)", "response": "Fetch an application associated with name if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the root directory of this : class:`Configurator`.", "response": "def root_dir(self):\n        \"\"\"Root directory of this :class:`Configurator`.\n\n        Evaluated from the :attr:`script` attribute.\n        \"\"\"\n        if self.cfg.script:\n            return os.path.dirname(self.cfg.script)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef python_path(self, script):\n        if not script:\n            try:\n                import __main__\n                script = getfile(__main__)\n            except Exception:  # pragma    nocover\n                return\n        script = os.path.realpath(script)\n        if self.cfg.get('python_path', True):\n            path = os.path.dirname(script)\n            if path not in sys.path:\n                sys.path.insert(0, path)\n        return script", "response": "Returns the real path of the python script which runs the application."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_config(self):\n        # get the actor if available and override default cfg values with those\n        # from the actor\n        actor = get_actor()\n        if actor and actor.is_running():\n            # actor available and running.\n            # Unless argv is set, skip parsing\n            if self.argv is None:\n                self.console_parsed = False\n            # copy global settings\n            self.cfg.copy_globals(actor.cfg)\n        #\n        for name in list(self.cfg.params):\n            if name in self.cfg.settings:\n                value = self.cfg.params.pop(name)\n                if value is not None:\n                    self.cfg.set(name, value)\n        # parse console args\n        if self.console_parsed:\n            self.cfg.parse_command_line(self.argv)\n        else:\n            self.cfg.params.update(self.cfg.import_from_module())", "response": "Load the application configuration from a file and the command line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, exit=True):\n        on_start = self()\n        actor = arbiter()\n        if actor and on_start:\n            actor.start(exit=exit)\n            if actor.exit_code is not None:\n                return actor.exit_code\n        return on_start", "response": "Invoked the application callable method and start\n            the arbiter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_config(cls, params, prefix=None, name=None):\n        if isinstance(cls.cfg, Config):\n            cfg = cls.cfg.copy(name=name, prefix=prefix)\n        else:\n            cfg = cls.cfg.copy()\n            if name:\n                cfg[name] = name\n            if prefix:\n                cfg[prefix] = prefix\n            cfg = Config(**cfg)\n        cfg.update_settings()\n        cfg.update(params, True)\n        return cfg", "response": "Create a new config object with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apps(self):\n        if self._apps is None:\n            # Add modified settings values to the list of cfg params\n            self.cfg.params.update(((s.name, s.value) for s in\n                                    self.cfg.settings.values() if s.modified))\n            self.cfg.settings = {}\n            self._apps = OrderedDict()\n            self._apps.update(self._build())\n            if not self._apps:\n                return []\n            # Load the configuration (command line and config file)\n            self.load_config()\n            kwargs = self._get_app_params()\n            apps = self._apps\n            self._apps = []\n            for App, name, callable, cfg in self._iter_app(apps):\n                settings = self.cfg.settings\n                new_settings = {}\n                for key in cfg:\n                    setting = settings[key].copy()\n                    if setting.orig_name and setting.orig_name != setting.name:\n                        setting.name = setting.orig_name\n                    new_settings[setting.name] = setting\n                cfg.settings = new_settings\n                kwargs.update({'name': name, 'cfg': cfg, 'callable': callable})\n                if name == self.name:\n                    params = kwargs.copy()\n                    params['version'] = self.version\n                else:\n                    params = kwargs\n                self._apps.append(App(**params))\n        return self._apps", "response": "Returns a list of all App objects for this MultiApp."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new application with the specified parameters.", "response": "def new_app(self, App, prefix=None, callable=None, **params):\n        \"\"\"Invoke this method in the :meth:`build` method as many times\n        as the number of :class:`Application` required by this\n        :class:`MultiApp`.\n\n        :param App: an :class:`Application` class.\n        :param prefix: The prefix to use for the application,\n            the prefix is appended to\n            the application :ref:`config parameters <settings>` and to the\n            application name. Each call to this method must use a different\n            value of for this parameter. It can be ``None``.\n        :param callable: optional callable (function of object) used during\n            initialisation of *App* (the :class:`Application.callable`).\n        :param params: additional key-valued parameters used when creating\n            an instance of *App*.\n        :return: a tuple used by the :meth:`apps` method.\n        \"\"\"\n        params.update(self.cfg.params)\n        params.pop('name', None)    # remove the name\n        prefix = prefix or ''\n        if not prefix and '' in self._apps:\n            prefix = App.name or App.__name__.lower()\n        if not prefix:\n            name = self.name\n            cfg = App.create_config(params, name=name)\n        else:\n            name = '%s_%s' % (prefix, self.name)\n            cfg = App.create_config(params, prefix=prefix, name=name)\n        # Add the config entry to the multi app config if not available\n        for k in cfg.settings:\n            if k not in self.cfg.settings:\n                self.cfg.settings[k] = cfg.settings[k]\n        return new_app(prefix, (App, name, callable, cfg))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting user and group of workers processes", "response": "def set_owner_process(uid, gid):\n    \"\"\" set user and group of workers processes \"\"\"\n    if gid:\n        try:\n            os.setgid(gid)\n        except OverflowError:\n            # versions of python < 2.6.2 don't manage unsigned int for\n            # groups like on osx or fedora\n            os.setgid(-ctypes.c_int(-gid).value)\n    if uid:\n        os.setuid(uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_bytes(s, encoding=None, errors=None):\n    '''Convert *s* into bytes'''\n    if not isinstance(s, bytes):\n        return ('%s' % s).encode(encoding or 'utf-8', errors or 'strict')\n    elif not encoding or encoding == 'utf-8':\n        return s\n    else:\n        d = s.decode('utf-8')\n        return d.encode(encoding, errors or 'strict')", "response": "Convert string s into bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait(value, must_be_child=False):\n    '''Wait for a possible asynchronous value to complete.\n    '''\n    current = getcurrent()\n    parent = current.parent\n    if must_be_child and not parent:\n        raise MustBeInChildGreenlet('Cannot wait on main greenlet')\n    return parent.switch(value) if parent else value", "response": "Wait for a possible asynchronous value to complete."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_response(content, code=200):\n    response = make_response( jsonify(content), content['code'] )\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    response.headers['Access-Control-Allow-Headers'] = \\\n            'Origin, X-Requested-With, Content-Type, Accept, Authorization'\n    return response", "response": "Build response, add headers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self):\n        '''return executed sql result to client.\n\n        post data format:\n\n            {\"options\": ['all', 'last', 'first', 'format'], \"sql_raw\": \"raw sql ...\"}\n\n        Returns:\n            sql result.\n        '''\n        ## format sql\n\n        data = request.get_json()\n        options, sql_raw = data.get('options'), data.get('sql_raw')\n\n        if options == 'format':\n            sql_formmated = sqlparse.format(sql_raw, keyword_case='upper', reindent=True)\n            return build_response(dict(data=sql_formmated, code=200))\n\n        elif options in ('all', 'selected'):\n            conn = SQL(config.sql_host, config.sql_port, config.sql_user,\n                       config.sql_pwd, config.sql_db)\n\n            result = conn.run(sql_raw)\n            return build_response(dict(data=result, code=200))\n        else:\n\n            pass\n\n\n\n\n\n\n\n        pass", "response": "return executed sql result to client.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an object to the redis server", "response": "def sender(obj, key, value=\"\", meta={}, force=True):\n    \"\"\"Send an object to storage[redis]. key is the obj name,\n    value is the serialized object[a dict most of the time]\n\n    Args:\n        obj: unserialized-obj need persistent in storage, currently using redis.\n             the object maybe [pandas.DataFrame, matplotlib.plt.plot, dict];\n        key: option, key to store in storage;\n        value: option, value to store in storage;\n        meta: option, meta info of the key-value in storage;\n        force: option, if true, will over-write the existing key if the key is used.\n    \"\"\"\n    suffix = '-meta'\n    # persistent key and value\n    if (key in r_kv or key + suffix in r_kv) and not force:\n        print 'Collision: key: {}, or {} exists in storage'.format(key, key + suffix)\n        return None\n\n    value = value if value else obj.to_json()\n    res = r_kv.set(key, value)\n\n    if meta:\n        res = r_kv.set(key + suffix, meta)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, page=0, size=10):\n        dash_list = r_db.zrevrange(config.DASH_ID_KEY, 0, -1, True)\n        id_list = dash_list[page * size : page * size + size]\n        dash_meta = []\n        data = []\n        if id_list:\n            dash_meta = r_db.hmget(config.DASH_META_KEY, [i[0] for i in id_list])\n            data = [json.loads(i) for i in dash_meta]\n\n        return build_response(dict(data=data, code=200))", "response": "Get the dashboard meta info from in page and size is size."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self):\n        keys = r_kv.keys()\n        keys.sort()\n        return build_response(dict(data=keys, code=200))", "response": "Get key list in storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a key - value from storage according to the key name.", "response": "def get(self, key):\n        \"\"\"Get a key-value from storage according to the key name.\n        \"\"\"\n        data = r_kv.get(key)\n        # data = json.dumps(data) if isinstance(data, str) else data\n        # data = json.loads(data) if data else {}\n\n        return build_response(dict(data=data, code=200))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, dash_id):\n        data = json.loads(r_db.hmget(config.DASH_CONTENT_KEY, dash_id)[0])\n        return build_response(dict(data=data, code=200))", "response": "Read the content of a specific dashboard."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate a dashboard meta and content. Returns a dict containing the updated content.", "response": "def put(self, dash_id=0):\n        \"\"\"Update a dash meta and content, return updated dash content.\n\n        Args:\n            dash_id: dashboard id.\n\n        Returns:\n            A dict containing the updated content of that dashboard, not include the meta info.\n        \"\"\"\n        data = request.get_json()\n        updated = self._update_dash(dash_id, data)\n        return build_response(dict(data=updated, code=200))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a dash meta and content.", "response": "def delete(self, dash_id):\n        \"\"\"Delete a dash meta and content, return updated dash content.\n\n        Actually, just remove it to a specfied place in database.\n\n        Args:\n            dash_id: dashboard id.\n\n        Returns:\n            Redirect to home page.\n        \"\"\"\n        removed_info = dict(\n            time_modified = r_db.zscore(config.DASH_ID_KEY, dash_id),\n            meta = r_db.hget(config.DASH_META_KEY, dash_id),\n            content = r_db.hget(config.DASH_CONTENT_KEY, dash_id))\n        r_db.zrem(config.DASH_ID_KEY, dash_id)\n        r_db.hdel(config.DASH_META_KEY, dash_id)\n        r_db.hdel(config.DASH_CONTENT_KEY, dash_id)\n        return {'removed_info': removed_info}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrain an LSTM encoder-decoder squence-to-sequence model on Anki flashcards for international translation >>> model = main('spa', n=400, epochs=3, batch_size=128, num_neurons=32) Train on 360 samples, validate on 40 samples Epoch 1/3 ... >>> len(model.get_weights()) 8 # 64 common characters in German, 56 in English >>> model.get_weights()[-1].shape[0] >=50 True >>> model.get_weights()[-2].shape[0] 32", "response": "def main(\n        lang='deu', n=900, epochs=50, batch_size=64, num_neurons=256,\n        encoder_input_data=None,\n        decoder_input_data=None,\n        decoder_target_data=None,\n        checkpoint_dir=os.path.join(BIGDATA_PATH, 'checkpoints'),\n        ):\n    \"\"\" Train an LSTM encoder-decoder squence-to-sequence model on Anki flashcards for international translation\n\n    >>> model = main('spa', n=400, epochs=3, batch_size=128, num_neurons=32)\n    Train on 360 samples, validate on 40 samples\n    Epoch 1/3\n    ...\n    >>> len(model.get_weights())\n    8\n\n    # 64 common characters in German, 56 in English\n    >>> model.get_weights()[-1].shape[0] >=50\n    True\n    >>> model.get_weights()[-2].shape[0]\n    32\n    \"\"\"\n    mkdir_p(checkpoint_dir)\n    encoder_input_path = os.path.join(\n        checkpoint_dir,\n        'nlpia-ch10-translate-input-{}.npy'.format(lang))\n    decoder_input_path = os.path.join(\n        checkpoint_dir,\n        'nlpia-ch10-translate-decoder-input-{}.npy'.format(lang))\n    decoder_target_path = os.path.join(\n        checkpoint_dir,\n        'nlpia-ch10-translate-target-{}.npy'.format('eng'))\n    data_paths = (encoder_input_path, decoder_input_path, decoder_target_path)\n\n    encoder_input_data = []\n    if all([os.path.isfile(p) for p in data_paths]):\n        encoder_input_data = np.load(encoder_input_path)\n        decoder_input_data = np.load(decoder_input_path)\n        decoder_target_data = np.load(decoder_target_path)\n    if len(encoder_input_data) < n:\n        encoder_input_data, decoder_input_data, decoder_target_data = onehot_char_training_data(\n            lang=lang, n=n, data_paths=data_paths)\n    encoder_input_data = encoder_input_data[:n]\n    decoder_input_data = decoder_input_data[:n] \n    decoder_target_data = decoder_target_data[:n]\n    model = fit(data_paths=data_paths, epochs=epochs, batch_size=batch_size, num_neurons=num_neurons)\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tablify(*args):\n    table = []\n    args = [listify(arg) for arg in args]\n    for row in zip(*args):\n        r = []\n        for x in row:\n            r += listify(x)\n        table += [r]\n    return table\n    return [sum([listify(el) for el in row]) for row in zip(*args)]", "response": "r Return a list of lists with the given arguments in a sorted order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the global energy for the current joint state of all nodes", "response": "def energy(self, v, h=None):\n        \"\"\"Compute the global energy for the current joint state of all nodes\n\n        >>> q11_4 = BoltzmanMachine(bv=[0., 0.], bh=[-2.], Whh=np.zeros((1, 1)), Wvv=np.zeros((2, 2)), Wvh=[[3.], [-1.]])\n        >>> q11_4.configurations()\n\n        >>> v1v2h = product([0, 1], [0, 1], [0, 1])\n        >>> E = np.array([q11_4.energy(v=x[0:2], h=[x[2]]) for x in v1v2h])\n        >>> expnegE = np.exp(-E)\n        >>> sumexpnegE = np.sum(expnegE)\n        >>> pvh = np.array([ene / sumexpnegE for ene in expnegE])\n        >>> pv = [0] * len(df)\n        >>> num_hid_states = 2 ** self.Nh\n        >>> for i in range(len(df)):\n                j = int(i / num_hid_states)\n                pv[i] = sum(pvh[k] for k in range(j * num_hid_states, (j + 1) * num_hid_states))\n        >>> pd.DataFrame(tablify(v1v2h, -E, expnegE, pvh, pv), columns='v1 v2 h -E exp(-E) p(v,h), p(v)'.split())\n        \"\"\"\n        h = np.zeros(self.Nh) if h is None else h\n        negE = np.dot(v, self.bv)\n        negE += np.dot(h, self.bh)\n        for j in range(self.Nv):\n            for i in range(j):\n                negE += v[i] * v[j] * self.Wvv[i][j]\n        for i in range(self.Nv):\n            for k in range(self.Nh):\n                negE += v[i] * h[k] * self.Wvh[i][k]\n        for l in range(self.Nh):\n            for k in range(l):\n                negE += h[k] * h[l] * self.Whh[k][l]\n        return -negE"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef energy(self):\n        s, b, W, N = self.state, self.b, self.W, self.N\n        self.E = - sum(s * b) - sum([s[i] * s[j] * W[i, j] for (i, j) in product(range(N), range(N)) if i < j])\n        self.low_energies[-1] = self.E\n        self.low_energies.sort()\n        self.high_energies[-1] = self.E\n        self.high_energies.sort()\n        self.high_energies = self.high_energies[::-1]\n        return self.E", "response": "r Compute the global energy for the current joint state of all nodes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ismatch(self, s):\n        if self._ismatchfun(s) and self._compiled_pattern.match(s):\n            return True\n        return False", "response": "like compiled_re. match but returns True or False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, text, to_template='{name} ({url})', from_template=None,\n                name_matcher=Matcher(looks_like_name), url_matcher=Matcher(r'.*[^:]+$')):\n        \"\"\" Replace all occurrences of rendered from_template in text with `template` rendered from each match.groupdict()\n\n        TODO: from_template \n\n        >>> translator = HyperlinkStyleCorrector()\n        >>> adoc = 'See http://totalgood.com[Total Good] about that.'\n        >>> translator.replace(adoc, '{scheme_type}s://', '{scheme}://')\n        'See http://totalgood.com[Total Good] about that.'\n        >>> adoc = \"Nada here:// Only a .com & no (parens.symbol) or http/[hyperlinks] or anything!\"\n        >>> translator.translate(adoc)\n        'Nada here:// Only a .com & no (parens.symbol) or http/[hyperlinks] or anything!'\n        >>> adoc = \"Two http://what.com[WAT] with https://another.com/api?q=1&a=2[longer url].\"\n        >>> translator.translate(adoc)\n        'Two WAT (http://what.com) with longer url (https://another.com/api?q=1&a=2).'\n        \"\"\"\n        self.name_matcher = name_matcher or Matcher()\n        self.url_matcher = url_matcher or Matcher()\n        matches = self.finditer(text)\n        newdoc = copy(text)\n        logger.debug('before translate: {}'.format(newdoc))\n        for m in matches:\n            # this outer m.captures() loop is overkill:\n            #   overlapping pattern matches probably won't match after the first replace\n            logger.debug('match: {}'.format(m))\n            logger.debug('match.captures(): {}'.format(m.captures()))\n            for i, captured_str in enumerate(m.captures()):\n                captureddict = {'name': None, 'scheme': None, 'url': None}\n                for k, v in m.capturesdict().items():\n                    if len(v) > i:\n                        captureddict[k] = v[i]\n                    else:\n                        captureddict[k] = None\n                        logger.warning('Overlapping captured matches were mishandled: {}'.format(m.capturesdict()))\n                # need to check for optional args:\n                name = captureddict.get('name', None)\n                url = captureddict.get('url', None)\n                scheme = captureddict.get('scheme', None)\n                if (not scheme or not name or not self.name_matcher.ismatch(name) or \n                        not url or not self.url_matcher.ismatch(url)):\n                    continue\n                if from_template:\n                    rendered_from_template = from_template.format(**captureddict)\n                else:\n                    rendered_from_template = captured_str\n                # TODO: render numbered references like r'\\1' before rendering named references\n                #    or do them together in one `.format(**kwargs)` after translating \\1 to {1} and groupsdict().update({1: ...})\n                rendered_to_template = to_template.format(**m.groupdict())\n                newdoc = newdoc.replace(rendered_from_template, rendered_to_template)\n        return newdoc", "response": "Replace all occurrences of rendered from_template in text with template rendered from each match."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate hyperlinks into printable book style for Manning Publishing", "response": "def translate(self, text, to_template='{name} ({url})', from_template=None, name_matcher=None, url_matcher=None):\n        \"\"\" Translate hyperinks into printable book style for Manning Publishing\n\n        >>> translator = HyperlinkStyleCorrector()\n        >>> adoc = 'See http://totalgood.com[Total Good] about that.'\n        >>> translator.translate(adoc)\n        'See Total Good (http://totalgood.com) about that.'\n        \"\"\"\n        return self.replace(text, to_template=to_template, from_template=from_template,\n                            name_matcher=name_matcher, url_matcher=url_matcher)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the state transition graph for a set of dialog - definition tables to find fix deadends", "response": "def main(dialogpath=None):\n    \"\"\" Parse the state transition graph for a set of dialog-definition tables to find an fix deadends \"\"\"\n    if dialogpath is None:\n        args = parse_args()\n        dialogpath = os.path.abspath(os.path.expanduser(args.dialogpath))\n    else:\n        dialogpath = os.path.abspath(os.path.expanduser(args.dialogpath))\n    return clean_csvs(dialogpath=dialogpath)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating the dialog to a list of lists of utterances.", "response": "def translate_dialog_to_lists(dialog_filename):\n    \"\"\"\n    Translates the dialog to a list of lists of utterances. In the first\n    list each item holds subsequent utterances from the same user. The second level\n    list holds the individual utterances.\n    :param dialog_filename:\n    :return:\n    \"\"\"\n\n    dialog_file = open(dialog_filename, 'r')\n    dialog_reader = unicodecsv.reader(dialog_file, delimiter='\\t', quoting=csv.QUOTE_NONE)\n\n    # go through the dialog\n    first_turn = True\n    dialog = []\n    same_user_utterances = []\n    #last_user = None\n    dialog.append(same_user_utterances)\n\n    for dialog_line in dialog_reader:\n\n        if first_turn:\n            last_user = dialog_line[1]\n            first_turn = False\n\n        if last_user != dialog_line[1]:\n            # user has changed\n            same_user_utterances = []\n            dialog.append(same_user_utterances)\n\n        same_user_utterances.append(dialog_line[3])\n\n        last_user = dialog_line[1]\n\n    dialog.append([dialog_end_symbol])\n\n    return dialog"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples multiple random utterances from the whole corpus.", "response": "def get_random_utterances_from_corpus(candidate_dialog_paths, rng, utterances_num=9, min_turn=3, max_turn=20):\n    \"\"\"\n    Sample multiple random utterances from the whole corpus.\n    :param candidate_dialog_paths:\n    :param rng:\n    :param utterances_num: number of utterances to generate\n    :param min_turn: minimal index of turn that the utterance is selected from\n    :return:\n    \"\"\"\n    utterances = []\n    dialogs_num = len(candidate_dialog_paths)\n\n    for i in xrange(0, utterances_num):\n        # sample random dialog\n        dialog_path = candidate_dialog_paths[rng.randint(0, dialogs_num - 1)]\n        # load the dialog\n        dialog = translate_dialog_to_lists(dialog_path)\n\n        # we do not count the last  _dialog_end__ urn\n        dialog_len = len(dialog) - 1\n        if(dialog_len < min_turn):\n            print \"Dialog {} was shorter than the minimum required lenght {}\".format(dialog_path, dialog_len)\n            exit()\n        # sample utterance, exclude the last round that is always \"dialog end\"\n        max_ix = min(max_turn, dialog_len) - 1\n\n        # this code deals with corner cases when dialogs are too short\n        if min_turn - 1 == max_ix:\n            turn_index = max_ix\n        else:\n            turn_index = rng.randint(min_turn, max_ix)\n\n        utterance = singe_user_utterances_to_string(dialog[turn_index])\n        utterances.append(utterance)\n    return utterances"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dialog_turns_to_string(dialog):\n    # join utterances\n    turns_as_strings = map(singe_user_utterances_to_string, dialog)\n    # join turns\n    return \"\".join(map(lambda x: x + \" \" + end_of_turn_symbol + \" \", turns_as_strings))", "response": "Translates the whole dialog to a string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a random context from a dialog.", "response": "def create_random_context(dialog, rng, minimum_context_length=2, max_context_length=20):\n    \"\"\"\n    Samples random context from a dialog. Contexts are uniformly sampled from the whole dialog.\n    :param dialog:\n    :param rng:\n    :return: context, index of next utterance that follows the context\n    \"\"\"\n    # sample dialog context\n    #context_turns = rng.randint(minimum_context_length,len(dialog)-1)\n    max_len = min(max_context_length, len(dialog)) - 2\n    if max_len <= minimum_context_length:\n        context_turns = max_len\n    else:\n        context_turns = rng.randint(minimum_context_length, max_len)\n\n    # create string\n    return dialog_turns_to_string(dialog[:context_turns]), context_turns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_single_dialog_train_example(context_dialog_path, candidate_dialog_paths, rng, positive_probability,\n                                       minimum_context_length=2, max_context_length=20):\n    \"\"\"\n    Creates a single example for training set.\n    :param context_dialog_path:\n    :param candidate_dialog_paths:\n    :param rng:\n    :param positive_probability:\n    :return:\n    \"\"\"\n\n    dialog = translate_dialog_to_lists(context_dialog_path)\n\n    context_str, next_utterance_ix = create_random_context(dialog, rng,\n                                                           minimum_context_length=minimum_context_length,\n                                                           max_context_length=max_context_length)\n\n    if positive_probability > rng.random():\n        # use the next utterance as positive example\n        response = singe_user_utterances_to_string(dialog[next_utterance_ix])\n        label = 1.0\n    else:\n        response = get_random_utterances_from_corpus(candidate_dialog_paths, rng, 1,\n                                                     min_turn=minimum_context_length + 1,\n                                                     max_turn=max_context_length)[0]\n        label = 0.0\n    return context_str, response, label", "response": "Creates a single example for training set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_examples_train(candidate_dialog_paths, rng, positive_probability=0.5, max_context_length=20):\n    i = 0\n    examples = []\n    for context_dialog in candidate_dialog_paths:\n        if i % 1000 == 0:\n            print str(i)\n        dialog_path = candidate_dialog_paths[i]\n        examples.append(create_single_dialog_train_example(dialog_path, candidate_dialog_paths, rng, positive_probability,\n                                                           max_context_length=max_context_length))\n        i += 1", "response": "Creates training examples for a single dialog."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a list of training examples from a list of dialogs and function that transforms a dialog to an example.", "response": "def create_examples(candidate_dialog_paths, examples_num, creator_function):\n    \"\"\"\n    Creates a list of training examples from a list of dialogs and function that transforms a dialog to an example.\n    :param candidate_dialog_paths:\n    :param creator_function:\n    :return:\n    \"\"\"\n    i = 0\n    examples = []\n    unique_dialogs_num = len(candidate_dialog_paths)\n\n    while i < examples_num:\n        context_dialog = candidate_dialog_paths[i % unique_dialogs_num]\n        # counter for tracking progress\n        if i % 1000 == 0:\n            print str(i)\n        i += 1\n\n        examples.append(creator_function(context_dialog, candidate_dialog_paths))\n\n    return examples"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_csv_with_dialog_paths(csv_file):\n    def convert_line_to_path(line):\n        file, dir = map(lambda x: x.strip(), line.split(\",\"))\n        return os.path.join(dir, file)\n\n    return map(convert_line_to_path, csv_file)", "response": "Converts CSV file with comma separated paths to filesystem paths."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare_data_maybe_download(directory):\n    filename = 'ubuntu_dialogs.tgz'\n    url = 'http://cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/ubuntu_dialogs.tgz'\n    dialogs_path = os.path.join(directory, 'dialogs')\n\n    # test it there are some dialogs in the path\n    if not os.path.exists(os.path.join(directory, \"10\", \"1.tst\")):\n        # dialogs are missing\n        archive_path = os.path.join(directory, filename)\n        if not os.path.exists(archive_path):\n            # archive missing, download it\n            print(\"Downloading %s to %s\" % (url, archive_path))\n            filepath, _ = urllib.request.urlretrieve(url, archive_path)\n            print \"Successfully downloaded \" + filepath\n\n        # unpack data\n        if not os.path.exists(dialogs_path):\n            print(\"Unpacking dialogs ...\")\n            with tarfile.open(archive_path) as tar:\n                tar.extractall(path=directory)\n            print(\"Archive unpacked.\")\n\n        return", "response": "Download and unpack dialogs if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line parameters as list of strings", "response": "def parse_args(args):\n    \"\"\"Parse command line parameters\n\n    Args:\n      args ([str]): command line parameters as list of strings\n\n    Returns:\n      :obj:`argparse.Namespace`: command line parameters namespace\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Just a Fibonnaci demonstration\")\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='nlpia {ver}'.format(ver=__version__))\n    parser.add_argument(\n        dest=\"n\",\n        help=\"n-th Fibonacci number\",\n        type=int,\n        metavar=\"INT\")\n    parser.add_argument(\n        '-v',\n        '--verbose',\n        dest=\"loglevel\",\n        help=\"set loglevel to INFO\",\n        action='store_const',\n        const=logging.INFO)\n    parser.add_argument(\n        '-vv',\n        '--very-verbose',\n        dest=\"loglevel\",\n        help=\"set loglevel to DEBUG\",\n        action='store_const',\n        const=logging.DEBUG)\n    return parser.parse_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optimize_feature_power(df, output_column_name=None, exponents=[2., 1., .8, .5, .25, .1, .01]):\n    output_column_name = list(df.columns)[-1] if output_column_name is None else output_column_name\n    input_column_names = [colname for colname in df.columns if output_column_name != colname]\n    results = np.zeros((len(exponents), len(input_column_names)))\n    for rownum, exponent in enumerate(exponents):\n        for colnum, column_name in enumerate(input_column_names):\n            results[rownum, colnum] = (df[output_column_name] ** exponent).corr(df[column_name])\n    results = pd.DataFrame(results, columns=input_column_names, index=pd.Series(exponents, name='power'))\n    # results.plot(logx=True)\n    return results", "response": "Plots the correlation coefficient for various exponential scalings of input features and outputs the result of the objective function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsampling vectors in X preferring edge cases and vectors farthest from other vectors in sample set", "response": "def representative_sample(X, num_samples, save=False):\n    \"\"\"Sample vectors in X, preferring edge cases and vectors farthest from other vectors in sample set\n\n\n    \"\"\"\n    X = X.values if hasattr(X, 'values') else np.array(X)\n    N, M = X.shape\n    rownums = np.arange(N)\n    np.random.shuffle(rownums)\n\n    idx = AnnoyIndex(M)\n    for i, row in enumerate(X):\n        idx.add_item(i, row)\n    idx.build(int(np.log2(N)) + 1)\n\n    if save:\n        if isinstance(save, basestring):\n            idxfilename = save\n        else:\n            idxfile = tempfile.NamedTemporaryFile(delete=False)\n            idxfile.close()\n            idxfilename = idxfile.name\n        idx.save(idxfilename)\n        idx = AnnoyIndex(M)\n        idx.load(idxfile.name)\n\n    samples = -1 * np.ones(shape=(num_samples,), dtype=int)\n    samples[0] = rownums[0]\n    # FIXME: some integer determined by N and num_samples and distribution\n    j, num_nns = 0, min(1000, int(num_samples / 2. + 1))\n    for i in rownums:\n        if i in samples:\n            continue\n        nns = idx.get_nns_by_item(i, num_nns)\n        # FIXME: pick vector furthest from past K (K > 1) points or outside of a hypercube\n        #        (sized to uniformly fill the space) around the last sample\n        samples[j + 1] = np.setdiff1d(nns, samples)[-1]\n        if len(num_nns) < num_samples / 3.:\n            num_nns = min(N, 1.3 * num_nns)\n        j += 1\n    return samples"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cosine_sim(vec1, vec2):\n    vec1 = [val for val in vec1.values()]\n    vec2 = [val for val in vec2.values()]\n    \n    dot_prod = 0\n    for i, v in enumerate(vec1):\n        dot_prod += v * vec2[i]\n        \n    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n    \n    return dot_prod / (mag_1 * mag_2)", "response": "Compute cosine similarity between two sets of vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tfidf_search(text, corpus=tfidf_dense, corpus_text=corpus):\n    tokens = tokenize(text, vocabulary=corpus.columns)\n    tfidf_vector_query = np.array(tfidfer.transform([' '.join(tokens)]).todense())[0]\n    query_series = pd.Series(tfidf_vector_query, index=corpus.columns)\n\n    return corpus_text[query_series.dot(corpus.T).values.argmax()]", "response": "search for the most relevant document in a corpus"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for the most relevant document in a corpus", "response": "def topic_search(text, corpus=doc_topic_vectors, pcaer=pcaer, corpus_text=corpus):\n    \"\"\" search for the most relevant document \"\"\"\n    tokens = tokenize(text, vocabulary=corpus.columns)\n    tfidf_vector_query = np.array(tfidfer.transform([' '.join(tokens)]).todense())[0]\n    topic_vector_query = pcaer.transform([tfidf_vector_query])\n    query_series = pd.Series(topic_vector_query, index=corpus.columns)\n    return corpus_text[query_series.dot(corpus.T).values.argmax()]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting a Linear Regression model to all X y pairs and return the model instance.", "response": "def fit(self, X, y):\n        \"\"\" Compute average slope and intercept for all X, y pairs\n\n        Arguments:\n          X (np.array): model input (independent variable)\n          y (np.array): model output (dependent variable)\n\n        Returns:\n          Linear Regression instance with `slope` and `intercept` attributes\n\n        References:\n          Based on: https://github.com/justmarkham/DAT4/blob/master/notebooks/08_linear_regression.ipynb\n\n        >>> n_samples = 100\n        >>> X = np.arange(100).reshape((n_samples, 1))\n        >>> slope, intercept = 3.14159, -4.242\n        >>> y = 3.14 * X + np.random.randn(*X.shape) + intercept\n        >>> line = LinearRegressor()\n        >>> line.fit(X, y)\n        <nlpia.models.LinearRegressor object ...\n        >>> abs(line.slope - slope) < abs(0.02 * (slope + 1))\n        True\n        >>> abs(line.intercept - intercept) < 0.2 * (abs(intercept) + 1)\n        True\n        \"\"\"\n\n        # initial sums\n        n = float(len(X))\n        sum_x = X.sum()\n        sum_y = y.sum()\n        sum_xy = (X * y).sum()\n        sum_xx = (X**2).sum()\n\n        # formula for w0\n        self.slope = (sum_xy - (sum_x * sum_y) / n) / (sum_xx - (sum_x * sum_x) / n)\n\n        # formula for w1\n        self.intercept = sum_y / n - self.slope * (sum_x / n)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the model to the data X y", "response": "def fit(self, X, y, n_iter=None):\n        \"\"\"w = w + \u03b1 * \u03b4 * X\"\"\"\n        self.n_iter = self.n_iter if n_iter is None else n_iter\n        X = getattr(X, 'values', X).reshape(len(X), 1)\n        X_1 = self.homogenize(X)\n        for i in range(self.n_iter):\n            for i in range(0, len(X), 10):  # minibatch learning for numerical stability\n                batch = slice(i, min(i + 10, len(X)))\n                Xbatch, ybatch = X[batch, :], y[batch]\n                X_1_batch = X_1[batch, :]\n                self.W += (self.alpha / len(X) ** 1.5) * (\n                    self.delta(Xbatch, ybatch).reshape((len(Xbatch), 1)).T.dot(X_1_batch))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef looks_like_url(url):\n    if not isinstance(url, basestring):\n        return False\n    if not isinstance(url, basestring) or len(url) >= 1024 or not cre_url.match(url):\n        return False\n    return True", "response": "Simplified check to see if the text appears to be a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to parse a URL returning None on exception", "response": "def try_parse_url(url):\n    \"\"\" User urlparse to try to parse URL returning None on exception \"\"\"\n    if len(url.strip()) < 4:\n        logger.info('URL too short: {}'.format(url))\n        return None\n    try:\n        parsed_url = urlparse(url)\n    except ValueError:\n        logger.info('Parse URL ValueError: {}'.format(url))\n        return None\n    if parsed_url.scheme:\n        return parsed_url\n    try:\n        parsed_url = urlparse('http://' + parsed_url.geturl())\n    except ValueError:\n        logger.info('Invalid URL for assumed http scheme: urlparse(\"{}\") from \"{}\" '.format('http://' + parsed_url.geturl(), url))\n        return None\n    if not parsed_url.scheme:\n        logger.info('Unable to guess a scheme for URL: {}'.format(url))\n        return None\n    return parsed_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequests HTML for the page at the URL indicated and return the url filename remote size remote size and basename and filename attributes.", "response": "def get_url_filemeta(url):\n    \"\"\" Request HTML for the page at the URL indicated and return the url, filename, and remote size\n\n    TODO: just add remote_size and basename and filename attributes to the urlparse object\n          instead of returning a dict\n\n    >>> sorted(get_url_filemeta('mozilla.com').items())\n    [('filename', ''),\n     ('hostname', 'mozilla.com'),\n     ('path', ''),\n     ('remote_size', -1),\n     ('url', 'http://mozilla.com'),\n     ('username', None)]\n    >>> sorted(get_url_filemeta('https://duckduckgo.com/about?q=nlp').items())\n    [('filename', 'about'),\n     ('hostname', 'duckduckgo.com'),\n     ('path', '/about'),\n     ('remote_size', -1),\n     ('url', 'https://duckduckgo.com/about?q=nlp'),\n     ('username', None)]\n    >>> 1000 <= int(get_url_filemeta('en.wikipedia.org')['remote_size']) <= 200000\n    True\n    \"\"\"\n    parsed_url = try_parse_url(url)\n\n    if parsed_url is None:\n        return None\n    if parsed_url.scheme.startswith('ftp'):\n        return get_ftp_filemeta(parsed_url)\n\n    url = parsed_url.geturl()\n    try:\n        r = requests.get(url, stream=True, allow_redirects=True, timeout=5)\n        remote_size = r.headers.get('Content-Length', -1)\n        return dict(url=url, hostname=parsed_url.hostname, path=parsed_url.path,\n                    username=parsed_url.username, remote_size=remote_size,\n                    filename=os.path.basename(parsed_url.path))\n    except ConnectionError:\n        return None\n    except (InvalidURL, InvalidSchema, InvalidHeader, MissingSchema):\n        return None\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_url_title(url):\n    parsed_url = try_parse_url(url)\n    if parsed_url is None:\n        return None\n    try:\n        r = requests.get(parsed_url.geturl(), stream=False, allow_redirects=True, timeout=5)\n        tree = parse_html(r.content)\n        title = tree.findtext('.//title')\n        return title\n    except ConnectionError:\n        logging.error('Unable to connect to internet to retrieve URL {}'.format(parsed_url.geturl()))\n        logging.error(format_exc())\n    except (InvalidURL, InvalidSchema, InvalidHeader, MissingSchema):\n        logging.warn('Unable to retrieve URL {}'.format(parsed_url.geturl()))\n        logging.error(format_exc())", "response": "Request HTML for the URL indicated and return it s title property"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_url_filename(url=None, driveid=None):\n    url = url or 'https://drive.google.com/open?id={}'.format(driveid)\n    if url.startswith('https://drive.google.com'):\n        filename = get_url_title(url)\n        if filename.endswith('Google Drive'):\n            filename = filename[:-len('Google Drive')].rstrip().rstrip('-:').rstrip()\n        return filename\n    logger.warn('Unable to find filename for the URL \"{}\"'.format(url))", "response": "r Get the filename associated with a google drive driveid or drive. google. com URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the content of the response to a file.", "response": "def save_response_content(response, filename='data.csv', destination=os.path.curdir, chunksize=32768):\n    \"\"\" For streaming response from requests, download the content one CHUNK at a time \"\"\"\n    chunksize = chunksize or 32768\n    if os.path.sep in filename:\n        full_destination_path = filename\n    else:\n        full_destination_path = os.path.join(destination, filename)\n    full_destination_path = expand_filepath(full_destination_path)\n    with open(full_destination_path, \"wb\") as f:\n        for chunk in tqdm(response.iter_content(CHUNK_SIZE)):\n            if chunk:  # filter out keep-alive new chunks\n                f.write(chunk)\n    return full_destination_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_file_from_google_drive(driveid, filename=None, destination=os.path.curdir):\n    if '&id=' in driveid:\n        # https://drive.google.com/uc?export=download&id=0BwmD_VLjROrfM1BxdkxVaTY2bWs  # dailymail_stories.tgz\n        driveid = driveid.split('&id=')[-1]\n    if '?id=' in driveid:\n        # 'https://drive.google.com/open?id=14mELuzm0OvXnwjb0mzAiG-Ake9_NP_LQ'  # SSD pretrainined keras model\n        driveid = driveid.split('?id=')[-1]\n\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params={'id': driveid}, stream=True)\n    token = get_response_confirmation_token(response)\n\n    if token:\n        params = {'id': driveid, 'confirm': token}\n        response = session.get(URL, params=params, stream=True)\n\n    filename = filename or get_url_filename(driveid=driveid)\n\n    full_destination_path = save_response_content(response, filename=fileanme, destination=destination)\n\n    return os.path.abspath(destination)", "response": "Download file from Google drive."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dropbox_basename(url):\n    filename = os.path.basename(url)\n    match = re.findall(r'\\?dl=[0-9]$', filename)\n    if match:\n        return filename[:-len(match[0])]\n    return filename", "response": "Strip off the dl = 0 suffix from dropbox links\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates random integer sequences from the specified length from the specified length_to and the specified vocabulary.", "response": "def random_sequences(length_from, length_to,\n                     vocab_lower, vocab_upper,\n                     batch_size):\n    \"\"\" Generates batches of random integer sequences,\n        sequence length in [length_from, length_to],\n        vocabulary in [vocab_lower, vocab_upper]\n    \"\"\"\n    if length_from > length_to:\n            raise ValueError('length_from > length_to')\n\n    def random_length():\n        if length_from == length_to:\n            return length_from\n        return np.random.randint(length_from, length_to + 1)\n    \n    while True:\n        yield [\n            np.random.randint(low=vocab_lower,\n                              high=vocab_upper,\n                              size=random_length()).tolist()\n            for _ in range(batch_size)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the greeting string Hi Hello or Yo if it occurs at the beginning of a string", "response": "def find_greeting(s):\n    \"\"\" Return the the greeting string Hi, Hello, or Yo if it occurs at the beginning of a string\n\n    >>> find_greeting('Hi Mr. Turing!')\n    'Hi'\n    >>> find_greeting('Hello, Rosa.')\n    'Hello'\n    >>> find_greeting(\"Yo, what's up?\")\n    'Yo'\n    >>> find_greeting(\"Hello\")\n    'Hello'\n    >>> print(find_greeting(\"hello\"))\n    None\n    >>> print(find_greeting(\"HelloWorld\"))\n    None\n    \"\"\"\n    if s[0] == 'H':\n        if s[:3] in ['Hi', 'Hi ', 'Hi,', 'Hi!']:\n            return s[:2]\n        elif s[:6] in ['Hello', 'Hello ', 'Hello,', 'Hello!']:\n            return s[:5]\n    elif s[0] == 'Y':\n        if s[1] == 'o' and s[:3] in ['Yo', 'Yo,', 'Yo ', 'Yo!']:\n            return s[:2]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a float for the sentiment strength based on the input text.", "response": "def sentiment(text):\r\n    \"\"\"\r\n    Returns a float for sentiment strength based on the input text.\r\n    Positive values are positive valence, negative value are negative valence.\r\n    \"\"\"\r\n    sentiment.valence_dict = load_valence_dict() if sentiment.valence_dict is None else sentiment_valence_dict\r\n    wordsAndEmoticons = str(text).split() #doesn't separate words from adjacent punctuation (keeps emoticons & contractions)\r\n    text_mod = regex_remove_punctuation.sub('', text) # removes punctuation (but loses emoticons & contractions)\r\n    wordsOnly = str(text_mod).split()\r\n    # get rid of empty items or single letter \"words\" like 'a' and 'I' from wordsOnly\r\n    for word in wordsOnly:\r\n        if len(word) <= 1:\r\n            wordsOnly.remove(word)    \r\n    # now remove adjacent & redundant punctuation from [wordsAndEmoticons] while keeping emoticons and contractions\r\n    puncList = [\".\", \"!\", \"?\", \",\", \";\", \":\", \"-\", \"'\", \"\\\"\", \r\n                \"!!\", \"!!!\", \"??\", \"???\", \"?!?\", \"!?!\", \"?!?!\", \"!?!?\"] \r\n    for word in wordsOnly:\r\n        for p in puncList:\r\n            pword = p + word\r\n            x1 = wordsAndEmoticons.count(pword)\r\n            while x1 > 0:\r\n                i = wordsAndEmoticons.index(pword)\r\n                wordsAndEmoticons.remove(pword)\r\n                wordsAndEmoticons.insert(i, word)\r\n                x1 = wordsAndEmoticons.count(pword)\r\n            \r\n            wordp = word + p\r\n            x2 = wordsAndEmoticons.count(wordp)\r\n            while x2 > 0:\r\n                i = wordsAndEmoticons.index(wordp)\r\n                wordsAndEmoticons.remove(wordp)\r\n                wordsAndEmoticons.insert(i, word)\r\n                x2 = wordsAndEmoticons.count(wordp)\r\n    # get rid of residual empty items or single letter \"words\" like 'a' and 'I' from wordsAndEmoticons\r\n    for word in wordsAndEmoticons:\r\n        if len(word) <= 1:\r\n            wordsAndEmoticons.remove(word)\r\n    \r\n    # remove stopwords from [wordsAndEmoticons]\r\n    #stopwords = [str(word).strip() for word in open('stopwords.txt')]\r\n    #for word in wordsAndEmoticons:\r\n    #    if word in stopwords:\r\n    #        wordsAndEmoticons.remove(word)\r\n    \r\n    # check for negation\r\n    negate = [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\r\n              \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\r\n              \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\r\n              \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\r\n              \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\", \r\n              \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\r\n              \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",  \r\n              \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\r\n    def negated(list, nWords=[], includeNT=True):\r\n        nWords.extend(negate)\r\n        for word in nWords:\r\n            if word in list:\r\n                return True\r\n        if includeNT:\r\n            for word in list:\r\n                if \"n't\" in word:\r\n                    return True\r\n        if \"least\" in list:\r\n            i = list.index(\"least\")\r\n            if i > 0 and list[i-1] != \"at\":\r\n                return True\r\n        return False\r\n        \r\n    def normalize(score, alpha=15):\r\n        # normalize the score to be between -1 and 1 using an alpha that approximates the max expected value \r\n        normScore = score/math.sqrt( ((score*score) + alpha) )\r\n        return normScore\r\n    \r\n    def wildCardMatch(patternWithWildcard, listOfStringsToMatchAgainst):\r\n        listOfMatches = fnmatch.filter(listOfStringsToMatchAgainst, patternWithWildcard)\r\n        return listOfMatches\r\n        \r\n    \r\n    def isALLCAP_differential(wordList):\r\n        countALLCAPS= 0\r\n        for w in wordList:\r\n            if str(w).isupper(): \r\n                countALLCAPS += 1\r\n        cap_differential = len(wordList) - countALLCAPS\r\n        if cap_differential > 0 and cap_differential < len(wordList):\r\n            isDiff = True\r\n        else: isDiff = False\r\n        return isDiff\r\n    isCap_diff = isALLCAP_differential(wordsAndEmoticons)\r\n    \r\n    b_incr = 0.293 #(empirically derived mean sentiment intensity rating increase for booster words)\r\n    b_decr = -0.293\r\n    # booster/dampener 'intensifiers' or 'degree adverbs' http://en.wiktionary.org/wiki/Category:English_degree_adverbs\r\n    booster_dict = {\"absolutely\": b_incr, \"amazingly\": b_incr, \"awfully\": b_incr, \"completely\": b_incr, \"considerably\": b_incr, \r\n                    \"decidedly\": b_incr, \"deeply\": b_incr, \"effing\": b_incr, \"enormously\": b_incr, \r\n                    \"entirely\": b_incr, \"especially\": b_incr, \"exceptionally\": b_incr, \"extremely\": b_incr,\r\n                    \"fabulously\": b_incr, \"flipping\": b_incr, \"flippin\": b_incr, \r\n                    \"fricking\": b_incr, \"frickin\": b_incr, \"frigging\": b_incr, \"friggin\": b_incr, \"fully\": b_incr, \"fucking\": b_incr, \r\n                    \"greatly\": b_incr, \"hella\": b_incr, \"highly\": b_incr, \"hugely\": b_incr, \"incredibly\": b_incr, \r\n                    \"intensely\": b_incr, \"majorly\": b_incr, \"more\": b_incr, \"most\": b_incr, \"particularly\": b_incr, \r\n                    \"purely\": b_incr, \"quite\": b_incr, \"really\": b_incr, \"remarkably\": b_incr, \r\n                    \"so\": b_incr,  \"substantially\": b_incr, \r\n                    \"thoroughly\": b_incr, \"totally\": b_incr, \"tremendously\": b_incr, \r\n                    \"uber\": b_incr, \"unbelievably\": b_incr, \"unusually\": b_incr, \"utterly\": b_incr, \r\n                    \"very\": b_incr, \r\n                    \r\n                    \"almost\": b_decr, \"barely\": b_decr, \"hardly\": b_decr, \"just enough\": b_decr, \r\n                    \"kind of\": b_decr, \"kinda\": b_decr, \"kindof\": b_decr, \"kind-of\": b_decr,\r\n                    \"less\": b_decr, \"little\": b_decr, \"marginally\": b_decr, \"occasionally\": b_decr, \"partly\": b_decr, \r\n                    \"scarcely\": b_decr, \"slightly\": b_decr, \"somewhat\": b_decr, \r\n                    \"sort of\": b_decr, \"sorta\": b_decr, \"sortof\": b_decr, \"sort-of\": b_decr}\r\n    sentiments = []\r\n    for item in wordsAndEmoticons:\r\n        v = 0\r\n        i = wordsAndEmoticons.index(item)\r\n        if (i < len(wordsAndEmoticons)-1 and str(item).lower() == \"kind\" and \\\r\n           str(wordsAndEmoticons[i+1]).lower() == \"of\") or str(item).lower() in booster_dict:\r\n            sentiments.append(v)\r\n            continue\r\n        item_lowercase = str(item).lower() \r\n        if  item_lowercase in sentiment.valence_dict:\r\n            #get the sentiment valence\r\n            v = float(sentiment.valence_dict[item_lowercase])\r\n            \r\n            #check if sentiment laden word is in ALLCAPS (while others aren't)\r\n            c_incr = 0.733 #(empirically derived mean sentiment intensity rating increase for using ALLCAPs to emphasize a word)\r\n            if str(item).isupper() and isCap_diff:\r\n                if v > 0: v += c_incr\r\n                else: v -= c_incr\r\n            \r\n            #check if the preceding words increase, decrease, or negate/nullify the valence\r\n            def scalar_inc_dec(word, valence):\r\n                scalar = 0.0\r\n                word_lower = str(word).lower()\r\n                if word_lower in booster_dict:\r\n                    scalar = booster_dict[word_lower]\r\n                    if valence < 0: scalar *= -1\r\n                    #check if booster/dampener word is in ALLCAPS (while others aren't)\r\n                    if str(word).isupper() and isCap_diff:\r\n                        if valence > 0: scalar += c_incr\r\n                        else:  scalar -= c_incr\r\n                return scalar\r\n            n_scalar = -0.74\r\n            if i > 0 and str(wordsAndEmoticons[i-1]).lower() not in sentiment.valence_dict:\r\n                s1 = scalar_inc_dec(wordsAndEmoticons[i-1], v)\r\n                v = v+s1\r\n                if negated([wordsAndEmoticons[i-1]]): v = v*n_scalar\r\n            if i > 1 and str(wordsAndEmoticons[i-2]).lower() not in sentiment.valence_dict:\r\n                s2 = scalar_inc_dec(wordsAndEmoticons[i-2], v)\r\n                if s2 != 0: s2 = s2*0.95\r\n                v = v+s2\r\n                # check for special use of 'never' as valence modifier instead of negation\r\n                if wordsAndEmoticons[i-2] == \"never\" and (wordsAndEmoticons[i-1] == \"so\" or wordsAndEmoticons[i-1] == \"this\"): \r\n                    v = v*1.5                    \r\n                # otherwise, check for negation/nullification\r\n                elif negated([wordsAndEmoticons[i-2]]): v = v*n_scalar\r\n            if i > 2 and str(wordsAndEmoticons[i-3]).lower() not in sentiment.valence_dict:\r\n                s3 = scalar_inc_dec(wordsAndEmoticons[i-3], v)\r\n                if s3 != 0: s3 = s3*0.9\r\n                v = v+s3\r\n                # check for special use of 'never' as valence modifier instead of negation\r\n                if wordsAndEmoticons[i-3] == \"never\" and \\\r\n                   (wordsAndEmoticons[i-2] == \"so\" or wordsAndEmoticons[i-2] == \"this\") or \\\r\n                   (wordsAndEmoticons[i-1] == \"so\" or wordsAndEmoticons[i-1] == \"this\"):\r\n                    v = v*1.25\r\n                # otherwise, check for negation/nullification\r\n                elif negated([wordsAndEmoticons[i-3]]): v = v*n_scalar\r\n                \r\n                # check for special case idioms using a sentiment-laden keyword known to SAGE\r\n                special_case_idioms = {\"the shit\": 3, \"the bomb\": 3, \"bad ass\": 1.5, \"yeah right\": -2, \r\n                                       \"cut the mustard\": 2, \"kiss of death\": -1.5, \"hand to mouth\": -2}\r\n                # future work: consider other sentiment-laden idioms\r\n                #other_idioms = {\"back handed\": -2, \"blow smoke\": -2, \"blowing smoke\": -2, \"upper hand\": 1, \"break a leg\": 2, \r\n                #                \"cooking with gas\": 2, \"in the black\": 2, \"in the red\": -2, \"on the ball\": 2,\"under the weather\": -2}\r\n                onezero = \"{} {}\".format(str(wordsAndEmoticons[i-1]), str(wordsAndEmoticons[i]))\r\n                twoonezero = \"{} {}\".format(str(wordsAndEmoticons[i-2]), str(wordsAndEmoticons[i-1]), str(wordsAndEmoticons[i]))\r\n                twoone = \"{} {}\".format(str(wordsAndEmoticons[i-2]), str(wordsAndEmoticons[i-1]))\r\n                threetwoone = \"{} {} {}\".format(str(wordsAndEmoticons[i-3]), str(wordsAndEmoticons[i-2]), str(wordsAndEmoticons[i-1]))\r\n                threetwo = \"{} {}\".format(str(wordsAndEmoticons[i-3]), str(wordsAndEmoticons[i-2]))                    \r\n                if onezero in special_case_idioms: v = special_case_idioms[onezero]\r\n                elif twoonezero in special_case_idioms: v = special_case_idioms[twoonezero]\r\n                elif twoone in special_case_idioms: v = special_case_idioms[twoone]\r\n                elif threetwoone in special_case_idioms: v = special_case_idioms[threetwoone]\r\n                elif threetwo in special_case_idioms: v = special_case_idioms[threetwo]\r\n                if len(wordsAndEmoticons)-1 > i:\r\n                    zeroone = \"{} {}\".format(str(wordsAndEmoticons[i]), str(wordsAndEmoticons[i+1]))\r\n                    if zeroone in special_case_idioms: v = special_case_idioms[zeroone]\r\n                if len(wordsAndEmoticons)-1 > i+1:\r\n                    zeroonetwo = \"{} {}\".format(str(wordsAndEmoticons[i]), str(wordsAndEmoticons[i+1]), str(wordsAndEmoticons[i+2]))\r\n                    if zeroonetwo in special_case_idioms: v = special_case_idioms[zeroonetwo]\r\n                \r\n                # check for booster/dampener bi-grams such as 'sort of' or 'kind of'\r\n                if threetwo in booster_dict or twoone in booster_dict:\r\n                    v = v+b_decr\r\n            \r\n            # check for negation case using \"least\"\r\n            if i > 1 and str(wordsAndEmoticons[i-1]).lower() not in sentiment.valence_dict \\\r\n                and str(wordsAndEmoticons[i-1]).lower() == \"least\":\r\n                if (str(wordsAndEmoticons[i-2]).lower() != \"at\" and str(wordsAndEmoticons[i-2]).lower() != \"very\"):\r\n                    v = v*n_scalar\r\n            elif i > 0 and str(wordsAndEmoticons[i-1]).lower() not in sentiment.valence_dict \\\r\n                and str(wordsAndEmoticons[i-1]).lower() == \"least\":\r\n                v = v*n_scalar\r\n        sentiments.append(v) \r\n            \r\n    # check for modification in sentiment due to contrastive conjunction 'but'\r\n    if 'but' in wordsAndEmoticons or 'BUT' in wordsAndEmoticons:\r\n        try: bi = wordsAndEmoticons.index('but')\r\n        except: bi = wordsAndEmoticons.index('BUT')\r\n        for s in sentiments:\r\n            si = sentiments.index(s)\r\n            if si < bi: \r\n                sentiments.pop(si)\r\n                sentiments.insert(si, s*0.5)\r\n            elif si > bi: \r\n                sentiments.pop(si)\r\n                sentiments.insert(si, s*1.5) \r\n                \r\n    if sentiments:                      \r\n        sum_s = float(sum(sentiments))\r\n        #print sentiments, sum_s\r\n        \r\n        # check for added emphasis resulting from exclamation points (up to 4 of them)\r\n        ep_count = str(text).count(\"!\")\r\n        if ep_count > 4: ep_count = 4\r\n        ep_amplifier = ep_count*0.292 #(empirically derived mean sentiment intensity rating increase for exclamation points)\r\n        if sum_s > 0:  sum_s += ep_amplifier\r\n        elif  sum_s < 0: sum_s -= ep_amplifier\r\n        \r\n        # check for added emphasis resulting from question marks (2 or 3+)\r\n        qm_count = str(text).count(\"?\")\r\n        qm_amplifier = 0\r\n        if qm_count > 1:\r\n            if qm_count <= 3: qm_amplifier = qm_count*0.18\r\n            else: qm_amplifier = 0.96\r\n            if sum_s > 0:  sum_s += qm_amplifier\r\n            elif  sum_s < 0: sum_s -= qm_amplifier\r\n\r\n        compound = normalize(sum_s)\r\n        \r\n        # want separate positive versus negative sentiment scores\r\n        pos_sum = 0.0\r\n        neg_sum = 0.0\r\n        neu_count = 0\r\n        for sentiment_score in sentiments:\r\n            if sentiment_score > 0:\r\n                pos_sum += (float(sentiment_score) +1) # compensates for neutral words that are counted as 1\r\n            if sentiment_score < 0:\r\n                neg_sum += (float(sentiment_score) -1) # when used with math.fabs(), compensates for neutrals\r\n            if sentiment_score == 0:\r\n                neu_count += 1\r\n        \r\n        if pos_sum > math.fabs(neg_sum): pos_sum += (ep_amplifier+qm_amplifier)\r\n        elif pos_sum < math.fabs(neg_sum): neg_sum -= (ep_amplifier+qm_amplifier)\r\n        \r\n        total = pos_sum + math.fabs(neg_sum) + neu_count\r\n        pos = math.fabs(pos_sum / total)\r\n        neg = math.fabs(neg_sum / total)\r\n        neu = math.fabs(neu_count / total)\r\n    else:\r\n        compound, pos, neg, neu = 0., 0., 0., 0.\r\n\r\n    s = {\"neg\" : round(neg, 3),\r\n         \"neu\" : round(neu, 3),\r\n         \"pos\" : round(pos, 3),\r\n         \"compound\" : round(compound, 4)}\r\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef record_audio(source='Microphone', energy_threshold=300, pause_threshold=.9,\n                 dynamic_energy_ratio=1.5, dynamic_energy_adjustment_damping=.15, **kwargs):\n    \"\"\" Listten for a single utterance (concluded with a 2 sec pause) and return a recording in an Audio object\n\n    Arguments:\n        energy_threshold (int): minimum audio energy to trigger start of recording (default=300)\n        dynamic_energy_adjustment_damping (float): dyn thresh adjustment slowness: 1=static energy_threshold (.15)\n        dynamic_energy_ratio (float): sound energy change that triggers recording: 1=static energy_threshold (1.5)\n        pause_threshold (float): non-speaking audio seconds before a phrase is considered complete (.9)\n        operation_timeout (float): internal operation timeout in seconds: None=never\n        self.phrase_threshold (float): minimum speaking duration in seconds to record (.3)\n        self.non_speaking_duration (float): nonspeaking audio seconds to retain before+after recording (pause_threshold)\n \"\"\"\n    r = sr.Recognizer()\n    r.energy_threshold = energy_threshold\n    r.pause_threshold = pause_threshold\n    r.dynamic_energy_threshold = dynamic_energy_ratio > 1 and dynamic_energy_adjustment_damping < 1\n    r.dynamic_energy_ratio = dynamic_energy_ratio\n    r.dynamic_energy_adjustment_damping = dynamic_energy_adjustment_damping\n    r.__dict__.update(kwargs)\n    with getattr(sr, 'Microphone', sr.Microphone)() as audio_source:\n        audio = r.listen(source=audio_source)\n    return audio", "response": "Listten for a single utterance and return a recording in an Audio object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef file_to_list(in_file):\n    ''' Reads file into list '''\n    lines = []\n    for line in in_file:\n        # Strip new line\n        line = line.strip('\\n')\n\n        # Ignore empty lines\n        if line != '':\n            # Ignore comments\n            if line[0] != '#':\n                lines.append(line)\n\n    return lines", "response": "Reads file into list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating prefixes or suffixes in a short form to parse and remove some redundancy", "response": "def generate_add_sub(self):\n        ''' Generates prefixes/suffixes in a short form to parse and remove some redundancy '''\n        # Prefix or Suffix\n        affix_type = 'p:' if self.opt == \"PFX\" else 's:'\n        remove_char = '-' + self.char_to_strip if self.char_to_strip != '' else ''\n\n        return affix_type + remove_char + '+' + self.affix"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the derivative of the base word by adding any affixes that apply", "response": "def create_derivative(self, word):\n        ''' Creates derivative of (base) word by adding any affixes that apply '''\n        result = None\n        if self.char_to_strip != '':\n            if self.opt == \"PFX\":\n                result = word[len(self.char_to_strip):len(word)]\n                result = self.affix + result \n            else: # SFX\n                result = word[0:len(word) - len(self.char_to_strip)]\n                result = result + self.affix\n        else: # No characters to strip\n            if self.opt == \"PFX\":\n                result = self.affix + word\n            else: # SFX\n                result = word + self.affix\n\n        # None means word does not meet the set condition\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd flag value to applicable compounds", "response": "def add_flag_values(self, entry, flag):\n        ''' Adds flag value to applicable compounds '''\n        if flag in self.flags:\n            self.flags[flag].append(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_regex(self):\n        ''' Generates and returns compound regular expression '''\n        regex = ''\n        for flag in self.compound:\n            if flag == '?' or flag == '*':\n                regex += flag\n            else:\n                regex += '(' + '|'.join(self.flags[flag]) + ')'\n\n        return regex", "response": "Generates and returns compound regular expression"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __parse_dict(self):\n        ''' Parses dictionary with according rules '''\n        i = 0\n        lines = self.lines\n\n        for line in lines:\n            line = line.split('/')\n            word = line[0]\n            flags = line[1] if len(line) > 1 else None\n\n            # Base Word\n            self.num_words += 1\n\n            if flags != None:\n                # Derivatives possible\n                for flag in flags:\n                    # Compound?\n                    if flag in self.aff.compound_flags or flag == self.aff.only_in_compound_flag:\n                        for rule in self.aff.compound_rules:\n                            rule.add_flag_values(word, flag)\n                    else:\n                        # No Suggest flags\n                        if self.aff.no_suggest_flag == flag:\n                            pass\n                        else:\n                            affix_rule_entries = self.aff.affix_rules[flag]\n                            # Get flag that meets condition\n                            for i in range(len(affix_rule_entries)):\n                                rule = affix_rule_entries[i]\n\n                                if rule.meets_condition(word):\n                                    # Add word to list if does not already exist\n                                    if word not in self.words:\n                                        self.words[word] = []\n\n                                    # Derivatives\n                                    self.num_words += 1\n\n                                    if self.format == \"addsub\":\n                                        add_sub = rule.generate_add_sub()\n\n                                        # Add to list of keys\n                                        if add_sub not in self.keys:\n                                            self.keys.append(add_sub)\n\n                                        # Check if key is to be generated\n                                        if self.key:\n                                            self.words[word].append(str(self.keys.index(add_sub)))\n                                        else:\n                                            # Generate addsub next to base word\n                                            self.words[word].append(rule.generate_add_sub())\n                                    else:\n                                        # Default, insert complete derivative word\n                                        self.words[word].append(rule.create_derivative(word))\n            else:\n                # No derivatives.\n                self.words[word] = []\n\n        # Create regular expression from compounds\n        for rule in self.aff.compound_rules:\n            # Add to list\n            self.regex_compounds.append(rule.get_regex())", "response": "Parses the dictionary with according rules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload IMDB review data from directory tree.", "response": "def load_imdb_df(dirpath=os.path.join(BIGDATA_PATH, 'aclImdb'), subdirectories=(('train', 'test'), ('pos', 'neg', 'unsup'))):\n    \"\"\" Walk directory tree starting at `path` to compile a DataFrame of movie review text labeled with their 1-10 star ratings\n\n    Returns:\n      DataFrame: columns=['url', 'rating', 'text'], index=MultiIndex(['train_test', 'pos_neg_unsup', 'id'])\n\n    TODO:\n      Make this more robust/general by allowing the subdirectories to be None and find all the subdirs containing txt files\n\n    >> imdb_df().head()\n                                                          url  rating                                               text\n    index0 index1 index2\n    train  pos    0       http://www.imdb.com/title/tt0453418       9  Bromwell High is a cartoon comedy. It ran at t...\n                  1       http://www.imdb.com/title/tt0210075       7  If you like adult comedy cartoons, like South ...\n                  2       http://www.imdb.com/title/tt0085688       9  Bromwell High is nothing short of brilliant. E...\n                  3       http://www.imdb.com/title/tt0033022      10  \"All the world's a stage and its people actors...\n                  4       http://www.imdb.com/title/tt0043137       8  FUTZ is the only show preserved from the exper...\n    \"\"\"\n    dfs = {}\n    for subdirs in tqdm(list(product(*subdirectories))):\n        urlspath = os.path.join(dirpath, subdirs[0], 'urls_{}.txt'.format(subdirs[1]))\n        if not os.path.isfile(urlspath):\n            if subdirs != ('test', 'unsup'):  # test/ dir doesn't usually have an unsup subdirectory\n                logger.warning('Unable to find expected IMDB review list of URLs: {}'.format(urlspath))\n            continue\n        df = pd.read_csv(urlspath, header=None, names=['url'])\n        # df.index.name = 'id'\n        df['url'] = series_strip(df.url, endswith='/usercomments')\n\n        textsdir = os.path.join(dirpath, subdirs[0], subdirs[1])\n        if not os.path.isdir(textsdir):\n            logger.warning('Unable to find expected IMDB review text subdirectory: {}'.format(textsdir))\n            continue\n        filenames = [fn for fn in os.listdir(textsdir) if fn.lower().endswith('.txt')]\n        df['index0'] = subdirs[0]  # TODO: column names more generic so will work on other datasets\n        df['index1'] = subdirs[1]\n        df['index2'] = np.array([int(fn[:-4].split('_')[0]) for fn in filenames])\n        df['rating'] = np.array([int(fn[:-4].split('_')[1]) for fn in filenames])\n        texts = []\n        for fn in filenames:\n            with ensure_open(os.path.join(textsdir, fn)) as f:\n                texts.append(f.read())\n        df['text'] = np.array(texts)\n        del texts\n        df.set_index('index0 index1 index2'.split(), inplace=True)\n        df.sort_index(inplace=True)\n        dfs[subdirs] = df\n    return pd.concat(dfs.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_glove_df(filepath, **kwargs):\n    pdkwargs = dict(index_col=0, header=None, sep=r'\\s', skiprows=[0], verbose=False, engine='python')\n    pdkwargs.update(kwargs)\n    return pd.read_csv(filepath, **pdkwargs)", "response": "Load a GloVE - format text file into a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads and parse English - > French translation dataset used in Keras seq2seq example", "response": "def get_en2fr(url='http://www.manythings.org/anki/fra-eng.zip'):\n    \"\"\" Download and parse English->French translation dataset used in Keras seq2seq example \"\"\"\n    download_unzip(url)\n    return pd.read_table(url, compression='zip', header=None, skip_blank_lines=True, sep='\\t', skiprows=0, names='en fr'.split())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading into a DataFrame statements in one language along with their translation into English", "response": "def load_anki_df(language='deu'):\n    \"\"\" Load into a DataFrame statements in one language along with their translation into English\n\n    >>> get_data('zsm').head(1)\n                    eng                                zsm\n    0      Are you new?                         Awak baru?\n    \"\"\"\n    if os.path.isfile(language):\n        filepath = language\n        lang = re.search('[a-z]{3}-eng/', filepath).group()[:3].lower()\n    else:\n        lang = (language or 'deu').lower()[:3]\n        filepath = os.path.join(BIGDATA_PATH, '{}-eng'.format(lang), '{}.txt'.format(lang))\n    df = pd.read_table(filepath, skiprows=1, header=None)\n    df.columns = ['eng', lang]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_big_urls_glove(bigurls=None):\n    bigurls = bigurls or {}\n    for num_dim in (50, 100, 200, 300):\n        # not all of these dimensionality, and training set size combinations were trained by Stanford\n        for suffixes, num_words in zip(\n                                       ('sm -sm _sm -small _small'.split(),\n                                        'med -med _med -medium _medium'.split(),\n                                        'lg -lg _lg -large _large'.split()),\n                                       (6, 42, 840)\n                                      ):\n            for suf in suffixes[:-1]:\n                name = 'glove' + suf + str(num_dim)\n                dirname = 'glove.{num_words}B'.format(num_words=num_words)\n                # glove.42B.300d.w2v.txt\n                filename = dirname + '.{num_dim}d.w2v.txt'.format(num_dim=num_dim)\n                # seed the alias named URL with the URL for that training set size's canonical name\n                bigurl_tuple = BIG_URLS['glove' + suffixes[-1]]\n                bigurls[name] =  list(bigurl_tuple[:2])\n                bigurls[name].append(os.path.join(dirname, filename))\n                bigurls[name].append(load_glove)\n                bigurls[name] = tuple(bigurls[name])\n    return bigurls", "response": "Generate a dictionary of URLs for various combinations of GloVe training set sizes and dimensionality."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename_file(source, dest):\n    logger.debug('nlpia.loaders.rename_file(source={}, dest={})'.format(source, dest))\n    if not isinstance(source, str):\n        dest = [dest] if isinstance(dest, str) else dest\n        return [rename_file(s, d) for (s, d) in zip_longest(source, dest, fillvalue=[source, dest][int(len(source) > len(dest))])]\n    logger.debug('nlpia.loaders.os.rename(source={}, dest={})'.format(source, dest))\n    if source == dest:\n        return dest\n    os.rename(source, dest)\n    return dest", "response": "Rename file from source to dest"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_ext_rename(filepath):\n    logger.debug('normalize_ext.filepath=' + str(filepath))\n    new_file_path = normalize_ext(filepath)\n    logger.debug('download_unzip.new_filepaths=' + str(new_file_path))\n    # FIXME: fails when name is a url filename\n    filepath = rename_file(filepath, new_file_path)\n    logger.debug('download_unzip.filepath=' + str(filepath))\n    return filepath", "response": "rename file ext like. tgz to 300d. glove. txt and return filepath"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef series_rstrip(series, endswith='/usercomments', ignorecase=True):\n    return series_strip(series, startswith=None, endswith=endswith, startsorendswith=None, ignorecase=ignorecase)", "response": "Strip a suffix str from a pd. Series of type str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip a prefix str from a pd. Series of type str", "response": "def series_lstrip(series, startswith='http://', ignorecase=True):\n    \"\"\" Strip a suffix str (`endswith` str) from a `df` columns or pd.Series of type str \"\"\"\n    return series_strip(series, startswith=startswith, endswith=None, startsorendswith=None, ignorecase=ignorecase)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef series_strip(series, startswith=None, endswith=None, startsorendswith=None, ignorecase=True):\n    if ignorecase:\n        mask = series.str.lower()\n        endswith = endswith.lower()\n    else:\n        mask = series\n    if not (startsorendswith or endswith or startswith):\n        logger.warning('In series_strip(): You must specify endswith, startswith, or startsorendswith string arguments.')\n        return series\n    if startsorendswith:\n        startswith = endswith = startsorendswith\n    if endswith:\n        mask = mask.str.endswith(endswith)\n        series[mask] = series[mask].str[:-len(endswith)]\n    if startswith:\n        mask = mask.str.endswith(startswith)\n        series[mask] = series[mask].str[len(startswith):]\n    return series", "response": "Strip a suffix or prefix str from a pd. Series or pd. Series of type str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef endswith_strip(s, endswith='.txt', ignorecase=True):\n    if ignorecase:\n        if s.lower().endswith(endswith.lower()):\n            return s[:-len(endswith)]\n    else:\n        if s.endswith(endswith):\n            return s[:-len(endswith)]\n    return s", "response": "Strip a suffix from the end of a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef startswith_strip(s, startswith='http://', ignorecase=True):\n    if ignorecase:\n        if s.lower().startswith(startswith.lower()):\n            return s[len(startswith):]\n    else:\n        if s.endswith(startswith):\n            return s[len(startswith):]\n    return s", "response": "Strip a prefix from the beginning of a string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the HTML tables from a URL and return the longest DataFrame", "response": "def get_longest_table(url='https://www.openoffice.org/dev_docs/source/file_extensions.html', header=0):\n    \"\"\" Retrieve the HTML tables from a URL and return the longest DataFrame found\n\n    >>> get_longest_table('https://en.wikipedia.org/wiki/List_of_sovereign_states').columns\n    Index(['Common and formal names', 'Membership within the UN System[a]',\n       'Sovereignty dispute[b]',\n       'Further information on status and recognition of sovereignty[d]'],\n      dtype='object')\n    \"\"\"\n    dfs = pd.read_html(url, header=header)\n    return longest_table(dfs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a dictionary of word - > word mapping from chat text abbreviations and acronyms like LMK => Let Me Know", "response": "def get_netspeak_map():\n    \"\"\" Retrieve mapping from chat/text abbreviations and acronyms like LMK => Let Me Know \"\"\"\n    dfs = pd.read_html('https://www.webopedia.com/quick_ref/textmessageabbreviations.asp')\n    df = dfs[0].drop(index=0)\n    df.columns = ['abbrev', 'definition']\n    csv_path = os.path.join(DATA_PATH, 'netspeak.csv')\n    logger.info('Saving netspeak dictionary (word mapping) to {}'.format(csv_path))\n    df.to_csv(csv_path)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning this single longest DataFrame that among an array or list of DataFrames Useful for automagically finding the DataFrame that is in a Wikipedia page.", "response": "def longest_table(dfs):\n    \"\"\" Return this single longest DataFrame that among an array/list/tuple of DataFrames\n\n    Useful for automagically finding the DataFrame you want when using pd.read_html() on a Wikipedia page.\n    \"\"\"\n    sorted_indices = sorted((len(df if hasattr(df, '__len__') else []), i) for i, df in enumerate(dfs))\n    return dfs[sorted_indices[-1][1]]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filename_extensions(url='https://www.webopedia.com/quick_ref/fileextensionsfull.asp'):\n    df = get_longest_table(url)\n    columns = list(df.columns)\n    columns[0] = 'ext'\n    columns[1] = 'description'\n    if len(columns) > 2:\n        columns[2] = 'details'\n    df.columns = columns\n    return df", "response": "Load a DataFrame of filename extensions from the indicated url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_big_url(name):\n    # BIG side effect\n    global BIG_URLS\n    filemeta = get_url_filemeta(name)\n    if not filemeta:\n        return None\n    filename = filemeta['filename']\n    remote_size = filemeta['remote_size']\n    url = filemeta['url']\n    name = filename.split('.')\n    name = (name[0] if name[0] not in ('', '.') else name[1]).replace(' ', '-')\n    name = name.lower().strip()\n    BIG_URLS[name] = (url, int(remote_size or -1), filename)\n    return name", "response": "Create a BIG url from a file name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ftp_filemeta(parsed_url, username='anonymous', password='nlpia@totalgood.com'):\n    return dict(\n        url=parsed_url.geturl(), hostname=parsed_url.hostname, path=parsed_url.path,\n        username=(parsed_url.username or username),\n        remote_size=-1,\n        filename=os.path.basename(parsed_url.path))\n    ftp = ftplib.FTP(parsed_url.hostname)\n    ftp.login(username, password)\n    ftp.cwd(parsed_url.path)\n    ftp.retrbinary(\"RETR \" + filename, open(filename, 'wb').write)\n    ftp.quit()", "response": "Get file metadata from FTP server using parsed_url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download_unzip(names=None, normalize_filenames=False, verbose=True):\n    names = [names] if isinstance(names, (str, basestring)) else names\n    # names = names or list(BIG_URLS.keys())  # download them all, if none specified!\n    file_paths = {}\n    for name in names:\n        created = create_big_url(name)\n        name = (created or name).lower().strip()\n\n        if name in BIG_URLS:\n            filepath = download_name(name, verbose=verbose)\n            if not filepath:\n                continue\n            file_paths[name] = normalize_ext_rename(filepath)\n            logger.debug('downloaded name={} to filepath={}'.format(name, file_paths[name]))\n            fplower = file_paths[name].lower()\n            if fplower.endswith('.tar.gz'):\n                logger.info('Extracting {}'.format(file_paths[name]))\n                file_paths[name] = untar(file_paths[name], verbose=verbose)\n                logger.debug('download_untar.filepaths=' + str(file_paths))\n            elif file_paths[name].lower().endswith('.zip'):\n                file_paths[name] = unzip(file_paths[name], verbose=verbose)\n                logger.debug('download_unzip.filepaths=' + str(file_paths))\n        else:\n            df = pd.read_html(DATA_INFO['url'][name], **DATA_INFO['downloader_kwargs'][name])[-1]\n            df.columns = clean_columns(df.columns)\n            file_paths[name] = os.path.join(DATA_PATH, name + '.csv')\n            df.to_csv(file_paths[name])\n        file_paths[name] = normalize_ext_rename(file_paths[name])\n    return file_paths", "response": "r Downloads CSV or HTML tables listed in names unzips and to DATA_PATH."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a file from a URL and return a list of files.", "response": "def download_file(url, data_path=BIGDATA_PATH, filename=None, size=None, chunk_size=4096, normalize_filename=False, verbose=True):\n    \"\"\"Uses stream=True and a reasonable chunk size to be able to download large (GB) files over https\n\n    Downloading this small file takes 1.5 sec. All subsequent \"downloads\" takes .6 sec to verify path and size.\n    >>> import time\n    >>> meta = BIG_URLS['ubuntu_dialog_test']\n    >>> pathend = os.path.join(*('nlpia/src/nlpia/bigdata/ubuntu_dialog_test.csv.gz'.split('/')))\n    >>> download_file(url=meta[0], verbose=False).endswith(pathend)\n    True\n    >>> t0 = time.time()\n    >>> localpath = download_file(url=BIG_URLS['ubuntu_dialog_test'][0], verbose=False)\n    >>> t1 = time.time()\n    >>> localpath is None or ((0.015 < (t1 - t0) < 5.0) and localpath.endswith(pathend))\n    True\n    >>> t0 = time.time()\n    >>> download_file(url=meta[0], size=meta[1], verbose=False).endswith(pathend)\n    True\n    >>> time.time() - t0 < 0.02\n    True\n    \"\"\"\n    if isinstance(url, (list, tuple)):\n        return [\n            download_file(\n                s, data_path=data_path, filename=filename, size=size, chunk_size=chunk_size, verbose=verbose)\n            for s in url]\n    if url.endswith('dl=0'):\n        url = url[:-1] + '1'  # noninteractive Dropbox download\n    remote_size = size\n\n    # figure out what filename to expect after download and how big it should be\n    if filename is None:\n        filename = dropbox_basename(url)\n    filepath = os.path.join(data_path, filename)\n    if normalize_filename:\n        filepath = normalize_filepath(filepath)\n    logger.info('expanded+normalized file path: {}'.format(filepath))\n    tqdm_prog = tqdm if verbose else no_tqdm\n    logger.info('requesting URL: {}'.format(url))\n\n    logger.info('remote_size: {}'.format(remote_size))\n    stat = path_status(filepath)\n    local_size = stat.get('size', None)\n    logger.info('local_size: {}'.format(local_size))\n\n    r = None\n    if not remote_size or not stat['type'] == 'file' or not local_size >= remote_size or not stat['size'] > MIN_DATA_FILE_SIZE:\n        try:\n            r = requests.get(url, stream=True, allow_redirects=True, timeout=5)\n            remote_size = r.headers.get('Content-Length', -1)\n        except ConnectionError:\n            logger.error('ConnectionError for url: {} => request {}'.format(url, r))\n            remote_size = -1 if remote_size is None else remote_size\n        except (InvalidURL, InvalidSchema, InvalidHeader, MissingSchema) as e:\n            logger.warn(e)\n            logger.warn('HTTP Error for url: {}\\n request: {}\\n traceback: {}'.format(url, r, format_exc()))\n            logger.warn('This can happen for Google Word Vector download links to Dropbox or Google Docs.')\n    try:\n        remote_size = int(remote_size)\n    except ValueError:\n        remote_size = -1\n\n    # remote_size has changed so need to check it again\n    # TODO: check md5 or get the right size of remote file\n    if stat['type'] == 'file' and local_size >= remote_size and stat['size'] > MIN_DATA_FILE_SIZE:\n        r = r.close() if r else r\n        logger.info('retained: {}'.format(filepath))\n        return filepath\n\n    filedir = os.path.dirname(filepath)\n    created_dir = mkdir_p(filedir)\n    logger.info('data path created: {}'.format(created_dir))\n    assert os.path.isdir(filedir)\n    assert created_dir.endswith(filedir)\n    bytes_downloaded = 0\n    if r:\n        logger.info('downloading to: {}'.format(filepath))\n        with open(filepath, 'wb') as f:\n            for chunk in tqdm_prog(r.iter_content(chunk_size=chunk_size), total=ceil(remote_size / float(chunk_size))):\n                bytes_downloaded += len(chunk)\n                if chunk:  # filter out keep-alive chunks\n                    f.write(chunk)\n        r.close()\n    else:\n        logger.error('Unable to request URL: {} using request object {}'.format(url, r))\n        return None\n\n    logger.debug('nlpia.loaders.download_file: bytes={}'.format(bytes_downloaded))\n    stat = path_status(filepath)\n    logger.info(\"local file stat {}\".format(stat))\n    logger.debug(\"filepath={}: local_size={}, remote_size={}, downloaded_bytes={}\".format(\n        filepath, size, remote_size, bytes_downloaded))\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_named_csv(name, data_path=DATA_PATH, nrows=None, verbose=True):\n    if os.path.isfile(name):\n        try:\n            return read_json(name)\n        except (IOError, UnicodeDecodeError, json.JSONDecodeError):\n            pass\n        try:\n            return read_csv(name, nrows=nrows)\n        except (IOError, pd.errors.ParserError):\n            pass\n        try:\n            return read_txt(name, nrows=nrows)\n        except (IOError, UnicodeDecodeError):\n            pass\n    data_path = expand_filepath(data_path)\n    if os.path.isfile(os.path.join(data_path, name)):\n        return read_csv(os.path.join(data_path, name), nrows=nrows)\n    if name in DATASET_NAME2FILENAME:\n        name = DATASET_NAME2FILENAME[name]\n        if name.lower().endswith('.txt') or name.lower().endswith('.txt.gz'):\n            return read_text(os.path.join(data_path, name), nrows=nrows)\n        else:\n            return read_csv(os.path.join(data_path, name), nrows=nrows)\n    try:\n        return read_csv(os.path.join(data_path, name + '.csv.gz'), nrows=nrows)\n    except IOError:\n        pass\n    try:\n        return read_csv(os.path.join(data_path, name + '.csv'), nrows=nrows)\n    except IOError:\n        pass\n    try:\n        return read_json(os.path.join(data_path, name + '.json'))\n    except IOError:\n        pass\n    try:\n        return read_txt(os.path.join(data_path, name + '.txt'), verbose=verbose)\n    except IOError:\n        pass\n\n    # FIXME: mapping from short name to uncompressed filename\n    # BIGDATA files are usually not loadable into dataframes\n    try:\n        return KeyedVectors.load_word2vec_format(os.path.join(BIGDATA_PATH, name + '.bin.gz'), binary=True)\n    except IOError:\n        pass\n    except ValueError:\n        pass\n    try:\n        return read_txt(os.path.join(BIGDATA_PATH, name + '.txt'), verbose=verbose)\n    except IOError:\n        pass", "response": "Read a named dataset into a Pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads data from a json csv or txt file.", "response": "def get_data(name='sms-spam', nrows=None, limit=None):\n    \"\"\" Load data from a json, csv, or txt file if it exists in the data dir.\n\n    References:\n      [cities_air_pollution_index](https://www.numbeo.com/pollution/rankings.jsp)\n      [cities](http://download.geonames.org/export/dump/cities.zip)\n      [cities_us](http://download.geonames.org/export/dump/cities_us.zip)\n\n    >>> from nlpia.data.loaders import get_data\n    >>> words = get_data('words_ubuntu_us')\n    >>> len(words)\n    99171\n    >>> list(words[:8])\n    ['A', \"A's\", \"AA's\", \"AB's\", \"ABM's\", \"AC's\", \"ACTH's\", \"AI's\"]\n    >>> get_data('ubuntu_dialog_test').iloc[0]\n    Context      i think we could import the old comments via r...\n    Utterance    basically each xfree86 upload will NOT force u...\n    Name: 0, dtype: object\n    >>> get_data('imdb_test').info()\n    <class 'pandas.core.frame.DataFrame'>\n    MultiIndex: 20 entries, (train, pos, 0) to (train, neg, 9)\n    Data columns (total 3 columns):\n    url       20 non-null object\n    rating    20 non-null int64\n    text      20 non-null object\n    dtypes: int64(1), object(2)\n    memory usage: 809.0+ bytes\n    \"\"\"\n    nrows = nrows or limit\n    if name in BIG_URLS:\n        logger.info('Downloading {}'.format(name))\n        filepaths = download_unzip(name, normalize_filenames=True)\n        logger.debug('nlpia.loaders.get_data.filepaths=' + str(filepaths))\n        filepath = filepaths[name][0] if isinstance(filepaths[name], (list, tuple)) else filepaths[name]\n        logger.debug('nlpia.loaders.get_data.filepath=' + str(filepath))\n        filepathlow = filepath.lower()\n\n        if len(BIG_URLS[name]) >= 4:\n            kwargs = BIG_URLS[name][4] if len(BIG_URLS[name]) >= 5 else {}\n            return BIG_URLS[name][3](filepath, **kwargs)\n        if filepathlow.endswith('.w2v.txt'):\n            try:\n                return KeyedVectors.load_word2vec_format(filepath, binary=False, limit=nrows)\n            except (TypeError, UnicodeError):\n                pass\n        if filepathlow.endswith('.w2v.bin') or filepathlow.endswith('.bin.gz') or filepathlow.endswith('.w2v.bin.gz'):\n            try:\n                return KeyedVectors.load_word2vec_format(filepath, binary=True, limit=nrows)\n            except (TypeError, UnicodeError):\n                pass\n        if filepathlow.endswith('.gz'):\n            try:\n                filepath = ensure_open(filepath)\n            except:  # noqa\n                pass\n        if re.match(r'.json([.][a-z]{0,3}){0,2}', filepathlow):\n            return read_json(filepath)\n        if filepathlow.endswith('.tsv.gz') or filepathlow.endswith('.tsv'):\n            try:\n                return pd.read_table(filepath)\n            except:  # noqa\n                pass\n        if filepathlow.endswith('.csv.gz') or filepathlow.endswith('.csv'):\n            try:\n                return read_csv(filepath)\n            except:  # noqa\n                pass\n        if filepathlow.endswith('.txt'):\n            try:\n                return read_txt(filepath)\n            except (TypeError, UnicodeError):\n                pass\n        return filepaths[name]\n    elif name in DATASET_NAME2FILENAME:\n        return read_named_csv(name, nrows=nrows)\n    elif name in DATA_NAMES:\n        return read_named_csv(DATA_NAMES[name], nrows=nrows)\n    elif os.path.isfile(name):\n        return read_named_csv(name, nrows=nrows)\n    elif os.path.isfile(os.path.join(DATA_PATH, name)):\n        return read_named_csv(os.path.join(DATA_PATH, name), nrows=nrows)\n\n    msg = 'Unable to find dataset \"{}\"\" in {} or {} (*.csv.gz, *.csv, *.json, *.zip, or *.txt)\\n'.format(\n        name, DATA_PATH, BIGDATA_PATH)\n    msg += 'Available dataset names include:\\n{}'.format('\\n'.join(DATASET_NAMES))\n    logger.error(msg)\n    raise IOError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlike pandas. read_csv but loads and concatenates DataFrames together", "response": "def multifile_dataframe(paths=['urbanslang{}of4.csv'.format(i) for i in range(1, 5)], header=0, index_col=None):\n    \"\"\"Like pandas.read_csv, but loads and concatenates (df.append(df)s) DataFrames together\"\"\"\n    df = pd.DataFrame()\n    for p in paths:\n        df = df.append(read_csv(p, header=header, index_col=index_col), ignore_index=True if not index_col else False)\n    if index_col and df.index.name == index_col:\n        del df[index_col]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the Query number for a wikidata database of metadata about a particular article", "response": "def get_wikidata_qnum(wikiarticle, wikisite):\n    \"\"\"Retrieve the Query number for a wikidata database of metadata about a particular article\n\n    >>> print(get_wikidata_qnum(wikiarticle=\"Andromeda Galaxy\", wikisite=\"enwiki\"))\n    Q2469\n    \"\"\"\n    resp = requests.get('https://www.wikidata.org/w/api.php', timeout=5, params={\n        'action': 'wbgetentities',\n        'titles': wikiarticle,\n        'sites': wikisite,\n        'props': '',\n        'format': 'json'\n    }).json()\n    return list(resp['entities'])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_column_names(df):\n    columns = df.columns if hasattr(df, 'columns') else df\n    columns = [c.lower().replace(' ', '_') for c in columns]\n    return columns", "response": "Clean up whitespace in column names. See better version at pugnlp. clean_columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts dollar value strings numbers with commas and percents into floating point values", "response": "def clean_column_values(df, inplace=True):\n    r\"\"\" Convert dollar value strings, numbers with commas, and percents into floating point values\n\n    >>> df = get_data('us_gov_deficits_raw')\n    >>> df2 = clean_column_values(df, inplace=False)\n    >>> df2.iloc[0]\n    Fiscal year                                                               10/2017-3/2018\n    President's party                                                                      R\n    Senate majority party                                                                  R\n    House majority party                                                                   R\n    Top-bracket marginal income tax rate                                                38.3\n    National debt millions                                                       2.10896e+07\n    National debt millions of 1983 dollars                                       8.47004e+06\n    Deficit\\n(millions of 1983 dollars)                                               431443\n    Surplus string in 1983 dollars                                                       NaN\n    Deficit string in 1983 dollars ($ = $10B)    $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n    Net surplus in 1983 dollars ($B)                                                    -430\n    Name: 0, dtype: object\n    \"\"\"\n    dollars_percents = re.compile(r'[%$,;\\s]+')\n    if not inplace:\n        df = df.copy()\n    for c in df.columns:\n        values = None\n        if df[c].dtype.char in '<U S O'.split():\n            try:\n                values = df[c].copy()\n                values = values.fillna('')\n                values = values.astype(str).str.replace(dollars_percents, '')\n                # values = values.str.strip().str.replace(dollars_percents, '').str.strip()\n                if values.str.len().sum() > .2 * df[c].astype(str).str.len().sum():\n                    values[values.isnull()] = np.nan\n                    values[values == ''] = np.nan\n                    values = values.astype(float)\n            except ValueError:\n                values = None\n            except:  # noqa\n                logger.error('Error on column {} with dtype {}'.format(c, df[c].dtype))\n                raise\n\n        if values is not None:\n            if values.isnull().sum() < .6 * len(values) and values.any():\n                df[c] = values\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_geonames(filepath='http://download.geonames.org/export/dump/cities1000.zip'):\n    columns = ['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature class',\n               'feature code', 'country code']\n    columns += ['cc2', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation',\n                'dem', 'timezone', 'modification date']\n    columns = normalize_column_names(columns)\n    df = pd.read_csv(filepath, sep='\\t', index_col=None, low_memory=False, header=None)\n    df.columns = columns\n    return df", "response": "Load the geonames table from download. geonames. org and return the table of city metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the city names from a GeoFile.", "response": "def load_geo_adwords(filename='AdWords API Location Criteria 2017-06-26.csv.gz'):\n    \"\"\" WARN: Not a good source of city names. This table has many errors, even after cleaning\"\"\"\n    df = pd.read_csv(filename, header=0, index_col=0, low_memory=False)\n    df.columns = [c.replace(' ', '_').lower() for c in df.columns]\n    canonical = pd.DataFrame([list(row) for row in df.canonical_name.str.split(',').values])\n\n    def cleaner(row):\n        cleaned = pd.np.array(\n            [s for i, s in enumerate(row.values) if s not in ('Downtown', None) and (i > 3 or row[i + 1] != s)])\n        if len(cleaned) == 2:\n            cleaned = [cleaned[0], None, cleaned[1], None, None]\n        else:\n            cleaned = list(cleaned) + [None] * (5 - len(cleaned))\n        if not pd.np.all(pd.np.array(row.values)[:3] == pd.np.array(cleaned)[:3]):\n            logger.info('{} => {}'.format(row.values, cleaned))\n        return list(cleaned)\n\n    cleancanon = canonical.apply(cleaner, axis=1)\n    cleancanon.columns = 'city region country extra extra2'.split()\n    df['region'] = cleancanon.region\n    df['country'] = cleancanon.country\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a dataframe of ~100k raw movie lines from the cornell movies dialog corpus and return a new DataFrame of ~100k raw movie lines.", "response": "def clean_cornell_movies(filename='cornell_movie_dialogs_corpus.zip', subdir='cornell movie-dialogs corpus'):\n    \"\"\" Load a dataframe of ~100k raw (uncollated) movie lines from the cornell movies dialog corpus\n    \n    >>> local_filepath = download_file(BIG_URLS['cornell_movie_dialogs_corpus'][0])\n    >>> df = clean_cornell_movies(filename='cornell_movie_dialogs_corpus.zip')\n    >>> df.describe(include='all')\n              user   movie  person utterance\n    count   304713  304713  304713    304446\n    unique    9035     617    5356    265783\n    top      u4525    m289    JACK     What?\n    freq       537    1530    3032      1684\n    \"\"\"\n    fullpath_zipfile = find_filepath(filename)\n    dirname = os.path.basename(filename)\n    subdir = 'cornell movie-dialogs corpus'\n    if fullpath_zipfile.lower().endswith('.zip'):\n        retval = unzip(fullpath_zipfile)\n        dirname = dirname[:-4]\n    fullpath_movie_lines = os.path.join(BIGDATA_PATH, dirname, subdir, 'movie_lines.txt')\n    dialog = pd.read_csv(\n        fullpath_movie_lines, sep=r'\\+\\+\\+\\$\\+\\+\\+', engine='python', header=None, index_col=0)\n    dialog.columns = 'user movie person utterance'.split()\n    dialog.index.name = 'line'\n    dialog.index = [int(s.strip()[1:]) for s in dialog.index.values]\n    dialog.sort_index(inplace=True)\n    for col in dialog.columns:\n        dialog[col] = dialog[col].str.strip()\n    return dialog"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the dimensionality of the first word vector in a GloVE file and return its dimensionality or False if not a vector", "response": "def isglove(filepath):\n    \"\"\" Get the first word vector in a GloVE file and return its dimensionality or False if not a vector\n\n    >>> isglove(os.path.join(DATA_PATH, 'cats_and_dogs.txt'))\n    False\n    \"\"\"\n\n    with ensure_open(filepath, 'r') as f:\n        header_line = f.readline()\n        vector_line = f.readline()\n    try:\n        num_vectors, num_dim = header_line.split()\n        return int(num_dim)\n    except (ValueError, TypeError):\n        pass\n    vector = vector_line.split()[1:]\n    if len(vector) % 10:\n        print(vector)\n        print(len(vector) % 10)\n        return False\n    try:\n        vector = np.array([float(x) for x in vector])\n    except (ValueError, TypeError):\n        return False\n    if np.all(np.abs(vector) < 12.):\n        return len(vector)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nlp(texts, lang='en', linesep=None, verbose=True):\n    # doesn't let you load a different model anywhere else in the module\n    linesep = os.linesep if linesep in ('default', True, 1, 'os') else linesep\n    tqdm_prog = no_tqdm if (not verbose or (hasattr(texts, '__len__') and len(texts) < 3)) else tqdm\n    global _parse\n    if not _parse:\n        try:\n            _parse = spacy.load(lang)\n        except (OSError, IOError):\n            try:\n                spacy.cli.download(lang)\n            except URLError:\n                logger.warning(\"Unable to download Spacy language model '{}' so nlp(text) just returns text.split()\".format(lang))\n    parse = _parse or str.split\n    # TODO: reverse this recursion (str first then sequence) to allow for sequences of sequences of texts\n    if isinstance(texts, str):\n        if linesep:\n            return nlp(texts.split(linesep))\n        else:\n            return nlp([texts])\n    if hasattr(texts, '__len__'):\n        if len(texts) == 1:\n            return parse(texts[0])\n        elif len(texts) > 1:\n            return [(parse or str.split)(text) for text in tqdm_prog(texts)]\n        else:\n            return None\n    else:\n        # return generator if sequence of strings doesn't have __len__ which means its an iterable or generator itself\n        return (parse(text) for text in tqdm_prog(texts))", "response": "r Returns a list of natural language strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload and clean tab - separated files saved on Windows OS (' \\ r \\ n')", "response": "def clean_win_tsv(filepath=os.path.join(DATA_PATH, 'Products.txt'),\n                  index_col=False, sep='\\t', lineterminator='\\r', error_bad_lines=False, **kwargs):\n    \"\"\" Load and clean tab-separated files saved on Windows OS ('\\r\\n') \"\"\"\n    df = pd.read_csv(filepath, index_col=index_col, sep=sep, lineterminator=lineterminator,\n                     error_bad_lines=error_bad_lines, **kwargs)\n    index_col = df.columns[0]\n    original_len = len(df)\n    if df[index_col].values[-1] == '\\n':\n        df.iloc[-1, 0] = np.nan\n        original_len = len(df) - 1\n    df.dropna(how='all', inplace=True)\n    df[index_col] = df[index_col].str.strip().apply(lambda x: x if x else str(INT_MIN)).astype(int)\n    df = df[~(df[index_col] == INT_NAN)]\n    df.set_index(index_col, inplace=True)\n    if len(df) != original_len:\n        logger.warning(('Loaded {} rows from tsv. Original file, \"{}\", contained {} seemingly valid lines.' +\n                        'Index column: {}').format(len(df), original_len, filepath, index_col))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_decoder(libdir=None, modeldir=None, lang='en-us'):\n    modeldir = modeldir or (os.path.join(libdir, 'model') if libdir else MODELDIR)\n    libdir = os.path.dirname(modeldir)\n    config = ps.Decoder.default_config()\n    config.set_string('-hmm', os.path.join(modeldir, lang))\n    config.set_string('-lm', os.path.join(modeldir, lang + '.lm.bin'))\n    config.set_string('-dict', os.path.join(modeldir, 'cmudict-' + lang + '.dict'))\n    print(config)\n    return ps.Decoder(config)", "response": "Create a decoder with the requested language model"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode streaming audio data from raw binary file on disk.", "response": "def transcribe(decoder, audio_file, libdir=None):\n    \"\"\" Decode streaming audio data from raw binary file on disk. \"\"\"\n    decoder = get_decoder()\n\n    decoder.start_utt()\n    stream = open(audio_file, 'rb')\n    while True:\n        buf = stream.read(1024)\n        if buf:\n            decoder.process_raw(buf, False, False)\n        else:\n            break\n    decoder.end_utt()\n    return evaluate_results(decoder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_unicode(sorb, allow_eval=False):\n    if sorb is None:\n        return sorb\n    if isinstance(sorb, bytes):\n        sorb = sorb.decode()\n    for i, s in enumerate([\"b'\", 'b\"', \"u'\", 'u\"']):\n        if (sorb.startswith(s) and sorb.endswith(s[-1])):\n            # print(i)\n            return to_unicode(eval(sorb, {'__builtins__': None}, {}))\n    return sorb", "response": "r Ensure that strings are unicode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a. txt file and yield lists of filtered tokens", "response": "def get_texts(self):\n        \"\"\" Parse documents from a .txt file assuming 1 document per line, yielding lists of filtered tokens \"\"\"\n        with self.getstream() as text_stream:\n            for i, line in enumerate(text_stream):\n                line = to_unicode(line)\n                line = (TweetCorpus.case_normalizer or passthrough)(line)\n                # line = self.case_normalizer(line)\n                if self.mask is not None and not self.mask[i]:\n                    continue\n                ngrams = []\n                for ng in tokens2ngrams((TweetCorpus.tokenizer or str.split)(line), n=self.num_grams):\n                    if self.ignore_matcher(ng):\n                        continue\n                    ngrams += [ng]\n                if not (i % 1000):\n                    print(line)\n                    print(ngrams)\n                yield ngrams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_texts(self):\n        with self.getstream() as text_stream:\n            for i, line in enumerate(text_stream):\n                line = SMSCorpus.case_normalizer(line)\n                if self.mask is not None and not self.mask[i]:\n                    continue\n                ngrams = []\n                for ng in tokens2ngrams(self.tokenizer(line)):\n                    if SMSCorpus.ignore_matcher(ng):\n                        continue\n                    ngrams += [ng]\n                yield ngrams", "response": "Parse a. txt file and yield a list of filtered tokens"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_file(url, data_path='.', filename=None, size=None, chunk_size=4096, verbose=True):\n    if filename is None:\n        filename = dropbox_basename(url)\n    file_path = os.path.join(data_path, filename)\n    if url.endswith('?dl=0'):\n        url = url[:-1] + '1'  # noninteractive download\n    if verbose:\n        tqdm_prog = tqdm\n        print('requesting URL: {}'.format(url))\n    else:\n        tqdm_prog = no_tqdm\n    r = requests.get(url, stream=True, allow_redirects=True, timeout=5)\n    size = r.headers.get('Content-Length', None) if size is None else size\n    print('remote size: {}'.format(size))\n\n    stat = path_status(file_path)\n    print('local size: {}'.format(stat.get('size', None)))\n    if stat['type'] == 'file' and stat['size'] == size:  # TODO: check md5 or get the right size of remote file\n        r.close()\n        return file_path\n\n    print('Downloading to {}'.format(file_path))\n\n    with open(file_path, 'wb') as f:\n        for chunk in r.iter_content(chunk_size=chunk_size):\n            if chunk:  # filter out keep-alive chunks\n                f.write(chunk)\n\n    r.close()\n    return file_path", "response": "Downloads a file from a URL to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pad_trunc(data, maxlen):\n    new_data = []\n\n    # Create a vector of 0's the length of our word vectors\n    zero_vector = []\n    for _ in range(len(data[0][0])):\n        zero_vector.append(0.0)\n\n    for sample in data:\n\n        if len(sample) > maxlen:\n            temp = sample[:maxlen]\n        elif len(sample) < maxlen:\n            temp = sample\n            additional_elems = maxlen - len(sample)\n            for _ in range(additional_elems):\n                temp.append(zero_vector)\n        else:\n            temp = sample\n        new_data.append(temp)\n    return new_data", "response": "For a given dataset pad with zero vectors or truncate to maxlen"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshift to lower case replace unknowns with UNK and listify", "response": "def clean_data(data):\n    \"\"\" Shift to lower case, replace unknowns with UNK, and listify \"\"\"\n    new_data = []\n    VALID = 'abcdefghijklmnopqrstuvwxyz123456789\"\\'?!.,:; '\n    for sample in data:\n        new_sample = []\n        for char in sample[1].lower():  # Just grab the string, not the label\n            if char in VALID:\n                new_sample.append(char)\n            else:\n                new_sample.append('UNK')\n\n        new_data.append(new_sample)\n    return new_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef char_pad_trunc(data, maxlen):\n    new_dataset = []\n    for sample in data:\n        if len(sample) > maxlen:\n            new_data = sample[:maxlen]\n        elif len(sample) < maxlen:\n            pads = maxlen - len(sample)\n            new_data = sample + ['PAD'] * pads\n        else:\n            new_data = sample\n        new_dataset.append(new_data)\n    return new_dataset", "response": "Truncates the data to maxlen or adds in PAD tokens"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies from Keras LSTM example", "response": "def create_dicts(data):\n    \"\"\" Modified from Keras LSTM example\"\"\"\n    chars = set()\n    for sample in data:\n        chars.update(set(sample))\n    char_indices = dict((c, i) for i, c in enumerate(chars))\n    indices_char = dict((i, c) for i, c in enumerate(chars))\n    return char_indices, indices_char"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef onehot_encode(dataset, char_indices, maxlen):\n    X = np.zeros((len(dataset), maxlen, len(char_indices.keys())))\n    for i, sentence in enumerate(dataset):\n        for t, char in enumerate(sentence):\n            X[i, t, char_indices[char]] = 1\n    return X", "response": "One hot encode the tokens\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef svd_flip(u, v, u_based_decision=True):\n    if u_based_decision:\n        # columns of u, rows of v\n        max_abs_cols = np.argmax(np.abs(u), axis=0)\n        signs = np.sign(u[max_abs_cols, xrange(u.shape[1])])\n        u *= signs\n        v *= signs[:, np.newaxis]\n    else:\n        # rows of v, columns of u\n        max_abs_rows = np.argmax(np.abs(v), axis=1)\n        signs = np.sign(v[xrange(v.shape[0]), max_abs_rows])\n        u *= signs\n        v *= signs[:, np.newaxis]\n    return u, v", "response": "Sign correction to ensure deterministic output from SVD."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the model by computing full SVD on X", "response": "def _fit_full(self=self, X=X, n_components=6):\n    \"\"\"Fit the model by computing full SVD on X\"\"\"\n    n_samples, n_features = X.shape\n\n    # Center data\n    self.mean_ = np.mean(X, axis=0)\n    print(self.mean_)\n    X -= self.mean_\n    print(X.round(2))\n\n    U, S, V = linalg.svd(X, full_matrices=False)\n    print(V.round(2))\n    # flip eigenvectors' sign to enforce deterministic output\n    U, V = svd_flip(U, V)\n\n    components_ = V\n    print(components_.round(2))\n\n    # Get variance explained by singular values\n    explained_variance_ = (S ** 2) / (n_samples - 1)\n    total_var = explained_variance_.sum()\n    explained_variance_ratio_ = explained_variance_ / total_var\n    singular_values_ = S.copy()  # Store the singular values.\n\n    # Postprocess the number of components required\n    if n_components == 'mle':\n        n_components = \\\n            _infer_dimension_(explained_variance_, n_samples, n_features)\n    elif 0 < n_components < 1.0:\n        # number of components for which the cumulated explained\n        # variance percentage is superior to the desired threshold\n        ratio_cumsum = stable_cumsum(explained_variance_ratio_)\n        n_components = np.searchsorted(ratio_cumsum, n_components) + 1\n\n    # Compute noise covariance using Probabilistic PCA model\n    # The sigma2 maximum likelihood (cf. eq. 12.46)\n    if n_components < min(n_features, n_samples):\n        self.noise_variance_ = explained_variance_[n_components:].mean()\n    else:\n        self.noise_variance_ = 0.\n\n    self.n_samples_, self.n_features_ = n_samples, n_features\n    self.components_ = components_[:n_components]\n    print(self.components_.round(2))\n    self.n_components_ = n_components\n    self.explained_variance_ = explained_variance_[:n_components]\n    self.explained_variance_ratio_ = \\\n        explained_variance_ratio_[:n_components]\n    self.singular_values_ = singular_values_[:n_components]\n\n    return U, S, V"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef concatenate_aiml(path='aiml-en-us-foundation-alice.v1-9.zip', outfile='aiml-en-us-foundation-alice.v1-9.aiml'):\n    path = find_data_path(path) or path\n\n    zf = zipfile.ZipFile(path)\n    for name in zf.namelist():\n        if not name.lower().endswith('.aiml'):\n            continue\n        with zf.open(name) as fin:\n            happyending = '#!*@!!BAD'\n            for i, line in enumerate(fin):\n                try:\n                    line = line.decode('utf-8').strip()\n                except UnicodeDecodeError:\n                    line = line.decode('ISO-8859-1').strip()\n                if line.lower().startswith('</aiml>') or line.lower().endswith('</aiml>'):\n                    happyending = (i, line)\n                    break\n                else:\n                    pass\n\n            if happyending != (i, line):\n                print('Invalid AIML format: {}\\nLast line (line number {}) was: {}\\nexpected \"</aiml>\"'.format(\n                    name, i, line))", "response": "Concatenate all valid AIML files found in the AIML file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting an aiml. zip file if it hasn t already been extracted and return a list of aiml file paths", "response": "def extract_aiml(path='aiml-en-us-foundation-alice.v1-9'):\n    \"\"\" Extract an aiml.zip file if it hasn't been already and return a list of aiml file paths \"\"\"\n    path = find_data_path(path) or path\n    if os.path.isdir(path):\n        paths = os.listdir(path)\n        paths = [os.path.join(path, p) for p in paths]\n    else:\n        zf = zipfile.ZipFile(path)\n        paths = []\n        for name in zf.namelist():\n            if '.hg/' in name:\n                continue\n            paths.append(zf.extract(name, path=BIGDATA_PATH))\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_brain(path='aiml-en-us-foundation-alice.v1-9.zip'):\n    path = find_data_path(path) or path\n\n    bot = Bot()\n    num_templates = bot._brain.template_count\n    paths = extract_aiml(path=path)\n    for path in paths:\n        if not path.lower().endswith('.aiml'):\n            continue\n        try:\n            bot.learn(path)\n        except AimlParserError:\n            logger.error(format_exc())\n            logger.warning('AIML Parse Error: {}'.format(path))\n        num_templates = bot._brain.template_count - num_templates\n        logger.info('Loaded {} trigger-response pairs.\\n'.format(num_templates))\n    print('Loaded {} trigger-response pairs from {} AIML files.'.format(bot._brain.template_count, len(paths)))\n    return bot", "response": "Create an aiml_bot. Bot brain from an AIML zip file or directory of AIML files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing bitly or similar minifier to shrink all URLs in text files within a folder structure.", "response": "def minify_urls(filepath, ext='asc', url_regex=None, output_ext='.urls_minified', access_token=None):\n    \"\"\" Use bitly or similar minifier to shrink all URLs in text files within a folder structure.\n\n    Used for the NLPIA manuscript directory for Manning Publishing\n\n    bitly API: https://dev.bitly.com/links.html\n\n    Args:\n      path (str): Directory or file path\n      ext (str): File name extension to filter text files by. default='.asc'\n      output_ext (str): Extension to append to filenames of altered files default='' (in-place replacement of URLs)\n\n    FIXME: NotImplementedError! Untested!\n    \"\"\"\n    access_token = access_token or secrets.bitly.access_token\n    output_ext = output_ext or ''\n    url_regex = regex.compile(url_regex) if isinstance(url_regex, str) else url_regex\n    filemetas = []\n    for filemeta in find_files(filepath, ext=ext):\n        filemetas += [filemeta]\n        altered_text = ''\n        with open(filemeta['path'], 'rt') as fin:\n            text = fin.read()\n        end = 0\n        for match in url_regex.finditer(text):\n            url = match.group()\n            start = match.start()\n            altered_text += text[:start]\n            resp = requests.get('https://api-ssl.bitly.com/v3/shorten?access_token={}&longUrl={}'.format(\n                access_token, url), allow_redirects=True, timeout=5)\n            js = resp.json()\n            short_url = js['shortUrl']\n            altered_text += short_url\n            end = start + len(url)\n        altered_text += text[end:]\n        with open(filemeta['path'] + (output_ext or ''), 'wt') as fout:\n            fout.write(altered_text)\n    return altered_text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a str of separated tokens found within a slugLikeThis W a TLA s", "response": "def delimit_slug(slug, sep=' '):\n    \"\"\" Return a str of separated tokens found within a slugLike_This => 'slug Like This'\n\n    >>> delimit_slug(\"slugLike_ThisW/aTLA's\")\n    'slug Like This W a TLA s'\n    >>> delimit_slug('slugLike_ThisW/aTLA', '|')\n    'slug|Like|This|W|a|TLA'\n    \"\"\"\n    hyphenated_slug = re.sub(CRE_SLUG_DELIMITTER, sep, slug)\n    return hyphenated_slug"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform asciidoc text into ASCII text that NL parsers can handle.", "response": "def clean_asciidoc(text):\n    r\"\"\" Transform asciidoc text into ASCII text that NL parsers can handle\n\n    TODO:\n      Tag lines and words with meta data like italics, underlined, bold, title, heading 1, etc\n\n    >>> clean_asciidoc('**Hello** _world_!')\n    '\"Hello\" \"world\"!'\n    \"\"\"\n    text = re.sub(r'(\\b|^)[\\[_*]{1,2}([a-zA-Z0-9])', r'\"\\2', text)\n    text = re.sub(r'([a-zA-Z0-9])[\\]_*]{1,2}', r'\\1\"', text)\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_sentences_regex(text):\n    parts = regex.split(r'([a-zA-Z0-9][.?!])[\\s$]', text)\n    sentences = [''.join(s) for s in zip(parts[0::2], parts[1::2])]\n    return sentences + [parts[-1]] if len(parts) % 2 else sentences", "response": "Use dead - simple regex to split text into sentences. Very poor accuracy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_sentences_spacy(text, language_model='en'):\n    doc = nlp(text)\n    sentences = []\n    if not hasattr(doc, 'sents'):\n        logger.warning(\"Using NLTK sentence tokenizer because SpaCy language model hasn't been loaded\")\n        return split_sentences_nltk(text)\n    for w, span in enumerate(doc.sents):\n        sent = ''.join(doc[i].string for i in range(span.start, span.end)).strip()\n        if len(sent):\n            sentences.append(sent)\n    return sentences", "response": "r Split text into sentences using spacy language model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all sentences and empty lines.", "response": "def segment_sentences(path=os.path.join(DATA_PATH, 'book'), splitter=split_sentences_nltk, **find_files_kwargs):\n    \"\"\" Return a list of all sentences and empty lines.\n\n    TODO:\n        1. process each line with an aggressive sentence segmenter, like DetectorMorse\n        2. process our manuscript to create a complete-sentence and heading training set normalized/simplified\n           syntax net tree is the input feature set common words and N-grams inserted with their label as additional feature\n        3. process a training set with a grammar checker and syntax to bootstrap a \"complete sentence\" labeler.\n        4. process each 1-3 line window (breaking on empty lines) with syntax net to label them\n        5. label each 1-3-line window of lines as \"complete sentence, partial sentence/phrase, or multi-sentence\"\n\n    >>> 10000 > len(segment_sentences(path=os.path.join(DATA_PATH, 'book'))) >= 4\n    True\n    >>> len(segment_sentences(path=os.path.join(DATA_PATH, 'psychology-scripts.txt'), splitter=split_sentences_nltk))\n    23\n    \"\"\"\n    sentences = []\n    if os.path.isdir(path):\n        for filemeta in find_files(path, **find_files_kwargs):\n            with open(filemeta['path']) as fin:\n                i, batch = 0, []\n                try:\n                    for i, line in enumerate(fin):\n                        if not line.strip():\n                            sentences.extend(splitter('\\n'.join(batch)))\n                            batch = [line]  # may contain all whitespace\n                        else:\n                            batch.append(line)\n                except (UnicodeDecodeError, IOError):\n                    logger.error('UnicodeDecodeError or IOError on line {} in file {} from stat: {}'.format(\n                        i + 1, fin.name, filemeta))\n                    raise\n\n                if len(batch):\n                    # TODO: tag sentences with line + filename where they started\n                    sentences.extend(splitter('\\n'.join(batch)))\n    else:\n        batch = []\n        for i, line in enumerate(iter_lines(path)):\n            # TODO: filter out code and meta lines using asciidoc or markdown parser\n            # split into batches based on empty lines\n            if not line.strip():\n                sentences.extend(splitter('\\n'.join(batch)))\n                # first line may contain all whitespace\n                batch = [line]\n            else:\n                batch.append(line)\n        if len(batch):\n            # TODO: tag sentences with line + filename where they started\n            sentences.extend(splitter('\\n'.join(batch)))\n\n    return sentences"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfix the invalid hunspellToJSON. py json format by inserting double - quotes in list of affix strings in list of affixes in json file that doesn t properly quote badjson_path goodjson_path", "response": "def fix_hunspell_json(badjson_path='en_us.json', goodjson_path='en_us_fixed.json'):\n    \"\"\"Fix the invalid hunspellToJSON.py json format by inserting double-quotes in list of affix strings\n\n    Args:\n      badjson_path (str): path to input json file that doesn't properly quote\n      goodjson_path (str): path to output json file with properly quoted strings in list of affixes\n\n    Returns:\n      list of all words with all possible affixes in *.txt format (simplified .dic format)\n\n    References:\n      Syed Faisal Ali 's Hunspell dic parser: https://github.com/SyedFaisalAli/HunspellToJSON\n    \"\"\"\n    with open(badjson_path, 'r') as fin:\n        with open(goodjson_path, 'w') as fout:\n            for i, line in enumerate(fin):\n                line2 = regex.sub(r'\\[(\\w)', r'[\"\\1', line)\n                line2 = regex.sub(r'(\\w)\\]', r'\\1\"]', line2)\n                line2 = regex.sub(r'(\\w),(\\w)', r'\\1\",\"\\2', line2)\n                fout.write(line2)\n\n    with open(goodjson_path, 'r') as fin:\n        words = []\n        with open(goodjson_path + '.txt', 'w') as fout:\n            hunspell = json.load(fin)\n            for word, affixes in hunspell['words'].items():\n                words += [word]\n                fout.write(word + '\\n')\n                for affix in affixes:\n                    words += [affix]\n                    fout.write(affix + '\\n')\n\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the words in a corpus and return a TfidfVectorizer and all the TFIDF vectors for the corpus.", "response": "def tfidf_corpus(docs=CORPUS):\n    \"\"\" Count the words in a corpus and return a TfidfVectorizer() as well as all the TFIDF vecgtors for the corpus\n\n    Args:\n      docs (iterable of strs): a sequence of documents (strings)\n\n    Returns:\n      (TfidfVectorizer, tfidf_vectors)\n    \"\"\"\n    vectorizer = TfidfVectorizer()\n    vectorizer = vectorizer.fit(docs)\n    return vectorizer, vectorizer.transform(docs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting a string on __eot__ markders", "response": "def split_turns(s, splitter=re.compile('__eot__')):\n    \"\"\" Split a string on __eot__ markders (turns) \"\"\"\n    for utterance in splitter.split(s):\n        utterance = utterance.replace('__eou__', '\\n')\n        utterance = utterance.replace('__eot__', '')\n        if len(utterance.strip()):\n            yield utterance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits all strings in df. Context and df. Utterance on __eot__ ( turn ) markers", "response": "def preprocess_ubuntu_corpus(df):\n    \"\"\"Split all strings in df.Context and df.Utterance on __eot__ (turn) markers \"\"\"\n    statements = []\n    replies = []\n    for i, record in tqdm(df.iterrows()):\n        turns = list(split_turns(record.Context))\n        statement = turns[-1] if len(turns) else '\\n'  # <1>\n        statements.append(statement)\n        turns = list(split_turns(record.Utterance))\n        reply = turns[-1] if len(turns) else '\\n'\n        replies.append(reply)\n    df['statement'] = statements\n    df['reply'] = replies\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_ubuntu_dialog(df):\n    s = ''\n    for i, record in df.iterrows():\n        statement = list(split_turns(record.Context))[-1]  # <1>\n        reply = list(split_turns(record.Utterance))[-1]  # <2>\n        s += 'Statement: {}\\n'.format(statement)\n        s += 'Reply: {}\\n\\n'.format(reply)\n    return s", "response": "Format a Ubuntu dialog to be displayed in a human readable format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike os. path. splitext except splits compound extensions as one long one", "response": "def splitext(filepath):\n    \"\"\" Like os.path.splitext except splits compound extensions as one long one\n\n    >>> splitext('~/.bashrc.asciidoc.ext.ps4.42')\n    ('~/.bashrc', '.asciidoc.ext.ps4.42')\n    >>> splitext('~/.bash_profile')\n    ('~/.bash_profile', '')\n    \"\"\"\n    exts = getattr(CRE_FILENAME_EXT.search(filepath), 'group', str)()\n    return (filepath[:(-len(exts) or None)], exts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving all regular expressions to a tsv file so that they can be more easily copy / pasted in Sublime", "response": "def to_tsv():\n    \"\"\" Save all regular expressions to a tsv file so they can be more easily copy/pasted in Sublime \"\"\"\n    with open(os.path.join(DATA_PATH, 'regexes.tsv'), mode='wt') as fout:\n        vars = copy.copy(tuple(globals().items()))\n        for k, v in vars:\n            if k.lower().startswith('cre_'):\n                fout.write(k[4:] + '\\t' + v.pattern + '\\n')\n            elif k.lower().startswith('re_'):\n                fout.write(k[3:] + '\\t' + v.pattern + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stdout_logging(loglevel=logging.INFO):\n    logformat = \"[%(asctime)s] %(levelname)s:%(name)s:%(lineno)d: %(message)s\"\n\n    logging.config.dictConfig(level=loglevel, stream=sys.stdout,\n                              format=logformat, datefmt=\"%Y-%m-%d %H:%M:%S\")", "response": "Setup basic logging for stdout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot an offline scatter plot colored according to the categories in the name column.", "response": "def offline_plotly_scatter3d(df, x=0, y=1, z=-1):\n    \"\"\" Plot an offline scatter plot colored according to the categories in the 'name' column.\n\n    >> df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/iris.csv')\n    >> offline_plotly(df)\n    \"\"\"\n    data = []\n    # clusters = []\n    colors = ['rgb(228,26,28)', 'rgb(55,126,184)', 'rgb(77,175,74)']\n\n    # df.columns = clean_columns(df.columns)\n\n    x = get_array(df, x, default=0)\n    y = get_array(df, y, default=1)\n    z = get_array(df, z, default=-1)\n    for i in range(len(df['name'].unique())):\n        name = df['Name'].unique()[i]\n        color = colors[i]\n        x = x[pd.np.array(df['name'] == name)]\n        y = y[pd.np.array(df['name'] == name)]\n        z = z[pd.np.array(df['name'] == name)]\n\n        trace = dict(\n            name=name,\n            x=x, y=y, z=z,\n            type=\"scatter3d\",\n            mode='markers',\n            marker=dict(size=3, color=color, line=dict(width=0)))\n        data.append(trace)\n\n    layout = dict(\n        width=800,\n        height=550,\n        autosize=False,\n        title='Iris dataset',\n        scene=dict(\n            xaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            yaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            zaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            aspectratio=dict(x=1, y=1, z=0.7),\n            aspectmode='manual'\n        ),\n    )\n\n    fig = dict(data=data, layout=layout)\n\n    # IPython notebook\n    # plotly.iplot(fig, filename='pandas-3d-iris', validate=False)\n\n    url = plotly.offline.plot(fig, filename='pandas-3d-iris', validate=False)\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a text label to the plot of a DataFrame indicated by the provided axis.", "response": "def annotate(row, ax, x='x', y='y', text='name', xytext=(7, -5), textcoords='offset points', **kwargs):\n    \"\"\"Add a text label to the plot of a DataFrame indicated by the provided axis (ax).\n\n    Reference:\n       https://stackoverflow.com/a/40979683/623735\n    \"\"\"\n    # idx = row.name\n    text = row[text] if text in row else str(text)\n    x = row[x] if x in row else float(x)\n    y = row[y] if y in row else float(y)\n    ax.annotate(text, (row[x], row[y]), xytext=xytext, textcoords=textcoords, **kwargs)\n    return row[text]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreformat a dataframe in etpinard s format for use in sklearn models", "response": "def normalize_etpinard_df(df='https://plot.ly/~etpinard/191.csv', columns='x y size text'.split(),\n                          category_col='category', possible_categories=['Africa', 'Americas', 'Asia', 'Europe', 'Oceania']):\n    \"\"\"Reformat a dataframe in etpinard's format for use in plot functions and sklearn models\"\"\"\n    possible_categories = ['Africa', 'Americas', 'Asia', 'Europe',\n                           'Oceania'] if possible_categories is None else possible_categories\n    df.columns = clean_columns(df.columns)\n    df = pd.read_csv(df) if isinstance(df, str) else df\n    columns = clean_columns(list(columns))\n    df2 = pd.DataFrame(columns=columns)\n    df2[category_col] = np.concatenate([np.array([categ] * len(df)) for categ in possible_categories])\n    columns = zip(columns, [[clean_columns(categ + ', ' + column) for categ in possible_categories] for column in columns])\n    for col, category_cols in columns:\n        df2[col] = np.concatenate([df[label].values for label in category_cols])\n    return df2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_hex(i, num_bytes=4, prefix='0x'):\n    prefix = str(prefix or '')\n    i = int(i or 0)\n    return prefix + '{0:0{1}x}'.format(i, num_bytes)", "response": "Format hexidecimal string from decimal integer value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure that there s a scheme specified at the beginning of a url.", "response": "def prepend_http(url):\n    \"\"\" Ensure there's a scheme specified at the beginning of a url, defaulting to http://\n\n    >>> prepend_http('duckduckgo.com')\n    'http://duckduckgo.com'\n    \"\"\"\n    url = url.lstrip()\n    if not urlparse(url).scheme:\n        return 'http://' + url\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_markdown_levels(lines, levels=set((0, 1, 2, 3, 4, 5, 6))):\n    if isinstance(levels, (int, float, basestring, str, bytes)):\n        levels = [float(levels)]\n    levels = set([int(i) for i in levels])\n    if isinstance(lines, basestring):\n        lines = lines.splitlines()\n    level_lines = []\n    for line in lines:\n        level_line = None\n        if 0 in levels:\n            level_line = (0, line)\n        lstripped = line.lstrip()\n        for i in range(6, 1, -1):\n            if lstripped.startswith('#' * i):\n                level_line = (i, lstripped[i:].lstrip())\n                break\n        if level_line and level_line[0] in levels:\n            level_lines.append(level_line)\n    return level_lines", "response": "r Return a list of 2 - tuples with a level integer for the heading levels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the UTF8 char descriptions returning DataFrame with ascii and mutliascii", "response": "def parse_utf_html(url=os.path.join(DATA_PATH, 'utf8_table.html')):\n    \"\"\" Parse HTML table UTF8 char descriptions returning DataFrame with `ascii` and `mutliascii` \"\"\"\n    utf = pd.read_html(url)\n    utf = [df for df in utf if len(df) > 1023 and len(df.columns) > 2][0]\n    utf = utf.iloc[:1024] if len(utf) == 1025 else utf\n    utf.columns = 'char name hex'.split()\n    utf.name = utf.name.str.replace('<control>', 'CONTTROL CHARACTER')\n    multiascii = [' '] * len(utf)\n    asc = [' '] * len(utf)\n    rows = []\n    for i, name in enumerate(utf.name):\n        if i < 128 and str.isprintable(chr(i)):\n            asc[i] = chr(i)\n        else:\n            asc[i] = ' '\n        big = re.findall(r'CAPITAL\\ LETTER\\ ([a-z0-9A-Z ]+$)', name)\n        small = re.findall(r'SMALL\\ LETTER\\ ([a-z0-9A-Z ]+$)', name)\n        pattern = r'(?P<description>' \\\n                      r'(?P<lang>LATIN|GREEK|COPTIC|CYRILLIC)?[\\s]*' \\\n                      r'(?P<case>CAPITAL|SMALL)?[\\s]*' \\\n                      r'(?P<length>CHARACTER|LETTER)?[\\s]*' \\\n                      r'(?P<ukrainian>BYELORUSSIAN-UKRAINIAN)?[\\s]*' \\\n                      r'(?P<name>[-_><a-z0-9A-Z\\s ]+)[\\s]*' \\\n                      r'\\(?(?P<code_point>U\\+[- a-fA-F0-9]{4,8})?\\)?)[\\s]*'  # noqa\n        match = re.match(pattern, name)\n        gd = match.groupdict()\n        gd['char'] = chr(i)\n        gd['suffix'] = None\n        gd['wordwith'] = None\n\n        withprefix = re.match(r'(?P<prefix>DOTLESS|TURNED|SMALL)(?P<name>.*)' +\n                              r'(?P<wordwith>WITH|SUPERSCRIPT|SUBSCRIPT|DIGRAPH)\\s+(?P<suffix>[-_><a-z0-9A-Z\\s ]+)',\n                              gd['name'])\n        if withprefix:\n            gd.update(withprefix.groupdict())\n\n        withsuffix = re.match(r'(?P<name>.*)(?P<wordwith>WITH|SUPERSCRIPT|SUBSCRIPT|DIGRAPH)\\s+' +\n                              r'(?P<suffix>[-_><a-z0-9A-Z\\s ]+)',\n                              gd['name'])\n        if withsuffix:\n            gd.update(withsuffix.groupdict())\n\n        gd['code_point'] = gd['code_point'] or format_hex(i, num_bytes=4, prefix='U+').upper()\n        if i < 128:\n            gd['ascii'] = chr(i)\n        else:\n            multiascii = gd['name']\n            if gd['suffix'] and gd['wordwith']:\n                multiascii = NAME_ACCENT.get(gd['suffix'], \"'\")\n            else:\n                if big:\n                    m = big[0]\n                    multiascii[i] = m\n                    if len(m) == 1:\n                        asc[i] = m\n                elif small:\n                    multiascii[i] = small[0].lower()\n                    if len(multiascii[i]) == 1:\n                        asc[i] = small[0].lower()\n        rows.append(gd)\n    df = pd.DataFrame(rows)\n    df.multiascii = df.multiascii.str.strip()\n    df['ascii'] = df['ascii'].str.strip()\n    df.name = df.name.str.strip()\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_csvs(dialogpath=None):\n    dialogdir = os.dirname(dialogpath) if os.path.isfile(dialogpath) else dialogpath\n    filenames = [dialogpath.split(os.path.sep)[-1]] if os.path.isfile(dialogpath) else os.listdir(dialogpath)\n    for filename in filenames:\n        filepath = os.path.join(dialogdir, filename)\n        df = clean_df(filepath)\n        df.to_csv(filepath, header=None)\n    return filenames", "response": "Translate non - ASCII characters to spaces or equivalent ASCII characters"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate Unicode characters to ASCII.", "response": "def unicode2ascii(text, expand=True):\n    r\"\"\" Translate UTF8 characters to ASCII\n\n    >> unicode2ascii(\"\u017c\u00f3\u0142w\")\n    zozw\n\n    utf8_letters =  '\u0105 \u0119 \u0107 \u017a \u017c \u00f3 \u0142 \u0144 \u015b \u201c \u201d \u2019'.split()\n    ascii_letters = 'a e c z z o l n s \" \" \\''\n    \"\"\"\n    translate = UTF8_TO_ASCII if not expand else UTF8_TO_MULTIASCII\n    output = ''\n    for c in text:\n        if not c or ord(c) < 128:\n            output += c\n        else:\n            output += translate[c] if c in translate else ' '\n    return output.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_df(df, header=None, **read_csv_kwargs):\n    df = read_csv(df, header=header, **read_csv_kwargs)\n    df = df.fillna(' ')\n    for col in df.columns:\n        df[col] = df[col].apply(unicode2ascii)\n    return df", "response": "Convert UTF8 characters in a CSV file or dataframe into ASCII\n     "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_lines(file_path=BOOK_PATH):\n    if os.path.isdir(file_path):\n        file_path = os.path.join(file_path, '*.asc')\n        files = glob.glob(file_path)\n    elif os.path.isfile(file_path):\n        files = [file_path]\n    elif '*' in file_path:\n        if os.path.sep not in file_path:\n            file_path = os.path.join(os.path.abspath(os.path.curdir), file_path)\n        files = glob.glob(file_path)\n    else:\n        raise FileNotFoundError(\"Unable to find the directory or files requested.\")\n    lines = []\n    for filepath in files:\n        with open(filepath, 'r') as f:\n            lines.append(f.readlines())\n    return zip(files, lines)", "response": "r Returns a list of lists of str one list for each Chapter or Appendix item in the directory containing manuscript Chapter. asc and Appendix. asc files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind all the 2 and 3 - letter acronyms in the manuscript and return as a sorted list of tuples", "response": "def get_acronyms(manuscript=os.path.expanduser('~/code/nlpia/lane/manuscript')):\n    \"\"\" Find all the 2 and 3-letter acronyms in the manuscript and return as a sorted list of tuples \"\"\"\n    acronyms = []\n    for f, lines in get_lines(manuscript):\n        for line in lines:\n            matches = CRE_ACRONYM.finditer(line)\n            if matches:\n                for m in matches:\n                    if m.group('a2'):\n                        acronyms.append((m.group('a2'), m.group('s2')))\n                    elif m.group('a3'):\n                        acronyms.append((m.group('a3'), m.group('s3')))\n                    elif m.group('a4'):\n                        acronyms.append((m.group('a4'), m.group('s4')))\n                    elif m.group('a5'):\n                        acronyms.append((m.group('a5'), m.group('s5')))\n\n    return sorted(dict(acronyms).items())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an asciidoc string with acronyms culled from the manuscript", "response": "def write_glossary(manuscript=os.path.expanduser('~/code/nlpia/lane/manuscript'), linesep=None):\n    \"\"\" Compose an asciidoc string with acronyms culled from the manuscript \"\"\"\n    linesep = linesep or os.linesep\n    lines = ['[acronyms]', '== Acronyms', '', '[acronyms,template=\"glossary\",id=\"terms\"]']\n    acronyms = get_acronyms(manuscript)\n    for a in acronyms:\n        lines.append('*{}*:: {} -- '.format(a[0], a[1][0].upper() + a[1][1:]))\n    return linesep.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntag a list of lines from manuscript with a list of lines.", "response": "def tag_lines(lines, include_tags=None):\n    r\"\"\" Naively tags lines from manuscript with: code, natural, heading, etc.\n\n    Returns:\n        list of tuples  [(tag, line), ...]\n\n    >>> ' '.join(sorted(VALID_TAGS))\n    'anchor attribute blank_line block_header caption code code_end code_header code_start\n     comment comment_end comment_start image_link latexmath latexmath_end latexmath_start\n     natural natural_asside natural_asside_end natural_asside_start natural_end\n     natural_heading1 natural_heading2 natural_heading3 natural_heading4 natural_heading5\n     natural_quote natural_quote_end natural_quote_start\n     natural_sidenote natural_sidenote_end natural_sidenote_start natural_start'\n    >>> list(tag_lines('|= Title| :chapter: 0|Hello|cruel world|==Heading Level 2| \\t| [source,bash]|====|$ grep this|====|'\\\n    ...                .split('|')))\n    [('blank_line', ''), ('natural_heading1', '= Title'), ('attribute', ' :chapter: 0'),\n     ('natural', 'Hello'), ('natural', 'cruel world'), ('natural_heading2', '==Heading Level 2'),\n     ('blank_line', ' \\t'), ('code_header', ' [source,bash]'),\n     ('code_start', '===='), ('code', '$ grep this'), ('code_end', '===='), ('blank_line', '')]\n    \"\"\"\n    current_block_type = None\n    block_terminator = None\n    tag = ''\n    tagged_lines = []\n    for idx, line in enumerate(lines):\n        normalized_line = line.lower().strip().replace(\" \", \"\")\n        # [source,...] with or without any following \"----\" block delimiter\n        # TODO: make this a regex that classifies among the different types (source, glossary, tip, etc)\n        header_type = next((HEADER_TYPES[i] for i in range(len(HEADER_TYPES)) if\n                            normalized_line.startswith('[') and normalized_line[1:].startswith(HEADER_TYPES[i][0])),\n                           None)\n        if header_type:\n            current_block_type = header_type[1]\n            tag = current_block_type + '_header'\n            block_terminator = None\n        elif normalized_line[:4] in BLOCK_HEADERS4:\n            current_block_type = BLOCK_HEADERS4[normalized_line[:4]]\n            tag = current_block_type + '_header'  # BLOCK_HEADERS[normalized_line]\n            block_terminator = None\n        elif (\n                CRE_BLOCK_DELIMITER.match(normalized_line) and\n                normalized_line[:2] in BLOCK_DELIMITERS):  # or (tag in set('caption anchor'.split()))):\n            if (not idx or not current_block_type or not block_terminator):\n                current_block_type = (current_block_type or BLOCK_DELIMITERS[normalized_line[:2]])\n                tag = current_block_type + '_start'\n                block_terminator = normalized_line\n            elif block_terminator and line.rstrip() == block_terminator:\n                tag = current_block_type + '_end'\n                current_block_type = None\n                block_terminator = None\n            else:\n                tag = current_block_type\n        elif current_block_type and (line.rstrip() == block_terminator or \n                                     (not block_terminator and not normalized_line)):\n            tag = current_block_type + '_end'\n            current_block_type = None\n            block_terminator = None\n        elif current_block_type:\n            tag = current_block_type\n        elif not normalized_line:\n            tag = 'blank_line'\n        elif normalized_line.startswith(r'//'):\n            tag = 'comment'\n        elif normalized_line.startswith(r':'):\n            tag = 'attribute'\n        elif normalized_line.startswith('='):\n            tag = 'natural_heading'\n            tag += str(len([c for c in normalized_line[:6].split()[0] if c == '=']))\n        elif normalized_line.startswith('.'):\n            tag = 'caption'\n        elif normalized_line.startswith('image:'):\n            tag = 'image_link'\n        elif normalized_line.startswith('[['):\n            tag = 'anchor'\n        else:\n            tag = 'natural'\n            current_block_type = None\n\n        tagged_lines.append((tag, line))\n\n    return filter_tagged_lines(tagged_lines, include_tags=include_tags)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget list of tagged sections.", "response": "def get_tagged_sections(book_dir=BOOK_PATH, include_tags=None):\n    \"\"\" Get list of (adoc_file_path, (adoc_syntax_tag, raw_line_str))\n\n    >>> get_tagged_sections()\n    [('...src/nlpia/data/book/Appendix F -- Glossary.asc', <generator object filter_tagged_lines at ...>)]\n    \"\"\"\n    return [(filepath, tag_lines(lines, include_tags=include_tags)) for filepath, lines in get_lines(book_dir)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_bad_footnote_urls(tagged_lines, include_tags=None):\n    section_baddies = []\n    logger.debug(tagged_lines[:2])\n    for lineno, (tag, line) in enumerate(tagged_lines):\n        line_baddies = None\n        if tag is None or include_tags is None or tag in include_tags or any((tag.startswith(t) for t in include_tags)):\n            line_baddies = get_line_bad_footnotes(line=line, tag=tag)\n        if line_baddies and len(line_baddies) > 1:\n            section_baddies.append([lineno] + line_baddies[1:])\n        else:\n            pass\n            # section_baddies.append(line)\n    return section_baddies", "response": "Find lines in the list of 2 - tuples of adoc - tagged lines that contain bad footnotes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef infer_url_title(url):\n    meta = get_url_filemeta(url)\n    title = ''\n    if meta:\n        if meta.get('hostname', url) == 'drive.google.com':\n            title = get_url_title(url)\n        else:\n            title = meta.get('filename', meta['hostname']) or meta['hostname']\n            title, fileext = splitext(title)\n    else:\n        logging.error('Unable to retrieve URL: {}'.format(url))\n        return None\n    return delimit_slug(title, ' ')", "response": "Guess what the page title is going to be from the path and FQDN in the URL\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_line_bad_footnotes(line, tag=None, include_tags=None):\n    if tag is None or include_tags is None or tag in include_tags or any((tag.startswith(t) for t in include_tags)):\n        found_baddies = re_bad_footnotes.findall(line)\n        return [line] + [baddie[0] for baddie in found_baddies]\n    return [line]", "response": "Return a list of bad footnotes in a line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate a single line of footnotes into a single footnote.", "response": "def translate_line_footnotes(line, tag=None, default_title='<NOT_FOUND>'):\n    r\"\"\" Find all bare-url footnotes, like \"footnote:[moz.org]\" and add a title like \"footnote:[Moz (moz.org)]\" \n\n    >>> translate_line_footnotes('*Morphemes*:: Parts of tokens or words that contain meaning in and of themselves.'\\\n    ...     'footnote:[https://spacy.io/usage/linguistic-features#rule-based-morphology]')\n    '*Morphemes*:: Parts of tokens or words that contain meaning in and of\n     themselves.footnote:[See the web page titled \"Linguistic Features : spaCy Usage Documentation\"\n     (https://spacy.io/usage/linguistic-features#rule-based-morphology).]'\n    \"\"\"\n    line_urls = get_line_bad_footnotes(line, tag=tag)\n    urls = line_urls[1:] if line_urls else []\n    for url in urls:\n        footnote = 'footnote:[{url}]'.format(url=url)\n        new_footnote = footnote\n        # TODO: use these to extract name from hyperlinks\n        title = get_url_title(url)\n        title = title or infer_url_title(url)\n        title = (title or '').strip(' \\t\\n\\r\\f-_:|=\"\\'/\\\\')\n        title = title if ' ' in (title or 'X') else None\n\n        if title:\n            brief_title = title.split('\\n')[0].strip().split('|')[0].strip().split('\u00c2')[0].strip().split('\u00b7')[0].strip()\n            logging.info('URL: {}'.format(url))\n            logging.info('TITLE: {}'.format(title))\n            title = brief_title if len(brief_title) > 3 and len(title) > 55 else title\n            title = title.replace('\u00c2', '').replace('\u00b7', ':').replace('|', ':').replace('\\n', '--')\n            logging.info('FINAL: {}'.format(title))\n        title = title or default_title\n        if title:\n            new_footnote = 'footnote:[See the web page titled \"{title}\" ({url}).]'.format(title=(title or default_title), url=url)\n        elif title is None:\n            logging.error('Unable to find a title for url: {}'.format(url))\n        else:\n            new_footnote = 'footnote:[See the web page ({url}).]'.format(url=url)\n        line = line.replace(\n            footnote,\n            new_footnote)\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate a list of hyperlinks into a single file.", "response": "def translate_book(translators=(HyperlinkStyleCorrector().translate, translate_line_footnotes),\n                   book_dir=BOOK_PATH, dest=None, include_tags=None,\n                   ext='.nlpiabak', skip_untitled=True):\n    \"\"\" Fix any style corrections listed in `translate` list of translation functions\n\n    >>> len(translate_book(book_dir=BOOK_PATH, dest='cleaned_hyperlinks'))\n    3\n    >>> rm_rf(os.path.join(BOOK_PATH, 'cleaned_hyperlinks'))\n    \"\"\"\n    if callable(translators) or not hasattr(translators, '__len__'):\n        translators = (translators,)\n\n    sections = get_tagged_sections(book_dir=book_dir, include_tags=include_tags)\n    file_line_maps = []\n\n    for fileid, (filepath, tagged_lines) in enumerate(sections):\n        logger.info('filepath={}'.format(filepath))\n        destpath = filepath\n        if not dest:\n            copyfile(filepath, filepath + '.' + ext.lstrip('.'))\n        elif os.path.sep in dest:\n            destpath = os.path.join(dest, os.path.basename(filepath))\n        else:\n            destpath = os.path.join(os.path.dirname(filepath), dest, os.path.basename(filepath))\n        ensure_dir_exists(os.path.dirname(destpath))\n        with open(destpath, 'w') as fout:\n            logger.info('destpath={}'.format(destpath))\n            for lineno, (tag, line) in enumerate(tagged_lines):\n                if (include_tags is None or tag in include_tags or\n                        any((tag.startswith(t) for t in include_tags))):\n                    for translate in translators:\n                        new_line = translate(line)  # TODO: be smarter about writing to files in-place\n                        if line != new_line:\n                            file_line_maps.append((fileid, lineno, filepath, destpath, line, new_line))\n                            line = new_line\n                fout.write(line)\n    return file_line_maps"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeprecate (see translate_line_footnotes) Find bad footnotes (only urls), visit the page, add the title to the footnote >>> len(correct_hyperlinks(book_dir=BOOK_PATH, dest='cleaned_hyperlinks')) 2 >>> rm_rf(os.path.join(BOOK_PATH, 'cleaned_hyperlinks'))", "response": "def correct_hyperlinks(book_dir=BOOK_PATH, dest=None, include_tags=None,\n                       ext='.nlpiabak', skip_untitled=True):\n    \"\"\" DEPRECATED (see translate_line_footnotes)\n\n    Find bad footnotes (only urls), visit the page, add the title to the footnote \n\n    >>> len(correct_hyperlinks(book_dir=BOOK_PATH, dest='cleaned_hyperlinks'))\n    2\n    >>> rm_rf(os.path.join(BOOK_PATH, 'cleaned_hyperlinks'))\n    \"\"\"\n    # bad_url_lines = find_all_bad_footnote_urls(book_dir=book_dir)\n    # file_line_maps = []\n    return translate_book(translators=HyperlinkStyleCorrector().translate,\n                          book_dir=book_dir, dest=dest, include_tags=include_tags,\n                          ext=ext, skip_untitled=skip_untitled)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate bad footnotes to a single file.", "response": "def correct_bad_footnote_urls(book_dir=BOOK_PATH, dest=None, include_tags=None,\n                              ext='.nlpiabak', skip_untitled=True):\n    \"\"\" DEPRECATED (see translate_line_footnotes)\n\n    Find bad footnotes (only urls), visit the page, add the title to the footnote \n\n    >>> len(correct_bad_footnote_urls(book_dir=BOOK_PATH, dest='cleaned_footnotes'))\n    1\n    >>> rm_r(os.path.join(BOOK_PATH, 'cleaned_footnotes'))\n    \"\"\"\n    # bad_url_lines = find_all_bad_footnote_urls(book_dir=book_dir)\n    # file_line_maps = []\n    return translate_book(translators=translate_line_footnotes, book_dir=book_dir, dest=dest, include_tags=include_tags,\n                          ext=ext, skip_untitled=skip_untitled)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_lines(input_file, output_file, translate=lambda line: line):\n    filepath, lines = get_lines([input_file])[0]\n    return filepath, [(tag, translate(line=line, tag=tag)) for (tag, line) in lines]", "response": "Translate all the lines of a single file into a single file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef accuracy_study(tdm=None, u=None, s=None, vt=None, verbosity=0, **kwargs):\n    smat = np.zeros((len(u), len(vt)))\n    np.fill_diagonal(smat, s)\n    smat = pd.DataFrame(smat, columns=vt.index, index=u.index)\n    if verbosity:\n        print()\n        print('Sigma:')\n        print(smat.round(2))\n        print()\n        print('Sigma without zeroing any dim:')\n        print(np.diag(smat.round(2)))\n    tdm_prime = u.values.dot(smat.values).dot(vt.values)\n    if verbosity:\n        print()\n        print('Reconstructed Term-Document Matrix')\n        print(tdm_prime.round(2))\n\n    err = [np.sqrt(((tdm_prime - tdm).values.flatten() ** 2).sum() / np.product(tdm.shape))]\n    if verbosity:\n        print()\n        print('Error without reducing dimensions:')\n        print(err[-1])\n    # 2.3481474529927113e-15\n\n    smat2 = smat.copy()\n    for numdim in range(len(s) - 1, 0, -1):\n        smat2.iloc[numdim, numdim] = 0\n        if verbosity:\n            print('Sigma after zeroing out dim {}'.format(numdim))\n            print(np.diag(smat2.round(2)))\n            #           d0    d1   d2   d3   d4   d5\n            # ship    2.16  0.00  0.0  0.0  0.0  0.0\n            # boat    0.00  1.59  0.0  0.0  0.0  0.0\n            # ocean   0.00  0.00  0.0  0.0  0.0  0.0\n            # voyage  0.00  0.00  0.0  0.0  0.0  0.0\n            # trip    0.00  0.00  0.0  0.0  0.0  0.0\n\n        tdm_prime2 = u.values.dot(smat2.values).dot(vt.values)\n        err += [np.sqrt(((tdm_prime2 - tdm).values.flatten() ** 2).sum() / np.product(tdm.shape))]\n        if verbosity:\n            print('Error after zeroing out dim {}'.format(numdim))\n            print(err[-1])\n    return err", "response": "Reconstruct the term - document matrix and measure error as SVD terms are truncated\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_anki_phrases(lang='english', limit=None):\n    lang = lang.strip().lower()[:3]\n    lang = LANG2ANKI[lang[:2]] if lang not in ANKI_LANGUAGES else lang\n    if lang[:2] == 'en':\n        return get_anki_phrases_english(limit=limit)\n    return sorted(get_data(lang).iloc[:, -1].str.strip().values)", "response": "Retrieve as many anki paired - statement corpora as you can for the requested language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_anki_phrases_english(limit=None):\n    texts = set()\n    for lang in ANKI_LANGUAGES:\n        df = get_data(lang)\n        phrases = df.eng.str.strip().values\n        texts = texts.union(set(phrases))\n        if limit and len(texts) >= limit:\n            break\n    return sorted(texts)", "response": "Return all the English phrases in the Anki translation flashcards \n\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a DataFrame containing all the words in the given docs along with their POS tags etc.", "response": "def get_vocab(docs):\n    \"\"\" Build a DataFrame containing all the words in the docs provided along with their POS tags etc\n\n    >>> doc = nlp(\"Hey Mr. Tangerine Man!\")\n    <BLANKLINE>\n    ...\n    >>> get_vocab([doc])\n            word    pos  tag       dep ent_type ent_iob  sentiment\n    0          !  PUNCT    .     punct                O        0.0\n    1        Hey   INTJ   UH      intj                O        0.0\n    2        Man   NOUN   NN      ROOT   PERSON       I        0.0\n    3        Mr.  PROPN  NNP  compound                O        0.0\n    4  Tangerine  PROPN  NNP  compound   PERSON       B        0.0\n    \"\"\"\n    if isinstance(docs, spacy.tokens.doc.Doc):\n        return get_vocab([docs])\n    vocab = set()\n    for doc in tqdm(docs):\n        for tok in doc:\n            vocab.add((tok.text, tok.pos_, tok.tag_, tok.dep_, tok.ent_type_, tok.ent_iob_, tok.sentiment))\n    # TODO: add ent type info and other flags, e.g. like_url, like_email, etc\n    return pd.DataFrame(sorted(vocab), columns='word pos tag dep ent_type ent_iob sentiment'.split())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_word_vectors(vocab):\n    wv = get_data('word2vec')\n    vectors = np.array(len(vocab), len(wv['the']))\n    for i, tok in enumerate(vocab):\n        word = tok[0]\n        variations = (word, word.lower(), word.lower()[:-1])\n        for w in variations:\n            if w in wv:\n                vectors[i, :] = wv[w]\n        if not np.sum(np.abs(vectors[i])):\n            logger.warning('Unable to find {}, {}, or {} in word2vec.'.format(*variations))\n    return vectors", "response": "Create a word2vec embedding matrix for all the words in the vocab."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_anki_vocab(lang=['eng'], limit=None, filename='anki_en_vocabulary.csv'):\n    texts = get_anki_phrases(lang=lang, limit=limit)\n    docs = nlp(texts, lang=lang)\n    vocab = get_vocab(docs)\n    vocab['vector'] = get_word_vectors(vocab)  # TODO: turn this into a KeyedVectors object\n    if filename:\n        vocab.to_csv(os.path.join(BIGDATA_PATH, filename))\n    return vocab", "response": "Get all the words tags and wordvectors for the tokens in the Anki translation corpus"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lsa_twitter(cased_tokens):\n\n    # Only 5 of these tokens are saved for a no_below=2 filter:\n    #   PyCons NLPS #PyCon2016 #NaturalLanguageProcessing #naturallanguageprocessing\n    if cased_tokens is None:\n        cased_tokens = ('PyConOpenSpaces PyCon PyCon2017 PyCon2018 PyCon2016 PyCon2015 OpenSpace PyconTutorial ' +\n                        'NLP NaturalLanguageProcessing NLPInAction NaturalLanguageProcessingInAction NLPIA Twote Twip'\n                        ).split()\n        cased_tokens += [s + 's' for s in cased_tokens]\n\n        cased_tokens += 'TotalGood TotalGoods HobsonLane Hob Hobs TotalGood.com ' \\\n                        'www.TotalGood.com http://www.TotalGood.com https://www.TotalGood.com'.split()\n\n    allcase_tokens = cased_tokens + [s.lower() for s in cased_tokens]\n    allcase_tokens += [s.title() for s in cased_tokens]\n    allcase_tokens += [s.upper() for s in cased_tokens]\n    KEEP_TOKENS = allcase_tokens + ['#' + s for s in allcase_tokens]\n\n    # takes 15 minutes and 10GB of RAM for 500k tweets if you keep all 20M unique tokens/names URLs\n    vocab_path = os.path.join(BIGDATA_PATH, 'vocab939370.pkl')\n    if os.path.isfile(vocab_path):\n        print('Loading vocab: {} ...'.format(vocab_path))\n        vocab = Dictionary.load(vocab_path)\n        print(' len(vocab) loaded: {}'.format(len(vocab.dfs)))\n    else:\n        tweets_path = os.path.join(BIGDATA_PATH, 'tweets.csv.gz')\n        print('Loading tweets: {} ...'.format(tweets_path))\n        tweets = read_csv(tweets_path)\n        tweets = pd.np.array(tweets.text.str.split())\n        with gzip.open(os.path.join(BIGDATA_PATH, 'tweets.txt.gz'), 'w') as f:\n            for tokens in tweets:\n                f.write((' '.join(tokens) + '\\n').encode('utf-8'))\n        # tweets['text'] = tweets.text.apply(lambda s: eval(s).decode('utf-8'))\n        # tweets['user'] = tweets.user.apply(lambda s: eval(s).decode('utf-8'))\n        # tweets.to_csv('tweets.csv.gz', compression='gzip')\n        print('Computing vocab from {} tweets...'.format(len(tweets)))\n        vocab = Dictionary(tweets, no_below=NO_BELOW, no_above=NO_ABOVE, keep_tokens=set(KEEP_TOKENS))\n\n    vocab.filter_extremes(no_below=NO_BELOW, no_above=NO_ABOVE, keep_n=KEEP_N, keep_tokens=set(KEEP_TOKENS))\n    print(' len(vocab) after filtering: {}'.format(len(vocab.dfs)))\n\n    # no time at all, just a bookeeping step, doesn't actually compute anything\n    tfidf = TfidfModel(id2word=vocab, dictionary=vocab)\n    tfidf.save(os.path.join(BIGDATA_PATH, 'tfidf{}.pkl'.format(len(vocab.dfs))))\n\n    tweets = [vocab.doc2bow(tw) for tw in tweets]\n    json.dump(tweets, gzip.open(os.path.join(BIGDATA_PATH, 'tweet_bows.json.gz'), 'w'))\n\n    gc.collect()\n\n    # LSA is more useful name than LSA\n    lsa = LsiModel(tfidf[tweets], num_topics=200, id2word=vocab, extra_samples=100, power_iters=2)\n\n    return lsa", "response": "This function returns a list of words that are available in the LSA twitter search."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all files and directories in a directory.", "response": "def ls(path, force=False):\n    \"\"\" bash `ls -a`: List both file paths or directory contents (files and directories)\n\n    >>> ls('.')\n    [...]\n    >>> ls('~/')\n    [...]\n\n    >>> __file__.endswith(os.path.join('nlpia', 'futil.py'))\n    True\n    >>> ls(__file__).endswith(os.path.join('nlpia', 'futil.py'))\n    True\n    \"\"\"\n    path = expand_filepath(path)\n    logger.debug('path={}'.format(path))\n    if os.path.isfile(path):\n        return path\n    elif os.path.isdir(path):\n        return os.listdir(path)\n    elif not force:\n        return os.listdir(path)\n    try:\n        return os.listdir(path)\n    except IOError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rm_r(path, force=False):\n    path = expand_filepath(path)\n    logger.debug('path={}'.format(path))\n    if os.path.isfile(path):\n        return os.remove(path)\n    elif os.path.isdir(path):\n        try:\n            return os.rmdir(path)\n        except OSError:  # OSError: [Errno 66] Directory not empty: \n            pass\n        except:\n            if not force:\n                raise\n    elif not force:\n        return os.rmdir(path)\n    names = ls(path, force=force)\n    # if ls() returns a list, path must be the full path to a directory\n    if isinstance(names, list):\n        if names:\n            for filename in names:\n                return rm_r(os.path.join(path, filename), force=force)\n        else:\n            os.rmdir(path)\n    # if ls() returns a str, path must be the full path to a file\n    elif isinstance(names, str):\n        return os.remove(names, force=force)\n    if force:\n        return None\n    return os.rmdir(path)", "response": "rm - r recursively removes the directory structure of a single object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpand any ~.. * variables in filepath.", "response": "def expand_filepath(filepath):\n    \"\"\" Expand any '~', '.', '*' variables in filepath.\n\n    See also: pugnlp.futil.expand_path\n\n    >>> len(expand_filepath('~')) > 3\n    True\n    \"\"\"\n    return os.path.abspath(os.path.expandvars(os.path.expanduser(filepath)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts file extensions to normalized form e. g.. tgz. gz. w2v. bin. gz. w2v. bin. gz.", "response": "def normalize_ext(filepath):\n    \"\"\" Convert file extension(s) to normalized form, e.g. '.tgz' -> '.tar.gz'\n\n    Normalized extensions are ordered in reverse order of how they should be processed.\n    Also extensions are ordered in order of decreasing specificity/detail.\n    e.g. zip last, then txt/bin, then model type, then model dimensionality\n\n    .TGZ => .tar.gz\n    .ZIP => .zip\n    .tgz => .tar.gz\n    .bin.gz => .w2v.bin.gz\n    .6B.zip => .6B.glove.txt.zip\n    .27B.zip => .27B.glove.txt.zip\n    .42B.300d.zip => .42B.300d.glove.txt.zip\n    .840B.300d.zip => .840B.300d.glove.txt.zip\n\n    FIXME: Don't do this! Stick with the original file names and let the text loader figure out what it is!\n    TODO: use regexes to be more general (deal with .300D and .42B extensions)\n\n    >>> normalize_ext('glove.42B.300d.zip')\n    'glove.42B.300d.glove.txt.zip'\n    \"\"\"\n    mapping = tuple(reversed((\n        ('.tgz', '.tar.gz'),\n        ('.bin.gz', '.w2v.bin.gz'),\n        ('.6B.zip', '.6b.glove.txt.zip'),\n        ('.42B.zip', '.42b.glove.txt.zip'),\n        ('.27B.zip', '.27b.glove.txt.zip'),\n        ('.300d.zip', '.300d.glove.txt.zip'),\n    )))\n    if not isinstance(filepath, str):\n        return [normalize_ext(fp) for fp in filepath]\n    if '~' == filepath[0] or '$' in filepath:\n        filepath = expand_filepath(filepath)\n    fplower = filepath.lower()\n    for ext, newext in mapping:\n        r = ext.lower().replace('.', r'\\.') + r'$'\n        r = r'^[.]?([^.]*)\\.([^.]{1,10})*' + r\n        if re.match(r, fplower) and not fplower.endswith(newext):\n            filepath = filepath[:-len(ext)] + newext\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_filepath(filepath):\n    filename = os.path.basename(filepath)\n    dirpath = filepath[:-len(filename)]\n    cre_controlspace = re.compile(r'[\\t\\r\\n\\f]+')\n    new_filename = cre_controlspace.sub('', filename)\n    if not new_filename == filename:\n        logger.warning('Stripping whitespace from filename: {} => {}'.format(\n            repr(filename), repr(new_filename)))\n        filename = new_filename\n    filename = filename.lower()\n    filename = normalize_ext(filename)\n    if dirpath:\n        dirpath = dirpath[:-1]  # get rid of the trailing os.path.sep\n        return os.path.join(dirpath, filename)\n    return filename", "response": "Normalize the filename and extension of a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the filepath of a file or path in a common path.", "response": "def find_filepath(\n        filename,\n        basepaths=(os.path.curdir, DATA_PATH, BIGDATA_PATH, BASE_DIR, '~', '~/Downloads', os.path.join('/', 'tmp'), '..')):\n    \"\"\" Given a filename or path see if it exists in any of the common places datafiles might be\n\n    >>> p = find_filepath('iq_test.csv')\n    >>> p == expand_filepath(os.path.join(DATA_PATH, 'iq_test.csv'))\n    True\n    >>> p[-len('iq_test.csv'):]\n    'iq_test.csv'\n    >>> find_filepath('exponentially-crazy-filename-2.718281828459045.nonexistent')\n    False\n    \"\"\"\n    if os.path.isfile(filename):\n        return filename\n    for basedir in basepaths:\n        fullpath = expand_filepath(os.path.join(basedir, filename))\n        if os.path.isfile(fullpath):\n            return fullpath\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading text from filepath then json. loads", "response": "def read_json(filepath, intkeys=True, intvalues=True):\n    \"\"\" read text from filepath (`open(find_filepath(expand_filepath(fp)))`) then json.loads()\n    \n    >>> read_json('HTTP_1.1  Status Code Definitions.html.json')\n    {'100': 'Continue',\n     '101': 'Switching Protocols',...\n    \"\"\"\n    d = json.load(ensure_open(find_filepath(filepath), mode='rt'))\n    d = update_dict_types(d, update_keys=intkeys, update_values=intvalues)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef looks_like_index(series, index_names=('Unnamed: 0', 'pk', 'index', '')):\n    if series.name in index_names:\n        return True\n    if (series == series.index.values).all():\n        return True\n    if (series == np.arange(len(series))).all():\n        return True\n    if (\n        (series.index == np.arange(len(series))).all() and\n        str(series.dtype).startswith('int') and\n        (series.count() == len(series))\n    ):\n        return True\n    return False", "response": "Checks if the Series is the index_col\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking pandas. read_csv but only little smarter", "response": "def read_csv(*args, **kwargs):\n    \"\"\"Like pandas.read_csv, only little smarter: check left column to see if it should be the index_col\n\n    >>> read_csv(os.path.join(DATA_PATH, 'mavis-batey-greetings.csv')).head()\n                                                    sentence  is_greeting\n    0     It was a strange little outfit in the cottage.            0\n    1  Organisation is not a word you would associate...            0\n    2  When I arrived, he said: \"Oh, hello, we're bre...            0\n    3                                       That was it.            0\n    4                I was never really told what to do.            0\n    \"\"\"\n    kwargs.update({'low_memory': False})\n    if isinstance(args[0], pd.DataFrame):\n        df = args[0]\n    else:\n        logger.info('Reading CSV with `read_csv(*{}, **{})`...'.format(args, kwargs))\n        df = pd.read_csv(*args, **kwargs)\n    if looks_like_index(df[df.columns[0]]):\n        df = df.set_index(df.columns[0], drop=True)\n        if df.index.name in ('Unnamed: 0', ''):\n            df.index.name = None\n    if ((str(df.index.values.dtype).startswith('int') and (df.index.values > 1e9 * 3600 * 24 * 366 * 10).any()) or\n            (str(df.index.values.dtype) == 'object')):\n        try:\n            df.index = pd.to_datetime(df.index)\n        except (ValueError, TypeError, pd.errors.OutOfBoundsDatetime):\n            logger.info('Unable to coerce DataFrame.index into a datetime using pd.to_datetime([{},...])'.format(\n                df.index.values[0]))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_text(forfn, nrows=None, verbose=True):\n    tqdm_prog = tqdm if verbose else no_tqdm\n    nrows = wc(forfn, nrows=nrows)  # not necessary when nrows==None\n    lines = np.empty(dtype=object, shape=nrows)\n    with ensure_open(forfn) as f:\n        for i, line in enumerate(tqdm_prog(f, total=nrows)):\n            if i >= len(lines):\n                break\n            lines[i] = ensure_str(line).rstrip('\\n').rstrip('\\r')\n        if all('\\t' in line for line in lines):\n            num_tabs = [sum([1 for c in line if c == '\\t']) for line in lines]\n            del lines\n            if all(i == num_tabs[0] for i in num_tabs):\n                f.seek(0)\n                return read_csv(f, sep='\\t', header=None, nrows=nrows)\n        elif sum((1 for line in lines if any((tag.lower() in line.lower() for tag in HTML_TAGS)))\n                ) / float(len(lines)) > .05:\n            return np.array(html2text(EOL.join(lines)).split(EOL))\n    return lines", "response": "r Read all the lines from a text file or txt. gz file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a basic auth token for a given user and password.", "response": "def basic_auth(user, password, realm=None):\n    \"\"\" Generate a basic auth token for a given user and password.\n\n    :param user: user name\n    :param password: current password\n    :param realm: specifies the authentication provider\n    :return: auth token for use with :meth:`GraphDatabase.driver`\n    \"\"\"\n    from neobolt.security import AuthToken\n    return AuthToken(\"basic\", user, password, realm)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef custom_auth(principal, credentials, realm, scheme, **parameters):\n    from neobolt.security import AuthToken\n    return AuthToken(scheme, principal, credentials, realm, **parameters)", "response": "Generate a basic auth token for a given user and password."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether a URI is compatible with a class.", "response": "def _check_uri(cls, uri):\n        \"\"\" Check whether a URI is compatible with a :class:`.Driver`\n        subclass. When called from a subclass, execution simply passes\n        through if the URI scheme is valid for that class. If invalid,\n        a `ValueError` is raised.\n\n        :param uri: URI to check for compatibility\n        :raise: `ValueError` if URI scheme is incompatible\n        \"\"\"\n        parsed = urlparse(uri)\n        if parsed.scheme != cls.uri_scheme:\n            raise ValueError(\"%s objects require the %r URI scheme\" % (cls.__name__, cls.uri_scheme))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        if not self._closed:\n            self._closed = True\n            if self._pool is not None:\n                self._pool.close()\n                self._pool = None", "response": "Closes any open connections in the pool."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hydrate_point(srid, *coordinates):\n    try:\n        point_class, dim = __srid_table[srid]\n    except KeyError:\n        point = Point(coordinates)\n        point.srid = srid\n        return point\n    else:\n        if len(coordinates) != dim:\n            raise ValueError(\"SRID %d requires %d coordinates (%d provided)\" % (srid, dim, len(coordinates)))\n        return point_class(coordinates)", "response": "Create a new Point instance from a raw\n    set of fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates through all items in a sequence of key - value pairs within an iterable dictionary - like object.", "response": "def iter_items(iterable):\n    \"\"\" Iterate through all items (key-value pairs) within an iterable\n    dictionary-like object. If the object has a `keys` method, this is\n    used along with `__getitem__` to yield each pair in turn. If no\n    `keys` method exists, each iterable element is assumed to be a\n    2-tuple of key and value.\n    \"\"\"\n    if hasattr(iterable, \"keys\"):\n        for key in iterable.keys():\n            yield key, iterable[key]\n    else:\n        for key, value in iterable:\n            yield key, value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts native values into PackStream values.", "response": "def dehydrate(self, values):\n        \"\"\" Convert native values into PackStream values.\n        \"\"\"\n\n        def dehydrate_(obj):\n            try:\n                f = self.dehydration_functions[type(obj)]\n            except KeyError:\n                pass\n            else:\n                return f(obj)\n            if obj is None:\n                return None\n            elif isinstance(obj, bool):\n                return obj\n            elif isinstance(obj, int):\n                if INT64_MIN <= obj <= INT64_MAX:\n                    return obj\n                raise ValueError(\"Integer out of bounds (64-bit signed integer values only)\")\n            elif isinstance(obj, float):\n                return obj\n            elif isinstance(obj, str):\n                return obj\n            elif isinstance(obj, (bytes, bytearray)):  # order is important here - bytes must be checked after string\n                if self.supports_bytes:\n                    return obj\n                else:\n                    raise TypeError(\"This PackSteam channel does not support BYTES (consider upgrading to Neo4j 3.2+)\")\n            elif isinstance(obj, (list, map_type)):\n                return list(map(dehydrate_, obj))\n            elif isinstance(obj, dict):\n                if any(not isinstance(key, str) for key in obj.keys()):\n                    raise TypeError(\"Non-string dictionary keys are not supported\")\n                return {key: dehydrate_(value) for key, value in obj.items()}\n            else:\n                raise TypeError(obj)\n\n        return tuple(map(dehydrate_, values))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nobtains a value from the record by key returning a default value if the key does not exist.", "response": "def get(self, key, default=None):\n        \"\"\" Obtain a value from the record by key, returning a default\n        value if the key does not exist.\n\n        :param key:\n        :param default:\n        :return:\n        \"\"\"\n        try:\n            index = self.__keys.index(str(key))\n        except ValueError:\n            return default\n        if 0 <= index < len(self):\n            return super(Record, self).__getitem__(index)\n        else:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the index of the given item.", "response": "def index(self, key):\n        \"\"\" Return the index of the given item.\n\n        :param key:\n        :return:\n        \"\"\"\n        if isinstance(key, int):\n            if 0 <= key < len(self.__keys):\n                return key\n            raise IndexError(key)\n        elif isinstance(key, str):\n            try:\n                return self.__keys.index(key)\n            except ValueError:\n                raise KeyError(key)\n        else:\n            raise TypeError(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nobtaining a single value from the record by index or key.", "response": "def value(self, key=0, default=None):\n        \"\"\" Obtain a single value from the record by index or key. If no\n        index or key is specified, the first value is returned. If the\n        specified item does not exist, the default value is returned.\n\n        :param key:\n        :param default:\n        :return:\n        \"\"\"\n        try:\n            index = self.index(key)\n        except (IndexError, KeyError):\n            return default\n        else:\n            return self[index]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the values of the record optionally filtering by index or key.", "response": "def values(self, *keys):\n        \"\"\" Return the values of the record, optionally filtering to\n        include only certain values by index or key.\n\n        :param keys: indexes or keys of the items to include; if none\n                     are provided, all values will be included\n        :return: list of values\n        \"\"\"\n        if keys:\n            d = []\n            for key in keys:\n                try:\n                    i = self.index(key)\n                except KeyError:\n                    d.append(None)\n                else:\n                    d.append(self[i])\n            return d\n        return list(self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the fields of the record as a list of key and value tuples", "response": "def items(self, *keys):\n        \"\"\" Return the fields of the record as a list of key and value tuples\n\n        :return:\n        \"\"\"\n        if keys:\n            d = []\n            for key in keys:\n                try:\n                    i = self.index(key)\n                except KeyError:\n                    d.append((key, None))\n                else:\n                    d.append((self.__keys[i], self[i]))\n            return d\n        return list((self.__keys[i], super(Record, self).__getitem__(i)) for i in range(len(self)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data(self, *keys):\n        if keys:\n            d = {}\n            for key in keys:\n                try:\n                    i = self.index(key)\n                except KeyError:\n                    d[key] = None\n                else:\n                    d[self.__keys[i]] = self[i]\n            return d\n        return dict(self)", "response": "Return the keys and values of this record optionally including only certain values by index or key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a Plan or ProfiledPlan from a dictionary of metadata values.", "response": "def _make_plan(plan_dict):\n    \"\"\" Construct a Plan or ProfiledPlan from a dictionary of metadata values.\n\n    :param plan_dict:\n    :return:\n    \"\"\"\n    operator_type = plan_dict[\"operatorType\"]\n    identifiers = plan_dict.get(\"identifiers\", [])\n    arguments = plan_dict.get(\"args\", [])\n    children = [_make_plan(child) for child in plan_dict.get(\"children\", [])]\n    if \"dbHits\" in plan_dict or \"rows\" in plan_dict:\n        db_hits = plan_dict.get(\"dbHits\", 0)\n        rows = plan_dict.get(\"rows\", 0)\n        return ProfiledPlan(operator_type, identifiers, arguments, children, db_hits, rows)\n    else:\n        return Plan(operator_type, identifiers, arguments, children)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the session. This will release any borrowed resources and roll back any outstanding transactions.", "response": "def close(self):\n        \"\"\" Close the session. This will release any borrowed resources,\n        such as connections, and will roll back any outstanding transactions.\n        \"\"\"\n        from neobolt.exceptions import ConnectionExpired, CypherError, ServiceUnavailable\n        try:\n            if self.has_transaction():\n                try:\n                    self.rollback_transaction()\n                except (CypherError, TransactionError, SessionError, ConnectionExpired, ServiceUnavailable):\n                    pass\n        finally:\n            self._closed = True\n        self._disconnect(sync=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a Cypher statement and returns a StatementResult object.", "response": "def run(self, statement, parameters=None, **kwparameters):\n        \"\"\" Run a Cypher statement within an auto-commit transaction.\n\n        The statement is sent and the result header received\n        immediately but the :class:`.StatementResult` content is\n        fetched lazily as consumed by the client application.\n\n        If a statement is executed before a previous\n        :class:`.StatementResult` in the same :class:`.Session` has\n        been fully consumed, the first result will be fully fetched\n        and buffered. Note therefore that the generally recommended\n        pattern of usage is to fully consume one result before\n        executing a subsequent statement. If two results need to be\n        consumed in parallel, multiple :class:`.Session` objects\n        can be used as an alternative to result buffering.\n\n        For more usage details, see :meth:`.Transaction.run`.\n\n        :param statement: template Cypher statement\n        :param parameters: dictionary of parameters\n        :param kwparameters: additional keyword parameters\n        :returns: :class:`.StatementResult` object\n        \"\"\"\n        from neobolt.exceptions import ConnectionExpired\n\n        self._assert_open()\n        if not statement:\n            raise ValueError(\"Cannot run an empty statement\")\n        if not isinstance(statement, (str, Statement)):\n            raise TypeError(\"Statement must be a string or a Statement instance\")\n\n        if not self._connection:\n            self._connect()\n        cx = self._connection\n        protocol_version = cx.protocol_version\n        server = cx.server\n\n        has_transaction = self.has_transaction()\n\n        statement_text = str(statement)\n        statement_metadata = getattr(statement, \"metadata\", None)\n        statement_timeout = getattr(statement, \"timeout\", None)\n        parameters = fix_parameters(dict(parameters or {}, **kwparameters), protocol_version,\n                                    supports_bytes=server.supports(\"bytes\"))\n\n        def fail(_):\n            self._close_transaction()\n\n        hydrant = PackStreamHydrator(protocol_version)\n        result_metadata = {\n            \"statement\": statement_text,\n            \"parameters\": parameters,\n            \"server\": server,\n            \"protocol_version\": protocol_version,\n        }\n        run_metadata = {\n            \"metadata\": statement_metadata,\n            \"timeout\": statement_timeout,\n            \"on_success\": result_metadata.update,\n            \"on_failure\": fail,\n        }\n\n        def done(summary_metadata):\n            result_metadata.update(summary_metadata)\n            bookmark = result_metadata.get(\"bookmark\")\n            if bookmark:\n                self._bookmarks_in = tuple([bookmark])\n                self._bookmark_out = bookmark\n\n        self._last_result = result = BoltStatementResult(self, hydrant, result_metadata)\n\n        if has_transaction:\n            if statement_metadata:\n                raise ValueError(\"Metadata can only be attached at transaction level\")\n            if statement_timeout:\n                raise ValueError(\"Timeouts only apply at transaction level\")\n        else:\n            run_metadata[\"bookmarks\"] = self._bookmarks_in\n\n        cx.run(statement_text, parameters, **run_metadata)\n        cx.pull_all(\n            on_records=lambda records: result._records.extend(\n                hydrant.hydrate_records(result.keys(), records)),\n            on_success=done,\n            on_failure=fail,\n            on_summary=lambda: result.detach(sync=False),\n        )\n\n        if not has_transaction:\n            try:\n                self._connection.send()\n                self._connection.fetch()\n            except ConnectionExpired as error:\n                raise SessionExpired(*error.args)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self):\n        from neobolt.exceptions import ConnectionExpired\n        if self._connection:\n            try:\n                self._connection.send()\n            except ConnectionExpired as error:\n                raise SessionExpired(*error.args)", "response": "Send all outstanding requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(self):\n        from neobolt.exceptions import ConnectionExpired\n        if self._connection:\n            try:\n                detail_count, _ = self._connection.fetch()\n            except ConnectionExpired as error:\n                raise SessionExpired(*error.args)\n            else:\n                return detail_count\n        return 0", "response": "Attempt to fetch at least one more record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detach(self, result, sync=True):\n        count = 0\n\n        if sync and result.attached():\n            self.send()\n            fetch = self.fetch\n            while result.attached():\n                count += fetch()\n\n        if self._last_result is result:\n            self._last_result = None\n            if not self.has_transaction():\n                self._disconnect(sync=False)\n\n        result._session = None\n        return count", "response": "Detach a result from this session by fetching and buffering any remaining records."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbeginning a new transaction.", "response": "def begin_transaction(self, bookmark=None, metadata=None, timeout=None):\n        \"\"\" Create a new :class:`.Transaction` within this session.\n        Calling this method with a bookmark is equivalent to\n\n        :param bookmark: a bookmark to which the server should\n                         synchronise before beginning the transaction\n        :param metadata:\n        :param timeout:\n        :returns: new :class:`.Transaction` instance.\n        :raise: :class:`.TransactionError` if a transaction is already open\n        \"\"\"\n        self._assert_open()\n        if self.has_transaction():\n            raise TransactionError(\"Explicit transaction already open\")\n\n        self._open_transaction(metadata=metadata, timeout=timeout)\n        return self._transaction"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commit_transaction(self):\n        self._assert_open()\n        if not self._transaction:\n            raise TransactionError(\"No transaction to commit\")\n        metadata = {}\n        try:\n            self._connection.commit(on_success=metadata.update)\n        finally:\n            self._disconnect(sync=True)\n            self._transaction = None\n        bookmark = metadata.get(\"bookmark\")\n        self._bookmarks_in = tuple([bookmark])\n        self._bookmark_out = bookmark\n        return bookmark", "response": "Commits the current transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rollback_transaction(self):\n        self._assert_open()\n        if not self._transaction:\n            raise TransactionError(\"No transaction to rollback\")\n        cx = self._connection\n        if cx:\n            metadata = {}\n            try:\n                cx.rollback(on_success=metadata.update)\n            finally:\n                self._disconnect(sync=True)\n                self._transaction = None", "response": "Rollback the current transaction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, statement, parameters=None, **kwparameters):\n        self._assert_open()\n        return self.session.run(statement, parameters, **kwparameters)", "response": "Executes a Cypher statement and returns the result of the statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose this transaction, triggering either a COMMIT or a ROLLBACK, depending on the value of :attr:`.success`. :raise TransactionError: if already closed", "response": "def close(self):\n        \"\"\" Close this transaction, triggering either a COMMIT or a ROLLBACK,\n        depending on the value of :attr:`.success`.\n\n        :raise TransactionError: if already closed\n        \"\"\"\n        from neobolt.exceptions import CypherError\n        self._assert_open()\n        try:\n            self.sync()\n        except CypherError:\n            self.success = False\n            raise\n        finally:\n            if self.session.has_transaction():\n                if self.success:\n                    self.session.commit_transaction()\n                else:\n                    self.session.rollback_transaction()\n            self._closed = True\n            self.on_close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detach(self, sync=True):\n        if self.attached():\n            return self._session.detach(self, sync=sync)\n        else:\n            return 0", "response": "Detach this result from its parent session by fetching the remaining records of this result from the network into the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the keys for the records in this result.", "response": "def keys(self):\n        \"\"\" The keys for the records in this result.\n\n        :returns: tuple of key names\n        \"\"\"\n        try:\n            return self._metadata[\"fields\"]\n        except KeyError:\n            if self.attached():\n                self._session.send()\n            while self.attached() and \"fields\" not in self._metadata:\n                self._session.fetch()\n            return self._metadata.get(\"fields\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef records(self):\n        records = self._records\n        next_record = records.popleft\n        while records:\n            yield next_record()\n        attached = self.attached\n        if attached():\n            self._session.send()\n        while attached():\n            self._session.fetch()\n            while records:\n                yield next_record()", "response": "Generator for records obtained from this result."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summary(self):\n        self.detach()\n        if self._summary is None:\n            self._summary = BoltStatementResultSummary(**self._metadata)\n        return self._summary", "response": "Obtain the summary of this result buffering any remaining records."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef single(self):\n        records = list(self)\n        size = len(records)\n        if size == 0:\n            return None\n        if size != 1:\n            warn(\"Expected a result with a single record, but this result contains %d\" % size)\n        return records[0]", "response": "Obtain the next and only remaining record from this result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nobtain the next record from this result without consuming it.", "response": "def peek(self):\n        \"\"\" Obtain the next record from this result without consuming it.\n        This leaves the record in the buffer for further processing.\n\n        :returns: the next :class:`.Record` or :const:`None` if none remain\n        \"\"\"\n        records = self._records\n        if records:\n            return records[0]\n        if not self.attached():\n            return None\n        if self.attached():\n            self._session.send()\n        while self.attached() and not records:\n            self._session.fetch()\n            if records:\n                return records[0]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value(self, item=0, default=None):\n        return [record.value(item, default) for record in self.records()]", "response": "Return the remainder of the result as a list of values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator containing the results of the next query in the pipeline", "response": "def pull(self):\n        \"\"\"Returns a generator containing the results of the next query in the pipeline\"\"\"\n        # n.b. pull is now somewhat misleadingly named because it doesn't do anything\n        # the connection isn't touched until you try and iterate the generator we return\n        lock_acquired = self._pull_lock.acquire(blocking=False)\n        if not lock_acquired:\n            raise PullOrderException()\n        return self._results_generator()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeprecate decorator for functions and methods.", "response": "def deprecated(message):\n    \"\"\" Decorator for deprecating functions and methods.\n\n    ::\n\n        @deprecated(\"'foo' has been deprecated in favour of 'bar'\")\n        def foo(x):\n            pass\n\n    \"\"\"\n    def f__(f):\n        def f_(*args, **kwargs):\n            from warnings import warn\n            warn(message, category=DeprecationWarning, stacklevel=2)\n            return f(*args, **kwargs)\n        f_.__name__ = f.__name__\n        f_.__doc__ = f.__doc__\n        f_.__dict__.update(f.__dict__)\n        return f_\n    return f__"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef relationship_type(self, name):\n        try:\n            cls = self._relationship_types[name]\n        except KeyError:\n            cls = self._relationship_types[name] = type(str(name), (Relationship,), {})\n        return cls", "response": "Obtain a : class :. Relationship subclass for a given\n        relationship type name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dehydrate_time(value):\n    if isinstance(value, Time):\n        nanoseconds = int(value.ticks * 1000000000)\n    elif isinstance(value, time):\n        nanoseconds = (3600000000000 * value.hour + 60000000000 * value.minute +\n                       1000000000 * value.second + 1000 * value.microsecond)\n    else:\n        raise TypeError(\"Value must be a neotime.Time or a datetime.time\")\n    if value.tzinfo:\n        return Structure(b\"T\", nanoseconds, value.tzinfo.utcoffset(value).seconds)\n    else:\n        return Structure(b\"t\", nanoseconds)", "response": "Dehydrator for time values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hydrate_datetime(seconds, nanoseconds, tz=None):\n    minutes, seconds = map(int, divmod(seconds, 60))\n    hours, minutes = map(int, divmod(minutes, 60))\n    days, hours = map(int, divmod(hours, 24))\n    seconds = (1000000000 * seconds + nanoseconds) / 1000000000\n    t = DateTime.combine(Date.from_ordinal(UNIX_EPOCH_DATE_ORDINAL + days), Time(hours, minutes, seconds))\n    if tz is None:\n        return t\n    if isinstance(tz, int):\n        tz_offset_minutes, tz_offset_seconds = divmod(tz, 60)\n        zone = FixedOffset(tz_offset_minutes)\n    else:\n        zone = timezone(tz)\n    return zone.localize(t)", "response": "Hydrator for DateTime and LocalDateTime values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dehydrate_datetime(value):\n\n    def seconds_and_nanoseconds(dt):\n        if isinstance(dt, datetime):\n            dt = DateTime.from_native(dt)\n        zone_epoch = DateTime(1970, 1, 1, tzinfo=dt.tzinfo)\n        t = dt.to_clock_time() - zone_epoch.to_clock_time()\n        return t.seconds, t.nanoseconds\n\n    tz = value.tzinfo\n    if tz is None:\n        # without time zone\n        value = utc.localize(value)\n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"d\", seconds, nanoseconds)\n    elif hasattr(tz, \"zone\") and tz.zone:\n        # with named time zone\n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"f\", seconds, nanoseconds, tz.zone)\n    else:\n        # with time offset\n        seconds, nanoseconds = seconds_and_nanoseconds(value)\n        return Structure(b\"F\", seconds, nanoseconds, tz.utcoffset(value).seconds)", "response": "Dehydrator for datetime values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dehydrate_timedelta(value):\n    months = 0\n    days = value.days\n    seconds = value.seconds\n    nanoseconds = 1000 * value.microseconds\n    return Structure(b\"E\", months, days, seconds, nanoseconds)", "response": "Dehydrator for timedelta values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nzoom in on an element a certain amount.", "response": "def zoom(self, locator, percent=\"200%\", steps=1):\r\n        \"\"\"\r\n        Zooms in on an element a certain amount.\r\n        \"\"\"\r\n        driver = self._current_application()\r\n        element = self._element_find(locator, True, True)\r\n        driver.zoom(element=element, percent=percent, steps=steps)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nswipe from one point to another point for an optional duration.", "response": "def swipe(self, start_x, start_y, offset_x, offset_y, duration=1000):\r\n        \"\"\"\r\n        Swipe from one point to another point, for an optional duration.\r\n\r\n        Args:\r\n         - start_x - x-coordinate at which to start\r\n         - start_y - y-coordinate at which to start\r\n         - offset_x - x-coordinate distance from start_x at which to stop\r\n         - offset_y - y-coordinate distance from start_y at which to stop\r\n         - duration - (optional) time to take the swipe, in ms.\r\n\r\n        Usage:\r\n        | Swipe | 500 | 100 | 100 | 0 | 1000 |\r\n\r\n        _*NOTE: *_\r\n        Android 'Swipe' is not working properly, use ``offset_x`` and ``offset_y`` as if these are destination points.\r\n        \"\"\"\r\n        driver = self._current_application()\r\n        driver.swipe(start_x, start_y, offset_x, offset_y, duration)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef swipe_by_percent(self, start_x, start_y, end_x, end_y, duration=1000):\r\n        width = self.get_window_width()\r\n        height = self.get_window_height()\r\n        x_start = float(start_x) / 100 * width\r\n        x_end = float(end_x) / 100 * width\r\n        y_start = float(start_y) / 100 * height\r\n        y_end = float(end_y) / 100 * height\r\n        x_offset = x_end - x_start\r\n        y_offset = y_end - y_start\r\n        platform = self._get_platform()\r\n        if platform == 'android':\r\n            self.swipe(x_start, y_start, x_end, y_end, duration)\r\n        else:\r\n            self.swipe(x_start, y_start, x_offset, y_offset, duration)", "response": "Swipe from one percent of the screen to another percent."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscroll from one element to another.", "response": "def scroll(self, start_locator, end_locator):\r\n        \"\"\"\r\n        Scrolls from one element to another\r\n        Key attributes for arbitrary elements are `id` and `name`. See\r\n        `introduction` for details about locating elements.\r\n        \"\"\"\r\n        el1 = self._element_find(start_locator, True, True)\r\n        el2 = self._element_find(end_locator, True, True)\r\n        driver = self._current_application()\r\n        driver.scroll(el1, el2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscroll up to element", "response": "def scroll_up(self, locator):\r\n        \"\"\"Scrolls up to element\"\"\"\r\n        driver = self._current_application()\r\n        element = self._element_find(locator, True, True)\r\n        driver.execute_script(\"mobile: scroll\", {\"direction\": 'up', 'element': element.id})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlongs press the element with optional duration", "response": "def long_press(self, locator, duration=1000):\r\n        \"\"\" Long press the element with optional duration \"\"\"\r\n        driver = self._current_application()\r\n        element = self._element_find(locator, True, True)\r\n        action = TouchAction(driver)\r\n        action.press(element).wait(duration).release().perform()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntap the specified element identified by locator.", "response": "def tap(self, locator, x_offset=None, y_offset=None, count=1):\r\n        \"\"\" Tap element identified by ``locator``.\r\n\r\n        Args:\r\n        - ``x_offset`` - (optional) x coordinate to tap, relative to the top left corner of the element.\r\n        - ``y_offset`` - (optional) y coordinate. If y is used, x must also be set, and vice versa\r\n        - ``count`` - can be used for multiple times of tap on that element\r\n        \"\"\"\r\n        driver = self._current_application()\r\n        el = self._element_find(locator, True, True)\r\n        action = TouchAction(driver)\r\n        action.tap(el,x_offset,y_offset, count).perform()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclicking on a point.", "response": "def click_a_point(self, x=0, y=0, duration=100):\r\n        \"\"\" Click on a point\"\"\"\r\n        self._info(\"Clicking on a point (%s,%s).\" % (x,y))\r\n        driver = self._current_application()\r\n        action = TouchAction(driver)\r\n        try:\r\n            action.press(x=float(x), y=float(y)).wait(float(duration)).release().perform()\r\n        except:\r\n            assert False, \"Can't click on a point at (%s,%s)\" % (x,y)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef click_element_at_coordinates(self, coordinate_X, coordinate_Y):\r\n        self._info(\"Pressing at (%s, %s).\" % (coordinate_X, coordinate_Y))\r\n        driver = self._current_application()\r\n        action = TouchAction(driver)\r\n        action.press(x=coordinate_X, y=coordinate_Y).release().perform()", "response": "click element at a certain coordinate"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting until the element identified with locator is visible.", "response": "def wait_until_element_is_visible(self, locator, timeout=None, error=None):\n        \"\"\"Waits until element specified with `locator` is visible.\n\n        Fails if `timeout` expires before the element is visible. See\n        `introduction` for more information about `timeout` and its\n        default value.\n\n        `error` can be used to override the default error message.\n\n        See also `Wait Until Page Contains`, `Wait Until Page Contains \n        Element`, `Wait For Condition` and BuiltIn keyword `Wait Until Keyword\n        Succeeds`.\n        \"\"\"\n        def check_visibility():\n            visible = self._is_visible(locator)\n            if visible:\n                return\n            elif visible is None:\n                return error or \"Element locator '%s' did not match any elements after %s\" % (locator, self._format_timeout(timeout))\n            else:\n                return error or \"Element '%s' was not visible in %s\" % (locator, self._format_timeout(timeout))\n        self._wait_until_no_error(timeout, check_visibility)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting until the given text appears on the current page.", "response": "def wait_until_page_contains(self, text, timeout=None, error=None):\n        \"\"\"Waits until `text` appears on current page.\n\n        Fails if `timeout` expires before the text appears. See\n        `introduction` for more information about `timeout` and its\n        default value.\n\n        `error` can be used to override the default error message.\n\n        See also `Wait Until Page Does Not Contain`,\n        `Wait Until Page Contains Element`,\n        `Wait Until Page Does Not Contain Element` and\n        BuiltIn keyword `Wait Until Keyword Succeeds`.\n        \"\"\"\n        if not error:\n            error = \"Text '%s' did not appear in <TIMEOUT>\" % text\n        self._wait_until(timeout, error, self._is_text_present, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting until the given text disappears from the current page.", "response": "def wait_until_page_does_not_contain(self, text, timeout=None, error=None):\n        \"\"\"Waits until `text` disappears from current page.\n\n        Fails if `timeout` expires before the `text` disappears. See\n        `introduction` for more information about `timeout` and its\n        default value.\n\n        `error` can be used to override the default error message.\n\n        See also `Wait Until Page Contains`,\n        `Wait Until Page Contains Element`,\n        `Wait Until Page Does Not Contain Element` and\n        BuiltIn keyword `Wait Until Keyword Succeeds`.\n        \"\"\"\n\n        def check_present():\n            present = self._is_text_present(text)\n            if not present:\n                return\n            else:\n                return error or \"Text '%s' did not disappear in %s\" % (text, self._format_timeout(timeout))\n\n        self._wait_until_no_error(timeout, check_present)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_until_page_contains_element(self, locator, timeout=None, error=None):\n        if not error:\n            error = \"Element '%s' did not appear in <TIMEOUT>\" % locator\n        self._wait_until(timeout, error, self._is_element_present, locator)", "response": "Waits until the element identified with locator appears on current page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until the element specified with locator disappears from current page.", "response": "def wait_until_page_does_not_contain_element(self, locator, timeout=None, error=None):\n        \"\"\"Waits until element specified with `locator` disappears from current page.\n\n        Fails if `timeout` expires before the element disappears. See\n        `introduction` for more information about `timeout` and its\n        default value.\n\n        `error` can be used to override the default error message.\n\n        See also `Wait Until Page Contains`,\n        `Wait Until Page Does Not Contain`,\n        `Wait Until Page Contains Element` and\n        BuiltIn keyword `Wait Until Keyword Succeeds`.\n        \"\"\"\n\n        def check_present():\n            present = self._is_element_present(locator)\n            if not present:\n                return\n            else:\n                return error or \"Element '%s' did not disappear in %s\" % (locator, self._format_timeout(timeout))\n\n        self._wait_until_no_error(timeout, check_present)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_network_connection_status(self, connectionStatus):\n        driver = self._current_application()\n        return driver.set_network_connection(int(connectionStatus))", "response": "Sets the network connection status."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pull_file(self, path, decode=False):\n        driver = self._current_application()\n        theFile = driver.pull_file(path)\n        if decode:\n            theFile = base64.b64decode(theFile)\n        return str(theFile)", "response": "Retrieves the file at path and returns it s content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull_folder(self, path, decode=False):\n        driver = self._current_application()\n        theFolder = driver.pull_folder(path)\n        if decode:\n            theFolder = base64.b64decode(theFolder)\n        return theFolder", "response": "Retrieves a folder at path. Returns the contents zipped."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push_file(self, path, data, encode=False):\n        driver = self._current_application()\n        data = to_bytes(data)\n        if encode:\n            data = base64.b64encode(data)\n        driver.push_file(path, data)", "response": "Pushes the data in the file specified as path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen an arbitrary activity during a test.", "response": "def start_activity(self, appPackage, appActivity, **opts):\n        \"\"\"Opens an arbitrary activity during a test. If the activity belongs to\n        another application, that application is started and the activity is opened.\n\n        Android only.\n\n        - _appPackage_ - The package containing the activity to start.\n        - _appActivity_ - The activity to start.\n        - _appWaitPackage_ - Begin automation after this package starts (optional).\n        - _appWaitActivity_ - Begin automation after this activity starts (optional).\n        - _intentAction_ - Intent to start (opt_ional).\n        - _intentCategory_ - Intent category to start (optional).\n        - _intentFlags_ - Flags to send to the intent (optional).\n        - _optionalIntentArguments_ - Optional arguments to the intent (optional).\n        - _stopAppOnReset_ - Should the app be stopped on reset (optional)?\n\n        \"\"\"\n\n\n        # Almost the same code as in appium's start activity,\n        # just to keep the same keyword names as in open application\n\n        arguments = {\n            'app_wait_package': 'appWaitPackage',\n            'app_wait_activity': 'appWaitActivity',\n            'intent_action': 'intentAction',\n            'intent_category': 'intentCategory',\n            'intent_flags': 'intentFlags',\n            'optional_intent_arguments': 'optionalIntentArguments',\n            'stop_app_on_reset': 'stopAppOnReset'\n        }\n\n        data = {}\n\n        for key, value in arguments.items():\n            if value in opts:\n                data[key] = opts[value]\n\n        driver = self._current_application()\n        driver.start_activity(app_package=appPackage, app_activity=appActivity, **data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_activity(self, activity, timeout, interval=1):\n\n        if not activity.startswith('.'):\n            activity = \".%s\" % activity\n\n        driver = self._current_application()\n        if not driver.wait_activity(activity=activity, timeout=float(timeout), interval=float(interval)):\n            raise TimeoutException(msg=\"Activity %s never presented, current activity: %s\" % (activity, self.get_activity()))", "response": "Wait until the activity presents in the current application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling App via Appium Android only.", "response": "def install_app(self, app_path, app_package):\n        \"\"\" Install App via Appium\n        \n        Android only.\n\n        - app_path - path to app\n        - app_package - package of install app to verify\n        \"\"\"\n        driver = self._current_application()\n        driver.install_app(app_path)\n        return driver.is_app_installed(app_package)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting location in AppiumLibrary 1. 5.", "response": "def set_location(self, latitude, longitude, altitude=10):\n        \"\"\" Set location\n\n        - _latitute_\n        - _longitude_\n        - _altitude_ = 10 [optional]\n        \n        Android only.\n        New in AppiumLibrary 1.5\n        \"\"\"\n        driver = self._current_application()\n        driver.set_location(latitude,longitude,altitude)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef click_element(self, locator):\r\n        self._info(\"Clicking element '%s'.\" % locator)\r\n        self._element_find(locator, True, True).click()", "response": "Clicks an arbitrary element identified by locator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef click_text(self, text, exact_match=False):\r\n        self._element_find_by_text(text,exact_match).click()", "response": "Click text identified by text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntypes the given text into text field identified by locator.", "response": "def input_text(self, locator, text):\r\n        \"\"\"Types the given `text` into text field identified by `locator`.\r\n\r\n        See `introduction` for details about locating elements.\r\n        \"\"\"\r\n        self._info(\"Typing text '%s' into text field '%s'\" % (text, locator))\r\n        self._element_input_text_by_locator(locator, text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntype the given password into text field identified by locator.", "response": "def input_password(self, locator, text):\r\n        \"\"\"Types the given password into text field identified by `locator`.\r\n\r\n        Difference between this keyword and `Input Text` is that this keyword\r\n        does not log the given password. See `introduction` for details about\r\n        locating elements.\r\n        \"\"\"\r\n        self._info(\"Typing password into text field '%s'\" % locator)\r\n        self._element_input_text_by_locator(locator, text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the given value into text field identified by locator.", "response": "def input_value(self, locator, text):\r\n        \"\"\"Sets the given value into text field identified by `locator`. This is an IOS only keyword, input value makes use of set_value\r\n\r\n        See `introduction` for details about locating elements.\r\n        \"\"\"\r\n        self._info(\"Setting text '%s' into text field '%s'\" % (text, locator))\r\n        self._element_input_value_by_locator(locator, text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef page_should_contain_text(self, text, loglevel='INFO'):\r\n        if not self._is_text_present(text):\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Page should have contained text '%s' \"\r\n                                 \"but did not\" % text)\r\n        self._info(\"Current page contains text '%s'.\" % text)", "response": "Verifies that current page contains text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that current page not contains text.", "response": "def page_should_not_contain_text(self, text, loglevel='INFO'):\r\n        \"\"\"Verifies that current page not contains `text`.\r\n\r\n        If this keyword fails, it automatically logs the page source\r\n        using the log level specified with the optional `loglevel` argument.\r\n        Giving `NONE` as level disables logging.\r\n        \"\"\"\r\n        if self._is_text_present(text):\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Page should not have contained text '%s'\" % text)\r\n        self._info(\"Current page does not contains text '%s'.\" % text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that current page contains locator element.", "response": "def page_should_contain_element(self, locator, loglevel='INFO'):\r\n        \"\"\"Verifies that current page contains `locator` element.\r\n\r\n        If this keyword fails, it automatically logs the page source\r\n        using the log level specified with the optional `loglevel` argument.\r\n        Giving `NONE` as level disables logging.\r\n        \"\"\"\r\n        if not self._is_element_present(locator):\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Page should have contained element '%s' \"\r\n                                 \"but did not\" % locator)\r\n        self._info(\"Current page contains element '%s'.\" % locator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef page_should_not_contain_element(self, locator, loglevel='INFO'):\r\n        if self._is_element_present(locator):\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Page should not have contained element '%s'\" % locator)\r\n        self._info(\"Current page not contains element '%s'.\" % locator)", "response": "Verifies that current page not contains locator element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that the element identified with locator is disabled.", "response": "def element_should_be_disabled(self, locator, loglevel='INFO'):\r\n        \"\"\"Verifies that element identified with locator is disabled.\r\n\r\n        Key attributes for arbitrary elements are `id` and `name`. See\r\n        `introduction` for details about locating elements.\r\n        \"\"\"\r\n        if self._element_find(locator, True, True).is_enabled():\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Element '%s' should be disabled \"\r\n                                 \"but did not\" % locator)\r\n        self._info(\"Element '%s' is disabled .\" % locator)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef element_should_be_visible(self, locator, loglevel='INFO'):\r\n        if not self._element_find(locator, True, True).is_displayed():\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Element '%s' should be visible \"\r\n                                 \"but did not\" % locator)", "response": "Verifies that the element identified with locator is visible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef element_attribute_should_match(self, locator, attr_name, match_pattern, regexp=False):\r\n        elements = self._element_find(locator, False, True)\r\n        if len(elements) > 1:\r\n            self._info(\"CAUTION: '%s' matched %s elements - using the first element only\" % (locator, len(elements)))\r\n\r\n        attr_value = elements[0].get_attribute(attr_name)\r\n\r\n        # ignore regexp argument if matching boolean\r\n        if isinstance(match_pattern, bool) or match_pattern.lower() == 'true' or match_pattern.lower() == 'false':\r\n            if isinstance(match_pattern, bool):\r\n                match_b = match_pattern\r\n            else:\r\n                match_b = ast.literal_eval(match_pattern.title())\r\n\r\n            if isinstance(attr_value, bool):\r\n                attr_b = attr_value\r\n            else:\r\n                attr_b = ast.literal_eval(attr_value.title())\r\n\r\n            self._bi.should_be_equal(match_b, attr_b)\r\n\r\n        elif regexp:\r\n            self._bi.should_match_regexp(attr_value, match_pattern,\r\n                                         msg=\"Element '%s' attribute '%s' should have been '%s' \"\r\n                                             \"but it was '%s'.\" % (locator, attr_name, match_pattern, attr_value),\r\n                                         values=False)\r\n        else:\r\n            self._bi.should_match(attr_value, match_pattern,\r\n                                  msg=\"Element '%s' attribute '%s' should have been '%s' \"\r\n                                      \"but it was '%s'.\" % (locator, attr_name, match_pattern, attr_value),\r\n                                  values=False)\r\n        # if expected != elements[0].get_attribute(attr_name):\r\n        #    raise AssertionError(\"Element '%s' attribute '%s' should have been '%s' \"\r\n        #                         \"but it was '%s'.\" % (locator, attr_name, expected, element.get_attribute(attr_name)))\r\n        self._info(\"Element '%s' attribute '%s' is '%s' \" % (locator, attr_name, match_pattern))", "response": "Verify that an attribute of an element matches the expected criteria."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef element_should_contain_text(self, locator, expected, message=''):\r\n        self._info(\"Verifying element '%s' contains text '%s'.\"\r\n                    % (locator, expected))\r\n        actual = self._get_text(locator)\r\n        if not expected in actual:\r\n            if not message:\r\n                message = \"Element '%s' should have contained text '%s' but \"\\\r\n                          \"its text was '%s'.\" % (locator, expected, actual)\r\n            raise AssertionError(message)", "response": "Verifies that the element identified by locator contains the expected text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the element identified by locator contains exactly text expected.", "response": "def element_text_should_be(self, locator, expected, message=''):\r\n        \"\"\"Verifies element identified by ``locator`` exactly contains text ``expected``.\r\n\r\n        In contrast to `Element Should Contain Text`, this keyword does not try\r\n        a substring match but an exact match on the element identified by ``locator``.\r\n\r\n        ``message`` can be used to override the default error message.\r\n\r\n        New in AppiumLibrary 1.4.\r\n        \"\"\"\r\n        self._info(\"Verifying element '%s' contains exactly text '%s'.\"\r\n                    % (locator, expected))\r\n        element = self._element_find(locator, True, True)\r\n        actual = element.text\r\n        if expected != actual:\r\n            if not message:\r\n                message = \"The text of element '%s' should have been '%s' but \"\\\r\n                          \"in fact it was '%s'.\" % (locator, expected, actual)\r\n            raise AssertionError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget element attribute using given attribute", "response": "def get_element_attribute(self, locator, attribute):\r\n        \"\"\"Get element attribute using given attribute: name, value,...\r\n\r\n        Examples:\r\n\r\n        | Get Element Attribute | locator | name |\r\n        | Get Element Attribute | locator | value |\r\n        \"\"\"\r\n        elements = self._element_find(locator, False, True)\r\n        ele_len = len(elements)\r\n        if ele_len == 0:\r\n            raise AssertionError(\"Element '%s' could not be found\" % locator)\r\n        elif ele_len > 1:\r\n            self._info(\"CAUTION: '%s' matched %s elements - using the first element only\" % (locator, len(elements)))\r\n\r\n        try:\r\n            attr_val = elements[0].get_attribute(attribute)\r\n            self._info(\"Element '%s' attribute '%s' value '%s' \" % (locator, attribute, attr_val))\r\n            return attr_val\r\n        except:\r\n            raise AssertionError(\"Attribute '%s' is not valid for element '%s'\" % (attribute, locator))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the location of an arbitrary element.", "response": "def get_element_location(self, locator):\r\n        \"\"\"Get element location\r\n\r\n        Key attributes for arbitrary elements are `id` and `name`. See\r\n        `introduction` for details about locating elements.\r\n        \"\"\"\r\n        element = self._element_find(locator, True, True)\r\n        element_location = element.location\r\n        self._info(\"Element '%s' location: %s \" % (locator, element_location))\r\n        return element_location"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_element_size(self, locator):\r\n        element = self._element_find(locator, True, True)\r\n        element_size = element.size\r\n        self._info(\"Element '%s' size: %s \" % (locator, element_size))\r\n        return element_size", "response": "Get the size of the element identified by locator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting element text (for hybrid and mobile browser use `xpath` locator, others might cause problem) Example: | ${text} | Get Text | //*[contains(@text,'foo')] | New in AppiumLibrary 1.4.", "response": "def get_text(self, locator):\r\n        \"\"\"Get element text (for hybrid and mobile browser use `xpath` locator, others might cause problem)\r\n\r\n        Example:\r\n\r\n        | ${text} | Get Text | //*[contains(@text,'foo')] |\r\n\r\n        New in AppiumLibrary 1.4.\r\n        \"\"\"\r\n        text = self._get_text(locator)\r\n        self._info(\"Element '%s' text is '%s' \" % (locator, text))\r\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of matching elements matching the given XPath.", "response": "def get_matching_xpath_count(self, xpath):\r\n        \"\"\"Returns number of elements matching ``xpath``\r\n\r\n        One should not use the `xpath=` prefix for 'xpath'. XPath is assumed.\r\n\r\n        | *Correct:* |\r\n        | ${count}  | Get Matching Xpath Count | //android.view.View[@text='Test'] |\r\n        | Incorrect:  |\r\n        | ${count}  | Get Matching Xpath Count | xpath=//android.view.View[@text='Test'] |\r\n\r\n        If you wish to assert the number of matching elements, use\r\n        `Xpath Should Match X Times`.\r\n\r\n        New in AppiumLibrary 1.4.\r\n        \"\"\"\r\n        count = len(self._element_find(\"xpath=\" + xpath, False, False))\r\n        return str(count)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying that the element identified with text is visible.", "response": "def text_should_be_visible(self, text, exact_match=False, loglevel='INFO'):\r\n        \"\"\"Verifies that element identified with text is visible.\r\n\r\n        New in AppiumLibrary 1.4.5\r\n        \"\"\"\r\n        if not self._element_find_by_text(text, exact_match).is_displayed():\r\n            self.log_source(loglevel)\r\n            raise AssertionError(\"Text '%s' should be visible \"\r\n                                 \"but did not\" % text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying that the current page contains the given number of elements located by the given XPath.", "response": "def xpath_should_match_x_times(self, xpath, count, error=None, loglevel='INFO'):\r\n        \"\"\"Verifies that the page contains the given number of elements located by the given ``xpath``.\r\n\r\n        One should not use the `xpath=` prefix for 'xpath'. XPath is assumed.\r\n\r\n        | *Correct:* |\r\n        | Xpath Should Match X Times | //android.view.View[@text='Test'] | 1 |\r\n        | Incorrect: |\r\n        | Xpath Should Match X Times | xpath=//android.view.View[@text='Test'] | 1 |\r\n\r\n        ``error`` can be used to override the default error message.\r\n\r\n        See `Log Source` for explanation about ``loglevel`` argument.\r\n\r\n        New in AppiumLibrary 1.4.\r\n        \"\"\"\r\n        actual_xpath_count = len(self._element_find(\"xpath=\" + xpath, False, False))\r\n        if int(actual_xpath_count) != int(count):\r\n            if not error:\r\n                error = \"Xpath %s should have matched %s times but matched %s times\"\\\r\n                            %(xpath, count, actual_xpath_count)\r\n            self.log_source(loglevel)\r\n            raise AssertionError(error)\r\n        self._info(\"Current page contains %s elements matching '%s'.\"\r\n                   % (actual_xpath_count, xpath))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing the current application and also close webdriver session.", "response": "def close_application(self):\r\n        \"\"\"Closes the current application and also close webdriver session.\"\"\"\r\n        self._debug('Closing application with session id %s' % self._current_application().session_id)\r\n        self._cache.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a new application to given Appium server.", "response": "def open_application(self, remote_url, alias=None, **kwargs):\r\n        \"\"\"Opens a new application to given Appium server.\r\n        Capabilities of appium server, Android and iOS,\r\n        Please check https://github.com/appium/appium/blob/master/docs/en/writing-running-appium/server-args.md\r\n        | *Option*            | *Man.* | *Description*     |\r\n        | remote_url          | Yes    | Appium server url |\r\n        | alias               | no     | alias             |\r\n\r\n        Examples:\r\n        | Open Application | http://localhost:4723/wd/hub | alias=Myapp1         | platformName=iOS      | platformVersion=7.0            | deviceName='iPhone Simulator'           | app=your.app                         |\r\n        | Open Application | http://localhost:4723/wd/hub | platformName=Android | platformVersion=4.2.2 | deviceName=192.168.56.101:5555 | app=${CURDIR}/demoapp/OrangeDemoApp.apk | appPackage=com.netease.qa.orangedemo | appActivity=MainActivity |\r\n        \"\"\"\r\n        desired_caps = kwargs\r\n        application = webdriver.Remote(str(remote_url), desired_caps)\r\n\r\n        self._debug('Opened application with session id %s' % application.session_id)\r\n\r\n        return self._cache.register(application, alias)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswitch the active application by index or alias.", "response": "def switch_application(self, index_or_alias):\r\n        \"\"\"Switches the active application by index or alias.\r\n\r\n        `index_or_alias` is either application index (an integer) or alias\r\n        (a string). Index is got as the return value of `Open Application`.\r\n\r\n        This keyword returns the index of the previous active application,\r\n        which can be used to switch back to that application later.\r\n\r\n        Example:\r\n        | ${appium1}=              | Open Application  | http://localhost:4723/wd/hub                   | alias=MyApp1 | platformName=iOS | platformVersion=7.0 | deviceName='iPhone Simulator' | app=your.app |\r\n        | ${appium2}=              | Open Application  | http://localhost:4755/wd/hub                   | alias=MyApp2 | platformName=iOS | platformVersion=7.0 | deviceName='iPhone Simulator' | app=your.app |\r\n        | Click Element            | sendHello         | # Executed on appium running at localhost:4755 |\r\n        | Switch Application       | ${appium1}        | # Switch using index                           |\r\n        | Click Element            | ackHello          | # Executed on appium running at localhost:4723 |\r\n        | Switch Application       | MyApp2            | # Switch using alias                           |\r\n        | Page Should Contain Text | ackHello Received | # Executed on appium running at localhost:4755 |\r\n\r\n        \"\"\"\r\n        old_index = self._cache.current_index\r\n        if index_or_alias is None:\r\n            self._cache.close()\r\n        else:\r\n            self._cache.switch(index_or_alias)\r\n        return old_index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_appium_timeout(self, seconds):\r\n        old_timeout = self.get_appium_timeout()\r\n        self._timeout_in_secs = robot.utils.timestr_to_secs(seconds)\r\n        return old_timeout", "response": "Sets the timeout in seconds used by various keywords that take timeout as an\r\n        argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_appium_sessionId(self):\r\n        self._info(\"Appium Session ID: \" + self._current_application().session_id)\r\n        return self._current_application().session_id", "response": "Returns the current Appium session ID as a reference"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_source(self, loglevel='INFO'):\r\n        ll = loglevel.upper()\r\n        if ll == 'NONE':\r\n            return ''\r\n        else:\r\n            if  \"run_keyword_and_ignore_error\" not in [check_error_ignored[3] for check_error_ignored in inspect.stack()]:\r\n                source = self._current_application().page_source\r\n                self._log(source, ll)\r\n                return source\r\n            else:\r\n                return ''", "response": "Logs and returns the entire html source of the current page or frame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlock the device for a certain number of seconds.", "response": "def lock(self, seconds=5):\r\n        \"\"\"\r\n        Lock the device for a certain period of time. iOS only.\r\n        \"\"\"\r\n        self._current_application().lock(robot.utils.timestr_to_secs(seconds))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the desired capability value by desired capability name", "response": "def get_capability(self, capability_name):\r\n        \"\"\"\r\n        Return the desired capability value by desired capability name\r\n        \"\"\"\r\n        try:\r\n            capability = self._current_application().capabilities[capability_name]\r\n        except Exception as e:\r\n            raise e\r\n        return capability"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds elements matching the given criteria and tag.", "response": "def _find_by_android(self, browser, criteria, tag, constraints):\r\n        \"\"\"Find element matches by UI Automator.\"\"\"\r\n        return self._filter_elements(\r\n            browser.find_elements_by_android_uiautomator(criteria),\r\n            tag, constraints)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_by_ios(self, browser, criteria, tag, constraints):\r\n        return self._filter_elements(\r\n            browser.find_elements_by_ios_uiautomation(criteria),\r\n            tag, constraints)", "response": "Find elements matching the given criteria by UI Automation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding elements matching the given iOSNsPredicateString.", "response": "def _find_by_nsp(self, browser, criteria, tag, constraints):\r\n        \"\"\"Find element matches by  iOSNsPredicateString.\"\"\"\r\n        return self._filter_elements(\r\n            browser.find_elements_by_ios_predicate(criteria),\r\n            tag, constraints)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind elements matching the given criteria and tag.", "response": "def _find_by_chain(self, browser, criteria, tag, constraints):\r\n        \"\"\"Find element matches by  iOSChainString.\"\"\"\r\n        return self._filter_elements(\r\n            browser.find_elements_by_ios_class_chain(criteria),\r\n            tag, constraints)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a press of keycode to the device.", "response": "def press_keycode(self, keycode, metastate=None):\n        \"\"\"Sends a press of keycode to the device.\n\n        Android only.\n\n        Possible keycodes & meta states can be found in\n        http://developer.android.com/reference/android/view/KeyEvent.html\n\n        Meta state describe the pressed state of key modifiers such as\n        Shift, Ctrl & Alt keys. The Meta State is an integer in which each\n        bit set to 1 represents a pressed meta key.\n\n        For example\n        - META_SHIFT_ON = 1\n        - META_ALT_ON = 2\n\n        | metastate=1 --> Shift is pressed\n        | metastate=2 --> Alt is pressed\n        | metastate=3 --> Shift+Alt is pressed\n\n         - _keycode- - the keycode to be sent to the device\n         - _metastate- - status of the meta keys\n        \"\"\"\n        driver = self._current_application()\n        driver.press_keycode(keycode, metastate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a long press of keycode to the device.", "response": "def long_press_keycode(self, keycode, metastate=None):\n        \"\"\"Sends a long press of keycode to the device.\n\n        Android only.\n\n        See `press keycode` for more details.\n        \"\"\"\n        driver = self._current_application()\n        driver.long_press_keycode(int(keycode), metastate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a screenshot of the current page and embeds it into the log.", "response": "def capture_page_screenshot(self, filename=None):\r\n        \"\"\"Takes a screenshot of the current page and embeds it into the log.\r\n\r\n        `filename` argument specifies the name of the file to write the\r\n        screenshot into. If no `filename` is given, the screenshot is saved into file\r\n        `appium-screenshot-<counter>.png` under the directory where\r\n        the Robot Framework log file is written into. The `filename` is\r\n        also considered relative to the same directory, if it is not\r\n        given in absolute format.\r\n\r\n        `css` can be used to modify how the screenshot is taken. By default\r\n        the bakground color is changed to avoid possible problems with\r\n        background leaking when the page layout is somehow broken.\r\n        \"\"\"\r\n        path, link = self._get_screenshot_paths(filename)\r\n\r\n        if hasattr(self._current_application(), 'get_screenshot_as_file'):\r\n            self._current_application().get_screenshot_as_file(path)\r\n        else:\r\n            self._current_application().save_screenshot(path)\r\n\r\n        # Image is shown on its own row and thus prev row is closed on purpose\r\n        self._html('</td></tr><tr><td colspan=\"3\"><a href=\"%s\">'\r\n                   '<img src=\"%s\" width=\"800px\"></a>' % (link, link))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the keyword to execute when a AppiumLibrary keyword fails.", "response": "def register_keyword_to_run_on_failure(self, keyword):\r\n        \"\"\"Sets the keyword to execute when a AppiumLibrary keyword fails.\r\n\r\n        `keyword_name` is the name of a keyword (from any available\r\n        libraries) that  will be executed if a AppiumLibrary keyword fails.\r\n        It is not possible to use a keyword that requires arguments.\r\n        Using the value \"Nothing\" will disable this feature altogether.\r\n\r\n        The initial keyword to use is set in `importing`, and the\r\n        keyword that is used by default is `Capture Page Screenshot`.\r\n        Taking a screenshot when something failed is a very useful\r\n        feature, but notice that it can slow down the execution.\r\n\r\n        This keyword returns the name of the previously registered\r\n        failure keyword. It can be used to restore the original\r\n        value later.\r\n\r\n        Example:\r\n        | Register Keyword To Run On Failure  | Log Source | # Run `Log Source` on failure. |\r\n        | ${previous kw}= | Register Keyword To Run On Failure  | Nothing    | # Disables run-on-failure functionality and stores the previous kw name in a variable. |\r\n        | Register Keyword To Run On Failure  | ${previous kw} | # Restore to the previous keyword. |\r\n\r\n        This run-on-failure functionality only works when running tests on Python/Jython 2.4\r\n        or newer and it does not work on IronPython at all.\r\n        \"\"\"\r\n        old_keyword = self._run_on_failure_keyword\r\n        old_keyword_text = old_keyword if old_keyword is not None else \"Nothing\"\r\n\r\n        new_keyword = keyword if keyword.strip().lower() != \"nothing\" else None\r\n        new_keyword_text = new_keyword if new_keyword is not None else \"Nothing\"\r\n\r\n        self._run_on_failure_keyword = new_keyword\r\n        self._info('%s will be run on failure.' % new_keyword_text)\r\n\r\n        return old_keyword_text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the power stats and return a dictionary", "response": "def rapl_read():\n    \"\"\" Read power stats and return dictionary\"\"\"\n    basenames = glob.glob('/sys/class/powercap/intel-rapl:*/')\n    basenames = sorted(set({x for x in basenames}))\n\n    pjoin = os.path.join\n    ret = list()\n    for path in basenames:\n        name = None\n        try:\n            name = cat(pjoin(path, 'name'), fallback=None, binary=False)\n        except (IOError, OSError, ValueError) as err:\n            logging.warning(\"ignoring %r for file %r\",\n                            (err, path), RuntimeWarning)\n            continue\n        if name:\n            try:\n                current = cat(pjoin(path, 'energy_uj'))\n                max_reading = 0.0\n                ret.append(RaplStats(name, float(current), max_reading))\n            except (IOError, OSError, ValueError) as err:\n                logging.warning(\"ignoring %r for file %r\",\n                                (err, path), RuntimeWarning)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the bar widths for a given size and bardata.", "response": "def calculate_bar_widths(self, size, bardata):\n        \"\"\"\n        Return a list of bar widths, one for each bar in data.\n\n        If self.bar_width is None this implementation will stretch\n        the bars across the available space specified by maxcol.\n        \"\"\"\n        (maxcol, _) = size\n\n        if self.bar_width is not None:\n            return [self.bar_width] * min(\n                len(bardata), int(maxcol / self.bar_width))\n\n        if len(bardata) >= maxcol:\n            return [1] * maxcol\n\n        widths = []\n        grow = maxcol\n        remain = len(bardata)\n        for _ in bardata:\n            w = int(float(grow) / remain + 0.5)\n            widths.append(w)\n            grow -= w\n            remain -= 1\n        return widths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing a column of the graph selected for display", "response": "def set_visible_graphs(self, visible_graph_list=None):\n        \"\"\"Show a column of the graph selected for display\"\"\"\n        if visible_graph_list is None:\n            visible_graph_list = self.visible_graph_list\n\n        vline = urwid.AttrWrap(urwid.SolidFill(u'|'), 'line')\n\n        graph_vector_column_list = []\n        for state, graph, sub_title in zip(visible_graph_list,\n                                           self.bar_graph_vector,\n                                           self.sub_title_list):\n            if state:\n                text_w = urwid.Text(sub_title, align='center')\n                sub_title_widget = urwid.ListBox([text_w])\n                graph_a = [('fixed', 1, sub_title_widget),\n                           ('weight', 1, graph)]\n                graph_and_title = urwid.Pile(graph_a)\n                graph_vector_column_list.append(('weight', 1, graph_and_title))\n                graph_vector_column_list.append(('fixed', 1, vline))\n\n        # if all sub graph are disabled\n        if not graph_vector_column_list:\n            self.visible_graph_list = visible_graph_list\n            self.original_widget = urwid.Pile([])\n            return\n\n        # remove the last vertical line separator\n        graph_vector_column_list.pop()\n\n        y_label_a = ('weight', 1, urwid.Columns(graph_vector_column_list))\n        y_label_and_graphs = [self.y_label,\n                              y_label_a]\n        column_w = urwid.Columns(y_label_and_graphs, dividechars=1)\n        y_label_and_graphs_widget = urwid.WidgetPlaceholder(column_w)\n\n        init_widget = urwid.Pile([('fixed', 1, self.title),\n                                  ('weight', 1, y_label_and_graphs_widget)])\n\n        self.visible_graph_list = visible_graph_list\n        self.original_widget = init_widget"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_processor_name():\n    if platform.system() == \"Linux\":\n        with open(\"/proc/cpuinfo\", \"rb\") as cpuinfo:\n            all_info = cpuinfo.readlines()\n            for line in all_info:\n                if b'model name' in line:\n                    return re.sub(b'.*model name.*:', b'', line, 1)\n\n    return platform.processor()", "response": "Returns the processor name in the system"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkills a process and all its children", "response": "def kill_child_processes(parent_proc):\n    \"\"\" Kills a process and all its children \"\"\"\n    logging.debug(\"Killing stress process\")\n    try:\n        for proc in parent_proc.children(recursive=True):\n            logging.debug('Killing %s', proc)\n            proc.kill()\n        parent_proc.kill()\n    except AttributeError:\n        logging.debug('No such process')\n        logging.debug('Could not kill process')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints statistics to csv file", "response": "def output_to_csv(sources, csv_writeable_file):\n    \"\"\"Print statistics to csv file\"\"\"\n    file_exists = os.path.isfile(csv_writeable_file)\n\n    with open(csv_writeable_file, 'a') as csvfile:\n        csv_dict = OrderedDict()\n        csv_dict.update({'Time': time.strftime(\"%Y-%m-%d_%H:%M:%S\")})\n        summaries = [val for key, val in sources.items()]\n        for summarie in summaries:\n            csv_dict.update(summarie.source.get_sensors_summary())\n\n        fieldnames = [key for key, val in csv_dict.items()]\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        if not file_exists:\n            writer.writeheader()  # file doesn't exist yet, write a header\n        writer.writerow(csv_dict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output_to_terminal(sources):\n    results = OrderedDict()\n    for source in sources:\n        if source.get_is_available():\n            source.update()\n            results.update(source.get_summary())\n    for key, value in results.items():\n        sys.stdout.write(str(key) + \": \" + str(value) + \", \")\n    sys.stdout.write(\"\\n\")\n    sys.exit()", "response": "Print statistics to the terminal"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output_to_json(sources):\n    results = OrderedDict()\n    for source in sources:\n        if source.get_is_available():\n            source.update()\n            source_name = source.get_source_name()\n            results[source_name] = source.get_sensors_summary()\n    print(json.dumps(results, indent=4))\n    sys.exit()", "response": "Print statistics to the terminal in Json format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_config_dir():\n    user_home = os.getenv('XDG_CONFIG_HOME')\n    if user_home is None or not user_home:\n        config_path = os.path.expanduser(os.path.join('~', '.config', 's-tui'))\n    else:\n        config_path = os.path.join(user_home, 's-tui')\n\n    return config_path", "response": "Return the path to the user s - tui config directory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the path to the user s - tui config file", "response": "def get_user_config_file():\n    \"\"\"\n    Return the path to the user s-tui config directory\n    \"\"\"\n    user_home = os.getenv('XDG_CONFIG_HOME')\n    if user_home is None or not user_home:\n        config_path = os.path.expanduser(os.path.join('~', '.config',\n                                                      's-tui', 's-tui.conf'))\n    else:\n        config_path = os.path.join(user_home, 's-tui', 's-tui.conf')\n\n    return config_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the user s - tui config directory if it doesn t exist", "response": "def make_user_config_dir():\n    \"\"\"\n    Create the user s-tui config directory if it doesn't exist\n    \"\"\"\n    config_path = get_user_config_dir()\n\n    if not user_config_dir_exists():\n        try:\n            os.mkdir(config_path)\n            os.mkdir(os.path.join(config_path, 'hooks.d'))\n        except OSError:\n            return None\n\n    return config_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef seconds_to_text(secs):\n    hours = (secs)//3600\n    minutes = (secs - hours*3600)//60\n    seconds = secs - hours*3600 - minutes*60\n    return \"%02d:%02d:%02d\" % (hours, minutes, seconds)", "response": "Converts seconds to a string of hours minutes and seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens a file in text mode by using fs encoding and errors handler.", "response": "def _open_text(fname, **kwargs):\n    \"\"\"On Python 3 opens a file in text mode by using fs encoding and\n    a proper en/decoding errors handler.\n    On Python 2 this is just an alias for open(name, 'rt').\n    \"\"\"\n    if PY3:\n        kwargs.setdefault('encoding', ENCODING)\n        kwargs.setdefault('errors', ENCODING_ERRS)\n    return open(fname, \"rt\", **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the content of a file.", "response": "def cat(fname, fallback=_DEFAULT, binary=True):\n    \"\"\"Return file content.\n    fallback: the value returned in case the file does not exist or\n              cannot be read\n    binary: whether to open the file in binary or text mode.\n    \"\"\"\n    try:\n        with _open_binary(fname) if binary else _open_text(fname) as f_d:\n            return f_d.read().strip()\n    except (IOError, OSError):\n        if fallback is not _DEFAULT:\n            return fallback\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the format of number is a valid byte", "response": "def get_valid_byte(num, default):\n        \"\"\"check if the format of number is (num)(G|m|B) i.e 500GB, 200mb. 400\n        etc.. \"\"\"\n        num_valid = re.match(r\"\\A([0-9]+)(M|G|m|g|)(B|b|\\b)\\Z\", num, re.I)\n        if num_valid:\n            return num\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a script from the scripts directory.", "response": "def load_script(self, source_name, timeoutMilliseconds=0):\n        \"\"\"\n        Return ScriptHook for source_name Source and with a ready timeout\n        of timeoutMilliseconds\n        \"\"\"\n\n        script_path = os.path.join(self.scripts_dir_path,\n                                   self._source_to_script_name(source_name))\n\n        if os.path.isfile(script_path):\n            return ScriptHook(script_path, timeoutMilliseconds)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_sensors_summary(self):\n        sub_title_list = self.get_sensor_list()\n\n        graph_vector_summary = OrderedDict()\n        for graph_idx, graph_data in enumerate(self.last_measurement):\n            val_str = str(round(graph_data, 1))\n            graph_vector_summary[sub_title_list[graph_idx]] = val_str\n\n        return graph_vector_summary", "response": "This returns a dict of sensors of the source and their values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_summary(self):\n        graph_vector_summary = OrderedDict()\n        graph_vector_summary[self.get_source_name()] = (\n            '[' + self.measurement_unit + ']')\n        graph_vector_summary.update(self.get_sensors_summary())\n        return graph_vector_summary", "response": "Returns a dict of source name and sensors with their values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_hooks(self):\n        logging.debug(\"Evaluating hooks\")\n        if self.get_edge_triggered():\n            logging.debug(\"Hook triggered\")\n            for hook in [h for h in self.edge_hooks if h.is_ready()]:\n                logging.debug(\"Hook invoked\")\n                hook.invoke()", "response": "Evaluate the current state of this Source and invoke any attached hooks if they ve been triggered."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invoke(self):\n\n        # Don't sleep a hook if it has never run\n        if self.timeout_milliseconds > 0:\n            self.ready_time = (\n                datetime.now() +\n                timedelta(milliseconds=self.timeout_milliseconds))\n\n        self.callback(self.callback_args)", "response": "Invoke the callback function with the number of arguments specified by callback_args."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef radio_button(g, l, fn):\n    w = urwid.RadioButton(g, l, False, on_state_change=fn)\n    w = urwid.AttrWrap(w, 'button normal', 'button select')\n    return w", "response": "Inheriting radio button of urwid"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a new stress process with a given cmd", "response": "def start_stress(self, stress_cmd):\n        \"\"\" Starts a new stress process with a given cmd \"\"\"\n        with open(os.devnull, 'w') as dev_null:\n            try:\n                stress_proc = subprocess.Popen(stress_cmd, stdout=dev_null,\n                                               stderr=dev_null)\n                self.set_stress_process(psutil.Process(stress_proc.pid))\n            except OSError:\n                logging.debug(\"Unable to start stress\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates all the graphs that are being displayed", "response": "def update_displayed_information(self):\n        \"\"\" Update all the graphs that are being displayed \"\"\"\n\n        for source in self.controller.sources:\n            source_name = source.get_source_name()\n            if (any(self.graphs_menu.active_sensors[source_name]) or\n                    any(self.summary_menu.active_sensors[source_name])):\n                source.update()\n\n        for graph in self.visible_graphs.values():\n            graph.update()\n\n        # update graph summery\n        for summary in self.visible_summaries.values():\n            summary.update()\n\n        # Only update clock if not is stress mode\n        if self.controller.stress_conroller.get_current_mode() != 'Monitor':\n            self.clock_view.set_text(seconds_to_text(\n                (timeit.default_timer() - self.controller.stress_start_time)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_reset_button(self, _):\n        for graph in self.visible_graphs.values():\n            graph.reset()\n        for graph in self.graphs.values():\n            try:\n                graph.source.reset()\n            except NotImplementedError:\n                pass\n        # Reset clock\n        self.clock_view.set_text(ZERO_TIME)\n\n        self.update_displayed_information()", "response": "Reset graph data and display empty graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_graphs_menu_close(self, update):\n        logging.info(\"closing sensor menu, update=%s\", update)\n        if update:\n            for sensor, visible_sensors in \\\n                    self.graphs_menu.active_sensors.items():\n                self.graphs[sensor].set_visible_graphs(visible_sensors)\n                # If not sensor is selected, do not display the graph\n                if sensor in self.visible_graphs and not any(visible_sensors):\n                    del self.visible_graphs[sensor]\n                elif not any(visible_sensors):\n                    pass\n                # Update visible graphs if a sensor was selected\n                else:\n                    self.visible_graphs[sensor] = self.graphs[sensor]\n            self.show_graphs()\n\n        self.original_widget = self.main_window_w", "response": "Return to main screen and update sensor that have active in the view"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns to main screen and update sensor that are active in the view", "response": "def on_summary_menu_close(self, update):\n        \"\"\"Return to main screen and update sensor that\n        are active in the view\"\"\"\n        logging.info(\"closing summary_menu menu, update=%s\", update)\n        if update:\n            for sensor, visible_sensors in \\\n                    self.summary_menu.active_sensors.items():\n                self.visible_summaries[sensor].update_visibility(\n                    visible_sensors)\n\n        self.main_window_w.base_widget[0].body[self.summary_widget_index] =\\\n            self._generate_summaries()\n\n        self.original_widget = self.main_window_w"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_graphs_menu_open(self, widget):\n        self.original_widget = urwid.Overlay(\n            self.graphs_menu.main_window,\n            self.original_widget,\n            ('relative', self.left_margin),\n            self.graphs_menu.get_size()[1],\n            ('relative', self.top_margin),\n            self.graphs_menu.get_size()[0])", "response": "Open Sensor menu on top of existing frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_summary_menu_open(self, widget):\n        self.original_widget = urwid.Overlay(\n            self.summary_menu.main_window,\n            self.original_widget,\n            ('relative', self.left_margin),\n            self.summary_menu.get_size()[1],\n            ('relative', self.top_margin),\n            self.summary_menu.get_size()[0])", "response": "Open Sensor menu on top of existing frame"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_mode_button(self, my_button, state):\n        if state:\n            # The new mode is the label of the button\n            self.controller.set_mode(my_button.get_label())", "response": "Notify the controller of a new mode setting."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables smooth edges if utf - 8 is supported", "response": "def on_unicode_checkbox(self, w=None, state=False):\n        \"\"\"Enable smooth edges if utf-8 is supported\"\"\"\n        logging.debug(\"unicode State is %s\", state)\n\n        # Update the controller to the state of the checkbox\n        self.controller.smooth_graph_mode = state\n        if state:\n            self.hline = urwid.AttrWrap(\n                urwid.SolidFill(u'\\N{LOWER ONE QUARTER BLOCK}'), 'line')\n        else:\n            self.hline = urwid.AttrWrap(urwid.SolidFill(u' '), 'line')\n\n        for graph in self.graphs.values():\n            graph.set_smooth_colors(state)\n\n        self.show_graphs()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _generate_graph_controls(self):\n        # setup mode radio buttons\n        stress_modes = self.controller.stress_conroller.get_modes()\n        group = []\n        for mode in stress_modes:\n            self.mode_buttons.append(radio_button(group, mode,\n                                                  self.on_mode_button))\n\n        # Set default radio button to \"Monitor\" mode\n        self.mode_buttons[0].set_state(True, do_callback=False)\n\n        # Create list of buttons\n        control_options = list()\n        control_options.append(button('Graphs',\n                                      self.on_graphs_menu_open))\n        control_options.append(button('Summaries',\n                                      self.on_summary_menu_open))\n        if self.controller.stress_exe:\n            control_options.append(button('Stress Options',\n                                          self.on_stress_menu_open))\n        control_options.append(button(\"Reset\", self.on_reset_button))\n        control_options.append(button('Help', self.on_help_menu_open))\n        control_options.append(button('About', self.on_about_menu_open))\n        control_options.append(button(\"Save Settings\",\n                                      self.on_save_settings))\n        control_options.append(button(\"Quit\", self.on_exit_program))\n\n        # Create the menu\n        animate_controls = urwid.GridFlow(control_options, 18, 2, 0, 'center')\n\n        # Create smooth graph selection button\n        default_smooth = self.controller.smooth_graph_mode\n        if urwid.get_encoding_mode() == \"utf8\":\n            unicode_checkbox = urwid.CheckBox(\n                \"UTF-8\", state=default_smooth,\n                on_state_change=self.on_unicode_checkbox)\n            # Init the state of the graph accoding to the selected mode\n            self.on_unicode_checkbox(state=default_smooth)\n        else:\n            unicode_checkbox = urwid.Text(\n                \"[N/A] UTF-8\")\n\n        install_stress_message = urwid.Text(\"\")\n        if not self.controller.stress_exe:\n            install_stress_message = urwid.Text(\n                ('button normal', u\"(N/A) install stress\"))\n\n        controls = [urwid.Text(('bold text', u\"Modes\"), align=\"center\")]\n        controls += self.mode_buttons\n        controls += [\n            install_stress_message,\n            urwid.Text(('bold text', u\"Stress Timer\"), align=\"center\"),\n            self.clock_view,\n            urwid.Divider(),\n            urwid.Text(('bold text', u\"Control Options\"), align=\"center\"),\n            animate_controls,\n            urwid.Divider(),\n            urwid.Text(('bold text', u\"Visual Options\"), align=\"center\"),\n            unicode_checkbox,\n            self.refresh_rate_ctrl,\n            urwid.Divider(),\n            urwid.Text(('bold text', u\"Summaries\"), align=\"center\"),\n        ]\n\n        return controls", "response": "Generate the graph controls. i. e. buttons and controls. i. e. buttons and controls. i. e. buttons and controls. i. e. buttons and controls. i. e. buttons and controls."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generate_cpu_stats():\n        cpu_name = urwid.Text(\"CPU Name N/A\", align=\"center\")\n        try:\n            cpu_name = urwid.Text(get_processor_name().strip(), align=\"center\")\n        except OSError:\n            logging.info(\"CPU name not available\")\n        return [urwid.Text(('bold text', \"CPU Detected\"),\n                           align=\"center\"), cpu_name, urwid.Divider()]", "response": "Read and display CPU name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow a pile of the graph selected for dislpay", "response": "def show_graphs(self):\n        \"\"\"Show a pile of the graph selected for dislpay\"\"\"\n        elements = itertools.chain.from_iterable(\n            ([graph]\n             for graph in self.visible_graphs.values()))\n        self.graph_place_holder.original_widget = urwid.Pile(elements)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads and configures the user - defined configuration file and returns a list of sources that are ready to be displayed.", "response": "def _load_config(self, t_thresh):\n        \"\"\"\n        Uses configurations defined by user to configure sources for display.\n        This should be the only place where sources are initiated\n\n        This returns a list of sources after configurations are applied\n        \"\"\"\n        # Load and configure user config dir when controller starts\n        if not user_config_dir_exists():\n            user_config_dir = make_user_config_dir()\n        else:\n            user_config_dir = get_user_config_dir()\n\n        if user_config_dir is None:\n            logging.warning(\"Failed to find or create scripts directory,\\\n                             proceeding without scripting support\")\n            self.script_hooks_enabled = False\n        else:\n            self.script_loader = ScriptHookLoader(user_config_dir)\n\n        # Use user config file if one was saved before\n        self.conf = None\n        if user_config_file_exists():\n            self.conf = configparser.ConfigParser()\n            self.conf.read(get_user_config_file())\n        else:\n            logging.debug(\"Config file not found\")\n\n        # Load refresh refresh rate from config\n        try:\n            self.refresh_rate = str(self.conf.getfloat(\n                'GraphControll', 'refresh'))\n            logging.debug(\"User refresh rate: %s\", self.refresh_rate)\n        except (AttributeError, ValueError, configparser.NoOptionError,\n                configparser.NoSectionError):\n            logging.debug(\"No refresh rate configed\")\n\n        # Change UTF8 setting from config\n        try:\n            if self.conf.getboolean('GraphControll', 'UTF8'):\n                self.smooth_graph_mode = True\n            else:\n                logging.debug(\"UTF8 selected as %s\",\n                              self.conf.get('GraphControll', 'UTF8'))\n        except (AttributeError, ValueError, configparser.NoOptionError,\n                configparser.NoSectionError):\n            logging.debug(\"No user config for utf8\")\n\n        # Try to load high temperature threshold if configured\n        if t_thresh is None:\n            try:\n                self.temp_thresh = self.conf.get('GraphControll', 'TTHRESH')\n                logging.debug(\"Temperature threshold set to %s\",\n                              self.temp_thresh)\n            except (AttributeError, ValueError, configparser.NoOptionError,\n                    configparser.NoSectionError):\n                logging.debug(\"No user config for temp threshold\")\n\n        # This should be the only place where sources are configured\n        possible_sources = [TempSource(self.temp_thresh),\n                            FreqSource(),\n                            UtilSource(),\n                            RaplPowerSource(),\n                            FanSource()]\n\n        # Load sensors config if available\n        sources = [x.get_source_name() for x in possible_sources\n                   if x.get_is_available()]\n        for source in sources:\n            try:\n                options = list(self.conf.items(source + \",Graphs\"))\n                for option in options:\n                    # Returns tuples of values in order\n                    self.graphs_default_conf[source].append(\n                        str_to_bool(option[1]))\n                options = list(self.conf.items(source + \",Summaries\"))\n                for option in options:\n                    # Returns tuples of values in order\n                    self.summary_default_conf[source].append(\n                        str_to_bool(option[1]))\n            except (AttributeError, ValueError, configparser.NoOptionError,\n                    configparser.NoSectionError):\n                logging.debug(\"Error reading sensors config\")\n\n        return possible_sources"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring the possible stress processes and modes", "response": "def _config_stress(self):\n        \"\"\" Configures the possible stress processes and modes \"\"\"\n        # Configure stress_process\n        self.stress_exe = None\n        stress_installed = False\n        self.stress_exe = which('stress')\n        if self.stress_exe:\n            stress_installed = True\n        else:\n            self.stress_exe = which('stress-ng')\n            if self.stress_exe:\n                stress_installed = True\n\n        self.firestarter = None\n        firestarter_installed = False\n        if os.path.isfile('./FIRESTARTER/FIRESTARTER'):\n            self.firestarter = os.path.join(os.getcwd(),\n                                            'FIRESTARTER', 'FIRESTARTER')\n            firestarter_installed = True\n        else:\n            firestarter_exe = which('FIRESTARTER')\n            if firestarter_exe is not None:\n                self.firestarter = firestarter_exe\n                firestarter_installed = True\n\n        return StressController(stress_installed, firestarter_installed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(self):\n        loop = MainLoop(self.view, DEFAULT_PALETTE,\n                        handle_mouse=self.handle_mouse)\n        self.view.show_graphs()\n        self.animate_graph(loop)\n        try:\n            loop.run()\n        except (ZeroDivisionError) as err:\n            # In case of Zero division, we want an error to return, and\n            # get a clue where this happens\n            logging.debug(\"Some stat caused divide by zero exception. Exiting\")\n            logging.error(err, exc_info=True)\n            print(ERROR_MESSAGE)\n        except (AttributeError) as err:\n            # In this case we restart the loop, to address bug #50, where\n            # urwid crashes on multiple presses on 'esc'\n            logging.debug(\"Catch attribute Error in urwid and restart\")\n            logging.debug(err, exc_info=True)\n            self.main()\n        except (psutil.NoSuchProcess) as err:\n            # This might happen if the stress process is not found, in this\n            # case, we want to know why\n            logging.error(\"No such process error\")\n            logging.error(err, exc_info=True)\n            print(ERROR_MESSAGE)", "response": "Main loop for the main loop and graph animation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_stress_mode(self):\n\n        self.stress_conroller.kill_stress_process()\n\n        # Start a new clock upon starting a new stress test\n        self.view.clock_view.set_text(ZERO_TIME)\n        self.stress_start_time = timeit.default_timer()\n\n        if self.stress_conroller.get_current_mode() == 'Stress':\n            stress_cmd = self.view.stress_menu.get_stress_cmd()\n            self.stress_conroller.start_stress(stress_cmd)\n\n        elif self.stress_conroller.get_current_mode() == 'FIRESTARTER':\n            stress_cmd = [self.firestarter]\n            self.stress_conroller.start_stress(stress_cmd)", "response": "Updates the current stress mode according to radio buttons state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the current configuration to a user config file", "response": "def save_settings(self):\n        \"\"\" Save the current configuration to a user config file \"\"\"\n        def _save_displayed_setting(conf, submenu):\n            for source, visible_sensors in \\\n                    self.view.graphs_menu.active_sensors.items():\n                section = source + \",\" + submenu\n                conf.add_section(section)\n\n                sources = self.sources\n                logging.debug(\"Saving settings for %s\", source)\n                logging.debug(\"Visible sensors %s\", visible_sensors)\n                # TODO: consider changing sensors_list to dict\n                curr_sensor = [x for x in sources if\n                               x.get_source_name() == source][0]\n                sensor_list = curr_sensor.get_sensor_list()\n                for sensor_id, sensor in enumerate(sensor_list):\n                    try:\n                        conf.set(section, sensor, str(\n                            visible_sensors[sensor_id]))\n                    except IndexError:\n                        conf.set(section, sensor, str(True))\n\n        if not user_config_dir_exists():\n            make_user_config_dir()\n\n        conf = configparser.ConfigParser()\n        config_file = get_user_config_file()\n        with open(config_file, 'w') as cfgfile:\n            conf.add_section('GraphControll')\n            # Save the configured refresh rete\n            conf.set('GraphControll', 'refresh', str(\n                self.refresh_rate))\n            # Save the configured UTF8 setting\n            conf.set('GraphControll', 'UTF8', str(\n                self.smooth_graph_mode))\n            # Save the configured t_thresh\n            if self.temp_thresh:\n                conf.set('GraphControll', 'TTHRESH', str(\n                    self.temp_thresh))\n\n            _save_displayed_setting(conf, \"Graphs\")\n            _save_displayed_setting(conf, \"Summaries\")\n            conf.write(cfgfile)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the graph and schedule the next update", "response": "def animate_graph(self, loop, user_data=None):\n        \"\"\"\n        Update the graph and schedule the next update\n        This is where the magic happens\n        \"\"\"\n        self.view.update_displayed_information()\n\n        # Save to CSV if configured\n        if self.save_csv or self.csv_file is not None:\n            output_to_csv(self.view.summaries, self.csv_file)\n\n        # Set next update\n        self.animate_alarm = loop.set_alarm_in(\n            float(self.refresh_rate), self.animate_graph)\n\n        if self.args.debug_run:\n            # refresh rate is a string in float format\n            self.debug_run_counter += int(float(self.refresh_rate))\n            if self.debug_run_counter >= 8:\n                self.exit_program()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obfuscation_machine(use_unicode=False, identifier_length=1):\n    # This generates a list of the letters a-z:\n    lowercase = list(map(chr, range(97, 123)))\n    # Same thing but ALL CAPS:\n    uppercase = list(map(chr, range(65, 90)))\n    if use_unicode:\n        # Python 3 lets us have some *real* fun:\n        allowed_categories = ('LC', 'Ll', 'Lu', 'Lo', 'Lu')\n        # All the fun characters start at 1580 (hehe):\n        big_list = list(map(chr, range(1580, HIGHEST_UNICODE)))\n        max_chars = 1000 # Ought to be enough for anybody :)\n        combined = []\n        rtl_categories = ('AL', 'R') # AL == Arabic, R == Any right-to-left\n        last_orientation = 'L'       # L = Any left-to-right\n        # Find a good mix of left-to-right and right-to-left characters\n        while len(combined) < max_chars:\n            char = choice(big_list)\n            if unicodedata.category(char) in allowed_categories:\n                orientation = unicodedata.bidirectional(char)\n                if last_orientation in rtl_categories:\n                    if orientation not in rtl_categories:\n                        combined.append(char)\n                else:\n                    if orientation in rtl_categories:\n                        combined.append(char)\n                last_orientation = orientation\n    else:\n        combined = lowercase + uppercase\n    shuffle(combined) # Randomize it all to keep things interesting\n    while True:\n        for perm in permutations(combined, identifier_length):\n            perm = \"\".join(perm)\n            if perm not in RESERVED_WORDS: # Can't replace reserved words\n                yield perm\n        identifier_length += 1", "response": "A generator that returns short sequential combinations of lower and upper - case letters that will never repeat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the source with all obfuscated.", "response": "def apply_obfuscation(source):\n    \"\"\"\n    Returns 'source' all obfuscated.\n    \"\"\"\n    global keyword_args\n    global imported_modules\n    tokens = token_utils.listified_tokenizer(source)\n    keyword_args = analyze.enumerate_keyword_args(tokens)\n    imported_modules = analyze.enumerate_imports(tokens)\n    variables = find_obfuscatables(tokens, obfuscatable_variable)\n    classes = find_obfuscatables(tokens, obfuscatable_class)\n    functions = find_obfuscatables(tokens, obfuscatable_function)\n    for variable in variables:\n        replace_obfuscatables(\n            tokens, obfuscate_variable, variable, name_generator)\n    for function in functions:\n        replace_obfuscatables(\n            tokens, obfuscate_function, function, name_generator)\n    for _class in classes:\n        replace_obfuscatables(tokens, obfuscate_class, _class, name_generator)\n    return token_utils.untokenize(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding obfuscated tokens in the list of tokens.", "response": "def find_obfuscatables(tokens, obfunc, ignore_length=False):\n    \"\"\"\n    Iterates over *tokens*, which must be an equivalent output to what\n    tokenize.generate_tokens() produces, calling *obfunc* on each with the\n    following parameters:\n\n        - **tokens:**     The current list of tokens.\n        - **index:**      The current position in the list.\n\n    *obfunc* is expected to return the token string if that token can be safely\n    obfuscated **or** one of the following optional values which will instruct\n    find_obfuscatables() how to proceed:\n\n        - **'__skipline__'**   Keep skipping tokens until a newline is reached.\n        - **'__skipnext__'**   Skip the next token in the sequence.\n\n    If *ignore_length* is ``True`` then single-character obfuscatables will\n    be obfuscated anyway (even though it wouldn't save any space).\n    \"\"\"\n    global keyword_args\n    keyword_args = analyze.enumerate_keyword_args(tokens)\n    global imported_modules\n    imported_modules = analyze.enumerate_imports(tokens)\n    #print(\"imported_modules: %s\" % imported_modules)\n    skip_line = False\n    skip_next = False\n    obfuscatables = []\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        if token_type == tokenize.NEWLINE:\n            skip_line = False\n        if skip_line:\n            continue\n        result = obfunc(tokens, index, ignore_length=ignore_length)\n        if result:\n            if skip_next:\n                skip_next = False\n            elif result == '__skipline__':\n                skip_line = True\n            elif result == '__skipnext__':\n                skip_next = True\n            elif result in obfuscatables:\n                pass\n            else:\n                obfuscatables.append(result)\n        else: # If result is empty we need to reset skip_next so we don't\n            skip_next = False # accidentally skip the next identifier\n    return obfuscatables"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the string that can be safely obfuscated by the current position.", "response": "def obfuscatable_variable(tokens, index, ignore_length=False):\n    \"\"\"\n    Given a list of *tokens* and an *index* (representing the current position),\n    returns the token string if it is a variable name that can be safely\n    obfuscated.\n\n    Returns '__skipline__' if the rest of the tokens on this line should be skipped.\n    Returns '__skipnext__' if the next token should be skipped.\n\n    If *ignore_length* is ``True``, even variables that are already a single\n    character will be obfuscated (typically only used with the ``--nonlatin``\n    option).\n    \"\"\"\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    line = tok[4]\n    if index > 0:\n        prev_tok = tokens[index-1]\n    else: # Pretend it's a newline (for simplicity)\n        prev_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n    prev_tok_type = prev_tok[0]\n    prev_tok_string = prev_tok[1]\n    try:\n        next_tok = tokens[index+1]\n    except IndexError: # Pretend it's a newline\n        next_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n    next_tok_string = next_tok[1]\n    if token_string == \"=\":\n        return '__skipline__'\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string.startswith('__'):\n        return None\n    if next_tok_string == \".\":\n        if token_string in imported_modules:\n            return None\n    if prev_tok_string == 'import':\n        return '__skipline__'\n    if prev_tok_string == \".\":\n        return '__skipnext__'\n    if prev_tok_string == \"for\":\n        if len(token_string) > 2:\n            return token_string\n    if token_string == \"for\":\n        return None\n    if token_string in keyword_args.keys():\n        return None\n    if token_string in [\"def\", \"class\", 'if', 'elif', 'import']:\n        return '__skipline__'\n    if prev_tok_type != tokenize.INDENT and next_tok_string != '=':\n        return '__skipline__'\n    if not ignore_length:\n        if len(token_string) < 3:\n            return None\n    if token_string in RESERVED_WORDS:\n        return None\n    return token_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the token string if it is a class name that can be safely obfuscated.", "response": "def obfuscatable_class(tokens, index, **kwargs):\n    \"\"\"\n    Given a list of *tokens* and an *index* (representing the current position),\n    returns the token string if it is a class name that can be safely\n    obfuscated.\n    \"\"\"\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    if index > 0:\n        prev_tok = tokens[index-1]\n    else: # Pretend it's a newline (for simplicity)\n        prev_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n    prev_tok_string = prev_tok[1]\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string.startswith('__'): # Don't mess with specials\n        return None\n    if prev_tok_string == \"class\":\n        return token_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces the given identifier with the obfuscated identifiers.", "response": "def replace_obfuscatables(module, tokens, obfunc, replace, name_generator, table=None):\n    \"\"\"\n    Iterates over *tokens*, which must be an equivalent output to what\n    tokenize.generate_tokens() produces, replacing the given identifier name\n    (*replace*) by calling *obfunc* on each token with the following parameters:\n\n        - **module:**       The name of the script we're currently obfuscating.\n        - **tokens:**       The current list of all tokens.\n        - **index:**        The current position.\n        - **replace:**      The token string that we're replacing.\n        - **replacement:**  A randomly generated, unique value that will be used to replace, *replace*.\n        - **right_of_equal:**   A True or False value representing whether or not the token is to the right of an equal sign.  **Note:** This gets reset to False if a comma or open paren are encountered.\n        - **inside_parens:**    An integer that is incremented whenever an open paren is encountered and decremented when a close paren is encountered.\n        - **inside_function:**  If not False, the name of the function definition we're inside of (used in conjunction with *keyword_args* to determine if a safe replacement can be made).\n\n    *obfunc* is expected to return the token string if that token can be safely\n    obfuscated **or** one of the following optional values which will instruct\n    find_obfuscatables() how to proceed:\n\n        - **'__open_paren__'**        Increment the inside_parens value\n        - **'__close_paren__'**       Decrement the inside_parens value\n        - **'__comma__'**             Reset the right_of_equal value to False\n        - **'__right_of_equal__'**    Sets the right_of_equal value to True\n\n    **Note:** The right_of_equal and the inside_parens values are reset whenever a NEWLINE is encountered.\n\n    When obfuscating a list of files, *table* is used to keep track of which\n    obfuscatable identifiers are which inside each resulting file.  It must be\n    an empty dictionary that will be populated like so::\n\n        {orig_name: obfuscated_name}\n\n    This *table* of \"what is what\" will be used to ensure that references from\n    one script/module that call another are kept in sync when they are replaced\n    with obfuscated values.\n    \"\"\"\n    # Pretend the first line is '#\\n':\n    skip_line = False\n    skip_next = False\n    right_of_equal = False\n    inside_parens = 0\n    inside_function = False\n    indent = 0\n    function_indent = 0\n    replacement = next(name_generator)\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.NEWLINE:\n            skip_line = False\n            right_of_equal = False\n            inside_parens = 0\n        elif token_type == tokenize.INDENT:\n            indent += 1\n        elif token_type == tokenize.DEDENT:\n            indent -= 1\n            if inside_function and function_indent == indent:\n                function_indent = 0\n                inside_function = False\n        if token_string == \"def\":\n            function_indent = indent\n            function_name = tokens[index+1][1]\n            inside_function = function_name\n        result = obfunc(\n            tokens,\n            index,\n            replace,\n            replacement,\n            right_of_equal,\n            inside_parens,\n            inside_function\n        )\n        if result:\n            if skip_next:\n                skip_next = False\n            elif skip_line:\n                pass\n            elif result == '__skipline__':\n                skip_line = True\n            elif result == '__skipnext__':\n                skip_next = True\n            elif result == '__open_paren__':\n                right_of_equal = False\n                inside_parens += 1\n            elif result == '__close_paren__':\n                inside_parens -= 1\n            elif result == '__comma__':\n                right_of_equal = False\n            elif result == '__right_of_equal__':\n                # We only care if we're right of the equal sign outside of\n                # parens (which indicates arguments)\n                if not inside_parens:\n                    right_of_equal = True\n            else:\n                if table: # Save it for later use in other files\n                    combined_name = \"%s.%s\" % (module, token_string)\n                    try: # Attempt to use an existing value\n                        tokens[index][1] = table[0][combined_name]\n                    except KeyError: # Doesn't exist, add it to table\n                        table[0].update({combined_name: result})\n                        tokens[index][1] = result\n                else:\n                    tokens[index][1] = result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nobfuscate a variable from a list of tokens.", "response": "def obfuscate_variable(\n        tokens,\n        index,\n        replace,\n        replacement,\n        right_of_equal,\n        inside_parens,\n        inside_function):\n    \"\"\"\n    If the token string inside *tokens[index]* matches *replace*, return\n    *replacement*. *right_of_equal*, and *inside_parens* are used to determine\n    whether or not this token is safe to obfuscate.\n    \"\"\"\n    def return_replacement(replacement):\n        VAR_REPLACEMENTS[replacement] = replace\n        return replacement\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    if index > 0:\n        prev_tok = tokens[index-1]\n    else: # Pretend it's a newline (for simplicity)\n        prev_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n    prev_tok_string = prev_tok[1]\n    try:\n        next_tok = tokens[index+1]\n    except IndexError: # Pretend it's a newline\n        next_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n    if token_string == \"import\":\n        return '__skipline__'\n    if next_tok[1] == '.':\n        if token_string in imported_modules:\n            return None\n    if token_string == \"=\":\n        return '__right_of_equal__'\n    if token_string == \"(\":\n        return '__open_paren__'\n    if token_string == \")\":\n        return '__close_paren__'\n    if token_string == \",\":\n        return '__comma__'\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string.startswith('__'):\n        return None\n    if prev_tok_string == 'def':\n        return '__skipnext__' # Don't want to touch functions\n    if token_string == replace and prev_tok_string != '.':\n        if inside_function:\n            if token_string not in keyword_args[inside_function]:\n                if not right_of_equal:\n                    if not inside_parens:\n                        return return_replacement(replacement)\n                    else:\n                        if next_tok[1] != '=':\n                            return return_replacement(replacement)\n                elif not inside_parens:\n                    return return_replacement(replacement)\n                else:\n                    if next_tok[1] != '=':\n                        return return_replacement(replacement)\n        elif not right_of_equal:\n            if not inside_parens:\n                return return_replacement(replacement)\n            else:\n                if next_tok[1] != '=':\n                    return return_replacement(replacement)\n        elif right_of_equal and not inside_parens:\n            return return_replacement(replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nobfuscating a function in a list of tokens.", "response": "def obfuscate_function(tokens, index, replace, replacement, *args):\n    \"\"\"\n    If the token string (a function) inside *tokens[index]* matches *replace*,\n    return *replacement*.\n    \"\"\"\n    def return_replacement(replacement):\n        FUNC_REPLACEMENTS[replacement] = replace\n        return replacement\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    prev_tok = tokens[index-1]\n    prev_tok_string = prev_tok[1]\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string.startswith('__'):\n        return None\n    if token_string == replace:\n        if prev_tok_string != '.':\n            if token_string == replace:\n                return return_replacement(replacement)\n        else:\n            parent_name = tokens[index-2][1]\n            if parent_name in CLASS_REPLACEMENTS:\n                # This should work for @classmethod methods\n                return return_replacement(replacement)\n            elif parent_name in VAR_REPLACEMENTS:\n                # This covers regular ol' instance methods\n                return return_replacement(replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obfuscate_class(tokens, index, replace, replacement, *args):\n    def return_replacement(replacement):\n        CLASS_REPLACEMENTS[replacement] = replace\n        return replacement\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    prev_tok = tokens[index-1]\n    prev_tok_string = prev_tok[1]\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string.startswith('__'):\n        return None\n    if prev_tok_string != '.':\n        if token_string == replace:\n            return return_replacement(replacement)", "response": "Obfuscate a class in a token list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nobfuscating a unique value in a token list.", "response": "def obfuscate_unique(tokens, index, replace, replacement, *args):\n    \"\"\"\n    If the token string (a unique value anywhere) inside *tokens[index]*\n    matches *replace*, return *replacement*.\n\n    .. note::\n\n        This function is only for replacing absolutely unique ocurrences of\n        *replace* (where we don't have to worry about their position).\n    \"\"\"\n    def return_replacement(replacement):\n        UNIQUE_REPLACEMENTS[replacement] = replace\n        return replacement\n    tok = tokens[index]\n    token_type = tok[0]\n    token_string = tok[1]\n    if token_type != tokenize.NAME:\n        return None # Skip this token\n    if token_string == replace:\n        return return_replacement(replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remap_name(name_generator, names, table=None):\n    out = \"\"\n    for name in names:\n        if table and name in table[0].keys():\n            replacement = table[0][name]\n        else:\n            replacement = next(name_generator)\n        out += \"%s=%s\\n\" % (replacement, name)\n    return out", "response": "Generates a series of variable assignments for each item in names using the name_generator function to generate a new unique name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_in_next_line(tokens, index, string):\n    tokenized_string = token_utils.listified_tokenizer(string)\n    for i, tok in list(enumerate(tokens[index:])):\n        token_type = tok[0]\n        if token_type in [tokenize.NL, tokenize.NEWLINE]:\n            for count, item in enumerate(tokenized_string):\n                tokens.insert(index+count+i+1, item)\n            break", "response": "Inserts the given string after the next newline inside the given tokens starting at index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef obfuscate_builtins(module, tokens, name_generator, table=None):\n    used_builtins = analyze.enumerate_builtins(tokens)\n    obfuscated_assignments = remap_name(name_generator, used_builtins, table)\n    replacements = []\n    for assignment in obfuscated_assignments.split('\\n'):\n        replacements.append(assignment.split('=')[0])\n    replacement_dict = dict(zip(used_builtins, replacements))\n    if table:\n        table[0].update(replacement_dict)\n    iter_replacements = iter(replacements)\n    for builtin in used_builtins:\n        replace_obfuscatables(\n            module, tokens, obfuscate_unique, builtin, iter_replacements)\n    # Check for shebangs and encodings before we do anything else\n    skip_tokens = 0\n    matched_shebang = False\n    matched_encoding = False\n    for tok in tokens[0:4]: # Will always be in the first four tokens\n        line = tok[4]\n        if analyze.shebang.match(line): # (e.g. '#!/usr/bin/env python')\n            if not matched_shebang:\n                matched_shebang = True\n                skip_tokens += 1\n        elif analyze.encoding.match(line): # (e.g. '# -*- coding: utf-8 -*-')\n            if not matched_encoding:\n                matched_encoding = True\n                skip_tokens += 1\n    insert_in_next_line(tokens, skip_tokens, obfuscated_assignments)", "response": "A function that replaces all of the built - in functions in a single file with a new identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef obfuscate_global_import_methods(module, tokens, name_generator, table=None):\n    global_imports = analyze.enumerate_global_imports(tokens)\n    #print(\"global_imports: %s\" % global_imports)\n    local_imports = analyze.enumerate_local_modules(tokens, os.getcwd())\n    #print(\"local_imports: %s\" % local_imports)\n    module_methods = analyze.enumerate_import_methods(tokens)\n    #print(\"module_methods: %s\" % module_methods)\n    # Make a 1-to-1 mapping dict of module_method<->replacement:\n    if table:\n        replacement_dict = {}\n        for module_method in module_methods:\n            if module_method in table[0].keys():\n                replacement_dict.update({module_method: table[0][module_method]})\n            else:\n                replacement_dict.update({module_method: next(name_generator)})\n        # Update the global lookup table with the new entries:\n        table[0].update(replacement_dict)\n    else:\n        method_map = [next(name_generator) for i in module_methods]\n        replacement_dict = dict(zip(module_methods, method_map))\n    import_line = False\n    # Replace module methods with our obfuscated names in *tokens*\n    for module_method in module_methods:\n        for index, tok in enumerate(tokens):\n            token_type = tok[0]\n            token_string = tok[1]\n            if token_type != tokenize.NAME:\n                continue # Speedup\n            tokens[index+1][1]\n            if token_string == module_method.split('.')[0]:\n                if tokens[index+1][1] == '.':\n                    if tokens[index+2][1] == module_method.split('.')[1]:\n                        if table: # Attempt to use an existing value\n                            tokens[index][1] = table[0][module_method]\n                            tokens[index+1][1] = \"\"\n                            tokens[index+2][1] = \"\"\n                        else:\n                            tokens[index][1] = replacement_dict[module_method]\n                            tokens[index+1][1] = \"\"\n                            tokens[index+2][1] = \"\"\n    # Insert our map of replacement=what after each respective module import\n    for module_method, replacement in replacement_dict.items():\n        indents = []\n        index = 0\n        for tok in tokens[:]:\n            token_type = tok[0]\n            token_string = tok[1]\n            if token_type == tokenize.NEWLINE:\n                import_line = False\n            elif token_type == tokenize.INDENT:\n                indents.append(tok)\n            elif token_type == tokenize.DEDENT:\n                indents.pop()\n            elif token_string == \"import\":\n                import_line = True\n            elif import_line:\n                if token_string == module_method.split('.')[0]:\n                    # Insert the obfuscation assignment after the import\n                    imported_module = \".\".join(module_method.split('.')[:-1])\n                    if table and imported_module in local_imports:\n                        line = \"%s=%s.%s\\n\" % ( # This ends up being 6 tokens\n                            replacement_dict[module_method],\n                            imported_module,\n                            replacement_dict[module_method]\n                        )\n                    else:\n                        line = \"%s=%s\\n\" % ( # This ends up being 6 tokens\n                            replacement_dict[module_method], module_method)\n                    for indent in indents: # Fix indentation\n                        line = \"%s%s\" % (indent[1], line)\n                        index += 1\n                    insert_in_next_line(tokens, index, line)\n                    index += 6 # To make up for the six tokens we inserted\n            index += 1", "response": "A function that replaces the used methods of globally - imported modules with obfuscated names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nobfuscate the given tokens in - place.", "response": "def obfuscate(module, tokens, options, name_generator=None, table=None):\n    \"\"\"\n    Obfuscates *tokens* in-place.  *options* is expected to be the options\n    variable passed through from pyminifier.py.\n\n    *module* must be the name of the module we're currently obfuscating\n\n    If *name_generator* is provided it will be used to obtain replacement values\n    for identifiers.  If not, a new instance of\n\n    If *table* is given (should be a list containing a single dictionary), it\n    will be used to perform lookups of replacements and any new replacements\n    will be added to it.\n    \"\"\"\n    # Need a universal instance of our generator to avoid duplicates\n    identifier_length = int(options.replacement_length)\n    ignore_length = False\n    if not name_generator:\n        if options.use_nonlatin:\n            ignore_length = True\n            if sys.version_info[0] == 3:\n                name_generator = obfuscation_machine(\n                    use_unicode=True, identifier_length=identifier_length)\n            else:\n                print(\n                    \"ERROR: You can't use nonlatin characters without Python 3\")\n        else:\n            name_generator = obfuscation_machine(\n                identifier_length=identifier_length)\n    if options.obfuscate:\n        variables = find_obfuscatables(\n            tokens, obfuscatable_variable, ignore_length=ignore_length)\n        classes = find_obfuscatables(\n            tokens, obfuscatable_class)\n        functions = find_obfuscatables(\n            tokens, obfuscatable_function)\n        for variable in variables:\n            replace_obfuscatables(\n                module,\n                tokens,\n                obfuscate_variable,\n                variable,\n                name_generator,\n                table\n            )\n        for function in functions:\n            replace_obfuscatables(\n                module,\n                tokens,\n                obfuscate_function,\n                function,\n                name_generator,\n                table\n            )\n        for _class in classes:\n            replace_obfuscatables(\n                module, tokens, obfuscate_class, _class, name_generator, table)\n        obfuscate_global_import_methods(module, tokens, name_generator, table)\n        obfuscate_builtins(module, tokens, name_generator, table)\n    else:\n        if options.obf_classes:\n            classes = find_obfuscatables(\n                tokens, obfuscatable_class)\n            for _class in classes:\n                replace_obfuscatables(\n                    module,\n                    tokens,\n                    obfuscate_class,\n                    _class,\n                    name_generator,\n                    table\n                )\n        if options.obf_functions:\n            functions = find_obfuscatables(\n                tokens, obfuscatable_function)\n            for function in functions:\n                replace_obfuscatables(\n                    module,\n                    tokens,\n                    obfuscate_function,\n                    function,\n                    name_generator,\n                    table\n                )\n        if options.obf_variables:\n            variables = find_obfuscatables(\n                tokens, obfuscatable_variable)\n            for variable in variables:\n                replace_obfuscatables(\n                    module,\n                    tokens,\n                    obfuscate_variable,\n                    variable,\n                    name_generator,\n                    table\n                )\n        if options.obf_import_methods:\n            obfuscate_global_import_methods(\n                module, tokens, name_generator, table)\n        if options.obf_builtins:\n            obfuscate_builtins(module, tokens, name_generator, table)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving comments from the given list of tokens.", "response": "def remove_comments(tokens):\n    \"\"\"\n    Removes comments from *tokens* which is expected to be a list equivalent of\n    tokenize.generate_tokens() (so we can update in-place).\n\n    .. note::\n\n        * If the comment makes up the whole line, the newline will also be removed (so you don't end up with lots of blank lines).\n        * Preserves shebangs and encoding strings.\n    \"\"\"\n    preserved_shebang = \"\"\n    preserved_encoding = \"\"\n    # This (short) loop preserves shebangs and encoding strings:\n    for tok in tokens[0:4]: # Will always be in the first four tokens\n        line = tok[4]\n        # Save the first comment line if it starts with a shebang\n        # (e.g. '#!/usr/bin/env python')\n        if analyze.shebang.match(line): # Must be first line\n            preserved_shebang = line\n        # Save the encoding string (must be first or second line in file)\n        # (e.g. '# -*- coding: utf-8 -*-')\n        elif analyze.encoding.match(line):\n            preserved_encoding = line\n    # Now remove comments:\n    prev_tok_type = 0\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        if token_type == tokenize.COMMENT:\n            tokens[index][1] = '' # Making it an empty string removes it\n        # TODO: Figure out a way to make this work\n        #elif prev_tok_type == tokenize.COMMENT:\n            #if token_type == tokenize.NL:\n                #tokens[index][1] = '' # Remove trailing newline\n        prev_tok_type = token_type\n    # Prepend our preserved items back into the token list:\n    if preserved_shebang: # Have to re-tokenize them\n        io_obj = io.StringIO(preserved_shebang + preserved_encoding)\n        preserved = [list(a) for a in tokenize.generate_tokens(io_obj.readline)]\n        preserved.pop() # Get rid of ENDMARKER\n        preserved.reverse() # Round and round we go!\n        for item in preserved:\n            tokens.insert(0, item)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_docstrings(tokens):\n    prev_tok_type = None\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        if token_type == tokenize.STRING:\n            if prev_tok_type == tokenize.INDENT:\n                # Definitely a docstring\n                tokens[index][1] = '' # Remove it\n                # Remove the leftover indentation and newline:\n                tokens[index-1][1] = ''\n                tokens[index-2][1] = ''\n            elif prev_tok_type == tokenize.NL:\n                # This captures whole-module docstrings:\n                if tokens[index+1][0] == tokenize.NEWLINE:\n                    tokens[index][1] = ''\n                    # Remove the trailing newline:\n                    tokens[index+1][1] = ''\n        prev_tok_type = token_type", "response": "Removes docstrings from the given list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_comments_and_docstrings(source):\n    io_obj = io.StringIO(source)\n    out = \"\"\n    prev_toktype = tokenize.INDENT\n    last_lineno = -1\n    last_col = 0\n    for tok in tokenize.generate_tokens(io_obj.readline):\n        token_type = tok[0]\n        token_string = tok[1]\n        start_line, start_col = tok[2]\n        end_line, end_col = tok[3]\n        if start_line > last_lineno:\n            last_col = 0\n        if start_col > last_col:\n            out += (\" \" * (start_col - last_col))\n        # Remove comments:\n        if token_type == tokenize.COMMENT:\n            pass\n        # This series of conditionals removes docstrings:\n        elif token_type == tokenize.STRING:\n            if prev_toktype != tokenize.INDENT:\n        # This is likely a docstring; double-check we're not inside an operator:\n                if prev_toktype != tokenize.NEWLINE:\n                    # Note regarding NEWLINE vs NL: The tokenize module\n                    # differentiates between newlines that start a new statement\n                    # and newlines inside of operators such as parens, brackes,\n                    # and curly braces.  Newlines inside of operators are\n                    # NEWLINE and newlines that start new code are NL.\n                    # Catch whole-module docstrings:\n                    if start_col > 0:\n                        # Unlabelled indentation means we're inside an operator\n                        out += token_string\n                    # Note regarding the INDENT token: The tokenize module does\n                    # not label indentation inside of an operator (parens,\n                    # brackets, and curly braces) as actual indentation.\n                    # For example:\n                    # def foo():\n                    #     \"The spaces before this docstring are tokenize.INDENT\"\n                    #     test = [\n                    #         \"The spaces before this string do not get a token\"\n                    #     ]\n        else:\n            out += token_string\n        prev_toktype = token_type\n        last_col = end_col\n        last_lineno = end_line\n    return out", "response": "Removes comments and docstrings from the source string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves spaces between operators in *source* and returns the result. Example:: def foo(foo, bar, blah): test = \"This is a %s\" % foo Will become:: def foo(foo,bar,blah): test=\"This is a %s\"%foo .. note:: Also removes trailing commas and joins disjointed strings like ``(\"foo\" \"bar\")``.", "response": "def reduce_operators(source):\n    \"\"\"\n    Remove spaces between operators in *source* and returns the result.\n    Example::\n\n        def foo(foo, bar, blah):\n            test = \"This is a %s\" % foo\n\n    Will become::\n\n        def foo(foo,bar,blah):\n            test=\"This is a %s\"%foo\n\n    ..  note::\n\n        Also removes trailing commas and joins disjointed strings like\n        ``(\"foo\" \"bar\")``.\n    \"\"\"\n    io_obj = io.StringIO(source)\n    prev_tok = None\n    out_tokens = []\n    out = \"\"\n    last_lineno = -1\n    last_col = 0\n    nl_types = (tokenize.NL, tokenize.NEWLINE)\n    joining_strings = False\n    new_string = \"\"\n    for tok in tokenize.generate_tokens(io_obj.readline):\n        token_type = tok[0]\n        token_string = tok[1]\n        start_line, start_col = tok[2]\n        end_line, end_col = tok[3]\n        if start_line > last_lineno:\n            last_col = 0\n        if token_type != tokenize.OP:\n            if start_col > last_col and token_type not in nl_types:\n                if prev_tok[0] != tokenize.OP:\n                    out += (\" \" * (start_col - last_col))\n            if token_type == tokenize.STRING:\n                if prev_tok[0] == tokenize.STRING:\n                    # Join the strings into one\n                    string_type = token_string[0] # '' or \"\"\n                    prev_string_type = prev_tok[1][0]\n                    out = out.rstrip(\" \") # Remove any spaces we inserted prev\n                    if not joining_strings:\n                        # Remove prev token and start the new combined string\n                        out = out[:(len(out)-len(prev_tok[1]))]\n                        prev_string = prev_tok[1].strip(prev_string_type)\n                        new_string = (\n                            prev_string + token_string.strip(string_type))\n                        joining_strings = True\n                    else:\n                        new_string += token_string.strip(string_type)\n        else:\n            if token_string in ('}', ')', ']'):\n                if prev_tok[1] == ',':\n                    out = out.rstrip(',')\n            if joining_strings:\n                # NOTE: Using triple quotes so that this logic works with\n                # mixed strings using both single quotes and double quotes.\n                out += \"'''\" + new_string + \"'''\"\n                joining_strings = False\n            if token_string == '@': # Decorators need special handling\n                if prev_tok[0] == tokenize.NEWLINE:\n                    # Ensure it gets indented properly\n                    out += (\" \" * (start_col - last_col))\n        if not joining_strings:\n            out += token_string\n        last_col = end_col\n        last_lineno = end_line\n        prev_tok = tok\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new tree of multiline strings.", "response": "def join_multiline_pairs(source, pair=\"()\"):\n    \"\"\"\n    Finds and removes newlines in multiline matching pairs of characters in\n    *source*.\n\n    By default it joins parens () but it will join any two characters given via\n    the *pair* variable.\n\n    .. note::\n\n        Doesn't remove extraneous whitespace that ends up between the pair.\n        Use `reduce_operators()` for that.\n\n    Example::\n\n        test = (\n            \"This is inside a multi-line pair of parentheses\"\n        )\n\n    Will become::\n\n        test = (            \"This is inside a multi-line pair of parentheses\"        )\n\n    \"\"\"\n    opener = pair[0]\n    closer = pair[1]\n    io_obj = io.StringIO(source)\n    out_tokens = []\n    open_count = 0\n    for tok in tokenize.generate_tokens(io_obj.readline):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.OP and token_string in pair:\n            if token_string == opener:\n                open_count += 1\n            elif token_string == closer:\n                open_count -= 1\n            out_tokens.append(tok)\n        elif token_type in (tokenize.NL, tokenize.NEWLINE):\n            if open_count == 0:\n                out_tokens.append(tok)\n        else:\n            out_tokens.append(tok)\n    return token_utils.untokenize(out_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dedent(source, use_tabs=False):\n    if use_tabs:\n        indent_char = '\\t'\n    else:\n        indent_char = ' '\n    io_obj = io.StringIO(source)\n    out = \"\"\n    last_lineno = -1\n    last_col = 0\n    prev_start_line = 0\n    indentation = \"\"\n    indentation_level = 0\n    for i, tok in enumerate(tokenize.generate_tokens(io_obj.readline)):\n        token_type = tok[0]\n        token_string = tok[1]\n        start_line, start_col = tok[2]\n        end_line, end_col = tok[3]\n        if start_line > last_lineno:\n            last_col = 0\n        if token_type == tokenize.INDENT:\n            indentation_level += 1\n            continue\n        if token_type == tokenize.DEDENT:\n            indentation_level -= 1\n            continue\n        indentation = indent_char * indentation_level\n        if start_line > prev_start_line:\n            if token_string in (',', '.'):\n                out += str(token_string)\n            else:\n                out += indentation + str(token_string)\n        elif start_col > last_col:\n            out += indent_char + str(token_string)\n        else:\n            out += token_string\n        prev_start_line = start_line\n        last_col = end_col\n        last_lineno = end_line\n    return out", "response": "De - indents a source string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_empty_methods(source):\n    def_indentation_level = 0\n    output = \"\"\n    just_matched = False\n    previous_line = None\n    method = re.compile(r'^\\s*def\\s*.*\\(.*\\):.*$')\n    for line in source.split('\\n'):\n        if len(line.strip()) > 0: # Don't look at blank lines\n            if just_matched == True:\n                this_indentation_level = len(line.rstrip()) - len(line.strip())\n                if def_indentation_level == this_indentation_level:\n                    # This method is empty, insert a 'pass' statement\n                    indent = \" \" * (def_indentation_level + 1)\n                    output += \"%s\\n%spass\\n%s\\n\" % (previous_line, indent, line)\n                else:\n                    output += \"%s\\n%s\\n\" % (previous_line, line)\n                just_matched = False\n            elif method.match(line):\n                def_indentation_level = len(line) - len(line.strip())\n                just_matched = True\n                previous_line = line\n            else:\n                output += \"%s\\n\" % line # Another self-test\n        else:\n            output += \"\\n\"\n    return output", "response": "Fixes empty methods and functions in a single file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_blank_lines(source):\n    io_obj = io.StringIO(source)\n    source = [a for a in io_obj.readlines() if a.strip()]\n    return \"\".join(source)", "response": "Removes blank lines from source and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms minification on *tokens* according to the values in *options*", "response": "def minify(tokens, options):\n    \"\"\"\n    Performs minification on *tokens* according to the values in *options*\n    \"\"\"\n    # Remove comments\n    remove_comments(tokens)\n    # Remove docstrings\n    remove_docstrings(tokens)\n    result = token_utils.untokenize(tokens)\n    # Minify our input script\n    result = multiline_indicator.sub('', result)\n    result = fix_empty_methods(result)\n    result = join_multiline_pairs(result)\n    result = join_multiline_pairs(result, '[]')\n    result = join_multiline_pairs(result, '{}')\n    result = remove_blank_lines(result)\n    result = reduce_operators(result)\n    result = dedent(result, use_tabs=options.tabs)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if obj is iterable but not a bytearray.", "response": "def is_iterable(obj):\n    \"\"\"\n    Returns `True` if *obj* is iterable but *not* if *obj* is a string, bytes,\n    or a bytearray.\n    \"\"\"\n    if isinstance(obj, (str, bytes, bytearray)):\n        return False\n    return isinstance(obj, Iterable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive an *options* object (from `optparse.OptionParser` or similar), performs minification and/or obfuscation on the given *files* (any iterable containing file paths) based on said *options*. All accepted options can be listed by running ``python __main__.py -h`` or examining the :py:func:`__init__.main` function.", "response": "def pyminify(options, files):\n    \"\"\"\n    Given an *options* object (from `optparse.OptionParser` or similar),\n    performs minification and/or obfuscation on the given *files* (any iterable\n    containing file paths) based on said *options*.\n\n    All accepted options can\u3000be listed by running ``python __main__.py -h`` or\n    examining the :py:func:`__init__.main` function.\n    \"\"\"\n    global name_generator\n    if not is_iterable(files):\n        print(\n            \"Error: The 'files' argument must be a list, tuple, etc of files.  \"\n            \"Strings and bytes won't work.\")\n        sys.exit(1)\n    if options.pyz:\n        # Check to make sure we were only passed one script (only one at a time)\n        if len(files) > 1:\n            print(\"ERROR: The --pyz option only works with one python file at \"\n                  \"a time.\")\n            print(\"(Dependencies will be automagically included in the \"\n                  \"resulting .pyz)\")\n            sys.exit(1)\n        # Make our .pyz:\n        compression.zip_pack(files, options)\n        return None # Make sure we don't do anything else\n    # Read in our prepend text (if any)\n    prepend = None\n    if options.prepend:\n        try:\n            prepend = open(options.prepend).read()\n        except Exception as err:\n            print(\"Error reading %s:\" % options.prepend)\n            print(err)\n\n    obfuscations = (options.obfuscate, options.obf_classes,\n                    options.obf_functions, options.obf_variables,\n                    options.obf_builtins, options.obf_import_methods)\n\n    # Automatically enable obfuscation if --nonlatin (implied if no explicit\n    # obfuscation is stated)\n    if options.use_nonlatin and not any(obfuscations):\n        options.obfuscate = True\n    if len(files) > 1: # We're dealing with more than one file\n        name_generator = None # So we can tell if we need to obfuscate\n        if any(obfuscations):\n            # Put together that will be used for all obfuscation functions:\n            identifier_length = int(options.replacement_length)\n            if options.use_nonlatin:\n                if sys.version_info[0] == 3:\n                    name_generator = obfuscate.obfuscation_machine(\n                        use_unicode=True, identifier_length=identifier_length\n                    )\n                else:\n                    print(\n                        \"ERROR: You can't use nonlatin characters without Python 3\")\n                    sys.exit(2)\n            else:\n                name_generator = obfuscate.obfuscation_machine(\n                    identifier_length=identifier_length)\n            table =[{}]\n        cumulative_size = 0 # For size reduction stats\n        cumulative_new = 0 # Ditto\n        for sourcefile in files:\n            # Record how big the file is so we can compare afterwards\n            filesize = os.path.getsize(sourcefile)\n            cumulative_size += filesize\n            # Get the module name from the path\n            module = os.path.split(sourcefile)[1]\n            module = \".\".join(module.split('.')[:-1])\n            source = open(sourcefile).read()\n            tokens = token_utils.listified_tokenizer(source)\n            if not options.nominify: # Perform minification\n                source = minification.minify(tokens, options)\n            # Have to re-tokenize for obfucation (it is quick):\n            tokens = token_utils.listified_tokenizer(source)\n            # Perform obfuscation if any of the related options were set\n            if name_generator:\n                obfuscate.obfuscate(\n                    module,\n                    tokens,\n                    options,\n                    name_generator=name_generator,\n                    table=table\n                )\n            # Convert back to text\n            result = ''\n            if prepend:\n                result += prepend\n            result += token_utils.untokenize(tokens)\n            # Compress it if we were asked to do so\n            if options.bzip2:\n                result = compression.bz2_pack(result)\n            elif options.gzip:\n                result = compression.gz_pack(result)\n            elif lzma and options.lzma:\n                result = compression.lzma_pack(result)\n            result += (\n                \"# Created by pyminifier \"\n                \"(https://github.com/liftoff/pyminifier)\\n\")\n            # Either save the result to the output file or print it to stdout\n            if not os.path.exists(options.destdir):\n                os.mkdir(options.destdir)\n            # Need the path where the script lives for the next steps:\n            filepath = os.path.split(sourcefile)[1]\n            path = options.destdir + '/' + filepath # Put everything in destdir\n            f = open(path, 'w')\n            f.write(result)\n            f.close()\n            new_filesize = os.path.getsize(path)\n            cumulative_new += new_filesize\n            percent_saved = round((float(new_filesize) / float(filesize)) * 100, 2) if float(filesize)!=0 else 0\n            print((\n                \"{sourcefile} ({filesize}) reduced to {new_filesize} bytes \"\n                \"({percent_saved}% of original size)\").format(**locals()))\n        p_saved = round(\n            (float(cumulative_new) / float(cumulative_size) * 100), 2)\n        print(\"Overall size reduction: {0}% of original size\".format(p_saved))\n    else:\n        # Get the module name from the path\n        _file = files[0]\n        module = os.path.split(_file)[1]\n        module = \".\".join(module.split('.')[:-1])\n        filesize = os.path.getsize(_file)\n        source = open(_file).read()\n        # Convert the tokens from a tuple of tuples to a list of lists so we can\n        # update in-place.\n        tokens = token_utils.listified_tokenizer(source)\n        if not options.nominify: # Perform minification\n            source = minification.minify(tokens, options)\n            # Convert back to tokens in case we're obfuscating\n            tokens = token_utils.listified_tokenizer(source)\n        # Perform obfuscation if any of the related options were set\n        if options.obfuscate or options.obf_classes or options.obf_functions \\\n                or options.obf_variables or options.obf_builtins \\\n                or options.obf_import_methods:\n            identifier_length = int(options.replacement_length)\n            name_generator = obfuscate.obfuscation_machine(\n                identifier_length=identifier_length)\n            obfuscate.obfuscate(module, tokens, options)\n        # Convert back to text\n        result = ''\n        if prepend:\n            result += prepend\n        result += token_utils.untokenize(tokens)\n        # Compress it if we were asked to do so\n        if options.bzip2:\n            result = compression.bz2_pack(result)\n        elif options.gzip:\n            result = compression.gz_pack(result)\n        elif lzma and options.lzma:\n            result = compression.lzma_pack(result)\n        result += (\n            \"# Created by pyminifier \"\n            \"(https://github.com/liftoff/pyminifier)\\n\")\n        # Either save the result to the output file or print it to stdout\n        if options.outfile:\n            f = io.open(options.outfile, 'w', encoding='utf-8')\n            f.write(result)\n            f.close()\n            new_filesize = os.path.getsize(options.outfile)\n            percent_saved = round(float(new_filesize)/float(filesize) * 100, 2)\n            print((\n                \"{_file} ({filesize}) reduced to {new_filesize} bytes \"\n                \"({percent_saved}% of original size)\".format(**locals())))\n        else:\n            print(result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    usage = '%prog [options] \"<input file>\"'\n    if '__main__.py' in sys.argv[0]: # python -m pyminifier\n        usage = 'pyminifier [options] \"<input file>\"'\n    parser = OptionParser(usage=usage, version=__version__)\n    parser.disable_interspersed_args()\n    parser.add_option(\n        \"-o\", \"--outfile\",\n        dest=\"outfile\",\n        default=None,\n        help=\"Save output to the given file.\",\n        metavar=\"<file path>\"\n    )\n    parser.add_option(\n        \"-d\", \"--destdir\",\n        dest=\"destdir\",\n        default=\"./minified\",\n        help=(\"Save output to the given directory. \"\n              \"This option is required when handling multiple files. \"\n              \"Defaults to './minified' and will be created if not present. \"),\n        metavar=\"<file path>\"\n    )\n    parser.add_option(\n        \"--nominify\",\n        action=\"store_true\",\n        dest=\"nominify\",\n        default=False,\n        help=\"Don't bother minifying (only used with --pyz).\",\n    )\n    parser.add_option(\n        \"--use-tabs\",\n        action=\"store_true\",\n        dest=\"tabs\",\n        default=False,\n        help=\"Use tabs for indentation instead of spaces.\",\n    )\n    parser.add_option(\n        \"--bzip2\",\n        action=\"store_true\",\n        dest=\"bzip2\",\n        default=False,\n        help=(\"bzip2-compress the result into a self-executing python script.  \"\n              \"Only works on stand-alone scripts without implicit imports.\")\n    )\n    parser.add_option(\n        \"--gzip\",\n        action=\"store_true\",\n        dest=\"gzip\",\n        default=False,\n        help=(\"gzip-compress the result into a self-executing python script.  \"\n              \"Only works on stand-alone scripts without implicit imports.\")\n    )\n    if lzma:\n        parser.add_option(\n            \"--lzma\",\n            action=\"store_true\",\n            dest=\"lzma\",\n            default=False,\n            help=(\"lzma-compress the result into a self-executing python script.  \"\n                  \"Only works on stand-alone scripts without implicit imports.\")\n        )\n    parser.add_option(\n        \"--pyz\",\n        dest=\"pyz\",\n        default=None,\n        help=(\"zip-compress the result into a self-executing python script. \"\n              \"This will create a new file that includes any necessary implicit\"\n              \" (local to the script) modules.  Will include/process all files \"\n              \"given as arguments to pyminifier.py on the command line.\"),\n        metavar=\"<name of archive>.pyz\"\n    )\n    parser.add_option(\n        \"-O\", \"--obfuscate\",\n        action=\"store_true\",\n        dest=\"obfuscate\",\n        default=False,\n        help=(\n            \"Obfuscate all function/method names, variables, and classes.  \"\n            \"Default is to NOT obfuscate.\"\n        )\n    )\n    parser.add_option(\n        \"--obfuscate-classes\",\n        action=\"store_true\",\n        dest=\"obf_classes\",\n        default=False,\n        help=\"Obfuscate class names.\"\n    )\n    parser.add_option(\n        \"--obfuscate-functions\",\n        action=\"store_true\",\n        dest=\"obf_functions\",\n        default=False,\n        help=\"Obfuscate function and method names.\"\n    )\n    parser.add_option(\n        \"--obfuscate-variables\",\n        action=\"store_true\",\n        dest=\"obf_variables\",\n        default=False,\n        help=\"Obfuscate variable names.\"\n    )\n    parser.add_option(\n        \"--obfuscate-import-methods\",\n        action=\"store_true\",\n        dest=\"obf_import_methods\",\n        default=False,\n        help=\"Obfuscate globally-imported mouled methods (e.g. 'Ag=re.compile').\"\n    )\n    parser.add_option(\n        \"--obfuscate-builtins\",\n        action=\"store_true\",\n        dest=\"obf_builtins\",\n        default=False,\n        help=\"Obfuscate built-ins (i.e. True, False, object, Exception, etc).\"\n    )\n    parser.add_option(\n        \"--replacement-length\",\n        dest=\"replacement_length\",\n        default=1,\n        help=(\n            \"The length of the random names that will be used when obfuscating \"\n            \"identifiers.\"\n        ),\n        metavar=\"1\"\n    )\n    parser.add_option(\n        \"--nonlatin\",\n        action=\"store_true\",\n        dest=\"use_nonlatin\",\n        default=False,\n        help=(\n            \"Use non-latin (unicode) characters in obfuscation (Python 3 only).\"\n            \"  WARNING: This results in some SERIOUSLY hard-to-read code.\"\n        )\n    )\n    parser.add_option(\n        \"--prepend\",\n        dest=\"prepend\",\n        default=None,\n        help=(\n            \"Prepend the text in this file to the top of our output.  \"\n            \"e.g. A copyright notice.\"\n        ),\n        metavar=\"<file path>\"\n    )\n    options, files = parser.parse_args()\n    if not files:\n        parser.print_help()\n        sys.exit(2)\n    pyminify(options, files)", "response": "This function is called by the command line tool. It sets up our command line options prints the usage and help for the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the output of tokenize. generate_tokens back into a human - readable string.", "response": "def untokenize(tokens):\n    \"\"\"\n    Converts the output of tokenize.generate_tokens back into a human-readable\n    string (that doesn't contain oddly-placed whitespace everywhere).\n\n    .. note::\n\n        Unlike :meth:`tokenize.untokenize`, this function requires the 3rd and\n        4th items in each token tuple (though we can use lists *or* tuples).\n    \"\"\"\n    out = \"\"\n    last_lineno = -1\n    last_col = 0\n    for tok in tokens:\n        token_string = tok[1]\n        start_line, start_col = tok[2]\n        end_line, end_col = tok[3]\n        # The following two conditionals preserve indentation:\n        if start_line > last_lineno:\n            last_col = 0\n        if start_col > last_col and token_string != '\\n':\n            out += (\" \" * (start_col - last_col))\n        out += token_string\n        last_col = end_col\n        last_lineno = end_line\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listified_tokenizer(source):\n    io_obj = io.StringIO(source)\n    return [list(a) for a in tokenize.generate_tokens(io_obj.readline)]", "response": "Tokenizes source and returns the tokens as a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the tokens and returns a dictionary with function names as the keys and lists of keyword arguments as the values.", "response": "def enumerate_keyword_args(tokens):\n    \"\"\"\n    Iterates over *tokens* and returns a dictionary with function names as the\n    keys and lists of keyword arguments as the values.\n    \"\"\"\n    keyword_args = {}\n    inside_function = False\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.NEWLINE:\n            inside_function = False\n        if token_type == tokenize.NAME:\n            if token_string == \"def\":\n                function_name = tokens[index+1][1]\n                inside_function = function_name\n                keyword_args.update({function_name: []})\n            elif inside_function:\n                if tokens[index+1][1] == '=': # keyword argument\n                    keyword_args[function_name].append(token_string)\n    return keyword_args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating over the tokens and returns a list of all imported modules.", "response": "def enumerate_imports(tokens):\n    \"\"\"\n    Iterates over *tokens* and returns a list of all imported modules.\n\n    .. note:: This ignores imports using the 'as' and 'from' keywords.\n    \"\"\"\n    imported_modules = []\n    import_line = False\n    from_import = False\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.NEWLINE:\n            import_line = False\n            from_import = False\n        elif token_string == \"import\":\n            import_line = True\n        elif token_string == \"from\":\n            from_import = True\n        elif import_line:\n            if token_type == tokenize.NAME and tokens[index+1][1] != 'as':\n                if not from_import:\n                    if token_string not in reserved_words:\n                        if token_string not in imported_modules:\n                            imported_modules.append(token_string)\n    return imported_modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all globally imported modules.", "response": "def enumerate_global_imports(tokens):\n    \"\"\"\n    Returns a list of all globally imported modules (skips modules imported\n    inside of classes, methods, or functions).  Example::\n\n        >>> enumerate_global_modules(tokens)\n        ['sys', 'os', 'tokenize', 're']\n\n    .. note::\n\n        Does not enumerate imports using the 'from' or 'as' keywords.\n    \"\"\"\n    imported_modules = []\n    import_line = False\n    from_import = False\n    parent_module = \"\"\n    function_count = 0\n    indentation = 0\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.INDENT:\n            indentation += 1\n        elif token_type == tokenize.DEDENT:\n            indentation -= 1\n        elif token_type == tokenize.NEWLINE:\n            import_line = False\n            from_import = False\n        elif token_type == tokenize.NAME:\n            if token_string in [\"def\", \"class\"]:\n                function_count += 1\n            if indentation == function_count - 1:\n                function_count -= 1\n            elif function_count >= indentation:\n                if token_string == \"import\":\n                    import_line = True\n                elif token_string == \"from\":\n                    from_import = True\n                elif import_line:\n                    if token_type == tokenize.NAME \\\n                        and tokens[index+1][1] != 'as':\n                        if not from_import \\\n                            and token_string not in reserved_words:\n                            if token_string not in imported_modules:\n                                if tokens[index+1][1] == '.': # module.module\n                                    parent_module = token_string + '.'\n                                else:\n                                    if parent_module:\n                                        module_string = (\n                                            parent_module + token_string)\n                                        imported_modules.append(module_string)\n                                        parent_module = ''\n                                    else:\n                                        imported_modules.append(token_string)\n\n    return imported_modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of all dynamically imported modules in a single tree node.", "response": "def enumerate_dynamic_imports(tokens):\n    \"\"\"\n    Returns a dictionary of all dynamically imported modules (those inside of\n    classes or functions) in the form of {<func or class name>: [<modules>]}\n\n    Example:\n        >>> enumerate_dynamic_modules(tokens)\n        {'myfunc': ['zlib', 'base64']}\n    \"\"\"\n    imported_modules = []\n    import_line = False\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.NEWLINE:\n            import_line = False\n        elif token_string == \"import\":\n            try:\n                if tokens[index-1][0] == tokenize.NEWLINE:\n                    import_line = True\n            except IndexError:\n                import_line = True # Just means this is the first line\n        elif import_line:\n            if token_type == tokenize.NAME and tokens[index+1][1] != 'as':\n                if token_string not in reserved_words:\n                    if token_string not in imported_modules:\n                        imported_modules.append(token_string)\n    return imported_modules"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all object or module method calls in the given tokens.", "response": "def enumerate_method_calls(tokens, modules):\n    \"\"\"\n    Returns a list of all object (not module) method calls in the given tokens.\n\n    *modules* is expected to be a list of all global modules imported into the\n    source code we're working on.\n\n    For example:\n        >>> enumerate_method_calls(tokens)\n        ['re.compile', 'sys.argv', 'f.write']\n    \"\"\"\n    out = []\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_type == tokenize.NAME:\n            next_tok_string = tokens[index+1][1]\n            if next_tok_string == '(': # Method call\n                prev_tok_string = tokens[index-1][1]\n                # Check if we're attached to an object or module\n                if prev_tok_string == '.': # We're attached\n                    prev_prev_tok_string = tokens[index-2][1]\n                    if prev_prev_tok_string not in ['\"\"',\"''\", ']', ')', '}']:\n                        if prev_prev_tok_string not in modules:\n                            to_replace = \"%s.%s\" % (\n                                prev_prev_tok_string, token_string)\n                            if to_replace not in out:\n                                out.append(to_replace)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all the builtins being used in tokens.", "response": "def enumerate_builtins(tokens):\n    \"\"\"\n    Returns a list of all the builtins being used in *tokens*.\n    \"\"\"\n    out = []\n    for index, tok in enumerate(tokens):\n        token_type = tok[0]\n        token_string = tok[1]\n        if token_string in builtins:\n            # Note: I need to test if print can be replaced in Python 3\n            special_special = ['print'] # Print is special in Python 2\n            if py3:\n                special_special = []\n            if token_string not in special_special:\n                if not token_string.startswith('__'): # Don't count magic funcs\n                    if tokens[index-1][1] != '.' and tokens[index+1][1] != '=':\n                        if token_string not in out:\n                            out.append(token_string)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of imported module methods inside a node.", "response": "def enumerate_import_methods(tokens):\n    \"\"\"\n    Returns a list of imported module methods (such as re.compile) inside\n    *tokens*.\n    \"\"\"\n    global_imports = enumerate_global_imports(tokens)\n    out = []\n    for item in global_imports:\n        for index, tok in enumerate(tokens):\n            try:\n                next_tok = tokens[index+1]\n                try:\n                    next_next_tok = tokens[index+2]\n                except IndexError:\n                    # Pretend it is a newline\n                    next_next_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n            except IndexError: # Last token, no biggie\n                # Pretend it is a newline here too\n                next_tok = (54, '\\n', (1, 1), (1, 2), '#\\n')\n            token_type = tok[0]\n            token_string = tok[1]\n            if token_string == item:\n                if next_tok[1] == '.': # We're calling a method\n                    module_method = \"%s.%s\" % (token_string, next_next_tok[1])\n                    if module_method not in out:\n                        out.append(module_method)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enumerate_local_modules(tokens, path):\n    # Have to get a list of all modules before we can do anything else\n    modules = enumerate_imports(tokens)\n    local_modules = []\n    parent = \"\"\n    # Now check the local dir for matching modules\n    for root, dirs, files in os.walk(path):\n        if not parent:\n            parent = os.path.split(root)[1]\n        for f in files:\n            if f.endswith('.py'):\n                f = f[:-3] # Strip .py\n                module_tree = root.split(parent)[1].replace('/', '.')\n                module_tree = module_tree.lstrip('.')\n                if module_tree:\n                    module = \"%s.%s\" % (module_tree, f)\n                else:\n                    module = f\n                if not module in modules:\n                    local_modules.append(module)\n    return local_modules", "response": "Returns a list of modules that are local to path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the shebang string in *tokens* if it exists.", "response": "def get_shebang(tokens):\n    \"\"\"\n    Returns the shebang string in *tokens* if it exists.  None if not.\n    \"\"\"\n    # This (short) loop preserves shebangs and encoding strings:\n    for tok in tokens[0:4]: # Will always be in the first four tokens\n        line = tok[4]\n        # Save the first comment line if it starts with a shebang\n        # (e.g. '#!/usr/bin/env python')\n        if shebang.match(line): # Must be first line\n            return line"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bz2_pack(source):\n    import bz2, base64\n    out = \"\"\n    # Preserve shebangs (don't care about encodings for this)\n    first_line = source.split('\\n')[0]\n    if analyze.shebang.match(first_line):\n        if py3:\n            if first_line.rstrip().endswith('python'): # Make it python3\n                first_line = first_line.rstrip()\n                first_line += '3' #!/usr/bin/env python3\n        out = first_line + '\\n'\n    compressed_source = bz2.compress(source.encode('utf-8'))\n    out += 'import bz2, base64\\n'\n    out += \"exec(bz2.decompress(base64.b64decode('\"\n    out += base64.b64encode(compressed_source).decode('utf-8')\n    out += \"')))\\n\"\n    return out", "response": "Returns source as a bzip2 - compressed self - extraction python script."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepend(line, path):\n    if isinstance(line, str):\n        line = line.encode('utf-8')\n    if not line.endswith(b'\\n'):\n        line += b'\\n'\n    temp = tempfile.NamedTemporaryFile('wb')\n    temp_name = temp.name # We really only need a random path-safe name\n    temp.close()\n    with open(temp_name, 'wb') as temp:\n        temp.write(line)\n        with open(path, 'rb') as r:\n            temp.write(r.read())\n    # Now replace the original with the modified version\n    shutil.move(temp_name, path)", "response": "Prepends a line to the beginning of the file at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npack a single module into a zip archive.", "response": "def zip_pack(filepath, options):\n    \"\"\"\n    Creates a zip archive containing the script at *filepath* along with all\n    imported modules that are local to *filepath* as a self-extracting python\n    script.  A shebang will be appended to the beginning of the resulting\n    zip archive which will allow it to\n\n    If being run inside Python 3 and the `lzma` module is available the\n    resulting 'pyz' file will use ZIP_LZMA compression to maximize compression.\n\n    *options* is expected to be the the same options parsed from pyminifier.py\n    on the command line.\n\n    .. note::\n\n        * The file resulting from this method cannot be imported as a module into another python program (command line execution only).\n        * Any required local (implied path) modules will be automatically included (well, it does its best).\n        * The result will be saved as a .pyz file (which is an extension I invented for this format).\n    \"\"\"\n    import zipfile\n    # Hopefully some day we'll be able to use ZIP_LZMA too as the compression\n    # format to save even more space...\n    compression_format = zipfile.ZIP_DEFLATED\n    cumulative_size = 0 # For tracking size reduction stats\n    # Record the filesize for later comparison\n    cumulative_size += os.path.getsize(filepath)\n    dest = options.pyz\n    z = zipfile.ZipFile(dest, \"w\", compression_format)\n    # Take care of minifying our primary script first:\n    source = open(filepath).read()\n    primary_tokens = token_utils.listified_tokenizer(source)\n    # Preserve shebangs (don't care about encodings for this)\n    shebang = analyze.get_shebang(primary_tokens)\n    if not shebang:\n    # We *must* have a shebang for this to work so make a conservative default:\n        shebang = \"#!/usr/bin/env python\"\n    if py3:\n        if shebang.rstrip().endswith('python'): # Make it python3 (to be safe)\n            shebang = shebang.rstrip()\n            shebang += '3\\n' #!/usr/bin/env python3\n    if not options.nominify: # Minify as long as we don't have this option set\n        source = minification.minify(primary_tokens, options)\n    # Write out to a temporary file to add to our zip\n    temp = tempfile.NamedTemporaryFile(mode='w')\n    temp.write(source)\n    temp.flush()\n    # Need the path where the script lives for the next steps:\n    path = os.path.split(filepath)[0]\n    if not path:\n        path = os.getcwd()\n    main_py = path + '/__main__.py'\n    if os.path.exists(main_py):\n        # There's an existing __main__.py, use it\n        z.write(main_py, '__main__.py')\n        z.write(temp.name, os.path.split(filepath)[1])\n    else:\n        # No __main__.py so we rename our main script to be the __main__.py\n        # This is so it will still execute as a zip\n        z.write(filepath, '__main__.py')\n    temp.close()\n    # Now write any required modules into the zip as well\n    local_modules = analyze.enumerate_local_modules(primary_tokens, path)\n    name_generator = None # So we can tell if we need to obfuscate\n    if options.obfuscate or options.obf_classes \\\n        or options.obf_functions or options.obf_variables \\\n        or options.obf_builtins or options.obf_import_methods:\n        # Put together that will be used for all obfuscation functions:\n        identifier_length = int(options.replacement_length)\n        if options.use_nonlatin:\n            if sys.version_info[0] == 3:\n                name_generator = obfuscate.obfuscation_machine(\n                    use_unicode=True, identifier_length=identifier_length\n                )\n            else:\n                print(\n                    \"ERROR: You can't use nonlatin characters without Python 3\")\n                sys.exit(2)\n        else:\n            name_generator = obfuscate.obfuscation_machine(\n                identifier_length=identifier_length)\n        table =[{}]\n    included_modules = []\n    for module in local_modules:\n        module = module.replace('.', '/')\n        module = \"%s.py\" % module\n        # Add the filesize to our total\n        cumulative_size += os.path.getsize(module)\n        # Also record that we've added it to the archive\n        included_modules.append(module)\n        # Minify these files too\n        source = open(os.path.join(path, module)).read()\n        tokens = token_utils.listified_tokenizer(source)\n        maybe_more_modules = analyze.enumerate_local_modules(tokens, path)\n        for mod in maybe_more_modules:\n            if mod not in local_modules:\n                local_modules.append(mod) # Extend the current loop, love it =)\n        if not options.nominify:\n            # Perform minification (this also handles obfuscation)\n            source = minification.minify(tokens, options)\n        # Have to re-tokenize for obfucation (it's quick):\n        tokens = token_utils.listified_tokenizer(source)\n        # Perform obfuscation if any of the related options were set\n        if name_generator:\n            obfuscate.obfuscate(\n                module,\n                tokens,\n                options,\n                name_generator=name_generator,\n                table=table\n            )\n        # Convert back to text\n        result = token_utils.untokenize(tokens)\n        result += (\n                \"# Created by pyminifier \"\n                \"(https://github.com/liftoff/pyminifier)\\n\")\n        # Write out to a temporary file to add to our zip\n        temp = tempfile.NamedTemporaryFile(mode='w')\n        temp.write(source)\n        temp.flush()\n        z.write(temp.name, module)\n        temp.close()\n    z.close()\n    # Finish up by writing the shebang to the beginning of the zip\n    prepend(shebang, dest)\n    os.chmod(dest, 0o755) # Make it executable (since we added the shebang)\n    pyz_filesize = os.path.getsize(dest)\n    percent_saved = round(float(pyz_filesize) / float(cumulative_size) * 100, 2)\n    print('%s saved as compressed executable zip: %s' % (filepath, dest))\n    print('The following modules were automatically included (as automagic '\n          'dependencies):\\n')\n    for module in included_modules:\n        print('\\t%s' % module)\n    print('\\nOverall size reduction: %s%% of original size' % percent_saved)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_variable_days(self, year):\n        days = super(LateSummer, self).get_variable_days(year)\n        days.append((\n            self.get_nth_weekday_in_month(year, 9, MON),\n            \"Late Summer Holiday\"\n        ))\n        return days", "response": "Return a list of variable days for the given year."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering Calendar class as country or region in IsoRegistry. Registered country must set class variables ``iso`` using this decorator. >>> from workalendar.core import Calendar >>> @iso_register('MC-MR') >>> class MyRegion(Calendar): >>> 'My Region' Region calendar is then retrievable from registry: >>> calendar = registry.get_calendar_class('MC-MR')", "response": "def iso_register(iso_code):\n    \"\"\"\n    Registers Calendar class as country or region in IsoRegistry.\n\n    Registered country must set class variables ``iso`` using this decorator.\n\n    >>> from workalendar.core import Calendar\n    >>> @iso_register('MC-MR')\n    >>> class MyRegion(Calendar):\n    >>>     'My Region'\n\n    Region calendar is then retrievable from registry:\n\n    >>> calendar = registry.get_calendar_class('MC-MR')\n    \"\"\"\n    def wrapper(cls):\n        registry.register(iso_code, cls)\n        return cls\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the calendar class associated with given ISO code.", "response": "def get_calendar_class(self, iso_code):\n        \"\"\"\n        Retrieves calendar class associated with given ``iso_code``.\n\n        If calendar of subdivision is not registered\n        (for subdivision like ISO codes, e.g. GB-ENG)\n        returns calendar of containing region\n        (e.g. United Kingdom for ISO code GB) if it's available.\n\n        :rtype: Calendar\n        \"\"\"\n        code_elements, is_subregion = self._code_elements(iso_code)\n        if is_subregion and iso_code not in self.region_registry:\n            # subregion code not in region_registry\n            code = code_elements[0]\n        else:\n            # subregion code in region_registry or is not a subregion\n            code = iso_code\n        return self.region_registry.get(code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subregions(self, iso_code):\n        items = OrderedDict()\n        for key, value in self.region_registry.items():\n            code_elements, is_subregion = self._code_elements(key)\n            if is_subregion and code_elements[0] == iso_code:\n                items[key] = value\n        return items", "response": "Returns a dictionary of calendar classes for given region iso_code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef items(self, region_codes, include_subregions=False):\n        items = OrderedDict()\n        for code in region_codes:\n            try:\n                items[code] = self.region_registry[code]\n            except KeyError:\n                continue\n            if include_subregions:\n                items.update(self.get_subregions(code))\n        return items", "response": "Returns a dictionary of calendar classes for selected regions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleaned_date(day, keep_datetime=False):\n    if not isinstance(day, (date, datetime)):\n        raise UnsupportedDateType(\n            \"`{}` is of unsupported type ({})\".format(day, type(day)))\n    if not keep_datetime:\n        if hasattr(day, 'date') and callable(day.date):\n            day = day.date()\n    return day", "response": "Return a date type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_fixed_holidays(self, year):\n        days = []\n        for month, day, label in self.FIXED_HOLIDAYS:\n            days.append((date(year, month, day), label))\n        return days", "response": "Return the fixed days according to the FIXED_HOLIDAYS class property."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing holidays for a given year.", "response": "def holidays(self, year=None):\n        \"\"\"Computes holidays (non-working days) for a given year.\n        Return a 2-item tuple, composed of the date and a label.\"\"\"\n        if not year:\n            year = date.today().year\n\n        if year in self._holidays:\n            return self._holidays[year]\n\n        # Here we process the holiday specific calendar\n        temp_calendar = tuple(self.get_calendar_holidays(year))\n\n        # it is sorted\n        self._holidays[year] = sorted(temp_calendar)\n        return self._holidays[year]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the label of the holiday", "response": "def get_holiday_label(self, day):\n        \"\"\"Return the label of the holiday, if the date is a holiday\"\"\"\n        day = cleaned_date(day)\n        return {day: label for day, label in self.holidays(day.year)\n                }.get(day)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a quick date index ( set )", "response": "def holidays_set(self, year=None):\n        \"Return a quick date index (set)\"\n        return set([day for day, label in self.holidays(year)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_working_day(self, day,\n                       extra_working_days=None, extra_holidays=None):\n        \"\"\"Return True if it's a working day.\n        In addition to the regular holidays, you can add exceptions.\n\n        By providing ``extra_working_days``, you'll state that these dates\n        **are** working days.\n\n        By providing ``extra_holidays``, you'll state that these dates **are**\n        holidays, even if not in the regular calendar holidays (or weekends).\n\n        Please note that the ``extra_working_days`` list has priority over the\n        ``extra_holidays`` list.\n\n        \"\"\"\n        day = cleaned_date(day)\n        if extra_working_days:\n            extra_working_days = tuple(map(cleaned_date, extra_working_days))\n        if extra_holidays:\n            extra_holidays = tuple(map(cleaned_date, extra_holidays))\n\n        # Extra lists exceptions\n        if extra_working_days and day in extra_working_days:\n            return True\n\n        # Regular rules\n        if day.weekday() in self.get_weekend_days():\n            return False\n\n        return not self.is_holiday(day, extra_holidays=extra_holidays)", "response": "Return True if the given date is a working day."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_holiday(self, day, extra_holidays=None):\n        day = cleaned_date(day)\n\n        if extra_holidays:\n            extra_holidays = tuple(map(cleaned_date, extra_holidays))\n\n        if extra_holidays and day in extra_holidays:\n            return True\n\n        return day in self.holidays_set(day.year)", "response": "Return True if it s a holiday."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds delta working days to the date.", "response": "def add_working_days(self, day, delta,\n                         extra_working_days=None, extra_holidays=None,\n                         keep_datetime=False):\n        \"\"\"Add `delta` working days to the date.\n\n        You can provide either a date or a datetime to this function that will\n        output a ``date`` result. You can alter this behaviour using the\n        ``keep_datetime`` option set to ``True``.\n\n        the ``delta`` parameter might be positive or negative. If it's\n        negative, you may want to use the ``sub_working_days()`` method with\n        a positive ``delta`` argument.\n\n        By providing ``extra_working_days``, you'll state that these dates\n        **are** working days.\n\n        By providing ``extra_holidays``, you'll state that these dates **are**\n        holidays, even if not in the regular calendar holidays (or weekends).\n\n        Please note that the ``extra_working_days`` list has priority over the\n        ``extra_holidays`` list.\n        \"\"\"\n        day = cleaned_date(day, keep_datetime)\n\n        if extra_working_days:\n            extra_working_days = tuple(map(cleaned_date, extra_working_days))\n\n        if extra_holidays:\n            extra_holidays = tuple(map(cleaned_date, extra_holidays))\n\n        days = 0\n        temp_day = day\n        if type(temp_day) is datetime and not keep_datetime:\n            temp_day = temp_day.date()\n        day_added = 1 if delta >= 0 else -1\n        delta = abs(delta)\n        while days < delta:\n            temp_day = temp_day + timedelta(days=day_added)\n            if self.is_working_day(temp_day,\n                                   extra_working_days=extra_working_days,\n                                   extra_holidays=extra_holidays):\n                days += 1\n        return temp_day"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks for the following working day.", "response": "def find_following_working_day(self, day):\n        \"\"\"Looks for the following working day, if not already a working day.\n\n        **WARNING**: this function doesn't take into account the calendar\n        holidays, only the days of the week and the weekend days parameters.\n        \"\"\"\n        day = cleaned_date(day)\n\n        while day.weekday() in self.get_weekend_days():\n            day = day + timedelta(days=1)\n        return day"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the nth weekday in a given month. e. g. Jan 1 MON 2 MON 3 4 MON 2 MON 2 MON 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 1 MON 2 MON 2 MON 2 MON 2 MON 2 MON 2 MON 2 MON 2.", "response": "def get_nth_weekday_in_month(year, month, weekday, n=1, start=None):\n        \"\"\"Get the nth weekday in a given month. e.g:\n\n        >>> # the 1st monday in Jan 2013\n        >>> Calendar.get_nth_weekday_in_month(2013, 1, MON)\n        datetime.date(2013, 1, 7)\n        >>> # The 2nd monday in Jan 2013\n        >>> Calendar.get_nth_weekday_in_month(2013, 1, MON, 2)\n        datetime.date(2013, 1, 14)\n        \"\"\"\n        # If start is `None` or Falsy, no need to check and clean\n        if start:\n            start = cleaned_date(start)\n\n        day = date(year, month, 1)\n        if start:\n            day = start\n        counter = 0\n        while True:\n            if day.month != month:\n                # Don't forget to break if \"n\" is too big\n                return None\n            if day.weekday() == weekday:\n                counter += 1\n            if counter == n:\n                break\n            day = day + timedelta(days=1)\n        return day"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the last weekday in a given month. e. g. Jan 1 MON or 28.", "response": "def get_last_weekday_in_month(year, month, weekday):\n        \"\"\"Get the last weekday in a given month. e.g:\n\n        >>> # the last monday in Jan 2013\n        >>> Calendar.get_last_weekday_in_month(2013, 1, MON)\n        datetime.date(2013, 1, 28)\n        \"\"\"\n        day = date(year, month, monthrange(year, month)[1])\n        while True:\n            if day.weekday() == weekday:\n                break\n            day = day - timedelta(days=1)\n        return day"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_first_weekday_after(day, weekday):\n        day_delta = (weekday - day.weekday()) % 7\n        day = day + timedelta(days=day_delta)\n        return day", "response": "Get the first weekday after a given day."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the number of working days between two given dates.", "response": "def get_working_days_delta(self, start, end):\n        \"\"\"\n        Return the number of working day between two given dates.\n        The order of the dates provided doesn't matter.\n\n        In the following example, there are 5 days, because of the week-end:\n\n        >>> cal = WesternCalendar()  # does not include easter monday\n        >>> day1 = date(2018, 3, 29)\n        >>> day2 = date(2018, 4, 5)\n        >>> cal.get_working_days_delta(day1, day2)\n        5\n\n        In France, April 1st 2018 is a holiday because it's Easter monday:\n\n        >>> cal = France()\n        >>> cal.get_working_days_delta(day1, day2)\n        4\n\n        This method should even work if your ``start`` and ``end`` arguments\n        are datetimes.\n        \"\"\"\n        start = cleaned_date(start)\n        end = cleaned_date(end)\n\n        if start == end:\n            return 0\n\n        if start > end:\n            start, end = end, start\n        # Starting count here\n        count = 0\n        while start < end:\n            start += timedelta(days=1)\n            if self.is_working_day(start):\n                count += 1\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_holy_thursday(self, year):\n        \"Return the date of the last thursday before easter\"\n        sunday = self.get_easter_sunday(year)\n        return sunday - timedelta(days=3)", "response": "Return the date of the last thursday before easter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the date of the last friday before easter", "response": "def get_good_friday(self, year):\n        \"Return the date of the last friday before easter\"\n        sunday = self.get_easter_sunday(year)\n        return sunday - timedelta(days=2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the clean monday date", "response": "def get_clean_monday(self, year):\n        \"Return the clean monday date\"\n        sunday = self.get_easter_sunday(year)\n        return sunday - timedelta(days=48)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_easter_saturday(self, year):\n        \"Return the Easter Saturday date\"\n        sunday = self.get_easter_sunday(year)\n        return sunday - timedelta(days=1)", "response": "Return the Easter Saturday date"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_easter_monday(self, year):\n        \"Return the date of the monday after easter\"\n        sunday = self.get_easter_sunday(year)\n        return sunday + timedelta(days=1)", "response": "Return the date of the monday after easter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shift_christmas_boxing_days(self, year):\n        christmas = date(year, 12, 25)\n        boxing_day = date(year, 12, 26)\n        boxing_day_label = \"{} Shift\".format(self.boxing_day_label)\n        results = []\n        if christmas.weekday() in self.get_weekend_days():\n            shift = self.find_following_working_day(christmas)\n            results.append((shift, \"Christmas Shift\"))\n            results.append((shift + timedelta(days=1), boxing_day_label))\n        elif boxing_day.weekday() in self.get_weekend_days():\n            shift = self.find_following_working_day(boxing_day)\n            results.append((shift, boxing_day_label))\n        return results", "response": "Return a list of shift dates for a given year."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the christian holidays list according to the mixin", "response": "def get_variable_days(self, year):  # noqa\n        \"Return the christian holidays list according to the mixin\"\n        days = super(ChristianMixin, self).get_variable_days(year)\n        if self.include_epiphany:\n            days.append((date(year, 1, 6), \"Epiphany\"))\n        if self.include_clean_monday:\n            days.append((self.get_clean_monday(year), \"Clean Monday\"))\n        if self.include_annunciation:\n            days.append((date(year, 3, 25), \"Annunciation\"))\n        if self.include_ash_wednesday:\n            days.append(\n                (self.get_ash_wednesday(year), self.ash_wednesday_label)\n            )\n        if self.include_palm_sunday:\n            days.append((self.get_palm_sunday(year), \"Palm Sunday\"))\n        if self.include_holy_thursday:\n            days.append((self.get_holy_thursday(year), \"Holy Thursday\"))\n        if self.include_good_friday:\n            days.append((self.get_good_friday(year), self.good_friday_label))\n        if self.include_easter_saturday:\n            days.append((self.get_easter_saturday(year), \"Easter Saturday\"))\n        if self.include_easter_sunday:\n            days.append((self.get_easter_sunday(year), \"Easter Sunday\"))\n        if self.include_easter_monday:\n            days.append((self.get_easter_monday(year), \"Easter Monday\"))\n        if self.include_assumption:\n            days.append((date(year, 8, 15), \"Assumption of Mary to Heaven\"))\n        if self.include_all_saints:\n            days.append((date(year, 11, 1), \"All Saints Day\"))\n        if self.include_all_souls:\n            days.append((date(year, 11, 2), \"All Souls Day\"))\n        if self.include_immaculate_conception:\n            days.append((date(year, 12, 8), self.immaculate_conception_label))\n        if self.include_christmas:\n            days.append((date(year, 12, 25), \"Christmas Day\"))\n        if self.include_christmas_eve:\n            days.append((date(year, 12, 24), \"Christmas Eve\"))\n        if self.include_boxing_day:\n            days.append((date(year, 12, 26), self.boxing_day_label))\n        if self.include_ascension:\n            days.append((\n                self.get_ascension_thursday(year), \"Ascension Thursday\"))\n        if self.include_whit_monday:\n            days.append((self.get_whit_monday(year), self.whit_monday_label))\n        if self.include_whit_sunday:\n            days.append((self.get_whit_sunday(year), self.whit_sunday_label))\n        if self.include_corpus_christi:\n            days.append((self.get_corpus_christi(year), \"Corpus Christi\"))\n        return days"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_chinese_new_year(self, year):\n        days = []\n\n        lunar_first_day = ChineseNewYearCalendar.lunar(year, 1, 1)\n        # Chinese new year's eve\n        if self.include_chinese_new_year_eve:\n            days.append((\n                lunar_first_day - timedelta(days=1),\n                self.chinese_new_year_eve_label\n            ))\n        # Chinese new year (is included by default)\n        if self.include_chinese_new_year:\n            days.append((lunar_first_day, self.chinese_new_year_label))\n\n        if self.include_chinese_second_day:\n            lunar_second_day = lunar_first_day + timedelta(days=1)\n            days.append((\n                lunar_second_day,\n                self.chinese_second_day_label\n            ))\n        if self.include_chinese_third_day:\n            lunar_third_day = lunar_first_day + timedelta(days=2)\n            days.append((\n                lunar_third_day,\n                self.chinese_third_day_label\n            ))\n\n        if self.shift_sunday_holidays:\n            if lunar_first_day.weekday() == SUN:\n                if self.shift_start_cny_sunday:\n                    days.append(\n                        (lunar_first_day - timedelta(days=1),\n                         \"Chinese Lunar New Year shift\"),\n                    )\n                else:\n                    if self.include_chinese_third_day:\n                        shift_day = lunar_third_day\n                    else:\n                        shift_day = lunar_second_day\n                    days.append(\n                        (shift_day + timedelta(days=1),\n                         \"Chinese Lunar New Year shift\"),\n                    )\n            if (lunar_second_day.weekday() == SUN\n                    and self.include_chinese_third_day):\n                days.append(\n                    (lunar_third_day + timedelta(days=1),\n                     \"Chinese Lunar New Year shift\"),\n                )\n        return days", "response": "Compute Chinese New Year days."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding a list of shifted holidays", "response": "def get_shifted_holidays(self, dates):\n        \"\"\"\n        Taking a list of existing holidays, yield a list of 'shifted' days if\n        the holiday falls on SUN.\n        \"\"\"\n        for holiday, label in dates:\n            if holiday.weekday() == SUN:\n                yield (\n                    holiday + timedelta(days=1),\n                    label + ' shift'\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_calendar_holidays(self, year):\n        # Unshifted days are here:\n        days = super(ChineseNewYearCalendar, self).get_calendar_holidays(year)\n        if self.shift_sunday_holidays:\n            days_to_inspect = copy(days)\n            for day_shifted in self.get_shifted_holidays(days_to_inspect):\n                days.append(day_shifted)\n        return days", "response": "Return a list of all holidays for a given year."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates equinoxes for a given year", "response": "def calculate_equinoxes(self, year, timezone='UTC'):\n        \"\"\" calculate equinox with time zone \"\"\"\n\n        tz = pytz.timezone(timezone)\n\n        d1 = ephem.next_equinox(str(year))\n        d = ephem.Date(str(d1))\n        equinox1 = d.datetime() + tz.utcoffset(d.datetime())\n\n        d2 = ephem.next_equinox(d1)\n        d = ephem.Date(str(d2))\n        equinox2 = d.datetime() + tz.utcoffset(d.datetime())\n\n        return (equinox1.date(), equinox2.date())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solar_term(self, year, degrees, timezone='UTC'):\n        twopi = 2 * pi\n        tz = pytz.timezone(timezone)\n\n        # Find out the sun's current longitude.\n\n        sun = ephem.Sun(ephem.Date(str(year)))\n        current_longitude = sun.hlong - pi\n\n        # Find approximately the right time of year.\n\n        target_longitude = degrees * ephem.degree\n        difference = (target_longitude - current_longitude) % twopi\n        t0 = ephem.Date(str(year)) + 365.25 * difference / twopi\n\n        # Zero in on the exact moment.\n\n        def f(t):\n            sun.compute(t)\n            longitude = sun.hlong - pi\n            return ephem.degrees(target_longitude - longitude).znorm\n\n        d = ephem.Date(ephem.newton(f, t0, t0 + ephem.minute))\n        solar_term = d.datetime() + tz.utcoffset(d.datetime())\n\n        return solar_term.date()", "response": "Returns the date of the solar term for the given longitude\n        and the given year."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of Islamic holidays.", "response": "def get_islamic_holidays(self):\n        \"\"\"Return a list of Islamic (month, day, label) for islamic holidays.\n        Please take note that these dates must be expressed using the Islamic\n        Calendar\"\"\"\n        days = list(super(IslamicMixin, self).get_islamic_holidays())\n\n        if self.include_islamic_new_year:\n            days.append((1, 1, \"Islamic New Year\"))\n        if self.include_prophet_birthday:\n            days.append((3, 12, \"Prophet's Birthday\"))\n        if self.include_day_after_prophet_birthday:\n            days.append((3, 13, \"Day after Prophet's Birthday\"))\n        if self.include_start_ramadan:\n            days.append((9, 1, \"Start of ramadan\"))\n        if self.include_nuzul_al_quran:\n            days.append((9, 17, \"Nuzul Al-Qur'an\"))\n        if self.include_eid_al_fitr:\n            for x in range(self.length_eid_al_fitr):\n                days.append((10, x + 1, self.eid_al_fitr_label))\n        if self.include_eid_al_adha:\n            for x in range(self.length_eid_al_adha):\n                days.append((12, x + 10, \"Eid al-Adha\"))\n        if self.include_day_of_sacrifice:\n            days.append((12, 10, self.day_of_sacrifice_label))\n        if self.include_laylat_al_qadr:\n            warnings.warn(\"The Islamic holiday named Laylat al-Qadr is decided\"\n                          \" by the religious authorities. It is not possible\"\n                          \" to compute it. You'll have to add it manually.\")\n        return tuple(days)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_spring_holiday(self, year):\n        easter = self.get_easter_monday(year)\n        spring_holiday = self.get_nth_weekday_in_month(year, 4, MON, 3)\n        if easter == spring_holiday:\n            spring_holiday = self.get_nth_weekday_in_month(\n                year, 4, MON, 2)\n\n        return (spring_holiday, self.spring_holiday_label)", "response": "Return the Spring Holiday for the given year."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the victoria day for Edinburgh.", "response": "def get_victoria_day(self, year):\n        \"\"\"\n        Return Victoria Day for Edinburgh.\n\n        Set to the Monday strictly before May 24th. It means that if May 24th\n        is a Monday, it's shifted to the week before.\n        \"\"\"\n        may_24th = date(year, 5, 24)\n        # Since \"MON(day) == 0\", it's either the difference between MON and the\n        # current weekday (starting at 0), or 7 days before the May 24th\n        shift = may_24th.weekday() or 7\n        victoria_day = may_24th - timedelta(days=shift)\n        return (victoria_day, \"Victoria Day\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the contents of the given file relative to this module.", "response": "def read_relative_file(filename):\n    \"\"\"\n    Return the contents of the given file.\n\n    Its path is supposed relative to this module.\n    \"\"\"\n    path = join(dirname(abspath(__file__)), filename)\n    with io.open(path, encoding='utf-8') as f:\n        return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a node to the KBucket.", "response": "def add_node(self, node):\n        \"\"\"\n        Add a C{Node} to the C{KBucket}.  Return True if successful,\n        False if the bucket is full.\n\n        If the bucket is full, keep track of node in a replacement list,\n        per section 4.1 of the paper.\n        \"\"\"\n        if node.id in self.nodes:\n            del self.nodes[node.id]\n            self.nodes[node.id] = node\n        elif len(self) < self.ksize:\n            self.nodes[node.id] = node\n        else:\n            if node.id in self.replacement_nodes:\n                del self.replacement_nodes[node.id]\n            self.replacement_nodes[node.id] = node\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lonely_buckets(self):\n        hrago = time.monotonic() - 3600\n        return [b for b in self.buckets if b.last_updated < hrago]", "response": "Get all of the buckets that have not been updated in over\n        an hour."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the index of the bucket that the given node would fall into.", "response": "def get_bucket_for(self, node):\n        \"\"\"\n        Get the index of the bucket that the given node would fall into.\n        \"\"\"\n        for index, bucket in enumerate(self.buckets):\n            if node.long_id < bucket.range[1]:\n                return index\n        # we should never be here, but make linter happy\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _find(self, rpcmethod):\n        log.info(\"crawling network with nearest: %s\", str(tuple(self.nearest)))\n        count = self.alpha\n        if self.nearest.get_ids() == self.last_ids_crawled:\n            count = len(self.nearest)\n        self.last_ids_crawled = self.nearest.get_ids()\n\n        dicts = {}\n        for peer in self.nearest.get_uncontacted()[:count]:\n            dicts[peer.id] = rpcmethod(peer, self.node)\n            self.nearest.mark_contacted(peer)\n        found = await gather_dict(dicts)\n        return await self._nodes_found(found)", "response": "Find the nodes in the network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling the result of a find call.", "response": "async def _nodes_found(self, responses):\n        \"\"\"\n        Handle the result of an iteration in _find.\n        \"\"\"\n        toremove = []\n        found_values = []\n        for peerid, response in responses.items():\n            response = RPCFindResponse(response)\n            if not response.happened():\n                toremove.append(peerid)\n            elif response.has_value():\n                found_values.append(response.get_value())\n            else:\n                peer = self.nearest.get_node(peerid)\n                self.nearest_without_value.push(peer)\n                self.nearest.push(response.get_node_list())\n        self.nearest.remove(toremove)\n\n        if found_values:\n            return await self._handle_found_values(found_values)\n        if self.nearest.have_contacted_all():\n            # not found!\n            return None\n        return await self.find()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the result of a find call.", "response": "async def _nodes_found(self, responses):\n        \"\"\"\n        Handle the result of an iteration in _find.\n        \"\"\"\n        toremove = []\n        for peerid, response in responses.items():\n            response = RPCFindResponse(response)\n            if not response.happened():\n                toremove.append(peerid)\n            else:\n                self.nearest.push(response.get_node_list())\n        self.nearest.remove(toremove)\n\n        if self.nearest.have_contacted_all():\n            return list(self.nearest)\n        return await self.find()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_dht_value_type(value):\n    typeset = [\n        int,\n        float,\n        bool,\n        str,\n        bytes\n    ]\n    return type(value) in typeset", "response": "Checks to see if the type of the value is a valid type for the dht."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def listen(self, port, interface='0.0.0.0'):\n        loop = asyncio.get_event_loop()\n        listen = loop.create_datagram_endpoint(self._create_protocol,\n                                               local_addr=(interface, port))\n        log.info(\"Node %i listening on %s:%i\",\n                 self.node.long_id, interface, port)\n        self.transport, self.protocol = await listen\n        # finally, schedule refreshing table\n        self.refresh_table()", "response": "Start listening on the given port."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrefreshes the cache table.", "response": "async def _refresh_table(self):\n        \"\"\"\n        Refresh buckets that haven't had any lookups in the last hour\n        (per section 2.3 of the paper).\n        \"\"\"\n        results = []\n        for node_id in self.protocol.get_refresh_ids():\n            node = Node(node_id)\n            nearest = self.protocol.router.find_neighbors(node, self.alpha)\n            spider = NodeSpiderCrawl(self.protocol, node, nearest,\n                                     self.ksize, self.alpha)\n            results.append(spider.find())\n\n        # do our crawling\n        await asyncio.gather(*results)\n\n        # now republish keys older than one hour\n        for dkey, value in self.storage.iter_older_than(3600):\n            await self.set_digest(dkey, value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all possible neighbors for this server.", "response": "def bootstrappable_neighbors(self):\n        \"\"\"\n        Get a :class:`list` of (ip, port) :class:`tuple` pairs suitable for\n        use as an argument to the bootstrap method.\n\n        The server should have been bootstrapped\n        already - this is just a utility for getting some neighbors and then\n        storing them if this server is going down for a while.  When it comes\n        back up, the list of nodes can be used to bootstrap.\n        \"\"\"\n        neighbors = self.protocol.router.find_neighbors(self.node)\n        return [tuple(n)[-2:] for n in neighbors]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbootstrap the server by connecting to other known nodes.", "response": "async def bootstrap(self, addrs):\n        \"\"\"\n        Bootstrap the server by connecting to other known nodes in the network.\n\n        Args:\n            addrs: A `list` of (ip, port) `tuple` pairs.  Note that only IP\n                   addresses are acceptable - hostnames will cause an error.\n        \"\"\"\n        log.debug(\"Attempting to bootstrap node with %i initial contacts\",\n                  len(addrs))\n        cos = list(map(self.bootstrap_node, addrs))\n        gathered = await asyncio.gather(*cos)\n        nodes = [node for node in gathered if node is not None]\n        spider = NodeSpiderCrawl(self.protocol, self.node, nodes,\n                                 self.ksize, self.alpha)\n        return await spider.find()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a key from the network.", "response": "async def get(self, key):\n        \"\"\"\n        Get a key if the network has it.\n\n        Returns:\n            :class:`None` if not found, the value otherwise.\n        \"\"\"\n        log.info(\"Looking up key %s\", key)\n        dkey = digest(key)\n        # if this node has it, return it\n        if self.storage.get(dkey) is not None:\n            return self.storage.get(dkey)\n        node = Node(dkey)\n        nearest = self.protocol.router.find_neighbors(node)\n        if not nearest:\n            log.warning(\"There are no known neighbors to get key %s\", key)\n            return None\n        spider = ValueSpiderCrawl(self.protocol, node, nearest,\n                                  self.ksize, self.alpha)\n        return await spider.find()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the given string key to the given value in the network.", "response": "async def set(self, key, value):\n        \"\"\"\n        Set the given string key to the given value in the network.\n        \"\"\"\n        if not check_dht_value_type(value):\n            raise TypeError(\n                \"Value must be of type int, float, bool, str, or bytes\"\n            )\n        log.info(\"setting '%s' = '%s' on network\", key, value)\n        dkey = digest(key)\n        return await self.set_digest(dkey, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def set_digest(self, dkey, value):\n        node = Node(dkey)\n\n        nearest = self.protocol.router.find_neighbors(node)\n        if not nearest:\n            log.warning(\"There are no known neighbors to set key %s\",\n                        dkey.hex())\n            return False\n\n        spider = NodeSpiderCrawl(self.protocol, node, nearest,\n                                 self.ksize, self.alpha)\n        nodes = await spider.find()\n        log.info(\"setting '%s' on %s\", dkey.hex(), list(map(str, nodes)))\n\n        # if this node is close too, then store here as well\n        biggest = max([n.distance_to(node) for n in nodes])\n        if self.node.distance_to(node) < biggest:\n            self.storage[dkey] = value\n        results = [self.protocol.call_store(n, dkey, value) for n in nodes]\n        # return true only if at least one store call succeeded\n        return any(await asyncio.gather(*results))", "response": "Set the given SHA1 digest key to the given value in the network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the state of this node to a pickle file with the given fname.", "response": "def save_state(self, fname):\n        \"\"\"\n        Save the state of this node (the alpha/ksize/id/immediate neighbors)\n        to a cache file with the given fname.\n        \"\"\"\n        log.info(\"Saving state to %s\", fname)\n        data = {\n            'ksize': self.ksize,\n            'alpha': self.alpha,\n            'id': self.node.id,\n            'neighbors': self.bootstrappable_neighbors()\n        }\n        if not data['neighbors']:\n            log.warning(\"No known neighbors, so not writing to cache.\")\n            return\n        with open(fname, 'wb') as file:\n            pickle.dump(data, file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the state of this node from a cache file with the given fname.", "response": "def load_state(cls, fname):\n        \"\"\"\n        Load the state of this node (the alpha/ksize/id/immediate neighbors)\n        from a cache file with the given fname.\n        \"\"\"\n        log.info(\"Loading state from %s\", fname)\n        with open(fname, 'rb') as file:\n            data = pickle.load(file)\n        svr = Server(data['ksize'], data['alpha'], data['id'])\n        if data['neighbors']:\n            svr.bootstrap(data['neighbors'])\n        return svr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_state_regularly(self, fname, frequency=600):\n        self.save_state(fname)\n        loop = asyncio.get_event_loop()\n        self.save_state_loop = loop.call_later(frequency,\n                                               self.save_state_regularly,\n                                               fname,\n                                               frequency)", "response": "Save the state of the given regularity to the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a list of peer ids from this heap.", "response": "def remove(self, peers):\n        \"\"\"\n        Remove a list of peer ids from this heap.  Note that while this\n        heap retains a constant visible size (based on the iterator), it's\n        actual size may be quite a bit larger than what's exposed.  Therefore,\n        removal of nodes may not change the visible size as previously added\n        nodes suddenly become visible.\n        \"\"\"\n        peers = set(peers)\n        if not peers:\n            return\n        nheap = []\n        for distance, node in self.heap:\n            if node.id not in peers:\n                heapq.heappush(nheap, (distance, node))\n        self.heap = nheap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push(self, nodes):\n        if not isinstance(nodes, list):\n            nodes = [nodes]\n\n        for node in nodes:\n            if node not in self:\n                distance = self.node.distance_to(node)\n                heapq.heappush(self.heap, (distance, node))", "response": "Push nodes onto heap."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the shared prefix between the strings.", "response": "def shared_prefix(args):\n    \"\"\"\n    Find the shared prefix between the strings.\n\n    For instance:\n\n        sharedPrefix(['blahblah', 'blahwhat'])\n\n    returns 'blah'.\n    \"\"\"\n    i = 0\n    while i < min(map(len, args)):\n        if len(set(map(operator.itemgetter(i), args))) != 1:\n            break\n        i += 1\n    return args[0][:i]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget ids to search for to keep old buckets up to date.", "response": "def get_refresh_ids(self):\n        \"\"\"\n        Get ids to search for to keep old buckets up to date.\n        \"\"\"\n        ids = []\n        for bucket in self.router.lonely_buckets():\n            rid = random.randint(*bucket.range).to_bytes(20, byteorder='big')\n            ids.append(rid)\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef welcome_if_new(self, node):\n        if not self.router.is_new_node(node):\n            return\n\n        log.info(\"never seen %s before, adding to router\", node)\n        for key, value in self.storage:\n            keynode = Node(digest(key))\n            neighbors = self.router.find_neighbors(keynode)\n            if neighbors:\n                last = neighbors[-1].distance_to(keynode)\n                new_node_close = node.distance_to(keynode) < last\n                first = neighbors[0].distance_to(keynode)\n                this_closest = self.source_node.distance_to(keynode) < first\n            if not neighbors or (new_node_close and this_closest):\n                asyncio.ensure_future(self.call_store(node, key, value))\n        self.router.add_contact(node)", "response": "This function is called when a new node is added to the routing table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_call_response(self, result, node):\n        if not result[0]:\n            log.warning(\"no response from %s, removing from router\", node)\n            self.router.remove_contact(node)\n            return result\n\n        log.info(\"got successful response from %s\", node)\n        self.welcome_if_new(node)\n        return result", "response": "Handle a response from a node to a routing table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deinit(self):\n        for i in range(len(self.buf)):\n            self.buf[i] = 0\n        neopixel_write(self.pin, self.buf)\n        self.pin.deinit()", "response": "Blank out the NeoPixels and release the pin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncoloring all pixels the given color.", "response": "def fill(self, color):\n        \"\"\"Colors all pixels the given ***color***.\"\"\"\n        auto_write = self.auto_write\n        self.auto_write = False\n        for i, _ in enumerate(self):\n            self[i] = color\n        if auto_write:\n            self.show()\n        self.auto_write = auto_write"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the new colors on the pixels themselves if they haven t already been autowritten.", "response": "def show(self):\n        \"\"\"Shows the new colors on the pixels themselves if they haven't already\n        been autowritten.\n\n        The colors may or may not be showing after this function returns because\n        it may be done asynchronously.\"\"\"\n        if self.brightness > 0.99:\n            neopixel_write(self.pin, self.buf)\n        else:\n            neopixel_write(self.pin, bytearray([int(i * self.brightness) for i in self.buf]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_k8s_attribute(obj, attribute, value):\n    current_value = None\n    attribute_name = None\n    # All k8s python client objects have an 'attribute_map' property\n    # which has as keys python style attribute names (api_client)\n    # and as values the kubernetes JSON API style attribute names\n    # (apiClient). We want to allow users to use the JSON API style attribute\n    # names only.\n    for python_attribute, json_attribute in obj.attribute_map.items():\n        if json_attribute == attribute:\n            attribute_name = python_attribute\n            break\n    else:\n        raise ValueError('Attribute must be one of {}'.format(obj.attribute_map.values()))\n\n    if hasattr(obj, attribute_name):\n        current_value = getattr(obj, attribute_name)\n\n    if current_value is not None:\n        # This will ensure that current_value is something JSONable,\n        # so a dict, list, or scalar\n        current_value = SERIALIZATION_API_CLIENT.sanitize_for_serialization(\n            current_value\n        )\n\n    if isinstance(current_value, dict):\n        # Deep merge our dictionaries!\n        setattr(obj, attribute_name, merge_dictionaries(current_value, value))\n    elif isinstance(current_value, list):\n        # Just append lists\n        setattr(obj, attribute_name, current_value + value)\n    else:\n        # Replace everything else\n        setattr(obj, attribute_name, value)", "response": "Set a specific value on a kubernetes object s attribute\n obj\nMimeType objMimeType obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging two dictionaries recursively.", "response": "def merge_dictionaries(a, b, path=None, update=True):\n    \"\"\"\n    Merge two dictionaries recursively.\n\n    From https://stackoverflow.com/a/25270947\n    \"\"\"\n    if path is None:\n        path = []\n    for key in b:\n        if key in a:\n            if isinstance(a[key], dict) and isinstance(b[key], dict):\n                merge_dictionaries(a[key], b[key], path + [str(key)])\n            elif a[key] == b[key]:\n                pass # same leaf value\n            elif isinstance(a[key], list) and isinstance(b[key], list):\n                for idx, val in enumerate(b[key]):\n                    a[key][idx] = merge_dictionaries(a[key][idx],\n                                                     b[key][idx],\n                                                     path + [str(key), str(idx)],\n                                                     update=update)\n            elif update:\n                a[key] = b[key]\n            else:\n                raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))\n        else:\n            a[key] = b[key]\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates generic pod template from input parameters.", "response": "def make_pod_spec(\n        image,\n        labels={},\n        threads_per_worker=1,\n        env={},\n        extra_container_config={},\n        extra_pod_config={},\n        memory_limit=None,\n        memory_request=None,\n        cpu_limit=None,\n        cpu_request=None,\n):\n    \"\"\"\n    Create generic pod template from input parameters\n\n    Examples\n    --------\n    >>> make_pod_spec(image='daskdev/dask:latest', memory_limit='4G', memory_request='4G')\n    \"\"\"\n    args = [\n        'dask-worker',\n        '$(DASK_SCHEDULER_ADDRESS)',\n        '--nthreads', str(threads_per_worker),\n        '--death-timeout', '60',\n    ]\n    if memory_limit:\n        args.extend(['--memory-limit', str(memory_limit)])\n    pod = client.V1Pod(\n        metadata=client.V1ObjectMeta(\n            labels=labels\n        ),\n        spec=client.V1PodSpec(\n            restart_policy='Never',\n            containers=[\n                client.V1Container(\n                    name='dask-worker',\n                    image=image,\n                    args=args,\n                    env=[client.V1EnvVar(name=k, value=v)\n                            for k, v in env.items()],\n                )\n            ],\n            tolerations=[\n                client.V1Toleration(\n                    key='k8s.dask.org/dedicated',\n                    operator='Equal',\n                    value='worker',\n                    effect='NoSchedule',\n                ),\n                # GKE currently does not permit creating taints on a node pool\n                # with a `/` in the key field\n                client.V1Toleration(\n                    key='k8s.dask.org_dedicated',\n                    operator='Equal',\n                    value='worker',\n                    effect='NoSchedule',\n                ),\n            ]\n        )\n    )\n\n    resources = client.V1ResourceRequirements(limits={}, requests={})\n\n    if cpu_request:\n        resources.requests['cpu'] = cpu_request\n    if memory_request:\n        resources.requests['memory'] = memory_request\n\n    if cpu_limit:\n        resources.limits['cpu'] = cpu_limit\n    if memory_limit:\n        resources.limits['memory'] = memory_limit\n\n    pod.spec.containers[0].resources = resources\n\n    for key, value in extra_container_config.items():\n        _set_k8s_attribute(\n            pod.spec.containers[0],\n            key,\n            value\n        )\n\n    for key, value in extra_pod_config.items():\n        _set_k8s_attribute(\n            pod.spec,\n            key,\n            value\n        )\n    return pod"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_pod_template(pod_template):\n    if isinstance(pod_template, str):\n        msg = ('Expected a kubernetes.client.V1Pod object, got %s'\n               'If trying to pass a yaml filename then use '\n               'KubeCluster.from_yaml')\n        raise TypeError(msg % pod_template)\n\n    if isinstance(pod_template, dict):\n        msg = ('Expected a kubernetes.client.V1Pod object, got %s'\n               'If trying to pass a dictionary specification then use '\n               'KubeCluster.from_dict')\n        raise TypeError(msg % str(pod_template))\n\n    pod_template = copy.deepcopy(pod_template)\n\n    # Make sure metadata / labels / env objects exist, so they can be modified\n    # later without a lot of `is None` checks\n    if pod_template.metadata is None:\n        pod_template.metadata = client.V1ObjectMeta()\n    if pod_template.metadata.labels is None:\n        pod_template.metadata.labels = {}\n\n    if pod_template.spec.containers[0].env is None:\n        pod_template.spec.containers[0].env = []\n\n    return pod_template", "response": "Normalize a kubernetes pod template and check for type errors"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_first(auth=None):\n        if auth is None:\n            auth = ClusterAuth.DEFAULT\n        elif isinstance(auth, ClusterAuth):\n            auth = [auth]\n        elif isinstance(auth, list):\n            if not auth:\n                raise kubernetes.config.ConfigException('No authorization methods were provided')\n        else:\n            msg = (\"Invalid authorization method provided. See ClusterAuth \"\n                   \"docstring for ways to specify authentication methods\")\n            raise ValueError(msg)\n\n        auth_exc = None\n        for auth_instance in auth:\n            try:\n                auth_instance.load()\n            except kubernetes.config.ConfigException as exc:\n                logger.debug('Failed to load configuration with %s method: %s', auth_instance.__class__, exc)\n                auth_exc = exc\n            else:\n                break\n        else:\n            raise auth_exc", "response": "Load the first valid configuration in the list auth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all pods with these labels in this namespace", "response": "def _cleanup_pods(namespace, labels):\n    \"\"\" Remove all pods with these labels in this namespace \"\"\"\n    api = kubernetes.client.CoreV1Api()\n    pods = api.list_namespaced_pod(namespace, label_selector=format_labels(labels))\n    for pod in pods.items:\n        try:\n            api.delete_namespaced_pod(pod.metadata.name, namespace)\n            logger.info('Deleted pod: %s', pod.metadata.name)\n        except kubernetes.client.rest.ApiException as e:\n            # ignore error if pod is already removed\n            if e.status != 404:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_labels(labels):\n    if labels:\n        return ','.join(['{}={}'.format(k, v) for k, v in labels.items()])\n    else:\n        return ''", "response": "Convert a dictionary of labels into a comma separated string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _namespace_default():\n    ns_path = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n    if os.path.exists(ns_path):\n        with open(ns_path) as f:\n            return f.read().strip()\n    return 'default'", "response": "Get current namespace if running in a k8s cluster"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting n workers to close from scheduler", "response": "def select_workers_to_close(scheduler, n_to_close):\n    \"\"\" Select n workers to close from scheduler \"\"\"\n    workers = list(scheduler.workers.values())\n    assert n_to_close <= len(workers)\n    key = lambda ws: ws.metrics['memory']\n    to_close = set(sorted(scheduler.idle, key=key)[:n_to_close])\n\n    if len(to_close) < n_to_close:\n        rest = sorted(workers, key=key, reverse=True)\n        while len(to_close) < n_to_close:\n            to_close.add(rest.pop())\n\n    return [ws.address for ws in to_close]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_yaml(cls, yaml_path, **kwargs):\n        if not yaml:\n            raise ImportError(\"PyYaml is required to use yaml functionality, please install it!\")\n        with open(yaml_path) as f:\n            d = yaml.safe_load(f)\n            d = dask.config.expand_environment_variables(d)\n            return cls.from_dict(d, **kwargs)", "response": "Create a KubeCluster from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pods(self):\n        return self.core_api.list_namespaced_pod(\n            self.namespace,\n            label_selector=format_labels(self.pod_template.metadata.labels)\n        ).items", "response": "A list of kubernetes pods corresponding to current workers\n            See Also\n        KubeCluster. logs\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets logs from a worker pod", "response": "def logs(self, pod=None):\n        \"\"\" Logs from a worker pod\n\n        You can get this pod object from the ``pods`` method.\n\n        If no pod is specified all pod logs will be returned. On large clusters\n        this could end up being rather large.\n\n        Parameters\n        ----------\n        pod: kubernetes.client.V1Pod\n            The pod from which we want to collect logs.\n\n        See Also\n        --------\n        KubeCluster.pods\n        Client.get_worker_logs\n        \"\"\"\n        if pod is None:\n            return {pod.status.pod_ip: self.logs(pod) for pod in self.pods()}\n\n        return self.core_api.read_namespaced_pod_log(pod.metadata.name,\n                                                     pod.metadata.namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscale the cluster to n workers.", "response": "def scale(self, n):\n        \"\"\" Scale cluster to n workers\n\n        Parameters\n        ----------\n        n: int\n            Target number of workers\n\n        Example\n        -------\n        >>> cluster.scale(10)  # scale cluster to ten workers\n\n        See Also\n        --------\n        KubeCluster.scale_up\n        KubeCluster.scale_down\n        \"\"\"\n        pods = self._cleanup_terminated_pods(self.pods())\n        if n >= len(pods):\n            return self.scale_up(n, pods=pods)\n        else:\n            n_to_delete = len(pods) - n\n            # Before trying to close running workers, check if we can cancel\n            # pending pods (in case the kubernetes cluster was too full to\n            # provision those pods in the first place).\n            running_workers = list(self.scheduler.workers.keys())\n            running_ips = set(urlparse(worker).hostname\n                              for worker in running_workers)\n            pending_pods = [p for p in pods\n                            if p.status.pod_ip not in running_ips]\n            if pending_pods:\n                pending_to_delete = pending_pods[:n_to_delete]\n                logger.debug(\"Deleting pending pods: %s\", pending_to_delete)\n                self._delete_pods(pending_to_delete)\n                n_to_delete = n_to_delete - len(pending_to_delete)\n                if n_to_delete <= 0:\n                    return\n\n            to_close = select_workers_to_close(self.scheduler, n_to_delete)\n            logger.debug(\"Closing workers: %s\", to_close)\n            if len(to_close) < len(self.scheduler.workers):\n                # Close workers cleanly to migrate any temporary results to\n                # remaining workers.\n                @gen.coroutine\n                def f(to_close):\n                    yield self.scheduler.retire_workers(\n                        workers=to_close, remove=True, close_workers=True)\n                    yield offload(self.scale_down, to_close)\n\n                self.scheduler.loop.add_callback(f, to_close)\n                return\n\n            # Terminate all pods without waiting for clean worker shutdown\n            self.scale_down(to_close)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scale_up(self, n, pods=None, **kwargs):\n        maximum = dask.config.get('kubernetes.count.max')\n        if maximum is not None and maximum < n:\n            logger.info(\"Tried to scale beyond maximum number of workers %d > %d\",\n                        n, maximum)\n            n = maximum\n        pods = pods or self._cleanup_terminated_pods(self.pods())\n        to_create = n - len(pods)\n        new_pods = []\n        for i in range(3):\n            try:\n                for _ in range(to_create):\n                    new_pods.append(self.core_api.create_namespaced_pod(\n                        self.namespace, self.pod_template))\n                    to_create -= 1\n                break\n            except kubernetes.client.rest.ApiException as e:\n                if e.status == 500 and 'ServerTimeout' in e.body:\n                    logger.info(\"Server timeout, retry #%d\", i + 1)\n                    time.sleep(1)\n                    last_exception = e\n                    continue\n                else:\n                    raise\n        else:\n            raise last_exception\n\n        return new_pods", "response": "Make sure we have n workers available for this cluster and return a list of pods that can be used to create the new cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scale_down(self, workers, pods=None):\n        # Get the existing worker pods\n        pods = pods or self._cleanup_terminated_pods(self.pods())\n\n        # Work out the list of pods that we are going to delete\n        # Each worker to delete is given in the form \"tcp://<worker ip>:<port>\"\n        # Convert this to a set of IPs\n        ips = set(urlparse(worker).hostname for worker in workers)\n        to_delete = [p for p in pods if p.status.pod_ip in ips]\n        if not to_delete:\n            return\n        self._delete_pods(to_delete)", "response": "Remove the pods for the requested workers and return the new set of pods that are deleted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef job_to_dict(job):\n\n    data = OrderedDict()\n    data['id'] = job.id\n    data['name'] = job.name\n    data['func'] = job.func_ref\n    data['args'] = job.args\n    data['kwargs'] = job.kwargs\n\n    data.update(trigger_to_dict(job.trigger))\n\n    if not job.pending:\n        data['misfire_grace_time'] = job.misfire_grace_time\n        data['max_instances'] = job.max_instances\n        data['next_run_time'] = None if job.next_run_time is None else job.next_run_time\n\n    return data", "response": "Converts a job to an OrderedDict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop trigger and trigger args from a given dict.", "response": "def pop_trigger(data):\n    \"\"\"Pops trigger and trigger args from a given dict.\"\"\"\n\n    trigger_name = data.pop('trigger')\n    trigger_args = {}\n\n    if trigger_name == 'date':\n        trigger_arg_names = ('run_date', 'timezone')\n    elif trigger_name == 'interval':\n        trigger_arg_names = ('weeks', 'days', 'hours', 'minutes', 'seconds', 'start_date', 'end_date', 'timezone')\n    elif trigger_name == 'cron':\n        trigger_arg_names = ('year', 'month', 'day', 'week', 'day_of_week', 'hour', 'minute', 'second', 'start_date', 'end_date', 'timezone')\n    else:\n        raise Exception('Trigger %s is not supported.' % trigger_name)\n\n    for arg_name in trigger_arg_names:\n        if arg_name in data:\n            trigger_args[arg_name] = data.pop(arg_name)\n\n    return trigger_name, trigger_args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a trigger to an OrderedDict.", "response": "def trigger_to_dict(trigger):\n    \"\"\"Converts a trigger to an OrderedDict.\"\"\"\n\n    data = OrderedDict()\n\n    if isinstance(trigger, DateTrigger):\n        data['trigger'] = 'date'\n        data['run_date'] = trigger.run_date\n    elif isinstance(trigger, IntervalTrigger):\n        data['trigger'] = 'interval'\n        data['start_date'] = trigger.start_date\n\n        if trigger.end_date:\n            data['end_date'] = trigger.end_date\n\n        w, d, hh, mm, ss = extract_timedelta(trigger.interval)\n\n        if w > 0:\n            data['weeks'] = w\n        if d > 0:\n            data['days'] = d\n        if hh > 0:\n            data['hours'] = hh\n        if mm > 0:\n            data['minutes'] = mm\n        if ss > 0:\n            data['seconds'] = ss\n    elif isinstance(trigger, CronTrigger):\n        data['trigger'] = 'cron'\n\n        if trigger.start_date:\n            data['start_date'] = trigger.start_date\n\n        if trigger.end_date:\n            data['end_date'] = trigger.end_date\n\n        for field in trigger.fields:\n            if not field.is_default:\n                data[field.name] = str(field)\n    else:\n        data['trigger'] = str(trigger)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfixing the date in string by datetime object.", "response": "def fix_job_def(job_def):\n    \"\"\"\n    Replaces the datetime in string by datetime object.\n    \"\"\"\n    if six.PY2 and isinstance(job_def.get('func'), six.text_type):\n        # when a job comes from the endpoint, strings are unicode\n        # because that's how json package deserialize the bytes.\n        # we had a case where APScheduler failed to import the func based\n        # on its name because Py2 expected a str and not unicode on __import__().\n        # it happened only for a user, I wasn't able to determine why that occurred for him,\n        # a workaround is to convert the func to str.\n\n        # full story: https://github.com/viniciuschiele/flask-apscheduler/issues/75\n\n        job_def['func'] = str(job_def.get('func'))\n\n    if isinstance(job_def.get('start_date'), six.string_types):\n        job_def['start_date'] = dateutil.parser.parse(job_def.get('start_date'))\n\n    if isinstance(job_def.get('end_date'), six.string_types):\n        job_def['end_date'] = dateutil.parser.parse(job_def.get('end_date'))\n\n    if isinstance(job_def.get('run_date'), six.string_types):\n        job_def['run_date'] = dateutil.parser.parse(job_def.get('run_date'))\n\n    # it keeps compatibility backward\n    if isinstance(job_def.get('trigger'), dict):\n        trigger = job_def.pop('trigger')\n        job_def['trigger'] = trigger.pop('type', 'date')\n        job_def.update(trigger)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the APScheduler with a Flask application instance.", "response": "def init_app(self, app):\n        \"\"\"Initialize the APScheduler with a Flask application instance.\"\"\"\n\n        self.app = app\n        self.app.apscheduler = self\n\n        self._load_config()\n        self._load_jobs()\n\n        if self.api_enabled:\n            self._load_api()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, paused=False):\n        if self.host_name not in self.allowed_hosts and '*' not in self.allowed_hosts:\n            LOGGER.debug('Host name %s is not allowed to start the APScheduler. Servers allowed: %s' %\n                         (self.host_name, ','.join(self.allowed_hosts)))\n            return\n\n        self._scheduler.start(paused=paused)", "response": "Start the scheduler.\n        :param bool paused: if True, don't start job processing until resume is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_listener(self, callback, mask=EVENT_ALL):\n        self._scheduler.add_listener(callback, mask)", "response": "Add a listener for scheduler events."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_job(self, id, func, **kwargs):\n\n        job_def = dict(kwargs)\n        job_def['id'] = id\n        job_def['func'] = func\n        job_def['name'] = job_def.get('name') or id\n\n        fix_job_def(job_def)\n\n        return self._scheduler.add_job(**job_def)", "response": "Add a job to the job list and wakes up the scheduler if it s already running."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeprecates use remove_job instead.", "response": "def delete_job(self, id, jobstore=None):\n        \"\"\"\n        DEPRECATED, use remove_job instead.\n\n        Remove a job, preventing it from being run any more.\n\n        :param str id: the identifier of the job\n        :param str jobstore: alias of the job store that contains the job\n        \"\"\"\n        warnings.warn('delete_job has been deprecated, use remove_job instead.', DeprecationWarning)\n\n        self.remove_job(id, jobstore)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodifies the properties of a single job.", "response": "def modify_job(self, id, jobstore=None, **changes):\n        \"\"\"\n        Modify the properties of a single job. Modifications are passed to this method as extra keyword arguments.\n\n        :param str id: the identifier of the job\n        :param str jobstore: alias of the job store that contains the job\n        \"\"\"\n\n        fix_job_def(changes)\n\n        if 'trigger' in changes:\n            trigger, trigger_args = pop_trigger(changes)\n            self._scheduler.reschedule_job(id, jobstore, trigger, **trigger_args)\n\n        return self._scheduler.modify_job(id, jobstore, **changes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the given job without scheduling it.", "response": "def run_job(self, id, jobstore=None):\n        \"\"\"\n        Run the given job without scheduling it.\n        :param id: the identifier of the job.\n        :param str jobstore: alias of the job store that contains the job\n        :return:\n        \"\"\"\n        job = self._scheduler.get_job(id, jobstore)\n\n        if not job:\n            raise JobLookupError(id)\n\n        job.func(*job.args, **job.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_config(self):\n        options = dict()\n\n        job_stores = self.app.config.get('SCHEDULER_JOBSTORES')\n        if job_stores:\n            options['jobstores'] = job_stores\n\n        executors = self.app.config.get('SCHEDULER_EXECUTORS')\n        if executors:\n            options['executors'] = executors\n\n        job_defaults = self.app.config.get('SCHEDULER_JOB_DEFAULTS')\n        if job_defaults:\n            options['job_defaults'] = job_defaults\n\n        timezone = self.app.config.get('SCHEDULER_TIMEZONE')\n        if timezone:\n            options['timezone'] = timezone\n\n        self._scheduler.configure(**options)\n\n        self.auth = self.app.config.get('SCHEDULER_AUTH', self.auth)\n        self.api_enabled = self.app.config.get('SCHEDULER_VIEWS_ENABLED', self.api_enabled)  # for compatibility reason\n        self.api_enabled = self.app.config.get('SCHEDULER_API_ENABLED', self.api_enabled)\n        self.api_prefix = self.app.config.get('SCHEDULER_API_PREFIX', self.api_prefix)\n        self.endpoint_prefix = self.app.config.get('SCHEDULER_ENDPOINT_PREFIX', self.endpoint_prefix)\n        self.allowed_hosts = self.app.config.get('SCHEDULER_ALLOWED_HOSTS', self.allowed_hosts)", "response": "Load the configuration from the Flask configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the job definitions from the Flask configuration.", "response": "def _load_jobs(self):\n        \"\"\"\n        Load the job definitions from the Flask configuration.\n        \"\"\"\n        jobs = self.app.config.get('SCHEDULER_JOBS')\n\n        if not jobs:\n            jobs = self.app.config.get('JOBS')\n\n        if jobs:\n            for job in jobs:\n                self.add_job(**job)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_api(self):\n        self._add_url_route('get_scheduler_info', '', api.get_scheduler_info, 'GET')\n        self._add_url_route('add_job', '/jobs', api.add_job, 'POST')\n        self._add_url_route('get_job', '/jobs/<job_id>', api.get_job, 'GET')\n        self._add_url_route('get_jobs', '/jobs', api.get_jobs, 'GET')\n        self._add_url_route('delete_job', '/jobs/<job_id>', api.delete_job, 'DELETE')\n        self._add_url_route('update_job', '/jobs/<job_id>', api.update_job, 'PATCH')\n        self._add_url_route('pause_job', '/jobs/<job_id>/pause', api.pause_job, 'POST')\n        self._add_url_route('resume_job', '/jobs/<job_id>/resume', api.resume_job, 'POST')\n        self._add_url_route('run_job', '/jobs/<job_id>/run', api.run_job, 'POST')", "response": "Load the scheduler API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a Flask route.", "response": "def _add_url_route(self, endpoint, rule, view_func, method):\n        \"\"\"\n        Add a Flask route.\n        :param str endpoint: The endpoint name.\n        :param str rule: The endpoint url.\n        :param view_func: The endpoint func\n        :param str method: The http method.\n        \"\"\"\n        if self.api_prefix:\n            rule = self.api_prefix + rule\n\n        if self.endpoint_prefix:\n            endpoint = self.endpoint_prefix + endpoint\n\n        self.app.add_url_rule(\n            rule,\n            endpoint,\n            self._apply_auth(view_func),\n            methods=[method]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying decorator to authenticate the user who is making the request. :param view_func: The flask view func.", "response": "def _apply_auth(self, view_func):\n        \"\"\"\n        Apply decorator to authenticate the user who is making the request.\n        :param view_func: The flask view func.\n        \"\"\"\n        @functools.wraps(view_func)\n        def decorated(*args, **kwargs):\n            if not self.auth:\n                return view_func(*args, **kwargs)\n\n            auth_data = self.auth.get_authorization()\n\n            if auth_data is None:\n                return self._handle_authentication_error()\n\n            if not self._authentication_callback or not self._authentication_callback(auth_data):\n                return self._handle_authentication_error()\n\n            return view_func(*args, **kwargs)\n\n        return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_authentication_error(self):\n        response = make_response('Access Denied')\n        response.headers['WWW-Authenticate'] = self.auth.get_authenticate_header()\n        response.status_code = 401\n        return response", "response": "Return an authentication error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_authorization_header():\n    header = request.environ.get('HTTP_AUTHORIZATION')\n\n    if not header:\n        return None\n\n    header = wsgi_to_bytes(header)\n\n    try:\n        auth_type, auth_info = header.split(None, 1)\n        auth_type = auth_type.lower()\n    except ValueError:\n        return None\n\n    return auth_type, auth_info", "response": "Return request s Authorization header as a two - tuple of type and info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_authorization(self):\n        auth = get_authorization_header()\n\n        if not auth:\n            return None\n\n        auth_type, auth_info = auth\n\n        if auth_type != b'basic':\n            return None\n\n        try:\n            username, password = base64.b64decode(auth_info).split(b':', 1)\n        except Exception:\n            return None\n\n        return Authorization('basic', username=bytes_to_wsgi(username), password=bytes_to_wsgi(password))", "response": "Get the username and password for Basic authentication header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the scheduler info.", "response": "def get_scheduler_info():\n    \"\"\"Gets the scheduler info.\"\"\"\n\n    scheduler = current_app.apscheduler\n\n    d = OrderedDict([\n        ('current_host', scheduler.host_name),\n        ('allowed_hosts', scheduler.allowed_hosts),\n        ('running', scheduler.running)\n    ])\n\n    return jsonify(d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new job to the cluster.", "response": "def add_job():\n    \"\"\"Adds a new job.\"\"\"\n\n    data = request.get_json(force=True)\n\n    try:\n        job = current_app.apscheduler.add_job(**data)\n        return jsonify(job)\n    except ConflictingIdError:\n        return jsonify(dict(error_message='Job %s already exists.' % data.get('id')), status=409)\n    except Exception as e:\n        return jsonify(dict(error_message=str(e)), status=500)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_jobs():\n\n    jobs = current_app.apscheduler.get_jobs()\n\n    job_states = []\n\n    for job in jobs:\n        job_states.append(job)\n\n    return jsonify(job_states)", "response": "Gets all scheduled jobs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_command(self, ctx: click.Context, name: str) -> click.Command:\n        info = ctx.ensure_object(ScriptInfo)\n        command = None\n        try:\n            command = info.load_app().cli.get_command(ctx, name)\n        except NoAppException:\n            pass\n        if command is None:\n            command = super().get_command(ctx, name)\n        return command", "response": "Return the relevant command given the context and name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the template with the given context.", "response": "async def render_template(template_name_or_list: Union[str, List[str]], **context: Any) -> str:\n    \"\"\"Render the template with the context given.\n\n    Arguments:\n        template_name_or_list: Template name to render of a list of\n            possible template names.\n        context: The variables to pass to the template.\n    \"\"\"\n    await current_app.update_template_context(context)\n    template = current_app.jinja_env.get_or_select_template(template_name_or_list)\n    return await _render(template, context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the template source with the context given.", "response": "async def render_template_string(source: str, **context: Any) -> str:\n    \"\"\"Render the template source with the context given.\n\n    Arguments:\n        source: The template source code.\n        context: The variables to pass to the template.\n    \"\"\"\n    await current_app.update_template_context(context)\n    template = current_app.jinja_env.from_string(source)\n    return await _render(template, context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the source of the template from the environment.", "response": "def get_source(\n            self, environment: Environment, template: str,\n    ) -> Tuple[str, Optional[str], Callable]:\n        \"\"\"Returns the template source from the environment.\n\n        This considers the loaders on the :attr:`app` and blueprints.\n        \"\"\"\n        for loader in self._loaders():\n            try:\n                return loader.get_source(environment, template)\n            except TemplateNotFound:\n                continue\n        raise TemplateNotFound(template)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a route to the blueprint. This is designed to be used as a decorator, and has the same arguments as :meth:`~quart.Quart.route`. An example usage, .. code-block:: python blueprint = Blueprint(__name__) @blueprint.route('/') def route(): ...", "response": "def route(\n            self,\n            path: str,\n            methods: Optional[List[str]]=None,\n            endpoint: Optional[str]=None,\n            defaults: Optional[dict]=None,\n            host: Optional[str]=None,\n            subdomain: Optional[str]=None,\n            *,\n            provide_automatic_options: Optional[bool]=None,\n            strict_slashes: bool=True,\n    ) -> Callable:\n        \"\"\"Add a route to the blueprint.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.route`. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.route('/')\n            def route():\n                ...\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.add_url_rule(\n                path, endpoint, func, methods, defaults=defaults, host=host, subdomain=subdomain,\n                provide_automatic_options=provide_automatic_options, strict_slashes=strict_slashes,\n            )\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a route or url rule to the blueprint.", "response": "def add_url_rule(\n            self,\n            path: str,\n            endpoint: Optional[str]=None,\n            view_func: Optional[Callable]=None,\n            methods: Optional[Iterable[str]]=None,\n            defaults: Optional[dict]=None,\n            host: Optional[str]=None,\n            subdomain: Optional[str]=None,\n            *,\n            provide_automatic_options: Optional[bool]=None,\n            is_websocket: bool=False,\n            strict_slashes: bool=True,\n    ) -> None:\n        \"\"\"Add a route/url rule to the blueprint.\n\n        This is designed to be used on the blueprint directly, and\n        has the same arguments as\n        :meth:`~quart.Quart.add_url_rule`. An example usage,\n\n        .. code-block:: python\n\n            def route():\n                ...\n\n            blueprint = Blueprint(__name__)\n            blueprint.add_url_rule('/', route)\n        \"\"\"\n        endpoint = endpoint or view_func.__name__\n        if '.' in endpoint:\n            raise ValueError('Blueprint endpoints should not contain periods')\n        self.record(\n            lambda state: state.add_url_rule(\n                path, endpoint, view_func, methods, defaults, host, self.subdomain,\n                provide_automatic_options=provide_automatic_options, is_websocket=is_websocket,\n                strict_slashes=strict_slashes,\n            ),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a websocket to the blueprint. This is designed to be used as a decorator, and has the same arguments as :meth:`~quart.Quart.websocket`. An example usage, .. code-block:: python blueprint = Blueprint(__name__) @blueprint.websocket('/') async def route(): ...", "response": "def websocket(\n            self,\n            path: str,\n            endpoint: Optional[str]=None,\n            defaults: Optional[dict]=None,\n            host: Optional[str]=None,\n            subdomain: Optional[str]=None,\n            *,\n            strict_slashes: bool=True,\n    ) -> Callable:\n        \"\"\"Add a websocket to the blueprint.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.websocket`. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.websocket('/')\n            async def route():\n                ...\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.add_websocket(\n                path, endpoint, func, defaults=defaults, host=host, subdomain=subdomain,\n                strict_slashes=strict_slashes,\n            )\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a websocket rule to the blueprint.", "response": "def add_websocket(\n            self,\n            path: str,\n            endpoint: Optional[str]=None,\n            view_func: Optional[Callable]=None,\n            defaults: Optional[dict]=None,\n            host: Optional[str]=None,\n            subdomain: Optional[str]=None,\n            *,\n            strict_slashes: bool=True,\n    ) -> None:\n        \"\"\"Add a websocket rule to the blueprint.\n\n        This is designed to be used on the blueprint directly, and\n        has the same arguments as\n        :meth:`~quart.Quart.add_websocket`. An example usage,\n\n        .. code-block:: python\n\n            def route():\n                ...\n\n            blueprint = Blueprint(__name__)\n            blueprint.add_websocket('/', route)\n        \"\"\"\n        return self.add_url_rule(\n            path, endpoint, view_func, {'GET'}, defaults=defaults, host=host, subdomain=subdomain,\n            provide_automatic_options=False, is_websocket=True, strict_slashes=strict_slashes,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an endpoint to the blueprint.", "response": "def endpoint(self, endpoint: str) -> Callable:\n        \"\"\"Add an endpoint to the blueprint.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.endpoint`. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.endpoint('index')\n            def index():\n                ...\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.record_once(lambda state: state.register_endpoint(endpoint, func))\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef app_template_filter(self, name: Optional[str]=None) -> Callable:\n        def decorator(func: Callable) -> Callable:\n            self.add_app_template_filter(func, name=name)\n            return func\n        return decorator", "response": "Add an application wide template filter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_app_template_filter(self, func: Callable, name: Optional[str]=None) -> None:\n        self.record_once(lambda state: state.register_template_filter(func, name))", "response": "Add an application wide template filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an application wide template global. This is a decorator that can be used as a decorator.", "response": "def app_template_global(self, name: Optional[str]=None) -> Callable:\n        \"\"\"Add an application wide template global.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.template_global`. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.app_template_global()\n            def global(value):\n                ...\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.add_app_template_global(func, name=name)\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_app_template_global(self, func: Callable, name: Optional[str]=None) -> None:\n        self.record_once(lambda state: state.register_template_global(func, name))", "response": "Add an application wide template global."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a before request function to the Blueprint.", "response": "def before_request(self, func: Callable) -> Callable:\n        \"\"\"Add a before request function to the Blueprint.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.before_request`. It applies only to requests that\n        are routed to an endpoint in this blueprint. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.before_request\n            def before():\n                ...\n        \"\"\"\n        self.record_once(lambda state: state.app.before_request(func, self.name))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a before request websocket to the Blueprint.", "response": "def before_websocket(self, func: Callable) -> Callable:\n        \"\"\"Add a before request websocket to the Blueprint.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.before_websocket`. It applies only to requests that\n        are routed to an endpoint in this blueprint. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.before_websocket\n            def before():\n                ...\n\n        \"\"\"\n        self.record_once(lambda state: state.app.before_websocket(func, self.name))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a before request function to the app. This is designed to be used as a decorator to all requests to the app.", "response": "def before_app_request(self, func: Callable) -> Callable:\n        \"\"\"Add a before request function to the app.\n\n        This is designed to be used as a decorator, and has the same arguments\n        as :meth:`~quart.Quart.before_request`. It applies to all requests to the\n        app this blueprint is registered on. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.before_app_request\n            def before():\n                ...\n        \"\"\"\n        self.record_once(lambda state: state.app.before_request(func))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef before_app_websocket(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.before_websocket(func))\n        return func", "response": "Add a before request websocket to the App.\n\n            This is designed to be used as a decorator to be used as a decorator to all requests to the App.\n           . It is designed to be used as a decorator to all requests to the App.\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef before_app_first_request(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.before_first_request(func))\n        return func", "response": "Add a before request first function to the app."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef after_request(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.after_request(func, self.name))\n        return func", "response": "Add an after request function to the Blueprint. After_requestIsUsed to add an after request function to the Blueprint. After_requestIsUsed to add an after request function to the Blueprint. After_requestIsUsed as a decorator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef after_websocket(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.after_websocket(func, self.name))\n        return func", "response": "Add an after websocket function to the Blueprint. AfterWebsocketIsDecorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef after_app_request(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.after_request(func))\n        return func", "response": "Add a after request function to the app.\n            This is designed to be used as a decorator to all requests to the\n            app."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef after_app_websocket(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.after_websocket(func))\n        return func", "response": "Add an after websocket function to the App. theAfterAppWebsocket is called when the App is started."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef teardown_request(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.teardown_request(func, self.name))\n        return func", "response": "Add a teardown request function to the Blueprint."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a teardown websocket function to the Blueprint. It is designed to be used as a decorator. It is designed to be used as a decorator. It is intended to be used as a decorator.", "response": "def teardown_websocket(self, func: Callable) -> Callable:\n        \"\"\"Add a teardown websocket function to the Blueprint.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as :meth:`~quart.Quart.teardown_websocket`. It\n        applies only to requests that are routed to an endpoint in\n        this blueprint. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.teardown_websocket\n            def teardown():\n                ...\n\n        \"\"\"\n        self.record_once(lambda state: state.app.teardown_websocket(func, self.name))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef teardown_app_request(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.teardown_request(func))\n        return func", "response": "Add a teardown request function to the app. Anonymized version of this decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an error handler function to the Blueprint.", "response": "def errorhandler(self, error: Union[Type[Exception], int]) -> Callable:\n        \"\"\"Add an error handler function to the Blueprint.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as :meth:`~quart.Quart.errorhandler`. It applies\n        only to errors that originate in routes in this blueprint. An\n        example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.errorhandler(404)\n            def not_found():\n                ...\n\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.register_error_handler(error, func)\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef app_errorhandler(self, error: Union[Type[Exception], int]) -> Callable:\n        def decorator(func: Callable) -> Callable:\n            self.record_once(lambda state: state.app.register_error_handler(error, func))\n            return func\n        return decorator", "response": "Add an error handler function to the App.\n            This is designed to be used as a decorator. It is designed to be used as a decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a function to be called when an error occurs.", "response": "def register_error_handler(self, error: Union[Type[Exception], int], func: Callable) -> None:\n        \"\"\"Add an error handler function to the blueprint.\n\n        This is designed to be used on the blueprint directly, and\n        has the same arguments as\n        :meth:`~quart.Quart.register_error_handler`. An example usage,\n\n        .. code-block:: python\n\n            def not_found():\n                ...\n\n            blueprint = Blueprint(__name__)\n            blueprint.register_error_handler(404, not_found)\n        \"\"\"\n        self.record_once(lambda state: state.app.register_error_handler(error, func, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a context processor function to this blueprint. This is designed to be used as a decorator.", "response": "def context_processor(self, func: Callable) -> Callable:\n        \"\"\"Add a context processor function to this blueprint.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as :meth:`~quart.Quart.context_processor`. This will\n        add context to all templates rendered in this blueprint's\n        routes. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.context_processor\n            def processor():\n                ...\n        \"\"\"\n        self.record_once(lambda state: state.app.context_processor(func, self.name))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a context processor function to the app. This is designed to be used as a decorator.", "response": "def app_context_processor(self, func: Callable) -> Callable:\n        \"\"\"Add a context processor function to the app.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as :meth:`~quart.Quart.context_processor`. This will\n        add context to all templates rendered. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.app_context_processor\n            def processor():\n                ...\n        \"\"\"\n        self.record_once(lambda state: state.app.context_processor(func))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a url value preprocessor. This is designed to be used as a decorator.", "response": "def url_value_preprocessor(self, func: Callable) -> Callable:\n        \"\"\"Add a url value preprocessor.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as :meth:`~quart.Quart.url_value_preprocessor`. This\n        will apply to urls in this blueprint. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.url_value_preprocessor\n            def processor(endpoint, view_args):\n                ...\n\n        \"\"\"\n        self.record_once(lambda state: state.app.url_value_preprocessor(func, self.name))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a url value preprocessor. This is designed to be used as a decorator.", "response": "def app_url_value_preprocessor(self, func: Callable) -> Callable:\n        \"\"\"Add a url value preprocessor.\n\n        This is designed to be used as a decorator, and has the same\n        arguments as\n        :meth:`~quart.Quart.app_url_value_preprocessor`. This will\n        apply to all URLs. An example usage,\n\n        .. code-block:: python\n\n            blueprint = Blueprint(__name__)\n            @blueprint.app_url_value_preprocessor\n            def processor(endpoint, view_args):\n                ...\n\n        \"\"\"\n        self.record_once(lambda state: state.app.url_value_preprocessor(func))\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url_defaults(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.url_defaults(func, self.name))\n        return func", "response": "Add a url default preprocessor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef app_url_defaults(self, func: Callable) -> Callable:\n        self.record_once(lambda state: state.app.url_defaults(func))\n        return func", "response": "Add a url default preprocessor. This is designed to be used as a decorator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing to register a deferred action that happens only once.", "response": "def record_once(self, func: DeferedSetupFunction) -> None:\n        \"\"\"Used to register a deferred action that happens only once.\"\"\"\n        def wrapper(state: 'BlueprintSetupState') -> None:\n            if state.first_registration:\n                func(state)\n        self.record(update_wrapper(wrapper, func))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(\n            self,\n            app: 'Quart',\n            first_registration: bool,\n            *,\n            url_prefix: Optional[str]=None,\n    ) -> None:\n        \"\"\"Register this blueprint on the app given.\"\"\"\n        state = self.make_setup_state(app, first_registration, url_prefix=url_prefix)\n\n        if self.has_static_folder:\n            state.add_url_rule(\n                self.static_url_path + '/<path:filename>',\n                view_func=self.send_static_file, endpoint='static',\n            )\n\n        for func in self.deferred_functions:\n            func(state)", "response": "Register this blueprint on the app given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a BlueprintSetupState instance for the blueprint.", "response": "def make_setup_state(\n            self,\n            app: 'Quart',\n            first_registration: bool,\n            *,\n            url_prefix: Optional[str]=None,\n    ) -> 'BlueprintSetupState':\n        \"\"\"Return a blueprint setup state instance.\n\n        Arguments:\n            first_registration: True if this is the first registration\n                of this blueprint on the app.\n            url_prefix: An optional prefix to all rules\n        \"\"\"\n        return BlueprintSetupState(self, app, first_registration, url_prefix=url_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the multidict to a plain dictionary.", "response": "def to_dict(self, flat: bool=True) -> Dict[Any, Any]:\n        \"\"\"Convert the multidict to a plain dictionary.\n\n        Arguments:\n\n            flat: If True only return the a value for each key, if\n                False return all values as lists.\n        \"\"\"\n        if flat:\n            return {key: value for key, value in self.items()}  # type: ignore\n        else:\n            return {key: self.getall(key) for key in self}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, destination: BinaryIO, buffer_size: int=16384) -> None:\n        close_destination = False\n        if isinstance(destination, str):\n            destination = open(destination, 'wb')\n            close_destination = True\n        try:\n            copyfileobj(self.stream, destination, buffer_size)\n        finally:\n            if close_destination:\n                destination.close()", "response": "Save the file to the destination."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a logger for the app based on the app settings.", "response": "def create_logger(app: 'Quart') -> Logger:\n    \"\"\"Create a logger for the app based on the app settings.\n\n    This creates a logger named quart.app that has a log level based\n    on the app configuration.\n    \"\"\"\n    logger = getLogger('quart.app')\n\n    if app.debug and logger.level == NOTSET:\n        logger.setLevel(DEBUG)\n\n    logger.addHandler(default_handler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a logger for serving.", "response": "def create_serving_logger() -> Logger:\n    \"\"\"Create a logger for serving.\n\n    This creates a logger named quart.serving.\n    \"\"\"\n    logger = getLogger('quart.serving')\n\n    if logger.level == NOTSET:\n        logger.setLevel(INFO)\n\n    logger.addHandler(serving_handler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Cookie object given the options set", "response": "def create_cookie(\n        key: str,\n        value: str='',\n        max_age: Optional[Union[int, timedelta]]=None,\n        expires: Optional[Union[int, float, datetime]]=None,\n        path: str='/',\n        domain: Optional[str]=None,\n        secure: bool=False,\n        httponly: bool=False,\n) -> SimpleCookie:\n    \"\"\"Create a Cookie given the options set\n\n    The arguments are the standard cookie morsels and this is a\n    wrapper around the stdlib SimpleCookie code.\n    \"\"\"\n    cookie = SimpleCookie()\n    cookie[key] = value\n    cookie[key]['path'] = path\n    cookie[key]['httponly'] = httponly  # type: ignore\n    cookie[key]['secure'] = secure  # type: ignore\n    if isinstance(max_age, timedelta):\n        cookie[key]['max-age'] = f\"{max_age.total_seconds():d}\"\n    if isinstance(max_age, int):\n        cookie[key]['max-age'] = str(max_age)\n    if expires is not None and isinstance(expires, (int, float)):\n        cookie[key]['expires'] = format_date_time(int(expires))\n    elif expires is not None and isinstance(expires, datetime):\n        cookie[key]['expires'] = format_date_time(expires.replace(tzinfo=timezone.utc).timestamp())\n    if domain is not None:\n        cookie[key]['domain'] = domain\n    return cookie"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jinja_env(self) -> Environment:\n        if self._jinja_env is None:\n            self._jinja_env = self.create_jinja_environment()\n        return self._jinja_env", "response": "The jinja environment used to load templates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlocating the instance path for the class.", "response": "def auto_find_instance_path(self) -> Path:\n        \"\"\"Locates the instace_path if it was not provided\n        \"\"\"\n        prefix, package_path = find_package(self.import_name)\n        if prefix is None:\n            return package_path / \"instance\"\n        return prefix / \"var\" / f\"{self.name}-instance\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_config(self, instance_relative: bool = False) -> Config:\n        config = self.config_class(\n            self.instance_path if instance_relative else self.root_path,\n            DEFAULT_CONFIG,\n        )\n        config['ENV'] = get_env()\n        config['DEBUG'] = get_debug_flag()\n        return config", "response": "Create and return the configuration with appropriate defaults."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a file for reading.", "response": "def open_instance_resource(self, path: FilePath, mode: str='rb') -> IO[AnyStr]:\n        \"\"\"Open a file for reading.\n\n        Use as\n\n        .. code-block:: python\n\n            with app.open_instance_resouce(path) as file_:\n                file_.read()\n        \"\"\"\n        return open(self.instance_path / file_path_to_path(path), mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and return a URL adapter based on the request.", "response": "def create_url_adapter(self, request: Optional[BaseRequestWebsocket]) -> Optional[MapAdapter]:\n        \"\"\"Create and return a URL adapter.\n\n        This will create the adapter based on the request if present\n        otherwise the app configuration.\n        \"\"\"\n        if request is not None:\n            host = request.host\n            return self.url_map.bind_to_request(\n                request.scheme, host, request.method, request.path, request.query_string,\n            )\n\n        if self.config['SERVER_NAME'] is not None:\n            return self.url_map.bind(\n                self.config['PREFERRED_URL_SCHEME'], self.config['SERVER_NAME'],\n            )\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating and return the jinja environment.", "response": "def create_jinja_environment(self) -> Environment:\n        \"\"\"Create and return the jinja environment.\n\n        This will create the environment based on the\n        :attr:`jinja_options` and configuration settings. The\n        environment will include the Quart globals by default.\n        \"\"\"\n        options = dict(self.jinja_options)\n        if 'autoescape' not in options:\n            options['autoescape'] = self.select_jinja_autoescape\n        if 'auto_reload' not in options:\n            options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD'] or self.debug\n        jinja_env = self.jinja_environment(self, **options)\n        jinja_env.globals.update({\n            'config': self.config,\n            'g': g,\n            'get_flashed_messages': get_flashed_messages,\n            'request': request,\n            'session': session,\n            'url_for': url_for,\n        })\n        jinja_env.filters['tojson'] = tojson_filter\n        return jinja_env"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_jinja_autoescape(self, filename: str) -> bool:\n        if filename is None:\n            return True\n        return Path(filename).suffix in {'.htm', '.html', '.xhtml', '.xml'}", "response": "Returns True if the filename indicates that it should be escaped."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def update_template_context(self, context: dict) -> None:\n        processors = self.template_context_processors[None]\n        if has_request_context():\n            blueprint = _request_ctx_stack.top.request.blueprint\n            if blueprint is not None and blueprint in self.template_context_processors:\n                processors = chain(processors, self.template_context_processors[blueprint])  # type: ignore # noqa\n        extra_context: dict = {}\n        for processor in processors:\n            extra_context.update(await processor())\n        original = context.copy()\n        context.update(extra_context)\n        context.update(original)", "response": "Update the provided template context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a context for interactive shell usage.", "response": "def make_shell_context(self) -> dict:\n        \"\"\"Create a context for interactive shell usage.\n\n        The :attr:`shell_context_processors` can be used to add\n        additional context.\n        \"\"\"\n        context = {'app': self, 'g': g}\n        for processor in self.shell_context_processors:\n            context.update(processor())\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a route or url rule to the application.", "response": "def add_url_rule(\n            self,\n            path: str,\n            endpoint: Optional[str]=None,\n            view_func: Optional[Callable]=None,\n            methods: Optional[Iterable[str]]=None,\n            defaults: Optional[dict]=None,\n            host: Optional[str]=None,\n            subdomain: Optional[str]=None,\n            *,\n            provide_automatic_options: Optional[bool]=None,\n            is_websocket: bool=False,\n            strict_slashes: bool=True,\n    ) -> None:\n        \"\"\"Add a route/url rule to the application.\n\n        This is designed to be used on the application directly. An\n        example usage,\n\n        .. code-block:: python\n\n            def route():\n                ...\n\n            app.add_url_rule('/', route)\n\n        Arguments:\n            path: The path to route on, should start with a ``/``.\n            func: Callable that returns a reponse.\n            methods: List of HTTP verbs the function routes.\n            endpoint: Optional endpoint name, if not present the\n                function name is used.\n            defaults: A dictionary of variables to provide automatically, use\n                to provide a simpler default path for a route, e.g. to allow\n                for ``/book`` rather than ``/book/0``,\n\n                .. code-block:: python\n\n                    @app.route('/book', defaults={'page': 0})\n                    @app.route('/book/<int:page>')\n                    def book(page):\n                        ...\n\n            host: The full host name for this route (should include subdomain\n                if needed) - cannot be used with subdomain.\n            subdomain: A subdomain for this specific route.\n            provide_automatic_options: Optionally False to prevent\n                OPTION handling.\n            strict_slashes: Strictly match the trailing slash present in the\n                path. Will redirect a leaf (no slash) to a branch (with slash).\n        \"\"\"\n        endpoint = endpoint or _endpoint_from_view_func(view_func)\n        handler = ensure_coroutine(view_func)\n        if methods is None:\n            methods = getattr(view_func, 'methods', ['GET'])\n\n        methods = cast(Set[str], set(methods))\n        required_methods = set(getattr(view_func, 'required_methods', set()))\n\n        if provide_automatic_options is None:\n            automatic_options = getattr(view_func, 'provide_automatic_options', None)\n            if automatic_options is None:\n                automatic_options = 'OPTIONS' not in methods\n        else:\n            automatic_options = provide_automatic_options\n\n        if automatic_options:\n            required_methods.add('OPTIONS')\n\n        methods.update(required_methods)\n\n        if not self.url_map.host_matching and (host is not None or subdomain is not None):\n            raise RuntimeError('Cannot use host or subdomain without host matching enabled.')\n        if host is not None and subdomain is not None:\n            raise ValueError('Cannot set host and subdomain, please choose one or the other')\n\n        if subdomain is not None:\n            if self.config['SERVER_NAME'] is None:\n                raise RuntimeError('SERVER_NAME config is required to use subdomain in a route.')\n            host = f\"{subdomain}.{self.config['SERVER_NAME']}\"\n        elif host is None and self.url_map.host_matching:\n            host = self.config['SERVER_NAME']\n            if host is None:\n                raise RuntimeError(\n                    'Cannot add a route with host matching enabled without either a specified '\n                    'host or a config SERVER_NAME',\n                )\n\n        self.url_map.add(\n            self.url_rule_class(\n                path, methods, endpoint, host=host, provide_automatic_options=automatic_options,\n                defaults=defaults, is_websocket=is_websocket, strict_slashes=strict_slashes,\n            ),\n        )\n        if handler is not None:\n            old_handler = self.view_functions.get(endpoint)\n            if getattr(old_handler, '_quart_async_wrapper', False):\n                old_handler = old_handler.__wrapped__  # type: ignore\n            if old_handler is not None and old_handler != view_func:\n                raise AssertionError(f\"Handler is overwriting existing for endpoint {endpoint}\")\n\n        self.view_functions[endpoint] = handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef endpoint(self, endpoint: str) -> Callable:\n        def decorator(func: Callable) -> Callable:\n            handler = ensure_coroutine(func)\n            self.view_functions[endpoint] = handler\n            return func\n        return decorator", "response": "Register a function as an endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a function as an error handler.", "response": "def register_error_handler(\n            self, error: Union[Type[Exception], int], func: Callable, name: AppOrBlueprintKey=None,\n    ) -> None:\n        \"\"\"Register a function as an error handler.\n\n        This is designed to be used on the application directly. An\n        example usage,\n\n        .. code-block:: python\n\n            def error_handler():\n                return \"Error\", 500\n\n            app.register_error_handler(500, error_handler)\n\n        Arguments:\n            error: The error code or Exception to handle.\n            func: The function to handle the error.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        if isinstance(error, int):\n            error = all_http_exceptions[error]\n        self.error_handler_spec[name][error] = handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a template filter. This is designed to be used as a decorator.", "response": "def template_filter(self, name: Optional[str]=None) -> Callable:\n        \"\"\"Add a template filter.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.template_filter('name')\n            def to_upper(value):\n                return value.upper()\n\n        Arguments:\n            name: The filter name (defaults to function name).\n        \"\"\"\n        def decorator(func: Callable) -> Callable:\n            self.add_template_filter(func, name=name)\n            return func\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a template filter.", "response": "def add_template_filter(self, func: Callable, name: Optional[str]=None) -> None:\n        \"\"\"Add a template filter.\n\n        This is designed to be used on the application directly. An\n        example usage,\n\n        .. code-block:: python\n\n            def to_upper(value):\n                return value.upper()\n\n            app.add_template_filter(to_upper)\n\n        Arguments:\n            func: The function that is the filter.\n            name: The filter name (defaults to function name).\n        \"\"\"\n        self.jinja_env.filters[name or func.__name__] = func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef template_global(self, name: Optional[str]=None) -> Callable:\n        def decorator(func: Callable) -> Callable:\n            self.add_template_global(func, name=name)\n            return func\n        return decorator", "response": "Add a template global."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a template global.", "response": "def add_template_global(self, func: Callable, name: Optional[str]=None) -> None:\n        \"\"\"Add a template global.\n\n        This is designed to be used on the application directly. An\n        example usage,\n\n        .. code-block:: python\n\n            def five():\n                return 5\n\n            app.add_template_global(five)\n\n        Arguments:\n            func: The function that is the global.\n            name: The global name (defaults to function name).\n        \"\"\"\n        self.jinja_env.globals[name or func.__name__] = func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef context_processor(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        self.template_context_processors[name].append(ensure_coroutine(func))\n        return func", "response": "Add a template context processor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a url default preprocessor.", "response": "def url_defaults(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        \"\"\"Add a url default preprocessor.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.url_defaults\n            def default(endpoint, values):\n                ...\n        \"\"\"\n        self.url_default_functions[name].append(func)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_value_preprocessor(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        self.url_value_preprocessors[name].append(func)\n        return func", "response": "Add a url value preprocessor function to be used as a decorator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninjecting default URL values into the passed values dict.", "response": "def inject_url_defaults(self, endpoint: str, values: dict) -> None:\n        \"\"\"Injects default URL values into the passed values dict.\n\n        This is used to assist when building urls, see\n        :func:`~quart.helpers.url_for`.\n        \"\"\"\n        functions = self.url_value_preprocessors[None]\n        if '.' in endpoint:\n            blueprint = endpoint.rsplit('.', 1)[0]\n            functions = chain(functions, self.url_value_preprocessors[blueprint])  # type: ignore\n\n        for function in functions:\n            function(endpoint, values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a build error.", "response": "def handle_url_build_error(self, error: Exception, endpoint: str, values: dict) -> str:\n        \"\"\"Handle a build error.\n\n        Ideally this will return a valid url given the error endpoint\n        and values.\n        \"\"\"\n        for handler in self.url_build_error_handlers:\n            result = handler(error, endpoint, values)\n            if result is not None:\n                return result\n        raise error"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def handle_http_exception(self, error: Exception) -> Response:\n        handler = self._find_exception_handler(error)\n        if handler is None:\n            return error.get_response()  # type: ignore\n        else:\n            return await handler(error)", "response": "Handle an HTTP exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles an exception that has been raised.", "response": "async def handle_user_exception(self, error: Exception) -> Response:\n        \"\"\"Handle an exception that has been raised.\n\n        This should forward :class:`~quart.exception.HTTPException` to\n        :meth:`handle_http_exception`, then attempt to handle the\n        error. If it cannot it should reraise the error.\n        \"\"\"\n        if isinstance(error, HTTPException) and not self.trap_http_exception(error):\n            return await self.handle_http_exception(error)\n\n        handler = self._find_exception_handler(error)\n        if handler is None:\n            raise error\n        return await handler(error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def handle_exception(self, error: Exception) -> Response:\n        await got_request_exception.send(self, exception=error)\n\n        self.log_exception(sys.exc_info())\n\n        if self.propagate_exceptions:\n            return await traceback_response()\n\n        internal_server_error = all_http_exceptions[500]()\n        handler = self._find_exception_handler(internal_server_error)\n\n        if handler is None:\n            return internal_server_error.get_response()\n        else:\n            return await self.finalize_request(await handler(error), from_error_handler=True)", "response": "Handle an uncaught exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles an uncaught exception.", "response": "async def handle_websocket_exception(self, error: Exception) -> Optional[Response]:\n        \"\"\"Handle an uncaught exception.\n\n        By default this logs the exception and then re-raises it.\n        \"\"\"\n        await got_websocket_exception.send(self, exception=error)\n\n        self.log_exception(sys.exc_info())\n\n        internal_server_error = all_http_exceptions[500]()\n        handler = self._find_exception_handler(internal_server_error)\n\n        if handler is None:\n            return internal_server_error.get_response()\n        else:\n            return await self.finalize_websocket(await handler(error), from_error_handler=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog an exception to the logger.", "response": "def log_exception(self, exception_info: Tuple[type, BaseException, TracebackType]) -> None:\n        \"\"\"Log a exception to the :attr:`logger`.\n\n        By default this is only invoked for unhandled exceptions.\n        \"\"\"\n        if has_request_context():\n            request_ = _request_ctx_stack.top.request\n            self.logger.error(\n                f\"Exception on request {request_.method} {request_.path}\",\n                exc_info=exception_info,\n            )\n        if has_websocket_context():\n            websocket_ = _websocket_ctx_stack.top.websocket\n            self.logger.error(\n                f\"Exception on websocket {websocket_.path}\",\n                exc_info=exception_info,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a before request function.", "response": "def before_request(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        \"\"\"Add a before request function.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.before_request\n            def func():\n                ...\n\n        Arguments:\n            func: The before request function itself.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.before_request_funcs[name].append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef before_websocket(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        handler = ensure_coroutine(func)\n        self.before_websocket_funcs[name].append(handler)\n        return func", "response": "Add a before websocket function. This is designed to be used as a decorator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a before first request function.", "response": "def before_first_request(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        \"\"\"Add a before **first** request function.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.before_first_request\n            def func():\n                ...\n\n        Arguments:\n            func: The before first request function itself.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.before_first_request_funcs.append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a before serving function.", "response": "def before_serving(self, func: Callable) -> Callable:\n        \"\"\"Add a before serving function.\n\n        This will allow the function provided to be called once before\n        anything is served (before any byte is received).\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.before_serving\n            def func():\n                ...\n\n        Arguments:\n            func: The function itself.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.before_serving_funcs.append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef after_request(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        handler = ensure_coroutine(func)\n        self.after_request_funcs[name].append(handler)\n        return func", "response": "Add an after request function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an after websocket function.", "response": "def after_websocket(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        \"\"\"Add an after websocket function.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.after_websocket\n            def func(response):\n                return response\n\n        Arguments:\n            func: The after websocket function itself.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.after_websocket_funcs[name].append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef after_serving(self, func: Callable) -> Callable:\n        handler = ensure_coroutine(func)\n        self.after_serving_funcs.append(handler)\n        return func", "response": "Add a after serving function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef teardown_request(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        handler = ensure_coroutine(func)\n        self.teardown_request_funcs[name].append(handler)\n        return func", "response": "Add a teardown request function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a teardown websocket function. This is designed to be used as a decorator.", "response": "def teardown_websocket(self, func: Callable, name: AppOrBlueprintKey=None) -> Callable:\n        \"\"\"Add a teardown websocket function.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.teardown_websocket\n            def func():\n                ...\n\n        Arguments:\n            func: The teardown websocket function itself.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.teardown_websocket_funcs[name].append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a teardown app context function.", "response": "def teardown_appcontext(self, func: Callable) -> Callable:\n        \"\"\"Add a teardown app (context) function.\n\n        This is designed to be used as a decorator. An example usage,\n\n        .. code-block:: python\n\n            @app.teardown_appcontext\n            def func():\n                ...\n\n        Arguments:\n            func: The teardown function itself.\n            name: Optional blueprint key name.\n        \"\"\"\n        handler = ensure_coroutine(func)\n        self.teardown_appcontext_funcs.append(handler)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a blueprint on the app.", "response": "def register_blueprint(self, blueprint: Blueprint, url_prefix: Optional[str]=None) -> None:\n        \"\"\"Register a blueprint on the app.\n\n        This results in the blueprint's routes, error handlers\n        etc... being added to the app.\n\n        Arguments:\n            blueprint: The blueprint to register.\n            url_prefix: Optional prefix to apply to all paths.\n        \"\"\"\n        first_registration = False\n        if blueprint.name in self.blueprints and self.blueprints[blueprint.name] is not blueprint:\n            raise RuntimeError(\n                f\"Blueprint name '{blueprint.name}' \"\n                f\"is already registered by {self.blueprints[blueprint.name]}. \"\n                \"Blueprints must have unique names\",\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n        blueprint.register(self, first_registration, url_prefix=url_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def open_session(self, request: BaseRequestWebsocket) -> Session:\n        return await ensure_coroutine(self.session_interface.open_session)(self, request)", "response": "Open and return a Session using the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the session to the response.", "response": "async def save_session(self, session: Session, response: Response) -> None:\n        \"\"\"Saves the session to the response.\"\"\"\n        await ensure_coroutine(self.session_interface.save_session)(self, session, response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def do_teardown_request(\n            self,\n            exc: Optional[BaseException],\n            request_context: Optional[RequestContext]=None,\n    ) -> None:\n        \"\"\"Teardown the request, calling the teardown functions.\n\n        Arguments:\n            exc: Any exception not handled that has caused the request\n                to teardown.\n            request_context: The request context, optional as Flask\n                omits this argument.\n        \"\"\"\n        request_ = (request_context or _request_ctx_stack.top).request\n        functions = self.teardown_request_funcs[None]\n        blueprint = request_.blueprint\n        if blueprint is not None:\n            functions = chain(functions, self.teardown_request_funcs[blueprint])  # type: ignore\n\n        for function in functions:\n            await function(exc=exc)\n        await request_tearing_down.send(self, exc=exc)", "response": "Teardown the request, calling the teardown functions.\n\n        Arguments:\n            exc: Any exception not handled that has caused the request\n                to teardown.\n            request_context: The request context, optional as Flask\n                omits this argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def do_teardown_websocket(\n            self,\n            exc: Optional[BaseException],\n            websocket_context: Optional[WebsocketContext]=None,\n    ) -> None:\n        \"\"\"Teardown the websocket, calling the teardown functions.\n\n        Arguments:\n            exc: Any exception not handled that has caused the websocket\n                to teardown.\n            websocket_context: The websocket context, optional as Flask\n                omits this argument.\n        \"\"\"\n        websocket_ = (websocket_context or _websocket_ctx_stack.top).websocket\n        functions = self.teardown_websocket_funcs[None]\n        blueprint = websocket_.blueprint\n        if blueprint is not None:\n            functions = chain(functions, self.teardown_websocket_funcs[blueprint])  # type: ignore\n\n        for function in functions:\n            await function(exc=exc)\n        await websocket_tearing_down.send(self, exc=exc)", "response": "Teardown the websocket, calling the teardown functions.\n\n        Arguments:\n            exc: Any exception not handled that has caused the websocket\n                to teardown.\n            websocket_context: The websocket context, optional as Flask\n                omits this argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(\n            self,\n            host: str='127.0.0.1',\n            port: int=5000,\n            debug: Optional[bool]=None,\n            use_reloader: bool=True,\n            loop: Optional[asyncio.AbstractEventLoop]=None,\n            ca_certs: Optional[str]=None,\n            certfile: Optional[str]=None,\n            keyfile: Optional[str]=None,\n            **kwargs: Any,\n    ) -> None:\n        \"\"\"Run this application.\n\n        This is best used for development only, see Hypercorn for\n        production servers.\n\n        Arguments:\n            host: Hostname to listen on. By default this is loopback\n                only, use 0.0.0.0 to have the server listen externally.\n            port: Port number to listen on.\n            debug: If set enable (or disable) debug mode and debug output.\n            use_reloader: Automatically reload on code changes.\n            loop: Asyncio loop to create the server in, if None, take default one.\n                If specified it is the caller's responsibility to close and cleanup the\n                loop.\n            ca_certs: Path to the SSL CA certificate file.\n            certfile: Path to the SSL certificate file.\n            keyfile: Path to the SSL key file.\n\n        \"\"\"\n        if kwargs:\n            warnings.warn(\n                f\"Additional arguments, {','.join(kwargs.keys())}, are not supported.\\n\"\n                \"They may be supported by Hypercorn, which is the ASGI server Quart \"\n                \"uses by default. This method is meant for development and debugging.\"\n            )\n\n        config = HyperConfig()\n        config.access_log_format = \"%(h)s %(r)s %(s)s %(b)s %(D)s\"\n        config.access_logger = create_serving_logger()  # type: ignore\n        config.bind = [f\"{host}:{port}\"]\n        config.ca_certs = ca_certs\n        config.certfile = certfile\n        if debug is not None:\n            self.debug = debug\n        config.error_logger = config.access_logger  # type: ignore\n        config.keyfile = keyfile\n        config.use_reloader = use_reloader\n\n        scheme = 'https' if config.ssl_enabled else 'http'\n        print(\"Running on {}://{} (CTRL + C to quit)\".format(scheme, config.bind[0]))  # noqa: T001\n\n        if loop is not None:\n            loop.set_debug(debug or False)\n            loop.run_until_complete(serve(self, config))\n        else:\n            asyncio.run(serve(self, config), debug=config.debug)", "response": "This method runs the application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def try_trigger_before_first_request_functions(self) -> None:\n        if self._got_first_request:\n            return\n\n        # Reverse the teardown functions, so as to match the expected usage\n        self.teardown_appcontext_funcs = list(reversed(self.teardown_appcontext_funcs))\n        for key, value in self.teardown_request_funcs.items():\n            self.teardown_request_funcs[key] = list(reversed(value))\n        for key, value in self.teardown_websocket_funcs.items():\n            self.teardown_websocket_funcs[key] = list(reversed(value))\n\n        async with self._first_request_lock:\n            if self._got_first_request:\n                return\n            for function in self.before_first_request_funcs:\n                await function()\n            self._got_first_request = True", "response": "Trigger the before first request methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a Response object from the result of the route handler.", "response": "async def make_response(self, result: ResponseReturnValue) -> Response:\n        \"\"\"Make a Response from the result of the route handler.\n\n        The result itself can either be:\n          - A Response object (or subclass).\n          - A tuple of a ResponseValue and a header dictionary.\n          - A tuple of a ResponseValue, status code and a header dictionary.\n\n        A ResponseValue is either a Response object (or subclass) or a str.\n        \"\"\"\n        status_or_headers = None\n        headers = None\n        status = None\n        if isinstance(result, tuple):\n            value, status_or_headers, headers = result + (None,) * (3 - len(result))\n        else:\n            value = result\n\n        if value is None:\n            raise TypeError('The response value returned by the view function cannot be None')\n\n        if isinstance(status_or_headers, (dict, list)):\n            headers = status_or_headers\n            status = None\n        elif status_or_headers is not None:\n            status = status_or_headers\n\n        if not isinstance(value, Response):\n            response = self.response_class(  # type: ignore\n                value, timeout=self.config['RESPONSE_TIMEOUT'],\n            )\n        else:\n            response = value\n\n        if status is not None:\n            response.status_code = status  # type: ignore\n\n        if headers is not None:\n            response.headers.update(headers)  # type: ignore\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndispatch the request and returns the response.", "response": "async def full_dispatch_request(\n        self, request_context: Optional[RequestContext]=None,\n    ) -> Response:\n        \"\"\"Adds pre and post processing to the request dispatching.\n\n        Arguments:\n            request_context: The request context, optional as Flask\n                omits this argument.\n        \"\"\"\n        await self.try_trigger_before_first_request_functions()\n        await request_started.send(self)\n        try:\n            result = await self.preprocess_request(request_context)\n            if result is None:\n                result = await self.dispatch_request(request_context)\n        except Exception as error:\n            result = await self.handle_user_exception(error)\n        return await self.finalize_request(result, request_context)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def dispatch_request(\n        self, request_context: Optional[RequestContext]=None,\n    ) -> ResponseReturnValue:\n        \"\"\"Dispatch the request to the view function.\n\n        Arguments:\n            request_context: The request context, optional as Flask\n                omits this argument.\n        \"\"\"\n        request_ = (request_context or _request_ctx_stack.top).request\n        if request_.routing_exception is not None:\n            raise request_.routing_exception\n\n        if request_.method == 'OPTIONS' and request_.url_rule.provide_automatic_options:\n            return await self.make_default_options_response()\n\n        handler = self.view_functions[request_.url_rule.endpoint]\n        return await handler(**request_.view_args)", "response": "Dispatches the request to the view function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn the view response return value into a response.", "response": "async def finalize_request(\n        self,\n        result: ResponseReturnValue,\n        request_context: Optional[RequestContext]=None,\n        from_error_handler: bool=False,\n    ) -> Response:\n        \"\"\"Turns the view response return value into a response.\n\n        Arguments:\n            result: The result of the request to finalize into a response.\n            request_context: The request context, optional as Flask\n                omits this argument.\n        \"\"\"\n        response = await self.make_response(result)\n        try:\n            response = await self.process_response(response, request_context)\n            await request_finished.send(self, response=response)\n        except Exception:\n            if not from_error_handler:\n                raise\n            self.logger.exception('Request finalizing errored')\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def process_response(\n        self,\n        response: Response,\n        request_context: Optional[RequestContext]=None,\n    ) -> Response:\n        \"\"\"Postprocess the request acting on the response.\n\n        Arguments:\n            response: The response after the request is finalized.\n            request_context: The request context, optional as Flask\n                omits this argument.\n        \"\"\"\n        request_ = (request_context or _request_ctx_stack.top).request\n        functions = (request_context or _request_ctx_stack.top)._after_request_functions\n        blueprint = request_.blueprint\n        if blueprint is not None:\n            functions = chain(functions, self.after_request_funcs[blueprint])\n        functions = chain(functions, self.after_request_funcs[None])\n\n        for function in functions:\n            response = await function(response)\n\n        session_ = (request_context or _request_ctx_stack.top).session\n        if not self.session_interface.is_null_session(session_):\n            await self.save_session(session_, response)\n        return response", "response": "Postprocess the request acting on the response.\n\n        Arguments:\n            response: The response after the request is finalized.\n            request_context: The request context, optional as Flask\n                omits this argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndispatch the websocket and returns the response.", "response": "async def full_dispatch_websocket(\n        self, websocket_context: Optional[WebsocketContext]=None,\n    ) -> Optional[Response]:\n        \"\"\"Adds pre and post processing to the websocket dispatching.\n\n        Arguments:\n            websocket_context: The websocket context, optional to match\n                the Flask convention.\n        \"\"\"\n        await self.try_trigger_before_first_request_functions()\n        await websocket_started.send(self)\n        try:\n            result = await self.preprocess_websocket(websocket_context)\n            if result is None:\n                result = await self.dispatch_websocket(websocket_context)\n        except Exception as error:\n            result = await self.handle_user_exception(error)\n        return await self.finalize_websocket(result, websocket_context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def preprocess_websocket(\n        self, websocket_context: Optional[WebsocketContext]=None,\n    ) -> Optional[ResponseReturnValue]:\n        \"\"\"Preprocess the websocket i.e. call before_websocket functions.\n\n        Arguments:\n            websocket_context: The websocket context, optional as Flask\n                omits this argument.\n        \"\"\"\n        websocket_ = (websocket_context or _websocket_ctx_stack.top).websocket\n        blueprint = websocket_.blueprint\n        processors = self.url_value_preprocessors[None]\n        if blueprint is not None:\n            processors = chain(processors, self.url_value_preprocessors[blueprint])  # type: ignore\n        for processor in processors:\n            processor(websocket_.endpoint, websocket_.view_args)\n\n        functions = self.before_websocket_funcs[None]\n        if blueprint is not None:\n            functions = chain(functions, self.before_websocket_funcs[blueprint])  # type: ignore\n        for function in functions:\n            result = await function()\n            if result is not None:\n                return result\n        return None", "response": "Preprocess the websocket i. e. call before_websocket functions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def dispatch_websocket(\n        self, websocket_context: Optional[WebsocketContext]=None,\n    ) -> None:\n        \"\"\"Dispatch the websocket to the view function.\n\n        Arguments:\n            websocket_context: The websocket context, optional to match\n                the Flask convention.\n        \"\"\"\n        websocket_ = (websocket_context or _websocket_ctx_stack.top).websocket\n        if websocket_.routing_exception is not None:\n            raise websocket_.routing_exception\n\n        handler = self.view_functions[websocket_.url_rule.endpoint]\n        return await handler(**websocket_.view_args)", "response": "Dispatch the websocket to the view function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def finalize_websocket(\n        self,\n        result: ResponseReturnValue,\n        websocket_context: Optional[WebsocketContext]=None,\n        from_error_handler: bool=False,\n    ) -> Optional[Response]:\n        \"\"\"Turns the view response return value into a response.\n\n        Arguments:\n            result: The result of the websocket to finalize into a response.\n            websocket_context: The websocket context, optional as Flask\n                omits this argument.\n        \"\"\"\n        if result is not None:\n            response = await self.make_response(result)\n        else:\n            response = None\n        try:\n            response = await self.postprocess_websocket(response, websocket_context)\n            await websocket_finished.send(self, response=response)\n        except Exception:\n            if not from_error_handler:\n                raise\n            self.logger.exception('Request finalizing errored')\n        return response", "response": "Turns the view response return value into a response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def postprocess_websocket(\n        self,\n        response: Optional[Response],\n        websocket_context: Optional[WebsocketContext]=None,\n    ) -> Response:\n        \"\"\"Postprocess the websocket acting on the response.\n\n        Arguments:\n            response: The response after the websocket is finalized.\n            webcoket_context: The websocket context, optional as Flask\n                omits this argument.\n        \"\"\"\n        websocket_ = (websocket_context or _websocket_ctx_stack.top).websocket\n        functions = (websocket_context or _websocket_ctx_stack.top)._after_websocket_functions\n        blueprint = websocket_.blueprint\n        if blueprint is not None:\n            functions = chain(functions, self.after_websocket_funcs[blueprint])\n        functions = chain(functions, self.after_websocket_funcs[None])\n\n        for function in functions:\n            response = await function(response)\n\n        session_ = (websocket_context or _request_ctx_stack.top).session\n        if not self.session_interface.is_null_session(session_):\n            if response is None and isinstance(session_, SecureCookieSession) and session_.modified:\n                self.logger.exception(\n                    \"Secure Cookie Session modified during websocket handling. \"\n                    \"These modifications will be lost as a cookie cannot be set.\"\n                )\n            else:\n                await self.save_session(session_, response)\n        return response", "response": "Postprocess the websocket acting on the response.\n\n        Arguments:\n            response: The response after the websocket is finalized.\n            webcoket_context: The websocket context, optional as Flask\n                omits this argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef after_this_request(func: Callable) -> Callable:\n    _request_ctx_stack.top._after_request_functions.append(func)\n    return func", "response": "Schedule the func to be called after the current request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nschedule the func to be called after the current websocket.", "response": "def after_this_websocket(func: Callable) -> Callable:\n    \"\"\"Schedule the func to be called after the current websocket.\n\n    This is useful in situations whereby you want an after websocket\n    function for a specific route or circumstance only, for example,\n\n    .. note::\n        The response is an optional argument, and will only be\n        passed if the websocket was not active (i.e. there was an\n        error).\n\n    .. code-block:: python\n\n        def index():\n            @after_this_websocket\n            def set_cookie(response: Optional[Response]):\n                response.set_cookie('special', 'value')\n                return response\n\n            ...\n\n    \"\"\"\n    _websocket_ctx_stack.top._after_websocket_functions.append(func)\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_current_app_context(func: Callable) -> Callable:\n    if not has_app_context():\n        raise RuntimeError('Attempt to copy app context outside of a app context')\n\n    app_context = _app_ctx_stack.top.copy()\n\n    @wraps(func)\n    async def wrapper(*args: Any, **kwargs: Any) -> Any:\n        async with app_context:\n            return await func(*args, **kwargs)\n    return wrapper", "response": "Share the current app context with the function decorated."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshare the current request context with the function decorated.", "response": "def copy_current_request_context(func: Callable) -> Callable:\n    \"\"\"Share the current request context with the function decorated.\n\n    The request context is local per task and hence will not be\n    available in any other task. This decorator can be used to make\n    the context available,\n\n    .. code-block:: python\n\n        @copy_current_request_context\n        async def within_context() -> None:\n            method = request.method\n            ...\n\n    \"\"\"\n    if not has_request_context():\n        raise RuntimeError('Attempt to copy request context outside of a request context')\n\n    request_context = _request_ctx_stack.top.copy()\n\n    @wraps(func)\n    async def wrapper(*args: Any, **kwargs: Any) -> Any:\n        async with request_context:\n            return await func(*args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_current_websocket_context(func: Callable) -> Callable:\n    if not has_websocket_context():\n        raise RuntimeError('Attempt to copy websocket context outside of a websocket context')\n\n    websocket_context = _websocket_ctx_stack.top.copy()\n\n    @wraps(func)\n    async def wrapper(*args: Any, **kwargs: Any) -> Any:\n        async with websocket_context:\n            return await func(*args, **kwargs)\n    return wrapper", "response": "Share the current websocket context with the function decorated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_request(self) -> None:\n        try:\n            self.request_websocket.url_rule, self.request_websocket.view_args = self.url_adapter.match()  # noqa\n        except (NotFound, MethodNotAllowed, RedirectRequired) as error:\n            self.request_websocket.routing_exception = error", "response": "Match the request against the adapter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, name: str, default: Optional[Any]=None) -> Any:\n        return self.__dict__.get(name, default)", "response": "Get a named attribute of this instance or return the default."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self, name: str, default: Any=_sentinel) -> Any:\n        if default is _sentinel:\n            return self.__dict__.pop(name)\n        else:\n            return self.__dict__.pop(name, default)", "response": "Pop get and remove the named attribute of this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setdefault(self, name: str, default: Any=None) -> Any:\n        return self.__dict__.setdefault(name, default)", "response": "Set an attribute with a default value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cookie_domain(self, app: 'Quart') -> Optional[str]:\n        if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        elif app.config['SERVER_NAME'] is not None:\n            return '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n        else:\n            return None", "response": "Helper method to return the Cookie Domain for the App."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_expiration_time(self, app: 'Quart', session: SessionMixin) -> Optional[datetime]:\n        if session.permanent:\n            return datetime.utcnow() + app.permanent_session_lifetime\n        else:\n            return None", "response": "Helper method to get the expiration time of the session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_signing_serializer(self, app: 'Quart') -> Optional[URLSafeTimedSerializer]:\n        if not app.secret_key:\n            return None\n\n        options = {\n            'key_derivation': self.key_derivation,\n            'digest_method': self.digest_method,\n        }\n        return URLSafeTimedSerializer(\n            app.secret_key, salt=self.salt, serializer=self.serializer, signer_kwargs=options,\n        )", "response": "Return a serializer for the session that also signs data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def open_session(\n            self,\n            app: 'Quart',\n            request: BaseRequestWebsocket,\n    ) -> Optional[SecureCookieSession]:\n        \"\"\"Open a secure cookie based session.\n\n        This will return None if a signing serializer is not availabe,\n        usually if the config SECRET_KEY is not set.\n        \"\"\"\n        signer = self.get_signing_serializer(app)\n        if signer is None:\n            return None\n\n        cookie = request.cookies.get(app.session_cookie_name)\n        if cookie is None:\n            return self.session_class()\n        try:\n            data = signer.loads(\n                cookie, max_age=app.permanent_session_lifetime.total_seconds(),\n            )\n            return self.session_class(**data)\n        except BadSignature:\n            return self.session_class()", "response": "Open a secure cookie based session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the session to the response in a secure cookie.", "response": "async def save_session(  # type: ignore\n            self, app: 'Quart', session: SecureCookieSession, response: Response,\n    ) -> None:\n        \"\"\"Saves the session to the response in a secure cookie.\"\"\"\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        if not session:\n            if session.modified:\n                response.delete_cookie(app.session_cookie_name, domain=domain, path=path)\n            return\n\n        if session.accessed:\n            response.vary.add('Cookie')\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        data = self.get_signing_serializer(app).dumps(dict(session))\n        response.set_cookie(\n            app.session_cookie_name,\n            data,\n            expires=self.get_expiration_time(app, session),\n            httponly=self.get_cookie_httponly(app),\n            domain=domain,\n            path=path,\n            secure=self.get_cookie_secure(app),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_data(self, raw: bool=True) -> AnyStr:\n        if self.implicit_sequence_conversion:\n            self.response = self.data_body_class(await self.response.convert_to_sequence())\n        result = b'' if raw else ''\n        async with self.response as body:  # type: ignore\n            async for data in body:\n                if raw:\n                    result += data\n                else:\n                    result += data.decode(self.charset)\n        return result", "response": "Return the body data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the response data. This will encode using the : attr : charset.", "response": "def set_data(self, data: AnyStr) -> None:\n        \"\"\"Set the response data.\n\n        This will encode using the :attr:`charset`.\n        \"\"\"\n        if isinstance(data, str):\n            bytes_data = data.encode(self.charset)\n        else:\n            bytes_data = data\n        self.response = self.data_body_class(bytes_data)\n        if self.automatically_set_content_length:\n            self.content_length = len(bytes_data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake the response conditional to the .", "response": "async def make_conditional(\n            self,\n            request_range: Range,\n            max_partial_size: Optional[int]=None,\n    ) -> None:\n        \"\"\"Make the response conditional to the\n\n        Arguments:\n            request_range: The range as requested by the request.\n            max_partial_size: The maximum length the server is willing\n                to serve in a single response. Defaults to unlimited.\n\n        \"\"\"\n        self.accept_ranges = \"bytes\"  # Advertise this ability\n        if len(request_range.ranges) == 0:  # Not a conditional request\n            return\n\n        if request_range.units != \"bytes\" or len(request_range.ranges) > 1:\n            from ..exceptions import RequestRangeNotSatisfiable\n            raise RequestRangeNotSatisfiable()\n\n        begin, end = request_range.ranges[0]\n        try:\n            complete_length = await self.response.make_conditional(  # type: ignore\n                begin, end, max_partial_size,\n            )\n        except AttributeError:\n            self.response = self.data_body_class(await self.response.convert_to_sequence())\n            return await self.make_conditional(request_range, max_partial_size)\n        else:\n            self.content_length = self.response.end - self.response.begin  # type: ignore\n            if self.content_length != complete_length:\n                self.content_range = ContentRange(\n                    request_range.units,\n                    self.response.begin, self.response.end - 1,  # type: ignore\n                    complete_length,\n                )\n                self.status_code = 206"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a cookie in the response headers.", "response": "def set_cookie(  # type: ignore\n            self,\n            key: str,\n            value: AnyStr='',\n            max_age: Optional[Union[int, timedelta]]=None,\n            expires: Optional[datetime]=None,\n            path: str='/',\n            domain: Optional[str]=None,\n            secure: bool=False,\n            httponly: bool=False,\n    ) -> None:\n        \"\"\"Set a cookie in the response headers.\n\n        The arguments are the standard cookie morsels and this is a\n        wrapper around the stdlib SimpleCookie code.\n        \"\"\"\n        if isinstance(value, bytes):\n            value = value.decode()  # type: ignore\n        cookie = create_cookie(key, value, max_age, expires, path, domain, secure, httponly)  # type: ignore  # noqa: E501\n        self.headers.add('Set-Cookie', cookie.output(header=''))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_cookie(self, key: str, path: str='/', domain: Optional[str]=None) -> None:\n        self.set_cookie(key, expires=datetime.utcnow(), max_age=0, path=path, domain=domain)", "response": "Delete a cookie (set to expire immediately)."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match(self, path: str) -> Tuple[Optional[Dict[str, Any]], bool]:\n        match = self._pattern.match(path)\n        if match is not None:\n            # If the route is a branch (not leaf) and the path is\n            # missing a trailing slash then it needs one to be\n            # considered a match in the strict slashes mode.\n            needs_slash = (\n                self.strict_slashes and not self.is_leaf and match.groupdict()['__slash__'] != '/'\n            )\n            try:\n                converted_varaibles = {\n                    name: self._converters[name].to_python(value)\n                    for name, value in match.groupdict().items()\n                    if name != '__slash__'\n                }\n            except ValidationError:  # Doesn't meet conversion rules, no match\n                return None, False\n            else:\n                return {**self.defaults, **converted_varaibles}, needs_slash\n        else:\n            return None, False", "response": "Check if the path matches this Rule."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef provides_defaults_for(self, rule: 'Rule', **values: Any) -> bool:\n        defaults_match = all(\n            values[key] == self.defaults[key] for key in self.defaults if key in values  # noqa: S101, E501\n        )\n        return self != rule and bool(self.defaults) and defaults_match", "response": "Returns true if this rule provides defaults for the argument and values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding this rule into a path using the values given.", "response": "def build(self, **values: Any) -> str:\n        \"\"\"Build this rule into a path using the values given.\"\"\"\n        converted_values = {\n            key: self._converters[key].to_url(value)\n            for key, value in values.items()\n            if key in self._converters\n        }\n        result = self._builder.format(**converted_values).split('|', 1)[1]\n        query_string = urlencode(\n            {\n                key: value\n                for key, value in values.items()\n                if key not in self._converters and key not in self.defaults\n            },\n            doseq=True,\n        )\n        if query_string:\n            result = \"{}?{}\".format(result, query_string)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef buildable(self, values: Optional[dict]=None, method: Optional[str]=None) -> bool:\n        if method is not None and method not in self.methods:\n            return False\n        defaults_match = all(\n            values[key] == self.defaults[key] for key in self.defaults if key in values  # noqa: S101, E501\n        )\n        return defaults_match and set(values.keys()) >= set(self._converters.keys())", "response": "Return True if this rule can build with the values and method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbinds the Rule to a Map and compile it.", "response": "def bind(self, map: Map) -> None:\n        \"\"\"Bind the Rule to a Map and compile it.\"\"\"\n        if self.map is not None:\n            raise RuntimeError(f\"{self!r} is already bound to {self.map!r}\")\n\n        self.map = map\n\n        pattern = ''\n        builder = ''\n        full_rule = \"{}\\\\|{}\".format(self.host or '', self.rule)\n        for part in _parse_rule(full_rule):\n            if isinstance(part, VariablePart):\n                converter = self.map.converters[part.converter](\n                    *part.arguments[0], **part.arguments[1],\n                )\n                pattern += f\"(?P<{part.name}>{converter.regex})\"\n                self._converters[part.name] = converter\n                builder += '{' + part.name + '}'\n                self._weights.append(WeightedPart(True, converter.weight))\n            else:\n                builder += part\n                pattern += part\n                self._weights.append(WeightedPart(False, -len(part)))\n        if not self.is_leaf or not self.strict_slashes:\n            # Pattern should match with or without a trailing slash\n            pattern = f\"{pattern.rstrip('/')}(?<!/)(?P<__slash__>/?)$\"\n        else:\n            pattern = f\"{pattern}$\"\n        self._pattern = re.compile(pattern)\n        self._builder = builder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_key(self) -> Tuple[bool, bool, int, List[WeightedPart]]:\n        if self.map is None:\n            raise RuntimeError(f\"{self!r} is not bound to a Map\")\n        complex_rule = any(weight.converter for weight in self._weights)\n        return (not bool(self.defaults), complex_rule, -len(self._weights), self._weights)", "response": "A key that can be used to sort the rules by weight."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_key(self) -> Tuple[bool, int]:\n        if self.map is None:\n            raise RuntimeError(f\"{self!r} is not bound to a Map\")\n        return (not bool(self.defaults), -sum(1 for weight in self._weights if weight.converter))", "response": "A key to sort the rules by weight for building."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a crop of img based on a sequence number tile_number.", "response": "def get_tile(tile_number):\n    \"\"\"\n    Returns a crop of `img` based on a sequence number `tile_number`.\n\n    :param int tile_number: Number of the tile between 0 and `max_tiles`^2.\n    :raises TileOutOfBoundsError: When `tile_number` exceeds `max_tiles`^2\n    :rtype PIL.Image:\n    \"\"\"\n    tile_number = int(tile_number)\n    max_tiles = app.max_tiles\n    if tile_number > max_tiles * max_tiles:\n        raise TileOutOfBoundsError('Requested an out of bounds tile')\n\n    tile_size = Point(\n        app.img.size[0] // max_tiles, app.img.size[1] // max_tiles)\n    tile_coords = Point(\n        tile_number % max_tiles, tile_number // max_tiles)\n    crop_box = (\n        tile_coords.x * tile_size.x,\n        tile_coords.y * tile_size.y,\n        tile_coords.x * tile_size.x + tile_size.x,\n        tile_coords.y * tile_size.y + tile_size.y,\n    )\n    return app.img.crop(crop_box)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def tile(tile_number):\n    try:\n        tile = get_tile(tile_number)\n    except TileOutOfBoundsError:\n        abort(404)\n\n    buf = BytesIO(tile.tobytes())\n    tile.save(buf, 'JPEG')\n\n    content = buf.getvalue()\n    response = await make_response(content)\n    response.headers['Content-Type'] = 'image/jpg'\n    response.headers['Accept-Ranges'] = 'bytes'\n    response.headers['Content-Length'] = str(len(content))\n    return response", "response": "Handles GET requests for a tile number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_json(self) -> bool:\n        content_type = self.mimetype\n        if content_type == 'application/json' or (\n                content_type.startswith('application/') and content_type.endswith('+json')\n        ):\n            return True\n        else:\n            return False", "response": "Returns True if the content_type is json like."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the body data as JSON and returns it.", "response": "async def get_json(\n        self, force: bool=False, silent: bool=False, cache: bool=True,\n    ) -> Any:\n        \"\"\"Parses the body data as JSON and returns it.\n\n        Arguments:\n            force: Force JSON parsing even if the mimetype is not JSON.\n            silent: Do not trigger error handling if parsing fails, without\n                this the :meth:`on_json_loading_failed` will be called on\n                error.\n            cache: Cache the parsed JSON on this request object.\n        \"\"\"\n        if cache and self._cached_json is not sentinel:\n            return self._cached_json\n\n        if not (force or self.is_json):\n            return None\n\n        data = await self._load_json_data()\n        try:\n            result = loads(data)\n        except ValueError as error:\n            if silent:\n                result = None\n            else:\n                self.on_json_loading_failed(error)\n        if cache:\n            self._cached_json = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the mimetype to the value.", "response": "def mimetype(self, value: str) -> None:\n        \"\"\"Set the mimetype to the value.\"\"\"\n        if (\n                value.startswith('text/') or value == 'application/xml' or\n                (value.startswith('application/') and value.endswith('+xml'))\n        ):\n            mimetype = f\"{value}; charset={self.charset}\"\n        else:\n            mimetype = value\n        self.headers['Content-Type'] = mimetype"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blueprint(self) -> Optional[str]:\n        if self.endpoint is not None and '.' in self.endpoint:\n            return self.endpoint.rsplit('.', 1)[0]\n        else:\n            return None", "response": "Returns the blueprint the matched endpoint belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the base url without query string and fragments.", "response": "def base_url(self) -> str:\n        \"\"\"Returns the base url without query string or fragments.\"\"\"\n        return urlunparse(ParseResult(self.scheme, self.host, self.path, '', '', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the full url requested.", "response": "def url(self) -> str:\n        \"\"\"Returns the full url requested.\"\"\"\n        return urlunparse(\n            ParseResult(\n                self.scheme, self.host, self.path, '', self.query_string.decode('ascii'), '',\n            ),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cookies(self) -> Dict[str, str]:\n        cookies = SimpleCookie()\n        cookies.load(self.headers.get('Cookie', ''))\n        return {key: cookie.value for key, cookie in cookies.items()}", "response": "The parsed cookies attached to this request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the configuration from an environment variable.", "response": "def from_envvar(self, variable_name: str, silent: bool=False) -> None:\n        \"\"\"Load the configuration from a location specified in the environment.\n\n        This will load a cfg file using :meth:`from_pyfile` from the\n        location specified in the environment, for example the two blocks\n        below are equivalent.\n\n        .. code-block:: python\n\n            app.config.from_envvar('CONFIG')\n\n        .. code-block:: python\n\n            filename = os.environ['CONFIG']\n            app.config.from_pyfile(filename)\n        \"\"\"\n        value = os.environ.get(variable_name)\n        if value is None and not silent:\n            raise RuntimeError(\n                f\"Environment variable {variable_name} is not present, cannot load config\",\n            )\n        return self.from_pyfile(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the configuration from a Python cfg file.", "response": "def from_pyfile(self, filename: str, silent: bool=False) -> None:\n        \"\"\"Load the configuration from a Python cfg or py file.\n\n        See Python's ConfigParser docs for details on the cfg format.\n        It is a common practice to load the defaults from the source\n        using the :meth:`from_object` and then override with a cfg or\n        py file, for example\n\n        .. code-block:: python\n\n            app.config.from_object('config_module')\n            app.config.from_pyfile('production.cfg')\n\n        Arguments:\n            filename: The filename which when appended to\n                :attr:`root_path` gives the path to the file\n\n        \"\"\"\n        file_path = self.root_path / filename\n        try:\n            spec = importlib.util.spec_from_file_location(\"module.name\", file_path)  # type: ignore\n            if spec is None:  # Likely passed a cfg file\n                parser = ConfigParser()\n                parser.optionxform = str  # type: ignore # Prevents lowercasing of keys\n                with open(file_path) as file_:\n                    config_str = '[section]\\n' + file_.read()\n                parser.read_string(config_str)\n                self.from_mapping(parser['section'])\n            else:\n                module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(module)  # type: ignore\n                self.from_object(module)\n        except (FileNotFoundError, IsADirectoryError):\n            if not silent:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the configuration from a Python object.", "response": "def from_object(self, instance: Union[object, str]) -> None:\n        \"\"\"Load the configuration from a Python object.\n\n        This can be used to reference modules or objects within\n        modules for example,\n\n        .. code-block:: python\n\n            app.config.from_object('module')\n            app.config.from_object('module.instance')\n            from module import instance\n            app.config.from_object(instance)\n\n        are valid.\n\n        Arguments:\n            instance: Either a str referencing a python object or the\n                object itself.\n\n        \"\"\"\n        if isinstance(instance, str):\n            try:\n                path, config = instance.rsplit('.', 1)\n            except ValueError:\n                path = instance\n                instance = importlib.import_module(path)\n            else:\n                module = importlib.import_module(path)\n                instance = getattr(module, config)\n\n        for key in dir(instance):\n            if key.isupper():\n                self[key] = getattr(instance, key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_json(self, filename: str, silent: bool=False) -> None:\n        file_path = self.root_path / filename\n        try:\n            with open(file_path) as file_:\n                data = json.loads(file_.read())\n        except (FileNotFoundError, IsADirectoryError):\n            if not silent:\n                raise\n        else:\n            self.from_mapping(data)", "response": "Load the configuration values from a JSON formatted file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the configuration values from a mapping object.", "response": "def from_mapping(self, mapping: Optional[Mapping[str, Any]]=None, **kwargs: Any) -> None:\n        \"\"\"Load the configuration values from a mapping.\n\n        This allows either a mapping to be directly passed or as\n        keyword arguments, for example,\n\n        .. code-block:: python\n\n            config = {'FOO': 'bar'}\n            app.config.from_mapping(config)\n            app.config.form_mapping(FOO='bar')\n\n        Arguments:\n            mapping: Optionally a mapping object.\n            kwargs: Optionally a collection of keyword arguments to\n                form a mapping.\n        \"\"\"\n        mappings: Dict[str, Any] = {}\n        if mapping is not None:\n            mappings.update(mapping)\n        mappings.update(kwargs)\n        for key, value in mappings.items():\n            if key.isupper():\n                self[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_namespace(\n            self,\n            namespace: str,\n            lowercase: bool=True,\n            trim_namespace: bool=True,\n    ) -> Dict[str, Any]:\n        \"\"\"Return a dictionary of keys within a namespace.\n\n        A namespace is considered to be a key prefix, for example the\n        keys ``FOO_A, FOO_BAR, FOO_B`` are all within the ``FOO``\n        namespace. This method would return a dictionary with these\n        keys and values present.\n\n        .. code-block:: python\n\n            config = {'FOO_A': 'a', 'FOO_BAR': 'bar', 'BAR': False}\n            app.config.from_mapping(config)\n            assert app.config.get_namespace('FOO_') == {'a': 'a', 'bar': 'bar'}\n\n        Arguments:\n            namespace: The namespace itself (should be uppercase).\n            lowercase: Lowercase the keys in the returned dictionary.\n            trim_namespace: Remove the namespace from the returned\n                keys.\n        \"\"\"\n        config = {}\n        for key, value in self.items():\n            if key.startswith(namespace):\n                if trim_namespace:\n                    new_key = key[len(namespace):]\n                else:\n                    new_key = key\n                if lowercase:\n                    new_key = new_key.lower()\n                config[new_key] = value\n        return config", "response": "Return a dictionary of keys within a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def make_response(*args: Any) -> Response:\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n\n    return await current_app.make_response(args)", "response": "Create a response a simple wrapper function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the flashed messages stored in the session.", "response": "def get_flashed_messages(\n        with_categories: bool=False,\n        category_filter: List[str]=[],\n) -> Union[List[str], List[Tuple[str, str]]]:\n    \"\"\"Retrieve the flashed messages stored in the session.\n\n    This is mostly useful in templates where it is exposed as a global\n    function, for example\n\n    .. code-block:: html+jinja\n\n        <ul>\n        {% for message in get_flashed_messages() %}\n          <li>{{ message }}</li>\n        {% endfor %}\n        </ul>\n\n    Note that caution is required for usage of ``category_filter`` as\n    all messages will be popped, but only those matching the filter\n    returned. See :func:`~quart.helpers.flash` for message creation.\n    \"\"\"\n    flashes = session.pop('_flashes') if '_flashes' in session else []\n    if category_filter:\n        flashes = [flash for flash in flashes if flash[0] in category_filter]\n    if not with_categories:\n        flashes = [flash[1] for flash in flashes]\n    return flashes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the url for a specific endpoint.", "response": "def url_for(\n        endpoint: str,\n        *,\n        _anchor: Optional[str]=None,\n        _external: Optional[bool]=None,\n        _method: Optional[str]=None,\n        _scheme: Optional[str]=None,\n        **values: Any,\n) -> str:\n    \"\"\"Return the url for a specific endpoint.\n\n    This is most useful in templates and redirects to create a URL\n    that can be used in the browser.\n\n    Arguments:\n        endpoint: The endpoint to build a url for, if prefixed with\n            ``.`` it targets endpoint's in the current blueprint.\n        _anchor: Additional anchor text to append (i.e. #text).\n        _external: Return an absolute url for external (to app) usage.\n        _method: The method to consider alongside the endpoint.\n        _scheme: A specific scheme to use.\n        values: The values to build into the URL, as specified in\n            the endpoint rule.\n    \"\"\"\n    app_context = _app_ctx_stack.top\n    request_context = _request_ctx_stack.top\n\n    if request_context is not None:\n        url_adapter = request_context.url_adapter\n        if endpoint.startswith('.'):\n            if request.blueprint is not None:\n                endpoint = request.blueprint + endpoint\n            else:\n                endpoint = endpoint[1:]\n        if _external is None:\n            _external = False\n    elif app_context is not None:\n        url_adapter = app_context.url_adapter\n        if _external is None:\n            _external = True\n    else:\n        raise RuntimeError('Cannot create a url outside of an application context')\n\n    if url_adapter is None:\n        raise RuntimeError(\n            'Unable to create a url adapter, try setting the the SERVER_NAME config variable.'\n        )\n    if _scheme is not None and not _external:\n        raise ValueError('External must be True for scheme usage')\n\n    app_context.app.inject_url_defaults(endpoint, values)\n    try:\n        url = url_adapter.build(\n            endpoint, values, method=_method, scheme=_scheme, external=_external,\n        )\n    except BuildError as error:\n        return app_context.app.handle_url_build_error(error, endpoint, values)\n\n    if _anchor is not None:\n        quoted_anchor = quote(_anchor)\n        url = f\"{url}#{quoted_anchor}\"\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshare the current request context with a generator.", "response": "def stream_with_context(func: Callable) -> Callable:\n    \"\"\"Share the current request context with a generator.\n\n    This allows the request context to be accessed within a streaming\n    generator, for example,\n\n    .. code-block:: python\n\n        @app.route('/')\n        def index() -> AsyncGenerator[bytes, None]:\n            @stream_with_context\n            async def generator() -> bytes:\n                yield request.method.encode()\n                yield b' '\n                yield request.path.encode()\n\n            return generator()\n\n    \"\"\"\n    request_context = _request_ctx_stack.top.copy()\n\n    @wraps(func)\n    async def generator(*args: Any, **kwargs: Any) -> Any:\n        async with request_context:\n            async for data in func(*args, **kwargs):\n                yield data\n    return generator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding packages install prefix and it s containing Folder", "response": "def find_package(name: str) -> Tuple[Optional[Path], Path]:\n    \"\"\"Finds packages install prefix (or None) and it's containing Folder\n    \"\"\"\n    module = name.split(\".\")[0]\n    loader = pkgutil.get_loader(module)\n    if name == \"__main__\" or loader is None:\n        package_path = Path.cwd()\n    else:\n        if hasattr(loader, 'get_filename'):\n            filename = loader.get_filename(module)  # type: ignore\n        else:\n            __import__(name)\n            filename = sys.modules[name].__file__\n        package_path = Path(filename).resolve().parent\n        if hasattr(loader, 'is_package'):\n            is_package = loader.is_package(module)  # type: ignore\n            if is_package:\n                package_path = Path(package_path).resolve().parent\n    sys_prefix = Path(sys.prefix).resolve()\n    try:\n        package_path.relative_to(sys_prefix)\n    except ValueError:\n        return None, package_path\n    else:\n        return sys_prefix, package_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_from_directory(\n        directory: FilePath,\n        file_name: str,\n        *,\n        mimetype: Optional[str]=None,\n        as_attachment: bool=False,\n        attachment_filename: Optional[str]=None,\n        add_etags: bool=True,\n        cache_timeout: Optional[int]=None,\n        conditional: bool=True,\n        last_modified: Optional[datetime]=None,\n) -> Response:\n    \"\"\"Send a file from a given directory.\n\n    Arguments:\n       directory: Directory that when combined with file_name gives\n           the file path.\n       file_name: File name that when combined with directory gives\n           the file path.\n       See :func:`send_file` for the other arguments.\n    \"\"\"\n    file_path = safe_join(directory, file_name)\n    if not file_path.is_file():\n        raise NotFound()\n    return await send_file(\n        file_path,\n        mimetype=mimetype,\n        as_attachment=as_attachment,\n        attachment_filename=attachment_filename,\n        add_etags=add_etags,\n        cache_timeout=cache_timeout,\n        conditional=conditional,\n        last_modified=last_modified,\n    )", "response": "Send a file from a given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_file(\n        filename: FilePath,\n        mimetype: Optional[str]=None,\n        as_attachment: bool=False,\n        attachment_filename: Optional[str]=None,\n        add_etags: bool=True,\n        cache_timeout: Optional[int]=None,\n        conditional: bool=False,\n        last_modified: Optional[datetime]=None,\n) -> Response:\n    \"\"\"Return a Reponse to send the filename given.\n\n    Arguments:\n        filename: The filename (path) to send, remember to use\n            :func:`safe_join`.\n        mimetype: Mimetype to use, by default it will be guessed or\n            revert to the DEFAULT_MIMETYPE.\n        as_attachment: If true use the attachment filename in a\n            Content-Disposition attachment header.\n        attachment_filename: Name for the filename, if it differs\n        add_etags: Set etags based on the filename, size and\n            modification time.\n        last_modified: Used to override the last modified value.\n        cache_timeout: Time in seconds for the response to be cached.\n\n    \"\"\"\n    file_path = file_path_to_path(filename)\n    if attachment_filename is None:\n        attachment_filename = file_path.name\n    if mimetype is None:\n        mimetype = mimetypes.guess_type(attachment_filename)[0] or DEFAULT_MIMETYPE\n    file_body = current_app.response_class.file_body_class(file_path)\n    response = current_app.response_class(file_body, mimetype=mimetype)\n\n    if as_attachment:\n        response.headers.add('Content-Disposition', 'attachment', filename=attachment_filename)\n\n    if last_modified is not None:\n        response.last_modified = last_modified\n    else:\n        response.last_modified = datetime.fromtimestamp(file_path.stat().st_mtime)\n\n    response.cache_control.public = True\n    cache_timeout = cache_timeout or current_app.get_send_file_max_age(file_path)\n    if cache_timeout is not None:\n        response.cache_control.max_age = cache_timeout\n        response.expires = datetime.utcnow() + timedelta(seconds=cache_timeout)\n\n    if add_etags:\n        response.set_etag(\n            '{}-{}-{}'.format(\n                file_path.stat().st_mtime, file_path.stat().st_size,\n                adler32(bytes(file_path)),\n            ),\n        )\n\n    if conditional:\n        await response.make_conditional(request.range)\n    return response", "response": "Send a file to the ACS."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_resource(self, path: FilePath, mode: str='rb') -> IO[AnyStr]:\n        if mode not in {'r', 'rb'}:\n            raise ValueError('Files can only be opened for reading')\n        return open(self.root_path / file_path_to_path(path), mode)", "response": "Open a file for reading."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spinner(self, spinner=None):\n\n        self._spinner = self._get_spinner(spinner)\n        self._frame_index = 0\n        self._text_index = 0", "response": "Setter for spinner property."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef placement(self, placement):\n        if placement not in self.SPINNER_PLACEMENTS:\n            raise ValueError(\n                \"Unknown spinner placement '{0}', available are {1}\".format(placement, self.SPINNER_PLACEMENTS))\n        self._placement = placement", "response": "Setter for placement property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef animation(self, animation):\n        self._animation = animation\n        self._text = self._get_text(self._text['original'])", "response": "Setter for animation property."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting spinner value from options and returns value containing frames and interval defining spinner.", "response": "def _get_spinner(self, spinner):\n        \"\"\"Extracts spinner value from options and returns value\n        containing spinner frames and interval, defaults to 'dots' spinner.\n        Parameters\n        ----------\n        spinner : dict, str\n            Contains spinner value or type of spinner to be used\n        Returns\n        -------\n        dict\n            Contains frames and interval defining spinner\n        \"\"\"\n        default_spinner = Spinners['dots'].value\n\n        if spinner and type(spinner) == dict:\n            return spinner\n\n        if is_supported():\n            if all([is_text_type(spinner), spinner in Spinners.__members__]):\n                return Spinners[spinner].value\n            else:\n                return default_spinner\n        else:\n            return Spinners['line'].value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_text(self, text):\n        animation = self._animation\n        stripped_text = text.strip()\n\n        # Check which frame of the animation is the widest\n        max_spinner_length = max([len(i) for i in self._spinner['frames']])\n\n        # Subtract to the current terminal size the max spinner length\n        # (-1 to leave room for the extra space between spinner and text)\n        terminal_width = get_terminal_columns() - max_spinner_length - 1\n        text_length = len(stripped_text)\n\n        frames = []\n\n        if terminal_width < text_length and animation:\n            if animation == 'bounce':\n                \"\"\"\n                Make the text bounce back and forth\n                \"\"\"\n                for x in range(0, text_length - terminal_width + 1):\n                    frames.append(stripped_text[x:terminal_width + x])\n                frames.extend(list(reversed(frames)))\n            elif 'marquee':\n                \"\"\"\n                Make the text scroll like a marquee\n                \"\"\"\n                stripped_text = stripped_text + ' ' + stripped_text[:terminal_width]\n                for x in range(0, text_length + 1):\n                    frames.append(stripped_text[x:terminal_width + x])\n        elif terminal_width < text_length and not animation:\n            # Add ellipsis if text is larger than terminal width and no animation was specified\n            frames = [stripped_text[:terminal_width - 6] + ' (...)']\n        else:\n            frames = [stripped_text]\n\n        return {\n            'original': text,\n            'frames': frames\n        }", "response": "Creates the frames based on the selected animation and the text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self):\n        if not self._enabled:\n            return self\n\n        self._stream.write('\\r')\n        self._stream.write(self.CLEAR_LINE)\n\n        return self", "response": "Clears the line and returns the cursor to the start."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _render_frame(self):\n        frame = self.frame()\n        output = '\\r{0}'.format(frame)\n        self.clear()\n        try:\n            self._stream.write(output)\n        except UnicodeEncodeError:\n            self._stream.write(encode_utf_8_text(output))", "response": "Renders the frame on the line after clearing it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self):\n        while not self._stop_spinner.is_set():\n            self._render_frame()\n            time.sleep(0.001 * self._interval)\n\n        return self", "response": "Runs the render until the stop_spinner flag is set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild and returns the frame to be rendered", "response": "def frame(self):\n        \"\"\"Builds and returns the frame to be rendered\n        Returns\n        -------\n        self\n        \"\"\"\n        frames = self._spinner['frames']\n        frame = frames[self._frame_index]\n\n        if self._color:\n            frame = colored_frame(frame, self._color)\n\n        self._frame_index += 1\n        self._frame_index = self._frame_index % len(frames)\n\n        text_frame = self.text_frame()\n        return u'{0} {1}'.format(*[\n            (text_frame, frame)\n            if self._placement == 'right' else\n            (frame, text_frame)\n        ][0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding and returns the text frame to be rendered by the user.", "response": "def text_frame(self):\n        \"\"\"Builds and returns the text frame to be rendered\n        Returns\n        -------\n        self\n        \"\"\"\n        if len(self._text['frames']) == 1:\n            if self._text_color:\n                return colored_frame(self._text['frames'][0], self._text_color)\n\n            # Return first frame (can't return original text because at this point it might be ellipsed)\n            return self._text['frames'][0]\n\n        frames = self._text['frames']\n        frame = frames[self._text_index]\n\n        self._text_index += 1\n        self._text_index = self._text_index % len(frames)\n\n        if self._text_color:\n            return colored_frame(frame, self._text_color)\n\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self, text=None):\n        if text is not None:\n            self.text = text\n\n        if not self._enabled or self._spinner_id is not None:\n            return self\n\n        if self._stream.isatty():\n            cursor.hide(stream=self._stream)\n\n        self._stop_spinner = threading.Event()\n        self._spinner_thread = threading.Thread(target=self.render)\n        self._spinner_thread.setDaemon(True)\n        self._render_frame()\n        self._spinner_id = self._spinner_thread.name\n        self._spinner_thread.start()\n\n        return self", "response": "Starts the spinner on a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self):\n        if not self._enabled:\n            return self\n\n        if self._spinner_thread:\n            self._stop_spinner.set()\n            self._spinner_thread.join()\n\n        self._frame_index = 0\n        self._spinner_id = None\n        self.clear()\n\n        if self._stream.isatty():\n            cursor.show(stream=self._stream)\n\n        return self", "response": "Stops the spinner and clears the line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing and persists a success log symbol and text and exits.", "response": "def succeed(self, text=None):\n        \"\"\"Shows and persists success symbol and text and exits.\n        Parameters\n        ----------\n        text : None, optional\n            Text to be shown alongside success symbol.\n        Returns\n        -------\n        self\n        \"\"\"\n        return self.stop_and_persist(symbol=LogSymbols.SUCCESS.value, text=text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fail(self, text=None):\n        return self.stop_and_persist(symbol=LogSymbols.ERROR.value, text=text)", "response": "Shows and persists fail symbol and text and exits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow and persists a warning symbol and text and exits.", "response": "def warn(self, text=None):\n        \"\"\"Shows and persists warn symbol and text and exits.\n        Parameters\n        ----------\n        text : None, optional\n            Text to be shown alongside warn symbol.\n        Returns\n        -------\n        self\n        \"\"\"\n        return self.stop_and_persist(symbol=LogSymbols.WARNING.value, text=text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow and persists info symbol and text and exits.", "response": "def info(self, text=None):\n        \"\"\"Shows and persists info symbol and text and exits.\n        Parameters\n        ----------\n        text : None, optional\n            Text to be shown alongside info symbol.\n        Returns\n        -------\n        self\n        \"\"\"\n        return self.stop_and_persist(symbol=LogSymbols.INFO.value, text=text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop_and_persist(self, symbol=' ', text=None):\n        if not self._enabled:\n            return self\n\n        symbol = decode_utf_8_text(symbol)\n\n        if text is not None:\n            text = decode_utf_8_text(text)\n        else:\n            text = self._text['original']\n\n        text = text.strip()\n\n        if self._text_color:\n            text = colored_frame(text, self._text_color)\n\n        self.stop()\n\n        output = u'{0} {1}\\n'.format(*[\n            (text, symbol)\n            if self._placement == 'right' else\n            (symbol, text)\n        ][0])\n\n        try:\n            self._stream.write(output)\n        except UnicodeEncodeError:\n            self._stream.write(encode_utf_8_text(output))\n\n        return self", "response": "Stops the spinner and persists the final frame to be shown."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if given parameter is a string or not", "response": "def is_text_type(text):\n    \"\"\"Check if given parameter is a string or not\n\n    Parameters\n    ----------\n    text : *\n        Parameter to be checked for text type\n\n    Returns\n    -------\n    bool\n        Whether parameter is a string or not\n    \"\"\"\n    if isinstance(text, six.text_type) or isinstance(text, six.string_types):\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the spinner and persists the final frame to be shown.", "response": "def stop_and_persist(self, symbol=' ', text=None):\n        \"\"\"Stops the spinner and persists the final frame to be shown.\n        Parameters\n        ----------\n        symbol : str, optional\n            Symbol to be shown in final frame\n        text: str, optional\n            Text to be shown in final frame\n\n        Returns\n        -------\n        self\n        \"\"\"\n        if not self._enabled:\n            return self\n\n        symbol = decode_utf_8_text(symbol)\n\n        if text is not None:\n            text = decode_utf_8_text(text)\n        else:\n            text = self._text['original']\n\n        text = text.strip()\n\n        if self._text_color:\n            text = colored_frame(text, self._text_color)\n\n        self.stop()\n\n        output = '\\r{0} {1}\\n'.format(*[\n            (text, symbol)\n            if self._placement == 'right' else\n            (symbol, text)\n        ][0])\n\n        with self.output:\n            self.output.outputs = self._output(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_stateless_by_name(name):\n    '''\n    Find stateless app given its name\n\n    First search the Django ORM, and if not found then look the app up in a local registry.\n    If the app does not have an ORM entry then a StatelessApp model instance is created.\n    '''\n    try:\n        dsa_app = StatelessApp.objects.get(app_name=name) # pylint: disable=no-member\n        return dsa_app.as_dash_app()\n    except: # pylint: disable=bare-except\n        pass\n\n    dash_app = get_stateless_by_name(name)\n    dsa_app = StatelessApp(app_name=name)\n    dsa_app.save()\n    return dash_app", "response": "Find stateless app given its name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_dash_app(self):\n        '''\n        Return a DjangoDash instance of the dash application\n        '''\n        dateless_dash_app = getattr(self, '_stateless_dash_app_instance', None)\n        if not dateless_dash_app:\n            dateless_dash_app = get_stateless_by_name(self.app_name)\n            setattr(self, '_stateless_dash_app_instance', dateless_dash_app)\n        return dateless_dash_app", "response": "Return a DjangoDash instance of the dash application that is the same as the one in the project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking to see if the current hydrated state and the saved state are different.", "response": "def handle_current_state(self):\n        '''\n        Check to see if the current hydrated state and the saved state are different.\n\n        If they are, then persist the current state in the database by saving the model instance.\n        '''\n        if getattr(self, '_current_state_hydrated_changed', False) and self.save_on_change:\n            new_base_state = json.dumps(getattr(self, '_current_state_hydrated', {}))\n            if new_base_state != self.base_state:\n                self.base_state = new_base_state\n                self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef have_current_state_entry(self, wid, key):\n        'Return True if there is a cached current state for this app'\n        cscoll = self.current_state()\n        c_state = cscoll.get(wid, {})\n        return key in c_state", "response": "Return True if there is a cached current state for this app"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the current state of a key associated with key with a new value associated with key MimeType.", "response": "def update_current_state(self, wid, key, value):\n        '''\n        Update current state with a (possibly new) value associated with key\n\n        If the key does not represent an existing entry, then ignore it\n        '''\n        cscoll = self.current_state()\n        c_state = cscoll.get(wid, {})\n        if key in c_state:\n            current_value = c_state.get(key, None)\n            if current_value != value:\n                c_state[key] = value\n                setattr(self, '_current_state_hydrated_changed', True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the current state of the current instance.", "response": "def current_state(self):\n        '''\n        Return the current internal state of the model instance.\n\n        This is not necessarily the same as the persisted state\n        stored in the self.base_state variable.\n        '''\n        c_state = getattr(self, '_current_state_hydrated', None)\n        if not c_state:\n            c_state = json.loads(self.base_state)\n            setattr(self, '_current_state_hydrated', c_state)\n            setattr(self, '_current_state_hydrated_changed', False)\n        return c_state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dash application instance for this model instance", "response": "def as_dash_instance(self, cache_id=None):\n        'Return a dash application instance for this model instance'\n        dash_app = self.stateless_app.as_dash_app() # pylint: disable=no-member\n        base = self.current_state()\n        return dash_app.do_form_dash_instance(replacements=base,\n                                              specific_identifier=self.slug,\n                                              cache_id=cache_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the base state of the object as defined by the app. layout code as a python dict", "response": "def _get_base_state(self):\n        '''\n        Get the base state of the object, as defined by the app.layout code, as a python dict\n        '''\n        base_app_inst = self.stateless_app.as_dash_app().as_dash_instance() # pylint: disable=no-member\n\n        # Get base layout response, from a base object\n        base_resp = base_app_inst.locate_endpoint_function('dash-layout')()\n\n        base_obj = json.loads(base_resp.data.decode('utf-8'))\n\n        # Walk the base layout and find all values; insert into base state map\n        obj = {}\n        base_app_inst.walk_tree_and_extract(base_obj, obj)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npopulates the base state with the values from the underlying dash layout configuration", "response": "def populate_values(self):\n        '''\n        Add values from the underlying dash layout configuration\n        '''\n        obj = self._get_base_state()\n        self.base_state = json.dumps(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlocate a dash application given either the the slug of an instance or the name for a stateless app", "response": "def locate_item(ident, stateless=False, cache_id=None):\n        '''Locate a dash application, given either the\n        slug of an instance or the name for a stateless app'''\n        if stateless:\n            dash_app = find_stateless_by_name(ident)\n        else:\n            dash_app = get_object_or_404(DashApp, slug=ident)\n\n        app = dash_app.as_dash_instance(cache_id=cache_id)\n        return dash_app, app"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_to_pipe_channel(channel_name,\n                         label,\n                         value):\n    'Send message through pipe to client component'\n    async_to_sync(async_send_to_pipe_channel)(channel_name=channel_name,\n                                              label=label,\n                                              value=value)", "response": "Send message through pipe to client component"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def async_send_to_pipe_channel(channel_name,\n                                     label,\n                                     value):\n    'Send message asynchronously through pipe to client component'\n    pcn = _form_pipe_channel_name(channel_name)\n\n    channel_layer = get_channel_layer()\n    await channel_layer.group_send(pcn,\n                                   {\"type\":\"pipe.value\",\n                                    \"label\":label,\n                                    \"value\":value})", "response": "Send message asynchronously through pipe to client component"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pipe_value(self, message):\n        'Send a new value into the ws pipe'\n        jmsg = json.dumps(message)\n        self.send(jmsg)", "response": "Send a new value into the ws pipe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate this consumer to listen on channel_name for the js widget associated with uid", "response": "def update_pipe_channel(self, uid, channel_name, label): # pylint: disable=unused-argument\n        '''\n        Update this consumer to listen on channel_name for the js widget associated with uid\n        '''\n        pipe_group_name = _form_pipe_channel_name(channel_name)\n\n        if self.channel_layer:\n            current = self.channel_maps.get(uid, None)\n            if current != pipe_group_name:\n                if current:\n                    async_to_sync(self.channel_layer.group_discard)(current, self.channel_name)\n\n                self.channel_maps[uid] = pipe_group_name\n                async_to_sync(self.channel_layer.group_add)(pipe_group_name, self.channel_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstoring initial arguments if any and return a cache identifier", "response": "def store_initial_arguments(request, initial_arguments=None):\n    'Store initial arguments, if any, and return a cache identifier'\n\n    if initial_arguments is None:\n        return None\n\n    # Generate a cache id\n    cache_id = \"dpd-initial-args-%s\" % str(uuid.uuid4()).replace('-', '')\n\n    # Store args in json form in cache\n    if initial_argument_location():\n        cache.set(cache_id, initial_arguments, cache_timeout_initial_arguments())\n    else:\n        request.session[cache_id] = initial_arguments\n\n    return cache_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_initial_arguments(request, cache_id=None):\n    'Extract initial arguments for the dash app'\n\n    if cache_id is None:\n        return None\n\n    if initial_argument_location():\n        return cache.get(cache_id)\n\n    return request.session[cache_id]", "response": "Extract initial arguments for the dash app"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the layout of the dash application", "response": "def layout(request, ident, stateless=False, cache_id=None, **kwargs):\n    'Return the layout of the dash application'\n    _, app = DashApp.locate_item(ident, stateless)\n\n    view_func = app.locate_endpoint_function('dash-layout')\n    resp = view_func()\n\n    initial_arguments = get_initial_arguments(request, cache_id)\n\n    response_data, mimetype = app.augment_initial_layout(resp, initial_arguments)\n    return HttpResponse(response_data,\n                        content_type=mimetype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating update json response", "response": "def update(request, ident, stateless=False, **kwargs):\n    'Generate update json response'\n    dash_app, app = DashApp.locate_item(ident, stateless)\n\n    request_body = json.loads(request.body.decode('utf-8'))\n\n    if app.use_dash_dispatch():\n        # Force call through dash\n        view_func = app.locate_endpoint_function('dash-update-component')\n\n        import flask\n        with app.test_request_context():\n            # Fudge request object\n            # pylint: disable=protected-access\n            flask.request._cached_json = (request_body, flask.request._cached_json[True])\n            resp = view_func()\n    else:\n        # Use direct dispatch with extra arguments in the argMap\n        app_state = request.session.get(\"django_plotly_dash\", dict())\n        arg_map = {'dash_app_id': ident,\n                   'dash_app': dash_app,\n                   'user': request.user,\n                   'session_state': app_state}\n        resp = app.dispatch_with_args(request_body, arg_map)\n        request.session['django_plotly_dash'] = app_state\n        dash_app.handle_current_state()\n\n    # Special for ws-driven edge case\n    if str(resp) == 'EDGECASEEXIT':\n        return HttpResponse(\"\")\n\n    # Change in returned value type\n    try:\n        rdata = resp.data\n        rtype = resp.mimetype\n    except:\n        rdata = resp\n        rtype = \"application/json\"\n\n    return HttpResponse(rdata,\n                        content_type=rtype)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main_view(request, ident, stateless=False, cache_id=None, **kwargs):\n    'Main view for a dash app'\n    _, app = DashApp.locate_item(ident, stateless, cache_id=cache_id)\n\n    view_func = app.locate_endpoint_function()\n    resp = view_func()\n    return HttpResponse(resp)", "response": "Main view for a dash app"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns part of a client - side component served locally for some reason", "response": "def component_component_suites(request, resource=None, component=None, **kwargs):\n    'Return part of a client-side component, served locally for some reason'\n    return component_suites(request,\n                            resource=resource,\n                            component=component,\n                            extra_element=\"_components/\",\n                            **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef component_suites(request, resource=None, component=None, extra_element=\"\", **kwargs):\n    'Return part of a client-side component, served locally for some reason'\n\n    get_params = request.GET.urlencode()\n    if get_params and False:\n        redone_url = \"/static/dash/component/%s/%s%s?%s\" %(component, extra_element, resource, get_params)\n    else:\n        redone_url = \"/static/dash/component/%s/%s%s\" %(component, extra_element, resource)\n\n    return HttpResponseRedirect(redirect_to=redone_url)", "response": "Return part of a client - side component served locally for some reason"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a local dash app asset served up through the Django static framework", "response": "def app_assets(request, **kwargs):\n    'Return a local dash app asset, served up through the Django static framework'\n    get_params = request.GET.urlencode()\n    extra_part = \"\"\n    if get_params:\n        redone_url = \"/static/dash/assets/%s?%s\" %(extra_part, get_params)\n    else:\n        redone_url = \"/static/dash/assets/%s\" % extra_part\n\n    return HttpResponseRedirect(redirect_to=redone_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_to_session(request, template_name=\"index.html\", **kwargs):\n    'Add some info to a session in a place that django-plotly-dash can pass to a callback'\n\n    django_plotly_dash = request.session.get(\"django_plotly_dash\", dict())\n\n    session_add_count = django_plotly_dash.get('add_counter', 0)\n    django_plotly_dash['add_counter'] = session_add_count + 1\n    request.session['django_plotly_dash'] = django_plotly_dash\n\n    return TemplateResponse(request, template_name, {})", "response": "Add some info to a session in a place that django - plotly - dash can pass to a callback"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef asset_redirection(request, path, ident=None, stateless=False, **kwargs):\n    'Redirect static assets for a component'\n\n    X, app = DashApp.locate_item(ident, stateless)\n\n    # Redirect to a location based on the import path of the module containing the DjangoDash app\n    static_path = X.get_asset_static_url(path)\n\n    return redirect(static_path)", "response": "Redirect static assets for a component"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef session_state_view(request, template_name, **kwargs):\n    'Example view that exhibits the use of sessions to store state'\n\n    session = request.session\n\n    demo_count = session.get('django_plotly_dash', {})\n\n    ind_use = demo_count.get('ind_use', 0)\n    ind_use += 1\n    demo_count['ind_use'] = ind_use\n\n    context = {'ind_use' : ind_use}\n\n    session['django_plotly_dash'] = demo_count\n\n    return render(request, template_name=template_name, context=context)", "response": "Example view that exhibits the use of sessions to store state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate placeholder magic strings and replace with content", "response": "def adjust_response(self, response):\n        'Locate placeholder magic strings and replace with content'\n\n        try:\n            c1 = self._replace(response.content,\n                               self.header_placeholder,\n                               self.embedded_holder.css)\n\n            response.content = self._replace(c1,\n                                             self.footer_placeholder,\n                                             \"\\n\".join([self.embedded_holder.config,\n                                                        self.embedded_holder.scripts]))\n        except AttributeError:\n            # Catch the \"FileResponse instance has no `content` attribute\" error when serving media files in the Django development server.\n            pass\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the output following a change of the input selection", "response": "def callback_c(*args, **kwargs):\n    'Update the output following a change of the input selection'\n    #da = kwargs['dash_app']\n\n    session_state = kwargs['session_state']\n\n    calls_so_far = session_state.get('calls_so_far', 0)\n    session_state['calls_so_far'] = calls_so_far + 1\n\n    user_counts = session_state.get('user_counts', None)\n    user_name = str(kwargs['user'])\n    if user_counts is None:\n        user_counts = {user_name:1}\n        session_state['user_counts'] = user_counts\n    else:\n        user_counts[user_name] = user_counts.get(user_name, 0) + 1\n\n    return \"Args are [%s] and kwargs are %s\" %(\",\".join(args), str(kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninputting app button pressed so do something interesting", "response": "def callback_liveIn_button_press(red_clicks, blue_clicks, green_clicks,\n                                 rc_timestamp, bc_timestamp, gc_timestamp, **kwargs): # pylint: disable=unused-argument\n    'Input app button pressed, so do something interesting'\n\n    if not rc_timestamp:\n        rc_timestamp = 0\n    if not bc_timestamp:\n        bc_timestamp = 0\n    if not gc_timestamp:\n        gc_timestamp = 0\n\n    if (rc_timestamp + bc_timestamp + gc_timestamp) < 1:\n        change_col = None\n        timestamp = 0\n    else:\n        if rc_timestamp > bc_timestamp:\n            change_col = \"red\"\n            timestamp = rc_timestamp\n        else:\n            change_col = \"blue\"\n            timestamp = bc_timestamp\n\n        if gc_timestamp > timestamp:\n            timestamp = gc_timestamp\n            change_col = \"green\"\n\n        value = {'red_clicks':red_clicks,\n                 'blue_clicks':blue_clicks,\n                 'green_clicks':green_clicks,\n                 'click_colour':change_col,\n                 'click_timestamp':timestamp,\n                 'user':str(kwargs.get('user', 'UNKNOWN'))}\n\n        send_to_pipe_channel(channel_name=\"live_button_counter\",\n                             label=\"named_counts\",\n                             value=value)\n    return \"Number of local clicks so far is %s red and %s blue; last change is %s at %s\" % (red_clicks,\n                                                                                             blue_clicks,\n                                                                                             change_col,\n                                                                                             datetime.fromtimestamp(0.001*timestamp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_liveOut_layout():\n    'Generate the layout per-app, generating each tine a new uuid for the state_uid argument'\n    return html.Div([\n        dpd.Pipe(id=\"named_count_pipe\",\n                 value=None,\n                 label=\"named_counts\",\n                 channel_name=\"live_button_counter\"),\n        html.Div(id=\"internal_state\",\n                 children=\"No state has been computed yet\",\n                 style={'display':'none'}),\n        dcc.Graph(id=\"timeseries_plot\"),\n        dcc.Input(value=str(uuid.uuid4()),\n                  id=\"state_uid\",\n                  style={'display':'none'},\n                 )\n        ])", "response": "Generate the layout per - app generating each tine a new uuid for the state_uid argument"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles something changing the value of the input pipe or the associated state uid", "response": "def callback_liveOut_pipe_in(named_count, state_uid, **kwargs):\n    'Handle something changing the value of the input pipe or the associated state uid'\n\n    cache_key = _get_cache_key(state_uid)\n    state = cache.get(cache_key)\n\n    # If nothing in cache, prepopulate\n    if not state:\n        state = {}\n\n    # Guard against missing input on startup\n    if not named_count:\n        named_count = {}\n\n    # extract incoming info from the message and update the internal state\n    user = named_count.get('user', None)\n    click_colour = named_count.get('click_colour', None)\n    click_timestamp = named_count.get('click_timestamp', 0)\n\n    if click_colour:\n        colour_set = state.get(click_colour, None)\n\n        if not colour_set:\n            colour_set = [(None, 0, 100) for i in range(5)]\n\n        _, last_ts, prev = colour_set[-1]\n\n        # Loop over all existing timestamps and find the latest one\n        if not click_timestamp or click_timestamp < 1:\n            click_timestamp = 0\n\n            for _, the_colour_set in state.items():\n                _, lts, _ = the_colour_set[-1]\n                if lts > click_timestamp:\n                    click_timestamp = lts\n\n            click_timestamp = click_timestamp + 1000\n\n        if click_timestamp > last_ts:\n            colour_set.append((user, click_timestamp, prev * random.lognormvariate(0.0, 0.1)),)\n            colour_set = colour_set[-100:]\n\n        state[click_colour] = colour_set\n        cache.set(cache_key, state, 3600)\n\n    return \"(%s,%s)\" % (cache_key, click_timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a timeseries from the internal state", "response": "def callback_show_timeseries(internal_state_string, state_uid, **kwargs):\n    'Build a timeseries from the internal state'\n\n    cache_key = _get_cache_key(state_uid)\n    state = cache.get(cache_key)\n\n    # If nothing in cache, prepopulate\n    if not state:\n        state = {}\n\n    colour_series = {}\n\n    colors = {'red':'#FF0000',\n              'blue':'#0000FF',\n              'green':'#00FF00',\n              'yellow': '#FFFF00',\n              'cyan': '#00FFFF',\n              'magenta': '#FF00FF',\n              'black' : '#000000',\n             }\n\n    for colour, values in state.items():\n        timestamps = [datetime.fromtimestamp(int(0.001*ts)) for _, ts, _ in values if ts > 0]\n        #users = [user for user, ts, _ in values if ts > 0]\n        levels = [level for _, ts, level in values if ts > 0]\n        if colour in colors:\n            colour_series[colour] = pd.Series(levels, index=timestamps).groupby(level=0).first()\n\n    df = pd.DataFrame(colour_series).fillna(method=\"ffill\").reset_index()[-25:]\n\n    traces = [go.Scatter(y=df[colour],\n                         x=df['index'],\n                         name=colour,\n                         line=dict(color=colors.get(colour, '#000000')),\n                        ) for colour in colour_series]\n\n    return {'data':traces,\n            #'layout': go.Layout\n           }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef session_demo_danger_callback(da_children, session_state=None, **kwargs):\n    'Update output based just on state'\n    if not session_state:\n        return \"Session state not yet available\"\n\n    return \"Session state contains: \" + str(session_state.get('bootstrap_demo_state', \"NOTHING\")) + \" and the page render count is \" + str(session_state.get(\"ind_use\", \"NOT SET\"))", "response": "Update output based just on state"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noutputs text based on both app state and session state", "response": "def session_demo_alert_callback(n_clicks, session_state=None, **kwargs):\n    'Output text based on both app state and session state'\n    if session_state is None:\n        raise NotImplementedError(\"Cannot handle a missing session state\")\n    csf = session_state.get('bootstrap_demo_state', None)\n    if not csf:\n        csf = dict(clicks=0)\n        session_state['bootstrap_demo_state'] = csf\n    else:\n        csf['clicks'] = n_clicks\n    return \"Button has been clicked %s times since the page was rendered\" %n_clicks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_usable_app(name, app):\n    'Add app to local registry by name'\n    name = slugify(name)\n    global usable_apps # pylint: disable=global-statement\n    usable_apps[name] = app\n    return name", "response": "Add app to local registry by name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbasing path name of this instance taking into account any state or statelessness", "response": "def get_base_pathname(self, specific_identifier, cache_id):\n        'Base path name of this instance, taking into account any state or statelessness'\n        if not specific_identifier:\n            app_pathname = \"%s:app-%s\"% (app_name, main_view_label)\n            ndid = self._uid\n        else:\n            app_pathname = \"%s:%s\" % (app_name, main_view_label)\n            ndid = specific_identifier\n\n        kwargs = {'ident': ndid}\n\n        if cache_id:\n            kwargs['cache_id'] = cache_id\n            app_pathname = app_pathname + \"--args\"\n\n        full_url = reverse(app_pathname, kwargs=kwargs)\n        if full_url[-1] != '/':\n            full_url = full_url + '/'\n        return ndid, full_url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_form_dash_instance(self, replacements=None, specific_identifier=None, cache_id=None):\n        'Perform the act of constructing a Dash instance taking into account state'\n\n        ndid, base_pathname = self.get_base_pathname(specific_identifier, cache_id)\n        return self.form_dash_instance(replacements, ndid, base_pathname)", "response": "Perform the act of constructing a Dash instance taking into account state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a Dash instance taking into account state", "response": "def form_dash_instance(self, replacements=None, ndid=None, base_pathname=None):\n        'Construct a Dash instance taking into account state'\n\n        if ndid is None:\n            ndid = self._uid\n\n        rd = WrappedDash(base_pathname=base_pathname,\n                         expanded_callbacks=self._expanded_callbacks,\n                         replacements=replacements,\n                         ndid=ndid,\n                         serve_locally=self._serve_locally)\n\n        rd.layout = self.layout\n        rd.config['suppress_callback_exceptions'] = self._suppress_callback_exceptions\n\n        for cb, func in self._callback_sets:\n            rd.callback(**cb)(func)\n        for s in self.css.items:\n            rd.css.append_css(s)\n        for s in self.scripts.items:\n            rd.scripts.append_script(s)\n\n        return rd"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callback(self, output, inputs=None, state=None, events=None):\n        'Form a callback function by wrapping, in the same way as the underlying Dash application would'\n        callback_set = {'output':output,\n                        'inputs':inputs and inputs or dict(),\n                        'state':state and state or dict(),\n                        'events':events and events or dict()}\n        def wrap_func(func, callback_set=callback_set, callback_sets=self._callback_sets): # pylint: disable=dangerous-default-value, missing-docstring\n            callback_sets.append((callback_set, func))\n            return func\n        return wrap_func", "response": "Form a callback function by wrapping in the same way as the underlying Dash application would"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expanded_callback(self, output, inputs=[], state=[], events=[]): # pylint: disable=dangerous-default-value\n        '''\n        Form an expanded callback.\n\n        This function registers the callback function, and sets an internal flag that mandates that all\n        callbacks are passed the enhanced arguments.\n        '''\n        self._expanded_callbacks = True\n        return self.callback(output, inputs, state, events)", "response": "This function registers the callback function that returns the expanded arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding application state to initial values", "response": "def augment_initial_layout(self, base_response, initial_arguments=None):\n        'Add application state to initial values'\n        if self.use_dash_layout() and not initial_arguments and False:\n            return base_response.data, base_response.mimetype\n\n        # Adjust the base layout response\n        baseDataInBytes = base_response.data\n        baseData = json.loads(baseDataInBytes.decode('utf-8'))\n\n        # Also add in any initial arguments\n        if initial_arguments:\n            if isinstance(initial_arguments, str):\n                initial_arguments = json.loads(initial_arguments)\n\n        # Walk tree. If at any point we have an element whose id\n        # matches, then replace any named values at this level\n        reworked_data = self.walk_tree_and_replace(baseData, initial_arguments)\n\n        response_data = json.dumps(reworked_data,\n                                   cls=PlotlyJSONEncoder)\n\n        return response_data, base_response.mimetype"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwalks tree of properties and extract identifiers and associated values", "response": "def walk_tree_and_extract(self, data, target):\n        'Walk tree of properties and extract identifiers and associated values'\n        if isinstance(data, dict):\n            for key in ['children', 'props',]:\n                self.walk_tree_and_extract(data.get(key, None), target)\n            ident = data.get('id', None)\n            if ident is not None:\n                idVals = target.get(ident, {})\n                for key, value in data.items():\n                    if key not in ['props', 'options', 'children', 'id']:\n                        idVals[key] = value\n                if idVals:\n                    target[ident] = idVals\n        if isinstance(data, list):\n            for element in data:\n                self.walk_tree_and_extract(element, target)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk_tree_and_replace(self, data, overrides):\n        '''\n        Walk the tree. Rely on json decoding to insert instances of dict and list\n        ie we use a dna test for anatine, rather than our eyes and ears...\n        '''\n        if isinstance(data, dict):\n            response = {}\n            replacements = {}\n            # look for id entry\n            thisID = data.get('id', None)\n            if thisID is not None:\n                replacements = overrides.get(thisID, None) if overrides else None\n                if not replacements:\n                    replacements = self._replacements.get(thisID, {})\n            # walk all keys and replace if needed\n            for k, v in data.items():\n                r = replacements.get(k, None)\n                if r is None:\n                    r = self.walk_tree_and_replace(v, overrides)\n                response[k] = r\n            return response\n        if isinstance(data, list):\n            # process each entry in turn and return\n            return [self.walk_tree_and_replace(x, overrides) for x in data]\n        return data", "response": "Walk the tree and replace all entries with their respective values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlocating endpoint function given name of view", "response": "def locate_endpoint_function(self, name=None):\n        'Locate endpoint function given name of view'\n        if name is not None:\n            ep = \"%s_%s\" %(self._base_pathname,\n                           name)\n        else:\n            ep = self._base_pathname\n        return self._notflask.endpoints[ep]['view_func']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noverloads layout function to fix component names as needed", "response": "def layout(self, value):\n        'Overloaded layout function to fix component names as needed'\n\n        if self._adjust_id:\n            self._fix_component_id(value)\n        return Dash.layout.fset(self, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_component_id(self, component):\n        'Fix name of component ad all of its children'\n\n        theID = getattr(component, \"id\", None)\n        if theID is not None:\n            setattr(component, \"id\", self._fix_id(theID))\n        try:\n            for c in component.children:\n                self._fix_component_id(c)\n        except: #pylint: disable=bare-except\n            pass", "response": "Fix name of component ad all of its children"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninvoke callback adjusting variable names as needed", "response": "def callback(self, output, inputs=[], state=[], events=[]): # pylint: disable=dangerous-default-value\n        'Invoke callback, adjusting variable names as needed'\n\n        if isinstance(output, (list, tuple)):\n            fixed_outputs = [self._fix_callback_item(x) for x in output]\n            # Temporary check; can be removed once the library has been extended\n            raise NotImplementedError(\"django-plotly-dash cannot handle multiple callback outputs at present\")\n        else:\n            fixed_outputs = self._fix_callback_item(output)\n\n        return super(WrappedDash, self).callback(fixed_outputs,\n                                                 [self._fix_callback_item(x) for x in inputs],\n                                                 [self._fix_callback_item(x) for x in state])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch(self):\n        'Perform dispatch, using request embedded within flask global state'\n        import flask\n        body = flask.request.get_json()\n        return self. dispatch_with_args(body, argMap=dict())", "response": "Perform dispatch using request embedded within flask global state"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms callback dispatching with enhanced arguments and recording of response", "response": "def dispatch_with_args(self, body, argMap):\n        'Perform callback dispatching, with enhanced arguments and recording of response'\n        inputs = body.get('inputs', [])\n        state = body.get('state', [])\n        output = body['output']\n\n        try:\n            output_id = output['id']\n            output_property = output['property']\n            target_id = \"%s.%s\" %(output_id, output_property)\n        except:\n            target_id = output\n            output_id, output_property = output.split(\".\")\n\n        args = []\n\n        da = argMap.get('dash_app', None)\n\n        for component_registration in self.callback_map[target_id]['inputs']:\n            for c in inputs:\n                if c['property'] == component_registration['property'] and c['id'] == component_registration['id']:\n                    v = c.get('value', None)\n                    args.append(v)\n                    if da:\n                        da.update_current_state(c['id'], c['property'], v)\n\n        for component_registration in self.callback_map[target_id]['state']:\n            for c in state:\n                if c['property'] == component_registration['property'] and c['id'] == component_registration['id']:\n                    v = c.get('value', None)\n                    args.append(v)\n                    if da:\n                        da.update_current_state(c['id'], c['property'], v)\n\n        # Special: intercept case of insufficient arguments\n        # This happens when a propery has been updated with a pipe component\n        # TODO see if this can be attacked from the client end\n\n        if len(args) < len(self.callback_map[target_id]['inputs']):\n            return 'EDGECASEEXIT'\n\n        res = self.callback_map[target_id]['callback'](*args, **argMap)\n        if da and da.have_current_state_entry(output_id, output_property):\n            response = json.loads(res.data.decode('utf-8'))\n            value = response.get('response', {}).get('props', {}).get(output_property, None)\n            da.update_current_state(output_id, output_property, value)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extra_html_properties(self, prefix=None, postfix=None, template_type=None):\n        '''\n        Return extra html properties to allow individual apps to be styled separately.\n\n        The content returned from this function is injected unescaped into templates.\n        '''\n\n        prefix = prefix if prefix else \"django-plotly-dash\"\n\n        post_part = \"-%s\" % postfix if postfix else \"\"\n        template_type = template_type if template_type else \"iframe\"\n\n        slugified_id = self.slugified_id()\n\n        return \"%(prefix)s %(prefix)s-%(template_type)s %(prefix)s-app-%(slugified_id)s%(post_part)s\" % {'slugified_id':slugified_id,\n                                                                                                         'post_part':post_part,\n                                                                                                         'template_type':template_type,\n                                                                                                         'prefix':prefix,\n                                                                                                        }", "response": "Return extra html properties to allow individual apps to be styled separately."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotly_app(context, name=None, slug=None, da=None, ratio=0.1, use_frameborder=False, initial_arguments=None):\n    'Insert a dash application using a html iframe'\n\n    fbs = '1' if use_frameborder else '0'\n\n    dstyle = \"\"\"\n    position: relative;\n    padding-bottom: %s%%;\n    height: 0;\n    overflow:hidden;\n    \"\"\" % (ratio*100)\n\n    istyle = \"\"\"\n    position: absolute;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    \"\"\"\n\n    cache_id = store_initial_arguments(context['request'], initial_arguments)\n\n    da, app = _locate_daapp(name, slug, da, cache_id=cache_id)\n\n    return locals()", "response": "Insert a dash application using a html iframe"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndirect insertion of a Dash app", "response": "def plotly_direct(context, name=None, slug=None, da=None):\n    'Direct insertion of a Dash app'\n\n    da, app = _locate_daapp(name, slug, da)\n\n    view_func = app.locate_endpoint_function()\n\n    # Load embedded holder inserted by middleware\n    eh = context.request.dpd_content_handler.embedded_holder\n    app.set_embedded(eh)\n    try:\n        resp = view_func()\n    finally:\n        app.exit_embedded()\n\n    return locals()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotly_app_identifier(name=None, slug=None, da=None, postfix=None):\n    'Return a slug-friendly identifier'\n\n    da, app = _locate_daapp(name, slug, da)\n\n    slugified_id = app.slugified_id()\n\n    if postfix:\n        return \"%s-%s\" %(slugified_id, postfix)\n    return slugified_id", "response": "Return a slug - friendly identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plotly_class(name=None, slug=None, da=None, prefix=None, postfix=None, template_type=None):\n    'Return a string of space-separated class names'\n\n    da, app = _locate_daapp(name, slug, da)\n\n    return app.extra_html_properties(prefix=prefix,\n                                     postfix=postfix,\n                                     template_type=template_type)", "response": "Return a string of space - separated class names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_wyckoff_csv(wyckoff_file):\n\n    rowdata = []\n    points = []\n    hP_nums = [433, 436, 444, 450, 452, 458, 460]\n    for i, line in enumerate(wyckoff_file):\n        if line.strip() == 'end of data':\n            break\n        rowdata.append(line.strip().split(':'))\n\n        # 2:P -1  ::::::: <-- store line number if first element is number\n        if rowdata[-1][0].isdigit():\n            points.append(i)\n    points.append(i)\n\n    wyckoff = []\n    for i in range(len(points) - 1):  # 0 to 529\n        symbol = rowdata[points[i]][1]  # e.g. \"C 1 2 1\"\n        if i + 1 in hP_nums:\n            symbol = symbol.replace('R', 'H', 1)\n        wyckoff.append({'symbol': symbol.strip()})\n\n    # When the number of positions is larger than 4,\n    # the positions are written in the next line.\n    # So those positions are connected.\n    for i in range(len(points) - 1):\n        count = 0\n        wyckoff[i]['wyckoff'] = []\n        for j in range(points[i] + 1, points[i + 1]):\n            # Hook if the third element is a number (multiplicity), e.g.,\n            #\n            # 232:P 2/b 2/m 2/b:::::::  <- ignored\n            # ::8:r:1:(x,y,z):(-x,y,-z):(x,-y+1/2,-z):(-x,-y+1/2,z)\n            # :::::(-x,-y,-z):(x,-y,z):(-x,y+1/2,z):(x,y+1/2,-z)  <- ignored\n            # ::4:q:..m:(x,0,z):(-x,0,-z):(x,1/2,-z):(-x,1/2,z)\n            # ::4:p:..2:(0,y,1/2):(0,-y+1/2,1/2):(0,-y,1/2):(0,y+1/2,1/2)\n            # ::4:o:..2:(1/2,y,0):(1/2,-y+1/2,0):(1/2,-y,0):(1/2,y+1/2,0)\n            # ...\n            if rowdata[j][2].isdigit():\n                pos = []\n                w = {'letter': rowdata[j][3].strip(),\n                     'multiplicity': int(rowdata[j][2]),\n                     'site_symmetry': rowdata[j][4].strip(),\n                     'positions': pos}\n                wyckoff[i]['wyckoff'].append(w)\n\n                for k in range(4):\n                    if rowdata[j][k + 5]:  # check if '(x,y,z)' or ''\n                        count += 1\n                        pos.append(rowdata[j][k + 5])\n            else:\n                for k in range(4):\n                    if rowdata[j][k + 5]:\n                        count += 1\n                        pos.append(rowdata[j][k + 5])\n\n        # assertion\n        for w in wyckoff[i]['wyckoff']:\n            n_pos = len(w['positions'])\n            n_pos *= len(lattice_symbols[wyckoff[i]['symbol'][0]])\n            assert n_pos == w['multiplicity']\n\n    return wyckoff", "response": "Parse the Wyckoff. csv file and return a list of dicts. Each object is a dict with the keys wyckoff_id and the values of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_site_symmetries(wyckoff):\n\n    ssyms = []\n    for w in wyckoff:\n        ssyms += [\"\\\"%-6s\\\"\" % w_s['site_symmetry'] for w_s in w['wyckoff']]\n\n    damp_array_site_symmetries(ssyms)", "response": "List up site symmetries in the data structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef incrementing_sleep(self, previous_attempt_number, delay_since_first_attempt_ms):\n        result = self._wait_incrementing_start + (self._wait_incrementing_increment * (previous_attempt_number - 1))\n        if result > self._wait_incrementing_max:\n            result = self._wait_incrementing_max\n        if result < 0:\n            result = 0\n        return result", "response": "Increment the amount of time after each attempt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform the model class into a single model class.", "response": "def transform_model(cls) -> None:\n    \"\"\"\n    Anything that uses the ModelMeta needs _meta and id.\n    Also keep track of relationships and make them in the related model class.\n    \"\"\"\n    if cls.name != \"Model\":\n        appname = \"models\"\n        for mcls in cls.get_children():\n            if isinstance(mcls, ClassDef):\n                for attr in mcls.get_children():\n                    if isinstance(attr, Assign):\n                        if attr.targets[0].name == \"app\":\n                            appname = attr.value.value\n\n        mname = \"{}.{}\".format(appname, cls.name)\n        MODELS[mname] = cls\n\n        for relname, relval in FUTURE_RELATIONS.get(mname, []):\n            cls.locals[relname] = relval\n\n        for attr in cls.get_children():\n            if isinstance(attr, Assign):\n                try:\n                    attrname = attr.value.func.attrname\n                except AttributeError:\n                    pass\n                else:\n                    if attrname in [\"ForeignKeyField\", \"ManyToManyField\"]:\n                        tomodel = attr.value.args[0].value\n                        relname = \"\"\n                        if attr.value.keywords:\n                            for keyword in attr.value.keywords:\n                                if keyword.arg == \"related_name\":\n                                    relname = keyword.value.value\n\n                        if not relname:\n                            relname = cls.name.lower() + \"s\"\n\n                        # Injected model attributes need to also have the relation manager\n                        if attrname == \"ManyToManyField\":\n                            relval = [\n                                attr.value.func,\n                                MANAGER.ast_from_module_name(\"tortoise.fields\").lookup(\n                                    \"ManyToManyRelationManager\"\n                                )[1][0],\n                            ]\n                        else:\n                            relval = [\n                                attr.value.func,\n                                MANAGER.ast_from_module_name(\"tortoise.fields\").lookup(\n                                    \"RelationQueryContainer\"\n                                )[1][0],\n                            ]\n\n                        if tomodel in MODELS:\n                            MODELS[tomodel].locals[relname] = relval\n                        else:\n                            FUTURE_RELATIONS.setdefault(tomodel, []).append((relname, relval))\n\n    cls.locals[\"_meta\"] = [\n        MANAGER.ast_from_module_name(\"tortoise.models\").lookup(\"MetaInfo\")[1][0].instantiate_class()\n    ]\n    if \"id\" not in cls.locals:\n        cls.locals[\"id\"] = [nodes.ClassDef(\"id\", None)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_type_shim(cls, _context=None) -> Iterator:\n    if cls.name in [\"IntField\", \"SmallIntField\"]:\n        base_nodes = scoped_nodes.builtin_lookup(\"int\")\n    elif cls.name in [\"CharField\", \"TextField\"]:\n        base_nodes = scoped_nodes.builtin_lookup(\"str\")\n    elif cls.name == \"BooleanField\":\n        base_nodes = scoped_nodes.builtin_lookup(\"bool\")\n    elif cls.name == \"FloatField\":\n        base_nodes = scoped_nodes.builtin_lookup(\"float\")\n    elif cls.name == \"DecimalField\":\n        base_nodes = MANAGER.ast_from_module_name(\"decimal\").lookup(\"Decimal\")\n    elif cls.name == \"DatetimeField\":\n        base_nodes = MANAGER.ast_from_module_name(\"datetime\").lookup(\"datetime\")\n    elif cls.name == \"DateField\":\n        base_nodes = MANAGER.ast_from_module_name(\"datetime\").lookup(\"date\")\n    elif cls.name == \"ForeignKeyField\":\n        base_nodes = MANAGER.ast_from_module_name(\"tortoise.fields\").lookup(\"BackwardFKRelation\")\n    elif cls.name == \"ManyToManyField\":\n        base_nodes = MANAGER.ast_from_module_name(\"tortoise.fields\").lookup(\n            \"ManyToManyRelationManager\"\n        )\n    else:\n        return iter([cls])\n\n    return iter([cls] + base_nodes[1])", "response": "Returns an iterator over the type shims that can be applied to the given class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_encoder(values, instance, field: Field):\n    return [field.to_db_value(element, instance) for element in values]", "response": "Encodes an iterable of a given field into a database - compatible format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def add(self, *instances, using_db=None) -> None:\n        if not instances:\n            return\n        if self.instance.id is None:\n            raise OperationalError(\n                \"You should first call .save() on {model}\".format(model=self.instance)\n            )\n        db = using_db if using_db else self.model._meta.db\n        through_table = Table(self.field.through)\n        select_query = (\n            db.query_class.from_(through_table)\n            .where(getattr(through_table, self.field.backward_key) == self.instance.id)\n            .select(self.field.backward_key, self.field.forward_key)\n        )\n        query = db.query_class.into(through_table).columns(\n            getattr(through_table, self.field.forward_key),\n            getattr(through_table, self.field.backward_key),\n        )\n\n        if len(instances) == 1:\n            criterion = getattr(through_table, self.field.forward_key) == instances[0].id\n        else:\n            criterion = getattr(through_table, self.field.forward_key).isin(\n                [i.id for i in instances]\n            )\n\n        select_query = select_query.where(criterion)\n\n        already_existing_relations_raw = await db.execute_query(str(select_query))\n        already_existing_relations = {\n            (r[self.field.backward_key], r[self.field.forward_key])\n            for r in already_existing_relations_raw\n        }\n\n        insert_is_required = False\n        for instance_to_add in instances:\n            if instance_to_add.id is None:\n                raise OperationalError(\n                    \"You should first call .save() on {model}\".format(model=instance_to_add)\n                )\n            if (self.instance.id, instance_to_add.id) in already_existing_relations:\n                continue\n            query = query.insert(instance_to_add.id, self.instance.id)\n            insert_is_required = True\n        if insert_is_required:\n            await db.execute_query(str(query))", "response": "Adds one or more instances to the relation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def remove(self, *instances, using_db=None) -> None:\n        db = using_db if using_db else self.model._meta.db\n        if not instances:\n            raise OperationalError(\"remove() called on no instances\")\n        through_table = Table(self.field.through)\n\n        if len(instances) == 1:\n            condition = (getattr(through_table, self.field.forward_key) == instances[0].id) & (\n                getattr(through_table, self.field.backward_key) == self.instance.id\n            )\n        else:\n            condition = (getattr(through_table, self.field.backward_key) == self.instance.id) & (\n                getattr(through_table, self.field.forward_key).isin([i.id for i in instances])\n            )\n        query = db.query_class.from_(through_table).where(condition).delete()\n        await db.execute_query(str(query))", "response": "Removes one or more of instances from the relation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_tortoise(\n    app: Quart,\n    config: Optional[dict] = None,\n    config_file: Optional[str] = None,\n    db_url: Optional[str] = None,\n    modules: Optional[Dict[str, List[str]]] = None,\n    generate_schemas: bool = False,\n) -> None:\n    \"\"\"\n    Registers ``before_serving`` and ``after_serving`` hooks to set-up and tear-down Tortoise-ORM\n    inside a Quart service.\n    It also registers a CLI command ``generate_schemas`` that will generate the schemas.\n\n    You can configure using only one of ``config``, ``config_file``\n    and ``(db_url, modules)``.\n\n    Parameters\n    ----------\n    app:\n        Quart app.\n    config:\n        Dict containing config:\n\n        Example\n        -------\n\n        .. code-block:: python3\n\n            {\n                'connections': {\n                    # Dict format for connection\n                    'default': {\n                        'engine': 'tortoise.backends.asyncpg',\n                        'credentials': {\n                            'host': 'localhost',\n                            'port': '5432',\n                            'user': 'tortoise',\n                            'password': 'qwerty123',\n                            'database': 'test',\n                        }\n                    },\n                    # Using a DB_URL string\n                    'default': 'postgres://postgres:@qwerty123localhost:5432/events'\n                },\n                'apps': {\n                    'models': {\n                        'models': ['__main__'],\n                        # If no default_connection specified, defaults to 'default'\n                        'default_connection': 'default',\n                    }\n                }\n            }\n\n    config_file:\n        Path to .json or .yml (if PyYAML installed) file containing config with\n        same format as above.\n    db_url:\n        Use a DB_URL string. See :ref:`db_url`\n    modules:\n        Dictionary of ``key``: [``list_of_modules``] that defined \"apps\" and modules that\n        should be discovered for models.\n    generate_schemas:\n        True to generate schema immediately. Only useful for dev environments\n        or SQLite ``:memory:`` databases\n    \"\"\"\n\n    @app.before_serving\n    async def init_orm():\n        await Tortoise.init(config=config, config_file=config_file, db_url=db_url, modules=modules)\n        print(\"Tortoise-ORM started, {}, {}\".format(Tortoise._connections, Tortoise.apps))\n        if generate_schemas:\n            print(\"Tortoise-ORM generating schema\")\n            await Tortoise.generate_schemas()\n\n    @app.after_serving\n    async def close_orm():\n        await Tortoise.close_connections()\n        print(\"Tortoise-ORM shutdown\")\n\n    @app.cli.command()  # type: ignore\n    def generate_schemas():  # pylint: disable=E0102\n        \"\"\"Populate DB with Tortoise-ORM schemas.\"\"\"\n\n        async def inner():\n            await Tortoise.init(\n                config=config, config_file=config_file, db_url=db_url, modules=modules\n            )\n            await Tortoise.generate_schemas()\n            await Tortoise.close_connections()\n\n        logging.basicConfig(level=logging.DEBUG)\n        loop = asyncio.get_event_loop()\n        loop.run_until_complete(inner())", "response": "Registers a Tortoise - ORM with the given app."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def init(\n        cls,\n        config: Optional[dict] = None,\n        config_file: Optional[str] = None,\n        _create_db: bool = False,\n        db_url: Optional[str] = None,\n        modules: Optional[Dict[str, List[str]]] = None,\n    ) -> None:\n        \"\"\"\n        Sets up Tortoise-ORM.\n\n        You can configure using only one of ``config``, ``config_file``\n        and ``(db_url, modules)``.\n\n        Parameters\n        ----------\n        config:\n            Dict containing config:\n\n            Example\n            -------\n\n            .. code-block:: python3\n\n                {\n                    'connections': {\n                        # Dict format for connection\n                        'default': {\n                            'engine': 'tortoise.backends.asyncpg',\n                            'credentials': {\n                                'host': 'localhost',\n                                'port': '5432',\n                                'user': 'tortoise',\n                                'password': 'qwerty123',\n                                'database': 'test',\n                            }\n                        },\n                        # Using a DB_URL string\n                        'default': 'postgres://postgres:@qwerty123localhost:5432/events'\n                    },\n                    'apps': {\n                        'models': {\n                            'models': ['__main__'],\n                            # If no default_connection specified, defaults to 'default'\n                            'default_connection': 'default',\n                        }\n                    }\n                }\n\n        config_file:\n            Path to .json or .yml (if PyYAML installed) file containing config with\n            same format as above.\n        db_url:\n            Use a DB_URL string. See :ref:`db_url`\n        modules:\n            Dictionary of ``key``: [``list_of_modules``] that defined \"apps\" and modules that\n            should be discovered for models.\n        _create_db:\n            If ``True`` tries to create database for specified connections,\n            could be used for testing purposes.\n\n        Raises\n        ------\n        ConfigurationError\n            For any configuration error\n        \"\"\"\n        if cls._inited:\n            await cls.close_connections()\n            await cls._reset_apps()\n        if int(bool(config) + bool(config_file) + bool(db_url)) != 1:\n            raise ConfigurationError(\n                'You should init either from \"config\", \"config_file\" or \"db_url\"'\n            )\n\n        if config_file:\n            config = cls._get_config_from_config_file(config_file)\n\n        if db_url:\n            if not modules:\n                raise ConfigurationError('You must specify \"db_url\" and \"modules\" together')\n            config = generate_config(db_url, modules)\n\n        try:\n            connections_config = config[\"connections\"]  # type: ignore\n        except KeyError:\n            raise ConfigurationError('Config must define \"connections\" section')\n\n        try:\n            apps_config = config[\"apps\"]  # type: ignore\n        except KeyError:\n            raise ConfigurationError('Config must define \"apps\" section')\n\n        logger.info(\n            \"Tortoise-ORM startup\\n    connections: %s\\n    apps: %s\",\n            str(connections_config),\n            str(apps_config),\n        )\n\n        await cls._init_connections(connections_config, _create_db)\n        cls._init_apps(apps_config)\n\n        cls._inited = True", "response": "Initialize Tortoise - ORM with the given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def generate_schemas(cls, safe=True) -> None:\n        if not cls._inited:\n            raise ConfigurationError(\"You have to call .init() first before generating schemas\")\n        for connection in cls._connections.values():\n            await generate_schema_for_client(connection, safe)", "response": "Generate schemas according to models provided to the application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _drop_databases(cls) -> None:\n        if not cls._inited:\n            raise ConfigurationError(\"You have to call .init() first before deleting schemas\")\n        for connection in cls._connections.values():\n            await connection.close()\n            await connection.db_delete()\n        cls._connections = {}\n        await cls._reset_apps()", "response": "Drop all databases in the database pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_transaction(connection_name: Optional[str] = None) -> BaseTransactionWrapper:\n    connection = _get_connection(connection_name)\n    return connection._in_transaction()", "response": "A context manager that runs in_transaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a new transaction.", "response": "async def start_transaction(connection_name: Optional[str] = None) -> BaseTransactionWrapper:\n    \"\"\"\n    Function to manually control your transaction.\n\n    Returns transaction object with ``.rollback()`` and ``.commit()`` methods.\n    All db calls in same coroutine context will run into transaction\n    before ending transaction with above methods.\n\n    :param connection_name: name of connection to run with, optional if you have only\n                            one db connection\n    \"\"\"\n    connection = _get_connection(connection_name)\n    transaction = connection._in_transaction()\n    await transaction.start()\n    return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self, *args, **kwargs) -> \"QuerySet\":\n        return self._filter_or_exclude(negate=False, *args, **kwargs)", "response": "Filters QuerySet by given args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exclude(self, *args, **kwargs) -> \"QuerySet\":\n        return self._filter_or_exclude(negate=True, *args, **kwargs)", "response": "Same as. filter but with appends all args with NOT\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new queryset with the specified orderings.", "response": "def order_by(self, *orderings: str) -> \"QuerySet\":\n        \"\"\"\n        Accept args to filter by in format like this:\n\n        .. code-block:: python3\n\n            .order_by('name', '-tournament__name')\n\n        Supports ordering by related models too.\n        \"\"\"\n        queryset = self._clone()\n        new_ordering = []\n        for ordering in orderings:\n            order_type = Order.asc\n            if ordering[0] == \"-\":\n                field_name = ordering[1:]\n                order_type = Order.desc\n            else:\n                field_name = ordering\n\n            if not (\n                field_name.split(\"__\")[0] in self.model._meta.fields\n                or field_name in self._annotations\n            ):\n                raise FieldError(\n                    \"Unknown field {} for model {}\".format(field_name, self.model.__name__)\n                )\n            new_ordering.append((field_name, order_type))\n        queryset._orderings = new_ordering\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef limit(self, limit: int) -> \"QuerySet\":\n        queryset = self._clone()\n        queryset._limit = limit\n        return queryset", "response": "Returns a new QuerySet with the given limit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef offset(self, offset: int) -> \"QuerySet\":\n        queryset = self._clone()\n        queryset._offset = offset\n        if self.capabilities.requires_limit and queryset._limit is None:\n            queryset._limit = 1000000\n        return queryset", "response": "Set the offset for this QuerySet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef annotate(self, **kwargs) -> \"QuerySet\":\n        queryset = self._clone()\n        for key, aggregation in kwargs.items():\n            if not isinstance(aggregation, Aggregate):\n                raise TypeError(\"value is expected to be Aggregate instance\")\n            queryset._annotations[key] = aggregation\n            from tortoise.models import get_filters_for_field\n\n            queryset._custom_filters.update(get_filters_for_field(key, None, key))\n        return queryset", "response": "Annotate result with aggregation result."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake QuerySet returns list of tuples for given fields instead of objects.", "response": "def values_list(\n        self, *fields_: str, flat: bool = False\n    ) -> \"ValuesListQuery\":  # pylint: disable=W0621\n        \"\"\"\n        Make QuerySet returns list of tuples for given args instead of objects.\n        If ```flat=True`` and only one arg is passed can return flat list.\n        \"\"\"\n        return ValuesListQuery(\n            db=self._db,\n            model=self.model,\n            q_objects=self._q_objects,\n            flat=flat,\n            fields_for_select_list=fields_,\n            distinct=self._distinct,\n            limit=self._limit,\n            offset=self._offset,\n            orderings=self._orderings,\n            annotations=self._annotations,\n            custom_filters=self._custom_filters,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef values(self, *args: str, **kwargs: str) -> \"ValuesQuery\":\n        fields_for_select = {}  # type: Dict[str, str]\n        for field in args:\n            if field in fields_for_select:\n                raise FieldError(\"Duplicate key {}\".format(field))\n            fields_for_select[field] = field\n\n        for return_as, field in kwargs.items():\n            if return_as in fields_for_select:\n                raise FieldError(\"Duplicate key {}\".format(return_as))\n            fields_for_select[return_as] = field\n\n        return ValuesQuery(\n            db=self._db,\n            model=self.model,\n            q_objects=self._q_objects,\n            fields_for_select=fields_for_select,\n            distinct=self._distinct,\n            limit=self._limit,\n            offset=self._offset,\n            orderings=self._orderings,\n            annotations=self._annotations,\n            custom_filters=self._custom_filters,\n        )", "response": "Make QuerySet return dicts instead of objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self) -> \"DeleteQuery\":\n        return DeleteQuery(\n            db=self._db,\n            model=self.model,\n            q_objects=self._q_objects,\n            annotations=self._annotations,\n            custom_filters=self._custom_filters,\n        )", "response": "Delete all objects in QuerySet."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate all objects in the QuerySet with given kwargs.", "response": "def update(self, **kwargs) -> \"UpdateQuery\":\n        \"\"\"\n        Update all objects in QuerySet with given kwargs.\n        \"\"\"\n        return UpdateQuery(\n            db=self._db,\n            model=self.model,\n            update_kwargs=kwargs,\n            q_objects=self._q_objects,\n            annotations=self._annotations,\n            custom_filters=self._custom_filters,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns count of objects in queryset instead of objects.", "response": "def count(self) -> \"CountQuery\":\n        \"\"\"\n        Return count of objects in queryset instead of objects.\n        \"\"\"\n        return CountQuery(\n            db=self._db,\n            model=self.model,\n            q_objects=self._q_objects,\n            annotations=self._annotations,\n            custom_filters=self._custom_filters,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef first(self) -> \"QuerySet\":\n        queryset = self._clone()\n        queryset._limit = 1\n        queryset._single = True\n        return queryset", "response": "Returns the first object in the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, *args, **kwargs) -> \"QuerySet\":\n        queryset = self.filter(*args, **kwargs)\n        queryset._limit = 2\n        queryset._get = True\n        return queryset", "response": "Fetch exactly one object matching the parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking fetch_related but works on all objects in QuerySet.", "response": "def prefetch_related(self, *args: str) -> \"QuerySet\":\n        \"\"\"\n        Like ``.fetch_related()`` on instance, but works on all objects in QuerySet.\n        \"\"\"\n        queryset = self._clone()\n        queryset._prefetch_map = {}\n\n        for relation in args:\n            if isinstance(relation, Prefetch):\n                relation.resolve_for_queryset(queryset)\n                continue\n            relation_split = relation.split(\"__\")\n            first_level_field = relation_split[0]\n            if first_level_field not in self.model._meta.fetch_fields:\n                raise FieldError(\n                    \"relation {} for {} not found\".format(first_level_field, self.model._meta.table)\n                )\n            if first_level_field not in queryset._prefetch_map.keys():\n                queryset._prefetch_map[first_level_field] = set()\n            forwarded_prefetch = \"__\".join(relation_split[1:])\n            if forwarded_prefetch:\n                queryset._prefetch_map[first_level_field].add(forwarded_prefetch)\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def explain(self) -> Any:\n        if self._db is None:\n            self._db = self.model._meta.db\n\n        return await self._db.executor_class(model=self.model, db=self._db).execute_explain(\n            self._make_query()\n        )", "response": "Fetch and return information about the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef using_db(self, _db: BaseDBAsyncClient) -> \"QuerySet\":\n        queryset = self._clone()\n        queryset._db = _db\n        return queryset", "response": "Returns a new QuerySet with the current queryset in the provided db client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_unique_together(cls):\n        if cls._meta.unique_together is None:\n            return\n\n        if not isinstance(cls._meta.unique_together, (tuple, list)):\n            raise ConfigurationError(\n                \"'{}.unique_together' must be a list or tuple.\".format(cls.__name__)\n            )\n\n        elif any(\n            not isinstance(unique_fields, (tuple, list))\n            for unique_fields in cls._meta.unique_together\n        ):\n            raise ConfigurationError(\n                \"All '{}.unique_together' elements must be lists or tuples.\".format(cls.__name__)\n            )\n\n        else:\n            for fields_tuple in cls._meta.unique_together:\n                for field_name in fields_tuple:\n                    field = cls._meta.fields_map.get(field_name)\n\n                    if not field:\n                        raise ConfigurationError(\n                            \"'{}.unique_together' has no '{}' \"\n                            \"field.\".format(cls.__name__, field_name)\n                        )\n\n                    if isinstance(field, ManyToManyField):\n                        raise ConfigurationError(\n                            \"'{}.unique_together' '{}' field refers \"\n                            \"to ManyToMany field.\".format(cls.__name__, field_name)\n                        )", "response": "Check the value of unique_together option."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_epub(name, book, options=None):\n    epub = EpubWriter(name, book, options)\n\n    epub.process()\n\n    try:\n        epub.write()\n    except IOError:\n        pass", "response": "Creates an epub file with the content defined in EpubBook."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the Epub file and returns a new instance of EpubBook with the content defined in the input file.", "response": "def read_epub(name, options=None):\n    \"\"\"\n    Creates new instance of EpubBook with the content defined in the input file.\n\n    >>> book = ebooklib.read_epub('book.epub')\n\n    :Args:\n      - name: full path to the input file\n      - options: extra options as dictionary (optional)\n\n    :Returns:\n      Instance of EpubBook.\n    \"\"\"\n    reader = EpubReader(name, options)\n\n    book = reader.load()\n    reader.process()\n\n    return book"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nguesses type of the item according to the file extension.", "response": "def get_type(self):\n        \"\"\"\n        Guess type according to the file extension. Might not be the best way how to do it, but it works for now.\n\n        Items can be of type:\n          - ITEM_UNKNOWN = 0\n          - ITEM_IMAGE = 1\n          - ITEM_STYLE = 2\n          - ITEM_SCRIPT = 3\n          - ITEM_NAVIGATION = 4\n          - ITEM_VECTOR = 5\n          - ITEM_FONT = 6\n          - ITEM_VIDEO = 7\n          - ITEM_AUDIO = 8\n          - ITEM_DOCUMENT = 9\n          - ITEM_COVER = 10\n\n        We map type according to the extensions which are defined in ebooklib.EXTENSIONS.\n\n        :Returns:\n          Returns type of the item as number.\n        \"\"\"\n        _, ext = zip_path.splitext(self.get_name())\n        ext = ext.lower()\n\n        for uid, ext_list in six.iteritems(ebooklib.EXTENSIONS):\n            if ext in ext_list:\n                return uid\n\n        return ebooklib.ITEM_UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds additional link to the document.", "response": "def add_link(self, **kwgs):\n        \"\"\"\n        Add additional link to the document. Links will be embeded only inside of this document.\n\n        >>> add_link(href='styles.css', rel='stylesheet', type='text/css')\n        \"\"\"\n        self.links.append(kwgs)\n        if kwgs.get('type') == 'text/javascript':\n            if 'scripted' not in self.properties:\n                self.properties.append('scripted')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of additional links of specific type.", "response": "def get_links_of_type(self, link_type):\n        \"\"\"\n        Returns list of additional links of specific type.\n\n        :Returns:\n          As tuple returns list of links.\n        \"\"\"\n        return (link for link in self.links if link.get('type', '') == link_type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_item(self, item):\n        if item.get_type() == ebooklib.ITEM_STYLE:\n            self.add_link(href=item.get_name(), rel='stylesheet', type='text/css')\n\n        if item.get_type() == ebooklib.ITEM_SCRIPT:\n            self.add_link(src=item.get_name(), type='text/javascript')", "response": "Add other item to this document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the content of the BODY element for this HTML document.", "response": "def get_body_content(self):\n        \"\"\"\n        Returns content of BODY element for this HTML document. Content will be of type 'str' (Python 2)\n        or 'bytes' (Python 3).\n\n        :Returns:\n          Returns content of this document.\n        \"\"\"\n\n        try:\n            html_tree = parse_html_string(self.content)\n        except:\n            return ''\n\n        html_root = html_tree.getroottree()\n\n        if len(html_root.find('body')) != 0:\n            body = html_tree.find('body')\n\n            tree_str = etree.tostring(body, pretty_print=True, encoding='utf-8', xml_declaration=False)\n\n            # this is so stupid\n            if tree_str.startswith(six.b('<body>')):\n                n = tree_str.rindex(six.b('</body>'))\n\n                return tree_str[6:n]\n\n            return tree_str\n\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_content(self, default=None):\n\n        tree = parse_string(self.book.get_template(self._template_name))\n        tree_root = tree.getroot()\n\n        tree_root.set('lang', self.lang or self.book.language)\n        tree_root.attrib['{%s}lang' % NAMESPACES['XML']] = self.lang or self.book.language\n\n        # add to the head also\n        #  <meta charset=\"utf-8\" />\n\n        try:\n            html_tree = parse_html_string(self.content)\n        except:\n            return ''\n\n        html_root = html_tree.getroottree()\n\n        # create and populate head\n\n        _head = etree.SubElement(tree_root, 'head')\n\n        if self.title != '':\n            _title = etree.SubElement(_head, 'title')\n            _title.text = self.title\n\n        for lnk in self.links:\n            if lnk.get('type') == 'text/javascript':\n                _lnk = etree.SubElement(_head, 'script', lnk)\n                # force <script></script>\n                _lnk.text = ''\n            else:\n                _lnk = etree.SubElement(_head, 'link', lnk)\n\n        # this should not be like this\n        # head = html_root.find('head')\n        # if head is not None:\n        #     for i in head.getchildren():\n        #         if i.tag == 'title' and self.title != '':\n        #             continue\n        #         _head.append(i)\n\n        # create and populate body\n\n        _body = etree.SubElement(tree_root, 'body')\n        if self.direction:\n            _body.set('dir', self.direction)\n            tree_root.set('dir', self.direction)\n\n        body = html_tree.find('body')\n        if body is not None:\n            for i in body.getchildren():\n                _body.append(i)\n\n        tree_str = etree.tostring(tree, pretty_print=True, encoding='utf-8', xml_declaration=True)\n\n        return tree_str", "response": "Returns the content of this document as HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_content(self):\n\n        self.content = self.book.get_template('cover')\n\n        tree = parse_string(super(EpubCoverHtml, self).get_content())\n        tree_root = tree.getroot()\n\n        images = tree_root.xpath('//xhtml:img', namespaces={'xhtml': NAMESPACES['XHTML']})\n\n        images[0].set('src', self.image_name)\n        images[0].set('alt', self.title)\n\n        tree_str = etree.tostring(tree, pretty_print=True, encoding='utf-8', xml_declaration=True)\n\n        return tree_str", "response": "Returns content of cover page as HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitialises all needed variables to default values", "response": "def reset(self):\n        \"Initialises all needed variables to default values\"\n\n        self.metadata = {}\n        self.items = []\n        self.spine = []\n        self.guide = []\n        self.pages = []\n        self.toc = []\n        self.bindings = []\n\n        self.IDENTIFIER_ID = 'id'\n        self.FOLDER_NAME = 'EPUB'\n\n        self._id_html = 0\n        self._id_image = 0\n        self._id_static = 0\n\n        self.title = ''\n        self.language = 'en'\n        self.direction = None\n\n        self.templates = {\n            'ncx': NCX_XML,\n            'nav': NAV_XML,\n            'chapter': CHAPTER_XML,\n            'cover': COVER_XML\n        }\n\n        self.add_metadata('OPF', 'generator', '', {\n            'name': 'generator', 'content': 'Ebook-lib %s' % '.'.join([str(s) for s in VERSION])\n        })\n\n        # default to using a randomly-unique identifier if one is not specified manually\n        self.set_identifier(str(uuid.uuid4()))\n\n        # custom prefixes and namespaces to be set to the content.opf doc\n        self.prefixes = []\n        self.namespaces = {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_identifier(self, uid):\n\n        self.uid = uid\n\n        self.set_unique_metadata('DC', 'identifier', self.uid, {'id': self.IDENTIFIER_ID})", "response": "Sets the unique identifier for this epub\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the title of the object.", "response": "def set_title(self, title):\n        \"\"\"\n        Set title. You can set multiple titles.\n\n        :Args:\n          - title: Title value\n        \"\"\"\n\n        self.title = title\n\n        self.add_metadata('DC', 'title', self.title)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_cover(self, file_name, content, create_page=True):\n\n        # as it is now, it can only be called once\n        c0 = EpubCover(file_name=file_name)\n        c0.content = content\n        self.add_item(c0)\n\n        if create_page:\n            c1 = EpubCoverHtml(image_name=file_name)\n            self.add_item(c1)\n\n        self.add_metadata(None, 'meta', '', OrderedDict([('name', 'cover'), ('content', 'cover-img')]))", "response": "Set cover and create cover document if needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd author for this document", "response": "def add_author(self, author, file_as=None, role=None, uid='creator'):\n        \"Add author for this document\"\n\n        self.add_metadata('DC', 'creator', author, {'id': uid})\n\n        if file_as:\n            self.add_metadata(None, 'meta', file_as, {'refines': '#' + uid,\n                                                      'property': 'file-as',\n                                                      'scheme': 'marc:relators'})\n        if role:\n            self.add_metadata(None, 'meta', role, {'refines': '#' + uid,\n                                                   'property': 'role',\n                                                   'scheme': 'marc:relators'})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an item to the book. If no item is defined it will be added. If no item is defined it will be added. If no item is defined it will be added.", "response": "def add_item(self, item):\n        \"\"\"\n        Add additional item to the book. If not defined, media type and chapter id will be defined\n        for the item.\n\n        :Args:\n          - item: Item instance\n        \"\"\"\n        if item.media_type == '':\n            (has_guessed, media_type) = guess_type(item.get_name().lower())\n\n            if has_guessed:\n                if media_type is not None:\n                    item.media_type = media_type\n                else:\n                    item.media_type = has_guessed\n            else:\n                item.media_type = 'application/octet-stream'\n\n        if not item.get_id():\n            # make chapter_, image_ and static_ configurable\n            if isinstance(item, EpubHtml):\n                item.id = 'chapter_%d' % self._id_html\n                self._id_html += 1\n                # If there's a page list, append it to the book's page list\n                self.pages += item.pages\n            elif isinstance(item, EpubImage):\n                item.id = 'image_%d' % self._id_image\n                self._id_image += 1\n            else:\n                item.id = 'static_%d' % self._id_image\n                self._id_image += 1\n\n        item.book = self\n        self.items.append(item)\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns item object for the given UID.", "response": "def get_item_with_id(self, uid):\n        \"\"\"\n        Returns item for defined UID.\n\n        >>> book.get_item_with_id('image_001')\n\n        :Args:\n          - uid: UID for the item\n\n        :Returns:\n          Returns item object. Returns None if nothing was found.\n        \"\"\"\n        for item in self.get_items():\n            if item.id == uid:\n                return item\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning item object for the given href.", "response": "def get_item_with_href(self, href):\n        \"\"\"\n        Returns item for defined HREF.\n\n        >>> book.get_item_with_href('EPUB/document.xhtml')\n\n        :Args:\n          - href: HREF for the item we are searching for\n\n        :Returns:\n          Returns item object. Returns None if nothing was found.\n        \"\"\"\n        for item in self.get_items():\n            if item.get_name() == href:\n                return item\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all items of specified type.", "response": "def get_items_of_type(self, item_type):\n        \"\"\"\n        Returns all items of specified type.\n\n        >>> book.get_items_of_type(epub.ITEM_IMAGE)\n\n        :Args:\n          - item_type: Type for items we are searching for\n\n        :Returns:\n          Returns found items as tuple.\n        \"\"\"\n        return (item for item in self.items if item.get_type() == item_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all items of specified media type.", "response": "def get_items_of_media_type(self, media_type):\n        \"\"\"\n        Returns all items of specified media type.\n\n        :Args:\n          - media_type: Media type for items we are searching for\n\n        :Returns:\n          Returns found items as tuple.\n        \"\"\"\n        return (item for item in self.items if item.media_type == media_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    import argparse\n\n    parser = argparse.ArgumentParser(\n        description=\"ftfy (fixes text for you), version %s\" % __version__\n    )\n    parser.add_argument('filename', default='-', nargs='?',\n                        help='The file whose Unicode is to be fixed. Defaults '\n                             'to -, meaning standard input.')\n    parser.add_argument('-o', '--output', type=str, default='-',\n                        help='The file to output to. Defaults to -, meaning '\n                             'standard output.')\n    parser.add_argument('-g', '--guess', action='store_true',\n                        help=\"Ask ftfy to guess the encoding of your input. \"\n                             \"This is risky. Overrides -e.\")\n    parser.add_argument('-e', '--encoding', type=str, default='utf-8',\n                        help='The encoding of the input. Defaults to UTF-8.')\n    parser.add_argument('-n', '--normalization', type=str, default='NFC',\n                        help='The normalization of Unicode to apply. '\n                             'Defaults to NFC. Can be \"none\".')\n    parser.add_argument('--preserve-entities', action='store_true',\n                        help=\"Leave HTML entities as they are. The default \"\n                             \"is to decode them, as long as no HTML tags \"\n                             \"have appeared in the file.\")\n\n    args = parser.parse_args()\n\n    encoding = args.encoding\n    if args.guess:\n        encoding = None\n\n    if args.filename == '-':\n        # Get a standard input stream made of bytes, so we can decode it as\n        # whatever encoding is necessary.\n        file = sys.stdin.buffer\n    else:\n        file = open(args.filename, 'rb')\n\n    if args.output == '-':\n        outfile = sys.stdout\n    else:\n        if os.path.realpath(args.output) == os.path.realpath(args.filename):\n            sys.stderr.write(SAME_FILE_ERROR_TEXT)\n            sys.exit(1)\n        outfile = open(args.output, 'w', encoding='utf-8')\n\n    normalization = args.normalization\n    if normalization.lower() == 'none':\n        normalization = None\n\n    if args.preserve_entities:\n        fix_entities = False\n    else:\n        fix_entities = 'auto'\n\n    try:\n        for line in fix_file(file, encoding=encoding,\n                             fix_entities=fix_entities,\n                             normalization=normalization):\n            try:\n                outfile.write(line)\n            except UnicodeEncodeError:\n                if sys.platform == 'win32':\n                    sys.stderr.write(ENCODE_ERROR_TEXT_WINDOWS)\n                else:\n                    sys.stderr.write(ENCODE_ERROR_TEXT_UNIX)\n                sys.exit(1)\n    except UnicodeDecodeError as err:\n        sys.stderr.write(DECODE_ERROR_TEXT % (encoding, err))\n        sys.exit(1)", "response": "This function is called by the command - line utility. It is intended to be used by the command - line utility."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_one_step_and_explain(text):\n    if isinstance(text, bytes):\n        raise UnicodeError(BYTES_ERROR_TEXT)\n    if len(text) == 0:\n        return text, []\n\n    # The first plan is to return ASCII text unchanged.\n    if possible_encoding(text, 'ascii'):\n        return text, []\n\n    # As we go through the next step, remember the possible encodings\n    # that we encounter but don't successfully fix yet. We may need them\n    # later.\n    possible_1byte_encodings = []\n\n    # Suppose the text was supposed to be UTF-8, but it was decoded using\n    # a single-byte encoding instead. When these cases can be fixed, they\n    # are usually the correct thing to do, so try them next.\n    for encoding in CHARMAP_ENCODINGS:\n        if possible_encoding(text, encoding):\n            encoded_bytes = text.encode(encoding)\n            encode_step = ('encode', encoding, ENCODING_COSTS.get(encoding, 0))\n            transcode_steps = []\n\n            # Now, find out if it's UTF-8 (or close enough). Otherwise,\n            # remember the encoding for later.\n            try:\n                decoding = 'utf-8'\n                # Check encoded_bytes for sequences that would be UTF-8,\n                # except they have b' ' where b'\\xa0' would belong.\n                if ALTERED_UTF8_RE.search(encoded_bytes):\n                    encoded_bytes = restore_byte_a0(encoded_bytes)\n                    cost = encoded_bytes.count(0xa0) * 2\n                    transcode_steps.append(('transcode', 'restore_byte_a0', cost))\n\n                # Check for the byte 0x1a, which indicates where one of our\n                # 'sloppy' codecs found a replacement character.\n                if encoding.startswith('sloppy') and 0x1a in encoded_bytes:\n                    encoded_bytes = replace_lossy_sequences(encoded_bytes)\n                    transcode_steps.append(('transcode', 'replace_lossy_sequences', 0))\n\n                if 0xed in encoded_bytes or 0xc0 in encoded_bytes:\n                    decoding = 'utf-8-variants'\n\n                decode_step = ('decode', decoding, 0)\n                steps = [encode_step] + transcode_steps + [decode_step]\n                fixed = encoded_bytes.decode(decoding)\n                return fixed, steps\n\n            except UnicodeDecodeError:\n                possible_1byte_encodings.append(encoding)\n\n    # Look for a-hat-euro sequences that remain, and fix them in isolation.\n    if PARTIAL_UTF8_PUNCT_RE.search(text):\n        steps = [('transcode', 'fix_partial_utf8_punct_in_1252', 1)]\n        fixed = fix_partial_utf8_punct_in_1252(text)\n        return fixed, steps\n\n    # The next most likely case is that this is Latin-1 that was intended to\n    # be read as Windows-1252, because those two encodings in particular are\n    # easily confused.\n    if 'latin-1' in possible_1byte_encodings:\n        if 'windows-1252' in possible_1byte_encodings:\n            # This text is in the intersection of Latin-1 and\n            # Windows-1252, so it's probably legit.\n            return text, []\n        else:\n            # Otherwise, it means we have characters that are in Latin-1 but\n            # not in Windows-1252. Those are C1 control characters. Nobody\n            # wants those. Assume they were meant to be Windows-1252. Don't\n            # use the sloppy codec, because bad Windows-1252 characters are\n            # a bad sign.\n            encoded = text.encode('latin-1')\n            try:\n                fixed = encoded.decode('windows-1252')\n                steps = []\n                if fixed != text:\n                    steps = [('encode', 'latin-1', 0),\n                             ('decode', 'windows-1252', 1)]\n                return fixed, steps\n            except UnicodeDecodeError:\n                # This text contained characters that don't even make sense\n                # if you assume they were supposed to be Windows-1252. In\n                # that case, let's not assume anything.\n                pass\n\n    # The cases that remain are mixups between two different single-byte\n    # encodings, and not the common case of Latin-1 vs. Windows-1252.\n    #\n    # These cases may be unsolvable without adding false positives, though\n    # I have vague ideas about how to optionally address them in the future.\n\n    # Return the text unchanged; the plan is empty.\n    return text, []", "response": "Fixes a single step of re - decoding text that s been decoded incorrectly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a plan to the encoding of text.", "response": "def apply_plan(text, plan):\n    \"\"\"\n    Apply a plan for fixing the encoding of text.\n\n    The plan is a list of tuples of the form (operation, encoding, cost):\n\n    - `operation` is 'encode' if it turns a string into bytes, 'decode' if it\n      turns bytes into a string, and 'transcode' if it keeps the type the same.\n    - `encoding` is the name of the encoding to use, such as 'utf-8' or\n      'latin-1', or the function name in the case of 'transcode'.\n    - The `cost` does not affect how the plan itself works. It's used by other\n      users of plans, namely `fix_encoding_and_explain`, which has to decide\n      *which* plan to use.\n    \"\"\"\n    obj = text\n    for operation, encoding, _ in plan:\n        if operation == 'encode':\n            obj = obj.encode(encoding)\n        elif operation == 'decode':\n            obj = obj.decode(encoding)\n        elif operation == 'transcode':\n            if encoding in TRANSCODERS:\n                obj = TRANSCODERS[encoding](obj)\n            else:\n                raise ValueError(\"Unknown transcode operation: %s\" % encoding)\n        else:\n            raise ValueError(\"Unknown plan step: %s\" % operation)\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces one matched HTML entity with the character it represents, if possible.", "response": "def _unescape_fixup(match):\n    \"\"\"\n    Replace one matched HTML entity with the character it represents,\n    if possible.\n    \"\"\"\n    text = match.group(0)\n    if text[:2] == \"&#\":\n        # character reference\n        try:\n            if text[:3] == \"&#x\":\n                codept = int(text[3:-1], 16)\n            else:\n                codept = int(text[2:-1])\n            if 0x80 <= codept < 0xa0:\n                # Decode this range of characters as Windows-1252, as Web\n                # browsers do in practice.\n                return bytes([codept]).decode('sloppy-windows-1252')\n            else:\n                return chr(codept)\n        except ValueError:\n            return text\n    else:\n        # This is a named entity; if it's a known HTML5 entity, replace\n        # it with the appropriate character.\n        try:\n            return entities.html5[text[1:]]\n        except KeyError:\n            return text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_surrogate_pair(match):\n    pair = match.group(0)\n    codept = 0x10000 + (ord(pair[0]) - 0xd800) * 0x400 + (ord(pair[1]) - 0xdc00)\n    return chr(codept)", "response": "Convert a surrogate pair to the single codepoint it represents."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_surrogates(text):\n    if SURROGATE_RE.search(text):\n        text = SURROGATE_PAIR_RE.sub(convert_surrogate_pair, text)\n        text = SURROGATE_RE.sub('\\ufffd', text)\n    return text", "response": "Fixes Unicode surrogates in a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore_byte_a0(byts):\n    def replacement(match):\n        \"The function to apply when this regex matches.\"\n        return match.group(0).replace(b'\\x20', b'\\xa0')\n\n    return ALTERED_UTF8_RE.sub(replacement, byts)", "response": "Restore the byte A0 of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_partial_utf8_punct_in_1252(text):\n    def latin1_to_w1252(match):\n        \"The function to apply when this regex matches.\"\n        return match.group(0).encode('latin-1').decode('sloppy-windows-1252')\n\n    def w1252_to_utf8(match):\n        \"The function to apply when this regex matches.\"\n        return match.group(0).encode('sloppy-windows-1252').decode('utf-8')\n\n    text = C1_CONTROL_RE.sub(latin1_to_w1252, text)\n    return PARTIAL_UTF8_PUNCT_RE.sub(w1252_to_utf8, text)", "response": "Fix some characters that are not found in wild encoded in\n    UTF - 8 and decoded in Windows - 1252."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying a string left - justified in a monospaced terminal.", "response": "def display_ljust(text, width, fillchar=' '):\n    \"\"\"\n    Return `text` left-justified in a Unicode string whose display width,\n    in a monospaced terminal, should be at least `width` character cells.\n    The rest of the string will be padded with `fillchar`, which must be\n    a width-1 character.\n\n    \"Left\" here means toward the beginning of the string, which may actually\n    appear on the right in an RTL context. This is similar to the use of the\n    word \"left\" in \"left parenthesis\".\n\n    >>> lines = ['Table flip', '(\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b', '\u3061\u3083\u3076\u53f0\u8fd4\u3057']\n    >>> for line in lines:\n    ...     print(display_ljust(line, 20, '\u2592'))\n    Table flip\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\n    (\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b\u2592\u2592\u2592\u2592\u2592\u2592\u2592\n    \u3061\u3083\u3076\u53f0\u8fd4\u3057\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\n\n    This example, and the similar ones that follow, should come out justified\n    correctly when viewed in a monospaced terminal. It will probably not look\n    correct if you're viewing this code or documentation in a Web browser.\n    \"\"\"\n    if character_width(fillchar) != 1:\n        raise ValueError(\"The padding character must have display width 1\")\n\n    text_width = monospaced_width(text)\n    if text_width == -1:\n        # There's a control character here, so just don't add padding\n        return text\n\n    padding = max(0, width - text_width)\n    return text + fillchar * padding"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn text centered in a Unicode string whose display width is at least width character cells.", "response": "def display_center(text, width, fillchar=' '):\n    \"\"\"\n    Return `text` centered in a Unicode string whose display width, in a\n    monospaced terminal, should be at least `width` character cells. The rest\n    of the string will be padded with `fillchar`, which must be a width-1\n    character.\n\n    >>> lines = ['Table flip', '(\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b', '\u3061\u3083\u3076\u53f0\u8fd4\u3057']\n    >>> for line in lines:\n    ...     print(display_center(line, 20, '\u2592'))\n    \u2592\u2592\u2592\u2592\u2592Table flip\u2592\u2592\u2592\u2592\u2592\n    \u2592\u2592\u2592(\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b\u2592\u2592\u2592\u2592\n    \u2592\u2592\u2592\u2592\u3061\u3083\u3076\u53f0\u8fd4\u3057\u2592\u2592\u2592\u2592\n    \"\"\"\n    if character_width(fillchar) != 1:\n        raise ValueError(\"The padding character must have display width 1\")\n\n    text_width = monospaced_width(text)\n    if text_width == -1:\n        return text\n\n    padding = max(0, width - text_width)\n    left_padding = padding // 2\n    right_padding = padding - left_padding\n    return fillchar * left_padding + text + fillchar * right_padding"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a codec name, and return a 'sloppy' version of that codec that can encode and decode the unassigned bytes in that encoding. Single-byte encodings in the standard library are defined using some boilerplate classes surrounding the functions that do the actual work, `codecs.charmap_decode` and `charmap_encode`. This function, given an encoding name, *defines* those boilerplate classes.", "response": "def make_sloppy_codec(encoding):\n    \"\"\"\n    Take a codec name, and return a 'sloppy' version of that codec that can\n    encode and decode the unassigned bytes in that encoding.\n\n    Single-byte encodings in the standard library are defined using some\n    boilerplate classes surrounding the functions that do the actual work,\n    `codecs.charmap_decode` and `charmap_encode`. This function, given an\n    encoding name, *defines* those boilerplate classes.\n    \"\"\"\n    # Make a bytestring of all 256 possible bytes.\n    all_bytes = bytes(range(256))\n\n    # Get a list of what they would decode to in Latin-1.\n    sloppy_chars = list(all_bytes.decode('latin-1'))\n\n    # Get a list of what they decode to in the given encoding. Use the\n    # replacement character for unassigned bytes.\n    if PY26:\n        decoded_chars = all_bytes.decode(encoding, 'replace')\n    else:\n        decoded_chars = all_bytes.decode(encoding, errors='replace')\n\n    # Update the sloppy_chars list. Each byte that was successfully decoded\n    # gets its decoded value in the list. The unassigned bytes are left as\n    # they are, which gives their decoding in Latin-1.\n    for i, char in enumerate(decoded_chars):\n        if char != REPLACEMENT_CHAR:\n            sloppy_chars[i] = char\n\n    # For ftfy's own purposes, we're going to allow byte 1A, the \"Substitute\"\n    # control code, to encode the Unicode replacement character U+FFFD.\n    sloppy_chars[0x1a] = REPLACEMENT_CHAR\n\n    # Create the data structures that tell the charmap methods how to encode\n    # and decode in this sloppy encoding.\n    decoding_table = ''.join(sloppy_chars)\n    encoding_table = codecs.charmap_build(decoding_table)\n\n    # Now produce all the class boilerplate. Look at the Python source for\n    # `encodings.cp1252` for comparison; this is almost exactly the same,\n    # except I made it follow pep8.\n    class Codec(codecs.Codec):\n        def encode(self, input, errors='strict'):\n            return codecs.charmap_encode(input, errors, encoding_table)\n\n        def decode(self, input, errors='strict'):\n            return codecs.charmap_decode(input, errors, decoding_table)\n\n    class IncrementalEncoder(codecs.IncrementalEncoder):\n        def encode(self, input, final=False):\n            return codecs.charmap_encode(input, self.errors, encoding_table)[0]\n\n    class IncrementalDecoder(codecs.IncrementalDecoder):\n        def decode(self, input, final=False):\n            return codecs.charmap_decode(input, self.errors, decoding_table)[0]\n\n    class StreamWriter(Codec, codecs.StreamWriter):\n        pass\n\n    class StreamReader(Codec, codecs.StreamReader):\n        pass\n\n    return codecs.CodecInfo(\n        name='sloppy-' + encoding,\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=StreamReader,\n        streamwriter=StreamWriter,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a list of regexs that match the weird characters in the current language.", "response": "def _make_weirdness_regex():\n    \"\"\"\n    Creates a list of regexes that match 'weird' character sequences.\n    The more matches there are, the weirder the text is.\n    \"\"\"\n    groups = []\n\n    # Match diacritical marks, except when they modify a non-cased letter or\n    # another mark.\n    #\n    # You wouldn't put a diacritical mark on a digit or a space, for example.\n    # You might put it on a Latin letter, but in that case there will almost\n    # always be a pre-composed version, and we normalize to pre-composed\n    # versions first. The cases that can't be pre-composed tend to be in\n    # large scripts without case, which are in class C.\n    groups.append('[^CM]M')\n\n    # Match non-Latin characters adjacent to Latin characters.\n    #\n    # This is a simplification from ftfy version 2, which compared all\n    # adjacent scripts. However, the ambiguities we need to resolve come from\n    # encodings designed to represent Latin characters.\n    groups.append('[Ll][AaC]')\n    groups.append('[AaC][Ll]')\n\n    # Match IPA letters next to capital letters.\n    #\n    # IPA uses lowercase letters only. Some accented capital letters next to\n    # punctuation can accidentally decode as IPA letters, and an IPA letter\n    # appearing next to a capital letter is a good sign that this happened.\n    groups.append('[LA]i')\n    groups.append('i[LA]')\n\n    # Match non-combining diacritics. We've already set aside the common ones\n    # like ^ (the CIRCUMFLEX ACCENT, repurposed as a caret, exponent sign,\n    # or happy eye) and assigned them to category 'o'. The remaining ones,\n    # like the diaeresis (\u00a8), are pretty weird to see on their own instead\n    # of combined with a letter.\n    groups.append('2')\n\n    # Match C1 control characters, which are almost always the result of\n    # decoding Latin-1 that was meant to be Windows-1252.\n    groups.append('X')\n\n    # Match private use and unassigned characters.\n    groups.append('P')\n    groups.append('_')\n\n    # Match adjacent characters from any different pair of these categories:\n    # - Modifier marks (M)\n    # - Letter modifiers (m)\n    # - Miscellaneous numbers (N)\n    # - Symbols (1 or 3, because 2 is already weird on its own)\n\n    exclusive_categories = 'MmN13'\n    for cat1 in exclusive_categories:\n        others_range = ''.join(c for c in exclusive_categories if c != cat1)\n        groups.append('{cat1}[{others_range}]'.format(\n            cat1=cat1, others_range=others_range\n        ))\n    regex = '|'.join(groups)\n    return re.compile(regex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sequence_weirdness(text):\n    text2 = unicodedata.normalize('NFC', text)\n    weirdness = len(WEIRDNESS_RE.findall(chars_to_classes(text2)))\n    adjustment = (\n        len(MOJIBAKE_SYMBOL_RE.findall(text2)) * 2 -\n        len(COMMON_SYMBOL_RE.findall(text2))\n    )\n    return weirdness * 2 + adjustment", "response": "Determines how often a text has unexpected characters or sequences of\n    characters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the compressed data file char_classes. dat and writes it to the char_classes. dat directory.", "response": "def make_char_data_file(do_it_anyway=False):\n    \"\"\"\n    Build the compressed data file 'char_classes.dat' and write it to the\n    current directory.\n\n    If you run this, run it in Python 3.7.0 or later. It will run in earlier\n    versions, but you won't get the Unicode 11 standard, leading to inconsistent\n    behavior. Pre-releases of Python 3.7 won't work (Unicode 11 wasn't out yet).\n\n    To protect against this, running this in the wrong version of Python will\n    raise an error unless you pass `do_it_anyway=True`.\n    \"\"\"\n    if sys.hexversion < 0x030700f0 and not do_it_anyway:\n        raise RuntimeError(\n            \"This function should be run in Python 3.7.0 or later.\"\n        )\n\n    cclasses = [None] * 0x110000\n    for codepoint in range(0x0, 0x110000):\n        char = chr(codepoint)\n        category = unicodedata.category(char)\n\n        if (0x250 <= codepoint < 0x300) and char != '\u0259':\n            # IPA symbols and modifiers.\n            #\n            # This category excludes the schwa (\u0259), which is used as a normal\n            # Latin letter in some languages.\n            cclasses[codepoint] = 'i'\n        elif category.startswith('L'):  # letters\n            if unicodedata.name(char, '').startswith('LATIN'):\n                if category == 'Lu':\n                    cclasses[codepoint] = 'L'\n                else:\n                    cclasses[codepoint] = 'l'\n            else:\n                if category == 'Lu' or category == 'Lt':\n                    cclasses[codepoint] = 'A'\n                elif category == 'Ll':\n                    cclasses[codepoint] = 'a'\n                elif category == 'Lo':\n                    cclasses[codepoint] = 'C'\n                elif category == 'Lm':\n                    cclasses[codepoint] = 'm'\n                else:\n                    raise ValueError('got some weird kind of letter')\n        elif 0xfe00 <= codepoint <= 0xfe0f or 0x1f3fb <= codepoint <= 0x1f3ff:\n            # Variation selectors and skin-tone modifiers have the category\n            # of non-spacing marks, but they act like symbols\n            cclasses[codepoint] = '3'\n        elif category.startswith('M'):  # marks\n            cclasses[codepoint] = 'M'\n        elif category == 'No':\n            cclasses[codepoint] = 'N'\n        elif category == 'Sm' or category == 'Sc':\n            cclasses[codepoint] = '1'\n        elif category == 'Sk':\n            cclasses[codepoint] = '2'\n        elif category == 'So':\n            cclasses[codepoint] = '3'\n        elif category == 'Cc':\n            cclasses[codepoint] = 'X'\n        elif category == 'Cs':\n            cclasses[codepoint] = 'S'\n        elif category == 'Co':\n            cclasses[codepoint] = 'P'\n        elif category.startswith('Z'):\n            cclasses[codepoint] = ' '\n        elif 0x1f000 <= codepoint <= 0x1ffff:\n            # This range is rapidly having emoji added to it. Assume that\n            # an unassigned codepoint in this range is just a symbol we\n            # don't know yet.\n            cclasses[codepoint] = '3'\n        elif category == 'Cn':\n            cclasses[codepoint] = '_'\n        else:\n            cclasses[codepoint] = 'o'\n\n    # Mark whitespace control characters as whitespace\n    cclasses[9] = cclasses[10] = cclasses[12] = cclasses[13] = ' '\n\n    # Some other exceptions for characters that are more commonly used as\n    # punctuation or decoration than for their ostensible purpose.\n    # For example, tilde is not usually a \"math symbol\", and the accents\n    # `\u00b4 are much more like quotation marks than modifiers.\n    for char in \"^~`\u00b4\u02dd\uff3e\uff40\":\n        cclasses[ord(char)] = 'o'\n\n    out = open('char_classes.dat', 'wb')\n    out.write(zlib.compress(''.join(cclasses).encode('ascii')))\n    out.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_function(encoding):\n    if encoding in _CACHE:\n        return _CACHE[encoding]\n\n    norm_encoding = normalize_encoding(encoding)\n    codec = None\n    if norm_encoding in UTF8_VAR_NAMES:\n        from ftfy.bad_codecs.utf8_variants import CODEC_INFO\n        codec = CODEC_INFO\n    elif norm_encoding.startswith('sloppy_'):\n        from ftfy.bad_codecs.sloppy import CODECS\n        codec = CODECS.get(norm_encoding)\n\n    if codec is not None:\n        _CACHE[encoding] = codec\n\n    return codec", "response": "Search for a codec for a given encoding name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _buffer_decode(self, input, errors, final):\n        # decoded_segments are the pieces of text we have decoded so far,\n        # and position is our current position in the byte string. (Bytes\n        # before this position have been consumed, and bytes after it have\n        # yet to be decoded.)\n        decoded_segments = []\n        position = 0\n        while True:\n            # Use _buffer_decode_step to decode a segment of text.\n            decoded, consumed = self._buffer_decode_step(\n                input[position:],\n                errors,\n                final\n            )\n            if consumed == 0:\n                # Either there's nothing left to decode, or we need to wait\n                # for more input. Either way, we're done for now.\n                break\n\n            # Append the decoded text to the list, and update our position.\n            decoded_segments.append(decoded)\n            position += consumed\n\n        if final:\n            # _buffer_decode_step must consume all the bytes when `final` is\n            # true.\n            assert position == len(input)\n\n        return ''.join(decoded_segments), position", "response": "Decode bytes that may be arriving in a stream following the CodecsBugs API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _buffer_decode_step(self, input, errors, final):\n        # Get a reference to the superclass method that we'll be using for\n        # most of the real work.\n        sup = UTF8IncrementalDecoder._buffer_decode\n\n        # Find the next byte position that indicates a variant of UTF-8.\n        match = SPECIAL_BYTES_RE.search(input)\n        if match is None:\n            return sup(input, errors, final)\n\n        cutoff = match.start()\n        if cutoff > 0:\n            return sup(input[:cutoff], errors, True)\n\n        # Some byte sequence that we intend to handle specially matches\n        # at the beginning of the input.\n        if input.startswith(b'\\xc0'):\n            if len(input) > 1:\n                # Decode the two-byte sequence 0xc0 0x80.\n                return '\\u0000', 2\n            else:\n                if final:\n                    # We hit the end of the stream. Let the superclass method\n                    # handle it.\n                    return sup(input, errors, True)\n                else:\n                    # Wait to see another byte.\n                    return '', 0\n        else:\n            # Decode a possible six-byte sequence starting with 0xed.\n            return self._buffer_decode_surrogates(sup, input, errors, final)", "response": "This method is called by the decoder class to decode a single character CESU - 8 sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _buffer_decode_surrogates(sup, input, errors, final):\n        if len(input) < 6:\n            if final:\n                # We found 0xed near the end of the stream, and there aren't\n                # six bytes to decode. Delegate to the superclass method to\n                # handle it as normal UTF-8. It might be a Hangul character\n                # or an error.\n                return sup(input, errors, final)\n            else:\n                # We found a surrogate, the stream isn't over yet, and we don't\n                # know enough of the following bytes to decode anything, so\n                # consume zero bytes and wait.\n                return '', 0\n        else:\n            if CESU8_RE.match(input):\n                # Given this is a CESU-8 sequence, do some math to pull out\n                # the intended 20-bit value, and consume six bytes.\n                codepoint = (\n                    ((input[1] & 0x0f) << 16) +\n                    ((input[2] & 0x3f) << 10) +\n                    ((input[4] & 0x0f) << 6) +\n                    (input[5] & 0x3f) +\n                    0x10000\n                )\n                return chr(codepoint), 6\n            else:\n                # This looked like a CESU-8 sequence, but it wasn't one.\n                # 0xed indicates the start of a three-byte sequence, so give\n                # three bytes to the superclass to decode as usual.\n                return sup(input[:3], errors, False)", "response": "This function is used to decode the surrogates in a CESU - 8 character stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfix text that is found in a file.", "response": "def fix_file(input_file,\n             encoding=None,\n             *,\n             fix_entities='auto',\n             remove_terminal_escapes=True,\n             fix_encoding=True,\n             fix_latin_ligatures=True,\n             fix_character_width=True,\n             uncurl_quotes=True,\n             fix_line_breaks=True,\n             fix_surrogates=True,\n             remove_control_chars=True,\n             remove_bom=True,\n             normalization='NFC'):\n    \"\"\"\n    Fix text that is found in a file.\n\n    If the file is being read as Unicode text, use that. If it's being read as\n    bytes, then we hope an encoding was supplied. If not, unfortunately, we\n    have to guess what encoding it is. We'll try a few common encodings, but we\n    make no promises. See the `guess_bytes` function for how this is done.\n\n    The output is a stream of fixed lines of text.\n    \"\"\"\n    entities = fix_entities\n    for line in input_file:\n        if isinstance(line, bytes):\n            if encoding is None:\n                line, encoding = guess_bytes(line)\n            else:\n                line = line.decode(encoding)\n        if fix_entities == 'auto' and '<' in line and '>' in line:\n            entities = False\n        yield fix_text_segment(\n            line,\n            fix_entities=entities,\n            remove_terminal_escapes=remove_terminal_escapes,\n            fix_encoding=fix_encoding,\n            fix_latin_ligatures=fix_latin_ligatures,\n            fix_character_width=fix_character_width,\n            uncurl_quotes=uncurl_quotes,\n            fix_line_breaks=fix_line_breaks,\n            fix_surrogates=fix_surrogates,\n            remove_control_chars=remove_control_chars,\n            remove_bom=remove_bom,\n            normalization=normalization\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies fixes to a single text segment.", "response": "def fix_text_segment(text,\n                     *,\n                     fix_entities='auto',\n                     remove_terminal_escapes=True,\n                     fix_encoding=True,\n                     fix_latin_ligatures=True,\n                     fix_character_width=True,\n                     uncurl_quotes=True,\n                     fix_line_breaks=True,\n                     fix_surrogates=True,\n                     remove_control_chars=True,\n                     remove_bom=True,\n                     normalization='NFC'):\n    \"\"\"\n    Apply fixes to text in a single chunk. This could be a line of text\n    within a larger run of `fix_text`, or it could be a larger amount\n    of text that you are certain is in a consistent encoding.\n\n    See `fix_text` for a description of the parameters.\n    \"\"\"\n    if isinstance(text, bytes):\n        raise UnicodeError(fixes.BYTES_ERROR_TEXT)\n\n    if fix_entities == 'auto' and '<' in text and '>' in text:\n        fix_entities = False\n    while True:\n        origtext = text\n        if remove_terminal_escapes:\n            text = fixes.remove_terminal_escapes(text)\n        if fix_encoding:\n            text = fixes.fix_encoding(text)\n        if fix_entities:\n            text = fixes.unescape_html(text)\n        if fix_latin_ligatures:\n            text = fixes.fix_latin_ligatures(text)\n        if fix_character_width:\n            text = fixes.fix_character_width(text)\n        if uncurl_quotes:\n            text = fixes.uncurl_quotes(text)\n        if fix_line_breaks:\n            text = fixes.fix_line_breaks(text)\n        if fix_surrogates:\n            text = fixes.fix_surrogates(text)\n        if remove_control_chars:\n            text = fixes.remove_control_chars(text)\n        if remove_bom and not remove_control_chars:\n            # Skip this step if we've already done `remove_control_chars`,\n            # because it would be redundant.\n            text = fixes.remove_bom(text)\n        if normalization is not None:\n            text = unicodedata.normalize(normalization, text)\n        if text == origtext:\n            return text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef guess_bytes(bstring):\n    if isinstance(bstring, str):\n        raise UnicodeError(\n            \"This string was already decoded as Unicode. You should pass \"\n            \"bytes to guess_bytes, not Unicode.\"\n        )\n\n    if bstring.startswith(b'\\xfe\\xff') or bstring.startswith(b'\\xff\\xfe'):\n        return bstring.decode('utf-16'), 'utf-16'\n\n    byteset = set(bstring)\n    try:\n        if 0xed in byteset or 0xc0 in byteset:\n            # Byte 0xed can be used to encode a range of codepoints that\n            # are UTF-16 surrogates. UTF-8 does not use UTF-16 surrogates,\n            # so when we see 0xed, it's very likely we're being asked to\n            # decode CESU-8, the variant that encodes UTF-16 surrogates\n            # instead of the original characters themselves.\n            #\n            # This will occasionally trigger on standard UTF-8, as there\n            # are some Korean characters that also use byte 0xed, but that's\n            # not harmful.\n            #\n            # Byte 0xc0 is impossible because, numerically, it would only\n            # encode characters lower than U+0040. Those already have\n            # single-byte representations, and UTF-8 requires using the\n            # shortest possible representation. However, Java hides the null\n            # codepoint, U+0000, in a non-standard longer representation -- it\n            # encodes it as 0xc0 0x80 instead of 0x00, guaranteeing that 0x00\n            # will never appear in the encoded bytes.\n            #\n            # The 'utf-8-variants' decoder can handle both of these cases, as\n            # well as standard UTF-8, at the cost of a bit of speed.\n            return bstring.decode('utf-8-variants'), 'utf-8-variants'\n        else:\n            return bstring.decode('utf-8'), 'utf-8'\n    except UnicodeDecodeError:\n        pass\n\n    if 0x0d in byteset and 0x0a not in byteset:\n        # Files that contain CR and not LF are likely to be MacRoman.\n        return bstring.decode('macroman'), 'macroman'\n    else:\n        return bstring.decode('sloppy-windows-1252'), 'sloppy-windows-1252'", "response": "Try to guess the bytes in a sequence of bytes from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef explain_unicode(text):\n    for char in text:\n        if char.isprintable():\n            display = char\n        else:\n            display = char.encode('unicode-escape').decode('ascii')\n        print('U+{code:04X}  {display} [{category}] {name}'.format(\n            display=display_ljust(display, 7),\n            code=ord(char),\n            category=unicodedata.category(char),\n            name=unicodedata.name(char, '<unknown>')\n        ))", "response": "A utility method that s useful for debugging mysterious Unicode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_regexes():\n    # Define a regex that matches ASCII text.\n    encoding_regexes = {'ascii': re.compile('^[\\x00-\\x7f]*$')}\n\n    for encoding in CHARMAP_ENCODINGS:\n        # Make a sequence of characters that bytes \\x80 to \\xFF decode to\n        # in each encoding, as well as byte \\x1A, which is used to represent\n        # the replacement character \ufffd in the sloppy-* encodings.\n        byte_range = bytes(list(range(0x80, 0x100)) + [0x1a])\n        charlist = byte_range.decode(encoding)\n\n        # The rest of the ASCII bytes -- bytes \\x00 to \\x19 and \\x1B\n        # to \\x7F -- will decode as those ASCII characters in any encoding we\n        # support, so we can just include them as ranges. This also lets us\n        # not worry about escaping regex special characters, because all of\n        # them are in the \\x1B to \\x7F range.\n        regex = '^[\\x00-\\x19\\x1b-\\x7f{0}]*$'.format(charlist)\n        encoding_regexes[encoding] = re.compile(regex)\n    return encoding_regexes", "response": "Build the ENCODING_REGEXES dictionary for the current charset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build_control_char_mapping():\n    control_chars = {}\n\n    for i in itertools.chain(\n            range(0x00, 0x09),\n            [0x0b],\n            range(0x0e, 0x20),\n            [0x7f],\n            range(0x206a, 0x2070),\n            [0xfeff],\n            range(0xfff9, 0xfffd),\n            range(0x1d173, 0x1d17b),\n            range(0xe0000, 0xe0080)\n    ):\n        control_chars[i] = None\n\n    return control_chars", "response": "Build a translate mapping that strips likely - unintended control characters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a translate mapping that replaces halfwidth and fullwidth forms with their standard - width forms.", "response": "def _build_width_map():\n    \"\"\"\n    Build a translate mapping that replaces halfwidth and fullwidth forms\n    with their standard-width forms.\n    \"\"\"\n    # Though it's not listed as a fullwidth character, we'll want to convert\n    # U+3000 IDEOGRAPHIC SPACE to U+20 SPACE on the same principle, so start\n    # with that in the dictionary.\n    width_map = {0x3000: ' '}\n    for i in range(0xff01, 0xfff0):\n        char = chr(i)\n        alternate = unicodedata.normalize('NFKC', char)\n        if alternate != char:\n            width_map[i] = alternate\n    return width_map"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_vml_accuracy_mode(mode):\n    if use_vml:\n        acc_dict = {None: 0, 'low': 1, 'high': 2, 'fast': 3}\n        acc_reverse_dict = {1: 'low', 2: 'high', 3: 'fast'}\n        if mode not in acc_dict.keys():\n            raise ValueError(\n                \"mode argument must be one of: None, 'high', 'low', 'fast'\")\n        retval = _set_vml_accuracy_mode(acc_dict.get(mode, 0))\n        return acc_reverse_dict.get(retval)\n    else:\n        return None", "response": "Sets the accuracy mode for VML operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_num_threads():\n    # Any platform-specific short-circuits\n    if 'sparc' in platform.machine():\n        log.warning('The number of threads have been set to 1 because problems related '\n                  'to threading have been reported on some sparc machine. '\n                  'The number of threads can be changed using the \"set_num_threads\" '\n                  'function.')\n        set_num_threads(1)\n        return 1\n\n    env_configured = False\n    n_cores = detect_number_of_cores()\n    if 'NUMEXPR_MAX_THREADS' in os.environ:\n        # The user has configured NumExpr in the expected way, so suppress logs.\n        env_configured = True\n        n_cores = MAX_THREADS\n    else:\n        # The use has not set 'NUMEXPR_MAX_THREADS', so likely they have not \n        # configured NumExpr as desired, so we emit info logs.\n        if n_cores > MAX_THREADS:\n            log.info('Note: detected %d virtual cores but NumExpr set to maximum of %d, check \"NUMEXPR_MAX_THREADS\" environment variable.'%(n_cores, MAX_THREADS))\n        if n_cores > 8:\n            # The historical 'safety' limit.\n            log.info('Note: NumExpr detected %d cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.'%n_cores)\n            n_cores = 8\n\n    # Now we check for 'NUMEXPR_NUM_THREADS' or 'OMP_NUM_THREADS' to set the \n    # actual number of threads used.\n    if 'NUMEXPR_NUM_THREADS' in os.environ:\n        requested_threads = int(os.environ['NUMEXPR_NUM_THREADS'])\n    elif 'OMP_NUM_THREADS' in os.environ:\n        requested_threads = int(os.environ['OMP_NUM_THREADS'])\n    else:\n        requested_threads = n_cores\n        if not env_configured:\n            log.info('NumExpr defaulting to %d threads.'%n_cores)\n\n    # The C-extension function performs its own checks against `MAX_THREADS`\n    set_num_threads(requested_threads)\n    return requested_threads", "response": "Initialize the number of threads for a threadpool."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_number_of_cores():\n    # Linux, Unix and MacOS:\n    if hasattr(os, \"sysconf\"):\n        if \"SC_NPROCESSORS_ONLN\" in os.sysconf_names:\n            # Linux & Unix:\n            ncpus = os.sysconf(\"SC_NPROCESSORS_ONLN\")\n            if isinstance(ncpus, int) and ncpus > 0:\n                return ncpus\n        else:  # OSX:\n            return int(subprocess.check_output([\"sysctl\", \"-n\", \"hw.ncpu\"]))\n    # Windows:\n    try:\n        ncpus = int(os.environ.get(\"NUMBER_OF_PROCESSORS\", \"\"))\n        if ncpus > 0:\n            return ncpus\n    except ValueError:\n        pass\n    return 1", "response": "Detects the number of cores on a system. Cribbed from pp.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting the number of threads in a node.", "response": "def detect_number_of_threads():\n    \"\"\"\n    DEPRECATED: use `_init_num_threads` instead.\n    If this is modified, please update the note in: https://github.com/pydata/numexpr/wiki/Numexpr-Users-Guide\n    \"\"\"\n    log.warning('Deprecated, use `init_num_threads` instead.')\n    try:\n        nthreads = int(os.environ.get('NUMEXPR_NUM_THREADS', ''))\n    except ValueError:\n        try:\n            nthreads = int(os.environ.get('OMP_NUM_THREADS', ''))\n        except ValueError:\n            nthreads = detect_number_of_cores()\n\n    # Check that we don't surpass the MAX_THREADS in interpreter.cpp\n    if nthreads > MAX_THREADS:\n        nthreads = MAX_THREADS\n    return nthreads"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchunk vectorizer which keeps memory use down.", "response": "def chunkify(chunksize):\n    \"\"\" Very stupid \"chunk vectorizer\" which keeps memory use down.\n        This version requires all inputs to have the same number of elements,\n        although it shouldn't be that hard to implement simple broadcasting.\n    \"\"\"\n\n    def chunkifier(func):\n\n        def wrap(*args):\n\n            assert len(args) > 0\n            assert all(len(a.flat) == len(args[0].flat) for a in args)\n\n            nelements = len(args[0].flat)\n            nchunks, remain = divmod(nelements, chunksize)\n\n            out = np.ndarray(args[0].shape)\n\n            for start in range(0, nelements, chunksize):\n                #print(start)\n                stop = start+chunksize\n                if start+chunksize > nelements:\n                    stop = nelements-start\n                iargs = tuple(a.flat[start:stop] for a in args)\n                out.flat[start:stop] = func(*iargs)\n            return out\n\n        return wrap\n\n    return chunkifier"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expressionToAST(ex):\n    return ASTNode(ex.astType, ex.astKind, ex.value,\n                   [expressionToAST(c) for c in ex.children])", "response": "Take an expression tree made out of expressions. ExpressionNode and convert to an AST tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sigPerms(s):\n    codes = 'bilfdc'\n    if not s:\n        yield ''\n    elif s[0] in codes:\n        start = codes.index(s[0])\n        for x in codes[start:]:\n            for y in sigPerms(s[1:]):\n                yield x + y\n    elif s[0] == 's':  # numbers shall not be cast to strings\n        for y in sigPerms(s[1:]):\n            yield 's' + y\n    else:\n        yield s", "response": "Generate all possible signatures derived by upcasting the given\n    signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning appropiate types to each node in the AST.", "response": "def typeCompileAst(ast):\n    \"\"\"Assign appropiate types to each node in the AST.\n\n    Will convert opcodes and functions to appropiate upcast version,\n    and add \"cast\" ops if needed.\n    \"\"\"\n    children = list(ast.children)\n    if ast.astType == 'op':\n        retsig = ast.typecode()\n        basesig = ''.join(x.typecode() for x in list(ast.children))\n        # Find some operation that will work on an acceptable casting of args.\n        for sig in sigPerms(basesig):\n            value = (ast.value + '_' + retsig + sig).encode('ascii')\n            if value in interpreter.opcodes:\n                break\n        else:\n            for sig in sigPerms(basesig):\n                funcname = (ast.value + '_' + retsig + sig).encode('ascii')\n                if funcname in interpreter.funccodes:\n                    value = ('func_%sn' % (retsig + sig)).encode('ascii')\n                    children += [ASTNode('raw', 'none',\n                                         interpreter.funccodes[funcname])]\n                    break\n            else:\n                raise NotImplementedError(\n                    \"couldn't find matching opcode for '%s'\"\n                    % (ast.value + '_' + retsig + basesig))\n        # First just cast constants, then cast variables if necessary:\n        for i, (have, want) in enumerate(zip(basesig, sig)):\n            if have != want:\n                kind = typecode_to_kind[want]\n                if children[i].astType == 'constant':\n                    children[i] = ASTNode('constant', kind, children[i].value)\n                else:\n                    opname = \"cast\"\n                    children[i] = ASTNode('op', kind, opname, [children[i]])\n    else:\n        value = ast.value\n        children = ast.children\n    return ASTNode(ast.astType, ast.astKind, value,\n                   [typeCompileAst(c) for c in children])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stringToExpression(s, types, context):\n    old_ctx = expressions._context.get_current_context()\n    try:\n        expressions._context.set_new_context(context)\n        # first compile to a code object to determine the names\n        if context.get('truediv', False):\n            flags = __future__.division.compiler_flag\n        else:\n            flags = 0\n        c = compile(s, '<expr>', 'eval', flags)\n        # make VariableNode's for the names\n        names = {}\n        for name in c.co_names:\n            if name == \"None\":\n                names[name] = None\n            elif name == \"True\":\n                names[name] = True\n            elif name == \"False\":\n                names[name] = False\n            else:\n                t = types.get(name, default_type)\n                names[name] = expressions.VariableNode(name, type_to_kind[t])\n        names.update(expressions.functions)\n        # now build the expression\n        ex = eval(c, names)\n        if expressions.isConstant(ex):\n            ex = expressions.ConstantNode(ex, expressions.getKind(ex))\n        elif not isinstance(ex, expressions.ExpressionNode):\n            raise TypeError(\"unsupported expression type: %s\" % type(ex))\n    finally:\n        expressions._context.set_new_context(old_ctx)\n    return ex", "response": "Given a string s convert it to a tree of ExpressionNode s."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nderiving the input order of the variables in an expression.", "response": "def getInputOrder(ast, input_order=None):\n    \"\"\"Derive the input order of the variables in an expression.\n    \"\"\"\n    variables = {}\n    for a in ast.allOf('variable'):\n        variables[a.value] = a\n    variable_names = set(variables.keys())\n\n    if input_order:\n        if variable_names != set(input_order):\n            raise ValueError(\n                \"input names (%s) don't match those found in expression (%s)\"\n                % (input_order, variable_names))\n\n        ordered_names = input_order\n    else:\n        ordered_names = list(variable_names)\n        ordered_names.sort()\n    ordered_variables = [variables[v] for v in ordered_names]\n    return ordered_variables"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all constants in the given AST node.", "response": "def getConstants(ast):\n    '''\n    RAM: implemented magic method __lt__ for ASTNode to fix issues\n    #88 and #209. The following test code works now, as does the test suite.\n    import numexpr as ne\n    a = 1 + 3j; b = 5.0\n    ne.evaluate( 'a*2 + 15j - b' )\n    '''\n    constants_order = sorted( ast.allOf('constant') )\n    constants = [convertConstantToKind(a.value, a.astKind)\n                 for a in constants_order]\n    return constants_order, constants"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning new registers to each of the leaf nodes.", "response": "def assignLeafRegisters(inodes, registerMaker):\n    \"\"\"Assign new registers to each of the leaf nodes.\n    \"\"\"\n    leafRegisters = {}\n    for node in inodes:\n        key = node.key()\n        if key in leafRegisters:\n            node.reg = leafRegisters[key]\n        else:\n            node.reg = leafRegisters[key] = registerMaker(node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assignBranchRegisters(inodes, registerMaker):\n    for node in inodes:\n        node.reg = registerMaker(node, temporary=True)", "response": "Assign temporary registers to each of the branch nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to minimize the number of temporaries needed by the given ast.", "response": "def optimizeTemporariesAllocation(ast):\n    \"\"\"Attempt to minimize the number of temporaries needed, by\n    reusing old ones.\n    \"\"\"\n    nodes = [n for n in ast.postorderWalk() if n.reg.temporary]\n    users_of = dict((n.reg, set()) for n in nodes)\n\n    node_regs = dict((n, set(c.reg for c in n.children if c.reg.temporary))\n                     for n in nodes)\n    if nodes and nodes[-1] is not ast:\n        nodes_to_check = nodes + [ast]\n    else:\n        nodes_to_check = nodes\n    for n in nodes_to_check:\n        for c in n.children:\n            if c.reg.temporary:\n                users_of[c.reg].add(n)\n\n    unused = dict([(tc, set()) for tc in scalar_constant_kinds])\n    for n in nodes:\n        for c in n.children:\n            reg = c.reg\n            if reg.temporary:\n                users = users_of[reg]\n                users.discard(n)\n                if not users:\n                    unused[reg.node.astKind].add(reg)\n        if unused[n.astKind]:\n            reg = unused[n.astKind].pop()\n            users_of[reg] = users_of[n.reg]\n            n.reg = reg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning register numbers to nodes in order.", "response": "def setOrderedRegisterNumbers(order, start):\n    \"\"\"Given an order of nodes, assign register numbers.\n    \"\"\"\n    for i, node in enumerate(order):\n        node.reg.n = start + i\n    return start + len(order)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nassign register numbers for temporary registers keeping track of aliases and handling immediate operands.", "response": "def setRegisterNumbersForTemporaries(ast, start):\n    \"\"\"Assign register numbers for temporary registers, keeping track of\n    aliases and handling immediate operands.\n    \"\"\"\n    seen = 0\n    signature = ''\n    aliases = []\n    for node in ast.postorderWalk():\n        if node.astType == 'alias':\n            aliases.append(node)\n            node = node.value\n        if node.reg.immediate:\n            node.reg.n = node.value\n            continue\n        reg = node.reg\n        if reg.n is None:\n            reg.n = start + seen\n            seen += 1\n            signature += reg.node.typecode()\n    for node in aliases:\n        node.reg = node.value.reg\n    return start + seen, signature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an AST to a three address form.", "response": "def convertASTtoThreeAddrForm(ast):\n    \"\"\"Convert an AST to a three address form.\n\n    Three address form is (op, reg1, reg2, reg3), where reg1 is the\n    destination of the result of the instruction.\n\n    I suppose this should be called three register form, but three\n    address form is found in compiler theory.\n    \"\"\"\n    return [(node.value, node.reg) + tuple([c.reg for c in node.children])\n            for node in ast.allOf('op')]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a three address form of the program return a string that contains the three address form of the program.", "response": "def compileThreeAddrForm(program):\n    \"\"\"Given a three address form of the program, compile it a string that\n    the VM understands.\n    \"\"\"\n\n    def nToChr(reg):\n        if reg is None:\n            return b'\\xff'\n        elif reg.n < 0:\n            raise ValueError(\"negative value for register number %s\" % reg.n)\n        else:\n            if sys.version_info[0] < 3:\n                return chr(reg.n)\n            else:\n                # int.to_bytes is not available in Python < 3.2\n                #return reg.n.to_bytes(1, sys.byteorder)\n                return bytes([reg.n])\n\n    def quadrupleToString(opcode, store, a1=None, a2=None):\n        cop = chr(interpreter.opcodes[opcode]).encode('ascii')\n        cs = nToChr(store)\n        ca1 = nToChr(a1)\n        ca2 = nToChr(a2)\n        return cop + cs + ca1 + ca2\n\n    def toString(args):\n        while len(args) < 4:\n            args += (None,)\n        opcode, store, a1, a2 = args[:4]\n        s = quadrupleToString(opcode, store, a1, a2)\n        l = [s]\n        args = args[4:]\n        while args:\n            s = quadrupleToString(b'noop', *args[:3])\n            l.append(s)\n            args = args[3:]\n        return b''.join(l)\n\n    prog_str = b''.join([toString(t) for t in program])\n    return prog_str"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef precompile(ex, signature=(), context={}):\n    types = dict(signature)\n    input_order = [name for (name, type_) in signature]\n\n    if isinstance(ex, (str, unicode)):\n        ex = stringToExpression(ex, types, context)\n\n    # the AST is like the expression, but the node objects don't have\n    # any odd interpretations\n\n    ast = expressionToAST(ex)\n\n    if ex.astType != 'op':\n        ast = ASTNode('op', value='copy', astKind=ex.astKind, children=(ast,))\n\n    ast = typeCompileAst(ast)\n\n    aliases = collapseDuplicateSubtrees(ast)\n\n    assignLeafRegisters(ast.allOf('raw'), Immediate)\n    assignLeafRegisters(ast.allOf('variable', 'constant'), Register)\n    assignBranchRegisters(ast.allOf('op'), Register)\n\n    # assign registers for aliases\n    for a in aliases:\n        a.reg = a.value.reg\n\n    input_order = getInputOrder(ast, input_order)\n    constants_order, constants = getConstants(ast)\n\n    if isReduction(ast):\n        ast.reg.temporary = False\n\n    optimizeTemporariesAllocation(ast)\n\n    ast.reg.temporary = False\n    r_output = 0\n    ast.reg.n = 0\n\n    r_inputs = r_output + 1\n    r_constants = setOrderedRegisterNumbers(input_order, r_inputs)\n    r_temps = setOrderedRegisterNumbers(constants_order, r_constants)\n    r_end, tempsig = setRegisterNumbersForTemporaries(ast, r_temps)\n\n    threeAddrProgram = convertASTtoThreeAddrForm(ast)\n    input_names = tuple([a.value for a in input_order])\n    signature = ''.join(type_to_typecode[types.get(x, default_type)]\n                        for x in input_names)\n    return threeAddrProgram, signature, tempsig, constants, input_names", "response": "Compile the expression to an intermediate form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile an expression built using E.<variable > variables to a function.", "response": "def NumExpr(ex, signature=(), **kwargs):\n    \"\"\"\n    Compile an expression built using E.<variable> variables to a function.\n\n    ex can also be specified as a string \"2*a+3*b\".\n\n    The order of the input variables and their types can be specified using the\n    signature parameter, which is a list of (name, type) pairs.\n\n    Returns a `NumExpr` object containing the compiled function.\n    \"\"\"\n    # NumExpr can be called either directly by the end-user, in which case\n    # kwargs need to be sanitized by getContext, or by evaluate,\n    # in which case kwargs are in already sanitized.\n    # In that case frame_depth is wrong (it should be 2) but it doesn't matter\n    # since it will not be used (because truediv='auto' has already been\n    # translated to either True or False).\n\n    context = getContext(kwargs, frame_depth=1)\n    threeAddrProgram, inputsig, tempsig, constants, input_names = precompile(ex, signature, context)\n    program = compileThreeAddrForm(threeAddrProgram)\n    return interpreter.NumExpr(inputsig.encode('ascii'),\n                               tempsig.encode('ascii'),\n                               program, constants, input_names)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disassemble(nex):\n    rev_opcodes = {}\n    for op in interpreter.opcodes:\n        rev_opcodes[interpreter.opcodes[op]] = op\n    r_constants = 1 + len(nex.signature)\n    r_temps = r_constants + len(nex.constants)\n\n    def getArg(pc, offset):\n        if sys.version_info[0] < 3:\n            arg = ord(nex.program[pc + offset])\n            op = rev_opcodes.get(ord(nex.program[pc]))\n        else:\n            arg = nex.program[pc + offset]\n            op = rev_opcodes.get(nex.program[pc])\n        try:\n            code = op.split(b'_')[1][offset - 1]\n        except IndexError:\n            return None\n        if sys.version_info[0] > 2:\n            # int.to_bytes is not available in Python < 3.2\n            #code = code.to_bytes(1, sys.byteorder)\n            code = bytes([code])\n        if arg == 255:\n            return None\n        if code != b'n':\n            if arg == 0:\n                return b'r0'\n            elif arg < r_constants:\n                return ('r%d[%s]' % (arg, nex.input_names[arg - 1])).encode('ascii')\n            elif arg < r_temps:\n                return ('c%d[%s]' % (arg, nex.constants[arg - r_constants])).encode('ascii')\n            else:\n                return ('t%d' % (arg,)).encode('ascii')\n        else:\n            return arg\n\n    source = []\n    for pc in range(0, len(nex.program), 4):\n        if sys.version_info[0] < 3:\n            op = rev_opcodes.get(ord(nex.program[pc]))\n        else:\n            op = rev_opcodes.get(nex.program[pc])\n        dest = getArg(pc, 1)\n        arg1 = getArg(pc, 2)\n        arg2 = getArg(pc, 3)\n        source.append((op, dest, arg1, arg2))\n    return source", "response": "Disassemble a NumExpr object into a list of binary files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the arguments based on the names.", "response": "def getArguments(names, local_dict=None, global_dict=None):\n    \"\"\"Get the arguments based on the names.\"\"\"\n    call_frame = sys._getframe(2)\n\n    clear_local_dict = False\n    if local_dict is None:\n        local_dict = call_frame.f_locals\n        clear_local_dict = True\n    try:\n        frame_globals = call_frame.f_globals\n        if global_dict is None:\n            global_dict = frame_globals\n\n        # If `call_frame` is the top frame of the interpreter we can't clear its \n        # `local_dict`, because it is actually the `global_dict`.\n        clear_local_dict = clear_local_dict and not frame_globals is local_dict\n\n        arguments = []\n        for name in names:\n            try:\n                a = local_dict[name]\n            except KeyError:\n                a = global_dict[name]\n            arguments.append(numpy.asarray(a))\n    finally:\n        # If we generated local_dict via an explicit reference to f_locals,\n        # clear the dict to prevent creating extra ref counts in the caller's scope\n        # See https://github.com/pydata/numexpr/issues/310\n        if clear_local_dict:\n            local_dict.clear()\n\n    return arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate(ex, local_dict=None, global_dict=None,\n             out=None, order='K', casting='safe', **kwargs):\n    \"\"\"Evaluate a simple array expression element-wise, using the new iterator.\n\n    ex is a string forming an expression, like \"2*a+3*b\". The values for \"a\"\n    and \"b\" will by default be taken from the calling function's frame\n    (through use of sys._getframe()). Alternatively, they can be specifed\n    using the 'local_dict' or 'global_dict' arguments.\n\n    Parameters\n    ----------\n\n    local_dict : dictionary, optional\n        A dictionary that replaces the local operands in current frame.\n\n    global_dict : dictionary, optional\n        A dictionary that replaces the global operands in current frame.\n\n    out : NumPy array, optional\n        An existing array where the outcome is going to be stored.  Care is\n        required so that this array has the same shape and type than the\n        actual outcome of the computation.  Useful for avoiding unnecessary\n        new array allocations.\n\n    order : {'C', 'F', 'A', or 'K'}, optional\n        Controls the iteration order for operands. 'C' means C order, 'F'\n        means Fortran order, 'A' means 'F' order if all the arrays are\n        Fortran contiguous, 'C' order otherwise, and 'K' means as close to\n        the order the array elements appear in memory as possible.  For\n        efficient computations, typically 'K'eep order (the default) is\n        desired.\n\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur when making a copy or\n        buffering.  Setting this to 'unsafe' is not recommended, as it can\n        adversely affect accumulations.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n    \"\"\"\n    global _numexpr_last\n    if not isinstance(ex, (str, unicode)):\n        raise ValueError(\"must specify expression as a string\")\n    # Get the names for this expression\n    context = getContext(kwargs, frame_depth=1)\n    expr_key = (ex, tuple(sorted(context.items())))\n    if expr_key not in _names_cache:\n        _names_cache[expr_key] = getExprNames(ex, context)\n    names, ex_uses_vml = _names_cache[expr_key]\n    arguments = getArguments(names, local_dict, global_dict)\n\n    # Create a signature\n    signature = [(name, getType(arg)) for (name, arg) in\n                 zip(names, arguments)]\n\n    # Look up numexpr if possible.\n    numexpr_key = expr_key + (tuple(signature),)\n    try:\n        compiled_ex = _numexpr_cache[numexpr_key]\n    except KeyError:\n        compiled_ex = _numexpr_cache[numexpr_key] = NumExpr(ex, signature, **context)\n    kwargs = {'out': out, 'order': order, 'casting': casting,\n              'ex_uses_vml': ex_uses_vml}\n    _numexpr_last = dict(ex=compiled_ex, argnames=names, kwargs=kwargs)\n    with evaluate_lock:\n        return compiled_ex(*arguments, **kwargs)", "response": "Evaluate a simple array expression element - wise using the new iterator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef re_evaluate(local_dict=None):\n    try:\n        compiled_ex = _numexpr_last['ex']\n    except KeyError:\n        raise RuntimeError(\"not a previous evaluate() execution found\")\n    argnames = _numexpr_last['argnames']\n    args = getArguments(argnames, local_dict)\n    kwargs = _numexpr_last['kwargs']\n    with evaluate_lock:\n        return compiled_ex(*args, **kwargs)", "response": "Re - evaluate the previous executed array expression without any check."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the row principal coordinates.", "response": "def row_coordinates(self, X):\n        \"\"\"Returns the row principal coordinates.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        # Check input\n        if self.check_input:\n            utils.check_array(X, dtype=[str, np.number])\n\n        # Prepare input\n        X = self._prepare_input(X)\n\n        return self._row_coordinates_from_global(self._build_X_global(X))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the row contributions towards each principal component.", "response": "def row_contributions(self, X):\n        \"\"\"Returns the row contributions towards each principal component.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        # Check input\n        if self.check_input:\n            utils.check_array(X, dtype=[str, np.number])\n\n        # Prepare input\n        X = self._prepare_input(X)\n\n        return super().row_contributions(self._build_X_global(X))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef partial_row_coordinates(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n\n        # Check input\n        if self.check_input:\n            utils.check_array(X, dtype=[str, np.number])\n\n        # Prepare input\n        X = self._prepare_input(X)\n\n        # Define the projection matrix P\n        P = len(X) ** 0.5 * self.U_ / self.s_\n\n        # Get the projections for each group\n        coords = {}\n        for name, cols in sorted(self.groups.items()):\n            X_partial = X.loc[:, cols]\n\n            if not self.all_nums_[name]:\n                X_partial = self.cat_one_hots_[name].transform(X_partial)\n\n            Z_partial = X_partial / self.partial_factor_analysis_[name].s_[0]\n            coords[name] = len(self.groups) * (Z_partial @ Z_partial.T) @ P\n\n        # Convert coords to a MultiIndex DataFrame\n        coords = pd.DataFrame({\n            (name, i): group_coords.loc[:, i]\n            for name, group_coords in coords.items()\n            for i in range(group_coords.shape[1])\n        })\n\n        return coords", "response": "Returns the row coordinates for each group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the column correlations.", "response": "def column_correlations(self, X):\n        \"\"\"Returns the column correlations.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        X_global = self._build_X_global(X)\n        row_pc = self._row_coordinates_from_global(X_global)\n\n        return pd.DataFrame({\n            component: {\n                feature: row_pc[component].corr(X_global[feature].to_dense())\n                for feature in X_global.columns\n            }\n            for component in row_pc.columns\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the row principal coordinates.", "response": "def plot_partial_row_coordinates(self, X, ax=None, figsize=(6, 6), x_component=0, y_component=1,\n                                     color_labels=None, **kwargs):\n        \"\"\"Plot the row principal coordinates.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=figsize)\n\n        # Add plotting style\n        ax = plot.stylize_axis(ax)\n\n        # Check input\n        if self.check_input:\n            utils.check_array(X, dtype=[str, np.number])\n\n        # Prepare input\n        X = self._prepare_input(X)\n\n        # Retrieve partial coordinates\n        coords = self.partial_row_coordinates(X)\n\n        # Determine the color of each group if there are group labels\n        if color_labels is not None:\n            colors = {g: ax._get_lines.get_next_color() for g in sorted(list(set(color_labels)))}\n\n        # Get the list of all possible markers\n        marks = itertools.cycle(list(markers.MarkerStyle.markers.keys()))\n        next(marks)  # The first marker looks pretty shit so we skip it\n\n        # Plot points\n        for name in self.groups:\n\n            mark = next(marks)\n\n            x = coords[name][x_component]\n            y = coords[name][y_component]\n\n            if color_labels is None:\n                ax.scatter(x, y, marker=mark, label=name, **kwargs)\n                continue\n\n            for color_label, color in sorted(colors.items()):\n                mask = np.array(color_labels) == color_label\n                label = '{} - {}'.format(name, color_label)\n                ax.scatter(x[mask], y[mask], marker=mark, color=color, label=label, **kwargs)\n\n        # Legend\n        ax.legend()\n\n        # Text\n        ax.set_title('Partial row principal coordinates')\n        ei = self.explained_inertia_\n        ax.set_xlabel('Component {} ({:.2f}% inertia)'.format(x_component, 100 * ei[x_component]))\n        ax.set_ylabel('Component {} ({:.2f}% inertia)'.format(y_component, 100 * ei[y_component]))\n\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n        if self.check_input:\n            utils.check_array(X)\n        return self.row_coordinates(X)", "response": "Computes the row principal coordinates of a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef column_coordinates(self, X):\n        utils.validation.check_is_fitted(self, 'V_')\n\n        _, _, _, col_names = util.make_labels_and_names(X)\n\n        if isinstance(X, pd.SparseDataFrame):\n            X = X.to_coo()\n        elif isinstance(X, pd.DataFrame):\n            X = X.to_numpy()\n\n        if self.copy:\n            X = X.copy()\n\n        # Transpose and make sure the rows sum up to 1\n        if isinstance(X, np.ndarray):\n            X = X.T / X.T.sum(axis=1)[:, None]\n        else:\n            X = X.T / X.T.sum(axis=1)\n\n        return pd.DataFrame(\n            data=X @ sparse.diags(self.row_masses_.to_numpy() ** -0.5) @ self.U_,\n            index=col_names\n        )", "response": "The column principal coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_coordinates(self, X, ax=None, figsize=(6, 6), x_component=0, y_component=1,\n                                   show_row_labels=True, show_col_labels=True, **kwargs):\n        \"\"\"Plot the principal coordinates.\"\"\"\n\n        utils.validation.check_is_fitted(self, 's_')\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=figsize)\n\n        # Add style\n        ax = plot.stylize_axis(ax)\n\n        # Get labels and names\n        row_label, row_names, col_label, col_names = util.make_labels_and_names(X)\n\n        # Plot row principal coordinates\n        row_coords = self.row_coordinates(X)\n        ax.scatter(\n            row_coords[x_component],\n            row_coords[y_component],\n            **kwargs,\n            label=row_label\n        )\n\n        # Plot column principal coordinates\n        col_coords = self.column_coordinates(X)\n        ax.scatter(\n            col_coords[x_component],\n            col_coords[y_component],\n            **kwargs,\n            label=col_label\n        )\n\n        # Add row labels\n        if show_row_labels:\n            x = row_coords[x_component]\n            y = row_coords[y_component]\n            for i, label in enumerate(row_names):\n                ax.annotate(label, (x[i], y[i]))\n\n        # Add column labels\n        if show_col_labels:\n            x = col_coords[x_component]\n            y = col_coords[y_component]\n            for i, label in enumerate(col_names):\n                ax.annotate(label, (x[i], y[i]))\n\n        # Legend\n        ax.legend()\n\n        # Text\n        ax.set_title('Principal coordinates')\n        ei = self.explained_inertia_\n        ax.set_xlabel('Component {} ({:.2f}% inertia)'.format(x_component, 100 * ei[x_component]))\n        ax.set_ylabel('Component {} ({:.2f}% inertia)'.format(y_component, 100 * ei[y_component]))\n\n        return ax", "response": "Plot the principal coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n        if self.check_input:\n            utils.check_array(X, dtype=[str, np.number])\n        return self.row_coordinates(X)", "response": "Computes the row principal coordinates of a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_coordinates(self, X, ax=None, figsize=(6, 6), x_component=0, y_component=1,\n                                   show_row_points=True, row_points_size=10, show_row_labels=False,\n                                   show_column_points=True, column_points_size=30,\n                                   show_column_labels=False, legend_n_cols=1):\n        \"\"\"Plot row and column principal coordinates.\n\n        Args:\n            ax (matplotlib.Axis): A fresh one will be created and returned if not provided.\n            figsize ((float, float)): The desired figure size if `ax` is not provided.\n            x_component (int): Number of the component used for the x-axis.\n            y_component (int): Number of the component used for the y-axis.\n            show_row_points (bool): Whether to show row principal components or not.\n            row_points_size (float): Row principal components point size.\n            show_row_labels (bool): Whether to show row labels or not.\n            show_column_points (bool): Whether to show column principal components or not.\n            column_points_size (float): Column principal components point size.\n            show_column_labels (bool): Whether to show column labels or not.\n            legend_n_cols (int): Number of columns used for the legend.\n\n        Returns:\n            matplotlib.Axis\n        \"\"\"\n\n        utils.validation.check_is_fitted(self, 'total_inertia_')\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=figsize)\n\n        # Add style\n        ax = plot.stylize_axis(ax)\n\n        # Plot row principal coordinates\n        if show_row_points or show_row_labels:\n\n            row_coords = self.row_coordinates(X)\n\n            if show_row_points:\n                ax.scatter(\n                    row_coords.iloc[:, x_component],\n                    row_coords.iloc[:, y_component],\n                    s=row_points_size,\n                    label=None,\n                    color=plot.GRAY['dark'],\n                    alpha=0.6\n                )\n\n            if show_row_labels:\n                for _, row in row_coords.iterrows():\n                    ax.annotate(row.name, (row[x_component], row[y_component]))\n\n        # Plot column principal coordinates\n        if show_column_points or show_column_labels:\n\n            col_coords = self.column_coordinates(X)\n            x = col_coords[x_component]\n            y = col_coords[y_component]\n\n            prefixes = col_coords.index.str.split('_').map(lambda x: x[0])\n\n            for prefix in prefixes.unique():\n                mask = prefixes == prefix\n\n                if show_column_points:\n                    ax.scatter(x[mask], y[mask], s=column_points_size, label=prefix)\n\n                if show_column_labels:\n                    for i, label in enumerate(col_coords[mask].index):\n                        ax.annotate(label, (x[mask][i], y[mask][i]))\n\n            ax.legend(ncol=legend_n_cols)\n\n        # Text\n        ax.set_title('Row and column principal coordinates')\n        ei = self.explained_inertia_\n        ax.set_xlabel('Component {} ({:.2f}% inertia)'.format(x_component, 100 * ei[x_component]))\n        ax.set_ylabel('Component {} ({:.2f}% inertia)'.format(y_component, 100 * ei[y_component]))\n\n        return ax", "response": "Plot row and column principal coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing an SVD with k components.", "response": "def compute_svd(X, n_components, n_iter, random_state, engine):\n    \"\"\"Computes an SVD with k components.\"\"\"\n\n    # Determine what SVD engine to use\n    if engine == 'auto':\n        engine = 'sklearn'\n\n    # Compute the SVD\n    if engine == 'fbpca':\n        if FBPCA_INSTALLED:\n            U, s, V = fbpca.pca(X, k=n_components, n_iter=n_iter)\n        else:\n            raise ValueError('fbpca is not installed; please install it if you want to use it')\n    elif engine == 'sklearn':\n        U, s, V = extmath.randomized_svd(\n            X,\n            n_components=n_components,\n            n_iter=n_iter,\n            random_state=random_state\n        )\n    else:\n        raise ValueError(\"engine has to be one of ('auto', 'fbpca', 'sklearn')\")\n\n    U, V = extmath.svd_flip(U, V)\n\n    return U, s, V"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the row principal coordinates.", "response": "def row_coordinates(self, X):\n        \"\"\"Returns the row principal coordinates.\n\n        The row principal coordinates are obtained by projecting `X` on the right eigenvectors.\n        \"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        # Extract index\n        index = X.index if isinstance(X, pd.DataFrame) else None\n\n        # Copy data\n        if self.copy:\n            X = np.copy(X)\n\n        # Scale data\n        if hasattr(self, 'scaler_'):\n            X = self.scaler_.transform(X)\n\n        return pd.DataFrame(data=X.dot(self.V_.T), index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef row_standard_coordinates(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n        return self.row_coordinates(X).div(self.eigenvalues_, axis='columns')", "response": "Returns the row standard coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef row_contributions(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n        return np.square(self.row_coordinates(X)).div(self.eigenvalues_, axis='columns')", "response": "Returns the row contributions towards each principal component."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef row_cosine_similarities(self, X):\n        utils.validation.check_is_fitted(self, 's_')\n        squared_coordinates = np.square(self.row_coordinates(X))\n        total_squares = squared_coordinates.sum(axis='columns')\n        return squared_coordinates.div(total_squares, axis='rows')", "response": "Returns the cosine similarities between the rows and their principal components."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the column correlations with each principal component.", "response": "def column_correlations(self, X):\n        \"\"\"Returns the column correlations with each principal component.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        # Convert numpy array to pandas DataFrame\n        if isinstance(X, np.ndarray):\n            X = pd.DataFrame(X)\n\n        row_pc = self.row_coordinates(X)\n\n        return pd.DataFrame({\n            component: {\n                feature: row_pc[component].corr(X[feature])\n                for feature in X.columns\n            }\n            for component in row_pc.columns\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_row_coordinates(self, X, ax=None, figsize=(6, 6), x_component=0, y_component=1,\n                             labels=None, color_labels=None, ellipse_outline=False,\n                             ellipse_fill=True, show_points=True, **kwargs):\n        \"\"\"Plot the row principal coordinates.\"\"\"\n        utils.validation.check_is_fitted(self, 's_')\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=figsize)\n\n        # Add style\n        ax = plot.stylize_axis(ax)\n\n        # Make sure X is a DataFrame\n        if not isinstance(X, pd.DataFrame):\n            X = pd.DataFrame(X)\n\n        # Retrieve principal coordinates\n        coordinates = self.row_coordinates(X)\n        x = coordinates[x_component].astype(np.float)\n        y = coordinates[y_component].astype(np.float)\n\n        # Plot\n        if color_labels is None:\n            ax.scatter(x, y, **kwargs)\n        else:\n            for color_label in sorted(list(set(color_labels))):\n                mask = np.array(color_labels) == color_label\n                color = ax._get_lines.get_next_color()\n                # Plot points\n                if show_points:\n                    ax.scatter(x[mask], y[mask], color=color, **kwargs, label=color_label)\n                # Plot ellipse\n                if (ellipse_outline or ellipse_fill):\n                    x_mean, y_mean, width, height, angle = plot.build_ellipse(x[mask], y[mask])\n                    ax.add_patch(mpl.patches.Ellipse(\n                        (x_mean, y_mean),\n                        width,\n                        height,\n                        angle=angle,\n                        linewidth=2 if ellipse_outline else 0,\n                        color=color,\n                        fill=ellipse_fill,\n                        alpha=0.2 + (0.3 if not show_points else 0) if ellipse_fill else 1\n                    ))\n\n        # Add labels\n        if labels is not None:\n            for i, label in enumerate(labels):\n                ax.annotate(label, (x[i], y[i]))\n\n        # Legend\n        ax.legend()\n\n        # Text\n        ax.set_title('Row principal coordinates')\n        ei = self.explained_inertia_\n        ax.set_xlabel('Component {} ({:.2f}% inertia)'.format(x_component, 100 * ei[x_component]))\n        ax.set_ylabel('Component {} ({:.2f}% inertia)'.format(y_component, 100 * ei[y_component]))\n\n        return ax", "response": "Plot the row principal coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing ellipse coordinates from two arrays of numbers.", "response": "def build_ellipse(X, Y):\n    \"\"\"Construct ellipse coordinates from two arrays of numbers.\n\n    Args:\n        X (1D array_like)\n        Y (1D array_like)\n\n    Returns:\n        float: The mean of `X`.\n        float: The mean of `Y`.\n        float: The width of the ellipse.\n        float: The height of the ellipse.\n        float: The angle of orientation of the ellipse.\n\n    \"\"\"\n    x_mean = np.mean(X)\n    y_mean = np.mean(Y)\n\n    cov_matrix = np.cov(np.vstack((X, Y)))\n    U, s, V = linalg.svd(cov_matrix, full_matrices=False)\n\n    chi_95 = np.sqrt(4.61)  # 90% quantile of the chi-square distribution\n    width = np.sqrt(cov_matrix[0][0]) * chi_95 * 2\n    height = np.sqrt(cov_matrix[1][1]) * chi_95 * 2\n\n    eigenvector = V.T[0]\n    angle = np.arctan(eigenvector[1] / eigenvector[0])\n\n    return x_mean, y_mean, width, height, angle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_start_time(self, start_time):\n        start_time = start_time or dt.time()\n        if isinstance(start_time, dt.time): # ensure that we operate with time\n            self.start_time = dt.time(start_time.hour, start_time.minute)\n        else:\n            self.start_time = dt.time(start_time.time().hour, start_time.time().minute)", "response": "set the start time of the drop down list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_time(match):\n    hour = int(match.group('hour'))\n    minute = int(match.group('minute'))\n    return dt.time(hour, minute)", "response": "extract time from a time_re match."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a string containing a fact and returns a dictionary of fact fields and achieved phase.", "response": "def parse_fact(text, phase=None, res=None, date=None):\n    \"\"\"tries to extract fact fields from the string\n        the optional arguments in the syntax makes us actually try parsing\n        values and fallback to next phase\n        start -> [end] -> activity[@category] -> tags\n\n        Returns dict for the fact and achieved phase\n\n        TODO - While we are now bit cooler and going recursively, this code\n        still looks rather awfully spaghetterian. What is the real solution?\n\n        Tentative syntax:\n        [date] start_time[-end_time] activity[@category][, description]{[,] { })#tag}\n        According to the legacy tests, # were allowed in the description\n    \"\"\"\n    now = dt.datetime.now()\n\n    # determine what we can look for\n    phases = [\n        \"date\",  # hamster day\n        \"start_time\",\n        \"end_time\",\n        \"tags\",\n        \"activity\",\n        \"category\",\n    ]\n\n    phase = phase or phases[0]\n    phases = phases[phases.index(phase):]\n    if res is None:\n        res = {}\n\n    text = text.strip()\n    if not text:\n        return res\n\n    fragment = re.split(\"[\\s|#]\", text, 1)[0].strip()\n\n    # remove a fragment assumed to be at the beginning of text\n    remove_fragment = lambda text, fragment: text[len(fragment):]\n\n    if \"date\" in phases:\n        # if there is any date given, it must be at the front\n        try:\n            date = dt.datetime.strptime(fragment, DATE_FMT).date()\n            remaining_text = remove_fragment(text, fragment)\n        except ValueError:\n            date = datetime_to_hamsterday(now)\n            remaining_text = text\n        return parse_fact(remaining_text, \"start_time\", res, date)\n\n    if \"start_time\" in phases or \"end_time\" in phases:\n\n        # -delta ?\n        delta_re = re.compile(\"^-[0-9]{1,3}$\")\n        if delta_re.match(fragment):\n            # TODO untested\n            # delta_re was probably thought to be used\n            # alone or together with a start_time\n            # but using \"now\" prevents the latter\n            res[phase] = now + dt.timedelta(minutes=int(fragment))\n            remaining_text = remove_fragment(text, fragment)\n            return parse_fact(remaining_text, phases[phases.index(phase)+1], res, date)\n\n        # only starting time ?\n        m = re.search(time_re, fragment)\n        if m:\n            time = extract_time(m)\n            res[phase] = hamsterday_time_to_datetime(date, time)\n            remaining_text = remove_fragment(text, fragment)\n            return parse_fact(remaining_text, phases[phases.index(phase)+1], res, date)\n\n        # start-end ?\n        start, __, end = fragment.partition(\"-\")\n        m_start = re.search(time_re, start)\n        m_end = re.search(time_re, end)\n        if m_start and m_end:\n            start_time = extract_time(m_start)\n            end_time = extract_time(m_end)\n            res[\"start_time\"] = hamsterday_time_to_datetime(date, start_time)\n            res[\"end_time\"] = hamsterday_time_to_datetime(date, end_time)\n            remaining_text = remove_fragment(text, fragment)\n            return parse_fact(remaining_text, \"tags\", res, date)\n\n    if \"tags\" in phases:\n        # Need to start from the end, because\n        # the description can hold some '#' characters\n        tags = []\n        remaining_text = text\n        while True:\n            m = re.search(tag_re, remaining_text)\n            if not m:\n                break\n            tag = m.group(1)\n            tags.append(tag)\n            # strip the matched string (including #)\n            remaining_text = remaining_text[:m.start()]\n        # put tags back in input order\n        res[\"tags\"] = list(reversed(tags))\n        return parse_fact(remaining_text, \"activity\", res, date)\n\n    if \"activity\" in phases:\n        activity = re.split(\"[@|#|,]\", text, 1)[0]\n        if looks_like_time(activity):\n            # want meaningful activities\n            return res\n\n        res[\"activity\"] = activity\n        remaining_text = remove_fragment(text, activity)\n        return parse_fact(remaining_text, \"category\", res, date)\n\n    if \"category\" in phases:\n        category, _, description = text.partition(\",\")\n        res[\"category\"] = category.lstrip(\"@\").strip() or None\n        res[\"description\"] = description.strip() or None\n        return res\n\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_logger(name):\n\n    # https://docs.python.org/3/howto/logging.html#logging-advanced-tutorial\n    logger = logging.getLogger(name)\n\n    # this is a basic handler, with output to stderr\n    logger_handler = logging.StreamHandler()\n    formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n    logger_handler.setFormatter(formatter)\n    logger.addHandler(logger_handler)\n\n    return logger", "response": "Return a default logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delta(self):\n        end_time = self.end_time if self.end_time else dt.datetime.now()\n        return end_time - self.start_time", "response": "Duration of the entry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string fully representing the fact.", "response": "def serialized(self, prepend_date=True):\n        \"\"\"Return a string fully representing the fact.\"\"\"\n        name = self.serialized_name()\n        datetime = self.serialized_time(prepend_date)\n        return \"%s %s\" % (datetime, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the actual dimensions after rotation", "response": "def _with_rotation(self, w, h):\n        \"\"\"calculate the actual dimensions after rotation\"\"\"\n        res_w = abs(w * math.cos(self.rotation) + h * math.sin(self.rotation))\n        res_h = abs(h * math.cos(self.rotation) + w * math.sin(self.rotation))\n        return res_w, res_h"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef queue_resize(self):\n        self._children_resize_queued = True\n        parent = getattr(self, \"parent\", None)\n        if parent and isinstance(parent, graphics.Sprite) and hasattr(parent, \"queue_resize\"):\n            parent.queue_resize()", "response": "request the element to re - check its child sprite sizes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns size required by the widget", "response": "def get_min_size(self):\n        \"\"\"returns size required by the widget\"\"\"\n        if self.visible == False:\n            return 0, 0\n        else:\n            return ((self.min_width or 0) + self.horizontal_padding + self.margin_left + self.margin_right,\n                    (self.min_height or 0) + self.vertical_padding + self.margin_top + self.margin_bottom)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, index = 0, *widgets):\n        for widget in widgets:\n            self._add(widget, index)\n            index +=1 # as we are moving forwards\n        self._sort()", "response": "insert widgets into the sprites list at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert this widget into the targets parent before the target", "response": "def insert_before(self, target):\n        \"\"\"insert this widget into the targets parent before the target\"\"\"\n        if not target.parent:\n            return\n        target.parent.insert(target.parent.sprites.index(target), self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert this widget into the targets parent container after the target", "response": "def insert_after(self, target):\n        \"\"\"insert this widget into the targets parent container after the target\"\"\"\n        if not target.parent:\n            return\n        target.parent.insert(target.parent.sprites.index(target) + 1, self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enabled(self):\n        enabled = self._enabled\n        if not enabled:\n            return False\n\n        if self.parent and isinstance(self.parent, Widget):\n            if self.parent.enabled == False:\n                return False\n\n        return True", "response": "whether the user is allowed to interact with the the\n        widget."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize_children(self):\n        width = self.width - self.horizontal_padding\n        height = self.height - self.vertical_padding\n\n        for sprite, props in (get_props(sprite) for sprite in self.sprites if sprite.visible):\n            sprite.alloc_w = width\n            sprite.alloc_h = height\n\n            w, h = getattr(sprite, \"width\", 0), getattr(sprite, \"height\", 0)\n            if hasattr(sprite, \"get_height_for_width_size\"):\n                w2, h2 = sprite.get_height_for_width_size()\n                w, h = max(w, w2), max(h, h2)\n\n            w = w * sprite.scale_x + props[\"margin_left\"] + props[\"margin_right\"]\n            h = h * sprite.scale_y + props[\"margin_top\"] + props[\"margin_bottom\"]\n\n            sprite.x = self.padding_left + props[\"margin_left\"] + (max(sprite.alloc_w * sprite.scale_x, w) - w) * getattr(sprite, \"x_align\", 0)\n            sprite.y = self.padding_top + props[\"margin_top\"] + (max(sprite.alloc_h * sprite.scale_y, h) - h) * getattr(sprite, \"y_align\", 0)\n\n\n        self.__dict__['_children_resize_queued'] = False", "response": "default container alignment is to pile stuff just up respecting only_padding margin and element s alignment properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh hamster every x secs - load today check last activity etc.", "response": "def check_hamster(self):\n        \"\"\"refresh hamster every x secs - load today, check last activity etc.\"\"\"\n        try:\n            # can't use the client because then we end up in a dbus loop\n            # as this is initiated in storage\n            todays_facts = self.storage._Storage__get_todays_facts()\n            self.check_user(todays_facts)\n        except Exception as e:\n            logger.error(\"Error while refreshing: %s\" % e)\n        finally:  # we want to go on no matter what, so in case of any error we find out about it sooner\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if we need to notify user perhaps", "response": "def check_user(self, todays_facts):\n        \"\"\"check if we need to notify user perhaps\"\"\"\n        interval = self.conf_notify_interval\n        if interval <= 0 or interval >= 121:\n            return\n\n        now = dt.datetime.now()\n        message = None\n\n        last_activity = todays_facts[-1] if todays_facts else None\n\n        # update duration of current task\n        if last_activity and not last_activity['end_time']:\n            delta = now - last_activity['start_time']\n            duration = delta.seconds /  60\n\n            if duration and duration % interval == 0:\n                message = _(\"Working on %s\") % last_activity['name']\n                self.notify_user(message)\n\n        elif self.conf_notify_on_idle:\n            #if we have no last activity, let's just calculate duration from 00:00\n            if (now.minute + now.hour * 60) % interval == 0:\n                self.notify_user(_(\"No activity\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_tracking(self, end_time):\n        facts = self.__get_todays_facts()\n        if facts and not facts[-1]['end_time']:\n            self.__touch_fact(facts[-1], end_time)\n            self.facts_changed()", "response": "Stops tracking the current activity"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_fact(self, fact_id):\n        self.start_transaction()\n        fact = self.__get_fact(fact_id)\n        if fact:\n            self.__remove_fact(fact_id)\n            self.facts_changed()\n        self.end_transaction()", "response": "Removes a fact from the storage by it s ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload interface from the glade file ; sorts out the path business", "response": "def load_ui_file(name):\n    \"\"\"loads interface from the glade file; sorts out the path business\"\"\"\n    ui = gtk.Builder()\n    ui.add_from_file(os.path.join(runtime.data_dir, name))\n    return ui"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fix_key(self, key):\n        if not key.startswith(self.GCONF_DIR):\n            return self.GCONF_DIR + key\n        else:\n            return key", "response": "Fixes the key if needed by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _key_changed(self, client, cnxn_id, entry, data=None):\n        key = self._fix_key(entry.key)[len(self.GCONF_DIR):]\n        value = self._get_value(entry.value, self.DEFAULTS[key])\n\n        self.emit('conf-changed', key, value)", "response": "Callback when a gconf key changes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_value(self, value, default):\n        vtype = type(default)\n\n        if vtype is bool:\n            return value.get_bool()\n        elif vtype is str:\n            return value.get_string()\n        elif vtype is int:\n            return value.get_int()\n        elif vtype in (list, tuple):\n            l = []\n            for i in value.get_list():\n                l.append(i.get_string())\n            return l\n\n        return None", "response": "calls appropriate gconf function by the default value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, key, default=None):\n\n        #function arguments override defaults\n        if default is None:\n            default = self.DEFAULTS.get(key, None)\n        vtype = type(default)\n\n        #we now have a valid key and type\n        if default is None:\n            logger.warn(\"Unknown key: %s, must specify default value\" % key)\n            return None\n\n        if vtype not in self.VALID_KEY_TYPES:\n            logger.warn(\"Invalid key type: %s\" % vtype)\n            return None\n\n        #for gconf refer to the full key path\n        key = self._fix_key(key)\n\n        if key not in self._notifications:\n            self._client.notify_add(key, self._key_changed, None)\n            self._notifications.append(key)\n\n        value = self._client.get(key)\n        if value is None:\n            self.set(key, default)\n            return default\n\n        value = self._get_value(value, default)\n        if value is not None:\n            return value\n\n        logger.warn(\"Unknown gconf key: %s\" % key)\n        return None", "response": "Returns the value of the key or the default value if the key is not yet in gconf\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, key, value):\n        logger.debug(\"Settings %s -> %s\" % (key, value))\n        if key in self.DEFAULTS:\n            vtype = type(self.DEFAULTS[key])\n        else:\n            vtype = type(value)\n\n        if vtype not in self.VALID_KEY_TYPES:\n            logger.warn(\"Invalid key type: %s\" % vtype)\n            return False\n\n        #for gconf refer to the full key path\n        key = self._fix_key(key)\n\n        if vtype is bool:\n            self._client.set_bool(key, value)\n        elif vtype is str:\n            self._client.set_string(key, value)\n        elif vtype is int:\n            self._client.set_int(key, value)\n        elif vtype in (list, tuple):\n            #Save every value as a string\n            strvalues = [str(i) for i in value]\n            #self._client.set_list(key, gconf.VALUE_STRING, strvalues)\n\n        return True", "response": "Sets the value of a key in gconf and connects adds a signal if the key changes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting of the hamster day.", "response": "def day_start(self):\n        \"\"\"Start of the hamster day.\"\"\"\n        day_start_minutes = self.get(\"day_start_minutes\")\n        hours, minutes = divmod(day_start_minutes, 60)\n        return dt.time(hours, minutes)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake sure fact has the correct start_time.", "response": "def localized_fact(self):\n        \"\"\"Make sure fact has the correct start_time.\"\"\"\n        fact = Fact(self.activity.get_text())\n        if fact.start_time:\n            fact.date = self.date\n        else:\n            fact.start_time = dt.datetime.now()\n        return fact"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_row_positions(self):\n        self.row_positions = [i * self.row_height for i in range(len(self.rows))]\n        self.set_size_request(0, self.row_positions[-1] + self.row_height if self.row_positions else 0)", "response": "creates a list of row positions for simpler manipulation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_suggestions(self, text=\"\"):\n\n        res = []\n\n        fact = Fact(text)\n        now = dt.datetime.now()\n\n        # figure out what we are looking for\n        # time -> activity[@category] -> tags -> description\n        # presence of an attribute means that we are not looking for the previous one\n        # we still might be looking for the current one though\n        looking_for = \"start_time\"\n        fields = [\"start_time\", \"end_time\", \"activity\", \"category\", \"tags\", \"description\", \"done\"]\n        for field in reversed(fields):\n            if getattr(fact, field, None):\n                looking_for = field\n                if text[-1] == \" \":\n                    looking_for = fields[fields.index(field)+1]\n                break\n\n\n        fragments = [f for f in re.split(\"[\\s|#]\", text)]\n        current_fragment = fragments[-1] if fragments else \"\"\n\n\n        search = extract_search(text)\n\n        matches = []\n        for match, score in self.suggestions:\n            if search in match:\n                if match.startswith(search):\n                    score += 10**8 # boost beginnings\n                matches.append((match, score))\n\n        # need to limit these guys, sorry\n        matches = sorted(matches, key=lambda x: x[1], reverse=True)[:7]\n\n        for match, score in matches:\n            label = (fact.start_time or now).strftime(\"%H:%M\")\n            if fact.end_time:\n                label += fact.end_time.strftime(\"-%H:%M\")\n\n            markup_label = label + \" \" + (stuff.escape_pango(match).replace(search, \"<b>%s</b>\" % search) if search else match)\n            label += \" \" + match\n\n            res.append(DataRow(markup_label, match, label))\n\n        # list of tuples (description, variant)\n        variants = []\n\n        if self.original_fact:\n            # editing an existing fact\n\n            variant_fact = None\n            if self.original_fact.end_time is None:\n                description = \"stop now\"\n                variant_fact = self.original_fact.copy()\n                variant_fact.end_time = now\n            elif self.original_fact == self.todays_facts[-1]:\n                # that one is too dangerous, except for the last entry\n                description = \"keep up\"\n                # Do not use Fact(..., end_time=None): it would be a no-op\n                variant_fact = self.original_fact.copy()\n                variant_fact.end_time = None\n\n            if variant_fact:\n                variant = variant_fact.serialized(prepend_date=False)\n                variants.append((description, variant))\n\n        else:\n            # brand new fact\n            description = \"start now\"\n            variant = now.strftime(\"%H:%M \")\n            variants.append((description, variant))\n\n            prev_fact = self.todays_facts[-1] if self.todays_facts else None\n            if prev_fact and prev_fact.end_time:\n                since = stuff.format_duration(now - prev_fact.end_time)\n                description = \"from previous activity, %s ago\" % since\n                variant = prev_fact.end_time.strftime(\"%H:%M \")\n                variants.append((description, variant))\n\n            description = \"start activity -n minutes ago (1 or 3 digits allowed)\"\n            variant = \"-\"\n            variants.append((description, variant))\n\n        text = text.strip()\n        if text:\n            description = \"clear\"\n            variant = \"\"\n            variants.append((description, variant))\n\n        for (description, variant) in variants:\n            res.append(DataRow(variant, description=description))\n\n        self.complete_tree.set_rows(res)", "response": "update the suggestions of the current node with the new text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dbus_fact(fact):\n    return Fact(fact[4],\n                start_time  = dt.datetime.utcfromtimestamp(fact[1]),\n                end_time = dt.datetime.utcfromtimestamp(fact[2]) if fact[2] else None,\n                description = fact[3],\n                activity_id = fact[5],\n                category = fact[6],\n                tags = fact[7],\n                date = dt.datetime.utcfromtimestamp(fact[8]).date(),\n            id = fact[0]\n            )", "response": "unpack the struct into a proper dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_facts(self, date, end_date=None, search_terms=\"\", ongoing_days=0):\n        facts = []\n        if ongoing_days:\n            # look for still ongoing activities\n            earlier_start = date - dt.timedelta(days=ongoing_days)\n            earlier_end = date - dt.timedelta(days=1)\n            earlier_facts = self._get_facts(earlier_start, earlier_end, search_terms=search_terms)\n            facts.extend(fact for fact in earlier_facts if not fact.end_time)\n        # add facts between date and end_date\n        facts.extend(self._get_facts(date, end_date, search_terms=search_terms))\n        return facts", "response": "Returns a list of facts for the time span between the date and the end_date."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of all tags. by default only those that have been set for autocomplete", "response": "def get_tags(self, only_autocomplete = False):\n        \"\"\"returns list of all tags. by default only those that have been set for autocomplete\"\"\"\n        return self._to_dict(('id', 'name', 'autocomplete'), self.conn.GetTags(only_autocomplete))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a fact to the cache.", "response": "def add_fact(self, fact, temporary_activity = False):\n        \"\"\"Add fact. activity name can use the\n        `[-]start_time[-end_time] activity@category, description #tag1 #tag2`\n        syntax, or params can be stated explicitly.\n        Params will take precedence over the derived values.\n        start_time defaults to current moment.\n        \"\"\"\n        if not fact.activity:\n            return None\n\n        serialized = fact.serialized_name()\n\n        start_timestamp = timegm((fact.start_time or dt.datetime.now()).timetuple())\n\n        end_timestamp = fact.end_time or 0\n        if end_timestamp:\n            end_timestamp = timegm(end_timestamp.timetuple())\n\n        new_id = self.conn.AddFact(serialized,\n                                   start_timestamp,\n                                   end_timestamp,\n                                   temporary_activity)\n\n        # TODO - the parsing should happen just once and preferably here\n        # we should feed (serialized_activity, start_time, end_time) into AddFact and others\n        return new_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_tracking(self, end_time = None):\n        end_time = timegm((end_time or dt.datetime.now()).timetuple())\n        return self.conn.StopTracking(end_time)", "response": "Stop tracking the current activity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the fact values. See add_fact for rules.", "response": "def update_fact(self, fact_id, fact, temporary_activity = False):\n        \"\"\"Update fact values. See add_fact for rules.\n        Update is performed via remove/insert, so the\n        fact_id after update should not be used anymore. Instead use the ID\n        from the fact dict that is returned by this function\"\"\"\n\n\n        start_time = timegm((fact.start_time or dt.datetime.now()).timetuple())\n\n        end_time = fact.end_time or 0\n        if end_time:\n            end_time = timegm(end_time.timetuple())\n\n        new_id =  self.conn.UpdateFact(fact_id,\n                                       fact.serialized_name(),\n                                       start_time,\n                                       end_time,\n                                       temporary_activity)\n        return new_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning activities for a category.", "response": "def get_category_activities(self, category_id = None):\n        \"\"\"Return activities for category. If category is not specified, will\n        return activities that have no category\"\"\"\n        category_id = category_id or -1\n        return self._to_dict(('id', 'name', 'category_id', 'category'), self.conn.GetCategoryActivities(category_id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn activity dict by name and optionally filtering by category.", "response": "def get_activity_by_name(self, activity, category_id = None, resurrect = True):\n        \"\"\"returns activity dict by name and optionally filtering by category.\n           if activity is found but is marked as deleted, it will be resurrected\n           unless told otherwise in the resurrect param\n        \"\"\"\n        category_id = category_id or 0\n        return self.conn.GetActivityByName(activity, category_id, resurrect)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling and disable action buttons depending on selected item", "response": "def category_changed_cb(self, selection, model):\n        \"\"\" enables and disables action buttons depending on selected item \"\"\"\n        (model, iter) = selection.get_selected()\n        id = 0\n        if iter is None:\n            self.activity_store.clear()\n        else:\n            self.prev_selected_activity = None\n\n            id = model[iter][0]\n            self.activity_store.load(model[iter][0])\n\n        #start with nothing\n        self.get_widget('activity_edit').set_sensitive(False)\n        self.get_widget('activity_remove').set_sensitive(False)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef activity_changed(self, selection, model):\n        (model, iter) = selection.get_selected()\n\n        # treat any selected case\n        unsorted_selected = self._get_selected_category() == -1\n        self.get_widget('activity_edit').set_sensitive(iter != None)\n        self.get_widget('activity_remove').set_sensitive(iter != None)", "response": "Enable and disable action buttons depending on selected item"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd new category to the tree and allows user to input name", "response": "def on_category_add_clicked(self, button):\n        \"\"\" appends row, jumps to it and allows user to input name \"\"\"\n\n        new_category = self.category_store.insert_before(self.category_store.unsorted_category,\n                                                         [-2, _(\"New category\")])\n\n        model = self.category_tree.get_model()\n\n        self.categoryCell.set_property(\"editable\", True)\n        self.category_tree.set_cursor_on_cell(model.get_path(new_category),\n                                         focus_column = self.category_tree.get_column(0),\n                                         focus_cell = None,\n                                         start_editing = True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_activity_add_clicked(self, button):\n        category_id = self._get_selected_category()\n\n        new_activity = self.activity_store.append([-1, _(\"New activity\"), category_id])\n\n        (model, iter) = self.selection.get_selected()\n\n        self.activityCell.set_property(\"editable\", True)\n        self.activity_tree.set_cursor_on_cell(model.get_path(new_activity),\n                                              focus_column = self.activity_tree.get_column(0),\n                                              focus_cell = None,\n                                              start_editing = True)", "response": "Adds new entry to the activity store and allows user to input name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninspect the bus for messages of interest", "response": "def bus_inspector(self, bus, message):\n        \"\"\"\n        Inspect the bus for screensaver messages of interest\n        \"\"\"\n\n        # We only care about stuff on this interface.  We did filter\n        # for it above, but even so we still hear from ourselves\n        # (hamster messages).\n        if message.get_interface() != self.screensaver_uri:\n            return True\n\n        member = message.get_member()\n\n        if member in (\"SessionIdleChanged\", \"ActiveChanged\"):\n            logger.debug(\"%s -> %s\" % (member, message.get_args_list()))\n\n            idle_state = message.get_args_list()[0]\n            if idle_state:\n                self.idle_from = dt.datetime.now()\n\n                # from gnome screensaver 2.24 to 2.28 they have switched\n                # configuration keys and signal types.\n                # luckily we can determine key by signal type\n                if member == \"SessionIdleChanged\":\n                    delay_key = \"/apps/gnome-screensaver/idle_delay\"\n                else:\n                    delay_key = \"/desktop/gnome/session/idle_delay\"\n\n                client = gconf.Client.get_default()\n                self.timeout_minutes = client.get_int(delay_key)\n\n            else:\n                self.screen_locked = False\n                self.idle_from = None\n\n            if member == \"ActiveChanged\":\n                # ActiveChanged comes before SessionIdleChanged signal\n                # as a workaround for pre 2.26, we will wait a second - maybe\n                # SessionIdleChanged signal kicks in\n                def dispatch_active_changed(idle_state):\n                    if not self.idle_was_there:\n                        self.emit('idle-changed', idle_state)\n                    self.idle_was_there = False\n\n                gobject.timeout_add_seconds(1, dispatch_active_changed, idle_state)\n\n            else:\n                # dispatch idle status change to interested parties\n                self.idle_was_there = True\n                self.emit('idle-changed', idle_state)\n\n        elif member == \"Lock\":\n            # in case of lock, lock signal will be sent first, followed by\n            # ActiveChanged and SessionIdle signals\n            logger.debug(\"Screen Lock Requested\")\n            self.screen_locked = True\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef C_(ctx, s):\n    translated = gettext.gettext('%s\\x04%s' % (ctx, s))\n    if '\\x04' in translated:\n        # no translation found, return input string\n        return s\n    return translated", "response": "Provide qualified translatable strings via context.\n    Taken from gnome - games.\n    Taken from gnome - games.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the attributes of the given class.", "response": "def def_attrs(cls,**kw):\n\t'''\n\tset attributes for class.\n\t@param cls [any class]: the class to update the given attributes in.\n\t@param kw [dictionary]: dictionary of attributes names and values.\n\n\tif the given class hasn't one (or more) of these attributes, add the attribute with its value to the class.\n\t'''\n\tfor k,v in kw.iteritems():\n\t\tif not hasattr(cls,k):\n\t\t\tsetattr(cls,k,v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_tool(tool,tooldir=None):\n\t'''\n\tload_tool: import a Python module, optionally using several directories.\n\t@param tool [string]: name of tool to import.\n\t@param tooldir [list]: directories to look for the tool.\n\t@return: the loaded module.\n\n\tWarning: this function is not thread-safe: plays with sys.path,\n\t\t\t\t\t so must run in sequence.\n\t'''\n\tif tooldir:\n\t\tassert isinstance(tooldir,list)\n\t\tsys.path=tooldir+sys.path\n\telse:\n\t\ttooldir=[]\n\ttry:\n\t\treturn __import__(tool)\n\tfinally:\n\t\tfor dt in tooldir:\n\t\t\tsys.path.remove(dt)", "response": "load_tool - load a Python module from a list of directories."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean(bld):\n\t'''removes the build files'''\n\ttry:\n\t\tproj=Environment.Environment(Options.lockfile)\n\texcept IOError:\n\t\traise Utils.WafError('Nothing to clean (project not configured)')\n\tbld.load_dirs(proj[SRCDIR],proj[BLDDIR])\n\tbld.load_envs()\n\tbld.is_install=0\n\tbld.add_subdirs([os.path.split(Utils.g_module.root_path)[0]])\n\ttry:\n\t\tbld.clean()\n\tfinally:\n\t\tbld.save()", "response": "removes the build files and the build directories"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the build files", "response": "def install(bld):\n\t'''installs the build files'''\n\tbld=check_configured(bld)\n\tOptions.commands['install']=True\n\tOptions.commands['uninstall']=False\n\tOptions.is_install=True\n\tbld.is_install=INSTALL\n\tbuild_impl(bld)\n\tbld.install()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uninstall(bld):\n\t'''removes the installed files'''\n\tOptions.commands['install']=False\n\tOptions.commands['uninstall']=True\n\tOptions.is_install=True\n\tbld.is_install=UNINSTALL\n\ttry:\n\t\tdef runnable_status(self):\n\t\t\treturn SKIP_ME\n\t\tsetattr(Task.Task,'runnable_status_back',Task.Task.runnable_status)\n\t\tsetattr(Task.Task,'runnable_status',runnable_status)\n\t\tbuild_impl(bld)\n\t\tbld.install()\n\tfinally:\n\t\tsetattr(Task.Task,'runnable_status',Task.Task.runnable_status_back)", "response": "uninstalls the installed files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the build directory", "response": "def distclean(ctx=None):\n\t'''removes the build directory'''\n\tglobal commands\n\tlst=os.listdir('.')\n\tfor f in lst:\n\t\tif f==Options.lockfile:\n\t\t\ttry:\n\t\t\t\tproj=Environment.Environment(f)\n\t\t\texcept:\n\t\t\t\tLogs.warn('could not read %r'%f)\n\t\t\t\tcontinue\n\t\t\ttry:\n\t\t\t\tshutil.rmtree(proj[BLDDIR])\n\t\t\texcept IOError:\n\t\t\t\tpass\n\t\t\texcept OSError,e:\n\t\t\t\tif e.errno!=errno.ENOENT:\n\t\t\t\t\tLogs.warn('project %r cannot be removed'%proj[BLDDIR])\n\t\t\ttry:\n\t\t\t\tos.remove(f)\n\t\t\texcept OSError,e:\n\t\t\t\tif e.errno!=errno.ENOENT:\n\t\t\t\t\tLogs.warn('file %r cannot be removed'%f)\n\t\tif not commands and f.startswith('.waf'):\n\t\t\tshutil.rmtree(f,ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dist(appname='',version=''):\n\t'''makes a tarball for redistributing the sources'''\n\timport tarfile\n\tif not appname:appname=Utils.g_module.APPNAME\n\tif not version:version=Utils.g_module.VERSION\n\ttmp_folder=appname+'-'+version\n\tif g_gz in['gz','bz2']:\n\t\tarch_name=tmp_folder+'.tar.'+g_gz\n\telse:\n\t\tarch_name=tmp_folder+'.'+'zip'\n\ttry:\n\t\tshutil.rmtree(tmp_folder)\n\texcept(OSError,IOError):\n\t\tpass\n\ttry:\n\t\tos.remove(arch_name)\n\texcept(OSError,IOError):\n\t\tpass\n\tblddir=getattr(Utils.g_module,BLDDIR,None)\n\tif not blddir:\n\t\tblddir=getattr(Utils.g_module,'out',None)\n\tcopytree('.',tmp_folder,blddir)\n\tdist_hook=getattr(Utils.g_module,'dist_hook',None)\n\tif dist_hook:\n\t\tback=os.getcwd()\n\t\tos.chdir(tmp_folder)\n\t\ttry:\n\t\t\tdist_hook()\n\t\tfinally:\n\t\t\tos.chdir(back)\n\tif g_gz in['gz','bz2']:\n\t\ttar=tarfile.open(arch_name,'w:'+g_gz)\n\t\ttar.add(tmp_folder)\n\t\ttar.close()\n\telse:\n\t\tUtils.zip_folder(tmp_folder,arch_name,tmp_folder)\n\ttry:from hashlib import sha1 as sha\n\texcept ImportError:from sha import sha\n\ttry:\n\t\tdigest=\" (sha=%r)\"%sha(Utils.readf(arch_name)).hexdigest()\n\texcept:\n\t\tdigest=''\n\tinfo('New archive created: %s%s'%(arch_name,digest))\n\tif os.path.exists(tmp_folder):shutil.rmtree(tmp_folder)\n\treturn arch_name", "response": "creates a tarball for redistributing the sources"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distcheck(appname='',version='',subdir=''):\n\t'''checks if the sources compile (tarball from 'dist')'''\n\timport tempfile,tarfile\n\tif not appname:appname=Utils.g_module.APPNAME\n\tif not version:version=Utils.g_module.VERSION\n\twaf=os.path.abspath(sys.argv[0])\n\ttarball=dist(appname,version)\n\tpath=appname+'-'+version\n\tif os.path.exists(path):\n\t\tshutil.rmtree(path)\n\tt=tarfile.open(tarball)\n\tfor x in t:t.extract(x)\n\tt.close()\n\tif subdir:\n\t\tbuild_path=os.path.join(path,subdir)\n\telse:\n\t\tbuild_path=path\n\tinstdir=tempfile.mkdtemp('.inst','%s-%s'%(appname,version))\n\tret=Utils.pproc.Popen([waf,'configure','build','install','uninstall','--destdir='+instdir],cwd=build_path).wait()\n\tif ret:\n\t\traise Utils.WafError('distcheck failed with code %i'%ret)\n\tif os.path.exists(instdir):\n\t\traise Utils.WafError('distcheck succeeded, but files were left in %s'%instdir)\n\tshutil.rmtree(path)", "response": "check dist and build"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show(self, start_date, end_date):\n\n        # title in the report file name\n        vars = {\"title\": _(\"Time track\"),\n                \"start\": start_date.strftime(\"%x\").replace(\"/\", \".\"),\n                \"end\": end_date.strftime(\"%x\").replace(\"/\", \".\")}\n        if start_date != end_date:\n            filename = \"%(title)s, %(start)s - %(end)s.html\" % vars\n        else:\n            filename = \"%(title)s, %(start)s.html\" % vars\n\n        self.dialog.set_current_name(filename)\n\n        response = self.dialog.run()\n\n        if response != gtk.ResponseType.OK:\n            self.emit(\"report-chooser-closed\")\n            self.dialog.destroy()\n            self.dialog = None\n        else:\n            self.on_save_button_clicked()", "response": "shows the report file name for the specified start and end date"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding tween for the object to set values.", "response": "def add_tween(self, obj, duration = None, easing = None, on_complete = None,\n                  on_update = None, round = False, delay = None, **kwargs):\n        \"\"\"\n            Add tween for the object to go from current values to set ones.\n            Example: add_tween(sprite, x = 500, y = 200, duration = 0.4)\n            This will move the sprite to coordinates (500, 200) in 0.4 seconds.\n            For parameter \"easing\" you can use one of the pytweener.Easing\n            functions, or specify your own.\n            The tweener can handle numbers, dates and color strings in hex (\"#ffffff\").\n            This function performs overwrite style conflict solving - in case\n            if a previous tween operates on same attributes, the attributes in\n            question are removed from that tween.\n        \"\"\"\n        if duration is None:\n            duration = self.default_duration\n\n        easing = easing or self.default_easing\n\n        tw = Tween(obj, duration, delay, easing, on_complete, on_update, round, **kwargs )\n\n        if obj in self.current_tweens:\n            for current_tween in tuple(self.current_tweens[obj]):\n                prev_keys = set((key for (key, tweenable) in current_tween.tweenables))\n                dif = prev_keys & set(kwargs.keys())\n\n                for key, tweenable in tuple(current_tween.tweenables):\n                    if key in dif:\n                        current_tween.tweenables.remove((key, tweenable))\n\n                if not current_tween.tweenables:\n                    current_tween.finish()\n                    self.current_tweens[obj].remove(current_tween)\n\n\n        self.current_tweens[obj].add(tw)\n        return tw"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kill_tweens(self, obj = None):\n        if obj is not None:\n            try:\n                del self.current_tweens[obj]\n            except:\n                pass\n        else:\n            self.current_tweens = collections.defaultdict(set)", "response": "Kill tweening an object without completing the motion or firing the the\n            on_complete"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_tween(self, tween):\n        if tween.target in self.current_tweens and tween in self.current_tweens[tween.target]:\n            self.current_tweens[tween.target].remove(tween)\n            if not self.current_tweens[tween.target]:\n                del self.current_tweens[tween.target]", "response": "remove given tween without completing the motion or firing the on_complete"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef finish(self):\n        for obj in self.current_tweens:\n            for tween in self.current_tweens[obj]:\n                tween.finish()\n        self.current_tweens = {}", "response": "jump the last frame of all tweens"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate tweeners. delta_seconds is time in seconds since last frame", "response": "def update(self, delta_seconds):\n        \"\"\"update tweeners. delta_seconds is time in seconds since last frame\"\"\"\n\n        for obj in tuple(self.current_tweens):\n            for tween in tuple(self.current_tweens[obj]):\n                done = tween.update(delta_seconds)\n                if done:\n                    self.current_tweens[obj].remove(tween)\n                    if tween.on_complete: tween.on_complete(tween.target)\n\n            if not self.current_tweens[obj]:\n                del self.current_tweens[obj]\n\n        return self.current_tweens"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, ptime):\n        delta = self.delta + ptime\n        total_duration = self.delay + self.duration\n\n        if delta > total_duration:\n            delta = total_duration\n\n        if delta < self.delay:\n            pass\n        elif delta == total_duration:\n            for key, tweenable in self.tweenables:\n                setattr(self.target, key, tweenable.target_value)\n        else:\n            fraction = self.ease((delta - self.delay) / (total_duration - self.delay))\n\n            for key, tweenable in self.tweenables:\n                res = tweenable.update(fraction)\n                if isinstance(res, float) and self.round:\n                    res = int(res)\n                setattr(self.target, key, res)\n\n        if delta == total_duration or len(self.tweenables) == 0:\n            self.complete = True\n\n        self.delta = delta\n\n        if self.on_update:\n            self.on_update(self.target)\n\n        return self.complete", "response": "Update tween with the time since the last frame"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpecting a list of key value to work with", "response": "def set_items(self, items):\n        \"\"\"expects a list of key, value to work with\"\"\"\n        res = []\n        max_value = max(sum((rec[1] for rec in items)), 1)\n        for key, val in items:\n            res.append((key, val, val * 1.0 / max_value))\n        self._items = res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_values(self, values):\n        self.values = values\n        self.height = len(self.values) * 14\n        self._max = max(rec[1] for rec in values) if values else dt.timedelta(0)", "response": "expects a list of 2 - tuples"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts now a new fact.", "response": "def start_new_fact(self, clone_selected=True, fallback=True):\n        \"\"\"Start now a new fact.\n        clone_selected (bool): whether to start a clone of currently\n            selected fact or to create a new fact from scratch.\n        fallback (bool): if True, fall back to creating from scratch\n                         in case of no selected fact.\n        \"\"\"\n        if not clone_selected:\n            dialogs.edit.show(self, base_fact=None)\n        elif self.fact_tree.current_fact or fallback:\n            dialogs.edit.show(self, base_fact=self.fact_tree.current_fact)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the hamster day corresponding to a given civil datetime.", "response": "def datetime_to_hamsterday(civil_date_time):\n    \"\"\"Return the hamster day corresponding to a given civil datetime.\n\n    The hamster day start is taken into account.\n    \"\"\"\n\n    # work around cyclic imports\n    from hamster.lib.configuration import conf\n\n    if civil_date_time.time() < conf.day_start:\n        # early morning, between midnight and day_start\n        # => the hamster day is the previous civil day\n        hamster_date_time = civil_date_time - dt.timedelta(days=1)\n    else:\n        hamster_date_time = civil_date_time\n    # return only the date\n    return hamster_date_time.date()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the civil datetime corresponding to a given hamster day and time.", "response": "def hamsterday_time_to_datetime(hamsterday, time):\n    \"\"\"Return the civil datetime corresponding to a given hamster day and time.\n\n    The hamster day start is taken into account.\n    \"\"\"\n\n    # work around cyclic imports\n    from hamster.lib.configuration import conf\n\n    if time < conf.day_start:\n        # early morning, between midnight and day_start\n        # => the hamster day is the previous civil day\n        civil_date = hamsterday + dt.timedelta(days=1)\n    else:\n        civil_date = hamsterday\n    return dt.datetime.combine(civil_date, time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_duration(minutes, human = True):\n\n    if isinstance(minutes, dt.timedelta):\n        minutes = duration_minutes(minutes)\n\n    if not minutes:\n        if human:\n            return \"\"\n        else:\n            return \"00:00\"\n\n    if minutes < 0:\n        # format_duration did not work for negative values anyway\n        # return a warning\n        return \"NEGATIVE\"\n\n    hours = minutes / 60\n    minutes = minutes % 60\n    formatted_duration = \"\"\n\n    if human:\n        if minutes % 60 == 0:\n            # duration in round hours\n            formatted_duration += (\"%dh\") % (hours)\n        elif hours == 0:\n            # duration less than hour\n            formatted_duration += (\"%dmin\") % (minutes % 60.0)\n        else:\n            # x hours, y minutes\n            formatted_duration += (\"%dh %dmin\") % (hours, minutes % 60)\n    else:\n        formatted_duration += \"%02d:%02d\" % (hours, minutes)\n\n\n    return formatted_duration", "response": "formats duration in a human readable format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef duration_minutes(duration):\n    if isinstance(duration, list):\n        res = dt.timedelta()\n        for entry in duration:\n            res += entry\n\n        return duration_minutes(res)\n    elif isinstance(duration, dt.timedelta):\n        return duration.total_seconds() / 60\n    else:\n        return duration", "response": "returns minutes from duration"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef locale_first_weekday():\n    first_weekday = 6 #by default settle on monday\n\n    try:\n        process = os.popen(\"locale first_weekday week-1stday\")\n        week_offset, week_start = process.read().split('\\n')[:2]\n        process.close()\n        week_start = dt.date(*time.strptime(week_start, \"%Y%m%d\")[:3])\n        week_offset = dt.timedelta(int(week_offset) - 1)\n        beginning = week_start + week_offset\n        first_weekday = int(beginning.strftime(\"%w\"))\n    except:\n        logger.warn(\"WARNING - Failed to get first weekday from locale\")\n\n    return first_weekday", "response": "figure if week starts on monday or sunday"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngroup items by field described in keyfunc and counts totals using value from sumfunc", "response": "def totals(iter, keyfunc, sumfunc):\n    \"\"\"groups items by field described in keyfunc and counts totals using value\n       from sumfunc\n    \"\"\"\n    data = sorted(iter, key=keyfunc)\n    res = {}\n\n    for k, group in groupby(data, keyfunc):\n        res[k] = sum([sumfunc(entry) for entry in group])\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dateDict(date, prefix = \"\"):\n    res = {}\n\n    res[prefix+\"a\"] = date.strftime(\"%a\")\n    res[prefix+\"A\"] = date.strftime(\"%A\")\n    res[prefix+\"b\"] = date.strftime(\"%b\")\n    res[prefix+\"B\"] = date.strftime(\"%B\")\n    res[prefix+\"c\"] = date.strftime(\"%c\")\n    res[prefix+\"d\"] = date.strftime(\"%d\")\n    res[prefix+\"H\"] = date.strftime(\"%H\")\n    res[prefix+\"I\"] = date.strftime(\"%I\")\n    res[prefix+\"j\"] = date.strftime(\"%j\")\n    res[prefix+\"m\"] = date.strftime(\"%m\")\n    res[prefix+\"M\"] = date.strftime(\"%M\")\n    res[prefix+\"p\"] = date.strftime(\"%p\")\n    res[prefix+\"S\"] = date.strftime(\"%S\")\n    res[prefix+\"U\"] = date.strftime(\"%U\")\n    res[prefix+\"w\"] = date.strftime(\"%w\")\n    res[prefix+\"W\"] = date.strftime(\"%W\")\n    res[prefix+\"x\"] = date.strftime(\"%x\")\n    res[prefix+\"X\"] = date.strftime(\"%X\")\n    res[prefix+\"y\"] = date.strftime(\"%y\")\n    res[prefix+\"Y\"] = date.strftime(\"%Y\")\n    res[prefix+\"Z\"] = date.strftime(\"%Z\")\n\n    for i, value in res.items():\n        res[i] = locale_to_utf8(value)\n\n    return res", "response": "converts a date into a dictionary having all the keys for all the keys"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __get_tag_ids(self, tags):\n\n        db_tags = self.fetchall(\"select * from tags where name in (%s)\"\n                                            % \",\".join([\"?\"] * len(tags)), tags) # bit of magic here - using sqlites bind variables\n\n        changes = False\n\n        # check if any of tags needs resurrection\n        set_complete = [str(tag[\"id\"]) for tag in db_tags if tag[\"autocomplete\"] == \"false\"]\n        if set_complete:\n            changes = True\n            self.execute(\"update tags set autocomplete='true' where id in (%s)\" % \", \".join(set_complete))\n\n\n        found_tags = [tag[\"name\"] for tag in db_tags]\n\n        add = set(tags) - set(found_tags)\n        if add:\n            statement = \"insert into tags(name) values(?)\"\n\n            self.execute([statement] * len(add), [(tag,) for tag in add])\n\n            return self.__get_tag_ids(tags)[0], True # all done, recurse\n        else:\n            return db_tags, changes", "response": "look up tags by their name. create if not found"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets most recent preferably not deleted activity by it s name", "response": "def __get_activity_by_name(self, name, category_id = None, resurrect = True):\n        \"\"\"get most recent, preferably not deleted activity by it's name\"\"\"\n\n        if category_id:\n            query = \"\"\"\n                       SELECT a.id, a.name, a.deleted, coalesce(b.name, ?) as category\n                         FROM activities a\n                    LEFT JOIN categories b ON category_id = b.id\n                        WHERE lower(a.name) = lower(?)\n                          AND category_id = ?\n                     ORDER BY a.deleted, a.id desc\n                        LIMIT 1\n            \"\"\"\n\n            res = self.fetchone(query, (self._unsorted_localized, name, category_id))\n        else:\n            query = \"\"\"\n                       SELECT a.id, a.name, a.deleted, coalesce(b.name, ?) as category\n                         FROM activities a\n                    LEFT JOIN categories b ON category_id = b.id\n                        WHERE lower(a.name) = lower(?)\n                     ORDER BY a.deleted, a.id desc\n                        LIMIT 1\n            \"\"\"\n            res = self.fetchone(query, (self._unsorted_localized, name, ))\n\n        if res:\n            keys = ('id', 'name', 'deleted', 'category')\n            res = dict([(key, res[key]) for key in keys])\n            res['deleted'] = res['deleted'] or False\n\n            # if the activity was marked as deleted, resurrect on first call\n            # and put in the unsorted category\n            if res['deleted'] and resurrect:\n                update = \"\"\"\n                            UPDATE activities\n                               SET deleted = null, category_id = -1\n                             WHERE id = ?\n                        \"\"\"\n                self.execute(update, (res['id'], ))\n\n            return res\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn category by it s name", "response": "def __get_category_id(self, name):\n        \"\"\"returns category by it's name\"\"\"\n\n        query = \"\"\"\n                   SELECT id from categories\n                    WHERE lower(name) = lower(?)\n                 ORDER BY id desc\n                    LIMIT 1\n        \"\"\"\n\n        res = self.fetchone(query, (name, ))\n\n        if res:\n            return res['id']\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __group_tags(self, facts):\n        if not facts: return facts  #be it None or whatever\n\n        grouped_facts = []\n        for fact_id, fact_tags in itertools.groupby(facts, lambda f: f[\"id\"]):\n            fact_tags = list(fact_tags)\n\n            # first one is as good as the last one\n            grouped_fact = fact_tags[0]\n\n            # we need dict so we can modify it (sqlite.Row is read only)\n            # in python 2.5, sqlite does not have keys() yet, so we hardcode them (yay!)\n            keys = [\"id\", \"start_time\", \"end_time\", \"description\", \"name\",\n                    \"activity_id\", \"category\", \"tag\"]\n            grouped_fact = dict([(key, grouped_fact[key]) for key in keys])\n\n            grouped_fact[\"tags\"] = [ft[\"tag\"] for ft in fact_tags if ft[\"tag\"]]\n            grouped_facts.append(grouped_fact)\n        return grouped_facts", "response": "group the facts by unique tags and return a list of facts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to put task in the given date if there are conflicts, we will only truncate the ongoing task and replace it's end part with our activity", "response": "def __squeeze_in(self, start_time):\n        \"\"\" tries to put task in the given date\n            if there are conflicts, we will only truncate the ongoing task\n            and replace it's end part with our activity \"\"\"\n\n        # we are checking if our start time is in the middle of anything\n        # or maybe there is something after us - so we know to adjust end time\n        # in the latter case go only few hours ahead. everything else is madness, heh\n        query = \"\"\"\n                   SELECT a.*, b.name\n                     FROM facts a\n                LEFT JOIN activities b on b.id = a.activity_id\n                    WHERE ((start_time < ? and end_time > ?)\n                           OR (start_time > ? and start_time < ? and end_time is null)\n                           OR (start_time > ? and start_time < ?))\n                 ORDER BY start_time\n                    LIMIT 1\n                \"\"\"\n        fact = self.fetchone(query, (start_time, start_time,\n                                     start_time - dt.timedelta(hours = 12),\n                                     start_time, start_time,\n                                     start_time + dt.timedelta(hours = 12)))\n        end_time = None\n        if fact:\n            if start_time > fact[\"start_time\"]:\n                #we are in middle of a fact - truncate it to our start\n                self.execute(\"UPDATE facts SET end_time=? WHERE id=?\",\n                             (start_time, fact[\"id\"]))\n\n            else: #otherwise we have found a task that is after us\n                end_time = fact[\"start_time\"]\n\n        return end_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind facts that happen in given interval and shifts them to make room for new fact", "response": "def __solve_overlaps(self, start_time, end_time):\n        \"\"\"finds facts that happen in given interval and shifts them to\n        make room for new fact\n        \"\"\"\n        if end_time is None or start_time is None:\n            return\n\n        # possible combinations and the OR clauses that catch them\n        # (the side of the number marks if it catches the end or start time)\n        #             |----------------- NEW -----------------|\n        #      |--- old --- 1|   |2 --- old --- 1|   |2 --- old ---|\n        # |3 -----------------------  big old   ------------------------ 3|\n        query = \"\"\"\n                   SELECT a.*, b.name, c.name as category\n                     FROM facts a\n                LEFT JOIN activities b on b.id = a.activity_id\n                LEFT JOIN categories c on b.category_id = c.id\n                    WHERE (end_time > ? and end_time < ?)\n                       OR (start_time > ? and start_time < ?)\n                       OR (start_time < ? and end_time > ?)\n                 ORDER BY start_time\n                \"\"\"\n        conflicts = self.fetchall(query, (start_time, end_time,\n                                          start_time, end_time,\n                                          start_time, end_time))\n\n        for fact in conflicts:\n            # won't eliminate as it is better to have overlapping entries than loosing data\n            if start_time < fact[\"start_time\"] and end_time > fact[\"end_time\"]:\n                continue\n\n            # split - truncate until beginning of new entry and create new activity for end\n            if fact[\"start_time\"] < start_time < fact[\"end_time\"] and \\\n               fact[\"start_time\"] < end_time < fact[\"end_time\"]:\n\n                logger.info(\"splitting %s\" % fact[\"name\"])\n                # truncate until beginning of the new entry\n                self.execute(\"\"\"UPDATE facts\n                                   SET end_time = ?\n                                 WHERE id = ?\"\"\", (start_time, fact[\"id\"]))\n                fact_name = fact[\"name\"]\n\n                # create new fact for the end\n                new_fact = Fact(fact[\"name\"],\n                                category = fact[\"category\"],\n                                description = fact[\"description\"])\n                new_fact_id = self.__add_fact(new_fact.serialized_name(), end_time, fact[\"end_time\"])\n\n                # copy tags\n                tag_update = \"\"\"INSERT INTO fact_tags(fact_id, tag_id)\n                                     SELECT ?, tag_id\n                                       FROM fact_tags\n                                      WHERE fact_id = ?\"\"\"\n                self.execute(tag_update, (new_fact_id, fact[\"id\"])) #clone tags\n\n            # overlap start\n            elif start_time < fact[\"start_time\"] < end_time:\n                logger.info(\"Overlapping start of %s\" % fact[\"name\"])\n                self.execute(\"UPDATE facts SET start_time=? WHERE id=?\",\n                             (end_time, fact[\"id\"]))\n\n            # overlap end\n            elif start_time < fact[\"end_time\"] < end_time:\n                logger.info(\"Overlapping end of %s\" % fact[\"name\"])\n                self.execute(\"UPDATE facts SET end_time=? WHERE id=?\",\n                             (start_time, fact[\"id\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of activities for autocomplete search string converted to lowercase", "response": "def __get_activities(self, search):\n        \"\"\"returns list of activities for autocomplete,\n           activity names converted to lowercase\"\"\"\n\n        query = \"\"\"\n                   SELECT a.name AS name, b.name AS category\n                     FROM activities a\n                LEFT JOIN categories b ON coalesce(b.id, -1) = a.category_id\n                LEFT JOIN facts f ON a.id = f.activity_id\n                    WHERE deleted IS NULL\n                      AND a.search_name LIKE ? ESCAPE '\\\\'\n                 GROUP BY a.id\n                 ORDER BY max(f.start_time) DESC, lower(a.name)\n                    LIMIT 50\n        \"\"\"\n        search = search.lower()\n        search = search.replace('\\\\', '\\\\\\\\').replace('%', '\\\\%').replace('_', '\\\\_')\n        activities = self.fetchall(query, ('%s%%' % search, ))\n\n        return activities"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving activity from database", "response": "def __remove_activity(self, id):\n        \"\"\" check if we have any facts with this activity and behave accordingly\n            if there are facts - sets activity to deleted = True\n            else, just remove it\"\"\"\n\n        query = \"select count(*) as count from facts where activity_id = ?\"\n        bound_facts = self.fetchone(query, (id,))['count']\n\n        if bound_facts > 0:\n            self.execute(\"UPDATE activities SET deleted = 1 WHERE id = ?\", (id,))\n        else:\n            self.execute(\"delete from activities where id = ?\", (id,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves category from unsorted list", "response": "def __remove_category(self, id):\n        \"\"\"move all activities to unsorted and remove category\"\"\"\n\n        affected_query = \"\"\"\n            SELECT id\n              FROM facts\n             WHERE activity_id in (SELECT id FROM activities where category_id=?)\n        \"\"\"\n        affected_ids = [res[0] for res in self.fetchall(affected_query, (id,))]\n\n        update = \"update activities set category_id = -1 where category_id = ?\"\n        self.execute(update, (id, ))\n\n        self.execute(\"delete from categories where id = ?\", (id, ))\n\n        self.__remove_index(affected_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __remove_index(self, ids):\n        if not ids:\n            return\n\n        ids = \",\".join((str(id) for id in ids))\n        self.execute(\"DELETE FROM fact_index where id in (%s)\" % ids)", "response": "remove affected ids from the index"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if index needs rebuilding in the time span", "response": "def __check_index(self, start_date, end_date):\n        \"\"\"check if maybe index needs rebuilding in the time span\"\"\"\n        index_query = \"\"\"SELECT id\n                           FROM facts\n                          WHERE (end_time >= ? OR end_time IS NULL)\n                            AND start_time <= ?\n                            AND id not in(select id from fact_index)\"\"\"\n\n        rebuild_ids = \",\".join([str(res[0]) for res in self.fetchall(index_query, (start_date, end_date))])\n\n        if rebuild_ids:\n            query = \"\"\"\n                       SELECT a.id AS id,\n                              a.start_time AS start_time,\n                              a.end_time AS end_time,\n                              a.description as description,\n                              b.name AS name, b.id as activity_id,\n                              coalesce(c.name, ?) as category,\n                              e.name as tag\n                         FROM facts a\n                    LEFT JOIN activities b ON a.activity_id = b.id\n                    LEFT JOIN categories c ON b.category_id = c.id\n                    LEFT JOIN fact_tags d ON d.fact_id = a.id\n                    LEFT JOIN tags e ON e.id = d.tag_id\n                        WHERE a.id in (%s)\n                     ORDER BY a.id\n            \"\"\" % rebuild_ids\n\n            facts = self.__group_tags(self.fetchall(query, (self._unsorted_localized, )))\n\n            insert = \"\"\"INSERT INTO fact_index (id, name, category, description, tag)\n                             VALUES (?, ?, ?, ?, ?)\"\"\"\n            params = [(fact['id'], fact['name'], fact['category'], fact['description'], \" \".join(fact['tags'])) for fact in facts]\n\n            self.executemany(insert, params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, statement, params = ()):\n        con = self.__con or self.connection\n        cur = self.__cur or con.cursor()\n\n        if isinstance(statement, list) == False: # we expect to receive instructions in list\n            statement = [statement]\n            params = [params]\n\n        for state, param in zip(statement, params):\n            logger.debug(\"%s %s\" % (state, param))\n            cur.execute(state, param)\n\n        if not self.__con:\n            con.commit()\n            cur.close()\n            self.register_modification()", "response": "execute sql statement. optionally you can give multiple statements\n        to save on cursor creation and closure"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_fixtures(self):\n        self.start_transaction()\n\n        \"\"\"upgrade DB to hamster version\"\"\"\n        version = self.fetchone(\"SELECT version FROM version\")[\"version\"]\n        current_version = 9\n\n        if version < 8:\n            # working around sqlite's utf-f case sensitivity (bug 624438)\n            # more info: http://www.gsak.net/help/hs23820.htm\n            self.execute(\"ALTER TABLE activities ADD COLUMN search_name varchar2\")\n\n            activities = self.fetchall(\"select * from activities\")\n            statement = \"update activities set search_name = ? where id = ?\"\n            for activity in activities:\n                self.execute(statement, (activity['name'].lower(), activity['id']))\n\n            # same for categories\n            self.execute(\"ALTER TABLE categories ADD COLUMN search_name varchar2\")\n            categories = self.fetchall(\"select * from categories\")\n            statement = \"update categories set search_name = ? where id = ?\"\n            for category in categories:\n                self.execute(statement, (category['name'].lower(), category['id']))\n\n        if version < 9:\n            # adding full text search\n            self.execute(\"\"\"CREATE VIRTUAL TABLE fact_index\n                                           USING fts3(id, name, category, description, tag)\"\"\")\n\n\n        # at the happy end, update version number\n        if version < current_version:\n            #lock down current version\n            self.execute(\"UPDATE version SET version = %d\" % current_version)\n            print(\"updated database from version %d to %d\" % (version, current_version))\n\n        self.end_transaction()", "response": "run the fixtures for the current version of the database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the index of the current fact in the self. facts list.", "response": "def current_fact_index(self):\n        \"\"\"Current fact index in the self.facts list.\"\"\"\n        facts_ids = [fact.id for fact in self.facts]\n        return facts_ids.index(self.current_fact.id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_row_heights(self):\n        if not self.height:\n            return\n\n        y, pos, heights = 0, [], []\n\n        for date, facts in self.days:\n            height = 0\n            for fact in facts:\n                fact_height = self.fact_row.height(fact)\n                fact.y = y + height\n                fact.height = fact_height\n\n                height += fact.height\n\n            height += self.day_padding\n\n            if not facts:\n                height = 10\n            else:\n                height = max(height, 60)\n\n            pos.append(y)\n            heights.append(height)\n            y += height\n\n\n        self.row_positions, self.row_heights = pos, heights\n\n        maxy = max(y, 1)\n\n        if self.vadjustment:\n            self.vadjustment.set_lower(0)\n            self.vadjustment.set_upper(max(maxy, self.height))\n            self.vadjustment.set_page_size(self.height)", "response": "This function sets the row heights for the current instance of the n - th row of the crowd table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chain(*steps):\n    if not steps:\n        return\n\n    def on_done(sprite=None):\n        chain(*steps[2:])\n\n    obj, params = steps[:2]\n\n    if len(steps) > 2:\n        params['on_complete'] = on_done\n    if callable(obj):\n        obj(**params)\n    else:\n        obj.animate(**params)", "response": "chains the given list of functions and object animations into a callback string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef full_pixels(space, data, gap_pixels=1):\n    available = space - (len(data) - 1) * gap_pixels # 8 recs 7 gaps\n\n    res = []\n    for i, val in enumerate(data):\n        # convert data to 0..1 scale so we deal with fractions\n        data_sum = sum(data[i:])\n        norm = val * 1.0 / data_sum\n\n\n        w = max(int(round(available * norm)), 1)\n        res.append(w)\n        available -= w\n    return res", "response": "returns the given data distributed in the given space ensuring it s full pixels\n    and with the given gap_pixels"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses string or a color tuple into color usable for cairo", "response": "def parse(self, color):\n        \"\"\"parse string or a color tuple into color usable for cairo (all values\n        in the normalized (0..1) range\"\"\"\n        assert color is not None\n\n        #parse color into rgb values\n        if isinstance(color, str):\n            match = self.hex_color_long.match(color)\n            if match:\n                color = [int(color, 16) / 65535.0 for color in match.groups()]\n            else:\n                match = self.hex_color_normal.match(color)\n                if match:\n                    color = [int(color, 16) / 255.0 for color in match.groups()]\n                else:\n                    match = self.hex_color_short.match(color)\n                    color = [int(color + color, 16) / 255.0 for color in match.groups()]\n\n        elif isinstance(color, gdk.Color):\n            color = [color.red / 65535.0,\n                     color.green / 65535.0,\n                     color.blue / 65535.0]\n\n        elif isinstance(color, (list, tuple)):\n            # otherwise we assume we have color components in 0..255 range\n            if color[0] > 1 or color[1] > 1 or color[2] > 1:\n                color = [c / 255.0 for c in color]\n        else:\n            color = [color.red, color.green, color.blue]\n\n\n        return color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn gdk. Color object of the given color", "response": "def gdk(self, color):\n        \"\"\"returns gdk.Color object of the given color\"\"\"\n        c = self.parse(color)\n        return gdk.Color.from_floats(c)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef darker(self, color, step):\n        hls = colorsys.rgb_to_hls(*self.rgb(color))\n        return colorsys.hls_to_rgb(hls[0], hls[1] - step, hls[2])", "response": "returns color darker by step"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contrast(self, color, step):\n        hls = colorsys.rgb_to_hls(*self.rgb(color))\n        if self.is_light(color):\n            return colorsys.hls_to_rgb(hls[0], hls[1] - step, hls[2])\n        else:\n            return colorsys.hls_to_rgb(hls[0], hls[1] + step, hls[2])", "response": "returns contrast of a color"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mix(self, ca, cb, xb):\n        r = (1 - xb) * ca.red + xb * cb.red\n        g = (1 - xb) * ca.green + xb * cb.green\n        b = (1 - xb) * ca.blue + xb * cb.blue\n        a = (1 - xb) * ca.alpha + xb * cb.alpha\n        return gdk.RGBA(red=r, green=g, blue=b, alpha=a)", "response": "Mix colors.\n\n        Args:\n            ca (gdk.RGBA): first color\n            cb (gdk.RGBA): second color\n            xb (float): between 0.0 and 1.0\n\n        Return:\n            gdk.RGBA: linear interpolation between ca and cb,\n                      0 or 1 return the unaltered 1st or 2nd color respectively,\n                      as in CSS."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a curve. x y x2 y2 x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3 is the middle point of the curve x3 y3", "response": "def curve_to(self, x, y, x2, y2, x3, y3):\n        \"\"\"draw a curve. (x2, y2) is the middle point of the curve\"\"\"\n        self._add_instruction(\"curve_to\", x, y, x2, y2, x3, y3)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging width and dash of a line", "response": "def set_line_style(self, width = None, dash = None, dash_offset = 0):\n        \"\"\"change width and dash of a line\"\"\"\n        if width is not None:\n            self._add_instruction(\"set_line_width\", width)\n\n        if dash is not None:\n            self._add_instruction(\"set_dash\", dash, dash_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_color(self, context, r, g, b, a):\n        if a < 1:\n            context.set_source_rgba(r, g, b, a)\n        else:\n            context.set_source_rgb(r, g, b)", "response": "set color of the current context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_color(self, color, alpha = 1):\n        color = self.colors.parse(color) # parse whatever we have there into a normalized triplet\n        if len(color) == 4 and alpha is None:\n            alpha = color[3]\n        r, g, b = color[:3]\n        self._add_instruction(\"set_color\", r, g, b, alpha)", "response": "set active color. You can use hex colors like \"#aaa\", or you can use\n        normalized RGB tripplets (where every value is in range 0..1), or\n        you can do the same thing in range 0..65535.\n        also consider skipping this operation and specify the color on stroke and\n        fill."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arc(self, x, y, radius, start_angle, end_angle):\n        self._add_instruction(\"arc\", x, y, radius, start_angle, end_angle)", "response": "draw arc going counter - clockwise from start_angle to end_angle"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ellipse(self, x, y, width, height, edges = None):\n        # the automatic edge case is somewhat arbitrary\n        steps = edges or max((32, width, height)) / 2\n\n        angle = 0\n        step = math.pi * 2 / steps\n        points = []\n        while angle < math.pi * 2:\n            points.append((width / 2.0 * math.cos(angle),\n                           height / 2.0 * math.sin(angle)))\n            angle += step\n\n        min_x = min((point[0] for point in points))\n        min_y = min((point[1] for point in points))\n\n        self.move_to(points[0][0] - min_x + x, points[0][1] - min_y + y)\n        for p_x, p_y in points:\n            self.line_to(p_x - min_x + x, p_y - min_y + y)\n        self.line_to(points[0][0] - min_x + x, points[0][1] - min_y + y)", "response": "draw perfect ellipse opposed to squashed circle. works also for forcesar polygons"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arc_negative(self, x, y, radius, start_angle, end_angle):\n        self._add_instruction(\"arc_negative\", x, y, radius, start_angle, end_angle)", "response": "draw arc going clockwise from start_angle to end_angle"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a rectangle. if corner_radius is specified, will draw rounded corners. corner_radius can be either a number or a tuple of four items to specify individually each corner, starting from top-left and going clockwise", "response": "def rectangle(self, x, y, width, height, corner_radius = 0):\n        \"\"\"draw a rectangle. if corner_radius is specified, will draw\n        rounded corners. corner_radius can be either a number or a tuple of\n        four items to specify individually each corner, starting from top-left\n        and going clockwise\"\"\"\n        if corner_radius <= 0:\n            self._add_instruction(\"rectangle\", x, y, width, height)\n            return\n\n        # convert into 4 border and  make sure that w + h are larger than 2 * corner_radius\n        if isinstance(corner_radius, (int, float)):\n            corner_radius = [corner_radius] * 4\n        corner_radius = [min(r, min(width, height) / 2) for r in corner_radius]\n\n        x2, y2 = x + width, y + height\n        self._rounded_rectangle(x, y, x2, y2, corner_radius)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fill_area(self, x, y, width, height, color, opacity = 1):\n        self.save_context()\n        self.rectangle(x, y, width, height)\n        self._add_instruction(\"clip\")\n        self.rectangle(x, y, width, height)\n        self.fill(color, opacity)\n        self.restore_context()", "response": "fill rectangular area with specified color"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fill_stroke(self, fill = None, stroke = None, opacity = 1, line_width = None):\n        if line_width: self.set_line_style(line_width)\n\n        if fill and stroke:\n            self.fill_preserve(fill, opacity)\n        elif fill:\n            self.fill(fill, opacity)\n\n        if stroke:\n            self.stroke(stroke)", "response": "fill and stroke the drawn area in one go"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_layout(self, size = None):\n        if not self.context:\n            # TODO - this is rather sloppy as far as exception goes\n            #        should explain better\n            raise Exception(\"Can not create layout without existing context!\")\n\n        layout = pangocairo.create_layout(self.context)\n        font_desc = pango.FontDescription(_font_desc)\n        if size: font_desc.set_absolute_size(size * pango.SCALE)\n\n        layout.set_font_description(font_desc)\n        return layout", "response": "utility function to create layout with the default font. Size and alignment parameters are shortcuts to according functions of the the\n            class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_label(self, text, size = None, color = None, font_desc = None):\n        font_desc = pango.FontDescription(font_desc or _font_desc)\n        if color: self.set_color(color)\n        if size: font_desc.set_absolute_size(size * pango.SCALE)\n        self.show_layout(text, font_desc)", "response": "display text. unless font_desc is provided will use system s default font"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying text in layout", "response": "def show_layout(self, text, font_desc, alignment = pango.Alignment.LEFT,\n                    width = -1, wrap = None, ellipsize = None,\n                    single_paragraph_mode = False):\n        \"\"\"display text. font_desc is string of pango font description\n           often handier than calling this function directly, is to create\n           a class:Label object\n        \"\"\"\n        layout = self._cache_layout = self._cache_layout or pangocairo.create_layout(cairo.Context(cairo.ImageSurface(cairo.FORMAT_A1, 0, 0)))\n        self._add_instruction(\"show_layout\", layout, text, font_desc,\n                              alignment, width, wrap, ellipsize, single_paragraph_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw accumulated instructions in context", "response": "def _draw(self, context, opacity):\n        \"\"\"draw accumulated instructions in context\"\"\"\n\n        # if we have been moved around, we should update bounds\n        fresh_draw = len(self.__new_instructions or []) > 0\n        if fresh_draw: #new stuff!\n            self.paths = []\n            self.__instruction_cache = self.__new_instructions\n            self.__new_instructions = []\n        else:\n            if not self.__instruction_cache:\n                return\n\n        for instruction, args in self.__instruction_cache:\n            if fresh_draw:\n                if instruction in (\"new_path\", \"stroke\", \"fill\", \"clip\"):\n                    self.paths.append((instruction, \"path\", context.copy_path()))\n\n                elif instruction in (\"save\", \"restore\", \"translate\", \"scale\", \"rotate\"):\n                    self.paths.append((instruction, \"transform\", args))\n\n            if instruction == \"set_color\":\n                self._set_color(context, args[0], args[1], args[2], args[3] * opacity)\n            elif instruction == \"show_layout\":\n                self._show_layout(context, *args)\n            elif opacity < 1 and instruction == \"paint\":\n                context.paint_with_alpha(opacity)\n            else:\n                getattr(context, instruction)(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(self, id):\n        for sprite in self.sprites:\n            if sprite.id == id:\n                return sprite\n\n        for sprite in self.sprites:\n            found = sprite.find(id)\n            if found:\n                return found", "response": "breadth - first sprite search by ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef traverse(self, attr_name = None, attr_value = None):\n        for sprite in self.sprites:\n            if (attr_name is None) or \\\n               (attr_value is None and hasattr(sprite, attr_name)) or \\\n               (attr_value is not None and getattr(sprite, attr_name, None) == attr_value):\n                yield sprite\n\n            for child in sprite.traverse(attr_name, attr_value):\n                yield child", "response": "traverse the whole sprite tree and return all child sprites which have the specified attribute and it s set to the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd one sprite at a time. used by add_child. split them up so that they are possible specify the index externally.", "response": "def _add(self, sprite, index = None):\n        \"\"\"add one sprite at a time. used by add_child. split them up so that\n        it would be possible specify the index externally\"\"\"\n        if sprite == self:\n            raise Exception(\"trying to add sprite to itself\")\n\n        if sprite.parent:\n            sprite.x, sprite.y = self.from_scene_coords(*sprite.to_scene_coords())\n            sprite.parent.remove_child(sprite)\n\n        if index is not None:\n            self.sprites.insert(index, sprite)\n        else:\n            self.sprites.append(sprite)\n        sprite.parent = self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _sort(self):\n        self.__dict__['_z_ordered_sprites'] = sorted(self.sprites, key=lambda sprite:sprite.z_order)", "response": "sort sprites by z_order"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds child sprite. Child will be nested within parent", "response": "def add_child(self, *sprites):\n        \"\"\"Add child sprite. Child will be nested within parent\"\"\"\n        for sprite in sprites:\n            self._add(sprite)\n        self._sort()\n        self.redraw()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_child(self, *sprites):\n\n        # first drop focus\n        scene = self.get_scene()\n\n        if scene:\n            child_sprites = list(self.all_child_sprites())\n            if scene._focus_sprite in child_sprites:\n                scene._focus_sprite = None\n\n\n        for sprite in sprites:\n            if sprite in self.sprites:\n                self.sprites.remove(sprite)\n                sprite._scene = None\n                sprite.parent = None\n            self.disconnect_child(sprite)\n        self._sort()\n        self.redraw()", "response": "Remove one or several child sprites from scene"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_child_sprites(self):\n        for sprite in self.sprites:\n            for child_sprite in sprite.all_child_sprites():\n                yield child_sprite\n            yield sprite", "response": "returns all child and grandchild sprites in a flat list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect_child(self, sprite, event, *args, **kwargs):\n        handler = sprite.connect(event, *args, **kwargs)\n        self._child_handlers[sprite].append(handler)\n        return handler", "response": "connect to a child event so that will disconnect if the child is absent from this sprite"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_child_after(self, sprite, event, *args, **kwargs):\n        handler = sprite.connect_after(event, *args, **kwargs)\n        self._child_handlers[sprite].append(handler)\n        return handler", "response": "connect to a child event so that will disconnect if the is\n        removed from this sprite"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_mouse_cursor(self):\n        if self.mouse_cursor is not None:\n            return self.mouse_cursor\n        elif self.interactive and self.draggable:\n            return gdk.CursorType.FLEUR\n        elif self.interactive:\n            return gdk.CursorType.HAND2", "response": "Determine mouse cursor.\n        By default look for self.mouse_cursor is defined and take that.\n        Otherwise use gdk.CursorType.FLEUR for draggable sprites and gdk.CursorType.HAND2 for\n        interactive sprites. Defaults to scenes cursor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadjusting the sprite s z - order so that the sprite is on top of its parent s _z_ordered_sprites list.", "response": "def bring_to_front(self):\n        \"\"\"adjusts sprite's z-order so that the sprite is on top of it's\n        siblings\"\"\"\n        if not self.parent:\n            return\n        self.z_order = self.parent._z_ordered_sprites[-1].z_order + 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadjusts the z - order so that the sprite is behind it s siblings", "response": "def send_to_back(self):\n        \"\"\"adjusts sprite's z-order so that the sprite is behind it's\n        siblings\"\"\"\n        if not self.parent:\n            return\n        self.z_order = self.parent._z_ordered_sprites[0].z_order - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grab_focus(self):\n        scene = self.get_scene()\n        if scene and scene._focus_sprite != self:\n            scene._focus_sprite = self", "response": "grab window s focus. Keyboard and scroll events will be forwarded\n        to the sprite who has the focus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blur(self):\n        scene = self.get_scene()\n        if scene and scene._focus_sprite == self:\n            scene._focus_sprite = None", "response": "removes focus from the current element if it has it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_parents(self):\n        res = []\n        parent = self.parent\n        while parent and isinstance(parent, Scene) == False:\n            res.insert(0, parent)\n            parent = parent.parent\n\n        return res", "response": "returns all the parent sprites up until scene"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmeasure the extents of the sprite s graphics.", "response": "def get_extents(self):\n        \"\"\"measure the extents of the sprite's graphics.\"\"\"\n        if self._sprite_dirty:\n            # redrawing merely because we need fresh extents of the sprite\n            context = cairo.Context(cairo.ImageSurface(cairo.FORMAT_A1, 0, 0))\n            context.transform(self.get_matrix())\n            self.emit(\"on-render\")\n            self.__dict__[\"_sprite_dirty\"] = False\n            self.graphics._draw(context, 1)\n\n\n        if not self.graphics.paths:\n            self.graphics._draw(cairo.Context(cairo.ImageSurface(cairo.FORMAT_A1, 0, 0)), 1)\n\n        if not self.graphics.paths:\n            return None\n\n        context = cairo.Context(cairo.ImageSurface(cairo.FORMAT_A1, 0, 0))\n\n        # bit of a hack around the problem - looking for clip instructions in parent\n        # so extents would not get out of it\n        clip_extents = None\n        for parent in self.get_parents():\n            context.transform(parent.get_local_matrix())\n            if parent.graphics.paths:\n                clip_regions = []\n                for instruction, type, path in parent.graphics.paths:\n                    if instruction == \"clip\":\n                        context.append_path(path)\n                        context.save()\n                        context.identity_matrix()\n\n                        clip_regions.append(context.fill_extents())\n                        context.restore()\n                        context.new_path()\n                    elif instruction == \"restore\" and clip_regions:\n                        clip_regions.pop()\n\n                for ext in clip_regions:\n                    ext = get_gdk_rectangle(int(ext[0]), int(ext[1]), int(ext[2] - ext[0]), int(ext[3] - ext[1]))\n                    intersect, clip_extents = gdk.rectangle_intersect((clip_extents or ext), ext)\n\n        context.transform(self.get_local_matrix())\n\n        for instruction, type, path in self.graphics.paths:\n            if type == \"path\":\n                context.append_path(path)\n            else:\n                getattr(context, instruction)(*path)\n\n        context.identity_matrix()\n\n\n        ext = context.path_extents()\n        ext = get_gdk_rectangle(int(ext[0]), int(ext[1]),\n                                int(ext[2] - ext[0]), int(ext[3] - ext[1]))\n        if clip_extents:\n            intersect, ext = gdk.rectangle_intersect(clip_extents, ext)\n\n        if not ext.width and not ext.height:\n            ext = None\n\n        self.__dict__['_stroke_context'] = context\n\n        return ext"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the given coordinates are inside the sprite s fill or stroke path", "response": "def check_hit(self, x, y):\n        \"\"\"check if the given coordinates are inside the sprite's fill or stroke path\"\"\"\n        extents = self.get_extents()\n\n        if not extents:\n            return False\n\n        if extents.x <= x <= extents.x + extents.width and extents.y <= y <= extents.y + extents.height:\n            return self._stroke_context is None or self._stroke_context.in_fill(x, y)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn class:`Scene` the sprite belongs to", "response": "def get_scene(self):\n        \"\"\"returns class:`Scene` the sprite belongs to\"\"\"\n        if self._scene is None:\n            parent = getattr(self, \"parent\", None)\n            if parent:\n                self._scene = parent.get_scene()\n        return self._scene"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest parent Scene to animate attributes using the internal tweener.", "response": "def animate(self, duration = None, easing = None, on_complete = None,\n                on_update = None, round = False, **kwargs):\n        \"\"\"Request parent Scene to Interpolate attributes using the internal tweener.\n           Specify sprite's attributes that need changing.\n           `duration` defaults to 0.4 seconds and `easing` to cubic in-out\n           (for others see pytweener.Easing class).\n\n           Example::\n             # tween some_sprite to coordinates (50,100) using default duration and easing\n             self.animate(x = 50, y = 100)\n        \"\"\"\n        scene = self.get_scene()\n        if scene:\n            return scene.animate(self, duration, easing, on_complete,\n                                 on_update, round, **kwargs)\n        else:\n            for key, val in kwargs.items():\n                setattr(self, key, val)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_matrix(self):\n        if self.parent:\n            return self.get_local_matrix() * (self._prev_parent_matrix or self.parent.get_matrix())\n        else:\n            return self.get_local_matrix()", "response": "return sprite s current transformation matrix"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_scene_coords(self, x=0, y=0):\n        matrix = self.get_matrix()\n        matrix.invert()\n        return matrix.transform_point(x, y)", "response": "Converts x y given in the scene coordinates to sprite s local ones\n        coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmeasure given text with label s font and size.", "response": "def measure(self, text, escape = True, max_width = None):\n        \"\"\"measures given text with label's font and size.\n        returns width, height and ascent. Ascent's null in case if the label\n        does not have font face specified (and is thusly using pango)\"\"\"\n\n        if escape:\n            text = text.replace (\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n\n        if (max_width, text) in self._measures:\n            return self._measures[(max_width, text)]\n\n        width, height = None, None\n\n        context = self._test_context\n\n        layout = self._test_layout\n        layout.set_font_description(self.font_desc)\n        layout.set_markup(text)\n        layout.set_single_paragraph_mode(self.single_paragraph)\n\n        if self.alignment:\n            layout.set_alignment(self.alignment)\n\n        if self.wrap is not None:\n            layout.set_wrap(self.wrap)\n            layout.set_ellipsize(pango.EllipsizeMode.NONE)\n        else:\n            layout.set_ellipsize(self.ellipsize or pango.EllipsizeMode.END)\n\n        if max_width is not None:\n            layout.set_width(max_width * pango.SCALE)\n        else:\n            if self.max_width:\n                max_width = self.max_width * pango.SCALE\n\n            layout.set_width(int(self._bounds_width or max_width or -1))\n\n        width, height = layout.get_pixel_size()\n\n        self._measures[(max_width, text)] = width, height\n        return self._measures[(max_width, text)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef animate(self, sprite, duration = None, easing = None, on_complete = None,\n                on_update = None, round = False, **kwargs):\n        \"\"\"Interpolate attributes of the given object using the internal tweener\n           and redrawing scene after every tweener update.\n           Specify the sprite and sprite's attributes that need changing.\n           `duration` defaults to 0.4 seconds and `easing` to cubic in-out\n           (for others see pytweener.Easing class).\n\n           Redraw is requested right after creating the animation.\n           Example::\n\n             # tween some_sprite to coordinates (50,100) using default duration and easing\n             scene.animate(some_sprite, x = 50, y = 100)\n        \"\"\"\n        if not self.tweener: # here we complain\n            raise Exception(\"pytweener was not found. Include it to enable animations\")\n\n        tween = self.tweener.add_tween(sprite,\n                                       duration=duration,\n                                       easing=easing,\n                                       on_complete=on_complete,\n                                       on_update=on_update,\n                                       round=round,\n                                       **kwargs)\n        self.redraw()\n        return tween", "response": "Interpolate attributes of the given object using the internal tweener."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop_animation(self, sprites):\n        if isinstance(sprites, list) is False:\n            sprites = [sprites]\n\n        for sprite in sprites:\n            self.tweener.kill_tweens(sprite)", "response": "stop animation without firing on_complete"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef redraw(self):\n        if self.__drawing_queued == False: #if we are moving, then there is a timeout somewhere already\n            self.__drawing_queued = True\n            self._last_frame_time = dt.datetime.now()\n            gobject.timeout_add(1000 / self.framerate, self.__redraw_loop)", "response": "Queue redraw. The redraw will be performed not more often than\n           the `framerate` allows"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __redraw_loop(self):\n        self.queue_draw() # this will trigger do_expose_event when the current events have been flushed\n\n        self.__drawing_queued = self.tweener and self.tweener.has_tweens()\n        return self.__drawing_queued", "response": "loop until there is nothing to tween"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn flat list of the sprite tree for simplified iteration", "response": "def all_mouse_sprites(self):\n        \"\"\"Returns flat list of the sprite tree for simplified iteration\"\"\"\n        def all_recursive(sprites):\n            if not sprites:\n                return\n\n            for sprite in sprites:\n                if sprite.visible:\n                    yield sprite\n\n                    for child in all_recursive(sprite.get_mouse_sprites()):\n                        yield child\n\n        return all_recursive(self.get_mouse_sprites())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the interactive sprite at the given coordinates", "response": "def get_sprite_at_position(self, x, y):\n        \"\"\"Returns the topmost visible interactive sprite for given coordinates\"\"\"\n        over = None\n        for sprite in self.all_mouse_sprites():\n            if sprite.interactive and sprite.check_hit(x, y):\n                over = sprite\n\n        return over"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts dragging given sprite", "response": "def start_drag(self, sprite, cursor_x = None, cursor_y = None):\n        \"\"\"start dragging given sprite\"\"\"\n        cursor_x, cursor_y = cursor_x or sprite.x, cursor_y or sprite.y\n\n        self._mouse_down_sprite = self._drag_sprite = sprite\n        sprite.drag_x, sprite.drag_y = self._drag_sprite.x, self._drag_sprite.y\n        self.__drag_start_x, self.__drag_start_y = cursor_x, cursor_y\n        self.__drag_started = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pretty_print(self, as_list=False, show_datetime=True):\n        ppl = [entry.pretty_print(show_datetime) for entry in self.entries]\n        if as_list:\n            return ppl\n        return u\"\\n\".join(ppl)", "response": "Return a Unicode string pretty print of the log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log(self, message, severity=INFO, tag=u\"\"):\n        entry = _LogEntry(\n            severity=severity,\n            time=datetime.datetime.now(),\n            tag=tag,\n            indentation=self.indentation,\n            message=self._sanitize(message)\n        )\n        self.entries.append(entry)\n        if self.tee:\n            gf.safe_print(entry.pretty_print(show_datetime=self.tee_show_datetime))\n        return entry.time", "response": "Add a given message to the log and return its time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noutput the log to file.", "response": "def write(self, path):\n        \"\"\"\n        Output the log to file.\n\n        :param string path: the path of the log file to be written\n        \"\"\"\n        with io.open(path, \"w\", encoding=\"utf-8\") as log_file:\n            log_file.write(self.pretty_print())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sanitize(cls, message):\n        if isinstance(message, list):\n            if len(message) == 0:\n                sanitized = u\"Empty log message\"\n            elif len(message) == 1:\n                sanitized = message[0]\n            else:\n                sanitized = message[0] % tuple(message[1:])\n        else:\n            sanitized = message\n        if not gf.is_unicode(sanitized):\n            raise TypeError(\"The given log message is not a Unicode string\")\n        return sanitized", "response": "Sanitize the given log message for use in a log file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Unicode string containing the pretty printing of a given log entry.", "response": "def pretty_print(self, show_datetime=True):\n        \"\"\"\n        Returns a Unicode string containing\n        the pretty printing of a given log entry.\n\n        :param bool show_datetime: if ``True``, print the date and time of the entry\n        :rtype: string\n        \"\"\"\n        if show_datetime:\n            return u\"[%s] %s %s%s: %s\" % (\n                self.severity,\n                gf.object_to_unicode(self.time),\n                u\" \" * self.indentation,\n                self.tag,\n                self.message\n            )\n        return u\"[%s] %s%s: %s\" % (\n            self.severity,\n            u\" \" * self.indentation,\n            self.tag,\n            self.message\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log(self, message, severity=Logger.DEBUG):\n        return self.logger.log(message, severity, self.TAG)", "response": "Log generic message\n\n        :param string message: the message to log\n        :param string severity: the message severity\n        :rtype: datetime"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_exc(self, message, exc=None, critical=True, raise_type=None):\n        log_function = self.log_crit if critical else self.log_warn\n        log_function(message)\n        if exc is not None:\n            log_function([u\"%s\", exc])\n        if raise_type is not None:\n            raise_message = message\n            if exc is not None:\n                raise_message = u\"%s : %s\" % (message, exc)\n            raise raise_type(raise_message)", "response": "Log an exception and possibly raise exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a waveform to the plot.", "response": "def add_waveform(self, waveform):\n        \"\"\"\n        Add a waveform to the plot.\n\n        :param waveform: the waveform to be added\n        :type  waveform: :class:`~aeneas.plotter.PlotWaveform`\n        :raises: TypeError: if ``waveform`` is not an instance of :class:`~aeneas.plotter.PlotWaveform`\n        \"\"\"\n        if not isinstance(waveform, PlotWaveform):\n            self.log_exc(u\"waveform must be an instance of PlotWaveform\", None, True, TypeError)\n        self.waveform = waveform\n        self.log(u\"Added waveform\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_timescale(self, timescale):\n        if not isinstance(timescale, PlotTimeScale):\n            self.log_exc(u\"timescale must be an instance of PlotTimeScale\", None, True, TypeError)\n        self.timescale = timescale\n        self.log(u\"Added timescale\")", "response": "Add a time scale to the plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_labelset(self, labelset):\n        if not isinstance(labelset, PlotLabelset):\n            self.log_exc(u\"labelset must be an instance of PlotLabelset\", None, True, TypeError)\n        self.labelsets.append(labelset)\n        self.log(u\"Added labelset\")", "response": "Adds a labelset to the plot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_png(self, output_file_path, h_zoom=5, v_zoom=30):\n        # check that output_file_path can be written\n        if not gf.file_can_be_written(output_file_path):\n            self.log_exc(u\"Cannot write to output file '%s'\" % (output_file_path), None, True, OSError)\n\n        # get widths and cumulative height, in modules\n        widths = [ls.width for ls in self.labelsets]\n        sum_height = sum([ls.height for ls in self.labelsets])\n        if self.waveform is not None:\n            widths.append(self.waveform.width)\n            sum_height += self.waveform.height\n        if self.timescale is not None:\n            sum_height += self.timescale.height\n        # in modules\n        image_width = max(widths)\n        image_height = sum_height\n        # in pixels\n        image_width_px = image_width * h_zoom\n        image_height_px = image_height * v_zoom\n\n        # build image object\n        self.log([u\"Building image with size (modules): %d %d\", image_width, image_height])\n        self.log([u\"Building image with size (px):      %d %d\", image_width_px, image_height_px])\n        image_obj = Image.new(\"RGB\", (image_width_px, image_height_px), color=PlotterColors.AUDACITY_BACKGROUND_GREY)\n        current_y = 0\n        if self.waveform is not None:\n            self.log(u\"Drawing waveform\")\n            self.waveform.draw_png(image_obj, h_zoom, v_zoom, current_y)\n            current_y += self.waveform.height\n        timescale_y = current_y\n        if self.timescale is not None:\n            # NOTE draw as the last thing\n            # COMMENTED self.log(u\"Drawing timescale\")\n            # COMMENTED self.timescale.draw_png(image_obj, h_zoom, v_zoom, current_y)\n            current_y += self.timescale.height\n        for labelset in self.labelsets:\n            self.log(u\"Drawing labelset\")\n            labelset.draw_png(image_obj, h_zoom, v_zoom, current_y)\n            current_y += labelset.height\n        if self.timescale is not None:\n            self.log(u\"Drawing timescale\")\n            self.timescale.draw_png(image_obj, h_zoom, v_zoom, timescale_y)\n        self.log([u\"Saving to file '%s'\", output_file_path])\n        image_obj.save(output_file_path)", "response": "Draw the current plot to a PNG file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the bounding box of the given text at the given font size.", "response": "def text_bounding_box(self, size_pt, text):\n        \"\"\"\n        Return the bounding box of the given text\n        at the given font size.\n\n        :param int size_pt: the font size in points\n        :param string text: the text\n\n        :rtype: tuple (width, height)\n        \"\"\"\n        if size_pt == 12:\n            mult = {\"h\": 9, \"w_digit\": 5, \"w_space\": 2}\n        elif size_pt == 18:\n            mult = {\"h\": 14, \"w_digit\": 9, \"w_space\": 2}\n        num_chars = len(text)\n        return (num_chars * mult[\"w_digit\"] + (num_chars - 1) * mult[\"w_space\"] + 1, mult[\"h\"])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _time_string(self, value):\n        if self.max_time < 60:\n            return \"%02d\" % (value)\n        elif self.max_time < 3600:\n            mm = value // 60\n            ss = value - mm * 60\n            return \"%02d:%02d\" % (mm, ss)\n        hh = value // 3600\n        mm = (value - hh * 3600) // 60\n        ss = (value - hh * 3600 - mm * 60)\n        return \"%02d:%02d:%02d\" % (hh, mm, ss)", "response": "Return a suitable time string for the current time value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_png(self, image, h_zoom, v_zoom, current_y):\n        # PIL object\n        draw = ImageDraw.Draw(image)\n        mws = self.rconf.mws\n        pixels_per_second = int(h_zoom / mws)\n        current_y_px = current_y * v_zoom\n\n        # create font, as tall as possible\n        font_height_pt = 18\n        font = ImageFont.truetype(self.FONT_PATH, font_height_pt)\n\n        # draw a tick every self.time_step seconds\n        for i in range(0, 1 + int(self.max_time), self.time_step):\n            # base x position\n            begin_px = i * pixels_per_second\n\n            # tick\n            left_px = begin_px - self.TICK_WIDTH\n            right_px = begin_px + self.TICK_WIDTH\n            top_px = current_y_px\n            bottom_px = current_y_px + v_zoom\n            draw.rectangle((left_px, top_px, right_px, bottom_px), fill=PlotterColors.BLACK)\n\n            # text\n            time_text = self._time_string(i)\n            left_px = begin_px + self.TICK_WIDTH + self.TEXT_MARGIN\n            top_px = current_y_px + (v_zoom - self.text_bounding_box(font_height_pt, time_text)[1]) // 2\n            draw.text((left_px, top_px), time_text, PlotterColors.BLACK, font=font)", "response": "Draw the time scale to PNG."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_png(self, image, h_zoom, v_zoom, current_y):\n        # PIL object\n        draw = ImageDraw.Draw(image)\n        mws = self.rconf.mws\n        pixels_per_second = int(h_zoom / mws)\n\n        # font for begin/end times\n        time_font_height_pt = 12\n        time_font = ImageFont.truetype(self.FONT_PATH, time_font_height_pt)\n\n        # font for labels\n        label_font_height_pt = 18\n        label_font = ImageFont.truetype(self.FONT_PATH, label_font_height_pt)\n\n        current_y_px = current_y * v_zoom + 0.25 * v_zoom\n        for (begin, end, label) in self.labelset:\n            # base x position\n            begin_px = int(begin * pixels_per_second)\n            end_px = int(end * pixels_per_second)\n\n            # select color for the horizontal bar\n            if label == \"speech\":\n                color = PlotterColors.RED\n            elif label == \"nonspeech\":\n                color = PlotterColors.GREEN\n            else:\n                color = self.parameters[\"color\"]\n\n            # horizontal bar\n            bar_top_px = current_y_px + v_zoom * 0.5 - self.TICK_WIDTH\n            bar_bottom_px = bar_top_px + 2 * self.TICK_WIDTH\n            bar_left_px = begin_px\n            bar_right_px = end_px\n            draw.rectangle((bar_left_px, bar_top_px, bar_right_px, bar_bottom_px), fill=color)\n\n            # left guide\n            if self.parameters[\"begin_guide\"]:\n                top_px = 0\n                bottom_px = current_y_px + v_zoom\n                left_px = begin_px\n                draw.rectangle((left_px, top_px, left_px, bottom_px), fill=color)\n\n            # left tick\n            top_px = current_y_px\n            bottom_px = current_y_px + v_zoom\n            left_px = begin_px\n            right_px = begin_px + self.TICK_WIDTH\n            draw.rectangle((left_px, top_px, right_px, bottom_px), fill=PlotterColors.BLACK)\n\n            # right guide\n            if self.parameters[\"end_guide\"]:\n                top_px = 0\n                bottom_px = current_y_px + v_zoom\n                left_px = end_px\n                draw.rectangle((left_px, top_px, left_px, bottom_px), fill=color)\n\n            # right tick\n            top_px = current_y_px\n            bottom_px = current_y_px + v_zoom\n            left_px = end_px - self.TICK_WIDTH\n            right_px = end_px\n            draw.rectangle((left_px, top_px, right_px, bottom_px), fill=PlotterColors.BLACK)\n\n            # begin time\n            if self.parameters[\"begin_time\"]:\n                sb = (\"%.03f\" % (begin - int(begin)))[2:]\n                left_px = begin_px + self.TICK_WIDTH + self.TEXT_MARGIN\n                top_px = current_y_px - self.TEXT_MARGIN\n                draw.text((left_px, top_px), sb, PlotterColors.BLACK, font=time_font)\n\n            # end time\n            if self.parameters[\"end_time\"]:\n                se = (\"%.03f\" % (end - int(end)))[2:]\n                left_px = end_px - self.TEXT_MARGIN - self.TICK_WIDTH - self.text_bounding_box(time_font_height_pt, se)[0]\n                top_px = current_y_px + v_zoom - self.text_bounding_box(time_font_height_pt, sb)[1]\n                draw.text((left_px, top_px), se, PlotterColors.BLACK, font=time_font)\n\n            # interval label\n            if self.parameters[\"labels\"]:\n                left_px = begin_px + (end_px - begin_px - self.text_bounding_box(label_font_height_pt, label)[0]) // 2\n                top_px = current_y_px + v_zoom\n                draw.text((left_px, top_px), label, PlotterColors.BLACK, font=label_font)\n\n        # label\n        left_px = 0\n        top_px = current_y_px + v_zoom\n        if self.label is not None:\n            draw.text((left_px, top_px), self.label, PlotterColors.BLACK, font=label_font)", "response": "Draw the set of labels to PNG."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_png(self, image, h_zoom, v_zoom, current_y):\n        draw = ImageDraw.Draw(image)\n        mws = self.rconf.mws\n        rate = self.audio_file.audio_sample_rate\n        samples = self.audio_file.audio_samples\n        duration = self.audio_file.audio_length\n\n        current_y_px = current_y * v_zoom\n        half_waveform_px = (self.height // 2) * v_zoom\n        zero_y_px = current_y_px + half_waveform_px\n\n        samples_per_pixel = int(rate * mws / h_zoom)\n        pixels_per_second = int(h_zoom / mws)\n        windows = len(samples) // samples_per_pixel\n\n        if self.label is not None:\n            font_height_pt = 18\n            font = ImageFont.truetype(self.FONT_PATH, font_height_pt)\n            draw.text((0, current_y_px), self.label, PlotterColors.BLACK, font=font)\n\n        for i in range(windows):\n            x = i * samples_per_pixel\n            pos = numpy.clip(samples[x:(x + samples_per_pixel)], 0.0, 1.0)\n            mpos = numpy.max(pos) * half_waveform_px\n            if self.fast:\n                # just draw a simple version, mirroring max positive samples\n                draw.line((i, zero_y_px + mpos, i, zero_y_px - mpos), fill=PlotterColors.AUDACITY_DARK_BLUE, width=1)\n            else:\n                # draw a better version, taking min and std of positive and negative samples\n                neg = numpy.clip(samples[x:(x + samples_per_pixel)], -1.0, 0.0)\n                spos = numpy.std(pos) * half_waveform_px\n                sneg = numpy.std(neg) * half_waveform_px\n                mneg = numpy.min(neg) * half_waveform_px\n                draw.line((i, zero_y_px - mneg, i, zero_y_px - mpos), fill=PlotterColors.AUDACITY_DARK_BLUE, width=1)\n                draw.line((i, zero_y_px + sneg, i, zero_y_px - spos), fill=PlotterColors.AUDACITY_LIGHT_BLUE, width=1)", "response": "Draw this waveform onto the image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform_command(self):\n        if len(self.actual_arguments) < 4:\n            return self.print_help()\n        text_format = gf.safe_unicode(self.actual_arguments[0])\n        if text_format == u\"list\":\n            text = gf.safe_unicode(self.actual_arguments[1])\n        elif text_format in TextFileFormat.ALLOWED_VALUES:\n            text = self.actual_arguments[1]\n            if not self.check_input_file(text):\n                return self.ERROR_EXIT_CODE\n        else:\n            return self.print_help()\n\n        l1_id_regex = self.has_option_with_value(u\"--l1-id-regex\")\n        l2_id_regex = self.has_option_with_value(u\"--l2-id-regex\")\n        l3_id_regex = self.has_option_with_value(u\"--l3-id-regex\")\n        id_regex = self.has_option_with_value(u\"--id-regex\")\n        class_regex = self.has_option_with_value(u\"--class-regex\")\n        sort = self.has_option_with_value(u\"--sort\")\n        parameters = {\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L1_ID_REGEX: l1_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L2_ID_REGEX: l2_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L3_ID_REGEX: l3_id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_CLASS_REGEX: class_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_REGEX: id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_SORT: sort,\n        }\n        if (text_format == TextFileFormat.MUNPARSED) and ((l1_id_regex is None) or (l2_id_regex is None) or (l3_id_regex is None)):\n            self.print_error(u\"You must specify --l1-id-regex and --l2-id-regex and --l3-id-regex for munparsed format\")\n            return self.ERROR_EXIT_CODE\n        if (text_format == TextFileFormat.UNPARSED) and (id_regex is None) and (class_regex is None):\n            self.print_error(u\"You must specify --id-regex and/or --class-regex for unparsed format\")\n            return self.ERROR_EXIT_CODE\n\n        language = gf.safe_unicode(self.actual_arguments[2])\n\n        audio_file_path = self.actual_arguments[3]\n        if not self.check_input_file(audio_file_path):\n            return self.ERROR_EXIT_CODE\n\n        text_file = self.get_text_file(text_format, text, parameters)\n        if text_file is None:\n            self.print_error(u\"Unable to build a TextFile from the given parameters\")\n            return self.ERROR_EXIT_CODE\n        elif len(text_file) == 0:\n            self.print_error(u\"No text fragments found\")\n            return self.ERROR_EXIT_CODE\n        text_file.set_language(language)\n        self.print_info(u\"Read input text with %d fragments\" % (len(text_file)))\n\n        self.print_info(u\"Reading audio...\")\n        try:\n            audio_file_mfcc = AudioFileMFCC(audio_file_path, rconf=self.rconf, logger=self.logger)\n        except AudioFileConverterError:\n            self.print_error(u\"Unable to call the ffmpeg executable '%s'\" % (self.rconf[RuntimeConfiguration.FFMPEG_PATH]))\n            self.print_error(u\"Make sure the path to ffmpeg is correct\")\n            return self.ERROR_EXIT_CODE\n        except (AudioFileUnsupportedFormatError, AudioFileNotInitializedError):\n            self.print_error(u\"Cannot read file '%s'\" % (audio_file_path))\n            self.print_error(u\"Check that its format is supported by ffmpeg\")\n            return self.ERROR_EXIT_CODE\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while reading the audio file:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n        self.print_info(u\"Reading audio... done\")\n\n        self.print_info(u\"Running VAD...\")\n        audio_file_mfcc.run_vad()\n        self.print_info(u\"Running VAD... done\")\n\n        min_head = gf.safe_float(self.has_option_with_value(u\"--min-head\"), None)\n        max_head = gf.safe_float(self.has_option_with_value(u\"--max-head\"), None)\n        min_tail = gf.safe_float(self.has_option_with_value(u\"--min-tail\"), None)\n        max_tail = gf.safe_float(self.has_option_with_value(u\"--max-tail\"), None)\n\n        self.print_info(u\"Detecting audio interval...\")\n        start_detector = SD(audio_file_mfcc, text_file, rconf=self.rconf, logger=self.logger)\n        start, end = start_detector.detect_interval(min_head, max_head, min_tail, max_tail)\n        self.print_info(u\"Detecting audio interval... done\")\n\n        self.print_result(audio_file_mfcc.audio_length, start, end)\n        return self.NO_ERROR_EXIT_CODE", "response": "Perform command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the result of SD.", "response": "def print_result(self, audio_len, start, end):\n        \"\"\"\n        Print result of SD.\n\n        :param audio_len: the length of the entire audio file, in seconds\n        :type  audio_len: float\n        :param start: the start position of the spoken text\n        :type  start: float\n        :param end: the end position of the spoken text\n        :type  end: float\n        \"\"\"\n        msg = []\n        zero = 0\n        head_len = start\n        text_len = end - start\n        tail_len = audio_len - end\n        msg.append(u\"\")\n        msg.append(u\"Head: %.3f %.3f (%.3f)\" % (zero, start, head_len))\n        msg.append(u\"Text: %.3f %.3f (%.3f)\" % (start, end, text_len))\n        msg.append(u\"Tail: %.3f %.3f (%.3f)\" % (end, audio_len, tail_len))\n        msg.append(u\"\")\n        zero_h = gf.time_to_hhmmssmmm(0)\n        start_h = gf.time_to_hhmmssmmm(start)\n        end_h = gf.time_to_hhmmssmmm(end)\n        audio_len_h = gf.time_to_hhmmssmmm(audio_len)\n        head_len_h = gf.time_to_hhmmssmmm(head_len)\n        text_len_h = gf.time_to_hhmmssmmm(text_len)\n        tail_len_h = gf.time_to_hhmmssmmm(tail_len)\n        msg.append(\"Head: %s %s (%s)\" % (zero_h, start_h, head_len_h))\n        msg.append(\"Text: %s %s (%s)\" % (start_h, end_h, text_len_h))\n        msg.append(\"Tail: %s %s (%s)\" % (end_h, audio_len_h, tail_len_h))\n        msg.append(u\"\")\n        self.print_info(u\"\\n\".join(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of non - empty leaves in the sync map associated with the task.", "response": "def sync_map_leaves(self, fragment_type=None):\n        \"\"\"\n        Return the list of non-empty leaves\n        in the sync map associated with the task.\n\n        If ``fragment_type`` has been specified,\n        return only leaves of that fragment type.\n\n        :param int fragment_type: type of fragment to return\n        :rtype: list\n\n        .. versionadded:: 1.7.0\n        \"\"\"\n        if (self.sync_map is None) or (self.sync_map.fragments_tree is None):\n            return []\n        return [f for f in self.sync_map.leaves(fragment_type)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noutputs the sync map file for this task.", "response": "def output_sync_map_file(self, container_root_path=None):\n        \"\"\"\n        Output the sync map file for this task.\n\n        If ``container_root_path`` is specified,\n        the output sync map file will be created\n        at the path obtained by joining\n        the ``container_root_path`` and the relative path\n        of the sync map inside the container.\n\n        Otherwise, the sync map file will be created at the path\n        ``self.sync_map_file_path_absolute``.\n\n        Return the the path of the sync map file created,\n        or ``None`` if an error occurred.\n\n        :param string container_root_path: the path to the root directory\n                                           for the output container\n        :rtype: string\n        \"\"\"\n        if self.sync_map is None:\n            self.log_exc(u\"The sync_map object has not been set\", None, True, TypeError)\n\n        if (container_root_path is not None) and (self.sync_map_file_path is None):\n            self.log_exc(u\"The (internal) path of the sync map has been set\", None, True, TypeError)\n\n        self.log([u\"container_root_path is %s\", container_root_path])\n        self.log([u\"self.sync_map_file_path is %s\", self.sync_map_file_path])\n        self.log([u\"self.sync_map_file_path_absolute is %s\", self.sync_map_file_path_absolute])\n\n        if (container_root_path is not None) and (self.sync_map_file_path is not None):\n            path = os.path.join(container_root_path, self.sync_map_file_path)\n        elif self.sync_map_file_path_absolute:\n            path = self.sync_map_file_path_absolute\n        gf.ensure_parent_directory(path)\n        self.log([u\"Output sync map to %s\", path])\n\n        eaf_audio_ref = self.configuration[\"o_eaf_audio_ref\"]\n        head_tail_format = self.configuration[\"o_h_t_format\"]\n        levels = self.configuration[\"o_levels\"]\n        smil_audio_ref = self.configuration[\"o_smil_audio_ref\"]\n        smil_page_ref = self.configuration[\"o_smil_page_ref\"]\n        sync_map_format = self.configuration[\"o_format\"]\n\n        self.log([u\"eaf_audio_ref is %s\", eaf_audio_ref])\n        self.log([u\"head_tail_format is %s\", head_tail_format])\n        self.log([u\"levels is %s\", levels])\n        self.log([u\"smil_audio_ref is %s\", smil_audio_ref])\n        self.log([u\"smil_page_ref is %s\", smil_page_ref])\n        self.log([u\"sync_map_format is %s\", sync_map_format])\n\n        self.log(u\"Calling sync_map.write...\")\n        parameters = {\n            gc.PPN_TASK_OS_FILE_EAF_AUDIO_REF: eaf_audio_ref,\n            gc.PPN_TASK_OS_FILE_HEAD_TAIL_FORMAT: head_tail_format,\n            gc.PPN_TASK_OS_FILE_LEVELS: levels,\n            gc.PPN_TASK_OS_FILE_SMIL_AUDIO_REF: smil_audio_ref,\n            gc.PPN_TASK_OS_FILE_SMIL_PAGE_REF: smil_page_ref,\n        }\n        self.sync_map.write(sync_map_format, path, parameters)\n        self.log(u\"Calling sync_map.write... done\")\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopulating the audio file object by reading the audio file at self. audio_file_path_absolute.", "response": "def _populate_audio_file(self):\n        \"\"\"\n        Create the ``self.audio_file`` object by reading\n        the audio file at ``self.audio_file_path_absolute``.\n        \"\"\"\n        self.log(u\"Populate audio file...\")\n        if self.audio_file_path_absolute is not None:\n            self.log([u\"audio_file_path_absolute is '%s'\", self.audio_file_path_absolute])\n            self.audio_file = AudioFile(\n                file_path=self.audio_file_path_absolute,\n                logger=self.logger\n            )\n            self.audio_file.read_properties()\n        else:\n            self.log(u\"audio_file_path_absolute is None\")\n        self.log(u\"Populate audio file... done\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _populate_text_file(self):\n        self.log(u\"Populate text file...\")\n        if (\n                (self.text_file_path_absolute is not None) and\n                (self.configuration[\"language\"] is not None)\n        ):\n            # the following values might be None\n            parameters = {\n                gc.PPN_TASK_IS_TEXT_FILE_IGNORE_REGEX: self.configuration[\"i_t_ignore_regex\"],\n                gc.PPN_TASK_IS_TEXT_FILE_TRANSLITERATE_MAP: self.configuration[\"i_t_transliterate_map\"],\n                gc.PPN_TASK_IS_TEXT_MPLAIN_WORD_SEPARATOR: self.configuration[\"i_t_mplain_word_separator\"],\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L1_ID_REGEX: self.configuration[\"i_t_munparsed_l1_id_regex\"],\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L2_ID_REGEX: self.configuration[\"i_t_munparsed_l2_id_regex\"],\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L3_ID_REGEX: self.configuration[\"i_t_munparsed_l3_id_regex\"],\n                gc.PPN_TASK_IS_TEXT_UNPARSED_CLASS_REGEX: self.configuration[\"i_t_unparsed_class_regex\"],\n                gc.PPN_TASK_IS_TEXT_UNPARSED_ID_REGEX: self.configuration[\"i_t_unparsed_id_regex\"],\n                gc.PPN_TASK_IS_TEXT_UNPARSED_ID_SORT: self.configuration[\"i_t_unparsed_id_sort\"],\n                gc.PPN_TASK_OS_FILE_ID_REGEX: self.configuration[\"o_id_regex\"]\n            }\n            self.text_file = TextFile(\n                file_path=self.text_file_path_absolute,\n                file_format=self.configuration[\"i_t_format\"],\n                parameters=parameters,\n                logger=self.logger\n            )\n            self.text_file.set_language(self.configuration[\"language\"])\n        else:\n            self.log(u\"text_file_path_absolute and/or language is None\")\n        self.log(u\"Populate text file... done\")", "response": "Populate the self. text_file object by reading the text file at self. text_file_path_absolute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aba_parameters(self):\n        ABA_MAP = {\n            AdjustBoundaryAlgorithm.AFTERCURRENT: [self[gc.PPN_TASK_ADJUST_BOUNDARY_AFTERCURRENT_VALUE]],\n            AdjustBoundaryAlgorithm.AUTO: [],\n            AdjustBoundaryAlgorithm.BEFORENEXT: [self[gc.PPN_TASK_ADJUST_BOUNDARY_BEFORENEXT_VALUE]],\n            AdjustBoundaryAlgorithm.OFFSET: [self[gc.PPN_TASK_ADJUST_BOUNDARY_OFFSET_VALUE]],\n            AdjustBoundaryAlgorithm.PERCENT: [self[gc.PPN_TASK_ADJUST_BOUNDARY_PERCENT_VALUE]],\n            AdjustBoundaryAlgorithm.RATE: [self[gc.PPN_TASK_ADJUST_BOUNDARY_RATE_VALUE]],\n            AdjustBoundaryAlgorithm.RATEAGGRESSIVE: [self[gc.PPN_TASK_ADJUST_BOUNDARY_RATE_VALUE]]\n        }\n        aba_algorithm = self[gc.PPN_TASK_ADJUST_BOUNDARY_ALGORITHM] or AdjustBoundaryAlgorithm.AUTO\n        ns_min = self[gc.PPN_TASK_ADJUST_BOUNDARY_NONSPEECH_MIN]\n        ns_string = self[gc.PPN_TASK_ADJUST_BOUNDARY_NONSPEECH_STRING]\n        nozero = self[gc.PPN_TASK_ADJUST_BOUNDARY_NO_ZERO] or False\n        return {\n            \"algorithm\": (aba_algorithm, ABA_MAP[aba_algorithm]),\n            \"nonspeech\": (ns_min, ns_string),\n            \"nozero\": nozero\n        }", "response": "Return a dictionary representing the necessary information for the ISO - 8601 AdjustBoundaryAlgorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_properties(self, audio_file_path):\n\n        # test if we can read the file at audio_file_path\n        if audio_file_path is None:\n            self.log_exc(u\"The audio file path is None\", None, True, TypeError)\n        if not gf.file_can_be_read(audio_file_path):\n            self.log_exc(u\"Input file '%s' cannot be read\" % (audio_file_path), None, True, OSError)\n\n        # call ffprobe\n        arguments = [self.rconf[RuntimeConfiguration.FFPROBE_PATH]]\n        arguments.extend(self.FFPROBE_PARAMETERS)\n        arguments.append(audio_file_path)\n        self.log([u\"Calling with arguments '%s'\", arguments])\n        try:\n            proc = subprocess.Popen(\n                arguments,\n                stdout=subprocess.PIPE,\n                stdin=subprocess.PIPE,\n                stderr=subprocess.PIPE\n            )\n            (stdoutdata, stderrdata) = proc.communicate()\n            proc.stdout.close()\n            proc.stdin.close()\n            proc.stderr.close()\n        except OSError as exc:\n            self.log_exc(u\"Unable to call the '%s' ffprobe executable\" % (self.rconf[RuntimeConfiguration.FFPROBE_PATH]), exc, True, FFPROBEPathError)\n        self.log(u\"Call completed\")\n\n        # check there is some output\n        if (stdoutdata is None) or (len(stderrdata) == 0):\n            self.log_exc(u\"ffprobe produced no output\", None, True, FFPROBEParsingError)\n\n        # decode stdoutdata and stderrdata to Unicode string\n        try:\n            stdoutdata = gf.safe_unicode(stdoutdata)\n            stderrdata = gf.safe_unicode(stderrdata)\n        except UnicodeDecodeError as exc:\n            self.log_exc(u\"Unable to decode ffprobe out/err\", exc, True, FFPROBEParsingError)\n\n        # dictionary for the results\n        results = {\n            self.STDOUT_CHANNELS: None,\n            self.STDOUT_CODEC_NAME: None,\n            self.STDOUT_DURATION: None,\n            self.STDOUT_SAMPLE_RATE: None\n        }\n\n        # scan the first audio stream the ffprobe stdout output\n        # TODO more robust parsing\n        # TODO deal with multiple audio streams\n        for line in stdoutdata.splitlines():\n            if line == self.STDOUT_END_STREAM:\n                self.log(u\"Reached end of the stream\")\n                break\n            elif len(line.split(\"=\")) == 2:\n                key, value = line.split(\"=\")\n                results[key] = value\n                self.log([u\"Found property '%s'='%s'\", key, value])\n\n        try:\n            self.log([u\"Duration found in stdout: '%s'\", results[self.STDOUT_DURATION]])\n            results[self.STDOUT_DURATION] = TimeValue(results[self.STDOUT_DURATION])\n            self.log(u\"Valid duration\")\n        except:\n            self.log_warn(u\"Invalid duration\")\n            results[self.STDOUT_DURATION] = None\n            # try scanning ffprobe stderr output\n            for line in stderrdata.splitlines():\n                match = self.STDERR_DURATION_REGEX.search(line)\n                if match is not None:\n                    self.log([u\"Found matching line '%s'\", line])\n                    results[self.STDOUT_DURATION] = gf.time_from_hhmmssmmm(line)\n                    self.log([u\"Extracted duration '%.3f'\", results[self.STDOUT_DURATION]])\n                    break\n\n        if results[self.STDOUT_DURATION] is None:\n            self.log_exc(u\"No duration found in stdout or stderr. Unsupported audio file format?\", None, True, FFPROBEUnsupportedFormatError)\n\n        # return dictionary\n        self.log(u\"Returning dict\")\n        return results", "response": "Read the properties of an audio file and return them as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_lines_from_node_text(cls, node):\n        # TODO more robust parsing\n        from lxml import etree\n        parts = ([node.text] + list(chain(*([etree.tostring(c, with_tail=False), c.tail] for c in node.getchildren()))) + [node.tail])\n        parts = [gf.safe_unicode(p) for p in parts]\n        parts = [p.strip() for p in parts if not p.startswith(u\"<br \")]\n        parts = [p for p in parts if len(p) > 0]\n        uparts = []\n        for part in parts:\n            uparts.append(gf.safe_unicode(part))\n        return uparts", "response": "Given an lxml node get lines from node. text where the line separator is... />."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an lxml tree as a Unicode string.", "response": "def _tree_to_string(cls, root_element, xml_declaration=True, pretty_print=True):\n        \"\"\"\n        Return an ``lxml`` tree as a Unicode string.\n        \"\"\"\n        from lxml import etree\n        return gf.safe_unicode(etree.tostring(\n            root_element,\n            encoding=\"UTF-8\",\n            method=\"xml\",\n            xml_declaration=xml_declaration,\n            pretty_print=pretty_print\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_generic(self, msg, prefix=None):\n        if prefix is None:\n            self._log(msg, Logger.INFO)\n        else:\n            self._log(msg, prefix)\n        if self.use_sys:\n            if (prefix is not None) and (prefix in self.PREFIX_TO_PRINT_FUNCTION):\n                self.PREFIX_TO_PRINT_FUNCTION[prefix](msg)\n            else:\n                gf.safe_print(msg)", "response": "Print a message and log it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting help message and exit.", "response": "def print_help(self, short=False):\n        \"\"\"\n        Print help message and exit.\n\n        :param short: print short help only\n        :type  short: bool\n        \"\"\"\n        header = [\n            u\"\",\n            u\"NAME\",\n            u\"  %s - %s\" % (self.NAME, self.HELP[\"description\"]),\n            u\"\",\n        ]\n\n        synopsis = [\n            u\"SYNOPSIS\",\n            u\"  %s [-h|--help|--help-rconf|--version]\" % (self.invoke),\n        ]\n        if \"synopsis\" in self.HELP:\n            for syn, opt in self.HELP[\"synopsis\"]:\n                if opt:\n                    opt = u\" [OPTIONS]\"\n                else:\n                    opt = u\"\"\n                synopsis.append(u\"  %s %s%s\" % (self.invoke, syn, opt))\n\n        synopsis.append(u\"\")\n\n        options = [\n            u\"  -h : print short help and exit\",\n            u\"  --help : print full help and exit\",\n            u\"  --help-rconf : list all runtime configuration parameters\",\n            u\"  --version : print the program name and version and exit\",\n            u\"  -l[=FILE], --log[=FILE] : log verbose output to tmp file or FILE if specified\",\n            u\"  -r=CONF, --runtime-configuration=CONF : apply runtime configuration CONF\",\n            u\"  -v, --verbose : verbose output\",\n            u\"  -vv, --very-verbose : verbose output, print date/time values\",\n        ]\n        if \"options\" in self.HELP:\n            for opt in self.HELP[\"options\"]:\n                options.append(u\"  %s\" % (opt))\n        options = [u\"OPTIONS\"] + sorted(options) + [u\"\"]\n\n        parameters = []\n        if (\"parameters\" in self.HELP) and (len(self.HELP[\"parameters\"]) > 0):\n            parameters.append(u\"PARAMETERS\")\n            for par in self.HELP[\"parameters\"]:\n                parameters.append(u\"  %s\" % (par))\n            parameters.append(u\"\")\n\n        examples = []\n        if (\"examples\" in self.HELP) and (len(self.HELP[\"examples\"]) > 0):\n            examples.append(u\"EXAMPLES\")\n            for exa in self.HELP[\"examples\"]:\n                examples.append(u\"  %s %s\" % (self.invoke, exa))\n            examples.append(u\"\")\n\n        footer = [\n            u\"EXIT CODES\",\n            u\"  %d : no error\" % (self.NO_ERROR_EXIT_CODE),\n            u\"  %d : error\" % (self.ERROR_EXIT_CODE),\n            u\"  %d : help shown, no command run\" % (self.HELP_EXIT_CODE),\n            u\"\",\n            u\"AUTHOR\",\n            u\"  Alberto Pettarin, http://www.albertopettarin.it/\",\n            u\"\",\n            u\"REPORTING BUGS\",\n            u\"  Please use the GitHub Issues Web page : %s\" % (self.ISSUES_URL),\n            u\"\",\n            u\"COPYRIGHT\",\n            u\"  2012-2017, Alberto Pettarin and ReadBeyond Srl\",\n            u\"  This software is available under the terms of the GNU Affero General Public License Version 3\",\n            u\"\",\n            u\"SEE ALSO\",\n            u\"  Code repository  : %s\" % (self.GITHUB_URL),\n            u\"  Documentation    : %s\" % (self.DOCS_URL),\n            u\"  Project Web page : %s\" % (self.AENEAS_URL),\n            u\"\",\n        ]\n\n        msg = header + synopsis + options + parameters + examples\n        if not short:\n            msg += footer\n        if self.use_sys:\n            self.print_generic(u\"\\n\".join(msg))\n        return self.exit(self.HELP_EXIT_CODE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_name_version(self):\n        if self.use_sys:\n            self.print_generic(u\"%s v%s\" % (self.NAME, aeneas_version))\n        return self.exit(self.HELP_EXIT_CODE)", "response": "Print program name and version and exit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the list of runtime configuration parameters and exit.", "response": "def print_rconf_parameters(self):\n        \"\"\"\n        Print the list of runtime configuration parameters and exit.\n        \"\"\"\n        if self.use_sys:\n            self.print_info(u\"Available runtime configuration parameters:\")\n            self.print_generic(u\"\\n\" + u\"\\n\".join(self.RCONF_PARAMETERS) + u\"\\n\")\n        return self.exit(self.HELP_EXIT_CODE)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprogram entry point. Please note that the first item in ``arguments`` is discarded, as it is assumed to be the script/invocation name; pass a \"dumb\" placeholder if you call this method with an argument different that ``sys.argv``. :param arguments: the list of arguments :type arguments: list :param show_help: if ``False``, do not show help on ``-h`` and ``--help`` :type show_help: bool :rtype: int", "response": "def run(self, arguments, show_help=True):\n        \"\"\"\n        Program entry point.\n\n        Please note that the first item in ``arguments`` is discarded,\n        as it is assumed to be the script/invocation name;\n        pass a \"dumb\" placeholder if you call this method with\n        an argument different that ``sys.argv``.\n\n        :param arguments: the list of arguments\n        :type  arguments: list\n        :param show_help: if ``False``, do not show help on ``-h`` and ``--help``\n        :type  show_help: bool\n        :rtype: int\n        \"\"\"\n        # convert arguments into Unicode strings\n        if self.use_sys:\n            # check that sys.stdin.encoding and sys.stdout.encoding are set to utf-8\n            if not gf.FROZEN:\n                if sys.stdin.encoding not in [\"UTF-8\", \"UTF8\"]:\n                    self.print_warning(u\"The default input encoding is not UTF-8.\")\n                    self.print_warning(u\"You might want to set 'PYTHONIOENCODING=UTF-8' in your shell.\")\n                if sys.stdout.encoding not in [\"UTF-8\", \"UTF8\"]:\n                    self.print_warning(u\"The default output encoding is not UTF-8.\")\n                    self.print_warning(u\"You might want to set 'PYTHONIOENCODING=UTF-8' in your shell.\")\n            # decode using sys.stdin.encoding\n            args = [gf.safe_unicode_stdin(arg) for arg in arguments]\n        else:\n            # decode using utf-8 (but you should pass Unicode strings as parameters anyway)\n            args = [gf.safe_unicode(arg) for arg in arguments]\n\n        if show_help:\n            if u\"-h\" in args:\n                return self.print_help(short=True)\n\n            if u\"--help\" in args:\n                return self.print_help(short=False)\n\n            if u\"--help-rconf\" in args:\n                return self.print_rconf_parameters()\n\n            if u\"--version\" in args:\n                return self.print_name_version()\n\n        # store formal arguments\n        self.formal_arguments_raw = arguments\n        self.formal_arguments = args\n\n        # to obtain the actual arguments,\n        # remove the first one and \"special\" switches\n        args = args[1:]\n        set_args = set(args)\n\n        # set verbosity, if requested\n        for flag in set([u\"-v\", u\"--verbose\"]) & set_args:\n            self.verbose = True\n            args.remove(flag)\n        for flag in set([u\"-vv\", u\"--very-verbose\"]) & set_args:\n            self.verbose = True\n            self.very_verbose = True\n            args.remove(flag)\n\n        # set RuntimeConfiguration string, if specified\n        for flag in [u\"-r\", u\"--runtime-configuration\"]:\n            rconf_string = self.has_option_with_value(flag, actual_arguments=False)\n            if rconf_string is not None:\n                self.rconf = RuntimeConfiguration(rconf_string)\n                args.remove(\"%s=%s\" % (flag, rconf_string))\n\n        # set log file path, if requested\n        log_path = None\n        for flag in [u\"-l\", u\"--log\"]:\n            log_path = self.has_option_with_value(flag, actual_arguments=False)\n            if log_path is not None:\n                args.remove(\"%s=%s\" % (flag, log_path))\n            elif flag in set_args:\n                handler, log_path = gf.tmp_file(suffix=u\".log\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n                args.remove(flag)\n            if log_path is not None:\n                self.log_file_path = log_path\n\n        # if no actual arguments left, print help\n        if (len(args) < 1) and (show_help):\n            return self.print_help(short=True)\n\n        # store actual arguments\n        self.actual_arguments = args\n\n        # create logger\n        self.logger = Logger(tee=self.verbose, tee_show_datetime=self.very_verbose)\n        self.log([u\"Running aeneas %s\", aeneas_version])\n        self.log([u\"Formal arguments: %s\", self.formal_arguments])\n        self.log([u\"Actual arguments: %s\", self.actual_arguments])\n        self.log([u\"Runtime configuration: '%s'\", self.rconf.config_string])\n\n        # perform command\n        exit_code = self.perform_command()\n        self.log([u\"Execution completed with code %d\", exit_code])\n\n        # output log if requested\n        if self.log_file_path is not None:\n            self.log([u\"User requested saving log to file '%s'\", self.log_file_path])\n            self.logger.write(self.log_file_path)\n            if self.use_sys:\n                self.print_info(u\"Log written to file '%s'\" % self.log_file_path)\n\n        return self.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_option(self, target):\n        if isinstance(target, list):\n            target_set = set(target)\n        else:\n            target_set = set([target])\n        return len(target_set & set(self.actual_arguments)) > 0", "response": "Return True if the actual arguments include the specified target option or a list of options at least one of them."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the actual arguments include an option with the given prefix and having a value.", "response": "def has_option_with_value(self, prefix, actual_arguments=True):\n        \"\"\"\n        Check if the actual arguments include an option\n        starting with the given ``prefix`` and having a value,\n        e.g. ``--format=ogg`` for ``prefix=\"--format\"``.\n\n        :param prefix: the option prefix\n        :type  prefix: Unicode string\n        :param actual_arguments: if ``True``, check among actual arguments;\n                                 otherwise check among formal arguments\n        :rtype actual_arguments: bool\n        :rtype: Unicode string or None\n        \"\"\"\n        if actual_arguments:\n            args = self.actual_arguments\n        else:\n            args = self.formal_arguments\n        for arg in [arg for arg in args if (arg is not None) and (arg.startswith(prefix + u\"=\"))]:\n            lis = arg.split(u\"=\")\n            if len(lis) >= 2:\n                return u\"=\".join(lis[1:])\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        self.log(u\"This function should be overloaded in derived classes\")\n        self.log([u\"Invoked with %s\", self.actual_arguments])\n        return self.NO_ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if C extensions can be run and emit a warning and return True. Otherwise return False.", "response": "def check_c_extensions(self, name=None):\n        \"\"\"\n        If C extensions cannot be run, emit a warning\n        and return ``False``. Otherwise return ``True``.\n        If ``name`` is not ``None``, check just\n        the C extension with that name.\n\n        :param name: the name of the Python C extension to test\n        :type  name: string\n        :rtype: bool\n        \"\"\"\n        if not gf.can_run_c_extension(name=name):\n            if name is None:\n                self.print_warning(u\"Unable to load Python C Extensions\")\n            else:\n                self.print_warning(u\"Unable to load Python C Extension %s\" % (name))\n            self.print_warning(u\"Running the slower pure Python code\")\n            self.print_warning(u\"See the documentation for directions to compile the Python C Extensions\")\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_input_file_or_directory(self, path):\n        if (not gf.file_can_be_read(path)) and (not os.path.isdir(path)):\n            self.print_error(u\"Unable to read file or directory '%s'\" % (path))\n            self.print_error(u\"Make sure the path is written/escaped correctly and that you have read permission on it\")\n            return False\n        return True", "response": "Check if the given path exists and if it is read return True. Otherwise return False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_input_file(self, path):\n        if not gf.file_can_be_read(path):\n            self.print_error(u\"Unable to read file '%s'\" % (path))\n            self.print_error(u\"Make sure the file path is written/escaped correctly and that you have read permission on it\")\n            return False\n        return True", "response": "Check if the given path exists and if it is read return True. Otherwise return False."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_output_file(self, path):\n        if not gf.file_can_be_written(path):\n            self.print_error(u\"Unable to create file '%s'\" % (path))\n            self.print_error(u\"Make sure the file path is written/escaped correctly and that you have write permission on it\")\n            return False\n        return True", "response": "Check if the given path can be written and return True. Otherwise return False."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the given directory can be written.", "response": "def check_output_directory(self, path):\n        \"\"\"\n        If the given directory cannot be written, emit an error\n        and return ``False``. Otherwise return ``True``.\n\n        :param path: the path of the output directory\n        :type  path: string (path)\n        :rtype: bool\n        \"\"\"\n        if not os.path.isdir(path):\n            self.print_error(u\"Directory '%s' does not exist\" % (path))\n            return False\n        test_file = os.path.join(path, u\"file.test\")\n        if not gf.file_can_be_written(test_file):\n            self.print_error(u\"Unable to write inside directory '%s'\" % (path))\n            self.print_error(u\"Make sure the directory path is written/escaped correctly and that you have write permission on it\")\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the container can be safely extracted False otherwise.", "response": "def is_safe(self):\n        \"\"\"\n        Return ``True`` if the container can be safely extracted,\n        that is, if all its entries are safe, ``False`` otherwise.\n\n        :rtype: bool\n        :raises: same as :func:`~aeneas.container.Container.entries`\n        \"\"\"\n        self.log(u\"Checking if this container is safe\")\n        for entry in self.entries:\n            if not self.is_entry_safe(entry):\n                self.log([u\"This container is not safe: found unsafe entry '%s'\", entry])\n                return False\n        self.log(u\"This container is safe\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if entry can be safely extracted False otherwise.", "response": "def is_entry_safe(self, entry):\n        \"\"\"\n        Return ``True`` if ``entry`` can be safely extracted,\n        that is, if it does start with ``/`` or ``../``\n        after path normalization, ``False`` otherwise.\n\n        :rtype: bool\n        \"\"\"\n        normalized = os.path.normpath(entry)\n        if normalized.startswith(os.sep) or normalized.startswith(\"..\" + os.sep):\n            self.log([u\"Entry '%s' is not safe\", entry])\n            return False\n        self.log([u\"Entry '%s' is safe\", entry])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the sorted list of entries in this container.", "response": "def entries(self):\n        \"\"\"\n        Return the sorted list of entries in this container,\n        each represented by its full path inside the container.\n\n        :rtype: list of strings (path)\n        :raises: TypeError: if this container does not exist\n        :raises: OSError: if an error occurred reading the given container\n                          (e.g., empty file, damaged file, etc.)\n        \"\"\"\n        self.log(u\"Getting entries\")\n        if not self.exists():\n            self.log_exc(u\"This container does not exist. Wrong path?\", None, True, TypeError)\n        if self.actual_container is None:\n            self.log_exc(u\"The actual container object has not been set\", None, True, TypeError)\n        return self.actual_container.entries"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_entry(self, entry, exact=True):\n        if exact:\n            self.log([u\"Finding entry '%s' with exact=True\", entry])\n            if entry in self.entries:\n                self.log([u\"Found entry '%s'\", entry])\n                return entry\n        else:\n            self.log([u\"Finding entry '%s' with exact=False\", entry])\n            for ent in self.entries:\n                if os.path.basename(ent) == entry:\n                    self.log([u\"Found entry '%s'\", ent])\n                    return ent\n        self.log([u\"Entry '%s' not found\", entry])\n        return None", "response": "Return the full path to the first entry whose file name equals the given entry path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the contents of an entry in this container and return them as a byte string.", "response": "def read_entry(self, entry):\n        \"\"\"\n        Read the contents of an entry in this container,\n        and return them as a byte string.\n\n        Return ``None`` if the entry is not safe\n        or it cannot be found.\n\n        :rtype: byte string\n        :raises: same as :func:`~aeneas.container.Container.entries`\n        \"\"\"\n        if not self.is_entry_safe(entry):\n            self.log([u\"Accessing entry '%s' is not safe\", entry])\n            return None\n\n        if entry not in self.entries:\n            self.log([u\"Entry '%s' not found in this container\", entry])\n            return None\n\n        self.log([u\"Reading contents of entry '%s'\", entry])\n        try:\n            return self.actual_container.read_entry(entry)\n        except:\n            self.log([u\"An error occurred while reading the contents of '%s'\", entry])\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decompress(self, output_path):\n        self.log([u\"Decompressing the container into '%s'\", output_path])\n        if not self.exists():\n            self.log_exc(u\"This container does not exist. Wrong path?\", None, True, TypeError)\n        if self.actual_container is None:\n            self.log_exc(u\"The actual container object has not been set\", None, True, TypeError)\n        if not gf.directory_exists(output_path):\n            self.log_exc(u\"The output path is not an existing directory\", None, True, ValueError)\n        if not self.is_safe:\n            self.log_exc(u\"This container contains unsafe entries\", None, True, ValueError)\n        self.actual_container.decompress(output_path)", "response": "Decompress the entire container into the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompress the contents of the given directory into this container.", "response": "def compress(self, input_path):\n        \"\"\"\n        Compress the contents of the given directory.\n\n        :param string input_path: path of the input directory\n        :raises: TypeError: if the container path has not been set\n        :raises: ValueError: if ``input_path`` is not an existing directory\n        :raises: OSError: if an error occurred compressing the given container\n                          (e.g., empty file, damaged file, etc.)\n        \"\"\"\n        self.log([u\"Compressing '%s' into this container\", input_path])\n\n        if self.file_path is None:\n            self.log_exc(u\"The container path has not been set\", None, True, TypeError)\n        if self.actual_container is None:\n            self.log_exc(u\"The actual container object has not been set\", None, True, TypeError)\n        if not gf.directory_exists(input_path):\n            self.log_exc(u\"The input path is not an existing directory\", None, True, ValueError)\n        gf.ensure_parent_directory(input_path)\n        self.actual_container.compress(input_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(self):\n        return gf.file_exists(self.file_path) or gf.directory_exists(self.file_path)", "response": "Return True if the container has its path set and it exists False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the actual container based on the specified container format.", "response": "def _set_actual_container(self):\n        \"\"\"\n        Set the actual container, based on the specified container format.\n\n        If the container format is not specified,\n        infer it from the (lowercased) extension of the file path.\n        If the format cannot be inferred, it is assumed to be\n        of type :class:`~aeneas.container.ContainerFormat.UNPACKED`\n        (unpacked directory).\n        \"\"\"\n        # infer container format\n        if self.container_format is None:\n            self.log(u\"Inferring actual container format...\")\n            path_lowercased = self.file_path.lower()\n            self.log([u\"Lowercased file path: '%s'\", path_lowercased])\n            self.container_format = ContainerFormat.UNPACKED\n            for fmt in ContainerFormat.ALLOWED_FILE_VALUES:\n                if path_lowercased.endswith(fmt):\n                    self.container_format = fmt\n                    break\n            self.log(u\"Inferring actual container format... done\")\n            self.log([u\"Inferred format: '%s'\", self.container_format])\n\n        # set the actual container\n        self.log(u\"Setting actual container...\")\n        class_map = {\n            ContainerFormat.ZIP: (_ContainerZIP, None),\n            ContainerFormat.EPUB: (_ContainerZIP, None),\n            ContainerFormat.TAR: (_ContainerTAR, \"\"),\n            ContainerFormat.TAR_GZ: (_ContainerTAR, \":gz\"),\n            ContainerFormat.TAR_BZ2: (_ContainerTAR, \":bz2\"),\n            ContainerFormat.UNPACKED: (_ContainerUnpacked, None)\n        }\n        actual_class, variant = class_map[self.container_format]\n        self.actual_container = actual_class(\n            file_path=self.file_path,\n            variant=variant,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        self.log([u\"Actual container format: '%s'\", self.container_format])\n        self.log(u\"Setting actual container... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nanalyze the given container and return the corresponding job object.", "response": "def analyze(self, config_string=None):\n        \"\"\"\n        Analyze the given container and\n        return the corresponding job object.\n\n        On error, it will return ``None``.\n\n        :param string config_string: the configuration string generated by wizard\n        :rtype: :class:`~aeneas.job.Job` or ``None``\n        \"\"\"\n        try:\n            if config_string is not None:\n                self.log(u\"Analyzing container with the given config string\")\n                return self._analyze_txt_config(config_string=config_string)\n            elif self.container.has_config_xml:\n                self.log(u\"Analyzing container with XML config file\")\n                return self._analyze_xml_config(config_contents=None)\n            elif self.container.has_config_txt:\n                self.log(u\"Analyzing container with TXT config file\")\n                return self._analyze_txt_config(config_string=None)\n            else:\n                self.log(u\"No configuration file in this container, returning None\")\n        except (OSError, KeyError, TypeError) as exc:\n            self.log_exc(u\"An unexpected error occurred while analyzing\", exc, True, None)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nanalyzing the given container and return the corresponding job.", "response": "def _analyze_txt_config(self, config_string=None):\n        \"\"\"\n        Analyze the given container and return the corresponding job.\n\n        If ``config_string`` is ``None``,\n        try reading it from the TXT config file inside the container.\n\n        :param string config_string: the configuration string\n        :rtype: :class:`~aeneas.job.Job`\n        \"\"\"\n        self.log(u\"Analyzing container with TXT config string\")\n\n        if config_string is None:\n            self.log(u\"Analyzing container with TXT config file\")\n            config_entry = self.container.entry_config_txt\n            self.log([u\"Found TXT config entry '%s'\", config_entry])\n            config_dir = os.path.dirname(config_entry)\n            self.log([u\"Directory of TXT config entry: '%s'\", config_dir])\n            self.log([u\"Reading TXT config entry: '%s'\", config_entry])\n            config_contents = self.container.read_entry(config_entry)\n            self.log(u\"Converting config contents to config string\")\n            config_contents = gf.safe_unicode(config_contents)\n            config_string = gf.config_txt_to_string(config_contents)\n        else:\n            self.log([u\"Analyzing container with TXT config string '%s'\", config_string])\n            config_dir = \"\"\n\n        self.log(u\"Creating the Job object\")\n        job = Job(config_string)\n\n        self.log(u\"Getting entries\")\n        entries = self.container.entries\n\n        self.log(u\"Converting config string into config dict\")\n        parameters = gf.config_string_to_dict(config_string)\n\n        self.log(u\"Calculating the path of the tasks root directory\")\n        tasks_root_directory = gf.norm_join(\n            config_dir,\n            parameters[gc.PPN_JOB_IS_HIERARCHY_PREFIX]\n        )\n        self.log([u\"Path of the tasks root directory: '%s'\", tasks_root_directory])\n\n        self.log(u\"Calculating the path of the sync map root directory\")\n        sync_map_root_directory = gf.norm_join(\n            config_dir,\n            parameters[gc.PPN_JOB_OS_HIERARCHY_PREFIX]\n        )\n        job_os_hierarchy_type = parameters[gc.PPN_JOB_OS_HIERARCHY_TYPE]\n        self.log([u\"Path of the sync map root directory: '%s'\", sync_map_root_directory])\n\n        text_file_relative_path = parameters[gc.PPN_JOB_IS_TEXT_FILE_RELATIVE_PATH]\n        self.log([u\"Relative path for text file: '%s'\", text_file_relative_path])\n        text_file_name_regex = re.compile(r\"\" + parameters[gc.PPN_JOB_IS_TEXT_FILE_NAME_REGEX])\n        self.log([u\"Regex for text file: '%s'\", parameters[gc.PPN_JOB_IS_TEXT_FILE_NAME_REGEX]])\n        audio_file_relative_path = parameters[gc.PPN_JOB_IS_AUDIO_FILE_RELATIVE_PATH]\n        self.log([u\"Relative path for audio file: '%s'\", audio_file_relative_path])\n        audio_file_name_regex = re.compile(r\"\" + parameters[gc.PPN_JOB_IS_AUDIO_FILE_NAME_REGEX])\n        self.log([u\"Regex for audio file: '%s'\", parameters[gc.PPN_JOB_IS_AUDIO_FILE_NAME_REGEX]])\n\n        if parameters[gc.PPN_JOB_IS_HIERARCHY_TYPE] == HierarchyType.FLAT:\n            self.log(u\"Looking for text/audio pairs in flat hierarchy\")\n            text_files = self._find_files(\n                entries,\n                tasks_root_directory,\n                text_file_relative_path,\n                text_file_name_regex\n            )\n            self.log([u\"Found text files: '%s'\", text_files])\n            audio_files = self._find_files(\n                entries,\n                tasks_root_directory,\n                audio_file_relative_path,\n                audio_file_name_regex\n            )\n            self.log([u\"Found audio files: '%s'\", audio_files])\n\n            self.log(u\"Matching files in flat hierarchy...\")\n            matched_tasks = self._match_files_flat_hierarchy(\n                text_files,\n                audio_files\n            )\n            self.log(u\"Matching files in flat hierarchy... done\")\n\n            for task_info in matched_tasks:\n                self.log([u\"Creating task: '%s'\", str(task_info)])\n                task = self._create_task(\n                    task_info,\n                    config_string,\n                    sync_map_root_directory,\n                    job_os_hierarchy_type\n                )\n                job.add_task(task)\n\n        if parameters[gc.PPN_JOB_IS_HIERARCHY_TYPE] == HierarchyType.PAGED:\n            self.log(u\"Looking for text/audio pairs in paged hierarchy\")\n            # find all subdirectories of tasks_root_directory\n            # that match gc.PPN_JOB_IS_TASK_DIRECTORY_NAME_REGEX\n            matched_directories = self._match_directories(\n                entries,\n                tasks_root_directory,\n                parameters[gc.PPN_JOB_IS_TASK_DIRECTORY_NAME_REGEX]\n            )\n            for matched_directory in matched_directories:\n                # rebuild the full path\n                matched_directory_full_path = gf.norm_join(\n                    tasks_root_directory,\n                    matched_directory\n                )\n                self.log([u\"Looking for text/audio pairs in directory '%s'\", matched_directory_full_path])\n\n                # look for text and audio files there\n                text_files = self._find_files(\n                    entries,\n                    matched_directory_full_path,\n                    text_file_relative_path,\n                    text_file_name_regex\n                )\n                self.log([u\"Found text files: '%s'\", text_files])\n                audio_files = self._find_files(\n                    entries,\n                    matched_directory_full_path,\n                    audio_file_relative_path,\n                    audio_file_name_regex\n                )\n                self.log([u\"Found audio files: '%s'\", audio_files])\n\n                # if we have found exactly one text and one audio file,\n                # create a Task\n                if (len(text_files) == 1) and (len(audio_files) == 1):\n                    self.log([u\"Exactly one text file and one audio file in '%s'\", matched_directory])\n                    task_info = [\n                        matched_directory,\n                        text_files[0],\n                        audio_files[0]\n                    ]\n                    self.log([u\"Creating task: '%s'\", str(task_info)])\n                    task = self._create_task(\n                        task_info,\n                        config_string,\n                        sync_map_root_directory,\n                        job_os_hierarchy_type\n                    )\n                    job.add_task(task)\n                elif len(text_files) > 1:\n                    self.log([u\"More than one text file in '%s'\", matched_directory])\n                elif len(audio_files) > 1:\n                    self.log([u\"More than one audio file in '%s'\", matched_directory])\n                else:\n                    self.log([u\"No text nor audio file in '%s'\", matched_directory])\n\n        return job"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _analyze_xml_config(self, config_contents=None):\n        self.log(u\"Analyzing container with XML config string\")\n\n        if config_contents is None:\n            self.log(u\"Analyzing container with XML config file\")\n            config_entry = self.container.entry_config_xml\n            self.log([u\"Found XML config entry '%s'\", config_entry])\n            config_dir = os.path.dirname(config_entry)\n            self.log([u\"Directory of XML config entry: '%s'\", config_dir])\n            self.log([u\"Reading XML config entry: '%s'\", config_entry])\n            config_contents = self.container.read_entry(config_entry)\n        else:\n            self.log(u\"Analyzing container with XML config contents\")\n            config_dir = \"\"\n\n        self.log(u\"Converting config contents into job config dict\")\n        job_parameters = gf.config_xml_to_dict(\n            config_contents,\n            result=None,\n            parse_job=True\n        )\n        self.log(u\"Converting config contents into tasks config dict\")\n        tasks_parameters = gf.config_xml_to_dict(\n            config_contents,\n            result=None,\n            parse_job=False\n        )\n\n        self.log(u\"Calculating the path of the sync map root directory\")\n        sync_map_root_directory = gf.norm_join(\n            config_dir,\n            job_parameters[gc.PPN_JOB_OS_HIERARCHY_PREFIX]\n        )\n        job_os_hierarchy_type = job_parameters[gc.PPN_JOB_OS_HIERARCHY_TYPE]\n        self.log([u\"Path of the sync map root directory: '%s'\", sync_map_root_directory])\n\n        self.log(u\"Converting job config dict into job config string\")\n        config_string = gf.config_dict_to_string(job_parameters)\n        job = Job(config_string)\n\n        for task_parameters in tasks_parameters:\n            self.log(u\"Converting task config dict into task config string\")\n            config_string = gf.config_dict_to_string(task_parameters)\n            self.log([u\"Creating task with config string '%s'\", config_string])\n            try:\n                custom_id = task_parameters[gc.PPN_TASK_CUSTOM_ID]\n            except KeyError:\n                custom_id = \"\"\n            task_info = [\n                custom_id,\n                gf.norm_join(\n                    config_dir,\n                    task_parameters[gc.PPN_TASK_IS_TEXT_FILE_XML]\n                ),\n                gf.norm_join(\n                    config_dir,\n                    task_parameters[gc.PPN_TASK_IS_AUDIO_FILE_XML]\n                )\n            ]\n            self.log([u\"Creating task: '%s'\", str(task_info)])\n            task = self._create_task(\n                task_info,\n                config_string,\n                sync_map_root_directory,\n                job_os_hierarchy_type\n            )\n            job.add_task(task)\n\n        return job", "response": "Analyze the given container and return the corresponding job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Task object from the given task_info and config_string.", "response": "def _create_task(\n            self,\n            task_info,\n            config_string,\n            sync_map_root_directory,\n            job_os_hierarchy_type\n    ):\n        \"\"\"\n        Create a task object from\n\n        1. the ``task_info`` found analyzing the container entries, and\n        2. the given ``config_string``.\n\n        :param list task_info: the task information: ``[prefix, text_path, audio_path]``\n        :param string config_string: the configuration string\n        :param string sync_map_root_directory: the root directory for the sync map files\n        :param job_os_hierarchy_type: type of job output hierarchy\n        :type  job_os_hierarchy_type: :class:`~aeneas.hierarchytype.HierarchyType`\n        :rtype: :class:`~aeneas.task.Task`\n        \"\"\"\n        self.log(u\"Converting config string to config dict\")\n        parameters = gf.config_string_to_dict(config_string)\n        self.log(u\"Creating task\")\n        task = Task(config_string, logger=self.logger)\n        task.configuration[\"description\"] = \"Task %s\" % task_info[0]\n        self.log([u\"Task description: %s\", task.configuration[\"description\"]])\n        try:\n            task.configuration[\"language\"] = parameters[gc.PPN_TASK_LANGUAGE]\n            self.log([u\"Set language from task: '%s'\", task.configuration[\"language\"]])\n        except KeyError:\n            task.configuration[\"language\"] = parameters[gc.PPN_JOB_LANGUAGE]\n            self.log([u\"Set language from job: '%s'\", task.configuration[\"language\"]])\n        custom_id = task_info[0]\n        task.configuration[\"custom_id\"] = custom_id\n        self.log([u\"Task custom_id: %s\", task.configuration[\"custom_id\"]])\n        task.text_file_path = task_info[1]\n        self.log([u\"Task text file path: %s\", task.text_file_path])\n        task.audio_file_path = task_info[2]\n        self.log([u\"Task audio file path: %s\", task.audio_file_path])\n        task.sync_map_file_path = self._compute_sync_map_file_path(\n            sync_map_root_directory,\n            job_os_hierarchy_type,\n            custom_id,\n            task.configuration[\"o_name\"]\n        )\n        self.log([u\"Task sync map file path: %s\", task.sync_map_file_path])\n\n        self.log(u\"Replacing placeholder in os_file_smil_audio_ref\")\n        task.configuration[\"o_smil_audio_ref\"] = self._replace_placeholder(\n            task.configuration[\"o_smil_audio_ref\"],\n            custom_id\n        )\n        self.log(u\"Replacing placeholder in os_file_smil_page_ref\")\n        task.configuration[\"o_smil_page_ref\"] = self._replace_placeholder(\n            task.configuration[\"o_smil_page_ref\"],\n            custom_id\n        )\n        self.log(u\"Returning task\")\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing the placeholder in string with custom_id and return the resulting string.", "response": "def _replace_placeholder(self, string, custom_id):\n        \"\"\"\n        Replace the prefix placeholder\n        :class:`~aeneas.globalconstants.PPV_OS_TASK_PREFIX`\n        with ``custom_id`` and return the resulting string.\n\n        :rtype: string\n        \"\"\"\n        if string is None:\n            return None\n        self.log([u\"Replacing '%s' with '%s' in '%s'\", gc.PPV_OS_TASK_PREFIX, custom_id, string])\n        return string.replace(gc.PPV_OS_TASK_PREFIX, custom_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_sync_map_file_path(\n            self,\n            root,\n            hierarchy_type,\n            custom_id,\n            file_name\n    ):\n        \"\"\"\n        Compute the sync map file path inside the output container.\n\n        :param string root: the root of the sync map files inside the container\n        :param job_os_hierarchy_type: type of job output hierarchy\n        :type  job_os_hierarchy_type: :class:`~aeneas.hierarchytype.HierarchyType`\n        :param string custom_id: the task custom id (flat) or\n                                 page directory name (paged)\n        :param string file_name: the output file name for the sync map\n        :rtype: string\n        \"\"\"\n        prefix = root\n        if hierarchy_type == HierarchyType.PAGED:\n            prefix = gf.norm_join(prefix, custom_id)\n        file_name_joined = gf.norm_join(prefix, file_name)\n        return self._replace_placeholder(file_name_joined, custom_id)", "response": "Compute the sync map file path inside the output container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_files(self, entries, root, relative_path, file_name_regex):\n        self.log([u\"Finding files within root: '%s'\", root])\n        target = root\n        if relative_path is not None:\n            self.log([u\"Joining relative path: '%s'\", relative_path])\n            target = gf.norm_join(root, relative_path)\n        self.log([u\"Finding files within target: '%s'\", target])\n        files = []\n        target_len = len(target)\n        for entry in entries:\n            if entry.startswith(target):\n                self.log([u\"Examining entry: '%s'\", entry])\n                entry_suffix = entry[target_len + 1:]\n                self.log([u\"Examining entry suffix: '%s'\", entry_suffix])\n                if re.search(file_name_regex, entry_suffix) is not None:\n                    self.log([u\"Match: '%s'\", entry])\n                    files.append(entry)\n                else:\n                    self.log([u\"No match: '%s'\", entry])\n        return sorted(files)", "response": "Find the files in the specified list of entries within the given root directory and relative path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmatch audio and text files in flat hierarchies.", "response": "def _match_files_flat_hierarchy(self, text_files, audio_files):\n        \"\"\"\n        Match audio and text files in flat hierarchies.\n\n        Two files match if their names,\n        once removed the file extension,\n        are the same.\n\n        Examples: ::\n\n            foo/text/a.txt foo/audio/a.mp3 => match: [\"a\", \"foo/text/a.txt\", \"foo/audio/a.mp3\"]\n            foo/text/a.txt foo/audio/b.mp3 => no match\n            foo/res/c.txt  foo/res/c.mp3   => match: [\"c\", \"foo/res/c.txt\", \"foo/res/c.mp3\"]\n            foo/res/d.txt  foo/res/e.mp3   => no match\n\n        :param list text_files: the entries corresponding to text files\n        :param list audio_files: the entries corresponding to audio files\n        :rtype: list of lists (see above)\n        \"\"\"\n        self.log(u\"Matching files in flat hierarchy\")\n        self.log([u\"Text files: '%s'\", text_files])\n        self.log([u\"Audio files: '%s'\", audio_files])\n        d_text = {}\n        d_audio = {}\n        for text_file in text_files:\n            text_file_no_ext = gf.file_name_without_extension(text_file)\n            d_text[text_file_no_ext] = text_file\n            self.log([u\"Added text file '%s' to key '%s'\", text_file, text_file_no_ext])\n        for audio_file in audio_files:\n            audio_file_no_ext = gf.file_name_without_extension(audio_file)\n            d_audio[audio_file_no_ext] = audio_file\n            self.log([u\"Added audio file '%s' to key '%s'\", audio_file, audio_file_no_ext])\n        tasks = []\n        for key in d_text.keys():\n            self.log([u\"Examining text key '%s'\", key])\n            if key in d_audio:\n                self.log([u\"Key '%s' is also in audio\", key])\n                tasks.append([key, d_text[key], d_audio[key]])\n                self.log([u\"Added pair ('%s', '%s')\", d_text[key], d_audio[key]])\n        return tasks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _match_directories(self, entries, root, regex_string):\n        self.log(u\"Matching directory names in paged hierarchy\")\n        self.log([u\"Matching within '%s'\", root])\n        self.log([u\"Matching regex '%s'\", regex_string])\n        regex = re.compile(r\"\" + regex_string)\n        directories = set()\n        root_len = len(root)\n        for entry in entries:\n            # look only inside root dir\n            if entry.startswith(root):\n                self.log([u\"Examining '%s'\", entry])\n                # remove common prefix root/\n                entry = entry[root_len + 1:]\n                # split path\n                entry_splitted = entry.split(os.sep)\n                # match regex\n                if ((len(entry_splitted) >= 2) and\n                        (re.match(regex, entry_splitted[0]) is not None)):\n                    directories.add(entry_splitted[0])\n                    self.log([u\"Match: '%s'\", entry_splitted[0]])\n                else:\n                    self.log([u\"No match: '%s'\", entry])\n        return sorted(directories)", "response": "Return a list of directories that match the given regex string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        text_format = gf.safe_unicode(self.actual_arguments[0])\n        if text_format == u\"list\":\n            text = gf.safe_unicode(self.actual_arguments[1])\n        elif text_format in TextFileFormat.ALLOWED_VALUES:\n            text = self.actual_arguments[1]\n            if not self.check_input_file(text):\n                return self.ERROR_EXIT_CODE\n        else:\n            return self.print_help()\n\n        l1_id_regex = self.has_option_with_value(u\"--l1-id-regex\")\n        l2_id_regex = self.has_option_with_value(u\"--l2-id-regex\")\n        l3_id_regex = self.has_option_with_value(u\"--l3-id-regex\")\n        id_regex = self.has_option_with_value(u\"--id-regex\")\n        id_format = self.has_option_with_value(u\"--id-format\")\n        class_regex = self.has_option_with_value(u\"--class-regex\")\n        sort = self.has_option_with_value(u\"--sort\")\n        parameters = {\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L1_ID_REGEX: l1_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L2_ID_REGEX: l2_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L3_ID_REGEX: l3_id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_REGEX: id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_CLASS_REGEX: class_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_SORT: sort,\n            gc.PPN_TASK_OS_FILE_ID_REGEX: id_format\n        }\n        if (text_format == TextFileFormat.MUNPARSED) and ((l1_id_regex is None) or (l2_id_regex is None) or (l3_id_regex is None)):\n            self.print_error(u\"You must specify --l1-id-regex and --l2-id-regex and --l3-id-regex for munparsed format\")\n            return self.ERROR_EXIT_CODE\n        if (text_format == TextFileFormat.UNPARSED) and (id_regex is None) and (class_regex is None):\n            self.print_error(u\"You must specify --id-regex and/or --class-regex for unparsed format\")\n            return self.ERROR_EXIT_CODE\n        if (text_format in [TextFileFormat.PLAIN, TextFileFormat.SUBTITLES]) and (id_format is not None):\n            try:\n                identifier = id_format % 1\n            except (TypeError, ValueError):\n                self.print_error(u\"The given string '%s' is not a valid id format\" % id_format)\n                return self.ERROR_EXIT_CODE\n\n        text_file = self.get_text_file(text_format, text, parameters)\n        if text_file is None:\n            self.print_error(u\"Unable to build a TextFile from the given parameters\")\n        elif len(text_file) == 0:\n            self.print_error(u\"No text fragments found\")\n        else:\n            self.print_generic(text_file.__unicode__())\n            return self.NO_ERROR_EXIT_CODE\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_task(self, task):\n        if not isinstance(task, Task):\n            self.log_exc(u\"task is not an instance of Task\", None, True, ExecuteTaskInputError)\n        self.task = task", "response": "Load the task from the given task object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _step_begin(self, label, log=True):\n        if log:\n            self.step_label = label\n            self.step_begin_time = self.log(u\"STEP %d BEGIN (%s)\" % (self.step_index, label))", "response": "Log begin of a step"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _step_end(self, log=True):\n        if log:\n            step_end_time = self.log(u\"STEP %d END (%s)\" % (self.step_index, self.step_label))\n            diff = (step_end_time - self.step_begin_time)\n            diff = float(diff.seconds + diff.microseconds / 1000000.0)\n            self.step_total += diff\n            self.log(u\"STEP %d DURATION %.3f (%s)\" % (self.step_index, diff, self.step_label))\n            self.step_index += 1", "response": "Log end of a step"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _step_failure(self, exc):\n        self.log_crit(u\"STEP %d (%s) FAILURE\" % (self.step_index, self.step_label))\n        self.step_index += 1\n        self.log_exc(u\"Unexpected error while executing task\", exc, True, ExecuteTaskExecutionError)", "response": "Log failure of a step"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self):\n        self.log(u\"Executing task...\")\n\n        # check that we have the AudioFile object\n        if self.task.audio_file is None:\n            self.log_exc(u\"The task does not seem to have its audio file set\", None, True, ExecuteTaskInputError)\n        if (\n                (self.task.audio_file.audio_length is None) or\n                (self.task.audio_file.audio_length <= 0)\n        ):\n            self.log_exc(u\"The task seems to have an invalid audio file\", None, True, ExecuteTaskInputError)\n        task_max_audio_length = self.rconf[RuntimeConfiguration.TASK_MAX_AUDIO_LENGTH]\n        if (\n                (task_max_audio_length > 0) and\n                (self.task.audio_file.audio_length > task_max_audio_length)\n        ):\n            self.log_exc(u\"The audio file of the task has length %.3f, more than the maximum allowed (%.3f).\" % (self.task.audio_file.audio_length, task_max_audio_length), None, True, ExecuteTaskInputError)\n\n        # check that we have the TextFile object\n        if self.task.text_file is None:\n            self.log_exc(u\"The task does not seem to have its text file set\", None, True, ExecuteTaskInputError)\n        if len(self.task.text_file) == 0:\n            self.log_exc(u\"The task text file seems to have no text fragments\", None, True, ExecuteTaskInputError)\n        task_max_text_length = self.rconf[RuntimeConfiguration.TASK_MAX_TEXT_LENGTH]\n        if (\n                (task_max_text_length > 0) and\n                (len(self.task.text_file) > task_max_text_length)\n        ):\n            self.log_exc(u\"The text file of the task has %d fragments, more than the maximum allowed (%d).\" % (len(self.task.text_file), task_max_text_length), None, True, ExecuteTaskInputError)\n        if self.task.text_file.chars == 0:\n            self.log_exc(u\"The task text file seems to have empty text\", None, True, ExecuteTaskInputError)\n\n        self.log(u\"Both audio and text input file are present\")\n\n        # execute\n        self.step_index = 1\n        self.step_total = 0.000\n        if self.task.text_file.file_format in TextFileFormat.MULTILEVEL_VALUES:\n            self._execute_multi_level_task()\n        else:\n            self._execute_single_level_task()\n        self.log(u\"Executing task... done\")", "response": "Execute the task.\n        The sync map produced will be stored inside the task object.\n\n        :raises: :class:`~aeneas.executetask.ExecuteTaskInputError`: if there is a problem with the input parameters\n        :raises: :class:`~aeneas.executetask.ExecuteTaskExecutionError`: if there is a problem during the task execution"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _execute_single_level_task(self):\n        self.log(u\"Executing single level task...\")\n        try:\n            # load audio file, extract MFCCs from real wave, clear audio file\n            self._step_begin(u\"extract MFCC real wave\")\n            real_wave_mfcc = self._extract_mfcc(\n                file_path=self.task.audio_file_path_absolute,\n                file_format=None,\n            )\n            self._step_end()\n\n            # compute head and/or tail and set it\n            self._step_begin(u\"compute head tail\")\n            (head_length, process_length, tail_length) = self._compute_head_process_tail(real_wave_mfcc)\n            real_wave_mfcc.set_head_middle_tail(head_length, process_length, tail_length)\n            self._step_end()\n\n            # compute alignment, outputting a tree of time intervals\n            self._set_synthesizer()\n            sync_root = Tree()\n            self._execute_inner(\n                real_wave_mfcc,\n                self.task.text_file,\n                sync_root=sync_root,\n                force_aba_auto=False,\n                log=True,\n                leaf_level=True\n            )\n            self._clear_cache_synthesizer()\n\n            # create syncmap and add it to task\n            self._step_begin(u\"create sync map\")\n            self._create_sync_map(sync_root=sync_root)\n            self._step_end()\n\n            # log total\n            self._step_total()\n            self.log(u\"Executing single level task... done\")\n        except Exception as exc:\n            self._step_failure(exc)", "response": "Execute a single - level task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a multi - level task.", "response": "def _execute_multi_level_task(self):\n        \"\"\" Execute a multi-level task \"\"\"\n        self.log(u\"Executing multi level task...\")\n\n        self.log(u\"Saving rconf...\")\n        # save original rconf\n        orig_rconf = self.rconf.clone()\n        # clone rconfs and set granularity\n        # TODO the following code assumes 3 levels: generalize this\n        level_rconfs = [None, self.rconf.clone(), self.rconf.clone(), self.rconf.clone()]\n        level_mfccs = [None, None, None, None]\n        force_aba_autos = [None, False, False, True]\n        for i in range(1, len(level_rconfs)):\n            level_rconfs[i].set_granularity(i)\n            self.log([u\"Level %d mmn: %s\", i, level_rconfs[i].mmn])\n            self.log([u\"Level %d mwl: %.3f\", i, level_rconfs[i].mwl])\n            self.log([u\"Level %d mws: %.3f\", i, level_rconfs[i].mws])\n            level_rconfs[i].set_tts(i)\n            self.log([u\"Level %d tts: %s\", i, level_rconfs[i].tts])\n            self.log([u\"Level %d tts_path: %s\", i, level_rconfs[i].tts_path])\n        self.log(u\"Saving rconf... done\")\n        try:\n            self.log(u\"Creating AudioFile object...\")\n            audio_file = self._load_audio_file()\n            self.log(u\"Creating AudioFile object... done\")\n\n            # extract MFCC for each level\n            for i in range(1, len(level_rconfs)):\n                self._step_begin(u\"extract MFCC real wave level %d\" % i)\n                if (i == 1) or (level_rconfs[i].mws != level_rconfs[i - 1].mws) or (level_rconfs[i].mwl != level_rconfs[i - 1].mwl):\n                    self.rconf = level_rconfs[i]\n                    level_mfccs[i] = self._extract_mfcc(audio_file=audio_file)\n                else:\n                    self.log(u\"Keeping MFCC real wave from previous level\")\n                    level_mfccs[i] = level_mfccs[i - 1]\n                self._step_end()\n\n            self.log(u\"Clearing AudioFile object...\")\n            self.rconf = level_rconfs[1]\n            self._clear_audio_file(audio_file)\n            self.log(u\"Clearing AudioFile object... done\")\n\n            # compute head tail for the entire real wave (level 1)\n            self._step_begin(u\"compute head tail\")\n            (head_length, process_length, tail_length) = self._compute_head_process_tail(level_mfccs[1])\n            level_mfccs[1].set_head_middle_tail(head_length, process_length, tail_length)\n            self._step_end()\n\n            # compute alignment at each level\n            sync_root = Tree()\n            sync_roots = [sync_root]\n            text_files = [self.task.text_file]\n            number_levels = len(level_rconfs)\n            for i in range(1, number_levels):\n                self._step_begin(u\"compute alignment level %d\" % i)\n                self.rconf = level_rconfs[i]\n                text_files, sync_roots = self._execute_level(\n                    level=i,\n                    audio_file_mfcc=level_mfccs[i],\n                    text_files=text_files,\n                    sync_roots=sync_roots,\n                    force_aba_auto=force_aba_autos[i],\n                )\n                self._step_end()\n\n            # restore original rconf, and create syncmap and add it to task\n            self._step_begin(u\"create sync map\")\n            self.rconf = orig_rconf\n            self._create_sync_map(sync_root=sync_root)\n            self._step_end()\n\n            self._step_total()\n            self.log(u\"Executing multi level task... done\")\n        except Exception as exc:\n            self._step_failure(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the given level of the task.", "response": "def _execute_level(self, level, audio_file_mfcc, text_files, sync_roots, force_aba_auto=False):\n        \"\"\"\n        Compute the alignment for all the nodes in the given level.\n\n        Return a pair (next_level_text_files, next_level_sync_roots),\n        containing two lists of text file subtrees and sync map subtrees\n        on the next level.\n\n        :param int level: the level\n        :param audio_file_mfcc: the audio MFCC representation for this level\n        :type  audio_file_mfcc: :class:`~aeneas.audiofilemfcc.AudioFileMFCC`\n        :param list text_files: a list of :class:`~aeneas.textfile.TextFile` objects,\n                                each representing a (sub)tree of the Task text file\n        :param list sync_roots: a list of :class:`~aeneas.tree.Tree` objects,\n                                each representing a SyncMapFragment tree,\n                                one for each element in ``text_files``\n        :param bool force_aba_auto: if ``True``, force using the AUTO ABA algorithm\n        :rtype: (list, list)\n        \"\"\"\n        self._set_synthesizer()\n        next_level_text_files = []\n        next_level_sync_roots = []\n        for text_file_index, text_file in enumerate(text_files):\n            self.log([u\"Text level %d, fragment %d\", level, text_file_index])\n            self.log([u\"  Len:   %d\", len(text_file)])\n            sync_root = sync_roots[text_file_index]\n            if (level > 1) and (len(text_file) == 1):\n                self.log(u\"Level > 1 and only one text fragment => return trivial tree\")\n                self._append_trivial_tree(text_file, sync_root)\n            elif (level > 1) and (sync_root.value.begin == sync_root.value.end):\n                self.log(u\"Level > 1 and parent has begin == end => return trivial tree\")\n                self._append_trivial_tree(text_file, sync_root)\n            else:\n                self.log(u\"Level == 1 or more than one text fragment with non-zero parent => compute tree\")\n                if not sync_root.is_empty:\n                    begin = sync_root.value.begin\n                    end = sync_root.value.end\n                    self.log([u\"  Setting begin: %.3f\", begin])\n                    self.log([u\"  Setting end:   %.3f\", end])\n                    audio_file_mfcc.set_head_middle_tail(head_length=begin, middle_length=(end - begin))\n                else:\n                    self.log(u\"  No begin or end to set\")\n                self._execute_inner(\n                    audio_file_mfcc,\n                    text_file,\n                    sync_root=sync_root,\n                    force_aba_auto=force_aba_auto,\n                    log=False,\n                    leaf_level=(level == 3)\n                )\n            # store next level roots\n            next_level_text_files.extend(text_file.children_not_empty)\n            # we added head and tail, we must not pass them to the next level\n            next_level_sync_roots.extend(sync_root.children[1:-1])\n        self._clear_cache_synthesizer()\n        return (next_level_text_files, next_level_sync_roots)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_inner(self, audio_file_mfcc, text_file, sync_root=None, force_aba_auto=False, log=True, leaf_level=False):\n        self._step_begin(u\"synthesize text\", log=log)\n        synt_handler, synt_path, synt_anchors, synt_format = self._synthesize(text_file)\n        self._step_end(log=log)\n\n        self._step_begin(u\"extract MFCC synt wave\", log=log)\n        synt_wave_mfcc = self._extract_mfcc(\n            file_path=synt_path,\n            file_format=synt_format,\n        )\n        gf.delete_file(synt_handler, synt_path)\n        self._step_end(log=log)\n\n        self._step_begin(u\"align waves\", log=log)\n        indices = self._align_waves(audio_file_mfcc, synt_wave_mfcc, synt_anchors)\n        self._step_end(log=log)\n\n        self._step_begin(u\"adjust boundaries\", log=log)\n        self._adjust_boundaries(indices, text_file, audio_file_mfcc, sync_root, force_aba_auto, leaf_level)\n        self._step_end(log=log)", "response": "Execute the inner method of the actual MFCC computation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_audio_file(self):\n        self._step_begin(u\"load audio file\")\n        # NOTE file_format=None forces conversion to\n        #      PCM16 mono WAVE with default sample rate\n        audio_file = AudioFile(\n            file_path=self.task.audio_file_path_absolute,\n            file_format=None,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        audio_file.read_samples_from_file()\n        self._step_end()\n        return audio_file", "response": "Load audio file into memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears the audio from memory.", "response": "def _clear_audio_file(self, audio_file):\n        \"\"\"\n        Clear audio from memory.\n\n        :param audio_file: the object to clear\n        :type  audio_file: :class:`~aeneas.audiofile.AudioFile`\n        \"\"\"\n        self._step_begin(u\"clear audio file\")\n        audio_file.clear_data()\n        audio_file = None\n        self._step_end()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the MFCCs from the given audio file.", "response": "def _extract_mfcc(self, file_path=None, file_format=None, audio_file=None):\n        \"\"\"\n        Extract the MFCCs from the given audio file.\n\n        :rtype: :class:`~aeneas.audiofilemfcc.AudioFileMFCC`\n        \"\"\"\n        audio_file_mfcc = AudioFileMFCC(\n            file_path=file_path,\n            file_format=file_format,\n            audio_file=audio_file,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        if self.rconf.mmn:\n            self.log(u\"Running VAD inside _extract_mfcc...\")\n            audio_file_mfcc.run_vad(\n                log_energy_threshold=self.rconf[RuntimeConfiguration.MFCC_MASK_LOG_ENERGY_THRESHOLD],\n                min_nonspeech_length=self.rconf[RuntimeConfiguration.MFCC_MASK_MIN_NONSPEECH_LENGTH],\n                extend_before=self.rconf[RuntimeConfiguration.MFCC_MASK_EXTEND_SPEECH_INTERVAL_BEFORE],\n                extend_after=self.rconf[RuntimeConfiguration.MFCC_MASK_EXTEND_SPEECH_INTERVAL_AFTER]\n            )\n            self.log(u\"Running VAD inside _extract_mfcc... done\")\n        return audio_file_mfcc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the audio file head or tail, by either reading the explicit values from the Task configuration, or using SD to determine them. This function returns the lengths, in seconds, of the (head, process, tail). :rtype: tuple (float, float, float)", "response": "def _compute_head_process_tail(self, audio_file_mfcc):\n        \"\"\"\n        Set the audio file head or tail,\n        by either reading the explicit values\n        from the Task configuration,\n        or using SD to determine them.\n\n        This function returns the lengths, in seconds,\n        of the (head, process, tail).\n\n        :rtype: tuple (float, float, float)\n        \"\"\"\n        head_length = self.task.configuration[\"i_a_head\"]\n        process_length = self.task.configuration[\"i_a_process\"]\n        tail_length = self.task.configuration[\"i_a_tail\"]\n        head_max = self.task.configuration[\"i_a_head_max\"]\n        head_min = self.task.configuration[\"i_a_head_min\"]\n        tail_max = self.task.configuration[\"i_a_tail_max\"]\n        tail_min = self.task.configuration[\"i_a_tail_min\"]\n        if (\n            (head_length is not None) or\n            (process_length is not None) or\n            (tail_length is not None)\n        ):\n            self.log(u\"Setting explicit head process tail\")\n        else:\n            self.log(u\"Detecting head tail...\")\n            sd = SD(audio_file_mfcc, self.task.text_file, rconf=self.rconf, logger=self.logger)\n            head_length = TimeValue(\"0.000\")\n            process_length = None\n            tail_length = TimeValue(\"0.000\")\n            if (head_min is not None) or (head_max is not None):\n                self.log(u\"Detecting HEAD...\")\n                head_length = sd.detect_head(head_min, head_max)\n                self.log([u\"Detected HEAD: %.3f\", head_length])\n                self.log(u\"Detecting HEAD... done\")\n            if (tail_min is not None) or (tail_max is not None):\n                self.log(u\"Detecting TAIL...\")\n                tail_length = sd.detect_tail(tail_min, tail_max)\n                self.log([u\"Detected TAIL: %.3f\", tail_length])\n                self.log(u\"Detecting TAIL... done\")\n            self.log(u\"Detecting head tail... done\")\n        self.log([u\"Head:    %s\", gf.safe_float(head_length, None)])\n        self.log([u\"Process: %s\", gf.safe_float(process_length, None)])\n        self.log([u\"Tail:    %s\", gf.safe_float(tail_length, None)])\n        return (head_length, process_length, tail_length)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_synthesizer(self):\n        self.log(u\"Setting synthesizer...\")\n        self.synthesizer = Synthesizer(rconf=self.rconf, logger=self.logger)\n        self.log(u\"Setting synthesizer... done\")", "response": "Create synthesizer and set it as self. synthesizer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing the cache of the synthesizer", "response": "def _clear_cache_synthesizer(self):\n        \"\"\" Clear the cache of the synthesizer \"\"\"\n        self.log(u\"Clearing synthesizer...\")\n        self.synthesizer.clear_cache()\n        self.log(u\"Clearing synthesizer... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _synthesize(self, text_file):\n        handler, path = gf.tmp_file(suffix=u\".wav\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n        result = self.synthesizer.synthesize(text_file, path)\n        return (handler, path, result[0], self.synthesizer.output_audio_format)", "response": "Synthesize text into a WAVE file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naligning two AudioFileMFCC objects and return a list of boundary indices.", "response": "def _align_waves(self, real_wave_mfcc, synt_wave_mfcc, synt_anchors):\n        \"\"\"\n        Align two AudioFileMFCC objects,\n        representing WAVE files.\n\n        Return a list of boundary indices.\n        \"\"\"\n        self.log(u\"Creating DTWAligner...\")\n        aligner = DTWAligner(\n            real_wave_mfcc,\n            synt_wave_mfcc,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        self.log(u\"Creating DTWAligner... done\")\n        self.log(u\"Computing boundary indices...\")\n        boundary_indices = aligner.compute_boundaries(synt_anchors)\n        self.log(u\"Computing boundary indices... done\")\n        return boundary_indices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadjusting the boundaries of the time map for the given text file.", "response": "def _adjust_boundaries(self, boundary_indices, text_file, real_wave_mfcc, sync_root, force_aba_auto=False, leaf_level=False):\n        \"\"\"\n        Adjust boundaries as requested by the user.\n\n        Return the computed time map, that is,\n        a list of pairs ``[start_time, end_time]``,\n        of length equal to number of fragments + 2,\n        where the two extra elements are for\n        the HEAD (first) and TAIL (last).\n        \"\"\"\n        # boundary_indices contains the boundary indices in the all_mfcc of real_wave_mfcc\n        # starting with the (head-1st fragment) and ending with (-1th fragment-tail)\n        aba_parameters = self.task.configuration.aba_parameters()\n        if force_aba_auto:\n            self.log(u\"Forced running algorithm: 'auto'\")\n            aba_parameters[\"algorithm\"] = (AdjustBoundaryAlgorithm.AUTO, [])\n            # note that the other aba settings (nonspeech and nozero)\n            # remain as specified by the user\n        self.log([u\"ABA parameters: %s\", aba_parameters])\n        aba = AdjustBoundaryAlgorithm(rconf=self.rconf, logger=self.logger)\n        aba.adjust(\n            aba_parameters=aba_parameters,\n            real_wave_mfcc=real_wave_mfcc,\n            boundary_indices=boundary_indices,\n            text_file=text_file,\n            allow_arbitrary_shift=leaf_level\n        )\n        aba.append_fragment_list_to_sync_root(sync_root=sync_root)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends trivial tree to the sync_root.", "response": "def _append_trivial_tree(self, text_file, sync_root):\n        \"\"\"\n        Append trivial tree, made by one HEAD,\n        one sync map fragment for each element of ``text_file``,\n        and one TAIL.\n\n        This function is called if either ``text_file`` has only one element,\n        or if ``sync_root.value`` is an interval with zero length\n        (i.e., ``sync_root.value.begin == sync_root.value.end``).\n        \"\"\"\n        interval = sync_root.value\n        #\n        # NOTE the following is correct, but it is a bit obscure\n        # time_values = [interval.begin] * (1 + len(text_file)) + [interval.end] * 2\n        #\n        if len(text_file) == 1:\n            time_values = [interval.begin, interval.begin, interval.end, interval.end]\n        else:\n            # interval.begin == interval.end\n            time_values = [interval.begin] * (3 + len(text_file))\n        aba = AdjustBoundaryAlgorithm(rconf=self.rconf, logger=self.logger)\n        aba.intervals_to_fragment_list(\n            text_file=text_file,\n            time_values=time_values\n        )\n        aba.append_fragment_list_to_sync_root(sync_root=sync_root)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_sync_map(self, sync_root):\n        sync_map = SyncMap(tree=sync_root, rconf=self.rconf, logger=self.logger)\n        if self.rconf.safety_checks:\n            self.log(u\"Running sanity check on computed sync map...\")\n            if not sync_map.leaves_are_consistent:\n                self._step_failure(ValueError(u\"The computed sync map contains inconsistent fragments\"))\n            self.log(u\"Running sanity check on computed sync map... passed\")\n        else:\n            self.log(u\"Not running sanity check on computed sync map\")\n        self.task.sync_map = sync_map", "response": "Create the SyncMap object for the Task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detect_interval(\n            self,\n            min_head_length=None,\n            max_head_length=None,\n            min_tail_length=None,\n            max_tail_length=None\n    ):\n        \"\"\"\n        Detect the interval of the audio file\n        containing the fragments in the text file.\n\n        Return the audio interval as a tuple of two\n        :class:`~aeneas.exacttiming.TimeValue` objects,\n        representing the begin and end time, in seconds,\n        with respect to the full wave duration.\n\n        If one of the parameters is ``None``, the default value\n        (``0.0`` for min, ``10.0`` for max) will be used.\n\n        :param min_head_length: estimated minimum head length\n        :type  min_head_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param max_head_length: estimated maximum head length\n        :type  max_head_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param min_tail_length: estimated minimum tail length\n        :type  min_tail_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param max_tail_length: estimated maximum tail length\n        :type  max_tail_length: :class:`~aeneas.exacttiming.TimeValue`\n        :rtype: (:class:`~aeneas.exacttiming.TimeValue`, :class:`~aeneas.exacttiming.TimeValue`)\n        :raises: TypeError: if one of the parameters is not ``None`` or a number\n        :raises: ValueError: if one of the parameters is negative\n        \"\"\"\n        head = self.detect_head(min_head_length, max_head_length)\n        tail = self.detect_tail(min_tail_length, max_tail_length)\n        begin = head\n        end = self.real_wave_mfcc.audio_length - tail\n        self.log([u\"Audio length: %.3f\", self.real_wave_mfcc.audio_length])\n        self.log([u\"Head length:  %.3f\", head])\n        self.log([u\"Tail length:  %.3f\", tail])\n        self.log([u\"Begin:        %.3f\", begin])\n        self.log([u\"End:          %.3f\", end])\n        if (begin >= TimeValue(\"0.000\")) and (end > begin):\n            self.log([u\"Returning %.3f %.3f\", begin, end])\n            return (begin, end)\n        self.log(u\"Returning (0.000, 0.000)\")\n        return (TimeValue(\"0.000\"), TimeValue(\"0.000\"))", "response": "Detect the audio interval of the audio file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_head(self, min_head_length=None, max_head_length=None):\n        return self._detect(min_head_length, max_head_length, tail=False)", "response": "Detect the audio head returning its duration in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects the audio tail returning its duration in seconds.", "response": "def detect_tail(self, min_tail_length=None, max_tail_length=None):\n        \"\"\"\n        Detect the audio tail, returning its duration, in seconds.\n\n        :param min_tail_length: estimated minimum tail length\n        :type  min_tail_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param max_tail_length: estimated maximum tail length\n        :type  max_tail_length: :class:`~aeneas.exacttiming.TimeValue`\n        :rtype: :class:`~aeneas.exacttiming.TimeValue`\n        :raises: TypeError: if one of the parameters is not ``None`` or a number\n        :raises: ValueError: if one of the parameters is negative\n        \"\"\"\n        return self._detect(min_tail_length, max_tail_length, tail=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _detect(self, min_length, max_length, tail=False):\n        def _sanitize(value, default, name):\n            if value is None:\n                value = default\n            try:\n                value = TimeValue(value)\n            except (TypeError, ValueError, InvalidOperation) as exc:\n                self.log_exc(u\"The value of %s is not a number\" % (name), exc, True, TypeError)\n            if value < 0:\n                self.log_exc(u\"The value of %s is negative\" % (name), None, True, ValueError)\n            return value\n\n        min_length = _sanitize(min_length, self.MIN_LENGTH, \"min_length\")\n        max_length = _sanitize(max_length, self.MAX_LENGTH, \"max_length\")\n        mws = self.rconf.mws\n        min_length_frames = int(min_length / mws)\n        max_length_frames = int(max_length / mws)\n        self.log([u\"MFCC window shift s:     %.3f\", mws])\n        self.log([u\"Min start length s:      %.3f\", min_length])\n        self.log([u\"Min start length frames: %d\", min_length_frames])\n        self.log([u\"Max start length s:      %.3f\", max_length])\n        self.log([u\"Max start length frames: %d\", max_length_frames])\n        self.log([u\"Tail?:                   %s\", str(tail)])\n\n        self.log(u\"Synthesizing query...\")\n        synt_duration = max_length * self.QUERY_FACTOR\n        self.log([u\"Synthesizing at least %.3f seconds\", synt_duration])\n        tmp_handler, tmp_file_path = gf.tmp_file(suffix=u\".wav\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n        synt = Synthesizer(rconf=self.rconf, logger=self.logger)\n        anchors, total_time, synthesized_chars = synt.synthesize(\n            self.text_file,\n            tmp_file_path,\n            quit_after=synt_duration,\n            backwards=tail\n        )\n        self.log(u\"Synthesizing query... done\")\n\n        self.log(u\"Extracting MFCCs for query...\")\n        query_mfcc = AudioFileMFCC(tmp_file_path, rconf=self.rconf, logger=self.logger)\n        self.log(u\"Extracting MFCCs for query... done\")\n\n        self.log(u\"Cleaning up...\")\n        gf.delete_file(tmp_handler, tmp_file_path)\n        self.log(u\"Cleaning up... done\")\n\n        search_window = max_length * self.AUDIO_FACTOR\n        search_window_end = min(int(search_window / mws), self.real_wave_mfcc.all_length)\n        self.log([u\"Query MFCC length (frames): %d\", query_mfcc.all_length])\n        self.log([u\"Real MFCC length (frames):  %d\", self.real_wave_mfcc.all_length])\n        self.log([u\"Search window end (s):      %.3f\", search_window])\n        self.log([u\"Search window end (frames): %d\", search_window_end])\n\n        if tail:\n            self.log(u\"Tail => reversing real_wave_mfcc and query_mfcc\")\n            self.real_wave_mfcc.reverse()\n            query_mfcc.reverse()\n\n        # NOTE: VAD will be run here, if not done before\n        speech_intervals = self.real_wave_mfcc.intervals(speech=True, time=False)\n        if len(speech_intervals) < 1:\n            self.log(u\"No speech intervals, hence no start found\")\n            if tail:\n                self.real_wave_mfcc.reverse()\n            return TimeValue(\"0.000\")\n\n        # generate a list of begin indices\n        search_end = None\n        candidates_begin = []\n        for interval in speech_intervals:\n            if (interval[0] >= min_length_frames) and (interval[0] <= max_length_frames):\n                candidates_begin.append(interval[0])\n            search_end = interval[1]\n            if search_end >= search_window_end:\n                break\n\n        # for each begin index, compute the acm cost\n        # to match the query\n        # note that we take the min over the last column of the acm\n        # meaning that we allow to match the entire query wave\n        # against a portion of the real wave\n        candidates = []\n        for candidate_begin in candidates_begin:\n            self.log([u\"Candidate interval starting at %d == %.3f\", candidate_begin, candidate_begin * mws])\n            try:\n                rwm = AudioFileMFCC(\n                    mfcc_matrix=self.real_wave_mfcc.all_mfcc[:, candidate_begin:search_end],\n                    rconf=self.rconf,\n                    logger=self.logger\n                )\n                dtw = DTWAligner(\n                    real_wave_mfcc=rwm,\n                    synt_wave_mfcc=query_mfcc,\n                    rconf=self.rconf,\n                    logger=self.logger\n                )\n                acm = dtw.compute_accumulated_cost_matrix()\n                last_column = acm[:, -1]\n                min_value = numpy.min(last_column)\n                min_index = numpy.argmin(last_column)\n                self.log([u\"Candidate interval: %d %d == %.3f %.3f\", candidate_begin, search_end, candidate_begin * mws, search_end * mws])\n                self.log([u\"  Min value: %.6f\", min_value])\n                self.log([u\"  Min index: %d == %.3f\", min_index, min_index * mws])\n                candidates.append((min_value, candidate_begin, min_index))\n            except Exception as exc:\n                self.log_exc(u\"An unexpected error occurred while running _detect\", exc, False, None)\n\n        # reverse again the real wave\n        if tail:\n            self.log(u\"Tail => reversing real_wave_mfcc again\")\n            self.real_wave_mfcc.reverse()\n\n        # return\n        if len(candidates) < 1:\n            self.log(u\"No candidates found\")\n            return TimeValue(\"0.000\")\n        self.log(u\"Candidates:\")\n        for candidate in candidates:\n            self.log([u\"  Value: %.6f Begin Time: %.3f Min Index: %d\", candidate[0], candidate[1] * mws, candidate[2]])\n        best = sorted(candidates)[0][1]\n        self.log([u\"Best candidate: %d == %.3f\", best, best * mws])\n        return best * mws", "response": "Detect the head or tail of a real wave MFCC and query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _synthesize_multiple_c_extension(self, text_file, output_file_path, quit_after=None, backwards=False):\n        self.log(u\"Synthesizing using C extension...\")\n\n        # convert parameters from Python values to C values\n        try:\n            c_quit_after = float(quit_after)\n        except TypeError:\n            c_quit_after = 0.0\n        c_backwards = 0\n        if backwards:\n            c_backwards = 1\n        self.log([u\"output_file_path: %s\", output_file_path])\n        self.log([u\"c_quit_after:     %.3f\", c_quit_after])\n        self.log([u\"c_backwards:      %d\", c_backwards])\n        self.log(u\"Preparing u_text...\")\n        u_text = []\n        fragments = text_file.fragments\n        for fragment in fragments:\n            f_lang = fragment.language\n            f_text = fragment.filtered_text\n            if f_lang is None:\n                f_lang = self.DEFAULT_LANGUAGE\n            f_voice_code = self._language_to_voice_code(f_lang)\n            if f_text is None:\n                f_text = u\"\"\n            u_text.append((f_voice_code, f_text))\n        self.log(u\"Preparing u_text... done\")\n\n        # call C extension\n        sr = None\n        sf = None\n        intervals = None\n        if self.rconf[RuntimeConfiguration.CEW_SUBPROCESS_ENABLED]:\n            self.log(u\"Using cewsubprocess to call aeneas.cew\")\n            try:\n                self.log(u\"Importing aeneas.cewsubprocess...\")\n                from aeneas.cewsubprocess import CEWSubprocess\n                self.log(u\"Importing aeneas.cewsubprocess... done\")\n                self.log(u\"Calling aeneas.cewsubprocess...\")\n                cewsub = CEWSubprocess(rconf=self.rconf, logger=self.logger)\n                sr, sf, intervals = cewsub.synthesize_multiple(output_file_path, c_quit_after, c_backwards, u_text)\n                self.log(u\"Calling aeneas.cewsubprocess... done\")\n            except Exception as exc:\n                self.log_exc(u\"An unexpected error occurred while running cewsubprocess\", exc, False, None)\n                # NOTE not critical, try calling aeneas.cew directly\n                # COMMENTED return (False, None)\n\n        if sr is None:\n            self.log(u\"Preparing c_text...\")\n            if gf.PY2:\n                # Python 2 => pass byte strings\n                c_text = [(gf.safe_bytes(t[0]), gf.safe_bytes(t[1])) for t in u_text]\n            else:\n                # Python 3 => pass Unicode strings\n                c_text = [(gf.safe_unicode(t[0]), gf.safe_unicode(t[1])) for t in u_text]\n            self.log(u\"Preparing c_text... done\")\n\n            self.log(u\"Calling aeneas.cew directly\")\n            try:\n                self.log(u\"Importing aeneas.cew...\")\n                import aeneas.cew.cew\n                self.log(u\"Importing aeneas.cew... done\")\n                self.log(u\"Calling aeneas.cew...\")\n                sr, sf, intervals = aeneas.cew.cew.synthesize_multiple(\n                    output_file_path,\n                    c_quit_after,\n                    c_backwards,\n                    c_text\n                )\n                self.log(u\"Calling aeneas.cew... done\")\n            except Exception as exc:\n                self.log_exc(u\"An unexpected error occurred while running cew\", exc, False, None)\n                return (False, None)\n\n        self.log([u\"sr: %d\", sr])\n        self.log([u\"sf: %d\", sf])\n\n        # create output\n        anchors = []\n        current_time = TimeValue(\"0.000\")\n        num_chars = 0\n        if backwards:\n            fragments = fragments[::-1]\n        for i in range(sf):\n            # get the correct fragment\n            fragment = fragments[i]\n            # store for later output\n            anchors.append([\n                TimeValue(intervals[i][0]),\n                fragment.identifier,\n                fragment.filtered_text\n            ])\n            # increase the character counter\n            num_chars += fragment.characters\n            # update current_time\n            current_time = TimeValue(intervals[i][1])\n\n        # return output\n        # NOTE anchors do not make sense if backwards == True\n        self.log([u\"Returning %d time anchors\", len(anchors)])\n        self.log([u\"Current time %.3f\", current_time])\n        self.log([u\"Synthesized %d characters\", num_chars])\n        self.log(u\"Synthesizing using C extension... done\")\n        return (True, (anchors, current_time, num_chars))", "response": "Synthesize multiple text fragments using the C extension."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef perform_command(self):\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        source_url = self.actual_arguments[0]\n        output_file_path = self.actual_arguments[1]\n\n        download = not self.has_option(\"--list\")\n        # largest_audio = True by default or if explicitly given\n        if self.has_option(\"--largest-audio\"):\n            largest_audio = True\n        else:\n            largest_audio = not self.has_option(\"--smallest-audio\")\n        download_format = self.has_option_with_value(\"--format\")\n\n        try:\n            if download:\n                self.print_info(u\"Downloading audio stream from '%s' ...\" % source_url)\n                downloader = Downloader(logger=self.logger)\n                result = downloader.audio_from_youtube(\n                    source_url,\n                    download=True,\n                    output_file_path=output_file_path,\n                    download_format=download_format,\n                    largest_audio=largest_audio,\n                )\n                self.print_info(u\"Downloading audio stream from '%s' ... done\" % source_url)\n                self.print_success(u\"Downloaded file '%s'\" % result)\n            else:\n                self.print_info(u\"Downloading stream info from '%s' ...\" % source_url)\n                downloader = Downloader(logger=self.logger)\n                result = downloader.audio_from_youtube(\n                    source_url,\n                    download=False\n                )\n                self.print_info(u\"Downloading stream info from '%s' ... done\" % source_url)\n                msg = []\n                msg.append(u\"%s\\t%s\\t%s\\t%s\" % (\"Format\", \"Extension\", \"Bitrate\", \"Size\"))\n                for r in result:\n                    filesize = gf.human_readable_number(r[\"filesize\"])\n                    msg.append(u\"%s\\t%s\\t%s\\t%s\" % (r[\"format\"], r[\"ext\"], r[\"abr\"], filesize))\n                self.print_generic(u\"Available audio streams:\")\n                self.print_generic(u\"\\n\".join(msg))\n            return self.NO_ERROR_EXIT_CODE\n        except ImportError:\n            self.print_no_dependency_error()\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while downloading audio from YouTube:\")\n            self.print_error(u\"%s\" % exc)\n\n        return self.ERROR_EXIT_CODE", "response": "Perform command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect the TTS engine to use by looking at the rconf object.", "response": "def _select_tts_engine(self):\n        \"\"\"\n        Select the TTS engine to be used by looking at the rconf object.\n        \"\"\"\n        self.log(u\"Selecting TTS engine...\")\n        requested_tts_engine = self.rconf[RuntimeConfiguration.TTS]\n        if requested_tts_engine == self.CUSTOM:\n            self.log(u\"TTS engine: custom\")\n            tts_path = self.rconf[RuntimeConfiguration.TTS_PATH]\n            if tts_path is None:\n                self.log_exc(u\"You must specify a value for tts_path\", None, True, ValueError)\n            if not gf.file_can_be_read(tts_path):\n                self.log_exc(u\"Cannot read tts_path\", None, True, OSError)\n            try:\n                import imp\n                self.log([u\"Loading CustomTTSWrapper module from '%s'...\", tts_path])\n                imp.load_source(\"CustomTTSWrapperModule\", tts_path)\n                self.log([u\"Loading CustomTTSWrapper module from '%s'... done\", tts_path])\n                self.log(u\"Importing CustomTTSWrapper...\")\n                from CustomTTSWrapperModule import CustomTTSWrapper\n                self.log(u\"Importing CustomTTSWrapper... done\")\n                self.log(u\"Creating CustomTTSWrapper instance...\")\n                self.tts_engine = CustomTTSWrapper(rconf=self.rconf, logger=self.logger)\n                self.log(u\"Creating CustomTTSWrapper instance... done\")\n            except Exception as exc:\n                self.log_exc(u\"Unable to load custom TTS wrapper\", exc, True, OSError)\n        elif requested_tts_engine == self.AWS:\n            try:\n                import boto3\n            except ImportError as exc:\n                self.log_exc(u\"Unable to import boto3 for AWS Polly TTS API wrapper\", exc, True, ImportError)\n            self.log(u\"TTS engine: AWS Polly TTS API\")\n            self.tts_engine = AWSTTSWrapper(rconf=self.rconf, logger=self.logger)\n        elif requested_tts_engine == self.NUANCE:\n            try:\n                import requests\n            except ImportError as exc:\n                self.log_exc(u\"Unable to import requests for Nuance TTS API wrapper\", exc, True, ImportError)\n            self.log(u\"TTS engine: Nuance TTS API\")\n            self.tts_engine = NuanceTTSWrapper(rconf=self.rconf, logger=self.logger)\n        elif requested_tts_engine == self.ESPEAKNG:\n            self.log(u\"TTS engine: eSpeak-ng\")\n            self.tts_engine = ESPEAKNGTTSWrapper(rconf=self.rconf, logger=self.logger)\n        elif requested_tts_engine == self.FESTIVAL:\n            self.log(u\"TTS engine: Festival\")\n            self.tts_engine = FESTIVALTTSWrapper(rconf=self.rconf, logger=self.logger)\n        elif requested_tts_engine == self.MACOS:\n            self.log(u\"TTS engine: macOS\")\n            self.tts_engine = MacOSTTSWrapper(rconf=self.rconf, logger=self.logger)\n        else:\n            self.log(u\"TTS engine: eSpeak\")\n            self.tts_engine = ESPEAKTTSWrapper(rconf=self.rconf, logger=self.logger)\n        self.log(u\"Selecting TTS engine... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsynthesizes the given fragment list into a wav file.", "response": "def synthesize(\n            self,\n            text_file,\n            audio_file_path,\n            quit_after=None,\n            backwards=False\n    ):\n        \"\"\"\n        Synthesize the text contained in the given fragment list\n        into a ``wav`` file.\n\n        Return a tuple ``(anchors, total_time, num_chars)``.\n\n        :param text_file: the text file to be synthesized\n        :type  text_file: :class:`~aeneas.textfile.TextFile`\n        :param string audio_file_path: the path to the output audio file\n        :param float quit_after: stop synthesizing as soon as\n                                 reaching this many seconds\n        :param bool backwards: if ``True``, synthesizing from the end of the text file\n        :rtype: tuple\n        :raises: TypeError: if ``text_file`` is ``None`` or not an instance of ``TextFile``\n        :raises: OSError: if ``audio_file_path`` cannot be written\n        :raises: OSError: if ``tts=custom`` in the RuntimeConfiguration and ``tts_path`` cannot be read\n        :raises: ValueError: if the TTS engine has not been set yet\n        \"\"\"\n        if text_file is None:\n            self.log_exc(u\"text_file is None\", None, True, TypeError)\n        if not isinstance(text_file, TextFile):\n            self.log_exc(u\"text_file is not an instance of TextFile\", None, True, TypeError)\n        if not gf.file_can_be_written(audio_file_path):\n            self.log_exc(u\"Audio file path '%s' cannot be written\" % (audio_file_path), None, True, OSError)\n        if self.tts_engine is None:\n            self.log_exc(u\"Cannot select the TTS engine\", None, True, ValueError)\n\n        # synthesize\n        self.log(u\"Synthesizing text...\")\n        result = self.tts_engine.synthesize_multiple(\n            text_file=text_file,\n            output_file_path=audio_file_path,\n            quit_after=quit_after,\n            backwards=backwards\n        )\n        self.log(u\"Synthesizing text... done\")\n\n        # check that the output file has been written\n        if not gf.file_exists(audio_file_path):\n            self.log_exc(u\"Audio file path '%s' cannot be read\" % (audio_file_path), None, True, OSError)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_shell_encoding(cls):\n        is_in_utf8 = True\n        is_out_utf8 = True\n        if sys.stdin.encoding not in [\"UTF-8\", \"UTF8\"]:\n            is_in_utf8 = False\n        if sys.stdout.encoding not in [\"UTF-8\", \"UTF8\"]:\n            is_out_utf8 = False\n        if (is_in_utf8) and (is_out_utf8):\n            gf.print_success(u\"shell encoding OK\")\n        else:\n            gf.print_warning(u\"shell encoding WARNING\")\n            if not is_in_utf8:\n                gf.print_warning(u\"  The default input encoding of your shell is not UTF-8\")\n            if not is_out_utf8:\n                gf.print_warning(u\"  The default output encoding of your shell is not UTF-8\")\n            gf.print_info(u\"  If you plan to use aeneas on the command line,\")\n            if gf.is_posix():\n                gf.print_info(u\"  you might want to 'export PYTHONIOENCODING=UTF-8' in your shell\")\n            else:\n                gf.print_info(u\"  you might want to 'set PYTHONIOENCODING=UTF-8' in your shell\")\n            return True\n        return False", "response": "Check whether sys. stdin and sys. stdout are UTF - 8 encoded."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether ffprobe can be called.", "response": "def check_ffprobe(cls):\n        \"\"\"\n        Check whether ``ffprobe`` can be called.\n\n        Return ``True`` on failure and ``False`` on success.\n\n        :rtype: bool\n        \"\"\"\n        try:\n            from aeneas.ffprobewrapper import FFPROBEWrapper\n            file_path = gf.absolute_path(u\"tools/res/audio.mp3\", __file__)\n            prober = FFPROBEWrapper()\n            properties = prober.read_properties(file_path)\n            gf.print_success(u\"ffprobe        OK\")\n            return False\n        except:\n            pass\n        gf.print_error(u\"ffprobe        ERROR\")\n        gf.print_info(u\"  Please make sure you have ffprobe installed correctly\")\n        gf.print_info(u\"  (usually it is provided by the ffmpeg installer)\")\n        gf.print_info(u\"  and that its path is in your PATH environment variable\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_ffmpeg(cls):\n        try:\n            from aeneas.ffmpegwrapper import FFMPEGWrapper\n            input_file_path = gf.absolute_path(u\"tools/res/audio.mp3\", __file__)\n            handler, output_file_path = gf.tmp_file(suffix=u\".wav\")\n            converter = FFMPEGWrapper()\n            result = converter.convert(input_file_path, output_file_path)\n            gf.delete_file(handler, output_file_path)\n            if result:\n                gf.print_success(u\"ffmpeg         OK\")\n                return False\n        except:\n            pass\n        gf.print_error(u\"ffmpeg         ERROR\")\n        gf.print_info(u\"  Please make sure you have ffmpeg installed correctly\")\n        gf.print_info(u\"  and that its path is in your PATH environment variable\")\n        return True", "response": "Check whether ffmpeg can be called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_espeak(cls):\n        try:\n            from aeneas.textfile import TextFile\n            from aeneas.textfile import TextFragment\n            from aeneas.ttswrappers.espeakttswrapper import ESPEAKTTSWrapper\n            text = u\"From fairest creatures we desire increase,\"\n            text_file = TextFile()\n            text_file.add_fragment(TextFragment(language=u\"eng\", lines=[text], filtered_lines=[text]))\n            handler, output_file_path = gf.tmp_file(suffix=u\".wav\")\n            ESPEAKTTSWrapper().synthesize_multiple(text_file, output_file_path)\n            gf.delete_file(handler, output_file_path)\n            gf.print_success(u\"espeak         OK\")\n            return False\n        except:\n            pass\n        gf.print_error(u\"espeak         ERROR\")\n        gf.print_info(u\"  Please make sure you have espeak installed correctly\")\n        gf.print_info(u\"  and that its path is in your PATH environment variable\")\n        gf.print_info(u\"  You might also want to check that the espeak-data directory\")\n        gf.print_info(u\"  is set up correctly, for example, it has the correct permissions\")\n        return True", "response": "Check whether espeak can be called."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_tools(cls):\n        try:\n            from aeneas.tools.convert_syncmap import ConvertSyncMapCLI\n            # disabling this check, as it requires the optional dependency youtube-dl\n            # COMMENTED from aeneas.tools.download import DownloadCLI\n            from aeneas.tools.execute_job import ExecuteJobCLI\n            from aeneas.tools.execute_task import ExecuteTaskCLI\n            from aeneas.tools.extract_mfcc import ExtractMFCCCLI\n            from aeneas.tools.ffmpeg_wrapper import FFMPEGWrapperCLI\n            from aeneas.tools.ffprobe_wrapper import FFPROBEWrapperCLI\n            # disabling this check, as it requires the optional dependency Pillow\n            # COMMENTED from aeneas.tools.plot_waveform import PlotWaveformCLI\n            from aeneas.tools.read_audio import ReadAudioCLI\n            from aeneas.tools.read_text import ReadTextCLI\n            from aeneas.tools.run_sd import RunSDCLI\n            from aeneas.tools.run_vad import RunVADCLI\n            from aeneas.tools.synthesize_text import SynthesizeTextCLI\n            from aeneas.tools.validate import ValidateCLI\n            gf.print_success(u\"aeneas.tools   OK\")\n            return False\n        except:\n            pass\n        gf.print_error(u\"aeneas.tools   ERROR\")\n        gf.print_info(u\"  Unable to import one or more aeneas.tools\")\n        gf.print_info(u\"  Please check that you installed aeneas properly\")\n        return True", "response": "Check whether aeneas. tools. xls or aeneas. tools. youtube can be imported."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_cdtw(cls):\n        if gf.can_run_c_extension(\"cdtw\"):\n            gf.print_success(u\"aeneas.cdtw    AVAILABLE\")\n            return False\n        gf.print_warning(u\"aeneas.cdtw    NOT AVAILABLE\")\n        gf.print_info(u\"  You can still run aeneas but it will be significantly slower\")\n        gf.print_info(u\"  Please refer to the installation documentation for details\")\n        return True", "response": "Check whether Python C extension cdtw can be imported."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_cmfcc(cls):\n        if gf.can_run_c_extension(\"cmfcc\"):\n            gf.print_success(u\"aeneas.cmfcc   AVAILABLE\")\n            return False\n        gf.print_warning(u\"aeneas.cmfcc   NOT AVAILABLE\")\n        gf.print_info(u\"  You can still run aeneas but it will be significantly slower\")\n        gf.print_info(u\"  Please refer to the installation documentation for details\")\n        return True", "response": "Check whether Python C extension cmfcc can be imported."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether Python C extension cew can be imported.", "response": "def check_cew(cls):\n        \"\"\"\n        Check whether Python C extension ``cew`` can be imported.\n\n        Return ``True`` on failure and ``False`` on success.\n\n        :rtype: bool\n        \"\"\"\n        if gf.can_run_c_extension(\"cew\"):\n            gf.print_success(u\"aeneas.cew     AVAILABLE\")\n            return False\n        gf.print_warning(u\"aeneas.cew     NOT AVAILABLE\")\n        gf.print_info(u\"  You can still run aeneas but it will be a bit slower\")\n        gf.print_info(u\"  Please refer to the installation documentation for details\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_all(cls, tools=True, encoding=True, c_ext=True):\n        # errors are fatal\n        if cls.check_ffprobe():\n            return (True, False, False)\n        if cls.check_ffmpeg():\n            return (True, False, False)\n        if cls.check_espeak():\n            return (True, False, False)\n        if (tools) and (cls.check_tools()):\n            return (True, False, False)\n        # warnings are non-fatal\n        warnings = False\n        c_ext_warnings = False\n        if encoding:\n            warnings = cls.check_shell_encoding()\n        if c_ext:\n            # we do not want lazy evaluation\n            c_ext_warnings = cls.check_cdtw() or c_ext_warnings\n            c_ext_warnings = cls.check_cmfcc() or c_ext_warnings\n            c_ext_warnings = cls.check_cew() or c_ext_warnings\n        # return results\n        return (False, warnings, c_ext_warnings)", "response": "Perform all checks.\n\n        Return a tuple of booleans ``(errors, warnings, c_ext_warnings)``.\n\n        :param bool tools: if ``True``, check aeneas tools\n        :param bool encoding: if ``True``, check shell encoding\n        :param bool c_ext: if ``True``, check Python C extensions\n        :rtype: (bool, bool, bool)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config_string(self):\n        return (gc.CONFIG_STRING_SEPARATOR_SYMBOL).join(\n            [u\"%s%s%s\" % (fn, gc.CONFIG_STRING_ASSIGNMENT_SYMBOL, self.data[fn]) for fn in sorted(self.data.keys()) if self.data[fn] is not None]\n        )", "response": "Builds the storable string corresponding\n            to this configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parameters(cls, sort=True, as_strings=False):\n        def cft(ftype, fdefault):\n            \"\"\" Convert field type and default value to string \"\"\"\n            if ftype is None:\n                return u\"\"\n            if ftype in [TimeValue, Decimal, float]:\n                cftype = u\"float\"\n                cfdefault = u\"%.3f\" % ftype(fdefault) if fdefault is not None else u\"None\"\n            elif ftype == int:\n                cftype = u\"int\"\n                cfdefault = u\"%d\" % ftype(fdefault) if fdefault is not None else u\"None\"\n            elif ftype == bool:\n                cftype = u\"bool\"\n                cfdefault = u\"%s\" % fdefault if fdefault is not None else u\"None\"\n            else:\n                cftype = u\"unknown\"\n                cfdefault = u\"%s\" % fdefault if fdefault is not None else u\"None\"\n            return u\" (%s, %s)\" % (cftype, cfdefault)\n\n        parameters = [(field, fdesc, ftype, fdefault) for (field, (fdefault, ftype, faliases, fdesc)) in cls.FIELDS]\n        if sort:\n            parameters = sorted(parameters)\n        if as_strings:\n            l = max([len(t[0]) for t in parameters])\n            parameters = [u\"%s : %s%s\" % (f.ljust(l), d, cft(t, df)) for (f, d, t, df) in parameters]\n        return parameters", "response": "Return a list of tuples that represent the configuration parameters of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_granularity(self, level):\n        if level in self.MFCC_GRANULARITY_MAP.keys():\n            margin_key, mask_key, length_key, shift_key = self.MFCC_GRANULARITY_MAP[level]\n            self[self.DTW_MARGIN] = self[margin_key]\n            self[self.MFCC_MASK_NONSPEECH] = self[mask_key]\n            self[self.MFCC_WINDOW_LENGTH] = self[length_key]\n            self[self.MFCC_WINDOW_SHIFT] = self[shift_key]", "response": "Set the values for MFCC_WINDOW_LENGTH and MFCC_WINDOW_SHIFT based on the given granularity level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the values for the TTS and TTS_PATH properties of the current object.", "response": "def set_tts(self, level):\n        \"\"\"\n        Set the values for\n        :data:`~aeneas.runtimeconfiguration.RuntimeConfiguration.TTS`\n        and\n        :data:`~aeneas.runtimeconfiguration.RuntimeConfiguration.TTS_PATH`\n        matching the given granularity level.\n\n        Currently supported levels:\n\n        * ``1`` (paragraph)\n        * ``2`` (sentence)\n        * ``3`` (word)\n\n        :param int level: the desired granularity level\n        \"\"\"\n        if level in self.TTS_GRANULARITY_MAP.keys():\n            tts_key, tts_path_key = self.TTS_GRANULARITY_MAP[level]\n            self[self.TTS] = self[tts_key]\n            self[self.TTS_PATH] = self[tts_path_key]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geq_multiple(self, other):\n        if other == TimeValue(\"0.000\"):\n            return self\n        return int(math.ceil(other / self)) * self", "response": "Return the next multiple of this time value greater than or equal to other."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef starts_at(self, time_point):\n        if not isinstance(time_point, TimeValue):\n            raise TypeError(u\"time_point is not an instance of TimeValue\")\n        return self.begin == time_point", "response": "Returns True if this interval starts at the given time point."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if this interval ends at the given time point.", "response": "def ends_at(self, time_point):\n        \"\"\"\n        Returns ``True`` if this interval ends at the given time point.\n\n        :param time_point: the time point to test\n        :type  time_point: :class:`~aeneas.exacttiming.TimeValue`\n        :raises TypeError: if ``time_point`` is not an instance of ``TimeValue``\n        :rtype: bool\n        \"\"\"\n        if not isinstance(time_point, TimeValue):\n            raise TypeError(u\"time_point is not an instance of TimeValue\")\n        return self.end == time_point"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the time value at the given percent of this interval.", "response": "def percent_value(self, percent):\n        \"\"\"\n        Returns the time value at ``percent`` of this interval.\n\n        :param percent: the percent\n        :type  percent: :class:`~aeneas.exacttiming.Decimal`\n        :raises TypeError: if ``time_point`` is not an instance of ``TimeValue``\n        :rtype: :class:`~aeneas.exacttiming.TimeValue`\n        \"\"\"\n        if not isinstance(percent, Decimal):\n            raise TypeError(u\"percent is not an instance of Decimal\")\n        percent = Decimal(max(min(percent, 100), 0) / 100)\n        return self.begin + self.length * percent"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves this interval by the given offset.", "response": "def offset(self, offset, allow_negative=False, min_begin_value=None, max_end_value=None):\n        \"\"\"\n        Move this interval by the given shift ``offset``.\n\n        The begin and end time points of the translated interval\n        are ensured to be non-negative\n        (i.e., they are maxed with ``0.000``),\n        unless ``allow_negative`` is set to ``True``.\n\n        :param offset: the shift to be applied\n        :type  offset: :class:`~aeneas.exacttiming.TimeValue`\n        :param allow_negative: if ``True``, allow the translated interval to have negative extrema\n        :type  allow_negative: bool\n        :param min_begin_value: if not ``None``, specify the minimum value for the begin of the translated interval\n        :type  min_begin_value: :class:`~aeneas.exacttiming.TimeValue`\n        :param max_begin_value: if not ``None``, specify the maximum value for the end of the translated interval\n        :type  max_begin_value: :class:`~aeneas.exacttiming.TimeValue`\n        :raises TypeError: if ``offset`` is not an instance of ``TimeValue``\n        :rtype: :class:`~aeneas.exacttiming.TimeInterval`\n        \"\"\"\n        if not isinstance(offset, TimeValue):\n            raise TypeError(u\"offset is not an instance of TimeValue\")\n        self.begin += offset\n        self.end += offset\n        if not allow_negative:\n            self.begin = max(self.begin, TimeValue(\"0.000\"))\n            self.end = max(self.end, TimeValue(\"0.000\"))\n        if (min_begin_value is not None) and (max_end_value is not None):\n            self.begin = min(max(self.begin, min_begin_value), max_end_value)\n            self.end = min(self.end, max_end_value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this interval contains the given time point and the inner interval contains the given time point.", "response": "def inner_contains(self, time_point):\n        \"\"\"\n        Returns ``True`` if this interval contains the given time point,\n        excluding its extrema (begin and end).\n\n        :param time_point: the time point to test\n        :type  time_point: :class:`~aeneas.exacttiming.TimeValue`\n        :rtype: bool\n        \"\"\"\n        if not isinstance(time_point, TimeValue):\n            raise TypeError(u\"time_point is not an instance of TimeValue\")\n        return (self.begin < time_point) and (time_point < self.end)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef relative_position_of(self, other):\n        if not isinstance(other, TimeInterval):\n            raise TypeError(u\"other is not an instance of TimeInterval\")\n        if self.has_zero_length:\n            if other.has_zero_length:\n                # TABLE 1\n                if other.begin < self.begin:\n                    return self.RELATIVE_POSITION_PP_L\n                elif other.begin == self.begin:\n                    return self.RELATIVE_POSITION_PP_C\n                else:\n                    # other.begin > self.begin\n                    return self.RELATIVE_POSITION_PP_G\n            else:\n                # TABLE 2\n                if other.end < self.begin:\n                    return self.RELATIVE_POSITION_PI_LL\n                elif other.end == self.begin:\n                    return self.RELATIVE_POSITION_PI_LC\n                elif other.begin < self.begin:\n                    return self.RELATIVE_POSITION_PI_LG\n                elif other.begin == self.begin:\n                    return self.RELATIVE_POSITION_PI_CG\n                else:\n                    # other.begin > self.begin\n                    return self.RELATIVE_POSITION_PI_GG\n        else:\n            if other.has_zero_length:\n                # TABLE 3\n                if other.begin < self.begin:\n                    return self.RELATIVE_POSITION_IP_L\n                elif other.begin == self.begin:\n                    return self.RELATIVE_POSITION_IP_B\n                elif other.begin < self.end:\n                    return self.RELATIVE_POSITION_IP_I\n                elif other.begin == self.end:\n                    return self.RELATIVE_POSITION_IP_E\n                else:\n                    # other.begin > self.end\n                    return self.RELATIVE_POSITION_IP_G\n            else:\n                if other.begin < self.begin:\n                    # TABLE 4\n                    if other.end < self.begin:\n                        return self.RELATIVE_POSITION_II_LL\n                    elif other.end == self.begin:\n                        return self.RELATIVE_POSITION_II_LB\n                    elif other.end < self.end:\n                        return self.RELATIVE_POSITION_II_LI\n                    elif other.end == self.end:\n                        return self.RELATIVE_POSITION_II_LE\n                    else:\n                        # other.end > self.end\n                        return self.RELATIVE_POSITION_II_LG\n                elif other.begin == self.begin:\n                    # TABLE 5\n                    if other.end < self.end:\n                        return self.RELATIVE_POSITION_II_BI\n                    elif other.end == self.end:\n                        return self.RELATIVE_POSITION_II_BE\n                    else:\n                        # other.end > self.end\n                        return self.RELATIVE_POSITION_II_BG\n                elif other.begin < self.end:\n                    # TABLE 6\n                    if other.end < self.end:\n                        return self.RELATIVE_POSITION_II_II\n                    elif other.end == self.end:\n                        return self.RELATIVE_POSITION_II_IE\n                    else:\n                        # other.end > self.end\n                        return self.RELATIVE_POSITION_II_IG\n                elif other.begin == self.end:\n                    # TABLE 7\n                    return self.RELATIVE_POSITION_II_EG\n                else:\n                    # other.begin > self.end\n                    # TABLE 8\n                    return self.RELATIVE_POSITION_II_GG", "response": "Return the position of the given other time interval relative to this time interval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the intersection between this time interval and the given time interval or None if the two intervals do not overlap.", "response": "def intersection(self, other):\n        \"\"\"\n        Return the intersection between this time interval\n        and the given time interval, or\n        ``None`` if the two intervals do not overlap.\n\n        :rtype: :class:`~aeneas.exacttiming.TimeInterval` or ``NoneType``\n        \"\"\"\n        relative_position = self.relative_position_of(other)\n        if relative_position in [\n            self.RELATIVE_POSITION_PP_C,\n            self.RELATIVE_POSITION_PI_LC,\n            self.RELATIVE_POSITION_PI_LG,\n            self.RELATIVE_POSITION_PI_CG,\n            self.RELATIVE_POSITION_IP_B,\n            self.RELATIVE_POSITION_II_LB,\n        ]:\n            return TimeInterval(begin=self.begin, end=self.begin)\n        if relative_position in [\n            self.RELATIVE_POSITION_IP_E,\n            self.RELATIVE_POSITION_II_EG,\n        ]:\n            return TimeInterval(begin=self.end, end=self.end)\n        if relative_position in [\n            self.RELATIVE_POSITION_II_BI,\n            self.RELATIVE_POSITION_II_BE,\n            self.RELATIVE_POSITION_II_II,\n            self.RELATIVE_POSITION_II_IE,\n        ]:\n            return TimeInterval(begin=other.begin, end=other.end)\n        if relative_position in [\n            self.RELATIVE_POSITION_IP_I,\n            self.RELATIVE_POSITION_II_LI,\n            self.RELATIVE_POSITION_II_LE,\n            self.RELATIVE_POSITION_II_LG,\n            self.RELATIVE_POSITION_II_BG,\n            self.RELATIVE_POSITION_II_IG,\n        ]:\n            begin = max(self.begin, other.begin)\n            end = min(self.end, other.end)\n            return TimeInterval(begin=begin, end=end)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if this time interval ends with other and both have non zero length.", "response": "def is_non_zero_before_non_zero(self, other):\n        \"\"\"\n        Return ``True`` if this time interval ends\n        when the given other time interval begins,\n        and both have non zero length.\n\n        :param other: the other interval\n        :type  other: :class:`~aeneas.exacttiming.TimeInterval`\n        :raises TypeError: if ``other`` is not an instance of ``TimeInterval``\n        :rtype: bool\n        \"\"\"\n        return self.is_adjacent_before(other) and (not self.has_zero_length) and (not other.has_zero_length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_adjacent_before(self, other):\n        if not isinstance(other, TimeInterval):\n            raise TypeError(u\"other is not an instance of TimeInterval\")\n        return (self.end == other.begin)", "response": "Return True if this time interval ends when the given other time interval begins."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef perform_command(self):\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        input_file_path = self.actual_arguments[0]\n        output_file_path = self.actual_arguments[1]\n        output_html = self.has_option(u\"--output-html\")\n\n        if not self.check_input_file(input_file_path):\n            return self.ERROR_EXIT_CODE\n        input_sm_format = self.has_option_with_value(u\"--input-format\")\n        if input_sm_format is None:\n            input_sm_format = gf.file_extension(input_file_path)\n        if not self.check_format(input_sm_format):\n            return self.ERROR_EXIT_CODE\n\n        if not self.check_output_file(output_file_path):\n            return self.ERROR_EXIT_CODE\n\n        if output_html:\n            if len(self.actual_arguments) < 3:\n                return self.print_help()\n            audio_file_path = self.actual_arguments[2]\n            if not self.check_input_file(audio_file_path):\n                return self.ERROR_EXIT_CODE\n        else:\n            output_sm_format = self.has_option_with_value(u\"--output-format\")\n            if output_sm_format is None:\n                output_sm_format = gf.file_extension(output_file_path)\n            if not self.check_format(output_sm_format):\n                return self.ERROR_EXIT_CODE\n\n        # TODO add a way to specify a text file for input formats like SMIL\n        #      that do not carry the source text\n        language = self.has_option_with_value(u\"--language\")\n        audio_ref = self.has_option_with_value(u\"--audio-ref\")\n        page_ref = self.has_option_with_value(u\"--page-ref\")\n        parameters = {\n            gc.PPN_SYNCMAP_LANGUAGE: language,\n            gc.PPN_TASK_OS_FILE_SMIL_AUDIO_REF: audio_ref,\n            gc.PPN_TASK_OS_FILE_SMIL_PAGE_REF: page_ref\n        }\n\n        try:\n            self.print_info(u\"Reading sync map in '%s' format from file '%s'\" % (input_sm_format, input_file_path))\n            self.print_info(u\"Reading sync map...\")\n            syncmap = SyncMap(logger=self.logger)\n            syncmap.read(input_sm_format, input_file_path, parameters)\n            self.print_info(u\"Reading sync map... done\")\n            self.print_info(u\"Read %d sync map fragments\" % (len(syncmap)))\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while reading the input sync map:\")\n            self.print_error(u\"%s\" % (exc))\n            return self.ERROR_EXIT_CODE\n\n        if output_html:\n            try:\n                self.print_info(u\"Writing HTML file...\")\n                syncmap.output_html_for_tuning(audio_file_path, output_file_path, parameters)\n                self.print_info(u\"Writing HTML file... done\")\n                self.print_success(u\"Created HTML file '%s'\" % (output_file_path))\n                return self.NO_ERROR_EXIT_CODE\n            except Exception as exc:\n                self.print_error(u\"An unexpected error occurred while writing the output HTML file:\")\n                self.print_error(u\"%s\" % (exc))\n        else:\n            try:\n                self.print_info(u\"Writing sync map...\")\n                syncmap.write(output_sm_format, output_file_path, parameters)\n                self.print_info(u\"Writing sync map... done\")\n                self.print_success(u\"Created '%s' sync map file '%s'\" % (output_sm_format, output_file_path))\n                return self.NO_ERROR_EXIT_CODE\n            except Exception as exc:\n                self.print_error(u\"An unexpected error occurred while writing the output sync map:\")\n                self.print_error(u\"%s\" % (exc))\n\n        return self.ERROR_EXIT_CODE", "response": "Perform command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the given sync map format is allowed.", "response": "def check_format(self, sm_format):\n        \"\"\"\n        Return ``True`` if the given sync map format is allowed,\n        and ``False`` otherwise.\n\n        :param sm_format: the sync map format to be checked\n        :type  sm_format: Unicode string\n        :rtype: bool\n        \"\"\"\n        if sm_format not in SyncMapFormat.ALLOWED_VALUES:\n            self.print_error(u\"Sync map format '%s' is not allowed\" % (sm_format))\n            self.print_info(u\"Allowed formats:\")\n            self.print_generic(u\" \".join(SyncMapFormat.ALLOWED_VALUES))\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_fragment(cls, syncmap, identifier, lines, begin, end, language=None):\n        syncmap.add_fragment(\n            SyncMapFragment(\n                text_fragment=TextFragment(\n                    identifier=identifier,\n                    lines=lines,\n                    language=language\n                ),\n                begin=begin,\n                end=end\n            )\n        )", "response": "Add a new fragment to the syncmap."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the given input_text and append the extracted fragments to the syncmap.", "response": "def parse(self, input_text, syncmap):\n        \"\"\"\n        Parse the given ``input_text`` and\n        append the extracted fragments to ``syncmap``.\n\n        :param input_text: the input text as a Unicode string (read from file)\n        :type input_text: string\n        :param syncmap: the syncmap to append to\n        :type syncmap: :class:`~aeneas.syncmap.SyncMap`\n        \"\"\"\n        self.log_exc(u\"%s is abstract and cannot be called directly\" % (self.TAG), None, True, NotImplementedError)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format(self, syncmap):\n        self.log_exc(u\"%s is abstract and cannot be called directly\" % (self.TAG), None, True, NotImplementedError)", "response": "Format the given syncmap as a Unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef perform_command(self):\n        if len(self.actual_arguments) < 1:\n            return self.print_help()\n\n        if self.has_option([u\"-e\", u\"--examples\"]):\n            return self.print_examples(False)\n\n        if self.has_option(u\"--examples-all\"):\n            return self.print_examples(True)\n\n        if self.has_option([u\"--list-parameters\"]):\n            return self.print_parameters()\n\n        parameter = self.has_option_with_value(u\"--list-values\")\n        if parameter is not None:\n            return self.print_values(parameter)\n        elif self.has_option(u\"--list-values\"):\n            return self.print_values(u\"?\")\n\n        # NOTE list() is needed for Python3, where keys() is not a list!\n        demo = self.has_option(list(self.DEMOS.keys()))\n        demo_parameters = u\"\"\n        download_from_youtube = self.has_option([u\"-y\", u\"--youtube\"])\n        largest_audio = self.has_option(u\"--largest-audio\")\n        keep_audio = self.has_option(u\"--keep-audio\")\n        output_html = self.has_option(u\"--output-html\")\n        validate = not self.has_option(u\"--skip-validator\")\n        print_faster_rate = self.has_option(u\"--faster-rate\")\n        print_rates = self.has_option(u\"--rate\")\n        print_zero = self.has_option(u\"--zero\")\n        presets_word = self.has_option(u\"--presets-word\")\n\n        if demo:\n            validate = False\n            for key in self.DEMOS:\n                if self.has_option(key):\n                    demo_parameters = self.DEMOS[key]\n                    audio_file_path = demo_parameters[u\"audio\"]\n                    text_file_path = demo_parameters[u\"text\"]\n                    config_string = demo_parameters[u\"config\"]\n                    sync_map_file_path = demo_parameters[u\"syncmap\"]\n                    # TODO allow injecting rconf options directly from DEMOS options field\n                    if key == u\"--example-cewsubprocess\":\n                        self.rconf[RuntimeConfiguration.CEW_SUBPROCESS_ENABLED] = True\n                    elif key == u\"--example-ctw-espeak\":\n                        self.rconf[RuntimeConfiguration.TTS] = \"custom\"\n                        self.rconf[RuntimeConfiguration.TTS_PATH] = self.CTW_ESPEAK\n                    elif key == u\"--example-ctw-speect\":\n                        self.rconf[RuntimeConfiguration.TTS] = \"custom\"\n                        self.rconf[RuntimeConfiguration.TTS_PATH] = self.CTW_SPEECT\n                    elif key == u\"--example-festival\":\n                        self.rconf[RuntimeConfiguration.TTS] = \"festival\"\n                    elif key == u\"--example-mws\":\n                        self.rconf[RuntimeConfiguration.MFCC_WINDOW_LENGTH] = \"1.500\"\n                        self.rconf[RuntimeConfiguration.MFCC_WINDOW_SHIFT] = \"0.500\"\n                    elif key == u\"--example-multilevel-tts\":\n                        self.rconf[RuntimeConfiguration.TTS_L1] = \"festival\"\n                        self.rconf[RuntimeConfiguration.TTS_L2] = \"festival\"\n                        self.rconf[RuntimeConfiguration.TTS_L3] = \"espeak\"\n                    elif key == u\"--example-words-festival-cache\":\n                        self.rconf[RuntimeConfiguration.TTS] = \"festival\"\n                        self.rconf[RuntimeConfiguration.TTS_CACHE] = True\n                    elif key == u\"--example-faster-rate\":\n                        print_faster_rate = True\n                    elif key == u\"--example-no-zero\":\n                        print_zero = True\n                    elif key == u\"--example-py\":\n                        self.rconf[RuntimeConfiguration.C_EXTENSIONS] = False\n                    elif key == u\"--example-rate\":\n                        print_rates = True\n                    elif key == u\"--example-remove-nonspeech-rateaggressive\":\n                        print_rates = True\n                    elif key == u\"--example-youtube\":\n                        download_from_youtube = True\n                    break\n        else:\n            if len(self.actual_arguments) < 4:\n                return self.print_help()\n            audio_file_path = self.actual_arguments[0]\n            text_file_path = self.actual_arguments[1]\n            config_string = self.actual_arguments[2]\n            sync_map_file_path = self.actual_arguments[3]\n\n        if presets_word:\n            self.print_info(u\"Preset for word-level alignment\")\n            self.rconf[RuntimeConfiguration.MFCC_MASK_NONSPEECH] = True\n            self.rconf[RuntimeConfiguration.MFCC_MASK_NONSPEECH_L3] = True\n\n        html_file_path = None\n        if output_html:\n            keep_audio = True\n            html_file_path = sync_map_file_path + u\".html\"\n\n        if download_from_youtube:\n            youtube_url = gf.safe_unicode(audio_file_path)\n\n        if (not download_from_youtube) and (not self.check_input_file(audio_file_path)):\n            return self.ERROR_EXIT_CODE\n        if not self.check_input_file(text_file_path):\n            return self.ERROR_EXIT_CODE\n        if not self.check_output_file(sync_map_file_path):\n            return self.ERROR_EXIT_CODE\n        if (html_file_path is not None) and (not self.check_output_file(html_file_path)):\n            return self.ERROR_EXIT_CODE\n\n        self.check_c_extensions()\n\n        if demo:\n            msg = []\n            msg.append(u\"Running example task with arguments:\")\n            if download_from_youtube:\n                msg.append(u\"  YouTube URL:   %s\" % youtube_url)\n            else:\n                msg.append(u\"  Audio file:    %s\" % audio_file_path)\n            msg.append(u\"  Text file:     %s\" % text_file_path)\n            msg.append(u\"  Config string: %s\" % config_string)\n            msg.append(u\"  Sync map file: %s\" % sync_map_file_path)\n            if len(demo_parameters[u\"options\"]) > 0:\n                msg.append(u\"  Options:       %s\" % demo_parameters[u\"options\"])\n            self.print_info(u\"\\n\".join(msg))\n\n        if validate:\n            self.print_info(u\"Validating config string (specify --skip-validator to bypass)...\")\n            validator = Validator(logger=self.logger)\n            result = validator.check_configuration_string(config_string, is_job=False, external_name=True)\n            if not result.passed:\n                self.print_error(u\"The given config string is not valid:\")\n                self.print_generic(result.pretty_print())\n                return self.ERROR_EXIT_CODE\n            self.print_info(u\"Validating config string... done\")\n\n        if download_from_youtube:\n            try:\n                self.print_info(u\"Downloading audio from '%s' ...\" % youtube_url)\n                downloader = Downloader(logger=self.logger)\n                audio_file_path = downloader.audio_from_youtube(\n                    youtube_url,\n                    download=True,\n                    output_file_path=None,\n                    largest_audio=largest_audio\n                )\n                self.print_info(u\"Downloading audio from '%s' ... done\" % youtube_url)\n            except ImportError:\n                self.print_no_dependency_error()\n                return self.ERROR_EXIT_CODE\n            except Exception as exc:\n                self.print_error(u\"An unexpected error occurred while downloading audio from YouTube:\")\n                self.print_error(u\"%s\" % exc)\n                return self.ERROR_EXIT_CODE\n        else:\n            audio_extension = gf.file_extension(audio_file_path)\n            if audio_extension.lower() not in AudioFile.FILE_EXTENSIONS:\n                self.print_warning(u\"Your audio file path has extension '%s', which is uncommon for an audio file.\" % audio_extension)\n                self.print_warning(u\"Attempting at executing your Task anyway.\")\n                self.print_warning(u\"If it fails, you might have swapped the first two arguments.\")\n                self.print_warning(u\"The audio file path should be the first argument, the text file path the second.\")\n\n        try:\n            self.print_info(u\"Creating task...\")\n            task = Task(config_string, logger=self.logger)\n            task.audio_file_path_absolute = audio_file_path\n            task.text_file_path_absolute = text_file_path\n            task.sync_map_file_path_absolute = sync_map_file_path\n            self.print_info(u\"Creating task... done\")\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while creating the task:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n\n        try:\n            self.print_info(u\"Executing task...\")\n            executor = ExecuteTask(task=task, rconf=self.rconf, logger=self.logger)\n            executor.execute()\n            self.print_info(u\"Executing task... done\")\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while executing the task:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n\n        try:\n            self.print_info(u\"Creating output sync map file...\")\n            path = task.output_sync_map_file()\n            self.print_info(u\"Creating output sync map file... done\")\n            self.print_success(u\"Created file '%s'\" % path)\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while writing the sync map file:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n\n        if output_html:\n            try:\n                parameters = {}\n                parameters[gc.PPN_TASK_OS_FILE_FORMAT] = task.configuration[\"o_format\"]\n                parameters[gc.PPN_TASK_OS_FILE_EAF_AUDIO_REF] = task.configuration[\"o_eaf_audio_ref\"]\n                parameters[gc.PPN_TASK_OS_FILE_SMIL_AUDIO_REF] = task.configuration[\"o_smil_audio_ref\"]\n                parameters[gc.PPN_TASK_OS_FILE_SMIL_PAGE_REF] = task.configuration[\"o_smil_page_ref\"]\n                self.print_info(u\"Creating output HTML file...\")\n                task.sync_map.output_html_for_tuning(audio_file_path, html_file_path, parameters)\n                self.print_info(u\"Creating output HTML file... done\")\n                self.print_success(u\"Created file '%s'\" % html_file_path)\n            except Exception as exc:\n                self.print_error(u\"An unexpected error occurred while writing the HTML file:\")\n                self.print_error(u\"%s\" % exc)\n                return self.ERROR_EXIT_CODE\n\n        if download_from_youtube:\n            if keep_audio:\n                self.print_info(u\"Option --keep-audio set: keeping downloaded file '%s'\" % audio_file_path)\n            else:\n                gf.delete_file(None, audio_file_path)\n\n        if print_zero:\n            zero_duration = [l for l in task.sync_map_leaves(SyncMapFragment.REGULAR) if l.begin == l.end]\n            if len(zero_duration) > 0:\n                self.print_warning(u\"Fragments with zero duration:\")\n                for fragment in zero_duration:\n                    self.print_generic(u\"  %s\" % (fragment.pretty_print))\n\n        if print_rates:\n            self.print_info(u\"Fragments with rates:\")\n            for fragment in task.sync_map_leaves(SyncMapFragment.REGULAR):\n                self.print_generic(u\"  %s\\t%.3f\" % (fragment.pretty_print, fragment.rate or 0.0))\n\n        if print_faster_rate:\n            max_rate = task.configuration[\"aba_rate_value\"]\n            if max_rate is not None:\n                faster = [l for l in task.sync_map_leaves(SyncMapFragment.REGULAR) if l.rate >= max_rate + Decimal(\"0.001\")]\n                if len(faster) > 0:\n                    self.print_warning(u\"Fragments with rate greater than %.3f:\" % max_rate)\n                    for fragment in faster:\n                        self.print_generic(u\"  %s\\t%.3f\" % (fragment.pretty_print, fragment.rate or 0.0))\n\n        return self.NO_ERROR_EXIT_CODE", "response": "Perform the command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_examples(self, full=False):\n        msg = []\n        i = 1\n        for key in sorted(self.DEMOS.keys()):\n            example = self.DEMOS[key]\n            if full or example[\"show\"]:\n                msg.append(u\"Example %d (%s)\" % (i, example[u\"description\"]))\n                msg.append(u\"  $ %s %s\" % (self.invoke, key))\n                msg.append(u\"\")\n                i += 1\n        self.print_generic(u\"\\n\" + u\"\\n\".join(msg) + u\"\\n\")\n        return self.HELP_EXIT_CODE", "response": "Print the examples and exit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the list of values for the given parameter and exit.", "response": "def print_values(self, parameter):\n        \"\"\"\n        Print the list of values for the given parameter and exit.\n\n        If ``parameter`` is invalid, print the list of\n        parameter names that have allowed values.\n\n        :param parameter: the parameter name\n        :type  parameter: Unicode string\n        \"\"\"\n        if parameter in self.VALUES:\n            self.print_info(u\"Available values for parameter '%s':\" % parameter)\n            self.print_generic(u\"\\n\".join(self.VALUES[parameter]))\n            return self.HELP_EXIT_CODE\n        if parameter not in [u\"?\", u\"\"]:\n            self.print_error(u\"Invalid parameter name '%s'\" % parameter)\n        self.print_info(u\"Parameters for which values can be listed:\")\n        self.print_generic(u\"\\n\".join(sorted(self.VALUES.keys())))\n        return self.HELP_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_cew_for_windows():\n    try:\n        # copy espeak_sapi.dll to C:\\Windows\\System32\\espeak.dll\n        espeak_dll_win_path = \"C:\\\\Windows\\\\System32\\\\espeak.dll\"\n        espeak_dll_dst_path = \"aeneas\\\\cew\\\\espeak.dll\"\n        espeak_dll_src_paths = [\n            \"C:\\\\aeneas\\\\eSpeak\\\\espeak_sapi.dll\",\n            \"C:\\\\sync\\\\eSpeak\\\\espeak_sapi.dll\",\n            \"C:\\\\Program Files\\\\eSpeak\\\\espeak_sapi.dll\",\n            \"C:\\\\Program Files (x86)\\\\eSpeak\\\\espeak_sapi.dll\",\n        ]\n        if os.path.exists(espeak_dll_dst_path):\n            print(\"[INFO] Found eSpeak DLL in %s\" % espeak_dll_dst_path)\n        else:\n            found = False\n            copied = False\n            for src_path in espeak_dll_src_paths:\n                if os.path.exists(src_path):\n                    found = True\n                    print(\"[INFO] Copying eSpeak DLL from %s into %s\" % (src_path, espeak_dll_dst_path))\n                    try:\n                        shutil.copyfile(src_path, espeak_dll_dst_path)\n                        copied = True\n                        print(\"[INFO] Copied eSpeak DLL\")\n                    except:\n                        pass\n                    break\n            if not found:\n                print(\"[WARN] Unable to find the eSpeak DLL, probably because you installed eSpeak in a non-standard location.\")\n                print(\"[WARN] If you want to run aeneas with the C extension cew,\")\n                print(\"[WARN] please copy espeak_sapi.dll from your eSpeak directory to %s\" % espeak_dll_win_path)\n                # print(\"[WARN] and run the aeneas setup again.\")\n                # return False\n            elif not copied:\n                print(\"[WARN] Unable to copy the eSpeak DLL, probably because you are not running with admin privileges.\")\n                print(\"[WARN] If you want to run aeneas with the C extension cew,\")\n                print(\"[WARN] please copy espeak_sapi.dll from your eSpeak directory to %s\" % espeak_dll_win_path)\n                # print(\"[WARN] and run the aeneas setup again.\")\n                # return False\n\n        # NOTE: espeak.lib is needed only while compiling the C extension, not when using it\n        #       so, we copy it in the current working directory from the included thirdparty\\ directory\n        # NOTE: PREV: copy thirdparty\\espeak.lib to $PYTHON\\libs\\espeak.lib\n        # NOTE: PREV: espeak_lib_dst_path = os.path.join(sys.prefix, \"libs\", \"espeak.lib\")\n        espeak_lib_src_path = os.path.join(os.path.dirname(__file__), \"thirdparty\", \"espeak.lib\")\n        espeak_lib_dst_path = os.path.join(os.path.dirname(__file__), \"espeak.lib\")\n        if os.path.exists(espeak_lib_dst_path):\n            print(\"[INFO] Found eSpeak LIB in %s\" % espeak_lib_dst_path)\n        else:\n            try:\n                print(\"[INFO] Copying eSpeak LIB into %s\" % espeak_lib_dst_path)\n                shutil.copyfile(espeak_lib_src_path, espeak_lib_dst_path)\n                print(\"[INFO] Copied eSpeak LIB\")\n            except:\n                print(\"[WARN] Unable to copy the eSpeak LIB, probably because you are not running with admin privileges.\")\n                print(\"[WARN] If you want to compile the C extension cew,\")\n                print(\"[WARN] please copy espeak.lib from the thirdparty directory into %s\" % espeak_lib_dst_path)\n                print(\"[WARN] and run the aeneas setup again.\")\n                return False\n\n        # if here, we have completed the setup, return True\n        return True\n    except Exception as e:\n        print(\"[WARN] Unexpected exception while preparing cew: %s\" % e)\n    return False", "response": "Prepare a new cew Python C extension on Windows."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_file_encoding(self, input_file_path):\n        self.log([u\"Checking encoding of file '%s'\", input_file_path])\n        self.result = ValidatorResult()\n        if self._are_safety_checks_disabled(u\"check_file_encoding\"):\n            return self.result\n        if not gf.file_can_be_read(input_file_path):\n            self._failed(u\"File '%s' cannot be read.\" % (input_file_path))\n            return self.result\n        with io.open(input_file_path, \"rb\") as file_object:\n            bstring = file_object.read()\n            self._check_utf8_encoding(bstring)\n        return self.result", "response": "Check whether the given file is UTF - 8 encoded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_raw_string(self, string, is_bstring=True):\n        self.log(u\"Checking the given byte string\")\n        self.result = ValidatorResult()\n        if self._are_safety_checks_disabled(u\"check_raw_string\"):\n            return self.result\n        if is_bstring:\n            self._check_utf8_encoding(string)\n            if not self.result.passed:\n                return self.result\n            string = gf.safe_unicode(string)\n        self._check_not_empty(string)\n        if not self.result.passed:\n            return self.result\n        self._check_reserved_characters(string)\n        return self.result", "response": "Checks whether the given string is properly UTF - 8 encoded and not empty."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether the given configuration string is well - formed and if it is required to appear in the job or task.", "response": "def check_configuration_string(\n            self,\n            config_string,\n            is_job=True,\n            external_name=False\n    ):\n        \"\"\"\n        Check whether the given job or task configuration string\n        is well-formed (if ``is_bstring`` is ``True``)\n        and it has all the required parameters.\n\n        :param string config_string: the byte string or Unicode string to be checked\n        :param bool is_job: if ``True``, ``config_string`` is a job config string\n        :param bool external_name: if ``True``, the task name is provided externally,\n                                   and it is not required to appear\n                                   in the config string\n        :rtype: :class:`~aeneas.validator.ValidatorResult`\n        \"\"\"\n        if is_job:\n            self.log(u\"Checking job configuration string\")\n        else:\n            self.log(u\"Checking task configuration string\")\n        self.result = ValidatorResult()\n        if self._are_safety_checks_disabled(u\"check_configuration_string\"):\n            return self.result\n        if is_job:\n            required_parameters = self.JOB_REQUIRED_PARAMETERS\n        elif external_name:\n            required_parameters = self.TASK_REQUIRED_PARAMETERS_EXTERNAL_NAME\n        else:\n            required_parameters = self.TASK_REQUIRED_PARAMETERS\n        is_bstring = gf.is_bytes(config_string)\n        if is_bstring:\n            self.log(u\"Checking that config_string is well formed\")\n            self.check_raw_string(config_string, is_bstring=True)\n            if not self.result.passed:\n                return self.result\n            config_string = gf.safe_unicode(config_string)\n        self.log(u\"Checking required parameters\")\n        parameters = gf.config_string_to_dict(config_string, self.result)\n        self._check_required_parameters(required_parameters, parameters)\n        self.log([u\"Checking config_string: returning %s\", self.result.passed])\n        return self.result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether the given TXT config file contents is well - formed and has all the required parameters.", "response": "def check_config_txt(self, contents, is_config_string=False):\n        \"\"\"\n        Check whether the given TXT config file contents\n        (if ``is_config_string`` is ``False``) or\n        TXT config string (if ``is_config_string`` is ``True``)\n        is well-formed and it has all the required parameters.\n\n        :param string contents: the TXT config file contents or TXT config string\n        :param bool is_config_string: if ``True``, contents is a config string\n        :rtype: :class:`~aeneas.validator.ValidatorResult`\n        \"\"\"\n        self.log(u\"Checking contents TXT config file\")\n        self.result = ValidatorResult()\n        if self._are_safety_checks_disabled(u\"check_config_txt\"):\n            return self.result\n        is_bstring = gf.is_bytes(contents)\n        if is_bstring:\n            self.log(u\"Checking that contents is well formed\")\n            self.check_raw_string(contents, is_bstring=True)\n            if not self.result.passed:\n                return self.result\n            contents = gf.safe_unicode(contents)\n        if not is_config_string:\n            self.log(u\"Converting file contents to config string\")\n            contents = gf.config_txt_to_string(contents)\n        self.log(u\"Checking required parameters\")\n        required_parameters = self.TXT_REQUIRED_PARAMETERS\n        parameters = gf.config_string_to_dict(contents, self.result)\n        self._check_required_parameters(required_parameters, parameters)\n        self.log([u\"Checking contents: returning %s\", self.result.passed])\n        return self.result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the given XML config file contents is well - formed and has all the required parameters.", "response": "def check_config_xml(self, contents):\n        \"\"\"\n        Check whether the given XML config file contents\n        is well-formed and it has all the required parameters.\n\n        :param string contents: the XML config file contents or XML config string\n        :param bool is_config_string: if ``True``, contents is a config string\n        :rtype: :class:`~aeneas.validator.ValidatorResult`\n        \"\"\"\n        self.log(u\"Checking contents XML config file\")\n        self.result = ValidatorResult()\n        if self._are_safety_checks_disabled(u\"check_config_xml\"):\n            return self.result\n        contents = gf.safe_bytes(contents)\n        self.log(u\"Checking that contents is well formed\")\n        self.check_raw_string(contents, is_bstring=True)\n        if not self.result.passed:\n            return self.result\n        self.log(u\"Checking required parameters for job\")\n        job_parameters = gf.config_xml_to_dict(contents, self.result, parse_job=True)\n        self._check_required_parameters(self.XML_JOB_REQUIRED_PARAMETERS, job_parameters)\n        if not self.result.passed:\n            return self.result\n        self.log(u\"Checking required parameters for task\")\n        tasks_parameters = gf.config_xml_to_dict(contents, self.result, parse_job=False)\n        for parameters in tasks_parameters:\n            self.log([u\"Checking required parameters for task: '%s'\", parameters])\n            self._check_required_parameters(self.XML_TASK_REQUIRED_PARAMETERS, parameters)\n            if not self.result.passed:\n                return self.result\n        return self.result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_container(self, container_path, container_format=None, config_string=None):\n        self.log([u\"Checking container '%s'\", container_path])\n        self.result = ValidatorResult()\n\n        if self._are_safety_checks_disabled(u\"check_container\"):\n            return self.result\n\n        if not (gf.file_exists(container_path) or gf.directory_exists(container_path)):\n            self._failed(u\"Container '%s' not found.\" % container_path)\n            return self.result\n\n        container = Container(container_path, container_format)\n        try:\n            self.log(u\"Checking container has config file\")\n            if config_string is not None:\n                self.log(u\"Container with config string from wizard\")\n                self.check_config_txt(config_string, is_config_string=True)\n            elif container.has_config_xml:\n                self.log(u\"Container has XML config file\")\n                contents = container.read_entry(container.entry_config_xml)\n                if contents is None:\n                    self._failed(u\"Unable to read the contents of XML config file.\")\n                    return self.result\n                self.check_config_xml(contents)\n            elif container.has_config_txt:\n                self.log(u\"Container has TXT config file\")\n                contents = container.read_entry(container.entry_config_txt)\n                if contents is None:\n                    self._failed(u\"Unable to read the contents of TXT config file.\")\n                    return self.result\n                self.check_config_txt(contents, is_config_string=False)\n            else:\n                self._failed(u\"Container does not have a TXT or XML configuration file.\")\n\n            self.log(u\"Checking we have a valid job in the container\")\n            if not self.result.passed:\n                return self.result\n            self.log(u\"Analyze the contents of the container\")\n            analyzer = AnalyzeContainer(container)\n            if config_string is not None:\n                job = analyzer.analyze(config_string=config_string)\n            else:\n                job = analyzer.analyze()\n            self._check_analyzed_job(job, container)\n\n        except OSError:\n            self._failed(u\"Unable to read the contents of the container.\")\n        return self.result", "response": "Check whether the given container is well - formed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if safety checks are disabled.", "response": "def _are_safety_checks_disabled(self, caller=u\"unknown_function\"):\n        \"\"\"\n        Return ``True`` if safety checks are disabled.\n\n        :param string caller: the name of the caller function\n        :rtype: bool\n        \"\"\"\n        if self.rconf.safety_checks:\n            return False\n        self.log_warn([u\"Safety checks disabled => %s passed\", caller])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs a validation failure.", "response": "def _failed(self, msg):\n        \"\"\"\n        Log a validation failure.\n\n        :param string msg: the error message\n        \"\"\"\n        self.log(msg)\n        self.result.passed = False\n        self.result.add_error(msg)\n        self.log(u\"Failed\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether the given byte string is properly encoded in UTF - 8.", "response": "def _check_utf8_encoding(self, bstring):\n        \"\"\"\n        Check whether the given sequence of bytes\n        is properly encoded in UTF-8.\n\n        :param bytes bstring: the byte string to be checked\n        \"\"\"\n        if not gf.is_bytes(bstring):\n            self._failed(u\"The given string is not a sequence of bytes\")\n            return\n        if not gf.is_utf8_encoded(bstring):\n            self._failed(u\"The given string is not encoded in UTF-8.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether the given Unicode string contains reserved characters.", "response": "def _check_reserved_characters(self, ustring):\n        \"\"\"\n        Check whether the given Unicode string contains reserved characters.\n\n        :param string ustring: the string to be checked\n        \"\"\"\n        forbidden = [c for c in gc.CONFIG_RESERVED_CHARACTERS if c in ustring]\n        if len(forbidden) > 0:\n            self._failed(u\"The given string contains the reserved characters '%s'.\" % u\" \".join(forbidden))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_allowed_values(self, parameters):\n        for key, allowed_values in self.ALLOWED_VALUES:\n            self.log([u\"Checking allowed values for parameter '%s'\", key])\n            if key in parameters:\n                value = parameters[key]\n                if value not in allowed_values:\n                    self._failed(u\"Parameter '%s' has value '%s' which is not allowed.\" % (key, value))\n                    return\n        self.log(u\"Passed\")", "response": "Check whether the given parameter value is allowed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether at least one of the keys in implied_keys is in parameters and if not log messages into self. result.", "response": "def _check_implied_parameters(self, parameters):\n        \"\"\"\n        Check whether at least one of the keys in implied_keys\n        is in ``parameters``,\n        when a given ``key=value`` is present in ``parameters``,\n        for some value in values.\n        Log messages into ``self.result``.\n\n        :param dict parameters: the given parameters\n        \"\"\"\n        for key, values, implied_keys in self.IMPLIED_PARAMETERS:\n            self.log([u\"Checking implied parameters by '%s'='%s'\", key, values])\n            if (key in parameters) and (parameters[key] in values):\n                found = False\n                for implied_key in implied_keys:\n                    if implied_key in parameters:\n                        found = True\n                if not found:\n                    if len(implied_keys) == 1:\n                        msg = u\"Parameter '%s' is required when '%s'='%s'.\" % (implied_keys[0], key, parameters[key])\n                    else:\n                        msg = u\"At least one of [%s] is required when '%s'='%s'.\" % (\",\".join(implied_keys), key, parameters[key])\n                    self._failed(msg)\n                    return\n        self.log(u\"Passed\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether the given parameter dictionary contains all the required parameters.", "response": "def _check_required_parameters(\n            self,\n            required_parameters,\n            parameters\n    ):\n        \"\"\"\n        Check whether the given parameter dictionary contains\n        all the required paramenters.\n        Log messages into ``self.result``.\n\n        :param list required_parameters: required parameters\n        :param dict parameters: parameters specified by the user\n        \"\"\"\n        self.log([u\"Checking required parameters '%s'\", required_parameters])\n        self.log(u\"Checking input parameters are not empty\")\n        if (parameters is None) or (len(parameters) == 0):\n            self._failed(u\"No parameters supplied.\")\n            return\n        self.log(u\"Checking no required parameter is missing\")\n        for req_param in required_parameters:\n            if req_param not in parameters:\n                self._failed(u\"Required parameter '%s' not set.\" % req_param)\n                return\n        self.log(u\"Checking all parameter values are allowed\")\n        self._check_allowed_values(parameters)\n        self.log(u\"Checking all implied parameters are present\")\n        self._check_implied_parameters(parameters)\n        return self.result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the given job object generated from the given container is well formed and that all of the Task text files of each task are well formed and that the text file of each task has the correct encoding.", "response": "def _check_analyzed_job(self, job, container):\n        \"\"\"\n        Check that the job object generated from the given container\n        is well formed, that it has at least one task,\n        and that the text file of each task has the correct encoding.\n        Log messages into ``self.result``.\n\n        :param job: the Job object generated from container\n        :type  job: :class:`~aeneas.job.Job`\n        :param container: the Container object\n        :type  container: :class:`~aeneas.container.Container`\n        \"\"\"\n        self.log(u\"Checking the Job object generated from container\")\n\n        self.log(u\"Checking that the Job is not None\")\n        if job is None:\n            self._failed(u\"Unable to create a Job from the container.\")\n            return\n\n        self.log(u\"Checking that the Job has at least one Task\")\n        if len(job) == 0:\n            self._failed(u\"Unable to create at least one Task from the container.\")\n            return\n\n        if self.rconf[RuntimeConfiguration.JOB_MAX_TASKS] > 0:\n            self.log(u\"Checking that the Job does not have too many Tasks\")\n            if len(job) > self.rconf[RuntimeConfiguration.JOB_MAX_TASKS]:\n                self._failed(u\"The Job has %d Tasks, more than the maximum allowed (%d).\" % (\n                    len(job),\n                    self.rconf[RuntimeConfiguration.JOB_MAX_TASKS]\n                ))\n                return\n\n        self.log(u\"Checking that each Task text file is well formed\")\n        for task in job.tasks:\n            self.log([u\"Checking Task text file '%s'\", task.text_file_path])\n            text_file_bstring = container.read_entry(task.text_file_path)\n            if (text_file_bstring is None) or (len(text_file_bstring) == 0):\n                self._failed(u\"Text file '%s' is empty\" % task.text_file_path)\n                return\n            self._check_utf8_encoding(text_file_bstring)\n            if not self.result.passed:\n                self._failed(u\"Text file '%s' is not encoded in UTF-8\" % task.text_file_path)\n                return\n            self._check_not_empty(text_file_bstring)\n            if not self.result.passed:\n                self._failed(u\"Text file '%s' is empty\" % task.text_file_path)\n                return\n            self.log([u\"Checking Task text file '%s': passed\", task.text_file_path])\n        self.log(u\"Checking each Task text file is well formed: passed\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty_print(self, warnings=False):\n        msg = []\n        if (warnings) and (len(self.warnings) > 0):\n            msg.append(u\"Warnings:\")\n            for warning in self.warnings:\n                msg.append(u\"  %s\" % warning)\n        if len(self.errors) > 0:\n            msg.append(u\"Errors:\")\n            for error in self.errors:\n                msg.append(u\"  %s\" % error)\n        return u\"\\n\".join(msg)", "response": "Pretty print the log entries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(\n            self,\n            input_file_path,\n            output_file_path,\n            head_length=None,\n            process_length=None\n    ):\n        \"\"\"\n        Convert the audio file at ``input_file_path``\n        into ``output_file_path``,\n        using the parameters set in the constructor\n        or through the ``parameters`` property.\n\n        You can skip the beginning of the audio file\n        by specifying ``head_length`` seconds to skip\n        (if it is ``None``, start at time zero),\n        and you can specify to convert\n        only ``process_length`` seconds\n        (if it is ``None``, process the entire input file length).\n\n        By specifying both ``head_length`` and ``process_length``,\n        you can skip a portion at the beginning and at the end\n        of the original input file.\n\n        :param string input_file_path: the path of the audio file to convert\n        :param string output_file_path: the path of the converted audio file\n        :param float head_length: skip these many seconds\n                                  from the beginning of the audio file\n        :param float process_length: process these many seconds of the audio file\n        :raises: :class:`~aeneas.ffmpegwrapper.FFMPEGPathError`: if the path to the ``ffmpeg`` executable cannot be called\n        :raises: OSError: if ``input_file_path`` does not exist\n                          or ``output_file_path`` cannot be written\n        \"\"\"\n        # test if we can read the input file\n        if not gf.file_can_be_read(input_file_path):\n            self.log_exc(u\"Input file '%s' cannot be read\" % (input_file_path), None, True, OSError)\n\n        # test if we can write the output file\n        if not gf.file_can_be_written(output_file_path):\n            self.log_exc(u\"Output file '%s' cannot be written\" % (output_file_path), None, True, OSError)\n\n        # call ffmpeg\n        arguments = [self.rconf[RuntimeConfiguration.FFMPEG_PATH]]\n        arguments.extend([\"-i\", input_file_path])\n        if head_length is not None:\n            arguments.extend([\"-ss\", head_length])\n        if process_length is not None:\n            arguments.extend([\"-t\", process_length])\n        if self.rconf.sample_rate in self.FFMPEG_PARAMETERS_MAP:\n            arguments.extend(self.FFMPEG_PARAMETERS_MAP[self.rconf.sample_rate])\n        else:\n            arguments.extend(self.FFMPEG_PARAMETERS_DEFAULT)\n        arguments.append(output_file_path)\n        self.log([u\"Calling with arguments '%s'\", arguments])\n        try:\n            proc = subprocess.Popen(\n                arguments,\n                stdout=subprocess.PIPE,\n                stdin=subprocess.PIPE,\n                stderr=subprocess.PIPE\n            )\n            proc.communicate()\n            proc.stdout.close()\n            proc.stdin.close()\n            proc.stderr.close()\n        except OSError as exc:\n            self.log_exc(u\"Unable to call the '%s' ffmpeg executable\" % (self.rconf[RuntimeConfiguration.FFMPEG_PATH]), exc, True, FFMPEGPathError)\n        self.log(u\"Call completed\")\n\n        # check if the output file exists\n        if not gf.file_exists(output_file_path):\n            self.log_exc(u\"Output file '%s' was not written\" % (output_file_path), None, True, OSError)\n\n        # returning the output file path\n        self.log([u\"Returning output file path '%s'\", output_file_path])\n        return output_file_path", "response": "Convert the audio file at input_file_path into output_file_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string representation of the current tag.", "response": "def pretty_print(self):\n        \"\"\"\n        Pretty print representation of this fragment,\n        as ``(identifier, begin, end, text)``.\n\n        :rtype: string\n\n        .. versionadded:: 1.7.0\n        \"\"\"\n        return u\"%s\\t%.3f\\t%.3f\\t%s\" % (\n            (self.identifier or u\"\"),\n            (self.begin if self.begin is not None else TimeValue(\"-2.000\")),\n            (self.end if self.end is not None else TimeValue(\"-1.000\")),\n            (self.text or u\"\")\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rate(self):\n        if (\n            (self.fragment_type != self.REGULAR) or\n            (self.has_zero_length)\n        ):\n            return None\n        return Decimal(self.chars / self.length)", "response": "Returns the rate in characters / second of this fragment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rate_lack(self, max_rate):\n        if self.fragment_type == self.REGULAR:\n            return self.chars / max_rate - self.length\n        return TimeValue(\"0.000\")", "response": "Returns the time interval that this fragment lacks at least the given max rate."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rate_slack(self, max_rate):\n        if self.fragment_type == self.REGULAR:\n            return -self.rate_lack(max_rate)\n        elif self.fragment_type == self.NONSPEECH:\n            return self.length\n        else:\n            return TimeValue(\"0.000\")", "response": "Returns the maximum time interval that can be stolen to this fragment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform_command(self):\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        audio_file_path = self.actual_arguments[0]\n        mode = self.actual_arguments[1]\n        if mode not in [u\"speech\", u\"nonspeech\", u\"both\"]:\n            return self.print_help()\n        output_file_path = None\n        if len(self.actual_arguments) >= 3:\n            output_file_path = self.actual_arguments[2]\n        output_time = not self.has_option([u\"-i\", u\"--index\"])\n\n        self.check_c_extensions(\"cmfcc\")\n        if not self.check_input_file(audio_file_path):\n            return self.ERROR_EXIT_CODE\n        if (output_file_path is not None) and (not self.check_output_file(output_file_path)):\n            return self.ERROR_EXIT_CODE\n\n        self.print_info(u\"Reading audio...\")\n        try:\n            audio_file_mfcc = AudioFileMFCC(audio_file_path, rconf=self.rconf, logger=self.logger)\n        except AudioFileConverterError:\n            self.print_error(u\"Unable to call the ffmpeg executable '%s'\" % (self.rconf[RuntimeConfiguration.FFMPEG_PATH]))\n            self.print_error(u\"Make sure the path to ffmpeg is correct\")\n            return self.ERROR_EXIT_CODE\n        except (AudioFileUnsupportedFormatError, AudioFileNotInitializedError):\n            self.print_error(u\"Cannot read file '%s'\" % (audio_file_path))\n            self.print_error(u\"Check that its format is supported by ffmpeg\")\n            return self.ERROR_EXIT_CODE\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while reading the audio file:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n        self.print_info(u\"Reading audio... done\")\n\n        self.print_info(u\"Executing VAD...\")\n        audio_file_mfcc.run_vad()\n        self.print_info(u\"Executing VAD... done\")\n\n        speech = audio_file_mfcc.intervals(speech=True, time=output_time)\n        nonspeech = audio_file_mfcc.intervals(speech=False, time=output_time)\n        if mode == u\"speech\":\n            if output_time:\n                intervals = [(i.begin, i.end) for i in speech]\n                template = u\"%.3f\\t%.3f\"\n            else:\n                intervals = speech\n                template = u\"%d\\t%d\"\n        elif mode == u\"nonspeech\":\n            if output_time:\n                intervals = [(i.begin, i.end) for i in nonspeech]\n                template = u\"%.3f\\t%.3f\"\n            else:\n                intervals = nonspeech\n                template = u\"%d\\t%d\"\n        elif mode == u\"both\":\n            if output_time:\n                speech = [(i.begin, i.end, u\"speech\") for i in speech]\n                nonspeech = [(i.begin, i.end, u\"nonspeech\") for i in nonspeech]\n                template = u\"%.3f\\t%.3f\\t%s\"\n            else:\n                speech = [(i[0], i[1], u\"speech\") for i in speech]\n                nonspeech = [(i[0], i[1], u\"nonspeech\") for i in nonspeech]\n                template = u\"%d\\t%d\\t%s\"\n            intervals = sorted(speech + nonspeech)\n        self.write_to_file(output_file_path, intervals, template)\n\n        return self.NO_ERROR_EXIT_CODE", "response": "Perform the actual command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the set of intervals to a file.", "response": "def write_to_file(self, output_file_path, intervals, template):\n        \"\"\"\n        Write intervals to file.\n\n        :param output_file_path: path of the output file to be written;\n                                 if ``None``, print to stdout\n        :type  output_file_path: string (path)\n        :param intervals: a list of tuples, each representing an interval\n        :type  intervals: list of tuples\n        \"\"\"\n        msg = [template % (interval) for interval in intervals]\n        if output_file_path is None:\n            self.print_info(u\"Intervals detected:\")\n            for line in msg:\n                self.print_generic(line)\n        else:\n            with io.open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n                output_file.write(u\"\\n\".join(msg))\n                self.print_success(u\"Created file '%s'\" % output_file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsynthesizing multiple text fragments using the CFW extension.", "response": "def _synthesize_multiple_c_extension(self, text_file, output_file_path, quit_after=None, backwards=False):\n        \"\"\"\n        Synthesize multiple text fragments, using the cfw extension.\n\n        Return a tuple (anchors, total_time, num_chars).\n\n        :rtype: (bool, (list, :class:`~aeneas.exacttiming.TimeValue`, int))\n        \"\"\"\n        self.log(u\"Synthesizing using C extension...\")\n\n        # convert parameters from Python values to C values\n        try:\n            c_quit_after = float(quit_after)\n        except TypeError:\n            c_quit_after = 0.0\n        c_backwards = 0\n        if backwards:\n            c_backwards = 1\n        self.log([u\"output_file_path: %s\", output_file_path])\n        self.log([u\"c_quit_after:     %.3f\", c_quit_after])\n        self.log([u\"c_backwards:      %d\", c_backwards])\n        self.log(u\"Preparing u_text...\")\n        u_text = []\n        fragments = text_file.fragments\n        for fragment in fragments:\n            f_lang = fragment.language\n            f_text = fragment.filtered_text\n            if f_lang is None:\n                f_lang = self.DEFAULT_LANGUAGE\n            f_voice_code = self.VOICE_CODE_TO_SUBPROCESS[self._language_to_voice_code(f_lang)]\n            if f_text is None:\n                f_text = u\"\"\n            u_text.append((f_voice_code, f_text))\n        self.log(u\"Preparing u_text... done\")\n\n        # call C extension\n        sr = None\n        sf = None\n        intervals = None\n\n        self.log(u\"Preparing c_text...\")\n        if gf.PY2:\n            # Python 2 => pass byte strings\n            c_text = [(gf.safe_bytes(t[0]), gf.safe_bytes(t[1])) for t in u_text]\n        else:\n            # Python 3 => pass Unicode strings\n            c_text = [(gf.safe_unicode(t[0]), gf.safe_unicode(t[1])) for t in u_text]\n        self.log(u\"Preparing c_text... done\")\n\n        self.log(u\"Calling aeneas.cfw directly\")\n        try:\n            self.log(u\"Importing aeneas.cfw...\")\n            import aeneas.cfw.cfw\n            self.log(u\"Importing aeneas.cfw... done\")\n            self.log(u\"Calling aeneas.cfw...\")\n            sr, sf, intervals = aeneas.cfw.cfw.synthesize_multiple(\n                output_file_path,\n                c_quit_after,\n                c_backwards,\n                c_text\n            )\n            self.log(u\"Calling aeneas.cfw... done\")\n        except Exception as exc:\n            self.log_exc(u\"An unexpected error occurred while running cfw\", exc, False, None)\n            return (False, None)\n\n        self.log([u\"sr: %d\", sr])\n        self.log([u\"sf: %d\", sf])\n\n        # create output\n        anchors = []\n        current_time = TimeValue(\"0.000\")\n        num_chars = 0\n        if backwards:\n            fragments = fragments[::-1]\n        for i in range(sf):\n            # get the correct fragment\n            fragment = fragments[i]\n            # store for later output\n            anchors.append([\n                TimeValue(intervals[i][0]),\n                fragment.identifier,\n                fragment.filtered_text\n            ])\n            # increase the character counter\n            num_chars += fragment.characters\n            # update current_time\n            current_time = TimeValue(intervals[i][1])\n\n        # return output\n        # NOTE anchors do not make sense if backwards == True\n        self.log([u\"Returning %d time anchors\", len(anchors)])\n        self.log([u\"Current time %.3f\", current_time])\n        self.log([u\"Synthesized %d characters\", num_chars])\n        self.log(u\"Synthesizing using C extension... done\")\n        return (True, (anchors, current_time, num_chars))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform_command(self):\n        if self.has_option([u\"--list-parameters\"]):\n            return self.print_parameters()\n\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n\n        container_path = self.actual_arguments[0]\n        output_directory_path = self.actual_arguments[1]\n        config_string = None\n        if (len(self.actual_arguments)) > 2 and (not self.actual_arguments[2].startswith(u\"-\")):\n            config_string = self.actual_arguments[2]\n        validate = not self.has_option(u\"--skip-validator\")\n        if self.has_option(u\"--cewsubprocess\"):\n            self.rconf[RuntimeConfiguration.CEW_SUBPROCESS_ENABLED] = True\n\n        if not self.check_input_file_or_directory(container_path):\n            return self.ERROR_EXIT_CODE\n\n        if not self.check_output_directory(output_directory_path):\n            return self.ERROR_EXIT_CODE\n\n        if validate:\n            try:\n                self.print_info(u\"Validating the container (specify --skip-validator to bypass)...\")\n                validator = Validator(rconf=self.rconf, logger=self.logger)\n                result = validator.check_container(container_path, config_string=config_string)\n                if not result.passed:\n                    self.print_error(u\"The given container is not valid:\")\n                    self.print_error(result.pretty_print())\n                    return self.ERROR_EXIT_CODE\n                self.print_info(u\"Validating the container... done\")\n            except Exception as exc:\n                self.print_error(u\"An unexpected error occurred while validating the container:\")\n                self.print_error(u\"%s\" % exc)\n                return self.ERROR_EXIT_CODE\n\n        try:\n            self.print_info(u\"Loading job from container...\")\n            executor = ExecuteJob(rconf=self.rconf, logger=self.logger)\n            executor.load_job_from_container(container_path, config_string)\n            self.print_info(u\"Loading job from container... done\")\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while loading the job:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n\n        try:\n            self.print_info(u\"Executing...\")\n            executor.execute()\n            self.print_info(u\"Executing... done\")\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while executing the job:\")\n            self.print_error(u\"%s\" % exc)\n            return self.ERROR_EXIT_CODE\n\n        try:\n            self.print_info(u\"Creating output container...\")\n            path = executor.write_output_container(output_directory_path)\n            self.print_info(u\"Creating output container... done\")\n            self.print_success(u\"Created output file '%s'\" % path)\n            executor.clean(True)\n            return self.NO_ERROR_EXIT_CODE\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while writing the output container:\")\n            self.print_error(u\"%s\" % exc)\n\n        return self.ERROR_EXIT_CODE", "response": "Perform the command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_parameters(self):\n        self.print_info(u\"Available parameters:\")\n        self.print_generic(u\"\\n\" + u\"\\n\".join(self.PARAMETERS) + u\"\\n\")\n        return self.HELP_EXIT_CODE", "response": "Print the list of parameters and exit."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns ``aeneas.cew``, reading input text from file and writing audio and interval data to file.", "response": "def main():\n    \"\"\"\n    Run ``aeneas.cew``, reading input text from file and writing audio and interval data to file.\n    \"\"\"\n\n    # make sure we have enough parameters\n    if len(sys.argv) < 6:\n        print(\"You must pass five arguments: QUIT_AFTER BACKWARDS TEXT_FILE_PATH AUDIO_FILE_PATH DATA_FILE_PATH\")\n        return 1\n\n    # read parameters\n    c_quit_after = float(sys.argv[1])   # NOTE: cew needs float, not TimeValue\n    c_backwards = int(sys.argv[2])\n    text_file_path = sys.argv[3]\n    audio_file_path = sys.argv[4]\n    data_file_path = sys.argv[5]\n\n    # read (voice_code, text) from file\n    s_text = []\n    with io.open(text_file_path, \"r\", encoding=\"utf-8\") as text:\n        for line in text.readlines():\n            # NOTE: not using strip() to avoid removing trailing blank characters\n            line = line.replace(u\"\\n\", u\"\").replace(u\"\\r\", u\"\")\n            idx = line.find(\" \")\n            if idx > 0:\n                f_voice_code = line[:idx]\n                f_text = line[(idx + 1):]\n                s_text.append((f_voice_code, f_text))\n\n    # convert to bytes/unicode as required by subprocess\n    c_text = []\n    if gf.PY2:\n        for f_voice_code, f_text in s_text:\n            c_text.append((gf.safe_bytes(f_voice_code), gf.safe_bytes(f_text)))\n    else:\n        for f_voice_code, f_text in s_text:\n            c_text.append((gf.safe_unicode(f_voice_code), gf.safe_unicode(f_text)))\n\n    try:\n        import aeneas.cew.cew\n        sr, sf, intervals = aeneas.cew.cew.synthesize_multiple(\n            audio_file_path,\n            c_quit_after,\n            c_backwards,\n            c_text\n        )\n        with io.open(data_file_path, \"w\", encoding=\"utf-8\") as data:\n            data.write(u\"%d\\n\" % (sr))\n            data.write(u\"%d\\n\" % (sf))\n            data.write(u\"\\n\".join([u\"%.3f %.3f\" % (i[0], i[1]) for i in intervals]))\n    except Exception as exc:\n        print(u\"Unexpected error: %s\" % str(exc))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef synthesize_multiple(self, audio_file_path, c_quit_after, c_backwards, u_text):\n        self.log([u\"Audio file path: '%s'\", audio_file_path])\n        self.log([u\"c_quit_after: '%.3f'\", c_quit_after])\n        self.log([u\"c_backwards: '%d'\", c_backwards])\n\n        text_file_handler, text_file_path = gf.tmp_file()\n        data_file_handler, data_file_path = gf.tmp_file()\n        self.log([u\"Temporary text file path: '%s'\", text_file_path])\n        self.log([u\"Temporary data file path: '%s'\", data_file_path])\n\n        self.log(u\"Populating the text file...\")\n        with io.open(text_file_path, \"w\", encoding=\"utf-8\") as tmp_text_file:\n            for f_voice_code, f_text in u_text:\n                tmp_text_file.write(u\"%s %s\\n\" % (f_voice_code, f_text))\n        self.log(u\"Populating the text file... done\")\n\n        arguments = [\n            self.rconf[RuntimeConfiguration.CEW_SUBPROCESS_PATH],\n            \"-m\",\n            \"aeneas.cewsubprocess\",\n            \"%.3f\" % c_quit_after,\n            \"%d\" % c_backwards,\n            text_file_path,\n            audio_file_path,\n            data_file_path\n        ]\n        self.log([u\"Calling with arguments '%s'\", u\" \".join(arguments)])\n        proc = subprocess.Popen(\n            arguments,\n            stdout=subprocess.PIPE,\n            stdin=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True)\n        proc.communicate()\n\n        self.log(u\"Reading output data...\")\n        with io.open(data_file_path, \"r\", encoding=\"utf-8\") as data_file:\n            lines = data_file.read().splitlines()\n            sr = int(lines[0])\n            sf = int(lines[1])\n            intervals = []\n            for line in lines[2:]:\n                values = line.split(u\" \")\n                if len(values) == 2:\n                    intervals.append((TimeValue(values[0]), TimeValue(values[1])))\n        self.log(u\"Reading output data... done\")\n\n        self.log(u\"Deleting text and data files...\")\n        gf.delete_file(text_file_handler, text_file_path)\n        gf.delete_file(data_file_handler, data_file_path)\n        self.log(u\"Deleting text and data files... done\")\n\n        return (sr, sf, intervals)", "response": "Synthesize the text contained in the given fragment list into a wav file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing SMIL file and adds new entries to the internal list.", "response": "def parse(self, input_text, syncmap):\n        \"\"\"\n        Read from SMIL file.\n\n        Limitations:\n        1. parses only ``<par>`` elements, in order\n        2. timings must have ``hh:mm:ss.mmm`` or ``ss.mmm`` format (autodetected)\n        3. both ``clipBegin`` and ``clipEnd`` attributes of ``<audio>`` must be populated\n        \"\"\"\n        from lxml import etree\n        smil_ns = \"{http://www.w3.org/ns/SMIL}\"\n        root = etree.fromstring(gf.safe_bytes(input_text))\n        for par in root.iter(smil_ns + \"par\"):\n            for child in par:\n                if child.tag == (smil_ns + \"text\"):\n                    identifier = gf.safe_unicode(gf.split_url(child.get(\"src\"))[1])\n                elif child.tag == (smil_ns + \"audio\"):\n                    begin_text = child.get(\"clipBegin\")\n                    if \":\" in begin_text:\n                        begin = gf.time_from_hhmmssmmm(begin_text)\n                    else:\n                        begin = gf.time_from_ssmmm(begin_text)\n                    end_text = child.get(\"clipEnd\")\n                    if \":\" in end_text:\n                        end = gf.time_from_hhmmssmmm(end_text)\n                    else:\n                        end = gf.time_from_ssmmm(end_text)\n            # TODO read text from additional text_file?\n            self._add_fragment(\n                syncmap=syncmap,\n                identifier=identifier,\n                lines=[u\"\"],\n                begin=begin,\n                end=end\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_valid_index(self, index):\n        if isinstance(index, int):\n            return (index >= 0) and (index < len(self))\n        if isinstance(index, list):\n            valid = True\n            for i in index:\n                valid = valid or self._is_valid_index(i)\n            return valid\n        return False", "response": "Return True if and only if the given index is valid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the interval of the given SyncMapFragment is within the boundaries of the list. Raises an error if not OK.", "response": "def _check_boundaries(self, fragment):\n        \"\"\"\n        Check that the interval of the given fragment\n        is within the boundaries of the list.\n        Raises an error if not OK.\n        \"\"\"\n        if not isinstance(fragment, SyncMapFragment):\n            raise TypeError(u\"fragment is not an instance of SyncMapFragment\")\n        interval = fragment.interval\n        if not isinstance(interval, TimeInterval):\n            raise TypeError(u\"interval is not an instance of TimeInterval\")\n        if (self.begin is not None) and (interval.begin < self.begin):\n            raise ValueError(u\"interval.begin is before self.begin\")\n        if (self.end is not None) and (interval.end > self.end):\n            raise ValueError(u\"interval.end is after self.end\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_overlap(self, fragment):\n        #\n        # NOTE bisect does not work if there is a configuration like:\n        #\n        #      *********** <- existing interval\n        #           ***    <- query interval\n        #\n        # TODO one should probably check this by doing bisect\n        #      over the begin and end lists separately\n        #\n        for existing_fragment in self.fragments:\n            if existing_fragment.interval.relative_position_of(fragment.interval) not in self.ALLOWED_POSITIONS:\n                self.log_exc(u\"interval overlaps another already present interval\", None, True, ValueError)", "response": "Check that the interval of the given fragment overlaps any existing intervals."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that the given start and end fragment indices make sense.", "response": "def _check_min_max_indices(self, min_index=None, max_index=None):\n        \"\"\"\n        Ensure the given start/end fragment indices make sense:\n        if one of them is ``None`` (i.e., not specified),\n        then set it to ``0`` or ``len(self)``.\n        \"\"\"\n        min_index = min_index or 0\n        max_index = max_index or len(self)\n        if min_index < 0:\n            self.log_exc(u\"min_index is negative\", None, True, ValueError)\n        if max_index > len(self):\n            self.log_exc(u\"max_index is bigger than the number of intervals in the list\", None, True, ValueError)\n        return min_index, max_index"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate through the regular fragments in the list.", "response": "def regular_fragments(self):\n        \"\"\"\n        Iterates through the regular fragments in the list\n        (which are sorted).\n\n        :rtype: generator of (int, :class:`~aeneas.syncmap.SyncMapFragment`)\n        \"\"\"\n        for i, fragment in enumerate(self.__fragments):\n            if fragment.fragment_type == SyncMapFragment.REGULAR:\n                yield (i, fragment)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate through the nonspeech fragments in the list.", "response": "def nonspeech_fragments(self):\n        \"\"\"\n        Iterates through the nonspeech fragments in the list\n        (which are sorted).\n\n        :rtype: generator of (int, :class:`~aeneas.syncmap.SyncMapFragment`)\n        \"\"\"\n        for i, fragment in enumerate(self.__fragments):\n            if fragment.fragment_type == SyncMapFragment.NONSPEECH:\n                yield (i, fragment)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, indices):\n        if not self._is_valid_index(indices):\n            self.log_exc(u\"The given list of indices is not valid\", None, True, ValueError)\n        new_fragments = []\n        sorted_indices = sorted(indices)\n        i = 0\n        j = 0\n        while (i < len(self)) and (j < len(sorted_indices)):\n            if i != sorted_indices[j]:\n                new_fragments.append(self[i])\n            else:\n                j += 1\n            i += 1\n        while i < len(self):\n            new_fragments.append(self[i])\n            i += 1\n        self.__fragments = new_fragments", "response": "Removes the fragments corresponding to the given list of indices."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort(self):\n        if self.is_guaranteed_sorted:\n            self.log(u\"Already sorted, returning\")\n            return\n        self.log(u\"Sorting...\")\n        self.__fragments = sorted(self.__fragments)\n        self.log(u\"Sorting... done\")\n        self.log(u\"Checking relative positions...\")\n        for i in range(len(self) - 1):\n            current_interval = self[i].interval\n            next_interval = self[i + 1].interval\n            if current_interval.relative_position_of(next_interval) not in self.ALLOWED_POSITIONS:\n                self.log(u\"Found overlapping fragments:\")\n                self.log([u\"  Index %d => %s\", i, current_interval])\n                self.log([u\"  Index %d => %s\", i + 1, next_interval])\n                self.log_exc(u\"The list contains two fragments overlapping in a forbidden way\", None, True, ValueError)\n        self.log(u\"Checking relative positions... done\")\n        self.__sorted = True", "response": "Sort the fragments in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all nonspeech fragments from the list.", "response": "def remove_nonspeech_fragments(self, zero_length_only=False):\n        \"\"\"\n        Remove ``NONSPEECH`` fragments from the list.\n\n        If ``zero_length_only`` is ``True``, remove only\n        those fragments with zero length,\n        and make all the others ``REGULAR``.\n\n        :param bool zero_length_only: remove only zero length NONSPEECH fragments\n        \"\"\"\n        self.log(u\"Removing nonspeech fragments...\")\n        nonspeech = list(self.nonspeech_fragments)\n        if zero_length_only:\n            nonspeech = [(i, f) for i, f in nonspeech if f.has_zero_length]\n        nonspeech_indices = [i for i, f in nonspeech]\n        self.remove(nonspeech_indices)\n        if zero_length_only:\n            for i, f in list(self.nonspeech_fragments):\n                f.fragment_type = SyncMapFragment.REGULAR\n        self.log(u\"Removing nonspeech fragments... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the list has at least one interval with zero length withing min_index and max_index.", "response": "def has_zero_length_fragments(self, min_index=None, max_index=None):\n        \"\"\"\n        Return ``True`` if the list has at least one interval\n        with zero length withing ``min_index`` and ``max_index``.\n        If the latter are not specified, check all intervals.\n\n        :param int min_index: examine fragments with index greater than or equal to this index (i.e., included)\n        :param int max_index: examine fragments with index smaller than this index (i.e., excluded)\n        :raises ValueError: if ``min_index`` is negative or ``max_index``\n                            is bigger than the current number of fragments\n        :rtype: bool\n        \"\"\"\n        min_index, max_index = self._check_min_max_indices(min_index, max_index)\n        zero = [i for i in range(min_index, max_index) if self[i].has_zero_length]\n        self.log([u\"Fragments with zero length: %s\", zero])\n        return (len(zero) > 0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_adjacent_fragments_only(self, min_index=None, max_index=None):\n        min_index, max_index = self._check_min_max_indices(min_index, max_index)\n        for i in range(min_index, max_index - 1):\n            current_interval = self[i].interval\n            next_interval = self[i + 1].interval\n            if not current_interval.is_adjacent_before(next_interval):\n                self.log(u\"Found non adjacent fragments\")\n                self.log([u\"  Index %d => %s\", i, current_interval])\n                self.log([u\"  Index %d => %s\", i + 1, next_interval])\n                return False\n        return True", "response": "Return True if the list contains only adjacent fragments and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the given syncmap. SyncMapFragment to the list and keep the latter sorted.", "response": "def add(self, fragment, sort=True):\n        \"\"\"\n        Add the given fragment to the list (and keep the latter sorted).\n\n        An error is raised if the fragment cannot be added,\n        for example if its interval violates the list constraints.\n\n        :param fragment: the fragment to be added\n        :type  fragment: :class:`~aeneas.syncmap.SyncMapFragment`\n        :param bool sort: if ``True`` ensure that after the insertion the list is kept sorted\n        :raises TypeError: if ``interval`` is not an instance of ``TimeInterval``\n        :raises ValueError: if ``interval`` does not respect the boundaries of the list\n                            or if it overlaps an existing interval,\n                            or if ``sort=True`` but the list is not guaranteed sorted\n        \"\"\"\n        self._check_boundaries(fragment)\n        if sort:\n            if not self.is_guaranteed_sorted:\n                self.log_exc(u\"Unable to add with sort=True if the list is not guaranteed sorted\", None, True, ValueError)\n            self._check_overlap(fragment)\n            insort(self.__fragments, fragment)\n            # self.log(u\"Inserted and kept sorted flag true\")\n        else:\n            self.__fragments.append(fragment)\n            self.__sorted = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove all the intervals in the list by the given offset.", "response": "def offset(self, offset):\n        \"\"\"\n        Move all the intervals in the list by the given ``offset``.\n\n        :param offset: the shift to be applied\n        :type  offset: :class:`~aeneas.exacttiming.TimeValue`\n        :raises TypeError: if ``offset`` is not an instance of ``TimeValue``\n        \"\"\"\n        self.log(u\"Applying offset to all fragments...\")\n        self.log([u\"  Offset %.3f\", offset])\n        for fragment in self.fragments:\n            fragment.interval.offset(\n                offset=offset,\n                allow_negative=False,\n                min_begin_value=self.begin,\n                max_end_value=self.end\n            )\n        self.log(u\"Applying offset to all fragments... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove the transition point between the current and next fragment.", "response": "def move_transition_point(self, fragment_index, value):\n        \"\"\"\n        Change the transition point between fragment ``fragment_index``\n        and the next fragment to the time value ``value``.\n\n        This method fails silently\n        (without changing the fragment list)\n        if at least one of the following conditions holds:\n\n        * ``fragment_index`` is negative\n        * ``fragment_index`` is the last or the second-to-last\n        * ``value`` is after the current end of the next fragment\n        * the current fragment and the next one are not adjacent and both proper intervals (not zero length)\n\n        The above conditions ensure that the move makes sense\n        and that it keeps the list satisfying the constraints.\n\n        :param int fragment_index: the fragment index whose end should be moved\n        :param value: the new transition point\n        :type  value: :class:`~aeneas.exacttiming.TimeValue`\n        \"\"\"\n        self.log(u\"Called move_transition_point with\")\n        self.log([u\"  fragment_index %d\", fragment_index])\n        self.log([u\"  value          %.3f\", value])\n        if (fragment_index < 0) or (fragment_index > (len(self) - 3)):\n            self.log(u\"Bad fragment_index, returning\")\n            return\n        current_interval = self[fragment_index].interval\n        next_interval = self[fragment_index + 1].interval\n        if value > next_interval.end:\n            self.log(u\"Bad value, returning\")\n            return\n        if not current_interval.is_non_zero_before_non_zero(next_interval):\n            self.log(u\"Bad interval configuration, returning\")\n            return\n        current_interval.end = value\n        next_interval.begin = value\n        self.log(u\"Moved transition point\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fragments_ending_inside_nonspeech_intervals(\n        self,\n        nonspeech_intervals,\n        tolerance\n    ):\n        \"\"\"\n        Determine a list of pairs (nonspeech interval, fragment index),\n        such that the nonspeech interval contains exactly one fragment\n        ending inside it (within the given tolerance) and\n        adjacent to the next fragment.\n\n        :param nonspeech_intervals: the list of nonspeech intervals to be examined\n        :type  nonspeech_intervals: list of :class:`~aeneas.exacttiming.TimeInterval`\n        :param tolerance: the tolerance to be applied when checking if the end point\n                          falls within a given nonspeech interval\n        :type  tolerance: :class:`~aeneas.exacttiming.TimeValue`\n        :rtype: list of (:class:`~aeneas.exacttiming.TimeInterval`, int)\n        \"\"\"\n        self.log(u\"Called fragments_ending_inside_nonspeech_intervals\")\n        self.log([u\"  List begin: %.3f\", self.begin])\n        self.log([u\"  List end:   %.3f\", self.end])\n        nsi_index = 0\n        frag_index = 0\n        nsi_counter = [(n, []) for n in nonspeech_intervals]\n        # NOTE the last fragment is not eligible to be returned\n        while (nsi_index < len(nonspeech_intervals)) and (frag_index < len(self) - 1):\n            nsi = nonspeech_intervals[nsi_index]\n            if nsi.end > self.end:\n                self.log(u\"    nsi ends after self.end => breaking\")\n                break\n            nsi_shadow = nsi.shadow(tolerance)\n            frag = self[frag_index]\n            self.log([u\"  nsi        %s\", nsi])\n            self.log([u\"  nsi_shadow %s\", nsi_shadow])\n            self.log([u\"  frag       %s\", frag.interval])\n            if not frag.is_head_or_tail:\n                self.log(u\"    Fragment is not HEAD or TAIL => inspecting it\")\n                if nsi_shadow.contains(frag.end):\n                    if nsi_shadow.contains(frag.begin):\n                        #\n                        #      *************** nsi shadow\n                        #      | *********** | nsi\n                        #      |   ***X      | frag (X=frag.end)\n                        #\n                        # NOTE this case might happen as the following:\n                        #\n                        #      *************** nsi shadow\n                        #      |     ***     | nsi\n                        #      | **X         | frag (X=frag.end)\n                        #\n                        #      so we must invalidate the nsi if this happens\n                        #\n                        nsi_counter[nsi_index] = (None, [])\n                        nsi_index += 1\n                        frag_index += 1\n                        self.log(u\"    nsi_shadow entirely contains frag => invalidate nsi, and skip to next fragment, nsi\")\n                    else:\n                        #\n                        #      *************** nsi shadow\n                        #      | *********** | nsi\n                        # *****|***X         | frag (X=frag.end)\n                        #\n                        nsi_counter[nsi_index][1].append(frag_index)\n                        frag_index += 1\n                        self.log(u\"    nsi_shadow contains frag end only => save it and go to next fragment\")\n                elif nsi_shadow.begin > frag.end:\n                    #\n                    #      *************** nsi shadow\n                    #      | *********** | nsi\n                    # **X  |             | frag (X=frag.end)\n                    #\n                    frag_index += 1\n                    self.log(u\"    nsi_shadow begins after frag end => skip to next fragment\")\n                else:\n                    #\n                    #       ***************    nsi shadow\n                    #       | *********** |    nsi\n                    #       |        *****|**X frag (X=frag.end)\n                    #\n                    nsi_index += 1\n                    self.log(u\"    nsi_shadow ends before frag end => skip to next nsi\")\n            else:\n                self.log(u\"    Fragment is HEAD or TAIL => skipping it\")\n                frag_index += 1\n            self.log(u\"\")\n        tbr = [(n, c[0]) for (n, c) in nsi_counter if len(c) == 1]\n        self.log([u\"Returning: %s\", tbr])\n        return tbr", "response": "Return a list of pairs that contain exactly one fragment ending inside a given nonspeech interval."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninjecting the long nonspeech fragments corresponding to the given intervals .", "response": "def inject_long_nonspeech_fragments(self, pairs, replacement_string):\n        \"\"\"\n        Inject nonspeech fragments corresponding to the given intervals\n        in this fragment list.\n\n        It is assumed that ``pairs`` are consistent, e.g. they are produced\n        by ``fragments_ending_inside_nonspeech_intervals``.\n\n        :param list pairs: list of ``(TimeInterval, int)`` pairs,\n                           each identifying a nonspeech interval and\n                           the corresponding fragment index ending inside it\n        :param string replacement_string: the string to be applied to the nonspeech intervals\n        \"\"\"\n        self.log(u\"Called inject_long_nonspeech_fragments\")\n        # set the appropriate fragment text\n        if replacement_string in [None, gc.PPV_TASK_ADJUST_BOUNDARY_NONSPEECH_REMOVE]:\n            self.log(u\"  Remove long nonspeech\")\n            lines = []\n        else:\n            self.log([u\"  Replace long nonspeech with '%s'\", replacement_string])\n            lines = [replacement_string]\n        # first, make room for the nonspeech intervals\n        self.log(u\"  First pass: making room...\")\n        for nsi, index in pairs:\n            self[index].interval.end = nsi.begin\n            self[index + 1].interval.begin = nsi.end\n        self.log(u\"  First pass: making room... done\")\n        self.log(u\"  Second pass: append nonspeech intervals...\")\n        for i, (nsi, index) in enumerate(pairs, 1):\n            identifier = u\"n%06d\" % i\n            self.add(SyncMapFragment(\n                text_fragment=TextFragment(\n                    identifier=identifier,\n                    language=None,\n                    lines=lines,\n                    filtered_lines=lines\n                ),\n                interval=nsi,\n                fragment_type=SyncMapFragment.NONSPEECH\n            ), sort=False)\n        self.log(u\"  Second pass: append nonspeech intervals... done\")\n        self.log(u\"  Third pass: sorting...\")\n        self.sort()\n        self.log(u\"  Third pass: sorting... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfixes the zero length fragments in the list to have length duration.", "response": "def fix_zero_length_fragments(self, duration=TimeValue(\"0.001\"), min_index=None, max_index=None, ensure_adjacent=True):\n        \"\"\"\n        Fix fragments with zero length,\n        enlarging them to have length ``duration``,\n        reclaiming the difference from the next fragment(s),\n        or moving the next fragment(s) forward.\n\n        This function assumes the fragments to be adjacent.\n\n        :param duration: set the zero length fragments to have this duration\n        :type  duration: :class:`~aeneas.exacttiming.TimeValue`\n        :param int min_index: examine fragments with index greater than or equal to this index (i.e., included)\n        :param int max_index: examine fragments with index smaller than this index (i.e., excluded)\n        :raises ValueError: if ``min_index`` is negative or ``max_index``\n                            is bigger than the current number of fragments\n        \"\"\"\n        self.log(u\"Called fix_zero_length_fragments\")\n        self.log([u\"  Duration %.3f\", duration])\n        min_index, max_index = self._check_min_max_indices(min_index, max_index)\n        if len(self) < 1:\n            self.log(u\"The list has no fragments: returning\")\n            return\n        if not self.has_adjacent_fragments_only(min_index, max_index):\n            self.log_warn(u\"There are non adjacent fragments: aborting\")\n            return\n        original_first_begin = None\n        if (\n                (ensure_adjacent) and\n                (min_index > 0) and\n                (self[min_index - 1].interval.is_adjacent_before(self[min_index].interval))\n        ):\n            original_first_begin = self[min_index].begin\n            self.log([u\"Original first was adjacent with previous, starting at %.3f\", original_first_begin])\n        original_last_end = None\n        if (\n                (ensure_adjacent) and\n                (len(self) > 1) and\n                (max_index < len(self)) and\n                (self[max_index - 1].interval.is_adjacent_before(self[max_index].interval))\n        ):\n            original_last_end = self[max_index - 1].end\n            self.log([u\"Original last was adjacent with next, ending at %.3f\", original_last_end])\n        i = min_index\n        while i < max_index:\n            if self[i].has_zero_length:\n                self.log([u\"  Fragment %d (%s) has zero length => ENLARGE\", i, self[i].interval])\n                moves = [(i, \"ENLARGE\", duration)]\n                slack = duration\n                j = i + 1\n                self.log([u\"  Entered while with j == %d\", j])\n                while (j < max_index) and (self[j].interval.length < slack):\n                    if self[j].has_zero_length:\n                        self.log([u\"  Fragment %d (%s) has zero length => ENLARGE\", j, self[j].interval])\n                        moves.append((j, \"ENLARGE\", duration))\n                        slack += duration\n                    else:\n                        self.log([u\"  Fragment %d (%s) has non zero length => MOVE\", j, self[j].interval])\n                        moves.append((j, \"MOVE\", None))\n                    j += 1\n                self.log([u\"  Exited while with j == %d\", j])\n                fixable = False\n                if (j == max_index) and (self[j - 1].interval.end + slack <= self.end):\n                    self.log(u\"  Fixable by moving back\")\n                    current_time = self[j - 1].interval.end + slack\n                    fixable = True\n                elif j < max_index:\n                    self.log(u\"  Fixable by shrinking\")\n                    self[j].interval.shrink(slack)\n                    current_time = self[j].interval.begin\n                    fixable = True\n                if fixable:\n                    for index, move_type, move_amount in moves[::-1]:\n                        self.log([u\"    Calling move_end_at with %.3f at index %d\", current_time, index])\n                        self[index].interval.move_end_at(current_time)\n                        if move_type == \"ENLARGE\":\n                            self.log([u\"    Calling enlarge with %.3f at index %d\", move_amount, index])\n                            self[index].interval.enlarge(move_amount)\n                        self.log([u\"    Interval %d is now: %s\", index, self[index].interval])\n                        current_time = self[index].interval.begin\n                else:\n                    self.log([u\"Unable to fix fragment %d (%s)\", i, self[i].interval])\n                i = j - 1\n            i += 1\n        if original_first_begin is not None:\n            if self[min_index].begin != self[min_index - 1].end:\n                self.log(u\"First fragment begin moved, restoring adjacency\")\n                self.log([u\"  Original was %.3f\", original_first_begin])\n                self.log([u\"  New      is  %.3f\", self[min_index - 1].end])\n                self[min_index].begin = self[min_index - 1].end\n        if original_last_end is not None:\n            if self[max_index].begin != self[max_index - 1].end:\n                self.log(u\"Last fragment end moved, restoring adjacency\")\n                self.log([u\"  Original was %.3f\", original_last_end])\n                self.log([u\"  New      is  %.3f\", self[max_index].begin])\n                self[max_index].begin = self[max_index - 1].end\n        self.log(u\"Fragments after fixing:\")\n        for i, fragment in enumerate(self):\n            self.log([u\"  %d => %.3f %.3f\", i, fragment.interval.begin, fragment.interval.end])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the accumulated cost matrix and return it.", "response": "def compute_accumulated_cost_matrix(self):\n        \"\"\"\n        Compute the accumulated cost matrix, and return it.\n\n        Return ``None`` if the accumulated cost matrix cannot be computed\n        because one of the two waves is empty after masking (if requested).\n\n        :rtype: :class:`numpy.ndarray` (2D)\n        :raises: RuntimeError: if both the C extension and\n                               the pure Python code did not succeed.\n\n        .. versionadded:: 1.2.0\n        \"\"\"\n        self._setup_dtw()\n        if self.dtw is None:\n            self.log(u\"Inner self.dtw is None => returning None\")\n            return None\n        self.log(u\"Returning accumulated cost matrix\")\n        return self.dtw.compute_accumulated_cost_matrix()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the min cost path between the two waves and return it.", "response": "def compute_path(self):\n        \"\"\"\n        Compute the min cost path between the two waves, and return it.\n\n        Return the computed path as a tuple with two elements,\n        each being a :class:`numpy.ndarray` (1D) of ``int`` indices: ::\n\n        ([r_1, r_2, ..., r_k], [s_1, s_2, ..., s_k])\n\n        where ``r_i`` are the indices in the real wave\n        and ``s_i`` are the indices in the synthesized wave,\n        and ``k`` is the length of the min cost path.\n\n        Return ``None`` if the accumulated cost matrix cannot be computed\n        because one of the two waves is empty after masking (if requested).\n\n        :rtype: tuple (see above)\n        :raises: RuntimeError: if both the C extension and\n                               the pure Python code did not succeed.\n        \"\"\"\n        self._setup_dtw()\n        if self.dtw is None:\n            self.log(u\"Inner self.dtw is None => returning None\")\n            return None\n        self.log(u\"Computing path...\")\n        wave_path = self.dtw.compute_path()\n        self.log(u\"Computing path... done\")\n        self.log(u\"Translating path to full wave indices...\")\n        real_indices = numpy.array([t[0] for t in wave_path])\n        synt_indices = numpy.array([t[1] for t in wave_path])\n        if self.rconf.mmn:\n            self.log(u\"Translating real indices with masked_middle_map...\")\n            real_indices = self.real_wave_mfcc.masked_middle_map[real_indices]\n            real_indices[0] = self.real_wave_mfcc.head_length\n            self.log(u\"Translating real indices with masked_middle_map... done\")\n            self.log(u\"Translating synt indices with masked_middle_map...\")\n            synt_indices = self.synt_wave_mfcc.masked_middle_map[synt_indices]\n            self.log(u\"Translating synt indices with masked_middle_map... done\")\n        else:\n            self.log(u\"Translating real indices by adding head_length...\")\n            real_indices += self.real_wave_mfcc.head_length\n            self.log(u\"Translating real indices by adding head_length... done\")\n            self.log(u\"Nothing to do with synt indices\")\n        self.log(u\"Translating path to full wave indices... done\")\n        return (real_indices, synt_indices)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the minimum cost path between two waves and return a list of boundary points representing the argmin values with respect to the synt_anchors timings.", "response": "def compute_boundaries(self, synt_anchors):\n        \"\"\"\n        Compute the min cost path between the two waves,\n        and return a list of boundary points,\n        representing the argmin values with respect to\n        the provided ``synt_anchors`` timings.\n\n        If ``synt_anchors`` has ``k`` elements,\n        the returned array will have ``k+1`` elements,\n        accounting for the tail fragment.\n\n        :param synt_anchors: the anchor time values (in seconds) of the synthesized fragments,\n                             each representing the begin time in the synthesized wave\n                             of the corresponding fragment\n        :type  synt_anchors: list of :class:`~aeneas.exacttiming.TimeValue`\n\n        Return the list of boundary indices.\n\n        :rtype: :class:`numpy.ndarray` (1D)\n        \"\"\"\n        self._setup_dtw()\n        if self.dtw is None:\n            self.log(u\"Inner self.dtw is None => returning artificial boundary indices\")\n            begin = self.real_wave_mfcc.middle_begin\n            end = self.real_wave_mfcc.tail_begin\n            n = len(synt_anchors)\n            step = float(end - begin) / n\n            boundary_indices = [begin + int(i * step) for i in range(n)] + [end]\n            return numpy.array(boundary_indices)\n\n        self.log(u\"Computing path...\")\n        real_indices, synt_indices = self.compute_path()\n        self.log(u\"Computing path... done\")\n\n        self.log(u\"Computing boundary indices...\")\n        # both real_indices and synt_indices are w.r.t. the full wave\n        self.log([u\"Fragments:        %d\", len(synt_anchors)])\n        self.log([u\"Path length:      %d\", len(real_indices)])\n        # synt_anchors as in seconds, convert them in MFCC indices\n        # see also issue #102\n        mws = self.rconf.mws\n        sample_rate = self.rconf.sample_rate\n        samples_per_mws = mws * sample_rate\n        if samples_per_mws.is_integer:\n            anchor_indices = numpy.array([int(a[0] / mws) for a in synt_anchors])\n        else:\n            #\n            # NOTE this is not elegant, but it saves the day for the user\n            #\n            self.log_warn(u\"The number of samples in each window shift is not an integer, time drift might occur.\")\n            anchor_indices = numpy.array([(int(a[0] * sample_rate / mws) / sample_rate) for a in synt_anchors])\n        #\n        # right side sets the split point at the very beginning of \"next\" fragment\n        #\n        # NOTE clip() is needed since searchsorted() with side=\"right\" might return\n        #      an index == len(synt_indices) == len(real_indices)\n        #      when the insertion point is past the last element of synt_indices\n        #      causing the fancy indexing real_indices[...] below might fail\n        begin_indices = numpy.clip(numpy.searchsorted(synt_indices, anchor_indices, side=\"right\"), 0, len(synt_indices) - 1)\n        # first split must occur at zero\n        begin_indices[0] = 0\n        #\n        # map onto real indices, obtaining \"default\" boundary indices\n        #\n        # NOTE since len(synt_indices) == len(real_indices)\n        #      and because the numpy.clip() above, the fancy indexing is always valid\n        #\n        boundary_indices = numpy.append(real_indices[begin_indices], self.real_wave_mfcc.tail_begin)\n        self.log([u\"Boundary indices: %d\", len(boundary_indices)])\n        self.log(u\"Computing boundary indices... done\")\n        return boundary_indices"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setup_dtw(self):\n        # check if the DTW object has already been set up\n        if self.dtw is not None:\n            return\n\n        # check we have the AudioFileMFCC objects\n        if (self.real_wave_mfcc is None) or (self.real_wave_mfcc.middle_mfcc is None):\n            self.log_exc(u\"The real wave MFCCs are not initialized\", None, True, DTWAlignerNotInitialized)\n        if (self.synt_wave_mfcc is None) or (self.synt_wave_mfcc.middle_mfcc is None):\n            self.log_exc(u\"The synt wave MFCCs are not initialized\", None, True, DTWAlignerNotInitialized)\n\n        # setup\n        algorithm = self.rconf[RuntimeConfiguration.DTW_ALGORITHM]\n        delta = int(2 * self.rconf.dtw_margin / self.rconf[RuntimeConfiguration.MFCC_WINDOW_SHIFT])\n        mfcc2_length = self.synt_wave_mfcc.middle_length\n        self.log([u\"Requested algorithm: '%s'\", algorithm])\n        self.log([u\"delta = %d\", delta])\n        self.log([u\"m = %d\", mfcc2_length])\n        # check if delta is >= length of synt wave\n        if mfcc2_length <= delta:\n            self.log(u\"We have mfcc2_length <= delta\")\n            if (self.rconf[RuntimeConfiguration.C_EXTENSIONS]) and (gf.can_run_c_extension()):\n                # the C code can be run: since it is still faster, do not run EXACT\n                self.log(u\"C extensions enabled and loaded: not selecting EXACT algorithm\")\n            else:\n                self.log(u\"Selecting EXACT algorithm\")\n                algorithm = DTWAlgorithm.EXACT\n\n        # select mask here\n        if self.rconf.mmn:\n            self.log(u\"Using masked MFCC\")\n            real_mfcc = self.real_wave_mfcc.masked_middle_mfcc\n            synt_mfcc = self.synt_wave_mfcc.masked_middle_mfcc\n        else:\n            self.log(u\"Using unmasked MFCC\")\n            real_mfcc = self.real_wave_mfcc.middle_mfcc\n            synt_mfcc = self.synt_wave_mfcc.middle_mfcc\n        n = real_mfcc.shape[1]\n        m = synt_mfcc.shape[1]\n        self.log([u\"  Number of MFCC frames in real wave: %d\", n])\n        self.log([u\"  Number of MFCC frames in synt wave: %d\", m])\n        if (n == 0) or (m == 0):\n            self.log(u\"Setting self.dtw to None\")\n            self.dtw = None\n        else:\n            # set the selected algorithm\n            if algorithm == DTWAlgorithm.EXACT:\n                self.log(u\"Computing with EXACT algo\")\n                self.dtw = DTWExact(\n                    m1=real_mfcc,\n                    m2=synt_mfcc,\n                    rconf=self.rconf,\n                    logger=self.logger\n                )\n            else:\n                self.log(u\"Computing with STRIPE algo\")\n                self.dtw = DTWStripe(\n                    m1=real_mfcc,\n                    m2=synt_mfcc,\n                    delta=delta,\n                    rconf=self.rconf,\n                    logger=self.logger\n                )", "response": "Setup the DTW object up."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 4:\n            return self.print_help()\n        text_format = gf.safe_unicode(self.actual_arguments[0])\n        if text_format == u\"list\":\n            text = gf.safe_unicode(self.actual_arguments[1])\n        elif text_format in TextFileFormat.ALLOWED_VALUES:\n            text = self.actual_arguments[1]\n            if not self.check_input_file(text):\n                return self.ERROR_EXIT_CODE\n        else:\n            return self.print_help()\n\n        l1_id_regex = self.has_option_with_value(u\"--l1-id-regex\")\n        l2_id_regex = self.has_option_with_value(u\"--l2-id-regex\")\n        l3_id_regex = self.has_option_with_value(u\"--l3-id-regex\")\n        id_regex = self.has_option_with_value(u\"--id-regex\")\n        class_regex = self.has_option_with_value(u\"--class-regex\")\n        sort = self.has_option_with_value(u\"--sort\")\n        backwards = self.has_option([u\"-b\", u\"--backwards\"])\n        quit_after = gf.safe_float(self.has_option_with_value(u\"--quit-after\"), None)\n        start_fragment = gf.safe_int(self.has_option_with_value(u\"--start\"), None)\n        end_fragment = gf.safe_int(self.has_option_with_value(u\"--end\"), None)\n        parameters = {\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L1_ID_REGEX: l1_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L2_ID_REGEX: l2_id_regex,\n            gc.PPN_TASK_IS_TEXT_MUNPARSED_L3_ID_REGEX: l3_id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_CLASS_REGEX: class_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_REGEX: id_regex,\n            gc.PPN_TASK_IS_TEXT_UNPARSED_ID_SORT: sort,\n        }\n        if (text_format == TextFileFormat.MUNPARSED) and ((l1_id_regex is None) or (l2_id_regex is None) or (l3_id_regex is None)):\n            self.print_error(u\"You must specify --l1-id-regex and --l2-id-regex and --l3-id-regex for munparsed format\")\n            return self.ERROR_EXIT_CODE\n        if (text_format == TextFileFormat.UNPARSED) and (id_regex is None) and (class_regex is None):\n            self.print_error(u\"You must specify --id-regex and/or --class-regex for unparsed format\")\n            return self.ERROR_EXIT_CODE\n\n        language = gf.safe_unicode(self.actual_arguments[2])\n\n        output_file_path = self.actual_arguments[3]\n        if not self.check_output_file(output_file_path):\n            return self.ERROR_EXIT_CODE\n\n        text_file = self.get_text_file(text_format, text, parameters)\n        if text_file is None:\n            self.print_error(u\"Unable to build a TextFile from the given parameters\")\n            return self.ERROR_EXIT_CODE\n        elif len(text_file) == 0:\n            self.print_error(u\"No text fragments found\")\n            return self.ERROR_EXIT_CODE\n        text_file.set_language(language)\n        self.print_info(u\"Read input text with %d fragments\" % (len(text_file)))\n        if start_fragment is not None:\n            self.print_info(u\"Slicing from index %d\" % (start_fragment))\n        if end_fragment is not None:\n            self.print_info(u\"Slicing to index %d\" % (end_fragment))\n        text_slice = text_file.get_slice(start_fragment, end_fragment)\n        self.print_info(u\"Synthesizing %d fragments\" % (len(text_slice)))\n\n        if quit_after is not None:\n            self.print_info(u\"Stop synthesizing upon reaching %.3f seconds\" % (quit_after))\n\n        try:\n            synt = Synthesizer(rconf=self.rconf, logger=self.logger)\n            synt.synthesize(\n                text_slice,\n                output_file_path,\n                quit_after=quit_after,\n                backwards=backwards\n            )\n            self.print_success(u\"Created file '%s'\" % output_file_path)\n            synt.clear_cache()\n            return self.NO_ERROR_EXIT_CODE\n        except ImportError as exc:\n            tts = self.rconf[RuntimeConfiguration.TTS]\n            if tts == Synthesizer.AWS:\n                self.print_error(u\"You need to install Python module boto3 to use the AWS Polly TTS API wrapper. Run:\")\n                self.print_error(u\"$ pip install boto3\")\n                self.print_error(u\"or, to install for all users:\")\n                self.print_error(u\"$ sudo pip install boto3\")\n            elif tts == Synthesizer.NUANCE:\n                self.print_error(u\"You need to install Python module requests to use the Nuance TTS API wrapper. Run:\")\n                self.print_error(u\"$ pip install requests\")\n                self.print_error(u\"or, to install for all users:\")\n                self.print_error(u\"$ sudo pip install requests\")\n            else:\n                self.print_error(u\"An unexpected error occurred while synthesizing text:\")\n                self.print_error(u\"%s\" % exc)\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while synthesizing text:\")\n            self.print_error(u\"%s\" % exc)\n\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint an error message.", "response": "def print_error(msg):\n    \"\"\" Print an error message \"\"\"\n    if IS_POSIX:\n        print(u\"%s[ERRO] %s%s\" % (ANSI_ERROR, msg, ANSI_END))\n    else:\n        print(u\"[ERRO] %s\" % (msg))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_success(msg):\n    if IS_POSIX:\n        print(u\"%s[INFO] %s%s\" % (ANSI_OK, msg, ANSI_END))\n    else:\n        print(u\"[INFO] %s\" % (msg))", "response": "Print a warning message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_warning(msg):\n    if IS_POSIX:\n        print(u\"%s[WARN] %s%s\" % (ANSI_WARNING, msg, ANSI_END))\n    else:\n        print(u\"[WARN] %s\" % (msg))", "response": "Print a warning message."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to import the aeneas Python package and return True if that fails.", "response": "def check_import():\n    \"\"\"\n    Try to import the aeneas package and return ``True`` if that fails.\n    \"\"\"\n    try:\n        import aeneas\n        print_success(u\"aeneas         OK\")\n        return False\n    except ImportError:\n        print_error(u\"aeneas         ERROR\")\n        print_info(u\"  Unable to load the aeneas Python package\")\n        print_info(u\"  This error is probably caused by:\")\n        print_info(u\"    A. you did not download/git-clone the aeneas package properly; or\")\n        print_info(u\"    B. you did not install the required Python packages:\")\n        print_info(u\"      1. BeautifulSoup4\")\n        print_info(u\"      2. lxml\")\n        print_info(u\"      3. numpy\")\n    except Exception as e:\n        print_error(e)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_pleasant(self):\n        levels = sorted([n.level for n in self.leaves])\n        return levels[0] == levels[-1]", "response": "Return True if all the leaves in this node are at the same level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a child to the current node s children list.", "response": "def add_child(self, node, as_last=True):\n        \"\"\"\n        Add the given child to the current list of children.\n\n        The new child is appended as the last child if ``as_last``\n        is ``True``, or as the first child if ``as_last`` is ``False``.\n\n        This call updates the ``__parent`` and ``__level`` fields of ``node``.\n\n        :param node: the child node to be added\n        :type  node: :class:`~aeneas.tree.Tree`\n        :param bool as_last: if ``True``, append the node as the last child;\n                             if ``False``, append the node as the first child\n        :raises: TypeError if ``node`` is not an instance of :class:`~aeneas.tree.Tree`\n        \"\"\"\n        if not isinstance(node, Tree):\n            self.log_exc(u\"node is not an instance of Tree\", None, True, TypeError)\n        if as_last:\n            self.__children.append(node)\n        else:\n            self.__children = [node] + self.__children\n        node.__parent = self\n        new_height = 1 + self.level\n        for n in node.subtree:\n            n.__level += new_height"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_child(self, index):\n        if index < 0:\n            index = index + len(self)\n        self.__children = self.__children[0:index] + self.__children[(index + 1):]", "response": "Removes the child at the given index from the current list of children."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self):\n        if self.parent is not None:\n            for i, child in enumerate(self.parent.children):\n                if id(child) == id(self):\n                    self.parent.remove_child(i)\n                    self.parent = None\n                    break", "response": "Removes this node from the list of children of its current parent."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_children(self, reset_parent=True):\n        if reset_parent:\n            for child in self.children:\n                child.parent = None\n        self.__children = []", "response": "Removes all the children of this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of leaves not empty in the tree rooted at this node in DFS order.", "response": "def leaves_not_empty(self):\n        \"\"\"\n        Return the list of leaves not empty\n        in the tree rooted at this node,\n        in DFS order.\n\n        :rtype: list of :class:`~aeneas.tree.Tree`\n        \"\"\"\n        return [n for n in self.dfs if ((n.is_leaf) and (not n.is_empty))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef height(self):\n        return max([n.level for n in self.subtree]) - self.level + 1", "response": "Return the height of the tree at this node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dfs(self):\n        for node in self.children:\n            for v in node.dfs:\n                yield v\n        yield self", "response": "Depth - first search of the tree rooted at this node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pre(self):\n        yield self\n        for node in self.children:\n            for v in node.pre:\n                yield v", "response": "Iterate over the pre - order tree rooted at this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef levels(self):\n        ret = [[] for i in range(self.height)]\n        for node in self.subtree:\n            ret[node.level - self.level].append(node)\n        return ret", "response": "Return a list of lists of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of nodes at the given index.", "response": "def level_at_index(self, index):\n        \"\"\"\n        Return the list of nodes at level ``index``,\n        in DFS order.\n\n        :param int index: the index\n        :rtype: list of :class:`~aeneas.tree.Tree`\n\n        :raises: ValueError if the given ``index`` is not valid\n        \"\"\"\n        if not isinstance(index, int):\n            self.log_exc(u\"Index is not an integer\", None, True, TypeError)\n        levels = self.levels\n        if (index < 0) or (index >= len(levels)):\n            self.log_exc(u\"The given level index '%d' is not valid\" % (index), None, True, ValueError)\n        return self.levels[index]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ancestor(self, index):\n        if not isinstance(index, int):\n            self.log_exc(u\"index is not an integer\", None, True, TypeError)\n        if index < 0:\n            self.log_exc(u\"index cannot be negative\", None, True, ValueError)\n        parent_node = self\n        for i in range(index):\n            if parent_node is None:\n                break\n            parent_node = parent_node.parent\n        return parent_node", "response": "Return the index - th ancestor of the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keep_levels(self, level_indices):\n        if not isinstance(level_indices, list):\n            self.log_exc(u\"level_indices is not an instance of list\", None, True, TypeError)\n        for l in level_indices:\n            if not isinstance(l, int):\n                self.log_exc(u\"level_indices contains an element not int\", None, True, TypeError)\n        prev_levels = self.levels\n        level_indices = set(level_indices)\n        if 0 not in level_indices:\n            level_indices.add(0)\n        level_indices = level_indices & set(range(self.height))\n        level_indices = sorted(level_indices)[::-1]\n        # first, remove children\n        for l in level_indices:\n            for node in prev_levels[l]:\n                node.remove_children(reset_parent=False)\n        # then, connect to the right new parent\n        for i in range(len(level_indices) - 1):\n            l = level_indices[i]\n            for node in prev_levels[l]:\n                parent_node = node.ancestor(l - level_indices[i + 1])\n                parent_node.add_child(node)", "response": "Rearrange the tree rooted at this node to keep only the given levels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the legacy not - quite - DCT matrix used by Sphinx", "response": "def s2dctmat(nfilt,ncep,freqstep):\n    \"\"\"Return the 'legacy' not-quite-DCT matrix used by Sphinx\"\"\"\n    melcos = numpy.empty((ncep, nfilt), 'double')\n    for i in range(0,ncep):\n        freq = numpy.pi * float(i) / nfilt\n        melcos[i] = numpy.cos(freq * numpy.arange(0.5, float(nfilt)+0.5, 1.0, 'double'))\n    melcos[:,0] = melcos[:,0] * 0.5\n    return melcos"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logspec2s2mfc(logspec, ncep=13):\n    nframes, nfilt = logspec.shape\n    melcos = s2dctmat(nfilt, ncep, 1./nfilt)\n    return numpy.dot(logspec, melcos.T) / nfilt", "response": "Convert log - power - spectrum bins to MFCC using the legacy Sphinx transform"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the orthogonal DCT - II matrix of size NxK.", "response": "def dctmat(N,K,freqstep,orthogonalize=True):\n    \"\"\"Return the orthogonal DCT-II/DCT-III matrix of size NxK.\n    For computing or inverting MFCCs, N is the number of\n    log-power-spectrum bins while K is the number of cepstra.\"\"\"\n    cosmat = numpy.zeros((N, K), 'double')\n    for n in range(0,N):\n        for k in range(0, K):\n            cosmat[n,k] = numpy.cos(freqstep * (n + 0.5) * k)\n    if orthogonalize:\n        cosmat[:,0] = cosmat[:,0] * 1./numpy.sqrt(2)\n    return cosmat"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dct(input, K=13):\n    nframes, N = input.shape\n    freqstep = numpy.pi / N\n    cosmat = dctmat(N,K,freqstep)\n    return numpy.dot(input, cosmat) * numpy.sqrt(2.0 / N)", "response": "Convert a log - power - spectrum to MFCC using the orthogonal DCT - II"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts log - power - spectrum to MFCC using the normalized DCT - II", "response": "def dct2(input, K=13):\n    \"\"\"Convert log-power-spectrum to MFCC using the normalized DCT-II\"\"\"\n    nframes, N = input.shape\n    freqstep = numpy.pi / N\n    cosmat = dctmat(N,K,freqstep,False)\n    return numpy.dot(input, cosmat) * (2.0 / N)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform_command(self):\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        input_file_path = self.actual_arguments[0]\n        output_file_path = self.actual_arguments[1]\n\n        output_text_format = self.has_option_with_value(u\"--format\")\n        if output_text_format is None:\n            output_text_format = u\"%.18e\"\n        output_binary = self.has_option([u\"-b\", u\"--binary\"])\n        output_npz = self.has_option([u\"-z\", u\"--npz\"])\n        output_npy = self.has_option([u\"-n\", u\"--npy\"])\n        delete_first = self.has_option([u\"-d\", u\"--delete-first\"])\n        transpose = self.has_option([u\"-t\", u\"--transpose\"])\n\n        self.check_c_extensions(\"cmfcc\")\n        if not self.check_input_file(input_file_path):\n            return self.ERROR_EXIT_CODE\n        if not self.check_output_file(output_file_path):\n            return self.ERROR_EXIT_CODE\n\n        try:\n            mfccs = AudioFileMFCC(input_file_path, rconf=self.rconf, logger=self.logger).all_mfcc\n            if delete_first:\n                mfccs = mfccs[1:, :]\n            if transpose:\n                mfccs = mfccs.transpose()\n            if output_binary:\n                # save as a raw C float64 binary file\n                mapped = numpy.memmap(output_file_path, dtype=\"float64\", mode=\"w+\", shape=mfccs.shape)\n                mapped[:] = mfccs[:]\n                mapped.flush()\n                del mapped\n            elif output_npz:\n                # save as a .npz compressed binary file\n                with io.open(output_file_path, \"wb\") as output_file:\n                    numpy.savez(output_file, mfccs)\n            elif output_npy:\n                # save as a .npy binary file\n                with io.open(output_file_path, \"wb\") as output_file:\n                    numpy.save(output_file, mfccs)\n            else:\n                # save as a text file\n                # NOTE: in Python 2, passing the fmt value a Unicode string crashes NumPy\n                #       hence, converting back to bytes, which works in Python 3 too\n                numpy.savetxt(output_file_path, mfccs, fmt=gf.safe_bytes(output_text_format))\n            self.print_info(u\"MFCCs shape: %d %d\" % (mfccs.shape))\n            self.print_success(u\"MFCCs saved to '%s'\" % (output_file_path))\n            return self.NO_ERROR_EXIT_CODE\n        except AudioFileConverterError:\n            self.print_error(u\"Unable to call the ffmpeg executable '%s'\" % (self.rconf[RuntimeConfiguration.FFMPEG_PATH]))\n            self.print_error(u\"Make sure the path to ffmpeg is correct\")\n        except (AudioFileUnsupportedFormatError, AudioFileNotInitializedError):\n            self.print_error(u\"Cannot read file '%s'\" % (input_file_path))\n            self.print_error(u\"Check that its format is supported by ffmpeg\")\n        except OSError:\n            self.print_error(u\"Cannot write file '%s'\" % (output_file_path))\n\n        return self.ERROR_EXIT_CODE", "response": "Perform the actual command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef audio_samples(self):\n        if self.__samples is None:\n            if self.file_path is None:\n                self.log_exc(u\"AudioFile object not initialized\", None, True, AudioFileNotInitializedError)\n            else:\n                self.read_samples_from_file()\n        return self.__samples[0:self.__samples_length]", "response": "The audio samples of the audio file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_properties(self):\n        self.log(u\"Reading properties...\")\n\n        # check the file can be read\n        if not gf.file_can_be_read(self.file_path):\n            self.log_exc(u\"File '%s' cannot be read\" % (self.file_path), None, True, OSError)\n\n        # get the file size\n        self.log([u\"Getting file size for '%s'\", self.file_path])\n        self.file_size = gf.file_size(self.file_path)\n        self.log([u\"File size for '%s' is '%d'\", self.file_path, self.file_size])\n\n        # get the audio properties using FFPROBEWrapper\n        try:\n            self.log(u\"Reading properties with FFPROBEWrapper...\")\n            properties = FFPROBEWrapper(\n                rconf=self.rconf,\n                logger=self.logger\n            ).read_properties(self.file_path)\n            self.log(u\"Reading properties with FFPROBEWrapper... done\")\n        except FFPROBEPathError:\n            self.log_exc(u\"Unable to call ffprobe executable\", None, True, AudioFileProbeError)\n        except (FFPROBEUnsupportedFormatError, FFPROBEParsingError):\n            self.log_exc(u\"Audio file format not supported by ffprobe\", None, True, AudioFileUnsupportedFormatError)\n\n        # save relevant properties in results inside the audiofile object\n        self.audio_length = TimeValue(properties[FFPROBEWrapper.STDOUT_DURATION])\n        self.audio_format = properties[FFPROBEWrapper.STDOUT_CODEC_NAME]\n        self.audio_sample_rate = gf.safe_int(properties[FFPROBEWrapper.STDOUT_SAMPLE_RATE])\n        self.audio_channels = gf.safe_int(properties[FFPROBEWrapper.STDOUT_CHANNELS])\n        self.log([u\"Stored audio_length: '%s'\", self.audio_length])\n        self.log([u\"Stored audio_format: '%s'\", self.audio_format])\n        self.log([u\"Stored audio_sample_rate: '%s'\", self.audio_sample_rate])\n        self.log([u\"Stored audio_channels: '%s'\", self.audio_channels])\n        self.log(u\"Reading properties... done\")", "response": "Populate the object by reading the audio properties of the file at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_samples_from_file(self):\n        self.log(u\"Loading audio data...\")\n\n        # check the file can be read\n        if not gf.file_can_be_read(self.file_path):\n            self.log_exc(u\"File '%s' cannot be read\" % (self.file_path), None, True, OSError)\n\n        # determine if we need to convert the audio file\n        convert_audio_file = (\n            (self.file_format is None) or\n            (\n                (self.rconf.safety_checks) and\n                (self.file_format != (\"pcm_s16le\", 1, self.rconf.sample_rate))\n            )\n        )\n\n        # convert the audio file if needed\n        if convert_audio_file:\n            # convert file to PCM16 mono WAVE with correct sample rate\n            self.log(u\"self.file_format is None or not good => converting self.file_path\")\n            tmp_handler, tmp_file_path = gf.tmp_file(suffix=u\".wav\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n            self.log([u\"Temporary PCM16 mono WAVE file: '%s'\", tmp_file_path])\n            try:\n                self.log(u\"Converting audio file to mono...\")\n                converter = FFMPEGWrapper(rconf=self.rconf, logger=self.logger)\n                converter.convert(self.file_path, tmp_file_path)\n                self.file_format = (\"pcm_s16le\", 1, self.rconf.sample_rate)\n                self.log(u\"Converting audio file to mono... done\")\n            except FFMPEGPathError:\n                gf.delete_file(tmp_handler, tmp_file_path)\n                self.log_exc(u\"Unable to call ffmpeg executable\", None, True, AudioFileConverterError)\n            except OSError:\n                gf.delete_file(tmp_handler, tmp_file_path)\n                self.log_exc(u\"Audio file format not supported by ffmpeg\", None, True, AudioFileUnsupportedFormatError)\n        else:\n            # read the file directly\n            if self.rconf.safety_checks:\n                self.log(u\"self.file_format is good => reading self.file_path directly\")\n            else:\n                self.log_warn(u\"Safety checks disabled => reading self.file_path directly\")\n            tmp_handler = None\n            tmp_file_path = self.file_path\n\n        # TODO allow calling C extension cwave to read samples faster\n        try:\n            self.audio_format = \"pcm16\"\n            self.audio_channels = 1\n            self.audio_sample_rate, self.__samples = scipywavread(tmp_file_path)\n            # scipy reads a sample as an int16_t, that is, a number in [-32768, 32767]\n            # so we convert it to a float64 in [-1, 1]\n            self.__samples = self.__samples.astype(\"float64\") / 32768\n            self.__samples_capacity = len(self.__samples)\n            self.__samples_length = self.__samples_capacity\n            self._update_length()\n        except ValueError:\n            self.log_exc(u\"Audio format not supported by scipywavread\", None, True, AudioFileUnsupportedFormatError)\n\n        # if we converted the audio file, delete the temporary converted audio file\n        if convert_audio_file:\n            gf.delete_file(tmp_handler, tmp_file_path)\n            self.log([u\"Deleted temporary audio file: '%s'\", tmp_file_path])\n\n        self._update_length()\n        self.log([u\"Sample length:  %.3f\", self.audio_length])\n        self.log([u\"Sample rate:    %d\", self.audio_sample_rate])\n        self.log([u\"Audio format:   %s\", self.audio_format])\n        self.log([u\"Audio channels: %d\", self.audio_channels])\n        self.log(u\"Loading audio data... done\")", "response": "Load the audio samples from file into memory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef minimize_memory(self):\n        if self.__samples is None:\n            self.log(u\"Not initialized, returning\")\n        else:\n            self.log(u\"Initialized, minimizing memory...\")\n            self.preallocate_memory(self.__samples_length)\n            self.log(u\"Initialized, minimizing memory... done\")", "response": "Reduce the allocated memory to the minimum required for storing the current audio samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_samples(self, samples, reverse=False):\n        self.log(u\"Adding samples...\")\n        samples_length = len(samples)\n        current_length = self.__samples_length\n        future_length = current_length + samples_length\n        if (self.__samples is None) or (self.__samples_capacity < future_length):\n            self.preallocate_memory(2 * future_length)\n        if reverse:\n            self.__samples[current_length:future_length] = samples[::-1]\n        else:\n            self.__samples[current_length:future_length] = samples[:]\n        self.__samples_length = future_length\n        self._update_length()\n        self.log(u\"Adding samples... done\")", "response": "Add the given samples to the current audio data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreverse the audio data.", "response": "def reverse(self):\n        \"\"\"\n        Reverse the audio data.\n\n        :raises: :class:`~aeneas.audiofile.AudioFileNotInitializedError`: if the audio file is not initialized yet\n\n        .. versionadded:: 1.2.0\n        \"\"\"\n        if self.__samples is None:\n            if self.file_path is None:\n                self.log_exc(u\"AudioFile object not initialized\", None, True, AudioFileNotInitializedError)\n            else:\n                self.read_samples_from_file()\n        self.log(u\"Reversing...\")\n        self.__samples[0:self.__samples_length] = numpy.flipud(self.__samples[0:self.__samples_length])\n        self.log(u\"Reversing... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a slice of the audio data of length seconds starting from begin seconds.", "response": "def trim(self, begin=None, length=None):\n        \"\"\"\n        Get a slice of the audio data of ``length`` seconds,\n        starting from ``begin`` seconds.\n\n        If audio data is not loaded, load it and then slice it.\n\n        :param begin: the start position, in seconds\n        :type  begin: :class:`~aeneas.exacttiming.TimeValue`\n        :param length: the  position, in seconds\n        :type  length: :class:`~aeneas.exacttiming.TimeValue`\n        :raises: TypeError: if one of the arguments is not ``None``\n                            or :class:`~aeneas.exacttiming.TimeValue`\n\n        .. versionadded:: 1.2.0\n        \"\"\"\n        for variable, name in [(begin, \"begin\"), (length, \"length\")]:\n            if (variable is not None) and (not isinstance(variable, TimeValue)):\n                raise TypeError(u\"%s is not None or TimeValue\" % name)\n        self.log(u\"Trimming...\")\n        if (begin is None) and (length is None):\n            self.log(u\"begin and length are both None: nothing to do\")\n        else:\n            if begin is None:\n                begin = TimeValue(\"0.000\")\n                self.log([u\"begin was None, now set to %.3f\", begin])\n            begin = min(max(TimeValue(\"0.000\"), begin), self.audio_length)\n            self.log([u\"begin is %.3f\", begin])\n            if length is None:\n                length = self.audio_length - begin\n                self.log([u\"length was None, now set to %.3f\", length])\n            length = min(max(TimeValue(\"0.000\"), length), self.audio_length - begin)\n            self.log([u\"length is %.3f\", length])\n            begin_index = int(begin * self.audio_sample_rate)\n            end_index = int((begin + length) * self.audio_sample_rate)\n            new_idx = end_index - begin_index\n            self.__samples[0:new_idx] = self.__samples[begin_index:end_index]\n            self.__samples_length = new_idx\n            self._update_length()\n        self.log(u\"Trimming... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, file_path):\n        if self.__samples is None:\n            if self.file_path is None:\n                self.log_exc(u\"AudioFile object not initialized\", None, True, AudioFileNotInitializedError)\n            else:\n                self.read_samples_from_file()\n        self.log([u\"Writing audio file '%s'...\", file_path])\n        try:\n            # our value is a float64 in [-1, 1]\n            # scipy writes the sample as an int16_t, that is, a number in [-32768, 32767]\n            data = (self.audio_samples * 32768).astype(\"int16\")\n            scipywavwrite(file_path, self.audio_sample_rate, data)\n        except Exception as exc:\n            self.log_exc(u\"Error writing audio file to '%s'\" % (file_path), exc, True, OSError)\n        self.log([u\"Writing audio file '%s'... done\", file_path])", "response": "Write the audio data to the specified file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_data(self):\n        self.log(u\"Clear audio_data\")\n        self.__samples_capacity = 0\n        self.__samples_length = 0\n        self.__samples = None", "response": "Clear the audio data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_length(self):\n        if (self.audio_sample_rate is not None) and (self.__samples is not None):\n            # NOTE computing TimeValue (... / ...) yields wrong results,\n            #      see issue #168\n            #      self.audio_length = TimeValue(self.__samples_length / self.audio_sample_rate)\n            self.audio_length = TimeValue(self.__samples_length) / TimeValue(self.audio_sample_rate)", "response": "Update the audio length property of the current object based on the length of the current audio data and audio sample rate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef audio_from_youtube(\n            self,\n            source_url,\n            download=True,\n            output_file_path=None,\n            download_format=None,\n            largest_audio=True,\n    ):\n        \"\"\"\n        Download an audio stream from a YouTube video,\n        and save it to file.\n\n        If ``download`` is ``False``, return the list\n        of available audiostreams but do not download.\n\n        Otherwise, download the audio stream best matching\n        the provided parameters, as follows.\n        If ``download_format`` is not ``None``,\n        download the audio stream with the specified format.\n        If ``largest_audio`` is ``True``,\n        download the largest audiostream;\n        otherwise, download the smallest audiostream.\n        If ``preferred_format`` is not ``None``,\n        download the audiostream having that format.\n        The latter option works in combination with ``largest_audio``.\n\n        Return the path of the downloaded file.\n\n        :param string source_url: the URL of the YouTube video\n        :param bool download: if ``True``, download the audio stream\n                              best matching ``preferred_index`` or\n                              ``preferred_format`` and ``largest_audio``;\n                              if ``False``, return the list of available audio streams\n        :param string output_file_path: the path where the downloaded audio should be saved;\n                                        if ``None``, create a temporary file\n        :param int download_format: download the audio stream with the given format\n        :param bool largest_audio: if ``True``, download the largest audio stream available;\n                                   if ``False``, download the smallest one.\n        :rtype: string or list of dict\n        :raises: ImportError: if ``youtube-dl`` is not installed\n        :raises: OSError: if ``output_file_path`` cannot be written\n        :raises: :class:`~aeneas.downloader.DownloadError`: if ``source_url`` is not a valid YouTube URL\n                                                            or it cannot be downloaded e.g. for temporary\n                                                            network issues\n        \"\"\"\n\n        def _list_audiostreams(self, source_url):\n            \"\"\"\n            Return a list of dicts, each describing\n            an available audiostream for the given ``source_url``.\n            \"\"\"\n            self.log(u\"Getting audiostreams...\")\n            audiostreams = []\n            options = {\n                \"download\": False,\n                \"quiet\": True,\n                \"skip_download\": True,\n            }\n            with youtube_dl.YoutubeDL(options) as ydl:\n                info = ydl.extract_info(source_url, download=False)\n                audio_formats = [f for f in info[\"formats\"] if f[\"vcodec\"] == \"none\" and f[\"acodec\"] != \"none\"]\n                for a in audio_formats:\n                    audiostreams.append({\n                        \"format\": a[\"format\"].split(\" \")[0],\n                        \"filesize\": a[\"filesize\"],\n                        \"ext\": a[\"ext\"],\n                        \"abr\": a[\"abr\"]\n                    })\n            self.log(u\"Getting audiostreams... done\")\n            return audiostreams\n\n        def _select_audiostream(self, audiostreams, download_format=None, largest_audio=False):\n            \"\"\"\n            Select the best-matching audiostream:\n            if a ``download_format`` is given, use it,\n            otherwise act according to ``largest_audio``.\n            If ``download_format`` is not matching any\n            of the available audiostreams, then just act\n            according to ``largest_audio``.\n            \"\"\"\n            self.log(u\"Selecting best-matching audiostream...\")\n            selected = None\n            if download_format is not None:\n                matching = [a for a in audiostreams if a[\"format\"] == download_format]\n                if len(matching) > 0:\n                    selected = matching[0]\n            if selected is None:\n                sa = sorted(audiostreams, key=lambda x: x[\"filesize\"])\n                selected = sa[-1] if largest_audio else sa[0]\n            self.log(u\"Selecting best-matching audiostream... done\")\n            return selected\n\n        def _compose_output_file_path(self, extension, output_file_path=None):\n            \"\"\"\n            If ``output_file_path`` is given, use it.\n            Otherwise (``output_file_path`` is ``None``),\n            create a temporary file with the correct extension.\n            \"\"\"\n            self.log(u\"Determining output file path...\")\n            if output_file_path is None:\n                self.log(u\"output_file_path is None: creating temp file\")\n                handler, output_file_path = gf.tmp_file(\n                    root=self.rconf[RuntimeConfiguration.TMP_PATH],\n                    suffix=(\".%s\" % extension)\n                )\n                gf.delete_file(handler, output_file_path)\n            else:\n                self.log(u\"output_file_path is not None: cheking that file can be written\")\n                if not gf.file_can_be_written(output_file_path):\n                    self.log_exc(u\"Path '%s' cannot be written. Wrong permissions?\" % (output_file_path), None, True, OSError)\n            self.log(u\"Determining output file path... done\")\n            self.log([u\"Output file path is '%s'\", output_file_path])\n            return output_file_path\n\n        def _download_audiostream(self, source_url, fmt, output_path):\n            self.log(u\"Downloading audiostream...\")\n            options = {\n                \"download\": True,\n                \"format\": fmt,\n                \"outtmpl\": output_path,\n                \"quiet\": True,\n                \"skip_download\": False,\n            }\n            with youtube_dl.YoutubeDL(options) as ydl:\n                ydl.download([source_url])\n            self.log(u\"Downloading audiostream... done\")\n\n        try:\n            import youtube_dl\n        except ImportError as exc:\n            self.log_exc(u\"Python module youtube-dl is not installed\", exc, True, ImportError)\n\n        # retry parameters\n        sleep_delay = self.rconf[RuntimeConfiguration.DOWNLOADER_SLEEP]\n        attempts = self.rconf[RuntimeConfiguration.DOWNLOADER_RETRY_ATTEMPTS]\n        self.log([u\"Sleep delay:    %.3f\", sleep_delay])\n        self.log([u\"Retry attempts: %d\", attempts])\n\n        # get audiostreams\n        att = attempts\n        while att > 0:\n            self.log(u\"Sleeping to throttle API usage...\")\n            time.sleep(sleep_delay)\n            self.log(u\"Sleeping to throttle API usage... done\")\n            try:\n                audiostreams = _list_audiostreams(self, source_url)\n                break\n            except:\n                self.log_warn(u\"Unable to list audio streams, retry\")\n                att -= 1\n        if att <= 0:\n            self.log_exc(u\"All downloader requests failed: wrong URL or you are offline\", None, True, DownloadError)\n\n        if not download:\n            self.log(u\"Returning list of audiostreams\")\n            return audiostreams\n\n        # download the best-matching audiostream\n        if len(audiostreams) == 0:\n            self.log_exc(u\"No audiostreams available for the provided URL\", None, True, OSError)\n        audiostream = _select_audiostream(self, audiostreams, download_format, largest_audio)\n        output_path = _compose_output_file_path(self, audiostream[\"ext\"], output_file_path)\n        att = attempts\n        while att > 0:\n            self.log(u\"Sleeping to throttle API usage...\")\n            time.sleep(sleep_delay)\n            self.log(u\"Sleeping to throttle API usage... done\")\n            try:\n                _download_audiostream(self, source_url, audiostream[\"format\"], output_path)\n                break\n            except:\n                self.log_warn(u\"Unable to download audio streams, retry\")\n                att -= 1\n        if att <= 0:\n            self.log_exc(u\"All downloader requests failed: wrong URL or you are offline\", None, True, DownloadError)\n\n        return output_path", "response": "Download an audio stream from a YouTube video and save it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef masked_middle_mfcc(self):\n        begin, end = self._masked_middle_begin_end()\n        return (self.masked_mfcc)[:, begin:end]", "response": "Return the MFCC speech frames in the MIDDLE portion of the wave."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the MFCC MIDDLE portion of the wave containing the MFCC FULL frame indices.", "response": "def masked_middle_map(self):\n        \"\"\"\n        Return the map\n        from the MFCC speech frame indices\n        in the MIDDLE portion of the wave\n        to the MFCC FULL frame indices.\n\n        :rtype: :class:`numpy.ndarray` (1D)\n        \"\"\"\n        begin, end = self._masked_middle_begin_end()\n        return self.__mfcc_mask_map[begin:end]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the begin and end indices w. r. t. self. mfcc_mask_map that are masked by MIDDLE_BEGIN and MIDDLE_END.", "response": "def _masked_middle_begin_end(self):\n        \"\"\"\n        Return the begin and end indices w.r.t. ``self.__mfcc_mask_map``,\n        corresponding to indices in the MIDDLE portion of the wave,\n        that is, which fall between ``self.__middle_begin`` and\n        ``self.__middle_end`` in ``self.__mfcc``.\n\n        :rtype: (int, int)\n        \"\"\"\n        self._ensure_mfcc_mask()\n        begin = numpy.searchsorted(self.__mfcc_mask_map, self.__middle_begin, side=\"left\")\n        end = numpy.searchsorted(self.__mfcc_mask_map, self.__middle_end, side=\"right\")\n        return (begin, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef intervals(self, speech=True, time=True):\n        self._ensure_mfcc_mask()\n        if speech:\n            self.log(u\"Converting speech runs to intervals...\")\n            intervals = self.__speech_intervals\n        else:\n            self.log(u\"Converting nonspeech runs to intervals...\")\n            intervals = self.__nonspeech_intervals\n        if time:\n            mws = self.rconf.mws\n            intervals = [TimeInterval(\n                begin=(b * mws),\n                end=((e + 1) * mws)\n            ) for b, e in intervals]\n        self.log(u\"Converting... done\")\n        return intervals", "response": "Return a list of intervals for the current MFCC."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a tuple of tuples representing the nonspeech interval that contains the index.", "response": "def inside_nonspeech(self, index):\n        \"\"\"\n        If ``index`` is contained in a nonspeech interval,\n        return a pair ``(interval_begin, interval_end)``\n        such that ``interval_begin <= index < interval_end``,\n        i.e., ``interval_end`` is assumed not to be included.\n\n        Otherwise, return ``None``.\n\n        :rtype: ``None`` or tuple\n        \"\"\"\n        self._ensure_mfcc_mask()\n        if (index < 0) or (index >= self.all_length) or (self.__mfcc_mask[index]):\n            return None\n        return self._binary_search_intervals(self.__nonspeech_intervals, index)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _binary_search_intervals(cls, intervals, index):\n        start = 0\n        end = len(intervals) - 1\n        while start <= end:\n            middle_index = start + ((end - start) // 2)\n            middle = intervals[middle_index]\n            if (middle[0] <= index) and (index < middle[1]):\n                return middle\n            elif middle[0] > index:\n                end = middle_index - 1\n            else:\n                start = middle_index + 1\n        return None", "response": "Binary search for the intervals containing index assuming there is such an interval."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef middle_begin(self, index):\n        if (index < 0) or (index > self.all_length):\n            raise ValueError(u\"The given index is not valid\")\n        self.__middle_begin = index", "response": "Set the index where MIDDLE starts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the index where MIDDLE ends.", "response": "def middle_end(self, index):\n        \"\"\"\n        Set the index (+1) where MIDDLE ends.\n\n        :param int index: the new index for MIDDLE end\n        \"\"\"\n        if (index < 0) or (index > self.all_length):\n            raise ValueError(u\"The given index is not valid\")\n        self.__middle_end = index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing MFCCs using the Python C extension cmfcc.", "response": "def _compute_mfcc_c_extension(self):\n        \"\"\"\n        Compute MFCCs using the Python C extension cmfcc.\n        \"\"\"\n        self.log(u\"Computing MFCCs using C extension...\")\n        try:\n            self.log(u\"Importing cmfcc...\")\n            import aeneas.cmfcc.cmfcc\n            self.log(u\"Importing cmfcc... done\")\n            self.__mfcc = (aeneas.cmfcc.cmfcc.compute_from_data(\n                self.audio_file.audio_samples,\n                self.audio_file.audio_sample_rate,\n                self.rconf[RuntimeConfiguration.MFCC_FILTERS],\n                self.rconf[RuntimeConfiguration.MFCC_SIZE],\n                self.rconf[RuntimeConfiguration.MFCC_FFT_ORDER],\n                self.rconf[RuntimeConfiguration.MFCC_LOWER_FREQUENCY],\n                self.rconf[RuntimeConfiguration.MFCC_UPPER_FREQUENCY],\n                self.rconf[RuntimeConfiguration.MFCC_EMPHASIS_FACTOR],\n                self.rconf[RuntimeConfiguration.MFCC_WINDOW_LENGTH],\n                self.rconf[RuntimeConfiguration.MFCC_WINDOW_SHIFT]\n            )[0]).transpose()\n            self.log(u\"Computing MFCCs using C extension... done\")\n            return (True, None)\n        except Exception as exc:\n            self.log_exc(u\"An unexpected error occurred while running cmfcc\", exc, False, None)\n        return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compute_mfcc_pure_python(self):\n        self.log(u\"Computing MFCCs using pure Python code...\")\n        try:\n            self.__mfcc = MFCC(\n                rconf=self.rconf,\n                logger=self.logger\n            ).compute_from_data(\n                self.audio_file.audio_samples,\n                self.audio_file.audio_sample_rate\n            ).transpose()\n            self.log(u\"Computing MFCCs using pure Python code... done\")\n            return (True, None)\n        except Exception as exc:\n            self.log_exc(u\"An unexpected error occurred while running pure Python code\", exc, False, None)\n        return (False, None)", "response": "Compute MFCCs using the pure Python code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreverse the audio file.", "response": "def reverse(self):\n        \"\"\"\n        Reverse the audio file.\n\n        The reversing is done efficiently using NumPy views inplace\n        instead of swapping values.\n\n        Only speech and nonspeech intervals are actually recomputed\n        as Python lists.\n        \"\"\"\n        self.log(u\"Reversing...\")\n        all_length = self.all_length\n        self.__mfcc = self.__mfcc[:, ::-1]\n        tmp = self.__middle_end\n        self.__middle_end = all_length - self.__middle_begin\n        self.__middle_begin = all_length - tmp\n        if self.__mfcc_mask is not None:\n            self.__mfcc_mask = self.__mfcc_mask[::-1]\n            # equivalent to\n            # self.__mfcc_mask_map = ((all_length - 1) - self.__mfcc_mask_map)[::-1]\n            # but done in place using NumPy view\n            self.__mfcc_mask_map *= -1\n            self.__mfcc_mask_map += all_length - 1\n            self.__mfcc_mask_map = self.__mfcc_mask_map[::-1]\n            self.__speech_intervals = [(all_length - i[1], all_length - i[0]) for i in self.__speech_intervals[::-1]]\n            self.__nonspeech_intervals = [(all_length - i[1], all_length - i[0]) for i in self.__nonspeech_intervals[::-1]]\n        self.is_reversed = not self.is_reversed\n        self.log(u\"Reversing...done\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine which frames contain speech and nonspeech, and store the resulting boolean mask internally. The four parameters might be ``None``: in this case, the corresponding RuntimeConfiguration values are applied. :param float log_energy_threshold: the minimum log energy threshold to consider a frame as speech :param int min_nonspeech_length: the minimum length, in frames, of a nonspeech interval :param int extend_before: extend each speech interval by this number of frames to the left (before) :param int extend_after: extend each speech interval by this number of frames to the right (after)", "response": "def run_vad(\n        self,\n        log_energy_threshold=None,\n        min_nonspeech_length=None,\n        extend_before=None,\n        extend_after=None\n    ):\n        \"\"\"\n        Determine which frames contain speech and nonspeech,\n        and store the resulting boolean mask internally.\n\n        The four parameters might be ``None``:\n        in this case, the corresponding RuntimeConfiguration values\n        are applied.\n\n        :param float log_energy_threshold: the minimum log energy threshold to consider a frame as speech\n        :param int min_nonspeech_length: the minimum length, in frames, of a nonspeech interval\n        :param int extend_before: extend each speech interval by this number of frames to the left (before)\n        :param int extend_after: extend each speech interval by this number of frames to the right (after)\n        \"\"\"\n        def _compute_runs(array):\n            \"\"\"\n            Compute runs as a list of arrays,\n            each containing the indices of a contiguous run.\n\n            :param array: the data array\n            :type  array: :class:`numpy.ndarray` (1D)\n            :rtype: list of :class:`numpy.ndarray` (1D)\n            \"\"\"\n            if len(array) < 1:\n                return []\n            return numpy.split(array, numpy.where(numpy.diff(array) != 1)[0] + 1)\n        self.log(u\"Creating VAD object\")\n        vad = VAD(rconf=self.rconf, logger=self.logger)\n        self.log(u\"Running VAD...\")\n        self.__mfcc_mask = vad.run_vad(\n            wave_energy=self.__mfcc[0],\n            log_energy_threshold=log_energy_threshold,\n            min_nonspeech_length=min_nonspeech_length,\n            extend_before=extend_before,\n            extend_after=extend_after\n        )\n        self.__mfcc_mask_map = (numpy.where(self.__mfcc_mask))[0]\n        self.log(u\"Running VAD... done\")\n        self.log(u\"Storing speech and nonspeech intervals...\")\n        # where( == True) already computed, reusing\n        # COMMENTED runs = _compute_runs((numpy.where(self.__mfcc_mask))[0])\n        runs = _compute_runs(self.__mfcc_mask_map)\n        self.__speech_intervals = [(r[0], r[-1]) for r in runs]\n        # where( == False) not already computed, computing now\n        runs = _compute_runs((numpy.where(~self.__mfcc_mask))[0])\n        self.__nonspeech_intervals = [(r[0], r[-1]) for r in runs]\n        self.log(u\"Storing speech and nonspeech intervals... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the head middle and tail of the audio file.", "response": "def set_head_middle_tail(self, head_length=None, middle_length=None, tail_length=None):\n        \"\"\"\n        Set the HEAD, MIDDLE, TAIL explicitly.\n\n        If a parameter is ``None``, it will be ignored.\n        If both ``middle_length`` and ``tail_length`` are specified,\n        only ``middle_length`` will be applied.\n\n        :param head_length: the length of HEAD, in seconds\n        :type  head_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param middle_length: the length of MIDDLE, in seconds\n        :type  middle_length: :class:`~aeneas.exacttiming.TimeValue`\n        :param tail_length: the length of TAIL, in seconds\n        :type  tail_length: :class:`~aeneas.exacttiming.TimeValue`\n        :raises: TypeError: if one of the arguments is not ``None``\n                            or :class:`~aeneas.exacttiming.TimeValue`\n        :raises: ValueError: if one of the arguments is greater\n                             than the length of the audio file\n        \"\"\"\n        for variable, name in [\n            (head_length, \"head_length\"),\n            (middle_length, \"middle_length\"),\n            (tail_length, \"tail_length\")\n        ]:\n            if (variable is not None) and (not isinstance(variable, TimeValue)):\n                raise TypeError(u\"%s is not None or TimeValue\" % name)\n            if (variable is not None) and (variable > self.audio_length):\n                raise ValueError(u\"%s is greater than the length of the audio file\" % name)\n        self.log(u\"Setting head middle tail...\")\n        mws = self.rconf.mws\n        self.log([u\"Before: 0 %d %d %d\", self.middle_begin, self.middle_end, self.all_length])\n        if head_length is not None:\n            self.middle_begin = int(head_length / mws)\n        if middle_length is not None:\n            self.middle_end = self.middle_begin + int(middle_length / mws)\n        elif tail_length is not None:\n            self.middle_end = self.all_length - int(tail_length / mws)\n        self.log([u\"After:  0 %d %d %d\", self.middle_begin, self.middle_end, self.all_length])\n        self.log(u\"Setting head middle tail... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of characters in the text fragment.", "response": "def chars(self):\n        \"\"\"\n        Return the number of characters of the text fragment,\n        not including the line separators.\n\n        :rtype: int\n        \"\"\"\n        if self.lines is None:\n            return 0\n        return sum([len(line) for line in self.lines])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the direct not empty children of the root of the fragments tree as TextFile objects.", "response": "def children_not_empty(self):\n        \"\"\"\n        Return the direct not empty children of the root of the fragments tree,\n        as ``TextFile`` objects.\n\n        :rtype: list of :class:`~aeneas.textfile.TextFile`\n        \"\"\"\n        children = []\n        for child_node in self.fragments_tree.children_not_empty:\n            child_text_file = self.get_subtree(child_node)\n            child_text_file.set_language(child_node.value.language)\n            children.append(child_text_file)\n        return children"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef characters(self):\n        chars = 0\n        for fragment in self.fragments:\n            chars += fragment.characters\n        return chars", "response": "Returns the number of characters in this text file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the given text fragment as the first or last child of the root node of the text file tree.", "response": "def add_fragment(self, fragment, as_last=True):\n        \"\"\"\n        Add the given text fragment as the first or last child of the root node\n        of the text file tree.\n\n        :param fragment: the text fragment to be added\n        :type  fragment: :class:`~aeneas.textfile.TextFragment`\n        :param bool as_last: if ``True`` append fragment, otherwise prepend it\n        \"\"\"\n        if not isinstance(fragment, TextFragment):\n            self.log_exc(u\"fragment is not an instance of TextFragment\", None, True, TypeError)\n        self.fragments_tree.add_child(Tree(value=fragment), as_last=as_last)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new : class : ~aeneas. textfile. TextFile object rooted at the given root.", "response": "def get_subtree(self, root):\n        \"\"\"\n        Return a new :class:`~aeneas.textfile.TextFile` object,\n        rooted at the given node ``root``.\n\n        :param root: the root node\n        :type  root: :class:`~aeneas.tree.Tree`\n        :rtype: :class:`~aeneas.textfile.TextFile`\n        \"\"\"\n        if not isinstance(root, Tree):\n            self.log_exc(u\"root is not an instance of Tree\", None, True, TypeError)\n        new_text_file = TextFile()\n        new_text_file.fragments_tree = root\n        return new_text_file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_slice(self, start=None, end=None):\n        if start is not None:\n            start = min(max(0, start), len(self) - 1)\n        else:\n            start = 0\n        if end is not None:\n            end = min(max(0, end), len(self))\n            end = max(end, start + 1)\n        else:\n            end = len(self)\n        new_text = TextFile()\n        for fragment in self.fragments[start:end]:\n            new_text.add_fragment(fragment)\n        return new_text", "response": "Returns a new list of text fragments indexed from start to end."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the given language for all the text fragments.", "response": "def set_language(self, language):\n        \"\"\"\n        Set the given language for all the text fragments.\n\n        :param language: the language of the text fragments\n        :type  language: :class:`~aeneas.language.Language`\n        \"\"\"\n        self.log([u\"Setting language: '%s'\", language])\n        for fragment in self.fragments:\n            fragment.language = language"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread text fragments from a given list of tuples with ids", "response": "def read_from_list_with_ids(self, lines):\n        \"\"\"\n        Read text fragments from a given list of tuples::\n\n            [(id_1, text_1), (id_2, text_2), ..., (id_n, text_n)].\n\n        :param list lines: the list of ``[id, text]`` fragments (see above)\n        \"\"\"\n        self.log(u\"Reading text fragments from list with ids\")\n        self._create_text_fragments([(line[0], [line[1]]) for line in lines])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the text fragments from the file.", "response": "def _read_from_file(self):\n        \"\"\"\n        Read text fragments from file.\n        \"\"\"\n        # test if we can read the given file\n        if not gf.file_can_be_read(self.file_path):\n            self.log_exc(u\"File '%s' cannot be read\" % (self.file_path), None, True, OSError)\n\n        if self.file_format not in TextFileFormat.ALLOWED_VALUES:\n            self.log_exc(u\"Text file format '%s' is not supported.\" % (self.file_format), None, True, ValueError)\n\n        # read the contents of the file\n        self.log([u\"Reading contents of file '%s'\", self.file_path])\n        with io.open(self.file_path, \"r\", encoding=\"utf-8\") as text_file:\n            lines = text_file.readlines()\n\n        # clear text fragments\n        self.clear()\n\n        # parse the contents\n        map_read_function = {\n            TextFileFormat.MPLAIN: self._read_mplain,\n            TextFileFormat.MUNPARSED: self._read_munparsed,\n            TextFileFormat.PARSED: self._read_parsed,\n            TextFileFormat.PLAIN: self._read_plain,\n            TextFileFormat.SUBTITLES: self._read_subtitles,\n            TextFileFormat.UNPARSED: self._read_unparsed\n        }\n        map_read_function[self.file_format](lines)\n\n        # log the number of fragments\n        self.log([u\"Parsed %d fragments\", len(self.fragments)])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mplain_word_separator(self):\n        word_separator = gf.safe_get(self.parameters, gc.PPN_TASK_IS_TEXT_MPLAIN_WORD_SEPARATOR, u\" \")\n        if (word_separator is None) or (word_separator == \"space\"):\n            return u\" \"\n        elif word_separator == \"equal\":\n            return u\"=\"\n        elif word_separator == \"pipe\":\n            return u\"|\"\n        elif word_separator == \"tab\":\n            return u\"\\u0009\"\n        return word_separator", "response": "Returns the word separator to split words in mplain format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_mplain(self, lines):\n        self.log(u\"Parsing fragments from subtitles text format\")\n        word_separator = self._mplain_word_separator()\n        self.log([u\"Word separator is: '%s'\", word_separator])\n        lines = [line.strip() for line in lines]\n        pairs = []\n        i = 1\n        current = 0\n        tree = Tree()\n        while current < len(lines):\n            line_text = lines[current]\n            if len(line_text) > 0:\n                sentences = [line_text]\n                following = current + 1\n                while (following < len(lines)) and (len(lines[following]) > 0):\n                    sentences.append(lines[following])\n                    following += 1\n\n                # here sentences holds the sentences for this paragraph\n\n                # create paragraph node\n                paragraph_identifier = u\"p%06d\" % i\n                paragraph_lines = [u\" \".join(sentences)]\n                paragraph_fragment = TextFragment(\n                    identifier=paragraph_identifier,\n                    lines=paragraph_lines,\n                    filtered_lines=paragraph_lines\n                )\n                paragraph_node = Tree(value=paragraph_fragment)\n                tree.add_child(paragraph_node)\n                self.log([u\"Paragraph %s\", paragraph_identifier])\n\n                # create sentences nodes\n                j = 1\n                for s in sentences:\n                    sentence_identifier = paragraph_identifier + u\"s%06d\" % j\n                    sentence_lines = [s]\n                    sentence_fragment = TextFragment(\n                        identifier=sentence_identifier,\n                        lines=sentence_lines,\n                        filtered_lines=sentence_lines\n                    )\n                    sentence_node = Tree(value=sentence_fragment)\n                    paragraph_node.add_child(sentence_node)\n                    j += 1\n                    self.log([u\"  Sentence %s\", sentence_identifier])\n\n                    # create words nodes\n                    k = 1\n                    for w in [w for w in s.split(word_separator) if len(w) > 0]:\n                        word_identifier = sentence_identifier + u\"w%06d\" % k\n                        word_lines = [w]\n                        word_fragment = TextFragment(\n                            identifier=word_identifier,\n                            lines=word_lines,\n                            filtered_lines=word_lines\n                        )\n                        word_node = Tree(value=word_fragment)\n                        sentence_node.add_child(word_node)\n                        k += 1\n                        self.log([u\"    Word %s\", word_identifier])\n\n                # keep iterating\n                current = following\n                i += 1\n            current += 1\n        self.log(u\"Storing tree\")\n        self.fragments_tree = tree", "response": "Read text fragments from a multilevel format text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads text fragments from an munparsed format text file.", "response": "def _read_munparsed(self, lines):\n        \"\"\"\n        Read text fragments from an munparsed format text file.\n\n        :param list lines: the lines of the unparsed text file\n        \"\"\"\n        from bs4 import BeautifulSoup\n\n        def nodes_at_level(root, level):\n            \"\"\" Return a dict with the bs4 filter parameters \"\"\"\n            LEVEL_TO_REGEX_MAP = [\n                None,\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L1_ID_REGEX,\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L2_ID_REGEX,\n                gc.PPN_TASK_IS_TEXT_MUNPARSED_L3_ID_REGEX,\n            ]\n            attribute_name = \"id\"\n            regex_string = self.parameters[LEVEL_TO_REGEX_MAP[level]]\n            indent = u\" \" * 2 * (level - 1)\n            self.log([u\"%sRegex for %s: '%s'\", indent, attribute_name, regex_string])\n            regex = re.compile(r\".*\\b\" + regex_string + r\"\\b.*\")\n            return root.findAll(attrs={attribute_name: regex})\n        #\n        # TODO better and/or parametric parsing,\n        #      for example, removing tags but keeping text, etc.\n        #\n        self.log(u\"Parsing fragments from munparsed text format\")\n        # transform text in a soup object\n        self.log(u\"Creating soup\")\n        soup = BeautifulSoup(\"\\n\".join(lines), \"lxml\")\n        # extract according to class_regex and id_regex\n        text_from_id = {}\n        ids = []\n        self.log(u\"Finding l1 elements\")\n        tree = Tree()\n        for l1_node in nodes_at_level(soup, 1):\n            has_word = False\n            try:\n                l1_id = gf.safe_unicode(l1_node[\"id\"])\n                self.log([u\"Found l1 node with id:   '%s'\", l1_id])\n                l1_text = []\n                paragraph_node = Tree()\n                paragraph_text = []\n                for l2_node in nodes_at_level(l1_node, 2):\n                    l2_id = gf.safe_unicode(l2_node[\"id\"])\n                    self.log([u\"  Found l2 node with id:   '%s'\", l2_id])\n                    l2_text = []\n                    sentence_node = Tree()\n                    paragraph_node.add_child(sentence_node)\n                    sentence_text = []\n                    for l3_node in nodes_at_level(l2_node, 3):\n                        l3_id = gf.safe_unicode(l3_node[\"id\"])\n                        l3_text = gf.safe_unicode(l3_node.text)\n                        self.log([u\"    Found l3 node with id:   '%s'\", l3_id])\n                        self.log([u\"    Found l3 node with text: '%s'\", l3_text])\n                        word_fragment = TextFragment(\n                            identifier=l3_id,\n                            lines=[l3_text],\n                            filtered_lines=[l3_text]\n                        )\n                        word_node = Tree(value=word_fragment)\n                        sentence_node.add_child(word_node)\n                        sentence_text.append(l3_text)\n                        has_word = True\n                    sentence_text = u\" \".join(sentence_text)\n                    paragraph_text.append(sentence_text)\n                    sentence_node.value = TextFragment(\n                        identifier=l2_id,\n                        lines=[sentence_text],\n                        filtered_lines=[sentence_text]\n                    )\n                    self.log([u\"  Found l2 node with text: '%s'\" % sentence_text])\n                if has_word:\n                    paragraph_text = u\" \".join(paragraph_text)\n                    paragraph_node.value = TextFragment(\n                        identifier=l1_id,\n                        lines=[paragraph_text],\n                        filtered_lines=[paragraph_text]\n                    )\n                    tree.add_child(paragraph_node)\n                    self.log([u\"Found l1 node with text: '%s'\" % paragraph_text])\n                else:\n                    self.log(u\"Found l1 node but it has no words, skipping\")\n            except KeyError:\n                self.log_warn(u\"KeyError while parsing a l1 node\")\n        # append to fragments\n        self.log(u\"Storing tree\")\n        self.fragments_tree = tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_subtitles(self, lines):\n        self.log(u\"Parsing fragments from subtitles text format\")\n        id_format = self._get_id_format()\n        lines = [line.strip() for line in lines]\n        pairs = []\n        i = 1\n        current = 0\n        while current < len(lines):\n            line_text = lines[current]\n            if len(line_text) > 0:\n                fragment_lines = [line_text]\n                following = current + 1\n                while (following < len(lines)) and (len(lines[following]) > 0):\n                    fragment_lines.append(lines[following])\n                    following += 1\n                identifier = id_format % i\n                pairs.append((identifier, fragment_lines))\n                current = following\n                i += 1\n            current += 1\n        self._create_text_fragments(pairs)", "response": "Read text fragments from a subtitles format text file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread text fragments from a parsed format text file.", "response": "def _read_parsed(self, lines):\n        \"\"\"\n        Read text fragments from a parsed format text file.\n\n        :param list lines: the lines of the parsed text file\n        :param dict parameters: additional parameters for parsing\n                                (e.g., class/id regex strings)\n        \"\"\"\n        self.log(u\"Parsing fragments from parsed text format\")\n        pairs = []\n        for line in lines:\n            pieces = line.split(gc.PARSED_TEXT_SEPARATOR)\n            if len(pieces) == 2:\n                identifier = pieces[0].strip()\n                text = pieces[1].strip()\n                if len(identifier) > 0:\n                    pairs.append((identifier, [text]))\n        self._create_text_fragments(pairs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_plain(self, lines):\n        self.log(u\"Parsing fragments from plain text format\")\n        id_format = self._get_id_format()\n        lines = [line.strip() for line in lines]\n        pairs = []\n        i = 1\n        for line in lines:\n            identifier = id_format % i\n            text = line.strip()\n            pairs.append((identifier, [text]))\n            i += 1\n        self._create_text_fragments(pairs)", "response": "Read text fragments from a plain format text file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading text fragments from an unparsed format text file.", "response": "def _read_unparsed(self, lines):\n        \"\"\"\n        Read text fragments from an unparsed format text file.\n\n        :param list lines: the lines of the unparsed text file\n        \"\"\"\n        from bs4 import BeautifulSoup\n\n        def filter_attributes():\n            \"\"\" Return a dict with the bs4 filter parameters \"\"\"\n            attributes = {}\n            for attribute_name, filter_name in [\n                    (\"class\", gc.PPN_TASK_IS_TEXT_UNPARSED_CLASS_REGEX),\n                    (\"id\", gc.PPN_TASK_IS_TEXT_UNPARSED_ID_REGEX)\n            ]:\n                if filter_name in self.parameters:\n                    regex_string = self.parameters[filter_name]\n                    if regex_string is not None:\n                        self.log([u\"Regex for %s: '%s'\", attribute_name, regex_string])\n                        regex = re.compile(r\".*\\b\" + regex_string + r\"\\b.*\")\n                        attributes[attribute_name] = regex\n            return attributes\n        #\n        # TODO better and/or parametric parsing,\n        #      for example, removing tags but keeping text, etc.\n        #\n        self.log(u\"Parsing fragments from unparsed text format\")\n\n        # transform text in a soup object\n        self.log(u\"Creating soup\")\n        soup = BeautifulSoup(\"\\n\".join(lines), \"lxml\")\n\n        # extract according to class_regex and id_regex\n        text_from_id = {}\n        ids = []\n        filter_attributes = filter_attributes()\n        self.log([u\"Finding elements matching attributes '%s'\", filter_attributes])\n        nodes = soup.findAll(attrs=filter_attributes)\n        for node in nodes:\n            try:\n                f_id = gf.safe_unicode(node[\"id\"])\n                f_text = gf.safe_unicode(node.text)\n                text_from_id[f_id] = f_text\n                ids.append(f_id)\n            except KeyError:\n                self.log_warn(u\"KeyError while parsing a node\")\n\n        # sort by ID as requested\n        id_sort = gf.safe_get(\n            dictionary=self.parameters,\n            key=gc.PPN_TASK_IS_TEXT_UNPARSED_ID_SORT,\n            default_value=IDSortingAlgorithm.UNSORTED,\n            can_return_none=False\n        )\n        self.log([u\"Sorting text fragments using '%s'\", id_sort])\n        sorted_ids = IDSortingAlgorithm(id_sort).sort(ids)\n\n        # append to fragments\n        self.log(u\"Appending fragments\")\n        self._create_text_fragments([(key, [text_from_id[key]]) for key in sorted_ids])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the id regex from the parameters", "response": "def _get_id_format(self):\n        \"\"\" Return the id regex from the parameters\"\"\"\n        id_format = gf.safe_get(\n            self.parameters,\n            gc.PPN_TASK_OS_FILE_ID_REGEX,\n            self.DEFAULT_ID_FORMAT,\n            can_return_none=False\n        )\n        try:\n            identifier = id_format % 1\n        except (TypeError, ValueError) as exc:\n            self.log_exc(u\"String '%s' is not a valid id format\" % (id_format), exc, True, ValueError)\n        return id_format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating text fragments and append them to this list.", "response": "def _create_text_fragments(self, pairs):\n        \"\"\"\n        Create text fragment objects and append them to this list.\n\n        :param list pairs: a list of pairs, each pair being (id, [line_1, ..., line_n])\n        \"\"\"\n        self.log(u\"Creating TextFragment objects\")\n        text_filter = self._build_text_filter()\n        for pair in pairs:\n            self.add_fragment(\n                TextFragment(\n                    identifier=pair[0],\n                    lines=pair[1],\n                    filtered_lines=text_filter.apply_filter(pair[1])\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a suitable TextFilter object.", "response": "def _build_text_filter(self):\n        \"\"\"\n        Build a suitable TextFilter object.\n        \"\"\"\n        text_filter = TextFilter(logger=self.logger)\n        self.log(u\"Created TextFilter object\")\n        for key, cls, param_name in [\n                (\n                    gc.PPN_TASK_IS_TEXT_FILE_IGNORE_REGEX,\n                    TextFilterIgnoreRegex,\n                    \"regex\"\n                ),\n                (\n                    gc.PPN_TASK_IS_TEXT_FILE_TRANSLITERATE_MAP,\n                    TextFilterTransliterate,\n                    \"map_file_path\"\n                )\n        ]:\n            cls_name = cls.__name__\n            param_value = gf.safe_get(self.parameters, key, None)\n            if param_value is not None:\n                self.log([u\"Creating %s object...\", cls_name])\n                params = {\n                    param_name: param_value,\n                    \"logger\": self.logger\n                }\n                try:\n                    inner_filter = cls(**params)\n                    text_filter.add_filter(inner_filter)\n                    self.log([u\"Creating %s object... done\", cls_name])\n                except ValueError as exc:\n                    self.log_exc(u\"Creating %s object failed\" % (cls_name), exc, False, None)\n        return text_filter"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompose this filter with the given new_filter.", "response": "def add_filter(self, new_filter, as_last=True):\n        \"\"\"\n        Compose this filter with the given ``new_filter`` filter.\n\n        :param new_filter: the filter to be composed\n        :type  new_filter: :class:`~aeneas.textfile.TextFilter`\n        :param bool as_last: if ``True``, compose to the right, otherwise to the left\n        \"\"\"\n        if as_last:\n            self.filters.append(new_filter)\n        else:\n            self.filters = [new_filter] + self.filters"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies the text filter to the given list of strings.", "response": "def apply_filter(self, strings):\n        \"\"\"\n        Apply the text filter filter to the given list of strings.\n\n        :param list strings: the list of input strings\n        \"\"\"\n        result = strings\n        for filt in self.filters:\n            result = filt.apply_filter(result)\n        self.log([u\"Applying regex: '%s' => '%s'\", strings, result])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying filter to single string", "response": "def _apply_single(self, string):\n        \"\"\" Apply filter to single string \"\"\"\n        if string is None:\n            return None\n        result = self.regex.sub(\"\", string)\n        result = self.SPACES_REGEX.sub(\" \", result).strip()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _apply_single(self, string):\n        if string is None:\n            return None\n        result = self.trans_map.transliterate(string)\n        result = self.SPACES_REGEX.sub(u\" \", result).strip()\n        return result", "response": "Apply filter to single string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_map(self):\n        if gf.is_py2_narrow_build():\n            self.log_warn(u\"Running on a Python 2 narrow build: be aware that Unicode chars above 0x10000 cannot be replaced correctly.\")\n        self.trans_map = {}\n        with io.open(self.file_path, \"r\", encoding=\"utf-8\") as file_obj:\n            contents = file_obj.read().replace(u\"\\t\", u\" \")\n            for line in contents.splitlines():\n                # ignore lines starting with \"#\" or blank (after stripping)\n                if not line.startswith(u\"#\"):\n                    line = line.strip()\n                    if len(line) > 0:\n                        self._process_map_rule(line)", "response": "Read the map file at path and build the trans_map dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_map_rule(self, line):\n        result = self.REPLACE_REGEX.match(line)\n        if result is not None:\n            what = self._process_first_group(result.group(1))\n            replacement = self._process_second_group(result.group(2))\n            for char in what:\n                self.trans_map[char] = replacement\n                self.log([u\"Adding rule: replace '%s' with '%s'\", char, replacement])\n        else:\n            result = self.DELETE_REGEX.match(line)\n            if result is not None:\n                what = self._process_first_group(result.group(1))\n                for char in what:\n                    self.trans_map[char] = \"\"\n                    self.log([u\"Adding rule: delete '%s'\", char])", "response": "Process the line containing a map rule."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the first group of a rule.", "response": "def _process_first_group(self, group):\n        \"\"\"\n        Process the first group of a rule.\n        \"\"\"\n        if \"-\" in group:\n            # range\n            if len(group.split(\"-\")) == 2:\n                arr = group.split(\"-\")\n                start = self._parse_codepoint(arr[0])\n                end = self._parse_codepoint(arr[1])\n        else:\n            # single char/U+xxxx\n            start = self._parse_codepoint(group)\n            end = start\n        result = []\n        if (start > -1) and (end >= start):\n            for index in range(start, end + 1):\n                result.append(gf.safe_unichr(index))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_second_group(self, group):\n        def _replace_codepoint(match):\n            \"\"\"\n            Replace the matched Unicode hex code\n            with the corresponding unicode character\n            \"\"\"\n            result = self._match_to_int(match)\n            if result == -1:\n                return u\"\"\n            return gf.safe_unichr(result)\n        result = group\n        try:\n            result = re.sub(self.CODEPOINT_REGEX, _replace_codepoint, result)\n        except:\n            pass\n        return result", "response": "Process the second group of a replace rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the given string either a Unicode character or U +... or return the corresponding Unicode code point as int.", "response": "def _parse_codepoint(self, string):\n        \"\"\"\n        Parse the given string, either a Unicode character or ``U+....``,\n        and return the corresponding Unicode code point as int.\n        \"\"\"\n        if len(string) > 1:\n            match = self.CODEPOINT_REGEX.match(string)\n            return self._match_to_int(match)\n        elif len(string) == 1:\n            return self._unichr_to_int(string)\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_job(self, job):\n        if not isinstance(job, Job):\n            self.log_exc(u\"job is not an instance of Job\", None, True, ExecuteJobInputError)\n        self.job = job", "response": "Load the job from the given job object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the job from the given container.", "response": "def load_job_from_container(self, container_path, config_string=None):\n        \"\"\"\n        Load the job from the given :class:`aeneas.container.Container` object.\n\n        If ``config_string`` is ``None``,\n        the container must contain a configuration file;\n        otherwise use the provided config string\n        (i.e., the wizard case).\n\n        :param string container_path: the path to the input container\n        :param string config_string: the configuration string (from wizard)\n        :raises: :class:`~aeneas.executejob.ExecuteJobInputError`: if the given container does not contain a valid :class:`~aeneas.job.Job`\n        \"\"\"\n        self.log(u\"Loading job from container...\")\n\n        # create working directory where the input container\n        # will be decompressed\n        self.working_directory = gf.tmp_directory(root=self.rconf[RuntimeConfiguration.TMP_PATH])\n        self.log([u\"Created working directory '%s'\", self.working_directory])\n\n        try:\n            self.log(u\"Decompressing input container...\")\n            input_container = Container(container_path, logger=self.logger)\n            input_container.decompress(self.working_directory)\n            self.log(u\"Decompressing input container... done\")\n        except Exception as exc:\n            self.clean()\n            self.log_exc(u\"Unable to decompress container '%s': %s\" % (container_path, exc), None, True, ExecuteJobInputError)\n\n        try:\n            self.log(u\"Creating job from working directory...\")\n            working_container = Container(\n                self.working_directory,\n                logger=self.logger\n            )\n            analyzer = AnalyzeContainer(working_container, logger=self.logger)\n            self.job = analyzer.analyze(config_string=config_string)\n            self.log(u\"Creating job from working directory... done\")\n        except Exception as exc:\n            self.clean()\n            self.log_exc(u\"Unable to analyze container '%s': %s\" % (container_path, exc), None, True, ExecuteJobInputError)\n\n        if self.job is None:\n            self.log_exc(u\"The container '%s' does not contain a valid Job\" % (container_path), None, True, ExecuteJobInputError)\n\n        try:\n            # set absolute path for text file and audio file\n            # for each task in the job\n            self.log(u\"Setting absolute paths for tasks...\")\n            for task in self.job.tasks:\n                task.text_file_path_absolute = gf.norm_join(\n                    self.working_directory,\n                    task.text_file_path\n                )\n                task.audio_file_path_absolute = gf.norm_join(\n                    self.working_directory,\n                    task.audio_file_path\n                )\n            self.log(u\"Setting absolute paths for tasks... done\")\n\n            self.log(u\"Loading job from container: succeeded\")\n        except Exception as exc:\n            self.clean()\n            self.log_exc(u\"Error while setting absolute paths for tasks\", exc, True, ExecuteJobInputError)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self):\n        self.log(u\"Executing job\")\n\n        if self.job is None:\n            self.log_exc(u\"The job object is None\", None, True, ExecuteJobExecutionError)\n        if len(self.job) == 0:\n            self.log_exc(u\"The job has no tasks\", None, True, ExecuteJobExecutionError)\n        job_max_tasks = self.rconf[RuntimeConfiguration.JOB_MAX_TASKS]\n        if (job_max_tasks > 0) and (len(self.job) > job_max_tasks):\n            self.log_exc(u\"The Job has %d Tasks, more than the maximum allowed (%d).\" % (len(self.job), job_max_tasks), None, True, ExecuteJobExecutionError)\n        self.log([u\"Number of tasks: '%d'\", len(self.job)])\n\n        for task in self.job.tasks:\n            try:\n                custom_id = task.configuration[\"custom_id\"]\n                self.log([u\"Executing task '%s'...\", custom_id])\n                executor = ExecuteTask(task, rconf=self.rconf, logger=self.logger)\n                executor.execute()\n                self.log([u\"Executing task '%s'... done\", custom_id])\n            except Exception as exc:\n                self.log_exc(u\"Error while executing task '%s'\" % (custom_id), exc, True, ExecuteJobExecutionError)\n            self.log(u\"Executing task: succeeded\")\n\n        self.log(u\"Executing job: succeeded\")", "response": "Execute the job and return the unique identifier of the job object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_output_container(self, output_directory_path):\n        self.log(u\"Writing output container for this job\")\n\n        if self.job is None:\n            self.log_exc(u\"The job object is None\", None, True, ExecuteJobOutputError)\n        if len(self.job) == 0:\n            self.log_exc(u\"The job has no tasks\", None, True, ExecuteJobOutputError)\n        self.log([u\"Number of tasks: '%d'\", len(self.job)])\n\n        # create temporary directory where the sync map files\n        # will be created\n        # this temporary directory will be compressed into\n        # the output container\n        self.tmp_directory = gf.tmp_directory(root=self.rconf[RuntimeConfiguration.TMP_PATH])\n        self.log([u\"Created temporary directory '%s'\", self.tmp_directory])\n\n        for task in self.job.tasks:\n            custom_id = task.configuration[\"custom_id\"]\n\n            # check if the task has sync map and sync map file path\n            if task.sync_map_file_path is None:\n                self.log_exc(u\"Task '%s' has sync_map_file_path not set\" % (custom_id), None, True, ExecuteJobOutputError)\n            if task.sync_map is None:\n                self.log_exc(u\"Task '%s' has sync_map not set\" % (custom_id), None, True, ExecuteJobOutputError)\n\n            try:\n                # output sync map\n                self.log([u\"Outputting sync map for task '%s'...\", custom_id])\n                task.output_sync_map_file(self.tmp_directory)\n                self.log([u\"Outputting sync map for task '%s'... done\", custom_id])\n            except Exception as exc:\n                self.log_exc(u\"Error while outputting sync map for task '%s'\" % (custom_id), None, True, ExecuteJobOutputError)\n\n        # get output container info\n        output_container_format = self.job.configuration[\"o_container_format\"]\n        self.log([u\"Output container format: '%s'\", output_container_format])\n        output_file_name = self.job.configuration[\"o_name\"]\n        if ((output_container_format != ContainerFormat.UNPACKED) and\n                (not output_file_name.endswith(output_container_format))):\n            self.log(u\"Adding extension to output_file_name\")\n            output_file_name += \".\" + output_container_format\n        self.log([u\"Output file name: '%s'\", output_file_name])\n        output_file_path = gf.norm_join(\n            output_directory_path,\n            output_file_name\n        )\n        self.log([u\"Output file path: '%s'\", output_file_path])\n\n        try:\n            self.log(u\"Compressing...\")\n            container = Container(\n                output_file_path,\n                output_container_format,\n                logger=self.logger\n            )\n            container.compress(self.tmp_directory)\n            self.log(u\"Compressing... done\")\n            self.log([u\"Created output file: '%s'\", output_file_path])\n            self.log(u\"Writing output container for this job: succeeded\")\n            self.clean(False)\n            return output_file_path\n        except Exception as exc:\n            self.clean(False)\n            self.log_exc(u\"Error while compressing\", exc, True, ExecuteJobOutputError)\n            return None", "response": "Writes the output container for this job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the temporary directory and the working directory.", "response": "def clean(self, remove_working_directory=True):\n        \"\"\"\n        Remove the temporary directory.\n        If ``remove_working_directory`` is ``True``\n        remove the working directory as well,\n        otherwise just remove the temporary directory.\n\n        :param bool remove_working_directory: if ``True``, remove\n                                              the working directory as well\n        \"\"\"\n        if remove_working_directory is not None:\n            self.log(u\"Removing working directory... \")\n            gf.delete_directory(self.working_directory)\n            self.working_directory = None\n            self.log(u\"Removing working directory... done\")\n        self.log(u\"Removing temporary directory... \")\n        gf.delete_directory(self.tmp_directory)\n        self.tmp_directory = None\n        self.log(u\"Removing temporary directory... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform_command(self):\n        # if no actual arguments, print help\n        if len(self.actual_arguments) < 1:\n            return self.print_help(short=True)\n\n        # check if we have a recognized tool switch\n        for cls, switches in self.TOOLS:\n            if self.has_option(switches):\n                arguments = [a for a in sys.argv if a not in switches]\n                return cls(invoke=(self.invoke + u\" %s\" % switches[0])).run(arguments=arguments)\n\n        # check if we have -h, --help, or --version\n        if u\"-h\" in self.actual_arguments:\n            return self.print_help(short=True)\n        if u\"--help\" in self.actual_arguments:\n            return self.print_help(short=False)\n        if u\"--version\" in self.actual_arguments:\n            return self.print_name_version()\n\n        # default to run ExecuteTaskCLI\n        return ExecuteTaskCLI(invoke=self.invoke).run(arguments=sys.argv)", "response": "Perform command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform_command(self):\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        input_file_path = self.actual_arguments[0]\n        output_file_path = self.actual_arguments[1]\n\n        if not self.check_input_file(input_file_path):\n            return self.ERROR_EXIT_CODE\n        if not self.check_output_file(output_file_path):\n            return self.ERROR_EXIT_CODE\n\n        fast = self.has_option(\"--fast\")\n        fragment_text = self.has_option(\"--text\")\n        h_zoom = gf.safe_int(self.has_option_with_value(\"--hzoom\"), 5)\n        label = self.has_option_with_value(\"--label\")\n        time_step = gf.safe_int(self.has_option_with_value(\"--time-step\"), 0)\n        v_zoom = gf.safe_int(self.has_option_with_value(\"--vzoom\"), 30)\n\n        labels = not self.has_option(\"--no-labels\")\n        begin_times = not self.has_option(\"--no-begin-times\")\n        end_times = not self.has_option(\"--no-end-times\")\n        begin_guides = not self.has_option(\"--no-begin-guides\")\n        end_guides = not self.has_option(\"--no-end-guides\")\n\n        try:\n            # import or ImportError\n            from aeneas.plotter import PlotLabelset\n            from aeneas.plotter import PlotTimeScale\n            from aeneas.plotter import PlotWaveform\n            from aeneas.plotter import Plotter\n\n            # create plotter object\n            self.print_info(u\"Plotting to file...\")\n            plotter = Plotter(rconf=self.rconf, logger=self.logger)\n\n            # add waveform\n            afm = AudioFile(input_file_path, rconf=self.rconf, logger=self.logger)\n            afm.read_samples_from_file()\n            plotter.add_waveform(PlotWaveform(afm, label=label, fast=fast, rconf=self.rconf, logger=self.logger))\n\n            # add time scale, if requested\n            if time_step > 0:\n                plotter.add_timescale(PlotTimeScale(afm.audio_length, time_step=time_step, rconf=self.rconf, logger=self.logger))\n\n            # add labelsets, if any\n            for i in range(len(self.actual_arguments)):\n                if (self.actual_arguments[i] == \"-i\") and (i + 1 < len(self.actual_arguments)):\n                    label_file_path = self.actual_arguments[i + 1]\n                    extension = gf.file_extension(label_file_path)\n                    if extension == \"vad\":\n                        labelset = self._read_syncmap_file(label_file_path, SyncMapFormat.TSV, False)\n                        ls = PlotLabelset(labelset, parameters=None, rconf=self.rconf, logger=self.logger)\n                        ls.parameters[\"labels\"] = False\n                        ls.parameters[\"begin_time\"] = begin_times\n                        ls.parameters[\"end_time\"] = end_times\n                        ls.parameters[\"begin_guide\"] = begin_guides\n                        ls.parameters[\"end_guide\"] = end_guides\n                        plotter.add_labelset(ls)\n                    if extension in SyncMapFormat.ALLOWED_VALUES:\n                        labelset = self._read_syncmap_file(label_file_path, extension, fragment_text)\n                        ls = PlotLabelset(labelset, parameters=None, rconf=self.rconf, logger=self.logger)\n                        ls.parameters[\"labels\"] = labels\n                        ls.parameters[\"begin_time\"] = begin_times\n                        ls.parameters[\"end_time\"] = end_times\n                        ls.parameters[\"begin_guide\"] = begin_guides\n                        ls.parameters[\"end_guide\"] = end_guides\n                        plotter.add_labelset(ls)\n\n            # output to file\n            plotter.draw_png(output_file_path, h_zoom=h_zoom, v_zoom=v_zoom)\n            self.print_info(u\"Plotting to file... done\")\n            self.print_success(u\"Created file '%s'\" % output_file_path)\n            return self.NO_ERROR_EXIT_CODE\n        except ImportError:\n            self.print_error(u\"You need to install Python module Pillow to output image to file. Run:\")\n            self.print_error(u\"$ pip install Pillow\")\n            self.print_error(u\"or, to install for all users:\")\n            self.print_error(u\"$ sudo pip install Pillow\")\n        except Exception as exc:\n            self.print_error(u\"An unexpected error occurred while generating the image file:\")\n            self.print_error(u\"%s\" % exc)\n\n        return self.ERROR_EXIT_CODE", "response": "Perform command and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a SyncMap file and return a list of tuples.", "response": "def _read_syncmap_file(self, path, extension, text=False):\n        \"\"\" Read labels from a SyncMap file \"\"\"\n        syncmap = SyncMap(logger=self.logger)\n        syncmap.read(extension, path, parameters=None)\n        if text:\n            return [(f.begin, f.end, u\" \".join(f.text_fragment.lines)) for f in syncmap.fragments]\n        return [(f.begin, f.end, f.text_fragment.identifier) for f in syncmap.fragments]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms the command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 1:\n            return self.print_help()\n        audio_file_path = self.actual_arguments[0]\n\n        if not self.check_input_file(audio_file_path):\n            return self.ERROR_EXIT_CODE\n\n        try:\n            prober = FFPROBEWrapper(rconf=self.rconf, logger=self.logger)\n            dictionary = prober.read_properties(audio_file_path)\n            for key in sorted(dictionary.keys()):\n                self.print_generic(u\"%s %s\" % (key, dictionary[key]))\n            return self.NO_ERROR_EXIT_CODE\n        except FFPROBEPathError:\n            self.print_error(u\"Unable to call the ffprobe executable '%s'\" % (self.rconf[RuntimeConfiguration.FFPROBE_PATH]))\n            self.print_error(u\"Make sure the path to ffprobe is correct\")\n        except (FFPROBEUnsupportedFormatError, FFPROBEParsingError):\n            self.print_error(u\"Cannot read properties of file '%s'\" % (audio_file_path))\n            self.print_error(u\"Make sure the input file has a format supported by ffprobe\")\n\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the current list of sync map fragments that are not empty.", "response": "def leaves(self, fragment_type=None):\n        \"\"\"\n        The current list of sync map fragments\n        which are (the values of) the leaves\n        of the sync map tree.\n\n        :rtype: list of :class:`~aeneas.syncmap.fragment.SyncMapFragment`\n\n        .. versionadded:: 1.7.0\n        \"\"\"\n        leaves = self.fragments_tree.vleaves_not_empty\n        if fragment_type is None:\n            return leaves\n        return [l for l in leaves if l.fragment_type == fragment_type]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_adjacent_leaves_only(self):\n        leaves = self.leaves()\n        for i in range(len(leaves) - 1):\n            current_interval = leaves[i].interval\n            next_interval = leaves[i + 1].interval\n            if not current_interval.is_adjacent_before(next_interval):\n                return False\n        return True", "response": "Return True if the sync map fragments\n        which are the leaves of the sync map tree\n        are all adjacent."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the sync map fragments are consistent.", "response": "def leaves_are_consistent(self):\n        \"\"\"\n        Return ``True`` if the sync map fragments\n        which are the leaves of the sync map tree\n        (except for HEAD and TAIL leaves)\n        are all consistent, that is,\n        their intervals do not overlap in forbidden ways.\n\n        :rtype: bool\n\n        .. versionadded:: 1.7.0\n        \"\"\"\n        self.log(u\"Checking if leaves are consistent\")\n        leaves = self.leaves()\n        if len(leaves) < 1:\n            self.log(u\"Empty leaves => return True\")\n            return True\n        min_time = min([l.interval.begin for l in leaves])\n        self.log([u\"  Min time: %.3f\", min_time])\n        max_time = max([l.interval.end for l in leaves])\n        self.log([u\"  Max time: %.3f\", max_time])\n        self.log(u\"  Creating SyncMapFragmentList...\")\n        smf = SyncMapFragmentList(\n            begin=min_time,\n            end=max_time,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        self.log(u\"  Creating SyncMapFragmentList... done\")\n        self.log(u\"  Sorting SyncMapFragmentList...\")\n        result = True\n        not_head_tail = [l for l in leaves if not l.is_head_or_tail]\n        for l in not_head_tail:\n            smf.add(l, sort=False)\n        try:\n            smf.sort()\n            self.log(u\"  Sorting completed => return True\")\n        except ValueError:\n            self.log(u\"  Exception while sorting => return False\")\n            result = False\n        self.log(u\"  Sorting SyncMapFragmentList... done\")\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef json_string(self):\n        def visit_children(node):\n            \"\"\" Recursively visit the fragments_tree \"\"\"\n            output_fragments = []\n            for child in node.children_not_empty:\n                fragment = child.value\n                text = fragment.text_fragment\n                output_fragments.append({\n                    \"id\": text.identifier,\n                    \"language\": text.language,\n                    \"lines\": text.lines,\n                    \"begin\": gf.time_to_ssmmm(fragment.begin),\n                    \"end\": gf.time_to_ssmmm(fragment.end),\n                    \"children\": visit_children(child)\n                })\n            return output_fragments\n        output_fragments = visit_children(self.fragments_tree)\n        return gf.safe_unicode(\n            json.dumps({\"fragments\": output_fragments}, indent=1, sort_keys=True)\n        )", "response": "Returns a JSON representation of the sync map."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_fragment(self, fragment, as_last=True):\n        if not isinstance(fragment, SyncMapFragment):\n            self.log_exc(u\"fragment is not an instance of SyncMapFragment\", None, True, TypeError)\n        self.fragments_tree.add_child(Tree(value=fragment), as_last=as_last)", "response": "Adds the given sync map fragment to the root node of the sync map tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noutputs an HTML file for fine tuning the sync map manually.", "response": "def output_html_for_tuning(\n            self,\n            audio_file_path,\n            output_file_path,\n            parameters=None\n    ):\n        \"\"\"\n        Output an HTML file for fine tuning the sync map manually.\n\n        :param string audio_file_path: the path to the associated audio file\n        :param string output_file_path: the path to the output file to write\n        :param dict parameters: additional parameters\n\n        .. versionadded:: 1.3.1\n        \"\"\"\n        if not gf.file_can_be_written(output_file_path):\n            self.log_exc(u\"Cannot output HTML file '%s'. Wrong permissions?\" % (output_file_path), None, True, OSError)\n        if parameters is None:\n            parameters = {}\n        audio_file_path_absolute = gf.fix_slash(os.path.abspath(audio_file_path))\n        template_path_absolute = gf.absolute_path(self.FINETUNEAS_PATH, __file__)\n        with io.open(template_path_absolute, \"r\", encoding=\"utf-8\") as file_obj:\n            template = file_obj.read()\n        for repl in self.FINETUNEAS_REPLACEMENTS:\n            template = template.replace(repl[0], repl[1])\n        template = template.replace(\n            self.FINETUNEAS_REPLACE_AUDIOFILEPATH,\n            u\"audioFilePath = \\\"file://%s\\\";\" % audio_file_path_absolute\n        )\n        template = template.replace(\n            self.FINETUNEAS_REPLACE_FRAGMENTS,\n            u\"fragments = (%s).fragments;\" % self.json_string\n        )\n        if gc.PPN_TASK_OS_FILE_FORMAT in parameters:\n            output_format = parameters[gc.PPN_TASK_OS_FILE_FORMAT]\n            if output_format in self.FINETUNEAS_ALLOWED_FORMATS:\n                template = template.replace(\n                    self.FINETUNEAS_REPLACE_OUTPUT_FORMAT,\n                    u\"outputFormat = \\\"%s\\\";\" % output_format\n                )\n                if output_format == \"smil\":\n                    for key, placeholder, replacement in [\n                            (\n                                gc.PPN_TASK_OS_FILE_SMIL_AUDIO_REF,\n                                self.FINETUNEAS_REPLACE_SMIL_AUDIOREF,\n                                \"audioref = \\\"%s\\\";\"\n                            ),\n                            (\n                                gc.PPN_TASK_OS_FILE_SMIL_PAGE_REF,\n                                self.FINETUNEAS_REPLACE_SMIL_PAGEREF,\n                                \"pageref = \\\"%s\\\";\"\n                            ),\n                    ]:\n                        if key in parameters:\n                            template = template.replace(\n                                placeholder,\n                                replacement % parameters[key]\n                            )\n        with io.open(output_file_path, \"w\", encoding=\"utf-8\") as file_obj:\n            file_obj.write(template)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the sync map fragments from the given file in the specified format and add them to the current sync map.", "response": "def read(self, sync_map_format, input_file_path, parameters=None):\n        \"\"\"\n        Read sync map fragments from the given file in the specified format,\n        and add them the current (this) sync map.\n\n        Return ``True`` if the call succeeded,\n        ``False`` if an error occurred.\n\n        :param sync_map_format: the format of the sync map\n        :type  sync_map_format: :class:`~aeneas.syncmap.SyncMapFormat`\n        :param string input_file_path: the path to the input file to read\n        :param dict parameters: additional parameters (e.g., for ``SMIL`` input)\n        :raises: ValueError: if ``sync_map_format`` is ``None`` or it is not an allowed value\n        :raises: OSError: if ``input_file_path`` does not exist\n        \"\"\"\n        if sync_map_format is None:\n            self.log_exc(u\"Sync map format is None\", None, True, ValueError)\n        if sync_map_format not in SyncMapFormat.CODE_TO_CLASS:\n            self.log_exc(u\"Sync map format '%s' is not allowed\" % (sync_map_format), None, True, ValueError)\n        if not gf.file_can_be_read(input_file_path):\n            self.log_exc(u\"Cannot read sync map file '%s'. Wrong permissions?\" % (input_file_path), None, True, OSError)\n\n        self.log([u\"Input format:     '%s'\", sync_map_format])\n        self.log([u\"Input path:       '%s'\", input_file_path])\n        self.log([u\"Input parameters: '%s'\", parameters])\n\n        reader = (SyncMapFormat.CODE_TO_CLASS[sync_map_format])(\n            variant=sync_map_format,\n            parameters=parameters,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n\n        # open file for reading\n        self.log(u\"Reading input file...\")\n        with io.open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n            input_text = input_file.read()\n        reader.parse(input_text=input_text, syncmap=self)\n        self.log(u\"Reading input file... done\")\n\n        # overwrite language if requested\n        language = gf.safe_get(parameters, gc.PPN_SYNCMAP_LANGUAGE, None)\n        if language is not None:\n            self.log([u\"Overwriting language to '%s'\", language])\n            for fragment in self.fragments:\n                fragment.text_fragment.language = language"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the current sync map to file in the given format.", "response": "def write(self, sync_map_format, output_file_path, parameters=None):\n        \"\"\"\n        Write the current sync map to file in the requested format.\n\n        Return ``True`` if the call succeeded,\n        ``False`` if an error occurred.\n\n        :param sync_map_format: the format of the sync map\n        :type  sync_map_format: :class:`~aeneas.syncmap.SyncMapFormat`\n        :param string output_file_path: the path to the output file to write\n        :param dict parameters: additional parameters (e.g., for ``SMIL`` output)\n        :raises: ValueError: if ``sync_map_format`` is ``None`` or it is not an allowed value\n        :raises: TypeError: if a required parameter is missing\n        :raises: OSError: if ``output_file_path`` cannot be written\n        \"\"\"\n        def select_levels(syncmap, levels):\n            \"\"\"\n            Select the given levels of the fragments tree,\n            modifying the given syncmap (always pass a copy of it!).\n            \"\"\"\n            self.log([u\"Levels: '%s'\", levels])\n            if levels is None:\n                return\n            try:\n                levels = [int(l) for l in levels if int(l) > 0]\n                syncmap.fragments_tree.keep_levels(levels)\n                self.log([u\"Selected levels: %s\", levels])\n            except ValueError:\n                self.log_warn(u\"Cannot convert levels to list of int, returning unchanged\")\n\n        def set_head_tail_format(syncmap, head_tail_format=None):\n            \"\"\"\n            Set the appropriate head/tail nodes of the fragments tree,\n            modifying the given syncmap (always pass a copy of it!).\n            \"\"\"\n            self.log([u\"Head/tail format: '%s'\", str(head_tail_format)])\n            tree = syncmap.fragments_tree\n            head = tree.get_child(0)\n            first = tree.get_child(1)\n            last = tree.get_child(-2)\n            tail = tree.get_child(-1)\n            # mark HEAD as REGULAR if needed\n            if head_tail_format == SyncMapHeadTailFormat.ADD:\n                head.value.fragment_type = SyncMapFragment.REGULAR\n                self.log(u\"Marked HEAD as REGULAR\")\n            # stretch first and last fragment timings if needed\n            if head_tail_format == SyncMapHeadTailFormat.STRETCH:\n                self.log([u\"Stretched first.begin: %.3f => %.3f (head)\", first.value.begin, head.value.begin])\n                self.log([u\"Stretched last.end:    %.3f => %.3f (tail)\", last.value.end, tail.value.end])\n                first.value.begin = head.value.begin\n                last.value.end = tail.value.end\n            # mark TAIL as REGULAR if needed\n            if head_tail_format == SyncMapHeadTailFormat.ADD:\n                tail.value.fragment_type = SyncMapFragment.REGULAR\n                self.log(u\"Marked TAIL as REGULAR\")\n            # remove all fragments that are not REGULAR\n            for node in list(tree.dfs):\n                if (node.value is not None) and (node.value.fragment_type != SyncMapFragment.REGULAR):\n                    node.remove()\n\n        if sync_map_format is None:\n            self.log_exc(u\"Sync map format is None\", None, True, ValueError)\n        if sync_map_format not in SyncMapFormat.CODE_TO_CLASS:\n            self.log_exc(u\"Sync map format '%s' is not allowed\" % (sync_map_format), None, True, ValueError)\n        if not gf.file_can_be_written(output_file_path):\n            self.log_exc(u\"Cannot write sync map file '%s'. Wrong permissions?\" % (output_file_path), None, True, OSError)\n\n        self.log([u\"Output format:     '%s'\", sync_map_format])\n        self.log([u\"Output path:       '%s'\", output_file_path])\n        self.log([u\"Output parameters: '%s'\", parameters])\n\n        # select levels and head/tail format\n        pruned_syncmap = self.clone()\n        try:\n            select_levels(pruned_syncmap, parameters[gc.PPN_TASK_OS_FILE_LEVELS])\n        except:\n            self.log_warn([u\"No %s parameter specified\", gc.PPN_TASK_OS_FILE_LEVELS])\n        try:\n            set_head_tail_format(pruned_syncmap, parameters[gc.PPN_TASK_OS_FILE_HEAD_TAIL_FORMAT])\n        except:\n            self.log_warn([u\"No %s parameter specified\", gc.PPN_TASK_OS_FILE_HEAD_TAIL_FORMAT])\n\n        # create writer\n        # the constructor will check for required parameters, if any\n        # if some are missing, it will raise a SyncMapMissingParameterError\n        writer = (SyncMapFormat.CODE_TO_CLASS[sync_map_format])(\n            variant=sync_map_format,\n            parameters=parameters,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n\n        # create dir hierarchy, if needed\n        gf.ensure_parent_directory(output_file_path)\n\n        # open file for writing\n        self.log(u\"Writing output file...\")\n        with io.open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n            output_file.write(writer.format(syncmap=pruned_syncmap))\n        self.log(u\"Writing output file... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_dct_matrix(self):\n        self.s2dct = numpy.zeros((self.mfcc_size, self.filter_bank_size))\n        for i in range(0, self.mfcc_size):\n            freq = numpy.pi * float(i) / self.filter_bank_size\n            self.s2dct[i] = numpy.cos(freq * numpy.arange(0.5, 0.5 + self.filter_bank_size, 1.0, 'float64'))\n        self.s2dct[:, 0] *= 0.5\n        self.s2dct = self.s2dct.transpose()", "response": "Create the not - quite - DCT matrix as used by Sphinx."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the Mel filter bank and store it in self. filters.", "response": "def _create_mel_filter_bank(self):\n        \"\"\"\n        Create the Mel filter bank,\n        and store it in ``self.filters``.\n\n        Note that it is a function of the audio sample rate,\n        so it cannot be created in the class initializer,\n        but only later in :func:`aeneas.mfcc.MFCC.compute_from_data`.\n        \"\"\"\n        self.filters = numpy.zeros((1 + (self.fft_order // 2), self.filter_bank_size), 'd')\n        dfreq = float(self.sample_rate) / self.fft_order\n        nyquist_frequency = self.sample_rate / 2\n        if self.upper_frequency > nyquist_frequency:\n            self.log_exc(u\"Upper frequency %f exceeds Nyquist frequency %f\" % (self.upper_frequency, nyquist_frequency), None, True, ValueError)\n        melmax = MFCC._hz2mel(self.upper_frequency)\n        melmin = MFCC._hz2mel(self.lower_frequency)\n        dmelbw = (melmax - melmin) / (self.filter_bank_size + 1)\n        filt_edge = MFCC._mel2hz(melmin + dmelbw * numpy.arange(self.filter_bank_size + 2, dtype='d'))\n\n        # TODO can this code be written more numpy-style?\n        #      (the performance loss is negligible, it is just ugly to see)\n        for whichfilt in range(0, self.filter_bank_size):\n            # int() casts to native int instead of working with numpy.float64\n            leftfr = int(round(filt_edge[whichfilt] / dfreq))\n            centerfr = int(round(filt_edge[whichfilt + 1] / dfreq))\n            rightfr = int(round(filt_edge[whichfilt + 2] / dfreq))\n            fwidth = (rightfr - leftfr) * dfreq\n            height = 2.0 / fwidth\n            if centerfr != leftfr:\n                leftslope = height / (centerfr - leftfr)\n            else:\n                leftslope = 0\n            freq = leftfr + 1\n            while freq < centerfr:\n                self.filters[freq, whichfilt] = (freq - leftfr) * leftslope\n                freq = freq + 1\n            # the next if should always be true!\n            if freq == centerfr:\n                self.filters[freq, whichfilt] = height\n                freq = freq + 1\n            if centerfr != rightfr:\n                rightslope = height / (centerfr - rightfr)\n            while freq < rightfr:\n                self.filters[freq, whichfilt] = (freq - rightfr) * rightslope\n                freq = freq + 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pre_emphasis(self):\n        self.data = numpy.append(self.data[0], self.data[1:] - self.emphasis_factor * self.data[:-1])", "response": "Pre - emphasize the entire signal at once by self. emphasis_factor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_from_data(self, data, sample_rate):\n        def _process_frame(self, frame):\n            \"\"\"\n            Process each frame, returning the log(power()) of it.\n            \"\"\"\n            # apply Hamming window\n            frame *= self.hamming_window\n            # compute RFFT\n            fft = numpy.fft.rfft(frame, self.fft_order)\n            # equivalent to power = fft.real * fft.real + fft.imag * fft.imag\n            power = numpy.square(numpy.absolute(fft))\n            #\n            # return the log(power()) of the transformed vector\n            # v1\n            # COMMENTED logspec = numpy.log(numpy.dot(power, self.filters).clip(self.CUTOFF, numpy.inf))\n            # COMMENTED return numpy.dot(logspec, self.s2dct) / self.filter_bank_size\n            # v2\n            return numpy.log(numpy.dot(power, self.filters).clip(self.CUTOFF, numpy.inf))\n\n        if len(data.shape) != 1:\n            self.log_exc(u\"The audio data must be a 1D numpy array (mono).\", None, True, ValueError)\n        if len(data) < 1:\n            self.log_exc(u\"The audio data must not be empty.\", None, True, ValueError)\n\n        self.data = data\n        self.sample_rate = sample_rate\n\n        # number of samples in the audio\n        data_length = len(self.data)\n\n        # frame length in number of samples\n        frame_length = int(self.window_length * self.sample_rate)\n\n        # frame length must be at least equal to the FFT order\n        frame_length_padded = max(frame_length, self.fft_order)\n\n        # frame shift in number of samples\n        frame_shift = int(self.window_shift * self.sample_rate)\n\n        # number of MFCC vectors (one for each frame)\n        # this number includes the last shift,\n        # where the data will be padded with zeros\n        # if the remaining samples are less than frame_length_padded\n        number_of_frames = int((1.0 * data_length) / frame_shift)\n\n        # create Hamming window\n        self.hamming_window = numpy.hamming(frame_length_padded)\n\n        # build Mel filter bank\n        self._create_mel_filter_bank()\n\n        # pre-emphasize the entire audio data\n        self._pre_emphasis()\n\n        # allocate the MFCCs matrix\n        # v1\n        # COMMENTED mfcc = numpy.zeros((number_of_frames, self.mfcc_size), 'float64')\n        # v2\n        mfcc = numpy.zeros((number_of_frames, self.filter_bank_size), 'float64')\n\n        # compute MFCCs one frame at a time\n        for frame_index in range(number_of_frames):\n            # COMMENTED print(\"Computing frame %d / %d\" % (frame_index, number_of_frames))\n\n            # get the start and end indices for this frame,\n            # do not overrun the data length\n            frame_start = frame_index * frame_shift\n            frame_end = min(frame_start + frame_length_padded, data_length)\n\n            # frame is zero-padded if the remaining samples\n            # are less than its length\n            frame = numpy.zeros(frame_length_padded)\n            frame[0:(frame_end - frame_start)] = self.data[frame_start:frame_end]\n\n            # process the frame\n            mfcc[frame_index] = _process_frame(self, frame)\n\n        # v1\n        # COMMENTED return mfcc\n        # v2\n        # return the dot product with the DCT matrix\n        return numpy.dot(mfcc, self.s2dct) / self.filter_bank_size", "response": "Compute the MFCCs for the given audio data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the sample rate and data from a WAV file.", "response": "def read(filename, mmap=False):\n    \"\"\"\n    Return the sample rate (in samples/sec) and data from a WAV file\n\n    Parameters\n    ----------\n    filename : string or open file handle\n        Input wav file.\n    mmap : bool, optional\n        Whether to read data as memory mapped.\n        Only to be used on real files (Default: False)\n\n        .. versionadded:: 0.12.0\n\n    Returns\n    -------\n    rate : int\n        Sample rate of wav file\n    data : numpy array\n        Data read from wav file\n\n    Notes\n    -----\n    * The file can be an open file or a filename.\n    * The returned sample rate is a Python integer.\n    * The data is returned as a numpy array with a data-type determined\n      from the file.\n    * This function cannot read wav files with 24 bit data.\n\n    \"\"\"\n    if hasattr(filename, 'read'):\n        fid = filename\n        mmap = False\n    else:\n        fid = open(filename, 'rb')\n\n    try:\n        fsize = _read_riff_chunk(fid)\n        noc = 1\n        bits = 8\n        comp = WAVE_FORMAT_PCM\n        while (fid.tell() < fsize):\n            # read the next chunk\n            chunk_id = fid.read(4)\n            if chunk_id == b'fmt ':\n                size, comp, noc, rate, sbytes, ba, bits = _read_fmt_chunk(fid)\n                if bits == 24:\n                    raise ValueError(\"Unsupported bit depth: the wav file \"\n                                     \"has 24 bit data.\")\n            elif chunk_id == b'fact':\n                _skip_unknown_chunk(fid)\n            elif chunk_id == b'data':\n                data = _read_data_chunk(fid, comp, noc, bits, mmap=mmap)\n            elif chunk_id == b'LIST':\n                # Someday this could be handled properly but for now skip it\n                _skip_unknown_chunk(fid)\n            else:\n                warnings.warn(\"Chunk (non-data) not understood, skipping it.\",\n                              WavFileWarning)\n                _skip_unknown_chunk(fid)\n    finally:\n        if not hasattr(filename, 'read'):\n            fid.close()\n        else:\n            fid.seek(0)\n\n    return rate, data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(filename, rate, data):\n    if hasattr(filename, 'write'):\n        fid = filename\n    else:\n        fid = open(filename, 'wb')\n\n    try:\n        dkind = data.dtype.kind\n        if not (dkind == 'i' or dkind == 'f' or (dkind == 'u' and\n                                                 data.dtype.itemsize == 1)):\n            raise ValueError(\"Unsupported data type '%s'\" % data.dtype)\n\n        fid.write(b'RIFF')\n        fid.write(b'\\x00\\x00\\x00\\x00')\n        fid.write(b'WAVE')\n        # fmt chunk\n        fid.write(b'fmt ')\n        if dkind == 'f':\n            comp = 3\n        else:\n            comp = 1\n        if data.ndim == 1:\n            noc = 1\n        else:\n            noc = data.shape[1]\n        bits = data.dtype.itemsize * 8\n        sbytes = rate * (bits // 8) * noc\n        ba = noc * (bits // 8)\n        fid.write(struct.pack('<ihHIIHH', 16, comp, noc, rate, sbytes,\n                              ba, bits))\n        # data chunk\n        fid.write(b'data')\n        fid.write(struct.pack('<i', data.nbytes))\n        if data.dtype.byteorder == '>' or (data.dtype.byteorder == '=' and\n                                           sys.byteorder == 'big'):\n            data = data.byteswap()\n        _array_tofile(fid, data)\n\n        # Determine file size and place it in correct\n        #  position at start of the file.\n        size = fid.tell()\n        fid.seek(4)\n        fid.write(struct.pack('<i', size - 8))\n\n    finally:\n        if not hasattr(filename, 'write'):\n            fid.close()\n        else:\n            fid.seek(0)", "response": "Writes a numpy array as a WAV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        input_file_path = self.actual_arguments[0]\n        output_file_path = self.actual_arguments[1]\n\n        if not self.check_input_file(input_file_path):\n            return self.ERROR_EXIT_CODE\n        if not self.check_output_file(output_file_path):\n            return self.ERROR_EXIT_CODE\n\n        try:\n            converter = FFMPEGWrapper(rconf=self.rconf, logger=self.logger)\n            converter.convert(input_file_path, output_file_path)\n            self.print_success(u\"Converted '%s' into '%s'\" % (input_file_path, output_file_path))\n            return self.NO_ERROR_EXIT_CODE\n        except FFMPEGPathError:\n            self.print_error(u\"Unable to call the ffmpeg executable '%s'\" % (self.rconf[RuntimeConfiguration.FFMPEG_PATH]))\n            self.print_error(u\"Make sure the path to ffmpeg is correct\")\n        except OSError:\n            self.print_error(u\"Cannot convert file '%s' into '%s'\" % (input_file_path, output_file_path))\n            self.print_error(u\"Make sure the input file has a format supported by ffmpeg\")\n\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a given Unicode string to stdout.", "response": "def safe_print(msg):\n    \"\"\"\n    Safely print a given Unicode string to stdout,\n    possibly replacing characters non-printable\n    in the current stdout encoding.\n\n    :param string msg: the message\n    \"\"\"\n    try:\n        print(msg)\n    except UnicodeEncodeError:\n        try:\n            # NOTE encoding and decoding so that in Python 3 no b\"...\" is printed\n            encoded = msg.encode(sys.stdout.encoding, \"replace\")\n            decoded = encoded.decode(sys.stdout.encoding, \"replace\")\n            print(decoded)\n        except (UnicodeDecodeError, UnicodeEncodeError):\n            print(u\"[ERRO] An unexpected error happened while printing to stdout.\")\n            print(u\"[ERRO] Please check that your file/string encoding matches the shell encoding.\")\n            print(u\"[ERRO] If possible, set your shell encoding to UTF-8 and convert any files with legacy encodings.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting an error message.", "response": "def print_error(msg, color=True):\n    \"\"\"\n    Print an error message.\n\n    :param string msg: the message\n    :param bool color: if ``True``, print with POSIX color\n    \"\"\"\n    if color and is_posix():\n        safe_print(u\"%s[ERRO] %s%s\" % (ANSI_ERROR, msg, ANSI_END))\n    else:\n        safe_print(u\"[ERRO] %s\" % (msg))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint a success message.", "response": "def print_success(msg, color=True):\n    \"\"\"\n    Print a success message.\n\n    :param string msg: the message\n    :param bool color: if ``True``, print with POSIX color\n    \"\"\"\n    if color and is_posix():\n        safe_print(u\"%s[INFO] %s%s\" % (ANSI_OK, msg, ANSI_END))\n    else:\n        safe_print(u\"[INFO] %s\" % (msg))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a warning message.", "response": "def print_warning(msg, color=True):\n    \"\"\"\n    Print a warning message.\n\n    :param string msg: the message\n    :param bool color: if ``True``, print with POSIX color\n    \"\"\"\n    if color and is_posix():\n        safe_print(u\"%s[WARN] %s%s\" % (ANSI_WARNING, msg, ANSI_END))\n    else:\n        safe_print(u\"[WARN] %s\" % (msg))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tmp_file(suffix=u\"\", root=None):\n    if root is None:\n        root = custom_tmp_dir()\n    return tempfile.mkstemp(suffix=suffix, dir=root)", "response": "Returns a handler and path for a temporary file with given suffix created by tempfile. mkstemp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the file extension.", "response": "def file_extension(path):\n    \"\"\"\n    Return the file extension.\n\n    Examples: ::\n\n        /foo/bar.baz => baz\n        None         => None\n\n    :param string path: the file path\n    :rtype: string\n    \"\"\"\n    if path is None:\n        return None\n    ext = os.path.splitext(os.path.basename(path))[1]\n    if ext.startswith(\".\"):\n        ext = ext[1:]\n    return ext"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a mimetype from the file extension.", "response": "def mimetype_from_path(path):\n    \"\"\"\n    Return a mimetype from the file extension.\n\n    :param string path: the file path\n    :rtype: string\n    \"\"\"\n    extension = file_extension(path)\n    if extension is not None:\n        extension = extension.lower()\n        if extension in gc.MIMETYPE_MAP:\n            return gc.MIMETYPE_MAP[extension]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the file name without extension.", "response": "def file_name_without_extension(path):\n    \"\"\"\n    Return the file name without extension.\n\n    Examples: ::\n\n        /foo/bar.baz => bar\n        /foo/bar     => bar\n        None         => None\n\n    :param string path: the file path\n    :rtype: string\n    \"\"\"\n    if path is None:\n        return None\n    return os.path.splitext(os.path.basename(path))[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datetime_string(time_zone=False):\n    time = datetime.datetime.now()\n    template = u\"%04d-%02d-%02dT%02d:%02d:%02d\"\n    if time_zone:\n        template += u\"+00:00\"\n    return template % (\n        time.year,\n        time.month,\n        time.day,\n        time.hour,\n        time.minute,\n        time.second\n    )", "response": "Return a string representing the current date and time of the current node in the specified time zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_get(dictionary, key, default_value, can_return_none=True):\n    return_value = default_value\n    try:\n        return_value = dictionary[key]\n        if (return_value is None) and (not can_return_none):\n            return_value = default_value\n    except (KeyError, TypeError):\n        # KeyError if key is not present in dictionary\n        # TypeError if dictionary is None\n        pass\n    return return_value", "response": "Safely perform a dictionary get returning the default value if the key is not found in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\njoins prefix and suffix paths and return the resulting path normalized.", "response": "def norm_join(prefix, suffix):\n    \"\"\"\n    Join ``prefix`` and ``suffix`` paths\n    and return the resulting path, normalized.\n\n    :param string prefix: the prefix path\n    :param string suffix: the suffix path\n    :rtype: string\n    \"\"\"\n    if (prefix is None) and (suffix is None):\n        return \".\"\n    if prefix is None:\n        return os.path.normpath(suffix)\n    if suffix is None:\n        return os.path.normpath(prefix)\n    return os.path.normpath(os.path.join(prefix, suffix))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the contents of a TXT config file into a corresponding configuration string.", "response": "def config_txt_to_string(string):\n    \"\"\"\n    Convert the contents of a TXT config file\n    into the corresponding configuration string ::\n\n        key_1=value_1|key_2=value_2|...|key_n=value_n\n\n    Leading and trailing blank characters will be stripped\n    and empty lines (after stripping) will be ignored.\n\n    :param string string: the contents of a TXT config file\n    :rtype: string\n    \"\"\"\n    if string is None:\n        return None\n    pairs = [l.strip() for l in string.splitlines() if len(l.strip()) > 0]\n    return gc.CONFIG_STRING_SEPARATOR_SYMBOL.join(pairs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a given configuration string into a dictionary.", "response": "def config_string_to_dict(string, result=None):\n    \"\"\"\n    Convert a given configuration string ::\n\n        key_1=value_1|key_2=value_2|...|key_n=value_n\n\n    into the corresponding dictionary ::\n\n        dictionary[key_1] = value_1\n        dictionary[key_2] = value_2\n        ...\n        dictionary[key_n] = value_n\n\n    :param string string: the configuration string\n    :rtype: dict\n    \"\"\"\n    if string is None:\n        return {}\n    pairs = string.split(gc.CONFIG_STRING_SEPARATOR_SYMBOL)\n    return pairs_to_dict(pairs, result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef config_xml_to_dict(contents, result, parse_job=True):\n    from lxml import etree\n    try:\n        root = etree.fromstring(contents)\n        pairs = []\n        if parse_job:\n            # parse job\n            for elem in root:\n                if (elem.tag != gc.CONFIG_XML_TASKS_TAG) and (elem.text is not None):\n                    pairs.append(u\"%s%s%s\" % (\n                        safe_unicode(elem.tag),\n                        gc.CONFIG_STRING_ASSIGNMENT_SYMBOL,\n                        safe_unicode(elem.text.strip())\n                    ))\n            return pairs_to_dict(pairs)\n        else:\n            # parse tasks\n            output_list = []\n            for task in root.find(gc.CONFIG_XML_TASKS_TAG):\n                if task.tag == gc.CONFIG_XML_TASK_TAG:\n                    pairs = []\n                    for elem in task:\n                        if elem.text is not None:\n                            pairs.append(u\"%s%s%s\" % (\n                                safe_unicode(elem.tag),\n                                gc.CONFIG_STRING_ASSIGNMENT_SYMBOL,\n                                safe_unicode(elem.text.strip())\n                            ))\n                    output_list.append(pairs_to_dict(pairs))\n            return output_list\n    except:\n        if result is not None:\n            result.passed = False\n            result.add_error(\"An error occurred while parsing XML file\")\n        if parse_job:\n            return {}\n        else:\n            return []", "response": "Convert the contents of a XML config file into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a given config dictionary into a string that can be used in the config file.", "response": "def config_dict_to_string(dictionary):\n    \"\"\"\n    Convert a given config dictionary ::\n\n        dictionary[key_1] = value_1\n        dictionary[key_2] = value_2\n        ...\n        dictionary[key_n] = value_n\n\n    into the corresponding string ::\n\n        key_1=value_1|key_2=value_2|...|key_n=value_n\n\n    :param dict dictionary: the config dictionary\n    :rtype: string\n    \"\"\"\n    parameters = []\n    for key in dictionary:\n        parameters.append(u\"%s%s%s\" % (\n            key,\n            gc.CONFIG_STRING_ASSIGNMENT_SYMBOL,\n            dictionary[key]\n        ))\n    return gc.CONFIG_STRING_SEPARATOR_SYMBOL.join(parameters)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pairs_to_dict(pairs, result=None):\n    dictionary = {}\n    for pair in pairs:\n        if len(pair) > 0:\n            tokens = pair.split(gc.CONFIG_STRING_ASSIGNMENT_SYMBOL)\n            if ((len(tokens) == 2) and\n                    (len(tokens[0])) > 0 and\n                    (len(tokens[1]) > 0)):\n                dictionary[tokens[0]] = tokens[1]\n            elif result is not None:\n                result.add_warning(\"Invalid key=value string: '%s'\" % pair)\n    return dictionary", "response": "Converts a list of key = value strings into a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure_parent_directory(path, ensure_parent=True):\n    parent_directory = os.path.abspath(path)\n    if ensure_parent:\n        parent_directory = os.path.dirname(parent_directory)\n    if not os.path.exists(parent_directory):\n        try:\n            os.makedirs(parent_directory)\n        except (IOError, OSError):\n            raise OSError(u\"Directory '%s' cannot be created\" % parent_directory)", "response": "Ensures that the parent directory of the file is created."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef time_from_hhmmssmmm(string, decimal_separator=\".\"):\n    if decimal_separator == \",\":\n        pattern = HHMMSS_MMM_PATTERN_COMMA\n    else:\n        pattern = HHMMSS_MMM_PATTERN\n    v_length = TimeValue(\"0.000\")\n    try:\n        match = pattern.search(string)\n        if match is not None:\n            v_h = int(match.group(1))\n            v_m = int(match.group(2))\n            v_s = int(match.group(3))\n            v_f = TimeValue(\"0.\" + match.group(4))\n            v_length = v_h * 3600 + v_m * 60 + v_s + v_f\n    except:\n        pass\n    return v_length", "response": "Parse the given string and return a time value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats the given time value into a HHMMSS. mmm string.", "response": "def time_to_hhmmssmmm(time_value, decimal_separator=\".\"):\n    \"\"\"\n    Format the given time value into a ``HH:MM:SS.mmm`` string.\n\n    Examples: ::\n\n        12        => 00:00:12.000\n        12.345    => 00:00:12.345\n        12.345432 => 00:00:12.345\n        12.345678 => 00:00:12.346\n        83        => 00:01:23.000\n        83.456    => 00:01:23.456\n        83.456789 => 00:01:23.456\n        3600      => 01:00:00.000\n        3612.345  => 01:00:12.345\n\n    :param float time_value: a time value, in seconds\n    :param string decimal_separator: the decimal separator, default ``.``\n    :rtype: string\n    \"\"\"\n    if time_value is None:\n        time_value = 0\n    tmp = time_value\n    hours = int(math.floor(tmp / 3600))\n    tmp -= (hours * 3600)\n    minutes = int(math.floor(tmp / 60))\n    tmp -= minutes * 60\n    seconds = int(math.floor(tmp))\n    tmp -= seconds\n    milliseconds = int(math.floor(tmp * 1000))\n    return \"%02d:%02d:%02d%s%03d\" % (\n        hours,\n        minutes,\n        seconds,\n        decimal_separator,\n        milliseconds\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_url(url):\n    if url is None:\n        return (None, None)\n    array = url.split(\"#\")\n    if len(array) == 1:\n        array.append(None)\n    return tuple(array[0:2])", "response": "Split the given URL into two or more tokens."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest whether a Python C extension loads correctly.", "response": "def can_run_c_extension(name=None):\n    \"\"\"\n    Determine whether the given Python C extension loads correctly.\n\n    If ``name`` is ``None``, tests all Python C extensions,\n    and return ``True`` if and only if all load correctly.\n\n    :param string name: the name of the Python C extension to test\n    :rtype: bool\n    \"\"\"\n    def can_run_cdtw():\n        \"\"\" Python C extension for computing DTW \"\"\"\n        try:\n            import aeneas.cdtw.cdtw\n            return True\n        except ImportError:\n            return False\n\n    def can_run_cmfcc():\n        \"\"\" Python C extension for computing MFCC \"\"\"\n        try:\n            import aeneas.cmfcc.cmfcc\n            return True\n        except ImportError:\n            return False\n\n    def can_run_cew():\n        \"\"\" Python C extension for synthesizing with eSpeak \"\"\"\n        try:\n            import aeneas.cew.cew\n            return True\n        except ImportError:\n            return False\n\n    def can_run_cfw():\n        \"\"\" Python C extension for synthesizing with Festival \"\"\"\n        try:\n            import aeneas.cfw.cfw\n            return True\n        except ImportError:\n            return False\n\n    if name == \"cdtw\":\n        return can_run_cdtw()\n    elif name == \"cmfcc\":\n        return can_run_cmfcc()\n    elif name == \"cew\":\n        return can_run_cew()\n    elif name == \"cfw\":\n        return can_run_cfw()\n    else:\n        # NOTE cfw is still experimental!\n        return can_run_cdtw() and can_run_cmfcc() and can_run_cew()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a function calling a C extension falling back to a pure Python function if the former does not succeed.", "response": "def run_c_extension_with_fallback(\n        log_function,\n        extension,\n        c_function,\n        py_function,\n        args,\n        rconf\n):\n    \"\"\"\n    Run a function calling a C extension, falling back\n    to a pure Python function if the former does not succeed.\n\n    :param function log_function: a logger function\n    :param string extension: the name of the extension\n    :param function c_function: the (Python) function calling the C extension\n    :param function py_function: the (Python) function providing the fallback\n    :param rconf: the runtime configuration\n    :type  rconf: :class:`aeneas.runtimeconfiguration.RuntimeConfiguration`\n    :rtype: depends on the extension being called\n    :raises: RuntimeError: if both the C extension and\n                           the pure Python code did not succeed.\n\n    .. versionadded:: 1.4.0\n    \"\"\"\n    computed = False\n    if not rconf[u\"c_extensions\"]:\n        log_function(u\"C extensions disabled\")\n    elif extension not in rconf:\n        log_function([u\"C extension '%s' not recognized\", extension])\n    elif not rconf[extension]:\n        log_function([u\"C extension '%s' disabled\", extension])\n    else:\n        log_function([u\"C extension '%s' enabled\", extension])\n        if c_function is None:\n            log_function(u\"C function is None\")\n        elif can_run_c_extension(extension):\n            log_function([u\"C extension '%s' enabled and it can be loaded\", extension])\n            computed, result = c_function(*args)\n        else:\n            log_function([u\"C extension '%s' enabled but it cannot be loaded\", extension])\n    if not computed:\n        if py_function is None:\n            log_function(u\"Python function is None\")\n        else:\n            log_function(u\"Running the pure Python code\")\n            computed, result = py_function(*args)\n    if not computed:\n        raise RuntimeError(u\"Both the C extension and the pure Python code failed. (Wrong arguments? Input too big?)\")\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_can_be_read(path):\n    if path is None:\n        return False\n    try:\n        with io.open(path, \"rb\") as test_file:\n            pass\n        return True\n    except (IOError, OSError):\n        pass\n    return False", "response": "Return True if the file at the given path can be read."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if a file can be written at the given path.", "response": "def file_can_be_written(path):\n    \"\"\"\n    Return ``True`` if a file can be written at the given ``path``.\n\n    :param string path: the file path\n    :rtype: bool\n\n    .. warning:: This function will attempt to open the given ``path``\n                 in write mode, possibly destroying the file previously existing there.\n\n    .. versionadded:: 1.4.0\n    \"\"\"\n    if path is None:\n        return False\n    try:\n        with io.open(path, \"wb\") as test_file:\n            pass\n        delete_file(None, path)\n        return True\n    except (IOError, OSError):\n        pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relative_path(path, from_file):\n    if path is None:\n        return None\n    abs_path_target = absolute_path(path, from_file)\n    abs_path_cwd = os.getcwd()\n    if is_windows():\n        # NOTE on Windows, if the two paths are on different drives,\n        #      the notion of relative path is not defined:\n        #      return the absolute path of the target instead.\n        t_drive, t_tail = os.path.splitdrive(abs_path_target)\n        c_drive, c_tail = os.path.splitdrive(abs_path_cwd)\n        if t_drive != c_drive:\n            return abs_path_target\n    return os.path.relpath(abs_path_target, start=abs_path_cwd)", "response": "Return the relative path of a file or directory specified by path relative to the current working directory of the file or directory of from_file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the absolute path of a file or directory specified by path relative to the parent directory of from_file.", "response": "def absolute_path(path, from_file):\n    \"\"\"\n    Return the absolute path of a file or directory, specified\n    as ``path`` relative to (the parent directory of) ``from_file``.\n\n    This method is intented to be called with ``__file__``\n    as second argument.\n\n    If ``path`` is ``None``, return ``None``.\n\n    Example: ::\n\n        path=\"res/foo.bar\"\n        from_file=\"/abc/def/ghi.py\"\n        => \"/abc/def/res/foo.bar\"\n\n    :param string path: the file path\n    :param string from_file: the reference file\n    :rtype: string\n    \"\"\"\n    if path is None:\n        return None\n    current_directory = os.path.dirname(from_file)\n    target = os.path.join(current_directory, path)\n    return os.path.abspath(target)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the file at the given path and returns its contents as a byte string.", "response": "def read_file_bytes(input_file_path):\n    \"\"\"\n    Read the file at the given file path\n    and return its contents as a byte string,\n    or ``None`` if an error occurred.\n\n    :param string input_file_path: the file path\n    :rtype: bytes\n    \"\"\"\n    contents = None\n    try:\n        with io.open(input_file_path, \"rb\") as input_file:\n            contents = input_file.read()\n    except:\n        pass\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the given number into a human - readable string.", "response": "def human_readable_number(number, suffix=\"\"):\n    \"\"\"\n    Format the given number into a human-readable string.\n\n    Code adapted from http://stackoverflow.com/a/1094933\n\n    :param variant number: the number (int or float)\n    :param string suffix: the unit of the number\n    :rtype: string\n    \"\"\"\n    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n        if abs(number) < 1024.0:\n            return \"%3.1f%s%s\" % (number, unit, suffix)\n        number /= 1024.0\n    return \"%.1f%s%s\" % (number, \"Y\", suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 2:\n            return self.print_help()\n        mode = self.actual_arguments[0]\n\n        validator = Validator(rconf=self.rconf, logger=self.logger)\n        if mode == u\"config\":\n            config_file_path = self.actual_arguments[1]\n            config_txt = None\n            if config_file_path.lower().endswith(u\".txt\"):\n                config_txt = True\n            elif config_file_path.lower().endswith(u\".xml\"):\n                config_txt = False\n            else:\n                return self.print_help()\n            if not self.check_input_file(config_file_path):\n                return self.ERROR_EXIT_CODE\n            contents = gf.read_file_bytes(config_file_path)\n            if contents is None:\n                return self.ERROR_EXIT_CODE\n            if config_txt:\n                result = validator.check_config_txt(contents)\n                msg = u\"TXT configuration\"\n            else:\n                result = validator.check_config_xml(contents)\n                msg = \"XML configuration\"\n        elif mode == u\"container\":\n            container_path = self.actual_arguments[1]\n            result = validator.check_container(container_path)\n            msg = \"container\"\n        elif mode == u\"job\":\n            config_string = self.actual_arguments[1]\n            result = validator.check_configuration_string(config_string, is_job=True)\n            msg = u\"job configuration string\"\n        elif mode == u\"task\":\n            config_string = self.actual_arguments[1]\n            result = validator.check_configuration_string(config_string, is_job=False, external_name=True)\n            msg = u\"task configuration string\"\n        elif mode == u\"wizard\":\n            if (len(self.actual_arguments) < 3) or (self.actual_arguments[2].startswith(u\"-\")):\n                return self.print_help()\n            config_string = self.actual_arguments[1]\n            container_path = self.actual_arguments[2]\n            if not self.check_input_file(container_path):\n                return self.ERROR_EXIT_CODE\n            result = validator.check_container(container_path, config_string=config_string)\n            msg = \"container with configuration string from wizard\"\n        else:\n            return self.print_help()\n\n        if result.passed:\n            self.print_success(u\"Valid %s\" % msg)\n            for warning in result.warnings:\n                self.print_warning(u\"%s\" % warning)\n            return self.NO_ERROR_EXIT_CODE\n        else:\n            self.print_error(u\"Invalid %s\" % msg)\n            for error in result.errors:\n                self.print_error(u\"%s\" % error)\n\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the given key - value pair to the cache.", "response": "def add(self, fragment_info, file_info):\n        \"\"\"\n        Add the given ``(key, value)`` pair to the cache.\n\n        :param fragment_info: the text key\n        :type  fragment_info: tuple of str ``(language, text)``\n        :param file_info: the path value\n        :type  file_info: tuple ``(handler, path)``\n        :raises: ValueError if the key is already present in the cache\n        \"\"\"\n        if self.is_cached(fragment_info):\n            raise ValueError(u\"Attempt to add text already cached\")\n        self.cache[fragment_info] = file_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, fragment_info):\n        if not self.is_cached(fragment_info):\n            raise KeyError(u\"Attempt to get text not cached\")\n        return self.cache[fragment_info]", "response": "Get the value associated with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears the cache and remove all the files from disk.", "response": "def clear(self):\n        \"\"\"\n        Clear the cache and remove all the files from disk.\n        \"\"\"\n        self.log(u\"Clearing cache...\")\n        for file_handler, file_info in self.cache.values():\n            self.log([u\"  Removing file '%s'\", file_info])\n            gf.delete_file(file_handler, file_info)\n        self._initialize_cache()\n        self.log(u\"Clearing cache... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate a language value to a voice code.", "response": "def _language_to_voice_code(self, language):\n        \"\"\"\n        Translate a language value to a voice code.\n\n        If you want to mock support for a language\n        by using a voice for a similar language,\n        please add it to the ``LANGUAGE_TO_VOICE_CODE`` dictionary.\n\n        :param language: the requested language\n        :type  language: :class:`~aeneas.language.Language`\n        :rtype: string\n        \"\"\"\n        voice_code = self.rconf[RuntimeConfiguration.TTS_VOICE_CODE]\n        if voice_code is None:\n            try:\n                voice_code = self.LANGUAGE_TO_VOICE_CODE[language]\n            except KeyError as exc:\n                self.log_exc(u\"Language code '%s' not found in LANGUAGE_TO_VOICE_CODE\" % (language), exc, False, None)\n                self.log_warn(u\"Using the language code as the voice code\")\n                voice_code = language\n        else:\n            self.log(u\"TTS voice override in rconf\")\n        self.log([u\"Language to voice code: '%s' => '%s'\", language, voice_code])\n        return voice_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_cache(self):\n        if self.use_cache:\n            self.log(u\"Requested to clear TTS cache\")\n            self.cache.clear()", "response": "Clear the TTS cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the list of arguments that the wrapper will pass to subprocess.", "response": "def set_subprocess_arguments(self, subprocess_arguments):\n        \"\"\"\n        Set the list of arguments that the wrapper will pass to ``subprocess``.\n\n        Placeholders ``CLI_PARAMETER_*`` can be used, and they will be replaced\n        by actual values in the ``_synthesize_multiple_subprocess()`` and\n        ``_synthesize_single_subprocess()`` built-in functions.\n        Literal parameters will be passed unchanged.\n\n        The list should start with the path to the TTS engine.\n\n        This function should be called in the constructor\n        of concrete subclasses.\n\n        :param list subprocess_arguments: the list of arguments to be passed to\n                                          the TTS engine via subprocess\n        \"\"\"\n        # NOTE this is a method because we might need to access self.rconf,\n        #      so we cannot specify the list of arguments as a class field\n        self.subprocess_arguments = subprocess_arguments\n        self.log([u\"Subprocess arguments: %s\", subprocess_arguments])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef synthesize_multiple(self, text_file, output_file_path, quit_after=None, backwards=False):\n        if text_file is None:\n            self.log_exc(u\"text_file is None\", None, True, TypeError)\n        if len(text_file) < 1:\n            self.log_exc(u\"The text file has no fragments\", None, True, ValueError)\n        if text_file.chars == 0:\n            self.log_exc(u\"All fragments in the text file are empty\", None, True, ValueError)\n        if not self.rconf[RuntimeConfiguration.ALLOW_UNLISTED_LANGUAGES]:\n            for fragment in text_file.fragments:\n                if fragment.language not in self.LANGUAGE_TO_VOICE_CODE:\n                    self.log_exc(u\"Language '%s' is not supported by the selected TTS engine\" % (fragment.language), None, True, ValueError)\n        for fragment in text_file.fragments:\n            for line in fragment.lines:\n                if not gf.is_unicode(line):\n                    self.log_exc(u\"The text file contain a line which is not a Unicode string\", None, True, TypeError)\n\n        # log parameters\n        if quit_after is not None:\n            self.log([u\"Quit after reaching %.3f\", quit_after])\n        if backwards:\n            self.log(u\"Synthesizing backwards\")\n\n        # check that output_file_path can be written\n        if not gf.file_can_be_written(output_file_path):\n            self.log_exc(u\"Cannot write to output file '%s'\" % (output_file_path), None, True, OSError)\n\n        # first, call Python function _synthesize_multiple_python() if available\n        if self.HAS_PYTHON_CALL:\n            self.log(u\"Calling TTS engine via Python\")\n            try:\n                computed, result = self._synthesize_multiple_python(text_file, output_file_path, quit_after, backwards)\n                if computed:\n                    self.log(u\"The _synthesize_multiple_python call was successful, returning anchors\")\n                    return result\n                else:\n                    self.log(u\"The _synthesize_multiple_python call failed\")\n            except Exception as exc:\n                self.log_exc(u\"An unexpected error occurred while calling _synthesize_multiple_python\", exc, False, None)\n\n        # call _synthesize_multiple_c_extension() or _synthesize_multiple_subprocess()\n        self.log(u\"Calling TTS engine via C extension or subprocess\")\n        c_extension_function = self._synthesize_multiple_c_extension if self.HAS_C_EXTENSION_CALL else None\n        subprocess_function = self._synthesize_multiple_subprocess if self.HAS_SUBPROCESS_CALL else None\n        return gf.run_c_extension_with_fallback(\n            self.log,\n            self.C_EXTENSION_NAME,\n            c_extension_function,\n            subprocess_function,\n            (text_file, output_file_path, quit_after, backwards),\n            rconf=self.rconf\n        )", "response": "Synthesize the text contained in the given fragment list into a WAVE file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsynthesizes multiple fragments via a Python call.", "response": "def _synthesize_multiple_python(self, text_file, output_file_path, quit_after=None, backwards=False):\n        \"\"\"\n        Synthesize multiple fragments via a Python call.\n\n        :rtype: tuple (result, (anchors, current_time, num_chars))\n        \"\"\"\n        self.log(u\"Synthesizing multiple via a Python call...\")\n        ret = self._synthesize_multiple_generic(\n            helper_function=self._synthesize_single_python_helper,\n            text_file=text_file,\n            output_file_path=output_file_path,\n            quit_after=quit_after,\n            backwards=backwards\n        )\n        self.log(u\"Synthesizing multiple via a Python call... done\")\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsynthesizing multiple fragments via subprocess.", "response": "def _synthesize_multiple_subprocess(self, text_file, output_file_path, quit_after=None, backwards=False):\n        \"\"\"\n        Synthesize multiple fragments via ``subprocess``.\n\n        :rtype: tuple (result, (anchors, current_time, num_chars))\n        \"\"\"\n        self.log(u\"Synthesizing multiple via subprocess...\")\n        ret = self._synthesize_multiple_generic(\n            helper_function=self._synthesize_single_subprocess_helper,\n            text_file=text_file,\n            output_file_path=output_file_path,\n            quit_after=quit_after,\n            backwards=backwards\n        )\n        self.log(u\"Synthesizing multiple via subprocess... done\")\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _synthesize_single_subprocess_helper(self, text, voice_code, output_file_path=None, return_audio_data=True):\n        # return zero if text is the empty string\n        if len(text) == 0:\n            #\n            # NOTE sample_rate, codec, data do not matter\n            #      if the duration is 0.000 => set them to None\n            #\n            self.log(u\"len(text) is zero: returning 0.000\")\n            return (True, (TimeValue(\"0.000\"), None, None, None))\n\n        # create a temporary output file if needed\n        synt_tmp_file = (output_file_path is None)\n        if synt_tmp_file:\n            self.log(u\"Synthesizer helper called with output_file_path=None => creating temporary output file\")\n            output_file_handler, output_file_path = gf.tmp_file(suffix=u\".wav\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n            self.log([u\"Temporary output file path is '%s'\", output_file_path])\n\n        try:\n            # if the TTS engine reads text from file,\n            # write the text into a temporary file\n            if self.CLI_PARAMETER_TEXT_PATH in self.subprocess_arguments:\n                self.log(u\"TTS engine reads text from file\")\n                tmp_text_file_handler, tmp_text_file_path = gf.tmp_file(suffix=u\".txt\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n                self.log([u\"Creating temporary text file '%s'...\", tmp_text_file_path])\n                with io.open(tmp_text_file_path, \"w\", encoding=\"utf-8\") as tmp_text_file:\n                    tmp_text_file.write(text)\n                self.log([u\"Creating temporary text file '%s'... done\", tmp_text_file_path])\n            else:\n                self.log(u\"TTS engine reads text from stdin\")\n                tmp_text_file_handler = None\n                tmp_text_file_path = None\n\n            # copy all relevant arguments\n            self.log(u\"Creating arguments list...\")\n            arguments = []\n            for arg in self.subprocess_arguments:\n                if arg == self.CLI_PARAMETER_VOICE_CODE_FUNCTION:\n                    arguments.extend(self._voice_code_to_subprocess(voice_code))\n                elif arg == self.CLI_PARAMETER_VOICE_CODE_STRING:\n                    arguments.append(voice_code)\n                elif arg == self.CLI_PARAMETER_TEXT_PATH:\n                    arguments.append(tmp_text_file_path)\n                elif arg == self.CLI_PARAMETER_WAVE_PATH:\n                    arguments.append(output_file_path)\n                elif arg == self.CLI_PARAMETER_TEXT_STDIN:\n                    # placeholder, do not append\n                    pass\n                elif arg == self.CLI_PARAMETER_WAVE_STDOUT:\n                    # placeholder, do not append\n                    pass\n                else:\n                    arguments.append(arg)\n            self.log(u\"Creating arguments list... done\")\n\n            # actual call via subprocess\n            self.log(u\"Calling TTS engine...\")\n            self.log([u\"Calling with arguments '%s'\", arguments])\n            self.log([u\"Calling with text '%s'\", text])\n            proc = subprocess.Popen(\n                arguments,\n                stdout=subprocess.PIPE,\n                stdin=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                universal_newlines=True\n            )\n            if self.CLI_PARAMETER_TEXT_STDIN in self.subprocess_arguments:\n                self.log(u\"Passing text via stdin...\")\n                if gf.PY2:\n                    (stdoutdata, stderrdata) = proc.communicate(input=gf.safe_bytes(text))\n                else:\n                    (stdoutdata, stderrdata) = proc.communicate(input=text)\n                self.log(u\"Passing text via stdin... done\")\n            else:\n                self.log(u\"Passing text via file...\")\n                (stdoutdata, stderrdata) = proc.communicate()\n                self.log(u\"Passing text via file... done\")\n            proc.stdout.close()\n            proc.stdin.close()\n            proc.stderr.close()\n\n            if self.CLI_PARAMETER_WAVE_STDOUT in self.subprocess_arguments:\n                self.log(u\"TTS engine wrote audio data to stdout\")\n                self.log([u\"Writing audio data to file '%s'...\", output_file_path])\n                with io.open(output_file_path, \"wb\") as output_file:\n                    output_file.write(stdoutdata)\n                self.log([u\"Writing audio data to file '%s'... done\", output_file_path])\n            else:\n                self.log(u\"TTS engine wrote audio data to file\")\n\n            if tmp_text_file_path is not None:\n                self.log([u\"Delete temporary text file '%s'\", tmp_text_file_path])\n                gf.delete_file(tmp_text_file_handler, tmp_text_file_path)\n\n            self.log(u\"Calling TTS ... done\")\n        except Exception as exc:\n            self.log_exc(u\"An unexpected error occurred while calling TTS engine via subprocess\", exc, False, None)\n            return (False, None)\n\n        # check the file can be read\n        if not gf.file_can_be_read(output_file_path):\n            self.log_exc(u\"Output file '%s' cannot be read\" % (output_file_path), None, True, None)\n            return (False, None)\n\n        # read audio data\n        ret = self._read_audio_data(output_file_path) if return_audio_data else (True, None)\n\n        # if the output file was temporary, remove it\n        if synt_tmp_file:\n            self.log([u\"Removing temporary output file path '%s'\", output_file_path])\n            gf.delete_file(output_file_handler, output_file_path)\n\n        # return audio data or (True, None)\n        return ret", "response": "This method is used to synthesize a single text fragment via subprocess."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads audio data from file.", "response": "def _read_audio_data(self, file_path):\n        \"\"\"\n        Read audio data from file.\n\n        :rtype: tuple (True, (duration, sample_rate, codec, data)) or (False, None) on exception\n        \"\"\"\n        try:\n            self.log(u\"Reading audio data...\")\n            # if we know the TTS outputs to PCM16 mono WAVE\n            # with the correct sample rate,\n            # we can read samples directly from it,\n            # without an intermediate conversion through ffmpeg\n            audio_file = AudioFile(\n                file_path=file_path,\n                file_format=self.OUTPUT_AUDIO_FORMAT,\n                rconf=self.rconf,\n                logger=self.logger\n            )\n            audio_file.read_samples_from_file()\n            self.log([u\"Duration of '%s': %f\", file_path, audio_file.audio_length])\n            self.log(u\"Reading audio data... done\")\n            return (True, (\n                audio_file.audio_length,\n                audio_file.audio_sample_rate,\n                audio_file.audio_format,\n                audio_file.audio_samples\n            ))\n        except (AudioFileUnsupportedFormatError, OSError) as exc:\n            self.log_exc(u\"An unexpected error occurred while reading audio data\", exc, True, None)\n            return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _synthesize_multiple_generic(self, helper_function, text_file, output_file_path, quit_after=None, backwards=False):\n        self.log(u\"Calling TTS engine using multiple generic function...\")\n\n        # get sample rate and codec\n        self.log(u\"Determining codec and sample rate...\")\n        if (self.OUTPUT_AUDIO_FORMAT is None) or (len(self.OUTPUT_AUDIO_FORMAT) != 3):\n            self.log(u\"Determining codec and sample rate with dummy text...\")\n            succeeded, data = helper_function(\n                text=u\"Dummy text to get sample_rate\",\n                voice_code=self._language_to_voice_code(self.DEFAULT_LANGUAGE),\n                output_file_path=None\n            )\n            if not succeeded:\n                self.log_crit(u\"An unexpected error occurred in helper_function\")\n                return (False, None)\n            du_nu, sample_rate, codec, da_nu = data\n            self.log(u\"Determining codec and sample rate with dummy text... done\")\n        else:\n            self.log(u\"Reading codec and sample rate from OUTPUT_AUDIO_FORMAT\")\n            codec, channels_nu, sample_rate = self.OUTPUT_AUDIO_FORMAT\n        self.log(u\"Determining codec and sample rate... done\")\n        self.log([u\"  codec:       %s\", codec])\n        self.log([u\"  sample rate: %d\", sample_rate])\n\n        # open output file\n        output_file = AudioFile(rconf=self.rconf, logger=self.logger)\n        output_file.audio_format = codec\n        output_file.audio_channels = 1\n        output_file.audio_sample_rate = sample_rate\n\n        # create output\n        anchors = []\n        current_time = TimeValue(\"0.000\")\n        num_chars = 0\n        fragments = text_file.fragments\n        if backwards:\n            fragments = fragments[::-1]\n        loop_function = self._loop_use_cache if self.use_cache else self._loop_no_cache\n        for num, fragment in enumerate(fragments):\n            succeeded, data = loop_function(\n                helper_function=helper_function,\n                num=num,\n                fragment=fragment\n            )\n            if not succeeded:\n                self.log_crit(u\"An unexpected error occurred in loop_function\")\n                return (False, None)\n            duration, sr_nu, enc_nu, samples = data\n            # store for later output\n            anchors.append([current_time, fragment.identifier, fragment.text])\n            # increase the character counter\n            num_chars += fragment.characters\n            # concatenate new samples\n            self.log([u\"Fragment %d starts at: %.3f\", num, current_time])\n            if duration > 0:\n                self.log([u\"Fragment %d duration: %.3f\", num, duration])\n                current_time += duration\n                output_file.add_samples(samples, reverse=backwards)\n            else:\n                self.log([u\"Fragment %d has zero duration\", num])\n            # check if we must stop synthesizing because we have enough audio\n            if (quit_after is not None) and (current_time > quit_after):\n                self.log([u\"Quitting after reached duration %.3f\", current_time])\n                break\n\n        # minimize memory\n        self.log(u\"Minimizing memory...\")\n        output_file.minimize_memory()\n        self.log(u\"Minimizing memory... done\")\n\n        # if backwards, we need to reverse the audio samples again\n        if backwards:\n            self.log(u\"Reversing audio samples...\")\n            output_file.reverse()\n            self.log(u\"Reversing audio samples... done\")\n\n        # write output file\n        self.log([u\"Writing audio file '%s'\", output_file_path])\n        output_file.write(file_path=output_file_path)\n\n        # return output\n        if backwards:\n            self.log_warn(u\"Please note that anchor time values do not make sense since backwards=True\")\n        self.log([u\"Returning %d time anchors\", len(anchors)])\n        self.log([u\"Current time %.3f\", current_time])\n        self.log([u\"Synthesized %d characters\", num_chars])\n        self.log(u\"Calling TTS engine using multiple generic function... done\")\n        return (True, (anchors, current_time, num_chars))", "response": "Synthesize multiple fragments using a generic function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _loop_no_cache(self, helper_function, num, fragment):\n        self.log([u\"Examining fragment %d (no cache)...\", num])\n        # synthesize and get the duration of the output file\n        voice_code = self._language_to_voice_code(fragment.language)\n        self.log(u\"Calling helper function\")\n        succeeded, data = helper_function(\n            text=fragment.filtered_text,\n            voice_code=voice_code,\n            output_file_path=None,\n            return_audio_data=True\n        )\n        # check output\n        if not succeeded:\n            self.log_crit(u\"An unexpected error occurred in helper_function\")\n            return (False, None)\n        self.log([u\"Examining fragment %d (no cache)... done\", num])\n        return (True, data)", "response": "Synthesize all fragments without using the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsynthesizing all fragments using the cache.", "response": "def _loop_use_cache(self, helper_function, num, fragment):\n        \"\"\" Synthesize all fragments using the cache \"\"\"\n        self.log([u\"Examining fragment %d (cache)...\", num])\n        fragment_info = (fragment.language, fragment.filtered_text)\n        if self.cache.is_cached(fragment_info):\n            self.log(u\"Fragment cached: retrieving audio data from cache\")\n\n            # read data from file, whose path is in the cache\n            file_handler, file_path = self.cache.get(fragment_info)\n            self.log([u\"Reading cached fragment at '%s'...\", file_path])\n            succeeded, data = self._read_audio_data(file_path)\n            if not succeeded:\n                self.log_crit(u\"An unexpected error occurred while reading cached audio file\")\n                return (False, None)\n            self.log([u\"Reading cached fragment at '%s'... done\", file_path])\n        else:\n            self.log(u\"Fragment not cached: synthesizing and caching\")\n\n            # creating destination file\n            file_info = gf.tmp_file(suffix=u\".cache.wav\", root=self.rconf[RuntimeConfiguration.TMP_PATH])\n            file_handler, file_path = file_info\n            self.log([u\"Synthesizing fragment to '%s'...\", file_path])\n\n            # synthesize and get the duration of the output file\n            voice_code = self._language_to_voice_code(fragment.language)\n            self.log(u\"Calling helper function\")\n            succeeded, data = helper_function(\n                text=fragment.filtered_text,\n                voice_code=voice_code,\n                output_file_path=file_path,\n                return_audio_data=True\n            )\n            # check output\n            if not succeeded:\n                self.log_crit(u\"An unexpected error occurred in helper_function\")\n                return (False, None)\n            self.log([u\"Synthesizing fragment to '%s'... done\", file_path])\n            duration, sr_nu, enc_nu, samples = data\n            if duration > 0:\n                self.log(u\"Fragment has > 0 duration, adding it to cache\")\n                self.cache.add(fragment_info, file_info)\n                self.log(u\"Added fragment to cache\")\n            else:\n                self.log(u\"Fragment has zero duration, not adding it to cache\")\n            self.log([u\"Closing file handler for cached output file path '%s'\", file_path])\n            gf.close_file_handler(file_handler)\n        self.log([u\"Examining fragment %d (cache)... done\", num])\n        return (True, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort(self, ids):\n        def extract_int(string):\n            \"\"\"\n            Extract an integer from the given string.\n\n            :param string string: the identifier string\n            :rtype: int\n            \"\"\"\n            return int(re.sub(r\"[^0-9]\", \"\", string))\n\n        tmp = list(ids)\n        if self.algorithm == IDSortingAlgorithm.UNSORTED:\n            self.log(u\"Sorting using UNSORTED\")\n        elif self.algorithm == IDSortingAlgorithm.LEXICOGRAPHIC:\n            self.log(u\"Sorting using LEXICOGRAPHIC\")\n            tmp = sorted(ids)\n        elif self.algorithm == IDSortingAlgorithm.NUMERIC:\n            self.log(u\"Sorting using NUMERIC\")\n            tmp = ids\n            try:\n                tmp = sorted(tmp, key=extract_int)\n            except (ValueError, TypeError) as exc:\n                self.log_exc(u\"Not all id values contain a numeric part. Returning the id list unchanged.\", exc, False, None)\n        return tmp", "response": "Sort the given list of identifiers and return a new list of identifiers sorted by the given algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadjusts the boundary of the current sync map entry for the given set of attributes.", "response": "def adjust(\n        self,\n        aba_parameters,\n        boundary_indices,\n        real_wave_mfcc,\n        text_file,\n        allow_arbitrary_shift=False\n    ):\n        \"\"\"\n        Adjust the boundaries of the text map\n        using the algorithm and parameters\n        specified in the constructor,\n        storing the sync map fragment list internally.\n\n        :param dict aba_parameters: a dictionary containing the algorithm and its parameters,\n                                    as produced by ``aba_parameters()`` in ``TaskConfiguration``\n        :param boundary_indices: the current boundary indices,\n                                 with respect to the audio file full MFCCs\n        :type  boundary_indices: :class:`numpy.ndarray` (1D)\n        :param real_wave_mfcc: the audio file MFCCs\n        :type  real_wave_mfcc: :class:`~aeneas.audiofilemfcc.AudioFileMFCC`\n        :param text_file: the text file containing the text fragments associated\n        :type  text_file: :class:`~aeneas.textfile.TextFile`\n        :param bool allow_arbitrary_shift: if ``True``, allow arbitrary shifts when adjusting zero length\n\n        :rtype: list of :class:`~aeneas.syncmap.SyncMapFragmentList`\n        \"\"\"\n        self.log(u\"Called adjust\")\n        if boundary_indices is None:\n            self.log_exc(u\"boundary_indices is None\", None, True, TypeError)\n        if not isinstance(real_wave_mfcc, AudioFileMFCC):\n            self.log_exc(u\"real_wave_mfcc is not an AudioFileMFCC object\", None, True, TypeError)\n        if not isinstance(text_file, TextFile):\n            self.log_exc(u\"text_file is not a TextFile object\", None, True, TypeError)\n\n        nozero = aba_parameters[\"nozero\"]\n        ns_min, ns_string = aba_parameters[\"nonspeech\"]\n        algorithm, algo_parameters = aba_parameters[\"algorithm\"]\n\n        self.log(u\"  Converting boundary indices to fragment list...\")\n        begin = real_wave_mfcc.middle_begin * real_wave_mfcc.rconf.mws\n        end = real_wave_mfcc.middle_end * real_wave_mfcc.rconf.mws\n        time_values = [begin] + list(boundary_indices * self.mws) + [end]\n        self.intervals_to_fragment_list(\n            text_file=text_file,\n            time_values=time_values\n        )\n        self.log(u\"  Converting boundary indices to fragment list... done\")\n\n        self.log(u\"  Processing fragments with zero length...\")\n        self._process_zero_length(nozero, allow_arbitrary_shift)\n        self.log(u\"  Processing fragments with zero length... done\")\n\n        self.log(u\"  Processing nonspeech fragments...\")\n        self._process_long_nonspeech(ns_min, ns_string, real_wave_mfcc)\n        self.log(u\"  Processing nonspeech fragments... done\")\n\n        self.log(u\"  Adjusting...\")\n        ALGORITHM_MAP = {\n            self.AFTERCURRENT: self._adjust_aftercurrent,\n            self.AUTO: self._adjust_auto,\n            self.BEFORENEXT: self._adjust_beforenext,\n            self.OFFSET: self._adjust_offset,\n            self.PERCENT: self._adjust_percent,\n            self.RATE: self._adjust_rate,\n            self.RATEAGGRESSIVE: self._adjust_rate_aggressive,\n        }\n        ALGORITHM_MAP[algorithm](real_wave_mfcc, algo_parameters)\n        self.log(u\"  Adjusting... done\")\n\n        self.log(u\"  Smoothing...\")\n        self._smooth_fragment_list(real_wave_mfcc.audio_length, ns_string)\n        self.log(u\"  Smoothing... done\")\n\n        return self.smflist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a list of at least 3 time values into a sync map fragment list.", "response": "def intervals_to_fragment_list(self, text_file, time_values):\n        \"\"\"\n        Transform a list of at least 4 time values\n        (corresponding to at least 3 intervals)\n        into a sync map fragment list and store it internally.\n        The first interval is a HEAD, the last is a TAIL.\n\n        For example:\n\n            time_values=[0.000, 1.000, 2.000, 3.456] => [(0.000, 1.000), (1.000, 2.000), (2.000, 3.456)]\n\n        :param text_file: the text file containing the text fragments associated\n        :type  text_file: :class:`~aeneas.textfile.TextFile`\n        :param time_values: the time values\n        :type  time_values: list of :class:`~aeneas.exacttiming.TimeValue`\n        :raises: TypeError: if ``text_file`` is not an instance of :class:`~aeneas.textfile.TextFile`\n                            or ``time_values`` is not a list\n        :raises: ValueError: if ``time_values`` has length less than four\n        \"\"\"\n        if not isinstance(text_file, TextFile):\n            self.log_exc(u\"text_file is not an instance of TextFile\", None, True, TypeError)\n        if not isinstance(time_values, list):\n            self.log_exc(u\"time_values is not a list\", None, True, TypeError)\n        if len(time_values) < 4:\n            self.log_exc(u\"time_values has length < 4\", None, True, ValueError)\n        self.log(u\"Converting time values to fragment list...\")\n        begin = time_values[0]\n        end = time_values[-1]\n        self.log([u\"  Creating SyncMapFragmentList with begin %.3f and end %.3f\", begin, end])\n        self.smflist = SyncMapFragmentList(\n            begin=begin,\n            end=end,\n            rconf=self.rconf,\n            logger=self.logger\n        )\n        self.log(u\"  Creating HEAD fragment\")\n        self.smflist.add(SyncMapFragment(\n            # NOTE lines and filtered lines MUST be set,\n            #      otherwise some output format might break\n            #      when adding HEAD/TAIL to output\n            text_fragment=TextFragment(identifier=u\"HEAD\", lines=[], filtered_lines=[]),\n            begin=time_values[0],\n            end=time_values[1],\n            fragment_type=SyncMapFragment.HEAD\n        ), sort=False)\n        self.log(u\"  Creating REGULAR fragments\")\n        # NOTE text_file.fragments() returns a list,\n        #      so we cache a copy here instead of\n        #      calling it once per loop\n        fragments = text_file.fragments\n        for i in range(1, len(time_values) - 2):\n            self.log([u\"    Adding fragment %d ...\", i])\n            self.smflist.add(SyncMapFragment(\n                text_fragment=fragments[i - 1],\n                begin=time_values[i],\n                end=time_values[i + 1],\n                fragment_type=SyncMapFragment.REGULAR\n            ), sort=False)\n            self.log([u\"    Adding fragment %d ... done\", i])\n        self.log(u\"  Creating TAIL fragment\")\n        self.smflist.add(SyncMapFragment(\n            # NOTE lines and filtered lines MUST be set,\n            #      otherwise some output format might break\n            #      when adding HEAD/TAIL to output\n            text_fragment=TextFragment(identifier=u\"TAIL\", lines=[], filtered_lines=[]),\n            begin=time_values[len(time_values) - 2],\n            end=end,\n            fragment_type=SyncMapFragment.TAIL\n        ), sort=False)\n        self.log(u\"Converting time values to fragment list... done\")\n        self.log(u\"Sorting fragment list...\")\n        self.smflist.sort()\n        self.log(u\"Sorting fragment list... done\")\n        return self.smflist"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend the list of nodes from the given sync map tree to the given sync map root.", "response": "def append_fragment_list_to_sync_root(self, sync_root):\n        \"\"\"\n        Append the sync map fragment list\n        to the given node from a sync map tree.\n\n        :param sync_root: the root of the sync map tree to which the new nodes should be appended\n        :type  sync_root: :class:`~aeneas.tree.Tree`\n        \"\"\"\n        if not isinstance(sync_root, Tree):\n            self.log_exc(u\"sync_root is not a Tree object\", None, True, TypeError)\n\n        self.log(u\"Appending fragment list to sync root...\")\n        for fragment in self.smflist:\n            sync_root.add_child(Tree(value=fragment))\n        self.log(u\"Appending fragment list to sync root... done\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _smooth_fragment_list(self, real_wave_mfcc_audio_length, ns_string):\n        self.log(u\"Called _smooth_fragment_list\")\n        self.smflist[0].begin = TimeValue(\"0.000\")\n        self.smflist[-1].end = real_wave_mfcc_audio_length\n        if ns_string in [None, gc.PPV_TASK_ADJUST_BOUNDARY_NONSPEECH_REMOVE]:\n            self.log(u\"Remove all NONSPEECH fragments\")\n            self.smflist.remove_nonspeech_fragments(zero_length_only=False)\n        else:\n            self.log(u\"Remove NONSPEECH fragments with zero length only\")\n            self.smflist.remove_nonspeech_fragments(zero_length_only=True)", "response": "Remove non - speech fragments from the list if needed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _adjust_auto(self, real_wave_mfcc, algo_parameters):\n        self.log(u\"Called _adjust_auto\")\n        self.log(u\"Nothing to do, return unchanged\")", "response": "Adjust the autocorrelation of the autocorrelation of the current set of wavems."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadjusting the offset of the wave file.", "response": "def _adjust_offset(self, real_wave_mfcc, algo_parameters):\n        \"\"\"\n        OFFSET\n        \"\"\"\n        self.log(u\"Called _adjust_offset\")\n        self._apply_offset(offset=algo_parameters[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _adjust_percent(self, real_wave_mfcc, algo_parameters):\n        def new_time(nsi):\n            \"\"\"\n            The new boundary time value is ``percent``\n            of the nonspeech interval ``nsi``.\n            \"\"\"\n            percent = Decimal(algo_parameters[0])\n            return nsi.percent_value(percent)\n        self.log(u\"Called _adjust_percent\")\n        self._adjust_on_nonspeech(real_wave_mfcc, new_time)", "response": "Adjust the percent of the nonspeech interval."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadjust the time of the nonspeech interval after the current time.", "response": "def _adjust_aftercurrent(self, real_wave_mfcc, algo_parameters):\n        \"\"\"\n        AFTERCURRENT\n        \"\"\"\n        def new_time(nsi):\n            \"\"\"\n            The new boundary time value is ``delay`` after\n            the begin of the nonspeech interval ``nsi``.\n            If ``nsi`` has length less than ``delay``,\n            set the new boundary time to the end of ``nsi``.\n            \"\"\"\n            delay = max(algo_parameters[0], TimeValue(\"0.000\"))\n            return min(nsi.begin + delay, nsi.end)\n        self.log(u\"Called _adjust_aftercurrent\")\n        self._adjust_on_nonspeech(real_wave_mfcc, new_time)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _adjust_beforenext(self, real_wave_mfcc, algo_parameters):\n        def new_time(nsi):\n            \"\"\"\n            The new boundary time value is ``delay`` before\n            the end of the nonspeech interval ``nsi``.\n            If ``nsi`` has length less than ``delay``,\n            set the new boundary time to the begin of ``nsi``.\n            \"\"\"\n            delay = max(algo_parameters[0], TimeValue(\"0.000\"))\n            return max(nsi.end - delay, nsi.begin)\n        self.log(u\"Called _adjust_beforenext\")\n        self._adjust_on_nonspeech(real_wave_mfcc, new_time)", "response": "Adjust the time of the nonspeech interval before the next nonspeech."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadjusting the rate of the current wave module.", "response": "def _adjust_rate(self, real_wave_mfcc, algo_parameters):\n        \"\"\"\n        RATE\n        \"\"\"\n        self.log(u\"Called _adjust_rate\")\n        self._apply_rate(max_rate=algo_parameters[0], aggressive=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _adjust_rate_aggressive(self, real_wave_mfcc, algo_parameters):\n        self.log(u\"Called _adjust_rate_aggressive\")\n        self._apply_rate(max_rate=algo_parameters[0], aggressive=True)", "response": "Adjust the rate of aggressive wavepasses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _apply_offset(self, offset):\n        if not isinstance(offset, TimeValue):\n            self.log_exc(u\"offset is not an instance of TimeValue\", None, True, TypeError)\n        self.log([u\"Applying offset %s\", offset])\n        self.smflist.offset(offset)", "response": "Apply the given offset to all time intervals."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadjusts the adjust_function to the values of the nonspeech intervals in the real_wave_mfcc.", "response": "def _adjust_on_nonspeech(self, real_wave_mfcc, adjust_function):\n        \"\"\"\n        Apply the adjust function to each boundary point\n        falling inside (extrema included) of a nonspeech interval.\n\n        The adjust function is not applied to a boundary index\n        if there are two or more boundary indices falling\n        inside the same nonspeech interval.\n\n        The adjust function is not applied to the last boundary index\n        to avoid anticipating the end of the audio file.\n\n        The ``adjust function`` takes\n        the nonspeech interval as its only argument.\n        \"\"\"\n        self.log(u\"Called _adjust_on_nonspeech\")\n        self.log(u\"  Getting nonspeech intervals...\")\n        nonspeech_intervals = real_wave_mfcc.intervals(speech=False, time=True)\n        self.log(u\"  Getting nonspeech intervals... done\")\n\n        self.log(u\"  First pass: find pairs of adjacent fragments transitioning inside nonspeech\")\n        tolerance = self.rconf[RuntimeConfiguration.ABA_NONSPEECH_TOLERANCE]\n        self.log([u\"    Tolerance: %.3f\", tolerance])\n        pairs = self.smflist.fragments_ending_inside_nonspeech_intervals(nonspeech_intervals, tolerance)\n        self.log(u\"  First pass: done\")\n\n        self.log(u\"  Second pass: move end point of good pairs\")\n        for nsi, frag_index, in pairs:\n            new_value = adjust_function(nsi)\n            self.log([u\"    Current interval: %s\", self.smflist[frag_index].interval])\n            self.log([u\"    New value:        %.3f\", new_value])\n            self.smflist.move_transition_point(frag_index, new_value)\n            self.log([u\"    New interval:     %s\", self.smflist[frag_index].interval])\n            self.log(u\"\")\n        self.log(u\"  Second pass: done\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply_rate(self, max_rate, aggressive=False):\n        self.log(u\"Called _apply_rate\")\n        self.log([u\"  Aggressive: %s\", aggressive])\n        self.log([u\"  Max rate:   %.3f\", max_rate])\n        regular_fragments = list(self.smflist.regular_fragments)\n        if len(regular_fragments) <= 1:\n            self.log(u\"  The list contains at most one regular fragment, returning\")\n            return\n        faster_fragments = [(i, f) for i, f in regular_fragments if (f.rate is not None) and (f.rate >= max_rate + Decimal(\"0.001\"))]\n        if len(faster_fragments) == 0:\n            self.log(u\"  No regular fragment faster than max rate, returning\")\n            return\n        self.log_warn(u\"  Some fragments have rate faster than max rate:\")\n        self.log([u\"  %s\", [i for i, f in faster_fragments]])\n        self.log(u\"Fixing rate for faster fragments...\")\n        for frag_index, fragment in faster_fragments:\n            self.smflist.fix_fragment_rate(frag_index, max_rate, aggressive=aggressive)\n        self.log(u\"Fixing rate for faster fragments... done\")\n        faster_fragments = [(i, f) for i, f in regular_fragments if (f.rate is not None) and (f.rate >= max_rate + Decimal(\"0.001\"))]\n        if len(faster_fragments) > 0:\n            self.log_warn(u\"  Some fragments still have rate faster than max rate:\")\n            self.log([u\"  %s\", [i for i, f in faster_fragments]])", "response": "This function applies the rate of the slack to the current slack and returns the new slack version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_vad(\n        self,\n        wave_energy,\n        log_energy_threshold=None,\n        min_nonspeech_length=None,\n        extend_before=None,\n        extend_after=None\n    ):\n        \"\"\"\n        Compute the time intervals containing speech and nonspeech,\n        and return a boolean mask with speech frames set to ``True``,\n        and nonspeech frames set to ``False``.\n\n        The last four parameters might be ``None``:\n        in this case, the corresponding RuntimeConfiguration values\n        are applied.\n\n        :param wave_energy: the energy vector of the audio file (0-th MFCC)\n        :type  wave_energy: :class:`numpy.ndarray` (1D)\n        :param float log_energy_threshold: the minimum log energy threshold to consider a frame as speech\n        :param int min_nonspeech_length: the minimum length, in frames, of a nonspeech interval\n        :param int extend_before: extend each speech interval by this number of frames to the left (before)\n        :param int extend_after: extend each speech interval by this number of frames to the right (after)\n        :rtype: :class:`numpy.ndarray` (1D)\n        \"\"\"\n        self.log(u\"Computing VAD for wave\")\n        mfcc_window_shift = self.rconf.mws\n        self.log([u\"MFCC window shift (s):         %.3f\", mfcc_window_shift])\n        if log_energy_threshold is None:\n            log_energy_threshold = self.rconf[RuntimeConfiguration.VAD_LOG_ENERGY_THRESHOLD]\n            self.log([u\"Log energy threshold:          %.3f\", log_energy_threshold])\n        if min_nonspeech_length is None:\n            min_nonspeech_length = int(self.rconf[RuntimeConfiguration.VAD_MIN_NONSPEECH_LENGTH] / mfcc_window_shift)\n            self.log([u\"Min nonspeech length (s):      %.3f\", self.rconf[RuntimeConfiguration.VAD_MIN_NONSPEECH_LENGTH]])\n        if extend_before is None:\n            extend_before = int(self.rconf[RuntimeConfiguration.VAD_EXTEND_SPEECH_INTERVAL_BEFORE] / mfcc_window_shift)\n            self.log([u\"Extend speech before (s):      %.3f\", self.rconf[RuntimeConfiguration.VAD_EXTEND_SPEECH_INTERVAL_BEFORE]])\n        if extend_after is None:\n            extend_after = int(self.rconf[RuntimeConfiguration.VAD_EXTEND_SPEECH_INTERVAL_AFTER] / mfcc_window_shift)\n            self.log([u\"Extend speech after (s):       %.3f\", self.rconf[RuntimeConfiguration.VAD_EXTEND_SPEECH_INTERVAL_AFTER]])\n        energy_length = len(wave_energy)\n        energy_threshold = numpy.min(wave_energy) + log_energy_threshold\n        self.log([u\"Min nonspeech length (frames): %d\", min_nonspeech_length])\n        self.log([u\"Extend speech before (frames): %d\", extend_before])\n        self.log([u\"Extend speech after (frames):  %d\", extend_after])\n        self.log([u\"Energy vector length (frames): %d\", energy_length])\n        self.log([u\"Energy threshold (log):        %.3f\", energy_threshold])\n\n        # using windows to be sure we have at least\n        # min_nonspeech_length consecutive frames with nonspeech\n        self.log(u\"Determining initial labels...\")\n        mask = wave_energy >= energy_threshold\n        windows = self._rolling_window(mask, min_nonspeech_length)\n        nonspeech_runs = self._compute_runs((numpy.where(numpy.sum(windows, axis=1) == 0))[0])\n        self.log(u\"Determining initial labels... done\")\n\n        # initially, everything is marked as speech\n        # we remove the nonspeech intervals as needed,\n        # possibly extending the adjacent speech interval\n        # if requested by the user\n        self.log(u\"Determining final labels...\")\n        mask = numpy.ones(energy_length, dtype=\"bool\")\n        for ns in nonspeech_runs:\n            start = ns[0]\n            if (extend_after > 0) and (start > 0):\n                start += extend_after\n            stop = ns[-1] + min_nonspeech_length\n            if (extend_before > 0) and (stop < energy_length - 1):\n                stop -= extend_before\n            mask[start:stop] = 0\n        self.log(u\"Determining final labels... done\")\n        return mask", "response": "Compute the time intervals containing speech and nonspeech and return a boolean mask with speech frames set to True and nonspeech frames set to False."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing runs as a list of arrays each containing the indices of a contiguous run.", "response": "def _compute_runs(self, array):\n        \"\"\"\n        Compute runs as a list of arrays,\n        each containing the indices of a contiguous run.\n\n        :param array: the data array\n        :type  array: numpy 1D array\n        :rtype: list of numpy 1D arrays\n        \"\"\"\n        if len(array) < 1:\n            return []\n        return numpy.split(array, numpy.where(numpy.diff(array) != 1)[0] + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the rolling windows of width size of the given array.", "response": "def _rolling_window(self, array, size):\n        \"\"\"\n        Compute rolling windows of width ``size`` of the given array.\n\n        Return a numpy 2D stride array,\n        where rows are the windows, each of ``size`` elements.\n\n        :param array: the data array\n        :type  array: numpy 1D array (n)\n        :param int size: the width of each window\n        :rtype: numpy 2D stride array (n // size, size)\n        \"\"\"\n        shape = array.shape[:-1] + (array.shape[-1] - size + 1, size)\n        strides = array.strides + (array.strides[-1],)\n        return numpy.lib.stride_tricks.as_strided(array, shape=shape, strides=strides)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms the command and return the appropriate exit code.", "response": "def perform_command(self):\n        \"\"\"\n        Perform command and return the appropriate exit code.\n\n        :rtype: int\n        \"\"\"\n        if len(self.actual_arguments) < 1:\n            return self.print_help()\n        audio_file_path = self.actual_arguments[0]\n\n        try:\n            audiofile = AudioFile(audio_file_path, rconf=self.rconf, logger=self.logger)\n            audiofile.read_properties()\n            if self.has_option([u\"-f\", u\"--full\"]):\n                audiofile.read_samples_from_file()\n            self.print_generic(audiofile.__unicode__())\n            return self.NO_ERROR_EXIT_CODE\n        except OSError:\n            self.print_error(u\"Cannot read file '%s'\" % (audio_file_path))\n            self.print_error(u\"Make sure the input file path is written/escaped correctly\")\n        except AudioFileProbeError:\n            self.print_error(u\"Unable to call the ffprobe executable '%s'\" % (self.rconf[RuntimeConfiguration.FFPROBE_PATH]))\n            self.print_error(u\"Make sure the path to ffprobe is correct\")\n        except AudioFileUnsupportedFormatError:\n            self.print_error(u\"Cannot read properties of file '%s'\" % (audio_file_path))\n            self.print_error(u\"Make sure the input file has a format supported by ffprobe\")\n\n        return self.ERROR_EXIT_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of a distutils build directory", "response": "def distutils_dir_name(dname):\n    \"\"\"Returns the name of a distutils build directory\n    see: http://stackoverflow.com/questions/14320220/\n               testing-python-c-libraries-get-build-path\n    \"\"\"\n    f = \"{dirname}.{platform}-{version[0]}.{version[1]}\"\n    return f.format(dirname=dname,\n                    platform=sysconfig.get_platform(),\n                    version=sys.version_info)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the samtools usage information for this command", "response": "def usage(self):\n        '''return the samtools usage information for this command'''\n        retval, stderr, stdout = _pysam_dispatch(\n            self.collection,\n            self.dispatch,\n            is_usage=True,\n            catch_stdout=True)\n        # some tools write usage to stderr, such as mpileup\n        if stderr:\n            return stderr\n        else:\n            return stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over samtools pileup - c formatted file. infile can be any iterator over a lines.", "response": "def iterate(infile):\n    '''iterate over ``samtools pileup -c`` formatted file.\n\n    *infile* can be any iterator over a lines.\n\n    The function yields named tuples of the type :class:`pysam.Pileup.PileupSubstitution`\n    or :class:`pysam.Pileup.PileupIndel`.\n\n    .. note::\n\n       The parser converts to 0-based coordinates\n    '''\n\n    conv_subst = (str, lambda x: int(x) - 1, str,\n                  str, int, int, int, int, str, str)\n    conv_indel = (str, lambda x: int(x) - 1, str, str, int,\n                  int, int, int, str, str, int, int, int)\n\n    for line in infile:\n        d = line[:-1].split()\n        if d[2] == \"*\":\n            try:\n                yield PileupIndel(*[x(y) for x, y in zip(conv_indel, d)])\n            except TypeError:\n                raise pysam.SamtoolsError(\"parsing error in line: `%s`\" % line)\n        else:\n            try:\n                yield PileupSubstitution(*[x(y) for x, y in zip(conv_subst, d)])\n            except TypeError:\n                raise pysam.SamtoolsError(\"parsing error in line: `%s`\" % line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef translateIndelGenotypeFromVCF(vcf_genotypes, ref):\n    '''translate indel from vcf to pileup format.'''\n\n    # indels\n    def getPrefix(s1, s2):\n        '''get common prefix of strings s1 and s2.'''\n        n = min(len(s1), len(s2))\n        for x in range(n):\n            if s1[x] != s2[x]:\n                return s1[:x]\n        return s1[:n]\n\n    def getSuffix(s1, s2):\n        '''get common sufix of strings s1 and s2.'''\n        n = min(len(s1), len(s2))\n        if s1[-1] != s2[-1]:\n            return \"\"\n        for x in range(-2, -n - 1, -1):\n            if s1[x] != s2[x]:\n                return s1[x + 1:]\n        return s1[-n:]\n\n    def getGenotype(variant, ref):\n\n        if variant == ref:\n            return \"*\", 0\n\n        if len(ref) > len(variant):\n            # is a deletion\n            if ref.startswith(variant):\n                return \"-%s\" % ref[len(variant):], len(variant) - 1\n            elif ref.endswith(variant):\n                return \"-%s\" % ref[:-len(variant)], -1\n            else:\n                prefix = getPrefix(ref, variant)\n                suffix = getSuffix(ref, variant)\n                shared = len(prefix) + len(suffix) - len(variant)\n                # print \"-\", prefix, suffix, ref, variant, shared, len(prefix), len(suffix), len(ref)\n                if shared < 0:\n                    raise ValueError()\n                return \"-%s\" % ref[len(prefix):-(len(suffix) - shared)], len(prefix) - 1\n\n        elif len(ref) < len(variant):\n            # is an insertion\n            if variant.startswith(ref):\n                return \"+%s\" % variant[len(ref):], len(ref) - 1\n            elif variant.endswith(ref):\n                return \"+%s\" % variant[:len(ref)], 0\n            else:\n                prefix = getPrefix(ref, variant)\n                suffix = getSuffix(ref, variant)\n                shared = len(prefix) + len(suffix) - len(ref)\n                if shared < 0:\n                    raise ValueError()\n\n                return \"+%s\" % variant[len(prefix):-(len(suffix) - shared)], len(prefix)\n        else:\n            assert 0, \"snp?\"\n\n    # in pileup, the position refers to the base\n    # after the coordinate, hence subtract 1\n    # pos -= 1\n\n    genotypes, offsets = [], []\n    is_error = True\n\n    for variant in vcf_genotypes:\n        try:\n            g, offset = getGenotype(variant, ref)\n        except ValueError:\n            break\n\n        genotypes.append(g)\n        if g != \"*\":\n            offsets.append(offset)\n\n    else:\n        is_error = False\n\n    if is_error:\n        raise ValueError()\n\n    assert len(set(offsets)) == 1, \"multiple offsets for indel\"\n    offset = offsets[0]\n\n    genotypes = \"/\".join(genotypes)\n    return genotypes, offset", "response": "translate indel from vcf to pileup format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vcf2pileup(vcf, sample):\n    '''convert vcf record to pileup record.'''\n\n    chromosome = vcf.contig\n    pos = vcf.pos\n    reference = vcf.ref\n    allelles = [reference] + vcf.alt\n\n    data = vcf[sample]\n\n    # get genotype\n    genotypes = data[\"GT\"]\n    if len(genotypes) > 1:\n        raise ValueError(\"only single genotype per position, %s\" % (str(vcf)))\n\n    genotypes = genotypes[0]\n\n    # not a variant\n    if genotypes[0] == \".\":\n        return None\n\n    genotypes = [allelles[int(x)] for x in genotypes if x != \"/\"]\n\n    # snp_quality is \"genotype quality\"\n    snp_quality = consensus_quality = data.get(\"GQ\", [0])[0]\n    mapping_quality = vcf.info.get(\"MQ\", [0])[0]\n    coverage = data.get(\"DP\", 0)\n\n    if len(reference) > 1 or max([len(x) for x in vcf.alt]) > 1:\n        # indel\n        genotype, offset = translateIndelGenotypeFromVCF(genotypes, reference)\n\n        return PileupIndel(chromosome,\n                           pos + offset,\n                           \"*\",\n                           genotype,\n                           consensus_quality,\n                           snp_quality,\n                           mapping_quality,\n                           coverage,\n                           genotype,\n                           \"<\" * len(genotype),\n                           0,\n                           0,\n                           0)\n\n    else:\n        genotype = encodeGenotype(\"\".join(genotypes))\n        read_bases = \"\"\n        base_qualities = \"\"\n\n        return PileupSubstitution(chromosome, pos, reference,\n                                  genotype, consensus_quality,\n                                  snp_quality, mapping_quality,\n                                  coverage, read_bases,\n                                  base_qualities)", "response": "convert vcf record to pileup record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over a vcf - formatted file and yield a list of named tuples of type and the corresponding pileup indels.", "response": "def iterate_from_vcf(infile, sample):\n    '''iterate over a vcf-formatted file.\n\n    *infile* can be any iterator over a lines.\n\n    The function yields named tuples of the type\n    :class:`pysam.Pileup.PileupSubstitution` or\n    :class:`pysam.Pileup.PileupIndel`.\n\n    Positions without a snp will be skipped.\n\n    This method is wasteful and written to support same legacy code\n    that expects samtools pileup output.\n\n    Better use the vcf parser directly.\n\n    '''\n    vcf = pysam.VCF()\n    vcf.connect(infile)\n\n    if sample not in vcf.getsamples():\n        raise KeyError(\"sample %s not vcf file\")\n\n    for row in vcf.fetch():\n        result = vcf2pileup(row, sample)\n        if result:\n            yield result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_pysam_files(cf, destdir):\n    '''update pysam files applying redirection of ouput'''\n    basename = os.path.basename(destdir)\n    for filename in cf:\n        if not filename:\n            continue\n        dest = filename + \".pysam.c\"\n        with open(filename, encoding=\"utf-8\") as infile:\n            lines = \"\".join(infile.readlines())\n\n            with open(dest, \"w\", encoding=\"utf-8\") as outfile:\n                outfile.write('#include \"{}.pysam.h\"\\n\\n'.format(basename))\n                subname, _ = os.path.splitext(os.path.basename(filename))\n                if subname in MAIN.get(basename, []):\n                    lines = re.sub(r\"int main\\(\", \"int {}_main(\".format(\n                        basename), lines)\n                else:\n                    lines = re.sub(r\"int main\\(\", \"int {}_{}_main(\".format(\n                        basename, subname), lines)\n                lines = re.sub(\"stderr\", \"{}_stderr\".format(basename), lines)\n                lines = re.sub(\"stdout\", \"{}_stdout\".format(basename), lines)\n                lines = re.sub(r\" printf\\(\", \" fprintf({}_stdout, \".format(basename), lines)\n                lines = re.sub(r\"([^kf])puts\\(\", r\"\\1{}_puts(\".format(basename), lines)\n                lines = re.sub(r\"putchar\\(([^)]+)\\)\",\n                               r\"fputc(\\1, {}_stdout)\".format(basename), lines)\n\n                fn = os.path.basename(filename)\n                # some specific fixes:\n                SPECIFIC_SUBSTITUTIONS = {\n                    \"bam_md.c\": (\n                        'sam_open_format(\"-\", mode_w',\n                        'sam_open_format({}_stdout_fn, mode_w'.format(basename)),\n                    \"phase.c\": (\n                        'putc(\"ACGT\"[f->seq[j] == 1? (c&3, {}_stdout) : (c>>16&3)]);'.format(basename),\n                        'putc(\"ACGT\"[f->seq[j] == 1? (c&3) : (c>>16&3)], {}_stdout);'.format(basename)),\n                    \"cut_target.c\": (\n                        'putc(33 + (cns[j]>>8>>2, {}_stdout));'.format(basename),\n                        'putc(33 + (cns[j]>>8>>2), {}_stdout);'.format(basename))\n                    }\n                if fn in SPECIFIC_SUBSTITUTIONS:\n                    lines = lines.replace(\n                        SPECIFIC_SUBSTITUTIONS[fn][0],\n                        SPECIFIC_SUBSTITUTIONS[fn][1])\n                outfile.write(lines)\n\n    with open(os.path.join(\"import\", \"pysam.h\")) as inf, \\\n         open(os.path.join(destdir, \"{}.pysam.h\".format(basename)), \"w\") as outf:\n        outf.write(re.sub(\"@pysam@\", basename, inf.read()))\n\n    with open(os.path.join(\"import\", \"pysam.c\")) as inf, \\\n         open(os.path.join(destdir, \"{}.pysam.c\".format(basename)), \"w\") as outf:\n        outf.write(re.sub(\"@pysam@\", basename, inf.read()))", "response": "update pysam files applying redirection of ouput"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of include directories.", "response": "def get_include():\n    '''return a list of include directories.'''\n    dirname = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n\n    #\n    # Header files may be stored in different relative locations\n    # depending on installation mode (e.g., `python setup.py install`,\n    # `python setup.py develop`. The first entry in each list is\n    # where develop-mode headers can be found.\n    #\n    htslib_possibilities = [os.path.join(dirname, '..', 'htslib'),\n                            os.path.join(dirname, 'include', 'htslib')]\n    samtool_possibilities = [os.path.join(dirname, '..', 'samtools'),\n                             os.path.join(dirname, 'include', 'samtools')]\n\n    includes = [dirname]\n    for header_locations in [htslib_possibilities, samtool_possibilities]:\n        for header_location in header_locations:\n            if os.path.exists(header_location):\n                includes.append(os.path.abspath(header_location))\n                break\n\n    return includes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of libraries to link against.", "response": "def get_libraries():\n    '''return a list of libraries to link against.'''\n    # Note that this list does not include libcsamtools.so as there are\n    # numerous name conflicts with libchtslib.so.\n    dirname = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n    pysam_libs = ['libctabixproxies',\n                  'libcfaidx',\n                  'libcsamfile',\n                  'libcvcf',\n                  'libcbcf',\n                  'libctabix']\n    if pysam.config.HTSLIB == \"builtin\":\n        pysam_libs.append('libchtslib')\n\n    so = sysconfig.get_config_var('SO')\n    return [os.path.join(dirname, x + so) for x in pysam_libs]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds given node to the digraph.", "response": "def add_node(self, node, attrs = None):\n        \"\"\"\n        Add given node to the graph.\n        \n        @attention: While nodes can be of any type, it's strongly recommended to use only\n        numbers and single-line strings as node identifiers if you intend to use write().\n\n        @type  node: node\n        @param node: Node identifier.\n        \n        @type  attrs: list\n        @param attrs: List of node attributes specified as (attribute, value) tuples.\n        \"\"\"\n        if attrs is None:\n            attrs = []\n        if (node not in self.node_neighbors):\n            self.node_neighbors[node] = []\n            self.node_incidence[node] = []\n            self.node_attr[node] = attrs\n        else:\n            raise AdditionError(\"Node %s already in digraph\" % node)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_node(self, node):\n        for each in list(self.incidents(node)):\n            # Delete all the edges incident on this node\n            self.del_edge((each, node))\n            \n        for each in list(self.neighbors(node)):\n            # Delete all the edges pointing to this node.\n            self.del_edge((node, each))\n        \n        # Remove this node from the neighbors and incidents tables   \n        del(self.node_neighbors[node])\n        del(self.node_incidence[node])\n        \n        # Remove any labeling which may exist.\n        self.del_node_labeling( node )", "response": "Removes a node from the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning whether an edge exists.", "response": "def has_edge(self, edge):\n        \"\"\"\n        Return whether an edge exists.\n\n        @type  edge: tuple\n        @param edge: Edge.\n\n        @rtype:  boolean\n        @return: Truth-value for edge existence.\n        \"\"\"\n        u, v = edge\n        return (u, v) in self.edge_properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_package_data(data, buf, format_=FileFormat.py, skip_attributes=None):\n    if format_ == FileFormat.txt:\n        raise ValueError(\"'txt' format not supported for packages.\")\n\n    data_ = dict((k, v) for k, v in data.iteritems() if v is not None)\n    data_ = package_serialise_schema.validate(data_)\n    skip = set(skip_attributes or [])\n\n    items = []\n    for key in package_key_order:\n        if key not in skip:\n            value = data_.pop(key, None)\n            if value is not None:\n                items.append((key, value))\n\n    # remaining are arbitrary keys\n    for key, value in data_.iteritems():\n        if key not in skip:\n            items.append((key, value))\n\n    dump_func = dump_functions[format_]\n    dump_func(items, buf)", "response": "Write package data to buf."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a Makefile - style file and return a dictionary containing name and value pairs.", "response": "def _parse_makefile(filename, vars=None):\n    \"\"\"Parse a Makefile-style file.\n\n    A dictionary containing name/value pairs is returned.  If an\n    optional dictionary is passed in as the second argument, it is\n    used instead of a new dictionary.\n    \"\"\"\n    # Regexes needed for parsing Makefile (and similar syntaxes,\n    # like old-style Setup files).\n    _variable_rx = re.compile(\"([a-zA-Z][a-zA-Z0-9_]+)\\s*=\\s*(.*)\")\n    _findvar1_rx = re.compile(r\"\\$\\(([A-Za-z][A-Za-z0-9_]*)\\)\")\n    _findvar2_rx = re.compile(r\"\\${([A-Za-z][A-Za-z0-9_]*)}\")\n\n    if vars is None:\n        vars = {}\n    done = {}\n    notdone = {}\n\n    with codecs.open(filename, encoding='utf-8', errors=\"surrogateescape\") as f:\n        lines = f.readlines()\n\n    for line in lines:\n        if line.startswith('#') or line.strip() == '':\n            continue\n        m = _variable_rx.match(line)\n        if m:\n            n, v = m.group(1, 2)\n            v = v.strip()\n            # `$$' is a literal `$' in make\n            tmpv = v.replace('$$', '')\n\n            if \"$\" in tmpv:\n                notdone[n] = v\n            else:\n                try:\n                    v = int(v)\n                except ValueError:\n                    # insert literal `$'\n                    done[n] = v.replace('$$', '$')\n                else:\n                    done[n] = v\n\n    # do variable interpolation here\n    variables = list(notdone.keys())\n\n    # Variables with a 'PY_' prefix in the makefile. These need to\n    # be made available without that prefix through sysconfig.\n    # Special care is needed to ensure that variable expansion works, even\n    # if the expansion uses the name without a prefix.\n    renamed_variables = ('CFLAGS', 'LDFLAGS', 'CPPFLAGS')\n\n    while len(variables) > 0:\n        for name in tuple(variables):\n            value = notdone[name]\n            m = _findvar1_rx.search(value) or _findvar2_rx.search(value)\n            if m is not None:\n                n = m.group(1)\n                found = True\n                if n in done:\n                    item = str(done[n])\n                elif n in notdone:\n                    # get it on a subsequent round\n                    found = False\n                elif n in os.environ:\n                    # do it like make: fall back to environment\n                    item = os.environ[n]\n\n                elif n in renamed_variables:\n                    if (name.startswith('PY_') and\n                        name[3:] in renamed_variables):\n                        item = \"\"\n\n                    elif 'PY_' + n in notdone:\n                        found = False\n\n                    else:\n                        item = str(done['PY_' + n])\n\n                else:\n                    done[n] = item = \"\"\n\n                if found:\n                    after = value[m.end():]\n                    value = value[:m.start()] + item + after\n                    if \"$\" in after:\n                        notdone[name] = value\n                    else:\n                        try:\n                            value = int(value)\n                        except ValueError:\n                            done[name] = value.strip()\n                        else:\n                            done[name] = value\n                        variables.remove(name)\n\n                        if (name.startswith('PY_') and\n                            name[3:] in renamed_variables):\n\n                            name = name[3:]\n                            if name not in done:\n                                done[name] = value\n\n            else:\n                # bogus variable reference (e.g. \"prefix=$/opt/python\");\n                # just drop it since we can't deal\n                done[name] = value\n                variables.remove(name)\n\n    # strip spurious spaces\n    for k, v in done.items():\n        if isinstance(v, str):\n            done[k] = v.strip()\n\n    # save the results in the global dictionary\n    vars.update(done)\n    return vars"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of all configuration variables relevant for the current platform.", "response": "def get_config_vars(*args):\n    \"\"\"With no arguments, return a dictionary of all configuration\n    variables relevant for the current platform.\n\n    On Unix, this means every variable defined in Python's installed Makefile;\n    On Windows and Mac OS it's a much smaller set.\n\n    With arguments, return a list of values that result from looking up\n    each argument in the configuration variable dictionary.\n    \"\"\"\n    global _CONFIG_VARS\n    if _CONFIG_VARS is None:\n        _CONFIG_VARS = {}\n        # Normalized versions of prefix and exec_prefix are handy to have;\n        # in fact, these are the standard versions used most places in the\n        # distutils2 module.\n        _CONFIG_VARS['prefix'] = _PREFIX\n        _CONFIG_VARS['exec_prefix'] = _EXEC_PREFIX\n        _CONFIG_VARS['py_version'] = _PY_VERSION\n        _CONFIG_VARS['py_version_short'] = _PY_VERSION_SHORT\n        _CONFIG_VARS['py_version_nodot'] = _PY_VERSION[0] + _PY_VERSION[2]\n        _CONFIG_VARS['base'] = _PREFIX\n        _CONFIG_VARS['platbase'] = _EXEC_PREFIX\n        _CONFIG_VARS['projectbase'] = _PROJECT_BASE\n        try:\n            _CONFIG_VARS['abiflags'] = sys.abiflags\n        except AttributeError:\n            # sys.abiflags may not be defined on all platforms.\n            _CONFIG_VARS['abiflags'] = ''\n\n        if os.name in ('nt', 'os2'):\n            _init_non_posix(_CONFIG_VARS)\n        if os.name == 'posix':\n            _init_posix(_CONFIG_VARS)\n        # Setting 'userbase' is done below the call to the\n        # init function to enable using 'get_config_var' in\n        # the init-function.\n        if sys.version >= '2.6':\n            _CONFIG_VARS['userbase'] = _getuserbase()\n\n        if 'srcdir' not in _CONFIG_VARS:\n            _CONFIG_VARS['srcdir'] = _PROJECT_BASE\n        else:\n            _CONFIG_VARS['srcdir'] = _safe_realpath(_CONFIG_VARS['srcdir'])\n\n        # Convert srcdir into an absolute path if it appears necessary.\n        # Normally it is relative to the build directory.  However, during\n        # testing, for example, we might be running a non-installed python\n        # from a different directory.\n        if _PYTHON_BUILD and os.name == \"posix\":\n            base = _PROJECT_BASE\n            try:\n                cwd = os.getcwd()\n            except OSError:\n                cwd = None\n            if (not os.path.isabs(_CONFIG_VARS['srcdir']) and\n                base != cwd):\n                # srcdir is relative and we are not in the same directory\n                # as the executable. Assume executable is in the build\n                # directory and make srcdir absolute.\n                srcdir = os.path.join(base, _CONFIG_VARS['srcdir'])\n                _CONFIG_VARS['srcdir'] = os.path.normpath(srcdir)\n\n        if sys.platform == 'darwin':\n            kernel_version = os.uname()[2]  # Kernel version (8.4.3)\n            major_version = int(kernel_version.split('.')[0])\n\n            if major_version < 8:\n                # On Mac OS X before 10.4, check if -arch and -isysroot\n                # are in CFLAGS or LDFLAGS and remove them if they are.\n                # This is needed when building extensions on a 10.3 system\n                # using a universal build of python.\n                for key in ('LDFLAGS', 'BASECFLAGS',\n                        # a number of derived variables. These need to be\n                        # patched up as well.\n                        'CFLAGS', 'PY_CFLAGS', 'BLDSHARED'):\n                    flags = _CONFIG_VARS[key]\n                    flags = re.sub('-arch\\s+\\w+\\s', ' ', flags)\n                    flags = re.sub('-isysroot [^ \\t]*', ' ', flags)\n                    _CONFIG_VARS[key] = flags\n            else:\n                # Allow the user to override the architecture flags using\n                # an environment variable.\n                # NOTE: This name was introduced by Apple in OSX 10.5 and\n                # is used by several scripting languages distributed with\n                # that OS release.\n                if 'ARCHFLAGS' in os.environ:\n                    arch = os.environ['ARCHFLAGS']\n                    for key in ('LDFLAGS', 'BASECFLAGS',\n                        # a number of derived variables. These need to be\n                        # patched up as well.\n                        'CFLAGS', 'PY_CFLAGS', 'BLDSHARED'):\n\n                        flags = _CONFIG_VARS[key]\n                        flags = re.sub('-arch\\s+\\w+\\s', ' ', flags)\n                        flags = flags + ' ' + arch\n                        _CONFIG_VARS[key] = flags\n\n                # If we're on OSX 10.5 or later and the user tries to\n                # compiles an extension using an SDK that is not present\n                # on the current machine it is better to not use an SDK\n                # than to fail.\n                #\n                # The major usecase for this is users using a Python.org\n                # binary installer  on OSX 10.6: that installer uses\n                # the 10.4u SDK, but that SDK is not installed by default\n                # when you install Xcode.\n                #\n                CFLAGS = _CONFIG_VARS.get('CFLAGS', '')\n                m = re.search('-isysroot\\s+(\\S+)', CFLAGS)\n                if m is not None:\n                    sdk = m.group(1)\n                    if not os.path.exists(sdk):\n                        for key in ('LDFLAGS', 'BASECFLAGS',\n                             # a number of derived variables. These need to be\n                             # patched up as well.\n                            'CFLAGS', 'PY_CFLAGS', 'BLDSHARED'):\n\n                            flags = _CONFIG_VARS[key]\n                            flags = re.sub('-isysroot\\s+\\S+(\\s|$)', ' ', flags)\n                            _CONFIG_VARS[key] = flags\n\n    if args:\n        vals = []\n        for name in args:\n            vals.append(_CONFIG_VARS.get(name))\n        return vals\n    else:\n        return _CONFIG_VARS"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_platform():\n    if os.name == 'nt':\n        # sniff sys.version for architecture.\n        prefix = \" bit (\"\n        i = sys.version.find(prefix)\n        if i == -1:\n            return sys.platform\n        j = sys.version.find(\")\", i)\n        look = sys.version[i+len(prefix):j].lower()\n        if look == 'amd64':\n            return 'win-amd64'\n        if look == 'itanium':\n            return 'win-ia64'\n        return sys.platform\n\n    if os.name != \"posix\" or not hasattr(os, 'uname'):\n        # XXX what about the architecture? NT is Intel or Alpha,\n        # Mac OS is M68k or PPC, etc.\n        return sys.platform\n\n    # Try to distinguish various flavours of Unix\n    osname, host, release, version, machine = os.uname()\n\n    # Convert the OS name to lowercase, remove '/' characters\n    # (to accommodate BSD/OS), and translate spaces (for \"Power Macintosh\")\n    osname = osname.lower().replace('/', '')\n    machine = machine.replace(' ', '_')\n    machine = machine.replace('/', '-')\n\n    if osname[:5] == \"linux\":\n        # At least on Linux/Intel, 'machine' is the processor --\n        # i386, etc.\n        # XXX what about Alpha, SPARC, etc?\n        return  \"%s-%s\" % (osname, machine)\n    elif osname[:5] == \"sunos\":\n        if release[0] >= \"5\":           # SunOS 5 == Solaris 2\n            osname = \"solaris\"\n            release = \"%d.%s\" % (int(release[0]) - 3, release[2:])\n        # fall through to standard osname-release-machine representation\n    elif osname[:4] == \"irix\":              # could be \"irix64\"!\n        return \"%s-%s\" % (osname, release)\n    elif osname[:3] == \"aix\":\n        return \"%s-%s.%s\" % (osname, version, release)\n    elif osname[:6] == \"cygwin\":\n        osname = \"cygwin\"\n        rel_re = re.compile(r'[\\d.]+')\n        m = rel_re.match(release)\n        if m:\n            release = m.group()\n    elif osname[:6] == \"darwin\":\n        #\n        # For our purposes, we'll assume that the system version from\n        # distutils' perspective is what MACOSX_DEPLOYMENT_TARGET is set\n        # to. This makes the compatibility story a bit more sane because the\n        # machine is going to compile and link as if it were\n        # MACOSX_DEPLOYMENT_TARGET.\n        cfgvars = get_config_vars()\n        macver = cfgvars.get('MACOSX_DEPLOYMENT_TARGET')\n\n        if True:\n            # Always calculate the release of the running machine,\n            # needed to determine if we can build fat binaries or not.\n\n            macrelease = macver\n            # Get the system version. Reading this plist is a documented\n            # way to get the system version (see the documentation for\n            # the Gestalt Manager)\n            try:\n                f = open('/System/Library/CoreServices/SystemVersion.plist')\n            except IOError:\n                # We're on a plain darwin box, fall back to the default\n                # behaviour.\n                pass\n            else:\n                try:\n                    m = re.search(r'<key>ProductUserVisibleVersion</key>\\s*'\n                                  r'<string>(.*?)</string>', f.read())\n                finally:\n                    f.close()\n                if m is not None:\n                    macrelease = '.'.join(m.group(1).split('.')[:2])\n                # else: fall back to the default behaviour\n\n        if not macver:\n            macver = macrelease\n\n        if macver:\n            release = macver\n            osname = \"macosx\"\n\n            if ((macrelease + '.') >= '10.4.' and\n                '-arch' in get_config_vars().get('CFLAGS', '').strip()):\n                # The universal build will build fat binaries, but not on\n                # systems before 10.4\n                #\n                # Try to detect 4-way universal builds, those have machine-type\n                # 'universal' instead of 'fat'.\n\n                machine = 'fat'\n                cflags = get_config_vars().get('CFLAGS')\n\n                archs = re.findall('-arch\\s+(\\S+)', cflags)\n                archs = tuple(sorted(set(archs)))\n\n                if len(archs) == 1:\n                    machine = archs[0]\n                elif archs == ('i386', 'ppc'):\n                    machine = 'fat'\n                elif archs == ('i386', 'x86_64'):\n                    machine = 'intel'\n                elif archs == ('i386', 'ppc', 'x86_64'):\n                    machine = 'fat3'\n                elif archs == ('ppc64', 'x86_64'):\n                    machine = 'fat64'\n                elif archs == ('i386', 'ppc', 'ppc64', 'x86_64'):\n                    machine = 'universal'\n                else:\n                    raise ValueError(\n                       \"Don't know machine value for archs=%r\" % (archs,))\n\n            elif machine == 'i386':\n                # On OSX the machine type returned by uname is always the\n                # 32-bit variant, even if the executable architecture is\n                # the 64-bit variant\n                if sys.maxsize >= 2**32:\n                    machine = 'x86_64'\n\n            elif machine in ('PowerPC', 'Power_Macintosh'):\n                # Pick a sane name for the PPC architecture.\n                # See 'i386' case\n                if sys.maxsize >= 2**32:\n                    machine = 'ppc64'\n                else:\n                    machine = 'ppc'\n\n    return \"%s-%s-%s\" % (osname, release, machine)", "response": "Returns a string that identifies the current platform."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd authors attribute based on repo contributions", "response": "def set_authors(data):\n    \"\"\"Add 'authors' attribute based on repo contributions\n    \"\"\"\n    if \"authors\" in data:\n        return\n\n    shfile = os.path.join(os.path.dirname(__file__), \"get_committers.sh\")\n\n    p = subprocess.Popen([\"bash\", shfile], stdout=subprocess.PIPE)\n    out, _ = p.communicate()\n    if p.returncode:\n        return\n\n    authors = out.strip().split('\\n')\n    authors = [x.strip() for x in authors]\n\n    data[\"authors\"] = authors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking and install a package into the repository.", "response": "def make_package(name, path, make_base=None, make_root=None, skip_existing=True,\n                 warn_on_skip=True):\n    \"\"\"Make and install a package.\n\n    Example:\n\n        >>> def make_root(variant, path):\n        >>>     os.symlink(\"/foo_payload/misc/python27\", \"ext\")\n        >>>\n        >>> with make_package('foo', '/packages', make_root=make_root) as pkg:\n        >>>     pkg.version = '1.0.0'\n        >>>     pkg.description = 'does foo things'\n        >>>     pkg.requires = ['python-2.7']\n\n    Args:\n        name (str): Package name.\n        path (str): Package repository path to install package into.\n        make_base (callable): Function that is used to create the package\n            payload, if applicable.\n        make_root (callable): Function that is used to create the package\n            variant payloads, if applicable.\n        skip_existing (bool): If True, detect if a variant already exists, and\n            skip with a warning message if so.\n        warn_on_skip (bool): If True, print warning when a variant is skipped.\n\n    Yields:\n        `PackageMaker` object.\n\n    Note:\n        Both `make_base` and `make_root` are called once per variant install,\n        and have the signature (variant, path).\n\n    Note:\n        The 'installed_variants' attribute on the `PackageMaker` instance will\n        be appended with variant(s) created by this function, if any.\n    \"\"\"\n    maker = PackageMaker(name)\n    yield maker\n\n    # post-with-block:\n    #\n\n    package = maker.get_package()\n    cwd = os.getcwd()\n    src_variants = []\n\n    # skip those variants that already exist\n    if skip_existing:\n        for variant in package.iter_variants():\n            variant_ = variant.install(path, dry_run=True)\n            if variant_ is None:\n                src_variants.append(variant)\n            else:\n                maker.skipped_variants.append(variant_)\n                if warn_on_skip:\n                    print_warning(\"Skipping installation: Package variant already \"\n                                  \"exists: %s\" % variant_.uri)\n    else:\n        src_variants = package.iter_variants()\n\n    with retain_cwd():\n        # install the package variant(s) into the filesystem package repo at `path`\n        for variant in src_variants:\n            variant_ = variant.install(path)\n\n            base = variant_.base\n            if make_base and base:\n                if not os.path.exists(base):\n                    os.makedirs(base)\n                os.chdir(base)\n                make_base(variant_, base)\n\n            root = variant_.root\n            if make_root and root:\n                if not os.path.exists(root):\n                    os.makedirs(root)\n                os.chdir(root)\n                make_root(variant_, root)\n\n            maker.installed_variants.append(variant_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the analogous package.", "response": "def get_package(self):\n        \"\"\"Create the analogous package.\n\n        Returns:\n            `Package` object.\n        \"\"\"\n        # get and validate package data\n        package_data = self._get_data()\n        package_data = package_schema.validate(package_data)\n\n        # check compatibility with rez version\n        if \"requires_rez_version\" in package_data:\n            ver = package_data.pop(\"requires_rez_version\")\n\n            if _rez_Version < ver:\n                raise PackageMetadataError(\n                    \"Failed reading package definition file: rez version >= %s \"\n                    \"needed (current version is %s)\" % (ver, _rez_Version))\n\n        # create a 'memory' package repository containing just this package\n        version_str = package_data.get(\"version\") or \"_NO_VERSION\"\n        repo_data = {self.name: {version_str: package_data}}\n        repo = create_memory_package_repository(repo_data)\n\n        # retrieve the package from the new repository\n        family_resource = repo.get_package_family(self.name)\n        it = repo.iter_packages(family_resource)\n        package_resource = it.next()\n\n        package = self.package_cls(package_resource)\n\n        # revalidate the package for extra measure\n        package.validate_data()\n        return package"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the current column within a string counting newlines as line separators.", "response": "def col (loc,strg):\r\n    \"\"\"Returns current column within a string, counting newlines as line separators.\r\n   The first column is number 1.\r\n\r\n   Note: the default parsing behavior is to expand tabs in the input string\r\n   before starting the parsing process.  See L{I{ParserElement.parseString}<ParserElement.parseString>} for more information\r\n   on parsing strings containing C{<TAB>}s, and suggested methods to maintain a\r\n   consistent view of the parsed string, the parse location, and line and column\r\n   positions within the parsed string.\r\n   \"\"\"\r\n    return (loc<len(strg) and strg[loc] == '\\n') and 1 or loc - strg.rfind(\"\\n\", 0, loc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef countedArray( expr, intExpr=None ):\r\n    arrayExpr = Forward()\r\n    def countFieldParseAction(s,l,t):\r\n        n = t[0]\r\n        arrayExpr << (n and Group(And([expr]*n)) or Group(empty))\r\n        return []\r\n    if intExpr is None:\r\n        intExpr = Word(nums).setParseAction(lambda t:int(t[0]))\r\n    else:\r\n        intExpr = intExpr.copy()\r\n    intExpr.setName(\"arrayLen\")\r\n    intExpr.addParseAction(countFieldParseAction, callDuringTry=True)\r\n    return ( intExpr + arrayExpr )", "response": "Returns a new expression that counts the number of times expr is matched."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matchPreviousLiteral(expr):\r\n    rep = Forward()\r\n    def copyTokenToRepeater(s,l,t):\r\n        if t:\r\n            if len(t) == 1:\r\n                rep << t[0]\r\n            else:\r\n                # flatten t tokens\r\n                tflat = _flatten(t.asList())\r\n                rep << And( [ Literal(tt) for tt in tflat ] )\r\n        else:\r\n            rep << Empty()\r\n    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)\r\n    return rep", "response": "Returns an expression that is indirectly defined from\r\n       the tokens matched in a previous expression that looks\r\n       for a repeat of a previous literal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keepOriginalText(s,startLoc,t):\r\n    try:\r\n        endloc = getTokensEndLoc()\r\n    except ParseException:\r\n        raise ParseFatalException(\"incorrect usage of keepOriginalText - may only be called as a parse action\")\r\n    del t[:]\r\n    t += ParseResults(s[startLoc:endloc])\r\n    return t", "response": "DEPRECATED - use new helper method to preserve original parsed text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTokensEndLoc():\r\n    import inspect\r\n    fstack = inspect.stack()\r\n    try:\r\n        # search up the stack (through intervening argument normalizers) for correct calling routine\r\n        for f in fstack[2:]:\r\n            if f[3] == \"_parseNoCache\":\r\n                endloc = f[0].f_locals[\"loc\"]\r\n                return endloc\r\n        else:\r\n            raise ParseFatalException(\"incorrect usage of getTokensEndLoc - may only be called from within a parse action\")\r\n    finally:\r\n        del fstack", "response": "Method to determine the end of the token list in the parse action."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asList( self ):\r\n        out = []\r\n        for res in self.__toklist:\r\n            if isinstance(res,ParseResults):\r\n                out.append( res.asList() )\r\n            else:\r\n                out.append( res )\r\n        return out", "response": "Returns the parse results as a nested list of matching tokens all converted to strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump(self,indent='',depth=0):\r\n        out = []\r\n        out.append( indent+_ustr(self.asList()) )\r\n        keys = self.items()\r\n        keys.sort()\r\n        for k,v in keys:\r\n            if out:\r\n                out.append('\\n')\r\n            out.append( \"%s%s- %s: \" % (indent,('  '*depth), k) )\r\n            if isinstance(v,ParseResults):\r\n                if v.keys():\r\n                    out.append( v.dump(indent,depth+1) )\r\n                else:\r\n                    out.append(_ustr(v))\r\n            else:\r\n                out.append(_ustr(v))\r\n        return \"\".join(out)", "response": "Diagnostic method for listing out the contents of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setParseAction( self, *fns, **kwargs ):\r\n        self.parseAction = list(map(_trim_arity, list(fns)))\r\n        self.callDuringTry = (\"callDuringTry\" in kwargs and kwargs[\"callDuringTry\"])\r\n        return self", "response": "Define action to perform when successfully matching parse element definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schema_keys(schema):\n    def _get_leaf(value):\n        if isinstance(value, Schema):\n            return _get_leaf(value._schema)\n        return value\n\n    keys = set()\n    dict_ = schema._schema\n    assert isinstance(dict_, dict)\n\n    for key in dict_.iterkeys():\n        key_ = _get_leaf(key)\n        if isinstance(key_, basestring):\n            keys.add(key_)\n\n    return keys", "response": "Get the string values of keys in a dict - based schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_to_schema(schema_dict, required, allow_custom_keys=True, modifier=None):\n    if modifier:\n        modifier = Use(modifier)\n\n    def _to(value):\n        if isinstance(value, dict):\n            d = {}\n            for k, v in value.iteritems():\n                if isinstance(k, basestring):\n                    k = Required(k) if required else Optional(k)\n                d[k] = _to(v)\n            if allow_custom_keys:\n                d[Optional(basestring)] = modifier or object\n            schema = Schema(d)\n        elif modifier:\n            schema = And(value, modifier)\n        else:\n            schema = value\n        return schema\n\n    return _to(schema_dict)", "response": "Convert a dict of Schemas into a Schema object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenters diff mode. Args: context_model (`ContextModel`): Context to diff against. If None, a copy of the current context is used.", "response": "def enter_diff_mode(self, context_model=None):\n        \"\"\"Enter diff mode.\n\n        Args:\n            context_model (`ContextModel`): Context to diff against. If None, a\n            copy of the current context is used.\n        \"\"\"\n        assert not self.diff_mode\n        self.diff_mode = True\n\n        if context_model is None:\n            self.diff_from_source = True\n            self.diff_context_model = self.context_model.copy()\n        else:\n            self.diff_from_source = False\n            self.diff_context_model = context_model\n\n        self.clear()\n        self.setColumnCount(5)\n        self.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_title(self):\n        def _title(context_model):\n            context = context_model.context()\n            if context is None:\n                return \"new context*\"\n            title = os.path.basename(context.load_path) if context.load_path \\\n                else \"new context\"\n            if context_model.is_modified():\n                title += '*'\n            return title\n\n        if self.diff_mode:\n            diff_title = _title(self.diff_context_model)\n            if self.diff_from_source:\n                diff_title += \"'\"\n            return \"%s  %s  %s\" % (_title(self.context_model),\n                                   self.short_double_arrow, diff_title)\n        else:\n            return _title(self.context_model)", "response": "Returns a string suitable for titling a window containing this table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _color_level(str_, level):\n    fore_color, back_color, styles = _get_style_from_config(level)\n    return _color(str_, fore_color, back_color, styles)", "response": "Return the string wrapped with the appropriate styling for the message\n    level."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the string wrapped with the appropriate color escape sequences.", "response": "def _color(str_, fore_color=None, back_color=None, styles=None):\n    \"\"\" Return the string wrapped with the appropriate styling escape sequences.\n\n    Args:\n      str_ (str): The string to be wrapped.\n      fore_color (str, optional): Any foreground color supported by the\n        `Colorama`_ module.\n      back_color (str, optional): Any background color supported by the\n        `Colorama`_ module.\n      styles (list of str, optional): Any styles supported by the `Colorama`_\n        module.\n\n    Returns:\n      str: The string styled with the appropriate escape sequences.\n\n    .. _Colorama:\n        https://pypi.python.org/pypi/colorama\n    \"\"\"\n    # TODO: Colorama is documented to work on Windows and trivial test case\n    # proves this to be the case, but it doesn't work in Rez.  If the initialise\n    # is called in sec/rez/__init__.py then it does work, however as discussed\n    # in the following comment this is not always desirable.  So until we can\n    # work out why we forcibly turn it off.\n    if not config.get(\"color_enabled\", False) or platform_.name == \"windows\":\n        return str_\n\n    # lazily init colorama. This is important - we don't want to init at startup,\n    # because colorama prints a RESET_ALL character atexit. This in turn adds\n    # unexpected output when capturing the output of a command run in a\n    # ResolvedContext, for example.\n    _init_colorama()\n\n    colored = \"\"\n    if not styles:\n        styles = []\n\n    if fore_color:\n        colored += getattr(colorama.Fore, fore_color.upper(), '')\n    if back_color:\n        colored += getattr(colorama.Back, back_color.upper(), '')\n    for style in styles:\n        colored += getattr(colorama.Style, style.upper(), '')\n\n    return colored + str_ + colorama.Style.RESET_ALL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemitting a record. If the stream associated with this handler provides tty then the record that is emitted with be formatted to include escape sequences for appropriate styling.", "response": "def emit(self, record):\n        \"\"\"Emit a record.\n\n        If the stream associated with this handler provides tty then the record\n        that is emitted with be formatted to include escape sequences for\n        appropriate styling.\n        \"\"\"\n        try:\n            message = self.format(record)\n\n            if not self.is_colorized:\n                self.stream.write(message)\n            else:\n                style = self._get_style_function_for_level(record.levelno)\n                self.stream.write(style(message))\n\n            self.stream.write(getattr(self, 'terminator', '\\n'))\n            self.flush()\n\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing by functions in package.py that are evaluated lazily. The term 'late' refers to the fact these package attributes are evaluated late, ie when the attribute is queried for the first time. If you want to implement a package.py attribute as a function, you MUST use this decorator - otherwise it is understood that you want your attribute to be a function, not the return value of that function.", "response": "def late():\n    \"\"\"Used by functions in package.py that are evaluated lazily.\n\n    The term 'late' refers to the fact these package attributes are evaluated\n    late, ie when the attribute is queried for the first time.\n\n    If you want to implement a package.py attribute as a function, you MUST use\n    this decorator - otherwise it is understood that you want your attribute to\n    be a function, not the return value of that function.\n    \"\"\"\n    from rez.package_resources_ import package_rex_keys\n\n    def decorated(fn):\n\n        # this is done here rather than in standard schema validation because\n        # the latter causes a very obfuscated error message\n        if fn.__name__ in package_rex_keys:\n            raise ValueError(\"Cannot use @late decorator on function '%s'\"\n                             % fn.__name__)\n\n        setattr(fn, \"_late\", True)\n        _add_decorator(fn, \"late\")\n        return fn\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses by functions in package.py to have access to named modules. See the 'package_definition_python_path' config setting for more info.", "response": "def include(module_name, *module_names):\n    \"\"\"Used by functions in package.py to have access to named modules.\n\n    See the 'package_definition_python_path' config setting for more info.\n    \"\"\"\n    def decorated(fn):\n        _add_decorator(fn, \"include\", nargs=[module_name] + list(module_names))\n        return fn\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_package_families(paths=None):\n    for path in (paths or config.packages_path):\n        repo = package_repository_manager.get_repository(path)\n        for resource in repo.iter_package_families():\n            yield PackageFamily(resource)", "response": "Iterate over package families in no particular order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_packages(name, range_=None, paths=None):\n    entries = _get_families(name, paths)\n\n    seen = set()\n    for repo, family_resource in entries:\n        for package_resource in repo.iter_packages(family_resource):\n            key = (package_resource.name, package_resource.version)\n            if key in seen:\n                continue\n\n            seen.add(key)\n            if range_:\n                if isinstance(range_, basestring):\n                    range_ = VersionRange(range_)\n                if package_resource.version not in range_:\n                    continue\n\n            yield Package(package_resource)", "response": "Iterate over all packages in a specific order."}
